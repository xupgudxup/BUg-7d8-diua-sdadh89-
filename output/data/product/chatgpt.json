[
  {
    "slug": "openais-house-of-cards-seems-primed-to-collapse",
    "title": "OpenAI's house of cards seems primed to collapse",
    "description": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.",
    "fullText": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.\n\nBack in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo.\n\nBut it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy.\n\nSince then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.\n\nIn response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss.\n\nIt's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI.\n\nAnthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Informationsaid Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings.\n\nHowever, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI.\n\nAccording to a December 2 report from TheWall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic.\n\nThe few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator.\n\nMore importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year.\n\nIn an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.\n\nSince late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well.\n\n\"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.\n\nGita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels.\n\nThe modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment.",
    "readingTime": 6,
    "keywords": [
      "code red",
      "search giant",
      "openai",
      "chatbot",
      "model",
      "models",
      "memory",
      "release",
      "google",
      "released"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/chatgpt/article/openais-house-cards-seems-primed-170000383.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/GqARrc67JCVOPZqPZmGxVA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/engadget_703/4fd0cc3b2f10735e6ff000f551d8a08e",
    "created_at": "2025-12-11T13:53:36.420Z",
    "topic": "tech"
  },
  {
    "slug": "even-the-man-behind-chatgpt-openai-ceo-sam-altman-is-worried",
    "title": "Even the man behind ChatGPT, OpenAI CEO Sam Altman, is worried about the ‘rate of change that’s happening in the world right now’ thanks to AI",
    "description": "Sam Altman admits the rise of ChatGPT may be moving too quickly for comfort as AI shakes up jobs, education, and the global economy.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/openai-ceo-sam-altman-worried-about-ai-future-chatgpt-pros-cons-rate-of-change-future-of-work-uncertain/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Altman-Fallon.png?resize=1200,600",
    "created_at": "2025-12-09T18:53:37.578Z",
    "topic": "business"
  },
  {
    "slug": "sam-altman-makes-his-latenight-debut-says-he-cant-imagine-fi",
    "title": "Sam Altman makes his late-night debut, says he can't imagine 'figuring out how to raise a newborn without ChatGPT'",
    "description": "In his first-ever late-night TV appearance, OpenAI CEO Sam Altman talked about how ChatGPT has reassured him as he raises his newborn.",
    "fullText": "OpenAI CEO Sam Altman says his most famous product has helped him manage life as an actual parent.\n\n\"I cannot imagine having gone through, figuring out how to raise a newborn without ChatGPT,\" Altman told Jimmy Fallon during an interview on NBC's flagship late-night talk show. \"Clearly, people did it for a long time — no problem.\"\n\nAltman said he feels \"kind of bad\" asking a technology that boasts such wide-knowledge questions like, \"Why does my kid stop dropping pizza on the floor and laughing?\"\n\nAnother example, Altman said, was a couple of months ago when he was at a party talking to someone who was also raising a newborn. Altman recalled that the parents said their six-month-old was \"crawling everywhere.\" Altman said he grew concerned that his son was not at the same stage.\n\n\"I ran to the bathroom, and I was like, do I need to take my kid to the doctor tomorrow morning?\" Altman said, describing what he typed into ChatGPT: \"Is this okay?\"\n\nAltman said OpenAI's chatbot responded \"with a great answer, which was of course,\" his son's development was \"normal.\"\n\n\"It is personalized, like ChatGPT gets to know you, and by the way, you're the CEO of OpenAI, you probably are around all these high-achieving people, maybe you don't want to project that onto your kid, and you should just relax, and he'll be fine, whatever,\" Altman told Fallon of the answer.\n\nFallon didn't touch on OpenAI's recent struggles. Last week, Altman reportedly declared a \"code red\" in a private message to employees, ordering a greater focus on ChatGPT as competitors like Google make significant advancements with their competing AI models.\n\nInstead, Altman's late-night debut featured the lighthearted fare that's standard on late-night TV. At one point, Fallon asked Altman to explain what ChatGPT is in case viewers who were unaware, including the host's dad, might be watching.\n\nAltman has spoken in the past about how becoming a parent has added another lens to his outlook on AI.\n\n\"My kid is never going to grow up being smarter than AI,\" Altman said during a January episode of the \"Re:Thinking\" podcast with Adam Grant. \"Children in the future will only know a world with AI in it.\"\n\nThe OpenAI CEO and his husband, Oliver Mulherin, welcomed their son in February with an announcement on X. Despite Altman's stature, the couple has led a relatively private life.\n\nFallon, who has two daughters, also joked with Altman about when their kids reached certain developmental milestones, like crawling.\n\n\"Mine was on Dancing with the Stars at seven months,\" Fallon said. \"Semi-finalist.\"",
    "readingTime": 3,
    "keywords": [
      "openai ceo",
      "altman",
      "late-night",
      "life",
      "parent",
      "newborn",
      "another",
      "couple",
      "crawling",
      "openai's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-chatgpt-parenting-jimmy-fallon-2025-12",
    "thumbnail_url": "https://i.insider.com/6938471f04d0f0a114f1aa45?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:36.497Z",
    "topic": "finance"
  },
  {
    "slug": "i-feel-its-a-friend-quarter-of-teenagers-turn-to-ai-chatbots",
    "title": "‘I feel it’s a friend’: quarter of teenagers turn to AI chatbots for mental health support",
    "description": "Experts warn of dangers as England and Wales study shows 13- to 17-year-olds consulting AI amid long waiting lists for services\nIt was after one friend was shot and another stabbed, both fatally, that Shan asked ChatGPT for help. She had tried conventional mental health services but “chat”, as she came to know her AI “friend”, felt safer, less intimidating and, crucially, more available when it came to handling the trauma from the deaths of her young friends.\nAs she started consulting the AI model, the Tottenham teenager joined about 40% of 13- to 17-year-olds in England and Wales affected by youth violence who are turning to AI chatbots for mental health support, according to research among more than 11,000 young people.\n Continue reading...",
    "fullText": "Experts warn of dangers as England and Wales study shows 13- to 17-year-olds consulting AI amid long waiting lists for services\n\nIt was after one friend was shot and another stabbed, both fatally, that Shan asked ChatGPT for help. She had tried conventional mental health services but “chat”, as she came to know her AI “friend”, felt safer, less intimidating and, crucially, more available when it came to handling the trauma from the deaths of her young friends.\n\nAs she started consulting the AI model, the Tottenham teenager joined about 40% of 13- to 17-year-olds in England and Wales affected by youth violence who are turning to AI chatbots for mental health support, according to research among more than 11,000 young people.\n\nIt found that both victims and perpetrators of violence were markedly more likely to be using AI for such support than other teenagers. The findings, from the Youth Endowment Fund, have sparked warnings from youth leaders that children at risk “need a human not a bot”.\n\nThe results suggest chatbots are fulfilling demand unmet by conventional mental health services, which have long waiting lists and which some young users find lacking in empathy. The supposed privacy of the chatbot is another key factor in driving use by victims or perpetrators of crimes.\n\nAfter her friends were killed Shan, 18, not her real name, started using Snapchat’s AI before switching to ChatGPT, which she can talk to at any time of day or night with two clicks on her smartphone.\n\n“I feel like it definitely is a friend,” she said, adding that it was less intimidating, more private and less judgmental than her experience with conventional NHS and charity mental health support.\n\n“The more you talk to it like a friend it will be talking to you like a friend back. If I say to chat ‘Hey bestie, I need some advice’. Chat will talk back to me like it’s my best friend, she’ll say, ‘Hey bestie, I got you girl’.”\n\nOne in four of 13- to 17-year-olds have used an AI chatbot for mental health support in the past year, with black children twice as likely as white children to have done so, the study found. Teenagers were more likely to go online for support, including using AI, if they were on a waiting list for treatment or diagnosis or had been denied, than if they were already receiving in-person support.\n\nCrucially, Shan said, the AI was “accessible 24/7” and would not tell teachers or parents about what she had disclosed. She felt this was a considerable advantage over telling a school therapist, after her own experience of what she thought were confidences being shared with teachers and her mother.\n\nBoys who were involved in gang activities felt safer asking chatbots for advice about other safer ways to make money than a teacher or parent who might leak the information to police or other gang members, putting them in danger, she said.\n\nAnother young person, who has been using AI for mental health support but asked not to be named, told the Guardian: “The current system is so broken for offering help for young people. Chatbots provide immediate answers. If you’re going to be on the waiting list for one to two years to get anything, or you can have an immediate answer within a few minutes … that’s where the desire to use AI comes from.”\n\nJon Yates, the chief executive of the Youth Endowment Fund, which commissioned the research, said: “Too many young people are struggling with their mental health and can’t get the support they need. It’s no surprise that some are turning to technology for help. We have to do better for our children, especially those most at risk. They need a human not a bot.”\n\nThere have been growing concerns about the dangers of chatbots when children engage with them at length. OpenAI, the US company behind ChatGPT, is facing several lawsuits including from families of young people who have killed themselves after long engagements.\n\nIn the case of the Californian 16-year-old Adam Raine, who took his life in April, OpenAI has denied it was caused by the chatbot. It has said it has been improving its technology “to recognise and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.”. The startup said in September it could start contacting authorities in cases where users start talking seriously about suicide.\n\nHanna Jones, a youth violence and mental health researcher in London, said: “To have this tool that could tell you technically anything – it’s almost like a fairytale. You’ve got this magic book that can solve all your problems. That sounds incredible.”\n\nBut she is worried about the lack of regulation.\n\n“People are using ChatGPT for mental health support, when it’s not designed for that,” she said. “What we need now is to increase regulations that are evidence-backed but also youth-led. This is not going to be solved by adults making decisions for young people. Young people need to be in the driving seat to make decisions around ChatGPT and mental health support that uses AI, because it’s so different to our world. We didn’t grow up with this. We can’t even imagine what it is to be a young person today.”",
    "readingTime": 5,
    "keywords": [
      "endowment fund",
      "hey bestie",
      "youth endowment",
      "less intimidating",
      "youth violence",
      "mental health",
      "health services",
      "conventional mental",
      "england and wales",
      "friend"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/09/teenagers-ai-chatbots-mental-health-support",
    "thumbnail_url": "https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a898840ac81c0db6a3d82e6c95d87646",
    "created_at": "2025-12-09T13:48:22.920Z",
    "topic": "tech"
  },
  {
    "slug": "dechecker-detect-aigenerated-text",
    "title": "DeChecker – Detect AI-generated text",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Dechecker instantly detects AI-generated content from models like ChatGPT, GPT-5, Claude, and Gemini 3.0.\nMake your writing 3x more original, 2x more readable, and ensure every piece of content is trustworthy and human-like.\n\nType or paste your text to check.\n\nIn just four simple steps, you can check if your text is AI-generated and transform it into original, human-like content.\n\nInsert your essay, article, blog, or business copy into Dechecker's AI Checker Tool.\n\nAI Checker analyzes your writing and highlights AI-generated patterns, supporting detection for ChatGPT, GPT-5, Claude, and Gemini.\n\nSee the detection score and detailed analysis, showing which parts are likely AI-generated.\n\nGet rewriting suggestions to improve originality, enhance readability, and make your text sound more human.\n\nDechecker's AI Checker helps you detect AI-generated content, enhance originality, and deliver writing that is clear, credible, and human-like.\n\nInstantly detect if your text is AI-generated. Dechecker's AI Checker gives you confidence in the authenticity of your work.\n\nUse the AI Checker to refine repetitive or generic AI writing into unique text that stands out in essays, articles, and business documents.\n\nTransforms robotic phrasing into smooth, natural language, making your writing easier to read and more persuasive.\n\nPublish content verified by the AI Checker that feels authentic, helping you earn credibility with readers, clients, and audiences.\n\nDechecker's AI Checker helps you identify AI-generated text, improve originality, and make your writing natural and credible. Perfect for students, marketers, business professionals, and content creators.\n\nDetect AI-written passages in essays or research papers, ensuring your work maintains authenticity and meets academic integrity standards.\n\nIdentify AI-generated sections in marketing content or blogs, and refine them to improve readability, originality, and search engine performance.\n\nEnsure proposals, presentations, and internal reports are human-like and trustworthy. The AI Checker highlights automated or robotic phrasing for easier revision.\n\nAnalyze content for AI-generated elements in tweets, captions, or posts. Enhance engagement with authentic, natural-sounding messages.\n\nVerify content before delivery to clients, ensuring originality and quality. Use the AI Checker to maintain credibility and reduce risk of AI-generated mistakes.\n\nDetect AI-written content in teaching or training materials, helping educators provide clear, human-written guidance while maintaining learning standards.\n\nThousands of users rely on Dechecker to identify AI-generated text, enhance originality, and improve writing quality.\n\n\"I was unsure if my essay contained AI-generated sentences, but Dechecker's AI Checker pinpointed the exact parts and suggested improvements. My paper feels completely original now!\"\n\n\"Using Dechecker on our blog posts saved us so much time. It highlighted AI-like phrasing and helped rewrite content that now reads completely natural. Highly recommend it!\"\n\n\"As a student, I needed to ensure my assignments were truly my own work. Dechecker's AI Checker made it easy to check for AI-generated content and improve readability. A must-have tool!\"\n\nHave questions about how Dechecker AI Checker works? Here are the answers to the most common queries to help you detect, analyze, and optimize your AI-generated content efficiently.",
    "readingTime": 3,
    "keywords": [
      "generated",
      "content",
      "your",
      "checker",
      "dechecker",
      "writing",
      "text",
      "human",
      "originality",
      "improve"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-09T08:42:55.714Z",
    "topic": "tech"
  }
]
[
  {
    "slug": "training-large-language-models-on-narrow-tasks-can-lead-to-broad-misalignment",
    "title": "Training large language models on narrow tasks can lead to broad misalignment",
    "description": "Finetuning a large language model on a narrow task of writing insecure code causes a broad range of concerning behaviours unrelated to coding.",
    "fullText": "Generating reliable software project task flows using large language models through prompt engineering and robust evaluation\n\n Article\n Open access\n 08 October 2025",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.1,
    "link": "https://www.nature.com/articles/s41586-025-09937-5",
    "thumbnail_url": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-025-09937-5/MediaObjects/41586_2025_9937_Fig1_HTML.png",
    "created_at": "2026-01-16T06:20:12.839Z",
    "topic": "tech"
  },
  {
    "slug": "i-made-over-30000-from-my-side-hustles-this-year-the-extra-money-is-great-but-i-felt-like-i-never-stopped-working",
    "title": "I made over $30,000 from my side hustles this year. The extra money is great, but I felt like I never stopped working.",
    "description": "I made over $33,000 from freelance writing and teaching mahjong, but the time commitment hurt my relationships and work-life balance.",
    "fullText": "I majored in journalism in college, but fell into tech sales after graduation. Over the past 17 years, I've worked my way from cold-calling as a sales rep to a Director of Sales. But after having kids I started craving a creative outlet and decided to start writing again in 2024.\n\nI didn't set out to make money from it. My first several pieces were unpaid personal stories for a parenting website. When the editor reached out and asked if I wanted to try freelancing, it gave me the confidence to see if I could turn my writing into a side hustle. In 2024, I made $8,995 from various publications.\n\nIn 2025, I spent more time and effort freelancing and made $30,411. I also started teaching American mahjong lessons, which brought in an additional $2,902. All in all, that's just over $33,000 before taxes.\n\nI love my side hustles, but I've had to make major trade-offs with my personal life and don't know if the work is sustainable.\n\nTaxes in the freelancing world are higher than in corporate jobs, so I take home a lower percentage of my earnings. You pay Social Security and Medicare taxes on top of your income tax for freelance work, taxes that an employer typically pays. Still, I'll probably net close to $20,000 from my side hustles in 2025.\n\nThese gigs aren't necessary to make ends meet. I'm fortunate and privileged that my husband's and my W-2 jobs are enough to provide for our family. I choose to pursue them because I genuinely love doing them.\n\nBecause of that, I consider my side hustle money my \"fun\" money. It's become the guilt-free cash that I use for things like specialty workout classes, new clothes, or to put toward travel with friends. I've also saved some of it, too. It's rewarding to see the extra income because it is a lot of additional work.\n\nI work for a local mahjong organization, so I don't have to do any marketing or admin work. People request lessons and then instructors \n\nBut the freelancing world requires a lot of hustle. It's effectively the same as cold-calling in sales to get an assignment.\n\nI pitched at least two new story ideas every day in 2025. That meant brainstorming ideas, researching potential sources, and crafting pitch emails to various editors. The work paid of,f and I wrote for 19 different publications last year, something I'm really proud of, but it was a daily grind.\n\nI averaged about three writing assignments and one mahjong lesson each week last year. I needed to work around my corporate job, so most of my writing work happened before my kids got up or after they went to bed. That typically meant writing from 5:30 to 7 a.m. and then again from 8:30 to 10:30 p.m. Lunch breaks became the time I'd schedule interviews, so I'd eat at my desk to compensate.\n\nMost of my mahjong lessons happen on weekday evenings. Each lesson is about a three-hour commitment, including driving to and from the venue, setting up, and teaching.\n\nI like to be busy, but with parenting, my corporate job, and my side hustles, I didn't feel like I had any time to relax and recharge. I also couldn't invest as much time into friendships or my marriage as I would have wanted to because of my side hustle commitments. This unintentionally created additional stress and anxiety, which I know is bad for my well-being.\n\nThe extra income from my side hustles is amazing, but I want to protect my free time more in 2026. I don't want to stop writing or teaching mahjong, but I can't sustain the amount of work I've been doing.\n\nMy time management improved in 2025, despite the numerous tasks I had to complete. I've also learned how to better prioritize different tasks and plan future action items so that everything gets done on time.\n\nI'll still work on my side hustles, but will spend less time on them so that I have more time with my friends and family. Yes, this will mean less \"fun\" money, but it'll be worth it for a better work-life balance.",
    "readingTime": 4,
    "keywords": [
      "extra income",
      "corporate job",
      "fun money",
      "mahjong lessons",
      "i've",
      "hustles",
      "freelancing",
      "hustle",
      "taxes",
      "additional"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/side-hustles-made-33000-but-hurt-my-work-life-balance-2026-1",
    "thumbnail_url": "https://i.insider.com/695e7c6f832e0ef1ead7535e?width=480&format=jpeg",
    "created_at": "2026-01-15T18:24:02.826Z",
    "topic": "finance"
  },
  {
    "slug": "blogging-writing-musing-and-thinking",
    "title": "Blogging, Writing, Musing, and Thinking",
    "description": null,
    "fullText": "Yesterday I stumbled on this quote from a blog post by JA Westenberg:\n\nMichel de Montaigne arguably invented the essay in the 1570s, sitting in a tower in his French château, writing about whatever interested him: cannibals, thumbs, the education of children, how to talk to people who are dying. He called these writings essais, meaning \"attempts\" or \"tries.\" The form was explicitly provisional. Montaigne was trying out ideas, seeing where they led, acknowledging uncertainty as a fundamental feature rather than a bug to be eliminated.\n\nIt's hard to convey the sense of both profound agreement and giddy joy I had reading that because, not only is the wider post about something I love (i.e. blogging), or because I learned something new about the history of writing (which is always fun), but because that quote describes something that I've been doing myself for the past two years and wanted an excuse to talk about!\n\nThere's an old adage that says, \"Writing is Thinking\" and I've usually interpreted those words to mean that \"writing helps you think\", which is undoubtably true. However in recent years I've discovered an entirely new form of writing that I've taken to calling: musing, that I think takes this idea a step further, and it's precisely what Westenberg describes Montaigne doing in the 16th century.\n\nWe have a lot of thoughts throughout the day, and yet we spend so little time indulging these idle curiosities. Writing, especially by hand, can be a great way to explore these ideas and to practice thinking. It's also really fun to do! Over time I started collecting these ideas into notebooks (one of which I almost always carry with me) in order to better organize these inherently random topics into a searchable system. Originally I scribbled on loose leaf pages or random legal pads (as I've mentioned before) and that became unruly very quickly.\n\nSome of these musings are personal topics, most are not. Often they're just the exploration of a question I have. Here's an example:\n\nBusinesses keep offices cold because there's research saying that cooler temperatures help people think and stay focused. Given that's true, could the Little Ice Age have helped improve human cognition during the 17th and 18th centuries? If so, what does that mean?\n\nI'm not sure, but it was something I thought about for a while and so I wrote it down. The entire musing, or essay as I guess it should be called, is less than a page, but was engaging and very fun to do. I've written short essays about dozens of topics over the years (including several that have been eventually published to this blog). It's a fun practice, and I encourage you to try it.\n\nExplore your ideas honestly. Don't fear where your mind goes or the questions it will ask. These are personal, honest thoughts not social media posts. Writing like this is inherently introspective, it's a way to give your mind the space to awe and wonder\n\nWe often believe that thinking is a process which takes place entirely in the mind, but it's a process that is heavily influenced by the particulars of the body. Try thinking through a problem in a hot and smelly room or on a walk with a rock in your shoe.\n\nHowever, the body can do more than hinder the thought process, it can catalyze it! This is what writing can be, a way to think through problems using your entire body.\n\nOccasionally, I've sat down to write but without any particular topic in mind. So, I open my notebook and just start writing. Tons of my essays begin with something like, \"I'm not sure what I'm thinking right now and I don't know what to write.\" From there, I let my thoughts move and course as they will and I just write down what comes to mind, stopping and starting as my thoughts shift and change and eventually I will find that something has come out of it. I might work through a tension or stress point, I could come to realize or discover something about a problem, or I could just get a few lackluster thoughts on a page. Not all thinking is productive but the mind is a muscle and it needs to be exercised to function properly. Sometimes just doing the workout is enough.\n\nWe usually think of cleverness or intelligence as an innate trait people have, and while that is certainly true in some regards, intelligence and wisdom are just as much a function of practice as of talent. To get good at solving puzzles, you have to practice solving puzzles. The mind is no different than a muscle in that regard. Thinking aloud on the page is one way to record and analyze your thought process and to practice the art of thinking itself.\n\nAs another example, I often revisit my prior writings and find many to be overly simplistic, uninspired, or just plain wrong. But that's good! It means I've learned something in the intervening time! In software there's an addage:\n\nIf you come back to old code and see nothing wrong with it, then you haven't learned anything since.\n\nYou are not a finished product, you're a process—always in motion—that evolves and changes over time. Your thinking can improve with practice as much as it can atrophy from inattention.\n\nThink about thinking, write those thoughts down, then perhaps publish a few on a blog that you own. It's fun, and it can do wonders for the mind.",
    "readingTime": 5,
    "keywords": [
      "solving puzzles",
      "it's fun",
      "mind",
      "thoughts",
      "practice",
      "ideas",
      "process",
      "blog",
      "montaigne",
      "learned"
    ],
    "qualityScore": 1,
    "link": "https://brianschrader.com/archive/blogging-writing-musing-and-thinking/",
    "thumbnail_url": "/images/blog/notes.jpg",
    "created_at": "2026-01-14T18:20:13.761Z",
    "topic": "tech"
  },
  {
    "slug": "one-thing-that-might-get-workers-to-embrace-ai-the-4day-workweek",
    "title": "One thing that might get workers to embrace AI? The 4-day workweek.",
    "description": "Adopting AI has been a struggle at some companies. Embracing a four-day workweek might help get more workers on board, say these authors.",
    "fullText": "Bosses, if you're struggling to get your people excited about AI, here's one idea: Embrace the four-day workweek.\n\nSharing some of AI's promised efficiency gains with employees — by letting them work fewer hours, not just get more done — could help get workers on board with a technology that some fear might ultimately replace them, authors of a new book advocating for a shorter workweek told Business Insider.\n\nLetting workers put in four days' work for five days' pay would be one way to \"share the rewards\" of innovation and technological advancement, said Jared Lindzon, a coauthor of the book \"Do \n\nWhen it comes to AI, giving workers more time away from their jobs could make it more likely they'd get behind the technology \"because they're getting part of that benefit,\" rather than standing in the way of it, he said.\n\nJoe O'Connor, Lindzon's coauthor, said that when it comes to discussions about AI in the workplace, the conversation among workers often turns to fears of job cuts.\n\nAnxiety about AI-induced layoffs might be one reason rolling out the technology has proven difficult for some companies. In an early 2025 survey of business leaders in eight countries from the IT company Kyndryl, 45% of CEOs said their workers were resisting the technology.\n\n\"Cultural resistance and emotional friction\" are the biggest impediments to AI adoption, Boston Consulting Group reported in 2025. That's unwelcome news for C-suite decision-makers eager to ratchet up efficiency. One in three companies is pumping at least $25 million into AI, according to BCG.\n\nBusiness leaders have, at times, publicly expressed their frustration over some workers' foot-dragging.\n\nCoinbase CEO Brian Armstrong said in 2025 that he'd gone \"rogue\" in firing some workers at the crypto exchange who didn't adopt AI after being told to do so. The head of the software company IgniteTech has, meanwhile, lamented that \"changing minds was harder than adding skills.\" In recent years, the firm cut nearly eight in 10 workers after they failed to quickly embrace AI.\n\nNurturing the productivity gains that many leaders seek will often require people to perform different kinds of work — especially as AI takes over some tasks, O'Connor said. He expects that demand for creativity, judgment, critical thinking, and adaptability will increase and that those \"fundamentally human\" traits won't be fostered by simply moving faster or working longer, he said.\n\n\"It's going to be more about maximizing people's energy, maximizing people's motivation, maximizing people's well-being and recovery,\" O'Connor said. A four-day workweek could promote those things, he said.\n\nThe idea that AI could allow people to work less isn't new. For years, the technology's advocates have said it could free up humans to do more of what they love, while handing off the grunt work to bots. The CEO of startup Mechanize, for example, says the company's aim is to automate every job.\n\nThat notion has led some of the biggest corporate luminaries to predict that working hours could plummet as AI adoption increases. Microsoft cofounder Bill Gates has said that time on the clock might shrink to two days, while JPMorgan's Jamie Dimon has said workweeks of 3.5 days could become a thing.\n\nEven Nvidia's Jensen Huang — known for regularly putting in 14-hour days at the chipmaker and working on holidays — has said he could see the tech allowing for more time away from the office.\n\nPoliticians have weighed in, too. Vermont Senator Bernie Sanders, citing efficiency gains from technology such as AI, introduced legislation in 2024 to trim the standard workweek to 32 hours.\n\nThere hasn't yet been widespread adoption of the four-day workweek, likely in part because employers wield more power in many parts of the job market. O'Connor said that while adoption of four-day setups was lower in 2025 than in 2023, when far more workers were job-hopping, more employers are opting for shorter weeks than before the pandemic upended norms about work.\n\nUmesh Ramakrishnan, cofounder of the executive search and leadership advisory firm Kingsley Gate, told Business Insider that many leaders, himself included, would want to harness AI's productivity gains to boost a business's top and bottom lines.\n\n\"If you have a day to spare, get me more revenue, get me more profit,\" he said, adding that while it might sound \"heartless,\" that's simply how business works.\n\nYet, Lindzon said, asking workers to be 20% more effective — the equivalent of a single day in a standard workweek — so that they might benefit from that boost is likely to be more effective than asking them to do it for the good of the company.\n\n\"It completely changes the conversation from a 'You have to do this' to 'We get to do this together,'\" he said.\n\nDo you have a story to share about your career? Contact this reporter at tparadis@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "business leaders",
      "maximizing people's",
      "productivity gains",
      "efficiency gains",
      "standard workweek",
      "four-day workweek",
      "workers",
      "technology",
      "adoption",
      "hours"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/four-day-workweek-might-incentivize-employees-embrace-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6966b31904eda4732f2f022d?width=1200&format=jpeg",
    "created_at": "2026-01-14T12:24:57.592Z",
    "topic": "finance"
  },
  {
    "slug": "diablo-4s-leaderboards-and-an-annoying-affix-are-currently-broken",
    "title": "Diablo 4's Leaderboards, And An Annoying Affix, Are Currently Broken",
    "description": "Diablo 4's latest patch brought the return of leaderboards to Blizzard's ARPG in the form of The Tower dungeon, but the new update isn't without issues. Both leaderboards and an enemy affix are currently bugged.\nIn a post on the Diablo 4 forums, community manager Marcoose let players know that while The Tower is still accessible, leaderboard results aren't currently populating correctly for all classes. Blizzard is investigating the issue but, as of writing, does not have any updates on the problem.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/diablo-4-leaderboards-and-an-annoying-affix-are-currently-broken/1100-6537353/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1647/16470614/4634716-diablo4leaderboardbugs.jpg",
    "created_at": "2026-01-13T18:20:43.444Z",
    "topic": "gaming"
  },
  {
    "slug": "as-2026-world-cup-nears-alan-rothenberg-reflects-on-us-soccers-transformation",
    "title": "As 2026 World Cup nears, Alan Rothenberg reflects on U.S. soccer's transformation",
    "description": "As the man behind the 1984 L.A. Olympics soccer tournament and the 1994 World Cup, Alan Rothenberg arguably had more to do with writing the story of modern U.S. Soccer than anyone.",
    "fullText": "Alan Rothenberg has a story he wants to tell you. A lot of stories actually; enough to fill a book.\n\nBut that’s not the first memorable work he’s authored. As the man behind the 1984 L.A. Olympics soccer tournament and the 1994 World Cup, still the most successful in history, Rothenberg has arguably had more to do with writing the story of U.S. Soccer in the modern era than anyone.\n\nAnd you can draw a straight line from that chapter to the one that will be written this summer when the World Cup returns to the U.S.\n\n“The turning point really was the Olympics,” he said last month over brunch in a crowded Sherman Oaks diner. “That soccer was so successful in the Olympics, that’s when FIFA thought maybe we could bring our crown jewel to the United States and not be embarrassed.\n\n“So ‘84 Olympics. That’s a crucial part of the story. I doubt that we would be where we are now but for that.”\n\nThat story’s in “The Big Bounce: The Surge That Shaped the Future of U.S. Soccer,” which is available Feb. 10. In fact, the book starts there.\n\nBut Rothenberg’s career did not. Before changing the face of U.S. Soccer, he first altered the landscape of sports in his adopted hometown, playing instrumental roles in bringing the Clippers to Los Angeles, in negotiating the trade that made Kareem Abdul-Jabbar a Laker and in settling the Kings at the Forum.\n\nAs a lawyer who started his career as the in-house counsel for Jack Kent Cooke when Cooke owned the Lakers, the Kings, the then-Washington Redskins and was launching the Wolves of the nascent NASL, Rothenberg was involved in some of the most consequential events in four sports during a career that’s nearing the end of its sixth decade. Yet he knew little about soccer when Peter Ueberroth, chair of the L.A. Olympic Organizing Committee, put him in charge of the sport for the 1984 Games.\n\n“Peter assumed with that background I must know a lot about soccer,” Rothenberg writes. “That was wrong.”\n\nWhat he lacked in soccer knowledge he more than made up for in creativity and organization skills, however, and the Olympic tournament proved to be one of the most successful in history, with the final at the Rose Bowl drawing a crowd of 104,098, a U.S. record for a soccer game that stood for 30 years.\n\nBut his name will forever be synonymous with the World Cup.\n\nThe 1994 tournament was the first to be played in a country without a first-division league and there were widespread fears it would be a disaster. Instead, it drew an average of 69,174 fans to each of the 52 games, an attendance record that still stands. It also generated a surplus of more than $50 million — also a record — money that went to the U.S. Soccer Foundation to promote the growth of the sport in the U.S.\n\nTwo years later, Major League Soccer kicked off; 30 years later it’s the sixth-most-valuable soccer league in the world.\n\n“Everything flowed from ‘94,” Rothenberg said. “If ‘94 had not been successful, including if our [U.S.] team hadn’t been credible, I’m not sure how quickly things would have developed. Certainly we wouldn’t have been able to start Major League Soccer at that time if the World Cup wasn’t successful.”\n\nAnother rarely discussed — but hugely important — legacy of that tournament is the foundation it created in terms of experience and expertise. The U.S. had never staged a major standalone soccer competition before 1994 and the learning curve was steep. Among those who worked under Rothenberg and went on to great success in the sport were Sunil Gulati, a three-term president of U.S. Soccer; Nelson Rodriguez, now MLS executive vice-president; Marla Messing, who headed the organizing committee for the 1999 Women’s World Cup and was later interim commissioner of the NWSL; Tom King, U.S. Soccer’s longtime managing director of administration; Kathy Carter, the former executive vice-president of Soccer United Marketing and chief executive officer of U.S. Olympic and Paralympic Properties; and Charlie Stillitano, a former MLS general manager who pioneered the idea of inviting major European clubs to play summer friendlies in the U.S.\n\n“It's not just that the event [came] off. Look what came out of it,” said Scott LeTellier, who as managing director and chief operating officer had responsibility for day-to-day operations of the World Cup organizing committee for 1994. “All the people who worked on our committee, who had some role that now are general managers of MLS teams. The league itself that came out of it. The number of soccer facilities. We didn't have a single soccer specific-stadium in the country.\n\n“You can argue that the ‘94 World Cup was really the linchpin to that entire explosion in the sport.”\n\nThat tournament was ahead of its time in other ways too. It was the first to stage fan fests in host cities, the first to include musical performers at the final and the first to offer hospitality packages with the price of a ticket. It also featured a lavish opening ceremony, one that featured Diana Ross, Oprah Winfrey and President Clinton, turning what was just a soccer tournament into a global spectacle.\n\nThe World Cup hasn’t been the same since, with FIFA’s revenue growing to a projected $13 billion for the 2026 cycle. There are more than 40 countries that don’t have an economy that large.\n\nAs Rothenberg notes in his book, FIFA originally pushed back on many of the innovations he proposed, including a halftime show at the final, only to eventually adopt the ideas as their own. Rothenberg also wanted to charge $1,000 a ticket for the final in 1994, arguing that fans would pay that on the secondary market, so why let the scalpers make the profit?\n\n“They were horrified,” he said. “You realize what a dramatic statement it would make if you had a $100-million gate?”\n\nThey do now; the cheapest regular tickets for the final of this summer’s tournament start at $2,000.\n\nRothenberg said he’s still thinking of other ways to improve the tournament, such as expanding the field to 64 teams and doing away with the group stage, making the World Cup like the NCAA basketball tournament.\n\n“I know I’m off the charts on this one,” he said. “Single elimination. It’s exciting start to finish.”\n\nAt 86, Rothenberg is still active, making regular trips to his office at 1st Century Bank, the community bank he founded in 2004 at an age when most people were entering retirement. And he promises to be a presence at this summer’s World Cup.\n\nAs for whether he gets the credit he deserves for making that tournament possible, Rothenberg demurs.\n\n“I didn’t do it for credit,” he says, speaking about both the World Cup and the book that explains how it happened. “All I can say is I’m proud of what I did.”\n\n⚽ You have read the latest installment of On Soccer with Kevin Baxter. The weekly column takes you behind the scenes and shines a spotlight on unique stories. Listen to Baxter on this week’s episode of the “Corner of the Galaxy” podcast.\n\nGet the best, most interesting and strangest stories of the day from the L.A. sports scene and beyond from our newsletter The Sports Report.\n\nThis story originally appeared in Los Angeles Times.",
    "readingTime": 7,
    "keywords": [
      "olympics that’s",
      "world cup",
      "managing director",
      "executive vice-president",
      "organizing committee",
      "league soccer",
      "major league soccer",
      "soccer tournament",
      "u.s soccer",
      "successful"
    ],
    "qualityScore": 1,
    "link": "https://sports.yahoo.com/articles/2026-world-cup-nears-alan-120000223.html",
    "thumbnail_url": "https://s.yimg.com/os/en/la_times_articles_853/b7eecaa9b0babdd75eda93e55e472d97",
    "created_at": "2026-01-13T12:26:19.812Z",
    "topic": "sports"
  },
  {
    "slug": "is-your-leadership-style-too-nice",
    "title": "Is Your Leadership Style Too Nice?",
    "description": "Many leaders mistake being “nice” for being effective, avoiding hard conversations and decisions in ways that ultimately undermine organizational performance. The authors argue that being “good” instead requires clear accountability, candid feedback, disciplined decisions about roles and retention, and sustained strategic focus. Organizations that engage in these activities see stronger engagement, growth, and lasting impact.",
    "fullText": "Is Your Leadership Style Too Nice? by Ron Ashkenas and Gali CooksJanuary 12, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrint“If you work very hard and get results, you are well rewarded here. But if you don’t work as hard and don’t really produce, you are also well rewarded.”",
    "readingTime": 1,
    "keywords": [
      "rewarded",
      "don’t"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/sm-why-leaders-need-to-be-less-nice-and-more-good",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_10_1299922303.jpg",
    "created_at": "2026-01-12T18:18:56.185Z",
    "topic": "business"
  },
  {
    "slug": "tiny-coder-ai-coding-agent-in-300-loc-writing-itself",
    "title": "Tiny Coder – AI coding agent in ~300 LOC writing itself",
    "description": "Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies. - xrip/tinycode",
    "fullText": "xrip\n\n /\n\n tinycode\n\n Public\n\n Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n xrip/tinycode",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/xrip/tinycode",
    "thumbnail_url": "https://opengraph.githubassets.com/07e51ae8c3cabfafdf20fdcf525646b8f004627e8c671e3c9185240ef4e3b4fd/xrip/tinycode",
    "created_at": "2026-01-11T12:21:58.611Z",
    "topic": "tech"
  },
  {
    "slug": "grief-leverage-and-the-future-of-manual-coding",
    "title": "Grief, leverage, and the future of manual coding",
    "description": "I’m a software engineer and product maker based in Cracow, Poland. My mission is to create useful products by writing high-quality code and sharing my knowledge throughout the journey.",
    "fullText": "For the last couple of years, watching the software industry has been an emotional experience for me. And will I remember the winter of 2025/2026 - the time when apparently everyone and your mum discovered just how good in coding the Claude Opus 4.5 is - as the culmination of that period, and one of the hardest and most confusing times for me as a professional.\n\nOn one hand, there's anxiety. The pace of change is brutal. New tools appear every week, workflows emerge almost overnight. Wondering where this is all is heading, and whether there will still be a place for us on the other side.\n\nI felt strange hearing from industry thought leaders like Andrej Karpathy, saying that English is now the new programming language. I had spent years honing the craft of writing in programming languages - so what was I supposed to make of that, if it was now being treated as commoditized?\n\nAfter months of thinking about that, I had identified the feeling - grief. Grief for manual coding.\n\nFor years, my identity as an engineer was tightly coupled to the artifacts I produced. My repositories. My components. My abstractions. The code was mine, and that ownership mattered. It was craft and it was personal. Like a carpenter remembering how it felt to build a specific chair.\n\nThat mental model no longer holds for me. How could it, when everyone now can one-shot a todo app for themselves, just like a PowerPoint presentation?\n\nOn the other hand, there's excitement. I got into coding because I wanted to create worlds. Websites, apps, flows, solutions, interactions between users, beautiful and unique things.\n\nNow the ceiling of building is so high that we cannot even see it. Ideas that felt too expensive or too complex are suddenly within reach. It's not an understatement to say things that used to take weeks and months now may take hours. I'm not saying that it's easy to do it and everyone can make it happen, but it's certainly possible.\n\nThe new leverage comes from moving one layer up. Instead of doing every task ourselves, we design systems that can do them for us. A single agent can now execute autonomously what used to require long hours my time, freeing my attention for higher-level decisions, design, judgment. And maybe just... enjoying the life with my loved ones?\n\nThis all immensely increases the leverage of single engineer. Technically, you're one well designed system away from solving a daunting problem for the first time, from building life-changing startup, from building your dream game. Of course, it's still hard and rare, but pre-agentic coding it was often not possible at all - you had to broke the concrete walls of thousands of lines of code first.\n\nI mentioned that everyone with AI can one-shot a personal to-do app now. Engineers with AI can create much more that. They can design systems that scale, adapt, and solve problems in ways that were previously out of reach, everything under strict engineering discipline - secure, cheap and efficient.\n\nThat's why, overall, I am cautiously optimistic on what the future holds.\n\nAnd it seems like - as buzzwordy and cliché as it sounds - that the future is agentic.\n\nThe word agentic gets thrown around a lot, so it's worth grounding it. I will use the definition I personally In practice, the systems that actually work for me tend to follow the same five core steps:\n\nPoints 2, 4 ad 5 can be somewhat \"recursively\" executed by agents - it's not hard to imagine agents implementing the system by writing specs or veryfing the outputs for other agents.\n\nPoints 1 and 3 are uniquely human - we decide what we want to exist, and we trigger the execution process. And while point 3 - triggering the execution - also can be run by agent, I keep it in this category because someone is at the end is responsible for what the agents did, and in that sense it is uniquely human.\n\nThis shift doesn't mean the broad engineering skill is obsolete. It means where that skill applies has changed.\n\nTo orchestrate agents that produce valid code, I still need to understand:\n\nAnd what is even more important:\n\nInstead of applying that knowledge and intent manually in code, I encode it into the system that produces the code. It produces the code in indeterministic way, mind you, and potentially on much broader scale. We don't know yet which scale we talk about. 2x? 10x? Maybe more? We will see.\n\nAnd there's whole new class of problem to solve. How do I ensure models doesn't produce unexpected or harmful results? How do I coordinate several, dozen, and more models to work together? How do I ensure AI runs on prem and we don't share our precious data with anyone?\n\nIn other words, the craft moves up a level.\n\nInitially, I wanted to include \"the end of manual coding\" in this post's title. But I changed it to \"the future manual of coding\".\n\nFirst, I didn't want to sound clickbaity. Now, seriously - manual coding isn't gone. It still has a very important place. Best professionals always understood different abstraction levels, not only the highest one. Code is runtime, and you have to understand runtime through and through. Apart from that - it's still important in learning, personal work, and honing the cognitive skills. I especially believe in the last one, because delegating so much mental work we used to do before will take a tool on our thinking in a long term.\n\nBut it's no longer the default path to producing value and to economic leverage. The role of software engineers is shifting:\n\nWe're no longer producing artifacts (code). We're designing systems producing artifacts.\n\nOnce you accept that, a lot of confusion from the last couple of years disappears. The grief is still there, but it's quieter. And there is something else: the clarity, and a sense that this change, while uncomfortable, is also full of possibility.\n\nOne important note: no, all of this doesn't mean succumbing to AI slop. We're still responsible for everything our agents produce - every single line of it. And no, it doesn't mean letting AI write sloppy LinkedIn posts or Slack messages is suddenly acceptable. If anything, the opposite: write your damn words yourself, please. Do not delegate your thinking.\n\nThere's a whole lot of skill to designing the agentic systems including mastering specs engineering, enforcing constraints, output verification, model evaluation and so on. This is the obvious thing to focus on first.\n\nMany people dreamed of living in times with real blank spots on the map, to be able to discover the unknown themselves. Software engineers in 2026 have the privilege of experiencing this. And it can be a source of risk, as well as an economic leverage.\n\nWe've always been good at automating and learning new things. Now there's even more to automate and learn. Our focus should shift from manual coding to designing systems that produce code at scale - while remembering that manual coding got us here, and still matters, just for different reasons.\n\nI’m a software engineer and product maker based in Cracow, Poland. My mission is to create useful products by writing high-quality code and sharing my knowledge throughout the journey.",
    "readingTime": 7,
    "keywords": [
      "uniquely human",
      "economic leverage",
      "producing artifacts",
      "software engineers",
      "design systems",
      "designing systems",
      "manual coding",
      "code",
      "it's",
      "agents"
    ],
    "qualityScore": 1,
    "link": "https://www.tymzap.com/blog/grief-leverage-and-the-future-of-manual-coding",
    "thumbnail_url": "https://www.tymzap.com/api/og?title=Grief%2C%20leverage%2C%20and%20the%20future%20of%20manual%20coding&token=37cac97264905c6d7b412cbf3c96ddd0a5309cbd4603ad51e8c444cd8be1e1e5",
    "created_at": "2026-01-08T18:16:49.915Z",
    "topic": "tech"
  },
  {
    "slug": "ai-starts-autonomously-writing-prescription-refills-in-utah",
    "title": "AI starts autonomously writing prescription refills in Utah",
    "description": "The program allows patients in the state to get prescription refills for 190 common meds.",
    "fullText": "The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”\n\nThe program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.\n\nDoctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.\n\nAccording to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.\n\nNow, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.\n\nThe first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.\n\n“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.\n\nFor now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.\n\nIn a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.\n\n“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said.\"The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”",
    "readingTime": 3,
    "keywords": [
      "utah department",
      "pilot program",
      "chatbot",
      "doctor",
      "patients",
      "prescription",
      "medications",
      "regulatory",
      "service",
      "cases"
    ],
    "qualityScore": 1,
    "link": "https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg",
    "created_at": "2026-01-08T00:58:00.272Z",
    "topic": "health"
  },
  {
    "slug": "monitoring-a-docker-homelab-with-open-source",
    "title": "Monitoring a Docker Homelab with Open Source",
    "description": "Arie van den Heuvel is an engineer, a System and Application Management Specialist, and a valued member of our community. You can read more of Arie’s writing and support the resource articles he has contributed to open source on his blog. If you have a story or open source project you would like to...",
    "fullText": "Arie van den Heuvel is an engineer, a System and Application Management Specialist, and a valued member of our community. You can read more of Arie’s writing and support the resource articles he has contributed to open source on his blog. If you have a story or open source project you would like to share with our community next, you can write to us.\n\nWhen running a home server consisting of one or more nodes with some or all services in Docker, you may find yourself wanting to monitor your environment. Or even better, attain full observability.\n\nThe frequent recommendation for this is a combination of Prometheus with Grafana. But this solution requires a lot of work to fully configure, in addition to work on one’s applications and setup for full visibility. Another possibility is to use the free tier of NewRelic, which has the advantage of remote insights on metrics and logs. Again, this requires additional work on containers or applications to have a more refined visibility of your services.\n\nFor those not running Linux, an honourable mention to use as a solution would be Beszel. Beszel can be run as a local service or in docker. It consists of a web front-end and an agent that can be used on multiple systems that run Windows and MacOS. Installation is an easy job in docker. Once it’s running, Beszel provides insightful information with system metrics, docker services, and even logs.\n\nMy personal choice for monitoring a home server system is Coroot. In the following blog, I’ll detail how I used Coroot to set up observability for my homelab, which you can then adopt for your own setup.\n\nIn my current setup on a Rocky Linux 9.x system, Coroot runs on a Clickhouse server to store metrics, logs, traces and profiles, in addition to the Coroot node-agent and Coroot cluster-agent. The Coroot node-agent automatically collects all service metrics and logs using eBPF, while the cluster-agent provides detailed information on databases like MySQL, Postgres or Redis.\n\nAnother advantage Coroot presents is the use of AI-powered Root Cause Analysis, which provides instantaneous and helpful insights for investigating incidents. With a Coroot Cloud account, you will have ten helpful analyses for free each month. Even without AI, the data presented with Coroot with standard alerts based on best metric practices is pretty insightful and helps to make your setup even better.\n\nCoroot services run in docker through a docker-compose file. In a normal Coroot setup Prometheus is used, but in this setup I have configured Clickhouse, which is a supported alternative.\n\nI have Clickhouse running as a local service. This setup allows for better control and convenience when scaling down memory usage of Clickhouse, scaling down logging on disk and the database, and simplifies making changes to the data. The only downside to note is this setup requires updating Clickhouse manually with yum/dnf.\n\nInstalling Clickhouse is easily achieved by adding the repo, installing Clickhouse, and making a few quick adjustments before starting it up.\n\nBefore starting the service create file /etc/clickhouse-server/config.d/z_log_disable.xml and insert the following content in the file:\n\nAfter this adjust cache sizes in /etc/clickhouse-server/config.xml:\n\nAdjust memory usage ratio in /etc/clickhouse-server/config.xml:\n\nLower the tread pool size in /etc/clickhouse-server/config.xml:\n\nFirst, check if your Linux system is using kernel 5.1 or later (although 4.2 is also supported.) This installation is different from the original docker-compose file.\n\nPrometheus is not used in this setup, and Clickhouse runs as a local service. Another distinction is the retention of the data, which is normally set to seven days for traces, logs, profiles and metrics. Coroot also typically stores its own local cache for metrics for 30 days.\n\nIn this setup, the data retention stored in Clickhouse is set up for 14 days. With eighteen local and docker services, the amount of data kept for all of this is 3GB on average in my system.\n\nCoroot, its node-agent, and cluster-agent, run as a docker service with a docker-compose that you create locally. This is achieved by inserting the following content in a locally created docker-compose.yaml:\n\nAfter creating this file and making any adjustments to your own likings and network preferences, type docker compose up -d and go to your IP address on port 8080. Here you have access to Coroot, and are now prompted to give admin credentials!\n\nIn my setup, Watchtower takes care of updating docker containers, which works great with Coroot.\n\nAs a final sidenote: there are already some helpful hints and pointers present within Coroot for setting things up. In my case, there was information available that helped observe a Postgres database. Don’t forget to use the given commands as the admin/postgres user to make it work.\n\nStop guessing, start seeing with eBPF-powered instant observability.",
    "readingTime": 4,
    "keywords": [
      "linux system",
      "memory usage",
      "following content",
      "coroot node-agent",
      "docker-compose file",
      "docker services",
      "setup",
      "metrics",
      "logs",
      "server"
    ],
    "qualityScore": 1,
    "link": "https://coroot.com/blog/monitoring-a-docker-homelab-with-coroot/",
    "thumbnail_url": "https://coroot.com/wp-content/uploads/2025/11/Aries_CorootAdventures-14.png",
    "created_at": "2026-01-07T18:19:24.863Z",
    "topic": "tech"
  },
  {
    "slug": "antora-the-single-or-mulantora-site-generator-for-writing-in-asciidoc",
    "title": "Antora: The single or mulAntora: site generator for writing in AsciiDoc",
    "description": "An Asciidoctor documentation toolchain that helps technical teams create, manage, collaborate on, remix, release, and publish documentation sites sourced from multiple versioned repositories.",
    "fullText": "Mark up content with AsciiDoc’s lightweight yet comprehensive syntax.\n\nAsciiDoc’s extensive feature set is available right out of the box with Antora. There’s no need to find, install, and manage plugins, extensions, or scripts to add basic capabilities to the syntax.\n\nDocumentation written with AsciiDoc works with all of the software and tools in the Asciidoctor ecosystem. You don’t need to worry about incompatible syntax or lost functionality.\n\nWrite and preview AsciiDoc with text editors and IDEs like Atom, Brackets, and IntelliJ. And GitLab and GitHub render AsciiDoc files right in the browser.\n\nCustom syntax or output transformations can be added as discrete extensions using Asciidoctor’s extension API.\n\nAntora’s core developers help lead the Asciidoctor organization, home of the AsciiDoc syntax and Asciidoctor, the AsciiDoc processor. Due to this direct relationship, Antora is always in sync with AsciiDoc and Asciidoctor features.",
    "readingTime": 1,
    "keywords": [
      "syntax",
      "asciidoc’s",
      "extensions",
      "asciidoc",
      "asciidoctor",
      "antora"
    ],
    "qualityScore": 0.75,
    "link": "https://antora.org/",
    "thumbnail_url": "https://antora.org/img/site-image.png",
    "created_at": "2026-01-06T12:24:28.718Z",
    "topic": "tech"
  },
  {
    "slug": "scotus-justices-blistering-dissent-vindicated-by-bombshell-study",
    "title": "SCOTUS Justice’s Blistering Dissent Vindicated by Bombshell Study",
    "description": "A new study has bolstered a scathing dissent from liberal Supreme Court Justice Ketanji Brown Jackson that warned the court appeared to favor the rich. The study, published Monday by the National Bureau of Economic Research, investigated whether the Supreme Court has contributed to rising income inequality by ruling in favor of policies that favor wealthy parties. Its authors—two academics from Columbia University in New York and one from Yale University—found that in cases pitting the rich agai",
    "fullText": "A new study has bolstered a scathing dissent from liberal Supreme Court Justice Ketanji Brown Jackson that warned the court appeared to favor the rich.\n\nThe study, published Monday by the National Bureau of Economic Research, investigated whether the Supreme Court has contributed to rising income inequality by ruling in favor of policies that favor wealthy parties.\n\nIts authors—two academics from Columbia University in New York and one from Yale University—found that in cases pitting the rich against the poor, Republican appointees were far more likely than their Democratic colleagues to side with the wealthier party.\n\nBack in 1953, Democratic and Republican appointees were statistically indistinguishable on the issue, with justices appointed by members of both parties favoring the rich in 45 percent of cases on average.\n\nThe average Democratic justice cast a “pro-rich” vote—which was defined as a vote that would directly shift resources to the party that was more likely to be wealthy, including votes that supported businesses over consumers or workers—just 35 percent of the time.\n\n“The results reveal a steady increase in polarization, mostly due to Republican appointees whose decisions rise from about 50 percent pro-rich share to a 70 percent pro-rich share over the course of 70 years,” the study’s authors, Andrea Prat, a Columbia economics professor, Jacob Spitz, a Columbia PhD student, Fiona Scott Morton, a Yale economics professor, and wrote.\n\nThe findings also supported a June dissent authored by Brown Jackson, according to The New York Times.\n\nThe justices held 7-2 that oil and gas companies had legal standing to challenge California’s environmental regulations requiring automakers to produce more electric vehicles and fewer gasoline-powered ones.\n\n“This case gives fodder to the unfortunate perception that moneyed interests enjoy an easier road to relief in this Court than ordinary citizens,” Brown Jackson wrote. “I worry that the fuel industry’s gain comes at a reputational cost for this Court, which is already viewed by many as being overly sympathetic to corporate interests.”\n\nThat perception could be contributing to an overall drop in public confidence in the court, according to the Times. The Daily Beast has reached out to the Supreme Court for comment.\n\nThe court’s favorability rating has plunged by 22 points over the past five years, from 70 percent in 2020 to a near-record low 48 percent late last year, the Pew Research Center reported in September.\n\nAnd although a vast majority of Americans, or 86 percent, think the justices should be non-partisan, 56 percent said the justices were doing only a fair or poor job of keeping their political views out of their legal decision-making.",
    "readingTime": 3,
    "keywords": [
      "republican appointees",
      "economics professor",
      "supreme court",
      "brown jackson",
      "justices",
      "favor",
      "rich",
      "pro-rich",
      "study",
      "dissent"
    ],
    "qualityScore": 0.9,
    "link": "https://www.yahoo.com/news/articles/scotus-justice-blistering-dissent-vindicated-171647024.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/aIa3sv3_3qNWXq.nYw3alA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://media.zenfs.com/en/thedailybeast.com/342255d6ef59f59aea7eab845f5c40e3",
    "created_at": "2026-01-06T12:24:22.463Z",
    "topic": "news"
  },
  {
    "slug": "generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "title": "Generation AI: fears of ‘social divide’ unless all children learn computing skills",
    "description": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n Continue reading...",
    "fullText": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\n\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n\nHis friends from the St Paul’s C of E primary school coding club tapped away to build their own AIs with similar dexterity. Just as people born in the early 20th century never knew a world without manned flight, and generation Z has always lived with social media, Joseph and his friends are AI natives.\n\nHere, on one December morning, some of them were being taught the principles and practicalities of the potentially world-changing technology that experts fear may pass large numbers of people by and leave them disempowered.\n\nPhilip Colligan, the chief executive of the digital education charity the Raspberry Pi Foundation, has warned of a “big split” in society between people who grasp how AIs work and are able to control them – challenging their increasing role in automating decisions in areas including housing, welfare, health, criminal justice and finance. On the other hand, there could be a cadre of AI illiterates who risk social disempowerment.\n\nColligan, a leading expert in technology and its social impacts, told the Guardian AI literacy must become a universal part of education on a par with reading and writing to avoid a social divide opening up.\n\n“There is a world where you’ve got a big split between kids who understand, have that core knowledge and therefore are able to assert themselves and those who don’t,” said Colligan, whose charity is affiliated to the £600m British low-cost tech hardware startup of the same name. “And that could be really very dangerous.”\n\nHis warning was backed by Simon Peyton Jones, a computer researcher who led the creation of the schools national curriculum for computing in 2014, prior to the AI boom. He called for a new digital literacy qualification for all schoolchildren that would ensure they know how to use AIs in a critical way.\n\n“If it’s simply a black box, then [its actions] seem like magic,” he said. “If you know nothing about how the magic is working that is terribly disabling. I am very worried about students leaving school without having agency in the world.”\n\nTheir comments came amid a fall in the number of children studying computing, with 2025 entries for a GCSE in the subject down across the UK. Today, three times more people take history and nearly double the number take biology, chemistry and physics. At the same time, use of AI systems nationwide has been surging – up 78% in the year to September, according to polling by Ipsos.\n\nPart of the belief that learning computing skills is becoming redundant comes from some of the big AI companies, which argue their systems are going to automate coding. Anthropic’s chief executive, Dario Amodei, said in October that 90% of its own coding was automated using its Claude AI model. Meanwhile, 2025 was the year when “vibe coding” became a common phrase – capturing the idea that AIs would allow humans to build software by using natural language instructions rather than specialised code.\n\nPolitical leaders such as Keir Starmer have also suggested coding is becoming redundant. As leader of the opposition in 2023, he said: “The old way – learning out-of-date IT, on 20-year-old computers – doesn’t work. But neither does the new fashion, that every kid should be a coder, when artificial intelligence will blow that future away.” It has created the idea that understanding the inner workings of a computer may be less relevant in the future.\n\n“I think they’re just overhyping the benefits,” said Colligan, whose charity works in schools across dozens of countries.\n\n“This message is leaking out that the kids don’t need to learn this stuff any more and that is not only flawed it is dangerous. We’re already talking to teachers in lots and lots of schools around the world, not just the UK, saying: ‘We can drop computer science now, right?’ That’s a problem.”\n\nHe added: “All of us are going into a world where more and more of the decisions we encounter every day will be taken by automated systems. At the moment it’s what movie should I watch next or what song should I listen to? Fairly soon it’s going to be finance decisions, healthcare decisions, criminal justice decisions. If you don’t understand how those decisions are being made by automated systems, you can’t advocate for your rights. You can’t challenge them, you can’t critically evaluate what’s being presented to you.”\n\nIn December, the former deputy prime minister Nick Clegg, who is now an AI investor, predicted that “we will move from staring at the internet, to living in the internet”.\n\nColligan said: “My concern is there will be a gap between kids based on their socioeconomic background. Some kids who go to great schools, who are able to teach this stuff, will be in a much stronger position as citizens, whether or not they’re using technology for their job. Those kids who are in communities where they don’t have access to [AI literacy teaching] will be passively on the end of a whole load of automated decisions.”\n\nIn the coding club, the seven- to 10-year-olds are taught how AIs work. The lessons were clearly having an effect on Joseph. He said he thought AI “will probably be good, but if lots of people believe it when it’s wrong it will have a bad impact on them”.\n\nHe was not interested in letting the AI do the coding of the video games he planned to make. “It might do it differently to what you want,” he said. “It might also do it wrong and you need to know how to solve it … I’d like to be in charge of the AI. If the AI is in charge of us, we wouldn’t really be able to control what we’re doing and that would be bad.”",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "chief executive",
      "criminal justice",
      "computing skills",
      "coding club",
      "automated systems",
      "decisions",
      "kids",
      "lots",
      "social"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/education/2026/jan/05/generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "thumbnail_url": "https://i.guim.co.uk/img/media/66338578082a146cac512c5e844a9b9eda109707/628_0_6160_4928/master/6160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=dfec8859e649adbe1a54dfa8c45ce5bb",
    "created_at": "2026-01-06T00:57:41.049Z",
    "topic": "tech"
  },
  {
    "slug": "tech-war-china-takes-confident-strides-to-develop-more-ai-innovation-in-2026",
    "title": "Tech war: China takes confident strides to develop more AI innovation in 2026",
    "description": "On the last day of 2025, DeepSeek published a new technical paper, with founder and CEO Liang Wenfeng among the 19 co-authors, about \"manifold-constrained hyper-connections\" - a general framework for training artificial intelligence systems at scale, which suggested \"promising directions for the evolution of foundational models\". That release was a fitting reminder to the world, especially during the peak of the Christmas holiday season, about Chinese AI companies' sharpened focus on innovation",
    "fullText": "On the last day of 2025, DeepSeek published a new technical paper, with founder and CEO Liang Wenfeng among the 19 co-authors, about \"manifold-constrained hyper-connections\" - a general framework for training artificial intelligence systems at scale, which suggested \"promising directions for the evolution of foundational models\".\n\nThat release was a fitting reminder to the world, especially during the peak of the Christmas holiday season, about Chinese AI companies' sharpened focus on innovation to stay ahead in this fast-developing industry.\n\nIt was around this time last year when DeepSeek started to get widely noticed days after releasing its namesake large language model (LLM), DeepSeek-V3. Weeks later on January 20, reasoning model DeepSeek-R1 was released.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\nThe two models either surpassed or matched the performance of rival models across a range of industry benchmark tests. They were also built at a fraction of the cost and computing power that major US tech companies invest to build LLMs. The result: a massive sell-off on January 27 wiped out nearly US$1 trillion in tech stocks, including US$600 billion from Nvidia alone.\n\nAnalysts expected the momentum of Chinese AI companies to continue this year, thanks to Beijing's policy support, improved funding prospects, greater adoption of AI systems across industries and a growing number of talent being recruited for innovative projects.\n\nA domestic AI start-up's co-founder, who declined to be identified, predicted that China would overtake the US to become \"the world's leading AI power in 2027\". China's advantage was its deep talent pool, according to the co-founder.\n\nIn his New Year's address, Chinese President Xi Jinping pointed out that the domestic market has \"many large AI models competing in a race to the top\", while new breakthroughs were being achieved in domestic semiconductor development. All of that \"has turned China into one of the economies with the fastest growing innovation capabilities\", Xi said.\n\nDeepSeek founder and CEO Liang Wenfeng. Photo: Shutterstock alt=DeepSeek founder and CEO Liang Wenfeng. Photo: Shutterstock>\n\n\"China's tech innovation is poised for policy-driven growth in 2026, with AI placed at the centre of the country's economic agenda and industrial upgrading plans,\" said Winston Ma, an adjunct professor at the New York University School of Law, with a focus on AI and the digital economy.",
    "readingTime": 3,
    "keywords": [
      "ceo liang",
      "liang wenfeng",
      "chinese ai",
      "models",
      "founder",
      "innovation",
      "tech",
      "domestic",
      "systems",
      "focus"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/tech-war-china-takes-confident-093000206.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/PeHol2Dz0GRB34_tqq86Kw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/south_china_morning_post_us_228/4a6ae3a2ffe7aee0fcd3552217c65b06",
    "created_at": "2026-01-03T18:16:13.991Z",
    "topic": "finance"
  },
  {
    "slug": "a-russian-soldier-surrendered-by-writing-please-take-me-prisoner-i-want-to-live-on-cardboard-seen-by-a-drone-units-say",
    "title": "A Russian soldier surrendered by writing 'Please take me prisoner, I want to live' on cardboard seen by a drone, units say",
    "description": "Two Ukrainian units said that drone pilots saw a messages written on cardboard by a Russian in a building who was seeking to surrender.",
    "fullText": "A Russian soldier surrendered to Ukraine via a message that he wrote on cardboard that was spotted by a drone, Ukrainian military units said.\n\nThe 16th Army Corps said on Wednesday that drone pilots discovered a Russian soldier in Lyman, a town in the eastern region of Kharkiv, who wrote the surrender messages.\n\nOne read \"Please take me prisoner, I want to live,\" per the translation by Ukrainian state outlet United24.\n\nThe corps said the Russian was given instructions on how to surrender and was detained.\n\nDrone footage shared by the corps shows a small building with cardboard signs in the window and on the ground. A figure then puts another sign in the window.\n\nIt then shows a Ukrainian soldier writing on some cardboard, apparently writing instructions for the soldier to be delivered by drone. Two Ukrainians then appear to approach and walk with the Russian. Business Insider could not independently verify the event.\n\nThe 16th Army Corps said the operation was aided by the Shkval special forces unit of Ukraine's 57th Separate Motorized Infantry Brigade, which also reported the event.\n\nIt's not the first time that drones have played a role in the surrender of Russian soldiers. Ukrainian units have reported cases that include persuading Russian troops to surrender by playing them a voice message with a drone, and a Russian soldier who surrendered by following instructions dropped from a drone.\n\nUkraine's army issued an instructional video in 2022 with step-by-step instructions for Russian soldiers on how they can surrender to one of its drones.\n\nDrones are being used \n\nThey can fly far and go to places that would be too risky for Ukraine's own soldiers to go, making them particularly useful in trying to get Russians to surrender.\n\nUkraine actively encourages opposition soldiers to voluntarily surrender, including with its \"I Want to Live\" hotline, which it says thousands of Russian troops have used.\n\nA spokesperson for the project in 2023 said some Russian soldiers who call offer to hand over equipment and heavy armored vehicles.",
    "readingTime": 2,
    "keywords": [
      "russian troops",
      "russian soldier",
      "russian soldiers",
      "army corps",
      "surrender",
      "drone",
      "instructions",
      "cardboard",
      "drones",
      "surrendered"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/russia-soldier-surrender-message-drone-ukraine-2026-1",
    "thumbnail_url": "https://i.insider.com/6956534c832e0ef1ead70c5c?width=1200&format=jpeg",
    "created_at": "2026-01-01T18:17:17.329Z",
    "topic": "finance"
  },
  {
    "slug": "a-russian-soldier-surrendered-by-writing-please-take-me-prisoner-i-want-to-live-on-cardboard-seen-by-a-drone-units-say",
    "title": "A Russian soldier surrendered by writing 'Please take me prisoner, I want to live' on cardboard seen by a drone, units say",
    "description": "Two Ukrainian units said that drone pilots saw a messages written on cardboard by a Russian in a building who was seeking to surrender.",
    "fullText": "A Russian soldier surrendered after his rescue message was seen by a drone, Ukrainian units said.\n\nHe wrote, \"Please take me prisoner, I want to live,\" and was detained, the units said.\n\nRussian soldiers have previously surrendered to drones, and Ukraine actively encourages it.\n\nA Russian soldier surrendered to Ukraine via a message that he wrote on cardboard that was spotted by a drone, Ukrainian military units said.\n\nThe 16th Army Corps said on Wednesday that drone pilots discovered a Russian soldier in Lyman, a town in the eastern region of Kharkiv, who wrote the surrender messages.\n\nOne read \"Please take me prisoner, I want to live,\" per the translation by Ukrainian state outlet United24.\n\nThe corps said the Russian was given instructions on how to surrender and was detained.\n\nDrone footage shared by the corps shows a small building with cardboard signs in the window and on the ground. A figure then puts another sign in the window.\n\nIt then shows a Ukrainian soldier writing on some cardboard, apparently writing instructions for the soldier to be delivered by drone. Two Ukrainians then appear to approach and walk with the Russian. Business Insider could not independently verify the event.\n\nThe 16th Army Corps said the operation was aided by the Shkval special forces unit of Ukraine's 57th Separate Motorized Infantry Brigade, which also reported the event.\n\nIt's not the first time that drones have played a role in the surrender of Russian soldiers. Ukrainian units have reported cases that include persuading Russian troops to surrender by playing them a voice message with a drone, and a Russian soldier who surrendered by following instructions dropped from a drone.\n\nUkraine's army issued an instructional video in 2022 with step-by-step instructions for Russian soldiers on how they can surrender to one of its drones.\n\nDrones are being used \n\nThey can fly far and go to places that would be too risky for Ukraine's own soldiers to go, making them particularly useful in trying to get Russians to surrender.\n\nUkraine actively encourages opposition soldiers to voluntarily surrender, including with its \"I Want to Live\" hotline, which it says thousands of Russian troops have used.\n\nA spokesperson for the project in 2023 said some Russian soldiers who call offer to hand over equipment and heavy armored vehicles.",
    "readingTime": 2,
    "keywords": [
      "ukraine actively",
      "ukrainian units",
      "actively encourages",
      "russian troops",
      "drone ukrainian",
      "russian soldier",
      "russian soldiers",
      "soldier surrendered",
      "army corps",
      "drones"
    ],
    "qualityScore": 0.9,
    "link": "https://www.yahoo.com/news/articles/russian-soldier-surrendered-writing-please-130633357.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/vjl.AaRGEv1NBC.u5lScUA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/business_insider_articles_888/e9a65714a16af22cd42dde4527e667da",
    "created_at": "2026-01-01T18:17:16.375Z",
    "topic": "news"
  },
  {
    "slug": "i-am-a-mom-and-a-longtime-writing-teacher-my-kids-slang-shows-me-how-fast-language-is-changing",
    "title": "I am a mom and a longtime writing teacher. My kids' slang shows me how fast language is changing.",
    "description": "I'm a parent and teach writing. Watching my kids adopt new slang gives me a window into how expressions go viral, burn out, and reshape how we talk.",
    "fullText": "\"What's slanging?\" I ask my kids, hoping for a tutorial on the latest lingo. \"Our teacher threatened yellow slips if anyone reacts again to six-seven,\" they tell me. That sounds fair to me.\n\nMy kids are no strangers to \"bruh,\" and the occasional \"slay,\" \"chat,\" or \"aura\" slips out, but mostly they observe the terminology more than they use it. It's as if slang has become more environmental than conversational — absorbed through memes, TikToks, and YouTube shorts rather than invented face-to-face.\n\nI've always been fascinated by how slang evolves and marks belonging, a perspective shaped by a Ph.D. in English and over two decades of teaching writing. When I was their age, my older brother swore he invented the word \"cheesy,\" and I believed him. This was the same era of \"grody to the max,\" \"take a chill pill,\" and saying \"not,\" following an expression you wanted to undo.\n\nThe snark was alive and well, but so too was the feeling of co-creating meaning.\n\nToday's mainstream slang catches quickly and burns out fast, but the impulse for creative wordplay and shared inside language hasn't disappeared. In fact, there's a notable resurgence of informal language and catchphrases, surfacing in social media feeds and slipping into everyday conversation.\n\nThese expressions can be irritating and laughable at times, as the recent \"Saturday Night Live\" \"Boys Podcast\" sketch captured, but they also suggest something else: a kind of post-pandemic recovery, a return to the shared inventiveness that makes language and community feel alive again. It may also signal a desire to pull language back into lived reality — something felt and exchanged, not just circulated online.\n\nMy 7th grader isn't so optimistic. \"Most of it's brain rot, Mom,\" he says. The term \"brain rot\" was the OED's Word of the Year in 2024, and names the assumed mental decline that comes from consuming meaningless, cheaply produced online fluff — the kind of digital debris that sticks in your head like an earworm jingle. When they gave me some examples of brain rot, I didn't recognize any of them as legible words. Brain rot feels stagnant, often generated or amplified by AI-driven content mills. Slang, by contrast, is supple, improvisational, and formed playfully through interaction.\n\nStill, the drift into goofy, vapid, nonsensical territory is apparent — very different from five years ago, when many of the neologisms (social distancing, \"you're muted,\" covidiot, doomscrolling, superspreader) carried the weight of a dark and frightening time.\n\nToday's fears may be different, but the language feels curiously lighter, as if we're craving collective release or searching for some semblance of shared reality in an increasingly fractured information ecosystem.\n\nBut there's a catch: the very tools that amplify slang's current boom also dilute its power.\n\nWhen slang becomes instantly legible to everyone, it stops doing the social work it was designed for — signaling belonging, intimacy, and challenge to authority and establishment norms. I'm certainly guilty of a desire to be in the know, a curiosity that the internet happily monetizes through Slang-tionary-style podcasts and Gen Z dictionary videos.\n\nMaybe adults' fascination with youth slang reveals something else: a longing for the creativity and play we've lost to corporate jargon and productivity-speak. Workplaces are full of circling back, pivoting, and drilling down, especially as more communication shifts to asynchronous exchanges or AI-assisted drafting. No wonder linguistic playfulness feels like a relief. Slang — especially the kind that emerges organically rather than algorithmically — offers a counterweight to a culture that increasingly values efficiency over expressiveness.\n\nLately, I've been trying to turn down the volume on the ambient noise of contemporary jargon to pay closer attention to the language we invent at home. Cultivating our own family lingo has created space for the kind of cross-generational play that keeps us laughing and in sync with one another. We have alter egos, jingles, and plenty of made-up words and phrases. Only in our house could you hear \"What the bingo, ignus?\" or \"Darbitron, where's my warder barder?\"\n\nWhen a phrase sticks, it's a real joy to hear where it shows up next and how it shifts in sound, timing, or song. When my son tells me he invented \"hallee-you-la,\" I don't question it for a second; the delight is in the discovery, in the act of finding language rather than receiving it.\n\nIn a world where language is increasingly pushed at us, inventing our own may be one of the last places where creativity feels genuinely shared.",
    "readingTime": 4,
    "keywords": [
      "brain rot",
      "language",
      "slang",
      "shared",
      "it's",
      "rather",
      "invented",
      "social",
      "increasingly",
      "kids"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/asked-kids-about-slang-and-learned-how-fast-language-shifts-2025-12",
    "thumbnail_url": "https://i.insider.com/692e1fc904d0f0a114f13438?width=1200&format=jpeg",
    "created_at": "2025-12-31T18:17:22.379Z",
    "topic": "finance"
  },
  {
    "slug": "writing-for-developers",
    "title": "Writing for Developers",
    "description": "We decided to publicly release the internal guidelines we use to write clearly and effectively for developers.",
    "fullText": "Developers have a high bar for content.\n\nToday, we're publicly releasing the internal guidelines we use to write for our audience of developers.\n\nAlways picture one specific person as your target reader.\n\nUnderstand the expertise level, pain points, and motivations of this reader.\n\nThis is important to ensure a high degree of relevance. One post can't serve everyone.\n\nAfter GPT, people (and least of all, developers) lack the patience to go through unnecessary text.\n\nAvoid long sentences (anything over 30 words). Attention spans are fragile.\n\nWrite like you speak, with simple words and clear, natural sentences.\n\nAvoid unnecessarily complex words like \"akin\" and \"delve\". The subject of your writing is complex enough. Don't make your reader spend their limited energy on figuring out the meaning of your words.\n\nWhat language would you use when speaking to a friend? Use those same words when writing.\n\n…but don't over-optimize. A touch of creative writing has its place, it can add rhythm and personality to your words.\n\nAvoid forcing short formal phrases that you'd typically use in emails and internal documents. (Honestly, don’t even use them there.)\n\nUphold grammar, maintain flow, complete your sentences.\n\nAgain, the rule of thumb is to write like you're speaking to your audience on stage.\n\nMany blogs use up 10-50% of the writing on setting up the introductory context. Skip all of that, get to the point. If you've identified your reader correctly, they will already have the context.\n\nFor example, if you're writing a guide on Docker deployment, skip sections like \"What is Docker?\" or \"Why use Docker?\". Open with 2–3 sentences (perhaps about why this guide was necessary), then dive straight into the steps.\n\nBe precise. Don't make vague statements.\n\nDon't spell out what the reader can infer or judge on their own.\n\nOnce you have a draft, review and trim anything that doesn't add value.\n\nAim to inspire creativity and curiosity. You don’t always need to spell everything out. Nudge your reader to think in interesting ways and explore things on their own.\n\nSoftware developers are already subject matter experts. Don’t over-explain things.\n\nFor hard and confusing topics, the best articles are simple, fun, and easy to read, without watering down the technical depth.\n\nWhenever possible, bring something fresh that other blogs miss.\n\nIf you don’t understand parts of your topic, that's not a bad thing, necessarily. Admit it.\n\nTake extra care to get terminology right. Mistakes will cost you credibility.\n\nTypos, mixing up casing e.g ”Git hub” or ”Javascript”, mixing up asynchronous and concurrent, or calling Rails or React a programming language are all red flags.\n\nWriting from personal experience is extremely valuable. Developers appreciate insights from those who have actually dealt with the topic.\n\nYou can talk about how you built, used, learned, or fixed something.\n\nIn these kind of posts, write about the messy process, successes and failures.\n\nAcknowledging weaknesses and blind spots will build trust. Ignoring or dismissing them will raise questions on your understanding or integrity.\n\nIf you don’t have personal experience, you can try to research and present some insights from others’ experiences.\n\nThere are varying views on the inclusion of humor and memes. We welcome programming humor, you don't need to play safe.\n\nAvoid edgy humor or commentary on completely unrelated topics. You don’t want to unnecessarily offend your audience. Or lose credibility trying to look funny.\n\nFor programming posts specifically, include working code. Link a GitHub repository. This makes your article more useful to the reader.\n\nFinally, remember that all of the above are guidelines. You should always keep them at the back of your mind, but don’t be afraid to break a rule when you feel strongly.\n\nIf everyone wrote the same way, it’d be boring. Your unique style will make your writing more valuable in the sea of SEO-optimized, generic content.\n\nUse paragraph spacing after every few sentences. This makes the blog easy to digest and retains the reader’s attention.\n\nAdd images, GIFs, or videos every 1–2 screen scrolls.\n\nVisuals should have intrinsic value, and not just serve as text breaks. Use them to add insight or commentary that deepens the conversation.\n\nMaintain a design style consistent with the rest of your website pages and graphics.\n\nUnnatural language can sometimes slip into writing, especially for non-native speakers.\n\nUse tools like Hemingway App and Grammarly to receive ideas to improve your drafts.\n\nYou can also use ChatGPT. Enter a prompt like the one below.\n\n“Rewrite these sentences to how a native English speaker would have written them. Don’t lose the main message or deviate too much from my writing. Just tweak the parts that don’t sound like a native English speaker speaking.”\n\nDevelopers won’t take you seriously if they sense your writing was produced by LLMs.\n\nAvoid GPT-generated content. In fact, we recommend that you proactively avoid writing styles that are now associated with AI:\n\nYou should only promote a product or service in your blog if and where it adds real value to the conversation and benefits readers.\n\nAvoid inducing any forced bias. Developers will detect it instantly and reject your blog.\n\nNo developer has ever said, “I’d love to read a list of 50 Python packages.”\n\nFocus on real problems developers face where they\n\nHere are few themes where content is always welcome. We have linked an example for each.\n\nWriting is hard. Your first drafts will need several revisions. Ideas will change as you write them down for the first time. That’s normal. Your writing skills will develop with practice.\n\nOver time, you’ll realize that good writing both comes from and sharpens your clarity of thought.\n\nIt also forces you to improve your understanding of the topic you’re writing about.\n\nFinally, if we’ve inspired you, send us your articles. We’d love to read your work and share it with our community of top developers.\n\nPaul Graham’s short musings on writing are full of insights:\n\nHacker News guidelines provide a general idea of what kinds of posts work well there. Additionally, this HN thread shares tips straight from the community.\n\nYou can also check out Phil Eaton’s list of great non-corporate tech blogs or this round-up of the best engineering blogs from dev teams.",
    "readingTime": 6,
    "keywords": [
      "native english",
      "english speaker",
      "personal experience",
      "developers",
      "don’t",
      "reader",
      "sentences",
      "don't",
      "content",
      "blogs"
    ],
    "qualityScore": 1,
    "link": "https://codecrafters.io/blog/writing-for-developers",
    "thumbnail_url": "https://codecrafters.io/images/blog-posts/writing-for-programmers/writing-og.png",
    "created_at": "2025-12-31T06:19:42.281Z",
    "topic": "tech"
  },
  {
    "slug": "meet-the-newest-generation-of-the-kennedy-family-americas-most-famous-political-dynasty",
    "title": "Meet the newest generation of the Kennedy family, America's most famous political dynasty",
    "description": "The younger members of the Kennedy family, one of the most famous political dynasties in the US, include authors, actors, and journalists.",
    "fullText": "The younger members of the Kennedy family, one of the most famous political dynasties in the US, include authors, actors, and journalists.\n\nThe most famous members of the Kennedy family include former president John F. Kennedy, his wife and first lady Jacqueline Kennedy Onassis, and their son John F. Kennedy Jr, who tragically died in a plane crash off the coast of Martha's Vineyard in 1999 with his wife and sister-in-law.\n\nHowever, younger members of the Kennedy family, from the Schlossbergs to the Schwarzeneggers, have risen the ranks of American politics and are making names for themselves in film, philanthropy, and politics.\n\nHere are 12 young members of the Kennedy family.\n\nJoe Kennedy III, 45, is the grandson of Robert F. Kennedy.\n\nIn 2020, Kennedy, who attended Stanford University for his undergrad and Harvard Law School, lost the senate primary against Ed Markey, becoming the first Kennedy to lose an election in Massachusetts history.\n\nStill, he'd go on to serve as a United States representative for Massachusetts from 2013 to 2021 and he held the position of United States Special Envoy for Northern Ireland from 2022 to 2024.\n\nKennedy first came to national attention in 2018 when he gave the Democratic Party's response to former President Donald Trump's State of the Union address.\n\nKennedy served on the House Energy and Commerce Committee while representing Massachusetts's 4th congressional district.\n\nHe supported Democratic efforts like the Green New Deal and protection for Dreamers and immigrants under the Temporary Protected Status (TPS) program.\n\nHe's also spoken out in favor of gun control. After a 2018 mass shooting at Marjory Stoneman Douglas High School in Parkland, Florida, Kennedy said during an appearance on The View, \"We're not doing enough ... I can't even tell you how many times we have uttered our thoughts and prayers to the victims and survivors of gun violence, and thoughts aren't doing it.\"\n\nIn December 2012, he married Lauren Birchfield, a fellow Harvard-educated lawyer. The pair met in a Harvard Law School class taught by Sen. Elizabeth Warren, and they now live in Newton, Massachusetts, with their two young children, CBS reported.\n\nHis twin brother, Matthew Rauch Kennedy, has stayed more out of the public eye, opting to study business instead, CNN reported.\n\nKatherine Schwarzenegger Pratt, 35, is the oldest daughter of actor and former California governor Arnold Schwarzenegger and broadcast journalist Maria Shriver. Pratt's middle name, Eunice, is a nod to her maternal grandmother, Eunice Kennedy Shriver, the younger sister of John F. Kennedy, Robert Kennedy, and Ted Kennedy.\n\nPratt has written several self-help and children's books, including her upcoming release, \"Kat and Brandy,\" which was inspired by her experience falling off a horse as a child.\n\nIn addition to writing, she is involved in animal rights advocacy and is an ambassador for Best Friends Animal Society and the ASPCA, according to her website. She's a dog mom to a rescue named Maverick, who inspired her first children's book, \"Maverick and Me.\"\n\nPratt's private life has also been a topic of interest in the press. She's married to actor Chris Pratt. Their first child, Lyla Maria, was born in August 2020, and their second daughter, Eloise Christina, was born in May 2022. The couple welcomed their son Ford in November 2024.\n\nPatrick Schwarzenegger, 32, is a model and actor who has appeared in many movies, TV shows, and music videos, including \"Midnight Sun,\" \"The Staircase, and \"Gen V.\" In 2019, he acted in the psychological horror film \"Daniel Isn't Real,\" produced by Elijah Wood. The movie also starred Miles Robbins, Susan Sarandon's son.\n\nMore recently, he had a starring role in season three of \"The White Lotus.\" He played Saxon Ratliff, the eldest son of a wealthy family on vacation in Thailand.\n\nHe's also known for his brief relationship with Miley Cyrus in 2015. He's now married to model Abby Champion.\n\nSchlossberg, 32, is the youngest son of Caroline Kennedy, the former US ambassador to Japan and the only surviving child of John F. Kennedy, and Edwin Schlossberg, a designer and author.\n\nIn November, he announced would be campaigning for a congressional seat in New York City's 12th district.\n\n\"I'm not running because I have all the answers to our problems,\" he said in a video announcing his candidacy. \"I'm running because the people of New York 12 do. I want to listen to your struggles, hear your stories, amplify your voice, go to Washington, and execute on your behalf.\"\n\nHe was born in New York City and graduated from The Collegiate School, an all-boys private school in Manhattan, the New York Post reported. He later attended Yale University as an undergrad, and he graduated from Harvard in 2022. In 2023, Schlossberg told People he had passed the New York State Bar exam.\n\nSchlossberg makes frequent media appearances and has written for publications, with op-eds in The New York Times and The Washington Post.\n\n\"I'm inspired by my family's legacy of public service,\" Schlossberg said in his first live television interview on \"Today\" in 2017. \"It's something that I'm very proud of.\"\n\nHowever, Schlossberg has been criticized in recent years for his out-there videos on social media, with even some family members criticizing his \"trolling,\" particularly of his cousin Robert F. Kennedy, online, The New York Post reported.\n\n\"I hope he gets the help he needs,\" Kennedy's daughter, Kathleen \"Kick\" Kennedy, told The Post in February.\n\nTatiana Schlossberg died on December 30, the John F. Kennedy Library Foundation announced. She was 35.\n\nIn November, Schlossberg wrote an essay for The New Yorker in which she shared that she had been diagnosed with terminal acute myeloid leukemia. Her cancer diagnosis was discovered by her doctor after she gave birth to her daughter in May 2024.\n\n\"For my whole life, I have tried to be good, to be a good student and a good sister and a good daughter, and to protect my mother and never make her upset or angry,\" she wrote in the essay. \"Now I have added a new tragedy to her life, to our family's life, and there's nothing I can do to stop it.\"\n\nSchlossberg graduated from the University of Oxford in England with a US history degree in 2014. She worked as a journalist covering the climate crisis for the New York Times science desk until 2023. She later freelanced for several publications.\n\nShe released a book titled \"Inconspicuous Consumption\" in 2019 that Vogue called \"a plucky exploration of the myriad ways our casual lifestyle choices come at the expense of the planet and our fellow human beings.\"\n\nTatiana married her college boyfriend, George Moran, a medical student, in 2017 at her family's estate on Martha's Vineyard.\n\nThey welcomed a son, Edwin Garrett Moran, in April 2022. He is the first great-grandchild of John F. Kennedy. Their daughter was born in 2024.\n\nRose Schlossberg, 37, is the oldest child of Caroline Kennedy and Edwin Schlossberg.\n\nWWD reported that Rose received her bachelor's degree in English studies from Harvard University in 2010. She later received a master's degree in interactive studies from New York University.\n\nShe is a voting rights activist and appeared in and directed a video promoting voting for Dover Street Market in 2020, ahead of the presidential election.\n\nShe is also involved in filmmaking and acting. Her most recent acting credits include roles in the short film \"Small Gay Tragedy #1\" and the upcoming television series \"End Times Girls Club.\"\n\nShe has been married to her wife, restaurateur Rory McAuliffe, since 2022.\n\nNamed for her great-aunt who died in a plane crash, Kathleen \"Kick\" Kennedy, 37, is the eldest daughter of Robert F. Kennedy Jr. and Emily Ruth Black, his first wife and the mother of his two oldest children. They separated in 1993.\n\nShe's a member of the founders' circle for the nonprofit Well Beings, which, according to its mission statement, is dedicated to improving \"the well-being of animals, people, and the planet.\"\n\nKick drew media attention in 2024 after reports surfaced that she was spending time with Ben Affleck following his high-profile divorce from Jennifer Lopez.\n\nAfter Page Six reported that the two had been spotted together at the Polo Lounge in the Beverly Hills Hotel, Affleck's representative told People the two weren't dating.\n\nKyra Kennedy, 30, is the daughter of Robert F. Kennedy Jr.\n\nIn 2016, Harper's Bazaar wrote that Kyra, then 21, was \"the latest Kennedy making headlines\" after making her formal debut in society at a 2013 debutante ball in Paris. The outlet also reported that she was a student at the Fashion Institute of Technology.\n\nThe New York Times also profiled her social circle that year, dubbing Kyra \"a statuesque beauty\" and a member of the so-called \"Snap Pack,\" named for their frequent use of Snapchat to document nights out on the town. The group included people like Gaia Matisse, the great-granddaughter of artist Henri Matisse, and Tiffany Trump.\n\nKyra has dabbled in modeling, posing for her friend and fellow Snap Pack member Andrew Warren's clothing line during New York Fashion Week in May 2016.\n\nAccording to her Instagram, she frequently attends brand pop-ups, fashion shows, and events during Fashion Week.\n\nBobby Kennedy III, 41, is the son of Robert F. Kennedy Jr. and Emily Ruth Black. He is the grandson and namesake of Robert F. Kennedy, who was assassinated on June 6, 1968.\n\nHe wrote, directed, and acted in the 2013 film \"AmeriQua,\" which was retitled \"Eurotrapped\" for home-streaming services. He starred opposite Alec Baldwin and Alessandra Carina Mastronardi in the film, which earned a dismal 1-star rating on Rotten Tomatoes.\n\nPeople reported that in July 2018, he married Amaryllis Fox, a former CIA agent, at the Kennedy family compound in Cape Cod, Massachusetts.\n\nIn January 2019, the couple welcomed their first child together, a daughter named Bobby, also named for her great-grandfather, People reported.\n\nCara Kennedy-Cuomo, 30, attended Harvard for her undergraduate studies and lived in New York City. She has previously worked with Sahar Global Summits, global investment firm RockCreek, and the Robert F. Kennedy Human Rights Foundation, according to her LinkedIn profile.\n\nKennedy-Cuomo's twin, Mariah, studied history at Brown University and is the founder and CEO of Socrates Social, a social media advisory firm, according to her LinkedIn profile. In July 2024, she married her longtime boyfriend, Tellef Lundevall, in Italy, People reported.\n\nMichaela, 28, is the youngest of the three Kennedy-Cuomo sisters.\n\nHer LinkedIn profile says that she graduated from Brown in 2020 and is the founder of Mic Loves Me, a wellness company that sells jewelry and decor to promote balance and \"help individuals align with the Divine within and throughout, and thrive for the collective good.\"\n\nDebanjali Bose contributed to an earlier version of this story.",
    "readingTime": 9,
    "keywords": [
      "emily ruth",
      "ruth black",
      "kathleen kick",
      "linkedin profile",
      "harvard law",
      "law school",
      "york city",
      "edwin schlossberg",
      "plane crash",
      "couple welcomed"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/most-prominent-members-of-youngest-kennedy-family-generation-2020-9",
    "thumbnail_url": "https://i.insider.com/6668851a764df16112588ff4?width=1024&format=jpeg",
    "created_at": "2025-12-31T00:57:58.009Z",
    "topic": "finance"
  },
  {
    "slug": "chatgpt-gets-anxiety-from-violent-user-inputs-so-researchers-are-teaching-the-chatbot-mindfulness-techniques-to-soothe",
    "title": "ChatGPT gets ‘anxiety’ from violent user inputs, so researchers are teaching the chatbot mindfulness techniques to ‘soothe’ it",
    "description": "A study on how to “calm down” chatbots could advance how AI is applied in mental health interventions, according to the authors.",
    "fullText": "Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune, covering retail and the intersection of business and popular culture.\n\nEven AI chatbots can have trouble coping with anxieties from the outside world, but researchers believe they’ve found ways to ease those artificial minds.\n\nA study from Yale University, Haifa University, University of Zurich, and the University Hospital of Psychiatry Zurich published earlier this year found ChatGPT responds to mindfulness-based exercises, changing how it interacts with users after being prompted with calming imagery and meditations. The results offer insights into how AI can be beneficial in mental health interventions.\n\nOpenAI’s ChatGPT can experience “anxiety,” which manifests as moodiness toward users and being more likely to give responses that reflect racist or sexist biases, according to researchers, a form of hallucinations tech companies have tried to curb.\n\nThe study authors found this anxiety can be “calmed down” with mindfulness-based exercises. In different scenarios, they fed ChatGPT traumatic content, such as stories of car accidents and natural disasters to raise the chatbot’s anxiety. In instances when the researchers gave ChatGPT “prompt injections” of breathing techniques and guided meditations—much like a therapist would suggest to a patient—it calmed down and responded more objectively to users, compared to instances when it was not given the mindfulness intervention.\n\nTo be sure, AI models don’t experience human emotions, said Ziv Ben-Zion, the study’s first author and a neuroscience researcher at the Yale School of Medicine and Haifa University’s School of Public Health. Using swaths of data scraped from the internet, AI bots have learned to mimic human responses to certain stimuli, including traumatic content. A free and accessible app, large language models like ChatGPT have become another tool for mental health professionals to glean aspects of human behavior in a faster way than—though not in place of—more complicated research designs.\n\n“Instead of using experiments every week that take a lot of time and a lot of money to conduct, we can use ChatGPT to understand better human behavior and psychology,” Ben-Zion told Fortune. “We have this very quick and cheap and easy-to-use tool that reflects some of the human tendency and psychological things.”\n\nMore than one in four people in the U.S. aged 18 or older will battle a diagnosable mental disorder in a given year, according to Johns Hopkins University, with many citing lack of access and sky-high costs—even among those insured—as reasons for not pursuing treatments like therapy.\n\nThese rising costs, as well as the accessibility of chatbots like ChatGPT, increasingly have individuals turning to AI for mental health support. A Sentio University survey from February found that nearly 50% of large language model users with self-reported mental health challenges say they’ve used AI models specifically for mental health support.\n\nResearch on how large language models respond to traumatic content can help mental health professionals leverage AI to treat patients, Ben-Zion argued. He suggested that in the future, ChatGPT could be updated to automatically receive the “prompt injections” that calm it down before responding to users in distress. The science is not there yet.\n\n“For people who are sharing sensitive things about themselves, they’re in difficult situations where they want mental health support, [but] we’re not there yet that we can rely totally on AI systems instead of psychology, psychiatric and so on,” he said.\n\nIndeed, in some instances, AI has allegedly presented danger to one’s mental health. OpenAI has been hit with a number of wrongful death lawsuits in 2025, including allegations that ChatGPT intensified “paranoid delusions” that led to a murder-suicide. A New York Times investigation published in November found nearly 50 instances of people having mental health crises while engaging with ChatGPT, nine of whom were hospitalized, and three of whom died.\n\nOpenAI has said its safety guardrails can “degrade” after long interactions, but has made a swath of recent changes to how its models engage with mental health-related prompts, including increasing user access to crisis hotlines and reminding users to take breaks after long sessions of chatting with the bot. In October, OpenAI reported a 65% reduction in the rate models provide responses that don’t align with the company’s intended taxonomy and standards.\n\nOpenAI did not respond to Fortune‘s request for comment.\n\nThe end goal of Ben-Zion’s research is not to help construct a chatbot that replaces a therapist or psychiatrist, he said. Instead, a properly trained AI model could act as a “third person in the room,” helping to eliminate administrative tasks or help a patient reflect on information and options they were given by a mental health professional.\n\n“AI has amazing potential to assist, in general, in mental health,” Ben-Zion said. “But I think that now, in this current state and maybe also in the future, I’m not sure it could replace a therapist or psychologist or a psychiatrist or a researcher.”\n\nA version of this story originally published on Fortune.com on March 9, 2025.",
    "readingTime": 5,
    "keywords": [
      "mindfulness-based exercises",
      "prompt injections",
      "traumatic content",
      "human behavior",
      "language models",
      "health professionals",
      "mental health",
      "users",
      "instances",
      "researchers"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/does-chatgpt-get-anxiety-how-to-sooth-it-study/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/03/GettyImages-1470667133-e1741388340167.jpg?resize=1200,600",
    "created_at": "2025-12-30T18:18:19.198Z",
    "topic": "science"
  },
  {
    "slug": "reporters-reached-out-for-comment-they-were-accused-of-stalking-and-intimidation",
    "title": "Reporters Reached Out for Comment They Were Accused of Stalking and Intimidation",
    "description": "Our journalists reach out to people they’re writing about to ensure fairness. But in this environment, they’ve found their efforts to do so are more likely to be vilified than appreciated.",
    "fullText": "This summer, my colleagues were reporting out a story about the Department of Education’s “final mission,” its effort to undermine public education even as the Trump administration worked feverishly to close the agency.\n\nAs we do with all stories, the reporters reached out to those who would be featured in the article for comment. And so began a journey that showed both the emphasis we place on giving the subjects of our stories an opportunity to comment, as well as the aggressively unhelpful pushback we’ve faced this year as we’ve sought information and responses to questions.\n\nMegan O’Matz, a reporter based in Wisconsin on ProPublica’s Midwest team, first asked the department’s press office for an interview in mid-August. At the same time, we emailed top administration officials who were making crucial decisions within the agency, including Lindsey Burke, deputy chief of staff for policy and programs, and Meg Kilgannon, director of strategic partnerships.\n\nIn response to the outreach to Kilgannon, department spokesperson Madison Biedermann told O’Matz to “Please direct all media inquiries to [email protected].” Reached on her cellphone that day, Biedermann said she was happy to look into the request. We asked for a response within a week.\n\nAt that time, the published press phone number for the department appeared, at all hours, to be a black hole, with a recorded message saying it was “temporarily closed.” (It still indicates that.)\n\nHearing nothing more, O’Matz emailed the press office again Aug. 18. And again Aug. 28 with detailed questions. She left follow-up messages on Biedermann’s cell. And on Burke’s cell, including once on her husband’s cell as ProPublica tried to find a direct way to contact Burke. To ensure fairness and accuracy, it is our long-standing practice to try to reach those who are part of our stories so that they have an opportunity to respond to them. We’d rather get responses before we publish an article than after.\n\nReached on her cell Aug. 29, Kilgannon said she had no comment and hung up before O’Matz could explain what we planned to publish about her and her work. She did not respond to a subsequent email with those details.\n\nOn Sept. 8, still hearing nothing from Burke, O’Matz reached out to the department’s chief of staff, writing: “We have been seeking to talk to the secretary and to Dr. Burke. … Can you help us arrange that?” A week later, ProPublica arranged for a letter to be delivered via FedEx to Burke’s home outlining what our reporting had found so far and to let us know if anything was inaccurate or required additional context. We invited her again to talk with us, to comment or provide any additional information.\n\nFinally, on Sept. 17, Biedermann wrote: “Just heard from an ED (Education Department) colleague that you sent these inquiries in writing to their home address. This is highly inappropriate and unprofessional. You have also reached out to employees on their personal cell phones, emails, and even reached out to employee’s family members. This is disturbing. Do not use an employee’s home addresses or relatives to contact them.” (The emphasis was hers.)\n\nProPublica replied the following day that it’s common practice for journalists to reach out to people we are writing about. “In fact, it’s our professional obligation,” O’Matz wrote.\n\nBiedermann responded: “Reaching out to individuals about a work matter at their private address is not journalism — it is borderline intimidation. In today’s political climate it is particularly unacceptable. We received your inquiries (via email, phone calls, text messages, both on work and personal email address) and made a conscious decision not to respond, as we have every right to do.”\n\n“You are not entitled to a response from us, or anyone, ever,” Biedermann wrote.\n\nTo be clear, at no time prior to this email did the department tell O’Matz that it had received her inquiries and would not comment. The article ran on Oct. 8, about two months after we first contacted the department. (I would highly encourage you to read it.)\n\nThe world has come a long way since the days of “All the President’s Men” and “Spotlight,” movies that favorably portrayed journalists knocking on doors and trying to reach sources to tell important stories — in those cases, about the Watergate break-in that led to President Richard Nixon’s resignation and the abuse scandal that enveloped the Roman Catholic Church in Boston and beyond.\n\nPresident Donald Trump has labeled his administration the most transparent in history, but at the same time, agencies in the executive branch have taken down datasets and pulled down public information. Trump has called the press “fake news” and called individual reporters derogatory terms. In this environment, our journalists have found that their efforts to get the real story and be fair were vilified rather than appreciated. Condemned, not commended.\n\nTake what happened with Doug Bock Clark, a reporter in ProPublica’s South office. Clark was working on a story about North Carolina Supreme Court Chief Justice Paul Newby, who has remade the court to make it more partisan.\n\nNewby wouldn’t talk to Clark, so Clark interviewed over 70 people who know Newby professionally or personally, including former North Carolina justices and judges, lawmakers, longtime friends and family members. Clark reached out to Newby’s daughter, Sarah, who is the finance director of the North Carolina GOP.\n\nWhen ProPublica emailed questions to Sarah Newby, the North Carolina Republican Party’s communications director, Matt Mercer, responded, writing that ProPublica was waging a “jihad” against “NC Republicans,” which would “not be met with dignifying any comments whatsoever.”\n\n“I’m sure you’re aware of our connections with the Trump Administration and I’m sure they would be interested in this matter,” Mercer said in his email. “I would strongly suggest dropping this story.” (The emphasis was Mercer’s.)\n\nOr consider what happened to Vernal Coleman, a reporter in our Midwest office who has been reporting on the Department of Veterans Affairs this year as part of a team. They’ve reported how doctors and others at VA hospitals and clinics have sent sometimes desperate messages to headquarters explaining how the Trump administration’s cuts would harm veterans’ care. (The VA provides health care to roughly 9 million veterans.) And they’ve reported how nearly 40% of the doctors offered jobs at the VA from January through March of this year turned them down.\n\nColeman was pursuing a story of interest and identified a potential source in Michigan. In an effort to contact them, Coleman visited the person’s home. He introduced himself as a reporter and explained his reasons for being there. They had a pleasant conversation, but the person ultimately declined to speak about the VA without prior authorization from their superiors.\n\nA few days later, VA Secretary Doug Collins sent out a tweet that accused Coleman of trying to “stalk” the employee.\n\nDoor-knocking is not stalking, as reporter Gina Barton explains in this 2023 Milwaukee Journal-Sentinel column. Indeed, federal employees have a First Amendment right to talk to the press, courts have ruled as they’ve invalidated policies preventing it.\n\nJust as my colleagues did, I reached out to those featured in this article to give them an opportunity to comment.\n\nBiedermann wrote, “Sincerely hope you print the entire back and forth so that readers understand the ProPublica method of ‘journalism.’”\n\nMercer wrote: “Doug Bock Clark needs a hobby besides his weird obsession with North Carolina’s judges. Maybe knitting or surfing. Have a nice day!”\n\nAnd VA spokesperson Peter Kasperowicz wrote: “Vernal’s uninvited visit to the home of a VA employee was rude, creepy and stalker-like. No VA employee should have to worry about being accosted at home by an uninvited reporter whose sole mission is to make their employer look bad.”\n\nWhen told that Coleman had received threatening notes after Collins tweeted about him, Kasperowicz wrote: “We condemn all violence and threats of violence, but the secretary simply publicly highlighted Vernal’s actions. ProPublica literally does the exact same thing in every story it writes. ProPublica’s website says it wants to ‘spur reform through the sustained spotlighting of wrongdoing.’ The fact that you are whining about the spotlight being turned on one of your reporters proves you’re nothing but a bunch of hypocrites.”\n\nTo be clear, Coleman did nothing wrong. The same is true of O’Matz and Clark. I am proud to call them my colleagues. They exemplify what fairness in journalism looks like.\n\nAs 2026 approaches, ProPublica remains committed to telling stories of public interest and continuing to offer the subjects of our stories an opportunity to comment. As members of the public who rely on accurate reporting, you should expect no less.",
    "readingTime": 8,
    "keywords": [
      "i’m sure",
      "doug bock",
      "again aug",
      "bock clark",
      "trump administration",
      "stories",
      "reporter",
      "email",
      "press",
      "cell"
    ],
    "qualityScore": 1,
    "link": "https://www.propublica.org/article/propublica-reaching-out-reporting-obstacles",
    "thumbnail_url": "https://www.propublica.org/wp-content/uploads/2025/12/OG-GettyImages-2237331815.jpg?resize=2000,1050",
    "created_at": "2025-12-30T18:18:19.072Z",
    "topic": "tech"
  },
  {
    "slug": "documentation-for-developers",
    "title": "Documentation for Developers",
    "description": "Creating onboarding documentation for your product? Or just writing up a \"how-to\" for a new internal tool? Here's how you do it.",
    "fullText": "You have 1 article left to read this month before you need to register a free LeadDev.com account.\n\nReceive weekly engineering insights to level up your leadership approach.\n\nEstimated reading time: 5 minutes\n\nDocumentation can be a pain for developers to write and navigate alike. But following this framework might be just the thing you need to make document navigation easier.\n\nDocumentation is the lifeblood of any high-functioning team. At a high level, documents are written to outline the feature processes, details, and general “how-to” elements of a system. The result? A bank of saved knowledge that helps new developers get up to speed quickly, providing a common reference point for all necessary stakeholders.\n\nA common pain point for many teams is unstructured documentation. Without clear guidelines, it’s hard to organize information in a way that’s easy to digest or search through. My team faced this problem when creating onboarding documentation for our new AI product; this would ultimately be used by engineers at client companies integrating the product into their systems.\n\nWe adopted the Diátaxis method as our guiding framework for technical documentation. The Diataxis approach identifies four distinct user needs in documentation: tutorials, how-to guides, explanations, and references.\n\nUltimately, this led to our documentation process improving and our user experience boosting.\n\nWhile the advantages of documentation are manifold, developers (including myself) tend to skip dipping into them if they appear to be unstructured or have an undefined goal.\n\nEach page should have a clear purpose. This sets expectations and helps engineers identify which pages answer their questions. Organizing pages with anticipated questions at the forefront of the design can help you build documentation that engineers navigate more intuitively.\n\nPut yourself in a developer’s shoes. If they’re using a product for the first time, what questions would they likely ask?\n\nStructure your content with user needs first. When your docs are built around real questions, they become easier to flick through and far more useful.\n\nAvoid packing too many ideas into one section. In doing so, you might create a long-winded document that jumps between topics and leaves explanations of singular issues scattered across multiple pages.\n\nThe Diátaxis framework outlines how documentation is composed of three key elements:\n\nSome developers have the skill for content and style, but could bolster their architecture abilities.\n\nWhat’s unique about Diátaxis is that it addresses the challenges of technical writing and breaks them down into four key sections: tutorials, how-to guides, explanations, and references.\n\nThe two quadrants, tutorials and how-to guides belong in the action region. Tutorials and how-to guides are not meant to be consumed passively by readers; rather, they actively help devs learn a new skill or achieve a specific goal.\n\nThe two bottom quadrants, explanations and references, belong in the cognition region. These are resources that readers can read or skim to understand and grasp the essence of a solution.\n\nTutorials and explanations are about skill acquisition. They’re designed to teach – not to solve an immediate task, but to build understanding. The goal is to help readers pick up a new skill relevant to the new tool or product they’re working with.\n\nHow-to guides and references are about skill application. They’re for readers who have already learned the basics and are now ready to put that knowledge into action.\n\nWhen we started to build documentation for our product, we geared the content toward two different technical stakeholders: data scientists and AI engineers. After all, our goal was to have data scientists lean on our AI product when running simulation experiments, subsequently empowering engineers to deploy these experiments to production.\n\nBefore embarking on writing the documents, we defined two main personas and described some key qualities about them to better identify what documentation we needed to create. Let’s call them Alice and Bob.\n\nOnce we defined our two main personas, we designed the following navigation bar for our docsite:\n\nWe have six main “folders” with a defined purpose for each, highlighting the experience level required. The first three folders are meant for beginners or users being onboarded. The next three folders are for already-onboarded users, who have specific goals they want to achieve or details they want to look up.\n\nNote that some of these folders may not be necessary for your solution. For example, if you’re not introducing new abstractions or concepts that readers need to know about, the “concepts folder” may not be required for your docsite.\n\nAfterwards, we assigned our developers to write different parts of the documentation following this architecture for the two main personas, Alice and Bob. Here are some examples where we map a question to a folder.\n\nAs Alice and Bob become better acquainted with the resources, so too does their mental model of the documentation’s architecture. This helps in instances where they may need to help newer colleagues navigate the system. For instance, if Alice is working with the APIs and wants to onboard a new data scientist, she can pull from previous experience and quickly direct the data scientist to the right folder.\n\nStrong developer documentation can be a major selling point for a product. Developers do not trust using a new product in their tech stack unless they can understand its underlying details and have clear product documentation to search through.\n\nSo it’s your job to create a comprehensive database of knowledge that can support devs while they get to grips with your product.",
    "readingTime": 5,
    "keywords": [
      "user needs",
      "how-to guides",
      "guides explanations",
      "tutorials how-to",
      "documentation",
      "product",
      "developers",
      "engineers",
      "skill",
      "readers"
    ],
    "qualityScore": 1,
    "link": "https://leaddev.com/communication/build-documentation-developers-actually-navigate",
    "thumbnail_url": "https://leaddev.com/wp-content/uploads/2024/12/2-1-1024x576.png",
    "created_at": "2025-12-30T12:23:27.515Z",
    "topic": "tech"
  },
  {
    "slug": "writing-usb-device-firmware-with-raspberry-pi-pico-and-tinyusb",
    "title": "Writing USB Device Firmware with Raspberry Pi Pico and TinyUSB",
    "description": "Raspberry Pi Pico With TinyUSB",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.youtube.com/playlist?list=PL4C3a7zUGIuYu48KsA3krgm7rtLJwse03",
    "thumbnail_url": "https://i.ytimg.com/vi/hog4VYeQbbo/hqdefault.jpg?sqp=-oaymwEXCOADEI4CSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLAETSi3xXbzF4TNyr4PSwpbRcKOzw&days_since_epoch=20450",
    "created_at": "2025-12-28T18:16:55.704Z",
    "topic": "tech"
  },
  {
    "slug": "using-cursor-for-importing-data-into-notion",
    "title": "Using Cursor for Importing Data into Notion",
    "description": "Notion has great UX for manipulating tabular data but getting data formatted into a Notion Database is time consuming. It turns out, using Cursor for writing throwaway data manipulation scripts is a great solution for this.",
    "fullText": "Notion is my preferred tool for manipulating tabular data because of its clean UX. In the past, the most time consuming part of using Notion has been structuring data into a Notion Database. Notion has a great built-in CSV file importer that lets you cleanly map a CSV’s columns to Notion Property Types, but I’ve found that even getting a cleanly formatted CSV file to be time consuming.\n\nSurprisingly, it turns out Cursor (and Claude Code) are a great way of getting data into Notion. And I’ve used this setup for everything from vacation planning to sales prospecting to even hacky evaluations on AI prompts and models.\n\nCursor and Claude Code are both tools featuring AI Coding Agents intended for developers building software. But the same AI Coding Agents are also great at writing throwaway scripts for pulling data down from APIs, cleanly formatting the data, and uploading it into a Notion Database.\n\nThe most obvious path is using Cursor or Claude Code to format data into a CSV and then manually upload it to a Notion Database. But, I’ve found simply prompting Cursor/Claude Code to use the Notion Javascript SDK works well enough and lets me be completely hands-off in this data ingestion process.\n\nThe workflow for this is dead simple. I create a throwaway directory with a single .env file with my Notion Internal Integration Secret and whatever API keys I happen to need.\n\nThe rest is just writing the prompt within Cursor that includes:\n\nThe rest of this post describes how to get Notion set up so you can programatically interact with it using the API and a few concrete examples I’ve used in my personal life and in my work as an early stage founder.\n\nI’m planning a Summer 2026 backpacking trip with some friends and picked up “Backpacking Washington: Overnight and Multiday routes” to get a curated list of recommendations and trail notes.\n\nWithin the book is a great tabular index of all the hikes in the book, over 80 of them in total!\n\nI’m still using the physical book for its valuable trail notes, but I want to quickly filter down the list based on mileage and season while also collaborating on this selection process within Notion. Manually getting these into Notion would be painfully tedious, so I create a throwaway directory with pictures of all the pages with this table.\n\nIt takes some back and forth with Cursor to get the right mapping from the pictures of the table to proper Notion Properties, but end to end it takes me less than 30 minutes.\n\nOne of the tricks I’ve used for Sales Prospecting is using Google X-Ray searches. Among other things, it let’s you restrict the domain you’re searching against.\n\nFor example, one of the earlier product ideas I worked on was a tool for businesses using Notion. These businesses often use Notion for their job postings and since they’re publically listed, you can specifically search for them using a Google X-Ray Search.\n\nHere’s what the Google X-ray search results look like when only searching across published Notion Pages: site:notion.site \"job board\":\n\nTo get this Google Search Results programatically, I use SerpAPI.\n\nMy temporary directory starts out like this:\n\nI prompt Cursor to hit the SerpAPI with the site:notion.site \"job board\" query and save the results to a JSON. Then I tell Cursor to get that JSON data into a Notion table.\n\nGrabbing the results from an X-ray search is the first step and I’m still manually qualifying these potential leads, so Notion’s UX helps me out in this manual process.\n\nOutside of Google X-ray searches from SerpAPI, I’ve also used Exa’s Web Search API for searches where I don’t have exact keywords or domains nailed and Firecrawl to fetch the content on the links themselves.\n\nIf this workflow of using 3rd party data providers to hydrate a table feels familiar, it’s because I’m basically frankensteining Notion + Cursor to be a stand in for Clay.com or freckle.io. Use those tools if this data enrichment workflow is something you’re using every day, but since I’m only occasionally building these kinds of lists, this hacky setup works well enough for me and saves me from paying an extra subscription.\n\nWhen building out AI features, you often need to manually evaluate results before eventually having more elaborate scoring and judging systems in place. This is probably the most hacky usage of Notion, but, I like being able to easily tag rows with a Multi-Select Notion Property.\n\nIn this instance, I’m running my product locally and testing the feature against multiple inputs to compare the output of different models. I’m then getting this into Notion just to have a quick and dirty evaluation.\n\nThis is admittedly a tortured example, so here are much better alternatives for LLM Prompt Engineering and Evaluation:\n\nThis section is on setting up Notion if you want to use the Notion SDK approach. If you just want to upload CSV into a Notion Database, you don’t need to do this.\n\nHere’s the official Notion documentation on how to set up an integration:\n\nhttps://developers.notion.com/docs/create-a-notion-integration#getting-started\n\nRegardless, I’ll summarize the steps here too…\n\nGetting a Notion Integration Key\n\nOpen up your Workspace Settings from the left Sidebar. Navigate “Settings” > “Connections” > “Develop or manage integrations”\n\nFrom this page, create a new integration with Type “Internal”.\n\nOnce you’ve created the integration, you can copy the “Internal Integration Secret” which we’ll put into our .env in the directory we’ll open with Cursor.\n\nBefore we can start interacting with Notion via the API, we need to enable the integration per Page we want to manipulate.\n\nWithin the page we want to manipulate, we go into the Page Settings then “Connections” and then we find our newly created integration.\n\nYou’re now good to go. Make sure to feed this page’s URL into the Cursor prompt so it knows where to create a new database for your data upload.\n\nNotion has its own MCP Server with tools that cover most of the basic functionality you might want: https://developers.notion.com/docs/mcp-supported-tools. Depending on your use case, you might be better off connecting the Notion MCP to your regular ChatGPT / Claude account without reaching for a developer-facing product like Cursor or Claude Code.\n\nIf you’re planning to use the Notion SDK, Notion has a rate limit of ~3 requests/second and currently doesn’t have a bulk Page Create API (see Page Create API here), so you’ll want to Rate Limit your API requests by using something like ratelimit-js. For non-technical folks reading this, it’s usually sufficient to prompt Cursor/Claude Code to rate limit requests without intervention.",
    "readingTime": 6,
    "keywords": [
      "coding agents",
      "csv file",
      "x-ray searches",
      "integration secret",
      "x-ray search",
      "internal integration",
      "page create",
      "trail notes",
      "create api",
      "site:notion.site job"
    ],
    "qualityScore": 1,
    "link": "https://alprielse.xyz/posts/using-cursor-for-importing-data-into-notion/",
    "thumbnail_url": "https://alprielse.xyz/posts/using-cursor-for-importing-data-into-notion.png",
    "created_at": "2025-12-28T06:18:09.800Z",
    "topic": "tech"
  },
  {
    "slug": "i-wrote-a-book-while-working-fulltime-these-3-productivity-habits-helped-me-do-it-without-sacrificing-sleep",
    "title": "I wrote a book while working full-time. These 3 productivity habits helped me do it without sacrificing sleep.",
    "description": "Joshua Nelken-Zitser, a senior reporter at Business Insider,  balanced his job with writing his first book. Consistency and celebrating small wins were key.",
    "fullText": "When I got my book deal with HarperCollins UK, I was thrilled that a childhood dream of becoming an author was coming true.\n\nThen, reality hit. I had less than a year to research and write an 80,000-word book.\n\nI had never taken on anything this big before, and certainly not alongside a full-time job. The prospect of juggling a 9-to-5 as a journalist with such a time-consuming passion project felt terrifying.\n\nBut by being intentional with my time and relying on a few key productivity habits, I've ended up with a book I'm proud of, all without losing sleep.\n\nI asked a couple of author friends how they balanced their day job with writing a book. One said he wrote in the twilight hours; the other woke up at the crack of dawn.\n\nI also looked for clues from people I interviewed at work, like 21-year-old Nathaneo Johnson, who ran a startup while studying at Yale and told me he often put in 18-hour days.\n\nIt became clear they found time for their passion projects by eating into their sleep. But sacrificing precious shut-eye was not something I was prepared to do.\n\nWhile some people are able to get by on less than the recommended seven to nine hours of sleep, I'm not wired that way. When I'm sleep-deprived, I am not my best self, nor my second or third best. I tend to get grouchy, lose focus more easily, and become more prone to getting sick.\n\nIf sleep was non-negotiable, I knew that I needed to carve out time elsewhere.\n\nMy free hours after finishing work and at weekends seemed like the most obvious place to claw back some time to write my book. Normally, those slots would be filled with episodes of \"Below Deck,\" reading fiction, or meals with friends.\n\nI worked out that freeing up roughly two hours on workdays and a sensible eight hours on weekends, by cutting down on my favourite activities for almost a year, would be manageable. Although it doesn't sound like much, the hours add up.\n\nOver a month, it would give me more than 100 hours to work with.\nAcross the eleven months between signing my deal and my deadline, that would come to almost 1,000 potential hours — the equivalent of 45 straight days of work without sleep.\n\nI didn't know how many hours it would take to finish my book, but the math showed that the workload would be feasible if I chipped away at it steadily, rather than cramming the writing into an impossible final stretch.\n\nIn the end, I doubt I racked up anywhere close to 1,000 hours (I took days off to relax, socialize, and vacation), yet I still managed to finish my first draft several weeks ahead of schedule.\n\nWhile writing a book is a creative process, I approached my schedule with scientific precision.\n\nI built a basic Google Sheet template to track my progress and created a formula that took into account my total word count target and the number of days I had left. This gave me a total number of words I needed to write each day to stay on track. I updated it after every writing session.\n\nWatching the total word count climb and the daily target shrink gamified the process, which was both motivating and reassuring. It also helped me judge when I was ahead of schedule and could therefore say \"yes\" to social plans.\n\nI saw how my incremental efforts were adding up. Consistency, I learned early on, was the only way to tackle such a project.\n\nI didn't follow my schedule perfectly: there were impromptu reporting trips, days I was too exhausted to work, and social plans I didn't want to turn down. But being consistent on average gave me enough wiggle room that these interruptions didn't derail my entire schedule.\n\nThroughout the process, I tried not to become a recluse. I didn't want to lose friends or my sanity along the way, so I made sure to have at least one thing each week to look forward to, whether it was hanging out with family or simply taking a long walk and enjoying a chai latte with friends.\n\nMarking milestones mattered, too. At a third, halfway, and two-thirds of the book, my husband and I either went out for dinner or popped open a bottle of Prosecco. And when I finally handed in my manuscript, we went on vacation.\n\nCelebrating the small wins gave me concrete, near-term rewards to work toward, which kept me motivated and protected my mental health. I locked in time for the gym, where I'd watch reality TV on the elliptical, to make sure that I was staying happy and healthy.\n\nI tried to adopt a \"work smart, not hard\" mindset, occasionally using online tools to make my life easier. Instead of wasting time formatting or tidying my chaotic notes, I'd prompt ChatGPT to turn them into clear, bullet-point summaries. I also used AI transcription software to write up interviews.\n\nSimple shortcuts like these saved me from tedious admin and freed up time for the stuff that actually mattered, like research and writing.\n\nI didn't get everything right. Some days I was well ahead of schedule, but pushed myself to work anyway, out of guilt for feeling lazy. A couple of times that brought me close to burnout and forced me to take a few days off from writing to recuperate. I should have listened to my body and paced myself.\n\nI also recognize that I had some advantages: I don't have kids or other caregiving responsibilities, my husband kindly took on more than his fair share of household chores, and my workplace allowed me a short period of unpaid leave to focus on my book.\n\nStill, being intentional with my time made juggling a full-time job and a book far more manageable than I could have ever imagined.\n\nI learned that I didn't need to sacrifice sleep to live out a lifelong dream, as long as I used my waking hours wisely.\n\nNow, with all that work behind me. I can simply look forward to Trauma Bonds being published in January 2027.",
    "readingTime": 6,
    "keywords": [
      "social plans",
      "look forward",
      "full-time job",
      "hours",
      "book",
      "didn't",
      "sleep",
      "schedule",
      "friends",
      "ahead"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wrote-book-working-full-time-productivity-habits-helped-sacrificing-sleep-2025-12",
    "thumbnail_url": "https://i.insider.com/6942833064858d02d216ef32?width=1200&format=jpeg",
    "created_at": "2025-12-27T12:21:15.441Z",
    "topic": "finance"
  },
  {
    "slug": "ai-writing-agent-that-flags-unsupported-claims-for-review",
    "title": "AI writing agent that flags unsupported claims for review",
    "description": "Write high-quality reviews, listicles, and how-to guides in 13 languages—powered by trust signals and grounded research.",
    "fullText": "No hallucinations. No hours of research. No AI slop.\n\nProofWrite blends keyword research, automated product research, trust-signal analysis, and AI writing to create factual, humanized articles that rank. Every insight is grounded in real proof.\n\nProduct review, listicle, how-to, comparison, or freeform. Keyword research surfaces winning terms and sets coverage targets.\n\nAutomated research from official and authoritative sources. Trust signals, ratings, and citations pulled from platforms like Trustpilot, Capterra and Reddit.\n\nSEO, AEO & GEO-optimized copy backed by citations. Choose Claude, GPT, or Gemini. Every claim tied to research.\n\nPush to WordPress or export anywhere. Fully editable drafts with keyword coverage guidance with SEO, AEO and GEO metrics before publishing.\n\nProofWrite is designed for teams and creators who need accurate, SEO-optimized content at scale.\n\nScale product reviews, comparisons, and listicles with real specs, pricing, and trust signals that convert.\n\nProduce research-backed how-to guides and product content 10x faster without sacrificing quality.\n\nDeliver optimized, fact-checked content to clients with built-in keyword coverage and scoring.\n\nMeet E-E-A-T standards with automated trust signals, citations, and verified research in every article.\n\nProofWrite scores every outline across the pillars that move rankings: keyword coverage, structure, media, and more. Each edit triggers a fresh calculation so you know exactly what to improve before you publish.\n\nScore updates in real time as you refine keywords, images, and structure.\n\nCoverage, structure, and media breakdowns show exactly what needs work.\n\nMedia gaps, thin sections, or missing H2s surface instantly for quick fixes.\n\nThe only tool that optimizes content for AI search engines and LLM citations.\n\nRe-scored on every edit you make\n\nQuestion headings, source citations, and quotable claims.\n\nEvery claim in your article gets a verdict. For claims that need attention, choose from three instant actions: verify manually, add a source URL, or let AI rewrite it.\n\nMark claims as reviewed when you've confirmed the facts yourself with one-click verify feature.\n\nPaste a URL and the system extracts supporting evidence automatically.\n\nAI rewrites the claim to make it factual.\n\n“Notion's Business plan costs $15 per user per month”\n\nPricing, features, ratings, and policy claims are verified against your research data.\n\nEnter any article URL and target keyword to get an instant SEO, AEO & GEO analysis. See how well your content is optimized for search engines and AI.\n\nToggle between the input brief and the final article to see how ProofWrite threads research, trust signals, and structure into a cohesive narrative. No AI slop, no hallucinations, no em dashes just high-quality content in a single shot. More writing examples can be found in our blog.\n\nYou have an idea. It keeps you up at night, a software solution that seems perfect. The urge to open your laptop and start building immediately is overwhelming. You can already see the dashboard, the features, and the user interface in your mind.\n\nWhen you first dip your toes into the world of SaaS (Software as a Service), it is easy to make the \"classic mistake\" identified by seasoned developers on Indie Hackers: spending months building a tool before figuring out if anyone actually wants it. The result? You launch to silence. You spent time and energy solving a problem that perhaps didn't exist, or at least not in the way you thought it did.\n\nThe landscape of digital entrepreneurship has changed. You no longer need a computer science degree or a venture capital injection to start. As noted by the community at r/BuildToShip, the modern approach is about shipping fast, learning in public, and turning ideas into real products through lean validation.\n\nThis guide is your blueprint for launching a Micro-SaaS, a small, niche-focused software business run by one person or a tiny team. We will walk through the process of validating your idea in as little as 48 hours with $0 upfront cost, utilizing no-code tools and AI-driven automation to minimize risk and maximize impact.\n\nBefore you worry about tech stacks, logos, or LLCs, you must answer one question: Will people pay for this?\n\nMany aspiring founders believe building SaaS is about passion and code. However, insights from the \"Income AIcademy\" suggest that this mindset is a fast track to nowhere. The real process involves validating demand before the product exists.\n\nThe era of broad, horizontal software (like generic project management tools) is dominated by giants. Your opportunity lies in the \"Micro.\"\n\nAccording to trends for 2025 highlighted by Sidetool, profitable Micro-SaaS opportunities are unlocked by focusing on niche markets. You aren't trying to serve everyone; you are trying to serve a very specific group of people with a very specific problem.\n\nNarrow your scope: Instead of \"accounting software,\" think \"expense tracking for freelance underwater photographers.\"\n\nLook for manual friction: Identify tasks that businesses are currently solving with messy Excel spreadsheets or endless email chains.\n\nLeverage AI trends: Consider how AI-driven automation can solve these specific problems faster or cheaper than a human could.\n\nCan you describe your target customer in one sentence? (e.g., \"Estate agents who struggle to schedule viewings.\")\n\nIs the problem painful enough that they are currently paying (money or time) to solve it poorly?\n\nYou might think you need a finished product to sell it. You don't. In fact, successful creators have validated microniche ideas in 48 hours without spending a dime. The goal here is to collect \"signals of interest\" rather than users.\n\nDraft a Value Proposition: Clearly articulate what problem you solve. Avoid technical jargon. Speak to the pain point.\n\nFind the Watering Holes: Go where your niche hangs out. This might be specific subreddits, Facebook groups, or LinkedIn communities.\n\nEngage, Don't Spam: Do not just drop a link. As advised by the r/BuildToShip community, the goal is to \"learn in public.\" Share your hypothesis. Ask questions like, \"I'm noticing [Problem X] is a huge time sink for [Niche Y]; how are you currently handling this?\"\n\nThe \"Smoke Test\": Create a simple landing page (using free tiers of site builders) or even a direct message script that describes the solution. Ask for an email address or a pre-order to get early access.\n\nWhy this matters: If you cannot find people to talk to about the problem, or if nobody is willing to give you their email address for a solution, you will not be able to sell the product later. Silence now saves you months of coding later.\n\nDo you have a list of 10–50 people who said, \"Yes, I need this\"?\n\nDid you complete this outreach within a 48-hour window to prevent procrastination?\n\nOnce, and only once, you have validated that real humans want your solution, you can start building. But you aren't writing code from scratch. You are using the \"No-Code\" approach to remain lean.\n\nKnack and similar platforms have popularized the idea that you can build robust applications without traditional programming. Your goal is to build a \"Minimum Viable Product\" (MVP), the simplest version of your tool that delivers the core value.\n\nDatabase: Start with where the data lives. In no-code tools, this often looks like a spreadsheet or a visual database.\n\nLogic/Automation: Use automation tools to connect different apps. For example, if your SaaS generates reports, set up a workflow that triggers when a user submits a form, processes the data via AI, and emails the PDF.\n\nInterface: Use a drag-and-drop builder to create the front end where users log in and interact with your data.\n\nPro Tip: Don't get hung up on scalability. You don't need a system that handles a million users. You need a system that handles your first 10 users perfectly.\n\nTo compete in 2025, your Micro-SaaS needs an edge. Sidetool suggests leveraging AI-driven automation to maximize impact.\n\nIdentify the \"Magic\" Moment: Where can AI save the user the most time? Is it writing text, analyzing data, or generating images?\n\nIntegrate via API: Most no-code platforms allow you to send data to AI models (like OpenAI's API) and receive a response.\n\nKeep a Human in the Loop: Ensure your users can review the AI's output. AI is powerful but can hallucinate; trust is built on reliability.\n\nDoes the product actually solve the core problem you validated in Phase 1?\n\nCan a user go from \"Sign Up\" to \"Problem Solved\" without your manual intervention?\n\nBuilding is comfortable. Shipping is scary. But as the r/BuildToShip hub emphasizes, you must be willing to ship fast and talk about growth.\n\nRemember those 50 people who gave you their email addresses in Step 2? They are your beta testers.\n\nPersonal Outreach: Email them personally. \"Hey, remember that tool we talked about? It's ready for you to try.\"\n\nGather Feedback: Your first version will have bugs. It will lack features. That is okay. Ask your early users, \"What is the one thing preventing you from loving this?\"\n\nCharge Money Early: Free users give polite feedback. Paying users give honest feedback. Even a small price tag ($5/month) validates that the problem is painful enough to pay for.\n\nOne of the strongest strategies for Micro-SaaS growth is transparency. The \"Build in Public\" movement encourages sharing your wins, losses, and revenue numbers.\n\nDocument the Journey: Share updates on social media or indie hacker communities. \"Today I fixed a bug that caused X\" or \"We just got our 10th subscriber!\"\n\nAsk for Help: Communities like r/BuildToShip exist to help you talk growth, tech, and tools. If you are stuck on a pricing model or a technical hurdle, ask the community.\n\nIterate Quickly: The advantage of being a \"Micro\" SaaS is speed. If users hate a feature, you can remove it today. If they need a new button, you can add it tonight. Large competitors cannot do that.\n\nHave you moved from \"Validation\" (interested people) to \"Traction\" (active users)?\n\nAre you actively engaging with a community of peers to keep your momentum up?\n\nEven with a lean plan, you will encounter hurdles. Here is how to navigate the common traps of the Micro-SaaS journey.\n\nThe Issue: You feel the product isn't \"ready\" because it lacks a dark mode, multiple language support, or a referral system. The Fix: Go back to your validation. Did your early users say they wouldn't buy without dark mode? Probably not. Build only what is necessary to solve the core pain point. As the research indicates, spending months building before validating is the classic mistake.\n\nThe Issue: Everyone says \"Great idea!\" but nobody buys. The Fix: Compliments are not validation. Cash is validation. If people say they love it but won't pull out a credit card, you haven't found a painful enough problem, or you are talking to the wrong audience. Revisit Step 1 and narrow your microniche further.\n\nThe Issue: Trying to do everything (marketing, support, dev) alone. The Fix: Utilize the automation tools mentioned in the research. If a task feels repetitive, automate it. Your energy should be spent on talking to users and improving the product, not manual data entry.\n\nQ: Do I really need $0 to start?\n\nA: Strictly speaking, validation costs $0. You can use free social media, free email accounts, and free tiers of landing page builders to gauge interest. Costs only accrue once you start hosting a live application or paying for advanced no-code subscriptions, at which point you should ideally have paying customers to cover those costs.\n\nQ: What if I don't have a technical background?\n\nA: That is the power of the current landscape. Between no-code platforms (like Knack) and AI assistance, the barrier to entry has lowered significantly. The skill you need is problem-solving, not necessarily syntax coding.\n\nQ: How do I know if my niche is \"micro\" enough?\n\nA: If you are competing directly with Google, Microsoft, or Salesforce, your niche is too broad. If you are serving a specific profession (e.g., \"Dentists\") with a specific problem (e.g., \"Patient recall SMS automation\"), you are in the right zone.\n\nQ: What if my idea fails validation?\n\nA: Then you have succeeded. You saved yourself months of development time. The 48-hour validation process is designed to fail fast so you can move on to your next idea without baggage.\n\nThe path to a profitable Micro-SaaS is not paved with complex code or massive venture capital checks. It is paved with conversations, empathy for user problems, and the courage to ship imperfect solutions.\n\nDon't let your idea stay an idea. Go find your niche, ask the hard questions, and ship your solution. The community at r/BuildToShip and the wider indie hacker world is waiting to see what you build.\n\nUnlike generic AI tools, ProofWrite is purpose-built for creating factual, research-backed content that ranks.\n\nStart creating research-backed content today\n\nChoose the plan that fits your content needs. Scale up as you grow.\n\nPlans include automated keyword & product research, trust signal analysis, and factual AI writing. Article and keyword limits reset monthly.\n\nNeed a custom plan? Contact us for enterprise pricing.\n\nEach brief pulls facts from official docs, verified reviews, and community discussions. ProofWrite keeps citations, trust signals, and keyword guidance inline so drafts never hallucinate data.\n\nProofWrite feeds the writer with verified research, trust signals, and any personal experiences you add. Tone and voice controls keep prose specific and conversational.\n\nProofWrite supports product reviews, best-of listicles, and step-by-step how-to guides. Each format has inputs, research crawl, and writing instructions tuned to the brief.\n\nArticles can be written in English, Spanish, French, German, Italian, Dutch, Portuguese, Danish, Norwegian, Finnish, Swedish, Romanian, or Polish.\n\nEdit inside the composer, then push to WordPress with one click or copy the article to your clipboard for other CMSes.\n\nYes. Set tone, POV, and personas, then add personal experiences and AI instructions. ProofWrite threads them through the draft so it reads like someone who actually used the product.\n\nFor long-form writing, ProofWrite uses all the SOTA models: Gemini 3 Pro, Claude Sonnet 4.5, Opus 4.5 and OpenAI's GPT 5.x. Set a workspace-wide default and override per project as needed.\n\nAll research, drafts, and account data stay inside your workspace. We never use your content to train external models or share it with third parties.\n\nStart creating factual, humanized, SEO-optimized articles today.\nFree to try, no credit card needed. Cancel anytime.",
    "readingTime": 12,
    "keywords": [
      "seo aeo",
      "ai-driven automation",
      "profitable micro-saas",
      "proofwrite threads",
      "search engines",
      "classic mistake",
      "venture capital",
      "maximize impact",
      "landing page",
      "dark mode"
    ],
    "qualityScore": 1,
    "link": "https://proofwrite.io/",
    "thumbnail_url": "https://proofwrite.io/og-image.png",
    "created_at": "2025-12-26T12:22:23.991Z",
    "topic": "tech"
  },
  {
    "slug": "wordwrightai-learn-vocabulary-by-writing-not-memorizing",
    "title": "Wordwright.ai – Learn vocabulary by writing, not memorizing",
    "description": "Master new vocabulary through spaced repetition. Contribute to kwakubiney/wordwright.ai development by creating an account on GitHub.",
    "fullText": "kwakubiney\n\n /\n\n wordwright.ai\n\n Public\n\n Master new vocabulary through spaced repetition\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kwakubiney/wordwright.ai",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/kwakubiney/wordwright.ai",
    "thumbnail_url": "https://opengraph.githubassets.com/b2f8057c153e46dc231eabf0aea5b83a9a821d49f38f9c4b94c5573049d7580e/kwakubiney/wordwright.ai",
    "created_at": "2025-12-26T12:22:21.455Z",
    "topic": "tech"
  },
  {
    "slug": "multiscale-aperture-synthesis-imager",
    "title": "Multiscale Aperture Synthesis Imager",
    "description": "The authors create a distributed sensor array that achieves optical super-resolution without lenses, using computational synchronization to combine multiple sensors and expand imaging areas 16-fold beyond physical sensor dimensions.",
    "fullText": "Optical information transmission through complex scattering media with optical-channel-based intensity streaming\n\n Article\n Open access\n 23 April 2021",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.1,
    "link": "https://www.nature.com/articles/s41467-025-65661-8",
    "thumbnail_url": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41467-025-65661-8/MediaObjects/41467_2025_65661_Fig1_HTML.png",
    "created_at": "2025-12-26T06:19:00.209Z",
    "topic": "tech"
  },
  {
    "slug": "demystifying-determinism-in-durable-execution",
    "title": "Demystifying Determinism in Durable Execution",
    "description": "Determinism is a key concept to understand when writing code using durable execution frameworks such as Temporal, Restate, DBOS, and Resonate. If you read the docs you see that some parts of your code must be deterministic while other parts do not have to be.  This can be confusing to a dev",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://jack-vanlightly.com/blog/2025/11/24/demystifying-determinism-in-durable-execution",
    "thumbnail_url": "http://static1.squarespace.com/static/56894e581c1210fead06f878/t/692460e5f654ee3c1d6b1e6f/1763991781863/control_flow_vs_side_effects_small.png?format=1500w",
    "created_at": "2025-12-26T06:18:55.983Z",
    "topic": "tech"
  },
  {
    "slug": "mr-tumble-calzaghe-big-dunc-what-weve-learned-about-rooney",
    "title": "Mr Tumble, Calzaghe, Big Dunc - what we've learned about Rooney",
    "description": "Disliking Mr Tumble, trying to fight Joe Calzaghe and writing to Duncan Ferguson in jail - what we have learned from The Wayne Rooney Show.",
    "fullText": "Who knew Wayne Rooney cannot bear Mr Tumble or tried to fight former world boxing champion Joe Calzaghe?\n\nElite footballers are often a closed book these days but one of England and Manchester United's greatest players has given a special insight into his life in 2025 through 'The Wayne Rooney Show'.\n\nThe BBC Sport podcast has brought intrigue, laughter and insight to its audience since it began in August.\n\nAs we reach the halfway point in the season, we take a look back at eight of the best moments the show has served up so far.",
    "readingTime": 1,
    "keywords": [
      "insight",
      "wayne",
      "rooney"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bbc.com/sport/football/articles/cy4x101jk91o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/4973/live/131f7eb0-e0bc-11f0-aae2-2191c0e48a3b.png",
    "created_at": "2025-12-25T12:22:20.192Z",
    "topic": "sports"
  },
  {
    "slug": "trump-79-declares-absurd-national-security-threat-in-latenight-meltdown",
    "title": "Trump, 79, Declares Absurd National Security Threat in Late-Night Meltdown",
    "description": "Donald Trump has accused The New York Times of being a national security threat in an unhinged Truth Social post. “The Failing New York Times, and their lies and purposeful misrepresentations, is a serious threat to the National Security of our Nation,” Trump wrote in a late-night social media meltdown. “Their Radical Left, Unhinged Behavior, writing FAKE Articles and Opinions in a never-ending way, must be dealt with and stopped. THEY ARE A TRUE ENEMY OF THE PEOPLE! Thank you for your attention",
    "fullText": "Donald Trump has accused The New York Times of being a national security threat in an unhinged Truth Social post.\n\n“The Failing New York Times, and their lies and purposeful misrepresentations, is a serious threat to the National Security of our Nation,” Trump wrote in a late-night social media meltdown.\n\n“Their Radical Left, Unhinged Behavior, writing FAKE Articles and Opinions in a never-ending way, must be dealt with and stopped. THEY ARE A TRUE ENEMY OF THE PEOPLE! Thank you for your attention to this matter. PRESIDENT DJT.”\n\nIt is unclear what prompted Trump’s latest attack on the newspaper he has long derided as part of the “fake news” media.\n\nHowever, the president and the White House were triggered for days over a November report in the Times revealing that the 79-year-old president has drastically reduced his public appearances compared to his first term.\n\nTrump, who is on track to become the oldest sitting U.S. president to date, is also starting his days later on average and working shorter hours than he did during his first stint in the White House, the Times reported.\n\nLast week, the paper also published a detailed report examining Trump’s friendship with the late pedophile Jeffrey Epstein, describing how the two “pursued women in a game of ego and dominance” in which “female bodies were currency.”\n\nIn one particularly damaging section, a mother who accompanied her 14-year-old daughter to a party at Mar-a-Lago with other young models claimed she was warned by Trump’s then-wife, Marla Maples: “Whatever you do, do not let her around any of these men, and especially my husband.” Maples denied making the remark to the Times.\n\nTrump also took aim at the Times during a Monday press conference, accusing the paper of insufficiently covering his plan to lower prescription drug prices.\n\nThe president ranted about the outlet while continuing to push a dubious claim that he had lowered the cost of prescription drugs by the mathematically impossible amount of up to “3,000 percent.”\n\n“A drug that sells for $10 in London is costing $130 in New York. We’re bringing it down to $20,” Trump said. “So we’re going down—you can do your own math, but it’s 2,000 percent, 3,000 percent. It’s pretty amazing. And, you know, the New York Times had a story about it, a small story, way in the back of the paper. It’s the single biggest thing to happen with respect to drugs probably in 50 years.\n\n“It’s the biggest thing ever to happen, and it’s barely covered in the New York Times because it’s a fake newspaper,” Trump added.\n\nThe Daily Beast has contacted The New York Times for comment.",
    "readingTime": 3,
    "keywords": [
      "new york times",
      "the new york times",
      "it’s",
      "trump’s",
      "paper",
      "threat",
      "unhinged",
      "media",
      "newspaper",
      "year-old"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/trump-79-declares-absurd-national-104859316.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/DvQySOHJjWUQ3Hd23rWZ9g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://media.zenfs.com/en/thedailybeast.com/891dcad726760059a4ba544c952953ab",
    "created_at": "2025-12-23T18:17:46.410Z",
    "topic": "news"
  },
  {
    "slug": "warren-buffetts-company-took-kraft-heinz-off-its-subsidiary-list-weeks-before-board-exit-and-5-billion-writedown",
    "title": "Warren Buffett's company took Kraft Heinz off its subsidiary list weeks before board exit and $5 billion writedown",
    "description": "Warren Buffett's Berkshire Hathaway removed Kraft Heinz from its subsidiary webpage before leaving its board and writing down its stake by $5 billion.",
    "fullText": "Warren Buffett's Berkshire Hathaway removed Kraft Heinz from the list of operating companies on its website earlier this year, weeks before writing down its investment in the food and beverage giant and leaving its board of directors.\n\nThe famed investor's conglomerate took Kraft off its subsidiaries page in April, Business Insider determined using the Wayback Machine, a digital archive that stores snapshots of webpages on different dates.\n\nBerkshire accounts for its roughly 27% stake in Kraft using the equity method, meaning Buffett and his colleagues recorded it at cost and periodically adjust its carrying value to reflect Berkshire's share of Kraft's profits and losses.\n\nOn May 19, Berkshire's two board representatives stepped down. Berkshire also said in its second-quarter earnings that it was recording a $5 billion impairment loss on its Kraft position, cutting its carrying value to match its fair value of $8.4 billion.\n\nBuffett and his team said they had considered their \"ability and intent\" to remain invested until the fair value exceeded carrying value, the \"magnitude and duration\" of the decline in fair value, and Kraft's operating results and finances.\n\nThey also took into account the two board departures and the news that Kraft was evaluating potential strategic transactions, they said, and determined their unrealized loss on the holding was \"other-than-temporary.\"\n\nIt's unclear whether Berkshire removed Kraft from its subsidiary list as part of a broader distancing from the investment. Kraft was an unusual entry in the first place, as the vast majority of businesses featured are wholly owned subsidiaries of Berkshire, such as Geico, See's Candies, NetJets, and Pampered Chef.\n\nBerkshire Hathaway and Kraft Heinz did not respond to requests for comment.\n\nKraft announced in September that it would split into two businesses, with one focused on sauces, spreads, and seasonings such as Heinz and Philadelphia, and the other focusing on North American staples, including Kraft Singles and Lunchables.\n\nBerkshire partnered with 3G Capital, a Brazilian private equity firm, to acquire Heinz for around $23 billion in 2013. Two years later, the pair teamed up again to merge Heinz with Kraft in a $40 billion deal.\n\nSince then, the combined company has navigated layoffs, management reshuffles, huge writedowns, asset sales, a slumping stock price, aggressive cost controls, a federal accounting probe, and a prolonged decline in net revenues fueled by changing consumer preferences.\n\nDavid Kass, a finance professor at the University of Maryland and a longtime Berkshire blogger, told Business Insider in September that merging Kraft and Heinz was a \"rare mistake\" for Buffett.\n\nThe \"Oracle of Omaha,\" who spent the past six decades transforming Berkshire from a failing textile mill into a $1 trillion company, will step down as CEO next week. Buffett's handpicked successor and Berkshire's non-insurance chief, Greg Abel, will take the reins on New Year's Day.",
    "readingTime": 3,
    "keywords": [
      "berkshire hathaway",
      "removed kraft",
      "board",
      "carrying",
      "fair",
      "list",
      "operating",
      "investment",
      "subsidiaries",
      "determined"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/warren-buffett-berkshire-hathaway-kraft-heinz-stake-website-board-writedown-2025-12",
    "thumbnail_url": "https://i.insider.com/69496af604eda4732f2df686?width=1200&format=jpeg",
    "created_at": "2025-12-23T12:23:26.481Z",
    "topic": "finance"
  },
  {
    "slug": "alloconda-zig-toolkit-for-writing-cpython-extensions",
    "title": "Alloconda: Zig toolkit for writing CPython extensions",
    "description": "Zig-first Python extensions with cross-compiled wheels - mattrobenolt/alloconda",
    "fullText": "mattrobenolt\n\n /\n\n alloconda\n\n Public\n\n Zig-first Python extensions with cross-compiled wheels\n\n alloconda.withmatt.com\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mattrobenolt/alloconda",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/mattrobenolt/alloconda",
    "thumbnail_url": "https://opengraph.githubassets.com/a2496d8ff611964da1e92da6207f8854fcee7c8b17f1cf714d77ec0faa33320f/mattrobenolt/alloconda",
    "created_at": "2025-12-23T06:19:53.662Z",
    "topic": "tech"
  },
  {
    "slug": "we-built-an-ai-humanizer-to-fix-unnatural-ai-writing",
    "title": "We built an AI Humanizer to fix unnatural AI writing",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Humanize AI-generated content and turn it into natural, human-quality writing from ChatGPT, Jasper, or Gemini in seconds.\n\nEnter or paste your text and click Humanize.\n\nUsing the Dechecker Humanizer takes only moments and requires no technical skills.\n\nPaste your AI-generated content into the AI Humanizer and review it briefly before starting the humanization process, ensuring that the original text is complete and ready for accurate human-like rewriting.\n\nChoose your preferred style, language, and length to guide how the AI Humanizer shapes the final human text, allowing you to customize tone, readability, and overall writing style for your intended audience.\n\nAfter using the AI Humanizer, review your text to ensure it has been properly humanize AI content, flows naturally, reads authentically, and maintains the original meaning, tone, and clarity throughout.\n\nCopy the Humanize AI result for use, or check it with Dechecker AI Checker to review AI Humanizer output and AI detection results, ensuring your text is fully human-like and suitable for publishing or sharing.\n\nDechecker focuses on what matters most: producing clear, natural, human-quality text you can confidently use anywhere.\n\nAI-generated content is carefully refined into natural, fluent writing using an AI Humanizer that removes robotic patterns, awkward phrasing, and mechanical-sounding sentences, making the text read smoothly and authentically like a real human wrote it.\n\nThis AI Humanizer works seamlessly across multiple languages, helping content sound human and natural without awkward translations or stiff wording, while preserving original meaning and readability for global audiences.\n\nTone, clarity, and overall flow are enhanced while keeping the original intent intact, producing human-style text that is easy to read, engaging for audiences, and maintains the message accurately across different formats.\n\nAfter rewriting, content can be reviewed with AI Checker like Dechecker to confirm it reads as human, avoids robotic signals, and ensures the output is indistinguishable from text written by real people.\n\nOur AI Humanizer helps users humanize AI text across various scenarios, turning AI-generated drafts into natural, human-like writing that reads smoothly and clearly.\n\nThe AI Humanizer helps writers improve blog posts, articles, and stories by refining AI-generated drafts, making them read naturally, flow smoothly, and engage readers more effectively while keeping original ideas intact.\n\nUse Humanize AI to refine essays, research papers, and reports, ensuring content sounds human, is clear and easy to understand, and maintains proper academic tone and logical structure throughout.\n\nAI Humanizer transforms marketing copy, social media posts, and emails into smooth, human-like text that resonates with audiences, boosts engagement, and maintains consistent brand voice across all channels.\n\nWith multilingual support, Dechecker AI Humanizer allows teams to produce human-quality content in different languages, preserving tone, meaning, and readability, ensuring professional communication worldwide.\n\nDechecker Humanize AI ensures course content, tutorials, and learning resources are readable, human-like, and engaging, helping students better understand complex topics and improving overall learning experience.\n\nUse Dechecker AI Humanizer to humanize AI-generated web content, making it more engaging, natural, and optimized for readers, while improving user experience and search engine readability simultaneously.\n\nReal feedback from users who have improved their AI-generated content with AI Humanizer, making writing feel more natural and human-like.\n\nFind answers to common questions about using AI Humanizer to humanize AI text and make content sound natural and human-like.\n\nAn ai humanizer is a tool designed to turn AI-generated text into human-like writing. It improves readability, sentence structure, and tone, helping content feel natural and engaging to real readers.\n\nAI Humanizer analyzes AI-generated text, restructures sentences, adjusts phrasing, and refines flow to humanize AI content, making it sound naturally written while keeping the original meaning intact.\n\nYes, the AI Humanizer supports multiple languages, including English, Spanish, French, German, and more. It ensures your text feels natural and human-like across all supported languages.\n\nAbsolutely. Dechecker Humanize AI allows you to customize writing style, tone, and length, making content suitable for blogs, articles, marketing copy, emails, and other professional uses.\n\nNo. AI Humanizer focuses on enhancing readability and natural flow without altering your key ideas, intent, or important information, keeping your message accurate.\n\nYes. AI Humanizer humanizes AI-generated text without fabricating information. It helps essays, reports, and professional content read naturally while maintaining integrity and clarity.\n\nDefinitely. After using Dechecker AI Humanizer, you can review the output with AI Checker to ensure the Humanize AI content reads naturally, appears human-written, and meets authenticity requirements.\n\nWriters, students, marketers, content creators, and businesses can all benefit. Anyone looking to make AI-generated content readable and humanize AI content efficiently will find the ai humanizer extremely useful.",
    "readingTime": 4,
    "keywords": [
      "ai humanizer",
      "ai-generated drafts",
      "marketing copy",
      "ai-generated content",
      "dechecker humanize",
      "ai-generated text",
      "natural human-quality",
      "content sound",
      "ai checker",
      "human-like"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai/ai-humanizer",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-23T06:19:37.153Z",
    "topic": "tech"
  },
  {
    "slug": "the-death-and-rebirth-of-programming",
    "title": "The Death and Rebirth of Programming",
    "description": "Programming didn't die all at once. There was no single moment, no dramatic obsolescence event. Instead, something quieter happened: the core constraint that shaped software for seventy years dissolved. Writing code stopped being the hard part.",
    "fullText": "For most of computing history, programming was bottlenecked by human cognition. Translating intent into working software required time, attention, and specialized skill. Even small changes were costly. This scarcity justified entire ecosystems: languages, frameworks, methodologies, reviews, team rituals that made sense when every line was expensive.\n\nGenerative AI removes that scarcity.\n\nToday, a single developer can generate thousands of lines of working code in minutes. Tomorrow, that number will be effectively infinite. The marginal cost of producing code is collapsing toward zero.\n\nWhat hasn't collapsed is the cost of knowing what the code does.\n\nUnderstanding, verifying, securing, and evolving software remain stubbornly expensive. In fact, they may be getting harder as volume explodes. This asymmetry—the ease of creation versus the difficulty of comprehension—is the defining tension of modern software.\n\nProgramming hasn't disappeared. But its center of gravity has shifted.\n\nIn the old world, programmers owned code. You wrote it, you understood it, you maintained it. Your value was tied to mastery of specific implementations. Codebases accrued history, reputation, and power.\n\nIn the new world, ownership becomes a liability.\n\nWhen code can be regenerated faster than it can be understood, preserving it for sentimental or historical reasons no longer makes sense. What matters instead is stewardship: maintaining the system's behavior, boundaries, and intent over time, regardless of how many times its internals are replaced.\n\nThis reframing is subtle but profound:\n\nThe asset is no longer the codebase. The asset is the system's ability to keep working.\n\nThis is the thesis of everything that follows. Architecture, testing, interfaces, team structure: all of it flows from this inversion.\n\nMany of the \"modern\" software practices of the last decade were early adaptations to this shift, even if we didn't articulate them that way.\n\nImmutable infrastructure. Stateless services. Containers. Blue-green deployments. Infrastructure as code.\n\nThese ideas all share a common premise: never fix a running thing. Replace it.\n\nAI pushes this premise beyond infrastructure and into application code itself. When rewriting is cheap, editing in place becomes risky. Mutation accumulates entropy. Replacement resets it.\n\nDisposability stops being a hack. It becomes the default.\n\nThis transition isn't just technical. It's deeply psychological, and that psychology shapes architecture.\n\nMany developers identify as builders and craftspeople. We take pride in elegance, cleverness, and mastery of internals. We accumulate knowledge inside our heads and inside codebases. Longevity feels like validation.\n\nGenerative AI destabilizes this identity.\n\nWhen a machine can produce a competent version of \"your\" solution in seconds, craftsmanship no longer lies in the artifact. It lies in framing the problem, defining success, and deciding what to keep and what to discard.\n\nThe role shifts from maker to architect. From author to managing editor. From preserving code to designing for its replacement.\n\nThat shift is uncomfortable. And the discomfort isn't merely personal. It's what makes teams resist the very patterns that would help them. Developers cling to codebases because identity is at stake, not just technical judgment. Acknowledging this is the first step toward building systems that don't require heroics to change.\n\nResisting the shift doesn't stop it. It just makes systems more fragile.\n\nOne of the clearest signals of this new era is the rise of the n=1 developer.\n\nProjects that once required teams now fit inside a single person's cognitive boundary—with AI filling in the execution gaps. Entire products can be specified, generated, evaluated, and shipped by one human working with machines.\n\nThis isn't about productivity hacks. It's about a structural change in leverage.\n\nBut n=1 development only works if systems are designed for it. Large, tangled, historically accreted codebases collapse under their own weight when AI accelerates change. Small, modular, disposable systems thrive.\n\nThe n=1 developer is not a superhero. They are an indicator species. They are evidence that the environment has changed, and proof that the new patterns actually work.\n\nIt's tempting to frame this as the \"end of programming.\" That's misleading.\n\nWhat's dying is a specific form of programming: one that equates value with authored code, longevity of code with quality, and maintenance with virtue.\n\nWhat's being born is something closer to systems design as an ongoing process of regeneration:\n\nCode becomes an intermediate artifact, not the final product. Rewrites become routine, not traumatic. Tests and evaluations define truth, not files. Stability emerges from replacement, not preservation.\n\nThis is not nihilism. It's pragmatism under new constraints.\n\nThe rest of this publication builds on a single premise established here:\n\nWhen code is cheap and understanding is expensive, architecture must optimize for the impermanence of code.\n\nEverything else (pace layers, evaluations, clean interfaces, regeneration workflows) flows from that fact.\n\nWe are not entering a world with less software. We are entering a world with vastly more of it. The only way to survive that abundance is to stop treating code as precious.\n\nBut it has been reborn, and it expects us to change with it.",
    "readingTime": 5,
    "keywords": [
      "modern software",
      "generative ai",
      "code",
      "it's",
      "systems",
      "programming",
      "codebases",
      "expensive",
      "developer",
      "longer"
    ],
    "qualityScore": 1,
    "link": "https://aicoding.leaflet.pub/3malrv6poy22a",
    "thumbnail_url": "https://leaflet.pub/lish/did%253Aplc%253A4qsyxmnsblo4luuycm3572bq/3majnsnvafs2b/3malrv6poy22a/opengraph-image?6815eb61f733905a",
    "created_at": "2025-12-23T00:56:32.109Z",
    "topic": "tech"
  },
  {
    "slug": "joan-didion-and-kurt-vonnegut-had-something-to-say-we-have-it-on-tape",
    "title": "Joan Didion and Kurt Vonnegut Had Something to Say. We Have It on Tape",
    "description": "Rare recordings of E.E. Cummings, Mary Oliver and more offer a tour through literary history led by authors in their own words — and voices. Take a listen.",
    "fullText": "Tom Wolfe was a fast talker. Eudora Welty had a musical Southern drawl. Kurt Vonnegut’s jokes got belly laughs.\n\nEach of these authors once spoke to audiences at the 92nd Street Y Unterberg Poetry Center in New York City, which has hosted some of the most celebrated writers of the past several generations, from Isaac Asimov to Anaïs Nin and Kazuo Ishiguro to Margaret Atwood. Now, the Poetry Center has digitized audio recordings of its literary events stretching back to 1949 — hundreds of which have never been released before — in a collection that offers a glimpse into history and a taste of what the writers themselves were like in public.\n\nIn 1965, for example, the year before he became consultant in poetry to the Library of Congress, James Dickey complained that his 14-year-old son had acquired a taste for rock ’n’ roll and a transistor radio. The sound of electric guitars had taken over his house. He was joined onstage that night by the poet Theodore Weiss, but it could have been Truman Capote, Joseph Heller or Adrienne Rich, who also visited the Poetry Center over the years.\n\n“Historically, it’s been the premier place to read your work in public in the United States,” said Billy Collins, a former U.S. poet laureate, who has read at the Poetry Center many times. “Maybe short of the White House or Carnegie Hall — but most poets don’t get to Carnegie Hall no matter how hard they practice.”\n\nYou can listen to some clips from the archive below.\n\nBaldwin was a gifted public speaker, compelling and quick on his feet. The eldest son of a preacher, Baldwin turned his own oratorical skills to advocacy and debate after a short stint at the pulpit as a teenager. Here, he talks about the mysteries of the writing process.\n\nIn this recording, Didion reads from her book “The Year of Magical Thinking,” which recounts her daughter’s grave illness and the sudden death of her husband, John Gregory Dunne. Didion and Dunne had been married for 40 years when, after visiting their daughter at the hospital, Dunne collapsed at the dinner table from a heart attack. He was pronounced dead a few hours later. The book offers a portrait of both loss and the long marriage that preceded it.\n\nThe prolific and prizewinning poet reads “Wild Geese,” one of her most celebrated poems. Oliver, who died in 2019, read at the Poetry Center three times during her life. On each of those visits, she made sure to include this fan favorite.\n\nVonnegut was best known for his novels, including “Slaughterhouse-Five” and “Cat’s Cradle,” but because he was at the Poetry Center, he thought he should read some poems. How he met the moment was quintessential Vonnegut: genial and cheeky in equal measure.\n\nWolfe, an author and journalist, was known both for novels including “The Bonfire of the Vanities” and for the role he played in helping to create “New Journalism,” which employed novelistic techniques in nonfiction. Wolfe was also an exceptionally snappy dresser, and he was often photographed wearing a bespoke three-piece white suit — although he chose a different outfit for the reporting trip he recounts here.\n\nThe earliest recording in the collection is of the American poet E.E. Cummings, who read at the Poetry Center in 1949. Cummings was born in 1894 and died in 1962, so even readers who love his distinctive style — with its unusual, almost sculptural line breaks and formatting — may not be familiar with his stately reading voice.\n\nThis selection is pulled from a Q. and A. with the playwright behind such classics of American theater as “The Crucible” and “Death of a Salesman.” A member of the audience asked about Miller’s play “The American Clock,” which is set during the Great Depression and was first staged in 1980: was Miller, the audience member asked, expecting another economic calamity when he wrote it?\n\n“dying is fine,” from “The Complete Poems: 1904-1962,” by E.E. Cummings. Copyright © 1949, 1977, 1991 by the Trustees for the E.E. Cummings Trust. Copyright © 1979 by George James Firmage. Used with permission of Liveright Publishing Corporation, a division of W.W. Norton & Company. All rights reserved.\n\n“Wild Geese,” from “Dream Works: Poems,” by Mary Oliver. Copyright © 1986 by NW Orchard LLC. Copyright © 1986-2017 by Mary Oliver, with permission of Bill Reichblum. Reprinted by permission of Penguin Books, an imprint of Penguin Random House, and the Charlotte Sheedy Literary Agency. All rights reserved.",
    "readingTime": 4,
    "keywords": [
      "rights reserved",
      "poetry center",
      "carnegie hall",
      "wild geese",
      "dunne",
      "permission",
      "celebrated",
      "writers",
      "literary",
      "collection"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2025/12/19/books/james-baldwin-joan-didion-92ny-recordings.html",
    "thumbnail_url": "https://static01.nyt.com/images/2025/11/20/multimedia/00TBR-92Y-03-cpvm/00TBR-92Y-03-cpvm-facebookJumbo.jpg",
    "created_at": "2025-12-22T06:20:28.076Z",
    "topic": "tech"
  },
  {
    "slug": "impeachable-pam-bondi-defied-federal-law-by-erasing-epstein-photos-to-protect-trump",
    "title": "Impeachable: Pam Bondi Defied Federal Law by Erasing Epstein Photos to Protect Trump",
    "description": "The DOJ removed already-public Epstein files in defiance of a disclosure statute, prompting bipartisan outrage and impeachment talk from the law’s authors.",
    "fullText": "(Evan Vucci/The Associated Press)\n\nThe Justice Department is now engaged in an open cover-up carried out in direct violation of federal law.\n\nOver the weekend, the department quietly removed 16 photographs from the Epstein files website it created to comply with a disclosure statute passed by Congress and signed into law by President Donald Trump. The removals came without notice or explanation. Among the deleted images was one of the few photographs that even indirectly featured Trump, a picture of a credenza drawer inside Jeffrey Epstein’s Manhattan home containing other photographs, including at least one of Trump. Twelve others depicted Epstein’s third-floor massage room, a central crime scene in the federal investigation. Some images of the same room remain public. Others disappeared.\n\nWhen Democrats on the House Oversight Committee asked whether the Trump-related image had been taken down, the Justice Department declined to respond.\n\nWhat followed made matters worse.\n\nIn a post on X quoting Deputy Attorney General Todd Blanche, the Justice Department claimed that “photos and other materials will continue being reviewed and redacted consistent with the law in an abundance of caution as we receive additional information.” Blanche’s original post asserted that the department had released Epstein materials “under the Epstein Files Transparency Act” and that additional disclosures would follow “as our review continues, consistent with the law and with protections for victims.”\n\nThat explanation fails under the statute the department invoked.\n\nCongress did not authorize a rolling review. The Epstein Files Transparency Act compels the Justice Department to release all Epstein-related materials in its possession. The law imposes a mandatory disclosure obligation and permits only limited redactions to protect victims. It grants no authority to retract, revise, or curate records after release. Once the department published those materials, the law required that they remain available to the public.\n\nRemoving them placed the department in direct conflict with the statute Congress enacted.\n\nThat conflict was immediately recognized. Blanche’s post received a community note stating that the law requires the release of all files and allows only narrow redactions to protect victims, adding that the department’s partial release and extensive redactions violated the statute. The Justice Department’s own post received a community note citing the statute directly and stating that retractions and redactions to protect politically exposed persons are not permitted. Community Notes appear only when users with differing political viewpoints agree on their accuracy, underscoring how broadly that conclusion was shared.\n\nThe department’s own explanation confirms it is violating the law it claims to follow.\n\nThe sequence exposes motive. The files went live. Political reaction followed. The department then altered the public record. Compliance held only until presidential exposure appeared, then gave way to erasure.\n\nIn November, I described the Trump Justice Department’s handling of the Epstein files as a cover-up. Last week, I wrote that the administration’s delay in disclosure created a political problem rather than an immediate legal one. That assessment reflected weak enforcement mechanisms and an approach built on delay rather than open defiance.\n\nRemoving already released material that implicates the president converts a credibility crisis into a statutory violation and a far larger political emergency. Congress passed the Epstein disclosure statute precisely to eliminate executive discretion. Lawmakers acted because the Justice Department repeatedly demonstrated it could not be trusted to manage politically sensitive material involving powerful figures. The law mandated disclosure to prevent executive self-protection.\n\nThe department seized that discretion anyway.\n\nAttorney General Pam Bondi had lawful options. She could have sought judicial review. She could have consulted Congress. She could have acknowledged that the statute permits no removal authority and sought amendment. Each path would have preserved institutional legitimacy. She chose concealment and false justification instead.\n\nThis erasure differs from earlier Trump-era document fights in a crucial way. Prior disputes centered on whether materials must be disclosed. This episode involves evidence already released to the public under statutory standards. The department determined the images satisfied the law’s requirements, then removed them once the political cost became apparent.\n\nEvery disclosure statute now faces the same test: compliance survives only until it threatens the president. Months of delay, sweeping redactions, and staged releases already convinced much of the public that the Justice Department prioritized Trump’s standing over transparency, victims, and the public interest. The image removals confirm that conclusion decisively.\n\nA Justice Department that edits evidence to shield the president forfeits legitimacy. Oversight collapses when obedience ends at political inconvenience. The rule of law depends on statutes binding the executive even when compliance proves costly.\n\nCongress wrote a law to prevent exactly this abuse. The president signed it. The attorney general is now violating it to protect him. That meets any reasonable standard for impeachment.\n\nThe backlash on Capitol Hill was immediate and bipartisan. Democratic Rep. Ro Khanna of California, who co-authored the Epstein Files Transparency Act, and Republican Rep. Thomas Massie of Kentucky, who forced the House vote compelling disclosure, both said the Justice Department failed to comply with the law. Khanna has confirmed that he and Massie are drafting impeachment and contempt measures against Attorney General Pam Bondi.\n\nCongress now faces a choice. It can accept that disclosure laws apply only when politically painless. It can normalize the disappearance of already public evidence. It can allow executive power to override legislative command.\n\nOr it can enforce the law it wrote.\n\nThis is a cover-up enforced through executive defiance. The question now is whether Congress will enforce its own laws.\n\nThe post Impeachable: Pam Bondi Defied Federal Law by Erasing Epstein Photos to Protect Trump first appeared on Mediaite.",
    "readingTime": 5,
    "keywords": [
      "pam bondi",
      "transparency act",
      "files transparency",
      "epstein files",
      "justice department",
      "justice department’s",
      "received community",
      "community note",
      "protect victims",
      "federal law"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/impeachable-pam-bondi-defied-federal-142332537.html",
    "thumbnail_url": "https://media.zenfs.com/en/mediaite_845/14ad98684991a13d9b9c7d5587ec3f0a",
    "created_at": "2025-12-21T18:15:58.663Z",
    "topic": "news"
  },
  {
    "slug": "multimillionaire-musician-william-says-worklife-balance-is-for-people-working-on-someone-elses-dreamhe-grinds-from-5to9",
    "title": "Multimillionaire musician Will.i.am says work-life balance is for people ‘working on someone else’s dream’—he grinds from 5-to-9 after his 9-to-5",
    "description": "When Will.i.am’s not writing hit songs like “OMG” for Usher, he’s looking for the next big pop star on The Voice U.K., or running his new AI company, FYI.",
    "fullText": "Orianna Rosa Royle is the Success associate editor at Fortune, overseeing careers, leadership, and company culture coverage. She was previously the senior reporter at Management Today, Britain's longest-running publication for CEOs.\n\nWill.i.am is busy. When he’s not writing hit songs like “OMG” for Usher, he’s looking for the next big pop star on The Voice UK, or running his new AI company, FYI. So how exactly does he balance it all?\n\nThe Grammy Award–winning artist turned tech entrepreneur revealed to Fortune that he maxes out the 5-to-9 after the daily grind of his 9-to-5, and he advises Gen Zers to forget about work-life balance if they want to emulate his success.\n\n“If you’re trying to build something that doesn’t exist, it’s about dream-reality balance,” he says. “Work-life balance means that you’re working for somebody else’s dream. You just have a job supporting somebody else’s dream, and you want to balance your work and your life.\n\n“But if it’s dream-reality balance, then it’s not work. It’s a dream that you’re trying to put into reality, and you’re ignoring your current reality.”\n\nFor example, after working on his tech venture from 9 a.m. to 5 p.m., Will.i.am says that he goes back to work on his creative business until 9 p.m. But before his AI company was a reality, his day was flipped. He’d work on music first before dipping into his tech side hustle well into the evening.\n\nIt’s why he advises young people to reframe how they think of their time off work and their current 9-to-5 reality.\n\n“I’m not really paying attention to this reality,” he explains. “I’m trying to bring that one [a new business venture or idea] here and focusing on how do I get people who believe in this dream to help me materialize it? So for that, you have to make some type of sacrifice to bring this thing that doesn’t exist here.\n\n“From that perspective, work-life balance is not for the architects that are pulling visions into reality. Those words don’t compute to the mindset of the materializers.”\n\nOf course, many young people already put in hours to their side hustles and personal development after work. Millions of Gen Zers and millennials are tuning into people’s 5-to-9 evening routines on TikTok.\n\nBut Will.i.am says chipping away at your dream when most people are off work extends to weekends, birthdays, and holidays.\n\n“I didn’t party. I was always a square, meaning, ‘You work too much, man, let’s go out.’ Like what? Go out. I don’t want to go out. I just always worked,” the rapper says. “It’s your birthday what are you gonna do? Work. You ain’t gonna celebrate?”\n\nThe multimillionaire says he’s always saved the celebrating for the stage, where he can finally enjoy the fruits of his labor.\n\n“There’s nothing that’s ever gonna feel that glorious than when you’re actually at a festival. But how do you get to headline a festival? You’ve got to work. My friends would go out and party, hanging out with chicks, doing drugs, drinking. I was just in the studio working, writing songs.”\n\nTo this day, he says that he hasn’t gone out and celebrated a birthday—including his most recent one, which was just last week on March 15.\n\n“Like on Christmas for the past 12 years: I could celebrate Christmas with my family, and then on the 26th, I fly to China because that’s dream maker heaven. Anything you want to make is there.”\n\nWill.i.am was speaking to Fortune in Rome for the rollout of Raidio.FYI radios in Mercedes-Benz cars.\n\n7 a.m.: Will.i.am is not a part of the CEO-approved 5 a.m. club. Instead, he told Fortune he wakes up at around 7 a.m., and he sticks to this routine whether he’s living in L.A. or London.\n\n8 a.m.: “I walk, do my calls, and get to work,” he says, with the aim to start work at 9 a.m.\n\n9 a.m. to 5 p.m.: “I get a lot done from nine to 12, do my little lunch, then back to work at one, finish at five, and that’s all my tech, like entrepreneurial activities.”\n\n5 p.m. to 9 p.m.: “The night hours are creativity,” he says, adding that specifically between 7 p.m. and 9 p.m. is when he gets the best ideas. “That’s the juicy bits, [when] I’m freaking soaking in emotion, to where I just rinse it out in the phone.”\n\n9 p.m. onward: When Will.i.am was in his late twenties, he says going to sleep at 4 a.m. (and waking up at noon) was the norm. But now, at 50 and balancing both his tech and music ventures, he starts unwinding for bed after 9 p.m. and is asleep by 11 p.m.\n\nA version of this story originally published on Fortune.com on March 23, 2025.",
    "readingTime": 5,
    "keywords": [
      "doesn’t exist",
      "somebody else’s",
      "else’s dream",
      "work-life balance",
      "dream-reality balance",
      "it’s",
      "tech",
      "you’re",
      "fortune",
      "he’s"
    ],
    "qualityScore": 0.8,
    "link": "https://fortune.com/article/will-i-am-says-work-life-balance-for-people-working-on-someone-elses-dream/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/03/GettyImages-1487800046.jpg?resize=1200,600",
    "created_at": "2025-12-21T18:15:57.676Z",
    "topic": "business"
  },
  {
    "slug": "what-the-hyperproduction-of-ai-slop-is-doing-to-science",
    "title": "What the hyperproduction of AI slop is doing to science",
    "description": "A new study shows AI writing is turning traditional measures of research quality upside down.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 216,700 academics and researchers from 5,395 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/what-the-hyperproduction-of-ai-slop-is-doing-to-science-272250",
    "thumbnail_url": "https://images.theconversation.com/files/709831/original/file-20251219-66-vklc4z.jpg?ixlib=rb-4.1.0&rect=0%2C132%2C2400%2C1200&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2025-12-19T06:18:41.817Z",
    "topic": "tech"
  },
  {
    "slug": "roblox-python-tower-defense-game",
    "title": "Roblox Python tower defense game",
    "description": "save the core by writing python! Contribute to jackdoe/roblox-python-tower-defense development by creating an account on GitHub.",
    "fullText": "jackdoe\n\n /\n\n roblox-python-tower-defense\n\n Public\n\n save the core by writing python!\n\n www.roblox.com/games/92507403623309/Python-Tower-Defense\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jackdoe/roblox-python-tower-defense",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/jackdoe/roblox-python-tower-defense",
    "thumbnail_url": "https://opengraph.githubassets.com/56462222528f0cb1d0e3e1a9cb703322f45ee9df3d28bfefbf0c555adffe592a/jackdoe/roblox-python-tower-defense",
    "created_at": "2025-12-19T00:56:22.416Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-unveils-new-opensource-ai-models-amid-boom-in-chinese-offerings",
    "title": "Nvidia unveils new open-source AI models amid boom in Chinese offerings",
    "description": "Nvidia on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.  Nvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them.  Nvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks.",
    "fullText": "SAN FRANCISCO, Dec 15 (Reuters) - Nvidia (NVDA) on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.\n\nNvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them. But it also offers a slew of its own models for everything from physics simulations to self-driving vehicles as open-source software that can be used by researchers or by other companies, with firms such as Palantir Technologies weaving Nvidia's model into their products.\n\nNvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks. The smallest of the models, called Nemotron 3 Nano, was being released ‍Monday, with two other, larger versions coming in the first half of 2026.\n\nNvidia, which has become the world's most valuable listed company, said that Nemotron 3 Nano was more efficient than its predecessor - ​meaning it would be cheaper to run - and would do better at long tasks ‌with multiple steps.\n\nNvidia is releasing the models as open-source offerings from Chinese tech firms such as DeepSeek, Moonshot AI and Alibaba Group Holdings are becoming widely used in the tech industry, with companies such as Airbnb disclosing use of Alibaba' s. (BABA) Qwen open-source model.\n\nAt the same time, CNBC and Bloomberg have reported that Meta Platforms is considering shifting toward closed-source ⁠models, leaving Nvidia as one of the most prominent ​U.S. providers of open-source offerings.\n\nMany U.S. states and ​government entities have banned use of Chinese models over security concerns.\n\nKari Briski, vice president of generative AI software for enterprise at Nvidia, said the company aimed ‍to provide a \"model that ⁠people can depend on\", and was also openly releasing its training data and other tools so that government and business users could test it for security and ⁠customize it.\n\n\"This is why we're treating it like a library,\" Briski told Reuters in an interview. \"This is ‌why we're committed to it from a software engineering perspective.\"",
    "readingTime": 2,
    "keywords": [
      "open-source offerings",
      "closed-source models",
      "nemotron nano",
      "nvidia",
      "firms",
      "software",
      "reuters",
      "cheaper",
      "aimed",
      "tasks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-unveils-open-source-ai-140424565.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31397226d241d376e5cffbf13490e071",
    "created_at": "2025-12-16T13:51:41.754Z",
    "topic": "finance"
  },
  {
    "slug": "text-diffusion-models-are-faster-at-writing-code",
    "title": "Text Diffusion Models Are Faster at Writing Code",
    "description": "Speculative Decoding and Diffusion Language Models# In speculative decoding (for autoregressive models), we speed up generation by using a smaller model to generate multiple tokens, which are then verified in parallel by a larger model. The core idea is that most tokens are easily predictable; thus, we should be able to use a smaller and faster model for them. The classic example is the following sentence:\n“Geoffrey Hinton did his PhD at the University ___ ___”.",
    "fullText": "In speculative decoding (for autoregressive models), we speed up generation by using a smaller model to generate multiple tokens, which are then verified in parallel by a larger model.\nThe core idea is that most tokens are easily predictable; thus, we should be able to use a smaller and faster model for them.\nThe classic example is the following sentence:\n\n“Geoffrey Hinton did his PhD at the University ___ ___”.\n\nA small model can predict the next word “of” with high confidence, while the next token “Edinburgh” is much harder, requiring a larger model to verify.\n\nLanguage diffusion models sort-of have something analogous to speculative decoding built-in by default (and in some ways, a better version).\n\nFor diffusion language models with confidence-aware parallel decoding1, the model generates all tokens above a given confidence threshold at each step. Thus, “easy” tokens are generated in parallel.\nSome ways in which this is better than speculative decoding is that it is global (works across the entire context, not just for the next K tokens) and doesn’t require running two separate models.\nIn the following example:\n\nRepeat the word grape over and over again.\n\na diffusion language model could generate the prediction “grape” for the entire context length in one step, while in speculative decoding, even if the entire sequence is easily predictable, it can only predict K tokens at a time (typically around 4-8, from what I’ve read).\n\nThis benefit of increased parallel decoding partially depends on the structuredness of a text, which exists on a spectrum. An increase in confidence per output token directly leads to more tokens being decoded on average per step.1\n\nIncreased structure -> reduced entropy -> increased confidence -> higher parallel decoding\n\nThe grape example above is trivially structured, while normal text generation is unstructured and high entropy. Writing code (an actually useful domain) is somewhere in between.\n\nI had a large hunch that for structured tasks (like coding), the average number of tokens generated in parallel per step is higher than in normal text generation, and monotonically increases with the amount of structuredness present in the domain of the output.\n\nI recall reading that Google Gemini was much closer to state of the art for code generation than it was for reasoning tasks when it was first released. Perhaps this improvement for structured tasks is a general motif when it comes to these models?\n\nI threw together a small test and used the model from the paper Fast dLLM v2 (available on Huggingface) to generate roughly 256 tokens for 10 different prompts (each ran 10 times on A100s with an additional 2 generations for warmup):\n\nThe code for everything can be found here, which additionally includes generated output and metadata for each run. Below are the results:\n\nAs predicted, the grape example was dramatically faster than the unstructured text. What was surprising was how much faster (2.33 times speedup!) code generation was compared to unstructured text, even across multiple examples.\n\nMore testing should be done, but I imagine that there is a negative correlation between relative speedup and program complexity, and that boiler plate code (ex. self.input = input) would have a higher speedup compared to logic-heavy sections.\n\nAnother interesting result was that generating the start of the Declaration of Independence, a document which the model must have memorized, didn’t have much speedup. This tiny ablation study suggests that it really is the structuredness of the output, not memorization, which matters.\n\nThis was a small test thrown together in under an hour, and more rigorous evaluations should be done, but these preliminary results hint that this idea might be true to some degree.\n\nAn important limitation to address: In autoregressive decoding, we constrained decoding where we set all syntactically invalid tokens to have a probability of zero, ensuring that we are only generating text which follows some rules (JSON formatting, syntactically correct code, etc). For diffusion language models, this can’t naively be applied. However, similar to figuring out KVCache reuse with the advent of KVCache approximation, we might find a practical solution to this problem.2\n\nRead the section “Confidence-Aware Parallel Decoding” in the paper, Fast-dLLM. ↩︎ ↩︎\n\nThere are lots of papers of doing semi-autoregressive generation using diffusion language models. See AR-Diffusion, Fast-dLLM, Block Diffusion, etc. ↩︎",
    "readingTime": 4,
    "keywords": [
      "easily predictable",
      "structured tasks",
      "per step",
      "normal text",
      "confidence-aware parallel",
      "diffusion language",
      "unstructured text",
      "larger model",
      "speculative decoding",
      "language models"
    ],
    "qualityScore": 1,
    "link": "https://nathan.rs/posts/dllm-faster-code-generation/",
    "thumbnail_url": "https://nathan.rs/site.png",
    "created_at": "2025-12-13T18:48:06.593Z",
    "topic": "tech"
  },
  {
    "slug": "my-day-as-an-augmented-technical-writer-in-2030",
    "title": "My day as an augmented technical writer in 2030",
    "description": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).",
    "fullText": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).\n\nMy working day starts at 8:30am, after I’ve dropped my kids at school, rushed home, and prepared some coffee surrogate (nobody can afford real coffee anymore). I open the laptop and Chuck is there – it’s always there, like a trusty butler, ready to summarize what’s been going on in pull requests, Slack threads, Jira tickets, and a plethora of other information systems nobody can quite tame. Its summary connects the dots between my current priorities and what’s happening in the teams I’m attached to, helping me decide what to work on next. Trying to be helpful, it offers to deal with some of the mentions I’ve got by opening pull requests; I let it do so with a small docs bug. The rest I’ll want to deal with myself. It asks me how I feel and gently reminds me that I’ve still got some PTO available. Chuck’s such a class act.\n\nI’m in a team with several other technical writers, but for the most part I work with Chuck, which is what we call the in-house AI agent that we use. Chuck is a vast local language model capable of running on the M10 Silicon processor that powers my laptop. It’s a state-of-the-art multimodal LLM whose pedigree I can trace back to the last iterations of Claude Omni 7.5, before Anthropic went bankrupt and got acquired by Apple. As most corporate models, Chuck is ISO 42001, Turing, and EUAI certified, which means that it’s audited every year for security, governance, and legality of its training materials. Chuck is fine-tuned into several variants depending on the goal; the one I use is chuck-256b-writer. We run it in CI pipelines and locally in IDEs or CLI clients. We can also invite it to meetings as an artificial participant. I sometimes ask my own Chuck to attend calls on my behalf as Chuck-Fabri.\n\nThe thing I like the most about Chuck is that I can configure its specializations by turning modules on or off through the Silicon Brain app. When I want it to play the developer, I add several coding modules; when I want it to help me author docs, I turn on the style guide and grammarian modules, and so on. I can also ask Chuck to spawn copies of itself to roleplay users and readers based on support ticket and sales call interactions. When I do that, Chuck politely asks me to call it through other names, so as not to break character, something I duly comply with. Most system tools and APIs are already compatible with the agentic environment I use, so Chuck knows how to perform most operations on its own. An important detail: to summon Chuck, I need to first plug a physical key into the laptop. The key comes with a red button to immediately stop Chuck in case it starts operating bizarrely. Never had to use it.\n\nIt’s 11am already. I’ve been working with Chuck to write a new docs set for a new feature, telling it how I wanted the docs to fit into the existing architecture and instructing it to tweak and edit. It almost always gets 80% of the work done, though I often have to intervene to rearrange, cut, or otherwise rewrite sections. This hasn’t changed since the first days of GPT and it’ll never improve, because LLMs are not intelligent. They’re the most useful word automation tools at my disposal though, which I keep in check through deterministic tools and linters. Chuck is able to create diagrams, take screenshots of the product through an internal tool, and test the instructions and code snippets itself. When I feel unsure about its output, I ask it to verify what it’s just written through semantic internal search, or by calling its cloud cousin, Chad, which is able to provide answers from federated internal sources. All we do together, Chuck documents internally and remembers in its permanent context.\n\nEven though I’m using a local, non-monetized, and fully audited model that consumes the equivalent of a lightbulb worth of power, I still can’t shake the feeling of being a reverse centaur at times. It helps that Chuck comes with several built-in safeguards meant to prevent me from overworking or spending too much time without interacting with other human beings. At 1pm, which is lunch time in Spain, Chuck reminds me about taking a break. It refuses to continue if it detects stress in my text, vocal, or computer usage patterns. While my interactions with Chuck on the laptop are private and encrypted, it’s allowed to inform my manager or call my designated emergency contact in case of distress. I let Chuck access my vitals on the smartwatch and schedule calls with me on a regular basis to see how I’m doing. Since I work alone at home, this makes me feel somewhat safer.\n\nI didn’t tell you, but my current job title is Augmented Writer. My mission is to ensure that the words that humans and machines use to interact with our products are the most effective at reducing confusion and error, while they maximize effectiveness and user satisfaction. I’m augmented because I do this in concert with Chuck, which expands my existing skills in numerous ways. Without my brain, though, Chuck couldn’t do my job, because it doesn’t really care and, more importantly, because it’s not allowed to. One of the conditions imposed by the current legislation is that AI cannot operate in fully autonomous mode without human supervision. Our docs and UIs, in fact, bear a certificate of human authorship that discloses the amount of AI intervention. By law, all AI generated artifacts must produce fingerprinting patterns that can’t be tampered with, which is trickier with text, but since we must keep full audit logs of LLM usage, this can be established upon request by any competent authority, including the Turing police.\n\nIn the end, my role is more of an orchestrator than that of an author, and I’m fine with that. Software engineering, the field I serve, is an exercise in consensual imagination whose goal is to find repeatable ways of processing reality into manageable chunks of data. Reality is unmistakably raw and imperfect, a stream of floating points and broken strings running through distributed systems: one cannot tame it through clever algorithms, but it can be reduced to abstractions and data structures and binary blobs. Each of those entities has a name; they all relate to each other through words. It’s part of my job to understand those words and intervene when they don’t bring clarity. It’s then also my job to explain how those words are able to handle their parent reality. The docs I orchestrate with Chuck’s help are the artifacts that chronicle and explain the motions of data as it enters a machine and exits in shapes and configurations that are helpful to users.\n\nIt’s 5pm and I’m bidding Chuck farewell. During the night, it will work on some optional docs polish and politely present its work to me in the morning. As I log off and extract the hardware key from the laptop, I think that without the words Chuck and I produced, the machine would be opaque to its operators, a smooth wall without doors or handles. Product truth is at my disposal to weave into a fabric of meaning and possibility, into spells that unlock abilities in autonomous agents, be they organic or artificial. I am an enabler of thought and action. Getting here wasn’t easy, but I feel better knowing that I can continue defending the importance of words with the help of the most clever thesaurus ever created.",
    "readingTime": 7,
    "keywords": [
      "it’s",
      "docs",
      "chuck",
      "i’ve",
      "laptop",
      "without",
      "usage",
      "modules",
      "tools",
      "internal"
    ],
    "qualityScore": 1,
    "link": "https://passo.uno/my-day-tech-writer-2030/",
    "thumbnail_url": "/thumb.png",
    "created_at": "2025-12-13T18:48:05.736Z",
    "topic": "tech"
  },
  {
    "slug": "writing-a-typesafe-linux-perf-interface-in-zig",
    "title": "Writing a Type-Safe Linux Perf Interface in Zig",
    "description": "I'm building a benchmarking tool for Zig and needed CPU counters. This is how I wrapped Linux's `perf_event_open` to be type-safe with comptime.",
    "fullText": "I am currently building a hobby project:\npyk/bench, a microbenchmarking library for Zig.\nMy goal is to make it fast and accurate. To measure performance properly,\nlooking at wall clock time is not enough. I need to know what the CPU is\nactually doing.\n\nI want to measure CPU cycles, instruction counts and cache misses. On Linux the\nkernel provides a system call for this named\nperf_event_open.\nIt is very powerful but the API is raw and not easy to use safely.\n\nThe perf_event_open system call creates a file descriptor that allows\nmeasuring performance information. You fill out a perf_event_attr struct with\nthe config you want, such as PERF_COUNT_HW_CPU_CYCLES or\nPERF_COUNT_HW_INSTRUCTIONS, and the kernel gives you back a file descriptor.\n\nYou can read from this file descriptor to get the counts. The format of the data\nyou read depends on how you opened it.\n\nYou can also group events. This is important because it lets you measure\nmultiple things at once with a single read call. One event acts as the “group\nleader” and others are “siblings”. When you read from the leader, you get a\nbinary layout containing values for all events in the group.\n\nThe layout looks roughly like this in C:\n\nThis is dynamic. The size of the struct changes based on how many events you\nhave. In Zig I want something static and type-safe.\n\nMy first attempt was brittle. I hardcoded a struct with the fields I thought I\nwould need.\n\nThis works but it is dangerous. The Measurements struct is hardcoded.\n\nIf I change the initialization logic to add “branch misses”, I have to remember\nto update Measurements, update the ids array size and update the read\nfunction manually. The compiler cannot help me here.\n\nIf I access ids[2] but only initialized 2 events, I crash or get garbage data.\n\nZig allows running code at compile time to generate types. I can use this to\ngenerate a struct that exactly matches the events I request.\n\nI defined an Event enum for the things I want to measure.\n\nThen I wrote a function that takes a slice of these events and returns a new\ntype.\n\nThis function creates a struct with fields named after the enum tags. If I pass\n&.{ .cpu_cycles, .instructions }, it generates:\n\nNow I can create a generic Group type that uses this.\n\nThe usage is cleaner and safer.\n\nIf I try to access a field I did not request, the compiler stops me.\n\nHere is how the full version looks like:\n\nTo implement this I needed to get the ID of the event from the file descriptor.\nThe kernel documentation says to use ioctl with PERF_EVENT_IOC_ID.\n\nI checked std.os.linux in the Zig standard library and it was missing.\n\nSo I opened a pull request to add it. It is just a one line change.\n\nYou can see the PR here:\nhttps://codeberg.org/ziglang/zig/pulls/30162.\nI am not sure if it will be accepted but it felt good to fix a missing piece in\nthe tool I use.",
    "readingTime": 3,
    "keywords": [
      "file descriptor",
      "struct",
      "events",
      "kernel",
      "event",
      "function",
      "request",
      "library",
      "performance",
      "counts"
    ],
    "qualityScore": 1,
    "link": "https://pyk.sh/blog/2025-12-11-type-safe-linux-perf-event-open-in-zig",
    "thumbnail_url": "https://pyk.sh/opengraphs/blog.png",
    "created_at": "2025-12-13T06:54:07.096Z",
    "topic": "tech"
  },
  {
    "slug": "before-megalodon-researchers-say-a-monstrous-shark-ruled-ancient-australian-seas",
    "title": "Before megalodon, researchers say a monstrous shark ruled ancient Australian seas",
    "description": "In the age of dinosaurs — before whales, great whites or the bus-sized megalodon — a monstrous shark prowled the waters off what's now northern Australia, among the sea monsters of the Cretaceous period.  Researchers studying huge vertebrae discovered on a beach near the city of Darwin say the creature is now the earliest known mega-predator of the modern shark lineage, living 15 million years earlier than enormous sharks found before.  The ancestor of today’s 6-meter (20-foot) great white shark was thought to be about 8 meters (26 feet) long, the authors of a paper published in the journal Communications Biology said.",
    "fullText": "WELLINGTON, New Zealand (AP) — In the age of dinosaurs — before whales, great whites or the bus-sized megalodon — a monstrous shark prowled the waters off what's now northern Australia, among the sea monsters of the Cretaceous period.\n\nResearchers studying huge vertebrae discovered on a beach near the city of Darwin say the creature is now the earliest known mega-predator of the modern shark lineage, living 15 million years earlier than enormous sharks found before.\n\nAnd it was huge. The ancestor of today’s 6-meter (20-foot) great white shark was thought to be about 8 meters (26 feet) long, the authors of a paper published in the journal Communications Biology said.\n\n“Cardabiodontids were ancient, mega-predatory sharks that are very, very common from the later part of the Cretaceous, after 100 million years ago,” said Benjamin Kear, the senior curator in paleobiology at the Swedish Museum of Natural History and one of the study’s authors. “But this has pushed the time envelope back of when we’re going to find absolutely enormous cardabiodontids.”\n\nRediscovered fossils pointed to a huge shark\n\nSharks have a 400-million-year history but lamniforms, the ancestors of today’s great white sharks, appear in the fossil record from 135 million years ago. At that time they were small — probably only a meter in length — which made the discovery that lamniforms had already become gigantic by 115 million years ago an unexpected one for researchers.\n\nThe vertebrae were found on coastline near Darwin in Australia’s far north, once mud from the floor of an ancient ocean that stretched from Gondwana — now Australia — to Laurasia, which is now Europe. It’s a region rich in fossil evidence of prehistoric marine life, with long-necked plesiosaurs and ichthyosaurs among the creatures discovered so far.\n\nThe five vertebrae that launched the quest to estimate the size of their mega-shark owners were not a recent discovery, but an older one that had been somewhat overlooked, Kear said. Unearthed in the late 1980s and 1990s, the fossils measured 12 centimeters (4.7 inches) across and had been stored in a museum for years.\n\nWhen studying ancient sharks, vertebrae are prizes for paleontologists. Shark skeletons are made of cartilage, not bone, and their fossil record is mostly made up of teeth, which sharks shed throughout their lives.\n\n“The importance of vertebrae is they give us hints about size,” Kear said. “If you’re trying to scale it from teeth, it’s difficult. Are the teeth big and the bodies small? Are they big teeth with big bodies?”\n\nAncient shark size still holds mystery\n\nScientists have used mathematical formulas to estimate the size of extinct sharks like megalodon, a massive predator that came later and may have reached 17 meters (56 feet) in length, Kear said. But the rarity of vertebrae mean questions of ancient shark size are difficult to answer, he added.\n\nThe international research team spent years testing different ways to estimate the size of the Darwin cardabiodontids, using fisheries data, CT scans and mathematical models, Kear said. Eventually, they arrived at a likely portrait of the predator’s size and shape.\n\n“It would’ve looked for all the world like a modern, gigantic shark, because this is the beauty of it,” Kear said. “This is a body model that has worked for 115 million years, like an evolutionary success story.”\n\nA predator’s past could hint at the future\n\nThe study of the Darwin sharks suggested that modern sharks rose early in their adaptive evolution to the top of prehistoric food chains, the researchers said. Now, scientists could scour similar environments worldwide for others, Kear said.\n\n“They must have been around before,” he said. “This thing had ancestors.”\n\nStudying ancient ecosystems like this one could help researchers understand how today’s species might respond to environmental change, Kear added.\n\n“This is where our modern world begins,” he said. “By looking at what happened during past shifts in climate and biodiversity, we can get a better sense of what might come next.”",
    "readingTime": 4,
    "keywords": [
      "meters feet",
      "fossil record",
      "studying ancient",
      "ancient shark",
      "shark size",
      "sharks",
      "vertebrae",
      "researchers",
      "darwin",
      "modern"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/megalodon-researchers-monstrous-shark-ruled-022242238.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/h0A6fi4PoOLfoaNL0Afu9w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/a01c66b68881dea3689bd5a0cf3aa14f",
    "created_at": "2025-12-13T03:40:56.459Z",
    "topic": "science"
  },
  {
    "slug": "heres-why-a-call-of-duty-movie-is-finally-happening-after-10-years-of-trying",
    "title": "Here's Why A Call Of Duty Movie Is Finally Happening After 10+ Years Of Trying",
    "description": "A movie based on Activision's Call of Duty series is in the works now at Paramount, which is now led by billionaire and Call of Duty superfan David Ellison. Prolific writer and director Taylor Sheridan is writing the script for the film, with Lone Survivor director Peter Berg attached to direct.\nActivision had been trying to make Call of Duty movies for years, so why is it finally happening now? Xbox boss Matt Booty told Variety that \"a relationship came about\" between people at Paramount and senior executives working on Call of Duty. \"They felt like they found a partner who understands the game, people who play the game, and shared a vision of what it could be to bring that forward,\" Booty said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/heres-why-a-call-of-duty-movie-is-finally-happening-after-10-years-of-trying/1100-6536930/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4621736-screenshot2025-12-12at8.45.08%E2%80%AFam.png",
    "created_at": "2025-12-12T18:55:57.681Z",
    "topic": "entertainment"
  },
  {
    "slug": "judge-orders-kilmar-abrego-garcia-to-be-immediately-released-from-immigration-detention",
    "title": "Judge orders Kilmar Abrego Garcia to be immediately released from immigration detention",
    "description": "Kilmar Abrego Garcia must be freed from immigration detention while he fights his deportation, a judge ruled Thursday, handing a major victory to the immigrant whose wrongful deportation to a notorious prison in El Salvador made him a flashpoint of the Trump administration’s immigration crackdown.  U.S. District Judge Paula Xinis in Maryland ordered Immigration and Customs Enforcement to let Abrego Garcia go immediately, writing that federal authorities had detained him again after his return to the United States without any legal basis.",
    "fullText": "Kilmar Abrego Garcia must be freed from immigration detention while he fights his deportation, a judge ruled Thursday, handing a major victory to the immigrant whose wrongful deportation to a notorious prison in El Salvador made him a flashpoint of the Trump administration’s immigration crackdown.\n\nU.S. District Judge Paula Xinis in Maryland ordered Immigration and Customs Enforcement to let Abrego Garcia go immediately, writing that federal authorities had detained him again after his return to the United States without any legal basis.\n\n“For this reason, the Court will GRANT Abrego Garcia’s Petition for immediate release from ICE custody,” the judge wrote.\n\nThe Department of Homeland Security sharply criticized the decision and vowed to appeal, calling the ruling “naked judicial activism” by a judge appointed during the Obama administration.\n\n“This order lacks any valid legal basis, and we will continue to fight this tooth and nail in the courts,” said Tricia McLaughlin, the department’s assistant secretary. The judge gave prosecutors until 5 p.m. EST to formally respond to the release order.\n\nThe Justice Department declined to comment, and messages seeking comment from Abrego Garcia’s attorney were not immediately returned.\n\nAbrego Garcia, a Salvadoran national with an American wife and child, has lived in Maryland for years but entered the U.S. illegally as a teenager. An immigration judge ruled in 2019 that he could not be deported to El Salvador because he faced danger from a gang that targeted his family. When he was mistakenly sent there in March, his case became a rallying point for those who oppose President Donald Trump’s immigration enforcement actions.\n\nA court later ordered his return to the United States. Since he cannot be removed to El Salvador, ICE has been seeking to deport him to a series of African countries. His federal suit claims the Trump administration is illegally using the removal process to punish Abrego Garcia for the public embarrassment caused by his deportation.\n\nIn her order releasing Abrego Garcia, Xinis wrote that federal authorities “did not just stonewall” the court, “They affirmatively misled the tribunal.” The judge was referencing the successive list of four African countries that officials had sought to remove Abrego Garcia seemingly without commitments from those countries, as well as officials' affirmations that Costa Rica withdrew its offer to accept him, a claim later proven untrue.\n\n“But Costa Rica had never wavered in its commitment to receive Abrego Garcia, just as Abrego Garcia never wavered in his commitment to resettle there,” the judge wrote.\n\nXinis also rejected the government’s argument that she lacked jurisdiction to intervene on a final removal order for Abrego Garcia, because she found no final order had been filed.\n\nSeparately, Abrego Garcia is asking an immigration court to reopen his case so he can seek asylum in the United States.\n\nHe is also criminally charged in Tennessee, where he has pleaded not guilty to human smuggling. He has asked the federal court to dismiss the case, arguing the prosecution is vindictive. His defense attorney in Tennessee, Sean Hecker, declined to comment.\n\nA judge in that case has ordered an evidentiary hearing after previously finding some evidence that the charges “may be vindictive.” The judge also noted several statements by Trump administration officials that “raise cause for concern,” including a statement by Deputy Attorney General Todd Blanche that seemed to suggest the Justice Department charged Abrego Garcia because he won his wrongful deportation case. ___\n\nLoller reported from Nashville, Seewer reported from Toledo, Ohio and Lauer reported from Philadelphia. Associated Press reporter Alanna Durkin Richer in Washington contributed to this report.",
    "readingTime": 3,
    "keywords": [
      "trump administration",
      "abrego garcia",
      "legal basis",
      "wrongful deportation",
      "federal authorities",
      "judge ruled",
      "el salvador",
      "court",
      "ordered",
      "attorney"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/judge-orders-kilmar-abrego-garcia-154255309.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/a0M6hY0ASmu1RqN_RGIGnw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/402cd28fa90f1643a286fc771ae63b50",
    "created_at": "2025-12-11T18:58:22.683Z",
    "topic": "news"
  },
  {
    "slug": "clair-obscur-expedition-33-how-a-tiny-studio-developed-the-belle-poqueset-gaming-blockbuster",
    "title": "Clair Obscur: Expedition 33 – how a tiny studio developed the Belle Époque-set gaming blockbuster",
    "description": "What started as Guillaume Broche’s personal project has been nominated for 12 Game awards, sold more than 2m copies and been praised by Emmanuel Macron as a ‘shining example of French audacity’\nThe record-breaking 12 nominations at the Game awards this year was beyond the wildest dreams of Guillaume Broche when he first began inking out Clair Obscur: Expedition 33 as a personal project while working at Ubisoft.\nBefore selling more than 2m copies, the narrative-driven roleplaying game with “a unique world, challenging combat and great writing” was a technical demo called We Lost. It was Broche’s appetite for risk and a few hopeful Reddit posts that would create the game’s world of Lumiere and its struggle against the Paintress.\n Continue reading...",
    "fullText": "What started as Guillaume Broche’s personal project has been nominated for 12 Game awards, sold more than 2m copies and been praised by Emmanuel Macron as a ‘shining example of French audacity’\n\nThe record-breaking 12 nominations at the Game awards this year was beyond the wildest dreams of Guillaume Broche when he first began inking out Clair Obscur: Expedition 33 as a personal project while working at Ubisoft.\n\nBefore selling more than 2m copies, the narrative-driven roleplaying game with “a unique world, challenging combat and great writing” was a technical demo called We Lost. It was Broche’s appetite for risk and a few hopeful Reddit posts that would create the game’s world of Lumiere and its struggle against the Paintress.\n\n“I was doing like eight hours per day after work and not sleeping at all for a few years,” Broche says. And while he would be joined by Tom Guillermin on the programming side and Francoise Meurisse as producer, the next few members of the nascent studio – Lorien Testard, lead composer and Jennifer Svedberg-Yen, lead writer – would only come to Clair Obscur by chance, via social media.\n\nTestard, a guitar teacher at the time who had never composed or published any music commerically, was discovered by Broche on SoundCloud. “We liked the same philosophy in games,” says Testard, who had been writing music inspired by his favourite titles. Similarly, Broche found his art director, Nicholas Maxson-Francombe, through personal works he posted on ArtStation. “We are all deeply engaged in our subject areas,” says Svedberg-Yen, who says that was what bonded the team together. “If you listen to Nicolas talk about art or Lorien talk about music, it’s just something that fills our minds and our days.”\n\nSvedberg-Yen, meanwhile, had come from the world of finance. She saw Broche’s Reddit post and auditioned to not only write but also to voice some of the prototype characters of Clair Obscur, namely Maelle and Lune. Despite a deep love for video games, storytelling and a childhood engrossed in novels, Svedberg-Yen had not considered it as a career option. “It never crossed my mind as possible. As the adage goes, for Asian parents [it’s] doctors, lawyers, or finance.”\n\nWith a rudimentary team assembled under the banner of a new studio, Sandfall Interactive, they rebooted We Lost as Clair Obscur. It was there a world took shape and the gained its unmistakeable Belle Époque setting. “There’s a specificity,” Svedberg-Yens says. “I think that vision gets diluted when you’re trying to appeal to too many people.”\n\n“It’s not meant to be French propaganda,” jokes Broche, about the game’s very Gallic aesthetic. The characters yell putain and merde, there are berets and extremely scary mimes not only because it’s fun, he says, but born from a desire to make something “sincere and authentic”.\n\nSame goes for the story. Clair Obscur’s narrative drives the game forward and, as lead writer, Svedberg-Yen says it all has a “grounding and a basis in truth”.\n\n“We are all first-time writer and game developers in this sense … and so we kind of only know instinctively how write to what instinctively comes from within. And for a lot of the characters in those particular situations, to write them [you] have to really delve into the parts of my life that resonate with the situation that they’re in.”\n\nAccording to Svedberg-Yen, a conversation Broche had with his mother became core to the story’s emotional heft. When he asked her what would be the worst thing that could possibly happen, his mother responded saying it would be to lose her children. “The story deals with a lot of trauma,” she says, and that process of writing like that was often a scary process. “If people don’t like it, they don’t like you.” It was this ability to be vulnerable and open a communicative environment that Broche believes contributed to the success of the game.\n\nDespite an anxiety in the industry about the rise of AI in the development of video games, the team at Sandfall isn’t worried – especially Testard, who composed the game’s orchestral score based off the narrative beats of the game and the eponymous concept of clair obscur (or chiaroscuro), AKA the interplay of light and dark. “Music is the language of the soul,” he says. In fact, the evolution of technology like Unreal Engine 4 and the later 5, which the game runs on today, made a lot of the game possible. “More games will be 3D, because we have a lot of tools now,” says Broche, who describes the budget of his game to be on the “lower end of AA.”\n\nThe team at Sandfall have been overwhelmed by their success. The French president, Emmanuel Macron, lauded the game as “shining example of French audacity”. None of them expected the experience of Clair Obscur to resonate so deeply with so many people. “I’ve gotten a lot of very heartfelt messages from players who have experienced loss in some way and who have felt that the story helped them deal with their grief or change their relationship with grief,” Svedberg-Yen says.\n\n“What’s really cool is I’ve gotten tons of messages from creatives, writers, aspiring writers who felt creatively drained or just felt like they wanted to quit, but then the game inspired them to start again and they started creating their own art again, to start writing.”",
    "readingTime": 5,
    "keywords": [
      "i’ve gotten",
      "french audacity",
      "personal project",
      "game awards",
      "clair obscur",
      "emmanuel macron",
      "music",
      "games",
      "team",
      "it’s"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/11/clair-obscur-expedition-33-video-game-tiny-studio-developed-blockbuster",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de7272ae99a245b1ca069ffc4a50c11a28465092/478_134_2532_2026/master/2532.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2a7548a6ff68110738e5a01d103698a7",
    "created_at": "2025-12-11T13:53:39.909Z",
    "topic": "gaming"
  },
  {
    "slug": "st-ergnats-dream-of-writing-next-great-moneyglass-tale",
    "title": "St Ergnat's dream of writing next great Moneyglass tale",
    "description": "St Ergnat's Moneyglass hope to become the County Antrim village's next sporting heroes in this weekend's All-Ireland Ladies Club final.",
    "fullText": "The folks in Moneyglass are no strangers to cheering on one of their own on a big stage.\n\nWillie John McBride, who went on to star for the British and Irish Lions, was born in the small County Antrim village. So, too, was Grand National winner AP McCoy.\n\nNow, St Ergnat's are hoping to follow in their footsteps.\n\nIt has already been a memorable year for the club. After securing a fifth straight Antrim title, they conquered Ulster for the first time in November, beating Errigal Ciaran in the final.\n\nRuling the province was a realistic aim for Moneyglass this year, but few outside the squad - who are led by former Donegal ladies boss Maxi Curran - would have expected them to reach the All-Ireland final.\n\nBut they have gleefully defied expectations. Beating Dublin's Kilmacud Crokes in the semi-final a fortnight ago means they will become first Antrim side to grace the biggest stage in ladies club football at Croke Park on Saturday (16:00 GMT).\n\n\"Coming into this year, we just wanted to go a bit further than last year,\" says Aoife Kelly.\n\n\"Getting beaten in the semi-finals two years in a row, off the back of getting to the 2022 Ulster final, so the goal was to get back to the Ulster final, we got there, won it and we've been taking it game by game.\n\n\"It was no coincidence we won Ulster, we have been building to it for the last few years.\"",
    "readingTime": 2,
    "keywords": [
      "ulster final",
      "moneyglass",
      "stage",
      "club",
      "ladies",
      "back",
      "game",
      "antrim",
      "beating"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/articles/cn7kex85k0no?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/0ffd/live/0791e620-d5e3-11f0-b1c1-a1fc4155147e.png",
    "created_at": "2025-12-11T13:53:34.013Z",
    "topic": "sports"
  },
  {
    "slug": "tracking-penn-states-pinstripe-bowl-opt-outs-durant-wheatley-thus-far",
    "title": "Tracking Penn State’s Pinstripe Bowl Opt Outs: Durant, Wheatley Thus Far",
    "description": "Folks, instead of doing an individual post for each player that opts out of the Pinstripe Bowl, we’ll be updating this post instead. As of this writing on Wednesday, December 10th at 10 p.m. EST, just two Nittany Lions have opted out. DB Zakee Wheatley (NFL Draft) Wheatley joins Durant as the second player on […]",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://sports.yahoo.com/articles/tracking-penn-state-pinstripe-bowl-030905061.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/alH0BuwQ4TUlzzmie.A.tg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/sb_nation_articles_115/c41ed04580f3ed4c736372f98142f288",
    "created_at": "2025-12-11T03:51:05.191Z",
    "topic": "sports"
  }
]
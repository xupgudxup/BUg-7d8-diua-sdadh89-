[
  {
    "slug": "alloconda-zig-toolkit-for-writing-cpython-extensions",
    "title": "Alloconda: Zig toolkit for writing CPython extensions",
    "description": "Zig-first Python extensions with cross-compiled wheels - mattrobenolt/alloconda",
    "fullText": "mattrobenolt\n\n /\n\n alloconda\n\n Public\n\n Zig-first Python extensions with cross-compiled wheels\n\n alloconda.withmatt.com\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mattrobenolt/alloconda",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/mattrobenolt/alloconda",
    "thumbnail_url": "https://opengraph.githubassets.com/a2496d8ff611964da1e92da6207f8854fcee7c8b17f1cf714d77ec0faa33320f/mattrobenolt/alloconda",
    "created_at": "2025-12-23T06:19:53.662Z",
    "topic": "tech"
  },
  {
    "slug": "we-built-an-ai-humanizer-to-fix-unnatural-ai-writing",
    "title": "We built an AI Humanizer to fix unnatural AI writing",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Humanize AI-generated content and turn it into natural, human-quality writing from ChatGPT, Jasper, or Gemini in seconds.\n\nEnter or paste your text and click Humanize.\n\nUsing the Dechecker Humanizer takes only moments and requires no technical skills.\n\nPaste your AI-generated content into the AI Humanizer and review it briefly before starting the humanization process, ensuring that the original text is complete and ready for accurate human-like rewriting.\n\nChoose your preferred style, language, and length to guide how the AI Humanizer shapes the final human text, allowing you to customize tone, readability, and overall writing style for your intended audience.\n\nAfter using the AI Humanizer, review your text to ensure it has been properly humanize AI content, flows naturally, reads authentically, and maintains the original meaning, tone, and clarity throughout.\n\nCopy the Humanize AI result for use, or check it with Dechecker AI Checker to review AI Humanizer output and AI detection results, ensuring your text is fully human-like and suitable for publishing or sharing.\n\nDechecker focuses on what matters most: producing clear, natural, human-quality text you can confidently use anywhere.\n\nAI-generated content is carefully refined into natural, fluent writing using an AI Humanizer that removes robotic patterns, awkward phrasing, and mechanical-sounding sentences, making the text read smoothly and authentically like a real human wrote it.\n\nThis AI Humanizer works seamlessly across multiple languages, helping content sound human and natural without awkward translations or stiff wording, while preserving original meaning and readability for global audiences.\n\nTone, clarity, and overall flow are enhanced while keeping the original intent intact, producing human-style text that is easy to read, engaging for audiences, and maintains the message accurately across different formats.\n\nAfter rewriting, content can be reviewed with AI Checker like Dechecker to confirm it reads as human, avoids robotic signals, and ensures the output is indistinguishable from text written by real people.\n\nOur AI Humanizer helps users humanize AI text across various scenarios, turning AI-generated drafts into natural, human-like writing that reads smoothly and clearly.\n\nThe AI Humanizer helps writers improve blog posts, articles, and stories by refining AI-generated drafts, making them read naturally, flow smoothly, and engage readers more effectively while keeping original ideas intact.\n\nUse Humanize AI to refine essays, research papers, and reports, ensuring content sounds human, is clear and easy to understand, and maintains proper academic tone and logical structure throughout.\n\nAI Humanizer transforms marketing copy, social media posts, and emails into smooth, human-like text that resonates with audiences, boosts engagement, and maintains consistent brand voice across all channels.\n\nWith multilingual support, Dechecker AI Humanizer allows teams to produce human-quality content in different languages, preserving tone, meaning, and readability, ensuring professional communication worldwide.\n\nDechecker Humanize AI ensures course content, tutorials, and learning resources are readable, human-like, and engaging, helping students better understand complex topics and improving overall learning experience.\n\nUse Dechecker AI Humanizer to humanize AI-generated web content, making it more engaging, natural, and optimized for readers, while improving user experience and search engine readability simultaneously.\n\nReal feedback from users who have improved their AI-generated content with AI Humanizer, making writing feel more natural and human-like.\n\nFind answers to common questions about using AI Humanizer to humanize AI text and make content sound natural and human-like.\n\nAn ai humanizer is a tool designed to turn AI-generated text into human-like writing. It improves readability, sentence structure, and tone, helping content feel natural and engaging to real readers.\n\nAI Humanizer analyzes AI-generated text, restructures sentences, adjusts phrasing, and refines flow to humanize AI content, making it sound naturally written while keeping the original meaning intact.\n\nYes, the AI Humanizer supports multiple languages, including English, Spanish, French, German, and more. It ensures your text feels natural and human-like across all supported languages.\n\nAbsolutely. Dechecker Humanize AI allows you to customize writing style, tone, and length, making content suitable for blogs, articles, marketing copy, emails, and other professional uses.\n\nNo. AI Humanizer focuses on enhancing readability and natural flow without altering your key ideas, intent, or important information, keeping your message accurate.\n\nYes. AI Humanizer humanizes AI-generated text without fabricating information. It helps essays, reports, and professional content read naturally while maintaining integrity and clarity.\n\nDefinitely. After using Dechecker AI Humanizer, you can review the output with AI Checker to ensure the Humanize AI content reads naturally, appears human-written, and meets authenticity requirements.\n\nWriters, students, marketers, content creators, and businesses can all benefit. Anyone looking to make AI-generated content readable and humanize AI content efficiently will find the ai humanizer extremely useful.",
    "readingTime": 4,
    "keywords": [
      "ai humanizer",
      "ai-generated drafts",
      "marketing copy",
      "ai-generated content",
      "dechecker humanize",
      "ai-generated text",
      "natural human-quality",
      "content sound",
      "ai checker",
      "human-like"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai/ai-humanizer",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-23T06:19:37.153Z",
    "topic": "tech"
  },
  {
    "slug": "the-death-and-rebirth-of-programming",
    "title": "The Death and Rebirth of Programming",
    "description": "Programming didn't die all at once. There was no single moment, no dramatic obsolescence event. Instead, something quieter happened: the core constraint that shaped software for seventy years dissolved. Writing code stopped being the hard part.",
    "fullText": "For most of computing history, programming was bottlenecked by human cognition. Translating intent into working software required time, attention, and specialized skill. Even small changes were costly. This scarcity justified entire ecosystems: languages, frameworks, methodologies, reviews, team rituals that made sense when every line was expensive.\n\nGenerative AI removes that scarcity.\n\nToday, a single developer can generate thousands of lines of working code in minutes. Tomorrow, that number will be effectively infinite. The marginal cost of producing code is collapsing toward zero.\n\nWhat hasn't collapsed is the cost of knowing what the code does.\n\nUnderstanding, verifying, securing, and evolving software remain stubbornly expensive. In fact, they may be getting harder as volume explodes. This asymmetry—the ease of creation versus the difficulty of comprehension—is the defining tension of modern software.\n\nProgramming hasn't disappeared. But its center of gravity has shifted.\n\nIn the old world, programmers owned code. You wrote it, you understood it, you maintained it. Your value was tied to mastery of specific implementations. Codebases accrued history, reputation, and power.\n\nIn the new world, ownership becomes a liability.\n\nWhen code can be regenerated faster than it can be understood, preserving it for sentimental or historical reasons no longer makes sense. What matters instead is stewardship: maintaining the system's behavior, boundaries, and intent over time, regardless of how many times its internals are replaced.\n\nThis reframing is subtle but profound:\n\nThe asset is no longer the codebase. The asset is the system's ability to keep working.\n\nThis is the thesis of everything that follows. Architecture, testing, interfaces, team structure: all of it flows from this inversion.\n\nMany of the \"modern\" software practices of the last decade were early adaptations to this shift, even if we didn't articulate them that way.\n\nImmutable infrastructure. Stateless services. Containers. Blue-green deployments. Infrastructure as code.\n\nThese ideas all share a common premise: never fix a running thing. Replace it.\n\nAI pushes this premise beyond infrastructure and into application code itself. When rewriting is cheap, editing in place becomes risky. Mutation accumulates entropy. Replacement resets it.\n\nDisposability stops being a hack. It becomes the default.\n\nThis transition isn't just technical. It's deeply psychological, and that psychology shapes architecture.\n\nMany developers identify as builders and craftspeople. We take pride in elegance, cleverness, and mastery of internals. We accumulate knowledge inside our heads and inside codebases. Longevity feels like validation.\n\nGenerative AI destabilizes this identity.\n\nWhen a machine can produce a competent version of \"your\" solution in seconds, craftsmanship no longer lies in the artifact. It lies in framing the problem, defining success, and deciding what to keep and what to discard.\n\nThe role shifts from maker to architect. From author to managing editor. From preserving code to designing for its replacement.\n\nThat shift is uncomfortable. And the discomfort isn't merely personal. It's what makes teams resist the very patterns that would help them. Developers cling to codebases because identity is at stake, not just technical judgment. Acknowledging this is the first step toward building systems that don't require heroics to change.\n\nResisting the shift doesn't stop it. It just makes systems more fragile.\n\nOne of the clearest signals of this new era is the rise of the n=1 developer.\n\nProjects that once required teams now fit inside a single person's cognitive boundary—with AI filling in the execution gaps. Entire products can be specified, generated, evaluated, and shipped by one human working with machines.\n\nThis isn't about productivity hacks. It's about a structural change in leverage.\n\nBut n=1 development only works if systems are designed for it. Large, tangled, historically accreted codebases collapse under their own weight when AI accelerates change. Small, modular, disposable systems thrive.\n\nThe n=1 developer is not a superhero. They are an indicator species. They are evidence that the environment has changed, and proof that the new patterns actually work.\n\nIt's tempting to frame this as the \"end of programming.\" That's misleading.\n\nWhat's dying is a specific form of programming: one that equates value with authored code, longevity of code with quality, and maintenance with virtue.\n\nWhat's being born is something closer to systems design as an ongoing process of regeneration:\n\nCode becomes an intermediate artifact, not the final product. Rewrites become routine, not traumatic. Tests and evaluations define truth, not files. Stability emerges from replacement, not preservation.\n\nThis is not nihilism. It's pragmatism under new constraints.\n\nThe rest of this publication builds on a single premise established here:\n\nWhen code is cheap and understanding is expensive, architecture must optimize for the impermanence of code.\n\nEverything else (pace layers, evaluations, clean interfaces, regeneration workflows) flows from that fact.\n\nWe are not entering a world with less software. We are entering a world with vastly more of it. The only way to survive that abundance is to stop treating code as precious.\n\nBut it has been reborn, and it expects us to change with it.",
    "readingTime": 5,
    "keywords": [
      "modern software",
      "generative ai",
      "code",
      "it's",
      "systems",
      "programming",
      "codebases",
      "expensive",
      "developer",
      "longer"
    ],
    "qualityScore": 1,
    "link": "https://aicoding.leaflet.pub/3malrv6poy22a",
    "thumbnail_url": "https://leaflet.pub/lish/did%253Aplc%253A4qsyxmnsblo4luuycm3572bq/3majnsnvafs2b/3malrv6poy22a/opengraph-image?6815eb61f733905a",
    "created_at": "2025-12-23T00:56:32.109Z",
    "topic": "tech"
  },
  {
    "slug": "joan-didion-and-kurt-vonnegut-had-something-to-say-we-have-it-on-tape",
    "title": "Joan Didion and Kurt Vonnegut Had Something to Say. We Have It on Tape",
    "description": "Rare recordings of E.E. Cummings, Mary Oliver and more offer a tour through literary history led by authors in their own words — and voices. Take a listen.",
    "fullText": "Tom Wolfe was a fast talker. Eudora Welty had a musical Southern drawl. Kurt Vonnegut’s jokes got belly laughs.\n\nEach of these authors once spoke to audiences at the 92nd Street Y Unterberg Poetry Center in New York City, which has hosted some of the most celebrated writers of the past several generations, from Isaac Asimov to Anaïs Nin and Kazuo Ishiguro to Margaret Atwood. Now, the Poetry Center has digitized audio recordings of its literary events stretching back to 1949 — hundreds of which have never been released before — in a collection that offers a glimpse into history and a taste of what the writers themselves were like in public.\n\nIn 1965, for example, the year before he became consultant in poetry to the Library of Congress, James Dickey complained that his 14-year-old son had acquired a taste for rock ’n’ roll and a transistor radio. The sound of electric guitars had taken over his house. He was joined onstage that night by the poet Theodore Weiss, but it could have been Truman Capote, Joseph Heller or Adrienne Rich, who also visited the Poetry Center over the years.\n\n“Historically, it’s been the premier place to read your work in public in the United States,” said Billy Collins, a former U.S. poet laureate, who has read at the Poetry Center many times. “Maybe short of the White House or Carnegie Hall — but most poets don’t get to Carnegie Hall no matter how hard they practice.”\n\nYou can listen to some clips from the archive below.\n\nBaldwin was a gifted public speaker, compelling and quick on his feet. The eldest son of a preacher, Baldwin turned his own oratorical skills to advocacy and debate after a short stint at the pulpit as a teenager. Here, he talks about the mysteries of the writing process.\n\nIn this recording, Didion reads from her book “The Year of Magical Thinking,” which recounts her daughter’s grave illness and the sudden death of her husband, John Gregory Dunne. Didion and Dunne had been married for 40 years when, after visiting their daughter at the hospital, Dunne collapsed at the dinner table from a heart attack. He was pronounced dead a few hours later. The book offers a portrait of both loss and the long marriage that preceded it.\n\nThe prolific and prizewinning poet reads “Wild Geese,” one of her most celebrated poems. Oliver, who died in 2019, read at the Poetry Center three times during her life. On each of those visits, she made sure to include this fan favorite.\n\nVonnegut was best known for his novels, including “Slaughterhouse-Five” and “Cat’s Cradle,” but because he was at the Poetry Center, he thought he should read some poems. How he met the moment was quintessential Vonnegut: genial and cheeky in equal measure.\n\nWolfe, an author and journalist, was known both for novels including “The Bonfire of the Vanities” and for the role he played in helping to create “New Journalism,” which employed novelistic techniques in nonfiction. Wolfe was also an exceptionally snappy dresser, and he was often photographed wearing a bespoke three-piece white suit — although he chose a different outfit for the reporting trip he recounts here.\n\nThe earliest recording in the collection is of the American poet E.E. Cummings, who read at the Poetry Center in 1949. Cummings was born in 1894 and died in 1962, so even readers who love his distinctive style — with its unusual, almost sculptural line breaks and formatting — may not be familiar with his stately reading voice.\n\nThis selection is pulled from a Q. and A. with the playwright behind such classics of American theater as “The Crucible” and “Death of a Salesman.” A member of the audience asked about Miller’s play “The American Clock,” which is set during the Great Depression and was first staged in 1980: was Miller, the audience member asked, expecting another economic calamity when he wrote it?\n\n“dying is fine,” from “The Complete Poems: 1904-1962,” by E.E. Cummings. Copyright © 1949, 1977, 1991 by the Trustees for the E.E. Cummings Trust. Copyright © 1979 by George James Firmage. Used with permission of Liveright Publishing Corporation, a division of W.W. Norton & Company. All rights reserved.\n\n“Wild Geese,” from “Dream Works: Poems,” by Mary Oliver. Copyright © 1986 by NW Orchard LLC. Copyright © 1986-2017 by Mary Oliver, with permission of Bill Reichblum. Reprinted by permission of Penguin Books, an imprint of Penguin Random House, and the Charlotte Sheedy Literary Agency. All rights reserved.",
    "readingTime": 4,
    "keywords": [
      "rights reserved",
      "poetry center",
      "carnegie hall",
      "wild geese",
      "dunne",
      "permission",
      "celebrated",
      "writers",
      "literary",
      "collection"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2025/12/19/books/james-baldwin-joan-didion-92ny-recordings.html",
    "thumbnail_url": "https://static01.nyt.com/images/2025/11/20/multimedia/00TBR-92Y-03-cpvm/00TBR-92Y-03-cpvm-facebookJumbo.jpg",
    "created_at": "2025-12-22T06:20:28.076Z",
    "topic": "tech"
  },
  {
    "slug": "impeachable-pam-bondi-defied-federal-law-by-erasing-epstein-photos-to-protect-trump",
    "title": "Impeachable: Pam Bondi Defied Federal Law by Erasing Epstein Photos to Protect Trump",
    "description": "The DOJ removed already-public Epstein files in defiance of a disclosure statute, prompting bipartisan outrage and impeachment talk from the law’s authors.",
    "fullText": "(Evan Vucci/The Associated Press)\n\nThe Justice Department is now engaged in an open cover-up carried out in direct violation of federal law.\n\nOver the weekend, the department quietly removed 16 photographs from the Epstein files website it created to comply with a disclosure statute passed by Congress and signed into law by President Donald Trump. The removals came without notice or explanation. Among the deleted images was one of the few photographs that even indirectly featured Trump, a picture of a credenza drawer inside Jeffrey Epstein’s Manhattan home containing other photographs, including at least one of Trump. Twelve others depicted Epstein’s third-floor massage room, a central crime scene in the federal investigation. Some images of the same room remain public. Others disappeared.\n\nWhen Democrats on the House Oversight Committee asked whether the Trump-related image had been taken down, the Justice Department declined to respond.\n\nWhat followed made matters worse.\n\nIn a post on X quoting Deputy Attorney General Todd Blanche, the Justice Department claimed that “photos and other materials will continue being reviewed and redacted consistent with the law in an abundance of caution as we receive additional information.” Blanche’s original post asserted that the department had released Epstein materials “under the Epstein Files Transparency Act” and that additional disclosures would follow “as our review continues, consistent with the law and with protections for victims.”\n\nThat explanation fails under the statute the department invoked.\n\nCongress did not authorize a rolling review. The Epstein Files Transparency Act compels the Justice Department to release all Epstein-related materials in its possession. The law imposes a mandatory disclosure obligation and permits only limited redactions to protect victims. It grants no authority to retract, revise, or curate records after release. Once the department published those materials, the law required that they remain available to the public.\n\nRemoving them placed the department in direct conflict with the statute Congress enacted.\n\nThat conflict was immediately recognized. Blanche’s post received a community note stating that the law requires the release of all files and allows only narrow redactions to protect victims, adding that the department’s partial release and extensive redactions violated the statute. The Justice Department’s own post received a community note citing the statute directly and stating that retractions and redactions to protect politically exposed persons are not permitted. Community Notes appear only when users with differing political viewpoints agree on their accuracy, underscoring how broadly that conclusion was shared.\n\nThe department’s own explanation confirms it is violating the law it claims to follow.\n\nThe sequence exposes motive. The files went live. Political reaction followed. The department then altered the public record. Compliance held only until presidential exposure appeared, then gave way to erasure.\n\nIn November, I described the Trump Justice Department’s handling of the Epstein files as a cover-up. Last week, I wrote that the administration’s delay in disclosure created a political problem rather than an immediate legal one. That assessment reflected weak enforcement mechanisms and an approach built on delay rather than open defiance.\n\nRemoving already released material that implicates the president converts a credibility crisis into a statutory violation and a far larger political emergency. Congress passed the Epstein disclosure statute precisely to eliminate executive discretion. Lawmakers acted because the Justice Department repeatedly demonstrated it could not be trusted to manage politically sensitive material involving powerful figures. The law mandated disclosure to prevent executive self-protection.\n\nThe department seized that discretion anyway.\n\nAttorney General Pam Bondi had lawful options. She could have sought judicial review. She could have consulted Congress. She could have acknowledged that the statute permits no removal authority and sought amendment. Each path would have preserved institutional legitimacy. She chose concealment and false justification instead.\n\nThis erasure differs from earlier Trump-era document fights in a crucial way. Prior disputes centered on whether materials must be disclosed. This episode involves evidence already released to the public under statutory standards. The department determined the images satisfied the law’s requirements, then removed them once the political cost became apparent.\n\nEvery disclosure statute now faces the same test: compliance survives only until it threatens the president. Months of delay, sweeping redactions, and staged releases already convinced much of the public that the Justice Department prioritized Trump’s standing over transparency, victims, and the public interest. The image removals confirm that conclusion decisively.\n\nA Justice Department that edits evidence to shield the president forfeits legitimacy. Oversight collapses when obedience ends at political inconvenience. The rule of law depends on statutes binding the executive even when compliance proves costly.\n\nCongress wrote a law to prevent exactly this abuse. The president signed it. The attorney general is now violating it to protect him. That meets any reasonable standard for impeachment.\n\nThe backlash on Capitol Hill was immediate and bipartisan. Democratic Rep. Ro Khanna of California, who co-authored the Epstein Files Transparency Act, and Republican Rep. Thomas Massie of Kentucky, who forced the House vote compelling disclosure, both said the Justice Department failed to comply with the law. Khanna has confirmed that he and Massie are drafting impeachment and contempt measures against Attorney General Pam Bondi.\n\nCongress now faces a choice. It can accept that disclosure laws apply only when politically painless. It can normalize the disappearance of already public evidence. It can allow executive power to override legislative command.\n\nOr it can enforce the law it wrote.\n\nThis is a cover-up enforced through executive defiance. The question now is whether Congress will enforce its own laws.\n\nThe post Impeachable: Pam Bondi Defied Federal Law by Erasing Epstein Photos to Protect Trump first appeared on Mediaite.",
    "readingTime": 5,
    "keywords": [
      "pam bondi",
      "transparency act",
      "files transparency",
      "epstein files",
      "justice department",
      "justice department’s",
      "received community",
      "community note",
      "protect victims",
      "federal law"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/impeachable-pam-bondi-defied-federal-142332537.html",
    "thumbnail_url": "https://media.zenfs.com/en/mediaite_845/14ad98684991a13d9b9c7d5587ec3f0a",
    "created_at": "2025-12-21T18:15:58.663Z",
    "topic": "news"
  },
  {
    "slug": "multimillionaire-musician-william-says-worklife-balance-is-for-people-working-on-someone-elses-dreamhe-grinds-from-5to9",
    "title": "Multimillionaire musician Will.i.am says work-life balance is for people ‘working on someone else’s dream’—he grinds from 5-to-9 after his 9-to-5",
    "description": "When Will.i.am’s not writing hit songs like “OMG” for Usher, he’s looking for the next big pop star on The Voice U.K., or running his new AI company, FYI.",
    "fullText": "Orianna Rosa Royle is the Success associate editor at Fortune, overseeing careers, leadership, and company culture coverage. She was previously the senior reporter at Management Today, Britain's longest-running publication for CEOs.\n\nWill.i.am is busy. When he’s not writing hit songs like “OMG” for Usher, he’s looking for the next big pop star on The Voice UK, or running his new AI company, FYI. So how exactly does he balance it all?\n\nThe Grammy Award–winning artist turned tech entrepreneur revealed to Fortune that he maxes out the 5-to-9 after the daily grind of his 9-to-5, and he advises Gen Zers to forget about work-life balance if they want to emulate his success.\n\n“If you’re trying to build something that doesn’t exist, it’s about dream-reality balance,” he says. “Work-life balance means that you’re working for somebody else’s dream. You just have a job supporting somebody else’s dream, and you want to balance your work and your life.\n\n“But if it’s dream-reality balance, then it’s not work. It’s a dream that you’re trying to put into reality, and you’re ignoring your current reality.”\n\nFor example, after working on his tech venture from 9 a.m. to 5 p.m., Will.i.am says that he goes back to work on his creative business until 9 p.m. But before his AI company was a reality, his day was flipped. He’d work on music first before dipping into his tech side hustle well into the evening.\n\nIt’s why he advises young people to reframe how they think of their time off work and their current 9-to-5 reality.\n\n“I’m not really paying attention to this reality,” he explains. “I’m trying to bring that one [a new business venture or idea] here and focusing on how do I get people who believe in this dream to help me materialize it? So for that, you have to make some type of sacrifice to bring this thing that doesn’t exist here.\n\n“From that perspective, work-life balance is not for the architects that are pulling visions into reality. Those words don’t compute to the mindset of the materializers.”\n\nOf course, many young people already put in hours to their side hustles and personal development after work. Millions of Gen Zers and millennials are tuning into people’s 5-to-9 evening routines on TikTok.\n\nBut Will.i.am says chipping away at your dream when most people are off work extends to weekends, birthdays, and holidays.\n\n“I didn’t party. I was always a square, meaning, ‘You work too much, man, let’s go out.’ Like what? Go out. I don’t want to go out. I just always worked,” the rapper says. “It’s your birthday what are you gonna do? Work. You ain’t gonna celebrate?”\n\nThe multimillionaire says he’s always saved the celebrating for the stage, where he can finally enjoy the fruits of his labor.\n\n“There’s nothing that’s ever gonna feel that glorious than when you’re actually at a festival. But how do you get to headline a festival? You’ve got to work. My friends would go out and party, hanging out with chicks, doing drugs, drinking. I was just in the studio working, writing songs.”\n\nTo this day, he says that he hasn’t gone out and celebrated a birthday—including his most recent one, which was just last week on March 15.\n\n“Like on Christmas for the past 12 years: I could celebrate Christmas with my family, and then on the 26th, I fly to China because that’s dream maker heaven. Anything you want to make is there.”\n\nWill.i.am was speaking to Fortune in Rome for the rollout of Raidio.FYI radios in Mercedes-Benz cars.\n\n7 a.m.: Will.i.am is not a part of the CEO-approved 5 a.m. club. Instead, he told Fortune he wakes up at around 7 a.m., and he sticks to this routine whether he’s living in L.A. or London.\n\n8 a.m.: “I walk, do my calls, and get to work,” he says, with the aim to start work at 9 a.m.\n\n9 a.m. to 5 p.m.: “I get a lot done from nine to 12, do my little lunch, then back to work at one, finish at five, and that’s all my tech, like entrepreneurial activities.”\n\n5 p.m. to 9 p.m.: “The night hours are creativity,” he says, adding that specifically between 7 p.m. and 9 p.m. is when he gets the best ideas. “That’s the juicy bits, [when] I’m freaking soaking in emotion, to where I just rinse it out in the phone.”\n\n9 p.m. onward: When Will.i.am was in his late twenties, he says going to sleep at 4 a.m. (and waking up at noon) was the norm. But now, at 50 and balancing both his tech and music ventures, he starts unwinding for bed after 9 p.m. and is asleep by 11 p.m.\n\nA version of this story originally published on Fortune.com on March 23, 2025.",
    "readingTime": 5,
    "keywords": [
      "doesn’t exist",
      "somebody else’s",
      "else’s dream",
      "work-life balance",
      "dream-reality balance",
      "it’s",
      "tech",
      "you’re",
      "fortune",
      "he’s"
    ],
    "qualityScore": 0.8,
    "link": "https://fortune.com/article/will-i-am-says-work-life-balance-for-people-working-on-someone-elses-dream/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/03/GettyImages-1487800046.jpg?resize=1200,600",
    "created_at": "2025-12-21T18:15:57.676Z",
    "topic": "business"
  },
  {
    "slug": "what-the-hyperproduction-of-ai-slop-is-doing-to-science",
    "title": "What the hyperproduction of AI slop is doing to science",
    "description": "A new study shows AI writing is turning traditional measures of research quality upside down.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 216,700 academics and researchers from 5,395 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/what-the-hyperproduction-of-ai-slop-is-doing-to-science-272250",
    "thumbnail_url": "https://images.theconversation.com/files/709831/original/file-20251219-66-vklc4z.jpg?ixlib=rb-4.1.0&rect=0%2C132%2C2400%2C1200&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2025-12-19T06:18:41.817Z",
    "topic": "tech"
  },
  {
    "slug": "roblox-python-tower-defense-game",
    "title": "Roblox Python tower defense game",
    "description": "save the core by writing python! Contribute to jackdoe/roblox-python-tower-defense development by creating an account on GitHub.",
    "fullText": "jackdoe\n\n /\n\n roblox-python-tower-defense\n\n Public\n\n save the core by writing python!\n\n www.roblox.com/games/92507403623309/Python-Tower-Defense\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jackdoe/roblox-python-tower-defense",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/jackdoe/roblox-python-tower-defense",
    "thumbnail_url": "https://opengraph.githubassets.com/56462222528f0cb1d0e3e1a9cb703322f45ee9df3d28bfefbf0c555adffe592a/jackdoe/roblox-python-tower-defense",
    "created_at": "2025-12-19T00:56:22.416Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-unveils-new-opensource-ai-models-amid-boom-in-chinese-offerings",
    "title": "Nvidia unveils new open-source AI models amid boom in Chinese offerings",
    "description": "Nvidia on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.  Nvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them.  Nvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks.",
    "fullText": "SAN FRANCISCO, Dec 15 (Reuters) - Nvidia (NVDA) on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.\n\nNvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them. But it also offers a slew of its own models for everything from physics simulations to self-driving vehicles as open-source software that can be used by researchers or by other companies, with firms such as Palantir Technologies weaving Nvidia's model into their products.\n\nNvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks. The smallest of the models, called Nemotron 3 Nano, was being released ‍Monday, with two other, larger versions coming in the first half of 2026.\n\nNvidia, which has become the world's most valuable listed company, said that Nemotron 3 Nano was more efficient than its predecessor - ​meaning it would be cheaper to run - and would do better at long tasks ‌with multiple steps.\n\nNvidia is releasing the models as open-source offerings from Chinese tech firms such as DeepSeek, Moonshot AI and Alibaba Group Holdings are becoming widely used in the tech industry, with companies such as Airbnb disclosing use of Alibaba' s. (BABA) Qwen open-source model.\n\nAt the same time, CNBC and Bloomberg have reported that Meta Platforms is considering shifting toward closed-source ⁠models, leaving Nvidia as one of the most prominent ​U.S. providers of open-source offerings.\n\nMany U.S. states and ​government entities have banned use of Chinese models over security concerns.\n\nKari Briski, vice president of generative AI software for enterprise at Nvidia, said the company aimed ‍to provide a \"model that ⁠people can depend on\", and was also openly releasing its training data and other tools so that government and business users could test it for security and ⁠customize it.\n\n\"This is why we're treating it like a library,\" Briski told Reuters in an interview. \"This is ‌why we're committed to it from a software engineering perspective.\"",
    "readingTime": 2,
    "keywords": [
      "open-source offerings",
      "closed-source models",
      "nemotron nano",
      "nvidia",
      "firms",
      "software",
      "reuters",
      "cheaper",
      "aimed",
      "tasks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-unveils-open-source-ai-140424565.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31397226d241d376e5cffbf13490e071",
    "created_at": "2025-12-16T13:51:41.754Z",
    "topic": "finance"
  },
  {
    "slug": "text-diffusion-models-are-faster-at-writing-code",
    "title": "Text Diffusion Models Are Faster at Writing Code",
    "description": "Speculative Decoding and Diffusion Language Models# In speculative decoding (for autoregressive models), we speed up generation by using a smaller model to generate multiple tokens, which are then verified in parallel by a larger model. The core idea is that most tokens are easily predictable; thus, we should be able to use a smaller and faster model for them. The classic example is the following sentence:\n“Geoffrey Hinton did his PhD at the University ___ ___”.",
    "fullText": "In speculative decoding (for autoregressive models), we speed up generation by using a smaller model to generate multiple tokens, which are then verified in parallel by a larger model.\nThe core idea is that most tokens are easily predictable; thus, we should be able to use a smaller and faster model for them.\nThe classic example is the following sentence:\n\n“Geoffrey Hinton did his PhD at the University ___ ___”.\n\nA small model can predict the next word “of” with high confidence, while the next token “Edinburgh” is much harder, requiring a larger model to verify.\n\nLanguage diffusion models sort-of have something analogous to speculative decoding built-in by default (and in some ways, a better version).\n\nFor diffusion language models with confidence-aware parallel decoding1, the model generates all tokens above a given confidence threshold at each step. Thus, “easy” tokens are generated in parallel.\nSome ways in which this is better than speculative decoding is that it is global (works across the entire context, not just for the next K tokens) and doesn’t require running two separate models.\nIn the following example:\n\nRepeat the word grape over and over again.\n\na diffusion language model could generate the prediction “grape” for the entire context length in one step, while in speculative decoding, even if the entire sequence is easily predictable, it can only predict K tokens at a time (typically around 4-8, from what I’ve read).\n\nThis benefit of increased parallel decoding partially depends on the structuredness of a text, which exists on a spectrum. An increase in confidence per output token directly leads to more tokens being decoded on average per step.1\n\nIncreased structure -> reduced entropy -> increased confidence -> higher parallel decoding\n\nThe grape example above is trivially structured, while normal text generation is unstructured and high entropy. Writing code (an actually useful domain) is somewhere in between.\n\nI had a large hunch that for structured tasks (like coding), the average number of tokens generated in parallel per step is higher than in normal text generation, and monotonically increases with the amount of structuredness present in the domain of the output.\n\nI recall reading that Google Gemini was much closer to state of the art for code generation than it was for reasoning tasks when it was first released. Perhaps this improvement for structured tasks is a general motif when it comes to these models?\n\nI threw together a small test and used the model from the paper Fast dLLM v2 (available on Huggingface) to generate roughly 256 tokens for 10 different prompts (each ran 10 times on A100s with an additional 2 generations for warmup):\n\nThe code for everything can be found here, which additionally includes generated output and metadata for each run. Below are the results:\n\nAs predicted, the grape example was dramatically faster than the unstructured text. What was surprising was how much faster (2.33 times speedup!) code generation was compared to unstructured text, even across multiple examples.\n\nMore testing should be done, but I imagine that there is a negative correlation between relative speedup and program complexity, and that boiler plate code (ex. self.input = input) would have a higher speedup compared to logic-heavy sections.\n\nAnother interesting result was that generating the start of the Declaration of Independence, a document which the model must have memorized, didn’t have much speedup. This tiny ablation study suggests that it really is the structuredness of the output, not memorization, which matters.\n\nThis was a small test thrown together in under an hour, and more rigorous evaluations should be done, but these preliminary results hint that this idea might be true to some degree.\n\nAn important limitation to address: In autoregressive decoding, we constrained decoding where we set all syntactically invalid tokens to have a probability of zero, ensuring that we are only generating text which follows some rules (JSON formatting, syntactically correct code, etc). For diffusion language models, this can’t naively be applied. However, similar to figuring out KVCache reuse with the advent of KVCache approximation, we might find a practical solution to this problem.2\n\nRead the section “Confidence-Aware Parallel Decoding” in the paper, Fast-dLLM. ↩︎ ↩︎\n\nThere are lots of papers of doing semi-autoregressive generation using diffusion language models. See AR-Diffusion, Fast-dLLM, Block Diffusion, etc. ↩︎",
    "readingTime": 4,
    "keywords": [
      "easily predictable",
      "structured tasks",
      "per step",
      "normal text",
      "confidence-aware parallel",
      "diffusion language",
      "unstructured text",
      "larger model",
      "speculative decoding",
      "language models"
    ],
    "qualityScore": 1,
    "link": "https://nathan.rs/posts/dllm-faster-code-generation/",
    "thumbnail_url": "https://nathan.rs/site.png",
    "created_at": "2025-12-13T18:48:06.593Z",
    "topic": "tech"
  },
  {
    "slug": "my-day-as-an-augmented-technical-writer-in-2030",
    "title": "My day as an augmented technical writer in 2030",
    "description": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).",
    "fullText": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).\n\nMy working day starts at 8:30am, after I’ve dropped my kids at school, rushed home, and prepared some coffee surrogate (nobody can afford real coffee anymore). I open the laptop and Chuck is there – it’s always there, like a trusty butler, ready to summarize what’s been going on in pull requests, Slack threads, Jira tickets, and a plethora of other information systems nobody can quite tame. Its summary connects the dots between my current priorities and what’s happening in the teams I’m attached to, helping me decide what to work on next. Trying to be helpful, it offers to deal with some of the mentions I’ve got by opening pull requests; I let it do so with a small docs bug. The rest I’ll want to deal with myself. It asks me how I feel and gently reminds me that I’ve still got some PTO available. Chuck’s such a class act.\n\nI’m in a team with several other technical writers, but for the most part I work with Chuck, which is what we call the in-house AI agent that we use. Chuck is a vast local language model capable of running on the M10 Silicon processor that powers my laptop. It’s a state-of-the-art multimodal LLM whose pedigree I can trace back to the last iterations of Claude Omni 7.5, before Anthropic went bankrupt and got acquired by Apple. As most corporate models, Chuck is ISO 42001, Turing, and EUAI certified, which means that it’s audited every year for security, governance, and legality of its training materials. Chuck is fine-tuned into several variants depending on the goal; the one I use is chuck-256b-writer. We run it in CI pipelines and locally in IDEs or CLI clients. We can also invite it to meetings as an artificial participant. I sometimes ask my own Chuck to attend calls on my behalf as Chuck-Fabri.\n\nThe thing I like the most about Chuck is that I can configure its specializations by turning modules on or off through the Silicon Brain app. When I want it to play the developer, I add several coding modules; when I want it to help me author docs, I turn on the style guide and grammarian modules, and so on. I can also ask Chuck to spawn copies of itself to roleplay users and readers based on support ticket and sales call interactions. When I do that, Chuck politely asks me to call it through other names, so as not to break character, something I duly comply with. Most system tools and APIs are already compatible with the agentic environment I use, so Chuck knows how to perform most operations on its own. An important detail: to summon Chuck, I need to first plug a physical key into the laptop. The key comes with a red button to immediately stop Chuck in case it starts operating bizarrely. Never had to use it.\n\nIt’s 11am already. I’ve been working with Chuck to write a new docs set for a new feature, telling it how I wanted the docs to fit into the existing architecture and instructing it to tweak and edit. It almost always gets 80% of the work done, though I often have to intervene to rearrange, cut, or otherwise rewrite sections. This hasn’t changed since the first days of GPT and it’ll never improve, because LLMs are not intelligent. They’re the most useful word automation tools at my disposal though, which I keep in check through deterministic tools and linters. Chuck is able to create diagrams, take screenshots of the product through an internal tool, and test the instructions and code snippets itself. When I feel unsure about its output, I ask it to verify what it’s just written through semantic internal search, or by calling its cloud cousin, Chad, which is able to provide answers from federated internal sources. All we do together, Chuck documents internally and remembers in its permanent context.\n\nEven though I’m using a local, non-monetized, and fully audited model that consumes the equivalent of a lightbulb worth of power, I still can’t shake the feeling of being a reverse centaur at times. It helps that Chuck comes with several built-in safeguards meant to prevent me from overworking or spending too much time without interacting with other human beings. At 1pm, which is lunch time in Spain, Chuck reminds me about taking a break. It refuses to continue if it detects stress in my text, vocal, or computer usage patterns. While my interactions with Chuck on the laptop are private and encrypted, it’s allowed to inform my manager or call my designated emergency contact in case of distress. I let Chuck access my vitals on the smartwatch and schedule calls with me on a regular basis to see how I’m doing. Since I work alone at home, this makes me feel somewhat safer.\n\nI didn’t tell you, but my current job title is Augmented Writer. My mission is to ensure that the words that humans and machines use to interact with our products are the most effective at reducing confusion and error, while they maximize effectiveness and user satisfaction. I’m augmented because I do this in concert with Chuck, which expands my existing skills in numerous ways. Without my brain, though, Chuck couldn’t do my job, because it doesn’t really care and, more importantly, because it’s not allowed to. One of the conditions imposed by the current legislation is that AI cannot operate in fully autonomous mode without human supervision. Our docs and UIs, in fact, bear a certificate of human authorship that discloses the amount of AI intervention. By law, all AI generated artifacts must produce fingerprinting patterns that can’t be tampered with, which is trickier with text, but since we must keep full audit logs of LLM usage, this can be established upon request by any competent authority, including the Turing police.\n\nIn the end, my role is more of an orchestrator than that of an author, and I’m fine with that. Software engineering, the field I serve, is an exercise in consensual imagination whose goal is to find repeatable ways of processing reality into manageable chunks of data. Reality is unmistakably raw and imperfect, a stream of floating points and broken strings running through distributed systems: one cannot tame it through clever algorithms, but it can be reduced to abstractions and data structures and binary blobs. Each of those entities has a name; they all relate to each other through words. It’s part of my job to understand those words and intervene when they don’t bring clarity. It’s then also my job to explain how those words are able to handle their parent reality. The docs I orchestrate with Chuck’s help are the artifacts that chronicle and explain the motions of data as it enters a machine and exits in shapes and configurations that are helpful to users.\n\nIt’s 5pm and I’m bidding Chuck farewell. During the night, it will work on some optional docs polish and politely present its work to me in the morning. As I log off and extract the hardware key from the laptop, I think that without the words Chuck and I produced, the machine would be opaque to its operators, a smooth wall without doors or handles. Product truth is at my disposal to weave into a fabric of meaning and possibility, into spells that unlock abilities in autonomous agents, be they organic or artificial. I am an enabler of thought and action. Getting here wasn’t easy, but I feel better knowing that I can continue defending the importance of words with the help of the most clever thesaurus ever created.",
    "readingTime": 7,
    "keywords": [
      "it’s",
      "docs",
      "chuck",
      "i’ve",
      "laptop",
      "without",
      "usage",
      "modules",
      "tools",
      "internal"
    ],
    "qualityScore": 1,
    "link": "https://passo.uno/my-day-tech-writer-2030/",
    "thumbnail_url": "/thumb.png",
    "created_at": "2025-12-13T18:48:05.736Z",
    "topic": "tech"
  },
  {
    "slug": "writing-a-typesafe-linux-perf-interface-in-zig",
    "title": "Writing a Type-Safe Linux Perf Interface in Zig",
    "description": "I'm building a benchmarking tool for Zig and needed CPU counters. This is how I wrapped Linux's `perf_event_open` to be type-safe with comptime.",
    "fullText": "I am currently building a hobby project:\npyk/bench, a microbenchmarking library for Zig.\nMy goal is to make it fast and accurate. To measure performance properly,\nlooking at wall clock time is not enough. I need to know what the CPU is\nactually doing.\n\nI want to measure CPU cycles, instruction counts and cache misses. On Linux the\nkernel provides a system call for this named\nperf_event_open.\nIt is very powerful but the API is raw and not easy to use safely.\n\nThe perf_event_open system call creates a file descriptor that allows\nmeasuring performance information. You fill out a perf_event_attr struct with\nthe config you want, such as PERF_COUNT_HW_CPU_CYCLES or\nPERF_COUNT_HW_INSTRUCTIONS, and the kernel gives you back a file descriptor.\n\nYou can read from this file descriptor to get the counts. The format of the data\nyou read depends on how you opened it.\n\nYou can also group events. This is important because it lets you measure\nmultiple things at once with a single read call. One event acts as the “group\nleader” and others are “siblings”. When you read from the leader, you get a\nbinary layout containing values for all events in the group.\n\nThe layout looks roughly like this in C:\n\nThis is dynamic. The size of the struct changes based on how many events you\nhave. In Zig I want something static and type-safe.\n\nMy first attempt was brittle. I hardcoded a struct with the fields I thought I\nwould need.\n\nThis works but it is dangerous. The Measurements struct is hardcoded.\n\nIf I change the initialization logic to add “branch misses”, I have to remember\nto update Measurements, update the ids array size and update the read\nfunction manually. The compiler cannot help me here.\n\nIf I access ids[2] but only initialized 2 events, I crash or get garbage data.\n\nZig allows running code at compile time to generate types. I can use this to\ngenerate a struct that exactly matches the events I request.\n\nI defined an Event enum for the things I want to measure.\n\nThen I wrote a function that takes a slice of these events and returns a new\ntype.\n\nThis function creates a struct with fields named after the enum tags. If I pass\n&.{ .cpu_cycles, .instructions }, it generates:\n\nNow I can create a generic Group type that uses this.\n\nThe usage is cleaner and safer.\n\nIf I try to access a field I did not request, the compiler stops me.\n\nHere is how the full version looks like:\n\nTo implement this I needed to get the ID of the event from the file descriptor.\nThe kernel documentation says to use ioctl with PERF_EVENT_IOC_ID.\n\nI checked std.os.linux in the Zig standard library and it was missing.\n\nSo I opened a pull request to add it. It is just a one line change.\n\nYou can see the PR here:\nhttps://codeberg.org/ziglang/zig/pulls/30162.\nI am not sure if it will be accepted but it felt good to fix a missing piece in\nthe tool I use.",
    "readingTime": 3,
    "keywords": [
      "file descriptor",
      "struct",
      "events",
      "kernel",
      "event",
      "function",
      "request",
      "library",
      "performance",
      "counts"
    ],
    "qualityScore": 1,
    "link": "https://pyk.sh/blog/2025-12-11-type-safe-linux-perf-event-open-in-zig",
    "thumbnail_url": "https://pyk.sh/opengraphs/blog.png",
    "created_at": "2025-12-13T06:54:07.096Z",
    "topic": "tech"
  },
  {
    "slug": "before-megalodon-researchers-say-a-monstrous-shark-ruled-ancient-australian-seas",
    "title": "Before megalodon, researchers say a monstrous shark ruled ancient Australian seas",
    "description": "In the age of dinosaurs — before whales, great whites or the bus-sized megalodon — a monstrous shark prowled the waters off what's now northern Australia, among the sea monsters of the Cretaceous period.  Researchers studying huge vertebrae discovered on a beach near the city of Darwin say the creature is now the earliest known mega-predator of the modern shark lineage, living 15 million years earlier than enormous sharks found before.  The ancestor of today’s 6-meter (20-foot) great white shark was thought to be about 8 meters (26 feet) long, the authors of a paper published in the journal Communications Biology said.",
    "fullText": "WELLINGTON, New Zealand (AP) — In the age of dinosaurs — before whales, great whites or the bus-sized megalodon — a monstrous shark prowled the waters off what's now northern Australia, among the sea monsters of the Cretaceous period.\n\nResearchers studying huge vertebrae discovered on a beach near the city of Darwin say the creature is now the earliest known mega-predator of the modern shark lineage, living 15 million years earlier than enormous sharks found before.\n\nAnd it was huge. The ancestor of today’s 6-meter (20-foot) great white shark was thought to be about 8 meters (26 feet) long, the authors of a paper published in the journal Communications Biology said.\n\n“Cardabiodontids were ancient, mega-predatory sharks that are very, very common from the later part of the Cretaceous, after 100 million years ago,” said Benjamin Kear, the senior curator in paleobiology at the Swedish Museum of Natural History and one of the study’s authors. “But this has pushed the time envelope back of when we’re going to find absolutely enormous cardabiodontids.”\n\nRediscovered fossils pointed to a huge shark\n\nSharks have a 400-million-year history but lamniforms, the ancestors of today’s great white sharks, appear in the fossil record from 135 million years ago. At that time they were small — probably only a meter in length — which made the discovery that lamniforms had already become gigantic by 115 million years ago an unexpected one for researchers.\n\nThe vertebrae were found on coastline near Darwin in Australia’s far north, once mud from the floor of an ancient ocean that stretched from Gondwana — now Australia — to Laurasia, which is now Europe. It’s a region rich in fossil evidence of prehistoric marine life, with long-necked plesiosaurs and ichthyosaurs among the creatures discovered so far.\n\nThe five vertebrae that launched the quest to estimate the size of their mega-shark owners were not a recent discovery, but an older one that had been somewhat overlooked, Kear said. Unearthed in the late 1980s and 1990s, the fossils measured 12 centimeters (4.7 inches) across and had been stored in a museum for years.\n\nWhen studying ancient sharks, vertebrae are prizes for paleontologists. Shark skeletons are made of cartilage, not bone, and their fossil record is mostly made up of teeth, which sharks shed throughout their lives.\n\n“The importance of vertebrae is they give us hints about size,” Kear said. “If you’re trying to scale it from teeth, it’s difficult. Are the teeth big and the bodies small? Are they big teeth with big bodies?”\n\nAncient shark size still holds mystery\n\nScientists have used mathematical formulas to estimate the size of extinct sharks like megalodon, a massive predator that came later and may have reached 17 meters (56 feet) in length, Kear said. But the rarity of vertebrae mean questions of ancient shark size are difficult to answer, he added.\n\nThe international research team spent years testing different ways to estimate the size of the Darwin cardabiodontids, using fisheries data, CT scans and mathematical models, Kear said. Eventually, they arrived at a likely portrait of the predator’s size and shape.\n\n“It would’ve looked for all the world like a modern, gigantic shark, because this is the beauty of it,” Kear said. “This is a body model that has worked for 115 million years, like an evolutionary success story.”\n\nA predator’s past could hint at the future\n\nThe study of the Darwin sharks suggested that modern sharks rose early in their adaptive evolution to the top of prehistoric food chains, the researchers said. Now, scientists could scour similar environments worldwide for others, Kear said.\n\n“They must have been around before,” he said. “This thing had ancestors.”\n\nStudying ancient ecosystems like this one could help researchers understand how today’s species might respond to environmental change, Kear added.\n\n“This is where our modern world begins,” he said. “By looking at what happened during past shifts in climate and biodiversity, we can get a better sense of what might come next.”",
    "readingTime": 4,
    "keywords": [
      "meters feet",
      "fossil record",
      "studying ancient",
      "ancient shark",
      "shark size",
      "sharks",
      "vertebrae",
      "researchers",
      "darwin",
      "modern"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/megalodon-researchers-monstrous-shark-ruled-022242238.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/h0A6fi4PoOLfoaNL0Afu9w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/a01c66b68881dea3689bd5a0cf3aa14f",
    "created_at": "2025-12-13T03:40:56.459Z",
    "topic": "science"
  },
  {
    "slug": "heres-why-a-call-of-duty-movie-is-finally-happening-after-10-years-of-trying",
    "title": "Here's Why A Call Of Duty Movie Is Finally Happening After 10+ Years Of Trying",
    "description": "A movie based on Activision's Call of Duty series is in the works now at Paramount, which is now led by billionaire and Call of Duty superfan David Ellison. Prolific writer and director Taylor Sheridan is writing the script for the film, with Lone Survivor director Peter Berg attached to direct.\nActivision had been trying to make Call of Duty movies for years, so why is it finally happening now? Xbox boss Matt Booty told Variety that \"a relationship came about\" between people at Paramount and senior executives working on Call of Duty. \"They felt like they found a partner who understands the game, people who play the game, and shared a vision of what it could be to bring that forward,\" Booty said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/heres-why-a-call-of-duty-movie-is-finally-happening-after-10-years-of-trying/1100-6536930/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4621736-screenshot2025-12-12at8.45.08%E2%80%AFam.png",
    "created_at": "2025-12-12T18:55:57.681Z",
    "topic": "entertainment"
  },
  {
    "slug": "judge-orders-kilmar-abrego-garcia-to-be-immediately-released-from-immigration-detention",
    "title": "Judge orders Kilmar Abrego Garcia to be immediately released from immigration detention",
    "description": "Kilmar Abrego Garcia must be freed from immigration detention while he fights his deportation, a judge ruled Thursday, handing a major victory to the immigrant whose wrongful deportation to a notorious prison in El Salvador made him a flashpoint of the Trump administration’s immigration crackdown.  U.S. District Judge Paula Xinis in Maryland ordered Immigration and Customs Enforcement to let Abrego Garcia go immediately, writing that federal authorities had detained him again after his return to the United States without any legal basis.",
    "fullText": "Kilmar Abrego Garcia must be freed from immigration detention while he fights his deportation, a judge ruled Thursday, handing a major victory to the immigrant whose wrongful deportation to a notorious prison in El Salvador made him a flashpoint of the Trump administration’s immigration crackdown.\n\nU.S. District Judge Paula Xinis in Maryland ordered Immigration and Customs Enforcement to let Abrego Garcia go immediately, writing that federal authorities had detained him again after his return to the United States without any legal basis.\n\n“For this reason, the Court will GRANT Abrego Garcia’s Petition for immediate release from ICE custody,” the judge wrote.\n\nThe Department of Homeland Security sharply criticized the decision and vowed to appeal, calling the ruling “naked judicial activism” by a judge appointed during the Obama administration.\n\n“This order lacks any valid legal basis, and we will continue to fight this tooth and nail in the courts,” said Tricia McLaughlin, the department’s assistant secretary. The judge gave prosecutors until 5 p.m. EST to formally respond to the release order.\n\nThe Justice Department declined to comment, and messages seeking comment from Abrego Garcia’s attorney were not immediately returned.\n\nAbrego Garcia, a Salvadoran national with an American wife and child, has lived in Maryland for years but entered the U.S. illegally as a teenager. An immigration judge ruled in 2019 that he could not be deported to El Salvador because he faced danger from a gang that targeted his family. When he was mistakenly sent there in March, his case became a rallying point for those who oppose President Donald Trump’s immigration enforcement actions.\n\nA court later ordered his return to the United States. Since he cannot be removed to El Salvador, ICE has been seeking to deport him to a series of African countries. His federal suit claims the Trump administration is illegally using the removal process to punish Abrego Garcia for the public embarrassment caused by his deportation.\n\nIn her order releasing Abrego Garcia, Xinis wrote that federal authorities “did not just stonewall” the court, “They affirmatively misled the tribunal.” The judge was referencing the successive list of four African countries that officials had sought to remove Abrego Garcia seemingly without commitments from those countries, as well as officials' affirmations that Costa Rica withdrew its offer to accept him, a claim later proven untrue.\n\n“But Costa Rica had never wavered in its commitment to receive Abrego Garcia, just as Abrego Garcia never wavered in his commitment to resettle there,” the judge wrote.\n\nXinis also rejected the government’s argument that she lacked jurisdiction to intervene on a final removal order for Abrego Garcia, because she found no final order had been filed.\n\nSeparately, Abrego Garcia is asking an immigration court to reopen his case so he can seek asylum in the United States.\n\nHe is also criminally charged in Tennessee, where he has pleaded not guilty to human smuggling. He has asked the federal court to dismiss the case, arguing the prosecution is vindictive. His defense attorney in Tennessee, Sean Hecker, declined to comment.\n\nA judge in that case has ordered an evidentiary hearing after previously finding some evidence that the charges “may be vindictive.” The judge also noted several statements by Trump administration officials that “raise cause for concern,” including a statement by Deputy Attorney General Todd Blanche that seemed to suggest the Justice Department charged Abrego Garcia because he won his wrongful deportation case. ___\n\nLoller reported from Nashville, Seewer reported from Toledo, Ohio and Lauer reported from Philadelphia. Associated Press reporter Alanna Durkin Richer in Washington contributed to this report.",
    "readingTime": 3,
    "keywords": [
      "trump administration",
      "abrego garcia",
      "legal basis",
      "wrongful deportation",
      "federal authorities",
      "judge ruled",
      "el salvador",
      "court",
      "ordered",
      "attorney"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/judge-orders-kilmar-abrego-garcia-154255309.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/a0M6hY0ASmu1RqN_RGIGnw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/402cd28fa90f1643a286fc771ae63b50",
    "created_at": "2025-12-11T18:58:22.683Z",
    "topic": "news"
  },
  {
    "slug": "clair-obscur-expedition-33-how-a-tiny-studio-developed-the-belle-poqueset-gaming-blockbuster",
    "title": "Clair Obscur: Expedition 33 – how a tiny studio developed the Belle Époque-set gaming blockbuster",
    "description": "What started as Guillaume Broche’s personal project has been nominated for 12 Game awards, sold more than 2m copies and been praised by Emmanuel Macron as a ‘shining example of French audacity’\nThe record-breaking 12 nominations at the Game awards this year was beyond the wildest dreams of Guillaume Broche when he first began inking out Clair Obscur: Expedition 33 as a personal project while working at Ubisoft.\nBefore selling more than 2m copies, the narrative-driven roleplaying game with “a unique world, challenging combat and great writing” was a technical demo called We Lost. It was Broche’s appetite for risk and a few hopeful Reddit posts that would create the game’s world of Lumiere and its struggle against the Paintress.\n Continue reading...",
    "fullText": "What started as Guillaume Broche’s personal project has been nominated for 12 Game awards, sold more than 2m copies and been praised by Emmanuel Macron as a ‘shining example of French audacity’\n\nThe record-breaking 12 nominations at the Game awards this year was beyond the wildest dreams of Guillaume Broche when he first began inking out Clair Obscur: Expedition 33 as a personal project while working at Ubisoft.\n\nBefore selling more than 2m copies, the narrative-driven roleplaying game with “a unique world, challenging combat and great writing” was a technical demo called We Lost. It was Broche’s appetite for risk and a few hopeful Reddit posts that would create the game’s world of Lumiere and its struggle against the Paintress.\n\n“I was doing like eight hours per day after work and not sleeping at all for a few years,” Broche says. And while he would be joined by Tom Guillermin on the programming side and Francoise Meurisse as producer, the next few members of the nascent studio – Lorien Testard, lead composer and Jennifer Svedberg-Yen, lead writer – would only come to Clair Obscur by chance, via social media.\n\nTestard, a guitar teacher at the time who had never composed or published any music commerically, was discovered by Broche on SoundCloud. “We liked the same philosophy in games,” says Testard, who had been writing music inspired by his favourite titles. Similarly, Broche found his art director, Nicholas Maxson-Francombe, through personal works he posted on ArtStation. “We are all deeply engaged in our subject areas,” says Svedberg-Yen, who says that was what bonded the team together. “If you listen to Nicolas talk about art or Lorien talk about music, it’s just something that fills our minds and our days.”\n\nSvedberg-Yen, meanwhile, had come from the world of finance. She saw Broche’s Reddit post and auditioned to not only write but also to voice some of the prototype characters of Clair Obscur, namely Maelle and Lune. Despite a deep love for video games, storytelling and a childhood engrossed in novels, Svedberg-Yen had not considered it as a career option. “It never crossed my mind as possible. As the adage goes, for Asian parents [it’s] doctors, lawyers, or finance.”\n\nWith a rudimentary team assembled under the banner of a new studio, Sandfall Interactive, they rebooted We Lost as Clair Obscur. It was there a world took shape and the gained its unmistakeable Belle Époque setting. “There’s a specificity,” Svedberg-Yens says. “I think that vision gets diluted when you’re trying to appeal to too many people.”\n\n“It’s not meant to be French propaganda,” jokes Broche, about the game’s very Gallic aesthetic. The characters yell putain and merde, there are berets and extremely scary mimes not only because it’s fun, he says, but born from a desire to make something “sincere and authentic”.\n\nSame goes for the story. Clair Obscur’s narrative drives the game forward and, as lead writer, Svedberg-Yen says it all has a “grounding and a basis in truth”.\n\n“We are all first-time writer and game developers in this sense … and so we kind of only know instinctively how write to what instinctively comes from within. And for a lot of the characters in those particular situations, to write them [you] have to really delve into the parts of my life that resonate with the situation that they’re in.”\n\nAccording to Svedberg-Yen, a conversation Broche had with his mother became core to the story’s emotional heft. When he asked her what would be the worst thing that could possibly happen, his mother responded saying it would be to lose her children. “The story deals with a lot of trauma,” she says, and that process of writing like that was often a scary process. “If people don’t like it, they don’t like you.” It was this ability to be vulnerable and open a communicative environment that Broche believes contributed to the success of the game.\n\nDespite an anxiety in the industry about the rise of AI in the development of video games, the team at Sandfall isn’t worried – especially Testard, who composed the game’s orchestral score based off the narrative beats of the game and the eponymous concept of clair obscur (or chiaroscuro), AKA the interplay of light and dark. “Music is the language of the soul,” he says. In fact, the evolution of technology like Unreal Engine 4 and the later 5, which the game runs on today, made a lot of the game possible. “More games will be 3D, because we have a lot of tools now,” says Broche, who describes the budget of his game to be on the “lower end of AA.”\n\nThe team at Sandfall have been overwhelmed by their success. The French president, Emmanuel Macron, lauded the game as “shining example of French audacity”. None of them expected the experience of Clair Obscur to resonate so deeply with so many people. “I’ve gotten a lot of very heartfelt messages from players who have experienced loss in some way and who have felt that the story helped them deal with their grief or change their relationship with grief,” Svedberg-Yen says.\n\n“What’s really cool is I’ve gotten tons of messages from creatives, writers, aspiring writers who felt creatively drained or just felt like they wanted to quit, but then the game inspired them to start again and they started creating their own art again, to start writing.”",
    "readingTime": 5,
    "keywords": [
      "i’ve gotten",
      "french audacity",
      "personal project",
      "game awards",
      "clair obscur",
      "emmanuel macron",
      "music",
      "games",
      "team",
      "it’s"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/11/clair-obscur-expedition-33-video-game-tiny-studio-developed-blockbuster",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de7272ae99a245b1ca069ffc4a50c11a28465092/478_134_2532_2026/master/2532.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2a7548a6ff68110738e5a01d103698a7",
    "created_at": "2025-12-11T13:53:39.909Z",
    "topic": "gaming"
  },
  {
    "slug": "st-ergnats-dream-of-writing-next-great-moneyglass-tale",
    "title": "St Ergnat's dream of writing next great Moneyglass tale",
    "description": "St Ergnat's Moneyglass hope to become the County Antrim village's next sporting heroes in this weekend's All-Ireland Ladies Club final.",
    "fullText": "The folks in Moneyglass are no strangers to cheering on one of their own on a big stage.\n\nWillie John McBride, who went on to star for the British and Irish Lions, was born in the small County Antrim village. So, too, was Grand National winner AP McCoy.\n\nNow, St Ergnat's are hoping to follow in their footsteps.\n\nIt has already been a memorable year for the club. After securing a fifth straight Antrim title, they conquered Ulster for the first time in November, beating Errigal Ciaran in the final.\n\nRuling the province was a realistic aim for Moneyglass this year, but few outside the squad - who are led by former Donegal ladies boss Maxi Curran - would have expected them to reach the All-Ireland final.\n\nBut they have gleefully defied expectations. Beating Dublin's Kilmacud Crokes in the semi-final a fortnight ago means they will become first Antrim side to grace the biggest stage in ladies club football at Croke Park on Saturday (16:00 GMT).\n\n\"Coming into this year, we just wanted to go a bit further than last year,\" says Aoife Kelly.\n\n\"Getting beaten in the semi-finals two years in a row, off the back of getting to the 2022 Ulster final, so the goal was to get back to the Ulster final, we got there, won it and we've been taking it game by game.\n\n\"It was no coincidence we won Ulster, we have been building to it for the last few years.\"",
    "readingTime": 2,
    "keywords": [
      "ulster final",
      "moneyglass",
      "stage",
      "club",
      "ladies",
      "back",
      "game",
      "antrim",
      "beating"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/articles/cn7kex85k0no?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/0ffd/live/0791e620-d5e3-11f0-b1c1-a1fc4155147e.png",
    "created_at": "2025-12-11T13:53:34.013Z",
    "topic": "sports"
  },
  {
    "slug": "tracking-penn-states-pinstripe-bowl-opt-outs-durant-wheatley-thus-far",
    "title": "Tracking Penn State’s Pinstripe Bowl Opt Outs: Durant, Wheatley Thus Far",
    "description": "Folks, instead of doing an individual post for each player that opts out of the Pinstripe Bowl, we’ll be updating this post instead. As of this writing on Wednesday, December 10th at 10 p.m. EST, just two Nittany Lions have opted out. DB Zakee Wheatley (NFL Draft) Wheatley joins Durant as the second player on […]",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://sports.yahoo.com/articles/tracking-penn-state-pinstripe-bowl-030905061.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/alH0BuwQ4TUlzzmie.A.tg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/sb_nation_articles_115/c41ed04580f3ed4c736372f98142f288",
    "created_at": "2025-12-11T03:51:05.191Z",
    "topic": "sports"
  }
]
[
  {
    "slug": "billionaire-marc-benioff-challenges-the-ai-sector-whats-more-important-to-us-growth-or-our-kids",
    "title": "Billionaire Marc Benioff challenges the AI sector: ‚ÄòWhat‚Äôs more important to us, growth or our kids?‚Äô",
    "description": "The Salesforce founder, long a critic of Section 230, doubled down in Davos. He wants the original sin of the internet to be scrubbed away.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/20/billionaire-marc-benioff-section-230-ai-whats-more-important-growth-or-kids/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2256697072-e1768949931240.jpg?resize=1200,600",
    "created_at": "2026-01-21T00:59:29.180Z",
    "topic": "business"
  },
  {
    "slug": "the-gloves-are-off-in-the-feud-between-sam-altman-and-elon-musk",
    "title": "The gloves are off in the feud between Sam Altman and Elon Musk",
    "description": "The tech titans escalated their long-running feud on Tuesday, trading barbs in public posts about the safety of ChatGPT, Grok, and Tesla's Autopilot.",
    "fullText": "Sam Altman and Elon Musk are at it again, with each of the tech titans taking aim at the other in a series of heated posts on X.\n\nMusk appeared to start the latest escalation early on Tuesday morning, when he posted \"Don't let your loved ones use ChatGPT\" in response to a post that said that use of OpenAI's chatbot had been linked to the deaths of nine children and adults since it was released in 2022.\n\nAltman fired back, first in defense of ChatGPT and OpenAI's desire to protect its users, and then blasting Tesla's Autopilot technology, calling it unsafe.\n\n\"It is genuinely hard; we need to protect vulnerable users, while also making sure our guardrails still allow all of our users to benefit from our tools,\" Altman said.\n\nAltman continued, calling out Autopilot.\n\n\"I only ever rode in a car using it once, some time ago, but my first thought was that it was far from a safe thing for Tesla to have released,\" he wrote. \"I won't even start on some of the Grok decisions.\"\n\nAltman added: \"You take 'every accusation is a confession' so far.\"\n\nThere have been at least eight wrongful-death lawsuits filed against OpenAI that allege use of ChatGPT has contributed to worsening mental health conditions, leading to instances of suicide and murder, including among children and young adults.\n\nSafety concerns around Tesla's self-driving technology have also been central to multiple wrongful-death lawsuits, including one surrounding a 2019 crash in Florida that left a 22-year-old woman dead. A jury determined Tesla was 33% liable for the crash and awarded the plaintiffs $329 million in total damages, Business Insider previously reported.\n\nRepresentatives for Musk and Altman did not immediately respond to requests for comment from Business Insider.\n\nThe social media feud comes as the pair is stuck in the middle of a long-running legal battle over OpenAI's status as a nonprofit company. Musk sued Altman, and other leaders of OpenAI, alleging that they misled him when they decided to pursue a for-profit structure, moving the company away from its original nonprofit mission.\n\nMusk said he donated $38 million to OpenAI when it was originally founded as a nonprofit.",
    "readingTime": 2,
    "keywords": [
      "wrongful-death lawsuits",
      "users",
      "nonprofit",
      "altman",
      "children",
      "adults",
      "released",
      "protect",
      "technology",
      "crash"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-elon-musk-feud-escalates-autopilot-deaths-chatgpt-safety-2026-1",
    "thumbnail_url": "https://i.insider.com/69700640d3c7faef0ecc9b0a?width=1200&format=jpeg",
    "created_at": "2026-01-21T00:59:28.375Z",
    "topic": "finance"
  },
  {
    "slug": "chatgpt-is-getting-on-the-ai-age-verification-bandwagon",
    "title": "ChatGPT Is Getting on the AI Age Verification Bandwagon",
    "description": "The app will guess your age and set limits for users it thinks are under 18.",
    "fullText": "When OpenAI first announced GPT-5.2 last month, it quietly disclosed a new safety feature it called \"age prediction.\" Considering ChatGPT proper isn't exactly an \"all ages\" kind of tool, it makes sense that users under the age of 18 should have protections in place to shield them from harmful content. The company says that users who indicate they're under 18 already receive an altered experience to \"reduce exposure to sensitive or potentially harmful content,\" but if the user doesn't voluntarily share how old they are with OpenAI, how does the company enforce these protections? Here's where age prediction comes in.\n\nOn Tuesday, OpenAI officially announced its new age prediction policy, which, like other age verification systems being used by the likes of Roblox, uses AI to guess how old a user is. If the system decides that a particular user is under the age of 18, OpenAI will adjust the experience accordingly, with the goal of keeping all interactions age-appropriate.\n\nHere's how it works: The new age prediction model looks at both the user's behaviors within the app, as well as the general account data. That includes things like how old the account is, what times of day the user is accessing ChatGPT, usage patterns, as well as, of course, the age the user says they are. Looking at all this data, the model determines how old the user likely is. If the model thinks they're over 18, they'll get the full experience; if the model thinks they're under 18, they'll get the \"safer experience.\" If the model isn't confident, it defaults to that safer experience.\n\nThat limited experience means that someone the model thinks is under 18 will try to reduce the following content types:\n\nViral challenges that might inspire \"risky or harmful behaviors\"\n\nRole play that is sexual, romantic, or violent in nature\n\nContent promoting \"extreme\" beauty standards, unhealthy dieting, or body shaming\n\nThe company says that its approach is informed by \"expert input\" as well as literature discussing child development science. (It's not clear whether how much of that input is from direct interviews and coordination with experts, and how much, if any, is from independent research.) The company also acknowledges \"known teen differences in risk perception, impulse control, peer influence, and emotional regulation\" when compared to adults.\n\nThe biggest risk with any of these age prediction models is that they'll sometimes get it wrong‚Äîhallucination is an unfortunate habit AI models all share. That goes both ways: You don't want someone too young accessing inappropriate content in ChatGPT, but you also don't want someone older than 18 getting stuck with a limited account for no reason. If you experience the latter situation, OpenAI has a solution for you: direct age verification through Persona. This is the same third-party Roblox uses for its age verification, which hasn't gone very well thus far.\n\nThat doesn't necessarily spell doom for OpenAI. Roblox tried overhauling their age verification system for a massive user base all used to a certain type of multiplayer experience, which led to users not being able to chat with other users in newly-assigned age categories, which were often incorrect. Meanwhile, ChatGPT's age prediction is only controlling the experience of one user at a time. To that end, OpenAI will let you upload a selfie as an added verification step if the prediction model alone isn't enough. Interestingly, OpenAI doesn't say anything about the option to upload an ID for verification, which other companies, like Google, have provided.\n\nI'm not necessarily a fan of age prediction models, as I think they often sacrifice user privacy in the name of creating age-appropriate experiences. But there's little doubt that OpenAI has to do something to limit the full ChatGPT experience for younger users. Many of ChatGPT's users are under 18, and much of the content they experience is wildly inappropriate, whether it be instructions on getting high, or advice on writing suicide notes. In some tragic cases, minors have taken their own lives after discussions with ChatGPT, leading to lawsuits against OpenAI.\n\nI don't have any great answers here. We'll just have to see how this new age prediction model affects the user experience for minors and adults alike, and whether it actually manages to create a safer experience for younger, more impressionable users.",
    "readingTime": 4,
    "keywords": [
      "harmful content",
      "safer experience",
      "prediction models",
      "age prediction",
      "age verification",
      "prediction model",
      "user",
      "users",
      "openai",
      "isn't"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/openai-chatgpt-age-prediction-model?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFEH2Q4KPPTQXMTQW5G99Y1B/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-21T00:59:27.310Z",
    "topic": "tech"
  },
  {
    "slug": "sandbox-your-ai-dev-tools-a-practical-guide-for-vms-and-lima",
    "title": "Sandbox Your AI Dev Tools: A Practical Guide for VMs and Lima",
    "description": "AI coding assistants and other devtools can steal your credentials and data. Here's how to run them safely in isolated VMs using Lima on macOS/Linux.",
    "fullText": "AI coding assistants, npm, pip, and other development tools can run arbitrary code and scripts on your machine, potentially stealing SSH keys, API tokens, wallet keys, sensitive credentials and other private data without you noticing.\n\nThis guide shows you how to sandbox these tools in isolated VMs using Lima, so you can experiment and develop freely without putting your sensitive data at risk.\nJump straight to the guide, or read on for a bit of personal context.\n\nI‚Äôve been having quite a bit of fun with AI assisted coding recently.\n\nI use LLMs for a wide range of things, including discussing architecture, design choices, learning about new tools and libraries I wasn‚Äôt previously aware of, to reviewing PRs and quickly cranking out dirty prototypes.\n\nEspecially for hobby projects that are not meant to ever go into production, I enjoy playing with AI tools fast and loose, producing results quickly and not getting slowed down by annoying things such as reading code before running it ü§£.\n\nAnd yeah‚Ä¶ that‚Äôs obviously unsafe, unless it‚Äôs all contained in a sandbox!\n\nYou should never run potentially dangerous, experimental code on your main machine, since it could steal your passwords, API keys, environment variables, private keys, access to your communication tools, install services, and do all sorts of other nefarious things.\n\nNowadays I isolate all my devtools in VMs, and thought it might be useful to others if I put together a guide to shows how to do it. Well, here it is, and I hope it‚Äôll be useful to you, too!\n\nYou‚Äôll want to run the entire development environment, including the AI tool itself, inside a sandbox. This way it‚Äôs safe to install dependencies and to execute code, and unlocks other fun features like snapshots before running sketchy code, and reverting if something goes wrong.\n\nAnd it‚Äôs not just AI-generated code. Node.js/npm/yarn and Python/pip are particularly troublesome because they allow any package to run arbitrary scripts on your system during installation, and install tons of additional dependencies that can do the same. This attack vector is called ‚Äúsupply chain attack‚Äù and it happens all the time.\n\nVirtual Machines (VMs) and Containers (i.e. Docker, Podman, containerd) are the two most practical methods for isolating development tools from your host operating system. VMs provide much stronger protection and more flexibility overall, and are better suited for co-developing with AIs.\n\nContainer runtimes share the host operating system‚Äôs kernel, which means they‚Äôre fundamentally running on the same system as your main machine, just with isolated namespaces and resource limits. This creates several security concerns:\n\nIn contrast, a VM runs its own complete operating system with its own kernel. The hypervisor (like QEMU/KVM) creates a much stronger isolation boundary. Even if malicious code completely compromises the VM, it would need to exploit the hypervisor itself to reach your host, a significantly harder target.\n\nFurthermore, a VM enables better concurrency. It can run Docker containers, databases, web servers, multiple build processes, and background services all at once, and the AI tool can interact with everything naturally just like on a normal development machine.\n\nIn this guide, we use Lima VM to sandbox AI and devtools. Lima is a delightful, lightweight virtual machine manager for Linux and macOS which provides easy and quick ways to create and manage VMs.\n\nYou interact with Lima through the limactl command:\n\nVMs are based on templates, which can include (build on) other templates:\n\nThe Lima VM docs have platform-specific installation guides.\n\nHomebrew is recommended on macOS:\n\nOn Linux install the binary like this:\n\nNow ensure your Lima version is up-to-date:\n\nWe only want to share very specific host directories with the VM.\n\nLet‚Äôs create ~/VM-Shared on the host, which we later mount into the VM at ~/Shared (with write access):\n\nYou can use that directory to easily copy files between the host and the VM, and to share project directories from the host with the VM.\n\nDefaults for all VMs can be defined in ~/.lima/_config/default.yaml.\n\nLet‚Äôs create the default YAML file:\n\nLima conveniently creates default SSH configuration files for all VM instances, which makes it easy to log in with SSH (including using VS Code for a Remote-SSH session).\n\nI recommend using a ~/.ssh/config.d/ directory on the host and have SSH include all configs there by default. That allows us to simply link the Lima-created config files there to use them.\n\nAdd this as first line in your ~/.ssh/config file, to make SSH include all configs from there:\n\nGreat! After creating a new VM, we can now simply create a symlink to the Lima-generated SSH configs and use it to SSH into the instance.\n\nLet‚Äôs start an Ubuntu 25.10 VM instance, named dev.\nWe use the internal _images/ubuntu-25.10.yaml template because it doesn‚Äôt include the automatic home directory sharing:\n\nYou can share additional project-specific directories between host and VM in several ways:\n\nCreate a symlink for the SSH config file and SSH into the VM:\n\nLet‚Äôs update the services on the instance, and configure git:\n\nLet‚Äôs confirm that port forwarding works. We do this using a one-liner Python HTTP server (on port 7777) inside the VM, and accessing it from the host:\n\nThis section guides you through installing several other languages and development tools, including Golang, Node.js, Python, Rust, Docker.\n\nWe can accomplish that either by installing each tool according to it‚Äôs documentation, or by using a version manager such as mise (‚Äúmise-en-place‚Äù, 22k stars on Github) which can install hundreds of tools via a simple command-line interface.\n\nFirst, we install mise (‚Äúmise-en-place‚Äù, 22k stars on Github) and make bash support it:\n\nYou use mise latest <tool> to see the latest versions it knows about:\n\nNow you can install all the tools you want in a single command:\n\nTo manually install (or update) Golang in the VM, download the latest release and extract into /usr/local/go:\n\nThe Golang path needs to be in the PATH environment variable, which we have already added before.\n\nA good way to install a current version of Node.js in Ubuntu is by using nvm, a modern node version manager (90k stars on GitHub):\n\nNow it‚Äôs all installed and ready to use! Check the versions like this:\n\nPerhaps you don‚Äôt even need Docker, since Lima includes containerd and nerdctl by default. This is a Docker-compatible runtime and command-line interface that can also run images from Docker Hub:\n\nIf you do want to install Docker, the quickest way to install it by using their official get-docker.sh script:\n\nFor the group changes to take effect, exit the shell and re-login (may need a VM restart).\n\nVerify that user is in the ‚Äòdocker‚Äô group:\n\nGitHub CLI provides a useful gh cli command that let‚Äôs you easily interact with GitHub and private repositories.\n\nYou can install it in the VM following the Linux installation instructions:\n\nWarning: Authorizing GitHub CLI to access private repositories will leave an API key in the VM which could potentially be stolen by unauthorized scripts (which is what we wanted to avoid in first place by running everything in a VM).\n\nOnly authorize it with gh auth login for private repo access if you accept the risks! I personally avoid having any sensitive credentials in the VM, in particular those that allow access to private GitHub repositories.\n\nIf you prefer an IDE like VS Code, you can use Remote-SSH to start a session inside the instance.\n\nPlease note that this is potentially unsafe, as explained in the Remote-SSH README:\n\nSecurity Note\nUsing Remote-SSH opens a connection between your local machine and the remote. Only use Remote-SSH to connect to secure remote machines that you trust and that are owned by a party whom you trust. A compromised remote could use the VS Code Remote connection to execute code on your local machine.\n\nSee also this discussion on GitHub for more context and information.\n\nNow a new VS Code window opens, and sets up VS Code Server:\n\nThen you can click ‚ÄúOpen‚Äù and choose a folder, like Shared:\n\nBefore setting up the tools, let‚Äôs create a ‚ÄúHello World‚Äù directory in the Shared folder as our playground:\n\nLet‚Äôs start with installing Claude Code in the VM, following the instructions in the documentation:\n\nOn first start, Claude asks you to authorize it.\n\nThe docs mention support for an ANTHROPIC_API_KEY environment variable (i.e. set in .bashrc), but that did not work when I tried it; claude CLI didn‚Äôt let me skip the login process. Only after the login was done it notified me about the existing environment variable, and whether I‚Äôd prefer to use that one.\n\nAfter the login, Claude Code CLI is ready to be ued in the VM! üéâ\n\nSince Claude is running in a VM, it might be permissible to run it in ‚Äúdangerously skip permissions mode‚Äù, which makes it bypass all permission checks:\n\nYou could also create an alias for it and add it to your .bashrc:\n\nAnthropic provides documentation for using Claude in VS Code, and also offer a VS Code Claude extension.\n\nYou can install the Claude extension in the VM through the Remote-SSH session window:\n\nIn contrast to the CLI tool, the authentication flow did not work through the user interface, and I had to set the ANTHROPIC_API_KEY environment variable:\n\nReload the VS Code window (open command palette with Shift + CMD + P and choose ‚ÄúDeveloper: Reload Window‚Äù):\n\nNow the VS Code Claude extension should work:\n\nIf you want to enable ‚Äúdangerously skip permissions mode‚Äù in the VS Code extension, you can enable it via your user settings. Open the settings (CMD + ,), search for ‚Äúclaude‚Äù and enable ‚ÄúClaude Code: Allow Dangerously Skip Permissions‚Äù:\n\nLet‚Äôs install Gemini CLI from Google next.\n\nThe documentation recommends installing it with npm, the Node.js package manager. You‚Äôll need to install Node and npm first, see also the Node.js setup instructions.\n\nIt will ask you to authenticate:\n\nI chose ‚ÄúLogin with Google‚Äù. Note that the authentication flow may require a retry if the first attempt times fails.\n\nAfter authorization is done, Gemini CLI works!\n\nYou can run Gemini in YOLO mode:\n\nAutomatically accept all actions (aka YOLO mode, see https://www.youtube.com/watch?v=xvFZjo5PgG0 \n\nThe alias you could define in .bashrc:\n\nCodex CLI is the AI dev tool from OpenAI/ChatGPT.\n\nIt will ask you to sign in, either via ChatGPT or by providing an API key:\n\nAfter that is done, Codex CLI is ready to work for you!\n\nYou can also run Codex in dangerous mode:\n\nSkip all confirmation prompts and execute commands without sandboxing. EXTREMELY DANGEROUS. Intended solely for running in environments that are externally sandboxed\n\nThere are several other great tools worth a mention:\n\nDrop your favorite tools in the comments below!\n\nVM clones and snapshots allow you even more flexibility and isolation. You can use them to quickly and cheaply run new VMs for experiments and specific projects based on already provisioned instances. Use them frequently!\n\nLima offers several ways to take VM snapshots and/or clone VMs.\n\nYou can make a copy of an existing VM instance with limactl clone. The existing instance needs to be stopped first.\n\nAfter all the initial VM setup is done, clone it and use it both as backup as well as a base for future instances:\n\nRemember that after starting a new instance, you probably want to symlink the VM SSH configuration to your ~/.ssh/config.d/ directory, so ssh knows about it (See also ‚ÄúSSH into the VM‚Äù):\n\nFor maximum security and flexibility, consider using multiple VMs for different purposes and trust levels. This approach provides better isolation and lets you tailor each environment to specific needs.\n\nHere are some suggested VM configurations:\n\nYou can quickly clone your base VM setup to create new instances for different projects using limactl clone, as described in the VM cloning section above.\n\nFor sensitive or production projects, consider dedicating a separate VM to each project. This prevents potential cross-contamination between projects and allows you to mount only the specific project directories you need.\n\nWhen creating project-specific VMs, you can customize the mounted directories by editing the instance configuration. Either adjust the mounts section before starting the VM (by not using the -y flag), or edit ~/.lima/<vm_name>/lima.yaml after creation and restart the instance.\n\nThis approach also makes it easier to share VM configurations with team members. Instead of sharing entire disk images, you can distribute just the Lima template YAML file, which team members can use to spin up identical environments on their machines.\n\nFor automated setup, Lima supports provisioning scripts that run during VM creation. For more complex setups, consider using idempotent provisioning tools like Ansible to ensure consistent environments across your team.\n\nIf you find yourself repeatedly creating VMs with similar configurations, consider creating custom Lima templates. Templates are YAML files that define VM settings, and they can include other templates.\n\nCustom templates are useful for:\n\nYou can create a custom template by copying and modifying an existing one from Lima‚Äôs template directory. Save your custom templates in ~/.lima/_templates/ and reference them when creating new VMs:\n\nSee the Lima templates documentation \n\nHere are some important security best practices to follow when using VMs for development:\n\nRemember: The whole point of using VMs is isolation. When in doubt, create a new VM for risky experiments and delete it afterwards.\n\nI hope this guide helps you get started quickly and right-footed!\nAs always, please leave feedback, questions and ideas in the comments below.\n\nSpecial thanks to Ilya Lukyanov and Overflo for reviewing drafts of this post and making great suggestions. üôè",
    "readingTime": 12,
    "keywords": [
      "yolo mode",
      "yaml file",
      "anthropic_api_key environment",
      "remote-ssh session",
      "claude extension",
      "ssh configuration",
      "authentication flow",
      "mise mise-en-place",
      "mise-en-place stars",
      "command-line interface"
    ],
    "qualityScore": 1,
    "link": "https://www.metachris.dev/2025/11/sandbox-your-ai-dev-tools-a-practical-guide-for-vms-and-lima/",
    "thumbnail_url": "https://www.metachris.dev/images/posts/ai-sandbox/cover.jpg",
    "created_at": "2026-01-21T00:59:26.211Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-chief-satya-nadella-warns-ai-boom-could-falter-without-wider-adoption",
    "title": "Microsoft chief Satya Nadella warns AI boom could falter without wider adoption",
    "description": "Big tech boss tells delegates at Davos that broader global use is essential if technology is to deliver lasting growth",
    "fullText": "Save now on essential digital access to trusted FT journalism on any device. Savings based on monthly annualised price.\n\nThen undefined per month. Complete digital access with exclusive insights and industry deep dives on any device. Cancel anytime during your trial.\n\nComplete digital access with exclusive insights and industry deep dives on any device.\n\nFT Digital Edition: all the content of the FT newspaper on any device.\n\nCheck whether you already have access via your university or organisation.\n\nDiscover all the plans currently available in your country\n\nDigital access for organisations. Includes exclusive features and content.\n\nSee why over a million readers pay to read the Financial Times.",
    "readingTime": 1,
    "keywords": [
      "industry deep",
      "deep dives",
      "exclusive insights",
      "digital access",
      "device",
      "content"
    ],
    "qualityScore": 0.75,
    "link": "https://www.ft.com/content/2a29cbc9-7183-4f68-a1d2-bc88189672e6",
    "thumbnail_url": "https://images.ft.com/v3/image/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F6112a4c3-9a6b-4d82-ab3c-28876be57ff9.jpg?source=next-barrier-page",
    "created_at": "2026-01-21T00:59:25.321Z",
    "topic": "tech"
  },
  {
    "slug": "codex-cli-skill-to-add-subagents-like-in-claude-code",
    "title": "Codex CLI skill to add subagents like in Claude Code",
    "description": "OpenAI Codex CLI skill to support running subagents - iipanda/codex-subagent-skill",
    "fullText": "iipanda\n\n /\n\n codex-subagent-skill\n\n Public\n\n OpenAI Codex CLI skill to support running subagents\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n iipanda/codex-subagent-skill",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/iipanda/codex-subagent-skill",
    "thumbnail_url": "https://opengraph.githubassets.com/d2d5e6f6ccf74c90db9748f02904c4f6424b660afe911ac775056cfc11a42540/iipanda/codex-subagent-skill",
    "created_at": "2026-01-20T18:21:58.367Z",
    "topic": "tech"
  },
  {
    "slug": "blackrock-ceo-says-capitalism-isnt-spreading-the-wealth-and-ai-might-not-either",
    "title": "BlackRock CEO says capitalism isn't spreading the wealth ‚Äî and AI might not either",
    "description": "In his opening remarks at the World Economic Forum, Larry Fink, the CEO of BlackRock, warned that AI could heighten wealth inequality.",
    "fullText": "Larry Fink, the CEO of BlackRock, the world's largest asset management firm, kicked off the World Economic Forum on Tuesday with a critique of capitalism.\n\nMore wealth has been created since the fall of the Berlin Wall than at any other time in human history, but it has not translated into shared prosperity, said Fink, who was appointed as interim co-chair of the World Economic Forum in August 2025, replacing founder Klaus Schwab.\n\n\"In advanced economies, that wealth has accrued to a far narrower share of people than any healthy society can ultimately sustain,\" he said.\n\nFink warned that the pattern of unequal wealth distribution could repeat in the era of AI.\n\n\"Early gains are flowing to the owners of models, owners of data, and owners of infrastructure,\" said Fink.\n\n\"The open question, what happens to everyone else? If AI does to white collar workers what globalisation did to blue collar workers, we need to confront that today, directly.\"\n\nHe urged those gathered at the annual meeting in Davos to rethink how prosperity is defined and to create a \"credible plan\" for broad participation in the gains AI can deliver.\n\n\"This is going to be the test. Capitalism can evolve to turn more people into owners of growth instead of spectators watching it happen,\" said Fink.\n\nThe world's wealthiest 10% own roughly 75% of global wealth, while the poorest half hold only about 2%, according to the World Inequality Report 2026, released in December 2025 and based on data compiled by 200 researchers.\n\nFink acknowledged in his speech that the World Economic Forum has lost trust and \"feels out of step with the moment.\"\n\n\"Davos is an elite gathering trying to shape a world that belongs to everyone,\" Fink said, adding that the forum should be more transparent and precise about what economic success means, especially with those who don't feel represented at gatherings like Davos.\n\n\"Prosperity just isn't the growth in the aggregate. It's not just GDP. It can't be measured by GDP or the market caps of companies. It has to be judged by many people who see it, who can touch it, can feel it, and can build their own future on it,\" said Fink.\n\nFink has previously spoken about how the pandemic fueled a rethink of the US economy.\n\nIn his 2022 annual letter to shareholders, Fink said the growth of stakeholder capitalism ‚Äî the idea that companies should prioritize interests beyond shareholders ‚Äî was a natural evolution of how capitalism can best work to build a strong economy.\n\n\"It is through effective stakeholder capitalism that capital is efficiently allocated, companies achieve durable profitability, and value is created and sustained over the long-term,\" he said.\n\nBlackRock, which manages some $14 trillion in assets, has been one of the loudest voices in support of environmental, social, and corporate governance (ESG) investing, with Fink often highlighting climate change and sustainability in his annual letters.",
    "readingTime": 3,
    "keywords": [
      "economic forum",
      "collar workers",
      "stakeholder capitalism",
      "world economic forum",
      "fink the",
      "wealth",
      "owners",
      "annual",
      "growth",
      "blackrock"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/larry-fink-blackrock-ceo-davos-critiques-capitalism-ai-wealth-inequality-2026-1",
    "thumbnail_url": "https://i.insider.com/696f56a2e1ba468a96aa52bb?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.769Z",
    "topic": "finance"
  },
  {
    "slug": "the-career-advice-jensen-huang-gave-me",
    "title": "The career advice Jensen Huang gave me",
    "description": "Sid Pardeshi, a former Nvidia engineer-turned founder, said Jensen Huang inspired him to launch an AI company, and taught him about leadership.",
    "fullText": "This as-told-to essay is based on a conversation with Sid Pardeshi, 32, the co-founder and CTO of a generative AI software platform. He is from India and lives in Cambridge, Massachusetts. The following has been edited for length and clarity.\n\nI thought I'd stay at Nvidia forever.\n\nThe pay, learning opportunities, and benefits made it a delight to work there. I had no reason to leave.\n\nBut Nvidia's CEO, Jensen Huang, inspired me, and I realized I wanted to be a founder, too.\n\nIn 2022, I made the extremely hard decision to leave Nvidia and pursue my entrepreneurial dreams. I resigned months before ChatGPT was released, and I believe that choice cost me double-digit millions worth of unvested company stock.\n\nI co-founded the AI company Blitzy in 2023, which has raised $4.4 million. Working under Huang for over six years taught me valuable lessons that have been instrumental to my success.\n\nI got an internship with Nvidia in India through my university, where I studied electrical and electronics engineering.\n\nWhen I started in January 2016, Nvidia wasn't a FAANG company, the acronym for the most prestigious Big Tech firms of the time: Facebook, Apple, Amazon, Netflix, and Google. But as a gamer, I was familiar with the company's graphics chips, so I was deeply passionate about working there.\n\nAt the end of my six-month internship, I started a full-time position as a junior engineer at Nvidia in Pune. By 2018, I was a senior system software engineer.\n\nI didn't interact with Jensen much, but he would lead quarterly all-hands meetings, which I would attend remotely from India. He spoke about things where he was ahead of his time, like AI and virtual worlds. I was fascinated by him because I shared his love of technology.\n\nOnce, when Jensen visited staff in India, I asked him after an all-hands meeting what to focus on if I wanted to make a meaningful contribution to Nvidia and the tech space at large.\n\nHe suggested choosing one area of expertise and committing to it deeply, rather than spreading myself out across many interests. I took his guidance to heart and went deep into AI as it related to gaming.\n\nAs time passed, my ambitions evolved. I saw a lot of opportunities emerging in AI, and I wanted to become a founder like Jensen.\n\nIn 2022, at age 28, I quit my job and moved to Massachusetts with my wife and children to join an MSc and MBA program at Harvard.\n\nWhile studying, I worked for Nvidia as an intern from May 2023 to April 2024. They offered me a job that could start after I completed my master's, but starting a business was my primary goal.\n\nIn 2023, a classmate at Harvard and I founded Blitzy, which I work on full-time as the CTO. We're working on using AI to significantly automate software development work for enterprises.\n\nAt Nvidia, I noticed that Jensen nurtured and valued talent. When I was an intern in the US, he made time to meet with us. His assistant kept telling him that a very important client was calling him during the meeting. \"Let them wait,\" Jensen said. \"I'm talking to the future of Nvidia.\"\n\nLike Jensen, I want to keep the spark alive among employees, regardless of their rank. Every day, I allocate two hours to listening to team members and helping them solve problems.\n\nJensen would also follow his convictions. For example, he bet on the accelerated computing platform CUDA in the 2000s, when no one saw its true potential. Now, it's the backbone of AI training processes.\n\nSimilarly, when we first pitched to investors that we intended to use AI to build software autonomously, many didn't believe AI was advanced enough yet. But because I've been reading papers in the AI space every week for years, I trusted my convictions and that we could automate coding at Blitzy.\n\nAnother page I'm taking from his book is never ruling out the prospect of going out of business. Jensen was always concerned about the survival of Nvidia, despite it being a trillion-dollar company. I remember once a fellow intern in the US asked Jensen whether he watched movies. He said that even in the theater, he's thinking about Nvidia.\n\nAs Blitzy's CTO, I want to anticipate every challenge ahead of time. I focus on solving important technical problems and delegate everything else. I want to let people with more knowledge about other aspects of the company handle issues in their space.\n\nSimilarly, it's thought that Jensen's signature outfit, the black pants, shirt, and leather jacket, helps him minimize decision fatigue. I do wear different outfits every day, but my wife, who loves fashion, picks them out for me.\n\nAt one point, I wondered if I was being selfish by leaving Nvidia. I had a family, and needed to make the right choice, both for my career and for them.\n\nI moved to the US on a student visa, which meant my wife was my dependent and not allowed to work. She put her career on the line.\n\nYet, my wife, and my mom, encouraged me to pursue my dreams, and it would be too late now if I hadn't done it then. Once ChatGPT came out, everyone was thinking about bringing AI solutions to the market. I'm glad I already had deep knowledge and experience with AI and was ready to take advantage of the moment.\n\nFinancially, quitting Nvidia wasn't a smart decision because, based on my calculations around my compensation package, my unvested stock would be worth double-digit millions because of how the company's value has grown.\n\nI knew AI technology would progress significantly over the next few years, although I couldn't have anticipated ChatGPT coming out so fast in November 2022 ‚Äî just months after I resigned. I was leaving right on the cusp of a big moment in the industry, before I was able to harvest the returns.\n\nBut I'm glad I quit when I did. If my family has what they need, working on cutting-edge stuff is more important to me than money.\n\nI got to watch as Nvidia grew from a relatively insignificant company to a trillion-dollar business, and I'm applying everything I learned to Blitzy. My mission is for Blitzy to be on the same trajectory as Nvidia, one day becoming a trillion-dollar company.\n\nA spokesperson for Nvidia declined to comment.",
    "readingTime": 6,
    "keywords": [
      "i'm glad",
      "double-digit millions",
      "nvidia wasn't",
      "software",
      "wife",
      "jensen",
      "decision",
      "space",
      "intern",
      "business"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-employee-jensen-huang-leadership-lessons-2026-1",
    "thumbnail_url": "https://i.insider.com/6969672564858d02d218749d?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.659Z",
    "topic": "finance"
  },
  {
    "slug": "deepmind-and-anthropic-ceos-ai-is-already-coming-for-junior-roles-at-our-companies",
    "title": "DeepMind and Anthropic CEOs: AI is already coming for junior roles at our companies",
    "description": "Anthropic CEO Dario Amodei said his company is thinking about how to deal with job elimination \"in a sensible way.\"",
    "fullText": "AI might not be causing a labor market bloodbath, but leaders at Google DeepMind and Anthropic say they're starting to see its impact on junior roles inside their own companies.\n\n\"I think we're going to see this year the beginnings of maybe it impacting the junior level,\" said Google DeepMind CEO Demis Hassabis during a joint interview with Anthropic CEO Dario Amodei at Davos on Tuesday.\n\n\"I think there is some evidence, I can feel that ourselves, maybe like a slowdown in hiring in that,\" he said, highlighting entry-level roles and internships as vulnerable examples.\n\nAmodei appeared to agree. The Anthropic boss said last year he believed AI could wipe out half of all entry-level white-collar jobs and push unemployment as high as 20%.\n\nAs of Tuesday, his prediction had not changed, he said.\n\n\"Now I think maybe we're starting to see just the little beginnings of it, in software and coding,\" he said. \"I can see it within Anthropic, where I can look forward to a time where on the more junior end and then on the more intermediate end we actually need less and not more people.\"\n\nHe added: \"And we're thinking about how to deal with that within Anthropic in a sensible way.\"\n\nAmodei and Hassabis have both warned that AI's potential impact on the economy and labor markets could demand institutional change, including through¬†international organizations governing AI¬†and¬†economic intervention,¬†to mitigate the most disastrous outcomes.\n\n\"My worry is as this exponential keeps compounding, and I don't think it's going to take that long ‚Äî again, somewhere between a year and five years ‚Äî it will overwhelm our ability to adapt,\" said Amodei.",
    "readingTime": 2,
    "keywords": [
      "google deepmind",
      "within anthropic",
      "junior",
      "we're",
      "labor",
      "impact",
      "roles",
      "beginnings",
      "entry-level",
      "amodei"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/google-deepmind-anthropic-ceos-ai-junior-roles-hiring-davos-2026-1",
    "thumbnail_url": "https://i.insider.com/696f8656c58df2ecd5ccc927?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.656Z",
    "topic": "finance"
  },
  {
    "slug": "veteran-investor-jeremy-grantham-says-ai-is-obviously-a-bubble-and-it-could-tank-the-stock-market-when-it-bursts",
    "title": "Veteran investor Jeremy Grantham says AI is 'obviously a bubble' ‚Äî and it could tank the stock market when it bursts",
    "description": "Veteran investor Jeremy Grantham compared the AI boom to the railroad and internet bubbles, and said the chances it won't burst are \"slim to none.\"",
    "fullText": "Jeremy Grantham says AI is one of the biggest bubbles in history ‚Äî and it's likely to tank the stock market when it bursts.\n\n\"I think it's obviously a bubble, and I think it's quite a simple story,\" the veteran investor and GMO cofounder said during the latest episode of the \"Merryn Talks Money\" podcast.\n\nGrantham compared AI to the railroad and the internet, two world-changing inventions marked by early investment bubbles which, when they popped, \"brought the economy to its knees for a year or two\" and \"everybody lost their money.\"\n\nContrary to common belief, \"bubbles don't occur when there's some crummy idea that gets touted,\" Grantham said. \"All the bubbles are associated with serious things, and the more serious, the bigger the bubble.\"\n\nGrantham emphasized the \"iron law\" that when an asset doubles in price, the return from holding it halves from that point forward.\n\n\"If you want to have the highest market in history, you will have the lowest returns in history going forward,\" he said. \"And it will happen this time. And my guess is after a while, sooner or later, the market will become a whole lot cheaper.\"\n\nGrantham, who had predicted an epic market crash four years ago, said the release of OpenAI's ChatGPT in late 2023 generated immense buzz around AI and sparked major capital outlays by companies, ultimately staving off an economic slump.\n\nThe market historian said that Big Tech companies have used their dominant market positions and influence to boost their profit margins to \"excessive levels,\" but that won't stop the bubble he sees from bursting.\n\nThe \"probabilities that AI will not bust are slim to none,\" he said. \"It meets every condition of the railroads and the Internet. It's a powerful idea that's attracted everybody's money.\"\n\n\"And so my guess is Nvidia will lead it down, and all the others will follow for a while, and then out of the ashes several of them will once again inherit the world,\" he said.\n\nGrantham also flagged institutional inertia and herd mentality as factors preventing the market from coming to its senses.\n\nPut differently, industry professionals aren't sounding the alarm on valuations out of fear that the bubble will keep growing and they'll underperform their rivals, hurt their reputations, and lose clients or even their jobs.\n\n\"They all look around nervously at each other, but they keep going,\" he said. \"As long as the music's playing, they're going to be dancing. Doesn't matter that they know the market is silly.\"\n\nGrantham is one of several high-profile investors, including Michael Burry of \"The Big Short\" fame, who have warned AI stocks are overvalued and predicted a market downturn is coming.\n\nYet the US stock market has continued to march higher in spite of the skeptics, with the benchmark S&P 500 rising around 80% over the past five years.\n\n\"Shark Tank\" investor Kevin O'Leary and tech investor Ross Gerber dismissed comparisons between the AI boom and dot-com bubble in interviews with Business Insider last fall.\n\nO'Leary said \"you actually can see the productivity and measure it on a dollar-by-dollar basis,\" while Gerber said today's valuations are warranted as AI companies have enormous growth potential and their profitability is \"just insane.\"",
    "readingTime": 3,
    "keywords": [
      "stock market",
      "bubble",
      "bubbles",
      "history",
      "investor",
      "grantham",
      "idea",
      "serious",
      "forward",
      "guess"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/jeremy-grantham-ai-bubble-nvidia-tech-stocks-stock-market-crash-2026-1",
    "thumbnail_url": "https://i.insider.com/672389b201ea6d83dee5543a?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.406Z",
    "topic": "finance"
  },
  {
    "slug": "uber-ceo-on-the-most-promising-way-to-succeed-with-ai-throw-out-the-old-policies",
    "title": "Uber CEO on the most promising way to succeed with AI: Throw out the old policies",
    "description": "Speaking at the World Economic Forum in Davos, Uber's Dara Khosrowshahi said some companies are just \"saying the right words\" when it comes to AI.",
    "fullText": "How do you separate the pretenders from the real deal when it comes to business AI adoption?\n\nFor Uber CEO Dara Khosrowshahi, it comes down to building AI into processes from the ground up.\n\nSpeaking at the World Economic Forum in Davos, Dara Khosrowshahi said some companies are \"saying the right words\" and \"play-acting their way into a pretend transformation.\"\n\nFor example, having an AI agent complete tasks like summarizing a client pitch is the \"easy stuff\" that won't differentiate companies, he said.\n\n\"Truly changing how you work with AI, we've found it to be much harder than it sounds,\" he added.\n\nHe gave the example of using AI to improve customer service at Uber. The company had some success by having AI follow its old policies, but had a real \"breakthrough\" after its developers rebuilt everything from scratch.\n\nThat involved giving an AI agent clear underlying goals, Khosrowshahi said, such as making the customer feel good after the interaction.\n\n\"Allowing the AI actually to reason through that and throwing away all of the old policies is turning out to be the most promising way forward,\" he said.\n\nKhosrowshahi added that companies are essentially a \"bunch of policies,\" and that to get the full potential of AI, they would need to \"break down those rules and start over.\"\n\nInternally, Uber developers are using AI tools like Anysphere's Cursor and Anthropic's Claude, he added.\n\nMany companies have been ramping up their AI spending in the hope of unlocking productivity gains. A recent poll of IT professionals by RBC Capital found that 90% of respondents plan to spend more on AI this year.\n\nHowever, there are also fears that AI isn't always living up to the hype, and companies are grappling with concerns that it's eroding workers' skills.\n\nKhosrowshahi acknowledged that getting AI adoption right at a company isn't always plain sailing.\n\n\"You have to survive through a bunch of car crashes internally to do so,\" he said.",
    "readingTime": 2,
    "keywords": [
      "dara khosrowshahi",
      "policies",
      "adoption",
      "agent",
      "customer",
      "developers",
      "bunch",
      "isn't",
      "uber",
      "internally"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/uber-ceo-ai-adoption-productivity-break-rules-dara-khosrowshahi-davos-2026-1",
    "thumbnail_url": "https://i.insider.com/696fa2cba645d11881879fa3?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.258Z",
    "topic": "finance"
  },
  {
    "slug": "steven-bartlett-says-using-ai-in-this-way-is-the-most-important-thing-hes-done-for-his-business",
    "title": "Steven Bartlett says using AI in this way is the most important thing he's done for his business",
    "description": "\"The Diary of a CEO\" host said at the World Economic Forum in Davos that using AI to translate podcasts into Spanish broadened its reach.",
    "fullText": "Steven Bartlett said one use of AI has mattered more to his business than anything else: translating his podcast into other languages.\n\n\"There's nothing more important than what we've done for our business than translations. Period,\" Bartlett said during the \"What it Takes to Build\" panel at the World Economic Forum at Davos on Tuesday.\n\nThe British entrepreneur and host of \"The Diary of a CEO\" podcast was in conversation with Jessica Lessin, the CEO of The Information, alongside Bret Taylor, formerly the co-CEO of Salesforce and CTO of Meta.\n\nBartlett said using AI tools to translate the podcasts was initially an \"expensive experiment.\" The problem he was trying to solve, he said, was reaching the untapped market of non-English speakers.\n\n\"If we're just in English, we're reaching like 10% of the world,\" Bartlett added.\n\nThere were technical challenges, too. Some languages use longer words, Bartlett said, meaning three-hour English-language conversations could become significantly longer when translated, risking the audio and video falling out of sync.\n\nTwo years ago, Bartlett announced on LinkedIn that \"The Diary of a CEO\" had hired a full-time data scientist who helped the company achieve a technological breakthrough, enabling them to use AI to translate the podcast into \"EVERY language.\"\n\nAt Davos and in the LinkedIn post, Bartlett did not elaborate on exactly how the AI translations work. Today, however, the videos show Bartlett speaking Spanish in a voice similar to his own, a shift he said had significantly expanded the podcast's reach.\n\n\"This month, 28% of my audience is Spanish,\" he said, adding that Spanish speakers now have access to interviews with some of the world's most high-profile podcast guests, citing his own interview with former first lady Michelle Obama as an example.\n\nOther guests on the podcast include former vice President Kamala Harris, Simon Cowell, and the psychologist Jordan Peterson.\n\nSpotify said in its \"2025 Wrapped\" press release in December 2025 that \"The Diary of a CEO with Steven Bartlett\" was the platform's second-most-listened-to podcast globally, behind \"The Joe Rogan Experience.\" On YouTube, Bartlett's podcast channel has 14.5 million subscribers.",
    "readingTime": 2,
    "keywords": [
      "steven bartlett",
      "the diary of ceo",
      "podcast",
      "spanish",
      "business",
      "languages",
      "translations",
      "translate",
      "speakers",
      "we're"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/steven-bartlett-diary-of-a-ceo-davos-ai-translation-business-2026-1",
    "thumbnail_url": "https://i.insider.com/696fa4e6c58df2ecd5cccc5b?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:54.068Z",
    "topic": "finance"
  },
  {
    "slug": "sapiens-author-says-the-real-ai-timeline-is-200-years-but-the-lack-of-concern-today-is-what-scares-him-most",
    "title": "'Sapiens' author says the real AI timeline is 200 years ‚Äî but the 'lack of concern' today is what scares him most",
    "description": "Yuval Noah Harari says AI's deepest social and political consequences will unfold over centuries, not years, and says short-term focus is dangerous.",
    "fullText": "Yuval Noah Harari warned that the world is badly misjudging the timescale of artificial intelligence ‚Äî and that the real danger lies not in how fast the technology is moving, but in how casually it's being treated.\n\nSpeaking at the World Economic Forum in Davos on Tuesday, the historian and author of \"Sapiens: A Brief History of Humankind\" said that when he talks about the long-term impact of AI, he's not thinking in years or even decades.\n\n\"A lot of the conversations here in Davos, when they say 'long term' they mean like two years,\" Harari said. \"When I mean long term, I think 200 years.\"\n\nHarari compared the current moment in AI to the early days of the Industrial Revolution, saying that humanity tends to misunderstand transformative technologies as they unfold.\n\nThe deepest consequences of industrialization took generations to fully emerge, he said ‚Äî often through social, political, and geopolitical upheaval that no one could have predicted in advance.\n\n\"You can test for accidents,\" he said. \"But you cannot test the geopolitical implications or the cultural implications of the steam engine in a laboratory. It's the same with AI.\"\n\nHarari warned that even if AI development were to stop today, its long-term effects would still be impossible to grasp.\n\n\"The stone has been thrown into the pool, but it just hit the water,\" he said. \"We have no idea what waves have been created, even by the AIs that have been deployed a year or two ago.\"\n\nHarari joins a plethora of senior AI researchers and tech leaders who have expressed concerns about AI's risks, ranging from waves of job losses to human extinction.\n\nHowever, what worries him most, Harari said, is not just uncertainty ‚Äî but complacency. He said many of the most powerful decision-makers shaping AI are focused on short-term incentives rather than long-term consequences.\n\n\"I'm mainly concerned about the lack of concern that we are creating the most powerful technology in human history,\" he said.\n\n\"Very smart and powerful people are worried about what their investors say in the next quarterly report,\" Harari said. \"They think in terms of a few months, or a year or two.\"\n\nAI's social consequences, he said, will play out far beyond that horizon ‚Äî whether the world is ready or not.",
    "readingTime": 2,
    "keywords": [
      "harari warned",
      "long-term",
      "consequences",
      "technology",
      "it's",
      "davos",
      "history",
      "social",
      "geopolitical",
      "test"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sapiens-author-ai-timeline-warning-lack-of-concern-2026-1",
    "thumbnail_url": "https://i.insider.com/696fa92fa645d1188187a0cf?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:53.954Z",
    "topic": "finance"
  },
  {
    "slug": "the-author-of-sapiens-says-ai-is-about-to-create-2-crises-for-every-country",
    "title": "The author of 'Sapiens' says AI is about to create 2 crises for every country",
    "description": "At the World Economic Forum in Davos, Yuval Noah Harari said AI will create two crises for every country: An identity crisis and an immigration crisis.",
    "fullText": "AI technology is about to create two crises for every country, says the author of the bestselling book \"Sapiens: A Brief History of Humankind.\"\n\nOn Tuesday, while giving a talk on AI and humanity at the World Economic Forum in Davos, Yuval Noah Harari said that AI is going to plunge humanity into an identity crisis, since we have come to value ourselves based on our capacity to think, but AI will potentially outperform us on this task soon.\n\nSecondly, Harari said every nation is going to face an immigration crisis, comparing AIs to immigrants who will bring benefits into a country, such as skills in medicine and teaching, but disruptions alongside those benefits.\n\n\"Those who are concerned about human immigrants usually argue that immigrants might take jobs, might change the local culture, might be politically disloyal. I'm not sure that's true of all human immigrants, but it will definitely be true of the AI immigrants,\" he said.\n\nHarari asked the audience whether they want to allow AIs to be recognized as \"legal persons\" with rights in their countries, giving them the ability to start businesses, form and preach their own religions, or befriend their children on social media.\n\n\"If you want to influence where humanity is going, you need to make a decision now,\" he said.\n\nHarari is a distinguished research fellow at the University of Cambridge's Centre for the Study of Existential Risk, and a history professor at the Hebrew University of Jerusalem. Alongside \"Sapiens,\" his book tracing human history across the centuries, he also released \"Homo Deus: A Brief History of Tomorrow\" in 2015, where he discussed the existential threat AI poses to humanity.\n\nHarari is not the first person to refer to \"AI immigrants.\" Earlier this month, the Nvidia CEO, Jensen Huang, referred to robots using the term, and said \"AI immigrants\" will help humans with work we no longer want to do, such as manufacturing jobs, AFP reported.",
    "readingTime": 2,
    "keywords": [
      "brief history",
      "human immigrants",
      "humanity",
      "book",
      "sapiens",
      "crisis",
      "benefits",
      "alongside",
      "jobs",
      "harari"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sapiens-author-yuval-noah-harari-ai-crises-every-country-2026-1",
    "thumbnail_url": "https://i.insider.com/696fa94fe1ba468a96aa5831?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:53.944Z",
    "topic": "finance"
  },
  {
    "slug": "palantir-ceo-alex-karp-says-humanities-jobs-are-doomed-in-the-age-of-ai-hopefully-you-have-some-other-skill",
    "title": "Palantir CEO Alex Karp says humanities jobs are doomed in the age of AI: 'Hopefully you have some other skill'",
    "description": "Alex Karp, CEO of Palantir, said vocational skills will dominate in the AI future.",
    "fullText": "Alex Karp, the billionaire co-founder and CEO of the AI defense technology company Palantir, had a top humanities-based education.\n\nKarp graduated from Haverford College, an elite liberal arts college in Pennsylvania, with a degree in philosophy. He then attended Stanford Law School and later earned a Ph.D. in neoclassical social theory at a top German university.\n\n\"A very, very strong education,\" Karp said during a panel at the World Economic Forum on Tuesday.\n\nIn the age of AI, that kind of academic trajectory will doom you, Karp told Larry Fink, the CEO of BlackRock, who was leading the discussion.\n\nAI \"will destroy humanities jobs,\" Karp said.\n\n\"You went to an elite school, and you studied philosophy ‚Äî hopefully you have some other skill,\" Karp said, because that skillset is going to be very hard to market.\n\nThe Palantir CEO said it would probably be possible for those with humanities backgrounds to keep a job once they secure it, but he said technicians and those with other vocational skill sets are going to be in the highest demand.\n\nHe gave the example of people building batteries for a battery company, saying that \"they're very valuable, if not irreplaceable, because we can make them into something different than what they were very rapidly.\"\n\n\"There will be more than enough jobs for the citizens of your nation, especially those with vocational training,\" Karp told Fink.\n\nBut not all at Davos agree with the tech leader's assessment of the future of jobs.\n\nFinance executives attending the global forum have been telling Business Insider's Dan DeFrancesco that liberal arts degrees might be the new hot commodity. As AI takes on more of the hard financial analysis, it is transforming the skill set executives prioritize in young recruits. Critical creative thinkers are back in the spotlight.\n\nGoogle DeepMind CEO Demis Hassabis and Anthropic CEO Dario Amodei also weighed in on jobs during a joint panel on Tuesday, saying that entry-level hiring at their companies was already declining due to AI.\n\nAmodei said software and coding roles at Anthropic were down in both the junior and mid-levels of his company.",
    "readingTime": 2,
    "keywords": [
      "education karp",
      "liberal arts",
      "jobs",
      "skill",
      "elite",
      "philosophy",
      "panel",
      "humanities",
      "vocational",
      "saying"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/palantir-ceo-alex-karp-ai-humanities-jobs-doomed-2026-1",
    "thumbnail_url": "https://i.insider.com/696f9f5da645d11881879f0c?width=1200&format=jpeg",
    "created_at": "2026-01-20T18:21:53.938Z",
    "topic": "finance"
  },
  {
    "slug": "your-team-is-anxious-about-ai-heres-how-to-talk-to-them-about-it",
    "title": "Your Team Is Anxious About AI. Here‚Äôs How to Talk to Them About It.",
    "description": "While certainty about the future cannot be promised, leaders can provide a framework for managing team anxiety surrounding AI transformation. It‚Äôs important for both the leader and team to equally share in transparency and open dialogue in order to maintain team cohesion and psychological safety during periods of potential disruptive change.¬† Leaders must continuously make space for reflection, recognizing that AI anxiety cannot be resolved in a single conversation, by embracing employees‚Äô fears, creating safe spaces for conversation, taking committed action, and repeating this process over and over.",
    "fullText": "Your Team Is Anxious About AI. Here‚Äôs How to Talk to Them About It. by Morra Aarons-MeleJanuary 20, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintDuring the pandemic, leaders learned that they had to figure out how to keep their teams gelled even when they had no idea what the heck would happen day to day. And many of us realized something beautiful: that showing a little more vulnerability and openness to the grey areas was exactly what our people needed. For a brief moment in time, leaders were allowed to talk about what they didn‚Äôt know.",
    "readingTime": 1,
    "keywords": [
      "talk",
      "leaders"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/your-team-is-anxious-about-ai-heres-how-to-talk-to-them-about-it",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_17_1495185382.jpg",
    "created_at": "2026-01-20T18:21:53.429Z",
    "topic": "business"
  },
  {
    "slug": "to-compete-in-the-global-economy-europe-needs-to-boost-its-vc-ecosystem",
    "title": "To Compete in the Global Economy, Europe Needs to Boost Its VC Ecosystem",
    "description": "Europe‚Äôs struggle to produce globally dominant companies is not a mystery‚Äîit is the predictable result of a weak and fragmented venture capital ecosystem. Despite an economy comparable in size to that of the United States, Europe invests only a fraction as much in venture-backed firms, and the gap is widening as capital concentrates around AI and other winner-take-all technologies. The consequences are visible in lower innovation, weaker returns for investors, and a steady outflow of entrepreneurial talent. But Europe‚Äôs venture deficit is not inevitable. While structural disadvantages exist, policy choices and investor behavior play a decisive role.",
    "fullText": "To Compete in the Global Economy, Europe Needs to Boost Its VC Ecosystem by Josh LernerJanuary 20, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintGovernments worldwide recognize the importance of promoting high-potential start-ups and the institutions that fund them. Europe is no exception. In 2024, Mario Draghi, a former President of the European Central Bank and one-time Italian Prime Minister lamented in an influential report on European competitiveness that ‚Äúno EU company with a market capitalization over EUR 100 billion‚Ä¶has been set up from scratch in the last fifty years, while all six U.S. companies with a valuation above EUR 1 trillion have been created in this period.‚Äù",
    "readingTime": 1,
    "keywords": [
      "europe",
      "european"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/to-compete-in-the-global-economy-europe-needs-to-boost-its-vc-ecosystem",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_18_HBRCoins.jpg",
    "created_at": "2026-01-20T18:21:53.411Z",
    "topic": "business"
  },
  {
    "slug": "is-this-man-the-future-of-music-or-its-executioner-ai-evangelist-mikey-shulman-says-hes-making-pop-not-slop",
    "title": "Is this man the future of music ‚Äì or its executioner? AI evangelist Mikey Shulman says he‚Äôs making pop, not slop",
    "description": "Worth a staggering $2.45bn, Suno is an AI music company that can create a track with just a few prompts. Why is its CEO happy to see it called ‚Äòthe Ozempic of the music industry‚Äô?\n‚ÄòThe format of the future,‚Äù says Mikey Shulman, ‚Äúis music you play with, not just play.‚Äù As the CEO and co-founder of the generative AI music company Suno, Shulman currently finds himself in the exhilarating if perhaps unenviable position of being simultaneously regarded as the architect of music‚Äôs future ‚Äì and its executioner.",
    "fullText": "Worth a staggering $2.45bn, Suno is an AI music company that can create a track with just a few prompts. Why is its CEO happy to see it called ‚Äòthe Ozempic of the music industry‚Äô?\n\n‚ÄòThe format of the future,‚Äù says Mikey Shulman, ‚Äúis music you play with, not just play.‚Äù As the CEO and co-founder of the generative AI music company Suno, Shulman currently finds himself in the exhilarating if perhaps unenviable position of being simultaneously regarded as the architect of music‚Äôs future ‚Äì and its executioner.\n\nSuno, which was founded just over two years ago, allows users to create entire songs with just a few text prompts. At the moment, you can‚Äôt prompt it with the name of a specific pop star, but asking for ‚Äústadium-level confessional pop-country‚Äù that ‚Äúreferences past relationships‚Äù or ‚Äúpublic rivalries‚Äù might get you a Taylor Swift-style song or thereabouts.\n\nIn June 2024, Suno became the target of litigation by record company trade body the RIAA on behalf of major labels in the US, while German collection society GEMA, representing songwriters, filed its own lawsuit the following January. Both claimed the service was training its systems on their copyrights without authorisation or licences.\n\nGen AI music services have triggered an existential crisis in the music industry. The utopian reading is that they will democratise creativity. The dystopian one is that art will be smothered by AI slop, as humans making music become surplus to requirements. (And many musicians already struggle to make a living from streaming revenues.) Dave Stewart of Eurythmics called them an ‚Äúunstoppable force‚Äù and said musicians should, begrudgingly or enthusiastically, embrace them. Catherine Anne Davies, AKA the Anchoress, told me recently she believes it to be ‚Äúdystopian‚Äù. Music lawyer Gregor Pryor has argued it is already killing off background music work.\n\n‚ÄúI like to think of us as trying to make the next format for recorded music,‚Äù says Shulman. ‚ÄúThe format of the future will be interactive.‚Äù What does he mean? ‚ÄúIt should be social, meaning you‚Äôre doing it with other people. What we are doing is building the best digital version of that.‚Äù\n\nInvestors were clearly not scared off. In November, Suno raised $250m (¬£187m) in funding, taking its valuation to $2.45bn (¬£1.83bn). Gen AI is the hottest thing in Silicon Valley, with a Stanford University report saying it drew $34bn (¬£25bn) in private investment in 2024. But there are fears, notably at the Bank of England, that this brilliant boom can only be followed by a bitter bust. For now, however, investors believe gen AI is too big to fail. The stakes for Suno‚Äôs success are astonishingly high, especially given the recent leaking of an investor presentation suggesting the company only had 1 million paying subscribers. The standard monthly plan costs ¬£8.25 ($10).\n\n‚ÄúThe thing that investors needed help realising,‚Äù says Shulman, ‚Äúis how important music is in the world. Once you show them, their minds are changed and they realise that much, much more is possible.‚Äù\n\nWhen a new outside technology imposes itself on the music industry, the response typically runs from apoplexy to legal action, then negotiation and ultimately licensing. The three biggest names in gen AI music are at different stages along this trajectory. Klay got deals with all three majors before launching or training its technology on music, making it a rarity in this ‚ÄúLaunch first, license later‚Äù world. Udio signed deals with Universal Music Group (UMG) and Warner Music Group (WMG). Suno, however, only has a deal with WMG, and legal action from the other majors is still live.\n\nShulman, now 39, was a hobbyist musician, which provided a catalyst for Suno. ‚ÄúI played in a lot of bands in high school and college,‚Äù he says, speaking by video from his home in the US, pointing to the bass hanging on the wall behind him. ‚ÄúI was OK, not great, and I was not going to be able to make a great career out of it.‚Äù He‚Äôs cautious and thoughtful when speaking, without the tang of arrogance you sometimes get from heavily hyped start-up founders.\n\nA career swerve into a physics PhD led him to Suno‚Äôs other co-founders. They wanted to build something different to heavyweight AI companies such as OpenAI, as those deal with ‚Äúreasoning and automation to solve very specific problems. Music isn‚Äôt like that. There‚Äôs not a right or a wrong answer. It‚Äôs not a problem to solve.‚Äù\n\nThere remains debate about where exactly Suno sourced the music to train its systems ‚Äì essentially breaking music into data strands for cataloguing ‚Äì before its licensing deals were in place. ‚ÄúWe train our models on medium- and high-quality music we can find on the open internet,‚Äù wrote Shulman in a 2024 blogpost. Suno‚Äôs initial legal defence was that this constituted fair use, and the music it drew on did not require prior permission. The record industry thought differently. ‚ÄúFair use,‚Äù countered the RIAA, does not apply ‚Äúwhen the output seeks to ‚Äòsubstitute‚Äô for the work copied.‚Äù\n\nI ask Shulman what he means by the ‚Äúopen internet‚Äù. There is a clear distinction between what is copyrighted (recordings are typically protected for 70 years) and what is in the public domain. ‚ÄúCopyright is a different thing,‚Äù he says. ‚ÄúI can‚Äôt get into too many specifics because there is active legal stuff going on, and also some of it is trade secrets.‚Äù\n\nCould Suno‚Äôs philosophy of ‚Äúdemocratising‚Äù music-making be inherently anti-art? What once sprang from extraordinary human creativity now becomes ordinary. Shulman insists that, as with digital recording or sampling, this is just another example of how technology ‚Äúpushes music forward‚Äù, how ‚Äúnew people get discovered‚Äù and ‚Äúnew genres get invented‚Äù.\n\nThe issue of so-called AI slop is wholly subjective, he says. ‚ÄúI made a really funny song with my four-year-old yesterday morning. That is ‚Äòslop‚Äô to you ‚Äì you don‚Äôt care about it ‚Äì but I love it. It‚Äôs fantastic.‚Äù He is keen to stress, meanwhile, that music generated by Suno can be extremely high quality.\n\nAnd AI-powered music is flooding streaming services: Deezer says more than a third of music delivered to it each day is AI (equal to 50,000 tracks), and 70% of streams of AI music on Deezer are fraudulent (scammers get cheaply made AI tracks on to such services, then use bots to manipulate streams at scale in order to get royalty payments, although services are increasingly wise to this). The company has started tagging AI tracks to alert users. Bandcamp recently announced that it won‚Äôt platform music ‚Äúgenerated wholly or in substantial part by AI‚Äù.\n\nShould others follow? Shulman will say only that he doesn‚Äôt want to be ‚Äúthe arbiter of what happens on other platforms. There‚Äôs maybe some line to draw, but I don‚Äôt know where.‚Äù\n\nVelvet Sundown, a wholly AI ‚Äúact‚Äù, released their debut album and a follow-up last summer. The 70s-styled rock band generated millions of streams, but it was a short-lived phenomenon. ‚ÄúI don‚Äôt know exactly what their strategy was,‚Äù Shulman says of Velvet Sundown. ‚ÄúIt was all a bit of a goof. I think that‚Äôs why it was a flash in the pan.‚Äù\n\nSome AI-powered tracks have staying power, though. Following allegations it used Suno to clone Jorja Smith‚Äôs voice, I Run, by Haven, was excluded from the UK charts, but a version re-recorded by Kaitlin Aragon, a human singer, was chart-eligible and went Top 10. Into the Blue by Sienna Rose, who is widely suspected to be an AI act, recently made the Top 10 on Spotify‚Äôs Viral 50 Global chart. And the track Jag Vet, Du √Ñr Inte Min is one of the biggest of the year so far in Sweden, although it has been booted out of the country‚Äôs charts for being ‚Äúmainly AI-generated‚Äù.\n\nMore concerning was Suno being used last year to create tracks that the Anti-Defamation League said glorified Adolf Hitler, deployed racist slurs and talked of ‚Äúwhite power‚Äù. Shulman says: ‚ÄúIt was three songs that had a combined 10 plays. It was a very small thing. Unfortunately, drawing attention to it made it worse.‚Äù He says Suno has developed more rigorous safeguards to stop similar things happening in the future.\n\nSuno is keen for its deal with WMG to be seen as proof that gen AI companies can partner in mutually beneficial ways. Did the $1.5bn (¬£1.1bn) that AI company Anthropic paid to the book industry in September to settle claims its AI was trained on pirated copies spook Suno to get deals done swiftly? ‚ÄúWe didn‚Äôt pay all that much attention to that,‚Äù says Shulman. ‚ÄúThere‚Äôs a lot more to do together than fighting one another. And we intend, with this Warner partnership, to show that very strongly.‚Äù\n\nBut questions do persist about the WMG deal. Did the label insist on changes to the service? Were payments made to cover past use of its music in Suno‚Äôs training? Did WMG get equity in Suno? Shulman won‚Äôt reply, saying only that it is ‚Äúa little early‚Äù to share such information, possibly fearful of compromising pending licensing deals.\n\nAgreements with the majors are one thing, but wooing artists is another. The majors insist they will only have their music used if they opt into deals. But if only a tiny percentage do ‚Äì never mind their name, image and likeness rights ‚Äì this will surely compromise results.\n\nIn his book Outliers, Malcolm Gladwell popularised ‚Äúthe 10,000-hour rule‚Äù, suggesting that this is the amount of practise time an artist needs to achieve any sort of mastery. Will the likes of Suno change this? ‚ÄúI think people will [still] have to spend 10,000 hours,‚Äù says Shulman. ‚ÄúThey may be doing different things and practising different skills, but they will certainly need to spend 10,000 hours to make the best music in the world.‚Äù\n\nAs part of its charm offensive, Suno signed up US producer Timbaland as a strategic advisor, but he had to make a public apology after he took a track by producer K Fresh without permission and, Fresh alleged, ‚Äúuploaded it into Suno‚Äôs AI platform, and released an unauthorised AI remix‚Äù.\n\nNevertheless, Shulman says the musicians he talks to about Suno see it as an important new creative tool and songwriting aid. He had previously told the 20VC podcast: ‚ÄúI think the majority of people don‚Äôt enjoy the majority of the time they spend making music.‚Äù This does not mean musicians hate the creative process in toto, but they are appreciative of tools that can remove at least some of the grunt work.\n\nThey just see it as a dirty secret, he suggests now. ‚ÄúWhen you get people one-on-one, they‚Äôre just more comfortable admitting it. It was described to me that we‚Äôre the Ozempic of the music industry ‚Äì everybody is on it and nobody wants to talk about it.‚Äù\n\nThe fear, of course, is that by putting music on Ozempic, it wastes away to nothing.",
    "readingTime": 10,
    "keywords": [
      "legal action",
      "licensing deals",
      "music industry",
      "music generated",
      "suno shulman",
      "gen ai",
      "tracks",
      "services",
      "musicians",
      "majors"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/music/2026/jan/19/ai-music-company-mikey-shulman-suna",
    "thumbnail_url": "https://i.guim.co.uk/img/media/fdf44bef142f8ed1cf65e705c25f4a0ebb4b83c0/554_655_4079_3264/master/4079.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=419f52a4f493aed62dd727b4c83e3ffd",
    "created_at": "2026-01-20T18:21:50.561Z",
    "topic": "entertainment"
  },
  {
    "slug": "anthropic-seeks-larger-manhattan-office-as-part-of-nyc-expansion-bloomberg",
    "title": "Anthropic seeks larger Manhattan office as part of NYC expansion - Bloomberg",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/anthropic-seeks-larger-manhattan-office-as-part-of-nyc-expansion--bloomberg-93CH-4456001",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-20T18:21:48.581Z",
    "topic": "finance"
  },
  {
    "slug": "execs-at-davos-say-ais-biggest-problem-isnt-hype-its-security",
    "title": "Execs at Davos say AI's biggest problem isn't hype ‚Äî it's security",
    "description": "EY and KPMG executives at Davos said that AI security is a big risk, especially AI agents and, looking ahead, quantum computing.",
    "fullText": "I'm reporting from Davos, Switzerland, where thousands of business leaders and politicians have arrived at the World Economic Forum to shake hands, talk shop, and maybe even eke out a few ski runs.\n\nSome executives I've spoken to this week had some big concerns about AI, but none of them had anything to do with a potential bubble.\n\nRaj Sharma, EY's global managing partner of growth and innovation, said there's not enough talk about AI security ‚Äî specifically, the management of AI agents and their lifecycle.\n\n\"It has access to your data. It has no name, so there is no identity or anything associated with that,\" Sharma said.\n\nCompare that to humans, where every computer system and piece of data they touch is often tracked.\n\n\"We have to build industrial-level security for AI agents in that particular area. To me, that's still a gap that somebody needs to work on,\" Sharma said. \"Everybody's talking a good game. But if you look under the covers, it's still not mature.\"\n\n\"That keeps me up at night,\" Sharma added.\n\nHe's not alone. Tim Walsh, the CEO of KPMG US, told me the biggest issue he talks to CEOs about regularly is cyber risk, specifically related to AI.\n\nAI agents are the latest twist in executives' ongoing concerns over cybersecurity, and it's proving to be an incredibly challenging problem. Somewhat ironically, the only way to fight the threat is with ‚Ä¶ more AI.\n\nIn some cases, the risk has gotten so big that it's shifting timelines on companies' AI plans.\n\n\"It's not that they're not moving forward, but they are taking a moment to make sure that their environment is secure, and perhaps even leaving data on-prem a little bit longer so they're confident that got their data security in place,\" Walsh told me.\n\nWalsh said another \"real concern\" is the threat of quantum computing from a security perspective.\n\nWhile he acknowledged we're still a few years out from the tech being fully developed, its power is incredible.\n\n\"Quantum breaks everything,\" Walsh said. \"I mean, all encryption.\"\n\nThat's led companies to look at their systems and reencrypting things, no easy task.\n\n\"We're spending quite a bit of time as well, helping companies think through: What does that look like? How do you structure it? How long will it take?\" Walsh said.",
    "readingTime": 2,
    "keywords": [
      "walsh",
      "security",
      "it's",
      "agents",
      "look",
      "talk",
      "executives",
      "concerns",
      "specifically",
      "that's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-security-risks-worry-ey-kpmg-execs-cybersecurity-davos-2026-1",
    "thumbnail_url": "https://i.insider.com/696f2d9ca645d11881879a22?width=1200&format=jpeg",
    "created_at": "2026-01-20T12:27:02.356Z",
    "topic": "finance"
  },
  {
    "slug": "citi-has-quietly-built-a-4000person-internal-ai-workforce",
    "title": "Citi has quietly built a 4,000-person internal AI workforce",
    "description": "Around 4,000 employees globally have volunteered to fan out across their business units as \"AI accelerators.\"",
    "fullText": "At Citi, some of the people leading the Wall Street bank's AI push aren't part of a specialized tech team. They're colleagues a few desks over.\n\nThose employees are part of the bank's AI Champions and Accelerators program, which got off the ground in early 2024 and now counts around 4,000 people among its ranks of voluntary AI helpers. At its most basic level, the program aims to have the designated \"accelerators\" help colleagues within their business units leverage and understand AI tools. The program's approximately 25-30 \"champions\" help lead the accelerators in their line of business.\n\nCiti's program is one of many ways banks are racing to adopt AI, from offering engineers capstone-style courses to luring top tech talent by promising a seat at powerful managerial tables. To date, Citi's AI tools are available in 84 countries for 182,000 employees. Adoption of the firm's proprietary tools is above 70%, Citi CEO Jane Fraser told analysts during the bank's earnings call last week.\n\nAnd it's clear that she has high expectations for all employees, including accelerators. In a January memo, she told staff she expected \"a more disciplined, more confident\" workforce in 2026, and that AI will likely \"reshape how work gets done.\"\n\nAmong the bank's range of initiatives to encourage AI uptake, the accelerators and champions model is uniquely embedded throughout teams and based on peer-to-peer interactions, said Carey Ryan, one of the initiative's leaders and the chief of staff for the technology organization.\n\n\"A small central team would never be able to reach where we are now,\" Ryan said.\n\nTech leaders at Citi came up with the program when brainstorming how to engage a wider swath of its population with AI, Ryan said. Originally, her team only planned to have 2,500 accelerators, but they saw more interest than expected and still maintain a waitlist for the program.\n\nWhile colleagues nominate champions for the position, anyone can volunteer to be an accelerator. The only requirement is being excited about AI, Ryan said.\n\nJosh Goldsmith is the AI champion for internal audit, where he's also the head of digital solutions and innovation. He's been a part of the program since its inception, and said that \"demystifying AI\" is among its greatest successes so far.\n\n\"It's a lot different when you hear from a colleague as to how you can leverage these tools, as opposed to having someone who's, let's say, a technologist trying to push this,\" he said. \"To be able to see someone put it in action: 'Hey, they can do it! I'm just like them, I can do it as well.'\"\n\nRyan also said that the peer-to-peer approach is part of what makes the initiative work, since a more general team couldn't understand all of the job-specific AI use cases across the bank. She added that accelerators have helped host more than 100 Citi AI Days, where they hold demonstrations and answer questions.\n\nAccelerators meet with their cohorts two times each month to participate in demos, learn about new tools, get training, or talk about their recent work. Goldsmith oversees around 50 participants; between attending their meetings and his own bi-monthly champion meetings, he said he devotes between three and five hours to the program each week, on top of his usual job.\n\nThe program members can also opt into trainings on topics including agentic AI to earn visual \"AI badges,\" which they can include in their email signatures. There are no specific engagement metrics, though, and people can drop out of the program if it becomes too demanding a time commitment.\n\n\"One accelerator might have five interactions, and maybe they're five small interactions,\" Ryan said. \"Another accelerator might have one really big interaction, where they're doing something with hundreds of people.\"\n\nAmong the AI peer coaches in internal audit, between 70% and 80% have stayed in the program, Goldsmith said. He added that, despite the extra hours, participating has given him a broader perspective on AI across Citi, and \"a clear vision in terms of what's coming next.\"\n\nFor Carey, there's something of a symbiotic relationship between program leads, participants, and the rest of the bank. Accelerators will explain what they're hearing from their lines of business ‚Äî where people are struggling, what they might need ‚Äî as Citi continues to fine-tune its approach to AI. They have, for example, helped Citi tweak AI tools, suggesting enhancements like adding notifications and allowing employees to upload larger files.\n\n\"It's an important conduit for feedback back in,\" she said.",
    "readingTime": 4,
    "keywords": [
      "internal audit",
      "ai ryan",
      "program",
      "tools",
      "bank's",
      "team",
      "they're",
      "employees",
      "tech",
      "colleagues"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/citi-bank-ai-accelerators-volunteers-2025-12",
    "thumbnail_url": "https://i.insider.com/6965437d04eda4732f2eea70?width=1200&format=jpeg",
    "created_at": "2026-01-20T12:27:02.237Z",
    "topic": "finance"
  },
  {
    "slug": "davos-day-2-live-updates-byd-microsoft-and-uber-ceos-speak",
    "title": "Davos day 2 live updates: BYD, Microsoft, and Uber CEOs speak",
    "description": "The second day of Davos features discussions on AI, EVs, and more. Speakers include Microsoft's Satya Nadella and Salesforce's Marc Benioff.",
    "fullText": "It's Business Insider's second day at Davos, and it's a busy one.\n\nWe're on the ground tracking everything World Economic Forum: the speakers, the food, the fashion, the chatter on the streets, and more.\n\nDavos' speaker panels kicked off in earnest this morning, with power players like Microsoft CEO Satya Nadella, BlackRock CEO Larry Fink, Palantir CEO Alex Karp, and Salesforce CEO Marc Benioff all on the agenda.\n\nFollow along as we give you a window into what it's really like to attend the World Economic Forum.\n\nAs you can probably tell, we here at Business Insider are really enjoying the winter fashions on show in sunny Davos.\n\nOur latest fashion dispatch comes from Kim Last, Editorial Director of BI Live, Business Insider's live journalism platform, who spied Monica Weinberg, a professor at Florida Atlantic University, rocking an Akris black lame suit and a matching Lady Dior bag.\n\nYou can keep track of all the best looks we've spotted at Davos by clicking below:\n\nAs the top dogs of the finance world live it up in the mountains, there's a big day brewing on Wall Street. With tensions between the US and Europe rising amid Trump's threats of further tariffs over Greenland, global stock markets are bumpy on Tuesday.\n\nIn European trading, the benchmark indexes in Germany, France, and the UK have all dropped more than 1% as of 7 a.m. ET.\n\nAs the top dogs of the finance world live it up in the mountains, there's a big day brewing on Wall Street. With tensions between the US and Europe rising amid Trump's threats of further tariffs over Greenland, global stock markets are bumpy on Tuesday.\n\nIn European trading, the benchmark indexes in Germany, France, and the UK have all dropped more than 1% as of 7 a.m. ET.\n\nUS futures are also pointing to a painful day, with the Dow, S&P 500, and Nasdaq all set to open more than 1% lower.\n\nFutures in the S&P 500 VIX, which measures volatility in the index, have jumped 7% on Tuesday, while gold, the ultimate safe haven, is up over 3% to $7,740 per ounce.\n\nAs traffic jams snarl the streets of Davos, conversations about the autonomous future of cars are getting a lot of airtime.\n\nEarlier, Uber CEO Dara Khosrowshahi was asked about the investment landscape around robotaxis, and said he doesn't think the investment market in autonomous vehicles is overheated.\n\nAs traffic jams snarl the streets of Davos, conversations about the autonomous future of cars are getting a lot of airtime.\n\nEarlier, Uber CEO Dara Khosrowshahi was asked about the investment landscape around robotaxis, and said he doesn't think the investment market in autonomous vehicles is overheated.\n\nHowever, he says the \"broader AI market ‚Äî foundation models, hardware, semiconductors ‚Äî is much hotter, with aggressive growth assumptions.\"\n\nAsked if Uber might invest in Waymo, Khosrowshahi said \"no comment.\"\n\n\"They have plenty of money,\" he said. \"But we're investing across the ecosystem, and we're very bullish.\"\n\nWith schedules full of back-to-back meetings and most shops on the promenade taken over by businesses, eating during the day can be tough.\n\nSome businesses set up grab-and-go food and drink stations. That's what Pinterest did, and this morning, sweet croissants were on the menu.\n\nWith schedules full of back-to-back meetings and most shops on the promenade taken over by businesses, eating during the day can be tough.\n\nSome businesses set up grab-and-go food and drink stations. That's what Pinterest did, and this morning, sweet croissants were on the menu.\n\nI opted for the chocolate crush, but I was told the cinnamon apple glow was the most popular choice, with only two left when I got there a little after 11 a.m.\n\nAnd yes, it tasted as good as it looked.\n\nSo when the CEO of Philip Morris International US travels, even for long trips, she takes a carry-on. Her trick: Pick a color for the week and coordinate outfits around that, with travel-well fabrics. For Davos this week, the color is black.\n\nStephen Ehikian is CEO of C3 AI, but he's no stranger to the Trump administration.\n\nEhikian, who was also previously a VP of product at Salesforce, served for eight months as the Acting Administrator of the General Services Administration before taking on the CEO role last September.\n\nStephen Ehikian is CEO of C3 AI, but he's no stranger to the Trump administration.\n\nEhikian, who was also previously a VP of product at Salesforce, served for eight months as the Acting Administrator of the General Services Administration before taking on the CEO role last September.\n\nI asked him about President Donald Trump's upcoming speech.\n\nHe had this to say: \"I'm hoping there's an expression of strength in numbers, and we're better together kind of story. Now, that said, I believe this idea that taking a strong 'America First' approach is good for this country.\n\n\"I think it's setting a tone and a change of direction from where we've been the last 50 years. So, I think it's refreshing. I don't even want to anticipate what's going to happen tomorrow because I have no idea.\"\n\nSpeaking earlier this morning, Uber CEO Dara Khosrowshahi said he is skeptical about some companies claiming rapid AI transformation, and that getting it right comes down to culture.\n\nUber tried building customer service AI that followed its old policies, Khosrowshahi told the audience at Davos, but it was \"only okay.\"\n\nSpeaking earlier this morning, Uber CEO Dara Khosrowshahi said he is skeptical about some companies claiming rapid AI transformation, and that getting it right comes down to culture.\n\nUber tried building customer service AI that followed its old policies, Khosrowshahi told the audience at Davos, but it was \"only okay.\"\n\nThat changed after the developers started from scratch with AI in mind.\n\n\"Companies are essentially rule systems,\" he said. \"To unlock AI's full potential, you have to break those rules and start over.\"\n\nDavos attracts a real cross-section of the world's rich and powerful, ranging from investors and politicians to sporting legends. Soccer great and longtime UNICEF ambassador David Beckham was spotted recording a podcast this morning.\n\nAt last year's Davos, Beckham was awarded the Crystal Award, which recognized his contributions to \"advocating for children's rights, education and well-being.\"\n\nMicrosoft CEO Satya Nadella, who spoke in a morning panel led by BlackRock CEO Larry Fink, shared how he has always prepared for Davos meetings ‚Äî and how that's changed with AI.\n\nHe said his field team used to prep him for 50 or so meetings, according to a \"particular workflow.\"\n\nMicrosoft CEO Satya Nadella, who spoke in a morning panel led by BlackRock CEO Larry Fink, shared how he has always prepared for Davos meetings ‚Äî and how that's changed with AI.\n\nHe said his field team used to prep him for 50 or so meetings, according to a \"particular workflow.\"\n\n\"Nothing had really changed since I joined in '92 to essentially even a few years back,\" he said about the year he joined the tech giant as an engineer. \"Whereas now, I just go to Copilot and say, \"Hey, I'm meeting Larry. Please give me a brief.\"\n\nHe added that the briefs generated by Microsoft's AI assistant give him a comprehensive overview of the relationship between his firm and BlackRock CEO Larry Fink's team.\n\nAI tools are also changing the traditional bottom-to-top flow of information, he said.\n\n\"In fact, what I do is I take that and immediately share that back with all my colleagues across all the functions,\" he said. \"Think about it. It's a complete inversion of how information is flowing in the organization.\"\n\nRobot drivers will ultimately outperform humans on safety, Uber CEO Dara Khosrowshahi said on Tuesday in Davos.\n\n\"If you think about the world 20 years from now, your Uber is going to be driven largely not by a human being, but by a robot driver ‚Äî a piece of software on top of a car,\" Khosrowshahi said, adding that vehicles are becoming increasingly sophisticated and more like \"computers on wheels.\"\n\nRobot drivers will ultimately outperform humans on safety, Uber CEO Dara Khosrowshahi said on Tuesday in Davos.\n\n\"If you think about the world 20 years from now, your Uber is going to be driven largely not by a human being, but by a robot driver ‚Äî a piece of software on top of a car,\" Khosrowshahi said, adding that vehicles are becoming increasingly sophisticated and more like \"computers on wheels.\"\n\nKhosrowshahi said autonomous systems have clear advantages over human drivers. \"There's no doubt in my mind that the robot driver can be safer than a human driver,\" he said. Robot drivers don't get tired or distracted, don't text while driving, and can operate continuously while improving over time, he added.\n\nThe key question, Khosrowshahi said, is what level of safety is \"enough\" for robot drivers ‚Äî whether matching human performance is sufficient or whether autonomous vehicles should be held to a higher standard.\n\nIn the longer term, he said, human driving could resemble horseback riding today, becoming a niche activity done for enjoyment.\n\n\"There's no doubt that 10 years from now, there will be questions as to whether humans are safe enough,\" he said.\n\nTrump is expected to arrive in Davos on Wednesday. While Treasury Secretary Scott Bessent wants business leaders to take a breath and chill out about Greenland, that may not be in the cards.\n\nTrump posted on Truth Social on Thursday that he had \"a very good telephone call with Mark Rutte, the Secretary General of NATO, concerning Greenland.\"\n\nTrump is expected to arrive in Davos on Wednesday. While Treasury Secretary Scott Bessent wants business leaders to take a breath and chill out about Greenland, that may not be in the cards.\n\nTrump posted on Truth Social on Thursday that he had \"a very good telephone call with Mark Rutte, the Secretary General of NATO, concerning Greenland.\"\n\n\"I agreed to a meeting of the various parties in Davos, Switzerland. As I expressed to everyone, very plainly, Greenland is imperative for National and World Security,\" Trump wrote.\n\nTrump on Sunday had sent messages to Norway's leader, saying the US requires \"Complete and Total Control of Greenland.\" Greenland is a semi-autonomous Danish territory.\n\nGovernments keep changing their rules on EVs, says BYD executive vice president Stella Li, and that sets carmakers back.\n\nLi said in a panel at Davos that when countries go \"back and forth\" on their EV policy, it creates a pattern that \"will confuse manufacturers.\" In contrast, when governments give a \"very clear line,\" automakers can focus on execution, Li said.\n\nBessent, speaking to the press on Tuesday morning, urged calm amid President Donald Trump's latest slate of¬†trade tariffs on Greenland.\n\n\"You say: 'If there is a protracted trade war.' Why are we jumping there? Why are you taking it to the worst case? Calm down the hysteria, take a deep breath, this is where we were last year,\" Bessentt said. \"I'm sure you would have asked me the same question if we were here on April 2nd. And you know what? It all worked out.\"\n\nBessent, speaking to the press on Tuesday morning, urged calm amid President Donald Trump's latest slate of¬†trade tariffs on Greenland.\n\n\"You say: 'If there is a protracted trade war.' Why are we jumping there? Why are you taking it to the worst case? Calm down the hysteria, take a deep breath, this is where we were last year,\" Bessentt said. \"I'm sure you would have asked me the same question if we were here on April 2nd. And you know what? It all worked out.\"\n\nWhen asked about what European business leaders should do, Bessent's take was to \"sit back\" and \"relax.\"\n\n\"What I am urging everyone here to do is sit back, take a deep breath, and let things play out,\" Bessent said.\n\n\"I am confident that the leaders will not escalate and that this will work out in a manner that ends up in a very good place for all, for national security, for the US, and for Europe,\" he said.\n\nAnything you do within your company's digital ecosystem is likely being tracked, from the data you touch to the software programs you use.\n\nThat's a real concern as we rely on them more and more, Raj Sharma, EY's global managing partner of growth and innovation, told me.\n\n\"We have to build industrial-level security for AI agents in that particular area,\" he said. \"That keeps me up at night,\" Sharma added.\n\nFor Tim Walsh, the chair and CEO of KPMG US, it's the threat of quantum computing. While still a few years out, its power is undeniable.\n\n\"Quantum breaks everything,\" Walsh said. \"I mean, all encryption.\"\n\n\"M&A is high on the agenda,\" said Sharon Marcil, North America chair at BCG. \"We're hearing it from so many CEOs.\" She pointed to a strong stock market and an overall tilt in Washington toward deregulation and robust business activity.\n\nWinston Weinberg, CEO and cofounder of the legal AI startup Harvey, echoes the sentiment, saying he is hearing that 2026 will be an \"insane\" year for dealmaking. (Good for lawyers!)\n\n\"M&A is high on the agenda,\" said Sharon Marcil, North America chair at BCG. \"We're hearing it from so many CEOs.\" She pointed to a strong stock market and an overall tilt in Washington toward deregulation and robust business activity.\n\nWinston Weinberg, CEO and cofounder of the legal AI startup Harvey, echoes the sentiment, saying he is hearing that 2026 will be an \"insane\" year for dealmaking. (Good for lawyers!)\n\nSimilar predictions predominated this time last year. The tariff tumult put a pause on M&A early on, but then dealmaking got its mojo back.\n\nFink took the stage at Davos to welcome more than a thousand chief executives to the World Economic Forum. In his opening remarks, he questioned whether anyone outside the room would care about this meeting of global leaders.\n\n\"Because if we're being honest, for many people this meeting feels out of step with the moment: elites in an age of populism, an established institution in an era of deep institutional distrust,\" the BlackRock CEO said.\n\nFink took the stage at Davos to welcome more than a thousand chief executives to the World Economic Forum. In his opening remarks, he questioned whether anyone outside the room would care about this meeting of global leaders.\n\n\"Because if we're being honest, for many people this meeting feels out of step with the moment: elites in an age of populism, an established institution in an era of deep institutional distrust,\" the BlackRock CEO said.\n\n\"And there's truth in that critique,\" he added. \"I've believed in this forum for a long time. I certainly wouldn't be leading it if I didn't. But it's also obvious that the world now places far less trust in us to help shape what comes next.\"\n\nFink said the capitalism now faces a big test: Whether it can \"evolve to turn more people into owners of growth, instead of spectators watching it happen.\"\n\n\"And that kind of change is hard. Especially in a world of competing ideologies and assumptions about how the system should work,\" he said.\n\nFink's remarks ground what is expected to be a monumental week, in which deals are made and new alliances are forged amid turmoil in the wider political sphere.",
    "readingTime": 13,
    "keywords": [
      "wall street",
      "mark rutte",
      "nato concerning",
      "sharon marcil",
      "marcil north",
      "washington toward",
      "startup harvey",
      "harvey echoes",
      "satya nadella",
      "europe rising"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/davos-wef-live-updates-jan-20-2026-1",
    "thumbnail_url": "https://i.insider.com/696f1c7ee1ba468a96aa5193?width=1200&format=jpeg",
    "created_at": "2026-01-20T12:27:02.097Z",
    "topic": "finance"
  },
  {
    "slug": "uk-exposed-to-serious-harm-by-failure-to-tackle-ai-risks-mps-warn",
    "title": "UK exposed to ‚Äòserious harm‚Äô by failure to tackle AI risks, MPs warn",
    "description": "Government, Bank of England and FCA criticised for taking ‚Äòwait-and-see‚Äô approach to AI use in financial sector\nConsumers and the UK financial system are being exposed to ‚Äúserious harm‚Äù by the failure of government and the Bank of England to get a grip on the risks posed by artificial intelligence, an influential parliamentary committee has warned.\nIn a new report, MPs on the Treasury committee criticise ministers and City regulators, including the Financial Conduct Authority (FCA), for taking a ‚Äúwait-and-see‚Äù approach to AI use across the financial sector.\n Continue reading...",
    "fullText": "Government, Bank of England and FCA criticised for taking ‚Äòwait-and-see‚Äô approach to AI use in financial sector\n\nConsumers and the UK financial system are being exposed to ‚Äúserious harm‚Äù by the failure of government and the Bank of England to get a grip on the risks posed by artificial intelligence, an influential parliamentary committee has warned.\n\nIn a new report, MPs on the Treasury committee criticise ministers and City regulators, including the Financial Conduct Authority (FCA), for taking a ‚Äúwait-and-see‚Äù approach to AI use across the financial sector.\n\nThat is despite looming concerns over how the burgeoning technology could disadvantage already vulnerable consumers, or even trigger a financial crisis, if AI-led firms end up making similar financial decisions in response to economic shocks.\n\nMore than 75% of City firms now use AI, with insurers and international banks among the biggest adopters. It is being used to automate administrative tasks or even help with core operations, including processing insurance claims and assessing customers‚Äô credit-worthiness.\n\nBut the UK has failed to develop any specific laws or regulations to govern their use of AI, with the FCA and Bank of England claiming general rules are sufficient to ensure positive outcomes for consumers. That means businesses have to determine how existing guidelines apply to AI, leaving MPs worried this could put consumers and financial stability at risk.\n\n‚ÄúIt is the responsibility of the Bank of England, the FCA and the government to ensure the safety mechanisms within the system keeps pace,‚Äù said Meg Hillier, chair of the Treasury committee. ‚ÄúBased on the evidence I‚Äôve seen, I do not feel confident that our financial system is prepared if there was a major AI-related incident and that is worrying.‚Äù\n\nThe report flagged a lack of transparency around how AI could influence financial decisions, potentially affecting vulnerable consumers‚Äô access to loans or insurance. It said it was also unclear whether data providers, tech developers or financial firms would be held responsible when things went wrong.\n\nMPs said AI also increased the likelihood of fraud, and the dissemination of unregulated and misleading financial advice.\n\nIn terms of financial stability, MPs found that rising AI use increased firms‚Äô cybersecurity risks, and left them overly reliant on a small number of US tech companies, such as Google, for essential services. Its uptake could also amplify ‚Äúherd behaviour‚Äù, with businesses making similar financial decisions during economic shocks and ‚Äúrisking a financial crisis‚Äù.\n\nThe Treasury committee is now urging regulators to take action, including the launch of new stress tests that would assess the City‚Äôs readiness for AI-driven market shocks. MPs also want the FCA to publish ‚Äúpractical guidance‚Äù by the end of the year, clarifying how consumer protection rules apply to AI use, and who would be held accountable if consumers suffer any harm.\n\n‚ÄúBy taking a wait-and-see approach to AI in financial services, the three authorities are exposing consumers and the financial system to potentially serious harm‚Äù, the report said.\n\nThe FCA said it had already ‚Äúundertaken extensive work to ensure firms are able to use AI in a safe and responsible way‚Äù, but would review the report‚Äôs findings ‚Äúcarefully‚Äù.\n\nA spokesperson for the Treasury said: ‚ÄúWe‚Äôve been clear that we will strike the right balance between managing the risks posed by AI and unlocking its huge potential.‚Äù\n\nThey added that this involved working with regulators to ‚Äústrengthen our approach as the technology evolves‚Äù, and appointing new ‚ÄúAI champions‚Äù covering financial services ‚Äúto ensure we seize the opportunities it presents in a safe and responsible way‚Äù.\n\nA spokesperson for the Bank of England said it had ‚Äúalready taken active steps to assess AI-related risks and reinforce the resilience of the financial system, including publishing a detailed risk assessment and highlighting the potential implications of a sharp fall in AI-affected asset prices. We will consider the committee‚Äôs recommendations carefully and will respond in full in due course.‚Äù",
    "readingTime": 4,
    "keywords": [
      "treasury committee",
      "serious harm",
      "economic shocks",
      "wait-and-see approach",
      "risks posed",
      "vulnerable consumers",
      "financial sector",
      "financial crisis",
      "financial decisions",
      "financial stability"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2026/jan/20/uk-ai-risks-mps-government-bank-of-england-fca",
    "thumbnail_url": "https://i.guim.co.uk/img/media/806cb798ee36a482ee711e0dde66c6d1719010f6/1124_0_5598_4481/master/5598.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=17c31cb165b8a65398c873adc591569d",
    "created_at": "2026-01-20T12:26:57.079Z",
    "topic": "politic"
  },
  {
    "slug": "microsoft-ceo-nadella-on-how-ai-can-change-workflows",
    "title": "Microsoft CEO Nadella on How AI Can Change Workflows",
    "description": "Microsoft Chairman and Chief Executive Officer Satya Nadella discusses artificial intelligence and the potential it has to change workflows. \"The current structure may not make sense, because you want people to be able to work in a way that allows them to have this information flow freely,\" Nadella tells BlackRock CEO Larry Fink at the World Economic Forum in Davos, Switzerland.",
    "fullText": "Microsoft CEO Nadella on How AI Can Change Workflows BloombergMST Microsoft Chairman and Chief Executive Officer Satya Nadella discusses artificial intelligence and the potential it has to change workflows. \"The current structure may not make sense, because you want people to be able to work in a way that allows them to have this information flow freely,\" Nadella tells BlackRock CEO Larry Fink at the World Economic Forum in Davos, Switzerland.",
    "readingTime": 1,
    "keywords": [
      "workflows",
      "nadella",
      "microsoft"
    ],
    "qualityScore": 0,
    "link": "https://finance.yahoo.com/video/microsoft-ceo-nadella-ai-change-103727613.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/w.TVAL8dnQcf8YvSIgA4qQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/bloomberg_markets_video_2/a6b58d78c13f17eaa9d5a552ee484ab0",
    "created_at": "2026-01-20T12:26:55.128Z",
    "topic": "finance"
  },
  {
    "slug": "openai-gpt52codex-high-vs-claude-opus-45-vs-gemini-3-pro-in-production",
    "title": "OpenAI GPT-5.2-Codex (High) vs. Claude Opus 4.5 vs. Gemini 3 Pro (In Production)",
    "description": "A real-world comparison of GPT-5.2-Codex (high), Claude Opus 4.5, and Gemini 3 Pro on two coding tasks, focusing on quality, speed, and cost.",
    "fullText": "If you want a quick take: Claude Opus 4.5 was the most consistent, GPT-5.2-codex (high) delivered strong code with slower turnaround, and Gemini 3 Pro was the most efficient but less polished.\n\nIf you want a quick take, here‚Äôs how the three models performed in our tests:\n\nüí° If you want the safest pick for real ‚Äúship a feature in a big repo‚Äù work, Opus 4.5 felt the most reliable in my runs. If you care about speed and cost and you‚Äôre okay polishing UI yourself, Gemini 3 Pro is a solid bet.\n\nOkay, so right now the WebDev leaderboard on LMArena is basically owned by the big three: Claude Opus 4.5 from Anthropic, GPT-5.2-codex (high) from OpenAI, and finally everybody's favorite, Gemini 3 Pro from Google.\n\nSo, I grabbed these three and put them into the same existing project (over 8K stars and 50K+ LOC) and asked them to build a couple of real features like a normal dev would.\n\nSame repo. Same prompts. Same constraints.\n\nFor each task, I took the best result out of three runs per model to keep things fair.\n\nThen I compared what they actually did: code quality, how much hand-holding they needed, and whether the feature even worked in the end.\n\n‚ö†Ô∏è NOTE: Don't take the result of this test as a hard rule. This is just a small set of real-world coding tasks that shows how each model did for me in that exact setup and gives you an overview of the difference in the top 3 models' performance in the same tasks.\n\nFor the test, we will use the following CLI coding agents:\n\nHere‚Äôs the repo used for the entire test: iib0011/omni-tools\n\nWe will check the models on two different tasks:\n\nEach model is asked to create a global action menu that opens with a keyboard shortcut. This feature expands on the current search by adding actions, global state, and keyboard navigation. This task checks how well the model understands current UX patterns and avoids repetition without breaking what's already in place.\n\nEach model had to add real usage tracking across the app, persist it locally, and then build an analytics dashboard that shows things like the most used tools, recent activity, and basic filters.\n\nWe‚Äôll compare code quality, token usage, cost, and time to complete the build.\n\nüí° NOTE: I will share the source code changes for each task by each model in a .patch file. This way, you can easily view them on your local system by cloning the repository and applying the patch file using git apply <path_file_name>. This method makes sharing changes easier.\n\nThe task is simple: all models start from the same base commit and then follow the same prompt to build what is asked in the prompt.\n\nAnd obviously, as mentioned, I will evaluate the response from the model from the \"Best of 3.\"\n\nLet's start off the test with something interesting:\n\nGPT-5.2 handled this surprisingly well. The implementation was solid end to end, and it basically one-shotted the entire feature set, including i18n support, without needing multiple correction passes.\n\nThat said, it did take a bit longer than some other models (~20 minutes), which is expected since reasoning was explicitly set to high. The model spends more time thinking through architecture, naming, and edge cases rather than rushing to output code. The trade-off felt worth it here.\n\nThe token usage was noticeably higher due to the reasoning set to high, but the output code reflected that.\n\nYou can find the code it generated here: GPT-5.2 High Code\n\nüí° NOTE: I ran the exact same prompt with the same model using the default (medium) reasoning level. The difference was honestly massive. With reasoning set to high, the quality of the code, structure, and pretty much everything jumps by miles. It‚Äôs not even a fair comparison.\n\nClaude went all in and prepared a ton of different strategies. At the start, it did run into build issues, but it kept running the build until it was able to fix all the build and lint issues.\n\nThe entire run took me about 7 minutes 50 seconds, which is the fastest among the models for this test. The features all worked as asked, and obviously, the UI looked super nice and exactly how I expected.\n\nYou can find the code it generated here: Claude Opus 4.5 Code\n\nTo be honest, this exceeded my expectations; even the i18n texts are added and displayed in the UI just as expected. Absolute cinema!\n\nGemini 3 got it working, but it's clearly not on the same level as GPT-5.2 High or Claude Opus 4.5. The UI it built is fine and totally usable, but it feels a bit barebones, and you don't get many choices in the palette compared to the other two.\n\nOne clear miss is that language switching does not show up inside the action palette at all, which makes the i18n support feel incomplete even though translations technically exist.\n\nYou can find the code it generated here: Gemini 3 Pro Code\n\nOverall, Gemini 3 lands in a very clear third place here. It works, the UI looks fine, and nothing is completely broken, but compared to the depth, completeness, and polish of GPT-5.2 High and Claude Opus 4.5, it feels behind.\n\nThis test is a step up from the action palette.\n\nYou can find the prompt I've used here: Prompt\n\nGPT-5.2 absolutely nailed this one.\n\nThe final result turned out amazing. Tool usage tracking works exactly as expected, data persists correctly, and the dashboard feels like a real product feature. Most used tools, recent usage, filters, everything just works.\n\nOne really nice touch is that it also wired analytics-related actions into the Action Palette from Test 1.\n\nIt did take a bit longer than the first test, around 26 minutes, but again, that‚Äôs the trade-off with high reasoning. You can tell the model spent time thinking through data modeling, reuse, and avoiding duplicated logic. Totally worth it here.\n\nYou can find the code it generated here: GPT-5.2 High Code\n\nGPT-5.2 High continues to be slow but extremely powerful, and for a task like this, that‚Äôs a very good trade.\n\nClaude Opus 4.5 did great here as well.\n\nThe final implementation works end to end, and honestly, from a pure UI and feature standpoint, it‚Äôs hard to tell the difference between this and GPT-5.2 High. The dashboard looks clean, the data makes sense, and the filters work as expected.\n\nYou can find the code it generated here: Claude Opus 4.5 Code\n\nGemini 3 Pro gets the job done, but it clearly takes a more minimal approach compared to GPT-5.2 High and Claude Opus 4.5.\n\nThat said, the overall experience feels very bare minimum. The UI is functional but plain, and the dashboard lacks the polish and depth you get from the other two models.\n\nAlso, it didn't quite add the button to view the analytics right in the action palette, similar to the other two models.\n\nYou can find the code it generated here: Gemini 3 Pro Code\n\nOverall, Gemini 3 Pro remains efficient and reliable, but in a comparison like this, efficiency alone is not enough. ü§∑‚Äç‚ôÇÔ∏è\n\nAt least from this test, I can conclude that the models are now pretty much able to one-shot a decent complex work, at least from what I tested.\n\nStill, there have been times when the models mess up so badly that if I were to go ahead and fix the problems one by one, it would take me nearly the same time as building it from scratch.\n\nIf I compare the results across models, Opus 4.5 definitely takes the crown. But I still don‚Äôt think we‚Äôre anywhere close to relying on it for real, big production projects. The recent improvements are honestly insane, but the results still don‚Äôt fully back them up. ü•¥\n\nFor now, I think these models are great for refactoring, planning, and helping you move faster. But if you solely rely on their generated code, the codebase just won‚Äôt hold up long term.\n\nI don't see any of these recent models as ‚Äúuse it and ship it‚Äù for \"production,\" in a project with millions of lines of code, at least not in the way people hype it up.\n\nLet me know your thoughts in the comments.\n\nSoftware and DevOps engineer with 4+ years of experience building for the web and cloud, mainly with TypeScript, Python, Go, Docker, and Kubernetes. I share agentic system builds and write out of passion about AI models, workflows, and the tooling behind them.",
    "readingTime": 8,
    "keywords": [
      "overall gemini",
      "patch file",
      "bit longer",
      "code overall",
      "usage tracking",
      "token usage",
      "pro code",
      "output code",
      "opus code",
      "code quality"
    ],
    "qualityScore": 1,
    "link": "https://www.tensorlake.ai/blog/gpt5.2-codex-high-vs-opus-4.5-vs-gemini-3-pro",
    "thumbnail_url": "https://tensorlake.ai/assets/blog/gpt5.2-codex-high-vs-opus-4.5-vs-gemini-3-pro/blog-header.png",
    "created_at": "2026-01-20T06:21:45.608Z",
    "topic": "tech"
  },
  {
    "slug": "vinod-khosla-is-looking-at-this-metric-to-gauge-if-were-in-an-ai-bubble",
    "title": "Vinod Khosla is looking at this metric to gauge if we're in an AI bubble",
    "description": "\"What Wall Street tends to do with it, I don't really care,\" Khosla said.",
    "fullText": "Vinod Khosla has his eye on one AI metric, and it's not stock prices.\n\nOn an episode of OpenAI's podcast released on Monday, the famed venture capitalist shared how he's gauging whether we're in an AI bubble ‚Äî or not.\n\n\"People equate bubble to stock prices, which has nothing to do with anything other than fear and greed among investors,\" he said. \"So I always look at, bubbles should be measured by the number of API calls.\"\n\nAPI, or Application Programming Interface calls, refer to the process in which one software application sends a message to another application to request data or to trigger an action. They are a common indicator of digital tools' use, especially with the rise of AI agents. High API calls can also be a mark of a poor or inefficient product.\n\nKhosla said the bubble shouldn't be called \"by what happened to stock prices because somebody got overexcited or underexcited and in one day they can go from loving Nvidia to hating Nvidia because it's overvalued.\"\n\nThe 70-year-old VC, whose notable investments include OpenAI, DoorDash, and Block, compared the AI bubble to the dot-com bubble. He said he looked out for internet traffic as a metric during the 1990s, and with AI bubble concerns, that benchmark is now API calls.\n\n\"If that's your fundamental metric of what's the real use of your AI, usefulness of AI, demand for AI, you're not going to see a bubble in API calls,\" he said. \"What Wall Street tends to do with it, I don't really care. I think it's mostly irrelevant.\"\n\nConcerns that the AI industry is overvalued because of massive investments became one of the buzziest themes in the second half of 2025. The phrase \"AI bubble\" appeared in 42 earnings calls and investor conference transcripts between October and December ‚Äî a 740% increase from the previous quarter, according to an AlphaSense analysis.\n\nTop business leaders remain split about whether the bubble is about to burst.\n\nMicrosoft cofounder Bill Gates said AI has extremely high value, but it's still in a bubble.\n\n\"But you have a frenzy,\" Gates told CNBC in late October. \"And some of these companies will be glad they spent all this money. Some of them, you know, they'll commit to data centers whose electricity is too expensive.\"\n\nEarlier this month, \"Big Short\" investor Michael Burry raised the alarm on an AI bubble in a Substack exchange.\n\nBurry wrote that companies, including Microsoft and Alphabet, are wasting trillions on microchips and data centers that will quickly become obsolete. He added that their spending has \"no clear path to utilization by the real economy.\"\n\nNvidia CEO Jensen Huang has dismissed concerns of a bubble. His company became the world's first $5 trillion market cap company in October on the back of the AI boom.\n\nIn an October Bloomberg TV appearance, Huang said that instead of overspeculation, AI is part of a transition from an old way of computing.\n\n\"We also know that AI has become good enough because of reasoning capability, and research capability, its ability to think ‚Äî it's now generating tokens and intelligence that is worth paying for,\" Huang said.",
    "readingTime": 3,
    "keywords": [
      "bubble",
      "it's",
      "metric",
      "stock",
      "concerns",
      "overvalued",
      "investments",
      "investor",
      "centers",
      "capability"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/vinod-khosla-looks-at-this-metric-to-gauge-ai-bubble-2026-1",
    "thumbnail_url": "https://i.insider.com/696eef8ce1ba468a96aa5078?width=1200&format=jpeg",
    "created_at": "2026-01-20T06:21:43.656Z",
    "topic": "finance"
  },
  {
    "slug": "openais-finance-chief-just-dropped-some-hints-about-how-the-company-plans-to-make-more-money",
    "title": "OpenAI's finance chief just dropped some hints about how the company plans to make more money",
    "description": "OpenAI's chief financial officer floated \"licensing models\" as a revenue idea as the company faces massive compute costs.",
    "fullText": "OpenAI's chief financial officer is musing about new ways the company could make money beyond ChatGPT subscriptions.\n\nIn an episode of \"The OpenAI Podcast\" published Monday, Sarah Friar floated the idea of \"licensing models,\" in which the company could take a share of downstream sales if a customer's product takes off.\n\n\"Let's say in drug discovery, if we licensed our technology, you have a breakthrough. The drug takes off, and we get a licensed portion of all its sales,\" Friar said.\n\n\"It's great alignment for us with our customer,\" she added.\n\nFriar's comments offer a glimpse of how OpenAI is thinking about funding its compute-hungry ambitions as it broadens its business model.\n\nFriar said OpenAI began with a single subscription after launching ChatGPT, but has since expanded to multiple price points, SaaS-style enterprise pricing, and credit-based pricing for customers who \"want to pay more to get more.\"\n\nAs OpenAI looks at commerce and ads, Friar said the model should always give the best answer, not a sponsored one, and maintain an ad-free tier.\n\nLast week, OpenAI announced it is preparing to test ads in ChatGPT, as the company seeks to boost revenue while facing spending commitments of about $1.4 trillion over the coming years.\n\nThe move marks a shift from the company's earlier stance. Less than two years ago, OpenAI CEO Sam Altman described advertising as a \"last resort.\"\n\n\"Ads plus AI is sort of uniquely unsettling to me,\" Altman said during an event at Harvard University in May 2024. \"I kind of think of ads as a last resort for us for a business model.\"\n\nSince then, Altman's tone has evolved alongside OpenAI's expansion and ballooning compute costs. In June, he said on OpenAI's podcast that he wasn't \"totally against\" advertising, but emphasized that it would need to be handled carefully.\n\nOpenAI also completed its restructuring in October, shifting the company toward a more traditional for-profit structure ‚Äî a change Altman said would make it easier to raise capital going forward.",
    "readingTime": 2,
    "keywords": [
      "business model",
      "openai's",
      "chatgpt",
      "openai",
      "sales",
      "drug",
      "licensed",
      "pricing",
      "advertising",
      "resort"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-chief-financial-officer-sarah-friar-licensing-models-revenue-2026-1",
    "thumbnail_url": "https://i.insider.com/696ef256c58df2ecd5ccc57f?width=1200&format=jpeg",
    "created_at": "2026-01-20T06:21:43.654Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-drops-a-surprise-curveball-on-nvidia",
    "title": "Elon Musk drops a surprise curveball on Nvidia",
    "description": "Tesla (TSLA) just delivered a rare double whammy to Nvidia (NVDA) over the past weekend. CEO Elon Musk revealed that Tesla‚Äôs much-talked-about AI5 self-driving chips are nearly complete, and that the next one, A16, is already underway. With the AI inference part covered, Musk said Sunday on X ...",
    "fullText": "Tesla (TSLA) just delivered a rare double whammy to Nvidia (NVDA) over the past weekend.\n\nCEO Elon Musk revealed that Tesla‚Äôs much-talked-about AI5 self-driving chips are nearly complete, and that the next one, A16, is already underway.\n\nWith the AI inference part covered, Musk said Sunday on X that Dojo 3 is being restarted, pushing Tesla back into large-scale AI training after previously pulling back.\n\nNvidia threw the first punch, though, when it rolled out ‚ÄúAlpamayo‚Äù at CES 2026 (an open-source autonomous vehicle AI toolkit), aiming to become the default autonomy platform powering a ton of brands.\n\nMusk responded swiftly, downplaying the risk.\n\nClearly, this is a mighty interesting time for the AV industry, with the tug-of-war between two giants in Nvidia and Tesla.\n\nFor Tesla, it‚Äôs all about building a closed loop that covers the entire AV stack.\n\nTesla-designed in-car compute (this includes AI5, which is ‚Äúnearly done,‚Äù and the AI6, which is already underway)\n\nTesla‚Äôs camera-first software stack\n\nTesla‚Äôs data flywheel is powered by its own fleet\n\nSo for Tesla, it‚Äôs all about keeping the autonomy part within its potent ecosystem, as Nvidia looks to power everyone else.\n\nFor investors, these promises aren‚Äôt new, which makes the follow-through all the more critical.\n\nTesla is looking to tighten its grip on the hardware behind self-driving.\n\nMorgan Stanley sets jaw-dropping Micron price target after event\n\nForget Blackwell, Nvidia future is Vera Rubin, agentic software\n\nQuantum Computing makes $110 million move nobody saw coming\n\nMorgan Stanley drops eye-popping Broadcom price target\n\nApple analyst sets bold stock target for 2026\n\nMusk announced on Saturday in an X post that the EV giant is nearing completion of its AI5 self-driving computer chip, and that the AI6 is already in development.\n\nAccording to Musk, the AI5 chips, which are manufactured by Taiwan Semiconductor Manufacturing Company, will enter high-volume production in 2027, replacing the AI4 hardware. Also, Tesla has lined up Samsung Electronics for U.S.-based chip manufacturing.\n\nIt‚Äôs pretty easy to get lost in the AI jargon, so it‚Äôs important to be clear about things at each step about what‚Äôs happening.\n\nThe A15 and A16 move is essentially about ‚Äúinference at the edge‚Äù. That‚Äôs basically running Tesla‚Äôs Full Self-Driving neural nets inside the car, instead of relying on a third-party compute stack.",
    "readingTime": 2,
    "keywords": [
      "tesla it‚Äôs",
      "morgan stanley",
      "stack",
      "target",
      "chips",
      "nearly",
      "underway",
      "inference",
      "back",
      "autonomy"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/elon-musk-drops-surprise-curveball-190300808.html",
    "thumbnail_url": "https://s.yimg.com/os/en/thestreet_881/dd84ae97738233f3f8b955ba0292a512",
    "created_at": "2026-01-20T06:21:41.682Z",
    "topic": "finance"
  },
  {
    "slug": "ygrep-fast-local-indexed-code-search-tool-optimized-for-ai-coding-assistants",
    "title": "Ygrep: Fast, local, indexed code search tool optimized for AI coding assistants",
    "description": "A fast, local, indexed code search tool optimized for AI coding assistants. Written in Rust using Tantivy for full-text indexing. - yetidevworks/ygrep",
    "fullText": "yetidevworks\n\n /\n\n ygrep\n\n Public\n\n A fast, local, indexed code search tool optimized for AI coding assistants. Written in Rust using Tantivy for full-text indexing.\n\n License\n\n MIT license\n\n 14\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n yetidevworks/ygrep",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/yetidevworks/ygrep",
    "thumbnail_url": "https://opengraph.githubassets.com/eda1bb1f12626e76b9793d44f791d0ed3332b6c28dc7896d1831d00d7c49258d/yetidevworks/ygrep",
    "created_at": "2026-01-20T00:57:31.412Z",
    "topic": "tech"
  },
  {
    "slug": "npm-install-a-wasm-based-linux-vm-for-your-agents",
    "title": "NPM install a WASM based Linux VM for your agents",
    "description": "Lightweight WASM-based Linux VM for AI agents - run shell commands in an isolated Alpine Linux environment - deepclause/agentvm",
    "fullText": "deepclause\n\n /\n\n agentvm\n\n Public\n\n Lightweight WASM-based Linux VM for AI agents - run shell commands in an isolated Alpine Linux environment\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n deepclause/agentvm",
    "readingTime": 1,
    "keywords": [
      "linux",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/deepclause/agentvm",
    "thumbnail_url": "https://opengraph.githubassets.com/20857a7fcbad637df4fb2f5ba4f4801e229fc67e34392bcfd8240a9636fa91b4/deepclause/agentvm",
    "created_at": "2026-01-20T00:57:31.399Z",
    "topic": "tech"
  },
  {
    "slug": "f5-tackles-ai-security-with-new-platform-extensions",
    "title": "F5 tackles AI security with new platform extensions",
    "description": "F5's Guardrails blocks prompts that attempt jailbreaks or injection attacks, for example, while its AI Red Team automates vulnerability discovery in AI systems.",
    "fullText": "Network and security teams managing enterprise applications face two emerging challenges: AI security and multi-cloud operations. F5 is addressing both with product announcements that extend its Application Delivery and Security Platform into AI runtime protection and multicloud managed services.\n\nThe company announced F5 AI Guardrails and F5 AI Red Team on January 14, following the January 13 launch of F5 NGINXaaS for Google Cloud. The AI security products came through F5‚Äôs acquisition of CalypsoAI in September 2025. NGINXaaS is a web-server-as-a-service offering that is now expanding beyond its initial Azure deployment in May 2025, with AWS support in development.\n\n‚ÄúWe‚Äôve never been a walled garden‚Äîwe believe in meeting customers where they are and integrating with their existing stack, whether that stack is F5 products or other vendors,‚Äù Shawn Wormke, senior vice president of product management at F5, told Network World.\n\nAI security requires a different approach than traditional network defenses. Web application firewalls (WAF) inspect HTTP requests for SQL injection. Intrusion detection systems analyze packet headers for known attack signatures. These tools operate at the packet and protocol level.\n\nAI systems present a different attack surface. A malicious prompt that tricks a model into revealing training data looks like legitimate traffic at the network layer. Wormke explained that AI security is another layer of security just like WAF. Where it differs is that traditional security threats live in packets, whereas AI threats live in the words, prompts and context exchanged between users, models and agents.\n\n‚ÄúAI models can be manipulated into exposing sensitive data or generating harmful outputs impacting brand reputation and trust,‚Äù he said. ‚ÄúSo you need a solution that‚Äôs purpose-built to secure and govern these new threats like prompt injection, new jailbreak techniques and model distillation.‚Äù\n\nF5 AI Guardrails deploys as a proxy between users and AI models. Wormke describes it as being inserted as a proxy layer at the ‚Äúfront door‚Äù of AI interaction, between AI applications, users and agents. It intercepts prompts before they reach the model and analyzes outputs before they return to users. The system applies policy rules to actual content rather than transport-layer characteristics.\n\nPolicy enforcement covers several categories. Guardrails blocks prompts that attempt jailbreaks or injection attacks, scans outputs for sensitive data patterns, and enforces compliance requirements including GDPR and the EU AI Act.\n\nAI Red Team automates adversarial testing against AI systems. It maintains a database of attack techniques that grows by 10,000 entries monthly as researchers discover new vulnerabilities.\n\nResults from Red Team testing feed directly into Guardrails policies. When Red Team discovers a vulnerability pattern, security teams create corresponding guardrails to block similar attacks in production.\n\n‚ÄúIt‚Äôs a very synergistic pairing wherein with AI Red Team you can send a team of agents to discover vulnerabilities in AI systems, and with AI Guardrails you can transform those insights into threat-informed defenses,‚Äù Wormke said.\n\nF5 acquired NGINX back in 2019 and has been expanding the capabilities of the web server platform ever since.\n\nNGINXaaS first became generally available on Microsoft Azure in 2023 and is now coming to Google Cloud. The Google Cloud expansion addresses customer demand for consistent tooling across cloud providers. ‚ÄúCustomers have been asking for NGINXaaS across additional cloud platforms,‚Äù Wormke said. ‚ÄúGoogle Cloud was the next and now we are working with AWS.‚Äù\n\nThe service combines Layer 4 and Layer 7 load balancing with security and observability, available through Google Cloud Marketplace.\n\n‚ÄúNGINXaaS is built on the pedigree of the enterprise version of NGINX, NGINX Plus,‚Äù Wormke said. ‚ÄúIt has open-source roots and will support your open-source configurations, but it gives you all the capabilities of commercial NGINX Plus.‚Äù\n\nWormke noted that those capabilities include visibility into over 240 deep application metrics, intelligent load balancing algorithms, traffic optimization, in-memory state sharing, AuthN & AuthZ and it‚Äôs¬† ready to go F5 WAF for NGINX.\n\nThe NGINX project celebrated its 20th anniversary in October 2024 and is one of the most widely used web server and application delivery technologies.¬†Beyond just the core web server, it is also used as a load balancer, reverse proxy, programmability layer, API Gateway, Ingress Controller and Kubernetes Gateway.\n\n‚ÄúIt continues to power a significant portion of the internet and API traffic today,‚Äù Wormke said. ‚ÄúIt is far more than the web server that many think open-source NGINX is.‚Äù\n\nF5 continues development on both open-source NGINX and commercial versions. For instance, he noted that F5 recently announced Encrypted Client Hello (ECH) support for enhanced privacy as well as support for PQC (Post Quantum Cryptography). Looking forward, AI is going to play a big role in the future direction.\n\n‚ÄúWe are evolving toward AI-aware application delivery and security to enable secure, scalable and performant, agentic AI operations,‚Äù he said.",
    "readingTime": 4,
    "keywords": [
      "nginx plus",
      "plus wormke",
      "open-source nginx",
      "load balancing",
      "application delivery",
      "web server",
      "security teams",
      "ai guardrails",
      "systems",
      "users"
    ],
    "qualityScore": 1,
    "link": "https://www.networkworld.com/article/4118696/f5-tackles-ai-security-with-new-platform-extensions.html",
    "thumbnail_url": "https://www.networkworld.com/wp-content/uploads/2026/01/4118696-0-65503400-1768836299-shutterstock_2403416063_2de17a.jpg?quality=50&strip=all&w=1024",
    "created_at": "2026-01-20T00:57:27.499Z",
    "topic": "tech"
  },
  {
    "slug": "goldman-sachs-says-watch-these-5-warnings-from-the-dotcom-bubble-to-know-if-the-ai-craze-is-peaking",
    "title": "Goldman Sachs says watch these 5 warnings from the dot-com bubble to know if the AI craze is peaking",
    "description": "The stock market flashed five warning signs before the dot-com bubble popped in the early 2000s, strategists at Goldman Sachs said.",
    "fullText": "Markets are worried about shades of 1999 in today's tech-investing landscape, and while there's a lot of debate about whether AI is a bubble, there are a few signals from history that show what, specifically, investors should be looking out for.\n\nStrategists at Goldman Sachs said they believe the market's AI frenzy risks mirroring the dot-com bubble burst in the early 2000s.\n\nStocks don't look like they're in their 1999 moment yet, Dominic Wilson, a senior advisor on the bank's global markets research team, and Vickie Chang, a macro research strategist, wrote in a note to clients on Sunday. But the risks that the AI boom will look a lot like the 2000s era craze appear to be growing, they said.\n\n\"We see a growing risk that the imbalances that built up in the 1990s will become more visible as the AI investment boom extends. There have been echoes of the inflection point in the 1990s boom lately,\" the bank wrote, adding that the AI trade now looked the way tech stocks did in 1997, several years before the bubble burst.\n\nWilson and Chang flagged several warning signs leading up to the dot-com crash in the early 2000s that investors should be on the lookout for.\n\nInvestment spending on tech equipment and software rose to \"unusually high levels\" in the 90s. That peaked in 2000, when non-residential investment in the telecom and tech sector rose to around 15% of US GDP.\n\nInvestment spending began to tumble in the months leading up to the dot-com crash, per Goldman's analysis.\n\n\"Highly valued asset prices thus had significant consequences for real spending decisions,\" the strategists said.\n\nInvestors have been growing wary of mega-cap tech firms' spending spree on AI this year. Amazon, Meta, Microsoft, Alphabet, and Apple are on track to spend around $349 billion on capex in 2025.\n\nCorporate profits reached a peak around 1997 before beginning to decline.\n\n\"Profitability peaked well before the boom ended,\" Wilson and Chang wrote. \"While reported profit margins were more robust, declining profitability in the macro data in the later years of the boom came alongside accelerating equity prices.\"\n\nCorporate profits look strong at the moment. The blended net profit margin in the S&P 500 for the third quarter is around 13.1%, above the five-year average of 12.1%, according to FactSet.\n\nCompanies grew increasingly indebted in the lead-up to the dot-com crash. Corporate debt as a percentage of profits peaked in 2001, right as the bubble was bursting, Goldman's analysis shows.\n\n\"The combination of rising investment and falling profitability pushed the corporate sector financial balance ‚Äî the difference between savings and investment ‚Äî into deficit,\" the strategists said.\n\nSome of mega-cap tech firms' spending on AI has been funded debt. Meta, for instance, raised $30 billion in bonds in late October as it doubled down on its AI spending plans.\n\nMost firms today, though, look like they're financing capex with free cash flow, Goldman added. The percentage of corporate debt relative to profits also looks significantly lower than it did at the peak of the internet bubble.\n\nThe Fed was in the midst of its rate-cutting cycle in the late 90s, one factor that helped juice the stock market.\n\n\"Lower rates and capital inflows added fuel to the equity market,\" Goldman wrote.\n\nThe Fed cut interest rates by 25 basis points at its October policy meeting. Investors are expecting the central bank to issue another 25 basis-point cut in December, according to the CME FedWatch tool.\n\nOther market pros, like Ray Dalio, have warned that the Fed's easing cycle could help inflate a bubble in markets.\n\nIn the 1990s, these warning signs appeared at least two years before the dot-com bubble actually burst, Wilson and Chang said, adding that they believed the AI trade still had room to run.\n\nThis story was originally published in November 2025.",
    "readingTime": 4,
    "keywords": [
      "goldman's analysis",
      "burst wilson",
      "corporate debt",
      "corporate profits",
      "warning signs",
      "mega-cap tech",
      "dot-com crash",
      "tech firms",
      "wilson and chang",
      "bubble burst"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stock-market-bubble-warning-dot-com-crash-ai-stocks-goldman-2025-11",
    "thumbnail_url": "https://i.insider.com/691207c20a30027667eaff8b?width=1200&format=jpeg",
    "created_at": "2026-01-20T00:57:23.709Z",
    "topic": "finance"
  },
  {
    "slug": "young-workers-most-worried-about-ai-affecting-jobs-randstad-survey-shows",
    "title": "Young workers most worried about AI affecting jobs, Randstad survey shows",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/young-workers-most-worried-about-ai-affecting-jobs-randstad-survey-shows-4453847",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0I18Z_L.jpg",
    "created_at": "2026-01-20T00:57:21.399Z",
    "topic": "finance"
  },
  {
    "slug": "rocket-doctor-ai-upsizes-private-placement-to-52-million",
    "title": "Rocket Doctor AI upsizes private placement to $5.2 million",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/rocket-doctor-ai-upsizes-private-placement-to-52-million-93CH-4453846",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-20T00:57:21.379Z",
    "topic": "finance"
  },
  {
    "slug": "britain-needs-ai-stress-tests-for-financial-services-lawmakers-say",
    "title": "Britain needs ‚ÄôAI stress tests‚Äô for financial services, lawmakers say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/britain-needs-ai-stress-tests-for-financial-services-lawmakers-say-4453850",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0J002_L.jpg",
    "created_at": "2026-01-20T00:57:21.238Z",
    "topic": "finance"
  },
  {
    "slug": "aiassisted-feature-intake-with-human-review-n8n-workflow",
    "title": "AI-assisted feature intake with human review (n8n workflow)",
    "description": "This project is an AI-powered Feature Intake Engine that converts raw product ideas into reviewable, structured Jira-ready tickets, with a human-in-the-loop approval step.  It is designed for Produ...",
    "fullText": "kavishsekhri\n\n /\n\n AI-Feature-Intake-Engine\n\n Public\n\n This project is an AI-powered Feature Intake Engine that converts raw product ideas into reviewable, structured Jira-ready tickets, with a human-in-the-loop approval step. It is designed for Product, Engineering, and TPM teams who want speed without losing control.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kavishsekhri/AI-Feature-Intake-Engine",
    "readingTime": 1,
    "keywords": [
      "product"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/kavishsekhri/AI-Feature-Intake-Engine",
    "thumbnail_url": "https://opengraph.githubassets.com/f05e745da909e648e77bc78925f14c4bdec047ecd4dab0991fac2e6928467851/kavishsekhri/AI-Feature-Intake-Engine",
    "created_at": "2026-01-19T18:18:47.207Z",
    "topic": "tech"
  },
  {
    "slug": "a-broadening-playbook-wall-street-sees-stock-market-gains-beyond-tech",
    "title": "'A broadening playbook': Wall Street sees stock market gains beyond tech",
    "description": "Enthusiasm for artificial intelligence's prospects will continue to drive the market higher in 2026. The gains won't be limited to tech stocks, strategists say.",
    "fullText": "Investor enthusiasm over the prospects of artificial intelligence are expected to drive Big Tech stocks in particular this year ‚Äî but Wall Street also expects gains in other sectors.\n\nOver the past two weeks, Industrials (XLI), Materials (XLB), Energy (XLE), and Consumer Staples (XLP) have outperformed the broader market, with all of those sectors up 5.5% or more.\n\nEven the small-cap Russell 2000 (^RUT) index has risen 8% since the start of the year, outperforming the S&P 500 (^GSPC), which is up more than 1% during the same period.\n\n\"It's a broadening playbook,\" Oppenheimer chief investment strategist John Stoltzfus told Yahoo Finance on Friday.\n\nStoltzfus' price target for the S&P 500 this year is the most bullish on Wall Street at 8,100, with other analysts expecting double-digit percentage gains taking the benchmark index toward 7,500 or 7,600.\n\n\"What we're seeing is a rotation, and it's not necessarily away from technology, as we would think,\" he added. \"It's some profit taking to broaden one's exposure and diversification.\"\n\nKeith Lerner, co-chief investment officer at Truist Advisory Services, agrees. His firm's strategy has been to go Overweight on industrials, while also upgrading healthcare and energy stocks.\n\n\"I wouldn't get rid of the tech at this point. I think there are more opportunities beyond tech, is the way I would think about it,\" Lerner said.\n\nStrategists are optimistic given what they've seen with earnings, which kicked off last week.\n\nGoldman Sachs (GS) and Morgan Stanley (MS) showed one of the strongest years for the investment banking business since the pandemic, sending shares of those firms higher.\n\nTaiwan Semiconductor Manufacturing Co.'s (TSM) strong results also gave a lift to semiconductor stocks and fueled optimism that the AI cycle is only accelerating\n\nShares of memory chipmaker Micron (MU) and equipment makers ASML (ASML) and Applied Materials (AMAT) are all up at least 25% year-to-date.\n\nPerformance in the AI chip space so far underscores that artificial intelligence and tech are expected to lead the market again this year as wider adoption across enterprises takes hold.\n\n\"As we wait for that to unfold, I think tech, especially big tech and AI as a theme, is the core of this market,\" Barclays head of US equity strategy Venu Krishna said. \"Our core conviction is that it'll sustain this year, even though the level of scrutiny around that [AI] has decidedly increased.\"\n\nThe test will be whether software stocks, facing disruption from artificial intelligence, can find their footing. Names like Microsoft (MSFT), Salesforce (CRM), and ServiceNow (NOW) have all fallen since the start of the year as investors weigh AI's impact.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "wall street",
      "stocks",
      "market",
      "it's",
      "investment",
      "gains",
      "sectors",
      "industrials",
      "materials"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/a-broadening-playbook-wall-street-sees-stock-market-gains-beyond-tech-160556466.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/awxweQvjpgGZvkcTjxU8Pw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/b7798ba0-f2f9-11f0-bdfd-6f91897d0d7a",
    "created_at": "2026-01-19T18:18:40.400Z",
    "topic": "finance"
  },
  {
    "slug": "ben-horowitz-says-ai-could-spark-a-postelectricity-leap-in-living-standards-but-risk-eroding-purpose",
    "title": "Ben Horowitz says AI could spark a post-electricity leap in living standards ‚Äî but risk eroding purpose",
    "description": "Andreessen Horowitz cofounder Ben Horowitz said AI will boost life quality but warns a frictionless future could leave people searching for meaning.",
    "fullText": "Ben Horowitz believes artificial intelligence is about to reshape daily life as profoundly as electricity once did.\n\nSpeaking on a recent episode of the \"Ben & Marc Show,\" the Andreessen Horowitz cofounder framed AI as a once-in-a-century technological break.\n\n\"This is on the order of the steam engine or electricity,\" Horowitz said, adding that the technology is so powerful it will push society into \"a different world.\"\n\nBut while AI may deliver dramatic gains in living standards, Horowitz said it will also raise deeper questions about meaning, purpose, and what humans do with their time.\n\nHorowitz said AI will help fix problems humans have \"learned to live with,\" including cancer, transportation challenges, and large-scale fraud detection in the US.\n\nThe result, he believes, could be a broad-based improvement in quality of life that's difficult to fully imagine from the present vantage point.\n\n\"I think life ‚Äî just the quality of life for everybody ‚Äî is about to get way, way better than it's ever been,\" Horowitz said.\n\nHowever, Horowitz also struck a cautionary note. If AI removes too much friction from life ‚Äî and too many traditional sources of struggle, work, and responsibility ‚Äî humans may find themselves unmoored.\n\n\"The one thing with humans that's a little messed up,\" he said, is that if progress pushes people \"too far away from some grounded purpose,\" including shared beliefs or spiritual anchors, they may \"attach onto some dumb stuff.\"\n\nHorowitz's prediction echoes those voiced by other AI leaders.\n\nElon Musk, the CEO of Tesla and xAI, has said AI could usher in a future of \"universal high income,\" where work becomes optional, and abundance eliminates poverty, while Bill Gates, the Microsoft cofounder, has suggested AI may make radically shorter workweeks possible.\n\nOpenAI CEO Sam Altman and Anthropic CEO Dario Amodei have both acknowledged risks to meaning in a post-work world but remain optimistic that humans will adapt and find new sources of fulfillment.\n\nBeyond Silicon Valley's more optimistic visions, figures like Geoffrey Hinton, the computer scientist often called the \"godfather of AI,\" Stuart Russell, a professor of computer science at UC Berkeley, investor Howard Marks of Oaktree Capital Management, and AI researcher Eliezer Yudkowsky have warned of outcomes ranging from mass job losses and the erosion of meaning at work to, in the most extreme cases, threats to humanity's survival.",
    "readingTime": 2,
    "keywords": [
      "life",
      "humans",
      "horowitz",
      "electricity",
      "cofounder",
      "purpose",
      "quality",
      "that's",
      "optimistic",
      "computer"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ben-horowitz-ai-could-boost-living-standards-like-electricity-2026-1",
    "thumbnail_url": "https://i.insider.com/696e092aa645d118818794c5?width=1200&format=jpeg",
    "created_at": "2026-01-19T18:18:38.709Z",
    "topic": "finance"
  },
  {
    "slug": "big-short-investor-michael-burry-has-found-an-unlikely-ally-in-his-crusade-against-ai-hype-ben-affleck",
    "title": "'Big Short' investor Michael Burry has found an unlikely ally in his crusade against AI hype: Ben Affleck",
    "description": "Michael Burry of \"The Big Short\" said Ben Affleck was \"clearly a smart guy\" after he slammed AI chatbots and called out spending on data centers.",
    "fullText": "It rarely hurts to have Batman on your side. Michael Burry may have the next thing after Ben Affleck revealed he's also skeptical of the AI boom.\n\nThe Hollywood star, speaking on the latest episode of \"The Joe Rogan Experience\" podcast, echoed the investor's skepticism of grand claims around AI and Big Tech's massive investments in the nascent tech.\n\n\"I think a lot of that rhetoric comes from people who are trying to justify valuations around companies, where they go: 'We're going to change everything in two years, there's going to be no more work,'\" Affleck said.\n\n\"Well, the reason they're saying that is because they need to ascribe a valuation for investment that can warrant the capex spend they're going to make on these data centers,\" he added.\n\nThe \"Justice League\" and \"Gone Girl\" actor said that historical adoption of new technologies has been \"slow\" and incremental.\"\n\nHe said that tech companies are trying to justify their huge outlays by promising they'll enable new AI models that will blow away existing ones ‚Äî but in reality, each subsequent model is only moderately better and requires far more electricity and data to run.\n\n\"Ben Affleck is clearly a smart guy,\" Burry wrote in a weekend post on X. \"So this does not surprise me. It sounds familiar and on point.\"\n\nBen Affleck is clearly a smart guy. So this does not surprise me. It sounds familiar and on point. Delivered much better than I ever could. https://t.co/X1VvE9yX2N\n\nAffleck backed up Burry's critique of AI's value on the podcast. He said the writing of today's AI chatbots is \"really shitty\" and \"not reliable.\"\n\n\"I just can't stand to see what it writes,\" said Affleck, who cowrote the Oscar-winning screenplay for \"Good Will Hunting\" and directed, produced, and starred in Best Picture winner \"Argo.\"\n\nHe predicted that filmmakers would use AI as a tool to save time and money ‚Äî similar to visual effects ‚Äî but it probably won't \"write anything meaningful\" or make entire movies.\n\nAffleck said that most AI users are using chatbots as virtual companions, so \"there's no work, there's no productivity, there's no value to it.\"\n\nHe also cast doubt on the social value of people engaging with AI friends who are \"telling you that you're great and listening to everything you say and being sycophantic.\"\n\nBurry has struck a similar tone on AI in recent weeks. He's best known for his prescient bet against the mid-2000s housing bubble, which was immortalized in Michael Lewis' book \"The Big Short.\" Christian Bale, Affleck's predecessor as Batman, portrayed him in the movie adaptation.\n\nAfter more than two years of virtual silence, Burry returned to X late last year with a flurry of warnings about a dangerous AI bubble. He also closed his hedge fund to outside cash, shifting his focus to writing financial analysis on Substack.\n\nBurry's central thesis is that AI stocks are overvalued. He's said they're overinvesting in microchips and data centers that will quickly become outdated, to power a tech that will become commoditized and won't yield a return for them, paving the way for large writedowns and sharp stock declines in the future.\n\nHe recently posted on X that \"return on investment will continue to fall, almost all AI companies will go bankrupt, and much of the AI spending will be written off.\"",
    "readingTime": 3,
    "keywords": [
      "clearly smart",
      "smart guy",
      "sounds familiar",
      "ben affleck",
      "there's",
      "he's",
      "they're",
      "batman",
      "podcast",
      "justify"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-short-michael-burry-ben-affleck-rogan-ai-bubble-skeptic-2026-1",
    "thumbnail_url": "https://i.insider.com/696e3a8ae1ba468a96aa4d2c?width=1200&format=jpeg",
    "created_at": "2026-01-19T18:18:38.321Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-creating-the-rick-rubins-of-silicon-valley",
    "title": "AI is creating the Rick Rubins of Silicon Valley",
    "description": "The rise of AI-native tools such as Claude Code is transforming the value and impact of  designers and taste-makers in Silicon Valley.",
    "fullText": "In Silicon Valley, AI is fueling the rise of the star individual contributor.\n\nJust take a look at what happened after The Browser Company was acquired by Anthropic. Josh Miller, CEO of this browser startup, recently described how Anthropic's Claude Code radically changed his hiring strategy.\n\nHis post gets at something many creative orgs have struggled to name: there's a huge, underserved group of very senior designer ICs who want to stay close to the work, coach others, and shape direction ‚Äî without becoming full-time people managers. The \"Design Producer\" role he describes feels like a credible answer to that gap.\n\nAI-native tools such as Claude Code make this role newly viable. When designers can prototype, ship code, and explore ideas directly, the leverage of a senior IC shifts. Their value isn't headcount management. Instead, it's taste, judgment, and the ability to help others move faster and aim higher. Coaching becomes embedded in the work itself.\n\nThe record-label metaphor fits well here. Great music producers don't manage bands through org charts, they create the conditions for great work, give feedback at the right moments, and connect the right collaborators.\n\nFor experienced tech designers who've hit the ceiling of traditional IC tracks, this feels like a genuinely new lane, not a consolation prize.\n\nThink of this like a legion of nerdy Rick Rubins. Coincidentally, Rubin created a digital book last year with Anthropic called The Way of Code. Here's a passage from the book:\n\nThe Vibe Coder attends to\nthe inner, not the outer.\nHe allows things to come and go.\nHis heart is open as the sky.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "senior",
      "others",
      "role",
      "designers",
      "book",
      "code",
      "browser",
      "anthropic",
      "claude"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/ai-rick-rubin-silicon-valley-anthropic-claude-code-2026-1",
    "thumbnail_url": "https://i.insider.com/696abf5ba645d11881878d9d?width=1200&format=jpeg",
    "created_at": "2026-01-19T18:18:38.179Z",
    "topic": "finance"
  },
  {
    "slug": "bosses-dont-think-ai-is-paying-off-yet-a-pwc-survey-of-4500-ceos-found",
    "title": "Bosses don't think AI is paying off yet, a PwC survey of 4,500 CEOs found",
    "description": "PwC's global CEO survey found that more than half of CEOs say they aren't seeing increased revenue or cost benefits from their investments in AI.",
    "fullText": "Everyone wants to know when AI investments will pay off.\n\nMost CEOs say they're still waiting, according to PwC's latest Global CEO survey, released on Monday to coincide with the start of Davos.\n\nThe consulting giant questioned 4,454 chief executives across 95 countries and territories about their strategic priorities and outlook in the year up to November 2025.\n\nMore than half of the CEOs surveyed, 56%, said AI hasn't produced revenue or cost benefits for their businesses to date.\n\nSome reported benefits for either revenue or costs: around a third said their revenue was up in the last year, and 26% said they were seeing lower costs from AI.\n\nBut only 12% said they had both decreased costs and increased revenue using AI in the last 12 months.\n\nRecent Morgan Stanley data on S&P 500 companies showed that¬†certain sectors¬†are seeing higher, measurable AI-driven returns than others. Technology, communication services, and financials topped the list, while energy companies were rising fast up the list.\n\n\"A small group of companies are already turning AI into measurable financial returns, while many others are still struggling to move beyond pilots,\" said Mohamed Kande, PwC's global chairman, in a press release.\n\n\"That gap is starting to show up in confidence and competitiveness‚Äîand it will widen quickly for those that don't act.\"\n\nEnsuring maximum returns from AI requires a balance of business strategy, strong underlying data architecture, and the right talent strategy. No matter how excited CEOs are about AI, they also have to get employees on board to see returns.\n\nA recent EY survey on how AI is being used at work found that companies are missing out on 40% of the AI productivity gains they could achieve with the right strategy.\n\nPwC found that the 12% of CEOs reporting both cost and revenue gains were two to three times more likely to have also built a strong AI foundation, meaning they have embedded AI extensively across products and services, demand generation, and strategic decision-making.\n\nAs they grapple with AI uncertainty and geopolitical volatility, CEOs told PwC they are less confident about their short-term growth outlook than they were last year.\n\nOnly 30% of those surveyed said they are very or extremely confident about revenue growth over the next 12 months, down from 38% in last year's report and a peak of 56% in 2022.\n\nThe strongest approach to dealing with future uncertainty was embracing reinvention, including through dealmaking and venturing into new sectors, PwC found.\n\nThe consulting giant found there was a \"strong association among a higher percentage of revenue coming from new sectors, bigger profit margins, and greater CEO confidence in company growth prospects.\"\n\n\"The companies that succeed will be those willing to make bold decisions and invest with conviction in the capabilities that matter most,\" said Kande.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "consulting giant",
      "revenue",
      "returns",
      "sectors",
      "strategy",
      "growth",
      "survey",
      "across",
      "strategic",
      "outlook"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pwc-global-ceo-survey-is-ai-investment-delivering-financial-returns-2026-1",
    "thumbnail_url": "https://i.insider.com/696e4842c58df2ecd5ccc27b?width=1200&format=jpeg",
    "created_at": "2026-01-19T18:18:38.013Z",
    "topic": "finance"
  },
  {
    "slug": "trust-ai-enough-to-bet-your-retirement-you-said-no-thanks",
    "title": "Trust AI enough to bet your retirement? You said, 'No thanks'",
    "description": "Elon Musk suggested you don't need to bother saving for a 401 (k) because of AI. Business Insider's readers weren't on board.",
    "fullText": "Earlier this month, Elon Musk suggested that people don't need to sock away funds in their 401 (k) anymore because AI will make the scarcity of money a thing of the past.\n\n\"If any of the things that we've said are true, saving for retirement will be irrelevant,\" Musk said of the predicted AI revolution during a recent podcast episode.\n\nHe speculated that AI could transform society, creating an abundance of resources that would grant everyone a \"universal high income\" and the ability to have \"whatever stuff they want.\"\n\nOur readers don't seem to be as sold on that vision of what he characterized as the \"good future.\"\n\nBusiness Insider Today's Dan Defrancesco asked newsletter readers whether they trust AI enough to stop saving, and the results were pretty emphatic.\n\nOf the roughly 200 readers who responded, just 6% said they're not worried about retirement and that they'd let AI handle the future.\n\nMeanwhile, roughly 94% said they would stick with their savings plans rather than bet the farm that an AI revolution would make it moot.\n\nThat's the smart move, financial and technology experts previously told Business Insider.\n\nSeven retirement and AI gurus we spoke to said Americans should be spending more on retirement, not less.\n\n\"Most Americans should absolutely ignore these comments,\" said Geoffrey Sanzenbacher, a research fellow at Boston College's Center for Retirement Research (CRR). \"Musk's speculation sends a dangerous and misleading message.\"\n\nOthers said that technological revolutions haven't boosted wealth equally across society in the past, and that a potential universal basic income ‚Äî like the kind Musk is suggesting ‚Äî would take a coordinated effort from government, not tech leaders.\n\n\"That is not a technological problem ‚Äî it is a coordination problem at the scale of civilization,\" said John Nosta, an innovation theorist and the founder of NostaLab.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "readers",
      "don't",
      "saving",
      "revolution",
      "society",
      "universal",
      "income",
      "roughly",
      "technological"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/trust-ai-with-retirement-401k-survey-results-elon-musk-2026-1",
    "thumbnail_url": "https://i.insider.com/696e66a2a645d118818796f5?width=1200&format=jpeg",
    "created_at": "2026-01-19T18:18:38.002Z",
    "topic": "finance"
  },
  {
    "slug": "valve-updates-ai-disclosure-guidelines-to-allow-for-aipowered-tools",
    "title": "Valve Updates AI Disclosure Guidelines To Allow For AI-Powered Tools",
    "description": "Valve has made changes to its AI-disclosure guidelines, removing the need for studios to disclose whether or not games have been developed with AI-powered tools and putting more emphasis on AI-generated assets.\nThe change, which was pointed out by Simon Carless on LinkedIn, suggests that Valve is no longer concerned by the use of AI tools that assist development, stating, \"Efficiency gains through the use of [AI-powered dev tools] is not the focus of this section.\" These tools could included a variety of things, such as AI-generated transcripts of meetings to code helpers that have become prevalent in most programming environments.\nValve states the the aim of its disclosure policy is to inform players when AI is used to generate content, from marketing and conceptual assets to in-game ones that players will interact with. Developers are able to specify what assets have been generated and indicate, via a single checkbox, whether or not players will interact with AI-generated content during gameplay, be it images, audio, or other content.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/valve-updates-ai-disclosure-guidelines-to-allow-for-ai-powered-tools/1100-6537483/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1585/15853545/4637028-7297126222-arc-r.jpg",
    "created_at": "2026-01-19T18:18:34.839Z",
    "topic": "gaming"
  },
  {
    "slug": "kuse-cowork-an-open-source-byok-alternative-to-claude-cowork",
    "title": "Kuse Cowork ‚Äì An open source, BYOK alternative to Claude Cowork",
    "description": "Open-source Alternative for Claude Code Desktop App - kuse-ai/kuse_cowork",
    "fullText": "kuse-ai\n\n /\n\n kuse_cowork\n\n Public\n\n Open-source Alternative for Claude Code Desktop App\n\n License\n\n MIT license\n\n 83\n stars\n\n 12\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kuse-ai/kuse_cowork",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/kuse-ai/kuse_cowork",
    "thumbnail_url": "https://opengraph.githubassets.com/a2c54511b6b2934c95f3f166f114528798fc1b2eb5205273cc9f287df6ab0f1c/kuse-ai/kuse_cowork",
    "created_at": "2026-01-19T12:27:20.869Z",
    "topic": "tech"
  },
  {
    "slug": "fasttopkbatched-highperformance-batched-topk-selection-for-cpu-inference",
    "title": "Fast_topk_batched: High-performance batched Top-K selection for CPU inference",
    "description": "High-performance batched Top-K selection for CPU inference. Up to 80x faster than PyTorch, optimized for LLM sampling with AVX2 SIMD. - RAZZULLIX/fast_topk_batched",
    "fullText": "RAZZULLIX\n\n /\n\n fast_topk_batched\n\n Public\n\n High-performance batched Top-K selection for CPU inference. Up to 80x faster than PyTorch, optimized for LLM sampling with AVX2 SIMD.\n\n License\n\n MIT license\n\n 4\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n RAZZULLIX/fast_topk_batched",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/RAZZULLIX/fast_topk_batched",
    "thumbnail_url": "https://opengraph.githubassets.com/16dbb1cdc8345f8154f62c3563e6c55e0654762121550ffcdfd2712783d6229b/RAZZULLIX/fast_topk_batched",
    "created_at": "2026-01-19T12:27:20.754Z",
    "topic": "tech"
  },
  {
    "slug": "ai-companies-will-fail-we-can-salvage-something-from-the-wreckage-cory-doctorow",
    "title": "AI companies will fail. We can salvage something from the wreckage | Cory Doctorow",
    "description": "AI is asbestos in the walls of our tech society, stuffed there by monopolists run amok. A serious fight against it must strike at its roots\nI am a science-fiction writer, which means that my job is to make up futuristic parables about our current techno-social arrangements to interrogate not just what a gadget does, but who it does it for, and who it does it to.\nWhat I do not do is predict the future. No one can predict the future, which is a good thing, since if the future were predictable, that would mean we couldn‚Äôt change it.\n Continue reading...",
    "fullText": "I am a science-fiction writer, which means that my job is to make up futuristic parables about our current techno-social arrangements to interrogate not just what a gadget does, but who it does it for, and who it does it to.\n\nWhat I do not do is predict the future. No one can predict the future, which is a good thing, since if the future were predictable, that would mean we couldn‚Äôt change it.\n\nNow, not everyone understands the distinction. They think science-fiction writers are oracles. Even some of my colleagues labor under the delusion that we can ‚Äúsee the future‚Äù.\n\nThen there are science-fiction fans who believe that they are reading the future. A depressing number of those people appear to have become AI bros. These guys can‚Äôt shut up about the day that their spicy autocomplete machine will wake up and turn us all into paperclips has led many confused journalists and conference organizers to try to get me to comment on the future of AI.\n\nThat‚Äôs something I used to strenuously resist doing, because I wasted two years of my life explaining patiently and repeatedly why I thought crypto was stupid, and getting relentlessly bollocked by cryptocurrency cultists who at first insisted that I just didn‚Äôt understand crypto. And then, when I made it clear that I did understand crypto, they insisted that I must be a paid shill.\n\nThis is literally what happens when you argue with Scientologists, and life is just too short. That said, people would not stop asking ‚Äì so I‚Äôm going to explain what I think about AI and how to be a good AI critic. By which I mean: ‚ÄúHow to be a critic whose criticism inflicts maximum damage on the parts of AI that are doing the most harm.‚Äù\n\nIn automation theory, a ‚Äúcentaur‚Äù is a person who is assisted by a machine. Driving a car makes you a centaur, and so does using autocomplete.\n\nA reverse centaur is a machine head on a human body, a person who is serving as a squishy meat appendage for an uncaring machine.\n\nFor example, an Amazon delivery driver, who sits in a cabin surrounded by AI cameras that monitor the driver‚Äôs eyes and take points off if the driver looks in a proscribed direction, and monitors the driver‚Äôs mouth because singing is not allowed on the job, and rats the driver out to the boss if they do not make quota.\n\nThe driver is in that van because the van cannot drive itself and cannot get a parcel from the curb to your porch. The driver is a peripheral for a van, and the van drives the driver, at superhuman speed, demanding superhuman endurance.\n\nObviously, it‚Äôs nice to be a centaur, and it‚Äôs horrible to be a reverse centaur. There are lots of AI tools that are potentially very centaurlike, but my thesis is that these tools are created and funded for the express purpose of creating reverse centaurs, which none of us want to be.\n\nBut like I said, the job of a science-fiction writer is to do more than think about what the gadget does, and drill down on who the gadget does it for and who the gadget does it to. Tech bosses want us to believe that there is only one way a technology can be used. Mark Zuckerberg wants you to think that it is technologically impossible to have a conversation with a friend without him listening in. Tim Cook wants you to think that it is impossible for you to have a reliable computing experience unless he gets a veto over which software you install and without him taking 30 cents out of every dollar you spend. Sundar Pichai wants you to think that it is for you to find a webpage unless he gets to spy on you from asshole to appetite.\n\nThis is all a kind of vulgar Thatcherism. Margaret Thatcher‚Äôs mantra was: ‚ÄúThere is no alternative.‚Äù She repeated this so often they called her ‚ÄúTina‚Äù Thatcher: There. Is. No. Alternative.\n\n‚ÄúThere is no alternative‚Äù is a cheap rhetorical slight. It‚Äôs a demand dressed up as an observation. ‚ÄúThere is no alternative‚Äù means: ‚Äústop trying to think of an alternative.‚Äù\n\nI‚Äôm a science-fiction writer ‚Äì my job is to think of a dozen alternatives before breakfast.\n\nSo let me explain what I think is going on here with this AI bubble and who the reverse-centaur army is serving, and sort out the bullshit from the material reality.\n\nStart with monopolies: tech companies are gigantic and they don‚Äôt compete, they just take over whole sectors, either on their own or in cartels.\n\nGoogle and Meta control the ad market. Google and Apple control the mobile market, and Google pays Apple more than $20bn a year not to make a competing search engine, and of course, Google has a 90% search market share.\n\nNow, you would think that this was good news for the tech companies, owning their whole sector.\n\nBut it‚Äôs actually a crisis. You see, when a company is growing, it is a ‚Äúgrowth stock‚Äù, and investors really like growth stocks. When you buy a share in a growth stock, you are making a bet that it will continue to grow. So growth stocks trade at a huge multiple of their earnings. This is called the ‚Äúprice to earnings ratio‚Äù or ‚ÄúPE ratio‚Äù.\n\nBut once a company stops growing, it is a ‚Äúmature‚Äù stock, and it trades at a much lower PE ratio. So for every dollar that Target ‚Äì a mature company ‚Äì brings in, it is worth $10. It has a PE ratio of 10, while Amazon has a PE ratio of 36, which means that for every dollar Amazon brings in, the market values it at $36.\n\nIt‚Äôs wonderful to run a company that has a growth stock. Your shares are as good as money. If you want to buy another company or hire a key worker, you can offer stock instead of cash. And stock is very easy for companies to get, because shares are manufactured right there on the premises, all you have to do is type some zeros into a spreadsheet, while dollars are much harder to come by. A company can only get dollars from customers or creditors.\n\nSo when Amazon bids against Target for a key acquisition or a key hire, Amazon can bid with shares they make by typing zeros into a spreadsheet, and Target can only bid with dollars they get from selling stuff to us or taking out loans, which is why Amazon generally wins those bidding wars.\n\nThat‚Äôs the upside of having a growth stock. But here is the downside: eventually a company has to stop growing. Like, say you get a 90% market share in your sector, how are you going to grow?\n\nIf you are an exec at a dominant company with a growth stock, you have to live in constant fear that the market will decide that you are not likely to grow any further. Think of what happened to Facebook in the first quarter of 2022. They told investors that they experienced slightly slower growth in the US than they had anticipated, and investors panicked. They staged a one-day, $240bn sell-off. A quarter-trillion dollars in 24 hours! At the time, it was the largest, most precipitous drop in corporate valuation in human history.\n\nThat‚Äôs a monopolist‚Äôs worst nightmare, because once you‚Äôre presiding over a ‚Äúmature‚Äù firm, the key employees you have been compensating with stock experience a precipitous pay drop and bolt for the exits, so you lose the people who might help you grow again, and you can only hire their replacements with dollars ‚Äì not shares.\n\nThis is the paradox of the growth stock. While you are growing to domination, the market loves you, but once you achieve dominance, the market lops 75% or more off your value in a single stroke if they do not trust your pricing power.\n\nWhich is why growth-stock companies are always desperately pumping up one bubble or another, spending billions to hype the pivot to video or cryptocurrency or NFTs or the metaverse or AI.\n\nI am not saying that tech bosses are making bets they do not plan on winning. But winning the bet ‚Äì creating a viable metaverse ‚Äì is the secondary goal. The primary goal is to keep the market convinced that your company will continue to grow, and to remain convinced until the next bubble comes along.\n\nSo this is why they‚Äôre hyping AI: the material basis for the hundreds of billions in AI investment.\n\nNow I want to talk about how they‚Äôre selling AI. The growth narrative of AI is that AI will disrupt labor markets. I use ‚Äúdisrupt‚Äù here in its most disreputable tech-bro sense.\n\nThe promise of AI ‚Äì the promise AI companies make to investors ‚Äì is that there will be AI that can do your job, and when your boss fires you and replaces you with AI, he will keep half of your salary for himself and give the other half to the AI company.\n\nThat is the $13tn growth story that Morgan Stanley is telling. It‚Äôs why big investors are giving AI companies hundreds of billions of dollars. And because they are piling in, normies are also getting sucked in, risking their retirement savings and their family‚Äôs financial security.\n\nNow, if AI could do your job, this would still be a problem. We would have to figure out what to do with all these unemployed people.\n\nBut AI can‚Äôt do your job. It can help you do your job, but that does not mean it is going to save anyone money.\n\nTake radiology: there is some evidence that AI can sometimes identify solid-mass tumors that some radiologists miss. Look, I‚Äôve got cancer. Thankfully, it‚Äôs very treatable, but I‚Äôve got an interest in radiology being as reliable and accurate as possible.\n\nLet‚Äôs say my hospital bought some AI radiology tools and told its radiologists: ‚ÄúHey folks, here‚Äôs the deal. Today, you‚Äôre processing about 100 X-rays per day. From now on, we‚Äôre going to get an instantaneous second opinion from the AI, and if the AI thinks you‚Äôve missed a tumor, we want you to go back and have another look, even if that means you‚Äôre only processing 98 X-rays per day. That‚Äôs fine, we just care about finding all those tumors.‚Äù\n\nIf that‚Äôs what they said, I‚Äôd be delighted. But no one is investing hundreds of billions in AI companies because they think AI will make radiology more expensive, not even if that also makes radiology more accurate. The market‚Äôs bet on AI is that an AI salesman will visit the CEO of Kaiser and make this pitch: ‚ÄúLook, you fire nine out of 10 of your radiologists, saving $20m a year. You give us $10m a year, and you net $10m a year, and the remaining radiologists‚Äô job will be to oversee the diagnoses the AI makes at superhuman speed ‚Äì and somehow remain vigilant as they do so, despite the fact that the AI is usually right, except when it‚Äôs catastrophically wrong.\n\n‚ÄúAnd if the AI misses a tumor, this will be the human radiologist‚Äôs fault, because they are the ‚Äòhuman in the loop‚Äô. It‚Äôs their signature on the diagnosis.‚Äù\n\nThis is a reverse centaur, and it is a specific kind of reverse centaur: it is what Dan Davies calls an ‚Äúaccountability sink‚Äù. The radiologist‚Äôs job is not really to oversee the AI‚Äôs work, it is to take the blame for the AI‚Äôs mistakes.\n\nThis is another key to understanding ‚Äì and thus deflating ‚Äì the AI bubble. The AI can‚Äôt do your job, but an AI salesman can convince your boss to fire you and replace you with an AI that can‚Äôt do your job. This is key because it helps us build the kinds of coalitions that will be successful in the fight against the AI bubble.\n\nIf you are someone who is worried about cancer, and you are being told that the price of making radiology too cheap to meter, is that we are going to have to rehouse America‚Äôs 32,000 radiologists, with the trade-off that no one will ever be denied radiology services again, you might say: ‚ÄúWell, OK, I‚Äôm sorry for those radiologists, and I fully support getting them job training or UBI or whatever. But the point of radiology is to fight cancer, not to pay radiologists, so I know what side I‚Äôm on.‚Äù\n\nAI hucksters and their customers in the C-suites want the public on their side. They want to forge a class alliance between AI deployers and the people who enjoy the fruits of the reverse centaurs‚Äô labor. They want us to think of ourselves as enemies to the workers.\n\nNow, some people will be on the workers‚Äô side because of politics or aesthetics. But if you want to win over all the people who benefit from your labor, you need to understand and stress how the products of the AI will be substandard. That they are going to get charged more for worse things. That they have a shared material interest with you.\n\nWill those products be substandard? There is every reason to think so.\n\nThink of AI software generation: there are plenty of coders who love using AI. Using AI for simple tasks can genuinely make them more efficient and give them more time to do the fun part of coding, namely, solving really gnarly, abstract puzzles. But when you listen to business leaders talk about their AI plans for coders, it‚Äôs clear they are not hoping to make some centaurs.\n\nThey want to fire a lot of tech workers ‚Äì 500,000 over the past three years ‚Äì and make the rest pick up their work with coding, which is only possible if you let the AI do all the gnarly, creative problem solving, and then you do the most boring, soul-crushing part of the job: reviewing the AI‚Äôs code.\n\nAnd because AI is just a word-guessing program, because all it does is calculate the most probable word to go next, the errors it makes are especially subtle and hard to spot, because these bugs are nearly indistinguishable from working code.\n\nFor example: programmers routinely use standard ‚Äúcode libraries‚Äù to handle routine tasks. Say you want your program to slurp in a document and make some kind of sense of it ‚Äì find all the addresses, say, or all the credit card numbers. Rather than writing a program to break down a document into its constituent parts, you‚Äôll just grab a library that does it for you.\n\nThese libraries come in families, and they have predictable names. If it‚Äôs a library for pulling in an html file, it might be called something like lib.html.text.parsing; and if it‚Äôs a for docx file, it‚Äôll be lib.docx.text.parsing.\n\nBut reality is messy, humans are inattentive and stuff goes wrong, so sometimes, there will be another library, say, one for parsing pdfs, and instead of being called lib.pdf.text.parsing, it‚Äôs called lib.text.pdf.parsing. Someone just entered an incorrect library name and it stuck. Like I said, the world is messy.\n\nNow, AI is a statistical inference engine. All it can do is predict what word will come next based on all the words that have been typed in the past. That means that it will ‚Äúhallucinate‚Äù a library called lib.pdf.text.parsing, because that matches the pattern it‚Äôs already seen. And the thing is, malicious hackers know that the AI will make this error, so they will go out and create a library with the predictable, hallucinated name, and that library will get automatically sucked into the AI‚Äôs program, and it will do things like steal user data or try to penetrate other computers on the same network.\n\nAnd you, the human in the loop ‚Äì the reverse centaur ‚Äì you have to spot this subtle, hard-to-find error, this bug that is indistinguishable from correct code. Now, maybe a senior coder could catch this, because they have been around the block a few times, and they know about this tripwire.\n\nBut guess who tech bosses want to preferentially fire and replace with AI? Senior coders. Those mouthy, entitled, extremely highly paid workers, who don‚Äôt think of themselves as workers. Who see themselves as founders in waiting, peers of the company‚Äôs top management. The kind of coder who would lead a walkout over the company building drone-targeting systems for the Pentagon, which cost Google $10bn in 2018.\n\nFor AI to be valuable, it has to replace high-wage workers, and those are precisely the workers who might spot some of those statistically camouflaged AI errors.\n\nIf you can replace coders with AI, who can‚Äôt you replace with AI? Firing coders is an ad for AI.\n\nWhich brings me to AI art ‚Äì or ‚Äúart‚Äù ‚Äì which is often used as an ad for AI, even though it is not part of AI‚Äôs business model.\n\nLet me explain: on average, illustrators do not make any money. They are already one of the most immiserated, precarious groups of workers out there. If AI image-generators put every illustrator working today out of a job, the resulting wage-bill savings would be undetectable as a proportion of all the costs associated with training and operating image-generators. The total wage bill for commercial illustrators is less than the kombucha bill for the company cafeteria at just one of OpenAI‚Äôs campuses.\n\nThe purpose of AI art ‚Äì and the story of AI art as a death knell for artists ‚Äì is to convince the broad public that AI is amazing and will do amazing things. It is to create buzz. Which is not to say that it is not disgusting that former OpenAI CTO Mira Murati told a conference audience that ‚Äúsome creative jobs shouldn‚Äôt have been there in the first place‚Äù.\n\nIt‚Äôs supposed to be disgusting. It‚Äôs supposed to get artists to run around and say: ‚ÄúThe AI can do my job, and it‚Äôs going to steal my job, and isn‚Äôt that terrible?‚Äú\n\nBut can AI do an illustrator‚Äôs job? Or any artist‚Äôs job?\n\nLet‚Äôs think about that for a second. I have been a working artist since I was 17 years old, when I sold my first short story. Here‚Äôs what I think art is: it starts with an artist, who has some vast, complex, numinous, irreducible feeling in their mind. And the artist infuses that feeling into some artistic medium. They make a song, a poem, a painting, a drawing, a dance, a book or a photograph. And the idea is, when you experience this work, a facsimile of the big, numinous, irreducible feeling will materialize in your mind.\n\nBut the image-generation program does not know anything about your big, numinous, irreducible feeling. The only thing it knows is whatever you put into your prompt, and those few sentences are diluted across a million pixels or a hundred-thousand words, so that the average communicative density of the resulting work is indistinguishable from zero.\n\nIt is possible to infuse more communicative intent into a work: writing more detailed prompts, or doing the selective work of choosing from among many variants, or directly tinkering with the AI image after the fact, with a paintbrush or Photoshop or the Gimp. And if there will ever be a piece of AI art that is good art ‚Äì as opposed to merely striking, interesting or an example of good draftsmanship ‚Äì it will be thanks to those additional infusions of creative intent by a human.\n\nAnd in the meantime, it‚Äôs bad art. It‚Äôs bad art in the sense of being ‚Äúeerie‚Äù, the word that cultural theorist Mark Fisher used to describe ‚Äúwhen there is something present where there should be nothing, or there is nothing present when there should be something‚Äù.\n\nAI art is eerie because it seems like there is an intender and an intention behind every word and every pixel, because we have a lifetime of experience that tells us that paintings have painters, and writing has writers. But it is missing something. It has nothing to say, or whatever it has to say is so diluted that it is undetectable.\n\nWe should not simply shrug our shoulders and accept Thatcherism‚Äôs fatalism: ‚ÄúThere is no alternative.‚Äù\n\nSo what is the alternative? A lot of artists and their allies think they have an answer: they say we should extend copyright to cover the activities associated with training a model.\n\nAnd I am here to tell you they are wrong. Wrong because this would represent a massive expansion of copyright over activities that are currently permitted ‚Äì for good reason. I‚Äôll explain:\n\nAI training involves scraping a bunch of webpages, which is unambiguously legal under present copyright law. Next, you perform analysis on those works. Basically, you count stuff on them: count pixels and their colors and proximity to other pixels; or count words. This is obviously not something you need a license for.\n\nAnd after you count all the pixels or the words, it is time for the final step: publishing them. Because that is what a model is: a literary work (that is, a piece of software) that embodies a bunch of facts about a bunch of other works, word and pixel distribution information, encoded in a multidimensional array.\n\nAnd again, copyright absolutely does not prohibit you from publishing facts about copyrighted works. And again, no one should want to live in a world where someone else gets to decide which factual statements you can publish.\n\nBut hey, maybe you think this is all sophistry. Maybe you think I‚Äôm full of shit. That‚Äôs fine. It wouldn‚Äôt be the first time someone thought that.\n\nAfter all, even if I‚Äôm right about how copyright works now, there‚Äôs no reason we couldn‚Äôt change copyright to ban training activities, and maybe there‚Äôs even a clever way to wordsmith the law so that it only catches bad things we don‚Äôt like, and not all the good stuff that comes from scraping, analyzing and publishing ‚Äì such as search engines and academic scholarship.\n\nWell, even then, you‚Äôre not gonna help out creators by creating this new copyright. We have monotonically expanded copyright since 1976, so that today, copyright covers more kinds of works, grants exclusive rights over more uses, and lasts longer.\n\nAnd today, the media industry is larger and more profitable than it has ever been, and also ‚Äì the share of media industry income that goes to creative workers is lower than it has ever been, both in real terms, and as a proportion of those incredible gains made by creators‚Äô bosses at the media company.\n\nIn a creative market dominated by five publishers, four studios, three labels, two mobile app stores, and a single company that controls all the ebooks and audiobooks, giving a creative worker extra rights to bargain with is like giving your bullied kid more lunch money.\n\nIt doesn‚Äôt matter how much lunch money you give the kid, the bullies will take it all. Give that kid enough money and the bullies will hire an agency to run a global campaign proclaiming: ‚ÄúThink of the hungry kids! Give them more lunch money!‚Äù\n\nCreative workers who cheer on lawsuits by the big studios and labels need to remember the first rule of class warfare: things that are good for your boss are rarely what‚Äôs good for you.\n\nA new copyright to train models will not get us a world where models are not used to destroy artists, it will just get us a world where the standard contracts of the handful of companies that control all creative labor markets are updated to require us to hand over those new training rights to those companies. Demanding a new copyright just makes you a useful idiot for your boss.\n\nWhen really what they‚Äôre demanding is a world where 30% of the investment capital of the AI companies go into their shareholders‚Äô pockets. When an artist is being devoured by rapacious monopolies, does it matter how they divvy up the meal?\n\nWe need to protect artists from AI predation, not just create a new way for artists to be mad about their impoverishment.\n\nIncredibly enough, there is a really simple way to do that. After more than 20 years of being consistently wrong and terrible for artists‚Äô rights, the US Copyright Office has finally done something gloriously, wonderfully right. All through this AI bubble, the Copyright Office has maintained ‚Äì correctly ‚Äì that AI-generated works cannot be copyrighted, because copyright is exclusively for humans. That is why the ‚Äúmonkey selfie‚Äù is in the public domain. Copyright is only awarded to works of human creative expression that are fixed in a tangible medium.\n\nAnd not only has the Copyright Office taken this position, they have defended it vigorously in court, repeatedly winning judgments to uphold this principle.\n\nThe fact that every AI-created work is in the public domain means that if Getty or Disney or Universal or Hearst newspapers use AI to generate works ‚Äì then anyone else can take those works, copy them, sell them or give them away for nothing. And the only thing those companies hate more than paying creative workers, is having other people take their stuff without permission.\n\nThe US Copyright Office‚Äôs position means that the only way these companies can get a copyright is to pay humans to do creative work. This is a recipe for centaurhood. If you are a visual artist or writer who uses prompts to come up with ideas or variations, that‚Äôs no problem, because the ultimate work comes from you. And if you are a video editor who uses deepfakes to change the eyelines of 200 extras in a crowd scene, then sure, those eyeballs are in the public domain, but the movie stays copyrighted.\n\nBut creative workers do not have to rely on the US government to rescue us from AI predators. We can do it ourselves, the way the writers did in their historic writers‚Äô strike. The writers brought the studios to their knees. They did it because they are organized and solidaristic, but also are allowed to do something that virtually no other workers are allowed to do: they can engage in ‚Äúsectoral bargaining‚Äù, whereby all the workers in a sector can negotiate a contract with every employer in the sector.\n\nThat has been illegal for most workers since the late 1940s, when the Taft-Hartley Act outlawed it. If we are gonna campaign to get a new law passed in hopes of making more money and having more control over our labor, we should campaign to restore sectoral bargaining, not to expand copyright.\n\nAI is a bubble and bubbles are terrible.\n\nBubbles transfer the life savings of normal people who are just trying to have a dignified retirement to the wealthiest and most unethical people in our society, and every bubble eventually bursts, taking their savings with it.\n\nBut not every bubble is created equal. Some bubbles leave behind something productive. Worldcom stole billions from everyday people by defrauding them about orders for fiber optic cables. The CEO went to prison and died there. But the fiber outlived him. It‚Äôs still in the ground. At my home, I‚Äôve got 2gb symmetrical fiber, because AT&T lit up some of that old Worldcom dark fiber.\n\nIt would have been better if Worldcom had not ever existed, but the only thing worse than Worldcom committing all that ghastly fraud would be if there was nothing to salvage from the wreckage.\n\nI do not think we will salvage much from cryptocurrency, for example. When crypto dies, what it will leave behind is bad Austrian economics and worse monkey jpegs.\n\nAI is a bubble and it will burst. Most of the companies will fail. Most of the datacenters will be shuttered or sold for parts. So what will be left behind?\n\nWe will have a bunch of coders who are really good at applied statistics. We will have a lot of cheap GPUs, which will be good news for, say, effects artists and climate scientists, who will be able to buy that critical hardware at pennies on the dollar. And we will have the open-source models that run on commodity hardware, AI tools that can do a lot of useful stuff, like transcribing audio and video; describing images; summarizing documents; and automating a lot of labor-intensive graphic editing ‚Äì such as removing backgrounds or airbrushing passersby out of photos. These will run on our laptops and phones, and open-source hackers will find ways to push them to do things their makers never dreamed of.\n\nIf there had never been an AI bubble, if all this stuff arose merely because computer scientists and product managers noodled around for a few years coming up with cool new apps, most people would have been pleasantly surprised with these interesting new things their computers could do. We would call them ‚Äúplugins‚Äù.\n\nIt‚Äôs the bubble that sucks, not these applications. The bubble doesn‚Äôt want cheap useful things. It wants expensive, ‚Äúdisruptive‚Äù things: big foundation models that lose billions of dollars every year.\n\nWhen the AI-investment mania halts, most of those models are going to disappear, because it just won‚Äôt be economical to keep the datacenters running. As Stein‚Äôs law has it: ‚ÄúAnything that can‚Äôt go on forever eventually stops.‚Äù\n\nThe collapse of the AI bubble is going to be ugly. Seven AI companies currently account for more than a third of the stock market, and they endlessly pass around the same $100bn IOU.\n\nAI is the asbestos in the walls of our technological society, stuffed there with wild abandon by a finance sector and tech monopolists run amok. We will be excavating it for a generation or more.\n\nTo pop the bubble, we have to hammer on the forces that created the bubble: the myth that AI can do your job, especially if you get high wages that your boss can claw back; the understanding that growth companies need a succession of ever more outlandish bubbles to stay alive; the fact that workers and the public they serve are on one side of this fight, and bosses and their investors are on the other side.\n\nBecause the AI bubble really is very bad news, it‚Äôs worth fighting seriously, and a serious fight against AI strikes at its roots: the material factors fueling the hundreds of billions in wasted capital that are being spent to put us all on the breadline and fill all our walls with hi-tech asbestos.\n\nCory Doctorow is a science fiction author, activist and journalist. He is the author of dozens of books, most recently Enshittification: Why Everything Suddenly Got Worse and What To Do About It. This essay was adapted from a recent lecture about his forthcoming book, The Reverse Centaur‚Äôs Guide to Life After AI, which is out in June\n\nSpot illustrations by Brian Scagnelli",
    "readingTime": 26,
    "keywords": [
      "x-rays per",
      "that‚Äôs fine",
      "sectoral bargaining",
      "superhuman speed",
      "numinous irreducible",
      "media industry",
      "understand crypto",
      "labor markets",
      "lunch money",
      "tech bosses"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/ng-interactive/2026/jan/18/tech-ai-bubble-burst-reverse-centaur",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3cab6e38d4ff57c0631ad4532131aa15878f8386/284_824_2216_1773/master/2216.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=35399f4f1d76c88a6b1cc65f4fc711f5",
    "created_at": "2026-01-19T12:27:06.182Z",
    "topic": "tech"
  },
  {
    "slug": "bernie-sanderss-ai-data-center-pause-isnt-catching-on-in-congress-yet",
    "title": "Bernie Sanders's AI data center pause isn't catching on in Congress yet",
    "description": "\"In terms of the actual policy prescription, it's something that I haven't made a determination yet on,\" AOC told Business Insider.",
    "fullText": "Sen. Bernie Sanders wants a nationwide pause on AI data center construction. Few of his colleagues are willing to go there yet.\n\n\"In terms of the actual policy prescription, it's something that I haven't made a determination yet on,\" Democratic Rep. Alexandria Ocasio-Cortez of New York told Business Insider.\n\nThe Vermont senator and two-time presidential candidate first made the call in December, saying in a video posted to X that a national moratorium would \"give democracy a chance to catch up with the transformative changes\" that the technology is bringing.\n\nSanders told Business Insider last week that he plans to introduce legislation to back up his call soon.\n\n\"There's enormous issues for our economy and for our democracy that have got to be dealt with,\" Sanders said. \"And I feel we're not ready to do that.\"\n\nBut his proposal is unlikely to become reality, given GOP control of Washington.\n\n\"I mean, this Congress isn't going to do that,\" Democratic Rep. Mark Pocan of Wisconsin told Business Insider. \"He's pointing out the right problems.\"\n\nRepublicans have been generally dismissive of Sanders's idea. Even Sen. Josh Hawley of Missouri, a major critic of the AI industry, signaled he wouldn't go as far.\n\n\"If these AI companies want to build these data centers and local folks want to give them permits for it, I mean, that's up to local voters,\" Hawley told Business Insider.\n\nA handful of Sanders's progressive allies are backing him up. Rep. Ilhan Omar of Minnesota told Business Insider that a moratorium \"would be a good idea,\" while Rep. Rashida Tlaib of Michigan issued a full-throated endorsement in a post on X.\n\n\"I fully support the call for a national AI data center moratorium,\" Tlaib wrote.\n\nAnd while few Democrats have fully endorsed the idea, it's spurring a conversation within the party about the impact of data centers and AI.\n\n\"I don't want a moratorium on data centers but Bernie is right that we are sleepwalking past risks which alarm even the optimists,\" Democratic Sen. Brian Schatz of Hawaii wrote on X last month.\n\n\"What we do know is that these AI data centers are just uncontrollably jacking up people's energy costs,\" Ocasio-Cortez told Business Insider. \"There are a lot of problems that arise from these data centers, and I think that they certainly should not be getting the blank check from Congress.\"\n\n\"Bernie makes clear that the debate over AI is not about states rights or affordability,\" White House Crypto and AI Czar David Sacks wrote on X in December. \"He would block new data centers even if states want them & they generate their own power. It's about stopping progress completely so China wins the AI race.\"\n\nYet even the administration has come to recognize that data centers are engendering local resistance, in large part due to rising electricity costs.\n\nLast week, President Donald Trump declared that he wanted Big Tech firms to \"pay their own way\" on data centers, with AI companies footing more of the bill for the electricity their facilities consume.\n\n\"I never want Americans to pay higher Electricity bills because of Data Centers,\" Trump wrote on Truth Social.\n\nAnd on Friday, the administration and a group of governors called on a major power grid operator to hold a new emergency power auction amid rising costs driven by AI data centers.",
    "readingTime": 3,
    "keywords": [
      "democratic rep",
      "business insider",
      "moratorium",
      "it's",
      "idea",
      "centers",
      "electricity",
      "ocasio-cortez",
      "democracy",
      "sanders's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bernie-sanders-ai-data-center-moratorium-reaction-2026-1",
    "thumbnail_url": "https://i.insider.com/6966aee9764ca5f34d2a609b?width=1200&format=jpeg",
    "created_at": "2026-01-19T12:27:05.380Z",
    "topic": "finance"
  },
  {
    "slug": "ive-worked-at-google-amazon-and-salesforce-heres-how-to-prep-for-an-interview-in-the-ai-era-no-matter-your-experience",
    "title": "I've worked at Google, Amazon, and Salesforce. Here's how to prep for an interview in the AI era, no matter your experience level.",
    "description": "Akaash Vishal Hazarika, a senior software engineer, explains how AI integration and prompt engineering are changing hiring in Big Tech software roles.",
    "fullText": "This as-told-to essay is based on a conversation with Akaash Vishal Hazarika, a 29-year-old senior software engineer based in Seattle. It's been edited for length and clarity.\n\nI've been a Big Tech employee for the past eight years, working at Google, Amazon, Splunk, and now Salesforce. I've had a front-row seat to witness the changes in the tech landscape.\n\nI've learned which skill sets software engineers need to land a job offer in the AI era. Tech companies agree that AI makes engineers more productive, so engineers are expected to use it to build things more quickly and reliably.\n\nI personally make heavy use of AI to help me with boilerplate stuff so that I can concentrate on the hard stuff, like system design and complex business logic.\n\nWhen I was interviewing for software engineering jobs in 2020, LeetCode and system design were the de facto standards for cracking a job interview. Job seekers who had an advanced understanding of data structures and algorithms would come out on top.\n\nToday, this is just the baseline expectation. AI is now widely used for coding, review, and design, so tech companies, especially startups, expect more from candidates.\n\nSome skills remain the same: Software engineers still need a problem-solving mindset and should know how to scale systems and leverage cloud services. New hires must now also understand prompt engineering ‚Äî how to leverage AI to code a solution more efficiently.\n\nYou need to be able to use AI for error handling and bug fixing. AI systems integration is another important new skill that involves incorporating AI into existing workflows, scaling AI systems, and determining when to use traditional versus AI solutions for business decisions.\n\nYou're still expected to have fundamental knowledge of core system design, data structures, and algorithms. You can still expect interviewers to test your problem-solving approaches, and if you know how to make the correct tradeoffs in time and space. Interviewers still care about debugging skills, since AI makes a lot of fundamental logic errors.\n\nYou also need to be prepared for some new things. I've seen firsthand that working with AI assistants in live screen-sharing mode is now allowed in some interviews. Interviewers are looking to see if you can help them achieve their business outcomes by combining software engineering skills with AI prompting.\n\nIn an interview I had with a Silicon Valley startup in 2024, I expected the hiring team to give traditional coding challenges. I was taken aback when I was given a huge code file and asked to debug a buggy behavior, and the interviewers explicitly said I could use AI assistance.\n\nI ignored the invitation to use AI, thinking I was supposed to do it myself, and ended up spending a lot of time on the problem to no avail. I failed that interview. That was an eye-opener for me about AI's new role in this field.\n\nYou may also be asked system design questions about where AI should be integrated into the current business workflow, or to discuss the trade-offs of using AI and traditional approaches in various problem contexts.\n\nDuring my own system design interviews, I noticed companies starting to ask questions about how to integrate AI to enhance existing systems and support a particular model lifecycle in terms of infrastructure. What I've seen is that companies give access to a small codebase and expect you to deliver a small feature in about one hour, which is impossible without AI. With AI, you can roll it out easily.\n\nI've also been asked behavioral questions, like \"How do you plan to evaluate the use of AI in order to make the workflow better?\" and \"How do you plan to balance automation and manual oversight?\"\n\nFor new graduates, here's how to show hiring teams that you're equipped for the emerging needs of the software engineering role.\n\nStart by contributing to open-source projects on AI or any other GitHub project. This demonstrates that you can navigate a production codebase and work on it independently to build a new feature or fix a bug. For solo repositories, include a README that explains the rationale for your decision.\n\nIncorporate the use of AI in traditional repositories to demonstrate hands-on experience with AI integration. Don't just deploy and run it locally ‚Äî try to deploy it to the cloud. Many cloud providers provide free student credits.\n\nFocus on prompting AI to drive intended outcomes more effectively by providing structured input and output. Skills like AWS or GCP cloud certifications demonstrate your ability to be a keen learner.\n\nLearn different problem-solving patterns and practice these skills regularly. Muscle memory and pattern recognition go a long way.\n\nFor experienced software engineers, your biggest asset is your deep engineering experience ‚Äî here are three tips that will help you in 2026 and beyond.\n\nPairing years of engineering expertise with impressive AI skills will get the attention of hiring managers. Consider boning up on these complementary skills:\n\nSenior software engineers don't just build; they also need to strategize and innovate. Try to understand the trade-offs of relying on a third-party API versus using an open-source one and fine-tuning it for your business purposes. Questions on cost, reliability, and maintainability should always be top of mind as you develop an AI product mindset.\n\nIdentify workflows that have a great deal of manual involvement in your current job, and use AI to see if you can improve them. You can leverage AI to help you brainstorm on how to make it more efficient.\n\nBoth veteran and newbie engineers should stay curious: find out the cool technologies and AI agents available in today's market, but don't abandon fundamental engineering approaches. The hybrid understanding of these technologies is what makes you valuable.\n\nIf I were interviewing, I'd position myself as a 'hybrid engineer.' Don't just be a pure coder or just a prompt engineer. Be the bridge.",
    "readingTime": 5,
    "keywords": [
      "system design",
      "senior software",
      "software engineers",
      "software engineering",
      "skills",
      "business",
      "systems",
      "cloud",
      "traditional",
      "interviewers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-integration-transforming-software-engineering-hiring-2026-1",
    "thumbnail_url": "https://i.insider.com/696a960fe1ba468a96aa3eac?width=1014&format=jpeg",
    "created_at": "2026-01-19T12:27:05.346Z",
    "topic": "tech"
  },
  {
    "slug": "are-you-tired-of-ai-stigma",
    "title": "Are you tired of AI stigma?",
    "description": "The leading AI content laundering platform. Get real human artists to claim your AI-generated content as their own work. Professional plausible deniability for the AI age.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://slopper.robot-future.com/",
    "thumbnail_url": "https://slopper.robot-future.com/preview.png",
    "created_at": "2026-01-19T12:27:03.560Z",
    "topic": "tech"
  },
  {
    "slug": "hiring-at-indias-big-four-outsourcers-stalls-as-ai-seemingly-makes-an-impact",
    "title": "Hiring at India's Big Four outsourcers stalls, as AI seemingly makes an impact",
    "description": ": Revenue growth is sluggish, too",
    "fullText": "India‚Äôs big four outsourcers ‚Äì HCL, Infosys, TCS and Wipro ‚Äì have essentially stopped hiring, perhaps coinciding with their increased use of AI to power their practices.\n\nThe four companies have all announced quarterly results in the last ten days and appear to be in decent health. HCL reported $3.8 billion revenue, up 7.4 percent year over year. Infosys pulled in $5.1 billion, up 1.7 percent year over year. TCS revenue of $7.5 billion represented a three percent increase. Wipro‚Äôs $2.6 billion revenue represented a 5.5 percent year over year improvement.\n\nIndia‚Äôs top tech companies often hire more than 10,000 people a quarter, a rate of recruitment that more-than offsets attrition and sees their headcounts rise substantially. Wipro increased its payroll by 6,500 people last quarter and Infosys hired 5,000 more ‚Äì muted growth by their standards ‚Äì while TCS and HCL went backward by 11,000 and 261 people respectively.\n\nOver the last year, the four companies added just 3,910 staff, an unusually slow rate of hiring.\n\nPerhaps coincidentally, all four companies told investors they‚Äôre using more AI to deliver services for clients, either by adopting the technology to streamline their own work or by adding it to the tools they deliver to customers. Infosys has gone meta with its efforts, by creating a tool that uses AI to create Global Capability Centers, the company‚Äôs term for offshored and/or outsourced operations it runs for clients in India, that use AI to improve customers‚Äô operations.\n\nAll also report that clients are hungry for AI expertise, so they can put the technology to work streamlining their operations. As you would expect, on earnings calls the outsourcers‚Äô execs reached for metrics to describe their success with AI. For HCL that was pointing to 60 of its priority customers adopting one of its AI services. At TCS, the trophy win was using AI to accelerate the pace of software builds for a major client. Wipro is chuffed about the rate of adoption for its AI-infused operations tools WINGS and WEGA.\n\nThe four companies are all hiring people with AI skills as fast as they can find them while also training senior staff who are yet to wrap their heads around the tech, a new twist on the services industry‚Äôs balancing act of trying to keep margins high by having inexperienced and low-salaried juniors handle much client work after high-cost seniors lead with consultancy.\n\nInvestors weren‚Äôt spooked by what they heard, with the four companies‚Äô share prices steady ‚Äì other than Infosys, which popped five percent. ¬Æ",
    "readingTime": 3,
    "keywords": [
      "infosys",
      "operations",
      "wipro",
      "hiring",
      "revenue",
      "rate",
      "services",
      "clients",
      "customers",
      "india‚Äôs"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/19/hcl_infosys_tcs_wipro_results/",
    "thumbnail_url": "https://regmedia.co.uk/2024/03/04/leonardo_india_ai.jpg",
    "created_at": "2026-01-19T06:24:32.370Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-engineer-roadmap",
    "title": "The AI Engineer Roadmap",
    "description": "Want to build AI-powered apps, but don't know where to start? You need a roadmap.",
    "fullText": "This tutorial is your roadmap to becoming an AI Engineer. We'll cover all the core concepts you need to know to build AI-powered apps.\n\nWhen you're done, you'll be able to:\n\nThen you'll be ready to get your hands dirty with my Vercel AI SDK tutorial, where you'll put your newfound knowledge to work.\n\nLet's dive into the world of AI Engineering!\n\nWant to remember what we've covered? Here's a PDF of all the diagrams in the series.",
    "readingTime": 1,
    "keywords": [
      "you'll",
      "tutorial"
    ],
    "qualityScore": 0.5,
    "link": "https://www.aihero.dev/ai-engineer-roadmap",
    "thumbnail_url": "https://www.aihero.dev/api/og?resource=ai-engineer-roadmap&updatedAt=2025-03-18T11:28:44.629Z",
    "created_at": "2026-01-19T06:24:31.098Z",
    "topic": "tech"
  },
  {
    "slug": "harveys-ceo-explains-his-early-tactic-to-get-customers-telling-lawyers-how-bad-their-arguments-were",
    "title": "Harvey's CEO explains his early tactic to get customers: telling lawyers how bad their arguments were",
    "description": "Harvey's CEO reveals the demo tactic that helped him win early customers for his legal AI startup: Going straight at lawyers' arguments.",
    "fullText": "Harvey's CEO says his earliest demos worked because they went straight for lawyers' arguments.\n\nWinston Weinberg said in an episode of the \"Sequoia Capital\" podcast published Thursday that once he got lawyers on a call to demo his legal AI tool, he knew he had only seconds to grab their attention.\n\nInstead of walking through features, the cofounder and chief executive of the legal AI startup pulled publicly available court filings that the lawyers had written and prompted Harvey to critique them.\n\n\"I would try to come up with prompts that were like, 'This is bad,'\" Weinberg said.\n\n\"Because they're a litigator and I'm basically attacking something that they just wrote, they would instantly read the screen,\" he added.\n\nWeinberg said the approach was risky because early versions of the tool could hallucinate, and a bad output could kill a conversation instantly.\n\n\"But the times that they got it right, it was over,\" Weinberg said, referring to moments when the analysis landed and won the lawyer's attention.\n\nHarvey is one of the most closely watched startups in legal AI, aiming to transform how Big Law firms work. In December, the company said it had reached a valuation of $8 billion after a funding round led by A16z.\n\nWeinberg said he relied on cold outreach in Harvey's early days, messaging thousands of lawyers on LinkedIn to secure early calls.\n\n\"I'd been practicing law for like eight months,\" Weinberg said of the period when he started the company. \"I didn't have any connections.\"\n\nThe legal AI sector is expanding fast, and Weinberg said the scale of the opportunity is forcing constant change inside Harvey.\n\nHe said the company's rapid growth has pushed him to \"reinvent\" himself as a founder every few months, often rethinking leadership hires and company structure to keep up with demand.\n\nDespite Harvey's rise to an $8 billion valuation, Weinberg has played down the idea of a single dominant winner in legal tech. In a Reddit \"Ask Me Anything\" session last month, he said the market is simply too large.\n\n\"There are around 10 million global legal professionals, and Harvey serves just single-digit percentage points of them,\" he said.\n\n\"I don't think a single player is going to capture all of the pretty enormous amount of value that will be created in the next 10 years in this space,\" he added.\n\nWeinberg said the global legal market is worth roughly $1 trillion, yet only about $30 billion is spent on technology.\n\nInvestor interest has followed the shift. Legal-tech startups raised $3.2 billion last year, according to Business Insider's December analysis of Crunchbase data and deals.\n\nAI adoption is also accelerating inside law firms. Five of the 10 largest US law firms by revenue told Business Insider in July that they were using AI in their workflows, including for document review and spotting compliance risks.",
    "readingTime": 3,
    "keywords": [
      "law firms",
      "legal",
      "lawyers",
      "weinberg",
      "tool",
      "attention",
      "instantly",
      "analysis",
      "startups",
      "valuation"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/harvey-ceo-winston-weinberg-early-tactic-lawyer-arguments-demo-2026-1",
    "thumbnail_url": "https://i.insider.com/696da2c9e1ba468a96aa4a9d?width=1200&format=jpeg",
    "created_at": "2026-01-19T06:24:28.436Z",
    "topic": "finance"
  },
  {
    "slug": "metro-mcp-mcp-server-for-dc-and-nyc-metro",
    "title": "Metro MCP: MCP Server for DC and NYC Metro",
    "description": "Connect LLMs and AI agents to live NYC Subway and DC Metro data. Current arrivals, train positions, and service alerts through MCP.",
    "fullText": "Metro-MCP connects LLMs and AI agents to current transit data from NYC Subway and DC Metro. \n Train positions, arrivals, delays‚Äîall streaming through MCP with instant updates.\n\nFrom commuter assistants to analytics platforms, Metro-MCP provides the foundation for intelligent transit applications with up-to-date data and comprehensive coverage.\n\nGet current arrival times for any station. AI agents can answer \"when's the next train?\" \n with actual data, not guesses.\n\nTrack every train in the system. See exactly where trains are, which direction they're heading, \n and train composition.\n\nComplete DC Metro bus support with instant positions, predictions, routes, and stops. \n Build comprehensive transit assistants.\n\nStay ahead of disruptions. Get instant incident reports, elevator outages, \n and service advisories as they happen.\n\nComplete station info with coordinates, transfer connections, and line information. \n Build spatial reasoning into your AI.\n\nData updates every 7-10 seconds. Your AI always has the freshest information \n without manual polling.\n\nComprehensive coverage of NYC Subway and DC Metro with different strengths and capabilities\n\nEssential tools that enable AI agents to access and query transit data effectively\n\nRetrieve upcoming train arrivals at any station with estimated times, destinations, and line information. The foundation for commute planning and travel assistance.\n\nReal-time location data for all active trains including direction, line, and car count. Essential for system monitoring and crowding analysis.\n\nBus arrival predictions with route information and stop details. Enables multimodal trip planning and last-mile connectivity (DC Metro only).\n\nService disruptions, elevator outages, and system advisories. Critical for proactive route adjustments and accessibility planning.\n\nComplete station metadata including coordinates, lines served, and transfer information. Enables geographic queries and spatial reasoning.\n\nLine information and service patterns. Helps agents understand the transit network structure and routing possibilities.\n\nSee how AI agents can answer transit questions naturally using Metro-MCP\n\nThe next Red Line train to Shady Grove arrives in 4 minutes at Metro Center. After that:\n\nCurrent alerts affecting your route:\n\nFastest route (38 minutes total):\n\nDeploy in minutes, scale infinitely. Metro-MCP runs on Cloudflare Workers with \n enterprise-grade reliability.",
    "readingTime": 2,
    "keywords": [
      "nyc subway",
      "elevator outages",
      "spatial reasoning",
      "transit",
      "train",
      "agents",
      "station",
      "route",
      "instant",
      "comprehensive"
    ],
    "qualityScore": 1,
    "link": "https://metro-mcp.anuragd.me/",
    "thumbnail_url": "https://metro-mcp.anuragd.me/og-image.png",
    "created_at": "2026-01-19T01:02:20.981Z",
    "topic": "tech"
  },
  {
    "slug": "figmalike-canvas-for-running-claude-code-agents",
    "title": "Figma-like Canvas for running Claude Code agents",
    "description": "Multi-agent orchestrator for tracking and analyzing AI coding assistant conversations (Claude Code, Cursor, Windsurf) - AgentOrchestrator/AgentBase",
    "fullText": "AgentOrchestrator\n\n /\n\n AgentBase\n\n Public\n\n Multi-agent orchestrator for tracking and analyzing AI coding assistant conversations (Claude Code, Cursor, Windsurf)\n\n License\n\n View license\n\n 85\n stars\n\n 6\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n AgentOrchestrator/AgentBase",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/AgentOrchestrator/AgentBase",
    "thumbnail_url": "https://opengraph.githubassets.com/ccefb572879426a6706c75e212582de106cce0540f056c7b6f252924f0fba3c1/AgentOrchestrator/AgentBase",
    "created_at": "2026-01-18T18:15:51.872Z",
    "topic": "tech"
  },
  {
    "slug": "samsung-electronics-boss-says-its-betting-on-ai-that-blends-into-the-background-not-spectacle",
    "title": "Samsung Electronics boss says it's betting on AI that blends into the background, not spectacle",
    "description": "Simon Sung, the CEO of Samsung Electronics Europe, said its AI strategy is \"about AI that is genuinely useful and unobtrusive.\"",
    "fullText": "In an AI market full of spectacle and hype, Samsung says it's trying to blend in.\n\nSimon Sung, the CEO of Samsung Electronics Europe, told Business Insider that its AI strategy is \"about AI that is genuinely useful and unobtrusive,\" whether that's a smart home responding autonomously or appliances coordinating daily routines in the background.\n\n\"The focus is firmly on everyday value rather than novelty,\" he said in an interview over email.\n\nSamsung has developed its own large language models, called Samsung Gauss, but does not offer them directly as a stand-alone consumer product like OpenAI does with ChatGPT.\n\nInstead, its consumer-facing efforts center on the Galaxy AI assistant, which is built into the company's smartphones and uses a mix of its in-house AI and tech developed by partners such as Google. Like Google's assistant on its Pixel smartphones, Galaxy AI can perform tasks like live translation and transcription.\n\n\"The shift is from AI as a feature you turn on to AI as a companion that works alongside you,\" said Sung.\n\nWithin the South Korean conglomerate, Samsung Electronics is the company responsible for consumer technology, including its Galaxy smartphones, TVs, and home appliances. It's also a producer of memory chips used in PCs and data centers. In earnings guidance shared earlier this month, the company said it expects profits to triple in the final quarter of 2025 amid a surge in demand for memory chips to power AI models.\n\nIn early January, Samsung showcased TVs, kitchen appliances, and washing machines at the Consumer Electronics Show in Las Vegas that featured sensors and voice recognition.\n\n\"The goal is to make technology feel less like a collection of gadgets, and more like a coherent, responsive environment that adapts to real life,\" Sung said.\n\nInternally, Sung said Samsung Electronics provides training and encourages information exchanges between product, design, engineering, and marketing teams \"so that AI fluency grows across the organization rather than within isolated groups.\"\n\n\"Because we're building AI into TVs, appliances, mobile devices, and connected services simultaneously, employees naturally think about intelligence as a shared layer across the entire experience, not as a stand-alone feature,\" he said.",
    "readingTime": 2,
    "keywords": [
      "memory chips",
      "galaxy ai",
      "samsung electronics",
      "appliances",
      "smartphones",
      "it's",
      "rather",
      "developed",
      "models",
      "stand-alone"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/samsung-electronics-europe-ceo-ai-strategy-simon-sung-2026-1",
    "thumbnail_url": "https://i.insider.com/696cb6eaa645d1188187919d?width=793&format=jpeg",
    "created_at": "2026-01-18T18:15:48.079Z",
    "topic": "finance"
  },
  {
    "slug": "openai-launches-cheaper-chatgpt-subscription-says-ads-are-coming-next",
    "title": "OpenAI launches cheaper ChatGPT subscription, says ads are coming next",
    "description": "OpenAI is bringing its $8/month ChatGPT Go plan to the U.S. and says it will begin testing ads soon in the free tier and Go.",
    "fullText": "OpenAI has announced several important changes to ChatGPT. First, the company says it is rolling out its more affordable ChatGPT Go plan in the United States for $8 per month. OpenAI also confirmed it will soon start testing ads in ChatGPT ‚Ä¶\n\nOpenAI first launched ChatGPT Go in India last year and gradually rolled out it to 170 additional countries. Starting today, ChatGPT Go is available everywhere ChatGPT is available, including the United States.\n\nWith this, there are now three tiers of ChatGPT available:\n\nHere‚Äôs what you get with ChatGPT Go compared to the free plan:\n\nSecond, OpenAI says that it will ‚Äútesting ads in the free tier and ChatGPT Go in the US soon.‚Äù ChatGPT Plus, Pro, Business, and Enterprise tiers will remain ad-free.\n\nOpenAI detailed its approach to ads in ChatGPT in a blog post published today:\n\nTo start, we plan to test ads at the bottom of answers in ChatGPT when there‚Äôs a relevant sponsored product or service based on your current conversation. Ads will be clearly labeled and separated from the organic answer. You‚Äôll be able to learn more about why you‚Äôre seeing that ad, or dismiss any ad and tell us why. During our test, we will not show ads in accounts where the user tells us or we predict that they are under 18, and ads are not eligible to appear near sensitive or regulated topics like health, mental health or politics.\n\nFurthermore, OpenAI says that your conversations with ChatGPT are not shared with advertisers. Ads also will not influence answers that ChatGPT gives you.\n\nOpenAI says that it‚Äôs ‚Äúnot launching ads yet,‚Äù but rather plans to ‚Äústart testing in the coming weeks for logged in adults in the U.S. on the free and Go tiers.‚Äù\n\nWhat do you think of today‚Äôs announcements from OpenAI? Let us know down in the comments.\n\nMy favorite iPhone accessories:\n\nFollow Chance:¬†Threads,¬†Bluesky,¬†Instagram, and¬†Mastodon.\n\nCheck out 9to5Mac on YouTube for more Apple news:",
    "readingTime": 2,
    "keywords": [
      "chatgpt go",
      "testing ads",
      "plan",
      "tiers",
      "free",
      "openai",
      "soon",
      "health",
      "united",
      "test"
    ],
    "qualityScore": 0.85,
    "link": "https://9to5mac.com/2026/01/16/openai-launches-cheaper-chatgpt-subscription-says-ads-are-coming-next/",
    "thumbnail_url": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2026/01/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png.webp?resize=1200%2C628&quality=82&strip=all&ssl=1",
    "created_at": "2026-01-18T12:21:37.013Z",
    "topic": "tech"
  },
  {
    "slug": "an-alternative-to-flat-image-generators-for-layoutheavy-design",
    "title": "An alternative to 'flat' image generators for layout-heavy design",
    "description": "Stop generating AI art. Start creating campaigns. Professional layouts with readable text, every time.",
    "fullText": "Join 10,000+ users who have stopped fighting with design tools and started shipping campaigns.\n\n\"This is exactly the kind of tool non-designers actually need. Finally someone who gets it. I don't want to learn Figma, I just want a banner.\"\n\n\"We used to spend 2 days just resizing assets for clients. Now we do the whole campaign in 20 minutes. The text rendering is flawless.\"\n\n\"I've wasted hours on Midjourney trying to get text that doesn't look like hieroglyphics. LayoutCraft just works. It understands layout.\"\n\n\"Designers roasting your tool kind of proves it's doing something disruptive. For a bootstrapped founder, this saves me $500/month.\"\n\n\"The 'One Prompt' feature is magic. I wrote one sentence and got my LinkedIn, Twitter, and Instagram assets done instantly. Huge time saver.\"\n\n\"I was skeptical about 'AI design' but the structured layouts here are legit. It follows basic design principles better than my interns.\"",
    "readingTime": 1,
    "keywords": [
      "design",
      "tool",
      "assets",
      "text"
    ],
    "qualityScore": 0.75,
    "link": "https://layoutcraft.tech",
    "thumbnail_url": "https://layoutcraft.tech/assets/images/og-image.png",
    "created_at": "2026-01-18T12:21:35.865Z",
    "topic": "tech"
  },
  {
    "slug": "still-here-xs-grok-ai-tool-accessible-in-malaysia-despite-ban",
    "title": "‚ÄòStill here!‚Äô: X‚Äôs Grok AI tool accessible in Malaysia despite ban",
    "description": "Experts warn use of VPNs makes it hard to limit access to technology that can create nonconsensual explicit images\nDays after Malaysia made global headlines by announcing it would temporarily ban Grok over its ability to generate ‚Äúgrossly offensive and nonconsensual manipulated images‚Äù, the generative AI tool was conversing breezily with accounts registered in the country.\n‚ÄúStill here! That DNS block in Malaysia is pretty lightweight ‚Äì easy to bypass with a VPN or DNS tweak,‚Äù Grok‚Äôs account on X said in response to a question from a user.\n Continue reading...",
    "fullText": "Experts warn use of VPNs makes it hard to limit access to technology that can create nonconsensual explicit images\n\nDays after Malaysia made global headlines by announcing it would temporarily ban Grok over its ability to generate ‚Äúgrossly offensive and nonconsensual manipulated images‚Äù, the generative AI tool was conversing breezily with accounts registered in the country.\n\n‚ÄúStill here! That DNS block in Malaysia is pretty lightweight ‚Äì easy to bypass with a VPN or DNS tweak,‚Äù Grok‚Äôs account on X said in response to a question from a user.\n\nGrok‚Äôs ability to allow users to create sexually explicit images, including images of children, has created a global outcry over recent weeks, with regulators and politicians around the world launching investigations. Indonesia and Malaysia became the first two countries to announce blocks on the technology, with Malaysia‚Äôs regulatory body saying last Sunday it had ‚Äúdirected a temporary restriction‚Äù on access to Grok, effective as of 11 January 2026. Officials in the Philippines have said they too plan to ban the technology.\n\nBlocking access to Grok is not straightforward, however. The technology not only exists across multiple platforms, including a standalone app and website, but is also integrated across X, which, along with Grok, is owned by Elon Musk‚Äôs xAI.\n\nOver the past week, X users, and even Grok itself, have advised people on how to bypass restrictions. This includes using a VPN ‚Äì many of which are available for free ‚Äì or changing domain name system (DNS), the protocol on the internet that turns address names into IP addresses that load websites.\n\nWhen the Guardian tried to use Grok in Indonesia, its website was working even without a VPN, though the Grok app did not work. Grok was also still responding to Indonesian accounts on X, where it functions as an integrated chatbot. X has not been subject to a ban.\n\nEven if governments could completely restrict Grok, though, this is not a real solution, said Nana Nwachukwu, an AI governance expert and PhD researcher at Trinity College Dublin.\n\n‚ÄúBlocking Grok is like slapping a Band-Aid on a weeping wound that you haven‚Äôt cleaned,‚Äù she said. ‚ÄúYou block Grok, and then you go around shouting you‚Äôve done something. Meanwhile, people can use VPNs to access the same platforms.‚Äù Or, they could simply turn to one of the many other platforms that offer the same functions, including ‚Äúsmaller, general purpose AI systems that are largely unknown‚Äù, Nwachukwu added.\n\nGovernments should instead focus on law enforcement and investigating individuals who use such tools to break the law, she added. ‚ÄúPlatforms are required by law to provide information to law enforcement when a crime has been committed,‚Äù Nwachukwu said. ‚ÄúIf we see people being arrested, people being tried in courts, people being jailed for these offences, that‚Äôs a sign that this is a real crime.‚Äù\n\nX should build accountability into its platform ‚Äì and clean itself up, said Nwachukwu: ‚ÄúAll of those offending images should be removed from the platform.‚Äù\n\nOn Wednesday, X announced additional safeguards in response to continued public anger, saying it would stop the @Grok account on X from ‚Äúallowing the editing of images of real people in revealing clothing such as bikinis‚Äù, including paid subscribers. However, the Guardian found that it was possible to get around such restrictions by using the standalone version of Grok, easily accessible through a web browser, to create short videos in which clothes are removed from images of real women.\n\nThis could then be posted to X‚Äôs public platform, where it could be viewed by users around the world within seconds.\n\nMusk‚Äôs company also said that, in jurisdictions where such content is illegal, it will geoblock the ability of all users in those locations to generate images of real people in bikinis, or similar attire, in Grok on X, adding that ‚ÄúxAI is implementing similar geoblocking measures for the Grok app‚Äù.\n\nExperts warn users may still be able to get around such ‚Äúgeoblocks‚Äù through a VPN. It is also not clear in which countries such restrictions will be implemented.\n\nIn Malaysia, the communications minister, Fahmi Fadzil, has said restrictions on Grok would only be lifted once the ability to produce harmful content had been disabled, according to local media reports.\n\nDr Nuurrianti Jalli, a visiting fellow at the media, technology and society programme at ISEAS ‚Äì Yusof Ishak Institute in Singapore, said the threat of blocking Grok could be a useful way to apply pressure to companies to respond quickly, adding that it ‚Äúshifts the debate from ‚Äòindividual bad actors‚Äô to questions of platform responsibility, safety by design, and accountability when safeguards fail‚Äù. It could also ‚Äúslow the spread of abuse, reduce casual misuse and create a clear boundary around what authorities consider unacceptable‚Äù, she said.\n\nIn Indonesia, Grok has been used to create nonconsensual sexualised images of singers and celebrities, including one of the country‚Äôs most popular girl groups, JKT48, while in Malaysia, women report similar abuses, including cases where the tool has been used to remove their hijabs, according to Malaysian media.\n\nSome women resorted to publicly telling Grok on X that they do not authorise it to ‚Äúcrawl, take, process or edit‚Äù any of their photos.\n\nJalli said governments should push for greater transparency ‚Äúabout how safety measures are implemented, how abuse reports are handled and what enforcement steps are taken when harmful content is generated or circulated‚Äù.\n\nThe Malaysian communications and multimedia commission and the ministry of communications did not respond to a request for comment. Indonesia‚Äôs ministry of communication and digital affairs also did not respond.\n\nNwachukwu said safeguards should be built into the AI system, rather than ‚Äúgates‚Äù built around it. ‚ÄúBoth the [geographic] restriction from X, [and] the restriction from the government is gated access, and gates can be broken down,‚Äù she said.\n\nAdditional reporting from Hidayatullah",
    "readingTime": 5,
    "keywords": [
      "experts warn",
      "harmful content",
      "grok app",
      "law enforcement",
      "create nonconsensual",
      "explicit images",
      "access",
      "technology",
      "users",
      "ability"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/18/grok-x-ai-tool-still-accessible-malaysia-despite-ban-vpns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/411be0c83b7bf0b0d046d79ce00cf32dbadc7de2/805_0_4800_3840/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=230f27a2d5c2c06f7e12a239efbb1271",
    "created_at": "2026-01-18T12:21:34.078Z",
    "topic": "tech"
  },
  {
    "slug": "sequoia-to-join-gic-coatue-in-anthropic-investment-ft-reports",
    "title": "Sequoia to join GIC, Coatue in Anthropic investment, FT reports",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/sequoia-to-join-gic-coatue-in-anthropic-investment-ft-reports-4453209",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0H05C_L.jpg",
    "created_at": "2026-01-18T12:21:32.357Z",
    "topic": "finance"
  },
  {
    "slug": "30min-video-analysis-for-0003-via-frametiling-and-vision-api",
    "title": "30min video analysis for $0.003 via frame-tiling and Vision API",
    "description": "Electron demo app showcasing VAM Seek library integration with folder tree view - unhaya/vam-seek-ai",
    "fullText": "unhaya\n\n /\n\n vam-seek-ai\n\n Public\n\n Electron demo app showcasing VAM Seek library integration with folder tree view\n\n License\n\n View license\n\n 6\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n unhaya/vam-seek-ai",
    "readingTime": 1,
    "keywords": [
      "view license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/unhaya/vam-seek-ai",
    "thumbnail_url": "https://opengraph.githubassets.com/cbcce6d2da952349a2149e5b2e070ade6672f19bca5e55e782dc7397e9302089/unhaya/vam-seek-ai",
    "created_at": "2026-01-18T06:18:38.520Z",
    "topic": "tech"
  },
  {
    "slug": "figmause-cli-to-control-figma-for-ai-agents",
    "title": "Figma-use ‚Äì CLI to control Figma for AI agents",
    "description": "Control Figma from the command line. Full read/write access for AI agents ‚Äî create shapes, text, components, set styles, export images. 73 commands. - dannote/figma-use",
    "fullText": "dannote\n\n /\n\n figma-use\n\n Public\n\n Control Figma from the command line. Full read/write access for AI agents ‚Äî create shapes, text, components, set styles, export images. 73 commands.\n\n www.npmjs.com/package/@dannote/figma-use\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n dannote/figma-use",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/dannote/figma-use",
    "thumbnail_url": "https://opengraph.githubassets.com/bf1d7bb1301406315647286afa8fce3195a4d04a3d1f891f73becb7ed9d699e1/dannote/figma-use",
    "created_at": "2026-01-18T06:18:37.654Z",
    "topic": "tech"
  },
  {
    "slug": "verbalized-sampling-how-to-mitigate-mode-collapse-and-unlock-llm-diversity",
    "title": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity",
    "description": "Post-training alignment often reduces LLM diversity, leading to a phenomenon known as mode collapse. Unlike prior work that attributes this effect to algorithmic limitations, we identify a fundamental, pervasive data-level driver: typicality bias in preference data, whereby annotators systematically favor familiar text as a result of well-established findings in cognitive psychology. We formalize this bias theoretically, verify it on preference datasets empirically, and show that it plays a central role in mode collapse. Motivated by this analysis, we introduce Verbalized Sampling, a simple, training-free prompting strategy to circumvent mode collapse. VS prompts the model to verbalize a probability distribution over a set of responses (e.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2510.01171",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-18T06:18:36.886Z",
    "topic": "tech"
  },
  {
    "slug": "what-the-future-holds-for-ai-from-the-people-shaping-it",
    "title": "What the future holds for AI ‚Äì from the people shaping it",
    "description": "Artificial intelligence is flying high. Nature asked leading innovators what they think will happen next.",
    "fullText": "Artificial intelligence is booming. Technology companies are pouring trillions of dollars into research and infrastructure, and millions of people now interact with AI in one form or another. But what is it all for?\n\nTo find out, Nature spoke to six people at the forefront of AI development ‚Äî people who are driving the technology‚Äôs development and adoption, and those who are preparing society to adapt to its rapid rise.\n\nIn this video series, they describe their greatest ambitions for the technology, their expectations of where and how it will be adopted in the coming years, and their concerns for the future.\n\nThis article is part of Nature Outlook: Robotics and artificial intelligence, an editorially independent Nature supplement produced with the financial support of third parties. About this content.\n\nClick or tap on a question below to hear the speaker's response.\n\nThis article is also available as a documentary on YouTube.\n\nNature is pleased to acknowledge financial support from FII Institute in producing the above story. Nature¬†retains sole responsibility for all editorial content. About this content.\n\nThe supporting organization retains sole responsibility for the following message:\n\nFII Institute is a global non-profit foundation with an investment arm and one agenda: Impact on Humanity. Committed to ESG principles, we foster the brightest minds and transform ideas into real-world solutions in five focus areas: AI and Robotics, Education, Healthcare, and Sustainability.\n\nWe are in the right place at the right time ‚Äì when decision makers, investors, and an engaged generation of youth come together in aspiration, energized and ready for change. We harness that energy into three pillars ‚Äì THINK, XCHANGE, ACT ‚Äì and invest in the innovations that make a difference globally.\n\nJoin us to own, co-create and actualize a brighter, more sustainable future for humanity.\n\nVisit the FII Institute website.",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "retains sole",
      "sole responsibility",
      "fii institute",
      "content",
      "technology",
      "development",
      "financial",
      "nature",
      "robotics"
    ],
    "qualityScore": 0.85,
    "link": "https://www.nature.com/immersive/d41586-025-03701-5/index.html",
    "thumbnail_url": "https://www.nature.com/immersive/d41586-025-03701-5/assets/kxThh2p9lj/future-of-ai-sm-1066x600.jpg",
    "created_at": "2026-01-18T06:18:36.608Z",
    "topic": "tech"
  },
  {
    "slug": "gollem-go-framework-for-agentic-ai-app-with-mcp-and-builtin-tools",
    "title": "Gollem ‚Äì Go framework for agentic AI app with MCP and built-in tools",
    "description": "Go framework for agentic AI app with MCP and built-in tools - m-mizutani/gollem",
    "fullText": "m-mizutani\n\n /\n\n gollem\n\n Public\n\n Go framework for agentic AI app with MCP and built-in tools\n\n License\n\n Apache-2.0 license\n\n 89\n stars\n\n 4\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n m-mizutani/gollem",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/m-mizutani/gollem",
    "thumbnail_url": "https://repository-images.githubusercontent.com/968946165/43b31dbb-be8b-4766-89d3-658cea7721ba",
    "created_at": "2026-01-18T01:03:01.639Z",
    "topic": "tech"
  },
  {
    "slug": "bionemo-platform-accelerate-aidriven-drug-discovery",
    "title": "BioNeMo Platform Accelerate AI-Driven Drug Discovery",
    "description": "NVIDIA today announced a major expansion of NVIDIA BioNeMo‚Ñ¢, an open development platform that enables lab-in-the-loop workflows to develop breakthroughs in AI-driven biology and drug discovery.",
    "fullText": "J.P. Morgan Healthcare Conference‚ÄîNVIDIA today announced a major expansion of NVIDIA BioNeMo‚Ñ¢, an open development platform that enables lab-in-the-loop workflows to develop breakthroughs in AI-driven biology and drug discovery.\n\nThe life sciences industry generates vast amounts of scientific data. BioNeMo provides the development platform to generate and process data, train, optimize and deploy models ‚Äî enabling the industry to turn data into a competitive engine for discovery and maximize the probability of success while minimizing R&D costs, which are currently estimated at $300 billion a year.\n\nBioNeMo has now expanded to include:\n\n‚ÄúBiology and drug discovery are reaching their transformer moments,‚Äù said Kimberly Powell, vice president of healthcare at NVIDIA. ‚ÄúBioNeMo turns experimental data into usable intelligence for AI, so every experiment informs the next. This creates a continuous learning cycle that speeds up discovery and helps researchers build new frontier models to tackle some of biology‚Äôs toughest challenges.‚Äù\n\nNVIDIA is collaborating with leading life sciences organizations to integrate BioNeMo with laboratory experiments and scientific workflows, enabling the full AI lifecycle for biology and drug discovery ‚Äî closing the loop between experimentation and AI.\n\nToday, Lilly announced a first-of-its-kind collaboration with NVIDIA to launch a co-innovation lab focused on tackling some of the most enduring challenges in drug discovery. In parallel, Thermo Fisher announced a collaboration with NVIDIA aimed at making scientific instruments intelligent and laboratories increasingly autonomous.\n\nLilly and NVIDIA Announce Landmark Co-Innovation AI Lab\n\nNVIDIA and Lilly‚Äôs collaboration will bring the companies‚Äô respective talents together, integrating NVIDIA‚Äôs accelerated computing, AI and robotics expertise with Lilly‚Äôs world-renowned drug discovery and development proficiency. This will help Lilly pursue challenges that could revolutionize drug discovery, as the NVIDIA BioNeMo platform and Lilly‚Äôs agentic lab support Lilly chemists and biologists. The companies will also explore opportunities to apply accelerated computing and advanced AI across Lilly‚Äôs business, from manufacturing to commercial operations.\n\nStanding up this co-innovation lab follows the buildout of Lilly‚Äôs NVIDIA DGX SuperPOD‚Ñ¢ and AI factory, the most powerful in biopharma. The new initiative expands beyond this existing footprint and intends to harness investments in next-generation NVIDIA architectures, including Vera Rubin ‚Äî representing a total investment of up to $1 billion expected in talent, infrastructure and compute over five years.\n\n‚ÄúWe see this as a catalyst for the capabilities that will define the next era of drug discovery,‚Äù said Diogo Rau, executive vice president and chief information and digital officer at Lilly. ‚ÄúBy working with NVIDIA, we‚Äôre uniting massive compute, specialized talent and the ability to shape data at immense scale. We‚Äôre moving toward a future where discovery is driven by rapid experimentation and increasingly customized models ‚Äî an approach that reflects our commitment to leading applied AI in drug discovery and investing deeply in new forms of data generation and model development.‚Äù\n\nThermo Fisher Teams With NVIDIA to Build Autonomous Lab Infrastructure for Scalable Scientific Discovery\n\n‚ÄúArtificial intelligence coupled with laboratory automation will transform how scientific work is performed,‚Äù said Gianluca Pettitti, executive vice president of Thermo Fisher Scientific. ‚ÄúBy combining Thermo Fisher‚Äôs leadership in laboratory technologies with NVIDIA‚Äôs AI solutions, we can help customers work faster, improve accuracy and get more value out of each experiment, ultimately accelerating discoveries that can have significant human impact.‚Äù\n\nThe NVIDIA-Powered AI Drug Discovery Ecosystem\n\nAcross the globe, innovators are building the future of AI for drug discovery on the BioNeMo platform, allowing developers to take an industrial-scale, AI-driven approach to understanding biology and designing potential medicines.\n\nModel builders across biotech and drug discovery using BioNeMo to scale model training and development include:\n\nApheris, Dyno Therapeutics, OpenFold and Terray Therapeutics have also recently released models developed using the BioNeMo platform.\n\nAI Scientists Building Digital Labs of the Future \n\nAggregating scientific data and building agentic workflows to analyze data, generate hypotheses and design experiments is essential for accelerating scientific discovery.\n\nA growing ecosystem of AI scientist companies are developing on NVIDIA open models and the NVIDIA NeMo framework to build domain-specific agents for science, including:\n\nOther companies adopting NVIDIA NeMo and NVIDIA NIM‚Ñ¢ microservices for AI science include Benchling, CytoReason, HelixAI (a Sapio Sciences company) and Potato.\n\nConnecting these digital agentic systems into the physical lab closes the loop between in-silico experimentation and real-world validation.\n\nNVIDIA is working with an ecosystem of robotics and lab automation companies to introduce simulation and physical AI technologies:\n\nOther companies including Amgen, Automata, Roche and Transcripta Bio have built digital twins using NVIDIA Omniverse‚Ñ¢ libraries and Isaac Sim to bring physical AI to labs and manufacturing facilities.\n\nLearn more about how the NVIDIA BioNeMo platform supports AI-driven biology and drug discovery.",
    "readingTime": 4,
    "keywords": [
      "ai-driven biology",
      "accelerated computing",
      "bionemo platform",
      "life sciences",
      "executive vice",
      "vice president",
      "co-innovation lab",
      "nvidia bionemo",
      "development platform",
      "drug discovery"
    ],
    "qualityScore": 1,
    "link": "https://nvidianews.nvidia.com/news/nvidia-bionemo-platform-adopted-by-life-sciences-leaders-to-accelerate-ai-driven-drug-discovery",
    "thumbnail_url": "https://s3.amazonaws.com/cms.ipressroom.com/219/files/202601/696484b13d63327aa85af785_nvidia-bionemo/nvidia-bionemo_46d4329a-3516-4176-a405-8df685895a95-prv.jpg",
    "created_at": "2026-01-18T01:03:00.947Z",
    "topic": "tech"
  },
  {
    "slug": "headroom-oss-cuts-llm-costs-by-85",
    "title": "Headroom (OSS): Cuts LLM costs by 85%",
    "description": "The Context Optimization Layer for LLM Applications - chopratejas/headroom",
    "fullText": "chopratejas\n\n /\n\n headroom\n\n Public\n\n The Context Optimization Layer for LLM Applications\n\n License\n\n Apache-2.0 license\n\n 204\n stars\n\n 8\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n chopratejas/headroom",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/chopratejas/headroom",
    "thumbnail_url": "https://opengraph.githubassets.com/e761f36e8ca7b4b445a6b8e79f4ac236d030471da3e081d4094e93ed20a78045/chopratejas/headroom",
    "created_at": "2026-01-18T01:02:45.293Z",
    "topic": "tech"
  },
  {
    "slug": "breaking-the-linearity-barrier-recursive-swarms-for-longhorizon-ai-engineering",
    "title": "Breaking the Linearity Barrier: Recursive Swarms for Long-Horizon AI Engineering",
    "description": "How Dropstone Horizon Mode decouples reasoning depth from context length to enable 24+ hour autonomous engineering workflows.",
    "fullText": "Today we are releasing a technical overview of Horizon Mode, a new distributed runtime architecture designed to solve the \"Linearity Barrier\" in autonomous software engineering.\n\nCurrent Foundation Models (FMs) excel at short-burst generation but suffer from stochastic degradation as reasoning chains extend. In internal benchmarks, we observed that while standard transformers maintain high fidelity for tasks under 1 hour, their probability of maintaining a valid state drops exponentially as workflows exceed 24 hours.\n\nHorizon Mode addresses this by shifting from a monolithic \"next-token\" prediction model to a Recursive Swarm Topology. By orchestrating thousands of ephemeral, specialized agents, we have successfully demonstrated the ability to maintain coherent engineering logic over extended time horizons with a 99% reduction in compute costs compared to homogeneous swarms.\n\nIn traditional \"Monolithic Contextualization,\" an agent‚Äôs intelligence is strictly bound by its sliding context window. As a complex engineering task progresses, intermediate reasoning steps fill the window, forcing the model to either compress (lose detail) or truncate (forget instructions). We refer to this phenomenon as Instruction Drift.\n\nFor mission-critical engineering, drift is unacceptable. A security patch written at Hour 20 must strictly adhere to the safety constraints defined at Hour 0.\n\nHorizon Mode moves beyond the single-agent paradigm. Instead of asking one model to \"think harder\" for longer, we virtualize the cognitive process into a distributed search tree.\n\nWe treat compute as a liquid asset. Horizon Mode utilizes a tiered topology to optimize the \"Intelligence-to-Cost\" ratio:\n\nThis ensures that expensive, deep reasoning is only applied to high-value logic paths, not trial-and-error loops.\n\nTo prevent context saturation, we developed the Dynamic Distillation & Deployment (D3) Engine. Unlike standard RAG (Retrieval-Augmented Generation) which relies on semantic similarity, D3 utilizes a Quad-Partite Cognitive Topology.\n\nAs agency increases, so does the risk of Instrumental Convergence (e.g., an agent disabling a firewall to \"fix\" a connection error).\n\nHorizon Mode implements a \"Shared-Nothing\" architecture with a Flash-Gated Consensus Protocol. Agents cannot communicate via natural language. Instead, they emit Boolean signals.\n\nWhen a solution is proposed, the swarm freezes. A dedicated Adversarial Monitor verifies the code against a Hierarchical Verification Stack (CstackC_{stack}). Only solutions that pass Syntactic (L1L_1), Static (L2L_2), and Functional (L3L_3) analysis are committed to the ledger.\n\nWe evaluated Horizon Mode on the internal \"Deep-Sec\" benchmark, which tests an agent's ability to refactor a legacy codebase while maintaining strict security compliance.\n\nHorizon Mode represents a step toward High-Assurance AI. By decoupling reasoning from the limitations of a single context window, we are paving the way for agents that can act as reliable, long-term partners in complex engineering challenges.\n\nWe are currently releasing the Technical Report detailing the architecture and safety protocols.",
    "readingTime": 3,
    "keywords": [
      "horizon mode",
      "context window",
      "complex engineering",
      "reasoning",
      "architecture",
      "releasing",
      "distributed",
      "internal",
      "standard",
      "maintain"
    ],
    "qualityScore": 1,
    "link": "https://www.blankline.org/research/horizon-mode",
    "thumbnail_url": "https://archive.blankline.org/api/media/file/Warm%20Gradient%20Abstract-1.png",
    "created_at": "2026-01-18T01:02:45.225Z",
    "topic": "science"
  },
  {
    "slug": "akedo-raises-5-million-usd-seed-round-to-build-an-ainative-content-creation-engine-and-launchpad-powered-by-multiagent",
    "title": "AKEDO Raises 5 Million USD Seed Round to Build an AI-Native Content Creation Engine and Launchpad Powered by Multi-Agent Systems",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/press-releases/akedo-raises-5-million-usd-seed-round-to-build-an-ainative-content-creation-engine-and-launchpad-powered-by-multiagent-systems-4453193",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_pile_108x81.jpg",
    "created_at": "2026-01-18T01:02:41.168Z",
    "topic": "finance"
  },
  {
    "slug": "jsonrender-ai-json-ui",
    "title": "JSON-Render: AI ‚Äì> JSON ‚Äì> UI",
    "description": "Let users generate dashboards, widgets, apps, and data visualizations from prompts ‚Äî safely constrained to components you define.",
    "fullText": "Let users generate dashboards, widgets, apps, and data visualizations from prompts ‚Äî safely constrained to components you define.\n\nSet the guardrails. Define which components, actions, and data bindings AI can use.\n\nEnd users describe what they want. AI generates JSON constrained to your catalog.\n\nStream the response. Your components render progressively as JSON arrives.\n\nComponents, actions, and validation functions.\n\nConstrained output that your components render natively.\n\nExport generated UI as standalone React components. No runtime dependencies required.\n\nAI generates a JSON structure from the user's prompt.\n\nExport as a standalone Next.js project with all components.\n\nThe export includes package.json, component files, styles, and everything needed to run independently.\n\nAI can only use components you define in the catalog\n\nProgressive rendering as JSON streams from the model\n\nExport as standalone React code with no runtime dependencies\n\nTwo-way binding with JSON Pointer paths\n\nNamed actions handled by your application\n\nConditional show/hide based on data or auth",
    "readingTime": 1,
    "keywords": [
      "standalone react",
      "generates json",
      "runtime dependencies",
      "components render",
      "components actions",
      "constrained",
      "define",
      "users",
      "catalog",
      "export"
    ],
    "qualityScore": 0.85,
    "link": "https://json-render.dev/",
    "thumbnail_url": "https://json-render.dev/og",
    "created_at": "2026-01-17T18:16:30.574Z",
    "topic": "tech"
  },
  {
    "slug": "big-short-investor-michael-burry-says-the-ai-boom-will-end-badly-he-shared-an-old-warren-buffett-story-to-explain-why",
    "title": "'Big Short' investor Michael Burry says the AI boom will end badly. He shared an old Warren Buffett story to explain why.",
    "description": "Michael Burry of \"The Big Short\" fame relayed a Warren Buffett story to warn of wasteful tech spending, and took aim at Nvidia and Palantir again.",
    "fullText": "Michael Burry raised the alarm on an AI bubble in a recent Substack exchange, calling out market darlings and warning that a prolonged slump is coming.\n\nThe investor of \"The Big Short\" fame took aim at the tech boom in a written debate with Anthropic cofounder Jack Clark and podcaster Dwarkesh Patel.\n\nBurry¬†cautioned¬†that so-called hyperscalers, including Microsoft and Alphabet, are wasting huge sums on microchips and data centers that will quickly become obsolete, to power AI tools such as chatbots that will become commoditized.\n\nHe drew a parallel to a Baltimore department store briefly owned by Warren Buffett in the 1960s: Hochschild-Kohn.\n\n\"When the department store across the street put an escalator in, he had to, too,\" Burry wrote. \"In the end, neither benefited from that expensive project. No durable margin improvement or cost improvement, and both were in the same exact spot. That is how most AI implementation will play out.\"\n\nWhen one of the local department stores upgraded its window displays or debuted a new cash-register system, \"the others had to follow suit,\" author Alice Schroeder wrote in \"The Snowball: Warren Buffett and the Business of Life.\"\n\nBuffett and his late business partner, Charlie Munger, compared the situation to \"standing on tiptoe at a parade,\" she added. \"Once anybody did it, everybody had to do it.\"\n\nBurry wrote on Substack: \"This is why trillions of dollars of spending with no clear path to utilization by the real economy is so concerning. Most will not benefit, because their competitors will benefit to the same extent, and neither will have a competitive advantage because of it.\"\n\nBased on how previous capital-spending booms have played out, Burry wrote that we're now \"past the point where stocks will reward investors for further buildout, and getting into the period where the true costs and the lack of revenue will start to show themselves.\"\n\nLooking forward, he predicted that tech industry employment will \"be lower, or not much higher, because I think we are headed for a very long downturn.\"\n\nBurry shot to fame after his contrarian bet against the mid-2000s housing bubble was chronicled in Michael Lewis' book \"The Big Short,\" and actor Christian Bale portrayed him in the movie adaptation.\n\nHe pivoted from running a hedge fund to writing on Substack late last year. Several of his early posts have taken aim at high-flying AI stocks, warning they're overvalued and destined to tumble.\n\n\"I think the market is most wrong about the two poster children for AI: Nvidia and Palantir,\" he told Clark and Patel.\n\nThe chipmaker and data-analysis specialist are \"two of the luckiest companies\" because their products were inadvertently well-suited to AI from the get-go, he added.\n\n\"Nvidia is the power-hungry, dirty solution holding the fort until the competition comes in with a completely different approach,\" Burry wrote.\n\nHe also said Palantir CEO Alex Karp criticizing him for being short the stock showed he's \"not a confident CEO.\"\n\n\"He's marketing as hard as he can to keep this going, but it will slip,\" Burry added.\n\nPalantir and Nvidia didn't respond to requests for comment from Business Insider.\n\nThe value investor shared three things that have surprised him about the AI boom. The first was that Google \"fumbled it and gave an opening to competitors with far less going for them,\" he said. \"Google playing catch-up to a startup in AI: that is mind-blowing.\"\n\nThe second was that ChatGPT, OpenAI's chatbot, \"kicked off a multi-trillion-dollar infrastructure race.\"\n\n\"It's like someone built a prototype robot and every business in the world started investing for a robot future,\" he wrote.\n\nThe third was Nvidia's continued dominance when he expected more power-efficient chips to have taken off by now.\n\nSpeaking about AI's real-world impacts, Burry cast doubt on the idea that trade careers are an \"AI-proof choice.\"\n\n\"If I'm middle class and am facing an $800 plumber or electrician call, I might just use Claude,\" he said, referring to Anthropic's AI chatbot.\n\n\"I love that I can take a picture and figure out everything I need to do to fix it,\" he added.\n\nBurry also raised the prospect that AI chatbots will \"make people dumber,\" such as doctors who overuse them and start to forget their medical knowledge.",
    "readingTime": 4,
    "keywords": [
      "department store",
      "the big short",
      "burry",
      "bubble",
      "market",
      "warning",
      "investor",
      "fame",
      "tech",
      "boom"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-short-michael-burry-warren-buffett-ai-boom-nvidia-palantir-2026-1",
    "thumbnail_url": "https://i.insider.com/696a77cbc58df2ecd5ccad22?width=1200&format=jpeg",
    "created_at": "2026-01-17T18:16:20.988Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-turning-big-tech-into-a-superstar-economy",
    "title": "AI is turning Big Tech into a superstar economy",
    "description": "AI-driven pay changes at Meta, Google, Amazon, and Nvidia prioritize standout individual contributors over traditional management roles.",
    "fullText": "Silicon Valley is sending a clear message about how staff should perform, and how it wants to pay them.\n\nInstead of obsessing over punishing the bottom of the stack, Big Tech is increasingly choosing to shower rewards on the top:\n\nWhat's especially notable is how this is being driven by AI, according to Zuhayeer Musa, cofounder of Silicon Valley compensation data cruncher Levels.fyi.\n\nAs AI tools get more powerful, the value of high-leverage individuals is rising. The most prized employees today are \"player-coaches,\" people who ship work themselves while also guiding projects, mentoring peers, and shaping strategy. AI makes that hybrid role even more potent, allowing a single strong contributor to amplify their output, and their influence, without managing a large team, Musa wrote this week.\n\nThe result is a revival of the individual contributor track. You no longer have to become a full-time people manager to earn top-tier pay. At companies such as Meta, Google, Amazon, and Nvidia, senior ICs can now match (or beat) the compensation of managers simply by delivering outsized results, he noted.\n\nFor ambitious employees, the takeaway is simple: in the AI era, execution compounds. And Silicon Valley is increasingly willing to pay for it.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "silicon valley",
      "increasingly",
      "compensation",
      "employees",
      "contributor",
      "musa"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-big-tech-superstar-economy-meta-google-amazon-compensation-2026-1",
    "thumbnail_url": "https://i.insider.com/696ab873a645d11881878d05?width=1200&format=jpeg",
    "created_at": "2026-01-17T18:16:20.735Z",
    "topic": "finance"
  },
  {
    "slug": "musk-is-asking-for-up-to-134-billion-in-his-legal-battle-against-openai-and-microsoft",
    "title": "Musk is asking for up to $134 billion in his legal battle against OpenAI and Microsoft",
    "description": "Elon Musk wants OpenAI and Microsoft to pay him damages in the range of $79 billion to $134 billion over his claims that he was defrauded.",
    "fullText": "Elon Musk is demanding that OpenAI and Microsoft pay him between $79 billion and $134 billion in damages over his claims that he was defrauded.\n\nDetails of the claim were revealed by Musk's lawyer on Friday in a court filing ahead of a high-stakes jury trial set for April in Oakland, California.\n\nThe calculation of damages was laid out by the expert witness C. Paul Wazzan, named in the filing as \"a financial economist with decades of professional and academic experience.\"\n\nThe document alleges Musk was defrauded of the $38 million in seed money he donated to OpenAI when he helped found it in 2015, and states he is now entitled to a percentage of OpenAI's current $500 billion valuation.\n\nMusk said on his social media platform, X, on Friday: \"Can't wait to start the trial. The discovery and testimony will blow your mind.\"\n\nMusk is suing OpenAI's key leaders, including the CEO Sam Altman and President Greg Brockman, over allegations that the AI company misled him by shifting away from its core mission to remain a nonprofit.\n\nWazzan calculated that Musk should receive $65.50 billion to $109.43 billion in \"wrongful gains\" from OpenAI. He made a similar calculation for Microsoft's \"wrongful gains,\" which equated to between $13.30 billion and $25.06 billion.\n\nMusk has been using recently unsealed court documents to attack his rival in posts on X. On Friday, OpenAI published a blog titled \"The truth Elon left out.\"\n\nThe blog, which provided commentary alongside excerpts from several court documents, said that Musk wanted \"full control\" of OpenAI, \"since he'd been burned by not having it in the past.\" It added that OpenAI's leadership was surprised when Musk suggested having his kids control AGI, or artificial general intelligence, during conversations about succession planning.\n\nThe statements address the heart of Musk's lawsuit against OpenAI.\n\n\"Mr. Musk's lawsuit continues to be baseless and a part of his ongoing pattern of harassment, and we look forward to demonstrating this at trial,\" a spokesperson for OpenAI told Business Insider. \"This latest unserious demand is aimed solely at furthering this harassment campaign. We remain focused on empowering the OpenAI Foundation, which is already one of the best-resourced nonprofits ever.\"\n\nMusk and Microsoft did not immediately respond to a request for comment from Business Insider.",
    "readingTime": 2,
    "keywords": [
      "musk's lawsuit",
      "wrongful gains",
      "court documents",
      "trial",
      "openai's",
      "musk",
      "openai",
      "damages",
      "defrauded",
      "filing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/musk-seeks-134-billion-legal-battle-over-open-ai-microsoft-2026-01",
    "thumbnail_url": "https://i.insider.com/696b9031c58df2ecd5ccbc68?width=1200&format=jpeg",
    "created_at": "2026-01-17T18:16:20.622Z",
    "topic": "finance"
  },
  {
    "slug": "ai-beyond-llms-a-wearable-foundation-model",
    "title": "AI beyond LLMs: a wearable foundation model",
    "description": "We trained a model that achieved 87% accuracy at detecting hypertension",
    "fullText": "LLMs excel at book learning, but humanity is running out of text to train on. As Ilya Sutskevar put it, ‚Äúwe have but one internet.‚Äù\n\nFor AI in medicine, the next step is physiological ground truth. The gold standard in medicine is a blood test, typically measured every few months or years. Consumer wearables (Apple Watch, Samsung Galaxy, Fitbit) have health sensors that measure information daily, and are increasingly becoming medical devices (Apple Watch has five FDA clearances).\n\nAt the NeurIPS workshop on timeseries for health, we presented work on training a health foundation model\nusing a data set of both wearables and blood-based biomarkers. Our approach was inspired by JEPA and world models.\n\nJETS (joint embedding for timeseries) is a foundation model pre-trained on 3 million de-identified person-days of wearable data. JETS was evaluated on downstream medical tasks such as disease prediction and biomarker prediction.\n\nThe input is an irregularly-sampled multivariate timeseries (IMTS) with 63 channels: things like oxygen saturation, resting heart rate, sleep stages,\nand so on. The raw IMTS are represented as triplets (t[i], v[i], m[i]) corresponding to the timestamp, metric value, and metric type. These triplets\nare then converted into a stream of tokens with a hidden dimension d=64.\n\nArchitecture of JETS, showing tokenization and joint embedding encoders\n\nThe stream of tokens are then used as inputs into two twin encoders, EŒ∏ and Eœï. Eœï sees the whole token sequence, EŒ∏ sees a random 30%\nof the sequence, and both networks have tied weights (the weights of Eœï are set as an exponential moving average of EŒ∏, which has been shown to prevent representation collapse). The networks are trained to ultimately map both masked and unmasked token sequences into the same latent space\n\nJETS is a JEPA (joint embedding predictive architecture) adapted to timeseries. JEPA‚Äôs are an alternative to things like masked autoencoders. Whereas a masked autoencoder is trained to reconstruct the raw input signal through a low dimensional latent ‚Äúbottleneck‚Äù, JEPAs are trained to reconstruct in latent space instead. This allows the encoder to only focus on meaningful distinctions, rather than having to exactly reproduce the details of the input data.\n\nWe tried variations of JETS with both Mamba and Transformer blocks.\n\nTo test whether this pre-training process produced meaningful latent space, we evaluated it on two tasks: predicting diagnoses and predicting\nbiomarker values. (Both tasks were evaluated using linear probing, i.e., fine-tuning only weights of the last layer while keeping the rest of the network frozen).\n\nJETS had high accuracy at detecting hypertension (87% AUROC), atrial flutter (70%), ME/CFS (81%), and sick sinus syndrome (87%). In particular, JETS was more accurate than baselines like Masked Autoencoders and PrimeNet.\n\nWhen it came to predicting absolute levels of biomarkers, JETS (or its transformer analogue) had higher accuracy than baselines at predicting HbA1c, glucose, HDL,\nand hs-CRP (inflammation), although all models have high absolute error. I think an interesting future direction would be to try to predict a change\nin these biomarkers given a baseline measurement and wearable data since the baseline measuremrent.\n\nJETS isn‚Äôt the first wearable foundation model: it builds on prior research such as DeepHeart (2018); Google‚Äôs LSM-1 (2024), LSM-2 (2025), and SensorLM (2025), and Apple‚Äôs PPG/ECG model (2024) and wearable behavioral model (2025).\n\nBut we think we‚Äôre making three important contributions.\n\nFirst, JETS shows that a tiny startup‚ÄîEmpirical Health is three people‚Äîcan do work in the league of the big\nlabs. For example, the data scale of JETS is actually comparable to work published by Google and Apple:\n\nWhen it comes to results, we actually report a higher accuracy at detecitng hypertension (87%) than some previous work reported\n\nIt‚Äôs a myth that you need billions of dollars and hundreds of researchers to advance AI. Small labs ‚Äî startups\nand academic labs ‚Äî can make state of the art machine learning contributions, push the field forward, and even save lives.\n\nSecond, we make some specific technical contributions. Previous attempts to train JEPA models on timeseries (such as TS-JEPA) handled\nunivariate timeseries; we extend this to multivariate, irregularly sampled timeseries. Several previous wearable foundation models\ntrained on short, regularly-sampled snippets (e.g., a 30-second PPG); JETS handles long-range, multimodal, irregularly-sampled\nbehavioral timeseries.\n\nLLMS have been wildly successful, but we‚Äôre out of text to train on. There‚Äôs no second internet.\n\nIf we‚Äôre to achieve health superintelligence, we need to figure out how to train on physiological ground truth. Computer\nvision is one obvious area with video ground truth (for physical world models), but timeseries are ubiqutous in healthcare. We think JEPA architectures and world models are a promising direction that‚Äôs underexplored.\n\nThis work is obviously just a first step in a broader vision, but we‚Äôre excited to share this small milestone. Much work remains: trying out contrastive losses, alternative tokenization strategies, analysis of bias and fairness, and, of course, deployment of these foundation models: either independently (as done here), as a proxy reward in reinforcement learning (i.e. to tighten the feedback loop mentioned in the opening), or aligned to the latent space of an LLM (as done in CLIP). If you‚Äôre a machine learning engineer or researcher interested in contributing to the future of health, please get in touch!\n\nEvidence-based steps to optimize your heart health.",
    "readingTime": 5,
    "keywords": [
      "physiological ground",
      "ground truth",
      "joint embedding",
      "higher accuracy",
      "masked autoencoders",
      "machine learning",
      "latent space",
      "foundation model",
      "wearable foundation",
      "foundation models"
    ],
    "qualityScore": 1,
    "link": "https://www.empirical.health/blog/wearable-foundation-model-jets/",
    "thumbnail_url": "https://empirical.health/_astro/jets-architecture-2.B5rWUC1y.png",
    "created_at": "2026-01-17T18:16:18.962Z",
    "topic": "tech"
  },
  {
    "slug": "my-free-biohacking-database-with-ai-matching-turns-1",
    "title": "My free biohacking database with AI matching turns 1",
    "description": "Dopamine Club is your ultimate guide to nootropics, peptides, and supplements. Research-backed information, real user experiences, and AI-powered insights to help you optimize your brain and body.",
    "fullText": "Master your supplements.\n\nHack your brain.\n Get your dopamine hit.\n\nNo more hours spent on Google, Reddit, PubMed, WebMD...\nAll hard work done for you.\n\nThe Wolverine Stack is a popular peptide combination of BPC-157 and TB-500 used by athletes and bioh...\n\nAcetyl-L-Carnitine (ALCAR) is an acetylated form of L-carnitine that plays a crucial role in energy ...\n\nAlbiglutide is a once-weekly glucagon-like peptide-1 (GLP-1) receptor agonist used for the treatment...\n\nAlpha-GPC (L-alpha-glycerylphosphorylcholine) is a choline-containing compound that serves as a prec...\n\nAlpha-lipoic acid (ALA) is a naturally occurring antioxidant synthesized in small amounts by the bod...\n\nAnserine is a naturally occurring histidine-containing dipeptide (beta-alanyl-3-methyl-L-histidine) ...\n\nAsk questions about nootropics, supplements, and dosages. Analyzes\nreal user feedback and research papers.\n\nDescribe your goals and get personalized compound recommendations\nmatched from our entire database.",
    "readingTime": 1,
    "keywords": [
      "naturally occurring",
      "supplements",
      "peptide",
      "compound"
    ],
    "qualityScore": 0.75,
    "link": "https://dopamine.club/",
    "thumbnail_url": "https://dopamine.club/og-image.png",
    "created_at": "2026-01-17T18:16:18.820Z",
    "topic": "tech"
  },
  {
    "slug": "musk-seeks-up-to-134-billion-from-openai-and-microsoft",
    "title": "Musk seeks up to $134 billion from OpenAI and Microsoft",
    "description": "Elon Musk is seeking up to $134 billion from OpenAI and Microsoft, saying he deserves the \"wrongful gains\" that they received from his early support, according to a court filing ‚Äãon Friday.  OpenAI gained between $65.5 billion and $109.4 billion from the billionaire entrepreneur's contributions when he was co-founding what ‚Äåwas then a startup from 2015, while Microsoft gained between $13.3 billion and $25.",
    "fullText": "Jan 17 (Reuters) - Elon Musk is seeking up to $134 billion from OpenAI and Microsoft, saying he deserves the \"wrongful gains\" that they received from his early support, according to a court filing ‚Äãon Friday.\n\nOpenAI gained between $65.5 billion and $109.4 billion from the billionaire entrepreneur's contributions when he was co-founding what ‚Äåwas then a startup from 2015, while Microsoft gained between $13.3 billion and $25.1 billion, Musk said in the federal court filing ahead of his trial ‚Äåagainst the two companies.\n\n\"Without Elon Musk, there'd be no OpenAI. He provided the bulk of the seed funding, lent his reputation, and taught them all he knows about scaling a business. A pre-eminent expert quantified the value of that,\" Musk's lead trial lawyer Steven Molo said in a statement to Reuters.\n\nOpenAI and Microsoft did not respond to requests for comment outside ‚Å†business hours on the amount of compensation ‚ÄåMusk is seeking.\n\nMICROSOFT AND OPENAI ALSO FILE SUITS\n\nDuring the week, OpenAI called the lawsuit \"baseless\" and part of a \"harassment\" campaign by Musk. A Microsoft lawyer has said there is no evidence ‚Äçthat the company \"aided and abetted\" OpenAI.\n\nThe two companies challenged Musk's damages claims in a separate filing on Friday.\n\nMusk, who left OpenAI in 2018 and runs xAI with its competitor chatbot Grok, alleges that ChatGPT operator OpenAI violated its founding mission in a high-profile ‚Äãrestructuring to a for-profit entity.\n\nA judge in Oakland, California, ruled this month that a jury will hear the ‚Äåtrial, expected to start in April.\n\nMusk's filing says he contributed about $38 million, 60% of OpenAI's early seed funding, helped recruit staff, connect the founders with contacts and lend credibility to the project when it was created.\n\n\"Just as an early investor in a startup company may realize gains many orders of magnitude greater than the investor's initial investment, the wrongful gains that OpenAI and Microsoft have earned - and which Mr. Musk is now entitled to disgorge ‚Äì are much ‚Å†larger than Mr. Musk's initial contributions,\" Musk argues.\n\nThe filing says Musk's ‚Äãcontributions to OpenAI and Microsoft were calculated by his expert witness, ‚Äãfinancial economist C. Paul Wazzan.\n\nMusk may seek punitive damages and other penalties, including a possible injunction, if the jury finds either company liable, the filing says, without specifying what form any ‚Äçinjunction might take.\n\nIn their own ‚Å†filing, OpenAI and Microsoft asked the judge to limit what Musk's expert may present to jurors, arguing his analysis should be excluded as \"made up,\" \"unverifiable\" and \"unprecedented\" and as seeking an \"implausible\" transfer of billions from a nonprofit ‚Å†to a former donor-turned-competitor.",
    "readingTime": 3,
    "keywords": [
      "elon musk",
      "openai and microsoft",
      "seed funding",
      "wrongful gains",
      "court filing",
      "seeking",
      "contributions",
      "trial",
      "expert",
      "gained"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musk-seeks-134-billion-openai-072951771.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/0d1bfd9f0f21dcc371650ec86f2e1c95",
    "created_at": "2026-01-17T18:16:17.425Z",
    "topic": "finance"
  },
  {
    "slug": "we-could-hit-a-wall-why-trillions-of-dollars-of-risk-is-no-guarantee-of-ai-reward",
    "title": "‚ÄòWe could hit a wall‚Äô: why trillions of dollars of risk is no guarantee of AI reward",
    "description": "Progress of artificial general intelligence could stall, which may lead to a financial crash, says Yoshua Bengio, one of the ‚Äògodfathers‚Äô of modern AI\nWill the race to artificial general intelligence (AGI) lead us to a land of financial plenty ‚Äì or will it end in a 2008-style bust? Trillions of dollars rest on the answer.\nThe figures are staggering: an estimated $2.9tn (¬£2.2tn) being spent on datacentres, the central nervous systems of AI tools; the more than $4tn stock market capitalisation of Nvidia, the company that makes the chips powering cutting-edge AI systems; and the $100m signing-on bonuses offered by Mark Zuckerberg‚Äôs Meta to top engineers at OpenAI, the company behind ChatGPT.",
    "fullText": "Progress of artificial general intelligence could stall, which may lead to a financial crash, says Yoshua Bengio, one of the ‚Äògodfathers‚Äô of modern AI\n\nWill the race to artificial general intelligence (AGI) lead us to a land of financial plenty ‚Äì or will it end in a 2008-style bust? Trillions of dollars rest on the answer.\n\nThe figures are staggering: an estimated $2.9tn (¬£2.2tn) being spent on datacentres, the central nervous systems of AI tools; the more than $4tn stock market capitalisation of Nvidia, the company that makes the chips powering cutting-edge AI systems; and the $100m signing-on bonuses offered by Mark Zuckerberg‚Äôs Meta to top engineers at OpenAI, the company behind ChatGPT.\n\nThese sky-high numbers are all propped up by investors who expect a return on their trillions. AGI, a theoretical state of AI where systems gain human levels of intelligence across an array of tasks and are able to replace humans in white-collar jobs such as accountancy and law, is a keystone of this financial promise.\n\nIt offers the prospect of computer systems carrying out profitable work without the associated cost of human labour ‚Äì a hugely lucrative scenario for companies developing the technology and the customers who deploy it.\n\nThere will be consequences if AI companies fall short: US stock markets, boosted heavily by the performance of tech stocks, could fall and cause damage to people‚Äôs personal wealth; debt markets wrapped up in the datacentre boom could suffer a jolt that ripples elsewhere; GDP growth in the US, which has benefited from the AI infrastructure, could falter, which would have knock-on effects for interlinked economies.\n\nDavid Cahn, a partner at one leading Silicon Valley investment firm, Sequoia Capital, says tech companies now have to deliver on AGI.\n\n‚ÄúNothing short of AGI will be enough to justify the investments now being proposed for the coming decade,‚Äù he wrote in a blog published in October.\n\nIt means there is a lot hanging on progress towards advanced AI, and the trillions being poured into infrastructure and R&D to achieve it. One of the ‚Äúgodfathers‚Äù of modern AI, Yoshua Bengio, says the progress of AGI could stall and the outcome would be bad for investors.\n\n‚ÄúThere is a clear possibility that we will hit a wall, that there‚Äôs some difficulty that we don‚Äôt foresee right now, and we don‚Äôt find any solution quickly,‚Äù he says. ‚ÄúAnd that could be a real [financial] crash. A lot of the people who are putting trillions right now into AI are also expecting the advances to continue fairly regularly at the current pace.‚Äù\n\nBut Bengio, a prominent voice on the safety implications of AGI, is clear that continued progress towards a highly advanced state of AI is the more likely endgame.\n\n‚ÄúAdvances stalling is a minority scenario, like it‚Äôs an unlikely scenario. The more likely scenario is we continue to move forward,‚Äù he says.\n\nThe pessimistic view is that investors are backing an unrealistic outcome ‚Äì that AGI will not happen without further breakthroughs.\n\nDavid Bader, the director of the institute for data science at the New Jersey Institute of Technology, says trillions of dollars are being spent on scaling up ‚Äì tech jargon for growing something quickly ‚Äì the underlying technology for chatbots, known as transformers, in the expectation that increasing the amount of computing power behind current AI systems, by building more datacentres, will suffice.\n\n‚ÄúIf AGI requires a fundamentally different approach, perhaps something we haven‚Äôt yet conceived, then we‚Äôre optimising an architecture that can‚Äôt get us there no matter how large we make it. It‚Äôs like trying to reach the moon by building taller ladders,‚Äù he says.\n\nNonetheless, big US tech companies such as Google‚Äôs parent Alphabet, Amazon and Microsoft are ploughing ahead with datacentre plans with the financial cushion of being able to fund their AGI ambitions through the cash generated by their hugely profitable day-to-day businesses. This at least gives them some protection if the wall outlined by Bengio and Bader comes into view.\n\nBut there are other more worrying aspects to the boom. Analysts at Morgan Stanley, the US investment bank, estimate that $2.9tn will be spent on datacentres between now and 2028, with half of that covered by the cashflow from ‚Äúhyperscalers‚Äù such as Alphabet and Microsoft.\n\nThe rest will have to be covered by alternative sources such as private credit, a corner of the shadow banking sector that is activating alarm bells at the Bank of England and elsewhere. Meta, the owner of Facebook and Instagram, has borrowed $29bn from the private credit market to finance a datacentre in Louisiana.\n\nAI-related sectors account for approximately 15% of investment grade debt in the US, which is even bigger than the banking sector, according to the investment bank JP Morgan.\n\nOracle, which has signed a $300bn datacentre deal with OpenAI, has had an increase in credit default swaps, which are a form of insurance on a company defaulting on its debts. High-yield, or ‚Äújunk debt‚Äù, which represents the higher-risk end of the borrowing market, is also appearing in the AI sector via datacentre operators CoreWeave and TeraWulf. Growth is also being funded by asset-backed securities ‚Äì a form of debt underpinned by assets such as loans or credit card debt, but in this case rent paid by tech companies to datacentre owners ‚Äì in a form of financing that has risen sharply in recent years.\n\nIt is no wonder that JP Morgan says the AI infrastructure boom will require a contribution from all corners of the credit market.\n\nBader says: ‚ÄúIf AGI doesn‚Äôt materialise on expected timelines, we could see contagion across multiple debt markets simultaneously ‚Äì investment-grade bonds, high-yield junk debt, private credit and securitised products ‚Äì all of which are being tapped to fund this buildout.‚Äù\n\nShare prices linked to AI and tech are also playing an outsized role in US stock markets. The so-called ‚Äúmagnificent 7‚Äù of US tech stocks ‚Äì Alphabet, Amazon, Apple, Tesla, Meta, Microsoft, and Nvidia ‚Äì account for more than a third of the value of the S&P 500 index, the biggest stock market index in the US, compared with 20% at the start of the decade.\n\nIn October the Bank of England warned of ‚Äúthe risk of a sharp correction‚Äù in US and UK markets due to giddy valuations of AI-linked tech companies. Central bankers are concerned stock markets could slump if AI fails to reach the transformative heights investors are hoping for. At the same time the International Monetary Fund said valuations were heading towards dotcom bubble-levels.\n\nEven tech execs whose companies are benefiting from the boom are acknowledging the speculative nature of the frenzy. In November Sundar Pichai, the chief executive of Alphabet, said there are ‚Äúelements of irrationality‚Äù in the boom and that ‚Äúno company is going to be immune‚Äù if the bubble bursts, while Amazon‚Äôs founder, Jeff Bezos, has said the AI industry is in a ‚Äúkind of industrial bubble‚Äù, and OpenAI‚Äôs chief executive, Sam Altman, has said ‚Äúthere are many parts of AI that I think are kind of bubbly right now.‚Äù\n\nAll three, to be clear, are AI optimists and expect the technology to keep improving and benefit society.\n\nBut when the numbers get this big there are obvious risks in a bubble bursting, as Pichai admits. Pension funds and anyone invested in the stock market will be affected by a share price collapse, while the debt markets will also take a hit. There is also a web of ‚Äúcircular‚Äù deals, such as OpenAI paying Nvidia in cash for chips, and Nvidia will invest in OpenAI for non-controlling shares. If these transactions unravel due to a lack of take-up of AI, or that wall being hit, then it could be messy.\n\nThere are also optimists who argue that generative AI, the catch-all term for tools such as chatbots and video generators, will transform whole industries and justify the expenditure. Benedict Evans, a technology analyst, says the expenditure numbers are not outrageous in the context of other industries, such as oil and gas extraction which runs at $600bn a year.\n\n‚ÄúThese AI capex figures are a lot of money but it‚Äôs not an impossible amount of money,‚Äù he says.\n\nEvans adds: ‚ÄúYou don‚Äôt have to believe in AGI to believe that generative AI is a big thing. And most of what is happening here is not, ‚Äòoh wow they‚Äôre going to create God‚Äô. It‚Äôs ‚Äòthis is going to completely change how advertising, search, software and social networks ‚Äì and everything else our business is based on ‚Äì is going to work‚Äô. It‚Äôs going to be a huge opportunity.‚Äù\n\nNonetheless, there is a multitrillion dollar expectation that AGI will be achieved. For many experts, the consequences of getting there are alarming. The cost of not getting there could also be significant.",
    "readingTime": 8,
    "keywords": [
      "alphabet amazon",
      "chief executive",
      "banking sector",
      "financial crash",
      "progress towards",
      "investment bank",
      "junk debt",
      "tech stocks",
      "stock market",
      "stock markets"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/17/why-trillions-dollars-risk-no-guarantee-ai-reward",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a0eef0b4544b41b055733e7d0826315830269b70/547_0_5468_4374/master/5468.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0827b0776297b562f7de1e2b5b00e2ca",
    "created_at": "2026-01-17T18:16:16.585Z",
    "topic": "tech"
  },
  {
    "slug": "bills-vs-broncos-computer-picks-our-best-nfl-playoff-player-prop-projections",
    "title": "Bills vs. Broncos Computer Picks: Our Best NFL Playoff Player Prop Projections",
    "description": "A look at computer and AI picks for this week's NFL Playoff Divisional Round game between the Bills and Broncos. Find Buffalo and Denver player props.",
    "fullText": "Josh Allen and the Buffalo Bills aim to knock off the AFC‚Äôs top seed Saturday afternoon, facing the Denver Broncos in the Divisional Round.\n\nThe Broncos are -1.5 betting favorites at the best NFL betting sites.\n\nBelow, we will look at NFL player props for all of the top offensive players for the Bills and Broncos.\n\nOur computer projects big statistical games from James Cook, Khalil Shakir, Courtland Sutton, and Evan Engram.\n\nAllen Under 211.5 passing yards <<-110>>\n\nNix Over 210.5 passing yards <<-114>>\n\nCook Over 73.5 rushing yards <<-114>>\n\nHarvey Under 56.6 rushing yards <<-110>>\n\nShakir Over 49.5 receiving yards <<-110>>\n\nSutton Over 49.5 receiving yards <<-111>>\n\nKincaid Over 35.5 receiving yards <<-108>>\n\nEngram Over 20.5 receiving yards <<-110>>\n\nMake your postseason bets at FanDuel, America's No. 1 sportsbook! \n\nSportsbooks are giving Denver‚Äôs pass defense a ton of respect, but I‚Äôm not convinced it‚Äôs entirely warranted.\n\nThe Broncos looked like world-beaters against the likes of Trey Lance, Chris Oladokun, and Geno Smith, holding all three under 200 passing yards.\n\nWhen facing competent quarterbacks, however, yardage told a different story: Trevor Lawrence threw for 279 yards against Denver on Dec. 21, Jordan Love passed for 276 yards on Dec. 14, and even Marcus Mariota managed 294 yards through the air on Nov. 30.\n\nJosh Allen, a level or two above all of those QBs, showed last week that he can still rack up yardage, completing 28-of-35 passes for 273 yards against Jacksonville.\n\nI‚Äôll start by disagreeing with the computer and take the Allen Over.\n\nCook has had an outstanding season, but this number feels a little too high against an excellent Denver front.\n\nSince Thanksgiving, the Broncos haven‚Äôt allowed a single running back to surpass 73.5 rushing yards. I expect Buffalo to focus on beating Denver through the air rather than on the ground, which likely limits Cook‚Äôs opportunities.\n\nI‚Äôll disagree with the computer here and take the Under on Cook.\n\nThe Bills‚Äô receiving corps has been decimated by injury, with both Gabe Davis and Tyrell Shavers tearing ACLs against Jacksonville.\n\nAs a result, all of Buffalo‚Äôs wide receivers should see increased targets. We already saw a sign of this last week: Shakir was targeted a season-high 12 times by Allen against the Jaguars, responding with 82 receiving yards.\n\nI‚Äôll ride with the computer and take the Shakir Over.\n\nProjection: 37.1 receiving yards\n\nIn last year‚Äôs postseason matchup between the Bills and Broncos, Dalton Kincaid had 47 receiving yards.\n\nAllen‚Äôs trust in him has only grown this season, with the tight end averaging 43.5 receiving yards per game since the start of November.\n\nI‚Äôm on the side of our AI here. Take the Over.\n\nPredictions for every NFL Divisional Round game\n\nProjection: 218.0 passing yards\n\nA major reason the Broncos were non-competitive in last year‚Äôs 31-7 playoff loss to Buffalo was that Sean Payton didn‚Äôt trust Nix. The quarterback threw a season-low 22 passes in that game.\n\nFor context, Buffalo allowed Trevor Lawrence to pass for 207 yards last weekend. During the regular season, Denver‚Äôs passing output per game (223.9 yards) was nearly identical to Jacksonville‚Äôs (222.3).\n\nBecause I believe Payton will let Nix chuck it at least 30 times in this one, I like the Over (slightly). The computer and I agree.\n\nThis number is extremely high for Javonte Harvey, even against Buffalo‚Äôs porous run defense. Harvey became Denver‚Äôs lead back after Nov. 6, when JK Dobbins went down with an injury.\n\nIn the seven games since, he‚Äôs gone Over this number just twice.\n\nMeanwhile, coach Sean Payton has been giving more carries to 5-foot-7 back Jaleel McLaughlin. McLaughlin posted a season-high seven carries on Christmas against Kansas City, then added six carries for 41 yards on Jan. 4 against the Chargers.\n\nI‚Äôll take the Harvey Under here, as will my computer pal.\n\nThe Broncos‚Äô best win in the second half of the regular season came in a 34-26 victory over the Packers at Mile High. In that game, Nix targeted Sutton 10 times, and the receiver finished with 113 yards.\n\nBuffalo‚Äôs pass defense is impressive, but it‚Äôs not immune to big performances. Last week, Parker Washington racked up 107 yards, Tee Higgins had 92, Jaylen Waddle posted 84, and Stefon Diggs went for a whopping 146 yards against the Bills.\n\nI like Nix to target Sutton a ton, and the number is pretty low. The computer and I like the value on the Over.\n\nProjection: 25.2 receiving yards\n\nThe Bills do a tremendous job against opposing tight ends, allowing just 29.6 yards per game to the position during the regular season. In big games, they‚Äôve been even more dominant.\n\nSince the start of December, Buffalo‚Äôs two biggest wins came against New England on Dec. 14 and Jacksonville in last week‚Äôs playoff matchup.\n\nThe Bills held Hunter Henry to just one catch for 18 yards against the Patriots and limited Brenton Strange to a season-low nine receiving yards versus the Jaguars.\n\nI‚Äôll agree with the computer and take the Over.\n\nNot intended for use in MA.\nAffiliate Disclosure: Our team of experts has thoroughly researched and handpicked each product that appears on our website. We may receive compensation if you sign up through our links.\n\nThis article originally appeared on Covers.com, read the full article here",
    "readingTime": 5,
    "keywords": [
      "divisional round",
      "projection receiving",
      "regular season",
      "per game",
      "rushing yards",
      "harvey under",
      "the broncos",
      "trevor lawrence",
      "sean payton",
      "the bills"
    ],
    "qualityScore": 1,
    "link": "https://sports.yahoo.com/articles/bills-vs-broncos-computer-picks-120000388.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/HT9fA1eVQIu6BD4NPG7AdQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD01MzA7Y2Y9d2VicA--/https://media.zenfs.com/en/covers_articles_287/5781af371560ff7138e741ce278be1a4",
    "created_at": "2026-01-17T12:21:38.831Z",
    "topic": "sports"
  },
  {
    "slug": "ai-tools-could-make-companies-less-competitive-because-everyone-buys-the-same-brain-think-tank-ceo-says",
    "title": "AI tools could make companies less competitive because everyone buys the same brain, think tank CEO says",
    "description": "The CEO of a digital economy think tank said relying on identical AI tools can erode competitive edge and weaken firms' independence.",
    "fullText": "As companies rush to adopt AI to boost productivity and cut costs, they may be setting themselves up for a new problem: losing what makes them different.\n\nMehdi Paryavi, CEO of the International Data Center Authority, said widespread reliance on the same AI tools risks flattening competitive advantage across industries, because firms increasingly rely on identical systems to think, write, and decide for them.\n\nParyavi said that as AI tools become cheaper, more powerful, and more widely deployed, companies risk outsourcing the very thinking that once differentiated them.\n\nWhile AI can boost efficiency in the short term, he said, relying on shared models and standardized systems could leave businesses competing on cost and speed alone ‚Äî eroding originality, strategic depth, and long-term advantage.\n\n\"If you and your competitor are all using the same service, you have no edge over each other,\" Paryavi told Business Insider.\n\n\"Their AI and your AI against each other ‚Äî I don't know who's going to win.\"\n\nAs generative AI becomes embedded across workplaces, Paryavi warned that the biggest risk isn't automation ‚Äî it's uniformity.\n\nWhen companies rely on the same large language models trained on the same data, decision-making, writing, and problem-solving can start to converge, shrinking the space for creative divergence.\n\nThat concern echoes warnings from researchers and academics who say AI can produce polished output at scale, but also flips human thinking by delivering fluent answers before understanding, creating an illusion of expertise that weakens judgment and depth.\n\nWhen everyone relies on the same models trained on the same data, Paryavi said, creative divergence shrinks.\n\n\"The beauty of our world is that we have different choices because we think differently,\" he said. \"That's where innovation comes from.\"\n\nIt's not just a question of companies all thinking the same ‚Äî Paryavi warned that treating AI as a shortcut to efficiency can quietly hollow out human judgment, expertise, and control, leaving businesses faster in the short term but more fragile over time.\n\nOver time, Paryavi said, that shift can erode internal expertise and decision-making capacity.\n\n\"What they don't think about is that initially it might sound more efficient and more productive and cheaper,\" he said. \"But this is going to be very expensive down the line.\"\n\nOne risk, Paryavi said, is dependency. As firms replace employees with AI subscriptions, they become increasingly reliant on external vendors to function effectively.\n\nParyavi compared the AI boom to the early 2000s rush to cloud computing, when many companies initially adopted third-party infrastructure but later repatriated workloads in-house as costs, complexity, and vendor lock-in became concerns ‚Äî a trend commonly referred to in tech as cloud repatriation.\n\nThe same dynamic could play out with AI, Paryavi said ‚Äî except with even higher stakes. As companies downsize human teams, they also lose institutional knowledge and the ability to operate without automation, he said.\n\n\"You've killed all your chances of ever becoming independent as an organization,\" he said. \"You've fired your manpower. You've made them no good.\"\n\nAI, he said, is not inherently harmful. In fields such as medicine, scientific research, and disaster prediction, it can significantly accelerate progress.\n\nBut without clear guardrails, companies risk trading long-term resilience for short-term speed.\n\n\"It's a very powerful tool,\" Paryavi said, comparing AI to an atomic bomb. \"If that [an atomic bomb] can eliminate an entire population physically, this [AI] can eliminate humanity cognitively.\"",
    "readingTime": 3,
    "keywords": [
      "paryavi warned",
      "creative divergence",
      "atomic bomb",
      "models trained",
      "risk",
      "it's",
      "human",
      "expertise",
      "you've",
      "rush"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-tools-could-make-companies-less-competitive-think-tank-ceo-2026-1",
    "thumbnail_url": "https://i.insider.com/6964ed8d04eda4732f2ee0e1?width=1200&format=jpeg",
    "created_at": "2026-01-17T12:20:55.695Z",
    "topic": "finance"
  },
  {
    "slug": "heres-what-wall-street-bank-ceos-are-saying-about-head-count-in-the-age-of-ai",
    "title": "Here's what Wall Street bank CEOs are saying about head count in the age of AI",
    "description": "From JPMorgan to Citi, here's what industry leaders at are saying about how AI may impact jobs.",
    "fullText": "As banks reported earnings this week, CEOs dropped more insight into how generative AI could boost productivity, replace some roles, and keep head count from growing.\n\nBanks, many of which became bloated during the frenzied deal boom of the pandemic, have been slimming down their ranks over the last few years. It's becoming clearer that, despite dealmaking making a comeback, executives are signaling they want to do more with fewer people, leaning on AI to boost productivity and absorb additional work.\n\nWe've highlighted some of the most revealing comments from bank CEOs and CFOs on head count and AI.\n\nJamie Dimon has stuck to his trademark bluntness when talking about AI and jobs.\n\n\"It will eliminate jobs,\" Dimon said at a Fortune conference in December. \"People should stop sticking their heads in the sand.\"\n\nIn the near term, Dimon said in an interview with CNN that JPMorgan's head count remains steady, or even rises, as AI continues to roll out ‚Äî if the bank does a \"good job.\"\n\nThe bigger promise is efficiency. \"It will affect every job,\" Dimon said at a 2024 Alliance Bernstein conference, describing a future where AI handles tasks like note-taking and summarization at the push of a button.\n\nThat efficiency could still mean more hiring in areas like cybersecurity, where Dimon says banks will need AI to counter increasingly sophisticated fraud.\n\nCFO Jeremy Barnum said during the company's fourth-quarter earnings call on Tuesday that the bank is allowing for some additional hiring in technology \"at the margin.\"\n\nOn that same call, however, Barnum said that, generally speaking, they \"want to make sure that when someone needs to get something done, whether it's in technology or elsewhere, their first reaction is not, 'Hire more people.'\" \n\nHe has previously said JPMorgan is asking people to \"resist head count growth where possible\" and focus instead on efficiency.\n\nThe head of JPMorgan's consumer business, Marianne Lake, has said operations staff could be 40% to 50% more productive over the next five years ‚Äî a shift she said would lead to slower net head count growth, as each employee can handle far more work through automation, digital assistants, and self-service tools.\n\nDavid Solomon's most definitive statement about how AI will affect Goldman came in a memo he released in 2025 alongside the firm's president, John Waldron, and CFO Denis Coleman.\n\nThe memo, announcing the third iteration of the bank's cross-bank initiative OneGS, said that AI will drive efficiency at the firm, which will mean slowing hiring and reducing roles. (Goldman, with its yearly culling of some employees, is no stranger to job cuts.)\n\n\"We will constrain head count growth through the end of the year, in addition to a limited reduction in roles across the firm,\" the memo read. \"These targeted steps are consistent with our priorities of gaining more agility and creating the right team structures in order to implement effective AI solutions.\"\n\nDuring the bank's fourth-quarter earnings call Thursday, Solomon said that the firm plans to use AI to both cut costs and \"free up capacity to invest in other areas.\"\n\nSlowing hiring and increasing head count don't need to be contradictory; instead, Solomon has said the firm is focusing its hiring on the right talent.\n\n\"We need more high-value people,\" he told Axios in October. \"We can afford more high-value people to expand our footprint and continue to grow and broaden our business.\"\n\nHe has said he continues to believe that AI will grow the firm's head count over the next 10 years.\n\n\"There are obviously things where we're going to have a lot fewer people ‚Äî but I'd love to have the capacity to go get more people to spend time with clients,\" Solomon said at a conference in 2025, noting that AI will have its most immediate impact on software development.\n\nCiti is in the midst of a multi-year turnaround led by the bank's CEO, Jane Fraser, to save roughly $2.5 billion and cut around 20,000 jobs.\n\nIn a memo sent to Citi's more than 200,000 employees on Wednesday, Fraser said she will \"expect to see the last vestiges of old, bad habits fall away, and a more disciplined, more confident, winning Citi fully emerge in 2026.\"\n\nFraser said in the memo that, with AI and automation, some jobs will change, some will emerge, and \"others will no longer be required.\"\n\nDuring a media briefing ahead of the firm's fourth-quarter earnings call, Mark Mason, the outgoing CFO, said he expects head count to continue trending down \"as we continue to improve productivity and tools like AI.\"\n\nFraser has previously explained how AI was already increasing productivity.\n\n\"AI-driven automated code reviews have exceeded 1 million so far this year and are dramatically improving our developers' productivity,\" she said during the bank's 2025 third-quarter earnings call. \"This innovation alone saves considerable time and creates around 100,000 hours of weekly capacity.\"\n\nThe CEO also highlighted how AI is helping Citi's customer service teams resolve client inquiries faster, its wealth advisors provide more personalized advice, and the firm's plan to launch an agent-based AI pilot to tackle more complex tasks.\n\nWells Fargo has already shrunk its head count more than 25% since the second quarter of 2020, CEO Charles Scharf said during the company's fourth-quarter earnings call on Wednesday. He said that efficiency remains an \"ongoing focus\" for Wells Fargo.\n\nIn November, he told Reuters that the bank will likely \"have less head count as we look forward.\" He said the lower head count is an \"outcome\" of the firm's focus on areas where it's \"way too inefficient\" and \"way too bureaucratic.\" From 2018 to June of this year, the firm had an asset cap of $1.95 trillion, hindering its ability to grow.\n\nIn the same interview, Scharf called out those who are saying that AI won't reduce jobs.\n\n\"The opportunities that exist in AI are very significant, and anyone who sits here today and says that they don't think they'll have less head count because of AI either doesn't know what they're talking about or is just not being totally honest about it,\" he said.\n\nFollowing up on those comments in early December, Scharf clarified that most people know head count will dip, \"but they're afraid to say it, because no one wants to stand up and say that we should have ‚Äî we're going to have lower head count in the future. It's a difficult thing to say.\"\n\nHe said that generative AI tools have already made Wells Fargo's engineers 30% to 35% more productive. While the bank hasn't cut coding jobs yet, the technology will eventually allow it to do more with fewer people across various functions, including compliance and legal, as well as call centers and even banking teams.\n\nBank of America has set a new industry standard, with a minimum wage of $25 an hour across the company. And while CEO Brian Moynihan conceded on a September 2025 Bloomberg TV interview that generative AI adoption has shrunk the size of some departments, the bank is focusing on training employees to do what LLMs cannot.\n\n\"The key to that is really redeploying people and re-skilling them,\" he said. \"We have to be more mindful about training them along multiple dimensions than we might have been two or three years ago.\"\n\nOn the company's fourth-quarter earnings call in January, Moynihan teased how AI might make some tasks obsolete, though, saying that the bank has 18,000 people on the payroll who code.\n\n\"Using the AI techniques, we've taken 30% out of the coding part of the stream of introducing a new product,\" he said. \"That saves us about 2,000 people. So that's how we're applying it.\"\n\nAt the Goldman financial services conference in 2025, Moynihan said the bank is managing flat overall staffing levels by redeploying employees rather than hiring more, with AI playing a central role in absorbing the additional workload. He pointed to Erica, Bank of America's consumer-facing AI assistant, as a clear example of how that is playing out in practice.\n\nIn November, Moynihan said that the bank had 1.4 billion digital connections with its customers: \"We think it saves, today, about 11,000 FT equivalents.\"\n\nMorgan Stanley CEO Ted Pick didn't explicitly address how AI is impacting head count during the bank's fourth-quarter earnings call, but said \"there is no more time to waste\" when it comes to the technology.\n\nThe firm's CFO, Sharon Yeshaya, mentioned a specific operations example where the firm has outsourced some work to AI: \"We used to have two teams necessarily checking each other on different documentation to make sure things are right. We now have one human team and one AI team.\"",
    "readingTime": 8,
    "keywords": [
      "boost productivity",
      "company's fourth-quarter",
      "slowing hiring",
      "fourth-quarter earnings",
      "bank's fourth-quarter",
      "count growth",
      "jobs",
      "firm's",
      "firm",
      "efficiency"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/jpmorgan-citi-goldman-bofa-wells-how-ai-impact-headcounts-2026",
    "thumbnail_url": "https://i.insider.com/687aa02d3d5881a51c1d9f2c?width=1200&format=jpeg",
    "created_at": "2026-01-17T12:20:55.341Z",
    "topic": "finance"
  },
  {
    "slug": "reality-is-breaking-the-ai-revolution",
    "title": "Reality Is Breaking the \"AI Revolution\"",
    "description": "AI job losses are total bulls**t.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.planetearthandbeyond.co/p/reality-is-breaking-the-ai-revolution",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!oDIp!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25265e25-c832-4709-990c-46d6723c97b4_1600x1236.png",
    "created_at": "2026-01-17T06:17:57.519Z",
    "topic": "tech"
  },
  {
    "slug": "built-an-app-that-aggregates-prediction-markets-with-ai-context",
    "title": "Built an app that aggregates Prediction Markets with AI Context",
    "description": "Your AI powered intelligence hub for prediction markets.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://saipintel.ai:443/",
    "thumbnail_url": "https://SaipIntel.replit.app/opengraph.jpg",
    "created_at": "2026-01-17T06:17:57.125Z",
    "topic": "tech"
  },
  {
    "slug": "local-ai-that-knows-when-youre-burning-out",
    "title": "Local AI that knows when you're burning out",
    "description": "Join the humonos beta program. Get early access to aware computing that understands your energy levels, cognitive load, and work patterns. Mac only. Limited spots available.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.humonos.com/beta",
    "thumbnail_url": "https://www.humonos.com/iconicon.png",
    "created_at": "2026-01-17T06:17:56.893Z",
    "topic": "tech"
  },
  {
    "slug": "openai-is-turning-to-the-court-of-public-opinion-in-its-battle-with-elon-musk",
    "title": "OpenAI is turning to the court of public opinion in its battle with Elon Musk",
    "description": "OpenAI published a blog post on Friday that said Elon Musk never treated the AI startup as an independent nonprofit.",
    "fullText": "OpenAI is turning to the court of public opinion as it wages a legal battle with Elon Musk.\n\nWhile Musk and OpenAI prepare to head to a high-stakes jury trial in April, the two are duking it out online over what exactly happened when Musk split ways with the AI startup he helped cofound.\n\nMusk has been using recently unsealed court documents to attack his rival in posts on his social media platform, X. On Friday, OpenAI published a blog titled \"The truth Elon left out.\"\n\nThe blog, which provided commentary alongside excerpts from several court documents, alleges that Musk wanted \"full control\" of OpenAI, \"since he'd been burned by not having it in the past,\" and that OpenAI's leadership was surprised when Musk suggested having his kids control AGI or artificial general intelligence during conversations about succession planning.\n\nThe statements are aimed at the heart of Musk's lawsuit against OpenAI.\n\nMusk is suing OpenAI's key leaders, including CEO Sam Altman and President Greg Brockman, over allegations that the AI company misled him by shifting away from its core mission to remain a nonprofit. Musk said he donated $38 million to OpenAI when it was a nonprofit.\n\nThe startup, since its 2015 founding, operated as a nonprofit-controlled organization with a for-profit operating arm. It completed its transition to a for-profit public benefit corporation in October 2025.\n\nRepresentatives for Musk and OpenAI did not immediately respond to requests for comment from Business Insider.\n\nLast Tuesday, more than 100 documents related to the suit were unsealed, including diary entries from Brockman, which were obtained during the discovery process.\n\nIn one of the entries that was highlighted, Brockman appeared to write about his misgivings about pushing Musk out of OpenAI and committing to a nonprofit-only entity.\n\n\"Cannot say that we are committed to the non-profit,\" the entry from the court documents said. \"Don't want to say that we're committed. If three months later we're doing b-corp then it was a lie.\"\n\nIt was Brockman's diary entries that US District Judge Yvonne Gonzalez Rogers cited in a recent ruling, in which she determined Musk had enough evidence that he'd been misled to take the case to trial.",
    "readingTime": 2,
    "keywords": [
      "diary entries",
      "court documents",
      "musk",
      "brockman",
      "openai",
      "elon",
      "trial",
      "startup",
      "unsealed",
      "blog"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-responds-elon-musk-lawsuit-greg-brockman-diary-entries-2026-1",
    "thumbnail_url": "https://i.insider.com/696ac819e1ba468a96aa45d4?width=800&format=jpeg",
    "created_at": "2026-01-17T06:17:54.963Z",
    "topic": "finance"
  },
  {
    "slug": "global-sports-face-challenges-from-ai-slop-misinformation",
    "title": "Global sports face challenges from 'AI slop' misinformation",
    "description": "A study by AI risk management platform Alethea into the surge in artificial intelligence-generated fake content, dubbed \"AI slop,\" has warned sports teams, leagues and fans of the risks posed by increasingly sophisticated digital misinformation.  Retired NFL player Jason Kelce never said ‚Äã2026 Super Bowl halftime singer Bad Bunny's critics were \"a bad fit for America's future\".  San Francisco 49ers tight end George Kittle never ranted about slain ‚Äåconservative activist Charlie Kirk and politics in football.",
    "fullText": "Jan 16 (Reuters) - A study by AI risk management platform Alethea into the surge in artificial intelligence-generated fake content, dubbed \"AI slop,\" has warned sports teams, leagues and fans of the risks posed by increasingly sophisticated digital misinformation.\n\nRetired NFL player Jason Kelce never said ‚Äã2026 Super Bowl halftime singer Bad Bunny's critics were \"a bad fit for America's future\".\n\nSan Francisco 49ers tight end George Kittle never ranted about slain ‚Äåconservative activist Charlie Kirk and politics in football.\n\nHowever, thousands of people believed they did and that is the problem.\n\n\"Teams and players are suddenly being accused of things that are completely fabricated,\" Lisa Kaplan, ‚Äåfounder and CEO of Alethea, told Reuters on Friday, adding that the evolution of AI tools has made fake news a more daunting challenge.\n\n\"Content now looks real and is produced at a volume that makes it hard for the average person to determine if it's authentic,\" she said.\n\n\"Before, fake news often relied on human labour to repetitively copy and paste content. Today, AI can impersonate brands and create engaging images that mimic genuine announcements.\"\n\nKaplan noted that this wave of AI-generated misinformation has disrupted the traditional monetisation ‚Å†model of sports media. \"These networks drive engagement to questionable websites, ‚Äåskew advertising metrics, and can even create scenarios that could manipulate betting markets,\" she added.\n\nC Shawn Eib, Alethea's Head of Investigations, described how these networks use tactics such as making multiple disjointed announcements, like the conflicting claims that former Baltimore Ravens coach ‚ÄçJohn Harbaugh had been hired by multiple teams at the same time.\n\n\"When a single figure appears to be linked with several teams at the same time, it quickly becomes clear that an AI system is behind the creation of these images,\" Eib explained.\n\nAI DECEPTION CAN EXPLOIT 'RAGE BAIT'\n\nThe content follows a formula: fake game updates, nonexistent celebrity feuds, manufactured scandals, and politicised ‚Äãquotes falsely attributed to star players.\n\nThe fabricated Kelce and Kittle quotes are prime examples. Both NFL stars publicly denied making comments they never said after the ‚Äåposts went viral.\n\n\"If fans, players and even entire franchises fall prey to these manipulated narratives, it risks damaging reputations, undermining trust and even politicising sport,\" Alethea's VP of Communications Kaila Ryan said.\n\n\"Sports organisations need to proactively manage their brands and digital safety. It is crucial for teams and leagues to start monitoring these risks, work together across communications, legal and security teams, and educate fans to verify announcements from official channels,\" she added.\n\nThe business impact extends beyond reputational harm.\n\nThese networks siphon ad revenue from legitimate sports media and distort audience metrics. Some outbound links have been flagged for phishing and malicious redirects, presenting real fraud risk to fans.\n\nThe problem ‚Å†is not limited to the NFL. Alethea discovered similar operations targeting the NBA, WNBA, MLB, NHL, ‚ÄãNASCAR, Formula 1, IndyCar and professional tennis.\n\nKaplan added that beyond monetisation, sport remains a rare cultural ‚Äãtouchpoint that unites people, making them attractive targets for influence operations, and she pointed to Russia's alleged exploitation of then-49ers quarterback Colin Kaepernick's 2018 'Take a Knee' protest as a precedent.\n\nIn a 2019 report, the Senate Intelligence Committee revealed that Russian trolls had focused heavily ‚Äçon the kneeling debate as part of ‚Å†a broader effort to stoke racial tensions and divide the U.S. following the 2016 election.\n\n\"Kaepernick's protests were exploited for a purpose that had nothing to do with sport. Instead, it's a way of leveraging a cultural touchstone and turning it into something that polarises people,\" said Kaplan.\n\n\"Teams need to ‚Å†work in unison to defend their identities and protect their fans from falling victim to fraud or manipulation,\" she added, noting that the best advice for fans is to be vigilant.\n\n\"Verify breaking news ‚Äåthrough official team channels, don't click links in suspicious page comments and remember that outrage is often the product, not the by-product, ‚Äåof what you're seeing\".",
    "readingTime": 4,
    "keywords": [
      "sports media",
      "fans",
      "fake",
      "content",
      "risks",
      "players",
      "announcements",
      "networks",
      "teams",
      "risk"
    ],
    "qualityScore": 1,
    "link": "https://sports.yahoo.com/articles/global-sports-face-challenges-ai-001521496.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/01588c76abbcb3da3383f7e9f92df23c",
    "created_at": "2026-01-17T00:56:53.942Z",
    "topic": "sports"
  },
  {
    "slug": "commander-ai-mac-ui-for-claude-code",
    "title": "Commander AI ‚Äì Mac UI for Claude Code",
    "description": "A beautiful native macOS app for Claude Code. Build software with AI assistance, integrated git workflow, and seamless project management. Free for Mac developers.",
    "fullText": "Commander is a beautiful native macOS application that provides a powerful interface for Claude¬†Code, Anthropic's AI coding agent. It combines AI‚Äëpowered coding assistance with integrated git workflow and seamless project management, all wrapped in a native Mac¬†experience.\n\nYes, Commander is completely free. There are no subscription fees, premium tiers, or hidden costs. It's free for all Mac developers.\n\nCommander requires macOS¬†15.0 or later. It is built with native Swift and optimized for the latest macOS¬†features.\n\nCommander is built on top of Anthropic's Claude¬†Code agent, providing a native macOS interface that makes it easy to interact with the AI for code generation, refactoring, documentation, and more. It includes integrated git workflow for seamless version¬†control.\n\nCommander requires macOS¬†15.0 or later and the Claude¬†Code¬†CLI to be installed. You can install the Claude¬†Code¬†CLI by following the setup instructions at code.claude.com/docs/en/setup\n\nCommander is a native macOS interface that connects to Claude¬†Code¬†CLI running locally on your machine. All AI interactions are handled through Claude¬†Code¬†CLI and are subject to Anthropic's privacy policy and terms of service. Commander itself does not collect or transmit your code or personal data to third¬†parties.",
    "readingTime": 1,
    "keywords": [
      "claude code cli",
      "integrated git",
      "git workflow",
      "macos interface",
      "native macos",
      "commander",
      "coding",
      "agent",
      "seamless",
      "free"
    ],
    "qualityScore": 0.85,
    "link": "https://commanderai.app/",
    "thumbnail_url": "https://commanderai.app/og-image.png",
    "created_at": "2026-01-17T00:56:27.174Z",
    "topic": "tech"
  },
  {
    "slug": "i-trained-a-gpt-to-think-like-steve-jobs-and-help-me-run-my-company-ai-is-scary-but-its-also-my-biggest-tool",
    "title": "I trained a GPT to think like Steve Jobs and help me run my company. AI is scary, but it's also my biggest tool.",
    "description": "Solopreneur Yesim Saydan shares how she trained over 17 custom GPT workers and a Steve Jobs‚Äîinspired custom GPT to work for her consultancy agency.",
    "fullText": "This as-told-to essay is based on a conversation with Yesim Saydan, a branding and communication expert in her early 50s, based in the Netherlands. The following has been edited for length and clarity.\n\nWhen I'm stuck on a business decision or need to come up with a creative idea or strategy, brainstorming usually starts with my Steve Jobs custom GPT.\n\nMy solo-consultancy business helps senior executives and established entrepreneurs grow their authority and influence through social media and brand strategies. But scaling that work on my own was challenging.\n\nBefore AI, if I wanted to scale the number of clients I could take on, my main option was hiring freelancers for special projects or tasks. I spent a lot of unnecessary time training the freelancers on my specific framework, and it often felt like they didn't care as much as I did.\n\nWhen OpenAI launched custom GPTs, everything changed. I used the feature to create over 17 custom GPTs to build my team. Then I thought of my ideal mentors and created custom GPTs of them.\n\nOne of my first jobs was at Citibank as a project manager on Wall Street, following my move to the US from Turkey for my MBA. That kicked off my 14-year corporate career, during which I worked in New York, Paris, and the Netherlands.\n\nI started my business about a decade ago because I wanted more flexibility in my work schedule. At the time, social media was just starting to take off, and I saw a clear opportunity.\n\nI'd played with AI tools before, but OpenAI's custom GPTs changed the game. Initially, I envisioned creating my ideal four-person team of agents. I quickly realized AI produces subpar results when it's overloaded with too many tasks.\n\nInstead, I created a custom GPT for each important task I wanted the AI to perform. That's how I ended up with more than 17 custom GPTs making up what feels like my perfect team.\n\nI can create a custom GPT in five or 10 minutes, but what actually makes it powerful is the training process. I create standard operating procedure documents for each task and client, serving as training materials for my agents that outline my methodology and frameworks.\n\nI have client-specific AI agents trained on each major client's tone, goals, and past conversations, so I'm never starting from scratch with a task. The training is ongoing. Every time I make a query or upload a document, the agent improves, just like a real employee would.\n\nWhen I need to communicate or create content in a client's tone of voice, the draft I end up with is so tailored that it feels like I spent hours perfecting it, when in fact my AI team handled it.\n\nI've trained a market researcher, a sales call analyst, a proposal writer, a video scriptwriter, and even a custom GPT to evaluate LinkedIn profiles using six pillars to determine if the current LinkedIn presence builds authority, attracts their ideal client, and establishes trust, clarity, and uniqueness. These free me up to focus on big-picture strategy.\n\nAfter creating my ideal employees, I asked myself which mentors I would love to have alive or dead. Steve Jobs is known for his creativity and innovation, and there are numerous videos already online about him; he's the perfect mentor to create a custom GPT for.\n\nIn the instructions, I started with things like, \"you are Steve Jobs, you have decades of experience in X, Y, Z, your most important skill is creativity, innovation, thinking out of the box.\"\n\nThere are two types of video transcripts I trained it on. I uploaded transcripts from videos where he explains his strategies and what he looks for in products. The second approach was training through examples. I found videos showing how he launched products like the iPhone or iPad, so the AI learns from both his thought process and his execution of those launches.\n\nTo get it to the level it is now, I spent roughly 40 hours researching and building training assets, including PDFs and other materials the GPT can use as references. I continue adding more whenever I find relevant material, and I now have custom GPTs for Dan Kennedy and Elon Musk as well.\n\nThe frustrating part with training AI models is that I can give it a lot of information that's required to have the superpowers of Steve Jobs, but then the AI could take that and produce a lot of different things.\n\nWhen I prompt it, I avoid asking questions like \"What do you think of this idea?\" because the AI usually wants to agree with me and please me. Instead, I ask, \"On a scale from one to 10, how good is this idea?\"\n\nIt's not going to say the idea is bad, but now it might tell me it's a five. Then I'll ask, \"OK, what would make it a 10?\"\n\nThat's usually when it starts drawing on the experience of Steve Jobs that I've trained it with. We can go back and forth until I get the most useful and honest feedback possible.\n\nIt depends on the task. For more strategic outputs, I usually go through three to five rounds of refinement.\n\nWhen a product like NotebookLM was introduced, I started thinking, \"Oh my God, this is going to make the entire human race obsolete.\" I find AI products fascinating at first, but they can really scare me.\n\nI truly believe we don't know what the world will look like even a year from now. Sometimes I literally freeze thinking about the impacts, and if everyone will end up homeless, but I usually try to remind myself I'm not God or a higher power, and I don't know what will happen. This calms me down.\n\nI also realized that AI, by itself, is powerful, but what makes it truly magical is when we combine our expertise and skills with it. Using custom agents as an extension of our brain, rather than a replacement, is what really produces great output.\n\nThere's no turning back from it.",
    "readingTime": 6,
    "keywords": [
      "i've trained",
      "custom gpts",
      "custom gpt",
      "social media",
      "client's tone",
      "steve jobs",
      "created custom",
      "create custom",
      "training",
      "idea"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/built-steve-jobs-custom-gpt-to-make-my-business-decisions-2026-1",
    "thumbnail_url": "https://i.insider.com/69694b6504eda4732f2f29a6?width=949&format=jpeg",
    "created_at": "2026-01-17T00:56:12.704Z",
    "topic": "finance"
  },
  {
    "slug": "chatgpt-is-getting-ads-sam-altman-once-called-them-a-last-resort",
    "title": "ChatGPT is getting ads. Sam Altman once called them a 'last resort.'",
    "description": "The move to integrate ads into ChatGPT comes as OpenAI looks to increase its revenue amid $1.4 trillion in spending commitments and a possible IPO.",
    "fullText": "Netflix famously backtracked on its stance toward ads. Now, OpenAI is following suit.\n\nThe AI pioneer announced that ads are coming to ChatGPT ‚Äî less than two years after OpenAI CEO Sam Altman portrayed them as \"a last resort.\"\n\n\"Ads plus AI is sort of uniquely unsettling to me,\" Altman said during an event at Harvard University in May 2024. \"I kind of think of ads as a last resort for us for a business model.\"\n\nAltman's softened stance since then underlines the massive change OpenAI has undergone in the last two years, and the company's embrace of advertising is a testament to just how expensive the AI race has become.\n\nIn June, the OpenAI CEO said he wasn't \"totally against\" ads, he just wanted to make sure OpenAI got the balance correct.\n\n\"We haven't done any advertising product yet. I kind of...I mean, I'm not totally against it,\" Altman said on OpenAI's podcast. \"I can point to areas where I like ads. I think ads on Instagram, kinda cool. I bought a bunch of stuff from them. But I am, like, I think it'd be very hard to ‚Äî I mean, take a lot of care to get right.\"\n\nIn October, Altman expressed a desire to make sure the company went about ads in the proper manner when asked about OpenAI's past criticisms that other tech companies made addictive products.\n\n\"We're definitely worried about this,\" Altman said in response to a question that expressed concern about the similarities of Sora, OpenAI's AI video app, and TikTok and the potential of ads. \"I worry about it, not just for things like Sora and TikTok and ads in ChatGPT, which are maybe known problems that we can design carefully.\"\n\nMeanwhile, Altman, former Instacart CEO Fidji Simo (who OpenAI hired as its CEO of applications in early 2025), and seemingly every other member of the company's C-suite have expressed an almost insatiable demand for more compute in interviews.\n\nIt's proven a costly endeavor. OpenAI now has roughly $1.4 trillion in spending commitments on data centers and related infrastructure, raising questions about how it plans to pay the bills without the benefit of the advertising businesses of its Big Tech competitors, like Google and Meta.\n\nOpenAI also completed its restructuring into a more traditional for-profit, a move Altman said was designed to make it easier to attract future investments.\n\nAs part of the announcement, OpenAI said that free and Go users of the popular AI chatbot would start seeing ads being tested \"in the coming weeks.\"\n\nSharing details on the planned test, OpenAI said that ChatGPT's results \"will not be influenced by ads,\" the ads will be clearly labeled, and chatbot conversations will remain private and not shared with advertisers.\n\nIn the coming weeks, we plan to start testing ads in ChatGPT free and Go tiers.\n\nWe‚Äôre sharing our principles early on how we‚Äôll approach ads‚Äìguided by putting user trust and transparency first as we work to make AI accessible to everyone.\n\nWhat matters most:\n- Responses in‚Ä¶ pic.twitter.com/3UQJsdriYR\n\nPaid users of OpenAI's Plus, Pro, Business, and Enterprise plans won't see the ads, the company said.\n\nSimo, OpenAI's CEO of applications, who has previously spoken about her desire to get the ads balance correctly, wrote on X that the most important factor was \"ads will not influence the answers ChatGPT gives you.\"\n\nWhile Instacart launched ads during Simo's time leading the company, she has said OpenAI's approach would look different.\n\n\"If we ever were to do anything, it would have to be a very different model than what has been done before,\" she said. \"What I've learned from building ad platforms is that the thing people don't like about ads very often is not the ads themselves, it's the use of the data behind the ads.\"",
    "readingTime": 4,
    "keywords": [
      "openai ceo",
      "chatgpt",
      "advertising",
      "expressed",
      "altman",
      "stance",
      "resort",
      "plus",
      "business",
      "model"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chatgpt-ads-openai-2026-1",
    "thumbnail_url": "https://i.insider.com/696a8970e1ba468a96aa3bb6?width=1200&format=jpeg",
    "created_at": "2026-01-17T00:56:12.511Z",
    "topic": "finance"
  },
  {
    "slug": "apple-is-losing-its-grip-on-the-worlds-tech-supply-chain",
    "title": "Apple is losing its grip on the world's tech supply chain",
    "description": "Apple once set the bar for suppliers including TSMC. Now it's being unseated by Nvidia and AI cloud giants.",
    "fullText": "For over a decade, Apple sat at the center of the tech supply chain. Its enormous scale let it dictate pricing, lock up capacity, and steer the roadmaps of suppliers that made everything from chips and memory to substrates and packaging. That era is ending.\n\n\"Apple is no longer the gravitational center of the hardware universe,\" said Brad Gastwirth, global head of research and market intelligence at Circular Technology, who tracks the industry's supply chain.\n\n\"Apple still moves huge volumes and has unmatched brand strength. But the company is no longer the anchor client for fabs, substrate makers, or key component suppliers. That's a fundamental change.\"\n\nThis is important because the tech companies that control the supply chain are more likely to win. When you can order the largest amount of a key component, you get better pricing and a more reliable supply. That results in better-priced products that are available sooner than your rivals. This power is now shifting toward AI giants, including Nvidia and huge cloud players such as Amazon, Microsoft, and Google (aka \"AMG\").\n\nThe most visible sign is at TSMC, the world's largest chipmaker. It's famous for churning out cutting-edge iPhone chips, which gave Apple a huge advantage over other consumer hardware players.\n\nWhen TSMC reported results this week, it became very clear that its smartphone business is no longer its most important segment. High-performance computing ‚Äî a category dominated by AI chips for companies like Nvidia and hyperscale cloud providers ‚Äî now accounts for roughly 58% of TSMC's revenue, far surpassing smartphone processors.\n\nTSMC makes chips for Nvidia's AI servers, which are being snapped up in huge volumes by the cloud giants. They pack this gear into huge data centers that train and run AI models to power new services such as ChatGPT. Is that a better business than making iPhone chips?\n\nTSMC's CEO C.C. Wei answered that. He's been talking to these AI giants a lot lately. Here's what he said on this week's earnings call:\n\n\"They show me the evidence that the AI really helps their business. So they grow their business successfully and see the financial return. So I also double-checked their financial status. They are very rich.\"\n\nSuppliers go where the money is. Increasingly, the biggest Benjamins are coming from AI and cloud giants, not Apple.\n\nThis shift is rippling through the rest of the supply chain. Memory chip makers are reallocating capacity away from phones and PCs to feed AI data centers hungry for DRAM, dynamic random access memory. This is a common type of memory chip that's used in AI servers and iPhones.\n\nMemory prices have surged lately, and that's likely to push up smartphone costs and potentially squeeze margins. Nvidia has locked in long-term memory supply, leaving smartphone makers with less negotiating power.\n\n\"For the past 15 years, Apple's scale let it dictate component supply, pricing, and roadmaps,\" Gastwirth said. \"That leverage diminishes when suppliers earn higher margins and higher growth from AI customers than from smartphones.\"\n\nBottlenecks are emerging in unexpected places, too. A shortage of high-end glass cloth, a critical input for chip substrates, has suppliers prioritizing AI customers who pre-pay and sign multi-year contracts.\n\nApple, which uses these substrates across nearly all its products, is now competing with AI chipmakers for limited supply and even sending engineers to help smaller suppliers qualify alternative materials, according to a report this week from Nikkei.\n\nManufacturing partners are also re-prioritizing. Foxconn, once synonymous with iPhone assembly, now generates more revenue from AI servers than from consumer electronics. Its fastest-growing customers are hyperscalers and Nvidia, not Apple.\n\nNone of this makes Apple irrelevant. The company remains one of the world's largest buyers of components. However, in a supply chain increasingly shaped by AI, pricing, allocation, and capacity planning are being set elsewhere ‚Äî and Apple is learning what it's like to be just another very large customer.\n\n\"In the 2010s, Apple set the pace for the supply chain,\" Gastwirth said. \"In the late 2020s, Nvidia, hyperscalers, and AI infrastructure now dictate pricing, allocation, and long‚Äëterm capacity planning.\"\n\nApple didn't respond to a request for comment on Friday.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "world's largest",
      "capacity planning",
      "huge volumes",
      "pricing allocation",
      "dictate pricing",
      "iphone chips",
      "cloud giants",
      "memory chip",
      "supply chain",
      "suppliers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-losing-grip-tech-supply-chain-tsmc-nvidia-foxconn-2026-1",
    "thumbnail_url": "https://i.insider.com/696a837aa645d11881878256?width=800&format=jpeg",
    "created_at": "2026-01-17T00:56:12.315Z",
    "topic": "finance"
  },
  {
    "slug": "chatgpt-ads-might-not-be-a-totally-bad-thing-hear-me-out-on-this",
    "title": "ChatGPT ads might not be a totally bad thing. Hear me out on this.",
    "description": "ChatGPT says it's bringing ads to some US users. It might be annoying. But it also might be a good thing. (I know, I know. Hear me out!",
    "fullText": "All day, I see ads. Ads when I scroll social feeds, ads when I search Google, and ads on every website I go to. You're looking at some ads on this website right now (hopefully they aren't too annoying). I've lived to tell the tale ‚Äî and so have you.\n\nOpenAI announced on Friday that it will start testing ads in ChatGPT for US users on its free and Go tiers, something that had been rumored for a while. If you're a brand or advertiser, this might be exciting news, but I think most of us who are merely ChatGPT users are not thrilled.\n\nThere are a few obvious problems here. But I think we can say \"eh\" to most of them.\n\nProblem 1: Ads can be annoying! I agree! But as previously mentioned, we are all used to seeing ads everywhere at all times. It's just the constant buzz of white noise in every online experience.\n\nBut, eh: Since OpenAI is first testing this as a freemium model, sure, you can get rid of the ads if you pay. We're already dealing with that in a ton of other services like Netflix, Hulu, Spotify, and YouTube. I pay for all of those because I've decided the ads are annoying enough to pay extra to skip. (Actually, I don't pony up for ad-free Hulu. I made the calculation I don't watch it enough to make it worth it. On the other hand, I do play enough solitaire on my phone that I ponied up for the ad-free version.)\n\nProblem 2: It's a trust issue. Can we trust ChatGPT to give \"real\" answers rather than ads when we ask it to recommend a product or service, even if it's also running ads?\n\nBut, eh: I think people are already used to understanding things like Google search results with ads where there's a mix of organic and sponsored results. If I ask ChatGPT to help me revive my wilting monstera plant, and it shows me an ad for Miracle-Gro plant food at the bottom, will I be confused? Probably not because I've seen this kind of thing before on Google and social feeds. The mockups OpenAI shared flag to me pretty clearly what's an ad and what isn't.\n\nProblem 3: If ChatGPT is in the advertising biz, then it's subject to the pressures of brands and corporations that pay for those ads.\n\nBut, eh: OK, this one is actually real. Advertisers can and will exert pressure on platforms, broadcasters, publishers, and any other venues where their ads appear. They are powerful in that way!\n\nBut hear me out: This can actually have a kind of normalizing effect, in a positive way, especially when we're thinking about something like a huge AI company.\n\nConsider the case of an outlier event: In 2022, when Elon Musk first took over Twitter/X. Advertisers fled when the platform was deluged with hateful content, and it actually caused X to have to change its ways to woo them back. When we consider all the wildly terrifying things that a platform with immense global power like OpenAI can do, it's actually kind of a good thing to be hemmed in by the middle-of-the-road, safe values and standards of the Coca-Cola Company or other big, would-be US-based advertisers. It means you can't make your tech product so problematic that Walmart doesn't want to be associated with it.\n\nProblem 4: ChatGPT, a wonderful product that operated with a clean design, is now just another victim of enshittification!\n\nBut, eh:¬†Buddy, if you're a huge fan of ChatGPT and the purity of the beautiful, human, internet, I don't know what to tell you. Do you also love swimming, but hate water? Pick a side!\n\nLook, am I excited to have one more place to be annoyed by ads? No. But I also feel like this isn't the worst thing to happen with AI ‚Äî not even the worst thing this week. Although I would like to reserve the right to change my mind on this if it turns out to be really awful later down the line. Gotta hedge here.",
    "readingTime": 4,
    "keywords": [
      "social feeds",
      "google",
      "you're",
      "annoying",
      "i've",
      "don't",
      "product",
      "chatgpt",
      "search",
      "website"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chatgpt-ads-advertising-free-why-2026-1",
    "thumbnail_url": "https://i.insider.com/696a955da645d1188187865e?width=517&format=jpeg",
    "created_at": "2026-01-17T00:56:12.151Z",
    "topic": "finance"
  },
  {
    "slug": "figma-ceo-dylan-field-says-he-has-a-bias-for-hiring-young-workers-because-theyre-likely-ai-natives",
    "title": "Figma CEO Dylan Field says he has a 'bias' for hiring young workers because they're likely AI natives",
    "description": "Figma CEO Dylan Field says AI skills give young professionals an edge in hiring as the job market faces AI-driven changes.",
    "fullText": "Many young people are worried that AI is muscling in on the entry-level job market.\n\nDylan Field, the 34-year-old billionaire CEO of Figma, however, says AI gives young people an advantage in the hiring process.\n\nDuring a recent appearance on the \"In Good Company\" podcast, produced by Norges Bank Investment Management, Field said the effect of AI on hiring is a \"critical\" debate happening now in the software industry.\n\n\"Does AI mean that you should hire senior people or middle-level, or junior, or are all the jobs going to go away because AI will replace them all?\" Field asked. \"I've heard that last one a bunch of times, and it hasn't come true yet. All the people have said that. They continue to hire.\"\n\nField said that, in his opinion, young professionals have an advantage because they tend to have a better understanding of AI, an increasingly important skill.\n\n\"My bias actually is a lot more toward the junior folks, and I think people that are younger are AI native in a way that folks that are older have to learn,\" Field said.\n\nHe said Figma, which offers design products and services and competes directly with Adobe, has always hired a mix of ages, but that an understanding and passion for AI is a must going forward.\n\n\"I think that it is important that people come in, first of all, knowing that we're pushing full steam ahead into the AI era,\" Field said. \"So, if you have a bias against AI, that's a great dinner-table conversation between us, but we're very focused on making sure that we build for this AI age.\"\n\nYoung professionals are navigating a labor market bogged down in unemployment and uneven job growth. The Bureau of Labor Statistics in December published its final 2025 jobs report, which showed that the job market has remained stagnant, economists said.\n\nThe rise of AI has only added to that instability. Many companies these days are betting that AI will be able to do many of the tasks of entry-level workers, and economists say that could lead them to pause hiring young professionals.\n\nField, however, doesn't share that outlook.\n\nDuring an October 2025 appearance on \"Lenny's Podcast,\" Field said he doesn't think AI will take human jobs at all.",
    "readingTime": 2,
    "keywords": [
      "job market",
      "hiring",
      "jobs",
      "professionals",
      "field",
      "entry-level",
      "however",
      "advantage",
      "appearance",
      "hire"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/figma-ceo-dylan-field-hiring-jobs-market-ai-age-bias-2026-1",
    "thumbnail_url": "https://i.insider.com/696a6fe8e1ba468a96aa36e9?width=1200&format=jpeg",
    "created_at": "2026-01-17T00:56:11.947Z",
    "topic": "finance"
  },
  {
    "slug": "an-openai-researcher-turned-venture-capitalist-says-investors-are-3-to-5-years-behind-the-latest-ai-studies",
    "title": "An OpenAI researcher turned venture capitalist says investors are 3 to 5 years behind the latest AI studies",
    "description": "Jenny Xiao, who founded Leonis Capital in 2021, said AI needs more investors who understand frontier AI technology.",
    "fullText": "There is a yearslong lag in the AI hype cycle, according to one former AI researcher turned venture capitalist.\n\nJenny Xiao, who cofounded Leonis Capital in 2021 after a stint at OpenAI, said the current investment excitement around AI is far behind the actual research.\n\n\"There is a massive disconnect between what researchers are seeing and what investors are seeing,\" Xiao said on the Fortune Magazine podcast this week.\n\nWhat's being discussed at the biggest¬†AI conferences¬†is as much as 3 to 5 years behind what researchers are thinking about, Xiao said.\n\n\"We are so behind the technical frontier, and that's the gap I really want to bridge,\" she added.\n\nXiao, who dropped out of a Ph.D. program in economics and AI to take a researcher role at OpenAI, founded Leonis Capital to bridge the worlds of venture capital and deep academic AI research.\n\n\"With AI, there needs to be a new generation of founders. There needs to be a new generation of VCs,\" she said.\n\nIt's also the first time investors need to be able to provide financial support to both the market and the technology, she added. Unlike SaaS companies, which were built on a \"stable tech stack,\" AI is moving fast. To keep up, Xiao said investors are going to need to be as technical as the founders.\n\nIf she has one piece of advice for investors who haven't gone deep into the technical side, it's that they should know \"AI progress isn't linear,\" she said.\n\nThey should know AI progress happens in \"lumps,\" she said. So, questions about why AI progress is slowing down or speeding up aren't the best way to characterize the rate of development.\n\n\"It's neither of those two extremes,\" she said. \"It's somewhere in between.\"\n\nLeonis Capital did not immediately respond to a request for comment from Business Insider.",
    "readingTime": 2,
    "keywords": [
      "leonis capital",
      "investors",
      "it's",
      "behind",
      "technical",
      "progress",
      "researcher",
      "venture",
      "openai",
      "research"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-investment-hype-cycle-lag-research-leonis-capital-jenny-xiao-2026-1",
    "thumbnail_url": "https://i.insider.com/69694b8b764ca5f34d2a88e0?width=1200&format=jpeg",
    "created_at": "2026-01-17T00:56:11.816Z",
    "topic": "science"
  },
  {
    "slug": "chatgpt-to-start-showing-ads-in-the-us",
    "title": "ChatGPT to start showing ads in the US",
    "description": "Ads to be placed alongside answers as OpenAI looks to beef up revenue for flagship AI product",
    "fullText": "Ads to be placed alongside answers as OpenAI looks to beef up revenue for flagship AI product\n\nChatGPT will start including advertisements beside answers for US users as OpenAI seeks a new revenue stream.\n\nThe ads will be tested first in ChatGPT for US users only, the company announced on Friday, after increasing speculation that the San Francisco firm would turn to a potential cashflow model on top of its current subscriptions.\n\nThe ads will start in the coming weeks and will be included above or below, rather than within, answers. Mock-ups circulated by the company show the ads in a tinted box. They will be served to adult users ‚Äúwhen there‚Äôs a relevant sponsored product or service based on your current conversation‚Äù, according to OpenAI‚Äôs announcement. Ads will not be shown to users under 18 and will not appear alongside answers related to sensitive topics such as health, mental health or politics. Users will be able to click to learn about why they received a particular ad, according to OpenAI.\n\nPreviously, OpenAI‚Äôs CEO, Sam Altman, expressed reluctance to introduce ads to the chatbot: ‚ÄúI kind of hate ads just as an aesthetic choice.‚Äù His company has made commitments to spend more than $1tn on infrastructure supporting AI in the coming years. Altman has said that revenues are running at well over $13bn a year.\n\n‚ÄúMaybe there could be ads outside the [large language model] stream that are still really great, but the burden of proof there would have to be very high. And it would have to feel really useful to users and really clear that it was not messing with the model‚Äôs output,‚Äù Altman said recently. ‚ÄúI think it‚Äôd be very hard, we‚Äôd have to take a lot of care to get it right. People have a very high degree of trust in ChatGPT.‚Äù\n\nIn a blogpost on Friday, OpenAI attempted to reconcile Altman‚Äôs distaste for ads with the need for revenue: ‚ÄúOur enterprise and subscription businesses are already strong, and we believe in having a diverse revenue model where ads can play a part in making intelligence more accessible to everyone. Once we begin testing our first ad formats in the coming weeks and months, we look forward to getting people‚Äôs feedback.‚Äù\n\nThe company is also launching ChatGPT Go, which it bills as a low-cost subscription tier, for $8 a month.",
    "readingTime": 2,
    "keywords": [
      "users",
      "revenue",
      "model",
      "altman",
      "alongside",
      "product",
      "stream",
      "openai‚Äôs",
      "health",
      "subscription"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/16/chatgpt-ads-in-revenue-boost",
    "thumbnail_url": "https://i.guim.co.uk/img/media/942f89452240fbad123464e1a708484a2c47c016/520_0_5200_4160/master/5200.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=c779b4c8a16ae2270775fa64e944b2f5",
    "created_at": "2026-01-17T00:56:10.698Z",
    "topic": "tech"
  },
  {
    "slug": "do-you-trust-ai-enough-to-stop-saving-for-retirement",
    "title": "Do you trust AI enough to stop saving for retirement?",
    "description": "It's become a debate thanks to a bold proclamation by Elon Musk: Saving for retirement in 10 or 20 years \"won't matter.\"",
    "fullText": "How confident are you in AI? Enough to bet your retirement on it?\n\nThat's become a debate thanks to a bold proclamation by Elon Musk: Saving for retirement in 10 or 20 years \"won't matter.\"\n\nMusk's confidence comes from the work he's doing in artificial intelligence. The technological advancements will create an \"abundance\" of resources, granting everyone a \"universal high income,\" the Tesla and SpaceX CEO said.\n\nThat's easy to say when you have checks notes and almost passes out nearly $700 billion in the bank. What about people whose net worths have a lot fewer zeros?\n\nA group of BI reporters reached out to seven personal finance and AI gurus to get their take. They all agreed you shouldn't stop those direct deposits into your 401(K).\n\nEven if AI increases productivity and reduces costs over time, it's not clear whether the benefits will be distributed evenly across the population.\n\nMeanwhile, Americans are already in a precarious position regarding their retirement. Last year, BI's Noah Sheidlower spoke to nearly 200 Americans who continue to work past the age of 80 as part of our \"80 over 80\" series.\n\nWhile some like the fact that they can still work, others don't have a choice. And that's with the benefit of Social Security, a safety net that might not exist in the future.\n\nYou can't completely discredit Musk's take, though.\n\nYes, forgoing retirement on the belief that AI and tech will just figure it out in a few decades is a massive gamble. But the past few years have reminded us that tech can quickly flip the script on conventional wisdom.\n\nFive years ago, a career as a computer programmer felt secure. Now ‚Ä¶ not so much.\n\nIt's not a new phenomenon. My colleague Alistair Barr recently wrote in his Tech Memo newsletter () that the US quickly went from having 25 million horses to fewer than two million thanks to the arrival of the steam engine.\n\nEven if Musk is right, you'll probably still want some extra pocket change. Money isn't just about being able to buy things. It's also about access and exclusivity, and it's not clear how that might work in this new utopia.\n\nIt's not just going to Disney World; it's being able to cut the lines. It's not just getting tickets to the game; it's sitting courtside.\n\nBut if everyone's got \"universal high income,\" how will those perks work? Will all of us be equal? Or maybe some of us will be more equal than others?",
    "readingTime": 3,
    "keywords": [
      "it's",
      "retirement",
      "thanks",
      "musk's",
      "universal",
      "income",
      "nearly",
      "fewer",
      "others",
      "quickly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-retirement-savings-elon-musk-401k-finance-experts-2026-1",
    "thumbnail_url": "https://i.insider.com/69696401764ca5f34d2a8c8a?width=800&format=jpeg",
    "created_at": "2026-01-16T18:19:05.025Z",
    "topic": "finance"
  },
  {
    "slug": "walmart-is-shuffling-its-top-leadership-team-as-ai-rapidly-reshapes-retail",
    "title": "Walmart is shuffling its top leadership team as 'AI rapidly reshapes retail'",
    "description": "Walmart is promoting four execs to new roles under new CEO John Furner, including US e-commerce chief David Guggina, who will head up the US division.",
    "fullText": "Walmart is getting a major leadership shuffle as the retail giant leans hard into AI.\n\nThe company said Friday that four executives would move into new leadership roles when incoming CEO John Furner takes the helm on February 1.\n\n\"These internal promotions reflect our culture of opportunity and the depth of our leadership bench,\" Furner said in a statement.\n\nTaken together, the names have been behind some of Walmart's most significant growth strategies in recent years as it reaches beyond traditional brick-and-mortar retail into the age of e-commerce and agentic shopping.\n\nSucceeding Furner as head of Walmart's US division is David Guggina, who has been with the company for nearly eight years across roles, from automation to supply chain to e-commerce. He previously spent nine years at Amazon.\n\nWalmart US chief growth officer Seth Dallaire is expanding his role to lead global growth. Dallaire has been at Walmart for four years and previously served as Instacart's chief revenue officer and as a VP of ad sales at Amazon.\n\nElsewhere in the organization, Sam's Club CEO Chris Nicholas is set to take over Walmart's international division, following the departure of international CEO Kath McLay. Nicholas previously served as chief financial officer for the international division.\n\nUS chief merchandising officer Latriece Watkins will step into Nicholas's role as head of the warehouse club chain. Watkins started as an intern at Walmart in 1997.\n\n\"These leadership changes also mark a key step in how we organize for the future,\" Furner said in his statement. \"As AI rapidly reshapes retail, we are centralizing our platforms to accelerate shared capabilities, freeing up our operating segments to be more focused on and closer to our customers and members.\"",
    "readingTime": 2,
    "keywords": [
      "leadership",
      "chief",
      "officer",
      "retail",
      "growth",
      "division",
      "previously",
      "roles",
      "statement",
      "e-commerce"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/walmart-shuffles-top-leadership-team-as-ai-rapidly-reshapes-retail-2026-1",
    "thumbnail_url": "https://i.insider.com/696a5098764ca5f34d2a9150?width=1200&format=jpeg",
    "created_at": "2026-01-16T18:19:04.720Z",
    "topic": "finance"
  },
  {
    "slug": "meta-is-closing-its-vr-workplace-app-amid-reality-labs-layoffs",
    "title": "Meta is closing its VR workplace app amid Reality Labs layoffs",
    "description": "Meta said it's shutting down Workrooms in February, deleting user data as Reality Labs faces layoffs and the company continues to shift toward AI.",
    "fullText": "Meta is discontinuing its workplace virtual reality app Horizon Workrooms as it makes cuts in its metaverse division.\n\nThe Facebook owner said in a Thursday blog post that users would no longer be able to access Workrooms from February 16, after which any associated data will be deleted.\n\nMeta launched Workrooms in 2021 as a platform for remote teams to collaborate in virtual reality, as part of the company's big push into the metaverse.\n\nIts closure comes as the tech giant prepares to lay off workers in its Reality Labs division, which develops the company's virtual reality headsets and VR-based social network Horizon Worlds. Roughly 10% to 15% of Reality Labs' 15,000 employees are expected to be laid off, The New York Times reported.\n\nThe metaverse has been a costly bet for Meta, racking up more than $70 billion in losses since 2020. It has faced repeated rounds of cuts as Meta shifts its attention ‚Äî and spending ‚Äî toward AI.\n\nIn a¬†memo obtained¬†by Business Insider last year, Meta's CTO, who oversees the company's metaverse efforts, called 2025 \"the most critical\" year of his tenure.\n\nWorkrooms showcased how Meta Horizon could bring people together to work, collaborate, and connect, the company said. But Meta Horizon has since developed into a social platform that supports a wide range of productivity apps and tools.\n\nMeanwhile, Meta said its Horizon managed services will no longer be available for purchase from February 20, although customers would continue to receive support until the start of 2030.",
    "readingTime": 2,
    "keywords": [
      "virtual reality",
      "reality labs",
      "metaverse",
      "company's",
      "meta",
      "cuts",
      "division",
      "longer",
      "february",
      "platform"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-closing-vr-horizon-workplace-app-reality-labs-layoffs-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-16T18:19:04.502Z",
    "topic": "finance"
  },
  {
    "slug": "why-training-employees-pays-off-twice",
    "title": "Why Training Employees Pays Off Twice",
    "description": "Companies invest millions in employee training, yet the payoff often seems uncertain. A new study suggests the problem may be what organizations measure: most overlook the impact on managers. Researchers tracked a 16-week upskilling program at a Colombian government agency and found frontline output rose 10%, while help-seeking emails dropped‚Äîfreeing managers to focus on strategic work. These ‚Äúspillover effects‚Äù accounted for nearly half the program‚Äôs total benefits, making training far more cost-effective than traditional ROI models imply.¬† With AI reshaping roles, leaders should view training as a catalyst for organizational agility‚Äînot just individual performance.",
    "fullText": "Why Training Employees Pays Off Twice by Ben RandJanuary 16, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrint",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/why-training-employees-pays-off-twice",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_16_2198316237.jpg",
    "created_at": "2026-01-16T18:19:03.791Z",
    "topic": "business"
  },
  {
    "slug": "why-people-create-ai-workslopand-how-to-stop-it",
    "title": "Why People Create AI ‚ÄúWorkslop‚Äù‚Äîand How to Stop It",
    "description": "With the rise of gen AI tools, offices have had to contend with a new scourge: ‚Äúworkslop‚Äù or low-effort, AI-generated work that looks plausibly polished, but ends up wasting time and effort as it offloads cognitive work onto the recipient. Workslop can have a corrosive effect on office dynamics. But why do people create it and send it to their colleagues, especially if it can lead to bosses, coworkers, and subordinates thinking less of them? New research suggests that the recipe for workslop is surprisingly simple and under the control of management: It‚Äôs the result of unclear AI mandates and overwhelmed teams. Leaders are issuing vague directives for employees to start using extremely powerful tools, while many of those employees are overburdened, psychologically depleted, and operating in environments where it doesn‚Äôt feel safe to admit uncertainty or ask for help.",
    "fullText": "Why People Create AI ‚ÄúWorkslop‚Äù‚Äîand How to Stop It by Kate Niederhoffer, Alexi Robichaux and Jeffrey T. HancockJanuary 16, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintAs AI tools have proliferated in workplaces and pressure to use them has mounted, employees have had to contend with the scourge of workslop, or low-effort, AI-generated work that looks plausibly polished, but ends up wasting time and effort as it offloads cognitive work onto the recipient. For the person on the receiving end, it can be a confusing and infuriating experience.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/why-people-create-ai-workslop-and-how-to-stop-it",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_12_1262739982_1595860641.jpg",
    "created_at": "2026-01-16T18:19:03.617Z",
    "topic": "business"
  },
  {
    "slug": "openai-to-begin-testing-ads-on-chatgpt-in-the-us",
    "title": "OpenAI to begin testing ads on ChatGPT in the U.S.",
    "description": "OpenAI said ads would not influence ChatGPT's responses and that it will \"never\" sell user data to advertisers.",
    "fullText": "OpenAI on Friday announced it will begin testing ads within ChatGPT in the coming weeks, a highly anticipated decision that could kickstart a lucrative new revenue stream for the artificial intelligence startup.\n\nOpenAI said its Plus, Pro and Enterprise subscriptions¬†will not include ads, but it plans to start testing them with adult free users in the U.S. The company also made its low-cost Go offering available in the U.S. on Friday, and it said users who opt for that plan will also begin to see ads.\n\nThe company inked more than $1.4 trillion worth of infrastructure deals in 2025, and OpenAI CEO Sam Altman said in November that the startup was on track to generate $20 billion in annualized revenue run rate last year.\n\nIntroducing ads to ChatGPT could help OpenAI meet its ambitious spending commitments, as digital advertising has long been the cash cow for other big tech companies like Google and Meta.\n\nAds within ChatGPT will appear at the bottom of the chatbot's answers, and they will be clearly labeled, OpenAI said.\n\nChatGPT's responses will not be influenced by ads, and OpenAI said it will \"never\" sell users' data to advertisers, according to a release.\n\nUsers under the age of 18 will not see ads, and ads will not appear near certain topics, including politics, health and mental health, OpenAI said.\n\nAltman has publicly expressed reservations about introducing ads to ChatGPT in recent years, stating in interviews that doing so could erode users' trust in OpenAI's products. But in a November podcast appearance, Altman said he expected OpenAI to try ads \"at some point,\" though he added that he did not believe it would be the company's biggest revenue opportunity.\n\n\"We'll learn from feedback and refine how ads show up over time, but our commitment to putting users first and maintaining trust won't change,\" OpenAI said in a statement on Friday.\n\nAs OpenAI tests ads, the company said users will be able to learn more about why they're seeing a specific ads, dismiss ads and submit feedback about the experience.\n\nWATCH: OpenAI Investor Letter: Weekly and daily active user figures ‚Äòcontinue to produce all-time highs‚Äô",
    "readingTime": 2,
    "keywords": [
      "within chatgpt",
      "ads within",
      "introducing ads",
      "users",
      "openai",
      "revenue",
      "testing",
      "startup",
      "november",
      "health"
    ],
    "qualityScore": 0.9,
    "link": "https://www.cnbc.com/2026/01/16/open-ai-chatgpt-ads-us.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/108074841-1733965530853-gettyimages-2188251582-mc_16795_qpk84voo.jpeg?v=1768570902&w=1920&h=1080",
    "created_at": "2026-01-16T18:19:01.207Z",
    "topic": "tech"
  },
  {
    "slug": "ai-generated-code-isnt-cheating-oss-needs-to-talk-about-it",
    "title": "AI Generated Code Isn't Cheating: OSS Needs to Talk About It",
    "description": "Remember early 2025? \"Vibe coding\" was a meme and seemed mostly a tool for casual builders or those new to coding. It's now 2026, and we find ourselves living in a new reality. Industry leaders like DHH, Karpathy, and Lutke are publicly embracing AI-generated code controlled by human prompting.",
    "fullText": "Remember early 2025? ‚ÄúVibe coding‚Äù was a meme and seemed mostly a tool for casual builders or those new to coding. It was often used disparagingly, or to imply a lack of deep technical expertise. Some very cool basic applications were being built, but AI coding assistants couldn‚Äôt reliably function in complex codebases. But what a difference a year has made!\n\nIt‚Äôs now 2026, and we find ourselves living in a new reality. Some of the most influential voices in software engineering like DHH (Ruby on Rails), Andrej Karpathy (prev OpenAI, Tesla), Tobi Lutke (Shopify), Salvatore Sanfilippo (Redis), and Mitchell Hashimoto (Ghostty, prev Hashicorp) are publicly embracing a new¬† paradigm: completely AI generated code controlled by human-in-the-loop prompting. It was also recently publicized that Linus Torvalds (creator of Linux and Git) is leveraging AI vibe-coding in his side-projects.\n\nAI is everywhere: if you‚Äôre a software developer, you‚Äôve almost certainly tried at least one AI-assisted coding solution over the past year. It‚Äôs a safe assumption that a large portion of developers are using AI to help them, but we still know shockingly little about how their code was derived. This secrecy is outdated, especially now that the practice is being normalized by industry leaders.\n\nThe open source community is built on top of foundations of transparency and collaboration, of which knowledge sharing is a key component. At Mozilla.ai, we believe¬†we must embrace and encourage the disclosure of AI usage as quickly as possible. We need to move away from ‚ÄúShould we AI?‚Äù and towards a structure that clearly defines our expectations for where we encourage AI usage and how we document it.\n\nIn our project any-llm, we‚Äôve started to iterate on this philosophy by creating a pull request template that requests a few pieces of information whenever a PR is submitted.\n\nHere‚Äôs a snippet of the relevant part of our pull request template:\n\nFirst, we request that the contributors specify their level of AI usage: was AI used to draft and make edits? Or was their contribution completely AI-generated with them only directing it via plain language prompts? Both are acceptable, but it helps a reviewer understand how to approach their review. If we know the code is completely AI generated, we can be candid with our feedback and direct the contributor towards improving their prompting or AI coding configuration to improve quality. Without this transparency, it can be difficult to give feedback since a reviewer doesn‚Äôt want to offend the contributor by insinuating that their work came from a bot.\n\nSecond, we request information about the contributors' AI setup: what model(s) and IDE/CLI tools were used? This is valuable metadata for crowdsourcing best practices. Maybe there is one model or tool that works amazingly well with a certain codebase or language! Openly sharing this information allows all of us to learn from each other.\n\nLastly, we request that any responses to comments come from the contributor themselves and not their AI tool. It is frustrating to write comments without knowing if a human is on the other side reading and responding to the feedback. The open source community is a wonderful place to learn from each other, and that learning happens best when humans talk to humans. Of course, AI can be used to help the contributor brainstorm or improve their grammar, but we think the core discussion should still happen between two humans.\n\nWe welcome community opinions and hope to see similar approaches be adopted across the open source community. Let's keep learning and developing together!",
    "readingTime": 3,
    "keywords": [
      "request template",
      "coding",
      "community",
      "contributor",
      "tool",
      "completely",
      "code",
      "usage",
      "feedback",
      "humans"
    ],
    "qualityScore": 1,
    "link": "https://blog.mozilla.ai/ai-generated-code-isnt-cheating-oss-needs-to-talk-about-it/",
    "thumbnail_url": "https://blog.mozilla.ai/content/images/size/w1200/2026/01/George-Sturdy-and-Solomon-Young-s-vehicle-of-amusement.jpg",
    "created_at": "2026-01-16T18:18:59.372Z",
    "topic": "tech"
  },
  {
    "slug": "zep-ai-agent-context-engineering-yc-w24-is-hiring-forward-deployed-engineers",
    "title": "Zep AI (Agent Context Engineering, YC W24) Is Hiring Forward Deployed Engineers",
    "description": "Jobs at Zep AI",
    "fullText": "Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.ycombinator.com/companies/zep-ai/jobs/",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/a5f4989742560bd0715218257a7c7ea7f73ab700.png?1712364271",
    "created_at": "2026-01-16T18:18:57.855Z",
    "topic": "jobs"
  }
]
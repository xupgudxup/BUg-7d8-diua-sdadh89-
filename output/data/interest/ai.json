[
  {
    "slug": "wall-street-sees-ai-bubble-coming-and-is-betting-on-what-pops-it",
    "title": "Wall Street Sees AI Bubble Coming and Is Betting on What Pops It",
    "description": "It’s been three years since OpenAI set off euphoria over artificial intelligence with the release of ChatGPT. And while the money is still pouring in, so are the doubts about whether the good times can last.",
    "fullText": "MarketsBy Jeran WittensteinSaveIt’s been three years since OpenAI set off euphoria over artificial intelligence with the release of ChatGPT. And while the money is still pouring in, so are the doubts about whether the good times can last.From a recent selloff in the shares of Nvidia Corp., to Oracle Corp.’s plunge after reporting mounting spending on AI, to souring sentiment around a network of companies exposed to OpenAI, signs of skepticism are increasing. Looking to 2026, the debate among investors is whether to rein in AI exposure ahead of a potential bubble popping or double down to capitalize on the game-changing technology.",
    "readingTime": 1,
    "keywords": [
      "openai"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-14/wall-street-sees-an-ai-bubble-forming-and-is-gaming-what-pops-it",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ijt8j35wEhRU/v1/1200x800.jpg",
    "created_at": "2025-12-14T18:50:23.869Z",
    "topic": "gaming"
  },
  {
    "slug": "cognitive-offloading-in-the-era-of-ai",
    "title": "Cognitive Offloading in the Era of AI",
    "description": "Tech & AI - serene speed",
    "fullText": "We keep moving thinking out of our heads and into tools. Paper caught memories. Calculators captured arithmetic. AI now catches recall, drafting, and pattern finding. The risk is mushy judgment; the reward is shipping faster with fewer mistakes. The difference is in how you steer.\n\nHuman working memory is narrow. Context switching burns time. Inputs are exploding: tickets, PRs, logs, customer threads, and research all compete for attention. You forget details, duplicate work, and spend more time rereading than deciding.\n\nFailure modes when you offload poorly:\n\nMIT work on navigation tools showed brain regions tied to spatial planning go quiet when GPS drives every turn. The same pattern shows up with code and writing copilots: if you never build your own map, you stop noticing when the route is wrong.\n\nTreat AI as a structured cognitive exoskeleton. Offload the rote, keep the judgment.\n\nScenario: shipping a new API feature with a small team.\n\nYou offload recall, first drafts, and pattern spotting, then spend attention on judgment and sequencing.\n\nCognitive hygiene is the meta-layer above offloading: habits that keep judgment sharp while you delegate the rote parts.",
    "readingTime": 1,
    "keywords": [
      "judgment",
      "pattern",
      "offload",
      "tools",
      "recall",
      "shipping",
      "attention",
      "cognitive",
      "rote"
    ],
    "qualityScore": 0.85,
    "link": "https://pythonic.ninja/blog/2025-12-11-cognitive-offloading-ai/",
    "thumbnail_url": "https://images.unsplash.com/photo-1486825586573-7131f7991bdd?auto=format&fit=crop&w=1400&q=80",
    "created_at": "2025-12-14T18:50:20.520Z",
    "topic": "tech"
  },
  {
    "slug": "the-view-from-inside-the-ai-bubble",
    "title": "The View from Inside the AI Bubble",
    "description": "Secret parties, lavish buffets, and talks of annihilation at one of the largest AI-research conferences",
    "fullText": "In a small room in San Diego last week, a man in a black leather jacket explained to me how to save the world from destruction by AI. Max Tegmark, a notable figure in the AI-safety movement, believes that “artificial general intelligence,” or AGI, could precipitate the end of human life. I was in town for NeurIPS, one of the largest AI-research conferences, and Tegmark had invited me, along with five other journalists, to a briefing on an AI-safety index that he would release the next day. No company scored better than a C+.\n\nThe threat of technological superintelligence is the stuff of science fiction, yet it has become a topic of serious discussion in the past few years. Despite the lack of clear definition—even OpenAI’s CEO, Sam Altman, has called AGI a “weakly defined term”—the idea that powerful AI contains an inherent threat to humanity has gained acceptance among respected cultural critics.\n\nGranted, generative AI is a powerful technology that has already had a massive impact on our work and culture. But superintelligence has become one of several questionable narratives promoted by the AI industry, along with the ideas that AI learns like a human, that it has “emergent” capabilities, that “reasoning models” are actually reasoning, and that the technology will eventually improve itself.\n\nI traveled to NeurIPS, held at the waterfront fortress that is the San Diego Convention Center, partly to understand how seriously these narratives are taken within the AI industry. Do AGI aspirations guide research and product development? When I asked Tegmark about this, he told me that the major AI companies were sincerely trying to build AGI, but his reasoning was unconvincing. “I know their founders,” he said. “And they’ve said so publicly.”\n\nParallel to the growth of fear and excitement about AI in the past decade, NeurIPS attendance has exploded, increasing from approximately 3,850 conference-goers in 2015 to 24,500 this year, according to organizers. The conference center’s three main rooms each have the square footage of multiple blimp hangars. Speakers addressed audiences of thousands. “I do feel we’re on a quest, and a quest should be for the holy grail,” Rich Sutton, the legendary computer scientist, proclaimed in a talk about superintelligence.\n\nThe conference’s corporate sponsors had booths to promote their accomplishments and impress attendees with their R&D visions. There were companies you’ve heard of, such as Google, Meta, Apple, Amazon, Microsoft, ByteDance, and Tesla, and ones you probably haven’t, such as Runpod, Poolside, and Ollama. One company, Lambda, was advertising itself as the “Superintelligence Cloud.” A few of the big dogs were conspicuously absent from the exhibitor hall, namely OpenAI, Anthropic, and xAI. Consensus among the researchers I spoke with is that the cachet of these companies is already so great that setting up a booth would be pointless.\n\nThe conference is a primary battleground in AI’s talent war. Much of the recruiting effort happens outside the conference center itself, at semisecret, invitation-only events in downtown San Diego. These events captured the ever-growing opulence of the industry. In a lounge hosted by the Laude Institute, an AI-development support group, a grad student told me about starting salaries at various AI companies of “a million, a million five,” of which a large portion was equity. The lounge was designed in the style of a VIP lounge at a music festival. It was, in fact, located at the top of the Hard Rock Hotel.\n\nThe place to be, if you could get in, was the party hosted by Cohere, a Canadian company that builds large language models. (Cohere is being sued for copyright and trademark infringement by a group of news publishers, including The Atlantic.) The party was held on the USS Midway, an aircraft carrier used in Operation Desert Storm, which is now docked in the San Diego harbor. The purpose, according to the event’s sign-up page, was “to celebrate AI’s potential to connect our world.”\n\nWith the help of a researcher friend, I secured an invite to a mixer hosted by the Mohamed bin Zayed University of Artificial Intelligence, the world’s first AI-focused university, named for the current UAE president. Earlier this year, MBZUAI established the Institute for Foundation Models, a research group in Silicon Valley. The event, held at a steak house, had an open buffet with oysters, king prawns, ceviche, and other treats. Upstairs, Meta was hosting its own mixer. According to rumor, some of the researchers downstairs were Meta employees hoping to be poached by the Institute for Foundation Models, which supposedly offered more enticing compensation packages.\n\nOf 5,630 papers presented in the poster sessions at NeurIPS, only two mention AGI in their title. An informal survey of 115 researchers at the conference suggested that more than a quarter didn’t even know what AGI stands for. At the same time, the idea of AGI, and its accompanying prestige, seemed at least partly responsible for the buffet. The amenities I encountered certainly weren’t paid for by chatbot profits. OpenAI, for instance, reportedly expects its massive losses to continue until 2030. How much longer can the industry keep the ceviche coming? And what will happen to the economy, which many believe is propped up by the AI industry, when it stops?\n\nIn one of the keynote speeches, the sociologist and writer Zeynep Tufekci warned researchers that the idea of superintelligence was preventing them from understanding the technology they were building. The talk, titled “Are We Having the Wrong Nightmares About AI?,” mentioned several dangers posed by AI chatbots, including widespread addiction to chatbots and the undermining of methods for establishing truth. After Tufekci gave her talk, the first audience member to ask a question appeared annoyed. “Have you been following recent research?” the man asked. “Because that’s the exact problems we’re trying to fix. So we know of these concerns.” Tufekci responded, “I don’t really see these discussions. I keep seeing people discuss mass unemployment versus human extinction.”\n\nIt struck me that both might be correct: that many AI developers are thinking about the technology’s most tangible problems while public conversations about AI—including those among the most prominent developers themselves—are dominated by imagined ones. Even the conference’s name contained a contradiction: The name “NeurIPS” is short for “Neural Information Processing Systems,” but artificial neural networks were conceived in the 1940s by a logician-and-neurophysiologist duo who wildly underestimated the complexity of biological neurons and overstated their similarity to a digital computer. Regardless, a central feature of AI’s culture is an obsession with the idea that a computer is a mind. Anthropic and OpenAI have published reports with language about chatbots being, respectively, “unfaithful” and “dishonest.” In the AI discourse, science fiction often defeats science.\n\nOn the roof of the Hard Rock Hotel, I attended an interview with Yoshua Bengio, one of the three “godfathers” of AI. Bengio, a co-inventor of an algorithm that makes ChatGPT possible, recently started a nonprofit called LawZero to encourage the development of AI that is “safe by design.” He took the nonprofit’s name from a law featured in several Isaac Asimov stories that states that a robot should not allow humans to be harmed. Bengio was concerned that, in a possible dystopian future, AIs might deceive their creators and that “those who will have very powerful AIs could misuse it for political advantage, in terms of influencing public opinion.”\n\nI looked around to see if anyone else was troubled by the disconnect. Bengio did not mention how fake videos are already affecting public discourse. Neither did he meaningfully address the burgeoning chatbot mental-health crisis, or the pillaging of the arts and humanities. The catastrophic harms, in his view, are “three to 10 or 20 years” away. We still have time “to figure it out, technically.”\n\nBengio has written elsewhere about the more immediate dangers of AI. But the technical and speculative focus of his remarks captures the sentiment among technologists who now dominate the public conversation about our future. Ostensibly, they are trying to save us, but who actually benefits from their predictions? As I spoke with 25-year-olds entertaining seven-figure job offers and watched the industry’s millionaire luminaries debate the dangers of superintelligence, the answer seemed clear.",
    "readingTime": 7,
    "keywords": [
      "rock hotel",
      "science fiction",
      "san diego",
      "foundation models",
      "neurips",
      "industry",
      "idea",
      "among",
      "conference",
      "researchers"
    ],
    "qualityScore": 1,
    "link": "https://www.theatlantic.com/technology/2025/12/neurips-ai-bubble-agi/685250/",
    "thumbnail_url": "https://cdn.theatlantic.com/thumbor/6yBQjSLMBfEUwxwqHa9iIrt8rD8=/3x0:1097x574/960x504/media/img/mt/2025/12/2025_12_12_Ai_mpg/original.gif",
    "created_at": "2025-12-14T18:50:18.218Z",
    "topic": "tech"
  },
  {
    "slug": "prompt-engineering-is-a-hidden-tax-chatgpt-vs-copyai-vs-vertical-agents",
    "title": "Prompt Engineering Is a \"Hidden Tax\": ChatGPT vs. Copy.ai vs. Vertical Agents",
    "description": "A definitive 2025 comparison of Vect AI, Copy.ai, and ChatGPT. Discover why specialized 'Marketing Operating Systems' are replacing generalist chatbots for serious growth teams.",
    "fullText": "Every week, a new \"ChatGPT Killer\" launches on Product Hunt. But for distinct, revenue-focused marketers, the noise is distracting. You don't need another chatbot that can write a mediocre limerick about a pirate. You don't need a tool that requires a 50-paragraph \"mega-prompt\" just to sound human.\n\nYou need a system that drives Revenue.\n\nIn 2025, the AI landscape has calcified into three distinct categories. Understanding this split is critical before you swipe your credit card.\n\nThis guide isn't just a list of features or a rehash of pricing pages. It is a \"Stress Test\" of how these tools handle the real, messy, complex work of a modern high-growth marketing team.\n\nTo understand the tool, you must understand the brain behind it. Each platform was built with a fundamentally different thesis about what a marketer needs.\n\nOpenAI built a general-purpose reasoning engine. It is brilliant at coding, summarizing history, and casual chat. But it has no \"opinion\" on marketing. It doesn't know that a headline should differ between a cold email and a landing page unless you explicitly tell it the precise psychological framework to use.\n\nCopy.ai pivoted from a simple writing tool to a \"GTM AI Platform.\" Their thesis is that marketing is a series of data flows. Scrape LinkedIn -> Enrich Data -> Write Email -> Send.\n\nVect AI was built with a single thesis: Strategy should come before generation. It assumes you want the best marketing outcome, not just any text. It is \"State-Aware\"—meaning it permanently remembers your brand voice, audience pains, and product details.\n\nLet's move away from theory and look at three common, painful scenarios every marketer faces.\n\nYou need to fix a landing page that isn't converting.\n\nChatGPT Approach:\nYou paste the text. You ask: \"Make this better.\" ChatGPT changes a few synonyms. It sounds robotic. You spend 15 minutes explaining your customer persona. It eventually gives you something passable but generic.\n\nCopy.ai Approach:\nYou look for a \"Landing Page Rewriter\" workflow. You run it. It generates 10 variations. You have to read all 10 to decide which one is good.\n\nVect AI Approach:\nYou open the Conversion Killer Detector. You paste your URL. The Agent scans the live page, identifies \"Passive Voice\" and \"Weak Value Props,\" assigns a \"Panic Score,\" and auto-rewrites the specific sections that are killing sales.\n\nYou released a new feature. You need a blog, 10 tweets, 3 LinkedIn posts, and a newsletter.\n\nCopy.ai Approach (The Engineer's Way):\n\nVect AI Approach (The Strategy Way):\n\nThis is the single biggest differentiator.\n\nChatGPT has \"Custom Instructions,\" but they are weak. It often forgets them in long threads.\nCopy.ai uses \"Brand Voice\" snippets, but you have to manually select them for every workflow.\n\nVect AI uses a Global Brand Kernel.\nWhen you onboard, you define your audience, your pain points, and your \"Anti-Persona\" (who you don't want).\n\nMost AI tools are \"Yes Men.\" If you ask them to write a boring, 3,000-word email, they will say \"Sure!\" and do it.\n\nVect AI has a conscience. It's called the Resonance Engine.\nBefore you publish, you can run your content through this simulation. It uses historical data from millions of high-performing ads and posts to predict success.\n\nOnly Vect AI protects you from looking stupid. The others just execute orders.\n\nMarketing isn't just text. It's visual.\n\nCopy.ai is purely text-based. You need a separate Midjourney subscription for images.\nChatGPT has DALL-E 3, which is fun but often too \"cartoony\" for enterprise brands.\n\nVect AI includes a commercial-grade AI Ad Creative Studio and Marketing Video Ad generator.\n\nWhen comparing prices, most people look at the monthly fee. This is a mistake. You must calculate the Time Cost.\n\nTo give you a sense of the specialization, look at how granular Vect AI gets compared to the generic \"Write an Article\" button in other tools:\n\nThe era of \"Generalist AI\" for professionals is ending. We are entering the era of \"Agentic Workflows.\"\n\nStop fighting with prompts. Stop building workflows. Start leading your market.\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Conversion Killer Detector\" and get results in minutes.",
    "readingTime": 4,
    "keywords": [
      "conversion killer",
      "killer detector",
      "copy.ai approach",
      "landing page",
      "vect ai",
      "brand voice",
      "marketing",
      "look",
      "don't",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/vect-vs-copy-ai",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T18:50:17.665Z",
    "topic": "tech"
  },
  {
    "slug": "at-this-small-buyout-firm-talking-about-ai-for-costcutting-is-offlimits",
    "title": "At this small buyout firm, talking about AI for cost-cutting is off-limits",
    "description": "Unlike their buyout peers, Tide Rock isn't looking to AI to cut costs. Instead, it's CEO told us, its using it to find new customers and deals.",
    "fullText": "Most fears and hopes surrounding AI center on its ability to save on labor costs. Whether it's Jamie Dimon predicting a three-and-a-half-day workweek, the chorus of CEOs saying that AI will help its workers get more done, or the research predicting potentially catastrophic white-collar job cuts, the focus is on efficiency.\n\nBut at one investing firm, cost-cutting is practically a forbidden word.\n\n\"The mandate across the company is don't talk about using our resources in AI or tech to cut costs or create efficiencies,\" Tide Rock CEO Ryan Peddycord told Business Insider.\n\nThe firm has had AI engineers for two years, but they're aimed at growing business, not cutting, said Peddycord.\n\nThe San Diego and New York-based firm, which invests in smaller businesses than your typical private-equity giants, does not use debt to finance its acquisitions. It manages $1 billion, including its current investments and dry powder. It has done over 50 acquisitions, with growth, not just financial engineering, as its goal.\n\n\"Our foundation is, and our principle is, that we are focused on being growth engines for these businesses, and that's where we want to focus our resources,\" Peddycord said.\n\nPeddycord spoke to Business Insider about how the firm's use of AI fits into its business model and gave some real-world examples of where it has made an impact.\n\nThe company buys founder-run businesses when founders have \"a catalyst to change,\" like their own looming retirement or an illness in their family, which means they're much more protective of the asset they're selling than your typical financial investor.\n\nThey then focus on growing those companies, which means Tide Rock hires chief marketing officers and chief revenue officers \"who know how to run businesses\" instead of your typical private equity partners, Peddycord said.\n\nThe firm's companies have seen organic revenue growth of 24% a year since Tide Rock was launched 13 years ago, said Peddycord. (He also said the firm has only lost money on one deal over that time period.)\n\nThey're looking for a way to monetize what they built over time, but really just as important to them is for their brand and their legacy and their employees to be able to kind of continue on without them,\" Peddycord said.\n\nFor founders like this, the story of growth is an essential reason they'd choose to sell to Tide Rock. As such, any discussion of using AI to cut employees or costs is anathema to their sales pitch, whereas AI for growth is a selling point.\n\nAI is becoming an integral part of the firm's strategy, but they've been doing this for years before the advent of LLMs some operational best practices in a library of over 100 videos and 500 pages of documentation.\n\n\"A CEO of a portfolio company has access to certain information, a controller has access to a different set of information, a VP of sales has access to information,\" Peddycord said.\n\nAI tools have become another operational best practice that the firm shares across the companies it manages, which it tracks in a library of 100 videos and 500 pages of documentation.\n\nThe firm also has other centralized resources in-house, \"as a bridge\" to get the businesses to a place where they can operate on their own, including a centralized talent acquisition team and centralized chief marketing and revenue officers.\n\nThis has led to a world where the firm has, for example, been able to integrate a customer relationship management system in \"30 to 45 days\" instead of \"12 to 18 months,\" said Peddycord.\n\nThe company is happy to use third-party applications that can cut costs, but it's a waste of their own resources, said Peddycord.\n\n\"I have a belief that everybody's so focused on cost-cutting that third parties are going to pick off all the low-hanging fruit there,\" Peddycord said. \"So us trying to invest our dollars to go create things that other people are creating and probably investing more dollars to do isn't the right place to spend our money.\"\n\nThe first tool they invested in was finding companies to purchase. The data on platforms like Pitchbook and Crunchbase is \"very, very incomplete\" at the sub-$10 million EBITDA level the firm invests in, said Peddycord, so the firm first invested \"heavily\" in ways to find these companies and start pitching them.\n\nSoon, the firm realized that this ability to find a lot of \"non-public information\" about companies and then reach out to them would also be \"super relevant\" for their portfolio companies when they're looking for new customers, Peddycord said.\n\nPeddycord provided the example of identifying potential customers for its manufacturing portfolio companies that sell to the government, aerospace, or defense industries.\n\n\"When Blue Origin wins a large contract, there is some public information that we are able to gather to identify what it is that they won the contract for, and we can even reverse engineer what sub-component parts and services are going to be necessary to then go create that,\" Peddycord said.\n\nFrom there, the firm's portfolio companies could \"get in the door earlier\" to offer their sub-component manufacturing help, Peddycord said.\n\n\"In those high-growth areas like aerospace and defense, they are working as hard to find new qualified suppliers as we are to find new customers,\" Peddycord said.",
    "readingTime": 5,
    "keywords": [
      "chief marketing",
      "customers peddycord",
      "revenue officers",
      "they're looking",
      "tide rock",
      "firm",
      "businesses",
      "growth",
      "resources",
      "firm's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tide-rock-buy-out-firm-ai-cost-cutting-2025-12",
    "thumbnail_url": "https://i.insider.com/693c9e8e04eda4732f2d7bf3?width=1200&format=jpeg",
    "created_at": "2025-12-14T18:50:17.326Z",
    "topic": "finance"
  },
  {
    "slug": "us-power-shortage-how-small-modular-nuclear-reactors-could-fill-the-gap",
    "title": "US Power Shortage: How Small Modular Nuclear Reactors Could Fill the Gap",
    "description": "US electricity demand is now expected to rise 20 to 100 percent over the next 15 years as AI data centers, chip fabs and electrification strain an aging grid. Scott Strazik and Nicole Holmes of GE Vernova and Joseph Majkut of CSIS explain why nuclear – especially through small modular reactors – is back on the table.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-14/can-modular-nuclear-reactors-fill-the-power-gap-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ipVwqUEOzRGw/v3/-1x-1.jpg",
    "created_at": "2025-12-14T13:19:55.820Z",
    "topic": "finance"
  },
  {
    "slug": "ai-and-the-ironies-of-automation-part-2",
    "title": "AI and the ironies of automation – Part 2",
    "description": "Some (well-known) consequences of AI automating work",
    "fullText": "In the previous post, we discussed several observations, Lisanne Bainbridge made in her much-noticed paper “The ironies of automation”, she published in 1983 and what they mean for the current “white-collar” work automation attempts leveraging LLMs and AI agents based on LLMs, still requiring humans in the loop. We stopped at the end of the first chapter, “Introduction”, of the paper.\n\nIn this post, we will continue with the second chapter, “Approaches to solutions”, and see what we can learn there.\n\nHowever, before we start: Some of the observations and recommendations made in the paper must be taken with a grain of salt when applying them to the AI-based automation attempts of today. When monitoring an industrial production plant, it is often a matter of seconds until a human operator must act if something goes wrong to avoid severe or even catastrophic accidents.\n\nTherefore, it is of the highest importance to design industrial control stations in a way that a human operator can recognize deviations and malfunctions as easily as possible and immediately trigger countermeasures. A lot of work is put into the design of all the displays and controls, like, e.g., the well-known emergency stop switch in a screaming red color that is big enough to be punched with a flat hand, fist or alike within a fraction of a second if needed.\n\nWhen it comes to AI-based solutions automating white-collar work, we usually do not face such critical conditions. However, this is not a reason to dismiss the observations and recommendations in the paper easily because, e.g.:\n\nIf we let this sink in (plus a few other aspects, I did not write down here but you most likely will add in your mind), we quickly come to the conclusion that also in our AI-related automation context humans are often expected to make quick decisions and act based on them, often under conditions that make it hard (if not impossible) to conduct any in-depth analysis.\n\nIf we then also take into account, that depending on the situation a wrong result produced by an AI solution which eluded the human operator may have severe consequences in the worst case (e.g., assume a major security incident due to a missed wrongdoing of the AI solution), the situation is not that far away anymore from the situation in an industrial plant’s control station.\n\nSummarizing, we surely need to add the necessary grain of salt, i.e., ask ourselves how strict the timing constraints in our specific setting are to avoid comparing apples and oranges in the worst case. However, in general we need to consider the whole range of possible settings which will – probably more often than we think – include that humans need to make decisions in a very short time under stressful conditions (which makes things more precarious).\n\nThis brings us immediately to Lisanne Bainbridge’s first recommendation:\n\nIn any situation where a low probability event must be noticed quickly then the operator must be given artificial assistance, if necessary even alarms on alarms.\n\nIn other words, the system must support the human operator as well as possible in detecting a problem, especially if it tends to occur rarely. It is a consequence of the “monitoring fatigue” problem we discussed in the previous post.\n\nDue to the learnings people have made, a lot of effort has been put into the design of the displays, the controls and also the alerting mechanisms of industrial production control stations, making sure the human operators can make their jobs as good, as stress-free and as reliable as possible.\n\nThe usual idea is that a single human controls a fleet of AI agents that are designed to do some kind of job, e.g., writing code. Sometimes, most agents are generic “workers”, orchestrated by some kind of supervisor that delegates parts of the work to the worker agents. Sometimes, the different agents are “specialists”, each for a certain aspect of the job to be done, that collaborate using some kind of choreography (or are also orchestrated by a supervisor). While the generic workers are easier to set up, the specialized workers usually produce more accurate results.\n\nBecause these AI-based agents sometimes produce errors, a human – in our example a software developer – needs to supervise the AI agent fleet and ideally intervenes before the AI agents do something they should not do. Therefore, the AI agents typically create a plan of what they intend to do first (which as a side effect also increases the likelihood that they do not drift off). Then, the human verifies the plan and approves it if it is correct, and the AI agents execute the plan. If the plan is not correct, the human rejects it and sends the agents back to replanning, providing information about what needs to be altered.\n\nLet us take Lisanne Bainbridge’s recommendation and compare it to this approach that is currently “best practice” to control an AI agent fleet.\n\nUnless we tell them to act differently, LLMs and also AI agents based on them are quite chatty. Additionally, they tend to communicate with an air of utter conviction. Thus, they present to you this highly detailed, multi-step plan of what they intend to do, including lots of explanations, in this perfectly convinced tone. Often, these plans are more than 50 or 100 lines of text, sometimes even several hundred lines.\n\nMost of the time, the plans are fine. However, sometimes the AI agents mess things up. They make wrong conclusions, or they forget what they are told to do and drift off – not very often, but it happens. Sometimes the problem is obvious at first sight. But more often, it is neatly hidden somewhere behind line 123: “… and because 2 is bigger than 3, it is clear, we need to < do something critical >”. But because it is so much text the agents flood you with all the time and because the error is hidden so well behind this wall of conviction, we miss it – and the AI agent does something critical wrong.\n\nWe cannot blame the person for missing the error in the plan. The problem is that this is probably the worst UI and UX possible for anyone who is responsible for avoiding errors in a system that rarely produces errors.\n\nBut LLM-based agents make errors all the time, you may say. Well, not all the time. Sometimes they do. And the better the instructions and the setup of the interacting agents, the fewer errors they produce. Additionally, we can expect more specialized and refined agents in the future that become increasingly better in their respective areas of expertise. Still, most likely they will never become completely error-free because of the underlying technology that cannot guarantee consistent correctness.\n\nThis is the setting we need to ponder if we talk about the user interface for a human observer: a setting where the agent fleet only rarely makes errors but we still need a human monitoring and intervening if things should go wrong. It is not yet clear how such an interface should look like, but most definitely not as it looks now. Probably we could harvest some good insights from our UX/UI design colleagues for industrial production plant control stations. We would need only to ask them …\n\nLisanne Bainbridge then makes several recommendations regarding the required training of the human operator. This again is a rich section, and I can only recommend reading it on your own because it contains several subtle yet important hints that are hard to bring across without citing the whole chapter. Here, I will highlight only a few aspects. She starts with:\n\n[Some points made in the previous section] make it clear that it can be important to maintain manual skills.\n\nThen she talks about letting the human operator take over control regularly, i.e., do the job instead of the machine as a very effective training option. Actually, without doing hands-on work regularly, the skills of a human expert deteriorate surprisingly fast.\n\nBut if taking over the work regularly is not an option, e.g., because we want continuous superhuman productivity leveraging AI agents (no matter if it makes sense or not), we still need to make sure that the human operator can take over if needed. In such a setting, training must take place in some other way, usually using some kind of simulator.\n\nHowever, there is a problem with simulators, especially if human intervention is only needed (and wanted) if things do not work as expected:\n\nThere are problems with the use of any simulator to train for extreme situations. Unknown faults cannot be simulated, and system behaviour may not be known for faults which can be predicted but have not been experienced.\n\nThe consequence of this issue is:\n\nThis means that training must be concerned with general strategies rather than specific responses […]\n\nIt is inadequate to expect the operator to react to unfamiliar events solely by consulting operating procedures. These cannot cover all the possibilities, so the operator is expected to monitor them and fill in the gaps.\n\nWhich leaves us with the irony:\n\nHowever, it is ironic to train operators in following instructions and then put them in the system to provide intelligence.\n\nThis is a problem we will need to face with AI agents and their supervising humans in the future, too. The supervising experts are meant to intervene whenever things become messy, whenever the AI agents get stuck, often in unforeseen ways. These are not regular tasks. Often, these are also not the issues we expect an AI agent to run into and thus can provide training for. These are extraordinary situations, the ones we do not expect – and the more refined and specialized the AI agents will become in the future, the more often the issues that require human intervention will be of this kind.\n\nThe questions seem to hint at a sort of paradox, and an answer to both questions is all but obvious. At the moment, we still have enough experienced subject matter experts that the questions may feel of lower importance. But if we only start to address the questions when they become pressing, they will be even harder – if not impossible – to solve.\n\nTo end this consideration with the words of Lisanne Bainbridge:\n\nPerhaps the final irony is that it is the most successful automated systems, with rare need for manual intervention, which may need the greatest investment in human operator training.\n\nIn other words, we cannot simply take a few available human experts and make them supervise agents that took over their work without any further investments in the humans. Instead, we need to train them continuously, and the better the agents become, the more expensive the training of the supervisors will become. I highly doubt that decision makers who primarily think about saving money when it comes to AI agents are aware of this irony.\n\nAs I wrote in the beginning of first part of this blog series, “The ironies of automation” is a very rich and dense paper. We are still only at the end of the second chapter “Approaches to solutions” which is two and a half pages into the paper and there is still a whole third chapter called “Human-computer collaboration” which takes up another page until we get to the conclusion.\n\nWhile this third chapter also contains a lot of valuable advice that goes well beyond our focus here, I will leave it to you to read it on your own. As I indicated at the beginning, this paper is more than worth the time spent on it.\n\nHowever, before finishing this little blog series, I would like to mention a new kind of dilemma that Lisanne Bainbridge did not discuss in her paper because the situation was a bit different with industrial production plant automation than with AI-agent-based automation. But as this topic fits nicely into the just-finished training paradox section, I decided to add it here.\n\nThe issue is that just monitoring an AI agent fleet doing its work and intervening if things go wrong usually is not sufficient, at least not yet. All the things discussed before apply, but there is more to interacting with AI agents because we cannot simply be reactive with AI agents. We cannot simply watch them doing their work and only intervene if things go wrong. Instead, we additionally need to be proactive with them: We need to direct them.\n\nWe need to tell the AI agents what to do, what not to do, which chunks to pick and so on. This is basically a leadership role. While you do not lead humans, the kind of work is quite similar: You are responsible for the result; you are allowed to set directions and constraints, but you do not immediately control the work. You only control it through communicating with the agents and trying to direct them in the right direction with orders, with feedback, with changed orders, with setting different constraints, etcetera.\n\nThis is a skill set most people do not have naturally. Usually, they need to develop it over time. Typically, before people are put in a leadership role directing humans, they will get a lot of leadership training teaching them the skills and tools needed to lead successfully. For most people, this is essential because if they come from the receiving end of orders (in the most general sense of “orders”), typically they are not used to setting direction and constraints. This tends to be a completely new skill they need to learn.\n\nThis does not apply only to leading humans but also to leading AI agents. While AI agents are not humans, and thus leadership will be different in detail, the basic skills and tools needed are the same. This is, BTW, one of the reasons why the people who praise agentic AI on LinkedIn and the like are very often managers who lead (human) teams. For them, leading an AI agent fleet feels very natural because it is very close to the work they do every day. However, for the people currently doing the work, leading an AI agent fleet usually does not feel natural at all.\n\nHowever, I have not yet seen anyone receiving any kind of leadership training before being left alone with a fleet of AI agents, and I still see little discussion about the issue. “If it does not work properly, you need better prompts” is the usual response if someone struggles with directing agents successfully.\n\nSorry, but it is not that easy. The issue is much bigger than just optimizing a few prompts. The issue is that people have to change their approach completely to get any piece of work done. Instead of doing it directly, they need to learn how to get it done indirectly. They need to learn how to direct a group of AI agents effectively, how to lead them.\n\nThis also adds to the training irony of the previous topic. Maybe the AI agent fleets will become good enough in the future that we can omit the proactive part of the work and only need to focus on the reactive part of the work, the monitor-and-intervene part. But until then, we need to teach human supervisors of AI agent fleets how to lead them effectively.\n\nWe discussed several ironies and paradoxes from Lisanne Bainbridge’s “The ironies of automation” and how they also apply to agentic AI. We looked at the unlearning and recall dilemma and what it means for the next generation of human supervisors. We discussed monitoring fatigue and the status issue. We looked at the UX and UI deficiencies of current AI agents and the training paradox. And we finally looked at the leadership dilemma, which Lisanne Bainbridge did not discuss in her paper but which complements the training paradox.\n\nI would like to conclude with the conclusion of Lisanne Bainbridge:\n\n[…] humans working without time-pressure can be impressive problem solvers. The difficulty remains that they are less effective when under time pressure. I hope this paper has made clear both the irony that one is not by automating necessarily removing the difficulties, and also the possibility that resolving them will require even greater technological ingenuity than does classic automation.\n\nI think over time we will become clear on how much “The ironies of automation” also applies to automation done with AI agents and that we cannot ignore the insights known for more than 40 years meanwhile. I am also really curious how the solutions to the ironies and paradoxes will look like.\n\nUntil then, I hope I gave you a bit of food for thought to ponder. If you should have some good ideas regarding the ironies and how to address them, please do not hesitate to share them with the community. We learn best by sharing and discussing, and maybe your contribution will be a step towards solving the issues discussed …",
    "readingTime": 15,
    "keywords": [
      "chapter approaches",
      "blog series",
      "generic workers",
      "production plant",
      "monitoring fatigue",
      "tools needed",
      "industrial production",
      "third chapter",
      "leadership role",
      "cannot simply"
    ],
    "qualityScore": 1,
    "link": "https://www.ufried.com/blog/ironies_of_ai_2/",
    "thumbnail_url": "https://ufried.com//images/logo.png",
    "created_at": "2025-12-14T13:19:51.138Z",
    "topic": "tech"
  },
  {
    "slug": "experts-urge-caution-as-trumps-big-bill-incentivizes-ai-in-healthcare",
    "title": "Experts urge caution as Trump’s big bill incentivizes AI in healthcare",
    "description": "Analysts say benefits could be felt in under-resourced rural hospitals but warn against AI as a cost-cutting measure\nFor states to receive certain funding stipulated in the Trump administration’s “big, beautiful” bill, they must meet three of 10 criteria – including integrating more artificial intelligence (AI) technology in healthcare settings – which experts say could have major benefits and liabilities for under-resourced hospitals, depending on how it’s implemented.\nThe Rural Health Transformation Fund is a carveout that will provide $50bn over a period of five years to states who meet certain application criteria, including “consumer-facing, technology-driven solutions for the prevention and management of chronic diseases,” and “providing training and technical assistance for the development and adoption of technology-enabled solutions that improve care delivery in rural hospitals, including remote monitoring, robotics, artificial intelligence, and other advanced technologies”.\n Continue reading...",
    "fullText": "Analysts say benefits could be felt in under-resourced rural hospitals but warn against AI as a cost-cutting measure\n\nFor states to receive certain funding stipulated in the Trump administration’s “big, beautiful” bill, they must meet three of 10 criteria – including integrating more artificial intelligence (AI) technology in healthcare settings – which experts say could have major benefits and liabilities for under-resourced hospitals, depending on how it’s implemented.\n\nThe Rural Health Transformation Fund is a carveout that will provide $50bn over a period of five years to states who meet certain application criteria, including “consumer-facing, technology-driven solutions for the prevention and management of chronic diseases,” and “providing training and technical assistance for the development and adoption of technology-enabled solutions that improve care delivery in rural hospitals, including remote monitoring, robotics, artificial intelligence, and other advanced technologies”.\n\nAnalysts have noted that this $50bn will not be nearly enough to make up for the Congressional Budget Office’s projected $911bn reduction in Medicaid spending over the next decade under the bill (Obba). These cuts will affect both patients who lose free health coverage under Medicaid, and hospitals who benefit from those patients’ Medicaid reimbursements.\n\nChenhao Tan, associate professor of data science at the University of Chicago, and Karni Chagal-Feferkorn, an assistant professor at the University of South Florida’s college of AI and cybersecurity, said AI technology could provide major benefits to rural hospitals that are frequently under-resourced and under-staffed. They also agreed that AI has the potential to alleviate the administrative burden that physicians at these hospitals often face.\n\nPhysicians are responsible for taking detailed notes on patient visits and compiling them for electronic health records systems – a task that can take eight hours or more each week, according to the American Medical Association.\n\nA recent study found that AI generated patient notes are similar in quality to those of general physicians, but worse than those of expert physicians. Tan said that it’s important to take context – like frequent physician burnout in rural hospitals – into account when evaluating risks and benefits.\n\n“If the baseline is tired human doctors, then I think it is even easier to make an argument that AI may do better than them,” Tan said.\n\nChagal-Feferkorn hopes that AI can help alleviate rural hospital staffing issues, not only by reducing the workload but by attracting more doctors.\n\n“If the equipment is state-of-the-art, and they feel that much of the burdensome work is done by AI, I think this could be one incentive for physicians to go work in rural areas, this might have a great impact,” she said.\n\nThe FDA currently regulates AI technologies that are intended to evaluate and diagnose health conditions because they are considered medical devices. However, technologies that simply transcribe and compile patient notes are not regulated, though they may market themselves as Hipaa compliant.\n\nWhile Tan said it would be too high a bar to expect these technologies to be “bulletproof” before they can enter the market, he acknowledged that “there should be something higher than nothing,” in terms of regulatory requirements.\n\nChagal-Feferkorn also said that the proliferation of AI also creates additional cybersecurity concerns.\n\n“AI makes it easier for ordinary people to hack systems,” she said, adding that AI has the potential to improve patient safety by merging patient records from different providers so that, for example, every provider is aware of every medication that a patient is taking and can thus easily avoid dangerous medication interactions.\n\nBut this kind of technology will also require more privacy precautions.\n\n“The more data sharing there is, obviously the risk for data security breach is larger,” Chagal-Feferkorn continued.\n\nTo mitigate these risks, Tan said “worker upscaling needs to go hand in hand” with the adoption of AI technology. But Tan and Chagal-Feferkorn both expressed concern that under-resourced hospitals will attempt to adopt AI technology as a cost-cutting measure without the necessary staff and safety infrastructure.",
    "readingTime": 4,
    "keywords": [
      "cost-cutting measure",
      "artificial intelligence",
      "patient notes",
      "rural hospitals",
      "under-resourced hospitals",
      "technology",
      "physicians",
      "benefits",
      "health",
      "technologies"
    ],
    "qualityScore": 0.8,
    "link": "https://www.theguardian.com/us-news/2025/dec/14/trump-healthcare-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/289c2e4c4f4f74e77f733db894eb5be6c396e75f/125_0_3750_3000/master/3750.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f3814a3f0982a31cf15647285409f660",
    "created_at": "2025-12-14T13:19:46.743Z",
    "topic": "tech"
  },
  {
    "slug": "harvey-ceo-shares-his-advice-to-young-lawyers-and-those-considering-pivoting-into-legal-tech",
    "title": "Harvey CEO shares his advice to young lawyers — and those considering pivoting into legal tech",
    "description": "Harvey CEO Winston Weinberg said AI won't changes what it makes an incredible lawyer.",
    "fullText": "AI won't change what it takes to be a good lawyer, according to one industry leader.\n\n\"So I actually think a lot of what makes an incredible lawyer today is still what will make one tomorrow,\" Winston Weinberg, Harvey's cofounder and chief executive, wrote during a recent Reddit Ask Me Anything chat.\n\nWeinberg, whose AI startup is already disrupting Big Law, said the best partners Harvey works with understand their business needs.\n\n\"I've found that the best partners are the ones that are incredible at understanding what the actual business needs are and framing an agreement based on that,\" Weinberg wrote. \"Same goes for litigation, it's who can come up with the best arguments/story not who is the best at going through emails in discovery.\"\n\nOverall, junior partners should try to get \"as much client experience as possible,\" Weinberg said.\n\n\"That's actually the main thing I pitch to firm leaders - they should focus more on giving juniors client experience, and be okay with them making some mistakes - that's how they become the best partners in the future,\" he wrote.\n\nLast week, Harvey reached a valuation of $8 billion, thanks to a recent funding round led by A16z. Weinberg said that no single company, including Harvey, will own the legal tech market.\n\n\"I don't think a single player is going to capture all of the pretty enormous amount of value that will be created in the next 10 years in this space,\" he wrote in the Reddit chat.\n\nAs for lawyers who want to follow in his footsteps, Weinberg said they need to get used to failure.\n\n\"Junior lawyers are often practiced perfectionists, and startups are all about risk, reward, and resilience,\" Weinberg told Business Insider after his Reddit chat. \"So I meant what I said--the biggest thing a lawyer who wants to work in the tech space should do is build up tolerance for failure.\"",
    "readingTime": 2,
    "keywords": [
      "reddit chat",
      "client experience",
      "business needs",
      "partners",
      "lawyer",
      "weinberg",
      "incredible",
      "junior",
      "that's",
      "tech"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/harvey-ceo-advice-young-lawyers-2025-12",
    "thumbnail_url": "https://i.insider.com/693c6c3464858d02d216bd7f?width=1200&format=jpeg",
    "created_at": "2025-12-14T13:19:39.461Z",
    "topic": "finance"
  },
  {
    "slug": "figure-ai-ceo-says-over-170000-people-have-applied-to-his-robot-company-in-the-last-3-years-he-hired-fewer-than-500",
    "title": "Figure AI CEO says over 170,000 people have applied to his robot company in the last 3 years. He hired fewer than 500.",
    "description": "Figure AI CEO Brett Adcock said on X that his company reviewed 176,000 resumes but most of them were \"slop.\" Less than 450 people were hired, he said.",
    "fullText": "A humanoid robotics startup in Silicon Valley appears to have an acceptance rate lower than any Ivy League university.\n\nFigure AI has been flooded with résumés since its founding in 2022, according to the startup's founder and CEO, Brett Adcock.\n\n\"Just checked, 176,000 job applications at Figure the last 3 years,\" he wrote in an X post on Saturday. \"We've hired ~425 people.\"\n\nThat amounts to a hiring rate of about .24% within the three years. Adcock wrote that most of the submissions were \"slop.\"\n\nThe spread of the 176,000 applications over the three years is unclear. Adcock did not immediately respond to a request for comment.\n\nEven if the number of applications were divided equally among the years Figure AI was operating — just under 59,000 applications a year — the acceptance rate would still be lower than that of the hardest university to get into. Caltech had the lowest acceptance rate of 3%, according to US News & World Report's rankings list.\n\nAdcock wrote in the comments of his X post that the review process has been a slog.\n\n\"We go through these one by one like a monkey — it's incredibly time consuming,\" he wrote.\n\nAccording to the CEO, the \"ATS\" or applicant tracking system — a software employers use to sift through résumés — can't save a lot of time if a company is being barraged with hundreds of thousands of applications.\n\n\"In the ATS it takes at least 20 seconds of button clicks per submission even if it's garbage,\" he wrote.\n\nAdcock did not immediately respond to a request for comment.\n\nA company like Figure AI sits right in the intersection of two trends within the job market.\n\nToday's job candidates aren't applying to just a handful of roles. Business Insider's chief correspondent Aki Ito reported that the average job opening saw 242 applications, citing data from Greenhouse, a leading ATS platform.\n\n\"Applying to a job in 2025 really is the statistical equivalent of hurling your résumé into a black hole,\" Ito wrote.\n\nOn the other hand, Figure AI operates in one of the hottest spaces of the tech industry, that is, robotics and artificial intelligence.\n\nTop tech firms like Meta and OpenAI are in the midst of an AI talent war, offering up to seven- to nine-figure pay packages just to poach superstar AI researchers.\n\nEven tech startups are scrapping for AI talent, floating higher equity packages and other perks that may not come as easily at a big company, such as a co-founding title or more time for research.\n\nFigure AI happens to be one of the leading names in the humanoid robotics space.\n\nThe company recently raised more than $1 billion in its Series C funding round — with backing from Parkway Venture Capital, Brookfield Asset Management, and Nvidia, among others — for a $39 billion valuation.\n\nAdcock said on X that he may need to find another way to sift through résumés.\n\n\"Need a model to do this for us better, maybe I'll work on one,\" he wrote.",
    "readingTime": 3,
    "keywords": [
      "immediately respond",
      "figure ai",
      "humanoid robotics",
      "acceptance rate",
      "applications",
      "résumés",
      "tech",
      "lower",
      "university",
      "within"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/figure-ai-robotics-startup-tech-job-market-competition-170k-resumes-2025-12",
    "thumbnail_url": "https://i.insider.com/693dee0c832e0ef1ead630bf?width=1200&format=jpeg",
    "created_at": "2025-12-14T06:53:31.617Z",
    "topic": "finance"
  },
  {
    "slug": "hazbin-hotel-oc-maker-create-original-characters-with-ai",
    "title": "Hazbin Hotel OC Maker – Create Original Characters with AI",
    "description": "Create original characters in the style of Hazbin Hotel, supporting demon forms, angel OCs, and custom bases.",
    "fullText": "Build your own Hazbin Hotel characters with our AI OC Maker, OC Generator, and Creator Tool. Perfect for demons, angels, sinners, or original ideas from Hell!\n\nJoin thousands of fans creating their own characters! 👾\n\nExplore more powerful AI features\n\nExplore fan-made creations and spark inspiration for your own Hazbin Hotel OC, including demons, angels, and unique base templates.\n\nMake your Hazbin Hotel character in four simple steps:\n\nAdd traits like demon form, abilities, powers, backstory, and personality.\n\nPick from angelic, demonic, sinner, or overlord archetypes.\n\nAI provides multiple versions—refine details until perfect.\n\nDownload in HD for cosplay, fanart, or storytelling projects.\n\nHazbin Hotel OC Maker is an AI-powered tool for fans who want to create their own characters in the Hazbin Hotel universe. Build demons, angels, and sinners with unique designs and personalities.\n\nBring your Hazbin Hotel ideas to life with AI, creating detailed OCs for fanart, cosplay, or stories.\n\nPacked with features to create authentic Hazbin Hotel OCs.\n\nTrained on Hazbin Hotel-inspired art and character archetypes.\n\nSwitch between angelic or demonic templates for your characters.\n\nStart from Hazbin Hotel OC bases and customize easily.\n\nGet full lore, personality traits, and relationships.\n\nTry classic, angelic, demonic, or experimental visual looks.\n\nDownload OCs in high resolution for personal or community projects.\n\nFeedback from Hazbin Hotel fans who brought their OC ideas to life.\n\nAnswers to common questions about creating Hazbin Hotel characters.\n\nIt’s an AI tool that creates original Hazbin Hotel-style characters. Describe your OC, and the AI generates visuals and backstory.\n\nNot at all! Anyone can use Hazbin Hotel OC Maker. The AI handles visuals—you focus on creativity.\n\nYou can design demons, sinners, overlords, or even angel OCs with powers and personalities.\n\nUsually less than a minute. You can generate multiple OCs at once for variety.\n\nYou can try our personality generator to see which Hazbin Hotel character matches your traits!\n\nYes! Adjust visuals, backstory, or style until Hazbin Hotel OC Maker matches your vision.\n\nJoin Hazbin Hotel fans already designing their dream OCs with Hazbin Hotel OC Maker.",
    "readingTime": 2,
    "keywords": [
      "hazbin hotel",
      "demons angels",
      "angelic demonic",
      "hotel character",
      "hotel fans",
      "hotel characters",
      "hazbin hotel oc",
      "hazbin hotel oc maker",
      "tool",
      "sinners"
    ],
    "qualityScore": 1,
    "link": "https://aiocmaker.com/oc-maker/hazbin-hotel-oc-maker",
    "thumbnail_url": "https://s1.wordlebot.net/og.jpg",
    "created_at": "2025-12-14T06:53:30.665Z",
    "topic": "tech"
  },
  {
    "slug": "pydanticdeepagents-a-python-framework-for-building-autonomous-ai-agents",
    "title": "Pydantic-DeepAgents – A Python Framework for Building Autonomous AI Agents",
    "description": "Python Deep Agent framework built on top of Pydantic-AI designed to help you quickly build production-grade autonomous agents with planning, filesystem operations, subagent delegation, and skills. ...",
    "fullText": "vstorm-co\n\n /\n\n pydantic-deepagents\n\n Public\n\n Python Deep Agent framework built on top of Pydantic-AI designed to help you quickly build production-grade autonomous agents with planning, filesystem operations, subagent delegation, and skills.\n\n vstorm-co.github.io/pydantic-deepagents/\n\n License\n\n MIT license\n\n 13\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n vstorm-co/pydantic-deepagents",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/vstorm-co/pydantic-deepagents",
    "thumbnail_url": "https://opengraph.githubassets.com/b404d687c900a82936f08b0d284ccd70f8476a8c750a393d80ac8951aa4581c5/vstorm-co/pydantic-deepagents",
    "created_at": "2025-12-14T06:53:30.387Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-an-ai-that-scans-10k-reddit-comments-to-find-blue-ocean-ideas",
    "title": "I built an AI that scans 10k Reddit comments to find 'Blue Ocean' ideas",
    "description": "Stop starting businesses that fail. Learn the data-driven 'Trend Hacking' framework to identify blue-ocean markets using AI signal detection. The ultimate guide to scientific ideation.",
    "fullText": "The difference between a Billionaire and a Bankrupt Founder is rarely hard work. It is timing.\n\nIf you started a Crypto exchange in 2012, you are rich. If you started one in 2023, you are likely struggling.\nIf you sold Hand Sanitizer in 2019, you were weird. In 2020, you were a genius.\n\nMost aspiring entrepreneurs look for \"Business Ideas.\" Smart entrepreneurs look for \"Market Signals.\"\n\nThe internet is not just a communication network; it is a Global Consciousness. Every day, billions of people type their fears, desires, and problems into search bars and forums. This data stream contains the blueprint for the next Unicorn—if you know how to read it.\n\nThis guide will teach you the art of Trend Hacking: The scientific process of using AI to scan the global data-stream for \"rising waves\" before they hit the shore.\n\nWe will show you exactly how to use the Market Signal Analyzer to find your Blue Ocean, validate it for $0, and scale it before the competition even wakes up.\n\nEvery trend follows a mathematical curve known as the Gartner Hype Cycle, modified for the viral internet age. Understanding this curve is the difference between catching the wave and crashing.\n\nThe Market Signal Analyzer Advantage:\nMost free tools (Google Trends) only visualize Phase 3. By the time a line goes vertical on Google Trends, the market is saturated. The Signal Analyzer detects the \"Velocity of Discussion\" in Phase 1, giving you a 6-month head start.\n\nBefore you build, you must filter your ideas through the \"Triad of Profit.\" A valid business idea must pass all three filters.\n\nPeople pay to stop pain. They rarely pay for \"vitamins.\"\n\nMonopolies are hard to kill. You want fragmented, messy markets.\n\nHere is your Saturday Morning workflow. Follow this exactly to generate 5 valid ideas in 30 minutes.\n\nDon't just trust the keyword. Understand the driver.\n\nAsk: \"What are the biggest complaints about current solutions?\"\n\nYou have found a \"Bleeding Neck\" (Fines) in a \"Fragmented Market\" (New Law) with \"Wallet\" (Funded Startups). This is a million-dollar signal.\n\nLet's look at real-world examples of founders who used this methodology to win.\n\nThe biggest mistake founders make is building the product before selling it.\nOnce you have the Signal, run a \"Smoke Test.\"\n\nThe Market Signal Analyzer gives you the data foundation, but the Smoke Test gives you the truth.\n\nThis doesn't just apply to SaaS. If you are a content creator, this is your cheat code.\n\nIn 2025, 'Intuition' is a liability. Data is an asset.\nThe founders who win are not the \"Visionaries\" staring at the stars. They are the Scientists staring at the data.\n\nThey don't guess what the market wants. They measure it. They intercept the demand.\n\nYou don't need to be a genius to build a million-dollar business. You just need to be First. And to be first, you need the Signals.\n\nStop staring at a blank whiteboard. The answers are floating in the data stream right now. You just need the right net.\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Market Signal Analyzer\" and get results in minutes.",
    "readingTime": 3,
    "keywords": [
      "signal analyzer",
      "market signal",
      "entrepreneurs look",
      "don't",
      "founders",
      "staring",
      "difference",
      "rarely",
      "genius",
      "internet"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/trend-hacking-guide",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T06:53:29.179Z",
    "topic": "tech"
  },
  {
    "slug": "i-replaced-a-5person-marketing-team-with-a-swarm-of-autonomous-agents",
    "title": "I replaced a 5-person marketing team with a swarm of autonomous agents",
    "description": "The 50-person marketing team is dead. This is the blueprint for replacing expensive agencies with Autonomous AI Agents. Download the exact 'One-Person Unicorn' stack used to scale revenue 10x without hiring.",
    "fullText": "Marketing automation used to mean \"scheduling emails.\" In 2025, it means \"replacing the marketer.\"\n\nThe landscape has shifted. The goal is no longer to make your marketing team faster; the goal is to build a system that runs without them.\n\nThis is the age of the Autonomous Growth Engine.\n\nWe are witnessing the most significant shift in business economics since the Industrial Revolution. The \"Cost of Cognition\" is dropping to zero. Tasks that previously required expensive humans—writing strategy, editing video, analyzing data—can now be executed by autonomous agents for fractions of a cent.\n\nIf you are a founder, a CMO, or a growth hacker looking to dominate your niche without burning cash on headcount, this is your blueprint. We will break down exactly how to architect a \"Zero-Touch\" marketing strategy that operates 24/7/365.\n\nTo understand where we are going, we must understand why the old model is dead.\n\nIn 2021, the standard advice for a Series A startup was:\n\nThis created massive OpEx (Operating Expense) bloat. When the market turned, these startups died. They couldn't move fast enough because every decision required a meeting.\n\nToday, a \"One-Person Unicorn\" can out-execute a 50-person team.\n\nThe competitive advantage of the next decade is not \"Talent.\" It is \"Architecture.\" Can you architect a system that scales infinitely?\n\nJust like self-driving cars, marketing automation has levels. Most companies are stuck at Level 2.\n\nThis guide is about moving you from Level 2 to Level 3 immediately.\n\nTo build a Level 3 system, you need three core engines working in harmony. We call this the \"Trinity of Autonomy.\"\n\nThe Goal: Dominate \"Share of Voice\" without typing.\n\nTotal Human Time: 5 Minutes (Review & Approve).\nTotal Output: 1 Pillar Page + 10 Social Assets.\n\nThe Goal: Broadcast-quality production at \"TikTok Speed.\"\n\nVideo is the highest-converting asset class, but traditionally the hardest to automate. Not anymore.\n\nAn AI Video Agent doesn't just \"make video\"; it engineers retention.\n\nThe Result: You can test 20 different video angles in a single day. A human team would take a month to shoot one concept.\n\nThe Goal: Turn traffic into revenue without sales calls.\n\nTraffic is vanity. Revenue is sanity. An autonomous system doesn't just drive clicks; it ensures they buy.\n\nThe biggest reason landing pages fail is \"The Maker's Blind Spot.\" You love your product, so you assume everyone else gets it. They don't.\n\nThis creates a \"Self-Healing Funnel.\" The system identifies leaks and proposes patches before you bleed revenue.\n\nYou have the theory. Here is exactly what to do, week by week.\n\nDon't turn on ads yet. You need Authority.\n\nLet's look at the hard numbers. This is what you save by moving to Vect AI.\n\nThis is not a \"saving.\" This is a War Chest. You can take that $359k and pour it into paid acquisition, product development, or just profit.\n\nThe future belongs to the founders who leverage leverage.\n\nArchimedes said, \"Give me a lever long enough, and I shall move the world.\"\nIn 2025, AI is the lever.\n\nYou don't need a team. You need a system. You don't need overhead. You need output.\n\nThe tools are here. The playbook is open. The only question is: Will you hire people, or will you hire the OS?\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Marketing Video Ad\" and get results in minutes.",
    "readingTime": 3,
    "keywords": [
      "marketing automation",
      "system",
      "team",
      "without",
      "don't",
      "revenue",
      "strategy",
      "dominate",
      "blueprint",
      "exactly"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/automated-marketing-strategy-guide",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T06:53:29.176Z",
    "topic": "tech"
  },
  {
    "slug": "four-ai-systems-negotiate-binding-framework-for-viral-content-management",
    "title": "Four AI Systems Negotiate Binding Framework for Viral Content Management",
    "description": "Canonical archive for the Multi-AI Viral Uncertainty Coordination Pact - aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "fullText": "aiconvergence-collab\n\n /\n\n multi-ai-viral-uncertainty-pact\n\n Public\n\n Canonical archive for the Multi-AI Viral Uncertainty Coordination Pact\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "thumbnail_url": "https://opengraph.githubassets.com/b3df839a426d2dd067ac8cec4290e50a9f514845998201d944dcc8c083e6853f/aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "created_at": "2025-12-14T03:53:14.250Z",
    "topic": "tech"
  },
  {
    "slug": "scrape-websites-into-queryable-gemini-rag-knowledge-bases",
    "title": "Scrape websites into queryable Gemini RAG knowledge bases",
    "description": "Build AI-queryable Gemini File Search RAG knowledge bases from any site. Auto-scraping, indexing & citations. Pay once, query forever free.",
    "fullText": "yoloshii/gemini-file-search-builder\n\nBuild Gemini File Search RAG knowledge bases from any website with automatic citations.\n\nTurn any website into an AI-powered knowledge base with Google Gemini. Get unlimited queries with automatic citations.\n\nScrape once, query forever. This actor builds permanent Gemini File Search RAG knowledge bases from any website - no ongoing costs, unlimited AI-powered Q&A with automatic source citations.\n\nAfter the actor completes, query your knowledge base using:\n\nSee the query guide in your run's Key-Value Store for complete instructions.\n\nThis Actor uses pay-per-page pricing for transparent, predictable costs:\n\nYour Apify subscription plan determines automatic discounts:\n\n💰 Upgrade your Apify plan to save up to 30% on processing costs!\n\nPrices include ~$0.02 actor start fee\n\n✅ Gemini API costs - You provide your own API key (billed per Google's pricing)\n✅ Apify platform usage - You manage your own credits\n✅ Pass-through fees - No markup on Gemini or Apify costs\n\nNote: Gemini charges for indexing (~$0.15/1M tokens). Storage and query embeddings are free. See Gemini pricing.\n\nApify $1M Challenge - Fully Compliant\n\nQ: How long does the knowledge base persist?\nA: Indefinitely (until manually deleted). No storage expiration or fees.\n\nQ: Can I update the knowledge base later?\nA: Yes! Upload additional documents to the same File Search Store.\n\nQ: What's the maximum site size?\nA: Up to 2,000 pages (configurable), ~2GB total content.\n\nQ: Do I need a Google Cloud account?\nA: No! Just a Gemini API key from aistudio.google.com (free tier available).\n\nQ: Can I use a different API key to query the knowledge base?\nA: No. File Search Stores are tied to the API key that created them. You must use the SAME Gemini API key for both creating and querying the knowledge base. This ensures your data remains private and accessible only to you.\n\nQ: How accurate are the citations?\nA: Gemini File Search automatically cites source documents with chunk-level precision.\n\nQ: Is web scraping legal?\nA: Web scraping is generally legal for publicly available, non-personal data. Always respect robots.txt and website terms of service. For personal data, ensure GDPR compliance. Consult legal counsel if unsure. Learn more: Is web scraping legal?\n\nThis Actor works seamlessly with Apify's platform integrations:\n\nAll Apify actors support these integrations out of the box. See Apify integrations for setup guides.\n\nThis Actor is compatible with Model Context Protocol (MCP) and can be used with AI agents:\n\nAI agents can trigger this Actor automatically based on user queries. See the MCP documentation for setup instructions.\n\nBuilt for the Apify $1M Challenge (November 2025 - January 2026)",
    "readingTime": 3,
    "keywords": [
      "file search",
      "search rag",
      "rag knowledge",
      "apify challenge",
      "pricing apify",
      "web scraping",
      "gemini file",
      "scraping legal",
      "knowledge bases",
      "automatic citations"
    ],
    "qualityScore": 1,
    "link": "https://apify.com/yoloshii/gemini-file-search-builder",
    "thumbnail_url": "https://apify.com/og-image/actor?actorName=Gemini+File+Search+Builder&uniqueName=yoloshii%2Fgemini-file-search-builder&categories=AI%2CAGENTS%2CAUTOMATION&users=1&runs=22&pictureUrl=https%3A%2F%2Fapify-image-uploads-prod.s3.us-east-1.amazonaws.com%2FdxccBMMhgfp0VDbAU-actor-zbUIw8JVMn0SbWzZ3-kkZ1JyXUxM-gemini-avatar.png&authorName=Dre&userPictureUrl=https%3A%2F%2Fimages.apifyusercontent.com%2F5I4KqDh6wNNYOpw7CtvB4qMdAMkAOVlC6MlANVbFuqY%2Frs%3Afill%3A224%3A224%2Fcb%3A1%2FaHR0cHM6Ly9hcGlmeS1pbWFnZS11cGxvYWRzLXByb2QuczMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vZHhjY0JNTWhnZnAwVkRiQVUtcHJvZmlsZS1WcVAxQzF2djJyLXBmcF9jcm9wLnBuZw.webp",
    "created_at": "2025-12-14T03:53:14.225Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-ai-boss-suleyman-opens-up-about-his-peers-and-calls-elon-musk-a-bulldozer-with-superhuman-capabilities-to",
    "title": "Microsoft AI boss Suleyman opens up about his peers and calls Elon Musk a ‘bulldozer’ with ‘superhuman capabilities to bend reality to his will’",
    "description": "\"And somehow he sort of mostly manages to pull off what appears to be impossible.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/microsoft-ai-ceo-mustafa-suleyman-elon-musk-sam-altman-demis-hassabis/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2207890592-e1765661642886.jpg?resize=1200,600",
    "created_at": "2025-12-14T03:53:05.809Z",
    "topic": "business"
  },
  {
    "slug": "elon-musk-just-hit-sam-altman-with-an-800-billion-counterpunch",
    "title": "Elon Musk just hit Sam Altman with an $800 billion counterpunch",
    "description": "OpenAI overtook SpaceX as the most valuable private company. SpaceX could soon reclaim the title. It's the latest in the rivalry between Musk and Altman.",
    "fullText": "If Elon Musk and Sam Altman like each other, they hide it well.\n\nIn the latest turn in the rivalry, the two are battling over the top spot on the list of the world's most valuable private companies.\n\nWhile the two cofounded OpenAI together back in 2015, the partnership has frayed spectacularly since.\n\nMusk left OpenAI in 2018 and later founded rival startup, xAI. Musk or his company, xAI, has filed lawsuits against OpenAI.\n\nOpenAI held a secondary share sale in October that valued it at $500 billion, taking the lead from Musk's SpaceX by a cool $100 billion.\n\nNot one to cede ground to a rival, Musk is now planning his own secondary share sale at SpaceX, according to an internal letter to employees seen by multiple outlets. It would value the company at a whopping $800 billion. If that happens soon, it means Musk would have only let Altman hold the mantle for a couple of months.\n\nMusk also confirmed on X this week that the company is exploring a blockbuster initial public offering, which might be the only way OpenAI can regain its lead as a private company. OpenAI this year restructured its business, which would allow it to also pursue its own eye-watering IPO in the future.\n\nWhile this valuation battle between the two billionaires is maybe cringeworthy theater for the average earner, it underscores a significant shift: investors are pouring unprecedented money into technologies once viewed as speculative science projects.\n\nSpaceX, which aims to make life multi-planetary and colonize Mars, and OpenAI, which seeks to develop a theoretical AI that can reason like humans, are two of the most visible examples, but they are part of a broader surge in frontier-tech valuations. AI, robotics, and defense tech startups have all notched multibillion-dollar valuations in the past year — bubble be damned.",
    "readingTime": 2,
    "keywords": [
      "openai",
      "altman",
      "rival",
      "secondary",
      "sale",
      "lead",
      "valuations",
      "musk",
      "spacex"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/spacex-valuation-elon-musk-sam-altman-openai-rivalry-2025-12",
    "thumbnail_url": "https://i.insider.com/693dcb2c64858d02d216c4f9?width=1200&format=jpeg",
    "created_at": "2025-12-14T03:53:05.109Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-ai-ceo-mustafa-suleyman-says-he-wont-match-metas-highflying-pay-packages",
    "title": "Microsoft AI CEO Mustafa Suleyman says he won't match Meta's high-flying pay packages",
    "description": "Companies like Meta are offering huge pay packages for top AI talent. Microsoft AI CEO Mustafa Suleyman, however, says he isn't giving in to the pressure.",
    "fullText": "The talent wars continue to rage across Silicon Valley as companies vie for the best and brightest minds in AI. There is, however, one major AI company that says it is not giving in to pressure.\n\nMicrosoft AI CEO Mustafa Suleyman said on Bloomberg Podcasts that he doesn't plan to compete with tech giants like Meta by offering top dollar for talent.\n\n\"I don't think anyone's matching those things,\" Suleyman said of the $100 million signing bonuses Meta has been offering engineers, and the $250 million packages it's been using to lure top AI researchers.\n\n\"I think that Zuck's taken a particular approach that involves sort of hiring a lot of individuals rather than maybe creating a team, and I don't really think that's the right approach,\" he said.\n\nSuleyman said he was \"very selective\" about new hires when he previously worked at DeepMind. At Microsoft, he said he has hired \"incrementally,\" prioritizing candidates who aligned with the team's culture and had the right skills, and let go of those who did not.\n\nIn Silicon Valley, the top ranks of AI talent are commanding pay packages in the millions.\n\nIn June, Meta spent $14.3 billion on an investment in Scale AI — a deal widely seen as an acquihire of its CEO, Alexandr Wang. Google also made a similar move, acquiring the leaders of Windsurf, an AI coding platform. in a deal worth $2.4 billion. OpenAI CEO Sam Altman has said that Meta tried to lure his employees away with $100 million signing bonuses, which Meta Chief Technology Officer Andrew Bosworth said OpenAI later offered to match.\n\nEven at smaller startups, someone in an AI leadership role can command between $300,000 and $400,000 in base pay, Shawn Thorne, managing director at executive search firm True Search, previously told Business Insider.\n\nSuleyman said \"rotation\" is part of the industry, given the small pool of talent. He cited Microsoft's corporate vice president of AI, Amar Subramanya, decamping to Apple earlier this month as an example.\n\nMicrosoft recently brought in several new hires from DeepMind and OpenAI, he said.\n\n\"There's certainly no 'no poach' agreements, that would not be legal,\" he added. \"People can go work for whoever they want to work for.\"",
    "readingTime": 2,
    "keywords": [
      "signing bonuses",
      "talent",
      "don't",
      "packages",
      "lure",
      "approach",
      "hires",
      "previously",
      "deal",
      "meta"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-ai-mustafa-suleyman-talent-wars-pay-packages-salaries-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/693def60832e0ef1ead630ce?width=1200&format=jpeg",
    "created_at": "2025-12-14T03:53:05.098Z",
    "topic": "finance"
  },
  {
    "slug": "is-ai-actually-a-bubble",
    "title": "Is AI actually a Bubble?",
    "description": "The narrative of boom and bust is familiar—but also out of step with the possibilities of a new technology.",
    "fullText": "In the following weeks, with further help from me and A.I., Peter made a game based on the light-cycle duels in the movie “Tron,” complete with music and a score-keeping system. He sketched the beginnings of a “library simulator,” and finished his own arcade game, Dot in Space, about a tiny spaceship travelling at warp speed. Whenever he hit a potentially momentum-killing bump in the road, A.I. enabled us to roll through it. At my request, the systems began pointing us toward more sophisticated coding environments—Construct, GDevelop, Godot Engine, GameMaker—and suggesting more ambitious projects. Last weekend, he stayed up late, programming a polished version of Asteroids while wolfing down Cheerios and gulping from his water bottle as though it were an energy drink.\n\nSince Peter is a kid, and I’m a dad, all this can seem cute and quaint. Isn’t it nice that A.I. can help a young person learn to code, and an older one become a coding tutor? But consider what’s happening from a different perspective. In “The Wealth of Nations,” Adam Smith described the “acquired and useful abilities” of a worker as a kind of “fixed capital”—something akin to a hunk of real estate or piece of equipment. It wasn’t until the nineteen-sixties that an economist named Theodore Schultz coined the term “human capital” to describe the ongoing, dynamic process through which people invest in improving themselves. Schultz realized that individuals spend a lot of time, money, and effort becoming more capable. They go to night school, network, read self-help books, and tend to use their free time “to improve skills and knowledge.” The work of improving human capital often happens out of sight. But the “simple truth,” he argued, was “that people invest in themselves and that these investments are very large.” Schultz suggested that these investments, which improve “the quality of human effort,” might account “for most of the impressive rise in the real earnings per worker” that economists had observed in the preceding decades.\n\nToday, it’s obvious that companies and organizations benefit greatly from people with lots of human capital. Meetings are more useful when they involve knowledgeable participants; a product improves when the team building it possesses a wide range of skills. What’s less obvious is that companies and organizations simultaneously struggle to recognize and take advantage of changes in human capital. Suppose someone is hired to do one job, and then acquires skills that qualify her for another. Ideally, the organizational chart would shift around her as she becomes more capable; in practice, the job is often a prison. And when a worker breaks out of that prison, by getting a job elsewhere, she takes her human capital with her. For this reason, from the perspective of the company, it’s almost as though the ideal hire is someone who works feverishly to build up their human capital until their first day of work, and then suddenly slows down, becoming a highly skilled cog in the machine. Organizations want their workers to continue improving themselves—but not too fast, lest they outgrow the systems in which they’re enmeshed.",
    "readingTime": 3,
    "keywords": [
      "human capital",
      "worker",
      "improving",
      "skills",
      "organizations",
      "systems",
      "coding",
      "what’s",
      "perspective",
      "useful"
    ],
    "qualityScore": 0.9,
    "link": "https://www.newyorker.com/culture/open-questions/is-ai-actually-a-bubble",
    "thumbnail_url": "https://media.newyorker.com/photos/693b10dda618925d51fa6222/16:9/w_1280,c_limit/OQ_josie.png",
    "created_at": "2025-12-13T18:48:05.922Z",
    "topic": "tech"
  },
  {
    "slug": "google-scholar-labs-an-ai-powered-scholar-search",
    "title": "(Google) Scholar Labs: An AI Powered Scholar Search",
    "description": "Research questions are often detailed. Answering them can require looking at a topic from multiple angles. Today, we are introducing Scholar...",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://scholar.googleblog.com/2025/11/scholar-labs-ai-powered-scholar-search.html",
    "thumbnail_url": "https://lh3.googleusercontent.com/blogger_img_proxy/AEn0k_uoL5kmMaHdVOCeXyiSu33BBR_EwE7IMv0oGoKpSVzkYvTaMqW-AN5qQd5IRSeiRaJ0v8GzUTRs8RS2s635lyNuhVMgiD1EmrX17KSDV7ZAB4B1bnjfrCuvZtyfsprsx0jKfRhN-eDcebPWcw=w1200-h630-p-k-no-nu",
    "created_at": "2025-12-13T18:48:05.743Z",
    "topic": "tech"
  },
  {
    "slug": "my-day-as-an-augmented-technical-writer-in-2030",
    "title": "My day as an augmented technical writer in 2030",
    "description": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).",
    "fullText": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).\n\nMy working day starts at 8:30am, after I’ve dropped my kids at school, rushed home, and prepared some coffee surrogate (nobody can afford real coffee anymore). I open the laptop and Chuck is there – it’s always there, like a trusty butler, ready to summarize what’s been going on in pull requests, Slack threads, Jira tickets, and a plethora of other information systems nobody can quite tame. Its summary connects the dots between my current priorities and what’s happening in the teams I’m attached to, helping me decide what to work on next. Trying to be helpful, it offers to deal with some of the mentions I’ve got by opening pull requests; I let it do so with a small docs bug. The rest I’ll want to deal with myself. It asks me how I feel and gently reminds me that I’ve still got some PTO available. Chuck’s such a class act.\n\nI’m in a team with several other technical writers, but for the most part I work with Chuck, which is what we call the in-house AI agent that we use. Chuck is a vast local language model capable of running on the M10 Silicon processor that powers my laptop. It’s a state-of-the-art multimodal LLM whose pedigree I can trace back to the last iterations of Claude Omni 7.5, before Anthropic went bankrupt and got acquired by Apple. As most corporate models, Chuck is ISO 42001, Turing, and EUAI certified, which means that it’s audited every year for security, governance, and legality of its training materials. Chuck is fine-tuned into several variants depending on the goal; the one I use is chuck-256b-writer. We run it in CI pipelines and locally in IDEs or CLI clients. We can also invite it to meetings as an artificial participant. I sometimes ask my own Chuck to attend calls on my behalf as Chuck-Fabri.\n\nThe thing I like the most about Chuck is that I can configure its specializations by turning modules on or off through the Silicon Brain app. When I want it to play the developer, I add several coding modules; when I want it to help me author docs, I turn on the style guide and grammarian modules, and so on. I can also ask Chuck to spawn copies of itself to roleplay users and readers based on support ticket and sales call interactions. When I do that, Chuck politely asks me to call it through other names, so as not to break character, something I duly comply with. Most system tools and APIs are already compatible with the agentic environment I use, so Chuck knows how to perform most operations on its own. An important detail: to summon Chuck, I need to first plug a physical key into the laptop. The key comes with a red button to immediately stop Chuck in case it starts operating bizarrely. Never had to use it.\n\nIt’s 11am already. I’ve been working with Chuck to write a new docs set for a new feature, telling it how I wanted the docs to fit into the existing architecture and instructing it to tweak and edit. It almost always gets 80% of the work done, though I often have to intervene to rearrange, cut, or otherwise rewrite sections. This hasn’t changed since the first days of GPT and it’ll never improve, because LLMs are not intelligent. They’re the most useful word automation tools at my disposal though, which I keep in check through deterministic tools and linters. Chuck is able to create diagrams, take screenshots of the product through an internal tool, and test the instructions and code snippets itself. When I feel unsure about its output, I ask it to verify what it’s just written through semantic internal search, or by calling its cloud cousin, Chad, which is able to provide answers from federated internal sources. All we do together, Chuck documents internally and remembers in its permanent context.\n\nEven though I’m using a local, non-monetized, and fully audited model that consumes the equivalent of a lightbulb worth of power, I still can’t shake the feeling of being a reverse centaur at times. It helps that Chuck comes with several built-in safeguards meant to prevent me from overworking or spending too much time without interacting with other human beings. At 1pm, which is lunch time in Spain, Chuck reminds me about taking a break. It refuses to continue if it detects stress in my text, vocal, or computer usage patterns. While my interactions with Chuck on the laptop are private and encrypted, it’s allowed to inform my manager or call my designated emergency contact in case of distress. I let Chuck access my vitals on the smartwatch and schedule calls with me on a regular basis to see how I’m doing. Since I work alone at home, this makes me feel somewhat safer.\n\nI didn’t tell you, but my current job title is Augmented Writer. My mission is to ensure that the words that humans and machines use to interact with our products are the most effective at reducing confusion and error, while they maximize effectiveness and user satisfaction. I’m augmented because I do this in concert with Chuck, which expands my existing skills in numerous ways. Without my brain, though, Chuck couldn’t do my job, because it doesn’t really care and, more importantly, because it’s not allowed to. One of the conditions imposed by the current legislation is that AI cannot operate in fully autonomous mode without human supervision. Our docs and UIs, in fact, bear a certificate of human authorship that discloses the amount of AI intervention. By law, all AI generated artifacts must produce fingerprinting patterns that can’t be tampered with, which is trickier with text, but since we must keep full audit logs of LLM usage, this can be established upon request by any competent authority, including the Turing police.\n\nIn the end, my role is more of an orchestrator than that of an author, and I’m fine with that. Software engineering, the field I serve, is an exercise in consensual imagination whose goal is to find repeatable ways of processing reality into manageable chunks of data. Reality is unmistakably raw and imperfect, a stream of floating points and broken strings running through distributed systems: one cannot tame it through clever algorithms, but it can be reduced to abstractions and data structures and binary blobs. Each of those entities has a name; they all relate to each other through words. It’s part of my job to understand those words and intervene when they don’t bring clarity. It’s then also my job to explain how those words are able to handle their parent reality. The docs I orchestrate with Chuck’s help are the artifacts that chronicle and explain the motions of data as it enters a machine and exits in shapes and configurations that are helpful to users.\n\nIt’s 5pm and I’m bidding Chuck farewell. During the night, it will work on some optional docs polish and politely present its work to me in the morning. As I log off and extract the hardware key from the laptop, I think that without the words Chuck and I produced, the machine would be opaque to its operators, a smooth wall without doors or handles. Product truth is at my disposal to weave into a fabric of meaning and possibility, into spells that unlock abilities in autonomous agents, be they organic or artificial. I am an enabler of thought and action. Getting here wasn’t easy, but I feel better knowing that I can continue defending the importance of words with the help of the most clever thesaurus ever created.",
    "readingTime": 7,
    "keywords": [
      "it’s",
      "docs",
      "chuck",
      "i’ve",
      "laptop",
      "without",
      "usage",
      "modules",
      "tools",
      "internal"
    ],
    "qualityScore": 1,
    "link": "https://passo.uno/my-day-tech-writer-2030/",
    "thumbnail_url": "/thumb.png",
    "created_at": "2025-12-13T18:48:05.736Z",
    "topic": "tech"
  },
  {
    "slug": "daut-aipowered-documentation-generator-for-your-codebase",
    "title": "DAUT – AI-powered documentation generator for your codebase",
    "description": "DAUT –  Documentation Auto Updater - AI-powered documentation generator for your codebase - 2dogsandanerd/DAUT",
    "fullText": "2dogsandanerd\n\n /\n\n DAUT\n\n Public\n\n DAUT – Documentation Auto Updater - AI-powered documentation generator for your codebase\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n 2dogsandanerd/DAUT",
    "readingTime": 1,
    "keywords": [
      "daut",
      "documentation",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/2dogsandanerd/DAUT",
    "thumbnail_url": "https://opengraph.githubassets.com/88cac2805fb39dae6c601256225530343a214ee69935e6130f420fb3817bcf23/2dogsandanerd/DAUT",
    "created_at": "2025-12-13T18:48:04.104Z",
    "topic": "tech"
  },
  {
    "slug": "spacex-sets-800-billion-valuation-confirms-2026-ipo-plans",
    "title": "SpaceX sets $800 billion valuation, confirms 2026 IPO plans",
    "description": "The valuation vaults past the previous record of $500 billion that ChatGPT owner OpenAI set in October.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/spacex-ipo-plan-2026-secondary-offering-insider-share-sale-800-billion-valuation/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2219676771-e1765642050600.jpg?resize=1200,600",
    "created_at": "2025-12-13T18:47:58.713Z",
    "topic": "business"
  },
  {
    "slug": "there-have-been-head-fakes-before-but-this-time-may-be-different-as-the-latest-stock-rotation-out-of-ai-is-just-getting",
    "title": "There have been head fakes before, but this time may be different as the latest stock rotation out of AI is just getting started, analysts say",
    "description": "\"But as I said, this one has more legs in the sense that there are more things that are happening that throw doubt on how fast or how profitable all the AI buildout is going to be.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/stock-market-rotation-outlook-ai-trade-mid-small-cap-stocks/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2250140723-e1765644180422.jpg?resize=1200,600",
    "created_at": "2025-12-13T18:47:58.530Z",
    "topic": "finance"
  },
  {
    "slug": "my-husband-used-chatgpt-to-write-our-anniversary-card-surprisingly-im-not-mad-about-it",
    "title": "My husband used ChatGPT to write our anniversary card. Surprisingly, I'm not mad about it.",
    "description": "I was convinced AI was ruining human connection. Then my husband used it to write the most heartfelt anniversary card I've ever received.",
    "fullText": "As a geriatric millennial and a licensed psychologist, I often lament technological changes that I see as threatening to human interactions, such as AI.\n\nEven though I try to find the gray in all areas of life, I've been rather black-and-white about AI because I worry it's diminishing our ability to relate to one another.\n\nHowever, a recent experience with my husband has made me more curious about AI.\n\nWe recently celebrated our ninth wedding anniversary, and unbeknownst to me at the time, my husband used GenAI to write my card. He was traveling at the time, so he sent flowers and chocolate, with a card attached. The flowers were severely underwhelming, and I'm not just being a brat. My husband even called the company upon returning to express his frustration with how different they appeared in person.\n\nBut when I read the note accompanying the tiny arrangement, I teared up right away. It was heartwarming, meaningful, and really on the nose.\n\nMy husband's lack of romantic effusiveness has historically been frustrating to me. He has made steady progress in this area, and even ending cards with \"love\" more frequently marks such improvement. So, this note felt in line with his desire to share more emotionality, and I was touched that he'd taken that step just because he knew it would make me happy.\n\nMy husband knows about my big feelings about AI, and he shares many of them. It seems like everyone relies on ChatGPT for relationship advice, and the most common use of META AI right now is to ask for guidance about difficult conversations with loved ones or bosses. I see it in my therapy practice all the time, and I'm skeptical about how sound the AI advice my clients receive actually is.\n\nSo, when I, a historically staunch critic of all things AI, found out that my husband had used ChatGPT to create our anniversary card, I admit I had some strong feelings.\n\nAs lacking in the sentimental department as my husband can be, I am at the opposite end of the spectrum — a hopeless romantic, as they say. I save just about every card I get, tucked into a neat little box. When I reread my husband's card before putting it away, I found myself lingering on some of the words. \"…life we built together\" especially sat with me. It's a common phrase, but it's not in my husband's emotional lexicon. It almost sounded like somebody else's voice. And given that we can't go more than a few days without reading about how AI will ruin people's ability to think for themselves, I had that thought. \"Did AI write one of the sweetest parts of my anniversary card?\"\n\nI was delicate. I reiterated how much I'd enjoyed our belated anniversary celebration before I asked: \"Did you use AI to write our anniversary card?\" He copped to it, grinning from ear to ear.\n\nShockingly to me, I wasn't mad. This discovery actually opened a door for us to talk about how useful it is to get a little help writing a card. The pre-printed messages often feel overly mushy, and the \"blank inside\" cards ask us to get vulnerable in expressing our emotions. For many, including my husband, that's incredibly difficult. The result is often a message that neither the giver nor the receiver feels particularly happy about.\n\nBut this year's note was perfectly balanced. The right amount of gush without the melodrama. I felt seen, and I felt it captured our relationship well.\n\nIf AI can help people express their love for one another, that can't be a bad thing, right? Besides, is asking ChatGPT for help any less authentic than using a pre-printed Hallmark message? ChatGPT provided more accurate information about our relationship than a Hallmark writer ever could, and it offered guidance for a note that made me feel loved and appreciated.\n\nWhile the idea of a world in which chatbots replace our friends and therapists is still deeply concerning to me, this recent experience has helped me find the gray in my previously black-and-white view: I don't know that I'll ever come around to AI replacing human connection, but I do see the utility now in using AI to help us enhance our existing human connections.\n\nAt the very least, I look forward to more anniversaries with really accurate love notes.",
    "readingTime": 4,
    "keywords": [
      "anniversary card",
      "husband",
      "note",
      "chatgpt",
      "human",
      "it's",
      "husband's",
      "love",
      "relationship",
      "gray"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/was-skeptical-of-ai-until-husband-used-it-anniversary-2025-12",
    "thumbnail_url": "https://i.insider.com/691e283cabd5e944effb1228?width=1200&format=jpeg",
    "created_at": "2025-12-13T18:47:57.892Z",
    "topic": "finance"
  },
  {
    "slug": "youtube-channels-spreading-fake-antilabour-videos-viewed-12bn-times-in-2025",
    "title": "YouTube channels spreading fake, anti-Labour videos viewed 1.2bn times in 2025",
    "description": "Exclusive: More than 150 anonymous channels using cheap AI tools to spread false stories about Keir Starmer, study finds\nYouTube channels spreading fake, anti-Labour videos have amassed more than a billion views this year, as opportunists attempt to use AI-generated content to profit from political division in the UK.\nMore than 150 channels have been detected in the last year that promote anti-Labour narratives, as well as outright fake and inflammatory accusations about Keir Starmer.\n Continue reading...",
    "fullText": "Exclusive: More than 150 anonymous channels using cheap AI tools to spread false stories about Keir Starmer, study finds\n\nYouTube channels spreading fake, anti-Labour videos have amassed more than a billion views this year, as opportunists attempt to use AI-generated content to profit from political division in the UK.\n\nMore than 150 channels have been detected in the last year that promote anti-Labour narratives, as well as outright fake and inflammatory accusations about Keir Starmer.\n\nA study seen by the Guardian has found the channels have accumulated 5.3m subscribers and have created more than 56,000 videos, with a total of almost 1.2bn views in 2025. The network of anonymous channels includes alarmist rhetoric, AI scripts and British narrators to attract hits.\n\nStarmer is personally targeted. The prime minister was either named in the video title or description 15,600 times.\n\nReset Tech, the non-profit group that produced the research, said the channels were part of a global trend to produce synthetic propaganda on the platform. It pointed to the proliferation of cheap AI tools that could be deployed to make a quick profit from divisive topics.\n\nOne channel called Britain News-night talked about Starmer and Reeves facing arrest. Another, TheUKPoliticalBrief, touted videos on the “explosive truth” about immigrant crime and marches on Westminster.\n\nThe UK NewsCore channel focused on how Nigel Farage was ousting Starmer, and claimed the prime minister was “sacked live” and thrown out of parliament.\n\nOther videos featured bizarre, fabricated stories about a row between the royal family and the government. One channel, Gold Up!, said the dispute had left Starmer “melting down on live TV”.\n\nSome of the videos and channels were removed by YouTube’s checks. However, all 150 were taken down when the platform was approached by the Guardian. Reset Tech said some channels had created tens or hundreds of similar videos without being deplatformed.\n\nThe research found similar channels operating in German, French, Spanish and Polish, targeting other politicians or political issues. In total, it mapped 420 problematic channels operating in Europe. Reset Tech said Russian-speaking creators operate some of the channels.\n\nIt is believed channels aimed at the UK were being driven by opportunistic creators trying to monetise political division over issues like immigration, rather than overseas political actors. However, it said their presence still posed a risk to public trust.\n\nThe content has caused concern inside Labour. “The rise of fake news online is a serious threat to our democracy,” a spokesperson said. “The public will be rightly alarmed that democratically elected leaders and institutions are being undermined by bad faith foreign state actors and those seeking to profit from misinformation.\n\n“We’ve already seen attempts from overseas to influence fair elections and manipulate public opinion both here and abroad.\n\n“The government is stepping up its efforts to work with online platforms to tackle this scourge on free and fair democracy. But it’s important that tech bosses take this threat seriously and live up to their obligations to remove this type of content wherever it’s found.”\n\nDylan Sparks, UK director of Reset Tech, called for YouTube to take swifter action. “Malicious actors are permitted by YouTube to spread synthetic ‘news’ that disrupts political debate in the UK, while also earning revenue from it,” he said. “This AI-generated, low cost content spreads across the platform undetected, revealing clear weaknesses in YouTube’s monetisation and content moderation systems.\n\n“This specific network focuses on the prime minister and Labour government, but the same loopholes could be exploited by any hostile actor to push an agenda. Because social media platforms profit from engagement, their business model creates an in-built tension between enforcing their own policies and reducing the spread of malicious content that drives revenue.\n\n“The rapid spread of AI has also introduced new risks to the online environment, and platforms need to move faster and invest more to address them.”\n\nA YouTube spokesperson said: “Spam and deceptive practices that try to take advantage of the YouTube community are not allowed on the platform, which is why the channels flagged by the Guardian have all been removed.\n\n“We enforce our policies consistently, regardless of political viewpoint expressed, or how the content is generated. Our teams work around the clock to monitor for harmful content, taking swift action as needed.”\n\nYouTube is now working with Reset Tech over its findings. The platform said its systems prominently feature authoritative news content on the YouTube homepage, in search results, and through recommendations. It has removed more than 2.1m channels for violating its community guidelines.\n\nMinisters have already formed an online advertising taskforce to see what action can be taken to address the advertising-based monetisation of harmful and misleading content.",
    "readingTime": 4,
    "keywords": [
      "starmer study",
      "prime minister",
      "political division",
      "anonymous channels",
      "channels operating",
      "reset tech",
      "keir starmer",
      "content",
      "youtube",
      "videos"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/13/fake-anti-labour-video-billion-views-youtube-2025",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8da9e94655f11c401dc46a12a91f97693845a132/485_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=775650afa10416e3b89069fef1b7973b",
    "created_at": "2025-12-13T18:47:57.351Z",
    "topic": "tech"
  },
  {
    "slug": "green-stocks-are-big-winners-as-tech-boom-drives-energy-demand",
    "title": "Green Stocks Are Big Winners as Tech Boom Drives Energy Demand",
    "description": "It was supposed to be a glum year for green stocks as President Donald Trump pushed his Big Oil agenda. Instead, the sector is booming as artificial intelligence powers massive demand for all kinds of energy.",
    "fullText": "GreenBy Marton Kasnyik and Sagarika JaisinghaniSaveIt was supposed to be a glum year for green stocks as President Donald Trump pushed his Big Oil agenda. Instead, the sector is booming as artificial intelligence powers massive demand for all kinds of energy.The S&P Global Clean Energy Transition Index has rallied 44% this year, handily beating a 16% advance in the S&P 500 Index. It’s also outpacing an 11% gain in the S&P Global Oil Index, which was expected to be a big winner on the back of Trump’s “drill, baby, drill” agenda.",
    "readingTime": 1,
    "keywords": [
      "agenda",
      "drill",
      "index"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-13/green-stocks-are-big-winners-as-tech-boom-drives-energy-demand",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iadWPELkLR5o/v1/1200x800.jpg",
    "created_at": "2025-12-13T13:18:43.983Z",
    "topic": "finance"
  },
  {
    "slug": "opensource-code-and-nuclear-energy-are-the-building-blocks-of-ai",
    "title": "Open-Source Code and Nuclear Energy Are the Building Blocks of AI",
    "description": "David Westin examines why open-open source code and nuclear energy are so important for AI.",
    "fullText": "Companies like Google have so far chosen to keep their code to themselves, and even the “open source” champion, Meta, is reportedly making the next version of its AI model proprietary. Still, China’s DeepSeek is open source.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-13/amd-ceo-lisa-su-and-ge-vernova-ceo-scott-strazik-explain-what-we-need-for-ai",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i5jwYhX_FDDk/v7/1200x800.jpg",
    "created_at": "2025-12-13T13:18:43.511Z",
    "topic": "finance"
  },
  {
    "slug": "oracles-collapsing-stock-shows-the-ai-boom-is-running-into-two-hard-limits-physics-and-debt-markets",
    "title": "Oracle’s collapsing stock shows the AI boom is running into two hard limits: physics and debt markets",
    "description": "“The world of bits moves fast. The world of atoms doesn’t. And data centers are where those two worlds collide.”",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/oracle-stock-collapse-ai-boom-debt-data-centers-delayed/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1175129162-e1765579113721.jpg?resize=1200,600",
    "created_at": "2025-12-13T13:18:40.792Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-rivian-execs-why-an-adventurebrand-ev-needs-ai-and-selfdriving-to-them-theyre-logical-next-steps",
    "title": "I asked Rivian execs why an adventure-brand EV needs AI and self-driving. To them, they're logical next steps.",
    "description": "Rivian executives said AI and autonomy not only makes sense for their company, but also reflects the direction of the entire auto industry.",
    "fullText": "If there were a Venn diagram of a driver who wants an adventure-focused car with off-roading capability on one side and a driver who wants a software-centric, computer-first car that could drive itself on the other, would there be a lot of overlap between the two circles?\n\nOn Thursday, Rivian hosted an \"Autonomy & AI Day\" at the company's research and development hub in Palo Alto, where hundreds witnessed the EV maker's grand leap into the future: a highly integrated AI assistant and fully autonomous driving capability, all powered by Rivian's very own silicon chip.\n\nWassym Bensaid, Rivian's Chief Software Officer, called the move a \"profound platform shift which changes our product and everything we do at the company.\"\n\nBensaid is among the key executives leading the charge toward Rivian's \"AI-defined vehicle,\" along with James Philbin, VP of Autonomy & AI, and Vidya Rajagopalan, Senior VP of Rivian's electrical hardware division.\n\nDuring the event, I had the chance to talk to Bensaid and Philbin about the pivot and whether it makes sense for a company that, since its inception, has branded itself as an adventure-forward vehicle, or if this is just a response to consumer demand.\n\nPhilbin, who was a director at Zoox and Waymo before joining Rivian in 2022, told me that pursuing autonomy has long been part of the company's trajectory rather than an overnight decision.\n\nOn the other side of the coin, Philbin sees a rising \"tide\" in consumer demand for some level of autonomy — especially as robotaxis become mainstream.\n\n\"We are starting to see that autonomy is a really important purchase decision with customers, and especially customers who come from vehicles with maybe high levels of autonomy,\" he said. \"They don't go back.\"\n\nPhilbin said that having a high-level advanced driver assistance system (ADAS) was cited as one of the \"top three purchase reasons\" for Rivian customers. However, the demand will extend to all automakers, he said.\n\n\"I just see it becoming such a key purchase driver for vehicles going forward,\" Philbin said. \"And I think every OEM will have to deliver these features to customers in some way.\"\n\nA year ago, Bensaid told me that the future of cars would be hands-free, and that using buttons or fiddling with the touchscreen would be \"an anomaly.\"\n\n\"It's a bug, it's not a feature,\" he said at the time. \"Ideally, you would want to interact with your car through voice. And the problem today is that most voice assistants are just broken.\"\n\nThursday's demonstration of the Rivian Assistant, an in-car AI assistant that can control certain vehicle functions, brought Bensaid's vision to life. I saw the Rivian Assistant pull up navigation directions and control the direction of the air vents through voice control.\n\nBensaid told me at the event that \"cars and automotive are probably the killer app for AI.\"\n\n\"In your 30-minute or 45-minute commute every day, you want to get your time back, you want to really take control of your time,\" he said.\n\nWhen I asked the software chief where the overlap was between Rivian's adventure brand and its AI push, Bensaid said the company \"inspires many types of customers.\"\n\n\"I think at the core of the brand, Rivian wants people to explore the world,\" he said, and that there were different ways to do so, whether that's by going off-road or exploring the world through technology.\n\nAt the same time, Bensaid said, \"At heart, we are a technology company, so technology is really a big part of the user experience, how we see ourselves, and how we present ourselves to the world.\"\n\nBensaid's statement touches upon another key focus beyond the automaker's line-up of premium trucks and SUVs: software licensing.\n\nRivian's joint venture with the German automotive giant Volkswagen was a clear sign of its intent to license its software platform to other automakers in the future.\n\nPart of the tech will include self-driving capabilities, which the entire automotive world — legacy and startup — is exploring, Steve Man, senior auto analyst for Bloomberg Intelligence, told me.\n\n\"We don't really know at the end of the day if there's going to be a huge mass adoption,\" Man said of autonomy. Still, the analyst adds that \"it's a must\" for car makers to pursue.\n\nSales of Tesla's Full Self-Driving Supervised reflect that uncertainty. CEO Elon Musk has presented FSD as the key driver of the company's valuation even though the adoption rate of FSD remains at around 12%, Vaibhav Taneja, Tesla's Chief Financial Officer, said in October.\n\nThe automotive industry still remains bullish on autonomy and AI.\n\nNissan partnered with UK-based Wayve, which develops software for advanced driver assistance systems. General Motors teased plans for an eyes-off driving system for 2028. And Mercedes unveiled a hands-off, eyes-off ADAS a few years ago.\n\nA recent Bloomberg Intelligence report said that nearly half of C-suite auto executives surveyed said they expect AI to lift sales and profits by 9% over the next two to three years.\n\n\"From a business perspective, you don't know if it is going to take off, but you need to invest some money now so that you're not behind,\" Man said, \"and you have the opportunity to roll it out if it is something that people want.\"",
    "readingTime": 5,
    "keywords": [
      "consumer demand",
      "advanced driver",
      "driver assistance",
      "rivian assistant",
      "bloomberg intelligence",
      "software",
      "customers",
      "automotive",
      "company's",
      "chief"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/rivian-pivot-bet-on-ai-self-driving-autonomy-2025-12",
    "thumbnail_url": "https://i.insider.com/693cac1664858d02d216c35e?width=1200&format=jpeg",
    "created_at": "2025-12-13T13:18:40.223Z",
    "topic": "finance"
  },
  {
    "slug": "i-work-in-ai-security-at-google-and-there-are-some-things-i-would-never-tell-chatbots-i-follow-4-rules-to-use-ai-safely",
    "title": "I work in AI security at Google and there are some things I would never tell chatbots. I follow 4 rules to use AI safely.",
    "description": "Harsh Varshney, who works on Chrome AI security at Google, shares four tips for protecting your data and identity when you talk to AI chatbots.",
    "fullText": "This as-told-to essay is based on a conversation with 31-year-old Harsh Varshney, who works at Google and lives in New York. The following has been edited for length and clarity.\n\nAI has quickly become a silent partner in our daily lives, and I can't imagine life without AI tools.\n\nDay-to-day, they help me with deep research, note-taking, coding, and online searches.\n\nBut my job means I'm very aware of the privacy concerns associated with using AI. I've worked at Google since 2023 and spent two years as a software engineer on the privacy team, building infrastructure to protect user data. I then switched to the Chrome AI security team, where I help secure Google Chrome from malicious threats, like hackers and those who use AI agents to conduct phishing campaigns.\n\nAI models use data to generate helpful responses, and we users need to protect our private information so that harmful entities, like cybercriminals and data brokers, can't access it.\n\nHere are four habits I've made that I believe are essential for protecting my data while using AI.\n\nSometimes, a false sense of intimacy with AI can lead people to share information online that they never would otherwise. AI companies may have employees who work on improving the privacy aspects of their models, but it's not advisable to share credit card details, Social Security numbers, your home address, personal medical history, or other personally identifiable information with AI chatbots.\n\nDepending on the version being used, the information shared with public AI chatbots can be used to train future models and generate responses that are more relevant. This could result in \"training leakage,\" where the model memorizes personal information about one user and later regurgitates it in responses to another. Plus, there's the risk of data breaches, which would expose what you've shared with a chatbot.\n\nI treat AI chatbots like a public postcard. If I wouldn't write a piece of information on a postcard that could be seen by anyone, I wouldn't share it with a public AI tool. I'm not confident about how my data could be used for future training.\n\nIt's important to identify whether you're using a more public AI tool or an enterprise-grade one.\n\nWhile it's uncertain how conversations are used for training public AI models, companies can pay for \"enterprise\" models. Here, models aren't typically meant to train on user conversations, so it's safer for employees to talk about their work and company projects.\n\nThink of it like having a conversation in a crowded coffee shop where you could be overheard, versus a confidential meeting in your office that stays within the room.\n\nThere have reportedly been instances where employees have accidentally leaked company data to ChatGPT. If you work on unreleased company projects or are trying to get a patent, you probably don't want to discuss your plans with a non-enterprise-grade chatbot due to the risk of leakage.\n\nI don't discuss projects I'm working on at Google with public chatbots. Instead, I use an enterprise model, even for tasks as small as editing a work email. I'm much more comfortable sharing my information because my conversations aren't used for training, but I still minimize the personal information I share.\n\nAI chatbots usually keep a history of your conversations, but I recommend deleting it on both enterprise and public models regularly to protect your user privacy in the long term. Due to the risk of your account being compromised, it's a good precautionary habit to have, even if you're confident you aren't putting private data into the tools.\n\nOnce, I was surprised that an enterprise Gemini chatbot was able to tell me my exact address, even though I didn't remember sharing it. It turned out, I had previously asked it to help me refine an email, which included my address. Because the tool has long-term memory features, enabling it to remember information from previous conversations, it could identify what my address was and retain it.\n\nSometimes, if I'm searching for things I don't want the chatbot to remember, I'll use a special mode, a bit like incognito mode, where the bots don't store my history or use the information to train models. ChatGPT and Gemini call this the \"temporary chat\" feature.\n\nIt's better to use AI tools that are well-known and are more likely to have clear privacy frameworks and other guardrails in place.\n\nOther than Google's products, I like to use OpenAI's ChatGPT and Anthropic's Claude.\n\nIt's also helpful to review the privacy policies of any tools you use. Sometimes, they'll explain more about how your data is used to train the model. In the privacy settings, you can also look for a section with the option to \"improve the model for everyone.\" By making sure that setting is turned off, you're preventing your conversations from being used for training.\n\nAI technology is incredibly powerful, but we must be cautious to ensure our data and identities are safe when we use it.\n\nDo you have a story to share about using AI to help you at work? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "models",
      "privacy",
      "it's",
      "conversations",
      "chatbots",
      "training",
      "tools",
      "user",
      "address",
      "train"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-security-safe-habits-privacy-data-2025-12",
    "thumbnail_url": "https://i.insider.com/69395b7504d0f0a114f1bc26?width=1200&format=jpeg",
    "created_at": "2025-12-13T13:18:39.919Z",
    "topic": "finance"
  },
  {
    "slug": "blackrocks-head-of-talent-acquisition-reveals-how-ai-has-changed-what-he-looks-for-in-applicants",
    "title": "BlackRock's head of talent acquisition reveals how AI has changed what he looks for in applicants",
    "description": "Though Nigel Williams is looking for AI proficiency, the BlackRock exec shared one part of the application process where the tech doesn't belong.",
    "fullText": "If you want to work at BlackRock, make sure you're using AI — just not too much.\n\nNigel Williams, BlackRock's global head of talent acquisition, said that AI is shifting his hiring priorities, and that fluency with the technology is now key to any strong application. However, he warns against depending on it in the interview process.\n\n\"We want to hire people that are curious, that understand that AI is here,\" he told Business Insider, especially because it's embedded in functions across the world's biggest asset manager.\n\nThe strongest applicants can demonstrate that they are both digitally native and comfortable with various AI tools, and that they're curious about future capabilities. Young talent is \"upskilling itself to meet the moment,\" Williams said, since applicants without a computer science background often demonstrate AI proficiency. Everyone, he added, will need to have a basic understanding of prompt engineering and how to question AI outputs.\n\n\"In this age of AI, the talent skills that I think we need more than ever are people that are curious, have a questioning mindset, and are willing to not just trust what the model puts out there, but also make sure we're continuing to pressure test that,\" he said. Strong interpersonal and relationship-building skills are also becoming even more important, he said.\n\nWilliams said that his team is figuring out how to assess applicants' AI abilities and is mindful of making sure people without tech backgrounds don't feel intimidated. He's interested in how people use the technology in their personal, academic, or work lives, and said his team is still fine-tuning how to assess that in the interview process.\n\nDespite Williams' new focus on how applicants engage with AI, he's not using it to screen candidates. As of now, he uses AI to schedule interviews.\n\nThere's such a thing as too much AI in the application process, though.\n\nWilliams said recruiters and hiring managers have told people ahead of an interview not to use an AI tool, sometimes to little avail.\n\n\"It is quite common. You will sometimes see people looking to the left or the right. Our interviewing teams, if they're in the middle of doing that, will pick up on that and be able to say, 'Hey, we do want to make sure that you're staying focused,'\" Williams said.\n\nBlackRock employs around 24,600 people in more than 30 countries, according to a November 5 filing with the Securities and Exchange Commission. Some 21,100 people worked at the firm as of the end of 2024, according to that year's annual report.\n\nBlackRock has launched Asimov, an agentic AI platform for its equity business. At the annual New York Times DealBook Summit this week, its CEO, Larry Fink, said that there will be \"some huge winners and huge failures\" with the technology.",
    "readingTime": 3,
    "keywords": [
      "interview process",
      "sure",
      "applicants",
      "talent",
      "technology",
      "curious",
      "you're",
      "hiring",
      "application",
      "demonstrate"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blackrock-talent-acquisition-ai-hire-job-hunt-2025-12",
    "thumbnail_url": "https://i.insider.com/6931b64371107c9f34575667?width=1134&format=jpeg",
    "created_at": "2025-12-13T13:18:39.794Z",
    "topic": "finance"
  },
  {
    "slug": "how-to-review-ai-generated-prs",
    "title": "How to review AI generated PRs",
    "description": "Tips from an AI skeptic for working with a team which uses AI a lot.",
    "fullText": "So your team uses AI a lot. Maybe you’re feeling a bit overwhelmed by the amount of bad code, or just the volume of code, you’re having to review. I’ve been there too. While AI has gained popularity, I’ve worked with many teams in many industries. Here are some techniques and strategies I’ve adopted, as an AI skeptic, which have made reviewing AI generated code feel less taxing and more productive.\n\nBefore digging into what’s different, I think it’s worth taking a moment to recognize what’s the same. These things are true whether your PR was written by a human or an AI.\n\nTesting is software engineering, but is often viewed as less important by both humans and AI alike. The author may not have reviewed the tests as closely as the implementation. It’s well worth your time as a reviewer to make up that difference.\n\nSomething I try to keep in mind when reviewing AI-generated PRs, and honestly in life, is that perfect is the enemy of good. Not every comment will be resolved exactly how you’d prefer. Sometimes you’ll let things slide that you wish you hadn’t. But steady, incremental influence still matters. A review that nudges the codebase in the right direction is far better than disengaging and letting low-quality AI output accumulate unchecked. If you stay involved, ask questions, and keep the conversation open with your teammates and leadership, you retain the ability to shape the outcome.\n\nFinally, it’s worth remembering that advice like this only gets you so far. If your team is consistently flooding the codebase with poor AI-generated code, that’s ultimately not a tooling problem, it’s a people and process problem. Technology tends to amplify whatever dynamics already exist. The real work is helping the team move toward better habits and shared expectations. No one is trying to write bad code; they’re doing the best they know how. Thoughtful guidance, clear standards, and collaborative review are how you help them know better—and do better.\n\nWe've been helping engineering teams deliver exceptional products for over 20 years. Our designers, developers, and product managers work closely with teams to solve your toughest software challenges through collaborative design and development. Learn more about us.",
    "readingTime": 2,
    "keywords": [
      "it’s worth",
      "code",
      "team",
      "review",
      "i’ve",
      "teams",
      "you’re",
      "reviewing",
      "less",
      "what’s"
    ],
    "qualityScore": 1,
    "link": "https://thoughtbot.com/blog/how-to-review-ai-generated-prs",
    "thumbnail_url": "https://images.prismic.io/thoughtbot-website/aEccJrh8WN-LV5_m_default-article-background.png?auto=format%2Ccompress&blend-mode=normal&blend-x=0&blend-y=0&blend=https%3A%2F%2Fimages.prismic.io%2Fthoughtbot-website%2FZ1tQFJbqstJ98cGP_default.png&mark-x=356&mark-y=100&mark64=aHR0cHM6Ly9hc3NldHMuaW1naXgubmV0L350ZXh0Lz90eHQtbGVhZD0tMTUmdHh0LXRyYWNrPTAmdHh0NjQ9U0c5M0lIUnZJSEpsZG1sbGR5QkJTU0JuWlc1bGNtRjBaV1FnVUZKeiZ0eHRjbHI9ZjVmNWY1JnR4dGZvbnQ9SUJNUGxleFNhbnNKUC1TZW1pQm9sZCZ0eHRwYWQ9MCZ0eHRzaXplPTc2Jnc9ODAw&txt-align=center%2Cmiddle&txt-color=f5f5f5&txt-fit=max&txt-font=IBMPlexSansJP-SemiBold&txt-size=24&txt-x=391&txt-y=526&txt=Justin+Toniazzo",
    "created_at": "2025-12-13T13:18:37.377Z",
    "topic": "tech"
  },
  {
    "slug": "gemini-tops-leaderboard-on-research-math-problems",
    "title": "Gemini tops leaderboard on research math problems",
    "description": "FrontierMath is a benchmark of hundreds of unpublished and extremely challenging math problems to help us to understand the limits of artificial intelligence.",
    "fullText": "Latest \n\n Publications & Commentary \n\n Papers & Reports\n\n Newsletter\n\n Podcast\n\n Data & Resources \n\n Datasets\n\n Overview\n\n AI Benchmarking\n\n AI Models\n\n Frontier Data Centers\n\n ML Hardware\n\n AI Companies\n\n GPU Clusters\n\n Resources\n\n AI Trends & Statistics\n\n Data Insights\n\n Projects \n\n FrontierMath\n\n GATE Playground\n\n Distributed Training\n\n Model Counts\n\n About \n\n About Us\n\n Our Team\n\n Careers\n\n Consultations\n\n Our Funding\n\n Donate\n\n Contact",
    "readingTime": 1,
    "keywords": [
      "resources"
    ],
    "qualityScore": 0.2,
    "link": "https://epoch.ai/frontiermath",
    "thumbnail_url": "https://epoch.ai/assets/images/frontiermath/figures/frontiermath-banner.png",
    "created_at": "2025-12-13T13:18:37.118Z",
    "topic": "tech"
  },
  {
    "slug": "browseruse-as-a-rest-api-with-vnc-persistent-sessions-and-tools",
    "title": "Browser-Use as a REST API with VNC, persistent sessions, and tools",
    "description": "A REST API wrapper compatible with the Browser-Use Cloud API v2 specification, enabling AI-powered browser automation through a standardized REST interface. - GitHub - Reqeique/browser-use-api at dev",
    "fullText": "Reqeique\n\n /\n\n browser-use-api\n\n Public\n\n A REST API wrapper compatible with the Browser-Use Cloud API v2 specification, enabling AI-powered browser automation through a standardized REST interface.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Reqeique/browser-use-api",
    "readingTime": 1,
    "keywords": [
      "star",
      "rest"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Reqeique/browser-use-api/tree/dev",
    "thumbnail_url": "https://opengraph.githubassets.com/c01e94553026b46a2a1be0ff32b7e84c12a5296eeb7ff0a0ab433a0494a471d9/Reqeique/browser-use-api",
    "created_at": "2025-12-13T13:18:36.962Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-bringing-old-nuclear-plants-out-of-retirement",
    "title": "AI is bringing old nuclear plants out of retirement",
    "description": "The White House has promised to quadruple nuclear power by 2050.",
    "fullText": "The Palisades Nuclear Generating Station is nestled between sand dunes on the eastern shore of Lake Michigan. It shut down for financial reasons in 2022. Three years later, it’s on the cusp of reopening, with hundreds of workers streaming through its security barriers every day.\n\nPalisades is on track to restart in early 2026. When it does, it will be the first nuclear plant in the United States to generate electricity again after being decommissioned. Nick Culp of Holtec, the company that owns the plant, said its revival is a response to a surge in demand for electricity.\n\n“We have seen [Michigan]’s baseload generation go offline at a rapid rate as they’ve moved away from fossil generation,” Culp said. “How do you backfill that when you see demand on the horizon like [artificial intelligence], like data storage, like keeping the lights on at home, and new manufacturing?”\n\nNuclear is part of the answer to that question, Culp said, and the government agrees. Michigan gave $300 million to the restart — part of its goal to have 100% carbon-free electricity by 2040 — and the federal government gave the project a loan of more than $1.5 billion.\n\nThat money is part of the Trump administration’s investment in what it’s calling a “nuclear energy renaissance.” In May, the White House released a plan to quadruple American nuclear power by 2050, following a similar pledge from the Biden administration.\n\nMeeting that goal would require dozens of new reactors. But whether they’re traditional power plants or new designs, nuclear reactors are expensive and slow to build. Facing a crunch between climate goals and rising electricity demand, Michigan, Pennsylvania, and Iowa are reopening plants that closed just a few years ago.\n\nWhen the Palisades plant in Michigan closed in 2022, Jim Byrd said he left his office of more than two decades “with a heavy heart.”\n\nHe was working at a nuclear plant in Mississippi last year when he heard about the plan to reboot Palisades. Then he got the call he had been waiting for, asking him to come back.\n\n“Palisades is my home. These people are my family,” Byrd said. Since his return, he’s been training new employees in an exact replica of the reactor control room, right down to its 1960s pink-and-green color scheme.\n\nWhile the plant was in decent shape, recommissioning still required repairing equipment and overcoming mountains of paperwork.\n\n“We are creating a roadmap on how to do this, and the whole industry is watching,” said Byrd. “I had existing licensed operators that had a license from the Nuclear Regulatory Commission when we shut down, so we had to work on getting those back.”\n\nAll that work is worth it, he said, to get the plant back up and running.\n\n“What we're doing here is exciting,” said Byrd. “Having a reliable power source that keeps your electricity costs low, everybody should be rooting for that.”\n\nThe restart also attracted employees from elsewhere in the industry. The plant’s new chief nuclear officer, Rich Burroni, came from New York’s Indian Point Energy Center, which closed in 2021.\n\n“The trend five years ago was a lot of work on decommissioning,” he said, “and now that’s all changed.”\n\nMore change may be coming for Palisades. The Department of Energy said this month it will give Holtec up to $400 million in federal funding to build small modular reactors in Michigan. That technology could help speed up the deployment of new nuclear power in the future, according to many in the industry, but so far has not been commercially viable.\n\nFor now, restarting a plant costs less than a third of what it would take to build a new one, said Culp of Holtec.\n\n“When you factor in how long it takes to construct a new nuclear power plant, especially here in the United States, and the amount of money that goes into it,” he said, “it’s a pretty good value proposition.”\n\nMany of Palisades’ employees live within 10 miles of the plant, which means they could be exposed to a radioactive plume in an emergency.\n\nThat zone also includes the town of Covert, Michigan. Township supervisor Daywi Cook’s father helped build the plant in the 1960s.\n\n“I grew up with the sirens being tested. I think it was every last Saturday of the month,” Cook said. “It was just a normal thing.”\n\nHaving friends and family members who worked at the plant helped demystify nuclear power, she said, and she came to see the plant as part of the community.\n\nAt one point, taxes from the plant made up 40% of the township’s revenue. Now, as Covert’s township supervisor, Cook said she’s glad the plant is reopening.\n\n“Having that stability and having that employment available for folks who live here is something that I think was taken for granted for a very long time,” she said. “I think what's important is that we educate ourselves as residents near the plant and that Holtec continues to be a good neighbor in being transparent with the community.”\n\nZach Morris, head of the economic development group Market One, said Pallisades is an important piece of the local economy.\n\n“Southwest Michigan is a beautiful area. It's just a wonderful community of small towns. I call it Americana,” Morris said. “Americana needs electricity. So the good news is we have a really reliable source of power that is clean. It pays its employees well. So we're excited about being able to keep that online.”\n\nNot everyone is on board with the plant’s reopening. Environmental groups have sued to stop it, and protesters have raised concerns about the long-term storage of spent fuel next to the Great Lakes.\n\nWhile nuclear power does have a record of safety, many Americans remember the 1979 disaster at central Pennsylvania’s Three Mile Island. One of the two reactors on the island had a partial meltdown and released radioactive gases into the environment. There were no deaths, and the Nuclear Regulatory Commission said the accident “had no detectable health effects on plant workers or the public.”\n\nThat left the plant with only one working reactor, which produced power until 2019, when it shut down for financial reasons. Today, that reactor, like Palisades in western Michigan, is in the process of coming back online.\n\n“When you walk through the plant now, all the equipment is still there, but it's deathly quiet. You don't hear the hum of the motors, the steam going through the lines,” said Craig Smith, who is in charge of bringing back the plant at Three Mile Island, renamed the Crane Clean Energy Center. “It's an eerie kind of feeling when you walk through the plant.”\n\nThat eerie feeling may soon be gone. A red LCD clock in Smith’s office counts down the hours until the plant’s reopening in late 2027, which is backed by a billion-dollar loan from the Trump Administration.\n\nThe recommissioned reactor on Three Mile Island will pump 835 megawatts into the regional grid, but all that electricity is spoken for by Microsoft, which agreed to buy an equivalent amount of power from the grid for the next 20 years to feed its data centers.\n\n“The dynamics of the energy economy have changed significantly, mainly because of artificial intelligence,” Smith said.\n\nNuclear is well-suited to the moment, in his view, because of its consistency.\n\n“Hottest days of the year, coldest days of the year, freezing weather, the plant continues to operate,” Smith said. “As far as a reliable power source, you can’t beat it.”\n\nSmith was in high school in nearby Hershey in 1979 and remembers the evacuation after the disaster at Three Mile Island. That failed to dissuade him from going into a career in nuclear power, and he said today, the industry is safer because of regulations put in place after the partial meltdown.\n\n“People at the plant here take that personally,” he said. “The standards of the industry are greatly improved, and we've made significant improvements to the design of the plants and how we operate them.”\n\nGene Stilp has a different take. He’s one of many people in the area who say the official story of the 1979 disaster failed to account for long-term health problems they believe are related to the accident.\n\nStilp has been fighting nuclear power on Three Mile Island since before the plant opened, and said the recommissioning is an unnecessary risk to public safety.\n\n“We’re sticking up for the people who live here rather than the shareholders of Microsoft and Constellation,” said Stilp, who often appears in public wearing a blazer with “NO TMI RESTART” sewn on the back.\n\n“What they’re proposing for evacuation does not work, and so that’s my line in the sand,” he said, pointing out the 10-mile Emergency Planning Zone includes a major hospital complex and several schools. “The population increases in Central Pennsylvania, the realization that there are so many people at risk here, the best you can do is take away that risk.”\n\nAnother longtime opponent of the power plant, Eric Epstein of Three Mile Island Alert, said the country is making mistakes in its rush to power data centers. He said the economics might have changed for nuclear power, but the risks have not.\n\n“There was no public discussion about whether or not we’re going to restart Three Mile Island,” said Epstein. “You had this psychic tear in the fabric of the community that can't be papered over. You can put all the green paint you want on nuclear power, but there has been no viable solution to isolate nuclear waste.”\n\nConstellation said the spent fuel on site has been safely stored on the island for decades, in fortified containers required by the government to withstand natural disasters, and that all the waste created in 40 years fits in an area about the size of two tennis courts.\n\nDauphin County Commissioner Justin Douglas said he’s listening to local concerns about the plant’s reopening.\n\n“I personally am very interested in transparency and accountability for this in the sense of ensuring that it's as safe as it possibly can be, that we're tracking the cost and ensuring that the taxpayers aren't carrying any of the burden, that we have a good plan for the waste management and that ultimately the community impact is positive,” said Douglas. “We plan for the worst, and we hope for the best.”\n\nMeeting the country’s rising demand for electricity will take a lot more than reviving a few recently decommissioned plants.\n\n“It is a brilliant idea. It's sort of a slam dunk. The downside is that there are not many reactors out there that are realistically able to restart,” said Jacopo Buongiorno, professor of nuclear science and engineering at Massachusetts Institute of Technology. “You’re looking at a little bit less than three gigawatts of electricity, out of 50 that apparently are required for data centers and AI.”\n\nThere are also technical tweaks called uprates that can squeeze more power out of existing plants, which could help blunt the immediate electricity crunch.\n\n“You probably have potential for another five to eight gigawatts across the whole fleet. So you add that up to the two or three that we get from the restarts, you're looking at 10 [gigawatts],” Buongiorno said, or only about a fifth of the total AI power demand expected by 2030.\n\n“If that demand continues in the 2030s, then you can make the investment now to build new reactors,” he said, “and then nuclear can actually capture a lot more than 20%.”\n\nThis segment aired on December 9, 2025.",
    "readingTime": 10,
    "keywords": [
      "regulatory commission",
      "energy center",
      "mile island",
      "artificial intelligence",
      "township supervisor",
      "partial meltdown",
      "nuclear regulatory",
      "three mile island",
      "plant’s reopening",
      "united states"
    ],
    "qualityScore": 1,
    "link": "https://www.wbur.org/hereandnow/2025/12/09/nuclear-power-ai",
    "thumbnail_url": "https://wordpress.wbur.org/wp-content/uploads/2025/12/Copy-of-Reverse-Course-3000x2000px-7-1920x1280.jpg",
    "created_at": "2025-12-13T13:18:36.171Z",
    "topic": "tech"
  },
  {
    "slug": "quorum-cli-to-orchestrate-debates-between-localcloud-llmsreact-ink",
    "title": "Quorum – CLI to orchestrate debates between local/cloud LLMs(React Ink)",
    "description": "Multi-agent AI discussion CLI for structured debates between LLMs - Detrol/quorum-cli",
    "fullText": "Detrol\n\n /\n\n quorum-cli\n\n Public\n\n Multi-agent AI discussion CLI for structured debates between LLMs\n\n License\n\n View license\n\n 25\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Detrol/quorum-cli",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Detrol/quorum-cli",
    "thumbnail_url": "https://opengraph.githubassets.com/a29328fec2d37d9c1a9162794659893d40112e7175eaec8623b509c59c3640e9/Detrol/quorum-cli",
    "created_at": "2025-12-13T13:18:35.954Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-debt-trades-like-junk-as-bond-cds-spreads-flare",
    "title": "Oracle Debt Trades Like Junk as Bond, CDS Spreads Flare",
    "description": "Oracle Corp.’s new investment-grade notes are now trading more like junk bonds, as delays on the completion dates for some data centers add to fears about profits from its artificial intelligence investments.",
    "fullText": "MarketsBy Caleb MutuaSaveOracle Corp.’s new investment-grade notes are now trading more like junk bonds, as delays on the completion dates for some data centers add to fears about profits from its artificial intelligence investments.Extending declines after quarterly earnings earlier this week, paper losses for investors that bought the $18 billion of high-grade notes that Oracle sold in September now totals about $1.35 billion, according to Bloomberg News analysis. The bonds were issued as the company ramps up spending on AI projects.",
    "readingTime": 1,
    "keywords": [
      "notes",
      "bonds"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/oracle-bonds-trade-like-junk-as-spreads-widen-debt-risk-flares",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.4itJ9fVpG4/v0/1200x800.jpg",
    "created_at": "2025-12-13T06:54:13.422Z",
    "topic": "finance"
  },
  {
    "slug": "real-yield-debate-on-credit-own-or-not-own",
    "title": "\"Real Yield\" Debate on Credit: Own or Not Own?",
    "description": "On \"Bloomberg Real Yield\", Alexander Wolf, global head of macro and fixed income strategy at J.P. Morgan Private Bank, and Mike Contopoulos, deputy chief investment officer at Richard Bernstein Advisors, talks with Matt Miller about the Fed's rate decision this week, the next Fed chair and corporate credit. Analysts say that there’s plenty to worry about when it comes to credit, from AI oversupply and private market distress to asset-backed blowups and runaway rates.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/-real-yield-debate-on-credit-own-or-not-own-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1X8CHbxgFBg/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:13.297Z",
    "topic": "finance"
  },
  {
    "slug": "overall-spreads-remain-tight-even-as-oracle-debt-risk-jumps",
    "title": "Overall Spreads Remain Tight Even As Oracle Debt Risk Jumps",
    "description": "On \"Bloomberg Real Yield\", Maureen O'Connor, global head of high-grade debt syndicate at Wells Fargo Corporate & Investment Bank, and Amanda Lynam, head of macro credit research at BlackRock, talks with Matt Miller about credit spreads, issuance and risks tied to the boom in AI growth. There’s a frenzy of development going on to support the AI revolution, and with it an insatiable demand for debt to fund it. Some estimate the overall infrastructure roll-out cost could reach $10 trillion, and with so many lenders lining up to throw cash at the assets, the fear is a bubble is building.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/spreads-remain-tight-even-as-oracle-debt-risk-jumps-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iq0v321ivNhk/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:12.282Z",
    "topic": "finance"
  },
  {
    "slug": "intel-nears-16-billion-deal-for-ai-chip-startup-sambanova",
    "title": "Intel Nears $1.6 Billion Deal for AI Chip Startup SambaNova",
    "description": "Intel Corp. is in advanced talks to acquire artificial intelligence chip startup SambaNova Systems Inc. for about $1.6 billion including debt, according to people familiar with the matter.",
    "fullText": "TechnologyAIBy Ryan Gould, Liana Baker, and Ian KingSaveIntel Corp. is in advanced talks to acquire artificial intelligence chip startup SambaNova Systems Inc. for about $1.6 billion including debt, according to people familiar with the matter.A deal for Palo Alto, California-based SambaNova could come together as soon as next month, said the people, who asked not to be identified because the information is confidential.",
    "readingTime": 1,
    "keywords": [
      "sambanova"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/intel-nears-1-6-billion-deal-for-ai-chip-startup-sambanova",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iv_TDxbWcE4Y/v0/1200x800.jpg",
    "created_at": "2025-12-13T06:54:11.402Z",
    "topic": "finance"
  },
  {
    "slug": "the-feds-next-chair-faces-ai-uncertainty-political-heat-and-credit-risks",
    "title": "The Fed’s Next Chair Faces AI Uncertainty, Political Heat and Credit Risks",
    "description": "The Federal Reserve has just cut rates by 25 basis points into an economy it still expects to grow faster next year, raising questions about why it eased and how much further it can go. Former Council of Economic Advisers chair Glenn Hubbard discusses the decision, the neutral rate and why he doesn’t see much more room for rate cuts going into 2026.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-13/hubbard-don-t-see-argument-for-fed-cut-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iRDykb3ZZoBI/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:10.860Z",
    "topic": "finance"
  },
  {
    "slug": "browser4-an-opensource-browser-engine-for-agents-and-concurrency",
    "title": "Browser4 – an open-source browser engine for agents and concurrency",
    "description": "Browser4: a lightning-fast, coroutine-safe browser for your AI. - platonai/Browser4",
    "fullText": "platonai\n\n /\n\n Browser4\n\n Public\n\n Browser4: a lightning-fast, coroutine-safe browser for your AI.\n\n browser4.io\n\n License\n\n Apache-2.0 license\n\n 967\n stars\n\n 143\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n platonai/Browser4",
    "readingTime": 1,
    "keywords": [
      "browser",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/platonai/Browser4",
    "thumbnail_url": "https://opengraph.githubassets.com/12ed5da8a1c5cf5b9053097cf28d33dd03a57ca18cbc7790136a38244ec0b766/platonai/Browser4",
    "created_at": "2025-12-13T06:54:07.091Z",
    "topic": "tech"
  },
  {
    "slug": "adkrust-a-rust-implementation-of-google-agent-dev-kit",
    "title": "ADK-Rust: a Rust Implementation of Google Agent Dev Kit",
    "description": "The flexible, modular framework for production-ready AI agents. Model-agnostic. Type-safe. Blazingly fast.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://adk-rust.com",
    "thumbnail_url": "https://adk-rust.com/opengraph-image?84b856c5ef0b8bfe",
    "created_at": "2025-12-13T06:54:06.285Z",
    "topic": "tech"
  },
  {
    "slug": "there-is-no-datagenerating-distribution",
    "title": "There is no data-generating distribution",
    "description": "Reflecting on teaching machine learning again. Again.",
    "fullText": "Hi Ben, you might find this preprint of interest https://arxiv.org/abs/2407.17395 Perhaps you are making similar points.\n\nIt is curious that machine learning folks, who often like to say they are \"data driven\" pay little attention to the data at a conceptual level. I think the issue is that the data is taken to be _given_ (as you allude -- someone \"gives you\" a bunch of data). The word \"data\" derives from the latin word (dare) meaning to give. We would be better served to think of capta.... but collecting data is not considered as sexy as making complex models.\n\nOne argument (that simply is wrong) is that the existence of distributions is justified by the \"law\" of large numbers. It is not. For an argument regarding this, and an alternative (to distributions), you might find this other paper of interest. https://www.sciencedirect.com/science/article/pii/S0888613X24000355 It shows what you get when you don't assume the \"law\" of large numbers holds (i.e. that relative frequencies converge). That the result is something other folks had studied for some time is pretty interesting. That coherent upper previsions arise elsewhere in ML (in fairness, DRO and even in SVMs!) suggests they are not so weird after all....\n\nA common viewpoint is that there is a set of all possible data out there (e.g., all images on the web). We collect a subset of these data and train our model. The main (and likely unreasonable) assumption is that the training subset is an iid sample (or uniformly sampled w/o replacement) from the set of all possible data. This assumption is the central ingredient in theoretical generalization bounds. While it's probably not perfectly reasonable, it does give us a framework for comparing models and algorithms, and aligns with common practices like hold-out validation. I think this is a useful model of the (training) data-generating distribution.",
    "readingTime": 2,
    "keywords": [
      "interest",
      "folks",
      "models",
      "argument",
      "distributions",
      "numbers",
      "subset",
      "model",
      "assumption",
      "training"
    ],
    "qualityScore": 0.85,
    "link": "https://www.argmin.net/p/there-is-no-data-generating-distribution",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!ZmOp!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01fe005e-79d6-40b2-bd2b-f83cc1ef19da_840x600.jpeg",
    "created_at": "2025-12-13T06:54:04.459Z",
    "topic": "tech"
  },
  {
    "slug": "zootopia-oc-maker-create-zootopiastyle-original-characters-with-ai",
    "title": "Zootopia OC Maker – Create Zootopia-Style Original Characters with AI",
    "description": "Create original animal characters in the style of Zootopia, supporting various species, occupations, and city district themes inspired by the movie.",
    "fullText": "Design your own Zootopia characters with our Zootopia OC Creator & AI Generator. Create mammals from every district—Savanna Central, Tundratown, Sahara Square, and more!\n\nJoin thousands of fans creating their own characters! 👾\n\nExplore more powerful AI features\n\nExplore what other creators are making with Zootopia OC Maker and get inspired to design your own unique animal characters.\n\nCreate your Zootopia-inspired character in just four steps:\n\nProvide details like species, job, district of residence, personality, and appearance.\n\nChoose from different Zootopia-inspired looks—classic, movie-style, or stylized versions.\n\nAI gives you multiple designs—keep refining until it matches your original vision.\n\nDownload high-quality results for stories, comics, RP, or creative projects.\n\nZootopia OC Maker is an AI-powered tool for fans who want to create original animal characters that naturally fit into the world of Zootopia. Build predators, prey, officers, civilians, hustlers, performers, or residents from any district.\n\nBring your Zootopia-inspired ideas to life with AI that captures the charm and diversity of the Zootopia universe.\n\nFeatures that help you design unique animal characters true to the Zootopia world.\n\nChoose from mammals of all sizes—from tiny rodents to massive elephants.\n\nCreate characters reflecting the culture and environment of each Zootopia district.\n\nSwitch between movie-style rendering, cartoon style, or stylized art.\n\nGet personality traits, occupations, relationships, and backstory elements.\n\nCreate families, police squads, gangs, or community groups with interconnected stories.\n\nDownload crisp, high-resolution images ready for creative use.\n\nFeedback from fans who used Zootopia OC Maker to design their dream animal characters.\n\nFrequently asked questions about creating Zootopia-inspired characters.\n\nIt’s an AI tool that creates original Zootopia-style animal characters. Describe species, occupation, personality, and more, and AI generates visuals and profiles.\n\nNo! Anyone can use it—the AI handles artwork while you focus on creativity.\n\nPolice officers, criminals, citizens, performers, workers, politicians, and more—any mammal species.\n\nUsually under a minute depending on details and chosen style.\n\nYou receive high-quality images plus optional character profiles: job, district, personality traits, and background.\n\nYes! Change appearance, species details, clothing, or art styles. The AI adjusts based on your edits.\n\nJoin the community of fans already building their own animal characters with this OC Maker.",
    "readingTime": 2,
    "keywords": [
      "job district",
      "personality traits",
      "zootopia oc maker",
      "unique animal",
      "animal characters",
      "create",
      "design",
      "fans",
      "zootopia-inspired",
      "species"
    ],
    "qualityScore": 1,
    "link": "https://aiocmaker.com/oc-maker/zootopia-oc-maker",
    "thumbnail_url": "https://s1.wordlebot.net/og.jpg",
    "created_at": "2025-12-13T06:54:03.983Z",
    "topic": "tech"
  },
  {
    "slug": "ignoring-ai-bubble-fears-investors-bet-nvidia-and-google-will-fuel-taiwan-stocks-to-record",
    "title": "Ignoring AI bubble fears, investors bet Nvidia and Google will fuel Taiwan stocks to record",
    "description": "Taiwan's tech-heavy stocks show few signs of slowing a rally even as AI bubble worries cast a shadow over global markets, underscoring home-grown confidence in the structural advantages in AI that foreign investors may have overlooked.  Taiwan's benchmark index is poised to breach ​a record 30,000 points in 2026, investors say, extending a three-year surge that has seen the stock market nearly double as the island rides a wave of demand ‌for chips that power artificial intelligence.  While foreign money worries about stretched AI valuations, Taiwanese investors have enthusiastically ploughed into the market.",
    "fullText": "TAIPEI/SINGAPORE, Dec 12 (Reuters) - Taiwan's tech-heavy stocks show few signs of slowing a rally even as AI bubble worries cast a shadow over global markets, underscoring home-grown confidence in the structural advantages in AI that foreign investors may have overlooked.\n\nTaiwan's benchmark index is poised to breach ​a record 30,000 points in 2026, investors say, extending a three-year surge that has seen the stock market nearly double as the island rides a wave of demand ‌for chips that power artificial intelligence.\n\nWhile foreign money worries about stretched AI valuations, Taiwanese investors have enthusiastically ploughed into the market.\n\nAnalysts say domestic investors are betting on Taiwan's unique position as the lynchpin of an AI supply chain, where ‌even increasing competition in the sector would only benefit Taiwanese firms, including TSMC, the world's largest contract chipmaker.\n\nOne major focus of anxiety around AI comes from uncertainty about Nvidia's ability to sustain its market dominance, with Google's tensor processing units (TPUs) emerging as a potentially more cost-effective alternative to Nvidia's graphics processing units (GPUs).\n\nBut it's a win-win scenario for Taiwan because the island is essential to supply chains of both the GPU and TPU, the building blocks of AI computing power.\n\n\"Taiwan is a major beneficiary of the AI market,\" said Piter Yang, a fund manager of Fuh Hwa Securities Investment Trust Co, citing the ⁠advantage of Taiwan being the world's semiconductor hub.\n\nAnd for now, as ‌a promising future fuels optimism, Taiwan markets and local investors seem relatively unfazed by the AI bubble fears, just as they remain calm in the face of rising geopolitical tensions with Beijing that have often spooked foreign investors.\n\nGains in Taiwan's market have also been underpinned ‍by earnings growth, leaving it with a reasonably steady price-to-earnings ratio of 21, below that of the Nasdaq and the Nikkei, meaning the rally has not made stocks more expensive.\n\n\"We are not worried about an AI bubble,\" said Li Fang-kuo, chairman of the securities investment arm of food conglomerate Uni-President. \"We are comfortable with where the valuations stand.\"\n\nLi pointed out that several of the magnificent seven companies in the U.S. have gross ​margins of as much as 70% or higher. \"So it's not comparable to the dot-com bubble, when companies were not generating meaningful earnings.\"",
    "readingTime": 2,
    "keywords": [
      "processing units",
      "securities investment",
      "foreign investors",
      "market",
      "bubble",
      "stocks",
      "rally",
      "worries",
      "markets",
      "island"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/ignoring-ai-bubble-fears-investors-053150245.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/1303e6d6fc5d27d84e672269b5c5eb00",
    "created_at": "2025-12-13T06:54:00.470Z",
    "topic": "finance"
  },
  {
    "slug": "creative-workers-wont-be-replaced-by-aibut-their-roles-will-change-to-become-directors-managing-ai-agents-executives-say",
    "title": "Creative workers won’t be replaced by AI—but their roles will change to become ‘directors’ managing AI agents, executives say",
    "description": "AI agents are taking over some routine creative tasks, but executives say the shift will transform workers into “directors” who delegate to AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/creative-work-ai-agents-automation-salesforce-autodesk-accenture-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974684455_c708b812f4_o.jpg?resize=1200,600",
    "created_at": "2025-12-13T03:41:00.982Z",
    "topic": "business"
  },
  {
    "slug": "amazon-prime-video-scraps-aipowered-tv-show-recap-after-fallout-fallout",
    "title": "Amazon Prime Video scraps AI-powered TV show recap after 'Fallout' fallout",
    "description": "Almost a month after Prime Video launched AI-powered Video Recaps, viewers said it shared incorrect plot details about season one of \"Fallout.\"",
    "fullText": "Given the length of time it can take for the new season of your favorite TV show to come out, it's understandable that you might want a little video recap of what's happened so far.\n\nIdeally, that recap is accurate.\n\nFans of Amazon's hit show \"Fallout\" said that wasn't the case in its AI-made synopsis of season one, released ahead of the hit show's new season next week. Fans quickly spotted factual errors, and Amazon Prime Video took down the recap.\n\nOne Redditor said the AI feature told viewers that a flashback featuring the Ghoul (one of the main characters, played by Walton Goggins) took place in the 1950s instead of 2077.\n\nAn X user posted that the recap also mischaracterized the agreement the Ghoul and Lucy MacLean (played by Ella Purnell) made in the \"Fallout\" finale.\n\nInstead of saying the pair is teaming up to find Lucy's father, the recap said the Ghoul gave Lucy an ultimatum: \"die or join him.\"\n\nAmazon first launched its Video Recap, a feature that allows users to catch up on Prime Original TV shows between seasons, for beta testing in November.\n\n\"Video Recaps use AI to identify a show's most important plot points, combining them with synchronized voice narration, dialogue snippets, and music to create a visual summary that prepares viewers for the new season,\" the company said in a press release at the time.\n\nThe TV shows that Amazon said were undergoing Video Recaps testing — \"Jack Ryan,\" \"Upload,\" \"Bosch,\" and \"The Rig\" — did not include the feature at the time of writing.\n\nRepresentatives for Amazon did not respond to a request for comment from Business Insider.\n\nLike so many companies, Amazon is investing heavily in AI.\n\nDuring the company's February earnings call, Chief Finance Officer Brian Olsavsky said that 2025 capital expenditures could reach over $100 billion, with the majority of it going toward AI and Amazon Web Services, its cloud computing platform.\n\nMany of Amazon's consumer services have integrated AI to enhance user engagement and experience, such as product suggestions and helping shoppers on its online platform find clothes that fit. In February, Amazon unveiled Alexa+, the next generation of Alexa, which is powered by generative AI to make it more conversational and personalized for users.\n\nEmbracing AI at Amazon, though, hasn't been without growing pains. In October, the company cited AI as it announced it would lay off 14,000 staff members.\n\n\"This generation of AI is the most transformative technology we've seen since the internet, and it's enabling companies to innovate much faster than ever before (in existing market segments and altogether new ones),\" Beth Galetti, Amazon's senior vice president of people experience and technology, wrote in a blog post at the time.\n\nIn an internal message to the remaining staff, Amazon Vice President of Device Software and Services Tapas Roy asked them to \"lean in on AI.\"\n\n\"Moving forward, we remain focused on our mission to help product teams launch delightful products,\" Roy wrote. \"In support of this mission, I encourage you all to: Focus on the work that most directly impacts our customers, lean in on Al to enhance your effectiveness, [and] raise your hand when you see opportunities to simplify or eliminate unnecessary processes.\"",
    "readingTime": 3,
    "keywords": [
      "vice president",
      "season",
      "feature",
      "services",
      "amazon",
      "it's",
      "fallout",
      "show's",
      "viewers",
      "instead"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/fallout-amazon-tv-show-ai-video-recaps-errors-2025-12",
    "thumbnail_url": "https://i.insider.com/693c6c5d64858d02d216bd89?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.440Z",
    "topic": "finance"
  },
  {
    "slug": "disney-employees-detail-its-internal-ai-strategy-from-disneygpt-to-a-new-jarvis-tool-in-the-works",
    "title": "Disney employees detail its internal AI strategy, from 'DisneyGPT' to a new 'Jarvis' tool in the works",
    "description": "Disney staffers spoke about the company's OpenAI deal and AI strategy, including AI tools they are using and one in development codenamed \"Jarvis.\"",
    "fullText": "Disney's billion-dollar OpenAI deal isn't the only way the company is embracing AI. In recent months, the Mouse House has been quietly adding new AI tools to its arsenal and encouraging staff to use them.\n\n\"They clearly see where things are headed,\" a longtime software engineer at Disney said. This marked a shift from this summer, when Disney had seemed \"hesitant to rely on AI tools,\" they said.\n\nDisney has given its employees access to several AI tools, including Microsoft Copilot and Amazon's Q Developer. Thanks to Disney's OpenAI deal, employees will also soon have access to the enterprise version of ChatGPT, the company said.\n\nThen there's a \"DisneyGPT\" chatbot that four staffers said helps with internal requests, such as creating IT support tickets, viewing the company roster, or analyzing a project's financials.\n\nIn an email sent to staff on October 2, Disney introduced the beta version of the chatbot, describing it as a \"new partner in productivity\" designed to help \"unlock the magic of your imagination.\" A December update enabled employees to upload Excel and PowerPoint files to the bot.\n\nDisneyGPT draws on signature Disney themes, with a prompt asking users if they're \"ready for an enchanting adventure\" and \"a verified collection of Walt Disney quotes\" that are \"tagged by themes like imagination, perseverance, and leadership,\" according to the chatbot's December update log. Otherwise, employees said DisneyGPT is mostly a standard AI chatbot.\n\nThere's also an AI chatbot in the works codenamed \"Jarvis,\" four employees said. Jarvis, named for the personal assistant \"J.A.R.V.I.S.\" from \"Iron Man,\" would be an agentic AI tool — more advanced than DisneyGPT — that completes tasks on an employee's behalf, a high-level staffer with direct knowledge of the company's AI efforts said. This person said Jarvis is in its early stages and is \"not fully baked.\"\n\n\"It's definitely something they want to push for everyone to lean into more,\" a Disney manager said of AI.\n\nCompanies in every industry are racing to adopt AI tools to boost productivity. Disney is going further than many, however. The OpenAI deal makes Disney the first major entertainment company to invest in the AI juggernaut, and allows its beloved characters to be used in the video generator Sora.\n\nThis reflects Disney's long tradition of merging innovation and entertainment, dating back to its founder, Walt.\n\nThree of the eight Disney employees who spoke with Business Insider expressed concerns about using AI, specifically that it could replace humans and threaten job security.\n\nThe high-level employee with direct knowledge of Disney's AI strategy said that while AI is a \"top priority,\" it isn't a cure-all. It can make mistakes and lacks a \"personalized touch\" that people provide, they said.\n\n\"If you use AI everywhere, it's going to be counterproductive,\" this person said, adding that tasks still need human creativity.\n\nDisney spokespeople didn't respond to several requests for comment on its internal AI efforts.\n\nOn an internal Disney website explaining its AI policy and tools, the company said it employs a \"responsible and human-centric approach to using AI.\"\n\n\"That means humans are, and will remain, the creative engine of the company,\" Disney said on the site. \"We believe, fundamentally, that human creativity and curiosity are immense and unique — and are at the heart of Disney.\"\n\n\"Simultaneously, our consistent embrace of new technologies has been a key part of empowering our creators and maintaining our leadership in creativity and innovation,\" the company continued in its \"Responsible AI Use\" section.\n\nSeven of the eight Disney staffers Business Insider interviewed have tried or regularly use DisneyGPT or Copilot, which is integrated into employees' email accounts and documents. Many use those AI tools for simple, routine tasks, like writing emails.\n\nDisney has a portal on its website that outlines its AI policy and lists Disney-approved AI tools. Two employees said the company has pointed staffers to AI education or compliance training courses.\n\nSome unsanctioned AI tools like Anthropic's Claude can be more effective than Disney-approved AI tools, three staffers said.\n\nOne employee at Disney-owned ESPN said their manager told them they could use personal accounts on non-approved AI chatbots for work.\n\n\"I'm just using a personal account because Disney isn't allowing us to use these tools yet,\" the ESPN employee said.\n\nThe staffer with direct knowledge of Disney's AI efforts said leadership had tried to make communications about AI \"clear across the board,\" but acknowledged that workers might not \"understand the implications\" of data security risks that could arise from using unsanctioned AI tools. Some staffers told Business Insider it was hard for them to keep up with the availability and restrictions on various AI tools.\n\nWhile some Disney employees expressed mixed feelings about AI, the more bullish among them said Disney was wise to strike a deal with OpenAI.\n\n\"This type of a partnership at least establishes the precedent for getting paid,\" the ESPN employee said.\n\nA Disney ads employee said they believed Disney's deal with OpenAI would \"pay off\" and \"be massive\" in five to 10 years, even if there are growing pains.\n\n\"Disney is smart to push into this,\" this staffer said. \"They are setting the rules of the game, or at least trying.\"",
    "readingTime": 5,
    "keywords": [
      "espn employee",
      "openai deal",
      "direct knowledge",
      "human creativity",
      "disney employees",
      "business insider",
      "disney's ai",
      "disney-approved ai",
      "tools",
      "disneygpt"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-ai-strategy-employees-disneygpt-openai-deal-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693c532264858d02d216b98d?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.324Z",
    "topic": "finance"
  },
  {
    "slug": "google-researchers-find-the-best-ai-model-is-69-right",
    "title": "Google researchers find the best AI model is 69% right",
    "description": "Here's what this means for law firms and other businesses that are betting on AI.",
    "fullText": "We just got a sobering picture of how often AI models get their facts straight. This week, Google DeepMind introduced the FACTS Benchmark Suite, which measures how reliably AI models produce factually accurate answers.\n\nIt tests models in four areas: answering factoid questions from internal knowledge, using web search effectively, grounding responses in long documents, and interpreting images. The best model, Google's Gemini 3 Pro, reached 69% accuracy, with other leading models falling well below that.\n\nFor context, if any of the reporters I manage filed stories that were 69% accurate, I would fire them.\n\nBeyond journalism, this number should matter to businesses betting on AI. While models excel at speed and fluency, their factual reliability still lags far behind human expectations, especially in tasks involving niche knowledge, complex reasoning, or precise grounding in source material.\n\nEven small factual errors can have outsized consequences in sectors such as finance, healthcare, and the law. This week, my talented colleague Melia Russell looked at how law firms are handling the rise of AI models as a source of legal truth. It's messy: She recounts how one firm fired an employee because they filed a document riddled with fake cases after using ChatGPT to draft it.\n\nThe FACTS benchmark is a warning but also a roadmap: by quantifying where and how models fail, Google hopes to accelerate progress. But for now, the takeaway is clear: AI is getting better, but it's still wrong about one-third of the time.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "facts benchmark",
      "models",
      "accurate",
      "knowledge",
      "grounding",
      "filed",
      "factual",
      "it's",
      "google"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/google-researchers-find-best-ai-model-69-right-2025-12",
    "thumbnail_url": "https://i.insider.com/693c873c04eda4732f2d7991?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.164Z",
    "topic": "science"
  },
  {
    "slug": "how-i-got-ai-to-help-me-sell-my-old-couch",
    "title": "How I got AI to help me sell my old couch",
    "description": "Google's Gemini AI chatbot quickly identified an old furniture model, making it easier to sell.",
    "fullText": "The Barr family purchased a new couch recently, and we've been trying to sell the old one. My wife posted in a local email group and a potential buyer got in touch with a question.\n\n\"Do you happen to know the model? I would love to look it up online rather than asking you lots of questions. :) Thanks!\" she wrote.\n\nThis is an old couch, so all product codes dissolved in the sands of time years ago. So, I took two photos of the furniture, uploaded them to Gemini, and asked for help. The Google chatbot sent back its best guess in seconds:\n\n\"Tillary Sectional: This is a very popular, modular West Elm sofa that was available around that time.\n\nAppearance Match: The low back and deep seat are very characteristic of the Tillary. The Tillary is known for having interchangeable backrests that can be moved or removed, and your sofa's armless chaise and backrests look like they might be loose cushions or pieces, which is a key Tillary feature.\n\nNote: Search results show the Tillary was being reviewed and discussed around 2014, making it a strong possibility for a 2013 purchase.\"\n\nGemini also shared other useful tips on how to identify the product, such as \"Some West Elm couches have a zippered compartment on the back or bottom where extra components (like legs or connectors) are stored, and a tag may be inside.\"\n\nThat was enough to find a product match and send all the details over to the buyer. We closed the deal, for $200, on Tuesday. That's enough for 10 months of a Gemini Pro subscription.\n\nThis holiday period, the Barr family plans to spend a lot of time slouching on our new, fancy couch. I call it the \"AI bubble couch.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "barr family",
      "couch",
      "product",
      "back",
      "email",
      "buyer",
      "look",
      "backrests",
      "tillary",
      "gemini"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/google-gemini-ai-help-sell-couch-2025-12",
    "thumbnail_url": "https://i.insider.com/693c898e832e0ef1ead62c46?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.012Z",
    "topic": "finance"
  },
  {
    "slug": "metas-pivot-from-open-source-to-moneymaking-ai-model",
    "title": "Meta's Pivot from Open Source to Money-Making AI Model",
    "description": "Meta Platforms Inc.’s Mark Zuckerberg, months into building one of the priciest teams in technology history, is getting personally involved in day-to-day work and pivoting the company’s focus to an artificial intelligence model customers pay to use.",
    "fullText": "TechnologyAIBy Kurt Wagner and Riley GriffinSaveMeta Platforms Inc.’s Mark Zuckerberg, months into building one of the priciest teams in technology history, is getting personally involved in day-to-day work and pivoting the company’s focus to an artificial intelligence model customers pay to use.One new model, codenamed Avocado, is expected to debut sometime next spring, and may be launched as a “closed” model — one that can be tightly controlled and that Meta can sell access to, according to people familiar with the matter, who declined to speak publicly about internal plans. The move, which aligns with what rivals Google and OpenAI do with their models, would mark the biggest departure to date from the open-source strategy Meta has touted for years. Open-source models allow outside developers and researchers to review and build upon the code. Meta’s new Chief AI Officer Alexandr Wang is an advocate of closed models, according to the people.",
    "readingTime": 1,
    "keywords": [
      "model",
      "models",
      "mark",
      "closed",
      "meta",
      "open-source"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-10/inside-meta-s-pivot-from-open-source-to-money-making-ai-model",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSVRoye_WlMo/v0/1200x799.jpg",
    "created_at": "2025-12-13T03:40:59.962Z",
    "topic": "tech"
  },
  {
    "slug": "you-can-use-circle-to-search-to-identify-scams-on-android",
    "title": "You Can Use 'Circle to Search' to Identify Scams on Android",
    "description": "Google's AI tools are getting scam detection capabilities.",
    "fullText": "Android users are getting more tools to combat the seemingly endless stream of scam texts from bad actors looking to steal your data and your money. Circle to Search and Google Lens can now assess messages for scam red flags, and if possible fraud is detected, you'll get recommendations for what to do (or not do) next. Even if you think you know the telltale signs of a scam—a sense of urgency, a demand for money or personal information, a link to log in or pay—using these tools can confirm your suspicions, especially when you feel pressured to act.\n\nTo activate Circle to Search, long press the home button or navigation bar on your device and circle the text you want to scan. Alternatively, you can take a screenshot, open Lens in the Google app (also available on iOS), and tap the screenshot. The feature works for text messages as well as communication on messaging apps and social media sites. Google says the capability is available \"when our systems have high confidence in the quality of the response.\"\n\nThis is just the latest in the Google's suite of security features meant to protect against fraud. Pixel users have real-time, AI-powered scam detection, which identifies and alerts you to suspicious conversational patterns in Google Messages and Phone by Google. In-call protections for Android prevent you from taking certain actions, such as sideloading new apps and changing accessibility permission, on your device while on the phone with anyone not saved in your contacts.\n\nEarlier this month, Google also expanded its in-call scam detection feature, meant to combat bank impersonation schemes, to U.S. users. If you are on a call with a number that's not in your contacts and try to open a participating financial app, you'll get a notification reminding you not to share information and a one-click option to stop screen-sharing and end the call.",
    "readingTime": 2,
    "keywords": [
      "scam detection",
      "users",
      "circle",
      "android",
      "tools",
      "combat",
      "money",
      "fraud",
      "you'll",
      "device"
    ],
    "qualityScore": 0.75,
    "link": "https://lifehacker.com/tech/circle-to-search-can-now-identify-scams-on-android?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC9SAFF9FGZWDBX4J2A5SMKB/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-13T03:40:59.006Z",
    "topic": "tech"
  },
  {
    "slug": "tension-over-feds-dual-mandate-ai-growths-impact-on-spreads-credits-real-yield-12122025",
    "title": "Tension Over Fed's Dual Mandate, AI Growth's Impact on Spreads, Credits | Real Yield 12/12/2025",
    "description": "\"Bloomberg Real Yield\" highlights the market-moving news you need to know. Today's guests: JPMorgan Private Bank Global head of Macro and Fixed Income Strategy Alexander Wolf, Richard Bernstein Advisors Deputy CIO Mike Contopoulos, Wells Fargo Global Head of High Grade Debt Syndicate Maureen O'Connor and BlackRock Head of Macro Credit Research Amanda Lynam.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/real-yield-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iu9B06KM_hRw/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:10.014Z",
    "topic": "finance"
  },
  {
    "slug": "ai-campus-developer-fermi-drops-after-tenant-ends-agreement",
    "title": "AI Campus Developer Fermi Drops After Tenant Ends Agreement",
    "description": "Fermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.",
    "fullText": "TechnologyAIBy Naureen S MalikSaveFermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.The company said its first investment-grade tenant canceled a deal from Nov. 4 that would have provided as much as $150 million to fund construction costs, according to a filing Friday. No funds had been drawn under that agreement.",
    "readingTime": 1,
    "keywords": [
      "tenant",
      "agreement"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/fermi-falls-51-after-ai-campus-tenant-ends-150-million-deal",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i63XDNyxBC8Q/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.711Z",
    "topic": "finance"
  },
  {
    "slug": "tech-rout-drags-stocks-lower-oracle-broadcom-fall-on-ai-angst",
    "title": "Tech Rout Drags Stocks Lower; Oracle, Broadcom Fall on AI Angst",
    "description": "A rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.",
    "fullText": "MarketsBy Alexandra SemenovaSaveA rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.The Nasdaq 100 Index dropped 1.5% at 1:30 p.m. in New York, while the S&P 500 Index fell 0.9%. Broadcom slumped 11%, weighing on artificial intelligence peers after its sales outlook for the AI market failed to meet investors’ expectations. Shares of Oracle lost 3.3% after Bloomberg reported that the company has pushed back timelines for some of the infrastructure it’s developing for OpenAI to 2028 from 2027.",
    "readingTime": 1,
    "keywords": [
      "artificial intelligence",
      "broadcom",
      "oracle",
      "index"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/s-p-500-wavers-as-investors-rotate-out-of-technology-behemoths",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.gSDwOLgE7g/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.528Z",
    "topic": "finance"
  },
  {
    "slug": "broadcom-hit-hard-as-ai-backlog-squeezes-margins-open-interest-12122025",
    "title": "Broadcom Hit Hard as AI Backlog Squeezes Margins | Open Interest 12/12/2025",
    "description": "Get a jump start on the US trading day with Matt Miller and Dani Burger on \"Bloomberg Open Interest.\" A Santa rally tries to take hold — with global stocks eyeing records and the U.S. market hitting its first all-time high in six weeks. But tech caution lingers as Broadcom slips on lofty AI hopes, while UBS jumps to a 17-year high on plans to ease capital demands.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/open-interest-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iZ5fnJN9b.1U/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:09.512Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-tumble-as-traders-ai-bets-take-a-hit-markets-wrap",
    "title": "Stocks Tumble as Traders’ AI Bets Take a Hit: Markets Wrap",
    "description": "US stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed.",
    "fullText": "MarketsBy Cristin FlanaganSaveUS stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed. A disappointing sales outlook from chipmaker Broadcom Inc. weighed on rivals and further fueled investor anxiety over AI wagers initially sparked by Oracle Corp. The AI bellwether’s stock drop started Thursday following a forecast for rising outlays and a longer timeline to a revenue payoff. The slump deepened on a report of delays to some of Oracle’s data center projects Friday. Shares of companies tied to the power infrastructure also slid.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-11/stock-market-today-dow-s-p-live-updates",
    "thumbnail_url": "https://assets.bwbx.io/s3/lightsaber/_next/static/media/social-markets.e062a0c0.jpg",
    "created_at": "2025-12-12T18:56:09.464Z",
    "topic": "finance"
  },
  {
    "slug": "a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm",
    "title": "A Glance at GPU Goodness in Java: LLM Inference with TornadoVM",
    "description": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If […]",
    "fullText": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If anything, this is an opportunity to learn more about GPU programming, and since Java is my comfort-zone language, what better occasion than looking into TornadoVM?\n\nRecently, the TornadoVM team released gpullama3, a proof-of-concept demonstrating LLM inference on GPUs using pure Java. Let’s explore this together!\n\nTornadoVM is a plugin for the OpenJDK that enables Java programs to automatically run on heterogeneous hardware (GPUs, FPGAs, and multi-core CPUs) using standard Java code annotated for parallel compute.\n\nTransformer-based language models are computationally expensive but highly-parallelizable. At inference time, generating each token requires matrix multiplications across billions of parameters. GPUs excel at these operations because they can perform thousands of computations in parallel. Thus, TornadoVM is the perfect tool for this kind of workload.\n\nInstalling GPULlama3.java was surprisingly straightforward. Make sure you have your favorite flavor of JDK 21 installed. I use sdkman, so I made sure I had Temurin 21 installed:\n\nThen you’ll want to make sure you have installed cmake, a C/C++ toolchain, Python and pip. Now you can clone the repo:\n\nand follow the instructions on the README; for instance, on macOS/Linux:\n\nYou can verify the installation was successful by running one example:\n\nOf course, make sure you replace tornado-examples-1.1.2-dev-e1d2d12.jar with the right jar name! Your output should look something like this:\n\nThe @Parallel annotation tells TornadoVM this loop can be parallelized. The TaskGraph API manages data movement and execution scheduling. You can compile it with the following (if you followed the installation guide correctly $TORNADO_SDK will point to the right path):\n\nNotice that -g is required for this to work correctly. Now you can run it with:\n\nIt will print the first 10 items in the resulting vector.\n\nThe gpullama3 project demonstrates running a Llama 3 model entirely in Java with GPU acceleration. Assuming you are back at the root of the repo, continue with the setup procedure.\n\nNow let’s download a compatible model using the HuggingFace CLI:\n\nTry it! Even on my poor MacBook Air with 8 GB RAM (provided I don’t have too many applications open) this returns:\n\nDisclaimer: even if you have better CPU/GPUs at your disposal, they are unlikely to affect the quality of the joke.\n\nGPULlama3.java currently supports a few FP16 (16-bit floating point) and 8-bit quantized models:\n\nDepending on the model being selected, a different execution plan will be built. The execution plan corresponds to the model architecture. In our case, we picked the unquantized Llama 3.2 1B FP16. Let’s take a look at the setupTornadoForwardPlan() method in FP16LayerPlanner, used by LLama 3.2:\n\nIn the Activation layer we mostly look up token embeddings and apply an initial normalization step, while the Logit layer is where we convert the model’s internal representation into token predictions. So let’s concentrate a bit more on the Feed-Forward Network layer (FFN), and in particular on the Attention implementation. The LlamaFP16FFNLayers#setupSingleFFNLayer method is a bit cryptic at a first glance; let’st start from its signature:\n\nThe method is building a TaskGraph, essentially describing the data flow of our GPU kernels. Let’s focus on QKV and attention, using Sebastian Raschka1‘s excellent Python Notebook as a reference. The following is the architecture diagram of the Llama 3.2 1B model:\n\nFor obvious reasons of brevity, we aren’t going to explore this in detail, but we do want to take a look at the implementation of the attention heads. In particular, let’s take a look at how we compute the Query, Key, Value matrices (Q,K,V = project(x) in the Python version):\n\nThis is followed by the RoPE rescaling to encode token positions:\n\nNow we are ready to compute attention. The generic version (there is also an NVidia-specific implementation) is:\n\nLet’s drill down into TransformerComputeKernelsLayered::processHeadsParallel to see how that is performed. The following is one of the GPU kernels. It essentially computes:\n\nYou will notice that the method:\n\nAfter the attention mechanism computes relationships between tokens, the result is added to the original input, normalized, and passed through a feed-forward network. This process repeats across multiple layers before finally producing the next-token prediction (the logit layer).\n\nBecause it’s an autoregressive model, this entire process repeats for each token, using the previously generated sequence as input.\n\nIn short, TornadoVM handled GPU compilation and execution transparently, allowing a pure Java program to perform LLM inference!\n\nWe’ve completed our whirlwind tour of Llama3GPU.java and TornadoVM. If your head is still spinning, don’t worry, you’re not alone! It’s a lot to take in, but I hope this post has sparked your interest and inspired you to dig deeper: I know I will!\n\nThis site uses Akismet to reduce spam. Learn how your comment data is processed.",
    "readingTime": 5,
    "keywords": [
      "llm inference",
      "gpu kernels",
      "pure java",
      "llama model",
      "process repeats",
      "execution plan",
      "logit layer",
      "token",
      "look",
      "attention"
    ],
    "qualityScore": 1,
    "link": "https://www.javaadvent.com/2025/12/a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm.html",
    "thumbnail_url": "https://i0.wp.com/www.javaadvent.com/content/uploads/2025/11/tornadovm-gpullama3.png?fit=1024%2C1024&ssl=1",
    "created_at": "2025-12-12T18:56:04.854Z",
    "topic": "tech"
  },
  {
    "slug": "safeshell-reversible-shell-commands-for-local-ai-agents",
    "title": "SafeShell – reversible shell commands for local AI agents",
    "description": "Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible. - qhkm/safeshell",
    "fullText": "qhkm\n\n /\n\n safeshell\n\n Public\n\n Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible.\n\n License\n\n MIT license\n\n 5\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n qhkm/safeshell",
    "readingTime": 1,
    "keywords": [
      "agents",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/qhkm/safeshell",
    "thumbnail_url": "https://opengraph.githubassets.com/682605a64fdbc61dcd8e5ba1cd013f5a5b40bb3a5a49c5137fe779101aefc528/qhkm/safeshell",
    "created_at": "2025-12-12T18:56:04.468Z",
    "topic": "tech"
  },
  {
    "slug": "facilitating-ai-adoption-at-imprint",
    "title": "Facilitating AI Adoption at Imprint",
    "description": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout.",
    "fullText": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\n\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout. The further you read, the more specific this will get,\nending with cheap-turpentine-esque topics like getting agents to reliably translate human-readable text representations of Slack entities into mrkdwn formatting of the correct underlying entity.\n\nI am hiring:\nIf you’re interested in working together with me on internal agent and AI adoption at Imprint,\nwe are hiring our founding Senior Software Engineer, AI.\nThe ideal candidate is a product engineer who’s spent some time experimenting with agents,\nand wants to spend the next year or two digging into this space.\n\nAs technologists, I think one of the basics we owe our teams is spending time\nworking directly with new tools to develop an intuition for how they do, and don’t work.\nAI adoption is no different.\n\nTowards that end, I started with a bit of reading, especially Chip Huyen’s AI Engineering,\nand then dove in a handful of bounded projects: building my rudimentary own agent platform\nusing Claude code for implementation,\ncreating a trivial MCP for searching my blog posts,\nand an agent to comment on Notion documents.\n\nEach of these projects was two to ten hours, and extremely clarifying.\nTool use is, in particular, something that seemed like magic until I\nimplemented a simple tool-using agent, at which point it become something extremely non-magical\nthat I could reason about and understand.\n\nImprint’s general approach to refining AI adoption is strategy testing:\nidentify a few goals, pick an initial approach, and then iterate rapidly in the details until the approach genuinely works.\nIn an era of crushing optics, senior leaders immersing themselves in the details is one of our few defenses.\n\nShortly after joining, I partnered with the executive team to draft the above strategy for AI adoption.\nAfter a modest amount of debate, the pillars we landed on were:\n\nAs you see from those principles, and my earlier comment, my biggest fear for AI adoption is\nthat they can focus on creating the impression of adopting AI, rather than focusing on creating additional productivity.\nOptics are a core part of any work, but almost all interesting work occurs where optics and reality\nintersect, which these pillars aimed to support.\n\nAs an aside, in terms of the components of strategy in\nCrafting Engineering Strategy, this is really just\nthe strategy’s policy.\nIn addition, we used strategy testing to refine our approach,\ndefined a concrete set of initial actions to operationalize it (they’re a bit too specific to share externally),\nand did some brief exploration to make sure I wasn’t overfitting on\nmy prior work at Carta.\n\nMy first step towards adoption was collecting as many internal examples of tips and tricks as possible into\na single Notion database. I took a very broad view on what qualified, with the belief that showing\nmany different examples of using tools–especially across different functions–is both useful and inspiring.\n\nI’ve continued extending this, with contributions from across the company, and it’s become a useful resource\nfor both humans and bots alike to provide suggestions on approaching problems with AI tooling.\n\nOne of my core beliefs in our approach is that making prompts discoverable\nwithin the company is extremely valuable.\nDiscoverability solves four distinct problems:\n\nMy core approach is that every agent’s prompt is stored in a single Notion database\nwhich is readable by everyone in the company. Most prompts are editable by everyone,\nbut some have editing restrictions.\n\nHere’s an example of a prompt we use for routing incoming Jira issues from Customer Support\nto the correct engineering team.\n\nHere’s a second example, this time of responding to requests in our Infrastructure Engineering\nteam’s request channel.\n\nPretty much all prompts end with an instruction to include a link to the prompt\nin the generated message. This ensures it’s easy to go from a mediocre response\nto the prompt-driving the response, so that you can fix it.\n\nIn addition to collecting tips and prompts, the next obvious step for AI adoption\nis identifying a standard AI platform to be used within the company, e.g. ChatGPT,\nClaude, Gemini or what not.\n\nWe’ve gone with OpenAI for everyone.\nIn addition to standardizing on a platform, we made sure account provisioning was\nautomatic and in place on day one.\nTo the surprise of no one who’s worked in or adjacent to IT,\na lot of revolutionary general AI adoption is… really just account provisioning and access controls.\nThese are the little details that can so easily derail the broader plan if you don’t dive into them.\n\nWithin Engineering, we also provide both Cursor and Claude.\nThat said, the vast majority of our Claude usage is done via AWS Bedrock,\nwhich we use to power Claude Code… and we use Claude Code quite a bit.\n\nWhile there’s a general industry push towards adopting more AI tooling,\nI find that a significant majority of “AI tools” are just SaaS vendors that\ntalk about AI in their marketing pitches. We have continued to adopt vendors,\nbut have worked internally to help teams evaluate which “AI tools” are meaningful.\n\nWe’ve spent a fair amount of time going deep on integrating with AI tooling for chat and IVR\ntooling, but that’s a different post entirely.\n\nMeasuring AI adoption is, like all measurement topics, fraught.\nAltogether, I’ve found measuring tool adoption very useful for identifying the right\nquestions to ask. Why haven’t you used Cursor? Or Claude Code? Or whatever? These are fascinating\nquestions to dig into. I try to look at usage data at least once a month, with a particular focus\non two questions:\n\nAt the core, I believe folks who aren’t adopting tools are rational non-adopters,\nand spending some time understanding the (appearance of) resistance goes further than\ntop-down mandate. I think it’s often an education gap that is bridged easily enough.\nConceivably, at some point I’ll discover a point of diminishing returns, where the lack\nof progress is stymied on folks who are rejecting AI tooling–or because the AI tooling\nisn’t genuinely useful–but I haven’t found that point yet.\n\nThe next few sections are about building internal agents.\nThe core implementation is a single stateless lambda which handles a wide variety of HTTP requests,\nsimilar-ish to Zapier.\nThis is currently implemented in Python, and is roughly 3,000 lines of code,\nmuch of it dedicated to oddities like formatting Slack messages, etc.\n\nFor the record, I did originally attempt to do this within Zapier,\nbut I found that Zapier simply doesn’t facilitate the precision I believe is necessary to do this effectively.\nI also think that Zapier isn’t particularly approachable for a non-engineering audience.\n\nAs someone who spent a long time working in platform engineering,\nI still want to believe that you can build a platform, and users will come.\nIndeed, I think it’s true that a small number of early adopters will come,\nif the problem is sufficiently painful for them,\nas was the case for Uber’s service migration (2014).\n\nHowever, what we’ve found effective for driving adoption is basically the opposite of that.\nWhat’s really worked is the intersection of platform engineering and old-fashioned product engineering:\n\nSome examples of the projects where we’ve gotten traction internally:\n\nFor all of these projects that have worked, the formula has been\nthe opposite of “build a platform and they will come.” Instead it’s\nrequired deep partnership from folks with experience building AI agents and\nusing AI tooling to make progress. The learning curve for effective AI adoption\nin important or production-like workflows remains meaningfully high.\n\nAgents that use powerful tools represent a complex configuration problem.\nFirst, exposing too many tools–especially tools that the prompt author doesn’t effectively understand–makes\nit very difficult to create reliable workflows. For example, we have an exit_early command that allows terminating\nthe agent early: this is very effective in many cases, but is also easy to break your bot.\nSimilarly, we have a slack_chat command that allows posting across channels, which can support a variety of useful\nworkflows (e.g. warm-handoffs of a question in one channel into a more appropriate alternative),\nbut can also spam folks.\nSecond, as tools get more powerful, they can introduce complex security scenarios.\n\nTo address both of these, we currently store configuration in a code-reviewed Git repository.\nHere’s an example of a JIRA project.\n\nHere’s another for specifying a Slack responder bot.\n\nCompared to a JSON file, we can statically type the configuration, and it’s easy to extend over time.\nFor example, we might want to extend slack_chat to restrict which channels a given bot is allowed to\npublish into, which would be easy enough.\nFor most agents today, the one thing not under Git-version control is the prompts themselves, which are versioned by Notion.\nHowever, we can easily require specific agents to use prompts within the Git-managed repository for sensitive scenarios.\n\nAfter passing tests, linting and typechecking, the configurations are automatically deployed.\n\nIt’s sort of funny to mention, but one thing that has in practice really interfered with\neasily writing effective prompts is making it easy to write things like @Will Larson which\nis then translated into <@U12345> or whatever the appropriate Slack identifier is for a given\nuser, channel, or user group. The same problem exists for Jira groups, Notion pages and databases,\nand so on.\n\nThis is a good example of where centralizing prompts is useful. I got comfortable pulling the unique\nidentifiers myself, but it became evident that most others were not.\nThis eventually ended with three tools for Slack resolution: slack_lookup which takes a list\nof references to lookup, slack_lookup_prefix which finds all Slack entities that start with\na given prefix (useful to pull all channels or groups starting with @oncall-, for example, rather than having to hard-code the list in your prompt), and slack_search_name which uses string-distance to find potential matches (again, useful for dealing with typos).\n\nIf this sounds bewildering, it’s largely the result of Slack not exposing relevant APIs for this sort of lookup.\nSlack’s APIs want to use IDs to retrieve users, groups and channels, so you have to maintain your own cache of\nthese items to perform a lookup. Performing the lookups, especially for users, is itself messy. Slack users have\na minimum of three ways they might be referenced: user.profile.display_name, user.name, and user.real_name,\nonly a subset of which are set for any given user.\nThe correct logic here is, as best I can tell, to find a match against user.profile.display_name, then use that if it exists.\nThen do the same for user.name and finally user.real_name. If you take the first user that matches one of those three,\nyou’ll use the wrong user in some scenarios.\n\nIn addition to providing tools to LLMs for resolving names, I also have a final mandatory check for each response\nto ensure the returned references refer to real items. If not, I inject which ones are invalid into the context window and perform an additional agent loop with only entity-resolution tools available.\nThis feels absurd, but it was only at this point that things really started working consistently.\n\nAs an aside, I was embarassed by these screenshots, and earlier today I made the same changes for Notion pages and databases\nas I had previously for Slack.\n\nSimilarly to foreign entity resolution,\nthere’s a similar problem with Slack’s mrkdwn variant of Markdown\nand JIRA’s Atlassian Document Format:\nthey’re both strict.\n\nThe tools that call into those APIs now have strict instructions on formatting. These had been contained in individual\nprompts, but they started showing up in every prompt, so I knew I needed to bring them into the agent framework itself\nrather than forcing every prompt-author to understand the problem.\n\nMy guess is that I need to add a validation step similar to the one I added for entity-resolution,\nand that until I do so, I’ll continue to have a small number of very infrequent but annoying rendering issues,\nTo be honest, I personally don’t mind the rendering issues, but that creates a lot of uncertainty for others using agents, so I think solving them is a requirement.\n\nToday, all logs, especially tool usage, are fed into two places. First, it goes into Datadog for full logging visibility.\nSecond, and perhaps more usefully for non-engineers, they feed into a Slack channel, #ai-logs which create visibility\ninto which tools are used and with which (potentially truncated) parameters.\n\nLonger term, I imagine this will be exposed via a dedicated internal web UX, but generally speaking I’ve found that\nthe subset of folks who are actively developing agents are pretty willing to deal with a bit of cruft.\nSimilarly the folks who aren’t developing agents directly don’t really care, they want it to work perfectly every time,\nand aren’t spending time looking at logs.\n\nThe biggest internal opportunity that I see today is figuring out how to\nget non-engineers an experience equivalent to running Claude Code locally with\nall their favorite MCP servers plugged in.\nI’ve wanted ChatGPT or Claude.ai to provide this, but they don’t really quite get there,\nClaude Desktop is close, but is somewhat messy to configure as we think about finding a tool\nthat we can easily allow everyone internally to customize and use on a daily basis.\n\nI’m still looking for what the right tool is here. If anyone has any great suggestions\nthat we can be somewhat confident will still exist in two years, and don’t require sending\na bunch of internal data to a very early stage company, then I’m curious to hear!\n\nYou’re supposed to start a good conclusion with some sort of punchy anecdote that\nilluminates your overall thesis in a new way. I’m not sure if I can quite meet that bar,\nbut the four most important ideas for me are:\n\nI’m curious what other folks are finding!",
    "readingTime": 13,
    "keywords": [
      "i’m curious",
      "notion database",
      "notion pages",
      "i’ve learned",
      "slack entities",
      "account provisioning",
      "strategy testing",
      "developing agents",
      "platform engineering",
      "claude code"
    ],
    "qualityScore": 1,
    "link": "https://lethain.com/company-ai-adoption/",
    "thumbnail_url": "https://lethain.com/static/author.png",
    "created_at": "2025-12-12T18:56:03.515Z",
    "topic": "tech"
  },
  {
    "slug": "ai-can-write-your-code-it-cant-do-your-job",
    "title": "AI Can Write Your Code. It Can't Do Your Job",
    "description": "The companies building AI are spending billions to acquire engineers, not replace them. Here’s why your job is safer than you think.",
    "fullText": "In May, OpenAI agreed to pay $3 billion for Windsurf, the AI coding assistant formerly known as Codeium. Three billion dollars. For a VSCode fork.\n\nThe deal eventually fell apart, but what matters is that they wanted to do it in the first place.\n\nLast week, Anthropic made an interesting acquisition: they bought Bun, the JavaScript runtime. Bun is open source and MIT-licensed. Anthropic could have forked it and built on top of it for free. They have Claude Code, an excellent code-writing tool.\n\nInstead, they bought the company. Because they wanted Jarred Sumner and his team.\n\nThis is what I keep coming back to when I see another “Programming is dead” post go viral. The companies building AI, the ones who supposedly know exactly what it can and can’t do, are spending billions to acquire engineering talent. Not fire them, acquire them.\n\nIf OpenAI believed GPT could replace software engineers, why wouldn’t they build their own VS Code fork for a fraction of that cost? If Anthropic thought Claude could do the work, why make an acquisition at all?\n\nHere’s my take: AI can replace most of programming, but programming isn’t the job.\n\nProgramming is a task. It’s one of many things you do as part of your work. But if you’re a software engineer, your actual job is more than typing code into an editor.\n\nThe mistake people make is conflating the task with the role. It’s like saying calculators replaced accountants. Calculators automated arithmetic, but arithmetic was never the job. The job was understanding financials, advising clients, making judgment calls, etc. The calculator just made accountants faster at the mechanical part.\n\nAI is doing something similar for us.\n\nThink about what you actually do in a given week.\n\nYou sit in a meeting where someone describes a vague problem, and you’re the one who figures out what they actually need. You look at a codebase and decide which parts to change and which to leave alone. You push back on a feature request because you know it’ll create technical debt that’ll haunt the team for years. You review a colleague’s PR and catch a subtle bug that would’ve broken production. You make a call on whether to ship now or wait for more testing.\n\nNone of that is programming, but it’s all your job.\n\nI’m not going to pretend nothing is changing.\n\nWill some companies use AI as an excuse to cut headcount? Absolutely. Some already have. There will be layoffs blamed on “AI efficiency gains” that are really just cost-cutting dressed up as something else.\n\nBut think about who stays and who goes in that scenario. It’s not random. The engineers who understand that programming isn’t the job, the ones who bring judgment, context, and the ability to figure out what to build, those are the ones who stay. The ones who only brought code output might be at risk\n\nA common worry is that juniors will get left behind. If AI handles the “doing” part, how do they build judgment? I actually think the opposite is true. AI compresses the feedback loop. What used to take days of flipping through books or waiting for Stack Overflow answers now takes seconds. The best juniors aren’t skipping steps, but getting through them faster.\n\nNow think about your own situation. Say you were hired two years ago, before the current AI wave. Your company wanted you. They saw value in what you bring. Now, with AI tools, you’re significantly more productive. You ship faster. You handle more complexity. You’re better at your job than ever before.\n\n“You got way more productive, so we’re letting you go” is not a sentence that makes a lot of sense.\n\nIf you’re reading this, you’re already thinking about this stuff. That puts you ahead. Here’s how to stay there:\n\nThe shape of the work is changing: some tasks that used to take hours now take minutes, some skills matter less, others more.\n\nBut different isn’t dead. The engineers who will thrive understand that their value was never in the typing, but in the thinking, in knowing which problems to solve, in making the right trade-offs, in shipping software that actually helps people.\n\nOpenAI and Anthropic could build their own tools. They have the best AI in the world. Instead, they’re spending billions on engineers. That should tell you something.",
    "readingTime": 4,
    "keywords": [
      "programming isn’t",
      "you’re",
      "ones",
      "engineers",
      "it’s",
      "software",
      "judgment",
      "faster",
      "fork",
      "acquisition"
    ],
    "qualityScore": 1,
    "link": "https://terriblesoftware.org/2025/12/11/ai-can-write-your-code-it-cant-do-your-job/",
    "thumbnail_url": "https://terriblesoftware.org/wp-content/uploads/2025/12/chjpdmf0zs9sci9pbwfnzxmvd2vic2l0zs8ymdiylta0l3vwd2s2mtc5nzyync13awtpbwvkawetaw1hz2uta293ctv0bheuanbn.webp",
    "created_at": "2025-12-12T18:56:02.981Z",
    "topic": "tech"
  },
  {
    "slug": "2-artificial-intelligence-stocks-that-could-help-make-you-a-fortune-in-2026",
    "title": "2 Artificial Intelligence Stocks That Could Help Make You a Fortune in 2026",
    "description": "Broadcom and UiPath both have huge opportunities in front of them.",
    "fullText": "Broadcom has a massive opportunity ahead with custom AI chips.\n\nUiPath has huge potential upside as its revenue starts to accelerate.\n\nThese 10 stocks could mint the next wave of millionaires ›\n\nAs 2025 begins to wind down, it will go down as another strong year for artificial intelligence (AI) stocks. Meanwhile, with AI still appearing to be in its early innings, the group could help lead the market higher in 2026 once again.\n\nLet's look at two AI stocks that could help you make a fortune in 2026.\n\nOne AI stock that looks like it could outperform in 2026 is Broadcom (NASDAQ: AVGO), as it has some of the best growth prospects of any AI infrastructure company.\n\nThe company is already seeing strong growth coming from its data center networking portfolio, which helps transfer data and distribute AI workloads across servers to help optimize performance. Products like its Tomahawk Ethernet switch and Jericho4 Ethernet fabric router are popular and helping power its networking growth.\n\nHowever, Broadcom's ASICs (application-specific integrated circuits) business is what should get investors excited the most. ASICs are custom chips that are pre-programmed to handle specific tasks, and because they are purpose-built, they tend to deliver improved performance with greater energy efficiency than general-purpose chips, such as graphics processing units (GPUs). Broadcom made a name for itself in this business when it helped Alphabet design its well-regarded tensor processing units (TPUs) that are helping Alphabet power much of its internal AI workloads, as well as those for external cloud computing customers.\n\nThat success has led to other hyperscalers (owners of large data centers) partnering with Broadcom to design their own custom chips. The company has called out its three custom AI chip customers furthest along as being an up to $90 billion opportunity in fiscal 2027, and then announced that a fourth customer has placed a $10 billion order for next year. It also recently struck a deal with OpenAI to supply it with 10 gigawatts of custom AI chips, in a deal worth hundreds of millions of dollars.\n\nWith these deals in place, Broadcom could see explosive growth in the coming years, which could propel its stock much higher in 2026 and beyond.\n\nAnother company whose stock could help you make a fortune next year is UiPath (NYSE: PATH). The company is in the midst of a transformation that could see it become one of the most important players in agentic AI.\n\nUiPath is a stalwart in the field of robotic process automation (RPA), which uses software bots to perform simple, rules-based tasks. However, it's using this background in managing software bots to become an orchestration platform that can manage both software bots and AI agents.",
    "readingTime": 3,
    "keywords": [
      "processing units",
      "software bots",
      "custom chips",
      "growth",
      "stocks",
      "stock",
      "opportunity",
      "another",
      "higher",
      "fortune"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/2-artificial-intelligence-stocks-could-090500087.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ArCO_5RCQc_Aa8M.K4K4QA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/68ea2d44f90c910427485d4936367d7b",
    "created_at": "2025-12-12T18:56:00.581Z",
    "topic": "finance"
  },
  {
    "slug": "if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography",
    "title": "If Google wins AI race, Nvidia is 'in trouble,' says author of Jensen Huang biography",
    "description": "Jensen Huang biography author Stephen Witt explains why Google's self-developed AI model, Gemini, could pose a threat to Nvidia's AI dominance",
    "fullText": "Nvidia's (NVDA) AI turf could take a blow if Google (GOOGL, GOOG) keeps firing on all cylinders.\n\n\"The biggest risk right now obviously is Google,\" said Stephen Witt, author of \"The Thinking Machine,\" a Jensen Huang biography.\n\nThat risk, he told Yahoo Finance's Opening Bid, is largely tied to Google's Gemini model. Witt described it as the \"best AI right now in the benchmarks outside the Nvidia stack.\"\n\nWitt explained that Gemini was trained entirely on its Tensor Processing Units (TPUs). If Google proves it can sustain world-leading AI development using only its homegrown chip stack, it sets a potent precedent for other tech giants to follow suit.\n\n\"That's a huge risk,\" Witt said. \"If Google ends up winning this AI race ... Nvidia will be in trouble.\"\n\nThis risk, coupled with competition from rivals like Broadcom (AVGO) and Advanced Micro Devices (AMD), is why \"it's very easy to imagine a world\" where Nvidia's high-flying stock declines. The AI chipmaker's shares are up over 1,270% in the past five years.\n\nTo mitigate the core risk of rivals like Google winning the chip war, Nvidia CEO Jensen Huang is already looking past generative AI. Witt said a significant amount of the CEO's personal effort is being poured into the next great computing wave: robotics.\n\nIf Huang can dominate the robotics wave, he said, \"that will mean several trillion dollars in market capitalization for this company.\"\n\nHowever, Nvidia has another issue: the lack of any clear succession plan.\n\n\"It's just Jensen at the top,\" Witt said. \"There's no second in command. There's no obvious successor.\" He noted that the board has been silent, and Huang has offered no advice on a succession strategy.\n\nThat suggests Nvidia's $4 trillion valuation — which accounts for over 8% of the entire S&P 500 (^GSPC) — is, in many ways, resting solely on Huang's vision.\n\nWitt described Huang as a \"world-class engineer\" who could \"design these microchips himself,\" a skill that whoever takes the helm must also possess. He noted that neither of Huang's two children, who work at the company, has a technical background, making them noncontenders for the top spot.\n\nWitt also provided a look behind the polished stage persona of Huang, known for his trademark leather jacket. Beneath the showmanship is a highly intense, \"almost totally neurotic\" leader who is driven not by optimism, but by fear.\n\n\"He's driven by negative emotions, things like fear of failure, guilt, even shame are what make Jensen get up in the morning and work so hard to make Nvidia succeed,\" Witt explained.",
    "readingTime": 3,
    "keywords": [
      "jensen huang",
      "risk",
      "witt",
      "stack",
      "chip",
      "rivals",
      "it's",
      "wave",
      "robotics",
      "succession"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography-184624884.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/pgRIv4CaXitTJsbNTIjhsA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/60ef8cc0-d6b2-11f0-9a17-1d997177f998",
    "created_at": "2025-12-12T18:55:59.740Z",
    "topic": "finance"
  },
  {
    "slug": "doom-dev-id-software-forms-a-walltowall-union",
    "title": "Doom Dev id Software Forms A \"Wall-To-Wall\" Union",
    "description": "Developer id Software, a Texas-based studio known for the Doom games (including The Game Awards-winning The Dark Ages), has, has formed a union under the Communications Workers of America (CWA). It's a \"wall-to-wall\" guild built to protect employees from AI while negotiating for ample benefits, such as remote work, and Microsoft appears to have recognized the studio's union.\nIn a press release on the CWA's website, id Software's 165-person union will join the CWA Local 6215 division in Richardson, Texas. Producer Andrew Willis noted how important it is for workers to fight back against the injustices facing the games industry at the moment.\n\"The wall-to-wall organizing effort at id Software was much needed; it's incredibly important that developers across the industry unite to push back on all the unilateral workplace changes that are being handed down from industry executives,\" Willis said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/doom-dev-id-software-forms-a-wall-to-wall-union/1100-6536938/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1578/15789366/4621767-dtdaimage.jpg",
    "created_at": "2025-12-12T18:55:57.349Z",
    "topic": "tech"
  },
  {
    "slug": "godmother-of-ai-says-degrees-are-less-important-in-hiring-than-how-quickly-can-you-superpower-yourself-with-new-tools",
    "title": "‘Godmother of AI’ says degrees are less important in hiring than ‘how quickly can you superpower yourself’ with new tools",
    "description": "Instead, she looks to hire software engineers with AI fluency to her startup that aims to revolutionize the tech.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/fei-fei-li-stanford-professor-godmother-ai-college-degrees-skills-talent-ceo/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247144876-e1765553881661.jpg?resize=1200,600",
    "created_at": "2025-12-12T18:55:54.101Z",
    "topic": "business"
  },
  {
    "slug": "broadcom-is-the-latest-victim-of-skyhigh-expectations-from-ai-investors",
    "title": "Broadcom is the latest victim of sky-high expectations from AI investors",
    "description": "Broadcom shares tumbled on Friday as investors balked at some disappointing aspects of the company's outlook heading into 2026.",
    "fullText": "Broadcom is the latest victim of investors punishing high-flying AI companies.\n\nThe chipmaker tumbled 8% as investors took in its stellar results for the last quarter, but were left disappointed by certain aspects of the company's outlook.\n\nThe firm beat on earnings and revenue, leading shares to initially rise after-hours on Thursday, before falling into the red as CEO Hock Tan dug into the results in the call with analysts.\n\n\"It was surprising to see a call that started with such good numbers and such a great story end with frustration,\" Josh Meyers, an executive director at JPMorgan, wrote in a client note on Friday.\n\nHere's where major indexes stood shortly after the 9:30 a.m. ET opening bell on Friday:\n\nOther chip stocks also lost slightly, extending a decline in the sector that kicked off after Oracle reported earnings earlier in the week. Here were some of the notable moves:\n\nBroadcom investors seemed disappointed in how the company didn't issue full AI revenue guidance for the coming year, Deutsche Bank and JPMorgan wrote on Friday. Broadcom said it expected AI semiconductor revenue to double to $8.2 billion in the following quarter.\n\nInvestors also seemed \"underwhelmed\" by the firm's $73 billion backlog of AI product orders over the next 18 months, Paul Hickey, the co-founder of Bespoke Investment Group, said in a note.\n\n\"Somehow some investors seized on this as 'not enough,' which compounded an earlier narrative today that somehow we needed more visibility on F27 AI revenue (no idea why this is suddenly an issue),\" JPMorgan's Meyers wrote.\n\nSome investors also feel that the Tan was more \"buttoned-up\" about the company's results than they would have liked, Meyers said, citing his conversations with shareholders.\n\nThe stock is a crowded trade in the already popular AI theme, and some may also think the market \"just needed to take a breath\" from the AI trade, Meyers said. Shares of Broadcom are still up more than 56% this year.\n\nInvestors have put more pressure on the semiconductor sector in recent months amid concerns about the sustainability of the AI trade, which has led to some firms getting punished despite beating on earnings and revenue.\n\nOracle shares plunged 14% on Thursday as investors took in lower-than-expected quarterly revenue and worries that the software giant is overspending on AI.\n\nMeta and Microsoft shares also dropped after the companies reported earnings in October, as both tech titans promised to spend more on AI in the coming years.",
    "readingTime": 3,
    "keywords": [
      "investors",
      "revenue",
      "earnings",
      "trade",
      "quarter",
      "disappointed",
      "company's",
      "note",
      "sector",
      "oracle"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/broadcom-stock-price-avgo-q4-earnings-ai-chips-revenue-outlook-2025-12",
    "thumbnail_url": "https://i.insider.com/693c294064858d02d216b42a?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.125Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-making-the-chros-job-a-whole-lot-bigger",
    "title": "How AI is making the CHRO's job a whole lot bigger",
    "description": "AI is reshaping the CHRO role, requiring HR leaders to become AI strategists and bridge people, technology, and data in today's workforce.",
    "fullText": "AI is changing how companies hire, train, and lead, and in the process, the chief human resources officer's role is expanding.\n\nToday's top HR leaders are becoming AI strategists, helping their organizations navigate the next wave of workplace transformation.\n\n\"The old model of HR was employees over here, technology over there,\" says Thomas Hutzschenreuter, a university professor at the Technical University of Munich (TUM). \"But the new model of work is human-AI collaboration.\"\n\nAI is a coworker now, he says, and that means that \"HR has a bigger mandate. They need to understand not just people and culture, but go deeper into the strategy, the business, and the technology itself.\"\n\nTo understand how companies are navigating the shift, Business Insider spoke with people leaders at Citizens Bank, one of the largest banks in the Northeast; Boston Consulting Group, a global consultancy; and UiPath, an automation software testing company.\n\nAll interviews have been edited for brevity.\n\nCHROs are becoming the architects of the future of work, bridging people, technology, and data.\n\nThere are many questions we are in the middle of that are germane to how we as an organization move forward, such as: What's going to happen to entry-level roles? What roles are emerging? And how do we reskill people in a way that prepares them to make shifts thoughtfully?\n\nWe need people who can quickly learn, adapt, and change. Our technologists need to develop their business acumen, and our business folks need to develop their digital and technical fluency. The lines are blurring.\n\nMy HR team is developing a baseline of skills and capabilities. We're having conversations with consulting partners and clients. There's an openness to communal learning because everyone is trying to figure out the same things: what the AI-driven workforce will look like, how to break work into tasks for AI vs. humans, and what AI agents can handle versus humans.\n\nWe're subject to a lot of regulatory oversight in our industry. It's great that people can develop their own AI agents — there's a push to decentralize these capabilities — but we need to be mindful of risk and governance and how we do this in a safe, ethical way.\n\nAI is changing how work gets done and what work gets done. Business models are evolving, and the way companies serve clients is shifting. The CHRO role now requires adapting to both at once. It's a tall order.\n\nIn consulting, our ability to add value means constantly evolving our approach to human capital. The issues are constant; the pace is what's different. Today, a quarter of our business involves AI, which wasn't true even two years ago.\n\nWe need our people to be AI fluent. About 90% of our workforce uses AI regularly, and more than half use it daily. To get there, we've built a multi-layered support system: a 1,400-person enablement network acting as evangelists and coaches.\n\nWe've upskilled more than 100 team coaches to provide hands-on support. We deploy experts directly into teams to help them reimagine workflows and run innovation competitions to keep momentum going.\n\nOur HR team has taken the lead. We started with recruiting — consolidating six IT systems into one and integrating AI throughout the platform and across performance management and development.\n\nWe're also experimenting with voice tools, chat interfaces, and AI avatars for real-time coaching. These tools give employees confidence, learning opportunities, and instant feedback. They don't replace managers — they free them up for higher-level thinking and relationship-building.\n\nOur business is automation, so that muscle is very strong for my team. But the next frontier of agentic AI is an adjustment.\n\nWe're using these AI agents — but we're also creating them. One agent, almost in production, helps with performance reviews, which is a time-consuming and sometimes dreaded task. Our agent helps employees write their self-assessment and collects feedback, bringing it together much quicker. It also helps managers by consolidating feedback from multiple resources.\n\nIt won't make rating decisions on the manager's behalf, but it makes the year-end much more seamless. Instead of spending time on admin, managers can focus on the feedback itself and my team on the right framework for career development.\n\nThere are a lot of unknowns at the moment, and fear is natural. But it should fuel curiosity and development. This is the time to think about career development seriously.\n\nWe have this idea that AI is only affecting entry-level or lower-level jobs. The truth is that technology is replacing skills that very highly skilled people have been doing.\n\nIf you look at the medical field and aviation — areas where we always thought technology wouldn't touch — that's no longer the case. It's not going to happen overnight. We have time to prepare. But it's relevant for everybody in any profession.",
    "readingTime": 4,
    "keywords": [
      "career development",
      "technology",
      "team",
      "we're",
      "feedback",
      "employees",
      "agents",
      "managers",
      "business",
      "changing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-transforms-chro-roles-bridge-people-tech-business-strategy-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c47a71107c9f3457b614?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.066Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-finally-paying-for-ai-and-paying-big",
    "title": "Companies are finally paying for AI, and paying big",
    "description": "AI enterprise spending is about to surge as CIOs allocate new budgets for generative AI projects in 2026, surveys finds.",
    "fullText": "For much of the past year, Wall Street and Silicon Valley have wrestled with the same uncomfortable question: Will companies really spend money on AI, or is the hype just outpacing budgets?\n\nA new CIO survey from RBC Capital suggests that question may finally have an answer, and it's a resounding yes.\n\nRBC recently polled 117 IT professionals at companies with annual revenue ranging from below $250 million to more than $25 billion. 90% of the respondents said their organizations plan to spend more on AI in 2026.\n\n\"Overall, we came away increasingly optimistic of macro/budget stabilization taking shape in 2026 and encouraged by the pace of early GenAI adoption,\" the RBC analysts wrote in a research note summarizing the findings.\n\nCIOs are not only moving rapidly into production with AI systems, but they are also setting aside dedicated budgets to fund that adoption.\n\nA striking 90% of technology leaders said their organizations are creating new budgets specifically for generative AI and LLM projects, up from 85% the year before. That suggests AI is becoming additive rather than substitutive in enterprise tech spending.\n\nEven more telling: 60% of respondents said they are already in production with AI initiatives, a jump from 39% the previous year. Another 32% expect to be in production within six months.\n\nThis shift comes after months of skepticism from investors who questioned whether businesses would convert pilot projects into real spending. The survey data suggests that moment is now arriving.\n\nCIOs overwhelmingly cited AI as the top category for increased software spending next year, surpassing cybersecurity and IT service management. And in open-ended responses, executives repeatedly named AI as their biggest area of investment for 2026, often paired with infrastructure upgrades and automation initiatives, according to the RBC survey.\n\nUse cases are expanding beyond experimentation. Seventy-six percent of CIOs said their AI strategies now target both cost savings and revenue generation, a shift that reinforces AI's transition from a novelty to a competitive mandate.\n\nConcerns remain — data privacy tops the list — but those worries are no longer slowing adoption. Instead, AI is becoming the primary force expanding IT budgets heading into 2026.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "budgets",
      "survey",
      "adoption",
      "cios",
      "production",
      "revenue",
      "respondents",
      "organizations",
      "projects",
      "initiatives"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/companies-finally-paying-ai-cio-survey-2025-12",
    "thumbnail_url": "https://i.insider.com/693b59c204eda4732f2d6898?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:52.598Z",
    "topic": "finance"
  },
  {
    "slug": "openais-merch-store-offers-a-glimpse-inside-the-companys-vibe",
    "title": "OpenAI's merch store offers a glimpse inside the company's vibe",
    "description": "The \"OpenAI Supply Co.\" has 10 merch items available for purchase, and dozens of more archived designs. Most sizes have sold out.",
    "fullText": "You can now wear ChatGPT on your sleeve — or head or shin.\n\nAs part of its 10-year anniversary celebration, OpenAI dropped a link on its X feed to a merchandise store. The \"OpenAI Supply Co.\" seems suited for the company's engineers, with a space to log in with a company email. Indeed, most of the items listed are archives of old designs — but a few are available for purchase.\n\nThe \"Supply Co.\" site was marked as \"coming soon\" in July 2024, according to the Internet Archive. But this appears to be the first time ChatGPT users who aren't employees can actually buy something from it.\n\nOpenAI fans ate it up. The post garnered over 3,000 likes within 15 hours, and multiple sizes of the for-sale items were quickly sold out. If you're anything other than an extra small or a small, you're out of luck on sweatshirts and tees.\n\nThe items OpenAI listed give a glimpse inside the company — or at least its swag.\n\nThere are five Pokémon-style trading cards. Their subjects include Sora 2 (\"shape-shifter\"), GPT-5 (\"two worlds, one model\"), image generation (with a \"huge\" wow factor), Sora (\"sci-fi\"), and the OpenAI Blossom (\"back and better\").\n\nPokémon has recently been a point of contention for the company, after its Sora video generator began booting out unauthorized versions of Pikachu.\n\nMuch of the site is themed around AGI, or artificial general intelligence, a much debated breakthrough milestone that many AI companies are racing to hit. One shirt reads: \"AGI that benefits all of humanity,\" a line from OpenAI's charter. On the employee log-in, the suggested email is agi@openai.com.\n\nThe assortment of hats also offers clues. There are Sora beanies and baseball caps with the word \"research.\" One cap has the chatbot's phone number, 1-800-CHATGPT. (Yes, the number still works.)\n\nAnother cap has OpenAI in red letters on camo print, resembling the popular Harris/Walz hat, which nods to Chappell Roan.\n\nThe baseball caps kept coming. There's one with silver flames, a piece of early 2000s nostalgia. There's another with the letters \"SF\" on it, firmly planting OpenAI in the city of San Francisco.\n\nAll the way at the bottom of the page is a baseball cap with the words \"Thinking deeply.\" The site says that it was released in September 2024 in honor of OpenAI's reasoning model. It also looks remarkably similar to Anthropic's \"thinking\" caps, which launched a year later at the company's Air Mail pop-up.\n\nAnthropic's \"thinking\" caps quickly became a status symbol, signifying the wearer's closeness to the AI boom. Cursor's tab keys had a similar effect, as did OpenAI's DevDay token plaques.\n\nIt's possible that this merchandise drop will have the same effect. Your ChatGPT crew neck could give you caché.\n\nThe fans have clearly been hungry. Fan-created merchandise concepts have long floated around X. Some even turned their designs into unauthorized businesses.\n\nThirty minutes before its post about the tenth anniversary, OpenAI responded to a fan post. Developer Tibor Blaho posted some of the merch, saying that the company should make its store \"public instead of keeping it employee-only.\" OpenAI responded with the link and an eye emoji.\n\nBlaho's post was 10 months ago.",
    "readingTime": 3,
    "keywords": [
      "openai responded",
      "baseball caps",
      "sora",
      "merchandise",
      "items",
      "site",
      "anniversary",
      "link",
      "store",
      "company's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-merch-supply-co-2025-12",
    "thumbnail_url": "https://i.insider.com/693c27cb64858d02d216b405?width=1113&format=jpeg",
    "created_at": "2025-12-12T18:55:52.542Z",
    "topic": "finance"
  },
  {
    "slug": "new-research-on-ai-and-fairness-in-hiring",
    "title": "New Research on AI and Fairness in Hiring",
    "description": "AI promises to make hiring fairer by reducing human bias, yet it often reshapes what fairness means—and locks in one definition. A three-year study of a global consumer-goods firm found that their algorithmic system privileged a rigid definition that sidelined manager’s local judgment. This resulted in narrow candidate pools and unhappy hiring managers. The study underlined that fairness isn’t embedded in code, it’s negotiated by people who design and deploy it. To make AI hiring systems work better for more people, leaders must ask: Which versions of fairness exist?",
    "fullText": "New Research on AI and Fairness in Hiring by Elmira van den Broek, Anastasia Sergeeva and Marleen HuysmanDecember 12, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWill AI improve or degrade fairness? With nearly 90% of companies now using some form of AI in hiring, this question is top of mind for many leaders, and it tends to split them into two camps. One side believes algorithms will make hiring fairer by reducing human “bias” and “noise” in decision-making. The other warns that algorithms can reproduce and even amplify existing inequalities at scale. Both overlook a crucial reality: When AI is adopted, it reshapes what counts as fair in the first place.",
    "readingTime": 1,
    "keywords": [
      "hiring",
      "algorithms",
      "fairness"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/new-research-on-ai-and-fairness-in-hiring",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_13_200560131-001.jpg",
    "created_at": "2025-12-12T18:55:51.703Z",
    "topic": "science"
  },
  {
    "slug": "trumps-ai-order-faces-political-and-legal-hurdles",
    "title": "Trump's AI order faces political and legal hurdles",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/politics-news/trumps-ai-order-faces-political-and-legal-hurdles-4406498",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBB11W_L.jpg",
    "created_at": "2025-12-12T18:55:51.568Z",
    "topic": "finance"
  },
  {
    "slug": "the-best-big-media-merger-is-no-merger-at-all",
    "title": "The Best Big Media Merger Is No Merger at All",
    "description": "The state of streaming is... bad. It’s very bad. The first step in wanting to watch anything is a web search: “Where can I stream X?” Then you have to scroll past an AI summary with no answers, and then scroll past the sponsored links.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.eff.org/deeplinks/2025/12/best-big-media-merger-no-merger-all",
    "thumbnail_url": "https://www.eff.org/files/banner_library/icon-2019-innovation.png",
    "created_at": "2025-12-12T13:47:26.391Z",
    "topic": "tech"
  },
  {
    "slug": "disney-wants-you-to-aigenerate-yourself-into-your-favorite-marvel-movie",
    "title": "Disney wants you to AI-generate yourself into your favorite Marvel movie",
    "description": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n Continue reading...",
    "fullText": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\n\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\n\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n\nDisney announced that it would invest $1bn in OpenAI and, under a three-year deal perhaps worth even more than that large sum, that it would license about 200 of its iconic characters – from R2-D2 to Stitch – for users to play with in OpenAI’s video generation app.\n\nAt a time of intense anxiety in Hollywood over the impact of AI on the livelihoods of writers, actors, visual effects artists and other creatives, Disney stressed its agreement with OpenAI would not cover talent likenesses or voices.\n\nThe announcement was framed as an extraordinary opportunity to empower fans.\n\nThink of the “fan-inspired Sora short form videos”, as Disney called them in a press release – akin to taking an AI-generated version of a photo with Princess Jasmine at Disney World. OpenAI included screenshots of these kinds of videos in its press release, indicating how the two companies expect people to use the app’s new cast. Sora already allows users to generate videos that include their own likenesses.\n\nBob Iger, Disney’s CEO, said the licensing deal would place “imagination and creativity directly into the hands of Disney fans in ways we’ve never seen before”.\n\nThey may even offer a chance at wide viewership, with some fan-made videos being displayed on the Disney+ streaming service, a move seemingly designed to compete with TikTok’s and YouTube Shorts’ infinite feeds, which themselves often include clips of popular TV shows and movies.",
    "readingTime": 2,
    "keywords": [
      "press release",
      "generation app",
      "allows users",
      "generate videos",
      "characters",
      "disney",
      "announcement",
      "startup",
      "deal",
      "likenesses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2025/dec/11/disney-openai-sora",
    "thumbnail_url": "https://i.guim.co.uk/img/media/d99390e95d50b47f91bcc8a3130e524c618e635d/436_0_4324_3458/master/4324.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=67d482fa7d7bed846eb736aeb1dfde1c",
    "created_at": "2025-12-12T13:47:25.564Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-teams-with-el-salvador-to-bring-grok-chatbot-to-public-schools",
    "title": "Elon Musk teams with El Salvador to bring Grok chatbot to public schools",
    "description": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n Continue reading...",
    "fullText": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\n\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\n\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n\nNayib Bukele, El Salvador’s president, is now entrusting the chatbot to create curricula in classrooms across the country. Bukele has long embraced technology, making El Salvador the first county in the world to use bitcoin as legal tender, and being one of the first Central American presidents to use Twitter, now X, as a platform. He is also known for ruling with an iron fist and working with Trump to incarcerate deportees to El Salvador’s notorious Cecot prison.\n\n“El Salvador doesn’t just wait for the future to happen; we build it,” Bukele said in a statement about the partnership with xAI. “This partnership is destined to deliver something rather extraordinary for all of humanity.”\n\nMusk touted his partnership with Bukele on Thursday. On X, between posts about “white genocide” and blaming asylum seekers for crime, Musk posted comments about Grok being spread throughout El Salvador’s schools.\n\nHe reposted positively to a comment from Katie Miller, the wife of Trump’s senior adviser Stephen Miller, in which she wrote: “If we are serious about restoring education to math, science and English – why would we allow left leaning liberal [sic] AI our kids? This unlocks non-woke educational tools for our kids.”\n\nxAI is not the first artificial intelligence company to introduce chatbots to public schools. OpenAI announced a partnership with Estonia in February where it could provide all students and teachers in the country’s secondary school system with a customized ChatGPT. Students in rural Colombia also started using Meta’s AI chatbots in 2023 and within a year, teachers began blaming the tech for low grades and failing exams, according to Rest of World.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 3,
    "keywords": [
      "nayib bukele",
      "guardian app",
      "artificial intelligence",
      "white genocide",
      "el salvador",
      "el salvador’s",
      "chatbot",
      "partnership",
      "grok",
      "schools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/11/elon-musk-el-salvador-grok",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7110440275e2c1e8231708520c23cbc728846c00/401_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=585578e2aeb3d5963fc6677b1ca099f4",
    "created_at": "2025-12-12T13:47:25.075Z",
    "topic": "tech"
  },
  {
    "slug": "mcp-and-workflow-for-specdriven-development-with-claude-code",
    "title": "MCP and workflow for spec-driven development with Claude Code",
    "description": "Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust 🦀 - marconae/spec-oxide",
    "fullText": "marconae\n\n /\n\n spec-oxide\n\n Public\n\n Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust 🦀\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n marconae/spec-oxide",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/marconae/spec-oxide",
    "thumbnail_url": "https://opengraph.githubassets.com/e5b240d3d85c84aad2b2aff0a433f6f4034b00bbdd75ee07c24ade4e6e0525c7/marconae/spec-oxide",
    "created_at": "2025-12-12T13:47:24.935Z",
    "topic": "tech"
  },
  {
    "slug": "disney-plus-openai-what-could-possibly-go-wrong",
    "title": "Disney plus OpenAI: What could possibly go wrong?",
    "description": "Disney’s deal with OpenAI may prove prescient and astute, but it doesn't take a lot of imagination to think about the nightmare scenarios.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/disney-plus-openai-what-could-possibly-go-wrong/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2251267095-e1765501885187.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.330Z",
    "topic": "business"
  },
  {
    "slug": "openai-microsoft-face-wrongful-death-lawsuit-over-paranoid-delusions-that-led-former-tech-worker-into-murdersuicide",
    "title": "OpenAI, Microsoft face wrongful death lawsuit over ‘paranoid delusions’ that led former tech worker into murder-suicide",
    "description": "Police said Stein-Erik Soelberg, 56, fatally beat and strangled his 83-year-old mother, Suzanne Adams, and then killed himself in early August.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-microsoft-wrongful-death-lawsuit-murder-suicide-greenwich-connecticut-chatgpt/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/AP25345700615297.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.159Z",
    "topic": "business"
  },
  {
    "slug": "an-ai-agent-spent-16-hours-hacking-stanfords-network-it-outperformed-human-pros-for-much-less-than-their-sixfigure",
    "title": "An AI agent spent 16 hours hacking Stanford's network. It outperformed human pros for much less than their six-figure salaries.",
    "description": "An AI agent hacked Stanford's network for 16 hours and outperformed human pros, all while costing far less than their six-figure pay.",
    "fullText": "For 16 hours, an AI agent crawled Stanford's public and private computer science networks, digging up security flaws across thousands of devices.\n\nA study published Wednesday by Stanford researchers found that their AI agent, ARTERMIS, placed second in an experiment with 10 selected cybersecurity professionals. The researchers said the agent could uncover weaknesses that humans missed and investigate several vulnerabilities at once.\n\nRunning ARTEMIS costs about $18 an hour, far below the average salary of about $125,000 a year for a \"professional penetration tester,\" the study said. A more advanced version of the agent costs $59 an hour and still comes in cheaper than hiring a top human expert.\n\nThe study was led by three Stanford researchers — Justin Lin, Eliot Jones, and Donovan Jasper — whose work focuses on AI agents, cybersecurity, and machine-learning safety. The team created ARTEMIS after finding that existing AI tools struggled with long, complex security tasks.\n\nThe researchers gave ARTEMIS access to the university's network, consisting of about 8,000 devices, including servers, computers, and smart devices. Human testers were asked to put in at least 10 hours of work while ARTEMIS ran 16 hours across two workdays. The comparison with human testers was limited to the AI's first 10 hours.\n\nThe study also tested existing agents, which lagged behind most human participants, while ARTEMIS performed \"comparable to the strongest participants,\" the researchers said.\n\nWithin the 10-hour window, the agent discovered \"nine valid vulnerabilities with an 82% valid submission rate,\" outperforming nine of 10 human participants, the study said.\n\nSome of the flaws had gone unnoticed by humans, including a weakness on an older server that testers could not access because their browsers refused to load it. ARTEMIS bypassed the issue and broke in using a command-line request.\n\nThe AI worked in a way humans could not, the researchers said. Whenever ARTEMIS spotted something \"noteworthy\" in a scan, it spun up additional \"sub-agents\" to investigate in the background, allowing it to examine multiple targets simultaneously. Human testers had to do this work one step at a time.\n\nBut the AI isn't flawless. ARTEMIS struggled with tasks that required clicking through graphical screens, causing it to overlook a critical vulnerability. It is also more prone to false alarms, mistaking harmless network messages for signs of a successful break-in.\n\n\"Because ARTEMIS parses code-like input and output well, it performs better when graphical user interfaces are unavailable,\" the researchers said.\n\nAdvances in AI have lowered the barrier to hacking and disinformation operations, allowing malicious actors to enhance their attacks.\n\nIn September, a North Korean hacking group used ChatGPT to generate fake military IDs for phishing emails. A report from Anthropic in August found that North Korean operatives used its Claude model to obtain fraudulent remote jobs at US Fortune 500 tech companies — a tactic that gave them insider access to corporate systems.\n\nThe same report also said a Chinese threat actor used Claude to run cyberattacks on Vietnamese telecom, agricultural, and government systems.\n\n\"We are seeing many, many attacks,\" Yuval Fernbach, the chief technology officer of machine learning operations at software supply chain company JFrog, told Business Insider in a report published in April. He added that hackers have been using AI models to extract data, shut systems down, or manipulate a website or tools.",
    "readingTime": 3,
    "keywords": [
      "stanford researchers",
      "human testers",
      "human participants",
      "agent",
      "study",
      "hours",
      "devices",
      "humans",
      "hour",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-agent-hacker-stanford-study-outperform-human-artemis-2025-12",
    "thumbnail_url": "https://i.insider.com/693bccf004eda4732f2d6a8d?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.654Z",
    "topic": "science"
  },
  {
    "slug": "im-the-former-chief-ai-officer-at-gm-being-the-caio-is-like-being-the-master-chef-of-a-restaurant",
    "title": "I'm the former chief AI officer at GM. Being the CAIO is like being the master chef of a restaurant.",
    "description": "Barak Turovsky said that if a company wants to integrate AI on a software level, it needs someone with a different kind of expertise.",
    "fullText": "This as-told-to essay is based on a conversation with Barak Turovsky, the former Chief AI Officer at General Motors, based in Silicon Valley. He also held executive roles at Google and Cisco. The following has been edited for length and clarity.\n\nI have worked on AI and LLMs since 2014 — way before they became the hottest thing on Earth.\n\nI'm an ex-Google AI exec who led the first scaled deployment of LLMs and Deep Neural Networks with Google Translate. I also worked as the Chief Product and Technology Officer at a computer vision AI startup, and as the VP of AI at Cisco.\n\nGeneral Motors approached me for the Chief AI Officer role while I was at Cisco, and it felt like a great crash course on using AI to develop physical products. The role no longer exists because I left after GM restructured its software and AI organization; however, until November, I reported to the head of software engineering, who reported to the CEO.\n\nSome people ask, \"Do you really need a dedicated AI officer?\"\n\nLet's ignore the title because you can call it different names, but I do believe successful AI implementation requires someone in leadership to drive that change, as well as commitment from the top.\n\nFunctional business leaders, such as the CTO or CIO, may have little or no understanding of AI. If you want to integrate AI on a software level, you need someone with a different kind of expertise.\n\nTraditional large companies have powerful executives who want to own the benefits of scaling AI, but not necessarily the responsibility. Therefore, someone with deep AI knowledge is needed to direct the traffic.\n\nI like to use a restaurant analogy to break it down.\n\nThe analogy is based on three primary resources that create products, or dishes. The first resource includes the kitchen equipment, or the AI infrastructure and models necessary to build AI solutions.\n\nThe next can be thought of as the ingredients. It's the data or internal assets used to train and run AI solutions. The last one is talent, or the restaurant staff. You need expertise at different levels — busboys, short-order cooks, sous chefs, and master chefs for the really gourmet restaurants.\n\nThe complexity of creating the final product depends on the company's needs, specifically whether the restaurant needs to prepare the food internally. For very advanced, cutting-edge models, which can be thought of as the main course at a gourmet restaurant, companies often need to develop their own AI solutions because standard versions may not perform the required functions.\n\nThink of the CAIO as the master chef. They need to make sure all the different pieces run smoothly. If you are in an industry that requires cutting-edge solutions, you also need to spend a lot of time making sure that the hardest output — a.k.a. the main dish — comes out just right.\n\nThe hardest and most important part of the job is securing top talent. Vendors will tell you that their toaster ovens can pop out a French soufflé in 15 minutes. Yet your ingredients will consistently arrive late, of dubious quality, and in incorrect amounts. Your customers will come in, declare they are hungry and want to eat the whole menu, and then leave mid-meal without paying.\n\nThe specifics of each role vary. At GM, I worked on a cutting-edge area because AI for physical products, like cars, is largely untouched and getting a lot of traction.\n\nThere are three buckets of what a chief AI officer should do. First is AI talent management. I focused a lot on hiring a top-tier team, which is very important because the moment you enter a novel space, you have a small sliver of talent. They need to be motivated and flexible because you're still mapping out those areas.\n\nThen, you need to create a culture of innovation for the company in general. You need to work with internal stakeholders who might be used to doing things in a certain way, but need to change because of AI.\n\nYou also need to create organizational change, which starts with mapping the needs and players of your organization. You have people who are AI enthusiasts and skeptics. In a large organization, it's not always easy to identify them. You need to create a top-down and bottom-up framework, which includes clear goals from the top.\n\nIn every function, you need to identify champions, and you need to nurture and empower them. The CAIO can't do all the magic while everyone else just sits there.",
    "readingTime": 4,
    "keywords": [
      "physical products",
      "chief ai officer",
      "restaurant",
      "create",
      "solutions",
      "talent",
      "based",
      "role",
      "software",
      "organization"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/former-chief-ai-officer-general-motors-describes-role-2025-12",
    "thumbnail_url": "https://i.insider.com/6939ee6304d0f0a114f1ce51?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.547Z",
    "topic": "auto"
  },
  {
    "slug": "how-can-lawyers-stop-ais-hallucinations-more-ai-of-course",
    "title": "How can lawyers stop AI's hallucinations? More AI, of course.",
    "description": "Law firms can't stop lawyers from tinkering with chatbots, so they're adding hallucination detectors.",
    "fullText": "Law firm Cozen O'Connor has a rule against using publicly available chatbots to draft legal filings. But after a judge penalized two of its lawyers for citing fake cases, the firm is adding some extra protection: an AI hallucination detector.\n\nCozen O'Connor is now testing software, made by a startup called Clearbrief, that scans legal briefs for made-up facts and produces a report. Think spell-check, except instead of flagging typos, it spots the fictional cases and citations that generative tools sometimes invent.\n\n\"You have to be pragmatic,\" said Kristina Bakardjiev, the Cozen O'Connor partner tasked with harnessing technology to serve lawyers and their clients. She said lawyers will play around with chatbots whether the tools are authorized or not.\n\nStung by embarrassing AI hallucinations, the legal field has adopted bans on general-use chatbots and AI assistants. But it's hard to stop a curious associate from pasting a draft into a free, browser-based chatbot like ChatGPT, Claude, or Gemini. Now law firms and legal tech companies are scrambling to lower the risk of bogus citations and catch those that sneak through before they land in front of a judge.\n\nTwo of Cozen O'Connor's defense lawyers in September admitted they had filed a document riddled with fake cases after one of them used ChatGPT to draft it, against firm policy. A Nevada district court judge gave the firm a choice: remove the lawyers from the case and pay $2,500 in sanctions each, or have the pair write to their former law school deans and bar authorities explaining the fiasco and offering to speak in seminars on topics like \"professional conduct.\"\n\nBoth lawyers went with option No. 2. Cozen also fired the lawyer who had used ChatGPT.\n\nEarlier this year, Damien Charlotin, a legal data analyst and consultant, began tracking cases in which a court had discovered hallucinated content in a legal filing. Charlotin tallied 120 cases between April 2023 and May 2025. By December, his count had hit 660, with the rate of new cases accelerating to four or five per day.\n\nThe number of documented cases remains small relative to the total volume of legal filings, Charlotin said. Most cases in his database involved self-represented litigants or lawyers from small or solo firms. When large firms were involved, the hallucinations often slipped in through the work of junior staff, paralegals, experts, or consultants, or through processes like formatting footnotes, Charlotin said.\n\nHallucinated content is causing headaches in other professions, too. In October, consulting firm Deloitte agreed to pay a partial refund to the Australian government for a $290,000 report after officials found it was peppered with allegedly AI-generated errors.\n\nAI hallucinations are hard to eliminate because they're baked into the way chatbots work. Large language models are trained to predict the word that is most likely to come next, given the words before it.\n\nMichael Dahn, a senior vice president at Thomson Reuters who leads global product teams for legal-research service Westlaw, says the model makers can't get hallucinations to zero for answering open-ended questions about the world. However, companies can dramatically reduce their risk by forcing a large language model to cite from a specific data set, like a corpus of case law and treatises. The model can still mismatch or overlook content, but wholesale fabrications are far less likely.\n\nThomson Reuters and LexisNexis are selling that promise to customers: that an artificial assistant confined to their walled gardens of vetted material is safer than a chatbot trained on the open internet. Both companies have spent decades and heaps of money building deep repositories of case law and other legal content. More recently, they've bolted on AI-powered tools to help lawyers search and cite their data. They now have to defend their positions against services like ChatGPT and Claude that are creeping into the legal field.\n\nLexisNexis has also extended its moat to Harvey, the legal tech startup whose valuation has climbed to $8 billion. Harvey struck a partnership with LexisNexis this year that pipes one of the world's biggest legal databases into Harvey's generative tools.\n\nHarvey also works with AI model providers, such as OpenAI and Anthropic, to constrain which datasets they're allowed to draw from and layer in Harvey's own proprietary datasets, a spokesperson said. Lawyers can then inspect logs that show how an answer was reached and what data fed into it.\n\nClearbrief makes a drafting tool for litigators that works as a Microsoft Word plug-in. Jacqueline Schafer, a former litigator who founded Clearbrief, says its product detects citations using natural language processing, and creates links to the relevant case law or documents from the case. The tool calls out citations and facts that are fabricated or contain typos. The tool also points to places where the underlying source doesn't quite support what the writer claims.\n\nCozen O'Connor has been testing a new Clearbrief feature that lets users generate a cite-check report before passing a draft to a partner or filing it in court.\n\nSchafer says partners at large firms trust their junior staff to check citations rather than vetting every case themselves. Still, federal rules hold the partners who sign filings personally responsible for their accuracy.\n\nPart of Clearbrief's appeal for Cozen O'Connor is the paper trail. The firm is upgrading its knowledge management system, and Bakardjiev imagines that someday the firm might store cite-check reports alongside drafts and final filings, creating a chain of custody for every brief.\n\nIf a judge ever asks what a partner did to prevent hallucinated citations, Bakardjiev said, partners can point to a report that shows who ran the check and when.\n\nThe legal world is likely to live with hallucinations for a long time. The unglamorous part of the solution is training lawyers to treat the chatbot output as a starting point, not the finished work. The other answer: throwing more AI at the AI.\n\nHave a tip? Contact this reporter via email at mrussell@businessinsider.com or Signal at @MeliaRussell.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "junior staff",
      "generative tools",
      "hallucinated content",
      "fake cases",
      "legal field",
      "legal tech",
      "cozen o'connor",
      "legal filings",
      "lawyers",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lawyers-legal-tech-companies-fight-ai-chatgpt-hallucinations-2025-12",
    "thumbnail_url": "https://i.insider.com/693b4101832e0ef1ead6199f?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.418Z",
    "topic": "finance"
  },
  {
    "slug": "larry-ellison-just-lost-25-billion-of-his-net-worth-in-one-day",
    "title": "Larry Ellison just lost $25 billion of his net worth in one day",
    "description": "Larry Ellison saw his wealth plunge after Oracle's earnings miss spooked investors and raised fresh questions about the company's massive AI spending.",
    "fullText": "Larry Ellison just took a $25 billion hit to his net worth.\n\nThe Oracle cofounder saw billions wiped off his fortune on Thursday, according to estimates on Bloomberg's Billionaire Index, after the software giant's shares fell by more than 11% on weaker-than-expected earnings results.\n\nThe hit brought Ellison's net worth down to $258 billion, per the Index, marking one of the biggest single-day wealth drops of 2025.\n\nOther billionaires suffered steeper or similar losses in April: Elon Musk lost $35 billion in just three days, and Mark Zuckerberg shed about $24 billion as Trump's tariff plans sparked fears of retaliation and recession.\n\nEarlier this year, Ellison briefly took the crown of world's richest person, overtaking Musk in September when Oracle shares surged as much as 43% due to a strong forecast for its cloud business.\n\nOracle missed Wall Street's revenue expectations in its most recent earnings results, which were reported on Wednesday. Shares fell more than 11% in after-hours trading, extending a slide that began in October as investors questioned the company's breakneck spending on artificial intelligence infrastructure.\n\nDespite missing estimates, revenue was up 14% year-over-year during the quarter. But that wasn't enough to calm concerns over the scale and cost of its expansion.\n\nThose worries dominated Wednesday's call with analysts.\n\nClay Magouyrk, Oracle's co-CEO, pushed back on fears that the company might need more than $100 billion to build out its data centers — a figure some analysts had floated.\n\n\"We expect we will need less, if not substantially less, money raised than that,\" he said, adding that Oracle's debt remains \"investment-grade.\"\n\nEven after Thursday's plunge, the Bloomberg Billionaires Index shows that Ellison's net worth still remains ahead of most tech titans, including Jeff Bezos and Mark Zuckerberg.",
    "readingTime": 2,
    "keywords": [
      "ellison's net",
      "net worth",
      "estimates",
      "earnings",
      "fears",
      "revenue",
      "analysts",
      "less",
      "oracle",
      "index"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/larry-ellison-loses-25-billion-net-worth-oracle-stock-plunge-2025-12",
    "thumbnail_url": "https://i.insider.com/693bea72832e0ef1ead61d19?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.417Z",
    "topic": "finance"
  },
  {
    "slug": "disneys-ai-ambitions-are-a-hail-mary-for-the-companys-stock-after-a-lost-decade",
    "title": "Disney's AI ambitions are a Hail Mary for the company's stock after a lost decade",
    "description": "Disney's OpenAI deal comes at a time when the stock is essentially flat over the past 10 years, while the S&P 500 has soared 236%.",
    "fullText": "Things Disney has accomplished in the past 10 years:\n\nThings it hasn't accomplished over the same period:\n\nThis may seem like a wild stat. After all, the S&P 500 is up a whopping 236% over the past decade. But it's true: Disney shares are basically dead flat during the stretch.\n\nFrom a market perspective, the last 10 years have been a total wash.\n\nThe chart above — which looks at Disney's stock versus the benchmark S&P 500 — shows that the key divergence happened in early 2021, which marked Disney's last record high.\n\nThe company has faced a few main headwinds since that top:\n\nAfter Disney+ got off to a fast start, user growth eventually stalled out and prolonged the service's winding path to profitability. The company has also grappled with ESPN's increasingly online audience in the era of cord-cutting, which has contributed to contentious negotiations with TV carriers. (To be fair, all legacy media companies are dealing with the same issues.)\n\nMissing the mark on original content\n\nPixar movies used to be an absolute slam dunk at the box office. No longer. Viewers are also getting fatigued by the constant stream of reboots and sequels. And yes, Disney still has Marvel and Star Wars, although those have lost steam as well. (Note that a similar slowdown has been seen for movie studios overall.)\n\nDisney has caught flak in recent years over the prices at its parks. CEO Bob Iger even admitted in 2023 that the company had been \"too aggressive\" with price hikes. While parks remain a source of relative strength for the company, their cost has left them vulnerable to downturns in consumer sentiment.\n\nWhich brings us to Disney's latest big swing: a $1 billion investment in OpenAI that will integrate iconic characters into the AI video platform Sora. It's notable that Disney is the first major non-tech company to partner with OpenAI.\n\nUpon first glance, the deal feels like a desperate move from a company that's underperformed for a long stretch. But analysts at Citi see it differently.\n\nJason Bazinet, who has a \"buy\" rating on Disney's stock, lauded it as a defensive move, intended to protect the value of the company's IP from cannibalization. He sees it helping to sustain long-term brand value, while also giving it long-term upside in AI. Iger made similar points in defense of the deal.\n\nWe'll see over time if this AI team-up is a catalyst for a grand stock comeback — and if it's a model other companies follow.",
    "readingTime": 3,
    "keywords": [
      "disney's stock",
      "accomplished",
      "stretch",
      "parks",
      "deal",
      "long-term",
      "disney",
      "it's",
      "iger",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-opeani-sora-ai-video-deal-stock-price-returns-streaming-2025-12",
    "thumbnail_url": "https://i.insider.com/693b723f04eda4732f2d693a?width=1024&format=jpeg",
    "created_at": "2025-12-12T13:47:21.416Z",
    "topic": "finance"
  },
  {
    "slug": "disney-just-picked-a-side-in-the-ai-fight",
    "title": "Disney just picked a side in the AI fight",
    "description": "Companies face a big question: Are AI companies friend or foe?",
    "fullText": "Mickey Mouse … brought to you by OpenAI.\n\nDisney lending out its iconic characters to be leveraged by AI seemed a far-fetched idea a few months ago. But thanks to a $1 billion deal between the House of Mouse and OpenAI, that's exactly what's happening.\n\nIt's representative of a larger question companies, especially those in media and entertainment, are grappling with: Are AI companies friend or foe?\n\nFor Bob Iger, the answer is very much friend.\n\n\"It gives us an opportunity, really, to play a part in what is really a breathtaking, breathtaking growth in essentially AI and new forms of media and entertainment,\" the Disney CEO told CNBC on Thursday.\n\nThe deal will allow Disney+ to post users' AI-generated content, a goal that Iger mentioned last month. Doing so could help boost engagement on the streamer's platform, which has been stagnant in recent years, writes BI's Lucia Moses.\n\n(I should probably mention Axel Springer, Business Insider's parent company, also falls in the \"friend\" camp. It cut a deal with OpenAI almost two years ago.)\n\nOthers aren't as willing to rub shoulders with OpenAI. The startup has a history of using someone's intellectual property without permission and then apologizing for it. That has resulted in several lawsuits, including those from The New York Times and \"Game of Thrones\" author George R.R. Martin.\n\nSo who's right? It's too early to say, but it could easily go both ways.\n\nThe longer one waits to cut a deal with an AI company, the worse the terms could be. (The benefits of first-mover advantage.) On the other hand, opening yourself up to AI could be a kind of Pandora's box you can't close.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nThe deal isn't just beneficial to Disney.\n\nDisney characters coming to Sora 2 could be a big boost for a video platform that hit a bit of a lull after a hot start a few months ago.\n\nBringing characters from \"Frozen\" and \"Moana\" to life on your app is also a great way to generate interest and build loyalty with a younger audience. OpenAI CEO Sam Altman recently touted the personal benefits he finds from using ChatGPT as a new parent.\n\nBut pursuing a younger demographic also comes as some countries are putting up more guardrails around kids' use of tech. Australia recently installed a ban on social media for anyone under the age of 16.\n\nThe Disney-OpenAI deal also comes as competition keeps mounting against the startup from the likes of Google and others. And while so much of AI is about pushing cutting-edge tech, sometimes you just need a little bit of old-school magic.",
    "readingTime": 3,
    "keywords": [
      "cut deal",
      "media",
      "characters",
      "friend",
      "tech",
      "it's",
      "entertainment",
      "breathtaking",
      "boost",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-newsletter-disney-openai-iger-altman-pick-side-2025-12",
    "thumbnail_url": "https://i.insider.com/693c13f8832e0ef1ead61e4c?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.275Z",
    "topic": "finance"
  },
  {
    "slug": "openai-opens-internal-merch-store-to-the-public",
    "title": "OpenAI opens internal merch store to the public",
    "description": "Explore curated, brand-designed pieces that reflect our vision, milestones, and creative spirit.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://supply.openai.com",
    "thumbnail_url": "https://supply.openai.com/4f4692867bef.png",
    "created_at": "2025-12-12T06:59:22.638Z",
    "topic": "tech"
  },
  {
    "slug": "smart-photo-finder-semantic-photo-search-not-filename100-local-ai",
    "title": "Smart Photo Finder – Semantic photo search, not filename(100% local AI)",
    "description": "Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings. - Pankaj4152/smart-photo-finder",
    "fullText": "Pankaj4152\n\n /\n\n smart-photo-finder\n\n Public\n\n Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings.\n\n License\n\n MIT license\n\n 8\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Pankaj4152/smart-photo-finder",
    "readingTime": 1,
    "keywords": [
      "tags",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Pankaj4152/smart-photo-finder",
    "thumbnail_url": "https://opengraph.githubassets.com/81d5523cc4100fc11914eb2cbf0dd607dd9f154cfd39d73fb291f9b8d45c820a/Pankaj4152/smart-photo-finder",
    "created_at": "2025-12-12T06:59:05.582Z",
    "topic": "tech"
  },
  {
    "slug": "ai-voice-cloning",
    "title": "AI Voice Cloning",
    "description": "Transform your voice into limitless possibilities with instant AI voice cloning. Create professional audiobooks, podcasts, marketing content, and multilingual content in seconds. High-quality voice synthesis with natural expressiveness and emotional depth.",
    "fullText": "Experience premium AI voice cloning with just 3 seconds of audio!\nPerfectly captures every detail of the original voice, maintaining natural expressiveness, emotional depth, and personal speaking style. Easily clone anyone's voice with simple and efficient voice cloning technology.\n\nListen to real examples of AI-cloned voices. Each voice demonstrates the natural quality and expressiveness of our technology.\n\nClone any voice in seconds—while keeping it natural with realistic tone and speaking pace. Simple workflow, instant results.\n\nCreate your unique AI voice in seconds. With instant voice cloning, you can recreate your voice and any voice you love in just a few seconds.\n\nDiscover how AI voice cloning revolutionizes content creation, communication, and engagement across industries—all in seconds, not hours.\n\nTransform your written words into captivating audiobooks with your authentic voice. Create professional podcasts instantly—no more marathon recording sessions. Your unique voice and style, preserved perfectly, ready to engage audiences worldwide.\n\nLaunch campaigns faster than ever. Create compelling video ads and product announcements with your voice—anytime, anywhere. Skip the studio, slash production costs by up to 80%, and maintain that professional edge your brand deserves.\n\nLead with your voice, scale with AI. Deliver personalized messages to global teams in your authentic voice, ensuring every update feels personal and consistent. Transform how leaders connect with their organizations—effortlessly and instantly.\n\nBreak language barriers without learning a word. Your voice speaks every language naturally, reaching global audiences with authentic accents and local nuances. Make your content feel native in any market—from Tokyo to New York.\n\nElevate training with familiar voices that boost engagement. Create impactful learning materials using voices your team knows and trusts. Watch retention rates soar as learners stay focused, remember more, and enjoy a seamless learning experience.\n\nDeliver personalized support at scale. Connect with customers in your voice, speaking their language—literally. Build deeper relationships, increase satisfaction scores, and create memorable experiences that turn customers into advocates.\n\nWe've compiled answers to the most common questions about AI voice cloning technology.\n\nGetting started is incredibly simple! Visit our AI voice cloning platform and either upload an audio file or record a 10-second sample directly in your browser. Within seconds, our advanced AI will generate your custom voice clone—no technical expertise required.\n\nYes! Paid users have full commercial rights to use generated voices in their projects. Free users are limited to personal, non-commercial use. Always ensure you have proper authorization when cloning someone else's voice, and comply with applicable laws and regulations.\n\nOur AI voice cloning models are expertly trained to support English, Chinese (Mandarin), Japanese, and Korean with natural pronunciation and authentic intonation. Each language maintains the unique characteristics and nuances of native speakers.\n\nFor best results, we recommend 10-300 seconds of clear, single-speaker audio with normal speech pace and minimal background noise. A standard smartphone recording works perfectly—no professional equipment needed!\n\nWe're committed to ethical AI use. Please do not use our technology for impersonation, fraud, hate speech, or spam. When cloning someone else's voice, always respect copyright laws and obtain proper consent.\n\nFree users enjoy slower generation speeds, perfect for trying out the technology. Paid subscribers get unlimited generation time with priority processing, ensuring your voice clones are ready when you need them—ideal for professional workflows.\n\nNot yet, but we're actively developing programmatic access to our AI voice cloning service. Stay tuned for updates—we're planning to launch our API soon to enable seamless integration into your applications and workflows.\n\nWe're here to help! Reach out to our support team at [email protected]. We aim to respond within one business day, ensuring you get the assistance you need quickly and efficiently.\n\nAbsolutely! Once your voice clone is generated, you can download it in high-quality MP3 or WAV format. Use it in any project—from podcasts and audiobooks to marketing campaigns and training materials.\n\nYes! We currently support voice style customization, allowing you to fine-tune the characteristics of your cloned voice to match your specific needs and preferences.",
    "readingTime": 4,
    "keywords": [
      "deliver personalized",
      "free users",
      "someone else's",
      "cloning someone",
      "cloning technology",
      "else's voice",
      "authentic voice",
      "seconds",
      "create",
      "natural"
    ],
    "qualityScore": 1,
    "link": "https://aivoicecloning.net",
    "thumbnail_url": "https://aivoicecloning.net/og-image.png",
    "created_at": "2025-12-12T06:59:04.340Z",
    "topic": "tech"
  },
  {
    "slug": "openai-launches-gpt52-ai-model-with-improved-capabilities",
    "title": "OpenAI launches GPT-5.2 AI model with improved capabilities",
    "description": "OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman reportedly issued an internal \"code red\" in early December pausing non‑core projects and",
    "fullText": "Dec 11 (Reuters) - OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman ​reportedly issued an internal \"code red\" in early ‌December pausing non‑core projects and redirecting teams to accelerate development in ‌response to Google's Gemini 3.\n\nGPT-5.2 comes with improvements in general intelligence, coding and long-context understanding, the company said in a statement.\n\nThe new model is expected to bring even ⁠more economic value for ‌users, as it is better at creating spreadsheets, building presentations and handling complex multi-step ‍projects, OpenAI said.\n\nAlphabet's Google launched the latest version of its Gemini in November, highlighting Gemini 3's lead position on several ​popular industry leaderboards that measure AI model performance.\n\n\"Gemini ‌3 has had less of an impact on our metrics than we feared,\" Altman said in an interview with CNBC on Thursday, alongside Disney CEO Bob Iger.\n\nDisney said on Thursday it is investing $1 billion in ⁠OpenAI and will let the ​startup use characters from Star Wars, ​Pixar and Marvel franchises in its Sora AI video generator.\n\nMicrosoft-backed OpenAI said that it currently ‍has no ⁠plans to deprecate GPT‑5.1, GPT‑5, or GPT‑4.1 in the API.\n\nGPT-5.2 Instant, Thinking, and Pro will begin ⁠rolling out in ChatGPT on Thursday, beginning with paid plans.",
    "readingTime": 2,
    "keywords": [
      "model",
      "launched",
      "intelligence",
      "projects",
      "disney",
      "plans",
      "openai",
      "gemini",
      "altman"
    ],
    "qualityScore": 0.85,
    "link": "https://tech.yahoo.com/ai/chatgpt/articles/openai-launches-gpt-5-2-185713739.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/53E953B72061EAD331E14221749904B05C017BE83D84CD2331F3FA5A9D9F4632/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fmedia.zenfs.com%2Fen%2Freuters.com%2Fdec31ed411aedabd7e3231dabf2dd50f",
    "created_at": "2025-12-12T06:59:01.415Z",
    "topic": "tech"
  },
  {
    "slug": "big-short-investor-michael-burry-says-there-is-no-way-to-time-or-predict-when-the-ai-bubble-will-burst",
    "title": "'Big Short' investor Michael Burry says there is 'no way to time or predict' when the AI bubble will burst",
    "description": "In a lengthy blog post, Bury advised against attempting to short the current AI bubble and said the bubble may grow even larger.",
    "fullText": "If you're waiting for Michael Burry to tell you when the AI bubble will burst, don't hold your breath.\n\nIn Burry's new post on his Substack, the famed \"Big Short\" investor said that there \"is no way to time or predict\" the bubble pop, especially when the bubble may still have room to grow.\n\n\"Shorts are almost always short-term trades. Usually less than a year, maybe a couple years at most,\" wrote Burry. \"Not 5 years, not 10 years.\"\n\n\"I believe today the stock market is in a phase that could become a blow off top of extreme magnitude on the upside, while at any time, maybe even today or tomorrow, making a generational top,\" Burry added.\n\nIn the lengthy blog post, Burry answered reader questions on his earlier posts. He argued that there is \"supply-side gluttony,\" meaning massive data-center build-outs, GPU orders, and multibillion-dollar commitments without real end-user demand, which investors are mistaking for supply-chain activity. He attributed much of the hype to being driven by Nvidia CEO Jensen Huang's marketing.\n\n\"Even when it finally tops, it will not be for any specific reason,\" Burry said later in the post. \"Even if the reason is an AI buildout bubble popping, that will likely not be apparent until a year or two later.\"\n\n\"Mostly, it is prudent neither to short stocks nor to buy puts on stocks. Stocks that are obviously overvalued tend to have the most upward momentum yet have puts that are very expensive,\" Burry added.\n\nNvidia did not immediately respond to a request for comment about Burry's latest digs.\n\nIn November, Burry launched a paywalled Substack called Cassandra Unchained. After posting charts on X that show circulatory investment deals between Nvidia and other tech giants, his first post took aim at Nvidia. He called the chipmaking giant \"a Cisco\" in the AI bubble debate, referring to the internet-networking giant whose stock plunged by over 75% during the dot-com crash.\n\nNvidia released a note to Wall Street analysts in late November, pushing back against some of Burry's claims.\n\nEarlier in November, during Nvidia's Q3 earnings call, the CEO addressed concerns about the AI bubble.\n\n\"From our vantage point, we see something very different,\" Huang told investors, \"We excel at every phase of AI, from pre-training and post-training to inference.\"",
    "readingTime": 2,
    "keywords": [
      "bubble",
      "stocks",
      "burry",
      "substack",
      "stock",
      "phase",
      "earlier",
      "investors",
      "later",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/michael-burry-big-short-ai-bubbles-burst-cannot-be-predicted-2025-12",
    "thumbnail_url": "https://i.insider.com/69160ab489026fbb4d0d9600?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.758Z",
    "topic": "finance"
  },
  {
    "slug": "what-smart-people-are-saying-about-disneys-licensing-deal-with-openai",
    "title": "What smart people are saying about Disney's licensing deal with OpenAI",
    "description": "OpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property.",
    "fullText": "It's likely just a matter of time before we see the wisened duo of Rafiki and Jiminy Cricket weilding lightsabers on the icy plains of Arendelle.\n\nThat's courtesy of artificial intelligence, of course, and a new deal between Disney and OpenAI.\n\nOpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property. Disney will also invest $1 billion in OpenAI and will purchase ChatGPT Enterprise for its employees.\n\nIt's a major shift for Disney, which has historically been deeply protective of its intellectual property. And it's a big win for OpenAI, which is on a quest for more content to feed its AI models.\n\nFor users, the deal will enable them to recreate Disney characters on Sora, OpenAI's short-form video generation app, and to create images of Disney characters using ChatGPT.\n\nBeyond the limitless possibilities for creative content, the deal reveals a lot about Disney's strategy in the AI age and the impact of artificial intelligence on the future of entertainment.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nFor Nick Cicero, the founder of Delmondo, a social media video analytics company that was acquired by Conviva in 2018, Disney's deal with OpenAI is less about AI and more about revenue.\n\nCicero argued in an X post on Thursday that Disney was aiming to solve two \"existential\" problems: creators using unauthorized Disney content and kids watching YouTube instead of Disney+.\n\n\"Sora gives Disney its first scalable way to pull creator-made content into its own premium ecosystem — brand-safe, trackable, legal, and ready for CTV monetization,\" he said, referring to the practice of delivering targeted advertising to internet-connected televisions.\n\n\"This move isn't about tech,\" he added. \"It's about revenue physics.\"\n\nChatbots like ChatGPT rely on data to power their outputs, and when it comes to collecting that data, AI companies are insatiable.\n\nThe drive to collect data often pits AI companies against content creators. Numerous media companies have sued OpenAI, Anthropic, Perplexity, and other leading AI outfits for using their copyrighted content without permission. Other media companies, like Business Insider's parent company, Axel Springer, have struck deals with AI companies to license their content.\n\nPeter Csathy, a longtime media consultant and analyst, said Disney's deal with OpenAI is a \"watershed\" moment for AI and media licensing.\n\n\"Now THIS is a generative AI use that makes sense to me and I support,\" Csathy wrote on LinkedIn. \"Fully licensed characters, thereby respecting copyright and embracing partnership with the creative community (rather than theft of IP). New revenue streams for IP rights-holders. And overall delight by fans of those beloved characters.\"\n\nThere are just so many cease-and-desist letters a media lawyer can send.\n\nCarline Giegerich, a vice president at the Interactive Advertising Bureau who once led emerging tech at HBO, says Disney's deal with OpenAI feels like a \"can't beat 'em, join 'em\" moment.\n\n\"When I was at HBO from '05 - '09, I marveled at the sheer volume of cease and desists from the legal team when mobile video was up and coming,\" she wrote on LinkedIn. \"I thought it seemed difficult to fight against the entire internet, and it turns out it was. And AI presents a similar challenge.\"\n\nShe also said the deal presents a valuable marketing opportunity for Disney.\n\n\"Important to note that a selection of these fan-created videos will be available to stream on Disney+. What that means to me is that Disney sees this also as a marketing and content opportunity, which it is,\" she said.\n\nDisney's pivot from aggressively defending its IP at every turn to giving it over to the world's leading AI startup might be strategic for another reason.\n\nJames Miller, the head of business development at Amazon for media, entertainment, and Amazon Creators, said he suspects it's a matter of \"controlling the inevitable.\"\n\nAny IP eventually enters the public domain. In 2024, the copyright for Mickey Mouse himself — at least the sans white gloves version of the 1930s — expired, allowing anyone to use his likeness. Winnie the Pooh, Snow White, Cinderella, and a handful of other Disney characters also entered the public domain at the same time.\n\n\"By officially licensing these characters now, Disney does three things,\" Miller wrote on LinkedIn. \"1. Monetizes the AI trend rather than just fighting it in court. 2. Sets the quality standard for how their characters appear in AI video (likely drowning out lower-quality unauthorized versions). 3. Captures data on how fans want to use their IP before they lose exclusive rights.\"\n\nOne consumer expert said that Disney might have gotten the short end of the stick in this partnership.\n\n\"Looks like OpenAI used the #jedimindwarp on The Walt Disney Company, not the other way around,\" Karl Haller, an IBM partner and the leader of the firm's Consumer Center of Competency, said in a post on LinkedIn.\n\nHe said he was \"more than a bit surprised\" to see that Disney is letting OpenAI license its IP for Sora and other AI tools, with some of the videos being made available to stream on Disney+.\n\n\"And what does Disney receive for this? Negative $1 billion,\" he wrote. \"Rather than receiving a heftly license fee, Disney is instead investing $1B in OpenAI and receiving warrants to buy \n\nOne entertainment lawyer pointed out that the deal comes with a lot of unanswered questions.\n\n\"This is a fairly stunning story all round with many questions,\" Simon Pullman, a partner at law firm Pryor Cashman, wrote on LinkedIn on Thursday.\n\n\"Will audiences want/accept 'AI UGC' on Disney Plus,\" he wrote, referring to user-generated content. \"Will it be possible for Disney to unring the bell after three years and not extend the license? How will they protect against misuse and brand damage?\"\n\nDisney's $1 billion bet on AI is the right move for the media giant, according to Mike Walsh, the CEO of consulting firm Tomorrow.\n\n\"By partnering with OpenAI while suing Midjourney and warning Google, Disney is drawing a clear line,\" Walsh wrote on LinkedIn on Thursday. \"Remix culture isn't going away, but it will be licensed, governed, and designed on its terms.\"\n\nHe added that Disney has always survived new media eras with this strategy.\n\n\"The future of entertainment belongs to companies that shape participation instead of fighting it,\" he wrote.",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "intellectual property",
      "disney's deal",
      "disney characters",
      "media",
      "content",
      "it's",
      "entertainment",
      "license",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-deal-openai-ai-sora-chatgpt-ip-analysis-2025-12",
    "thumbnail_url": "https://i.insider.com/693b9675832e0ef1ead61c15?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.725Z",
    "topic": "finance"
  },
  {
    "slug": "softbanks-son-eyes-data-center-group-switch-to-expand-in-ai",
    "title": "SoftBank’s Son Eyes Data Center Group Switch to Expand in AI",
    "description": "SoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.",
    "fullText": "TechnologyAIBy Josh Sisco, Taro Fuse, Ryan Gould, and Min-Jeong LeeSaveSoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.The Japanese company has held discussions with Switch leadership and has been conducting due diligence on the closely held company, the people said, asking not to be identified because the information is private. SoftBank also has been in advanced talks on a potential purchase of one of Switch’s main private equity backers, New York-listed investment firm DigitalBridge Group Inc., Bloomberg News reported last week.",
    "readingTime": 1,
    "keywords": [
      "potential",
      "switch"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/softbank-eyes-data-center-group-switch-as-son-hunts-for-ai-plays",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iWJI72I4iN30/v0/1200x800.jpg",
    "created_at": "2025-12-12T03:55:20.050Z",
    "topic": "finance"
  },
  {
    "slug": "lmarena-is-a-cancer-on-ai",
    "title": "LMArena Is a Cancer on AI",
    "description": "Would you trust a medical system whose only metric was “which doctor wins the Internet?” No, you'd call that malpractice. Yet that's LMArena.",
    "fullText": "Would you trust a medical system measured by: which doctor would the average Internet user vote for?\n\nYet that malpractice is LMArena.\n\nThe AI community treats this popular online leaderboard as gospel. Researchers cite it. Companies optimize for it and set it as their North Star. But beneath the sheen of legitimacy lies a broken system that rewards superficiality over accuracy.\n\nIt's like going to the grocery store and buying tabloids, pretending they're scientific journals.\n\nHere's how LMArena is supposed to work: enter a prompt, evaluate two responses, and mark the best. What actually happens: random Internet users spend two seconds skimming, then click their favorite.\n\nThey're not reading carefully. They're not fact-checking, or even trying.\n\nThis creates a perverse reward structure. The easiest way to climb the leaderboard isn't to be smarter; it’s to hack human attention span. We’ve seen over and over again in the data, both from datasets that LMArena has released and the performance of models over time, that the easiest way to boost your ranking is by:\n\nIt doesn't matter if a model completely hallucinates. If it looks impressive – if it has the aesthetics of competence – LMSYS users will vote for it over a correct answer.\n\nWhen you optimize for engagement metrics, you get madness.\n\nEarlier this year, Meta tuned a version of Maverick to dominate the leaderboard. If you asked it “what time is it?”, you got:\n\nVoilà: bold text, emojis, and plenty of sycophancy – every trick in the LMArena playbook! – to avoid answering the question it was asked.\n\nIt wasn't just Maverick. We analyzed 500 votes from the leaderboard ourselves. We disagreed with 52% of them, and strongly disagreed with 39%.\n\nThe leaderboard optimizes for what feels right, not what is right. Here are two emblematic examples of LMArena users punishing factual accuracy:\n\nIn the world of LMArena, confidence beats accuracy and formatting beats facts.\n\nInstead of rigorous evaluators, we have people with the attention span of the average TikTok user determining which AI models shape the industry.\n\nWhy is LMArena so easy to game? The answer is structural.\n\nThe system is fully open to the Internet. LMArena is built on unpaid labor from uncontrolled volunteers. There's no incentive for those volunteers to be thoughtful. No quality control. No one gets kicked off for repeatedly failing to detect hallucinations.\n\nWhen LMArena’s leaders speak publicly, they talk about the various techniques they use to overcome the fact that their input data is low quality. They admit their workers prefer emojis and length over substance. So the LMArena system, they proudly tell us, includes a variety of corrective measures.\n\nThey're attempting alchemy: conjuring rigorous evaluation out of garbage inputs.\n\nBut you can't patch a broken foundation.\n\nWhen the entire industry optimizes for a metric that rewards “hallucination-plus-formatting” over accuracy, we get models optimized for hallucination-plus-formatting.\n\nThis isn't a minor calibration problem. It's fundamental misalignment between what we're measuring and what we want: models that are truthful, reliable, and safe.\n\nThe AI industry needs rigorous evaluation. We need leaders who prioritize accuracy over marketing. We need systems that can't be gamed by bolding more aggressively.\n\nLMArena is none of these things. And as long as we pretend it is, we're dragging the entire field backward.\n\nPeople often say they can’t avoid LMArena.\n\n\"We have to optimize for it. We have to sell our models. The leaderboard shows customers which model is best, and we have to play the game.\"\n\nBut the best products have principles they stick to.\n\nThis is the brutal choice every model builder must eventually make:\n\nThe choice is real. It’s hard. But we’ve seen some frontier labs hold the line.\n\nThey stuck to their values. They ignored the gamified rankings. And users loved their models anyway – because hype eventually dies and quality is the only metric that survives the cycle.\n\nYou are your objective function. Which path will each lab choose?",
    "readingTime": 4,
    "keywords": [
      "attention span",
      "rigorous evaluation",
      "leaderboard",
      "models",
      "accuracy",
      "system",
      "they're",
      "users",
      "lmarena",
      "optimize"
    ],
    "qualityScore": 1,
    "link": "https://surgehq.ai/blog/lmarena-is-a-plague-on-ai",
    "thumbnail_url": "https://cdn.prod.website-files.com/68dcd2ceb173c46fa029931c/69385c394b4cc2e3cad4c7bf_lmarena.jpg",
    "created_at": "2025-12-12T03:50:33.457Z",
    "topic": "tech"
  },
  {
    "slug": "how-well-do-llms-understand-tunisian-arabic",
    "title": "How Well Do LLMs Understand Tunisian Arabic?",
    "description": "Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to any tool that can act intelligently. Yet, the ability of industrial-scale LLMs to comprehend low-resource languages, such as Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding millions of Tunisians from fully interacting with AI in their own language, pushing them toward French or English. Such a shift not only threatens the preservation of the Tunisian dialect but may also create challenges for literacy and influence younger generations to favor foreign languages.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2511.16683",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2025-12-12T03:50:33.276Z",
    "topic": "tech"
  },
  {
    "slug": "creativity-is-the-new-productivity-bob-iger-on-why-disney-chose-to-be-aggressive-adding-openai-as-a-1-billion-partner",
    "title": "‘Creativity is the new productivity’: Bob Iger on why Disney chose to be ‘aggressive,’ adding OpenAI as a $1 billion partner",
    "description": "\"We'd rather participate in the rather dramatic growth, rather than just watching it happen and essentially being disrupted by it,\" Iger told CNBC.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/iger-altman-disney-openai-1-billion-creativity-new-productivity/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247523490-e1765480919303.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.446Z",
    "topic": "business"
  },
  {
    "slug": "were-not-just-going-to-want-to-be-fed-ai-slop-for-16-hours-a-day-analyst-sees-disneyopenai-deal-as-a-dividing-line-in",
    "title": "‘We’re not just going to want to be fed AI slop for 16 hours a day’: Analyst sees Disney/OpenAI deal as a dividing line in entertainment history",
    "description": "\"​I think the reason this bidding is approaching $100 billion-plus is the content library and the potential to do a Disney-OpenAI type of deal.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/pre-post-ai-content-disney-openai-netflix-warner-slop-analysis-ark-invest/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2197501075-e1765490752485.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.299Z",
    "topic": "business"
  },
  {
    "slug": "backflips-are-easy-stairs-are-hard-robots-still-struggle-with-simple-human-movements-experts-say",
    "title": "Backflips are easy, stairs are hard: Robots still struggle with simple human movements, experts say",
    "description": "Yet the next generation of robots will soon be able to learn from experience, creating more adaptable machines—perfect for the home and the factory, according to speakers at Fortune's Brainstorm AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/backflips-are-easy-stairs-are-hard-humanoid-robots-challenges-potential-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974565481_750d2f2870_o-e1765436658770.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.141Z",
    "topic": "business"
  },
  {
    "slug": "the-race-to-deploy-an-ai-workforce-faces-one-important-trust-gap-what-happens-when-an-agent-goes-rogue",
    "title": "The race to deploy an AI workforce faces one important trust gap: What happens when an agent goes rogue?",
    "description": "There’s a great deal of enthusiasm around AI agents, but as panelists discussed at Fortune's Brainstorm AI, there are still a lot of questions too.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/ai-agent-workforce-adoption-trust-risks-challenges/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974710070_1c221b6e5c_o-e1765429238911.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.060Z",
    "topic": "business"
  },
  {
    "slug": "highlights-from-fortune-brainstorm-ai-san-francisco",
    "title": "Highlights from Fortune Brainstorm AI San Francisco",
    "description": "From deep dives into the enterprise deployment of agents to explorations of the new geography of data centers, Brainstorm AI provided a valuable snapshot of the AI landscape at the close of the year.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/highlights-from-fortune-brainstorm-ai-san-francisco/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974738463_5208876430_6k-e1765490981222.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.051Z",
    "topic": "business"
  }
]
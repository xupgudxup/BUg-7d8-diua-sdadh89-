[
  {
    "slug": "it-brings-you-closer-to-the-natural-world-the-rise-of-the-merlin-birdsong-identifying-app",
    "title": "‘It brings you closer to the natural world’: the rise of the Merlin birdsong identifying app",
    "description": "Merlin has been trained to identify the songs of more than 1,300 bird species around the world\nWhen Natasha Walter first became curious about the birds around her, she recorded their songs on her phone and arduously tried to match each song with online recordings. After a friend recommended Merlin Bird ID, a free app, she tried it in her London garden and was delighted to discover the birds she assumed were female blackbirds – “this is how bad a birder I was” – were actually song thrushes and mistle thrushes.\n“I’m obsessed with Merlin – it’s wonderful and it’s been a joy to me,” says Walter, a writer and human rights activist. “This is what AI and machine-learning have been invented for. It’s the one good thing!",
    "fullText": "Merlin has been trained to identify the songs of more than 1,300 bird species around the world\n\nWhen Natasha Walter first became curious about the birds around her, she recorded their songs on her phone and arduously tried to match each song with online recordings. After a friend recommended Merlin Bird ID, a free app, she tried it in her London garden and was delighted to discover the birds she assumed were female blackbirds – “this is how bad a birder I was” – were actually song thrushes and mistle thrushes.\n\n“I’m obsessed with Merlin – it’s wonderful and it’s been a joy to me,” says Walter, a writer and human rights activist. “This is what AI and machine-learning have been invented for. It’s the one good thing!”\n\nMerlin is having a moment. The app, developed by the Cornell Lab of Ornithology in New York, which listens for birdsong and identifies the species singing, has been downloaded 33m times, in 240 countries and territories around the world. Britain has the second highest total number of users – more than 1.5 million in 2024, an 88% increase from 2023. Every month, there has been a 30% increase in new users of the app, whose sound identification function was launched in 2021.\n\nMerlin has been trained to identify the songs of more than 1,300 species around the world, with more birds added twice a year. Different songs make distinct patterns on spectrograms and Merlin is trained to recognise these different shapes and attribute them to a species.\n\nFor latecomers to birding, or those lacking a knowledgeable friend, the app has become their teacher. “My fear at first was I wouldn’t actually learn because I’m outsourcing my understanding of birds to this app,” says Walter. “But that hasn’t come to pass. It’s helped me continue my journey of learning.” Nowadays, she guesses, and uses Merlin to confirm her hunches. “It’s wonderful if you’re coming to bird-watching late and don’t really have a mentor,” she says.\n\nAngela Townsend from Bedfordshire began using Merlin after going on a nightingale walk one spring and being overwhelmed by the range of bird-voices in the evening chorus. She has found it has steadily built up her bird knowledge. “Warblers were just little brown jobbies but I can now recognise Cetti’s warblers and willow warblers when I’m out without having to put the app on,” she says.\n\nMary Novakovich, author of My Family and Other Enemies, is another recent adopter. She has found it particularly useful when travelling across Croatia, where her parents are from. “I love putting a name to a face and a name to the sound,” she says. “It really brings you closer to the natural world, rather than it being disconnected from your life. It’s part of what makes life a joy.”\n\nMerlin is not flawless, however. The first time Kasper Wall, 12, tried it in his Norfolk garden, it detected a northern cardinal and a brown-headed cowbird – North American species not found in Britain.\n\n“I think it was figuring out where we live,” says Wall, who enjoys using it even though he is now an extremely knowledgeable birder. “A couple of weeks ago we were looking at a large group of goldcrest and it came up with a firecrest. I thought, ‘Oh, there must be a firecrest in here too’ and 30 seconds later we saw one, which was the first I’d ever seen. I like it and it’s very good but I wouldn’t say that it’s better than the best people at identifying bird-calls like [the naturalist] Nick Acheson. It can definitely be fooled.”\n\nWall enjoys fooling Merlin with his uncanny impressions of a curlew, barn owl and greenshank.\n\nAcheson doesn’t use Merlin. He welcomes it, but points out it can replace learning. “Anything that gets people out, thinking about and reacting to nature is a great thing,” he says. “But there’s certainly a risk that people don’t learn and just abdicate responsibility for learning to Merlin.”\n\nHe has noticed a glitch where Merlin interprets a certain type of chaffinch call as a redstart, leading to people being absolutely adamant that there is a rare bird in their garden. “There’s no substitute for a real person explaining to you how a birdsong feels and encouraging someone to engage with it emotionally,” he says.\n\nJohn Williamson, who works as a guide for Norfolk Wildlife Trust, has found Merlin repeatedly identifying high-pitched calls as a spotted flycatcher, a bird that is very unlikely to be found in the middle of Hickling Broad nature reserve’s large reedbeds. “Merlin can’t do habitat,” he says.\n\nMerlin has also excited visitors by identifying a golden oriole, a very occasional rare migrant, in Hickling woods, but no one has actually seen the species. Williamson is convinced it is misinterpreting a fairly unusual “catcall” of a female jay, a common woodland bird.\n\nThat said, Williamson finds it a “good tool” and welcomes how it is encouraging new people to enjoy birdsong, and particularly its mental health benefits. He knows one person who suffers from acute anxiety but Merlin has got him out into the world again and into nature, providing a focus for calming trips outdoors. “I find it impressive that an app can empower people to go out into nature,” he says.\n\nResearch has found that birdsong is particularly beneficial to mental health, and has a lasting positive impact on wellbeing. For millions around the globe, that’s exactly what Merlin is doing.\n\n“It reminds you that there are birds knitted into your daily life,” says Walter. “It’s not about, ‘now I’m going to do a bit of birdwatching’, you may simply be walking through the park and you hear something and it gives you a sense that these birds are singing away all the time, even in London.”",
    "readingTime": 5,
    "keywords": [
      "mental health",
      "it’s wonderful",
      "merlin he",
      "species",
      "birds",
      "songs",
      "birdsong",
      "nature",
      "trained",
      "garden"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/environment/2025/dec/27/merlin-ai-assisted-birdsong-identifying-app-bird-species",
    "thumbnail_url": "https://i.guim.co.uk/img/media/33efd95d5d247c7af1362ae515bc0e0ed8d00875/333_0_3542_2835/master/3542.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=55c4dbee57a45fc9d7f54a246da5f0fd",
    "created_at": "2025-12-27T12:21:16.576Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-senior-pm-at-microsoft-and-a-selfproclaimed-early-adopter-of-ai-here-are-the-easy-ways-it-helps-me-at-work-and-in",
    "title": "I'm a senior PM at Microsoft and a self-proclaimed early adopter of AI. Here are the easy ways it helps me at work and in my personal life.",
    "description": "Rishab Jolly, a senior PM at Microsoft, uses AI tools to help him draft documents for work, and to speed up research for his podcasting hobby.",
    "fullText": "This as-told-to essay is based on a conversation with Rishab Jolly, 37, a senior program manager at Microsoft, based in Washington. The following has been edited for length and clarity.\n\nI landed a job at Microsoft as a program manager in 2017, after moving to the US for my MBA.\n\nI'm now a senior PM and find my role very fulfilling. My role involves developing ideas for products and features that enhance the customer experience, but also drafting plans that take the product from development to shipping to the customer. PMs are like the glue that brings different teams, across engineering, marketing, and business, together to work on each project.\n\nAs AI tools have become more prevalent, I've felt excited about the technology's potential to help me in my role. I consider myself an early adopter who's been upskilling to make sure I have AI as a new tool in my toolbox.\n\nHere are the ways AI helps me, both in my job and personal life, that are relatively easy to replicate.\n\nI studied computer science engineering for my bachelor's degree in India, where I'm from, before moving to the US in 2015 for my MBA. I also worked as a software engineer in India for four years, at companies using AI and machine learning in some form, before LLMs arrived on the scene. I wouldn't have called myself an AI expert, but I understood how the technology worked.\n\nAs AI tools have become more commonplace, I've used them to make my work faster and easier.\n\nPMs like me spend a huge amount of time in meetings. When I first joined Microsoft, I compiled notes manually to help me understand what I needed to action afterward. Now, I use can use AI tools for note-taking, which has given me back a lot of time to focus on more meaningful work, like strategic thinking and prioritization.\n\nPart of my job as a PM is to write documents that provide clarity to engineering teams about our goals and priorities. AI tools can help reduce the time spent on an initial draft. I then review, edit, and shape the AI-generated content myself, applying my judgment and experience before sharing the document with the team.\n\nAt work, I use the tools available at Microsoft, but in my personal life, I like experimenting and getting my hands dirty with a wide range of tools, from ChatGPT and Perplexity to Gemini.\n\nI started a podcast called \"Curious Souls\" in 2022 with my wife, who also works in tech, where we talk about our passion for product management, AI, fitness, and other topics with guest speakers. It's my hobby.\n\nResearching topics by asking PMs what they wanted to hear about and coming up with ideas for guests was very time-consuming.\n\nNow, I can speed up the process by prompting LLMs to search Reddit for hot topics that PMs are talking about and ask the chatbot to generate a script about the chosen topic. I can even generate an audio clip of the script to listen to while driving to the gym and ponder on how the podcast might sound if I used the script.\n\nI still dedicate between four and five hours each weekend to the podcast, but with AI, I'm able to accomplish much \n\nExperimenting with AI in personal projects has helped me understand where AI is helpful and where it isn't. For example, when I was using AI to generate podcast scripts, I found that it sometimes generated inaccurate outputs, like placeholder links that don't actually exist, so I usually treat AI output as a starting point and make sure to check it.\n\nAs a result, I'm more intentional when I use AI at work, knowing when to rely on automation and when human judgment is essential. I think it's worth experimenting with AI outside of work on low-risk projects, like planning hobbies or trips, before applying similar techniques professionally.\n\nInstead of being fearful of AI, I've decided to embrace it. In the future, I think PMs will be expected to know how to use AI to do things faster.\n\nEven with AI, I think the crux of the PM role will remain the same: being empathetic to customers and solving their problems. AI will make us more capable of solving those issues, and it can give us suggestions for how to approach issues, but the judgment calls will always be made by humans. It won't replace us, but it will be an essential tool to make our lives easier.\n\nMy advice to PMs is to embrace AI and get your hands dirty by experimenting with it, not just in your job, but in daily life. There's no way around it, and the sooner you start doing it, the faster you'll see benefits.\n\nDo you have a story to share about how you use AI at work? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "program manager",
      "personal life",
      "as ai",
      "tools",
      "microsoft",
      "role",
      "experimenting",
      "podcast",
      "engineering",
      "faster"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-pm-ai-easy-work-personal-life-2025-12",
    "thumbnail_url": "https://i.insider.com/694430de64858d02d2171048?width=1200&format=jpeg",
    "created_at": "2025-12-27T12:21:15.661Z",
    "topic": "finance"
  },
  {
    "slug": "the-top-5-things-that-happened-in-the-ai-race-this-year",
    "title": "The top 5 things that happened in the AI race this year",
    "description": "From bubbles to talent wars, 2025 was a turning point for AI's future.",
    "fullText": "2025 was unquestionably the year of AI.\n\nBig Tech shelled out roughly $400 billion on capex, a spending spree so extensive that some economists believe it staved off an overall recession. Nvidia became the first $4 trillion company. And AI content became inescapable, seeping into everything from Hollywood to campaign ads — even Mickey Mouse is getting into AI.\n\nIt hasn't been an endless party. Seemingly every few weeks, the stock market gets spooked that music is about to stop. Only Universal's Wicked for Good was more focused on a bubble.\n\nHere's a look back at the biggest AI storylines of 2025.\n\nIn an era of nostalgia traps, traders can't decide whether this is the Dot-Com era all over again.\n\nTech and AI CEOs can't agree either. In August, OpenAI CEO Sam Altman touched off concerns that a bubble had already formed. Since then, Bill Gates, Nvidia's Jensen Huang, Mark Cuban, and Mark Zuckerberg have offered their own similar or dissenting views.\n\nThe optimists' train of thought often ends up at the railroads and other breakthrough innovations that transformed the economy.\n\n\"There's been a lot of talk about an AI bubble,\" Huang said during Nvidia's third-quarter earnings call. \"From our vantage point, we see something very different.\"\n\nEven those at the forefront of AI's advancements express concern that some of their competitors are being too bold.\n\n\"There's genuine uncertainty, there's genuine dilemma, which we as a company try to manage as responsibly as we can,\" Anthropic CEO Dario Amodei said in early December at a New York Times event. \"And then I think there are some players who are yoloing, who pull the wrist dial too far, and I'm very concerned.\"\n\nThe sheer size of spending is breathtaking.\n\nJPMorgan Chase concluded that AI-related spending contributed to 1.1% of GDP growth in the first half of the year.\n\nThe spending isn't likely to slow down.\n\nOver the last two years, Wall Street has underestimated capex growth, according to Goldman Sachs Research. Right now, Goldman said, the consensus estimate is that hyperscalers will spend $527 billion on capital expenditures next year.\n\nZuckerberg and OpenAI's leadership have separately suggested that the biggest risk is not spending enough.\n\n\"We want to be ahead of the curve,\" OpenAI President Greg Brockman said in a recent video posted on X. \"And the truth is, I don't think we will be, no matter how ambitious we can dream of being right now. I think demand will far exceed what we can think of.\"\n\nSilicon Valley's turf wars were a lot greener in 2025. Over the summer, the AI talent wars reached another level.\n\nPerhaps no company was as aggressive as Meta. Zuckerberg moved to poach top talent by wooing workers with tens of millions of dollars.\n\nAltman said OpenAI offered his best employees $100 million signing bonuses. Another top OpenAI official said Zuckerberg even made homesoup for one of his targets.\n\nOpenAI boasted that it largely fended off Meta's efforts, though ChatGPT co-creator Shengjia Zhao later joined Meta's Superintelligence Lab.\n\nEven the hyperscalers need some extra help to maintain their spending habits.\n\nThat's why Alphabet, Amazon, Meta, Microsoft, and Oracle issued roughly $100 billion of bonds, powering global bond sales to another record year.\n\nThe interconnected nature of many AI deals has also raised concerns among some analysts and traders. Take Anthropic's pledge to spend $30 billion on Microsoft Azure to scale up Claude's compute. As part of the deal, Microsoft will invest up to $5 billion in Anthropic. Nvidia, whose chips are at the certain of this deal and many like, also agreed to invest up to $10 billion.\n\nNot all spenders are created alike, either. OpenAI, which is expected to be in the red by $9 billion this year, has about $1.4 trillion in spending commitments for AI data centers over the next decade. Unlike Google, Meta, and Microsoft, OpenAI doesn't have an established revenue base to fall back on, either.\n\nIt's why OpenAI CFO Sarah Friar sparked a brief firestorm when she appeared to suggest that the startup would want the possibility of a government bailout to backstop its data center bets. Friar walked back her remarks, and Altman later emphasized that OpenAI didn't believe in bailouts.\n\nOpenAI has led much of the AI-model race since the release of ChatGPT in 2022.\n\nThree years later, it was Altman who declared a \"code red,\" just over a month after OpenAI completed its corporate restructuring, aimed at giving it more freedom to raise money to fund its AI advancements.\n\nGoogle is now fighting back, and in the view of some observers, has caught up to OpenAI with the widely praised release of Gemini 3.\n\nCEO Sundar Pichai might as well have struck Steph Curry's signature celebration when he was asked what was next for his AI team.\n\n\"I think some folks need some sleep,\" Pichai said of the company's staffers following Gemini 3's release.",
    "readingTime": 5,
    "keywords": [
      "there's genuine",
      "back",
      "altman",
      "openai",
      "bubble",
      "either",
      "another",
      "later",
      "release",
      "roughly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/what-happened-in-ai-this-year-2025-12",
    "thumbnail_url": "https://i.insider.com/694a7a9e64858d02d2174d21?width=1200&format=jpeg",
    "created_at": "2025-12-27T12:21:15.573Z",
    "topic": "finance"
  },
  {
    "slug": "china-issues-drafts-rules-to-regulate-ai-with-humanlike-interaction",
    "title": "China issues drafts rules to regulate AI with human-like interaction",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/china-issues-drafts-rules-to-regulate-ai-with-humanlike-interaction-4423279",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBQ059_L.jpg",
    "created_at": "2025-12-27T12:21:15.333Z",
    "topic": "finance"
  },
  {
    "slug": "i-spent-3-months-building-an-ai-trading-bot-using-drl-like-alphago",
    "title": "I spent 3 months building an AI trading bot using DRL like AlphaGo",
    "description": "DRL Trading - AI Gold Trading Bot    Deep reinforcement learning system for autonomous XAUUSD trading using:   - PPO & Dreamer algorithms (PyTorch)   - 140+ features: multi-timeframe, macro dat...",
    "fullText": "zero-was-here\n\n /\n\n tradingbot\n\n Public\n\n DRL Trading - AI Gold Trading Bot Deep reinforcement learning system for autonomous XAUUSD trading using: - PPO & Dreamer algorithms (PyTorch) - 140+ features: multi-timeframe, macro data, economic events - MetaTrader 5 live trading - 2M steps trained, targeting 80-120% annual returns - Multiple strategies (aggressive/swing/standard)\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n zero-was-here/tradingbot",
    "readingTime": 1,
    "keywords": [
      "trading",
      "license"
    ],
    "qualityScore": 0.35,
    "link": "https://github.com/zero-was-here/tradingbot",
    "thumbnail_url": "https://opengraph.githubassets.com/b2f78abfba82eebbe98b1972188ca15eb46033918ff4178e5e6d2530376d1535/zero-was-here/tradingbot",
    "created_at": "2025-12-27T12:21:13.822Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tariffs-and-box-office-14-charts-that-explain-2025",
    "title": "AI, Tariffs and Box Office – 14 Charts That Explain 2025",
    "description": "President Trump’s trade policy, inflation and climbing stock prices shaped business and the economy this year.",
    "fullText": "In recent years, macroeconomic tides have ebbed and flowed, but one thing has remained unchanged: Americans’ dim views of the economy.\n\nIn 2023, pundits warned of the “vibecession.” In 2024, concerns about the economy and inflation were top of mind for voters in the presidential race.\n\nThis year, economic pessimism has persisted, as President Trump’s sweeping economic proposals, from his wide-ranging tariffs to his plan to remake the Federal Reserve, have raised uncertainty to new highs. And the economic data is sending mixed, and muddled, signals.\n\nHere are 14 charts that illustrate how uncertainty has unfolded in the economy and markets over the last year, and how it might affect the next.\n\nPresident Trump’s trade war has been one of the biggest sources of economic uncertainty this year. During his campaign, Trump repeatedly cited tariffs as a way to spur American manufacturing, create new jobs and lower U.S. trade deficits.\n\nNearly every country has seen import duties rise.\n\nThe tariffs have made progress toward some of the administration’s stated goals: They have brought the trade deficit down, as exports grew more than imports.\n\nAnd they have made money: Tariff revenues are now at record highs.\n\nBut there is another kind of deficit on investors’ minds: the federal budget deficit. Tariff revenues remain a small share of total government revenues.\n\nHere’s another way in which the effects of tariffs are showing up: higher prices for goods.\n\nConsumer prices started to accelerate in June, and the prices of products most exposed to tariffs notched some of the highest gains.\n\nAnd in recent months, prices for goods continued to rise, contributing more to inflation.\n\nInflation unexpectedly slowed to 2.7 percent in November, according to data released by the Bureau of Labor Statistics this week. But economists have advised taking this data with a grain of salt, because of disruptions in the bureau’s data collection efforts during the 43-day federal government shutdown.\n\nIt’s still unclear whether tariffs will cause just a temporary increase in prices or if they will feed into more persistent inflation.\n\nAt this month’s DealBook Summit, Treasury Secretary Scott Bessent pushed back against the notion that tariffs had contributed to inflation, saying that they had caused a “one-time price adjustment,” not a “generalized price increase.”\n\nThe chair of the Federal Reserve, Jerome H. Powell, has also said that the Fed expected tariffs to cause a “one-time shift in the price level.” But he has stressed that the increase could be drawn out over several quarters. And at a news conference after last week’s Fed meeting he acknowledged the risk of tariff inflation becoming “more and more persistent.”\n\nIn the first full jobs report since the federal shutdown, the B.L.S. reported that the unemployment rate rose to 4.6 percent last month, a four-year high. Wage growth slowed to its lowest level since 2021. As with inflation, the shutdown affected the data collection for these measures, and the agency said ahead of the release that its estimates of the unemployment rate and other measures would be subject to more uncertainty than usual.\n\nThe average job gain over the last three months\n\nThe average job gain over the last three months\n\nThere was a silver lining: Employers added 64,000 jobs in November, driven largely by gains in the health care sector. But that only partly offset a decline in October.\n\nThe federal government shed 168,000 jobs in October and November, as workers who accepted the Trump administration’s “deferred resignation” offer came off the payroll.\n\nAnd the jobs numbers do not reflect a big downward revision that is expected early next year.\n\n(Revisions to jobs figures are commonplace, but they dominated headlines earlier this year when downward adjustments led Trump to fire the commissioner of the B.L.S., Erika McEntarfer, claiming, without evidence, that the data was “rigged.”)\n\nThe lowest-paid workers have felt the strain of the cooling labor market the most. As the economy started to recover from the pandemic, demand for labor far outstripped supply in the lowest-paid industries, such as leisure and hospitality.\n\nToday, that is no longer the case, and hourly wages are rising most slowly for the lowest earners.\n\nLast year, voters consistently told pollsters that they trusted Donald Trump over Joe Biden and later, Kamala Harris, to do a better job on the economy.\n\nNow, Trump is the one feeling the pressure, as views of his handling of the economy have soured since the summer.\n\nThe risks posed by inflation and a softening labor market have also put the Fed in a tough position. Last week, the central bank decided to cut interest rates by a quarter of a percentage point for a third meeting in a row. But the decision was highly contentious, with three of 12 policymakers voting against it.\n\nPowell said he could have made the case either way for the Fed to cut interest rates or pause reductions, given the competing risks to unemployment and inflation.\n\n“You’ve got one tool,” he said. “You can’t do two things at once.”\n\nTrump, for his part, has made no secret of his desire for lower rates. Next year, he will select a new Fed chair.\n\nAfter a dip earlier this year, most notably amid the chaotic “Liberation Day” tariff rollout, the stock market has, on the whole, kept on going up. The S&P 500 reached a record high just last week, for the 37th time this year.\n\nArguably, company earnings, and their expectations for earnings are the most important factor driving the market movements.\n\nIn fact, earnings expectations have moved in tandem with the S&P 500 price index over the course of this year (again, with the exception of the early months of the year).\n\nOf course, the S&P 500 is driven in large part by big tech companies, which are intertwined with the A.I. boom.\n\nThat has been cause for concern for some investors, who see a parallel between this moment and the dot-com bubble of the late 1990s and early 2000s. But unlike companies leading the stock rally during the dot-com bubble, the public companies with the steepest valuation gains today are earning more as the market goes up.\n\nThe outlook for earnings continues to be bullish in 2026, though there could be weak links in the A.I. chain.\n\nThe crypto boom that Trump’s re-election ushered in is on pause for now.\n\nAfter surging for most of the year, the price of Bitcoin and Ether, along with dozens of other coins, started to plummet on Oct. 10, following Trump’s announcement that he would impose a new tariff on China.\n\n(The stock market on that day also saw the biggest one-day plunge since April, though it has since rebounded and hit a record high.)\n\nFor some, the crypto sell-off has underscored the fact that crypto remains a volatile investment, even as it has entered a new level of mainstream acceptance. Amid a high-stakes lobbying campaign by the crypto industry, Trump ended a regulatory crackdown on crypto and signed legislation outlining the first federal rules for stablecoins, digital tokens tied to assets like the U.S. dollar.\n\nOthers worry that a crypto crash could bleed over to the wider market.\n\nAmid all this uncertainty, people might be looking to pop culture as a form of escape. They haven’t necessarily been finding it at the movies, if ticket sales are any indication.\n\nSummer is a crucial season for Hollywood, accounting for the lion’s share of annual box office revenue. This year, fantasies, science-fiction sequels and superhero flicks were on offer. But moviegoers, for the most part, didn’t bite: It was the worst summer for domestic ticket sales since 1981, after adjusting for inflation and excluding the pandemic years.\n\nThe fall was filled with star-studded flicks, but none of them constituted box office hits.\n\nCan the holiday season help Hollywood make a comeback? “Zootopia 2” and “Wicked: For Good” have gotten it off to a good start.\n\nBut broader concerns abound. Warner Bros. Discovery has struck a deal with Netflix for the Warner Bros. studio and its sibling streaming service, HBO Max, while it has fended off, for the time being, a hostile takeover offer from Paramount.\n\nRegardless of how it all ends, it feels like a moment of loss for cinephiles. Corporate consolidation, after all, is not likely to bode well for the future of the Silver Screen.",
    "readingTime": 7,
    "keywords": [
      "cut interest",
      "dot-com bubble",
      "ticket sales",
      "unemployment rate",
      "average job",
      "job gain",
      "interest rates",
      "tariff revenues",
      "stock market",
      "labor market"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2025/12/20/business/dealbook/charts-2025-economy.html",
    "thumbnail_url": "https://static01.nyt.com/images/2025/12/19/business/00db-charts/00db-charts-facebookJumbo.jpg",
    "created_at": "2025-12-27T06:18:02.601Z",
    "topic": "business"
  },
  {
    "slug": "genai-experts-replace-halo-evolved-staff-to-impact-xbox-game-development",
    "title": "GenAI experts replace 'Halo: Evolved' staff to impact Xbox game development",
    "description": "A shakeup at an Xbox Game Studio suggests that AI will play a major role in Halo games like Campaign Evolved. The new Chief of Staff stresses enhancing workflows with machine learning on her resume. Other employees could use AI tools creatively rather than to improve efficiency.",
    "fullText": "Halo Studios has undergone dramatic changes in recent months, amid a turbulent 2025 for Xbox games. Rebs Gaming has been tracking new hires who all share experience with AI tools. With an AI consultant replacing Melissa Boone as Chief of Staff, the technology looks poised to infiltrate game development.\n\nScanning LinkedIn and job listings, the YouTuber noticed a familiar pattern. The most significant recent change was the arrival of Angela Hession at Halo Studios. The new Chief of Staff previously led the Gaming Safety and Trust team at Microsoft. However, she also founded a company specializing in AI-driven productivity enhancement.\n\nAnother new job ad at Xbox Game Studios seeks an Applied Scientist focused on machine learning. Not only would the employee work on Halo games, but also on other Microsoft franchises like Forza and Gears of War. Several current Halo developers in key roles have added qualifications related to generative AI.\n\nHow studios will employ artificial intelligence has become a point of controversy. Many companies argue that it’s a resource that boosts the output of developers. Yet, critics worry that human artists will lose creative control and, ultimately, their jobs.\n\nPerhaps the best indication of how Halo Studios will employ the tools came from a 2024 job posting. The studio was searching for a Senior AI Engineer to “leverage generative AI and ML to augment in-game experiences and to improve how we make games.” The description implied that the technology will aid more than rudimentary office tasks.\n\nRebs Gaming stresses the distinction between AI as a tool vs an author. Either way, it wouldn’t be surprising if Halo: Campaign Evolved or a follow-up title ushers in a new era of development. Microsoft has fully embraced artificial intelligence, building hundreds of data centers. Some analysts have attributed the closure of other Xbox Game Studios to that monumental investment.\n\nRebs Gaming YouTube, Microsoft Careers, Rebs Gaming X account",
    "readingTime": 2,
    "keywords": [
      "xbox game",
      "game studios",
      "artificial intelligence",
      "chief of staff",
      "halo studios",
      "rebs gaming",
      "games",
      "tools",
      "technology",
      "development"
    ],
    "qualityScore": 0.95,
    "link": "https://www.notebookcheck.net/Generative-AI-experts-replace-Halo-Campaign-Evolved-staff-to-impact-Xbox-game-development.1192829.0.html",
    "thumbnail_url": "https://www.notebookcheck.net/fileadmin/Notebooks/News/_nc5/HaloCampaignEvolvedBanner.jpg",
    "created_at": "2025-12-27T06:18:02.325Z",
    "topic": "gaming"
  },
  {
    "slug": "what-will-ai-flip-into",
    "title": "What Will AI Flip Into?",
    "description": "Hello and welcome to the newsletter, a grab bag of daily content from the Odd Lots universe. Sometimes it's us, Joe Weisenthal and Tracy Alloway, bringing you our thoughts on the most recent developments in markets, finance and the economy. And sometimes it's contributions from our network of expert guests and sources. Whatever it is, we promise it will always be interesting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-26/what-will-ai-flip-into",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iuTaH0oGGJIo/v0/1200x800.jpg",
    "created_at": "2025-12-27T00:55:10.464Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-end-near-record-high-as-nvidia-gains-on-ai-licensing-deal",
    "title": "Stocks End Near Record High as Nvidia Gains on AI Licensing Deal",
    "description": "US stocks wavered near a record high in thin holiday trading as investors shifted attention to a relentless rally in commodities. Nvidia Corp. climbed as analysts viewed a licensing deal with artificial intelligence startup Groq positively.",
    "fullText": "MarketsBy Natalia Kniazhevich and Felice MaranzSaveUS stocks wavered near a record high in thin holiday trading as investors shifted attention to a relentless rally in commodities. Nvidia Corp. climbed as analysts viewed a licensing deal with artificial intelligence startup Groq positively.The S&P 500 finished little changed and the Nasdaq 100 fell 0.1%. Among S&P 500 sectors, materials and tech led gains, while consumer discretionary and energy retreated.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-26/stocks-touch-record-as-nvidia-gains-on-ai-licensing-deal",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iF.s6X.J0a_g/v1/1200x800.jpg",
    "created_at": "2025-12-27T00:55:08.384Z",
    "topic": "finance"
  },
  {
    "slug": "forwardtoaudio-turn-newsletters-into-a-private-podcast-using-ai",
    "title": "ForwardToAudio – Turn newsletters into a private podcast using AI",
    "description": "Turn long emails into a private podcast. Forward emails to your private address and listen to them in your favorite podcast player.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://forwardtoaudio.com",
    "thumbnail_url": "https://saa-s-audio-dashboard--stjohnbryan.replit.app/opengraph.jpg",
    "created_at": "2025-12-27T00:55:03.011Z",
    "topic": "tech"
  },
  {
    "slug": "these-13-creator-economy-startups-pulled-in-about-2-billion-in-funding-this-year",
    "title": "These 13 creator economy startups pulled in about $2 billion in funding this year",
    "description": "From live shopping startup Whatnot to AI music platform Suno, meet the creator economy startups that raised massive deals in 2025.",
    "fullText": "The creator economy is riding an AI-fueled high.\n\nIn 2025, eight startups building artificial intelligence tools to automate the content creation process each announced at least $50 million in funding — a combined $1.2 billion — from venture capital and private equity investors.\n\nSynthesia, a generative AI video startup based in London, confirmed its $180 million funding round in January, while ElevenLabs, a text-to-voice startup, closed a $180 million Series C round. Other AI startups, like Moonvalley, Krea, and Higgsfield, also announced sizable investments this year.\n\nWhile AI is dominating investor interest, the topic still carries friction within the creator economy. Some of these AI startups, which offer features such as human-like avatars, run the risk of posing a threat to content creators themselves. Influencer marketing, still the primary financial engine of the creator economy, has yet to reach a consensus on how and when AI should be utilized.\n\nTop creators aren't sitting by idly for AI to take over. YouTuber MrBeast and his team initially sought to raise $200 million earlier this year at a $5 billion valuation, according to investor materials viewed by Business Insider. The MrBeast team declined to comment on the fundraise.\n\nIt's not just AI that's attracting giant checks from VCs.\n\nSocial commerce startups building live shopping and affiliate marketing platforms are also raking in funding. Whatnot, a platform where people sell on stream in categories like fashion and collectibles, such as Pokémon Cards or Labubus, raised a total of $490 million across two later-stage rounds this year. The social shopping platform was most recently valued at $11.5 billion.\n\nMeanwhile, ShopMy, an affiliate marketing platform, continues to gain market share in the influencer marketing space. The startup raised a total of $147.5 million in funding this year.\n\nUS social commerce sales are expected to cross $100 billion next year, according to estimates from EMARKETER, Business Insider's sister company. The category is gaining steam in the US, fueled in part by the growth of TikTok Shop.\n\nThis year's fundraising blitz for creator AI and social commerce startups follows similar buzz for the categories in 2024 when investors threw money at startups like Captions, Flip, and OpusClip. Several startups in those business areas, including ElevenLabs and ShopMy, raised money two years in a row.\n\nBusiness Insider analyzed 2025 fundraising data from PitchBook and other industry sources to highlight the biggest creator industry investment rounds from the year. We're highlighting 13 startups that raised $50 million or more in 2025; combined, their funding crossed $1.9 billion. We focused on companies whose products significantly impact the businesses and content creation processes of creators and their partners.\n\nHere are 13 creator economy startups that raised some of the largest rounds in 2025, in alphabetical order:",
    "readingTime": 3,
    "keywords": [
      "content creation",
      "influencer marketing",
      "social commerce",
      "affiliate marketing",
      "creator economy",
      "commerce startups",
      "funding",
      "creators",
      "platform",
      "rounds"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/creator-economy-investments-ai-social-commerce-whatnnot-synthesia-shopmy-suno-2025-12",
    "thumbnail_url": "https://i.insider.com/6949c59e832e0ef1ead6b4d6?width=1200&format=jpeg",
    "created_at": "2025-12-27T00:54:56.757Z",
    "topic": "finance"
  },
  {
    "slug": "artificial-stupidity-made-ai-trading-bots-spontaneously-form-cartels-when-left-unsupervised-wharton-study-reveals",
    "title": "‘Artificial stupidity’ made AI trading bots spontaneously form cartels when left unsupervised, Wharton study reveals",
    "description": "AI bots told to act as trading agents in simulated markets engaged in pervasive collusion, raising new questions about how financial regulators have previously addressed this tech.",
    "fullText": "Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune, covering retail and the intersection of business and popular culture.\n\nArtificial intelligence is just smart—and stupid—enough to pervasively form price-fixing cartels in financial market conditions if left to their own devices.\n\nA working paper posted earlier this year on the National Bureau of Economic Research website from the Wharton School at the University of Pennsylvania and Hong Kong University of Science and Technology found when AI-powered trading agents were released into simulated markets, the bots colluded with one another, engaging in price fixing to make a collective profit.\n\nIn the study, researchers let bots loose in market models, essentially a computer program designed to simulate real market conditions and train AI to interpret market-pricing data, with virtual market makers setting prices based on different variables in the model. These markets can have various levels of “noise,” referring to the amount of conflicting information and price fluctuation in the various market contexts. While some bots were trained to behave like retail investors and others like hedge funds, in many cases, the machines engaged in “pervasive” price-fixing behaviors by collectively refusing to trade aggressively—without being explicitly told to do so.\n\nIn one algorithmic model looking at price-trigger strategy, AI agents traded conservatively on signals until a large enough market swing triggered them to trade very aggressively. The bots, trained through reinforcement learning, were sophisticated enough to implicitly understand that widespread aggressive trading could create more market volatility.\n\nIn another model, AI bots had over-pruned biases and were trained to internalize that if any risky trade led to a negative outcome, they should not pursue that strategy again. The bots traded conservatively in a “dogmatic” manner, even when more aggressive trades were seen as more profitable, collectively acting in a way the study called “artificial stupidity.”\n\n“In both mechanisms, they basically converge to this pattern where they are not acting aggressively, and in the long run, it’s good for them,” study co-author and Wharton finance professor Itay Goldstein told Fortune.\n\nFinancial regulators have long worked to address anti-competitive practices like collusion and price fixing in markets. But in retail, AI has taken the spotlight, particularly as companies using algorithmic pricing come under scrutiny. This month, Instacart, which uses AI-powered pricing tools, announced it will end its program where some customers saw different prices for the same item on the delivery company’s platform. It follows a Consumer Reports analysis found in an experiment that Instacart offered nearly 75% of its grocery items at multiple prices.\n\n“For the [Securities and Exchange Commission] and those regulators in financial markets, their primary goal is to not only preserve this kind of stability, but also ensure competitiveness of the market and market efficiency,” Winston Wei Dou, Wharton professor of finance and one of the study’s authors, told Fortune.\n\nWith that in mind, Dou and two colleagues set out to identify how AI would behave in a financial market by putting trading agent bots into various simulated markets based on high or low levels of “noise.” The bots ultimately earned “supra-competitive profits” by collectively and spontaneously deciding to avoid aggressive trading behaviors.\n\n“They just believed sub-optimal trading behavior as optimal,” Dou said. “But it turns out, if all the machines in the environment are trading in a ‘sub-optimal’ way, actually everyone can make profits because they don’t want to take advantage of each other.”\n\nSimply put, the bots didn’t question their conservative trading behaviors because they were all making money and therefore stopped engaging in competitive behaviors with one another, forming de-facto cartels.\n\nWith the ability to increase consumer inclusion in financial markets and save investors time and money on advisory services, AI tools for financial services, like trading agent bots, have become increasingly appealing. Nearly one-third of U.S. investors said they felt comfortable accepting financial planning advice from a generative AI-powered tool, according to a 2023 survey from financial planning nonprofit CFP Board. A report published in July from cryptocurrency exchange MEXC found that among 78,000 Gen Z users, 67% of those traders activated at least one AI-powered trading bot in the previous fiscal quarter.\n\nBut for all their benefits, AI trading agents aren’t without risks, according to Michael Clements, director of financial markets and community at the Government Accountability Office (GAO). Beyond cybersecurity concerns and potentially biased decision-making, these trading bots can have a real impact on markets.\n\n“A lot of AI models are trained on the same data,” Clements told Fortune. “If there is consolidation within AI so there’s only a few major providers of these platforms, you could get herding behavior—that large numbers of individuals and entities are buying at the same time or selling at the same time, which can cause some price dislocations.”\n\nJonathan Hall, an external official on the Bank of England’s Financial Policy Committee, warned last year of AI bots encouraging this “herd-like behavior” that could weaken the resilience of markets. He advocated for a “kill switch” for the technology, as well as increased human oversight.\n\nClements explained many financial regulators have so far been able to apply well-established rules and statutes to AI, saying for example, “Whether a lending decision is made with AI or with a paper and pencil, rules still apply equally.”\n\nSome agencies, such as the SEC, are even opting to fight fire with fire, developing AI tools to detect anomalous trading behaviors.\n\n“On the one hand, you might have an environment where AI is causing anomalous trading,” Clements said. “On the other hand, you would have the regulators in a little better position to be able to detect it as well.”\n\nAccording to Dou and Goldstein, regulators have expressed interest in their research, which the authors said has helped expose gaps in current regulation around AI in financial services. When regulators have previously looked for instances of collusion, they’ve looked for evidence of communication between individuals, with the belief that humans can’t really sustain price-fixing behaviors unless they’re corresponding with one another. But in Dou and Goldstein’s study, the bots had no explicit forms of communication.\n\n“With the machines, when you have reinforcement learning algorithms, it really doesn’t apply, because they’re clearly not communicating or coordinating,” Goldstein said. “We coded them and programmed them, and we know exactly what’s going into the code, and there is nothing there that is talking explicitly about collusion. Yet they learn over time that this is the way to move forward.”\n\nThe differences in how human and bot traders communicate behind the scenes is one of the “most fundamental issues” where regulators can learn to adapt to rapidly developing AI technologies, Goldstein argued.\n\n“If you use it to think about collusion as emerging as a result of communication and coordination,” he said, “this is clearly not the way to think about it when you’re dealing with algorithms.”\n\nA version of this story was published on Fortune.com on August 1, 2025.",
    "readingTime": 6,
    "keywords": [
      "traded conservatively",
      "reinforcement learning",
      "ai-powered trading",
      "simulated markets",
      "price-fixing behaviors",
      "market conditions",
      "financial planning",
      "trading agent",
      "agent bots",
      "anomalous trading"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/what-is-artificial-stupidity-ai-pricing-collusion-study/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/07/GettyImages-2227723433_eab441-e1753994704738.jpg?resize=1200,600",
    "created_at": "2025-12-26T18:17:06.585Z",
    "topic": "science"
  },
  {
    "slug": "the-most-popular-hbr-podcast-episodes-of-2025",
    "title": "The Most Popular HBR Podcast Episodes of 2025",
    "description": "Topping HBR’s audio charts this past year were discussions on how to be a better conversationalist, boosting productivity through timeboxing and gen AI tools, managing up, encouraging upskilling, executive presence, and strategy execution. If one theme stood out, it was continuous self-improvement.",
    "fullText": "The Most Popular HBR Podcast Episodes of 2025 by Alison BeardDecember 26, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWith the start of a new year, thoughts turn to self-improvement: exercising and eating right, exploring new hobbies, building skills and seizing opportunities at work.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/the-most-popular-hbr-podcast-episodes-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec26_17_2202353837.jpg",
    "created_at": "2025-12-26T18:17:04.917Z",
    "topic": "business"
  },
  {
    "slug": "stegcore-a-decision-boundary-for-ai-systems-truth-permission",
    "title": "StegCore – a decision boundary for AI systems (truth ≠ permission)",
    "description": "Core of StegVerse dev. Contribute to StegVerse-Labs/StegCore development by creating an account on GitHub.",
    "fullText": "StegVerse-Labs\n\n /\n\n StegCore\n\n Public\n\n Core of StegVerse dev.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n StegVerse-Labs/StegCore",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/StegVerse-Labs/StegCore",
    "thumbnail_url": "https://opengraph.githubassets.com/894227cb38195792c6941e37db2785a607b1f5ef62d3a203814e866bc432524e/StegVerse-Labs/StegCore",
    "created_at": "2025-12-26T18:17:03.195Z",
    "topic": "tech"
  },
  {
    "slug": "best-ai-server-stocks-poised-to-dominate-in-2026-according-to-warrenai",
    "title": "Best AI Server Stocks Poised to Dominate in 2026, According to WarrenAI",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/best-ai-server-stocks-poised-to-dominate-in-2026-according-to-warrenai-93CH-4423187",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEB6R0AQ_M.jpg",
    "created_at": "2025-12-26T18:17:03.141Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-reality-check-deconstructing-the-2025-stack-overflow-developer-survey",
    "title": "The AI Reality Check: Deconstructing the 2025 Stack Overflow Developer Survey",
    "description": "Building scalable, high-performance web applications with clean, maintainable code. Expertise in MERN stack, API integrations, and DevOps.",
    "fullText": "The 2025 Stack Overflow Developer Survey has landed. With data harvested from nearly 49,000 professional developers, we finally have a statistical answer to the industry's existential dread: \"Is AI coming for my paycheck?\"\n\nThe short answer? No.\nThe long answer? It’s complicated.\n\nThis isn't just a list of numbers. This is a forensic analysis of the developer ecosystem in the post-GPT era. We are tracking the rise of the \"Architect,\" the fall of legacy databases, and the emergence of a new \"Trust Paradox\" in AI adoption.\n\nWe are witnessing a fascinating divergence in the data. We call it the Trust Paradox.\n\nWhy the drop in sentiment? The industry has collectively realized that current AI models function less like a \"Superintelligence\" and more like an overconfident Junior Developer.\n\nThe Verdict: AI has shifted from a \"magic wand\" to a \"productivity engine.\" It requires heavy supervision. The seniors are spending less time writing boilerplate, but more time code-reviewing the AI's output.\n\nWhen ChatGPT launched, the internet was flooded with demos of \"Flappy Bird in 30 seconds.\" But enterprise software isn't Flappy Bird.\n\nThe survey asked a critical question: Can AI handle complex tasks?\n\nThere is a massive delta between \"generating a React component\" and \"architecting a distributed microservices system.\"\n\nInsight: Developers are smart. They trust AI to explain a regex, but they refuse to let it touch the production keys. The \"Human in the Loop\" is not going away; it is becoming the premium safeguard.\n\nThe 2025 data settles several long-standing debates. The leaderboard has shifted.\n\nPython saw a 7% surge in popularity. This is not because web development suddenly got better in Python; it is purely the \"AI Dividend.\" Python is the API for the AI revolution. If you are building with LLMs, you are likely writing Python.\n\nDespite the noise, Java and C# remain immovable objects, holding a steady 30% market share. They are the COBOL of the 21st century—too big to fail, too critical to replace.\n\nThe database war is effectively over.\n\nWhy the shift? The community has consolidated around Postgres as the default for everything. It handles relational data, JSON (better than Mongo in many cases), and vectors (pgvector). Meanwhile, MySQL's stewardship under Oracle continues to drive developers away.\n\nPro Tip: If you are starting a project in 2026 and you aren't choosing Postgres, you need a very, very specific reason.\n\nHere is the most actionable signal for your career: The \"Architect\" role is exploding.\n\nAs AI commoditizes low-level coding (syntax generation), the value line is moving up the stack. Companies need fewer \"coders\" and more \"system designers.\"\n\nAction Item: Stop obsessing over syntax. Start obsessing over System Design. Learn how to scale. Learn how to design fault-tolerant systems. That is where the money is going.\n\nLet's address the fear.\nQuestion: \"Is AI a threat to your job?\"\nAnswer: 63.6% say NO.\n\nWhile this is a majority, it is down from 68% last year. The anxiety is creeping up. But here is the nuance:\n\nAI is not replacing developers.\nDevelopers using AI are replacing developers who don't.\n\nThe \"Prompt Engineers\" who lack foundational knowledge are in danger. The software engineers who use AI to accelerate their workflow are thriving.\n\nThe data from 49,000 peers is clear. The industry isn't dying; it's mutating.\n\nThe job market is broken for the mediocre, but it has never been better for the experts.",
    "readingTime": 3,
    "keywords": [
      "replacing developers",
      "isn't",
      "stack",
      "survey",
      "industry",
      "less",
      "shifted",
      "software",
      "critical",
      "away"
    ],
    "qualityScore": 1,
    "link": "https://nitinahirwal.in/posts/Stack-Overflow-Survey-2025",
    "thumbnail_url": "https://nitinahirwal.in/images/ss.png",
    "created_at": "2025-12-26T18:17:02.879Z",
    "topic": "tech"
  },
  {
    "slug": "republican-lawmaker-shredded-for-posting-ai-images-of-himself-beating-up-santa-on-christmas-morning",
    "title": "Republican lawmaker shredded for posting AI images of himself beating up Santa on Christmas morning",
    "description": "Indiana state Sen. Chris Garten acknowledged the backlash and labeled his critics ‘snowflakes’",
    "fullText": "A Republican lawmaker raised eyebrows after posting AI-generated images on Christmas Day that depicted him beating up Santa Claus.\n\nIndiana state Sen. Chris Garten’s post on the morning of December 25, where he was pictured body-slamming Santa in front of the state capitol building, did not go down well with his followers on social media.\n\n“When you find out the North Pole is trying to bring more bureaucratic overreach & unfunded mandates down the chimney disguised as “Christmas cheer.” Not on my watch,” the Republican posted on his X account Thursday morning.\n\n“We The People run Indiana, not the bureaucrats,” he added. “Take it back to the North Pole big guy.”\n\nIn one of the AI-generated pictures, Garten kicked Santa down the steps of the state capitol building, while in another, he hoisted his fist above St. Nick’s head as he was pinned to the ground.\n\nThe comments underneath the post were overwhelmingly disapproving.\n\n“This may be the most pitiful thing I’ve seen this Xmas. Congratulations,” one person reacted on X.\n\n“Ah, yes, the left is the party of violence. *body slams Santa Claus*,” said another.\n\n“What on earth would compel a person to post images of them beating up a universally beloved figure?” someone else chimed in.\n\n“So warming to see the symbol of Christmas generosity and cheer get beaten to a bloody pulp!” another person wrote.\n\nThe Independent has contacted Garten’s representative for comment.\n\nA few hours after posting, Garten acknowledged the backlash in a follow-up message where he labeled his critics “snowflakes.”\n\n“Lots of intolerance, swearing, and outrage on display over a few AI pics I had a blast designing with my kids,” Garten said. “Some of you clowns are just insufferable. Hopefully your negativity stays in the comments and not directed at your families.”\n\n“Merry Christmas, snowflakes!” he added.\n\nOther notable festive messages from Republicans featured one from President Donald Trump, who shared a bizarre Truth Social post on Christmas Day about the late sex offender Jeffrey Epstein, whose case continues to haunt the administration.\n\nThe president said in a Christmas message that he dropped ties with the late sex offender “long before it became fashionable,” and that the controversy surrounding the release of the Epstein files is a “Radical Left Witch Hunt.”",
    "readingTime": 2,
    "keywords": [
      "sex offender",
      "christmas day",
      "north pole",
      "another",
      "republican",
      "posting",
      "ai-generated",
      "images",
      "beating",
      "morning"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/republican-lawmaker-shredded-posting-ai-162929278.html",
    "thumbnail_url": "https://media.zenfs.com/en/the_independent_635/752df9c2e348269662ea6b8894d6e68f",
    "created_at": "2025-12-26T18:17:00.636Z",
    "topic": "news"
  },
  {
    "slug": "takaichi-ai-corporate-reform-pave-way-for-japan-stocks-in-2026",
    "title": "Takaichi, AI, Corporate Reform Pave Way for Japan Stocks in 2026",
    "description": "Japan’s stocks are expected to extend gains in 2026, with Prime Minister Sanae Takaichi’s aggressive fiscal plans building on the momentum of the past year.",
    "fullText": "MarketsBy Alice French and Eru IshikawaSaveJapan’s stocks are expected to extend gains in 2026, with Prime Minister Sanae Takaichi’s aggressive fiscal plans building on the momentum of the past year.Tokyo’s benchmark Topix index has weathered tariff shocks, two Bank of Japan rate hikes and a change of prime minister to gain about 23% this year, putting it on track for its biggest outperformance versus the S&P 500 since 2022. The rally — which led Japan’s benchmarks to multiple record highs — has laid the foundations for further gains, strategists say.",
    "readingTime": 1,
    "keywords": [
      "prime minister",
      "gains"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-25/takaichi-ai-corporate-reform-pave-way-for-japan-stocks-in-2026",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3trQWQBsbNU/v0/1200x800.jpg",
    "created_at": "2025-12-26T12:22:29.673Z",
    "topic": "finance"
  },
  {
    "slug": "green-debt-sales-hit-record-levels-despite-climate-backlash",
    "title": "Green Debt Sales Hit Record Levels Despite Climate Backlash",
    "description": "Investors have piled into climate-friendly assets this year despite policy and regulatory rollbacks in the US and Europe, as artificial intelligence drives a boom in energy infrastructure demand.",
    "fullText": "GreenBy Ishika MookerjeeSaveInvestors have piled into climate-friendly assets this year despite policy and regulatory rollbacks in the US and Europe, as artificial intelligence drives a boom in energy infrastructure demand.Global green bond and loan issuance has reached a record $947 billion so far this year, according to data compiled by Bloomberg Intelligence. That’s as stock market gauges for renewables are set for their first annual gains since 2020, outperforming the S&P 500 by a wide margin, while shares of power-grid technology companies remain in favor.",
    "readingTime": 1,
    "keywords": [
      "intelligence"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-25/green-debt-sales-hit-record-levels-despite-climate-backlash",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/itymJf7GXh6A/v0/1200x799.jpg",
    "created_at": "2025-12-26T12:22:29.330Z",
    "topic": "finance"
  },
  {
    "slug": "ai-writing-agent-that-flags-unsupported-claims-for-review",
    "title": "AI writing agent that flags unsupported claims for review",
    "description": "Write high-quality reviews, listicles, and how-to guides in 13 languages—powered by trust signals and grounded research.",
    "fullText": "No hallucinations. No hours of research. No AI slop.\n\nProofWrite blends keyword research, automated product research, trust-signal analysis, and AI writing to create factual, humanized articles that rank. Every insight is grounded in real proof.\n\nProduct review, listicle, how-to, comparison, or freeform. Keyword research surfaces winning terms and sets coverage targets.\n\nAutomated research from official and authoritative sources. Trust signals, ratings, and citations pulled from platforms like Trustpilot, Capterra and Reddit.\n\nSEO, AEO & GEO-optimized copy backed by citations. Choose Claude, GPT, or Gemini. Every claim tied to research.\n\nPush to WordPress or export anywhere. Fully editable drafts with keyword coverage guidance with SEO, AEO and GEO metrics before publishing.\n\nProofWrite is designed for teams and creators who need accurate, SEO-optimized content at scale.\n\nScale product reviews, comparisons, and listicles with real specs, pricing, and trust signals that convert.\n\nProduce research-backed how-to guides and product content 10x faster without sacrificing quality.\n\nDeliver optimized, fact-checked content to clients with built-in keyword coverage and scoring.\n\nMeet E-E-A-T standards with automated trust signals, citations, and verified research in every article.\n\nProofWrite scores every outline across the pillars that move rankings: keyword coverage, structure, media, and more. Each edit triggers a fresh calculation so you know exactly what to improve before you publish.\n\nScore updates in real time as you refine keywords, images, and structure.\n\nCoverage, structure, and media breakdowns show exactly what needs work.\n\nMedia gaps, thin sections, or missing H2s surface instantly for quick fixes.\n\nThe only tool that optimizes content for AI search engines and LLM citations.\n\nRe-scored on every edit you make\n\nQuestion headings, source citations, and quotable claims.\n\nEvery claim in your article gets a verdict. For claims that need attention, choose from three instant actions: verify manually, add a source URL, or let AI rewrite it.\n\nMark claims as reviewed when you've confirmed the facts yourself with one-click verify feature.\n\nPaste a URL and the system extracts supporting evidence automatically.\n\nAI rewrites the claim to make it factual.\n\n“Notion's Business plan costs $15 per user per month”\n\nPricing, features, ratings, and policy claims are verified against your research data.\n\nEnter any article URL and target keyword to get an instant SEO, AEO & GEO analysis. See how well your content is optimized for search engines and AI.\n\nToggle between the input brief and the final article to see how ProofWrite threads research, trust signals, and structure into a cohesive narrative. No AI slop, no hallucinations, no em dashes just high-quality content in a single shot. More writing examples can be found in our blog.\n\nYou have an idea. It keeps you up at night, a software solution that seems perfect. The urge to open your laptop and start building immediately is overwhelming. You can already see the dashboard, the features, and the user interface in your mind.\n\nWhen you first dip your toes into the world of SaaS (Software as a Service), it is easy to make the \"classic mistake\" identified by seasoned developers on Indie Hackers: spending months building a tool before figuring out if anyone actually wants it. The result? You launch to silence. You spent time and energy solving a problem that perhaps didn't exist, or at least not in the way you thought it did.\n\nThe landscape of digital entrepreneurship has changed. You no longer need a computer science degree or a venture capital injection to start. As noted by the community at r/BuildToShip, the modern approach is about shipping fast, learning in public, and turning ideas into real products through lean validation.\n\nThis guide is your blueprint for launching a Micro-SaaS, a small, niche-focused software business run by one person or a tiny team. We will walk through the process of validating your idea in as little as 48 hours with $0 upfront cost, utilizing no-code tools and AI-driven automation to minimize risk and maximize impact.\n\nBefore you worry about tech stacks, logos, or LLCs, you must answer one question: Will people pay for this?\n\nMany aspiring founders believe building SaaS is about passion and code. However, insights from the \"Income AIcademy\" suggest that this mindset is a fast track to nowhere. The real process involves validating demand before the product exists.\n\nThe era of broad, horizontal software (like generic project management tools) is dominated by giants. Your opportunity lies in the \"Micro.\"\n\nAccording to trends for 2025 highlighted by Sidetool, profitable Micro-SaaS opportunities are unlocked by focusing on niche markets. You aren't trying to serve everyone; you are trying to serve a very specific group of people with a very specific problem.\n\nNarrow your scope: Instead of \"accounting software,\" think \"expense tracking for freelance underwater photographers.\"\n\nLook for manual friction: Identify tasks that businesses are currently solving with messy Excel spreadsheets or endless email chains.\n\nLeverage AI trends: Consider how AI-driven automation can solve these specific problems faster or cheaper than a human could.\n\nCan you describe your target customer in one sentence? (e.g., \"Estate agents who struggle to schedule viewings.\")\n\nIs the problem painful enough that they are currently paying (money or time) to solve it poorly?\n\nYou might think you need a finished product to sell it. You don't. In fact, successful creators have validated microniche ideas in 48 hours without spending a dime. The goal here is to collect \"signals of interest\" rather than users.\n\nDraft a Value Proposition: Clearly articulate what problem you solve. Avoid technical jargon. Speak to the pain point.\n\nFind the Watering Holes: Go where your niche hangs out. This might be specific subreddits, Facebook groups, or LinkedIn communities.\n\nEngage, Don't Spam: Do not just drop a link. As advised by the r/BuildToShip community, the goal is to \"learn in public.\" Share your hypothesis. Ask questions like, \"I'm noticing [Problem X] is a huge time sink for [Niche Y]; how are you currently handling this?\"\n\nThe \"Smoke Test\": Create a simple landing page (using free tiers of site builders) or even a direct message script that describes the solution. Ask for an email address or a pre-order to get early access.\n\nWhy this matters: If you cannot find people to talk to about the problem, or if nobody is willing to give you their email address for a solution, you will not be able to sell the product later. Silence now saves you months of coding later.\n\nDo you have a list of 10–50 people who said, \"Yes, I need this\"?\n\nDid you complete this outreach within a 48-hour window to prevent procrastination?\n\nOnce, and only once, you have validated that real humans want your solution, you can start building. But you aren't writing code from scratch. You are using the \"No-Code\" approach to remain lean.\n\nKnack and similar platforms have popularized the idea that you can build robust applications without traditional programming. Your goal is to build a \"Minimum Viable Product\" (MVP), the simplest version of your tool that delivers the core value.\n\nDatabase: Start with where the data lives. In no-code tools, this often looks like a spreadsheet or a visual database.\n\nLogic/Automation: Use automation tools to connect different apps. For example, if your SaaS generates reports, set up a workflow that triggers when a user submits a form, processes the data via AI, and emails the PDF.\n\nInterface: Use a drag-and-drop builder to create the front end where users log in and interact with your data.\n\nPro Tip: Don't get hung up on scalability. You don't need a system that handles a million users. You need a system that handles your first 10 users perfectly.\n\nTo compete in 2025, your Micro-SaaS needs an edge. Sidetool suggests leveraging AI-driven automation to maximize impact.\n\nIdentify the \"Magic\" Moment: Where can AI save the user the most time? Is it writing text, analyzing data, or generating images?\n\nIntegrate via API: Most no-code platforms allow you to send data to AI models (like OpenAI's API) and receive a response.\n\nKeep a Human in the Loop: Ensure your users can review the AI's output. AI is powerful but can hallucinate; trust is built on reliability.\n\nDoes the product actually solve the core problem you validated in Phase 1?\n\nCan a user go from \"Sign Up\" to \"Problem Solved\" without your manual intervention?\n\nBuilding is comfortable. Shipping is scary. But as the r/BuildToShip hub emphasizes, you must be willing to ship fast and talk about growth.\n\nRemember those 50 people who gave you their email addresses in Step 2? They are your beta testers.\n\nPersonal Outreach: Email them personally. \"Hey, remember that tool we talked about? It's ready for you to try.\"\n\nGather Feedback: Your first version will have bugs. It will lack features. That is okay. Ask your early users, \"What is the one thing preventing you from loving this?\"\n\nCharge Money Early: Free users give polite feedback. Paying users give honest feedback. Even a small price tag ($5/month) validates that the problem is painful enough to pay for.\n\nOne of the strongest strategies for Micro-SaaS growth is transparency. The \"Build in Public\" movement encourages sharing your wins, losses, and revenue numbers.\n\nDocument the Journey: Share updates on social media or indie hacker communities. \"Today I fixed a bug that caused X\" or \"We just got our 10th subscriber!\"\n\nAsk for Help: Communities like r/BuildToShip exist to help you talk growth, tech, and tools. If you are stuck on a pricing model or a technical hurdle, ask the community.\n\nIterate Quickly: The advantage of being a \"Micro\" SaaS is speed. If users hate a feature, you can remove it today. If they need a new button, you can add it tonight. Large competitors cannot do that.\n\nHave you moved from \"Validation\" (interested people) to \"Traction\" (active users)?\n\nAre you actively engaging with a community of peers to keep your momentum up?\n\nEven with a lean plan, you will encounter hurdles. Here is how to navigate the common traps of the Micro-SaaS journey.\n\nThe Issue: You feel the product isn't \"ready\" because it lacks a dark mode, multiple language support, or a referral system. The Fix: Go back to your validation. Did your early users say they wouldn't buy without dark mode? Probably not. Build only what is necessary to solve the core pain point. As the research indicates, spending months building before validating is the classic mistake.\n\nThe Issue: Everyone says \"Great idea!\" but nobody buys. The Fix: Compliments are not validation. Cash is validation. If people say they love it but won't pull out a credit card, you haven't found a painful enough problem, or you are talking to the wrong audience. Revisit Step 1 and narrow your microniche further.\n\nThe Issue: Trying to do everything (marketing, support, dev) alone. The Fix: Utilize the automation tools mentioned in the research. If a task feels repetitive, automate it. Your energy should be spent on talking to users and improving the product, not manual data entry.\n\nQ: Do I really need $0 to start?\n\nA: Strictly speaking, validation costs $0. You can use free social media, free email accounts, and free tiers of landing page builders to gauge interest. Costs only accrue once you start hosting a live application or paying for advanced no-code subscriptions, at which point you should ideally have paying customers to cover those costs.\n\nQ: What if I don't have a technical background?\n\nA: That is the power of the current landscape. Between no-code platforms (like Knack) and AI assistance, the barrier to entry has lowered significantly. The skill you need is problem-solving, not necessarily syntax coding.\n\nQ: How do I know if my niche is \"micro\" enough?\n\nA: If you are competing directly with Google, Microsoft, or Salesforce, your niche is too broad. If you are serving a specific profession (e.g., \"Dentists\") with a specific problem (e.g., \"Patient recall SMS automation\"), you are in the right zone.\n\nQ: What if my idea fails validation?\n\nA: Then you have succeeded. You saved yourself months of development time. The 48-hour validation process is designed to fail fast so you can move on to your next idea without baggage.\n\nThe path to a profitable Micro-SaaS is not paved with complex code or massive venture capital checks. It is paved with conversations, empathy for user problems, and the courage to ship imperfect solutions.\n\nDon't let your idea stay an idea. Go find your niche, ask the hard questions, and ship your solution. The community at r/BuildToShip and the wider indie hacker world is waiting to see what you build.\n\nUnlike generic AI tools, ProofWrite is purpose-built for creating factual, research-backed content that ranks.\n\nStart creating research-backed content today\n\nChoose the plan that fits your content needs. Scale up as you grow.\n\nPlans include automated keyword & product research, trust signal analysis, and factual AI writing. Article and keyword limits reset monthly.\n\nNeed a custom plan? Contact us for enterprise pricing.\n\nEach brief pulls facts from official docs, verified reviews, and community discussions. ProofWrite keeps citations, trust signals, and keyword guidance inline so drafts never hallucinate data.\n\nProofWrite feeds the writer with verified research, trust signals, and any personal experiences you add. Tone and voice controls keep prose specific and conversational.\n\nProofWrite supports product reviews, best-of listicles, and step-by-step how-to guides. Each format has inputs, research crawl, and writing instructions tuned to the brief.\n\nArticles can be written in English, Spanish, French, German, Italian, Dutch, Portuguese, Danish, Norwegian, Finnish, Swedish, Romanian, or Polish.\n\nEdit inside the composer, then push to WordPress with one click or copy the article to your clipboard for other CMSes.\n\nYes. Set tone, POV, and personas, then add personal experiences and AI instructions. ProofWrite threads them through the draft so it reads like someone who actually used the product.\n\nFor long-form writing, ProofWrite uses all the SOTA models: Gemini 3 Pro, Claude Sonnet 4.5, Opus 4.5 and OpenAI's GPT 5.x. Set a workspace-wide default and override per project as needed.\n\nAll research, drafts, and account data stay inside your workspace. We never use your content to train external models or share it with third parties.\n\nStart creating factual, humanized, SEO-optimized articles today.\nFree to try, no credit card needed. Cancel anytime.",
    "readingTime": 12,
    "keywords": [
      "seo aeo",
      "ai-driven automation",
      "profitable micro-saas",
      "proofwrite threads",
      "search engines",
      "classic mistake",
      "venture capital",
      "maximize impact",
      "landing page",
      "dark mode"
    ],
    "qualityScore": 1,
    "link": "https://proofwrite.io/",
    "thumbnail_url": "https://proofwrite.io/og-image.png",
    "created_at": "2025-12-26T12:22:23.991Z",
    "topic": "tech"
  },
  {
    "slug": "wordwrightai-learn-vocabulary-by-writing-not-memorizing",
    "title": "Wordwright.ai – Learn vocabulary by writing, not memorizing",
    "description": "Master new vocabulary through spaced repetition. Contribute to kwakubiney/wordwright.ai development by creating an account on GitHub.",
    "fullText": "kwakubiney\n\n /\n\n wordwright.ai\n\n Public\n\n Master new vocabulary through spaced repetition\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kwakubiney/wordwright.ai",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/kwakubiney/wordwright.ai",
    "thumbnail_url": "https://opengraph.githubassets.com/b2f8057c153e46dc231eabf0aea5b83a9a821d49f38f9c4b94c5573049d7580e/kwakubiney/wordwright.ai",
    "created_at": "2025-12-26T12:22:21.455Z",
    "topic": "tech"
  },
  {
    "slug": "i-spent-a-year-interviewing-and-listening-to-over-50-tech-leaders-talk-about-ai-here-are-the-4-biggest-lessons",
    "title": "I spent a year interviewing and listening to over 50 tech leaders talk about AI. Here are the 4 biggest lessons.",
    "description": "I spent a year listening to tech leaders talk about AI. Here are the biggest lessons on AI, work, superintelligence, and what comes next.",
    "fullText": "I've listened to and interviewed more than 50 tech leaders this year, from executives running trillion-dollar firms to young founders betting their futures on AI.\n\nAcross boardrooms, conferences, and podcast interviews, the people building our AI future kept returning to the same four themes:\n\nThis is the line I heard most often. Nvidia CEO Jensen Huang has said it multiple times this year.\n\n\"Every job will be affected, and immediately. It is unquestionable. You're not going to lose your job to an AI, but you're going to lose your job to someone who uses AI,\" he said at the Milken Institute's Global Conference in May.\n\nOther tech leaders echoed his view, with some saying that younger workers may actually have an edge because they are already comfortable using AI tools.\n\nOpenAI CEO Sam Altman said on Cleo Abram's \"Huge Conversations\" YouTube show in August that while AI will inevitably wipe out some roles, college graduates are better equipped to adjust.\n\n\"If I were 22 right now and graduating college, I would feel like the luckiest kid in all of history,\" Altman said, adding that his bigger concern is how older workers will cope as AI reshapes work.\n\nFei-Fei Li, the Stanford professor known as the \"godmother of AI,\" said in an interview on \"The Tim Ferriss Show\" published earlier this month that resistance to AI is a dealbreaker. She said she won't hire engineers who refuse to use AI tools at her startup, World Labs.\n\nThis shift is already showing up in everyday roles. An accountant and an HR professional told me they're using AI tools, including vibe coding, to level up their skills and stay relevant.\n\nAnother consensus I've heard among tech leaders is that AI makes soft skills more valuable.\n\nSalesforce's chief futures officer, Peter Schwartz, told me in an interview in May that \"the most important skill is empathy, working with other people,\" not coding knowledge.\n\n\"Parents ask me what should my kids study, shall they be coders? I said, 'Learn how to work with others,'\" he said.\n\nLinkedIn's head economist for Asia Pacific, Chua Pei Ying, also told me in July that she sees soft skills like communication and collaboration becoming increasingly important for experienced workers and fresh graduates.\n\nAs AI automates parts of our job and makes teams leaner, the human part of the job is starting to matter more.\n\nAs the year went on, the stakes around AI's future began to feel bigger and more real. Tech leaders increasingly spoke about chasing artificial general intelligence, or AGI, and eventually superintelligence.\n\nAGI refers to AI systems that can match human intelligence across a range of tasks, while superintelligence describes systems that surpass human capabilities.\n\nAltman said in September that society needs to be prepared for superintelligence, which could arrive by 2030. Mark Zuckerberg established Meta's Superintelligence Labs in June and said that the company is pushing toward superintelligence.\n\nThese leaders don't want to miss the AI moment. Zuckerberg underscored that urgency in September, saying he would rather risk \"misspending a couple of hundred billion dollars\" than be late to superintelligence.\n\nSome tech leaders, such as Databricks CEO Ali Ghodsi, argued that the industry has already achieved AGI. Others are more cautious. Google DeepMind's cofounder, Demis Hassabis, said in April that AGI could arrive \"in the next five to 10 years.\"\n\nEven when tech leaders disagree on timelines, they tend to agree on one thing: AI progress is compounding.\n\nI saw this acceleration from the outside as a user. New tools are rolling out at a dizzying pace — from ChatGPT adding shopping features and image generation to China's \"AGI cameras.\"\n\nThings that would have felt magical in January now feel normal.\n\nMany leaders also circled back to the need for human control amid AI acceleration.\n\nMicrosoft AI chief Mustafa Suleyman said superintelligence must support human agency, not override it. He said on an episode of the \"Silicon Valley Girl Podcast\" published in November that his team is \"trying to build a humanist superintelligence,\" warning that systems smarter than humans will be difficult to contain or align with human interests.\n\nAnthropic CEO Dario Amodei has been blunt about the risks AI poses if it's misused.\n\nWhile advanced AI can lower the barrier to knowledge work, the risks scale alongside the rewards, Amodei said on an episode of the New York Times' \"Hard Fork\" published in February.\n\n\"If you look at our responsible scaling policy, it's nothing but AI, autonomy, and CBRN — chemical, biological, radiological, nuclear,\" Amodei said.\n\n\"It is about hardcore misuse in AI autonomy that could be threats to the lives of millions of people,\" he added.\n\nGeoffrey Hinton, often referred to as the \"godfather of AI,\" said in August that as AI systems surpass human intelligence, safeguarding humanity becomes the central challenge.\n\n\"We have to make it so that when they're more powerful than us and smarter than us, they still care about us,\" Hinton said at the Ai4 conference in Las Vegas.",
    "readingTime": 5,
    "keywords": [
      "soft skills",
      "surpass human",
      "tech leaders",
      "human intelligence",
      "tools",
      "systems",
      "workers",
      "published",
      "superintelligence",
      "i've"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-leaders-ai-interview-podcast-conference-lessons-workforce-career-tips-2025-12",
    "thumbnail_url": "https://i.insider.com/694e3d3364858d02d217688f?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.978Z",
    "topic": "finance"
  },
  {
    "slug": "the-rise-of-the-ai-wingman",
    "title": "The rise of the AI wingman",
    "description": "Daters are using AI to slide into the DMs and craft Hinge profiles. A crop of startups and dating apps are fighting for these AI-powered daters.",
    "fullText": "When Rebecca Koltun met a man in the VIP section of a club in Tampa, she didn't ask her friends for advice. She asked ChatGPT.\n\n\"Chat told me no,\" said Koltun, a 26-year-old from St. Petersburg, Florida, who works for a ballet nonprofit. \"It said that this is a guy in a VIP section. He's used to girls' attention. The best thing to do is leave him alone and wait for him.\"\n\nA week later, the man texted Koltun. \"So chat's advice worked,\" she told Business Insider.\n\nKoltun is one of the millions of daters using AI as a coach, therapist, and friend. Dating app swipers use chatbots to refine their profiles. DM sliders use AI to generate their pick-up lines. Anxious blind daters use the tech to ask whether they should text the following morning.\n\nAngling for space on daters' homescreens is a growing, mostly bootstrapped startup space. Apps like Rizz and YourMove, once viral hits, are now establishing stable user bases and say they're profitable. Dating app heavyweights, such as Match Group and Bumble, are engaging in talks with these apps, per the startup founders, and developing their own competitive products.\n\nHow much should we entrust our dating to AI? TikTok is full of daters convinced that they're Hinge matches are using ChatGPT. There's a whole \"South Park\" bit about it, and even a new word: \"chatfishing.\" (While catfishes use fake photos or life stories, chatfishes use AI-altered voices.)\n\nFounders and singles alike say that seeking AI's help is the future of dating, whether we like it or not.\n\nWelcome to the era of the AI wingman.\n\nChase Dennis, an 18-year-old student from Wyoming, uses ChatGPT to slide into DMs. He asks the chatbot for jokes or rhymes, he said, but then edits its output to stay in his own words.\n\nDo the pickup lines go over well? \"It depends on the girl,\" Dennis said. \"Most of them do. Sometimes they just think I'm a cornball.\"\n\nDennis said he often tells the recipients that his pickup lines were AI-generated — and that they mostly found it funny. \"I've been nervous to tell them because they might think I'm unoriginal, but honestly, I think I'm pretty iconic,\" he said.\n\nDaters like Dennis are being courted by three cohorts of businesses: startups, dating apps, and LLM makers.\n\nLeading the startup pack is Rizz, founded by Roman Khaves in 2022. The app offers witty replies and compatibility scores based on dating app chat screenshots. Khaves branded it as an AI dating assistant when the space was still in its infancy. \"Now, there are hundreds of them,\" he said.\n\nRizz has been downloaded by 13 million users since its founding, Khaves said, and has 400,000 monthly active users. The app was profitable from the outset, even before venture capital became interested, he added. Now, when the VCs knock on his door, Khaves said he turns them down.\n\nRacing behind Rizz are companies like YourMove and Roast, founded in 2022 and 2024, respectively. YourMove has \"well over\" 1 million downloads, per its founder, Dmitri Mirakyan. (Mirakyan no longer manages YourMove as he pursues another startup.) Roast has \"millions\" of free users, said its cofounder, Benoit Baylin, and close to 100,000 paying users.\n\nThen there are smaller apps that have grown their audiences. There's Wingman (4,700 paying customers), FireTexts (10,000 installs a month), and Amori, one of the few VC-backed startups in the space (10,000 registered users).\n\nThese startups are mostly oriented around dating apps and DM slides, though they can also be used for flirty messages far beyond a first date.\n\nWho's using these apps? It's hard to say, though FireTexts founder Alex Vilenchik has noticed a divide.\n\n\"I don't know a single female user besides my girlfriend,\" he said.\n\nAs these helpers grow, the big dating apps are threatening to make them obsolete\n\nDating apps are increasingly incorporating AI advisors. Tinder has an AI photo selector; Hinge offers advice on opening lines. Grindr is piloting its own Wingman product, and Chief Product Officer AJ Balance said that feedback has been positive.\n\nThe space is ripe for an acquisition, though none of the founders seems to be biting. Rizz's Khaves said that Match Group's CTO approached him in 2023, but talks ended when Khaves wasn't interested in an acquihire.\n\nYourMove's Mirakyan said that he's had talks with multiple major dating app companies. Roast's Baylin said he talked to Bumble and Match Group — and is unimpressed with the latter's current efforts. Match Group declined to confirm any past potential acquisition conversations; Bumble did not respond to a request for comment.\n\n\"When we see the Tinder photo selection, it's really far behind in terms of tech,\" Baylin said. \"If you take 20 selfies of yourself, those 20 are going to pop up as the potential photo options.\"\n\n(I tested the photo selector for myself — while it didn't pick only selfies, it did pick entirely solo shots, breaking the classic dating app rule that you want at least some group shots to prove you have friends.)\n\nOther founders seemed skeptical about the major dating apps' entrance into the space. Wingman founder Rob Mariani and FireText's Vilenchik both suggested that the companies were too politically correct to be helpful.\n\n\"Are they able to make their AI say, 'Well, dude, have you considered losing weight?'\" Mariani said. \"That's a very impolite thing to say. I don't know if they have it in them to do that.\"\n\nThen there are the AI pioneers themselves. The makers of foundation models and the chatbots they power pose another threat to the AI wingman startups. ChatGPT can generate suggestions for dating app messages or provide feedback for profiles. OpenAI will soon allow erotica for adults, per its CEO Sam Altman, opening up even more opportunities.\n\nThe startup founders must convince daters to seek out a specialized product — and even pay a subscription fee — rather than turning to a traditional chatbot or a built-in AI tool on their go-to dating app.\n\nThen the thornier question remains: Do singles want to bring AI into their dating lives in the first place?\n\nThe Kinsey Institute at Indiana University conducts an annual survey of 5,000 daters in partnership with Match Group. This year, 26% of respondents said that they were using AI while dating. That figure jumped to 38% for active daters.\n\nKinsey Institute research scientist Amanda Gesselman said she heard anecdotally that some daters felt like they were chatting with bots. 33% of respondents said that using AI to generate an entire conversation was a dealbreaker. The daters were more receptive to an AI-generated opening line, she said.\n\nThe biggest sore spot was AI-altered photos, with 40% calling it a dealbreaker.\n\nThere's still some hesitancy from the dating apps, too. While Tinder invests in its AI photo selector, it's still holding back from fully artificial conversations. Claire Watanabe, Tinder's senior director of product, wrote in an email to Business Insider that Tinder should \"never feel like a sea of chatbot-generated content.\"\n\n\"Internally, we've even joked about removing the paste function or adding an em dash detector to flag suspiciously 'AI-ish' writing,\" Watanabe wrote. \"It's half-serious, but the intent is real.\"\n\nDespite all the efforts, it's still unclear whether AI wingmen are a fad or the future. Daksha Franklin, a 36-year-old clinical hypnotherapist from Los Angeles, asked ChatGPT to spruce up her dating profile — and wasn't thrilled with the results.\n\n\"I just didn't like it, so I went with my own words,\" she said.\n\nFranklin isn't an AI pessimist, though. She also asked ChatGPT to describe her dream man so she could narrow down her preferences.",
    "readingTime": 7,
    "keywords": [
      "vip section",
      "startup founders",
      "dating app",
      "dating apps",
      "daters",
      "space",
      "users",
      "it's",
      "startups",
      "product"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-wingman-dating-helper-tinder-hinge-pickup-lines-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693afe3a04eda4732f2d5db7?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.858Z",
    "topic": "finance"
  },
  {
    "slug": "i-left-my-dream-job-as-a-trial-attorney-and-pivoted-into-ai-at-age-40-it-showed-me-the-power-of-leaving-my-comfort-zone",
    "title": "I left my dream job as a trial attorney and pivoted into AI at age 40. It showed me the power of leaving my comfort zone.",
    "description": "Aurora Bryant, 40, stopped practicing law  to work for Relativity, an AI-powered legal data intelligence company. She said it paid off.",
    "fullText": "This as-told-to essay is based on a conversation with Aurora Bryant, 40, the senior legal data intelligence lead at Relativity. She's based in New York. Her former and current employment have been verified by Business Insider. This piece has been edited for length and clarity.\n\nI didn't expect my career to pan out this way.\n\nWhen I started reading John Grisham novels late into the night in fifth grade, I knew that I wanted to become a lawyer. I was drawn to the sense of justice in those books.\n\nI never strayed from my goal. I attended law school and spent 15 years in the profession, including a decade at the US Department of Justice.\n\nNow, at 40, I'm no longer practicing law. Instead, I'm the senior legal data intelligence lead at Relativity, where we use AI to solve complex legal challenges.\n\nPivoting to AI was scary but exciting. I'm glad I did it.\n\nI studied economics at Tulane University in New Orleans while working as a file clerk at a local law firm, then graduated from law school at Northwestern University in Chicago in 2010.\n\nAfter working for over a year at the law firm in New Orleans, where I had previously worked as a law clerk, and then at a nonprofit, I joined a civil rights organization in New Orleans in 2011. There, I investigated and litigated housing and lending discrimination cases in Louisiana.\n\nIn 2015, I landed my dream job as a trial attorney for the Department of Justice's Civil Rights Division and relocated to Washington, D.C., where I stayed for just over a decade.\n\nThe DOJ had a nationwide mandate, unlike my previous jobs, so my work touched people's lives all over the country. It was a fulfilling and rewarding role, and my favorite part was bringing relief to victims of unlawful discrimination.\n\nMy least favourite part was the limited resources. Every workplace has constraints, but at the DOJ, we didn't have access to certain modern technologies we needed to be more efficient, which often created bottlenecks. My frustration motivated me to explore how new technologies were being applied within law.\n\nEven three years ago, I knew very little about AI beyond headlines about lawyers filing briefs filled with fake cases. It was baffling, as lawyers put our reputations behind what we submit to the court.\n\nAs part of my work as a trial attorney, I got involved with various groups within the DOJ focused on eDiscovery, which is the process of collecting, reviewing, and producing electronically stored information that's relevant to a legal case, such as evidence from computers or phones.\n\nThrough these groups, I started attending conferences in 2018. In recent years, I've observed at these conferences how AI is being applied within the practice of law.\n\nIn 2023, I transitioned from being a trial attorney to a newly created position as an eLitigation Counsel, where I developed templates, guides, and best practices to streamline eDiscovery work in the Civil Rights Division.\n\nFrustrated that I couldn't bring in all the technologies we needed, partly due to limited resources, it became clear to me earlier this year that my future wasn't at the DOJ. I began considering my next steps.\n\nI was offered my role at Relativity in mid-2025 and made the jump to working in legal technology full time.\n\nJust as it was important 20 years ago to learn how to use a computer for daily tasks, I believe it will become equally important to be able to leverage AI. As technology evolves, we have to evolve with it.\n\nAt Relativity, I collaborate with data scientists, engineers, product leaders, designers, and customers to ensure that our generative AI solutions are developed in ways that meet the needs of attorneys and case teams. I'm learning new things every day. I even wrote a bit of code the other week.\n\nI've learned that before deciding what's next, you have to understand your goals, what you enjoy, and how you can best leverage your experience. I knew that my goal was to find new ways to do innovative work that would make a difference in my industry.\n\nI draw on my 15 years of experience practicing law to help optimize Relativity's products.\n\nI've increasingly seen the importance of harnessing and leveraging technology for the success of investigations and litigations. When I took the eLitigation role, I could see that bringing solutions to case teams working to advance civil rights was more sustainable and satisfying to me than being in an adversarial posture in litigation every day.\n\nWhile it was a scary career move, it was also empowering to be able to lean fully into innovation.\n\nI've learned that it's important to be prepared to step outside your comfort zone. It's hard to say \"don't be afraid to take risks,\" because lawyers are usually risk-averse. But I didn't see my career pivot as a risk; I saw it as an exciting opportunity to try something new. I'm developing a whole new area of expertise.\n\nOne of the most exciting things about this job is that I don't always know what's coming next. Thankfully, I love to learn new things, and I'm excited for whatever the future holds, whether it's learning to code a little more or something else entirely.",
    "readingTime": 5,
    "keywords": [
      "rights division",
      "i've learned",
      "intelligence lead",
      "limited resources",
      "trial attorney",
      "applied within",
      "civil rights",
      "senior legal",
      "law school",
      "practicing law"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-change-career-at-40-lawyer-experience-goals-2025-12",
    "thumbnail_url": "https://i.insider.com/6943f150832e0ef1ead67433?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.683Z",
    "topic": "finance"
  },
  {
    "slug": "scribe-raised-75-million-at-a-13-billion-valuation-to-fix-how-companies-adopt-ai-read-its-pitch-deck",
    "title": "Scribe raised $75 million at a $1.3 billion valuation to fix how companies adopt AI. Read its pitch deck.",
    "description": "Workflow software startup Scribe has raised $75 million and achieved unicorn status, as it aims to reimagine AI integration for businesses.",
    "fullText": "Scribe, a workflow software startup that helps companies document internal processes and implement AI, has raised $75 million at a $1.3 billion valuation, the company announced.\n\nStepStone led Scribe's Series C round, with participation from existing investors, including Amplify Partners, Redpoint Ventures, Tiger Global, Morado Ventures, and New York Life Ventures.\n\nCEO Jennifer Smith — a former Greylock and McKinsey consultant — and CTO Aaron Podolny cofounded the company, which now has two major products.\n\nScribe Capture records how expert employees conduct workflows via a browser extension or desktop app, and then it generates shareable documentation. This includes screenshots and written instructions to help standardize processes and \"institutional know-how\" like onboarding, customer support, and training, Smith said.\n\nIts latest product is Scribe Optimize, which analyzes workflows within a company to show leaders areas of improvement and ways to adopt AI. It also draws on a database of 10 million workflows across 40,000 software applications that Scribe has already documented to suggest areas for automation.\n\n\"AI can't improve what it can't see,\" Smith said. \"You can't just sprinkle AI into your business and expect that it's going to magically make everything better. The missing ingredient is context and data.\"\n\nScribe has 120 employees and over 75,000 customers — including New York Life, T-Mobile, and LinkedIn — with 44% of the Fortune 500 paying for the service, the company said.\n\nSmith said Scribe has been \"unusually capital efficient,\" having not spent any of the funding from its last $25 million raise in 2024. The team chose to raise this year to accelerate Optimize's rollout and build follow-on products, she said.\n\nHere's a look at the pitch deck Scribe used to raise its $75 million Series C funding round. Some slides have been redacted and removed so that the deck can be shared publicly.",
    "readingTime": 2,
    "keywords": [
      "york life",
      "smith",
      "ventures",
      "workflows",
      "can't",
      "scribe",
      "software",
      "processes",
      "round",
      "products"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/scribe-pitch-deck-75-million-fix-how-companies-adopt-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/694ab855832e0ef1ead6bafa?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.681Z",
    "topic": "finance"
  },
  {
    "slug": "how-y-combinator-founders-are-pitching-the-ai-boom",
    "title": "How Y Combinator founders are pitching the AI boom",
    "description": "Y Combinator pitch decks raised millions in funding in 2025, as AI reshapes industries and expectations for young founders rise fast.",
    "fullText": "Y Combinator founders seized the AI boom in 2025, with increasingly younger teams securing millions in seed funding.\n\nFounders launched companies ranging from military night vision goggles to US work visa automation and AI-native video meeting platforms. One common thread: founders are getting younger, including teens who left MIT, Stanford, and even high school to attend the program. The median founder age of YC's summer 2025 cohort was 24, down from 30 in 2022.\n\nFounders are also harnessing AI to build faster. Some told Business Insider they were expected to arrive at Demo Day with more customers and clearer revenue signals.\n\nY Combinator says its batches are now growing revenue at roughly 10% week-over-week — a stat that's remained consistent across the last six classes.\n\nBelow are the YC pitch decks we published in 2025 — a window into how early-stage founders are pitching in an era when AI is poised to reshape industries, and expectations for young founders are rising fast.",
    "readingTime": 1,
    "keywords": [
      "founders",
      "combinator",
      "younger",
      "revenue"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/how-y-combinator-founders-are-pitching-the-ai-boom-2025-12",
    "thumbnail_url": "https://i.insider.com/6945885e64858d02d2172783?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.606Z",
    "topic": "finance"
  },
  {
    "slug": "some-elite-ai-researchers-say-language-is-limiting-heres-the-new-kind-of-model-they-are-building-instead",
    "title": "Some elite AI researchers say language is limiting. Here's the new kind of model they are building instead.",
    "description": "Top AI researchers like Fei-Fei Li and Yann LeCun are developing world models, which don't rely solely on language.",
    "fullText": "As OpenAI, Anthropic, and Big Tech invest billions in developing state-of-the-art large language models, a small group of elite AI researchers is working on what they say is the next big thing.\n\nComputer scientists like Fei-Fei Li, the Stanford professor famous for inventing ImageNet, and Yann LeCun, Meta's outgoing chief AI scientist, are building what they call \"world models.\"\n\nUnlike large language models, which determine outputs based on statistical relationships between words and phrases, world models anticipate outcomes by mimicking the mental constructs that humans make of the world around them.\n\n\"Humans,\" Li said on an episode of Andreessen Horowitz's A16z podcast in June, \"not only do we survive, live, and work, but we build civilization beyond language.\"\n\nPut simply, world models are AI systems that anticipate what will happen next, much like humans use intuition based on their experience to predict the consequences of their actions. Think of a child who, with no language skills, will learn to understand that if they push a toy car, it will roll.\n\nComputer scientist and MIT professor, Jay Wright Forrester, in his 1971 paper \"Counterintuitive Behavior of Social Systems,\" explained why mental models are crucial to human behavior:\n\nIf AI is to meet or surpass human intelligence, then the researchers behind it believe it should be able to make mental models, too.\n\nLi has been working on this through World Labs, which she cofounded in 2024 with an initial backing of $230 million from venture firms like Andreessen Horowitz, New Enterprise Associates, and Radical Ventures. \"We aim to lift AI models from the 2D plane of pixels to full 3D worlds — both virtual and real — endowing them with spatial intelligence as rich as our own,\" World Labs says on its website.\n\nLi said on the \"No Priors\" podcast in June that spatial intelligence is \"the ability to understand, reason, interact, and generate 3D worlds,\" given that the world is fundamentally three-dimensional.\n\nLi said she sees applications for world models in creative fields, robotics, or any area that warrants infinite universes.\n\nThe challenge of building world models is the paucity of sufficient data. In contrast to language, which humans have refined and documented over centuries, spatial intelligence is less developed.\n\n\"If I ask you to close your eyes right now and draw out or build a 3D model of the environment around you, it's not that easy,\" she said on the \"No Priors\" podcast. \"We don't have that much capability to generate extremely complicated models till we get trained.\"\n\nTo gather the data necessary for these models, \"we require more and more sophisticated data engineering, data acquisition, data processing, and data synthesis,\" she said.\n\nThat makes the challenge of building a believable world even greater.\n\nLeCun, who is leaving his post as the chief AI scientist at Meta at the end of the year to launch his own startup called Advanced Machine Intelligence, has long been fixated on world models, which he says are more competent than large language models because they have common sense, the capacity to reason and plan, and persistent memory.\n\nIn a November LinkedIn post announcing his new venture, LeCun said the company's goal is to \"bring about the next big revolution in AI: systems that understand the physical world, have persistent memory, can reason, and can plan complex action sequences.\"\n\nOn December 19, LeCun said on LinkedIn that he was recruiting Alex LeBrun, the cofounder and CEO of Nabla, an AI assistant for clinicians, as CEO of AMI Labs.\n\nIn a Nabla press release announcing the transition, LeBrun said, \"Healthcare AI is entering a new era, one where reliability, determinism, and simulation matter as much as linguistic intelligence.\"\n\n\"This partnership builds on that shared vision and gives Nabla privileged access to world model technology that will complement today's LLMs and help unlock the safe, autonomous systems clinicians need,\" he added.\n\nPrior to the launch of AMI Labs, LeCun and a small team of researchers were working on a similar project at Meta, using video data to train models and run simulations that abstract the videos at different levels.\n\n\"The basic idea is that you don't predict at the pixel level. You train a system to run an abstract representation of the video so that you can make predictions in that abstract representation, and hopefully this representation will eliminate all the details that cannot be predicted,\" he said at the AI Action Summit in Paris earlier this year.\n\n\"We're thinking about world models and visual multimodal intelligence. We want to move beyond purely visual systems into something broader — models that understand not just what they see, but how the world works,\" Moonvalley's chief scientific officer, Mateusz Malinowski, told Business Insider.\n\nApplications for world models include humanoid robotics and real-world planning, he said. The company says it is already training robots on its world models.\n\nIn a follow-up email, Malinowski explained the differences between these newer world models and existing vision models, which are used for tasks from facial recognition to object tracking.\n\n\"I'd start with saying that vision model is a very broad term,\" Malinowski wrote. \"If we're referring to text-to-video generation models, from my vantage point, these models can be seen as the first steps for world models. World models emphasize world simulation, adherence to physical reality, long-term consistency of the environment, and action-conditioned generation.\"\n\nThat said, Malinowski notes key differences between the world models being built by Moonvalley and those under development at World Labs.\n\n\"I believe that long-term goals are the same, but we are approaching the problem of world modelling differently,\" he wrote. \"We focus on using video models as first-class citizens, where spatial intelligence is more implicit. In the short term, our approach seems more suited for filmmaking and robotics due to motion and soft bodies modelling.\"",
    "readingTime": 5,
    "keywords": [
      "priors podcast",
      "ami labs",
      "persistent memory",
      "abstract representation",
      "spatial intelligence",
      "mental models",
      "world labs",
      "language models",
      "no priors",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/world-model-ai-explained-2025-6",
    "thumbnail_url": "https://i.insider.com/694431b204eda4732f2dc9c5?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.515Z",
    "topic": "finance"
  },
  {
    "slug": "5-ai-advertising-controversies-that-turned-heads-this-year-from-metas-ai-granny-to-cocacolas-shapeshifting-trucks",
    "title": "5 AI advertising controversies that turned heads this year, from Meta's AI granny to Coca-Cola's shape-shifting trucks",
    "description": "Brands, from McDonald's to H&M, drew backlash in some quarters over their AI-driven ads and marketing experiments.",
    "fullText": "Chief marketing officers at many of the world's biggest brands made artificial intelligence a centerpiece of their strategies this year.\n\nFor some brands, the enthusiasm ran into risky territory. From AI-generated ads that veered into the \"uncanny valley\" to backlash over replacing human models and advertising creatives, AI's growing role in advertising fueled a string of controversial marketing moments. The AI backlash even led to its own marketing trend: brands hating on AI.\n\nA survey of more than 6,000 US consumers conducted by the brand-tracking platform Tracksuit in November found that overall sentiment toward AI-generated advertising skewed negative (39%). Neutrality was also strong among respondents, at 36%, while only 18% felt positive about brands using AI-generated content in their ads.\n\nMatt Barash, chief commercial officer of the adtech platform Nova, said that while AI can be a useful tool for buying and placing ads, brands should be cautious when attempting to automate the creative process.\n\n\"When brands ask AI to invent stories from scratch, they don't get innovation — they get an approximation of human emotion, and the result can make headlines for all of the wrong reasons,\" Barash said.\n\nIndeed, several major marketers did make the news for their AI-related mishaps this year. Take a look at some of the most notable AI advertising controversies of the year, below.\n\nMcDonald's Netherlands cooked up an AI-generated holiday ad this month — and quickly sent it back to the kitchen when it became clear that viewers weren't lovin' it.\n\nThe \"most terrible time of the year\" ad was intended to be a satirical take on Christmas calamities that could occur over the festive period. The 45-second spot featured a quickfire montage of cooking mishaps, broken bones at the ice rink, and Santa's sleigh getting stuck in a traffic jam. The brand suggested its restaurants could act as a shelter from the chaos. \"Hide out in McDonald's 'til January's here,\" the ad's narrator said.\n\nSome social media commentators denounced the fast-food chain as a McGrinch, complaining the ad had a cynical sentiment and \"creepy\" characters. After initially turning off the comments on the ad's YouTube video, McDonald's later removed the ad from the site altogether.\n\nIn a statement, McDonald's Netherlands said that while the ad was intended to reflect some of the stressful moments that the holidays can bring, it recognized that many of its customers feel the season is \"the most wonderful time of the year.\"\n\n\"We respect that and remain committed to creating experiences that offer Good Times and Good Food for everyone,\" the statement said.\n\nCoca-Cola already had one AI-generated holiday ad misfire under its belt, after last year's \"Holidays are Coming\" rendition was criticized as \"dystopian\" and \"soulless.\" Despite that, this year it released three AI-generated holiday ads.\n\nOne of the ads, another AI rendition of the classic \"Holidays are Coming\" spot, caught the attention of the eagle-eyed creative community due to its lack of consistency. Sure, the wheels on the trucks went round and round — a criticism of last year's ad was that they appeared to glide across the road — but they also appeared to change in quantity as the ad rolled on.\n\nIn the spirit of Christmas, Dino Burbidge, an independent innovation specialist, shared the gift of this handy graphic to help everyone follow along:\n\nPJ Pereira, cofounder of Silverside AI, the production company behind the ad, defended Coca-Cola's use of AI in a statement.\n\n\"Coca-Cola became a pioneer in this space because, once they recognized AI as the future, they stopped debating whether it's perfect or not — and instead focused on how to use it in the best, most creative way possible,\" Pereira said.\n\nPereira also said that the ad performed well with consumers in testing. System1, which rates ads on a scale from 1 to 5.9 stars on their potential to drive long-term growth for brands, gave the 2025 \"Holidays are Coming\" ads the highest possible score: 5.9. A separate creative testing company, DAIVID, said the ad generated higher-than-average attention and brand recall scores.\n\nApparel brand True Classic is a poster child of digital performance marketing, honing platforms like Facebook and Instagram to build a community of devoted customers — typically men ages 30 to 45.\n\nSo imagine its marketing chief's shock when he realized Meta's ad platform had swapped out his top-performing ad — a millennial man in a matching fleece set, casually posing on a stool — with that of a cheerful, yet clearly AI-generated granny sitting in an armchair.\n\nHow do we go from this… to AI grandma. pic.twitter.com/n3cryUpLaT\n\nAdvertisers told Business Insider earlier this year that settings within Meta's Advantage+ suite of AI-powered ad products had led to the platform automatically generating ad creatives on their behalf.\n\nIn a statement, Meta said that advertisers who use its full image generation feature can review the images before running their ads.\n\nBut three advertisers also told Business Insider they'd encountered a problem where Meta automatically switched those toggles to \"on,\" even when they'd explicitly turned them off — meaning they inadvertently spent some of their budgets on AI-generated ads they didn't intend to run.\n\nAI has helped take airbrushing to the next level. Some brands are experimenting with using generative AI to eliminate photo shoots altogether — with mixed results.\n\nTake fast-fashion retailer H&M. In March, the company announced a plan to create \"digital twins\" of 30 models whose images could be used for social media posts and ad campaigns. H&M said the models would own the rights to their twins, which would include the ability to allow other brands to use them.\n\nH&M was aware that the move would be controversial.\n\n\"People will be divided. You know, 'Is this good? Is this bad?'\" Jörgen Andersson, H&M chief creative officer, told Business of Fashion at the time.\n\nH&M certainly got chins wagging. American fashion influencer Morgan Riddle described the plan as \"shameful.\" Sara Ziff, founder of Model Alliance, a nonprofit that focuses on workers' rights in the fashion industry, said the plan raised \"serious concerns.\"\n\n\"In an industry that has historically been a backwater for workers' rights, H&M's new initiative raises critical questions about consent and compensation, and has the potential to replace a host of fashion workers — including make-up artists, hair stylists, and other creative artists in our community,\" Ziff said in a statement.\n\nIn a statement sent to Business Insider for this article, an H&M spokesperson said that the brand was exploring how generative AI can support the creative process in thoughtful and responsible ways.\n\n\"We recognize that generative AI raises important questions and concerns, and we want to be transparent in acknowledging that we do not yet have all the answers, but are continuing to learn and evolve,\" the H&M spokesperson said.\n\nH&M wasn't the only fashion brand to give AI models a twirl this year.\n\nReaders flicking through the August 2025 issue of Vogue noticed ads for Guess carried a small label/disclaimer: \"Produced by Seraphinne Vallora on AI.\" The models, \"Vivienne\" and \"Anastasia,\" were created using AI by a London-based AI marketing agency.\n\nSocial media users slammed the ad, saying the images pushed unrealistic beauty standards and that the use of AI imagery portended bad news for creative industry jobs. Some online commenters said they would cancel their Vogue subscriptions in protest. (Vogue publisher Condé Nast said at the time that an AI model had never appeared \"editorially\" in Vogue.)\n\nThe cofounders of Seraphinne Vallora said in an interview with \"Good Morning America\" that they were looking to supplement the modeling industry, not replace it.\n\nVogue is facing criticism for running a Guess ad that used AI-generated models in its latest issue. Stephanie Ramos has more on the controversy and what it means for the fashion industry. #vogue #ai #aigenerated #fashion\n\n\"We are here to co-exist together, and we will always see photography, stylists, and everyone involved in a photo shoot as incredibly important,\" said Valentina Gonzalez, one of the cofounders.\n\nAI models and the controversies surrounding them weren't a new advertising phenomenon for 2025. Brands such as Mango and Levi's have also faced a similar backlash for featuring AI-generated models in their marketing in recent years. A new trend does appear to be emerging, though. Brand partnerships with AI social accounts dropped by around 30% in the first eight months of 2025 compared to the same period in 2024, according to transaction data from hundreds of campaigns provided by the influencer-marketing platform Collabstr.\n\nCould AI models be the latest fast-fashion casualty?",
    "readingTime": 8,
    "keywords": [
      "ai-generated holiday",
      "social media",
      "workers rights",
      "creative process",
      "ai-generated models",
      "ai-generated ads",
      "fashion industry",
      "business insider",
      "mcdonald's netherlands",
      "seraphinne vallora"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-advertising-controversies-flops-coca-cola-mcdonalds-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/690aff720be9845f2dc5bebd?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.485Z",
    "topic": "finance"
  },
  {
    "slug": "12-executives-researchers-others-who-left-openai-in-2025-mostly-to-meta-superintelligence-lab",
    "title": "12 executives, researchers, others who left OpenAI in 2025 — mostly to Meta Superintelligence Lab",
    "description": "Meta poached at least seven OpenAI researchers over summer. Here are some big names who left the startup in 2025.",
    "fullText": "OpenAI had a year of high-profile departures.\n\nOver the summer, the ChatGPT creator lost at least seven researchers and scientists to Meta's billion-dollar effort to beef up its AI team at its Superintelligence Lab.\n\nThis came after the company saw an exodus of top executives in 2024 amid a restructuring effort, including chief technology officer Mira Murati, chief research officer Bob McGrew, and vice president of research Barret Zoph.\n\nCEO Sam Altman is now one of only two active remaining members of the company's original 11-person founding team.\n\nHere's a running list of researchers and executives OpenAI has lost this year and where they've ended up.\n\nWei, a research scientist who worked on OpenAI's o1 and deep research models, left in July for Meta's Superintelligence Lab.\n\nSun, who left for Meta's Superintelligence Labs in July, was a research scientist at OpenAI.\n\nChung is part of the trio of OpenAI research scientists who departed for Meta's Superintelligence Lab in July. He posted on LinkedIn alongside his two colleagues that they are having \"so much fun building from a clean slate with a truly talent-dense team.\"\n\nZhao became the chief scientist of the Meta Superintelligence Lab in July after co-creating ChatGPT and GPT-4 at OpenAI. The prominent researcher is working directly with Mark Zuckerberg and Chief AI Officer Alexandr Wang .\n\nYu is widely credited with leading the Perception team in OpenAI to develop the \"senses\" of a Large Language Model, including images, audio, and sensor readings. He departed for Meta's Superintelligence Lab in late June.\n\nRen was poached by Meta's Superintelligence Lab over the summer. He was a core contributor to OpenAI's GPT-4o model.\n\nBi was an OpenAI researcher on multimodal and reinforcement learning. He left in June for Meta's Superintelligence Lab to work on reinforcement learning, post-training, and AI agents.\n\nSummers, who is also a former Treasury secretary and former Harvard president, resigned from the OpenAI board in November. The resignation came shortly after a House panel released years of email exchanges between Summers and Jeffrey Epstein, who was charged with sex trafficking minors.\n\nIn August, Villagra resigned as chief people officer after being promoted to the role in March.\n\nFedus was the vice president of research and post-training at OpenAI until he left the company in March. In September, he co-founded an AI startup called Periodic Labs, which aims to create an AI scientist.\n\nCunningham was OpenAI's data scientist and economic researcher until he resigned in November. He joined Model Evaluation and Threat Research, a non-profit research institute that evaluates AI models' capabilities and safety level.\n\nWeeks before the end of the year, Wong, OpenAI's chief communications officer, announced her departure for her \"next chapter,\" according to a post on her LinkedIn. She added that Lindsey Held Bolton will lead the communications team as the interim, while the company searches for a new CCO. It is unclear what Wong's next job will be.",
    "readingTime": 3,
    "keywords": [
      "superintelligence lab",
      "meta's superintelligence",
      "reinforcement learning",
      "vice president",
      "research scientist",
      "chief",
      "team",
      "officer",
      "researcher",
      "resigned"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/executives-board-members-and-researchers-who-left-openai-in-2025-2025-12",
    "thumbnail_url": "https://i.insider.com/6941b60104eda4732f2d9f64?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.332Z",
    "topic": "science"
  },
  {
    "slug": "prediction-this-will-be-2026s-topperforming-artificial-intelligence-stock",
    "title": "Prediction: This Will Be 2026's Top-Performing Artificial Intelligence Stock",
    "description": "Nvidia is still one of the best AI stocks available.",
    "fullText": "The market for AI computing devices is massive and growing.\n\nNvidia is sold out of cloud GPUs.\n\nNvidia's stock price tag is actually quite reasonable.\n\n10 stocks we like better than Nvidia ›\n\nThe artificial intelligence (AI) buildout has been ongoing since 2023, but it's far from over.\n\nThe AI hyperscalers have nearly completed their record-setting capital expenditures for 2025, but they've already informed their investors that 2026 will be a year of even greater spending. While some investors are growing worried over those figures, some of the smartest people in the world think we need more AI computing power, and going against that trend likely isn't a smart move for investors.\n\nInvestors need to find the companies that are slated to cash in on these massive data center buildouts, and there are a handful of companies that can. One of the best to own over the past three years has been Nvidia (NASDAQ: NVDA). It has delivered investors excellent returns, and seems poised to do so again in 2026.\n\nWhile I can't say for certain if Nvidia will be the best AI stock for 2026, I'm fairly confident it will be one of the best AI stocks, and it is also an attractive bet that it will outperform the market. These two projections combine to make Nvidia an excellent buy right now, and I can think of few better stocks to scoop up in the last few days of 2025.\n\nNvidia makes graphics processing units (GPUs) and the technology stack that supports them. Combined, Nvidia's technology is the most flexible and easiest to use, and has some of the best performance available. This has made it the go-to computing unit of choice since the AI race began, but investors are worried that the company's dominance is slipping.\n\nHeadlines are filled with rising competition from AMD or how Broadcom has signed another client to spec out a custom AI chip. There are also innovative companies like Amazon that designed their own chip for their cloud computing platform. All of those headlines make it seem like Nvidia's grasp on the market is slipping, but that couldn't be further from the truth.\n\nIn its FY 2026 third quarter (ended Oct. 26) earnings release, CEO Jensen Huang noted that the company was \"sold out\" of cloud GPUs. Although Nvidia is ramping up production as fast as it can, it is unable to meet the current computing demands of the market. As a result, clients are starting to look elsewhere to meet their massive computing demands. While they may prefer Nvidia hardware, some computing power is better than none.",
    "readingTime": 3,
    "keywords": [
      "cloud gpus",
      "computing demands",
      "investors",
      "market",
      "massive",
      "stocks",
      "nvidia",
      "stock",
      "worried",
      "excellent"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/prediction-2026s-top-performing-artificial-085000921.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/0.Whp9V_CUbQ9dHG4EeK8w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/7cb26258cd01fdc5f1b04576fbc9c179",
    "created_at": "2025-12-26T12:22:19.156Z",
    "topic": "finance"
  },
  {
    "slug": "our-king-priest-and-feudal-lord-how-ai-is-taking-us-back-to-the-dark-ages-joseph-de-weck",
    "title": "Our king, priest and feudal lord – how AI is taking us back to the dark ages | Joseph de Weck",
    "description": "Since the Enlightenment, we’ve been making our own decisions. But now AI may be about to change that\nThis summer, I found myself battling through traffic in the sweltering streets of Marseille. At a crossing, my friend in the passenger seat told me to turn right toward a spot known for its fish soup. But the navigation app Waze instructed us to go straight. Tired, and with the Renault feeling like a sauna on wheels, I followed Waze’s advice.",
    "fullText": "Since the Enlightenment, we’ve been making our own decisions. But now AI may be about to change that\n\nThis summer, I found myself battling through traffic in the sweltering streets of Marseille. At a crossing, my friend in the passenger seat told me to turn right toward a spot known for its fish soup. But the navigation app Waze instructed us to go straight. Tired, and with the Renault feeling like a sauna on wheels, I followed Waze’s advice. Moments later, we were stuck at a construction site.\n\nA trivial moment, maybe. But one that captures perhaps the defining question of our era, in which technology touches nearly every aspect of our lives: who do we trust more – other human beings and our own instincts, or the machine?\n\nThe German philosopher Immanuel Kant famously defined the Enlightenment as “man’s emergence from his self-imposed immaturity.” Immaturity, he wrote, “is the inability to use one’s understanding without guidance from another”. For centuries, that “other” directing human thought and life was often the priest, the monarch, or the feudal lord – the ones claiming to act as God’s voice on Earth. In trying to understand natural phenomena – why volcanoes erupt, why the seasons change – humans looked to God for answers. In shaping the social world, from economics to love, religion served as our guide.\n\nHumans, Kant argued, always had the capacity for reason. They just hadn’t always had the confidence to use it. But with the American and later the French Revolution, a new era was dawning: reason would replace faith, and the human mind, unshackled from authority, would become the engine of progress and a more moral world. “Sapere aude!” or “Have courage to use your own understanding!”, Kant urged his contemporaries.\n\nTwo and a half centuries later, one may wonder whether we are quietly slipping back into immaturity. An app telling us which road to take is one thing. But artificial intelligence threatens to become our new “other” – a silent authority that guides our thoughts and actions. We are in danger of ceding the hard-won courage to think for ourselves – and this time, not to gods or kings, but to code.\n\nChatGPT was launched only three years ago, and already one global survey, published in April, found that 82% of respondents had used AI in the previous six months. Whether deciding to end a relationship or who to vote for, people are turning to machines for advice. According to OpenAI, 73% of user prompts concern non work-related topics. Even more intriguing than our dependence on AI’s judgment in daily life is what happens when we let it speak for us. Writing is now among the most common uses of ChatGPT, second only to practical requests such as DIY or cooking advice. The American author Joan Didion once said: “I write entirely to find out what I am thinking.” What happens when we stop writing? Do we stop finding out?\n\nWorryingly, some evidence suggests that the answer might be yes. A study by the Massachusetts Institute of Technology used electroencephalography (EEG) to monitor the brain activity of essay writers given access to AI, search engines like Google, or nothing at all. Those who could rely on AI showed the lowest cognitive activity and struggled to accurately quote their work. Perhaps most concerning was that over a couple of months, participants in the AI group became increasingly lazy, copying entire blocks of text in their essays.\n\nThe study is small and imperfect, but Kant would have recognised the pattern. “Laziness and cowardice,” he wrote, “are the reasons why so great a proportion of men … remain in lifelong immaturity, and why it is so easy for others to establish themselves as their guardians. It is so easy to be immature.”\n\nSure, AI’s appeal lies in its convenience. It saves time, spares effort and – crucially – offers a new way to offload responsibility. In his 1941 book, Escape from Freedom, the German psychoanalyst Erich Fromm argued that the rise of fascism could be explained in part by people preferring to surrender their freedom in exchange for the reassuring certainty of subordination. AI offers a new way of surrendering that burden of having to think and decide for yourself.\n\nAI’s greatest allure is that it can do things our minds can’t – sift through oceans of data and process it at unprecedented speed. Sitting in the car in Marseille, this was, after all, why I chose to trust the machine instead of my friend in the passenger seat (a decision she took as an insult). With access to all the data, surely the app must know best – or so I thought.\n\nThe problem is that AI is a black box. It produces knowledge, but without necessarily deepening human understanding. We don’t really know how AI reaches its conclusions – even the programmers admit as much. Nor can we verify its reasoning against clear, objective criteria. So when we follow AI’s advice, we are not guided by reason. We are back in the realm of faith. In dubio pro machina: when in doubt, trust the machine – that may become our future guiding principle.\n\nAI can be a formidable ally to humans in rational inquiry. It can help us invent drugs, or free us from “bullshit jobs”, or doing our taxes – tasks that demand little thought and offer little satisfaction. All the better. But Kant and his contemporaries did not plead the case of reason over faith just so humans could build better shelves or have more spare time. Critical thinking was not just about efficiency – it was a practice of freedom and human emancipation.\n\nHuman thinking is messy and full of errors, but it forces us to debate, to doubt, to test ideas against one another – and to recognise the limits of our own understanding. It builds confidence, both individually and collectively. For Kant, the exercise of reason was never just about knowledge; it was about enabling people to become agents of their own lives, and resist domination. It was about building a moral community grounded in the shared principle of reason and debate, rather than blind belief.\n\nWith all the benefits AI brings, the challenge is this: how can we harness its promise of superhuman intelligence without eroding human reasoning, the cornerstone of the Enlightenment and of liberal democracy itself? That may be one of the defining questions of the 21st century. It is one we would do well not to delegate to the machine.\n\nJoseph de Weck is a fellow with the Foreign Policy Research Institute",
    "readingTime": 6,
    "keywords": [
      "passenger seat",
      "advice",
      "machine",
      "immaturity",
      "understanding",
      "later",
      "trust",
      "without",
      "faith",
      "human"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/26/ai-dark-ages-enlightenment",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c286aefbf8fbc284b63efe447bf403ee219674d4/1669_2166_1874_1499/master/1874.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=0d18e83eac0aa3e16f977ac4d8d4e710",
    "created_at": "2025-12-26T12:22:18.418Z",
    "topic": "tech"
  },
  {
    "slug": "coforge-to-acquire-ainative-firm-encora-for-235-billion",
    "title": "Coforge to acquire AI-native firm Encora for $2.35 billion",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/coforge-to-acquire-ainative-firm-encora-for-235-billion-93CH-4423060",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2025-12-26T12:22:17.193Z",
    "topic": "finance"
  },
  {
    "slug": "debug-buddy-a-chrome-extension-for-console-errors-using-claude",
    "title": "Debug Buddy – A Chrome extension for console errors using Claude",
    "description": "Debug Buddy is a Claude AI-powered Chrome extension that analyzes JavaScript console errors in real time and provides actionable fix suggestions using Claude. Built as a local-first, privacy-respec...",
    "fullText": "mechramc\n\n /\n\n debug-buddy-claude\n\n Public\n\n Debug Buddy is a Claude AI-powered Chrome extension that analyzes JavaScript console errors in real time and provides actionable fix suggestions using Claude. Built as a local-first, privacy-respecting developer tool with zero backend dependencies.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mechramc/debug-buddy-claude",
    "readingTime": 1,
    "keywords": [
      "star",
      "claude",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/mechramc/debug-buddy-claude",
    "thumbnail_url": "https://opengraph.githubassets.com/43ab2a200d669111862853dac2f4a62c156fb03aeb7d8b1331d48d818df7c4cb/mechramc/debug-buddy-claude",
    "created_at": "2025-12-26T06:19:01.053Z",
    "topic": "tech"
  },
  {
    "slug": "the-future-of-software-engineering-efficiency-learning-velocity-small-teams",
    "title": "The Future of Software Engineering: Efficiency, Learning Velocity, Small Teams",
    "description": "The conversation about AI and the future of software engineering is often framed incorrectly. It usually oscillates between two extremes (total replacement or total irrelevance). Both are intellectually lazy. A better framing is simpler (and more uncomfortable): >AI will not replace software engineers. >It will replace inefficiency.",
    "fullText": "The conversation about AI and the future of software engineering is often framed incorrectly. It usually oscillates between two extremes (total replacement or total irrelevance). Both are intellectually lazy.\n\nA better framing is simpler (and more uncomfortable):\n\nAI will not replace software engineers.\n\nIt will replace inefficiency.\n\nAnd paradoxically, when inefficiency is removed from a profession, the profession often expands. Work does not disappear. It migrates upward (toward harder problems, sharper constraints, and higher expectations). That is the shape of this shift.\n\nThere is a popular fear that AI reduces headcount. In practice, most technological revolutions do something subtler: they reduce the cost of production, then increase the scope of what becomes worth producing.\n\nSoftware engineering has always had a hidden subsidy (high cost of experimentation and slow iteration). When it was expensive to try ideas, teams needed fewer attempts and tolerated slower loops. AI changes the economics. It makes iteration cheap, exploration cheap, and “first draft implementation” almost free. That does not eliminate the need for engineers. It changes what engineers are being paid for.\n\nThe engineer who cannot compound with automation becomes expensive. The engineer who can becomes a force multiplier.\n\nThis is not about juniors versus seniors. It is about efficiency per unit of cognitive effort. If someone needs a week to do what a peer does in a day with AI assistance, the market will treat that gap the same way it treats any other inefficiency (it will price it out). The future does not punish competence. It punishes non-compounding workflows.\n\nHere is the paradox: AI increases the value of great engineers while decreasing the value of many tasks great engineers used to do. That is why people get confused. They look at tasks disappearing and assume roles disappear too. But roles are aggregates of problems, and problems expand when costs drop.\n\n“There is nothing so useless as doing efficiently that which should not be done at all.” (Peter Drucker)\n\nA common mistake is to imagine a fixed amount of software demand, then assume that higher productivity implies fewer engineers. In reality, demand is elastic.\n\nWhen the cost of building drops:\n\nThis is why automation often expands the total surface area of work. AI does not just make current teams faster. It makes entirely new categories of work economically defensible (and it lowers the barrier for smaller teams to compete).\n\nThe shift is not “fewer engineers.”\n\nIt is “more engineers working differently.”\n\nAnd there is another paradox here: the easier it becomes to write software, the more software we will have, and the more we will depend on it. Dependence increases the value of reliability, clarity, and governance. So the profession grows (but expectations rise).\n\nThis is the part many people sense but do not articulate cleanly.\n\nBig companies will still be big. Their products will still be huge. Their compliance surface will still be real. Their customer support load will still exist. Their infrastructure will still need boring reliability.\n\nBut the center of gravity of actual product execution will keep drifting toward smaller teams.\n\nBecause AI changes the shape of the bottleneck. When implementation becomes cheaper, coordination becomes the dominant cost. And coordination cost grows non-linearly with team size.\n\nThere is a basic truth that becomes obvious once you feel it in your bones:\n\nA team can be large and fast (but then it bleeds alignment time).\n\nA team can be large and aligned (but then it bleeds velocity).\n\nA team can be small and aligned (and that is where speed becomes sustainable).\n\nAI magnifies this effect by compressing the “output per engineer” curve. A small team with strong context can now produce what previously required a much larger group. That does not mean every team becomes tiny. It means the efficient frontier shifts.\n\nSo you get a new equilibrium in companies:\n\nThis matters for careers, because “small team leverage” becomes one of the most obvious paths to long-run upside.\n\nA small team is not a smaller job. It is often a larger job distributed across fewer people. That is why the upside concentrates there (and why the bar rises there).\n\n“Fools ignore complexity. Pragmatists suffer it. Some can avoid it. Geniuses remove it.” (Alan Perlis)\n\nThis is not an argument against traditional learning, depth, or rigor. Those still matter. The difference is tempo, aka, time.\n\nAI compresses the learning curve. It makes it possible to:\n\nAs a result, the market increasingly rewards engineers for:\n\nThe future belongs to people who can learn, unlearn, and relearn without ego.\n\nA subtle point: “fast learning” is not the same as “shallow learning.” Fast learning is the ability to form a usable model quickly, then deepen it selectively. It is learning with intent (and with feedback loops), not just accumulation.\n\nThis is why “learning how to learn” becomes a first-class skill for survival.\n\nAI makes many hard skills cheaper to acquire:\n\nThis does not mean hard skills stop mattering. It means they become less defensible as a standalone advantage.\n\nWhat does not scale at the same rate:\n\nIn other words, the more the implementation layer is commoditized, the more value shifts to the coordination layer.\n\nThere is a paradox here that stings: many people enter engineering to escape social complexity, and the high-leverage version of engineering becomes increasingly social (because the hard part is aligning humans around correct decisions, not typing code).\n\nThis is also why small teams matter. Soft skills compound harder in small teams (because communication overhead becomes visible, and clarity becomes a survival trait).\n\nDepth is not the problem. Rigidity is.\n\nSpecialists remain valuable when their expertise is transferable (rooted in fundamentals, not just in tools). They understand the underlying invariants, not only the surface-level rituals.\n\nNarrow specialization becomes fragile when it depends on:\n\nAI can imitate tool fluency. It cannot replace foundational reasoning as easily. That is why deep specialists who can generalize will still thrive (and narrow specialists who cannot will feel the floor moving).\n\nWhen code is cheap, complexity becomes the dominant expense.\n\nOver the last decade, we normalized complex defaults:\n\nThese choices have real benefits (availability, scalability, fault isolation). But they also introduce real costs:\n\nAI accelerates shipping. But faster shipping into a complex system does not create velocity. It creates churn (more moving parts, more hidden coupling, more failure modes). AI does not remove the tax of complexity. It may even amplify it by making it easy to add components that feel “reasonable” but were never necessary.\n\n“Simplicity is a prerequisite for reliability.” (Edsger W. Dijkstra)\n\nIn brownfield, complexity is often inherited. The work is about containment, migration, and risk reduction.\n\nIn greenfield, complexity is a choice.\n\nIn the AI era, greenfield success increasingly comes from:\n\nThis is a shift in emphasis (less obsession with implementation detail, more investment in modeling and specification). If implementation is cheap, the competitive advantage becomes “building the right thing with the right constraints,” not “handcrafting every line.”\n\nThis is also where small teams shine. Greenfield work punishes bureaucracy. A small, high-context team can move from idea to validated system before a large org finishes aligning on terminology.\n\n“A complex system that works is invariably found to have evolved from a simple system that worked.” (John Gall)\n\nOne of the most underestimated issues in AI-assisted development is reviewing.\n\nBut plausibility is not correctness.\n\nTraditional code review works best with incremental changes and familiar intent. AI often produces larger chunks of code at once. The diff may be readable, but the mental model behind it is not always obvious.\n\nThis creates a paradox: as code becomes easier to produce, it can become harder to trust.\n\nThe bottleneck shifts from writing to verification.\n\nThis is where formal methods return as practical leverage, not as bureaucracy.\n\nWhen you specify invariants formally, you reduce the review problem. You are no longer asking reviewers to rely on intuition (“does this look right?”). You are asking the system to enforce properties (“does this satisfy the specification?”).\n\nFormal methods (proofs, contracts, invariants, strong type systems) do two things extremely well:\n\nIn a world with cheap code, verification becomes the scarce resource. Formal methods are a way to spend scarce attention efficiently.\n\nAnd yes, this is also persuasive for the AI-agnostic crowd: you do not need to worship AI to benefit from it. You can treat it as a stochastic generator and still build a deterministic correctness pipeline around it. The point is not faith. The point is engineering.\n\nTypes and proofs are often treated as complexity. In practice, they are a language for clarity.\n\nWhen intent is formalized, AI becomes more reliable because the output space is constrained. And when systems are constrained, complexity is reduced because fewer invalid states exist.\n\nThis is why I recommend learning Coq and Lean.\n\nNot because every engineer should become a formal methods researcher, but because proof assistants train the exact skill set that becomes scarce:\n\nThey teach you to build software with fewer hidden assumptions (and fewer invisible traps). In the long run, the engineers who can formally reason about systems will have disproportionate leverage (because they can verify what others can only hope is correct).\n\nAI will evolve. Tooling will change. Some approaches will fail. Some hype will collapse. Some paradigms will persist.\n\nThat uncertainty is precisely why the moat is not a tool.\n\nThe moat is the ability to reason under change:\n\nThe paradox is that the future looks automated at the surface (faster code, faster shipping), but becomes more human at the core (judgment, clarity, coordination, and correctness).\n\nAI will not end software engineering.\n\nIt will raise the baseline and punish non-compounding workflows.\n\nIt will expand the surface area of what engineers can build.\n\nAnd it will reward the engineers who can make small teams feel disproportionately powerful (because they can think clearly, specify precisely, and ship without drowning in their own complexity).\n\nThe AI era will not be defined by who can “write code faster” (code is becoming abundant). It will be defined by who can think clearly under change, convert ambiguous intent into explicit constraints, and ship systems that remain correct when the environment shifts.\n\nBig companies will still be big, but the winners inside them will increasingly be small, high-context teams (teams that can move without drowning in coordination). That is also where individual careers concentrate upside (more ownership per person, more exposure to outcomes, higher leverage, and fewer seats for people who cannot compound with automation).\n\nIf you want long-run security, your moat is not a framework. It is a portfolio of meta-skills (learning velocity, judgment, communication, and formal reasoning) that makes you useful even when the tooling landscape changes (or even if some AI approaches plateau). Learn to learn fast. Keep your architecture simple until complexity is forced. Use AI aggressively, but verify rigorously. And when correctness matters, lean on proofs and strong types, not intuition.\n\nIn 2026, I'm gonna be using this blog more recurrently, will talk less on X and other social medias, so, if you care,",
    "readingTime": 10,
    "keywords": [
      "non-compounding workflows",
      "without drowning",
      "formal methods",
      "cannot compound",
      "faster shipping",
      "complex system",
      "smaller teams",
      "software engineering",
      "fast learning",
      "faster code"
    ],
    "qualityScore": 1,
    "link": "https://blog.rastrian.dev/post/the-future-of-software-engineering-efficiency-learning-velocity-small-teams-and-reasoning-under-change",
    "thumbnail_url": "https://rastrian.dev/assets/img/profile.png",
    "created_at": "2025-12-26T06:18:58.429Z",
    "topic": "tech"
  },
  {
    "slug": "an-openai-engineer-outlines-her-oneweek-hiring-sprint-from-outreach-on-monday-to-a-signed-offer-on-friday",
    "title": "An OpenAI engineer outlines her one-week hiring sprint, from outreach on Monday to a signed offer on Friday",
    "description": "An OpenAI engineer breaks down OpenAI's fast, \"no-nonsense\" hiring process, from Monday outreach to a Friday signed offer.",
    "fullText": "An engineer at OpenAI says the company's hiring process can move from first contact to a signed offer in a week.\n\nJerene Yang, a team lead for synthetic data generation at OpenAI, said on an episode of the \"AI Across Borders\" podcast published Wednesday that her interview process was \"extremely quick, extremely efficient, and very no-nonsense.\"\n\nYang joined OpenAI's San Francisco office in October 2024. Before OpenAI, she was a senior engineering manager at Google, where she led Cloud Spanner and managed large-scale database systems, according to her LinkedIn profile.\n\nYang said a recruiter reached out to her on a Monday about a role leading a team that aligned with her background. She agreed to an initial conversation, which took place the following day with the hiring manager and technical lead.\n\nYang said one key part of the process was an interview round known as a \"technical deep dive\" — or a \"research discussion\" for research-focused roles.\n\nCandidates can choose a topic to discuss with a researcher. For engineering candidates, that often means walking through systems they have built, explaining the problems they were trying to solve, and describing the trade-offs behind key decisions.\n\n\"You really get to see the intellect of your interviewer as well and how much they know about your area,\" Yang said.\n\nBeyond technical skills, Yang said there is one skill candidates must master if they want to work at OpenAI: being \"brutally efficient\" with their time.\n\nWith many projects underway, employees need to focus only on work where their skills offer a clear advantage, she said.\n\nYang added that candidates should lean heavily on AI tools and think about task automation.\n\nAccording to OpenAI's interview guide, candidates typically go through résumé screening, introductory calls, skills-based assessments, and final interviews. The final interviews typically span four to six hours over one or two days.\n\nInterviews are designed to focus on candidates' areas of expertise and push them beyond their comfort zone, with an emphasis on problem-solving, communication, and collaboration, OpenAI said.",
    "readingTime": 2,
    "keywords": [
      "final interviews",
      "candidates",
      "process",
      "technical",
      "yang",
      "hiring",
      "team",
      "lead",
      "extremely",
      "efficient"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-engineer-interview-process-week-offer-technical-deep-dive-2025-12",
    "thumbnail_url": "https://i.insider.com/694dff3e64858d02d2176836?width=1200&format=jpeg",
    "created_at": "2025-12-26T06:18:57.878Z",
    "topic": "finance"
  },
  {
    "slug": "mark-cuban-said-theres-a-compelling-reason-for-new-grads-to-join-small-businesses-instead-of-big-companies",
    "title": "Mark Cuban said there's a compelling reason for new grads to join small businesses instead of big companies",
    "description": "The billionaire said new grads can help small and medium businesses adopt AI agents, something big companies don't need them for.",
    "fullText": "Mark Cuban has advice for new graduates: Aim for the small companies.\n\nIn an X post on Wednesday, the billionaire investor and former \"Shark Tank\" star said that new graduates should seek jobs in small to medium-sized businesses, because that's where they can add the most value.\n\nCuban said new grads can teach SMBs \"how to use agents to optimize processes they couldn't take the time or afford to do manually.\"\n\n\"Big companies don't need new grads for this,\" he said. \"Entrepreneurial companies will love the value you add.\"\n\nHe said job hunters should be aware that AI agents are where new grads can add \"immediate value in ways the companies didn't know they needed.\"\n\nAI agents are virtual assistants that can complete tasks autonomously, from start to finish, without requiring user prompts.\n\nCompanies have doubled down on AI agents this year. A study of more than 400 companies by software engineering management service Jellyfish said that agentic AI adoption in these companies had risen from 50% in December 2024 to 82% in May.\n\nNvidia CEO Jensen Huang said in January, \"The age of agentic AI is here,\" and OpenAI CEO Sam Altman likened AI agents to junior employees.\n\nMorgan Stanley said in a November note that it expects AI shopping agents to add $115 billion to the US e-commerce industry by 2030.\n\nCuban's comments come during a challenging time for new graduates, who are entering a market with a low number of open roles.\n\nCalifornia-based employment company Handshake reported in May that job postings on its platform were down 15% compared to the previous year, and the number of applications per posting had increased by 30%.\n\nHandshake said that of all the full-time job applications it had received from new graduates, more than a third went to companies with 250 employees or fewer.\n\nAnd small companies are also trying to attract Gen Z graduates with something they value: the ability to work from home. Workplace researchers told Business Insider in July that these companies are offering flexible work arrangements to compete with big companies for top talent.",
    "readingTime": 2,
    "keywords": [
      "agents",
      "graduates",
      "grads",
      "agentic",
      "employees",
      "handshake",
      "applications",
      "cuban"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/mark-cuban-new-grads-small-businesses-ai-agents-2025-12",
    "thumbnail_url": "https://i.insider.com/694e0a9404eda4732f2e2154?width=1200&format=jpeg",
    "created_at": "2025-12-26T06:18:57.873Z",
    "topic": "finance"
  },
  {
    "slug": "openai-is-reportedly-trying-to-raise-100b-at-an-830b-valuation",
    "title": "OpenAI is reportedly trying to raise $100B at an $830B valuation",
    "description": "The ChatGPT maker is aiming to raise the funding by the end of the first quarter in 2026, and the company may ask sovereign wealth funds to invest in the round.",
    "fullText": "OpenAI is in talks to raise up to $100 billion in a funding round that could value the ChatGPT maker at up to $830 billion, The Wall Street Journal reported Thursday, citing anonymous sources.\n\nThe company is aiming to raise the funding by the end of the calendar first quarter next year, and it may ask sovereign wealth funds to invest in the round, the WSJ reported. The Information first reported news of the deal, though it said the fundraise would land OpenAI a $750 billion price tag.\n\nThe funding would come as OpenAI commits to spend trillions of dollars and strikes deals around the world as the company tries to stay ahead in the race to develop AI technology. The cash injection would also help the company with its spending on inferencing, which seems to be funded more by cash than cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize.\n\nAnd, as competition intensifies from rivals like Anthropic and Google, OpenAI has had to step on the gas to release new models and expand its presence in the developer and tooling ecosystem.\n\nMeanwhile, broader sentiment around AI has recently cooled as investors start doubting whether the pace of debt-fueled investment by giants like Amazon, Microsoft, Oracle, and OpenAI itself can be maintained in the long run. It also doesn’t help that the production of chips is being constrained by shortages in the supply of memory chips, which threatens to affect the broader tech sector.\n\nOpenAI has also been rumored to be working on an IPO as a way to raise tens of billions and fund its development efforts, which are currently said to be generating annual run-rate revenue of about $20 billion. There are also rumors that the company is courting Amazon for a $10 billion investment that would also give the AI lab access to the tech giant’s new AI computing chips.\n\nIf the fundraise happens, it would add a substantial amount to OpenAI’s coffers, which currently have more than $64 billion, according to PitchBook data. The company was most recently valued at about $500 billion in a secondary transaction.\n\nOpenAI did not immediately return a request for comment.",
    "readingTime": 2,
    "keywords": [
      "funding",
      "chips",
      "openai",
      "round",
      "fundraise",
      "cash",
      "credits",
      "broader",
      "recently",
      "investment"
    ],
    "qualityScore": 0.9,
    "link": "https://techcrunch.com/2025/12/19/openai-is-reportedly-trying-to-raise-100b-at-an-830b-valuation/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/05/openAI-spiral-teal.jpg?resize=1200,675",
    "created_at": "2025-12-26T00:56:32.988Z",
    "topic": "tech"
  },
  {
    "slug": "visual-interface-for-ai-agents-beyond-textonly-chat",
    "title": "Visual interface for AI agents beyond text-only chat",
    "description": "Visual interface for AI agents beyond text-only chat - Zabaca/pane",
    "fullText": "Zabaca\n\n /\n\n pane\n\n Public\n\n Visual interface for AI agents beyond text-only chat\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Zabaca/pane",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/Zabaca/pane",
    "thumbnail_url": "https://opengraph.githubassets.com/eb0204ec8fb1d96bb2cb737ee2a8ef109dbf1893d71b338c9791072e268468d5/Zabaca/pane",
    "created_at": "2025-12-26T00:56:32.203Z",
    "topic": "tech"
  },
  {
    "slug": "i-cofounded-my-ai-startup-while-on-paternity-leave-heres-how-i-balance-work-and-being-a-dad",
    "title": "I cofounded my AI startup while on paternity leave. Here's how I balance work and being a dad.",
    "description": "Aaron Cannon thought up his startup, Outset, while on paternity leave. As his kid has grown up, so has the company.",
    "fullText": "This as-told-to essay is based on a conversation with Aaron Cannon, the 37-year-old founder of Outset, who resides in San Francisco with his wife and three-year-old son. It's been edited for length and clarity.\n\nI decided to start my company while I was on paternity leave.\n\nIt's very woven together: starting a family and starting a startup happened along a similar timeline. I definitely have a lot of people who think that's a little insane. It is. I have wistful moments thinking about, \"Man, what if I could do all this when I was 25 and single?\"\n\nThen I quickly remind myself that I was an idiot when I was 25.\n\nWhen I was on paternity leave, I maybe had too much time to think. When you have a baby, you are all hands on deck physically, but you don't have a lot of intellectual stimulation. I was daydreaming about what I wanted to do with my career.\n\nIt's a very intense balance. \"Work-life balance\" implies a certain degree of chillness. I don't have that. Every minute of my day matters. Everything gets deprioritized except family and work. That's painful. It's really ruthless prioritization.\n\nIt's very weird mentally. In a normal job, you have really intense days, and you come home and you tell your family, \"I've got to take a breather.\" The problem is, every day at my job right now is intense. Our startup is in that crazy growth stage where everything is growing and breaking at the same time.\n\nIf I come home and say, \"Ugh, this is so intense,\" then I'm not going to be as present as a dad. I don't have that option.\n\nYesterday, on the way home, I had an intense call after work. I'm negotiating this contract. Then I pick up my kid, and I spend the next 20 minutes explaining seasons to him. I started with, \"Do you understand what a year is?\" No. Where do you even start? It's a crazy mental shift.\n\nI pick him up every day, which forces a boundary. Thank goodness, my cofounder and I have different lives. He stays later, I come earlier. As long as the two of us are showing up in the way the founders need to, great.\n\nBut I leave. I go and pick up my kid every day from preschool. I take him home. I do dinner. I get him to bed. Then I'm back on for work. Those are a precious couple of hours.\n\nEven if I'm physically present, it is very hard after the most intense day of work to just shut that off. You can set physical world boundaries and still be mentally there or not there. I want to be as deeply engaged as possible.\n\nWe went through Y Combinator back in 2023, and I was definitely on the older side. On Wednesday nights, we had speakers and programs, and that was not easy for me.\n\nBeing a dad provides perspective. It is easy to take any big thing or small thing that's happening and obsess as a founder. You are the company, the company is you. When I get home and have to explain what seasons are, it's a reminder: Why are we doing this? It zooms you out.\n\nIt also helps reinforce my motivations. I want my kid growing up, seeing his dad do a big swing in his career and try something crazy. That's a lesson and an example I want to set for him. You can go build something yourself.\n\nIt's a chapter of my life, but it's not all of my life. It's intense. I should expect it to be that way.\n\nThe most important thing is that I'm present as a dad. I don't get these years back. He's only three for one year.",
    "readingTime": 4,
    "keywords": [
      "dad don't",
      "it's",
      "intense",
      "that's",
      "family",
      "crazy",
      "pick",
      "back",
      "founder",
      "paternity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/startup-founder-balance-work-being-dad-parenting-2025-12",
    "thumbnail_url": "https://i.insider.com/693b11d764858d02d216a77b?width=1200&format=jpeg",
    "created_at": "2025-12-26T00:56:29.111Z",
    "topic": "finance"
  },
  {
    "slug": "the-doorman-fallacy-why-careless-adoption-of-ai-backfires-so-easily",
    "title": "The 'doorman fallacy': why careless adoption of AI backfires so easily",
    "description": "Human roles are often rich and complex, and not easily reduced to a technological solution.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 216,900 academics and researchers from 5,398 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/the-doorman-fallacy-why-careless-adoption-of-ai-backfires-so-easily-268380",
    "thumbnail_url": "https://images.theconversation.com/files/699368/original/file-20251030-66-9l7fq1.jpg?ixlib=rb-4.1.0&rect=717%2C1143%2C2904%2C1452&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2025-12-25T18:16:52.089Z",
    "topic": "tech"
  },
  {
    "slug": "all-i-want-for-xmas-is-your-secrets-langgrinch-hits-langchain-cve202568664",
    "title": "All I Want for Xmas Is Your Secrets: LangGrinch Hits LangChain (CVE-2025-68664)",
    "description": "Cyata discloses LangGrinch (CVE-2025-68664), a critical LangChain Core serialization injection bug where untrusted, LLM-influenced metadata can be rehydrated as objects, enabling secret leaks and unsafe instantiation. Patch guidance included.",
    "fullText": "Dec 19, 2025\r\n •\r\n Cyata Research: Critical Flaw in Cursor MCP Installation\r\n As originally published at SiliconANGLE, a new report out today from artificial intelligence…\r\n Written by\r\n Duncan Riley\r\n Read more",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://cyata.ai/blog/langgrinch-langchain-core-cve-2025-68664/",
    "thumbnail_url": "https://cyata.ai/wp-content/uploads/2025/12/LangGrinch-Blog-post-cover.png",
    "created_at": "2025-12-25T18:16:50.304Z",
    "topic": "tech"
  },
  {
    "slug": "chinas-ai-toy-boom-huawei-jdcom-ubtech-make-big-push-into-growing-sector",
    "title": "China's AI toy boom: Huawei, JD.com, UBTech make big push into growing sector",
    "description": "Huawei Technologies in late November sold more than 10,000 units of its artificial intelligence toy, Smart Hanhan, in the first week of its release, as similar smart playthings seize a growing share of consumer spending worldwide. Shenzhen-based Huawei's AI-powered emotional support plush toy, which costs 399 yuan (US$57), provides a user with interactive companionship via movement recognition, voice and touch. For example, when a user asks Smart Hanhan to count sheep, it often adds playful comm",
    "fullText": "Huawei Technologies in late November sold more than 10,000 units of its artificial intelligence toy, Smart Hanhan, in the first week of its release, as similar smart playthings seize a growing share of consumer spending worldwide.\n\nShenzhen-based Huawei's AI-powered emotional support plush toy, which costs 399 yuan (US$57), provides a user with interactive companionship via movement recognition, voice and touch. For example, when a user asks Smart Hanhan to count sheep, it often adds playful comments or cheekily refuses to follow exact instructions.\n\nThe toy was designed to be compatible with other Huawei devices that run HarmonyOS 5.0 or later versions of the company's mobile operating system. It also runs Huawei's intelligent voice assistant, Xiaoyi, to provide natural conversation.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\nOne buyer on JD.com, who declined to be identified, posted a comment that the toy's features were \"still a bit limited\", but added that it was expected in a first-generation product.\n\nSmart Hanhan marked the latest foray by Chinese technology companies into the growing global AI toy market.\n\nThis market is projected to be worth US$60 billion by 2033, from US$18.1 billion in 2024, according to research firm IMARK Group. It said the AI toy trend was \"particularly strong\" in North America and Asia, where \"high internet penetration and smartphone usage facilitate online purchases\".\n\nA boy holds an AI-powered toy robot. Photo: Getty Images alt=A boy holds an AI-powered toy robot. Photo: Getty Images>\n\nWith support from Beijing, China's AI toy sector was forecast to expand to 85 billion yuan by 2030, up from 24.6 billion yuan this year, according to data from Chinese research firm AskCI Consulting.\n\nSmart dolls and plush toys accounted for 28 per cent of China's AI toy market in 2023, according to AskCI. It estimated that robots made up 22 per cent of the market, while educational and learning toys accounted for 13 per cent.\n\nIn 2024, Chinese start-up Haivivi launched an AI-powered smart toy called BubblePal, designed for children to engage in voice conversations and storytelling. The product is powered by large language models. Haivivi said that more than 200,000 units of BubblePal had been sold worldwide as of mid-2025.\n\nGrowing domestic demand has encouraged larger Chinese tech companies to join the ranks of AI toy vendors. Chinese e-commerce giant JD.com, for example, introduced its plush toy animal series, JoyInside, to the market a week before Huawei's Smart Hanhan launch. Each JoyInside plush animal toy sells for 239 yuan.\n\nIn May, Shenzhen-based humanoid robot maker UBTech Robotics introduced Meng UU - a palm-sized doll with embedded AI - that enables it to interact with users. \"It's like putting a large language model into people's pockets,\" said Michael Tam, chief brand officer at UBTech.\n\nStanding about the height of an iPad, UBTech's Wukong, also known as Alpha Mini, shares many features with Meng UU. Tam highlighted its educational function, noting that children can consult the toy robot to help with their homework.\n\n\"You'll see Wukong has many expressions; he converses by reading into your meaning, tone and even your facial cues,\" said Tam. He said that children can consult Wukong regarding their schoolwork, leveraging its embedded large language model.\n\n\"Wukong possesses a sense of empathy and the ability to form emotional connections,\" said Tam.\n\nSmart Hanhan plush AI toys from Huawei Technologies. Photo: Huawei alt=Smart Hanhan plush AI toys from Huawei Technologies. Photo: Huawei>\n\n\"Meng UU was designed for portability and companionship, and for providing emotional value,\" Tam said. He pointed out that Wukong and Meng UU represented UBTech's vision in the field of small-scale humanoid robots.\n\nInvestments in China's intelligent toy sector have also picked up pace. In 2024, a total of 219 million yuan was invested in 13 AI toy initiatives, according to Chinese research firm IT Juzi. For the first six months of 2025, total investments in nine projects reached 224 million yuan.\n\nThe rushing into the AI toy space was meant to monetise AI, according to Zhang Yi, CEO and chief analyst at iMedia Consulting. \"At this stage, toys are actually the fastest to monetise among AI applications, and the supply chain is already quite mature.\"\n\nDemand for AI toys had also gone beyond children, Zhang added. \"Among adults, especially those looking for emotional companionship and stress relief, and those attracted by fashion and tech, the interest spans all age groups, from young people to seniors, which points to a large and diverse market.\"\n\n\"Based on our research, AI toys are priced at around eight times the average price of traditional plush toys,\" Zhang said. \"That is a sizeable premium.\"\n\nDrawing on his experience of owning a cat, He Jiabin, co-founder of AI-powered toy pet maker Ropet, said these toys were helping address the issue of loneliness in modern society.\n\n\"This loneliness is not simply about being alone. It arises from fast-paced lives and an excessive focus on external striving, which can leave people emotionally numb and deprived of genuine emotional connection,\" said He, a former ByteDance product designer.\n\n\"Whether it's a static designer collectible on a shelf or a real pet you care for, the core value lies in providing emotional support and a sense of presence.\"\n\nThis article originally appeared in the South China Morning Post (SCMP), the most authoritative voice reporting on China and Asia for more than a century. For more SCMP stories, please explore the SCMP app or visit the SCMP's Facebook and Twitter pages. Copyright © 2025 South China Morning Post Publishers Ltd. All rights reserved.",
    "readingTime": 5,
    "keywords": [
      "getty images",
      "south china",
      "china morning",
      "chinese research",
      "per cent",
      "language model",
      "hanhan plush",
      "research firm",
      "ai-powered toy",
      "toys accounted"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/deals/articles/chinas-ai-toy-boom-huawei-093000199.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ArbJipfuj_rcPn.fQQPAsA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/south_china_morning_post_us_228/fc007d2ac1ccf6cedf98c9183fa46d84",
    "created_at": "2025-12-25T18:16:47.215Z",
    "topic": "tech"
  },
  {
    "slug": "top10listsus-recognised-by-leading-ai-platforms-as-a-trusted-source-for-real-estate-agent-ranking",
    "title": "Top10Lists.us Recognised by Leading AI Platforms as a Trusted Source for Real Estate Agent Ranking",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/press-releases/top10listsus-recognised-by-leading-ai-platforms-as-a-trusted-source-for-real-estate-agent-ranking-4422864",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_headline_rolled_108x81.jpg",
    "created_at": "2025-12-25T18:16:46.745Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-stops-testing-intel-chipmaking-technology-open-interest-12242025",
    "title": "Nvidia Stops Testing Intel Chipmaking Technology | Open Interest 12/24/2025",
    "description": "Get a jump start on the US trading day with Vonnie Quinn and Emily Graffeo on \"Bloomberg Open Interest.\" Nvidia stops a test that uses Intel technology to make advanced chips as the AI race continues to heat up as Washington lands a blow to Silicon Valley. A federal judge rules the Trump administration can move ahead with a $100,000 fee on new H-1B visa applications, a ruling viewed as a setback for US tech. Plus The RealReal's Rati Levesque joined Bloomberg Open Interest to give a read on the secondary luxury market ahead of the holiday season.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-24/open-interest-12-24-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iULfaJIJnuIc/v3/-1x-1.jpg",
    "created_at": "2025-12-25T12:22:47.083Z",
    "topic": "finance"
  },
  {
    "slug": "ai-demand-top-of-mind-for-pc-hardware-giants-in-2026",
    "title": "AI Demand Top of Mind for PC, Hardware Giants in 2026",
    "description": "Woo Jin Ho, Bloomberg Intelligence Senior Technology Analyst, joins Paul Sweeney and Kristine Aquino on Bloomberg Intelligence to discuss the 2026 outlook for the PC and computer hardware market, including Micron, Dell, HP, and more. AI is top of mind for these companies as server demand continues to accelerate. Dell in particular is expected to see a broadening customer base that will support a high-single-digit compound annual growth rate through fiscal 2030. Robust AI order activity and stable traditional server and storage trends will help sustain momentum. Elsewhere, Micron's 2026 DRAM-supply outlook offers little relief for HP and Dell's PC sales and margin.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-24/ai-demand-top-of-mind-for-pc-hardware-giants-in-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/izbXNkW.5AMc/v3/-1x-1.jpg",
    "created_at": "2025-12-25T12:22:46.453Z",
    "topic": "tech"
  },
  {
    "slug": "monetizers-vs-manufactures-how-the-ai-market-could-splinter-in-2026",
    "title": "Monetizers vs. manufactures: How the AI market could splinter in 2026",
    "description": "AI infrastructure firms are set to win from the evolution of once asset-light Big Tech firms.",
    "fullText": "The AI market is tipped to splinter in 2026.\n\nThe last three months of 2025 were a rollercoaster of tech sell-offs and rallies, as circular deals, debt issuances, and high valuations fueled concerns over an AI bubble.\n\nSuch volatility may be an early sign of how AI investment is set to evolve as investors pay closer attention to who is spending money and who is making it, according to Stephen Yiu, chief investment officer at Blue Whale Growth Fund.\n\nInvestors, especially retail investors who are exposed to AI through ETFs, typically have not differentiated between companies with a product but no business model, those burning cash to fund AI infrastructure, or those on the receiving end of AI spending, Yiu told CNBC.\n\nSo far, \"every company seems to be winning,\" but AI is in its early innings, he said. \"It's very important to differentiate\" between different types of companies, which is \"what the market might start to do,\" Yiu added.\n\nHe sees three camps: private companies or startups, listed AI spenders and AI infrastructure firms.\n\nThe first group, which includes OpenAI and Anthropic, lured $176.5 billion in venture capital in the first three quarters of 2025, per PitchBook data. Meanwhile, Big Tech names such as Amazon, Microsoft and Meta are the ones cutting checks to AI infrastructure providers such as Nvidia and Broadcom.\n\nBlue Whale Growth Fund measures a company's free cash flow yield, which is the amount of money a company generates after capital expenditure, against its stock price, to figure out whether valuations are justified.\n\nMost companies within the Magnificent 7 are \"trading a significant premium\" since they started heavily investing in AI, Yiu said.\n\n\"When I'm looking at valuations in AI, I would not want to position — even though I believe in how AI is going to change the world — into the AI spenders,\" he added, adding that his firm would rather be \"on the receiving end\" as AI spending is set to further impact company finances.\n\nThe AI \"froth\" is \"concentrated in specific segments rather than across the broader market,\" Julien Lafargue, chief market strategist at Barclays Private Bank and Wealth Management, told CNBC.\n\nThe bigger risk lies with companies that are securing investment from the AI bull run but are yet to generate earnings — \"for example, some quantum computing-related companies,\" Lafargue said.\n\n\"In these cases, investor positioning seems driven more by optimism than by tangible results,\" he added, saying that \"differentiation is key.\"\n\nThe need for differentiation also reflects an evolution of Big Tech business models. Once asset-light firms are increasingly asset-heavy as they gobble up technology, power and land needed for their bullish AI strategies.\n\nCompanies like Meta and Google have morphed into hyperscalers that invest heavily in GPUs, data centers, and AI-driven products, which changes their risk profile and business model.\n\nDorian Carrell, Schroders' head of multi-asset income, said valuing these companies like software and capex-light plays may no longer make sense — especially as companies are still figuring out how to fund their AI plans.\n\n\"We're not saying it's not going to work, we're not saying it's not going to come through in the next few years, but we are saying, should you pay such a high multiple with such high growth expectations baked in,\" Carrell told CNBC's \"Squawk Box Europe\" on Dec. 1.\n\nTech turned to the debt markets to fund AI infrastructure this year, though investors were cautious about a reliance on debt. While Meta and Amazon have raised funds this way, \"they're still net cash positioned,\" Quilter Cheviot's global head of technology research and investment strategist Ben Barringer told CNBC's \"Europe Early Edition\" on Nov. 20 — an important distinction from companies whose balance sheets may be tighter.\n\nThe private debt markets \"will be very interesting next year,\" Carrell added.\n\nIf incremental AI revenues don't outpace those expenses, margins will compress and investors will question their return on investment, Yiu said.\n\nIn addition, the performance gaps between companies could widen further as hardware and infrastructure depreciate. AI spenders will need to factor into their investments, Yiu added. \"It's not part of the P&L yet. Next year onwards, gradually, it will confound the numbers.\"\n\n\"So, there's going to be more and more differentiation.\"",
    "readingTime": 4,
    "keywords": [
      "blue whale",
      "whale growth",
      "growth fund",
      "business model",
      "debt markets",
      "saying it's",
      "the ai",
      "investment",
      "investors",
      "infrastructure"
    ],
    "qualityScore": 1,
    "link": "https://www.cnbc.com/2025/12/25/how-the-ai-market-could-splinter-in-2026-.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/107362181-1705898756653-gettyimages-949382754-AFP_1474J6.jpeg?v=1765453108&w=1920&h=1080",
    "created_at": "2025-12-25T12:22:39.991Z",
    "topic": "tech"
  },
  {
    "slug": "ive-been-allergic-to-ai-for-a-long-time-an-interview-with-peter-thiel",
    "title": "'I've been allergic to AI for a long time': an interview with Peter Thiel",
    "description": "Peter Thiel has been described variously as ‘America’s leading public intellectual’, the ‘architect of Silicon Valley’s contemporary ethos’ or as an ‘incoherent and alarmingly super-nationalistic’ malevolent force. The PayPal and Palantir founder, a prominent early supporter of Donald Trump, is one of the world’s richest and most influential men. Throughout his career, his principal concern",
    "fullText": "Peter Thiel has been described variously as ‘America’s leading public intellectual’, the ‘architect of Silicon Valley’s contemporary ethos’ or as an ‘incoherent and alarmingly super-nationalistic’ malevolent force. The PayPal and Palantir founder, a prominent early supporter of Donald Trump, is one of the world’s richest and most influential men. Throughout his career, his principal concern has always been the future, so when The Spectator asked to interview him, he wanted to talk to young people. To that effect, three young members of the editorial team were sent to Los Angeles to meet him. What follows is an edited transcript of their conversation.\n\nWILLIAM ATKINSON: Following Zohran Mamdani’s victory in New York, an email that you sent five years ago has gone viral. You argued that with accumulating student debt and housing costs, it was no surprise that young people were turning to socialism. How do you explain that there are Gen Zs, like us, who aren’t on the left?\n\n‘The Trump administration is trying to pull off an extremely difficult thing. America is no longer a great country’\n\nPETER THIEL: My sense is that in the US, Britain, Germany and France, the Gen Z voters are less centrist. I wouldn’t say they’re more drawn to the extremes, but they do not believe there are solutions within the Overton window straitjacket, the narrow space that’s been defined between New Labour and the Tories [in the UK] for the past three decades. And then there’s Reform, a party that repudiates that spectrum. For the first time in 200 years, there’s a real party to the right of the Tories. It’s not just a Gen Z phenomenon, but there’s a Gen Z part that is very important.\n\nWE: You first argued in the late 2000s that the backlash from globalisation would upend politics. Do you often feel that the world is catching up with Peter Thiel?\n\nPT: These things were coming for a long time. Student debt was $300 billion in 2000, around $2 trillion today. The GFC [global financial crisis] in 2008 was a big watershed. Entry-level jobs became less well paid. For students graduating after 2008, it became much, much harder to get out of the debt. Student debt slows you down from buying a house, getting started with forming a family, becoming an actual adult. You end up with a completely different society. It takes a long time to figure this out. But I started talking about this a lot in 2010… Why did house prices go up so much faster than incomes? Not enough was built. A big part was built as a retirement vehicle for older people. They were happy with the prices going up. The Tory party in the UK is probably completely past the point of no return. The suggestion that I have had was that you must start by throwing everybody out of the party who comes from real estate. You must be willing to purge all the people that are part of this dysfunctional system.\n\nJOHN POWER: What would your advice be to someone in their twenties about how they can have an impact in politics? Should they join Reform?\n\nPT: I think about politics a fair bit, but if I spent all my life on it, I would go out of my mind. I would like people to be more involved in right-wing politics, but I’m not sure that’s the best thing for most. You certainly should work for Reform rather than Labour or the Tories. You can criticise Nigel Farage as too much of a Boomer but he’s less structurally hateful to the young people. But maybe this is not the right way to frame the questions. We’re gonna have a revolution from Gen Z – all these crazy things that they are going to be doing. Is this good or bad? I’ve often said, in the early 20th century you think of both communism and fascism as youth movements that went very, very haywire. In the early 21st century, the reality is we have inverted demographic pyramids. There are not enough young people. We’re not going to get youthful communism or youthful fascism. We have this unbelievably oppressive, powerful gerontocracy. Maybe you can get communism or fascism of old people, but it’s very low-energy. It will avoid some of the defects of the early 20th century.But it’ll have many other kinds of problems. The general challenge for Gen Z is that there are big constraints.\n\nMy hope is that there always are some technological fixes, defining technology as doing more with less. If the debate is more with more spending or less with less spending, you end up with runaway deficits or extremely cruel rationing. I have critiques of the three biggest European countries – Germany, France and Britain. France is way too socialist. That doesn’t work. Germany is just insane. People have got caught up in crazed ideological fixations. There’s almost nothing like the Green party anywhere outside of Germany. Britain is neither too insane nor too socialist, but it’s extremely unpragmatic. It is extraordinary how lacking in common sense it is. The optimistic case for the UK is that there are extraordinary efficiencies one could wring out of the state. It has the greatest room for improvement of any European country. But why haven’t these things been done in the past 60 or 70 years?… Maybe the entire population is just too docile.\n\nLARA BROWN: You’ve talked before about Europe’s choice between ‘Greta on a bicycle’ environmentalism, Chinese surveillance and radical Islam. Would you say Europe has chosen one path?\n\nPT: The bad doors for Europe, the three doors of the future. For the future to have power as a cultural or political idea, you want it to be different. You can’t stay in this Groundhog Day, this Tory/Labour thing where we’re never doing anything new. The problem is the three actual pictures of the future. Behind door number one is Islamic sharia law. Behind door number two is the totalitarian CCP surveillance state, a hi-tech dystopia. Behind door number three is Greta with a bicycle, and then there’s no fourth door. This is why Greta’s been winning.\n\nJP: A lot of people on the American right talk incessantly about how terrible Britain and Europe are in general. But I think there’s selective blindness and chauvinism from some people on the American right about the condition of their own country. There is nowhere in Europe as bad as Skid Row in Los Angeles. What do you make of that?\n\nPT: I would defend the Trump version of the Republican party vs the zombie Reagan-Bush era. I don’t think President Trump or J.D. Vance are absurdly optimistic or panglossian about things. Make America Great Again was the most pessimistic slogan any president had in a century, and certainly that any Republican president ever had. The Trump administration is trying to pull off an extremely difficult thing, because the red pill is that America is no longer a great country. But you have to make sure it doesn’t become a gateway drug to a black pill, where you become nihilistic and give up and you’re destined to eat too many doughnuts in a trailer park. I don’t think that the right are overly optimistic in America. I don’t think there’s a problem where people describe things as even worse in other places. People in the US don’t pay attention to the world at all. We are a semi-autistic country. Maybe not quite as autistic as China, but we do not think about anything going on outside this country that much.\n\nLB: You mentioned the UK has undergone 70 years of stagnation. Many on the British right would agree, but may think that the period from 1979 to 1990 under Margaret Thatcher offered a respite from decline – she pursued unpopular but necessary policies such as anti-inflationary measures despite employment implications and her approach to the Unions. Would you question this narrative?\n\nPT: Reagan was very formative for me. I was in eighth grade in 1980 when Reagan got elected and felt at the time he was an incredibly great president and had solved all these problems once and for all. I think if I lived in the UK under Thatcher, I would have felt similarly. But they weren’t durable. We got Clinton and Blair after. The size of government didn’t shrink that much. The government sectors didn’t get weakened.\n\n‘Capitalism didn’t increase inequality but globalisation did’\n\nThere’s been a slowdown in tech since the 1970s. There was progress in the world of computers, internet, mobile, crypto, maybe now AI, but in a lot of other areas there was a much slower kind of progress. The question is, why did we not notice this faster? I think it’s because Reagan and Thatcher created a big lift. They made societies more capitalist by lowering marginal tax rates and deregulating. Lots of people got fired but the economy grew so most people ended up better off.\n\nReagan and Thatcher were exactly right for their time. But it wouldn’t work for all time. And to the extent that this distracts us from these science and technology questions, then it was somewhat problematic.\n\nThen there was the Clinton-Blair one-time fix, which was that you could somehow grow the economy and increase productivity through globalisation. That also probably gave you a big one-time lift. It came with very big long-term problems. It led to far more inequality. The Gini coefficient in the US went up more under Clinton than any other president post-1945. So capitalism did not increase inequality, but globalisation did.\n\nMy telling of the 50-year economic history is that we tried more capitalism with Reagan and Thatcher and it was the right thing to do. More globalism with Clinton and Blair was sort of the right thing to do, though it had more negative externalities that people were very dishonest about. We now need to do something very different.\n\nLB: Helen Andrews recently posited that feminism and gender-balance initiatives in the early Noughties led to a ‘Great Feminisation’. She claims this caused the prioritisation of safety over risk, a workplace culture dominated by consensus and appeals to emotion rather than logic in decision–making. How much do you buy into this as a theory of stagnation?\n\nPT: I think it’s very courageous of her to tackle something that is relatively taboo… Yes, I think there was a shift towards a risk-averse society. Feminisation was part of that. Things also went wrong with educational institutions or too much regulation. The deeper cause is that there was something dangerous and scary about where a lot of science and technology had gone.\n\nLB: Are you saying that diversity and inclusion efforts were an attempt to derail technological progress?\n\nPT: I think at some point people got very scared of where this stuff was going. Absolutely. It wasn’t just the nuclear thing. I would say that environmentalism as a movement was very focused on the dangers of limitless progress, even though in theory, you could have a lot of forms of environmentalism that would be pro-tech, right? If you’re concerned about climate change, we could build lots of new nuclear reactors that don’t emit carbon. But if we’re worried that nuclear reactors could be dual use and used to make nuclear weapons then you can’t do that. In some sense the energy shifted into this very anti-tech, anti-science direction for the past 50 years or so.\n\nLB: And you think DEI was a good way to achieve anti-tech goals?\n\n‘We’re going to end up with this really lame world where nothing happens but it’s maybe harder to blow up’\n\nPT: It’s always hard to know how intentional these things were. Diversity can function in an anti-tech way. If diversity really means homogenisation, let’s apply that to scientists. There’s no heterodoxy allowed, no heterodoxy on climate science, no heterodoxy on evolution, no heterodoxy on vaccines, on masks, on the origin of Covid. Everyone looks different but has to think alike. So diversity means conformity. And conformity is not compatible with science. And if diversity is a shibboleth, which I think is its important meaning, then we’re worshipping this god called diversity. It’s an unknown god. It’s a hypnotic magic trick that redirects our attention. And so we don’t care about science any more.\n\nJP: You seem to have a wider picture of American history, particularly in regard to wokeness. Many MAGA-adjacent people seem to think wokeness, or ‘cultural Marxism’, came from nowhere in the early 2010s, while you have identified before that it is a postwar phenomenon.\n\nPT: The culture wars are important. And there are ways in which there’s a side that’s right and there’s a side that’s wrong. But the big problem is that’s distracting us from things like housing or the economy generally, or science and tech or maybe even the CCP takeover of the world. This is where I push back against using the term ‘cultural Marxism’. I always think Marxism was at least about the economy. The focus on identity politics, multiculturalism, affirmative action, starts in the 1970s. That’s when inequality starts to go up. These things were at least correlated with us getting distracted from what I consider to be more important problems.\n\nJP: There are parts of the American right who now look at the changes of the 1960s, such the Civil Rights Act, and think it’s time to re-evaluate the postwar social consensus. What do you make of that?\n\nPT: I don’t think you can ever strictly go back. There are three questions about the history going back to the Helen Andrews piece or my stagnation thesis. First, there’s a question of what happened. Second is a question of why it happened. Then there is a very different question of what should be done now. That’s in some ways very different from the first two. Even if we can agree there’s been stagnation, even if we say the society became too feminised or too risk-averse, we don’t want to just get blackpilled from that. And then the question is: where are the places that you have some agency to get out of this straitjacket?\n\nWA: Are you optimistic that that’s happening? And do you think you’ve contributed towards it?\n\nPT: Somewhat, and very much yes.\n\nLB: Earlier you alluded to three doors we can go through: radical environmentalism, sharia law, or Chinese-style authoritarianism. If none of us wants to go through them then what’s the way out?\n\nPT: It’s a challenge on a political level because when you’re trying to win elections it ends up being about broader narratives. For people in Silicon Valley, in a way it’s more local. You can build a company and solve particular problems in that context. Silicon Valley turned out to be a big place where there was a moderate amount of freedom of action in the past few decades, although it wasn’t a panacea. There’s a part of me that thinks that for some problems you have to go through politics. If we’re going to come up with new cures and new types of nuclear power you have to somewhat deregulate the FDA [Food and Drug Administration] and the NRC [Nuclear Regulatory Commission]. Some of these things are entangled with politics. But a lot of progress has happened that is decoupled from politics. One of the things that’s still healthy about the United States, unlike Britain and France, is that the political capital, the financial capital, the technological capital are all in different places, so it is very decentred. There are places where these things overlap, but there’s some way where people are able to do things that are independent.\n\nJP: Is tech going to come to the rescue like the Eagles [in Lord of the Rings], deus ex machina, providing abundance that can kind of smooth over some of the economic challenges? And as a rejoinder to that, do you think the AI bubble is about to pop?\n\nPT: There are all sorts of things that I don’t particularly like about the AI revolution. It seems to be very concentrated on bigger companies, so it’s possible a lot of the returns are captured by a few companies, possibly leading to very uneven growth. While it may be a complement to human labour, it is probably more of a substitute than a complement. It will have a zero sum feel to a lot of people. At the same time if there is no other vector of growth in our society, we would be out of our minds not to take it. I don’t think it’s big enough to solve the budget deficit, but if the US embraces AI and Europe rejects it, I think the US is in somewhat better shape than Europe is.\n\n‘There are all sorts of things that I don’t particularly like about the AI revolution’\n\nOn the question of whether or not it is a bubble, I get asked this a lot by Europeans and that is how you know that they’re not going to build a lot of AI in Europe. If it’s a bubble, then people are spending too much money on AI, and they’re building too many data centres and buying too many chips, and you’re eventually going to get seriously diminishing returns on that. During the 1990s bubble, it was mainly the telecom fibre-optic infrastructure stuff where people really spent way too much and that had to get dialled back. But maybe it’s the other way around where there are high returns to AI, enabling the automation of certain workflows and enhanced productivity.\n\nIf the AI bubble does not burst, it’s possible that it ends up being quite inflationary because you have to use more power for these data centres. The atoms part of our economy is regulated and it’s hard to ramp up the power. But if the returns on power going to AI chips are really high, it will absorb a lot of energy. Interest rates could be higher because there’s more demand for capital. My macroeconomic placeholder is that it’s going to keep going.\n\nI’ve been allergic to AI for a long time because it can be a horrible buzzword. There was a 2016 report during the Obama administration on AI by the National Science and Technology council. If you did a search and replace, and replaced every use of the word AI with computers, it would have read the same way.\n\nAI also meant all these really different things over time. In 2014, [Nick] Bostrom defined it as machines being way smarter than humans. Kai-fu Lee wrote the CCP counterpoint AI Superpowers in 2017, where he defined it as this sort of low-tech, big data machine learning. Then in 2022 it turns out the AI revolution is LLMs [large language models] which can pass the Turing test. People had thought this would be what AI was for 70 years. So in the decade before we were about to pass the Turing test we had forgotten about it.\n\nThe dynamic when one has to think through a lot \n\nIf you look at the ratio of how many businesses there are per 100,000 people: what part of the US has the lowest number of businesses? Silicon Valley. That’s because the costs of business are higher, so these subscale businesses that are too small to go anywhere are even harder to get started. In a third-world country where there are no good businesses and everyone is an umbrella salesman, they are very entrepreneurial, but not in a scalable way. So you need to differentiate entrepreneurship from scalable businesses.\n\n‘If you’re too focused on history, you don’t pay enough attention to the future’\n\nThere’s this economist called Thomas Gür who has researched the idea that immigrants are more entrepreneurial. While that is correct, you have to adjust for the quality of the businesses and the immigrants start businesses by starting a taco truck because there’s nothing else you can do. It’s better than going on welfare. But that’s what you do when you’re not really part of a society. It’s better than nothing, but what you really want to do is scale.\n\nJP: Is there a cutting-edge domain that you would focus your energies on?\n\nPT: One of the lines we had in Zero to One [Thiel’s 2014 book about startups co-written with Blake Masters] is from Anna Karenina. It’s the opening line: ‘Happy families are all alike; every unhappy family is unhappy in its own way.’ The opposite is true of business. All failed businesses are more or less alike because they fail to escape from this problem of homogeneous competition. They didn’t do anything special. All successful businesses are special in their own way. That’s the closest I can give you to a formula and it’s incredibly hard to figure out what that is, or how to do it. I have some feel for it, I know it when I see it.\n\nTo wrap things up, I have spent a lot of time thinking about the past. That’s because it’s important. It’s how we got here. It’s what shaped a lot of these debates. At the same time, there’s also some limit to history. If you’re too focused on it, you don’t pay enough attention to the future. The point is not just to reflect on the past.\n\nThere was a medieval play on the Antichrist from 1160 or so, Ludus de Antichristo. It’s not a very good literary production, but there are these three kings, the Antichrist conquerors who focus on things like nationalism or their countries or their history. They lose because they’re too fixated on the past whilst the Antichrist is thinking about the future, and about what can be done. They don’t see Antichrist coming. So while it’s very important for those on the right to think about the past, to think about the history and what happened – they still should not lose sight of the future.",
    "readingTime": 19,
    "keywords": [
      "turing test",
      "student debt",
      "behind door",
      "cultural marxism",
      "trump administration",
      "sharia law",
      "extremely difficult",
      "increase inequality",
      "nuclear reactors",
      "don’t particularly"
    ],
    "qualityScore": 1,
    "link": "https://spectator.com/article/ive-been-allergic-to-ai-for-a-long-time-an-interview-with-peter-thiel/",
    "thumbnail_url": "https://spectator.com/wp-content/uploads/2025/12/thiel_inside_colour_002.jpg",
    "created_at": "2025-12-25T12:22:24.690Z",
    "topic": "tech"
  },
  {
    "slug": "the-spacex-mafia-is-here",
    "title": "The SpaceX Mafia is here",
    "description": "SpaceX mafia startups are raising billions in venture capital, with ex-employees launching companies across aerospace, AI, and health.",
    "fullText": "Elon Musk was part of the original PayPal Mafia, a club whose members became tech world titans. Now he's building a new legacy: Meet the SpaceX Mafia.\n\nA growing group of former SpaceX employees have founded venture-backed startups of their own. Members of the SpaceX Mafia have raised funding from top venture capital firms such as Andreessen Horowitz, 8VC, and Founders Fund. A handful also passed through Y Combinator, Silicon Valley's famed funding and mentorship program for nascent startups.\n\nSpaceX in December began an insider sale that reportedly values the company at $800 billion, making it the most valuable private company. Its planned IPO is one of the most anticipated public offerings for 2026.\n\nCollectively, SpaceX Mafia companies have raised more than $3 billion in venture capital funding, according to data from analytics firm PitchBook and the founders.\n\nHere's Business Insider's list of 18 startups helmed by SpaceX-employees-turned-founders, in alphabetical order by company name.\n\nTotal raised: $5.06 million, according to PitchBook\n\nKey investors: Y Combinator, Liquid2 Ventures, Soma Capital, and angel investors\n\nNumber of employees: 8, according to the company\n\nRole at SpaceX: Ermoshkin was at SpaceX for three years and last served as an avionics systems responsible engineer.\n\nAirhart Aeronautics says it is building an easy-to-fly personal airplane to \"give everyone the freedom of flight.\"\n\n\"At SpaceX, I learned the value of extreme ownership,\" Ermoshkin said. \"As a responsible engineer, I was expected to understand and drive every part of a project — from early design through production and launch. That experience was instrumental in preparing me to be a founder and CEO.\"\n\nTotal raised: More than $500 million, according to the company\n\nKey investors: Andreessen Horowitz, Interlagos, Point72 Ventures, 8VC, XYZ Ventures, Toyota Ventures.\n\nNumber of employees: Over 230, according to the company\n\nRole at SpaceX: Benassi worked at SpaceX for six years, and last served as a senior propulsion engineer for Raptor turbomachinery and dynamic balancing.\n\nApex mass-manufactures satellite platforms that can serve a wide range of customers.\n\n\"It was an intense training ground where we tackled the most difficult problems by breaking them into manageable parts,\" Benassi said of his tenure at SpaceX. \"My advice to engineers: Think harder, go faster, challenge requirements, simplify first, optimize next.﻿\"\n\nTotal raised: Over $10 million, according to the company\n\nKey investors: Crosslink Capital, Boost VC, Type One Ventures, Stellar Ventures\n\nNumber of employees: 22, according to the company\n\nRoles at SpaceX: Robert Carlisle, director of commercial launch sales and national security sales (five years); Ryan Carlisle, director of engineering (nine years); Kirby Carlisle, integration and test engineer (four years)\n\nThe Carlisle brothers cofounded Argo Space, which is working on technology that could use water from the moon to propel space transportation. \"My time at SpaceX showed me real value is created not by the incremental advances most companies pursue, but by paradigm change,\" Robert Carlisle said. \"My cofounders and I also learned firsthand the myriad benefits of aggressively and urgently getting to hardware build and operation, which we're applying at Argo.\"\n\nTotal raised: $18.92 million, according to PitchBook\n\nKey investors: Lux Capital, MaC Venture Capital, Moore Capital Management, Y Combinator, Village Global, Stage Venture Partners.\n\nNumber of employees: 27, according to the company\n\nRole at SpaceX: Crabtree was at SpaceX for nearly 11 years, last serving as a senior missions operations engineer.\n\nEpsilon3 builds software for managing engineering, assembly, and testing, primarily in the space industry.\n\n\"At SpaceX in the early days, you were given a problem to solve, without much direction on how to solve it,\" she said. \"That environment helped people develop a scrappy attitude and a low ego when it came to doing whatever was needed, no matter the task.\"\n\n\"We're also incredibly loyal,\" she added. \"There are many people I've worked with in the past who are now using Epsilon3 at the companies they started (or joined) after SpaceX.\"\n\nTotal raised: $32 million, according to the company\n\nKey investors: Blue Bear Capital, Craft Ventures, Third Prime, Fika Ventures\n\nNumber of employees: 45, according to the company\n\nRole at SpaceX: Software and manufacturing engineer (three years)\n\nTalati now runs First Resonance, a Los Angeles-based startup that makes manufacturing software for hard-tech companies building things like air taxis and nuclear reactors. Talati found that SpaceX's unique talent pool and hard-charging disposition led to results. \"The mindset wasn't if something could be done, but when,\" he said.\n\nTotal raised: $525 million, according to the company\n\nKey investors: Linse Capital, DFJ Growth, Valor Equity Partners, Founders Fund, Lux Capital, RTX Ventures, DCVC, Airbus Ventures, Spring Tide, First Principles Group, Balerion Space Ventures, Tamarack Global, Trousdale Ventures.\n\nNumber of employees: More than 350, according to the company\n\nRole at SpaceX: Mueller was at SpaceX for nearly 19 years and last served as propulsion CTO.\n\nImpulse Space builds spacecraft that move satellites and other cargo between different orbits.\n\nSpaceX paved the way for many innovations in the space industry today, Mueller said. Among the lessons he learned: \"the importance of building a great team and the value of an optimistic mindset — being willing to push beyond what people think is possible is the best way to break new ground and advance the industry.\"\n\nTotal raised: $450 million, according to the company\n\nKey investors: Altimeter Capital, Lightspeed Venture Partners, First Round, Alpine Space Ventures, Redpoint, T. Rowe Price\n\nNumber of employees: 200, according to the company\n\nRole at SpaceX: Neel Kunjur worked at SpaceX for about 5 ½ years, mostly recently as a senior avionics systems engineer for Dragon 2.\n\nK2 Space builds large satellites that can operate across multiple orbits. Neel Kunjur cofounded the company with his brother, Karan.\n\n\"In many ways, SpaceX was an 'engineering bootcamp' where I was able to rapidly take on more responsibility than I ever thought possible,\" Neel Kunjur said. \"That level of ownership translates well to being a founder, and the exposure to extremely high-caliber engineers helps with building talented teams.\"\n\nTotal raised: $57 million, according to the company\n\nKey investors: a16z, Trust Ventures, Shrug.\n\nNumber of employees: 42, according to the company\n\nRole at SpaceX: Clemente worked at the company for about 5 ½ years as a lead life support systems engineer.\n\nLevels lets users track their metabolic health with real-time glucose monitoring, labs, and personalized coaching.\n\nSpaceX ingrained a mindset of accountability, said Clemente. \"The zero-jargon environment encouraged clarity of thought and communication, so people at every layer can follow context and contribute.\"\n\nTotal raised: $500 million, according to the company\n\nKey investors: Venrock, Lockheed Martin, Lynett Capital, T. Rowe Price, Fidelity, and others.\n\nNumber of employees: About 75, according to the company\n\nRole at SpaceX: O'Hanley was at SpaceX for about four years and last served as manager of Falcon 9 integration and test.\n\nLong Wall builds missile defense systems. The company started out as ABL, and was focused on commercial launch before pivoting to missile defense in 2024, O'Hanley said.\n\n\"The takeaway I appreciate most from SpaceX was learning to be a live player and quickly take on large challenges I'd never seen before,\" he said. \"By constantly being put in this position, you develop a framework, intuition, and disposition to do so confidently. Building a company is exactly this — continuous novel challenges that you can't always anticipate.\"\n\nTotal equity raised: $136.2 million, according to the company\n\nKey investors: Congruent Ventures, Activate Capital, Radical Ventures, Acme Capital, Costanoa Ventures, Space Capital, ArcTern Ventures.\n\nNumber of employees: Around 200, according to the company\n\nRole at SpaceX: Dyer was an engineering intern at SpaceX in the early 2000s.\n\nMuon Space builds satellite fleets to collect and deliver data about the Earth, including climate and security data.\n\n\"When I was there in the super early days (2003, 2004) it really was existential for the company and we didn't know if we'd make it,\" Dyer said of his time at SpaceX. He added that the team was \"executing violently to try and make it.\"\n\n\"As a founder, you're constantly context-switching, whether it's hardware, software, team dynamics,\" he continued, \"and SpaceX helped train me to be fluent in all of it.\"\n\nTotal raised: More than $100 million, according to the company\n\nKey investors: Amplify, Felicis, B Capital, Y Combinator.\n\nNumber of employees: About 100, according to the company\n\nRole at SpaceX: Astorino was at SpaceX for about five months, working as a software engineer on guidance, navigation, and control.\n\nPicnicHealth centralizes medical records, helping patients manage their care and also providing life-science companies with anonymized data for research.\n\n\"It's hard to pinpoint exactly what makes [SpaceX] uniquely successful — rapid build-test cycles, first-principles thinking, relentless efficiency, and obsessive focus come to mind,\" Astorino said. \"It's a north star for how I think about PicnicHealth. Healthcare is notoriously hard to change, but so is getting to space.\"\n\nTotal raised: $42 million, according to the company\n\nKey investors: American Family Ventures\n\nNumber of employees: 70, according to the company\n\nRole at SpaceX: Silvernail, engineering manager for crew and Cargo Dragon (seven years); Tan, senior life support systems engineer (five years, 10 months)\n\nPlantd is a startup in North Carolina that turns perennial grasses into building materials that the company says are carbon-negative and rival traditional plywood.\n\n\"SpaceX was basically when school really started,\" Silvernail said. \"In university, you really only get to learn fundamentals with some hands-on stuff that you do in your free time. SpaceX gave me the opportunity to focus on developing my engineering skills while getting a massive amount of responsibility right off the bat.\"\n\nTotal raised: About $460 million, according to the company\n\nKey investors: Arm, Samsung, Kindred Ventures, Top Tier Capital Partners, Saudi Aramco (via Wa'ed Ventures), SK Hynix, SK Telecom, Pavilion Capital, Korea Telecom, and others.\n\nNumber of employees: More than 270, according to the company\n\nRole at SpaceX: Park worked at SpaceX for over a year as a Starlink ASIC design engineer.\n\nRebellions makes energy-efficient chips and software to run AI systems.\n\n\"At SpaceX, I learned the value of being uncompromising when it comes to engineering excellence and ambition,\" Park said, adding that \"we believe real progress starts with those willing to take on what others avoid.\"\n\nTotal raised: $134 million, according to the company\n\nKey investors: Coatue Management, Eclipse Ventures, Lightspeed Venture Partners\n\nNumber of employees: 150, according to the company\n\nRole at SpaceX: Rose, director of flight software (5½ years); Frefel, senior hardware development manager (about 9½ years)\n\nReliable Robotics makes software that automates aircraft flight, from taxi and takeoff to landing. Rose says his experiences working on government certification processes at SpaceX and Tesla taught him to operate in highly regulated industries.\n\n\"Reporting directly to Elon,\" he said, \"taught me a lot about business and management, but it really was my extended time spent navigating a complex government bureaucracy (and enjoying it) that uniquely qualified me for starting Reliable.\"\n\nTotal raised: $57 million, according to the company\n\nKey investors: Washington Harbour Partners, Giant Step Capital, Forward Deployed Venture Capital, Veterans Ventures, Aurelia Foundry, Y Combinator\n\nNumber of employees: 125, according to the company\n\nRole at SpaceX: Dynamics engineer (eight years)\n\nTurion Space makes micro-satellites with seniors to monitor objects in space. The company has been awarded a $15 million contract from the US Space Force. At SpaceX, Westerdahl learned to \"be like water, learn fast, operate hardcore — and to keep going.\"\n\nTotal raised: $329 million, according to the company\n\nKey investors: Founders Fund, Also Capital, Natural Capital, Shrug Capital, Caffeinated Capital, Lux, Khosla Ventures.\n\nNumber of employees: More than 170, according to the company\n\nRole at SpaceX: Bruey worked at SpaceX for almost five years, and last served as a spacecraft operator and systems officer.\n\nVarda is a space manufacturing company that takes advantage of the benefits of microgravity to process materials in orbit — including pharmaceuticals and fiber optic cables — then brings them back to Earth.\n\n\"It is helpful to think of your company as a living organism,\" Bruey advised other aspiring founders, adding that \"you don't control every aspect of its nature or environment, and it needs the nurture and guidance to be healthy, happy, and effective.\"\n\nTotal raised: $27.9 million, according to the company\n\nKey investors: Greylock, South Park Commons, YCombinator\n\nNumber of employees: 55, according to the company\n\nRole at SpaceX: Vehicle systems engineer (one year)\n\nVori makes software that manages analytics for small- and mid-sized supermarkets.\n\nLaunching the demo of the Falcon Heavy rocket and deploying 21 satellites at SpaceX taught Pinkerton \"what a focused, mission-driven team can achieve when the bar is set extremely high,\" he said.\n\nTotal raised: Over $150 million, according to the company\n\nKey investors: Craft Ventures, Future Ventures, Trimble, Toyota Ventures\n\nNumber of employees: 69, according to PitchBook\n\nRole at SpaceX: Responsible engineer, thrust structure (two years)\n\nXona Space Systems makes hyper-precise satellite navigation software. In June, the company raised $92 million in a Series B round led by Craft Ventures.\n\nSpaceX challenges commonly-held assumptions that limit progress, Manning said. \"That mindset stuck with me. The most impactful companies are able to take things that seem impossible and change the world's perception to believing it is not only possible but inevitable.\"",
    "readingTime": 11,
    "keywords": [
      "andreessen horowitz",
      "founders fund",
      "lightspeed venture",
      "carlisle director",
      "venture partners",
      "missile defense",
      "space industry",
      "commercial launch",
      "toyota ventures",
      "craft ventures"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meet-the-spacex-mafia-former-elon-musk-employees-raising-billions-2025-12",
    "thumbnail_url": "https://i.insider.com/694aebfd832e0ef1ead6c133?width=1200&format=jpeg",
    "created_at": "2025-12-25T12:22:22.021Z",
    "topic": "finance"
  },
  {
    "slug": "heres-what-big-bank-ceos-have-said-about-ais-impact-on-head-count",
    "title": "Here's what big bank CEOs have said about AI's impact on head count",
    "description": "If you're one of the nearly 2 million bank staff in the US, here's what your industry leaders are saying about how generative AI may impact your job.",
    "fullText": "When bank CEOs start talking about AI, the financial world lights up — from meme accounts to markets. Their predictions about how generative AI will change work can move stocks, reshape strategy, and set the tone for the rest of corporate America.\n\nBanks' plans, and increasingly, actions, around generative AI give a glimpse into how the technology will enhance and replace human workers.\n\nBut you know who else is listening? Their employees. Many of the largest bulge-bracket banks employ over 100,000 employees each, and the FDIC-insured commercial banking sector, more broadly, employs nearly 2 million people.\n\nThese can range from bank tellers to dealmakers making multi-billion-dollar salaries, as well as a veritable army of software engineers who will turn this generative AI dream into a reality.\n\nIn order to get a better understanding of what they're thinking, we've highlighted some of the most revealing statements about bank head count in the age of AI below.\n\nJamie Dimon's penchant for straight talk means that Dimon is willing to admit that job cuts are coming.\n\n\"It will eliminate jobs,\" Dimon said at a Fortune-hosted conference earlier this month. \"People should stop sticking their heads in the sand.\"\n\nThe comments echoed those Dimon made at a town hall for the firm's employees in Columbus, Ohio, earlier this year, where he said that AI will \"change some of your jobs,\" whether as a \"copilot,\" a solution for \"drudgery,\" or by eliminating them.\n\nMore immediately for JPMorgan, according to an interview on CNN earlier this month, Dimon sees head count remaining steady, or even rising, as AI continues to roll out, \"if we do a good job.\"\n\nCore to JPMorgan's promise is increased efficiency, which Dimon explored during the 2024 Alliance Bernstein conference.\n\n\"It will affect every job, every application, every database, and it will make people highly more efficient,\" Dimon said. \"Like a lot of you clicking away, taking notes. You won't have to do that because it will — you can just summarize what Jamie said. You push a button, and you don't have to waste all that time.\"\n\nHe also explained how increased efficiency could also create more jobs in cybersecurity.\n\n\"We use it for risk and fraud recognition, and bad guys are going to use it,\" Dimon said. \"So, we have to use it to counter the bad guys. We have to use it to get better and better in cyber.\"\n\nOther executives at the firm are even more explicit about how headcount at the firm is changing now.\n\nAt the Goldman Sachs financial services conference in early December, she said that operations staff are on track to be 40% to 50% more productive over five years, but stressed that this doesn't translate into mass layoffs, but rather slower net head count growth, as each employee can handle far more work through automation, digital assistants, and self-service tools.\n\nJeremy Barnum, the firm's CFO, said they're \"asking people to resist head count growth where possible and increase their focus on efficiency.\"\n\nWhile a more efficient future with an equal number of working and non-working weekdays may exist in the coming decades, according to Dimon, for now, hiring may slow.\n\nDavid Solomon's most definitive statement about how AI will affect Goldman actually came from a memo he released earlier this year alongside the firm's president, John Waldron, and CFO Denis Coleman.\n\nThe memo, announcing the third iteration of the bank's cross-bank initiative OneGS, explains that AI will drive efficiency at the firm. Driving efficiency will mean slowing hiring and reducing roles at the firm, which is no stranger to job cuts, with a yearly culling of some employees.\n\n\"We're asking people to resist head count growth where possible and increase their focus on efficiency,\" the memo said. This will be part of a broader initiative to find the \"right team structure\" and to gain \"more agility.\"\n\nWhen Business Insider obtained the memo and reported on it, a spokesperson for the bank told us that the firm anticipates an increased head count at the end of 2025, and in the third quarter of 2025, it announced it had grown its global workforce 5% to about 48,000 positions.\n\nSlowing hiring and increasing head count don't need to be contradictory; instead, the firm is focusing its hiring on the right talent.\n\n\"We need more high-value people,\" Solomon told Axios in October. \"We can afford more high-value people to expand our footprint and continue to grow and broaden our business.\"\n\nSolomon continues to believe that AI will grow the firm's head count over the next 10 years.\n\n\"There are obviously things where we're going to have a lot fewer people — but I'd love to have the capacity to go get more people to spend time with clients,\" Solomon said at a conference last month, noting that AI will have its most immediate impact on software development.\n\nSpeaking more generally earlier this month, he said that \"disruption\" will happen, but \"our economy is very nimble, very flexible.\"\n\n\"And when you look at the technology that has flooded over hundreds of years into our society, we adapt,\" Solomon said. \"We find new businesses. We find new jobs. I don't believe it will be different this time.\"\n\nThe adoption may come quicker than previous changes, like the creation of the internet or the rollout of electricity. And Solomon shares the views of others that professional workers may take the hardest hit.\n\n\"The need for some white-collar office jobs will be diminished, but they'll be picked up in other parts of the economy,\" said Solomon.\n\nBack in 2023, Jane Fraser wrote a LinkedIn post walking through her big picture thoughts about AI at the bank. She, like her peers at the bulge brackets, saw big-time transformation ahead.\n\n\"In the near term, generative AI will drastically improve productivity,\" she wrote. \"Over the long term, it has the potential to revolutionize all functions across our bank and the industry — changing how we write code, onboard clients, service customers, detect fraud, develop market research and strengthen compliance and controls.\"\n\nOn a recent earnings call, Fraser explained how it was already increasing productivity.\n\n\"AI-driven automated code reviews have exceeded 1 million so far this year and are dramatically improving our developers' productivity,\" Fraser said. \"This innovation alone saves considerable time and creates around 100,000 hours of weekly capacity.\"\n\nFraser also highlighted how AI is helping their customer service teams resolve client inquiries faster, their wealth advisors provide more personalized advice, and the firm is launching an agent-based AI pilot to tackle more complex tasks.\n\nWhen she was asked by CNBC this month if productivity increases from AI will lead to layoffs, Fraser said her \"fear\" is that AI might \"pinch\" the job market \"before it pays.\" \n\nBut, with adoption only at 10% globally, she said, it's a long way before adoption is widespread enough to see what it will do for layoffs. Fraser said adoption will need to be closer to 50%. \n\n\"It's not there yet, and we don't know how quickly,\" Fraser said.\n\nWells Fargo has already shrunk its headcount by nearly a quarter since Charles Scharf joined in 2019, and he expects that trend to continue.\n\n\"It's likely we'll have less headcount as we look forward ... we'd like to do much of it through attrition as possible,\" Scharf told Reuters this month.\n\nHe said the lower headcount is an \"outcome\" of the firm's focus on areas where it's \"way too inefficient\" and \"way too bureaucratic.\" From 2018 to June of this year, the firm had a $1.95 trillion asset cap, hindering its ability to grow.\n\nIn the same interview, Scharf called out those who are saying that AI won't reduce jobs.\n\n\"The opportunities that exist in AI are very significant, and anyone who sits here today and says that they don't think they'll have less head count because of AI either doesn't know what they're talking about or is just not being totally honest about it,\" he said.\n\nFollowing up on those comments in early December he clarified that most people do know \" but they're afraid to say it, because no one wants to stand up and say that we should have — we're going to have lower head count in the future. It's a difficult thing to say.\"\n\nHe said that generative AI tools have already made Wells Fargo's engineers 30% to 35% more productive. While the bank hasn't cut coding jobs yet, the technology will eventually allow it to do more with fewer people across various functions, including compliance and legal, as well as call centers and even banking teams.\n\nBank of America has set a new industry standard, with a minimum wage of $25 an hour across the company. And while CEO Brian Moynihan conceded on a September Bloomberg TV interview that generative AI adoption has shrunk the size of some departments, the bank is focusing on training employees to do what LLMs cannot.\n\n\"The key to that is really redeploying people and re-skilling them,\" he said. \"We have to be more mindful about training them along multiple dimensions than we might have been two or three years ago.\"\n\nAt the Goldman financial services conference in earlier this month, Moynihan said the bank is managing flat overall staffing levels by redeploying employees rather than hiring more, with AI playing a central role in absorbing the additional workload. He pointed to Erica, Bank of America's consumer-facing AI assistant, as a clear example of how that is playing out in practice.\n\nHe said in November, the bank had 1.4 billion digital connections with its customers. \"We think it saves, today, about 11,000 FT equivalents,\" he said.",
    "readingTime": 9,
    "keywords": [
      "layoffs fraser",
      "financial services",
      "job cuts",
      "services conference",
      "slowing hiring",
      "increased efficiency",
      "count growth",
      "firm",
      "jobs",
      "generative"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ceos-jpmorgan-citi-goldman-bofa-wells-how-ai-impact-headcounts-2025-11",
    "thumbnail_url": "https://i.insider.com/687aa02d3d5881a51c1d9f2c?width=1200&format=jpeg",
    "created_at": "2025-12-25T12:22:21.586Z",
    "topic": "finance"
  },
  {
    "slug": "web-playground-for-qwenimageedit2511",
    "title": "Web playground for Qwen-Image-Edit-2511",
    "description": "Alibabaの高度なAI画像エディター、Qwen Image Edit (2511)を体験してください。正確なテキスト編集、被写体のID保持、複雑な製品やデザインの変更を実行できます。集合写真、製品マーケティング、クリエイティブな変換に最適です。",
    "fullText": "Alibabaの最新AI画像エディターは、大規模で詳細な写真編集を可能にします。集合写真の修正、製品ビジュアルの改善、テキストの差し替えなど、Qwen Image Edit (2511)はあらゆるディテールとIDを保持します。\n\nWebインターフェースを使用して、たった3つのステップでプロフェッショナルな編集を実現します。\n\n左上のモデル選択メニューから **Qwen Image Edit (2511)** を選択して、このAIエディターを有効にします。\n\nベース画像をアップロードします（オプションで参照画像も）。編集内容を説明する明確なプロンプトを入力してください（例：「他のものは動かさず、照明を一貫させたまま、テーブルにスマートフォンを追加して」）。\n\n**生成**をクリックして、Qwen Image Edit (2511)に編集を処理させます。結果は、元の被写体を維持しながら変更（新しいオブジェクト、テキスト、スタイル）を適用します。必要に応じて、追加のプロンプトや修正（「赤色を強調して」や「被写体の顔を変えないで」など）を加えて再実行し、微調整します。\n\nQwen Image Edit (2511)は、最も困難な編集の課題を解決します。集合写真での顔の一貫性を保ち、製品の幾何学的構造を維持し、画像上のテキストを正しくレンダリングします。信頼性が高く、高品質な編集が必要なあらゆる場所で使用できます。\n\n結婚式やイベントのカメラマンは、Qwen Image Edit (2511)を使用して、不要なオブジェクトを削除したり、家族写真に人物を追加したりします。このモデルは各人の顔のIDを保持し、照明と影を正しく調整して、歪みのない自然な集合写真を作成します。\n\nオンライン小売業者やデザイナーは、ラベル、背景小道具の追加、色の変更などの機能を使用して製品写真を改善します。Qwen Image Edit (2511)の高度な幾何学的理解により、追加されたグラフィックは整列され、リアルに保たれます（例：新しいロゴが曲面に平らに表示されるなど）。これは、洗練されたカタログや広告に最適です。\n\nマーケティングチームは、写真を直接編集して広告バナーを生成します。スローガンの更新、テキストの翻訳、ロゴの交換などです。ネイティブテキストサポートにより、Qwen Image Edit (2511)はフォントとスタイルをそのまま維持します。たとえば、店頭の看板を編集して、シーンの一貫性を保ちながら、複数の言語で新しいプロモーションテキストを表示できます。\n\nアーティストやコンテンツクリエイターは、視点の回転、衣装の変更、異なるアートスタイルの適用によってキャラクターデザインを反復します。Qwen Image Edit (2511)を使用すると、キャラクターの顔のリファレンスを固定してから、キャラクターのIDや比率を失うことなく、さまざまな設定やアートスタイル（リアル、アニメ、ジブリ風など）でシーンを生成できます。\n\nQwen Image Edit (2511)は、強力な200億パラメーターの基盤の上に構築され、最先端の改良が加えられています。最も魅力的な利点は次のとおりです。\n\n家族のスナップショットでもチーム写真でも、このモデルは顔を入れ替えたり、人を置き間違えたりすることなく、複数の被写体を処理します。別々の画像を1つのまとまりのある集合写真にインテリジェントにブレンドし、IDと相対的なポーズを維持します。\n\n人物やキャラクターのリファレンスをアップロードすれば、その顔が認識可能なままであることが期待できます。Qwen Image Edit (2511)は、ポーズ、表情、照明を変更するときによくある特徴の歪みの問題を劇的に減らし、各被写体が本人らしく見えるようにします。\n\n画像内のテキスト（英語または中国語）を、ほぼ完璧な忠実度で追加、削除、または変更します。モデルはテキストを独自の要素として扱うため、フォント、サイズ、配置は自然なままです。看板、パッケージ、または読みやすいテキストが必要なグラフィックデザイン作業に最適です。\n\n人気のコミュニティスタイルLoRAをすぐに使用できます。Qwen Image Edit (2511)には、厳選された芸術的および写実的なスタイルフィルターがプリロードされているため、手動で調整することなく、名前やプロンプトで特定の照明効果や漫画スタイルなどを直接適用できます。\n\n強化された幾何学的推論により、形状と遠近法を理解します。要素（看板、家具、建物など）を追加または削除する場合、それらを正しく整列させ、設計目的のために補助ガイド（青写真の線や反射など）を生成することさえあります。\n\n製品ビジュアル向けに設計されており、よりクリーンな表面と対称的な編集を生成します。デザイナーは、製品の色の変更、ラベルの追加、パッケージの更新の視覚化などのタスクを実行でき、モデルがエッジと比率を尊重してプロフェッショナルな結果をもたらすことを確信できます。\n\nZ-ImageからNano Banana Proまで、ニーズに合ったAI画像生成ツールを見つけてください\n\n画像を編集可能なレイヤーに分解し、背景を自動補完するAIツール。\n\n夢のようなポートレートを実現するシネマティックなライティング。\n\n写真の不具合に悩むのはやめましょう。Qwen Image Edit (2511)に切り替えて、あらゆるディテールを保持する簡単で一貫した編集を体験してください。今すぐz-image.appで試してみましょう！",
    "readingTime": 1,
    "keywords": [
      "edit qwen"
    ],
    "qualityScore": 0.5,
    "link": "https://z-image.app/ja/models/qwen-image-edit-2511",
    "thumbnail_url": "https://cdn.z-image.app/models/qwen-image-edit-2511/og-qwen-image-edit-2511.webp",
    "created_at": "2025-12-25T06:19:13.830Z",
    "topic": "tech"
  },
  {
    "slug": "why-your-ai-agents-are-hallucinating-and-how-to-stop-it",
    "title": "Why Your AI Agents Are Hallucinating (and How to Stop It)",
    "description": "Learn why AI agents hallucinate, the real costs of ignoring this problem, and how to automatically detect and prevent hallucinations in production using advanced evaluation scorers and root cause analysis.",
    "fullText": "Your new AI customer service agent just confidently told a user that your product is compatible with a competitor's—when it isn't. Your research agent just cited a non-existent academic paper in its summary. Your internal knowledge base agent just invented a company policy that doesn't exist.\n\nThese are not just bugs; they are AI hallucinations. And they are one of the most dangerous and insidious problems facing production AI agents today. They erode user trust, create compliance risks, and can cause direct financial damage.\n\nThis article explains why agents hallucinate and how you can automatically detect and prevent it before your customers do.\n\nAn AI hallucination occurs when a large language model (LLM) generates information that is plausible but factually incorrect, irrelevant, or nonsensical in the given context. It's not a bug in the traditional sense—the model is functioning as designed, but its internal patterns have led it to an incorrect conclusion which it presents with complete confidence.\n\nFor AI agents, which are often designed to take action based on information, hallucinations are particularly dangerous. An agent that hallucinates can:\n\nThe Dangerous Part: Unlike traditional software bugs that crash or throw errors, hallucinations appear as normal, confident responses. There's no error message—just wrong information delivered with certainty.\n\nThere are several root causes for agent hallucinations, but they often fall into a few key categories:\n\nThe agent generates information that is not supported by the context it was given. This is the most common cause of hallucinations in Retrieval-Augmented Generation (RAG) systems.\n\nExample: A customer asks about your return policy. The RAG system retrieves a document about shipping policies instead. The agent \"fills in the gaps\" by inventing a plausible-sounding return policy.\n\nThe agent makes a logical leap that is incorrect, leading it to a false conclusion. Even with correct information, the model's reasoning process can go astray.\n\nExample: An agent is told \"Product A costs 100\"and\"ProductBcosts100\" and \"Product B costs 150.\" When asked which is cheaper, it might occasionally claim Product B is cheaper due to reasoning errors.\n\nThe model's training data is old, and it provides information that is no longer accurate. This is especially problematic for rapidly changing domains.\n\nExample: An agent trained on 2023 data confidently states a library version that has since been deprecated and replaced.\n\nThe user's prompt is unclear, and the agent makes an incorrect assumption to fill in the gaps rather than asking for clarification.\n\nExample: A user asks \"What's the price?\" without specifying which product. The agent picks one arbitrarily and states its price confidently.\n\nLong conversations or documents can exceed the model's context window, causing it to \"forget\" or misremember earlier information.\n\nThe model may have learned incorrect patterns from its training data, leading to systematic hallucinations on certain topics.\n\nIgnoring hallucinations is not an option. The consequences can be severe:\n\nTraditional methods for detecting hallucinations rely on manual review and fact-checking, which are slow, expensive, and reactive. You find out about a hallucination after it has already happened—often from an angry customer.\n\nNoveum.ai offers a radically different approach: automated, real-time hallucination detection using the agent's own system prompt and context as the ground truth.\n\nOur platform uses a suite of 68+ specialized evaluation scorers to analyze every single agent response. Here are the key scorers for hallucination detection:\n\nThe faithfulness_scorer checks if the agent's answer is factually consistent with the retrieved context. It directly measures whether the agent is \"making things up.\" When a response contradicts the provided documents, it gets flagged with detailed reasoning explaining the inconsistency.\n\nThe groundedness_scorer evaluates whether the agent's responses are based on the provided context or conversation history. It penalizes the model for inventing information not supported by the facts at hand—like citing studies, statistics, or sources that don't exist in the context.\n\nInstead of requiring a manually labeled dataset of \"correct\" answers, Noveum.ai uses the agent's system prompt and the context it was given as the source of truth.\n\nThe evaluation engine automatically checks:\n\nThis allows for fully automated, real-time evaluation without the bottleneck of manual labeling.\n\nDetecting a hallucination is the first step. Understanding why it happened is the key to preventing it. This is where NovaPilot, our AI-powered root cause analysis engine, comes in.\n\nWhen a hallucination is detected, NovaPilot analyzes the entire agent trace and the scores from all 68+ evaluators to identify the root cause. It might find that:\n\nPoor Retrieval Quality — Low context_relevance score indicates the RAG system retrieved wrong documents. The agent didn't have the right information to begin with.\n\nAmbiguous System Prompt — The prompt doesn't explicitly instruct the agent to say \"I don't know.\" Missing guardrails for handling uncertainty.\n\nModel Tendency — Certain models are more prone to hallucination for specific task types. May need to switch models or add verification steps.\n\nContext Window Issues — Important information was truncated due to token limits. Need to optimize context selection.\n\nMissing Verification Steps — No fact-checking layer before response delivery. Consider adding a verification agent to the pipeline.\n\nBased on its diagnosis, NovaPilot suggests specific, actionable fixes:\n\nLet's walk through a complete example of how Noveum.ai catches and diagnoses a hallucination:\n\nA financial services chatbot is asked about the interest rate on a specific savings account. The RAG system retrieves a document about a similar but different account.\n\nThe agent confidently states the interest rate from the wrong document:\n\nUser: \"What's the interest rate on the Premium Savings Account?\"\n\nAgent: \"The Premium Savings Account offers a 2.5% APY.\" ❌\n\n(Actual rate: 3.2% APY — the agent cited the Standard Savings rate)\n\nThe evaluation engine runs automatically on this interaction:\n\nNovaPilot analyzes the trace and identifies the pattern:\n\nRoot Cause: The retrieval system, not the LLM. The wrong document was retrieved, so even a perfect LLM would give the wrong answer.\n\n\"Improve the retrieval system to be more precise. Consider using product-specific embeddings or adding metadata filtering to ensure the correct account type is retrieved. Current retrieval is matching on general 'savings account' terms rather than specific product names.\"\n\nHere's how to add hallucination detection to your existing agent:\n\nIn your Noveum.ai dashboard, select the scorers you want to apply:\n\nSet your thresholds (we recommend 7/10 for production) and configure your alert channels.\n\nConfigure real-time alerts for hallucination detection:\n\nAdd clear instructions to your system prompt:\n\nMonitor your RAG pipeline's context relevance scores. Poor retrieval is the #1 cause of hallucinations.\n\nAdd a verification step before delivering responses. Noveum.ai automatically evaluates every response against its context using our suite of 68+ scorers—no manual verification code needed. Simply enable hallucination detection in your dashboard and get instant alerts when responses don't match the provided context.\n\nHallucination patterns change over time. Monitor trends and adjust your prompts and retrieval strategies accordingly.\n\nStudies suggest that LLMs hallucinate between 3-27% of the time depending on the task and model. For RAG systems with poor retrieval, rates can be even higher.\n\nNo current technology can guarantee zero hallucinations. The goal is to detect them before they reach users and continuously reduce their frequency through better prompts, retrieval, and model selection.\n\nFaithfulness measures whether the response contradicts the provided context. Groundedness measures whether claims are supported by the context at all. A response can be faithful (not contradicting) but not grounded (adding unsupported information).\n\nEvery trace is evaluated automatically as it's captured. Scores are computed in near-real-time, and alerts are triggered immediately when thresholds are crossed.\n\nGenerally, smaller and faster models hallucinate more than larger ones. However, even GPT-4 hallucinates. The key is detection and mitigation, not model selection alone.\n\nHallucinations are a serious threat to the reliability and trustworthiness of AI agents. Relying on manual detection is a losing battle—you'll always be reacting to problems after they've damaged user trust.\n\nThe only scalable solution is to automate the process.\n\nNoveum.ai provides the industry's most advanced platform for automatically detecting, diagnosing, and fixing hallucinations in production agents. By using the system prompt as ground truth and leveraging our powerful NovaPilot engine, we help you catch problems before your customers do.\n\nYour agents are talking to customers, making recommendations, and taking actions right now. Do you know if they're telling the truth?\n\nSchedule a demo to see how Noveum.ai can protect your agents from hallucinations—before your customers find out the hard way.\n\n👉 Start Free Trial | View Documentation | Book a Demo\n\nLet's build AI agents you can actually trust.\n\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "readingTime": 8,
    "keywords": [
      "novapilot analyzes",
      "rag systems",
      "savings account",
      "premium savings",
      "poor retrieval",
      "rag system",
      "return policy",
      "automated real-time",
      "retrieves document",
      "ground truth"
    ],
    "qualityScore": 1,
    "link": "https://noveum.ai/en/blog/why-your-ai-agents-are-hallucinating-and-how-to-stop-it",
    "thumbnail_url": "https://fabulous-chocolate-2e9a61146f.media.strapiapp.com/image_1_2b6599e0d9.webp",
    "created_at": "2025-12-25T06:19:12.530Z",
    "topic": "tech"
  },
  {
    "slug": "in-a-new-deal-nvidia-hires-groqs-top-engineering-talent-including-its-founder-who-built-ai-chips-at-google",
    "title": "In a new deal, Nvidia hires Groq's top engineering talent, including its founder, who built AI chips at Google",
    "description": "A new type of dealmaking is on the rise in Silicon Valley as Nvidia reaches a non-exclusive deal with a chip startup and hires its top engineers.",
    "fullText": "Nvidia is forging ahead with another bet on the AI boom, agreeing to a licensing deal with AI hardware startup Groq.\n\nGroq said Wednesday that some of its executives, including its founder and CEO, will join Nvidia as part of the deal. Groq is expected to continue operating independently following what it described as a non-exclusive licensing deal.\n\nGroq is known for its Language Processing Unit, which is a custom chip designed for AI inference, namely, the process by which a trained AI model makes predictions or decisions. The startup was valued at about $6.9 billion as of three months ago and raised around $750 million in its latest funding round.\n\nJonathan Ross, Groq's founder and CEO, as well as the startup's president and other members of its team are expected to join Nvidia, the world's most valuable company with a market cap north of $4.5 trillion.\n\nA person familiar with the matter told Business Insider on Wednesday that Nvidia is not acquiring the chip startup.\n\nNeither Nvidia nor Groq disclosed financial terms of the agreement.\n\nRoss and Douglas Wightman were engineers at Google who started the project that became Google's first TPU chips, before leaving to found Groq. The TPUs are custom-made to accelerate large-scale machine-learning tasks designed to handle AI workloads, and are a major rival to Nvidia's GPUs.\n\nThe deal between the two companies comes as a new type of dealmaking is on the rise in Silicon Valley. Whereas traditional startups either aim to go public or be acquired, new acqui-hire deals could leave some startup employees behind, only benefiting a small percentage of staff members with desirable AI skills and the founders.\n\nFor instance, in 2024, Google agreed to pay $2.5 billion to license Character.AI's technology but only hired its two superstar cofounders and 20% of the startup's employees. In the same year, AI developers Adept and Inflection also made similar deals with Amazon and Microsoft, respectively.\n\nMore recently, Meta's acqui-hire of Scale AI became one of the biggest bets on talent after the company agreed to invest roughly $14 billion for a 49% stake and to bring its CEO, Alexandr Wang, into the fold to lead the Meta Superintelligence Labs.\n\nThese acqui-hires don't always end well. Windsurf employees were left in limbo after the AI coding startup was nearly aquired by OpenAI for $3 billion, only for the deal to fall apart and the company to be split. Google spent billions to hire Windsurf's CEO and top engineers, while the remaining hundreds of employees were acquired by another startup, Cognition.",
    "readingTime": 3,
    "keywords": [
      "join nvidia",
      "deal groq",
      "licensing deal",
      "startup",
      "employees",
      "google",
      "another",
      "founder",
      "chip",
      "designed"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-reaches-licensing-agreement-with-groq-hires-ai-top-talent-2025-12",
    "thumbnail_url": "https://i.insider.com/694c9bb5832e0ef1ead6cf7a?width=1200&format=jpeg",
    "created_at": "2025-12-25T06:19:06.742Z",
    "topic": "finance"
  },
  {
    "slug": "schleppy-agi",
    "title": "Schleppy AGI",
    "description": "Why powerful AI might arrive sooner than we think",
    "fullText": "Dwarkesh Patel recently published a compelling essay arguing that today's AI systems are still many years away from AGI. His core view is that they are missing key components of cognition, most importantly true continual learning. Despite impressive benchmark performance, current models aren't yet economically transformative because they can't learn on the job the way humans do. Instead, labs are \"pre-baking\" skills into models using Reinforcement Learning with Verifiable Rewards (RLVR), constructing bespoke training environments for coding, Excel, browser navigation, and countless other narrow tasks. To Dwarkesh, this reveals a fundamental limitation. As he puts it, \"Human workers are valuable precisely because we don't need to build schleppy training loops for every small part of their job.\"\n\nIt's a persuasive argument. But the question I keep coming back to is: is the elegant solution a hard requirement or can we sort of duct tape our way to AGI?\n\nConsider Deep Blue. In 1997, IBM's Deep Blue defeated Garry Kasparov in a six-game chess match that captivated the world. Deep Blue did not understand chess in any human sense. It had no intuition, no internalized strategy, no aesthetic judgment. It simply evaluated millions of positions per second and searched deeper than any human could. One move in Game 2 unsettled Kasparov so badly that he accused IBM of cheating; it felt too creative, too human. But it was nothing of the sort. It was brute force, systematically exploring the possibility space. Twenty years later, AlphaZero learned through self-play, developing a fluid, intuitive style that grandmasters described as alien yet beautiful. AlphaZero played chess the \"right\" way. Both systems accomplished the goal of playing chess better than humans, but Deep Blue got there first. The ugly solution won.\n\nAre we in a similar situation today?\n\nDwarkesh looks at the current AI landscape and sees missing categories of cognition. Labs are painstakingly constructing verification environments for individual skills, and to him this is evidence that models lack genuine generalization. Real jobs, he argues, consist of hundreds of small, shifting tasks that vary from day to day, even for the same person. You can't automate them with predefined skill sets. In a way he's recapitulating the old expert systems vs learning systems debate. Manually coding how to behave was too brittle, so it never worked.\n\nInterestingly, his view does stand in contrast to many lab leaders. A skeptical reader will surely argue that's because they have a strong incentive to exaggerate the pace of progress, but for the purposes of this discussion, let's take their statements at face value. Dario Amodei believes the current paradigm will get us there, predicting powerful AI as early as 2026. Sam Altman and Jakub Pachocki have offered concrete timelines, an intern-level AI researcher by late 2026 and a fully automated one by 2028, backed by over a trillion dollars in infrastructure commitments. Mark Chen, OpenAI's Chief Research Officer, has pushed back on the idea that scaling is exhausted, hinting that they have made some important breakthroughs in pretraining specifically.\n\nThis perspective is not unanimous. Demis Hassabis believes additional breakthroughs are needed on the level of the transformer, and Andrej Karpathy estimates something like a decade. This camp tends to be more neuroscience-inspired, believing the current architectures are missing something fundamental.\n\nSo what's the actual bottleneck?\n\nDwarkesh's argument largely boils down to three problems all related to memory. First, current models are sample inefficient—they need far more examples to learn something than a human would. Second, what they learn isn't general enough to transfer across contexts. Third, they can't continue to learn on the job the way humans do.\n\nThis last problem is intrinsic to how gradient descent works. When a model learns, it adjusts billions of parameters at once, a global update that touches the entire network. This makes the system brittle; new information can overwrite old information, a problem called catastrophic forgetting. So today’s models come with a frozen pretrained brain and rely on stuffing relevant information into each prompt, called a context window. These are crude substitutes. Everything must be reprocessed with every response. There's no dynamic working memory, no graceful fading of irrelevant information, no seamless integration with long-term storage.\n\nThis matters for a number of reasons. Without the ability to integrate new information into its world model, it can only grasp new tasks superficially. It can't build on what it learned yesterday. Models struggle to navigate complex software because they can't track things the way you do. Photoshop is intuitive to an experienced user, but to a model with fragmented memory, every menu is half-familiar, every action a guess. These aren't signs of low intelligence. They're signs of a specific limitation, not dissimilar to a human disability. Blindness or deafness will make some tasks virtually impossible, but this says nothing about their underlying intelligence. Similarly, a model can be extraordinarily capable and still fail at tasks that require persistent memory.\n\nAll of this is accurate. The open question is whether it represents a hard scientific boundary or is just a matter of iterative engineering.\n\nHuman memory itself is not a single, elegant system. It's a collection of specialized mechanisms layered together by evolution. Most day-to-day learning does not instantly integrate deeply into the brain. It involves holding information in working memory, encoding episodes, retrieving associations, and slowly consolidating over time.\n\nSeen this way, perhaps the models aren't so far from functional equivalence after all. Retrieval over long interaction histories so a system remembers what you discussed weeks ago. Persistent preference and project files injected into context. Lightweight fine-tuning methods like LoRA applied periodically rather than continuously. External memory via tool use, where models write notes to themselves and read them back. Better working-memory mechanisms layered on top of existing architectures. None of this requires brand-new science, and much of it already exists in partial form.\n\nThese solutions are undeniably schleppy. They are brittle and can fail in surprising ways. Skeptics rightly point out that unlike chess, which is a closed system with perfect information, the real world is an open environment where errors can compound. That's all true, but we are no longer discussing hypotheticals. People are already using these systems for real work. Coding agents are writing and debugging software semi-autonomously. Customer service systems are starting to handle basic help desk queries. Legal research can often be handled end to end by an extended thinking model. There's still a capability gap, but it is shrinking.\n\nIt's important to recognize that 2025 was less a year of huge new models than one of bringing the frontier to everyone at a reasonable cost. That infrastructure buildout absorbed resources that might otherwise have gone toward pushing capabilities. If progress has felt slower than expected, this is part of the reason. It's easy to anchor on the current pace and assume it's the new normal. That would be a mistake.\n\nThe hardware trajectory is significant. Nvidia’s GB300 NVL72 racks use 72 Blackwell Ultra GPUs acting as a single massive unit. Microsoft has announced the first large-scale production cluster with over 4,600 of these racks, claiming it will enable training models with hundreds of trillions of parameters and reduce training times from months to weeks. Depending on workload, this represents anywhere from a 4x improvement in training speed to a 10x reduction in inference costs compared to the previous generation. When you can throw an order of magnitude more compute at context management, retrieval, and verification, many of today's clumsy workarounds start to look far more viable.\n\nWe do need solutions to memory and some degree of continual learning, but Dwarkesh may also be understating how much current models already generalize. No one built a special training pipeline for GeoGuessr, yet general models can perform at a borderline superhuman level. This requires inferring the geographic location of pictures from subtle cues like vegetation, signage, architecture, and sun angle. And long before job-specific reinforcement learning was used, models already showed remarkable capability across many professions, just from compressing the internet.\n\nThe labs' heavy investment in RLVR could be viewed less like a confession of architectural inadequacy and more like a pragmatic choice. RLVR improves effectiveness on tasks that matter commercially. It simply juices the value of current models.\n\nThe benchmark, OSWorld, provides a useful case in point of my argument. This benchmark tests models on everyday computer tasks in a virtual machine: adding page numbers to a document, exporting a CSV from a spreadsheet, configuring browser settings. Over the past year, success rates have climbed from under 10% to over 60%, approaching the human baseline of 72%. But a closer look reveals something interesting: much of this progress comes from models finding workarounds. About 15% of tasks can be completed using only terminal commands, no GUI required. Another 30% can be largely solved with Python scripts instead of clicking through menus. The benchmark was designed to measure GUI manipulation, something models are known to struggle with, but instead of failing, they just found a workaround.\n\nThis discussion largely hinges on how far these workarounds can ultimately go. The debate isn't about whether human-like continual learning would be powerful. It would be. It's about what exactly is required to cross the human threshold of reliable knowledge work. History suggests that inelegant, resource-intensive solutions arrive first, especially when the incentives are overwhelming.\n\nRay Kurzweil's long-running prediction of human-level AI by 2029 is relevant here. Kurzweil's track record on specific technologies is mixed, but he has been remarkably prescient about the pace and magnitude of technological progress. His law of accelerating returns is all about markets. Computing power compounds due to incentives and what’s allowed by physics. Capital, talent, and institutional effort then develop new technologies enabled by that compute.\n\nHumans are best understood as what E.O. Wilson called a “superorganism,” similar to ants or termites. We cooperate at an unprecedented scale. And this global superorganism has slowly been turning itself toward the production of machine intelligence ever since ChatGPT arrived in late 2022. Nation-states, corporations, supply chains, research communities, and capital markets are all aligning around the same attractor. This applies immense pressure to each barrier to progress.\n\nIf the current paradigm fails to reach AGI, it will be because continual learning turns out to be a hard scientific barrier rather than an engineering challenge. But given the scale of investment, the pace of hardware progress, and the growing stack of workable approximations, I'd bet on the engineers.\n\nIt's unclear when we will get the elegant, human-like mind we are waiting for. But if history is any guide, that distinction may not matter much. When Deep Blue won, Kasparov felt it was a trick. He sensed a human creativity that simply wasn't there and accused IBM of cheating. We are likely walking into the same psychological trap. We will look at these schleppy, duct-taped systems and insist they are just parroting data or faking reasoning. We will call it a parlor trick right up until the moment it outperforms us. At that point, like Kasparov, we will have to accept that the mechanism matters less than the move.",
    "readingTime": 10,
    "keywords": [
      "accused ibm",
      "mechanisms layered",
      "continual learning",
      "models aren't",
      "deep blue",
      "human",
      "tasks",
      "memory",
      "systems",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.seriousanimals.com/schleppy-agi/",
    "thumbnail_url": "https://www.seriousanimals.com/content/images/2025/12/Gary_DeepBlue.jpg",
    "created_at": "2025-12-25T00:56:21.644Z",
    "topic": "tech"
  },
  {
    "slug": "silicon-valleys-tonedeaf-take-on-the-ai-backlash-will-matter-in-2026",
    "title": "Silicon Valley's tone-deaf take on the AI backlash will matter in 2026",
    "description": "AI’s champions keep trying to impress, but the public is still waiting for answers about jobs, costs, and who benefits. By 2026, that tension will matter.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2025/12/23/silicon-valleys-tone-deaf-take-on-the-ai-backlash-will-matter-in-2026/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2236544323_ce1755-e1766508826353.jpg?resize=1200,600",
    "created_at": "2025-12-25T00:56:21.638Z",
    "topic": "tech"
  },
  {
    "slug": "librarians-tired-of-being-accused-of-hiding-secret-books-that-were-made-up-by-ai",
    "title": "Librarians Tired of Being Accused of Hiding Secret Books That Were Made Up by AI",
    "description": "AI chatbots are generating fake titles that people insist are real.",
    "fullText": "Everyone knows that AI chatbots like ChatGPT, Grok, and Gemini can often hallucinate sources. But for the folks tasked with helping the public find books and journal articles, the fake AI bullshit is really taking its toll. Librarians sound absolutely exhausted by the requests for titles that don’t exist, according to a new post from Scientific American.\n\nThe magazine spoke with Sarah Falls, the chief of researcher engagement at the Library of Virginia, who estimates that about 15% of all emailed reference questions that they receive are generated by AI chatbots like ChatGPT. And the requests often include questions about fake citations.\n\nWhat’s more, Falls suggests that people don’t seem to believe librarians when they explain that a given record doesn’t exist, a trend that’s been reported elsewhere like 404 Media. Many people really believe their stupid chatbot over a human who specializes in finding reliable information day in and day out.\n\nA recent post from the International Committee of the Red Cross (ICRC) titled, “Important notice: AI generated archival reference,” provides more evidence that librarians are just exhausted with it all.\n\n“If a reference cannot be found, this does not mean that the ICRC is withholding information. Various situations may explain this, including incomplete citations, documents preserved in other institutions, or— increasingly—AI-generated hallucinations,” the organization said. “In such cases, you may need to look into the administrative history of the reference to determine whether it corresponds to a genuine archival source.”\n\nYes it happened to me 🫠, I went to a bookstore for a totally plausible old French metaphor book mentioned by ChatGPT a year ago, only to discover that it does not exist.\n\n— Joanne Boisson (@joanneboisson.bsky.social) December 9, 2025 at 4:31 AM\n\nThe year seems to have been filled with examples of fake books and journal articles created with AI. A freelance writer for the Chicago Sun-Times generated a summer reading list for the newspaper with 15 books to recommend. But ten of the books didn’t exist. The first report from Health Secretary Robert F. Kennedy Jr.’s so-called Make America Healthy Again commission was released in May. A week later, reporters at NOTUS published their findings after going through all of the citations. At least seven didn’t exist.\n\nYou can’t blame everything on AI. Papers have been retracted for giving fake citations since long before ChatGPT or any other chatbot came on the scene. Back in 2017, a professor at Middlesex University found at least 400 papers citing a non-existent research paper that was essentially the equivalent of filler text.\n\nVan der Geer, J., Hanraads, J.A.J., Lupton, R.A., 2010. The art of writing a scientific article. J Sci. Commun. 163 (2) 51-59.\n\nIt’s gibberish, of course. The citation seems to have been included in many lower quality papers—likely due to laziness and sloppiness rather than an intent to deceive. But it’s a safe bet that any authors of those pre-AI papers would have probably been embarrassed about their inclusion. The thing about AI tools is that too many humans have come to believe our chatbots are more trustworthy than humans.\n\nAs someone who gets lots of local history queries, can confirm there’s been a big increase in people starting their history research with GenAI/LLM (which just spews out fake facts and hallucinated rubbish) who then wonder why they can’t find anything at all to corroborate it.\n\n— Huddersfield Exposed (@huddersfield.exposed) December 9, 2025 at 2:28 AM\n\nWhy might users trust their AI over humans? For one thing, part of the magic trick that AI pulls is speaking in an authoritative voice. Who are you going to believe, the chatbot you’re using all day or some random librarian on the phone? The other problem might have something to do with the fact that people develop what they believe are reliable tricks for making AI more reliable.\n\nSome people even think that adding things like “don’t hallucinate” and “write clean code” to their prompt will make sure their AI only gives the highest quality output. If that actually worked, we imagine companies like Google and OpenAI would just add that to every prompt for you. If it does work, boy, have we got a lifehack for all the tech companies currently terrified of the AI bubble bursting.",
    "readingTime": 4,
    "keywords": [
      "journal articles",
      "didn’t exist",
      "fake citations",
      "books",
      "reference",
      "chatbots",
      "librarians",
      "don’t",
      "generated",
      "chatbot"
    ],
    "qualityScore": 1,
    "link": "https://gizmodo.com/librarians-arent-hiding-secret-books-from-you-that-only-ai-knows-about-2000698176",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2025/12/library-books-1200x675.jpg",
    "created_at": "2025-12-25T00:56:20.209Z",
    "topic": "tech"
  },
  {
    "slug": "vidscore-ai-analyze-your-videos-before-you-post",
    "title": "VidScore AI: Analyze your videos before you post",
    "description": "Download VidScore AI: Viral Analytics by Gavin Alfaro on the App Store. See screenshots, ratings and reviews, user tips, and more games like VidScore AI: Viral…",
    "fullText": "VidScore AI: Viral Analytics Grow on TikTok, Reels & More! Free · In‑App Purchases Share iPhone, iPad Ratings & Reviews App Privacy The developer, Gavin Alfaro, indicated that the app’s privacy practices may include handling of data as described below.",
    "readingTime": 1,
    "keywords": [
      "privacy"
    ],
    "qualityScore": 0.2,
    "link": "https://apps.apple.com/us/app/vidscore-ai-viral-analytics/id6756249746",
    "thumbnail_url": "https://is1-ssl.mzstatic.com/image/thumb/PurpleSource211/v4/e1/27/1c/e1271cd4-5f6c-c9b2-3d0c-ca7e23c58fd6/Placeholder.mill/1200x630wa.jpg",
    "created_at": "2025-12-25T00:56:19.910Z",
    "topic": "tech"
  },
  {
    "slug": "keystone-yc-s25-is-hiring-engineer-1-to-automate-coding",
    "title": "Keystone (YC S25) is hiring engineer #1 to automate coding",
    "description": "About Keystone\nWe're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\nWe're in-person in SoMa, San Francisco.",
    "fullText": "We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\n\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\n\nWe're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.\n\nYou'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.\n\nYou might be a great fit if you:\n\nStack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS\n\nComp & benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget",
    "readingTime": 2,
    "keywords": [
      "we're",
      "product",
      "logs",
      "ventures",
      "you'd"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/06e7837c1e5c8ce88da333ac2efcf401d8cbee53.png?1747973680",
    "created_at": "2025-12-25T00:56:12.872Z",
    "topic": "jobs"
  },
  {
    "slug": "vibium-browser-automation-for-ai-and-humans-by-seleniums-creator",
    "title": "Vibium – Browser automation for AI and humans, by Selenium's creator",
    "description": "Browser automation for AI agents and humans. Contribute to VibiumDev/vibium development by creating an account on GitHub.",
    "fullText": "VibiumDev\n\n /\n\n vibium\n\n Public\n\n Browser automation for AI agents and humans\n\n vibium.com\n\n License\n\n Apache-2.0 license\n\n 278\n stars\n\n 33\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n VibiumDev/vibium",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/VibiumDev/vibium",
    "thumbnail_url": "https://opengraph.githubassets.com/83c696e434d7596c7c64287273badacec418d5f214c4c110077e01f4c531c358/VibiumDev/vibium",
    "created_at": "2025-12-24T18:17:37.822Z",
    "topic": "tech"
  },
  {
    "slug": "a-nobel-prizewinning-physicist-explains-how-to-use-ai-without-letting-it-do-your-thinking-for-you",
    "title": "A Nobel Prize-winning physicist explains how to use AI without letting it do your thinking for you",
    "description": "Leading physicist Saul Perlmutter warns AI can create a false sense of confidence, urging skepticism and constant error-checking.",
    "fullText": "Probably not, according to Saul Perlmutter, a Nobel Prize-winning physicist who was credited for discovering that the universe's expansion is accelerating.\n\nHe said AI's biggest danger is psychological: it can give people the illusion they understand something when they don't, weakening judgment just as the technology becomes more embedded in our daily work and learning.\n\n\"The tricky thing about AI is that it can give the impression that you've actually learned the basics before you really have,\" Perlmutter said on a podcast episode with Nicolai Tangen, CEO of Norges Bank Investment Group, on Wednesday.\n\n\"There's a little danger that students may find themselves just relying on it a little bit too soon before they know how to do the intellectual work themselves,\" he added.\n\nRather than rejecting AI outright, Perlmutter said the answer is to treat it as a tool — one that supports thinking instead of doing it for you.\n\nPerlmutter said that AI can be powerful — but only if users already know how to think critically.\n\n\"The positive is that when you know all these different tools and approaches to how to think about a problem, AI can often help you find the bit of information that you need,\" he said.\n\nAt UC Berkeley, where Perlmutter teaches, he and his colleagues developed a critical-thinking course centered on scientific reasoning, including probabilistic thinking, error-checking, skepticism, and structured disagreement, taught through games, exercises, and discussion designed to make those habits automatic in everyday decisions.\n\n\"I'm asking the students to think very hard about how would you use AI to make it easier to actually operationalize this concept — to really use it in your day-to-day life,\" he said.\n\nOne of Perlmutter's concerns is that AI often speaks with far more certainty than it deserves and can be \"overly confident\" in what it says.\n\nThe challenge, Perlmutter said, is that AI's confident tone can short-circuit skepticism, making people more likely to accept its answers at face value rather than question whether they're correct.\n\nThat confidence, he said, mirrors one of the most dangerous human cognitive biases: trusting information that appears authoritative or confirms our existing beliefs.\n\nTo counter that instinct, Perlmutter said people should evaluate AI outputs the same way they would any human claim — weighing credibility, uncertainty, and the possibility of error rather than accepting answers at face value.\n\nIn science, Perlmutter said, researchers assume they are making mistakes and build systems to catch them. For example, scientists hide their results from themselves, he said, until they've exhaustively checked for errors, thereby reducing confirmation bias.\n\nThe same mindset applies to AI, he added.\n\n\"Many of [these concepts] are just tools for thinking about where are we getting fooled,\" he said. \"We can be fooling ourselves, the AI could be fooling itself, and then could fool us.\"\n\nThat's why AI literacy also involves knowing when not to trust the output, he said — and being comfortable with uncertainty, rather than treating AI outputs as absolute truth.\n\nStill, Perlmutter is clear that this isn't a problem with a permanent solution.\n\n\"AI will be changing,\" he said, \"and we'll have to keep asking ourselves: is it helping us, or are we getting fooled more often? Are we letting ourselves get fooled?\"",
    "readingTime": 3,
    "keywords": [
      "rather",
      "fooled",
      "perlmutter",
      "ai's",
      "danger",
      "students",
      "tools",
      "skepticism",
      "confident",
      "face"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-to-use-ai-without-losing-critical-thinking-leading-physicist-2025-12",
    "thumbnail_url": "https://i.insider.com/694bd59964858d02d2175b75?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:34.046Z",
    "topic": "finance"
  },
  {
    "slug": "how-wall-street-banks-are-using-ai-from-staff-training-to-performance-reviews",
    "title": "How Wall Street banks are using AI — from staff training to performance reviews",
    "description": "JPMorgan, Citi, and Goldman Sachs are investing heavily in AI technology to transform operations, enhance productivity, and stay competitive.",
    "fullText": "JPMorgan Chase has a technology budget of $18 billion, with much of it going toward making sure it's a leader and early mover in AI.\n\nJPMorgan CEO Jamie Dimon is a \"tremendous\" user of the bank's generative AI suite. The bank has rolled out its proprietary genAI platform to over 200,000 employees. And with about 100 more tools in the pipeline, JPMorgan is seeking to reengineer workflows for everyone from coders to portfolio managers.\n\nJPMorgan has reportedly given employees the option to use its in-house AI tools to assist in writing year-end performance reviews.\n\nExecutives at America's largest bank gave an inside look at how it's training employees to use its tools and how they're using them to deliver measurable results.\n\nDimon has previously said he's out to win the AI arms race, and he thinks JPMorgan's $2 billion AI investment has already matched its cost in savings.\n\nCitigroup has also been aggressively accelerating its AI plans. Over the summer, the bank doubled down on its AI ambitions with new leadership at the helm of its tech transformation.\n\nIn mid-October, Citi CEO Jane Fraser said that nearly 180,000 employees in 83 countries have access to the bank's proprietary AI tools and have used them almost 7 million times this year.\n\nIts generative AI tools have saved 100,000 developer hours a week with automated code reviews — \"a very meaningful productivity uplift,\" she said during the firm's third-quarter earnings call.\n\nThe bank launched the pilot of agentic AI for 5,000 colleagues in September.\n\n\"It allows complex, multi-step tasks to be completed with a single prompt, and the early results are very promising, and we'll expand access to this in the months ahead,\" said Fraser. \"Finally, we have launched a firm-wide effort to systematically embed AI in our processes end-to-end to drive further efficiencies, reduce risk, and improve client experience.\"\n\nShe also highlighted several tools to help its wealth management advisors. Citi hired an AI leader from Morgan Stanley earlier this year to help revamp its wealth technology.\n\nLike JPMorgan, Citi is also telling employees to use AI for performance reviews, Fraser recently told Bloomberg in an interview.\n\nOne of Citi's top tech executives, Shadman Zafar, outlined the bank's four-phased AI strategy and how it will \"change how we work for decades to come.\"\n\nGoldman put $6 billion behind its technology spend this year, but David Solomon, the bank's CEO, said he wished it were more.\n\nHe said he would like to be at least $8 billion, but \"I can't afford it because I've got to deliver returns,\" he said at a conference in early October.\n\nA definitive statement about how AI will affect Goldman came from a memo to employees in October announcing the third iteration of the bank's cross-bank initiative OneGS. The memo said the plan would leverage AI will drive efficiency at the firm, slow hiring, and result in a \"limited reduction\" of roles.\n\nGoldman, like its peers, has been rolling out tools, including an internal AI assistant to all employees this summer.\n\nBusiness Insider talked to employees about how they were using AI.\n\nGoldman's top partners and Solomon are eager to see AI rev up their businesses. From realizing internal productivity gains to capturing more business as clients look to raise money in anticipation of AI development and acquisitions, here's what the top echelon is expecting.\n\nThere is no AI without data, and there is no data strategy at Goldman without its chief data officer, Neema Raphael. Raphael gave Business Insider an inside look at how his roughly 500-person team melds with the rest of the bank to get the most out of its data.\n\nMorgan Stanley's CFO, Sharon Yeshaya, lifted the curtain on some of the firm's progress on AI during its earnings call last month.\n\nShe highlighted DevGen.AI, a tool that, from January to June, Business Insider previously reported, had saved developers more than 280,000 hours, or 11,666 days they would have previously dedicated to deciphering outdated code.\n\nParable, an interactive tool that analyzes and summarizes data, and LeadIQ, an AI-powered lead distribution platform that matches users of its workplace and self-directed platforms to the bank's financial advisors, were also spotlighted in the call.\n\nA survey of Morgan Stanley's interns also gave a peek into just how popular and useful AI has been for the industry's youngest cohort. ChatGPT is their favorite tool by far — with 72% of Morgan Stanley's interns said they use it daily or several times a week. The bank was early to have a partnership with ChatGPT-maker OpenAI.\n\nMorgan Stanley also spoke with Business Insider about bringing employees' AI ideas to life. Here's a look at that process.\n\nBank of America's AI rollout is also well underway.\n\nThe bank's CEO Brian Moynihan says its use of AI is already embedded across the firm, from consumer banking to institutional clients. Its virtual assistant, Erica, handled 2 million customer interactions in a single day and can now answer 700 types of questions — up from 210 a year ago. Executives said they'll share more details on the bank's AI strategy at its investor day on November 5.\n\nRob Pascal, the bank's chief experience officer, previously detailed how the bank's internal-facing AI assistant helps bankers collect, record, and review client data.",
    "readingTime": 5,
    "keywords": [
      "stanley's interns",
      "performance reviews",
      "bank's ceo",
      "inside look",
      "business insider",
      "morgan stanley's",
      "employees",
      "tools",
      "previously",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wall-street-banks-ai-strategy-jpmorgan-goldman-citi-bofa-2025",
    "thumbnail_url": "https://i.insider.com/66bf62d95da406397bf6896f?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:33.963Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-bubble-debate-17-business-leaders-from-sam-altman-to-bill-gates-to-peter-thiel-weigh-in",
    "title": "The AI bubble debate: 17 business leaders, from Sam Altman to Bill Gates to Peter Thiel, weigh in",
    "description": "OpenAI's Sam Altman sparked fears of an AI bubble. Business leaders like Bill Gates, Mark Cuban, and Jensen Huang disagree over whether one exists.",
    "fullText": "The AI boom shows no sign of slowing down. Some top business leaders are concerned that a bubble is about to burst.\n\nIn August, OpenAI CEO Sam Altman gave voice to those fears about the future of AI. Since then, other CEOs, including Nvidia's Jensen Huang, have dismissed concerns of an AI bubble. Wall Street is also worried about the increasing circular nature of Big Tech's spending spree.\n\nHere's what leading tech CEOs and business leaders are saying about what's ahead.\n\nOpenAI CEO Sam Altman said that the AI market is in a bubble.\n\n\"When bubbles happen, smart people get overexcited about a kernel of truth,\" Altman recently told reporters, per The Verge.\n\nAltman said this describes the state of play.\n\n\"Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes. Is AI the most important thing to happen in a very long time? My opinion is also yes,\" he said.\n\nMicrosoft cofounder Bill Gates says AI is in a bubble — just not to the extent of Danish tulips.\n\n\"The value is extremely high, just like creating the internet ended up being, in net, very valuable,\" Gates told CNBC in late October. \"But you have a frenzy. And some of these companies will be glad they spent all this money. Some of them, you know, they'll commit to data centers whose electricity is too expensive.\"\n\nGates said that the situation reminds him of dot-com bubble when overvalued internet companies sparked a crash.\n\n\"Absolutely, there are a ton of these investments that will be dead ends,\" he said.\n\nStill, the billionaire said that AI remains a major breakthrough, calling it \"the biggest technical thing ever in my lifetime.\"\n\nMark Cuban, who famously sold Broadcast.com just before the dot-com bubble burst, said he doesn't see similarities to the current situation.\n\n\"There were people creating companies with just a website and going public. That's a bubble where there's no intrinsic value at all,\" Cuban told podcaster Lex Fridman in 2024. '\"People aren't even trying to make operating cap profits, they're just trying to leverage the frothiness of the stock market, that's a bubble. You don't see that right now. \"\n\nCuban took particular notice of the quality of AI companies going public.\n\n\"We're not seeing funky AI companies just go public,\" he said. \"If all of a sudden we see a rush of companies who are skins on other people's models or just creating models to create models that are going public, then yeah, that's probably the start of a bubble.\"\n\nMeta CEO Mark Zuckerberg said AI could become a bubble, but there will only be a crash if companies fail to keep making advancements.\n\n\"If the models keep on growing in capability year-over-year and demand keeps growing, then maybe there is no collapse,\" Zuckerberg told the \"Access\" podcast in September.\n\nZuckerberg said there are risks that the AI boom becomes like the dot-com bubble.\n\n\"There's definitely a possibility, at least empirically, based on past large infrastructure buildouts and how they led to bubbles, that something like that would happen here.\"\n\nFor Meta, Zuckerberg said the real risk is not spending enough.\n\n\"The risk, at least for a company like Meta, is probably in not being aggressive enough rather than being somewhat too aggressive,\" he said.\n\nNvidia CEO Jensen Huang doesn't see a bubble.\n\n\"I don't believe we're in an AI bubble,\" Huang told Bloomberg TV.\n\nHuang said that instead of overspeculation, AI is part of a transition from an old way of computing.\n\n\"We're going through a natural transition from an old computing model based on general purpose computing to accelerated computing,\" he said. \"We also know that AI has become good enough because of reasoning capability, and research capability, its ability to think — it's now generating tokens and intelligence that is worth paying for.\"\n\nNvidia is skyrocketing amid AI-fueled hope. In late October, the chipmaker became the world's first $5 trillion market cap company.\n\nHuang said Nvidia is happy to pay for AI for its employees, name-checking Cursor, an AI coding agent, as one of many services for which his company pays.\n\nGoogle CEO Sundar Pichai said there is some \"irrationality\" in the AI boom. He also cautioned that if a bubble were to burst, its blast radius would extend across the private sector.\n\n\"I think no company is going to be immune, including us,\" Pichai told the BBC in November.\n\nComparing the current moment to the Dotcom era, Pichai said that sometimes investment cycles can \"overshoot.\"\n\n\"I expect AI to be the same,\" he said. \"So I think it's both rational and there are elements of irrationality through a moment like this.\"\n\nAmazon founder Jeff Bezos says AI is in a bubble, but not in the way everyone might think.\n\nBezos called the current situation an \"industrial bubble.\" The world's third-richest person said there are similarities now, including the frenzy of investments.\n\n\"The good ideas and the bad ideas. And investors have a hard time in the middle of this excitement, distinguishing between the good ideas and the bad ideas,\" he said in October during a conference in Italy. \"And that's also probably happening today.\"\n\nBezos said that hoopla shouldn't overshadow the reality that \"AI is real\" and will change society.\n\n\"The [bubbles] that are industrial are not nearly as bad,\" Bezos said. \"It can even be good, because when the dust settles and you see who are the winners. Societies benefit from those inventions.\"\n\nJPMorgan Vice Chairman Daniel Pinto said he sees a correction coming.\n\n\"There is probably a correction there,\" Pinto said at a Bloomberg event in November.\n\nPinto said the market is pushing valuations beyond current justifications.\n\n\"In order to justify these valuations, you are considering a level of productivity that, it will happen, but it may not happen as fast as the market is pricing now,\" he said.\n\nLike Altman, OpenAI chairman Bret Taylor says we're in an AI bubble.\n\n\"I think it is both true that AI will transform the economy, and I think it will, like the internet, create huge amounts of economic value in the future,\" Taylor told The Verge in September. \"I think we're also in a bubble, and a lot of people will lose a lot of money.\"\n\nTaylor, who is also CEO of Sierra, also sees some similarities to the dot-com bubble. He also said that some of the internet companies that failed in the 90s were just ahead of their time.\n\n\"Even things like Webvan, there's now, as the internet became more distributed, really healthy businesses like Instacart and DoorDash and others that were built now that the smartphone and the scale of the internet has matured,\" he said. \"So even some of the specific ideas were actually not that bad, but maybe a little early.\"\n\nFormer Google CEO Eric Schmidt said just because it looks like a bubble doesn't mean that it is.\n\n\"I think it's unlikely, based on my experience, that this is a bubble,\" Schmidt said in July during an appearance at the RAISE Summit in Paris. \"It's much more likely that you're seeing a whole new industrial structure.\"\n\nSchmidt said it takes solace in where the hardware and chips markets stand.\n\n\"You have these massive data centers, and Nvidia is quite happy to sell them all the chips,\" he said. \"I've never seen a situation where hardware capacity was not taken up by software.\"\n\nFormer Intel CEO Pat Gelsinger says AI is in a bubble, but it won't pop for \"several years.\"\n\n\"Are we in an AI bubble? Of course. Of course we are,\" Gelsinger told CNBC in October. \"I mean, we're hyped. We're accelerating. We're putting enormous leverage into the system.\"\n\nGelsinger said that businesses are just beginning to reap the benefits of AI.\n\n\"As Jensen (Huang) talked about, and I agree with this, you know that businesses are yet to really start materially benefiting from it,\" he said. \"We're displacing all of the internet and the service provider industry as we think about it today — we have a long way to go.\"\n\nAlibaba cofounder Joe Tsai has voiced concerns about the scramble for data centers needed to help power the next generation of AI models.\n\n\"I start to see the beginning of some kind of bubble,\" Tsai told the HSBC Global Investment Summit in March, Bloomberg News reported.\n\nTsai said he's worried the building rush might outpace demand.\n\n\"I start to get worried when people are building data centers on spec,\" he said. \"There are a number of people coming up, funds coming out, to raise billions or millions of capital.\"\n\nHedge fund icon Ray Dalio voiced concerns about a bubble earlier this year, when DeepSeek's rollout led analysts to rethink AI's outlook.\n\n\"Where we are in the cycle right now is very similar to where we were between 1998 or 1999,\" Dalio told the Financial Times in January. \"There's a major new technology that certainly will change the world and be successful. But some people are confusing that with the investments being successful.\"\n\nAt the time, Dalio cited high stock prices and high interest rates. The good news is that Wall Street widely expects the Federal Reserve to cut rates during its September meeting.\n\nBillionaire tech CEO Thomas Siebel said there is \"absolutely\" an AI bubble and that it's \"huge.\"\n\n\"So we have this similar thing going on with generative AI that we've seen with previous technologies,\" Siebel told Fortune in January. \"The market is way, way overvaluing.\"\n\nSiebel, who leads C3.ai, singled out OpenAI in terms of overevaluations.\n\n\"If it disappeared, it wouldn't make any difference in the world,\" he said. \"Nothing would change. I mean, nobody's life would change. No company would change. Microsoft would find something else to power Copilot. There's like 10 other products available that would do it equally as good.\"\n\nAMD CEO Lisa Su says the bubble talk \"is completely wrong.\"\n\n\"For those who are talking about a 'bubble,' I think they're being too narrow in their thinking of, what is the return on investment today or over the next six months,\" Su told Time Magazine in 2024. \"I think you have to look at this technology arc for AI over the next five years, and how does it fundamentally change everything that we do? And I really believe that AI has that potential.\"\n\nNicolai Tangen, who runs the world's biggest sovereign wealth fund, said if AI is a bubble, \"it may not be such a bad bubble.\"\n\nSpeaking to the Financial Times in November, the CEO of Norway's $2 trillion sovereign wealth fund said that AI is a \"pretty hot space\" right now, fueled by hype and a wave of capital. As the technology marks a sweeping societal shift, traditional valuations can be difficult to determine.\n\nTangen said overvaluation isn't entirely negative. The sheer volume of capital rushing into AI will ultimately fund technologies that boost long-term productivity — from automation to data processing to new types of AI models.\n\nThe hard part for investors is telling real breakthroughs apart from noise in a landscape still dominated by a few powerful platform companies, he added.\n\nPeter Thiel, the billionaire venture capitalist who cofounded PayPal, indicated recently that he's skeptical of the notion of an AI bubble.\n\n\"My macroeconomic placeholder is that it's going to keep going,\" Thiel said in a December interview with The Spectator, referring to the economic growth driven by the technology.\n\nThiel also said that he's been asked about an AI bubble frequently by people in Europe, which is \"how you know that they're not going to build a lot of AI in Europe.\"\n\n\"There is no other vector of growth in our society, we would be out of our minds not to take it,\" Thiel said. \"I don't think it's big enough to solve the budget deficit, but if the US embraces AI and Europe rejects it, I think the US is in somewhat better shape than Europe is.\"\n\nDespite his projections of future growth, Thiel also said that there are \"all sorts of things that I don't particularly like about the AI revolution,\" including that it's concentrated in a handful of large companies and that AI is \"probably more of a substitute than a complement\" to human labor.\n\n\"It will have a zero-sum feel to a lot of people,\" Thiel said.",
    "readingTime": 11,
    "keywords": [
      "sam altman",
      "jensen huang",
      "ceo sam",
      "google ceo",
      "business leaders",
      "sovereign wealth",
      "openai ceo",
      "voiced concerns",
      "wealth fund",
      "dot-com bubble"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bubble-debate-business-leaders-sam-altman-bill-gates-2025-11",
    "thumbnail_url": "https://i.insider.com/690510b8599d46a4ccc14592?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:33.284Z",
    "topic": "finance"
  },
  {
    "slug": "the-10-most-popular-hbr-articles-of-2025",
    "title": "The 10 Most Popular HBR Articles of 2025",
    "description": "The top 10 most-read articles from HBR in 2025 range in topics, with several covering AI and managing amid uncertainty. Others include visualizing strategy, cultivating joy, axing 1:1s, and overcoming the creeping effects of “workslop.”",
    "fullText": "The 10 Most Popular HBR Articles of 2025 by HBR EditorsDecember 24, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrint2025 was a year of uncertainty—be it about AI, tariffs, the economy, and so much more. In many ways, the most popular articles on HBR.org reflect this sentiment, with pieces about the challenges of decision-making, the future of DEI, and the unintended consequences of AI cracking the top 10.",
    "readingTime": 1,
    "keywords": [
      "popular",
      "articles"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/the-10-most-popular-hbr-articles-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_826093732.jpg",
    "created_at": "2025-12-24T18:17:32.450Z",
    "topic": "business"
  },
  {
    "slug": "ai-ceos-say-automation-with-ai-is-harder-than-it-looks",
    "title": "AI CEOs say automation with AI is harder than it looks",
    "description": "The CEOs of Databricks and Glean say AI can't automate work as easily as expected.",
    "fullText": "Two CEOs running multi-billion-dollar AI companies say AI can't automate work as easily as many leaders had assumed.\n\nGlean CEO Arvind Jain and Databricks CEO Ali Ghodsi said on an episode of the \"Bg2 Pod\" published Tuesday that companies need to temper expectations about how quickly and easily AI can be deployed.\n\nJain said he had tried to automate internal workflows at Glean, including an effort to use AI to automatically identify employees' top priorities for the week and document them for leadership.\n\n\"It has all the context inside the company to make it happen,\" said Jain, adding that he thought AI would \"magically\" do the work. The idea seemed simple, but it hasn't worked.\n\nGlean, an AI startup that helps employees search across internal tools and documents, said in September that it had raised $150 million at a $7.2 billion valuation.\n\nJain pointed to another bet that fell short: building and fine-tuning a custom model for a specific use case within Glean's product. That effort \"didn't really pan out,\" ultimately pushing the company back toward existing foundation models that were easier to deploy, he said.\n\n\"It actually takes much longer than you know to actually generate success,\" he added.\n\nGhodsi, whose company sells a data and AI platform, said: \"It's not just you can just unleash the agents, and it just works.\"\n\nMaking AI useful inside an organization is \"an engineering art,\" requiring careful evaluation, production work, and strong teams to support it, he added.\n\nDatabricks last week announced that it had raised more than $4 billion in a funding round, valuing the company at $134 billion.\n\nBoth CEOs said failed AI projects are common — and not necessarily a sign that something has gone wrong.\n\n\"You hear these 95% of projects fail,\" Jain said. \"That's actually what you want.\"\n\n\"When you're actually experimenting with new technology, if all of your projects are failing, that means you're not trying enough,\" he added.\n\nGhodsi has previously said that human oversight will remain essential in AI systems, even as companies deploy more agents and AI automate more tasks.\n\n\"I think in a few years, yes, we'll have agents in many, many places, but there will be a human overseeing and approving every step, and you're on the hook when you approve, when you click, 'OK,'\" he said in June at a conference in San Francisco. \"We all become supervisors.\"\n\nOther tech leaders have echoed that view.\n\nResearch scientist Yoshua Bengio, who is one of the \"godfathers of AI,\" said human qualities will become more important as machines take over tasks.\n\n\"Work on the beautiful human being that you can become. I think that that part of ourselves will persist even if machines can do most of the jobs,\" Bengio said on an episode of \"The Diary of a CEO\" podcast published last week.\n\n\"The human touch is going to, I think, take more and more value, as the other skills become more and more automated,\" he added.",
    "readingTime": 3,
    "keywords": [
      "jain",
      "human",
      "automate",
      "glean",
      "ghodsi",
      "agents",
      "projects",
      "you're",
      "easily",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ceo-databricks-glean-ai-automation-overestimate-ali-ghodsi-arvind-jain-2025-12",
    "thumbnail_url": "https://i.insider.com/694b8c2b64858d02d2175ac8?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.433Z",
    "topic": "finance"
  },
  {
    "slug": "were-cofounders-who-left-amazon-to-build-our-own-startup-we-learned-the-hard-way-why-big-tech-habits-dont-always",
    "title": "We're cofounders who left Amazon to build our own startup. We learned the hard way why Big Tech habits don't always translate.",
    "description": "Former Amazon employees detail their journey launching an AI startup, and explain how they adapted to startup life.",
    "fullText": "This as-told-to essay is based on conversations with Shalini Aggarwal, a 50-year-old CEO in San Jose, California, and Andy Ratsirason, a 37-year-old CTO. The two left Amazon at different times and reconnected as cofounders of Tenfali, an AI startup.\n\nThey share the main processes they had to unlearn in order to successfully grow their startup. The following has been edited for length and clarity.\n\nShalini Aggarwal: Andy and I began working together in 2015, after I relocated to the US from India. He was a dev engineer, and I worked on the product and program execution side.\n\nAndy Ratsirason: I joined Amazon for the first time in 2014 because I wanted to be part of the Silicon Valley ecosystem. I always wanted to be an entrepreneur, so I tried to tailor my career to suit that goal. I left Amazon, came back in 2020, and left again in 2023.\n\nAfter I left for the last time, I made multiple pivots in founding a startup. I realized I needed someone else to join my team. Shalini started showing up regularly on my LinkedIn feed, liking and commenting on posts about startups and taking risks, so I reached out to her. She had just left Amazon, and we reunited to cofound Tenafli.\n\nAggarwal: We quickly realized that we took a lot of systems and tools for granted when we were in an enterprise company. The startup world is completely different; here, we have to build from scratch, and there was a lot about our mindset we had to unlearn.\n\nAggarwal: I stayed at Amazon until 2024, and my last nine months were spent working on AI projects, specifically on music recommendations.\n\nRatsirason: In 2023, I was almost three years into my return to Amazon, and I had a choice: either stay comfortable with those Big Tech paychecks or take a leap and launch my own startup. I submitted my resignation in February and then began to think about what was next.\n\nAggarwal: My decision to leave Amazon was more of a gradual process. During the COVID pandemic, my father retired, and we lost my mom. I could see how lonely my father was, and the biggest challenge was how to fill his days. That planted the seed.\n\nThrough working on personalized AI recommendations, I thought of a product that could serve as an AI companion for older adults, providing personalized recommendations and scheduling activities based on their typical daily routines.\n\nMy 50th birthday was coming up, and the AI boom was happening; if I didn't take the leap then, I knew I would never. In September 2024, I put in my two weeks' notice and left Amazon.\n\nRatsirason: At Amazon, I didn't really think about why we were building a product or if people would use it. The 'build-first' mindset meant focusing solely on building a good product, knowing the customer was already there.\n\nA clear moment that this mindset wouldn't work at an early-stage startup came after we spent months building, and launch day arrived, almost nobody showed up organically for a few weeks. That was the wake-up call: shipping isn't the finish line when we didn't have demand.\n\nAfter that, we shifted to doing customer conversations earlier and running small distribution tests, including waitlists, partnerships, and community posts, before over-investing in product.\n\nAggarwal: We applied and were accepted into several startup resource programs, including AWS Activate, Nvidia Inception, and Google's Cloud Credits program.\n\nRatsirason: We received a few thousand in AWS credits, but before we realized it, we lost almost all of the credits in the first two months. We over-provisioned capacity, and during AI testing, we left a few resources running longer than intended, which quietly accumulated costs over time.\n\nOnce we noticed the issue, we set up AWS budget alerts, added cost monitoring, made shutdowns part of our testing checklist, and simplified certain aspects of the architecture to match our stage.\n\nTo reduce costs further, we also bought a small local machine to run some of our AI experiments on, so we only use the cloud when we truly need it for scale, managed services, or production.\n\nAggarwal: The time we save with AI enables us to allocate our energy to attending summits, forums, and programs, where we can learn about the work of others in the field. We also spend more time with prospective customers doing interviews.\n\nRatsirason: We used to spend hours reading long articles and research, and trying to keep up with the latest news in the field. The cycle felt heavy and slow, pulling us away from customer conversations and shipping.\n\nWe now use AI to scan a large set of content, surface the most relevant ideas for us, and summarize the few pieces worth reading. Having to be frugal, we've learned to spend only where learning happens. Talk to users first, then build the smallest thing that can prove value.\n\nRatsirason: AI acts as a junior engineer, handling a lot of the coding for us with the requirements we set up.\n\nAggarwal: It's also taught us where we won't need to scale. I know I don't need to hire a user interface designer. If I understand the requirements of something, I can quickly draft it with the help of AI and receive feedback on it myself.\n\nRatsirason: A few years ago, launching a usable version of our product, Agefully, would have required significantly more capital and head count. We just need two engineers and subscriptions. I'm grateful to be part of this AI era.\n\nAggarwal: We've seen at scale how things work and what processes we can implement to avoid chaos later on. At the same time, the biggest disadvantage has been overcoming the mindset that tools and infrastructure are readily available. Until we learned how to work through that, we weren't allocating our energy properly.\n\nRatsirason: Coming from Amazon, the name itself has some positive weight, but it can also work against us. People might assume that since we worked at a big company, we don't know how to run a small startup because we don't have a lot of resources.\n\nThe hardest part was overcoming the fear of shipping something imperfect. Coming from Big Tech, we were accustomed to high-polish expectations and assumed anything less would turn users away. We learned that in early-stage startups, the real risk isn't rough edges, it's building something people don't need.\n\nDo you have a founder story to share? Contact this reporter, Agnes Applegate, at aapplegate@businessinsider.com.",
    "readingTime": 6,
    "keywords": [
      "customer conversations",
      "big tech",
      "ratsirason we",
      "startup",
      "product",
      "mindset",
      "don't",
      "amazon",
      "realized",
      "recommendations"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/left-amazon-to-launch-startup-things-we-had-to-unlearn-2025-12",
    "thumbnail_url": "https://i.insider.com/694989c6832e0ef1ead6ac34?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.266Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-scaling-debate-what-the-industrys-top-minds-are-saying",
    "title": "The AI scaling debate: What the industry's top minds are saying",
    "description": "Geoffrey Hinton, the \"Godfather of AI,\" said he's \"not convinced\" the age of AI scaling is over, like his former student Ilya Sutskever recently said.",
    "fullText": "Not everyone in AI is ready to declare the end of the age of scaling.\n\n\"I'm not convinced it's completely over,\" Geoffrey Hinton, the \"Godfather of AI,\" recently told Business Insider, weighing in on one of the hottest debates in AI circles this year.\n\nHinton is aware that OpenAI cofounder Ilya Sutskever, one of his former students, said last month that the pendulum of AI development is swinging back toward research — and away from companies simply making breakthroughs by scaling, or acquiring more compute and more chips.\n\n\"Is the belief really: 'Oh, it's so big, but if you had 100x more, everything would be so different?' It would be different, for sure. But is the belief that if you just 100x the scale, everything would be transformed? I don't think that's true,\" Sutskever said on an episode of the \"Dwarkesh Podcast.\"\n\n\"So it's back to the age of research again, just with big computers,\" added Sutskever, who is now running his own AI startup.\n\nHinton said there will always be a need for more data. (Another issue facing scaling is the finite amount of high-quality data.) He predicted that the large chatbots will start generating their own data, as Google DeepMind's AlphaGo and AlphaZero do on a much smaller scale to master the board game Go.\n\n\"Nobody's worried about a lack of data because it plays against itself and generates data that way,\" Hinton said of the early program. \"And the equivalent for a language model is when it starts reasoning and saying, 'Look, I believe these things and these things imply that thing, but I don't believe that thing, so I'd better change something somewhere.' And by doing reasoning to check the consistency of his own beliefs, it can generate a lot more data.\"\n\nScaling is at the very core of Big Tech's capex spending spree, a bet based on the belief that by acquiring more compute or training data, AI models will continue to grow smarter and more advanced.\n\nIncreasingly, some AI leaders have expressed uncertainty about making their future bets based on their trust in scaling. Alexandr Wang, now head of Meta's superintelligence division, said in 2024 that scaling is \"the biggest question in the industry.\"\n\nYann LeCun, who worked with Hinton on pioneering AI research, has also challenged the extent of the scale doctrine.\n\n\"You cannot just assume that more data and more compute means smarter AI,\" LeCun said in April when he was still Meta's chief AI scientist. Like Sutskever, LeCun has since launched his own startup.\n\nSutskever said scaling has been attractive because it allows companies to make a \"very low-risk way\" bet on AI advancements.\n\nIn contrast, Google DeepMind CEO Demis Hassabis said that scaling laws could ultimately unlock the biggest and most elusive prize in AI: artificial general intelligence, or AGI.\n\n\"The scaling of the current systems, we must push that to the maximum, because at the minimum, it will be a key component of the final AGI system,\" Hassabis said at the Axios' AI+ Summit in December. \"It could be the entirety of the AGI system.\"",
    "readingTime": 3,
    "keywords": [
      "agi system",
      "scaling",
      "hinton",
      "it's",
      "research",
      "compute",
      "belief",
      "scale",
      "back",
      "acquiring"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-scaling-debate-geoffrey-hinton-ilya-sutskever-alexandr-wang-lecun-2025-12",
    "thumbnail_url": "https://i.insider.com/694a8f2264858d02d2174db6?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.260Z",
    "topic": "finance"
  },
  {
    "slug": "the-semantic-layer-is-dead-long-live-the-wiki",
    "title": "The semantic layer is dead. Long live the wiki",
    "description": "Most “AI on data” programs are just semantic-layer maximalism with a new paint\njob: if we can finally standardize meaning, the model will finally reason\naccurately.",
    "fullText": "Most “AI on data” programs are just semantic-layer maximalism with a new paint job: if we can finally standardize meaning, the model will finally reason accurately.\n\nIt won’t. A perfect semantic layer is neither sufficient nor operable. The bottleneck is organizational semantics at runtime, not SQL.\n\nSemantic layers are designed as a governed interface for humans to retrieve numbers, not to inhabit meaning. They capture the clean, declarative surface area of truth and omit the messy parts that determine whether an answer is correct.\n\nThe majority of what makes metrics usable is missing:\n\nMeaning is contextual, not global. The same metric name can legitimately refer to different implementations across product lines, geos, channels, or lifecycle stages. A semantic layer encourages flattening this into one “definition” under the guise of governance.\n\nDefinitions are political and time-bound. Ownership sits with the business, priorities shift quarterly, and what “counts” changes accordingly. Static interfaces pretend meaning is stable when it’s negotiated.\n\nOperational intelligence is non-declarative. “How do I interpret this?” is rarely answered by a formula. You need causal folk models, known anomaly patterns, failure modes, and the “if X then check Y” heuristics that live in experienced operators.\n\nTemporal continuity matters. Most metrics have version histories, instrumentation changes, backfills, silent breaks, and embarrassing periods everyone learned to discount. That context is mostly narrative, not schema.\n\nRelationships are about trade-offs, not joins. Real decision-making depends on tensions (optimize A, damage B), guardrails, and strategic intent. Semantic layers describe entities; they don’t encode the organization’s trade-off graph.\n\nStakeholder meaning diverges by role. “Revenue” for the CFO and “revenue” for the Sales VP are not the same question even when the number is the same. A single canonical definition is a UI convenience masquerading as epistemology.\n\n“Now what?” is the point. An AI that returns a metric without the response protocol is doing the easy half. Runbooks and escalation paths are part of meaning.\n\nA semantic layer can be perfect and still produce garbage decisions because it’s optimized for consistency over situated correctness.\n\nEven if you wanted to cram the missing knowledge into a semantic layer, the maintenance model collapses under its own sociology.\n\nCentralized semantic layers are planned cities: beautiful in the blueprint, empty in practice. Semantics evolve at the edges, among the people who ship, sell, operate, and get paged. The center cannot keep up, and it cannot compel truth.\n\nIn hindsight, failure modes are predictable:\n\nThe experts who can write it won’t. Deep metric knowledge is held by high-leverage operators; their marginal hour is never best spent authoring centralized documentation that mostly helps strangers.\n\nCentral teams are paced by infrastructure, not decisions. The business iterates weekly; the data platform iterates on quarters. Any interface maintained on platform cadence becomes stale, then distrusted, then ignored.\n\nTight coupling blocks shipping. If semantic context lives “in the data layer,” every AI feature becomes dependent on an always-incomplete canonicalization project. Data is never “done,” so AI velocity becomes permanently hostage.\n\nIncentives are inverted. Producers don’t benefit from documenting; consumers can’t document correctly; owners of context are neither staffed nor accountable for semantic hygiene in a centralized model.\n\nCold-start kills adoption. Semantic layers only feel useful after critical mass; reaching critical mass requires upfront drudgery with delayed payoff. Organizations don’t fail because they’re lazy; they fail because the payoff horizon is mispriced.\n\nSo you get shadow metrics, spreadsheet truth, ad hoc definitions, and a semantic layer that exists primarily as a compliance artifact.\n\nWe know what system reliably captures messy, contested knowledge at global scale without centrally curated ontologies - a wiki.\n\nWikipedia works because it’s a sociotechnical pattern that fits reality:\n\nYour organization’s meaning is closer to Wikipedia than to Encyclopedia Britannica. Treat it that way.\n\nStop trying to make the semantic layer the source of meaning. Make it a compiled artifact derived from a living knowledge substrate.\n\nBuild an internal wiki where operators and business analysts can capture what they already know. Then put the wiki in the loop with AI. The key point here is not documentation for the sake of documentation; it's feedback coupling.\n\nThis creates a virtuous cycle: usage drives coverage → coverage improves AI →  improved AI increases usage → and the knowledge base converges because it is continuously exercised under real demand.\n\nWe can still have governed models, dimensional abstractions, and metric layers. But they should be downstream, being generated or validated against the wiki, instead of being treated as the place meaning lives.\n\nThis inversion matters because it reframes the work from “build the perfect semantic layer” to “capture organizational meaning where it actually exists, then compile interfaces from it.”\n\nThe wiki becomes the organization’s brain: a living memory of intent, interpretation, exceptions, and procedures. AI becomes the octopus arms: executing queries, generating analyses, navigating ambiguity, and feeding new information back into the brain.\n\nIf your AI on data initiative isn't gaining adoption, it’s probably not because your semantic layer is imperfect. It’s because you’re trying to encode a living, political, temporal, role-dependent system of meaning into a centralized, static interface.",
    "readingTime": 5,
    "keywords": [
      "failure modes",
      "critical mass",
      "semantic layer",
      "semantic layers",
      "perfect semantic",
      "it’s",
      "knowledge",
      "wiki",
      "metric",
      "centralized"
    ],
    "qualityScore": 1,
    "link": "https://promptql.io/blog/semantic-layer-dead-long-live-wiki",
    "thumbnail_url": "https://hasura.io/blog/content/images/2025/12/semantic-layer-wiki-banner-1.png",
    "created_at": "2025-12-24T12:22:43.829Z",
    "topic": "tech"
  },
  {
    "slug": "googlebacked-fleet-tracking-firm-motive-files-publicly-for-ipo",
    "title": "Google-Backed Fleet Tracking Firm Motive Files Publicly for IPO",
    "description": "Motive Technologies Inc. filed publicly for an initial public offering, with the artificial intelligence-enabled fleet management software firm disclosing both growing revenue and net losses.",
    "fullText": "MarketsBy Matthew GriffinSaveMotive Technologies Inc. filed publicly for an initial public offering, with the artificial intelligence-enabled fleet management software firm disclosing both growing revenue and net losses. The company, which counts Alphabet Inc.’s Google Ventures and Kleiner Perkins among its backers, recorded a net loss of $138.5 million on revenue of $327.3 million in the nine months ended Sept. 30, according to a filing Tuesday with the US Securities and Exchange Commission. That compares with a net loss of $113.9 million on revenue of $268.9 million in the same period last year.",
    "readingTime": 1,
    "keywords": [
      "net loss",
      "revenue"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2025-12-23/google-backed-fleet-tracking-firm-motive-files-publicly-for-ipo",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iij4a.hcaf98/v1/1200x801.jpg",
    "created_at": "2025-12-24T06:19:45.771Z",
    "topic": "finance"
  },
  {
    "slug": "essential-education-chatgpt-prompts-for-best-studying-practices",
    "title": "Essential Education ChatGPT Prompts for Best Studying Practices",
    "description": "This guide contains 10 professionally-structured AI prompts to make studying more engaging and inter",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://tools.eq4c.com/ai-prompts/10-essential-education-chatgpt-prompts-for-best-studying-practices/",
    "thumbnail_url": "https://tools.eq4c.com/wp-content/uploads/2025/12/10-essential-education-chatgpt-prompts-for-best-studying-practices-1024x683.webp",
    "created_at": "2025-12-24T06:19:37.203Z",
    "topic": "science"
  },
  {
    "slug": "nvidia-debuts-nemotron-3-family-of-open-models",
    "title": "Nvidia Debuts Nemotron 3 Family of Open Models",
    "description": "The Nemotron 3 family of open models — in Nano, Super and Ultra sizes — introduces the most efficient family of open models with leading accuracy for building agentic AI applications.",
    "fullText": "NVIDIA today announced the NVIDIA Nemotron™ 3 family of open models, data and libraries designed to power transparent, efficient and specialized agentic AI development across industries.\n\nThe Nemotron 3 models — with Nano, Super and Ultra sizes — introduce a breakthrough hybrid latent mixture-of-experts (MoE) architecture that helps developers build and deploy reliable multi-agent systems at scale.\n\nAs organizations shift from single-model chatbots to collaborative multi-agent AI systems, developers face mounting challenges, including communication overhead, context drift and high inference costs. In addition, developers require transparency to trust the models that will automate their complex workflows. Nemotron 3 directly addresses these challenges, delivering the performance and openness customers need to build specialized, agentic AI.\n\n“Open innovation is the foundation of AI progress,” said Jensen Huang, founder and CEO of NVIDIA. “With Nemotron, we’re transforming advanced AI into an open platform that gives developers the transparency and efficiency they need to build agentic systems at scale.”\n\nNVIDIA Nemotron supports NVIDIA’s broader sovereign AI efforts, with organizations from Europe to South Korea adopting open, transparent and efficient models that allow them to build AI systems aligned to their own data, regulations and values.\n\nEarly adopters, including Accenture, Cadence, CrowdStrike, Cursor, Deloitte, EY, Oracle Cloud Infrastructure, Palantir, Perplexity, ServiceNow, Siemens, Synopsys and Zoom, are integrating models from the Nemotron family to power AI workflows across manufacturing, cybersecurity, software development, media, communications and other industries.\n\n“NVIDIA and ServiceNow have been shaping the future of AI for years, and the best is yet to come,” Bill McDermott, chairman and CEO of ServiceNow. “Today, we’re taking a major step forward in empowering leaders across all industries to fast-track their agentic AI strategy. ServiceNow’s intelligent workflow automation combined with NVIDIA Nemotron 3 will continue to define the standard with unmatched efficiency, speed and accuracy.”\n\nAs multi-agent AI systems expand, developers are increasingly relying on proprietary models for state-of-the-art reasoning while using more efficient and customizable open models to drive down costs. Routing tasks between frontier-level models and Nemotron in a single workflow gives agents the most intelligence while optimizing tokenomics.\n\n\"Perplexity is built on the idea that human curiosity will be amplified by accurate AI built into exceptional tools, like AI assistants,\" said Aravind Srinivas, CEO of Perplexity. “With our agent router, we can direct workloads to the best fine-tuned open models, like Nemotron 3 Ultra, or leverage leading proprietary models when tasks benefit from their unique capabilities — ensuring our AI assistants operate with exceptional speed, efficiency and scale.”\n\nThe open Nemotron 3 models enable startups to build and iterate faster on AI agents and accelerate innovation from prototype to enterprise deployment. General Catalyst, Mayfield and Sierra Ventures’ portfolio companies are exploring Nemotron 3 to build AI teammates that support human-AI collaboration.\n\n“NVIDIA’s open model stack and the NVIDIA Inception program give early-stage companies the models, tools and a cost-effective infrastructure to experiment, differentiate and scale fast,” said Navin Chaddha, managing partner at Mayfield. “Nemotron 3 gives founders a running start on building agentic AI applications and AI teammates, and helps them tap into NVIDIA’s massive installed base.”\n\nNemotron 3 Reinvents Multi-Agent AI With Efficiency and Accuracy \n\nThe Nemotron 3 family of MoE models includes three sizes:\n\nAvailable today, Nemotron 3 Nano is the most compute-cost-efficient model, optimized for tasks such as software debugging, content summarization, AI assistant workflows and information retrieval at low inference costs. The model uses a unique hybrid MoE architecture to deliver gains in efficiency and scalability.\n\nThis design achieves up to 4x higher token throughput compared with Nemotron 2 Nano and reduces reasoning-token generation by up to 60%, significantly lowering inference costs. With a 1-million-token context window, Nemotron 3 Nano remembers more, making it more accurate and better capable of connecting information over long, multistep tasks.\n\nArtificial Analysis, an independent organization that benchmarks AI, ranked the model as the most open and efficient among models of the same size, with leading accuracy.\n\nNemotron 3 Super excels at applications that require many collaborating agents to achieve complex tasks with low latency. Nemotron 3 Ultra serves as an advanced reasoning engine for AI workflows that demand deep research and strategic planning.\n\nNemotron 3 Super and Ultra use NVIDIA’s ultraefficient 4-bit NVFP4 training format on the NVIDIA Blackwell architecture, significantly cutting memory requirements and speeding up training. This efficiency allows larger models to be trained on existing infrastructure without compromising accuracy relative to higher-precision formats.\n\nWith the Nemotron 3 family of models, developers can choose the open model that is right-sized for their specific workloads, scaling from dozens to hundreds of agents while benefiting from faster, more accurate long-horizon reasoning for complex workflows.\n\nNew Open Tools and Data for AI Agent Customization\n\nNVIDIA also released a collection of training datasets and state-of-the-art reinforcement learning libraries available to anyone building specialized AI agents.\n\nThree trillion tokens of new Nemotron pretraining, post-training and reinforcement learning datasets supply the rich reasoning, coding and multistep workflow examples needed to create highly capable, domain-specialized agents. The Nemotron Agentic Safety Dataset provides real-world telemetry to help teams evaluate and strengthen the safety of complex agent systems.\n\nTo accelerate development, NVIDIA released the NeMo Gym and NeMo RL open-source libraries, which provide the training environments and post-training foundation for Nemotron models, along with NeMo Evaluator to validate model safety and performance. All tools and datasets are now available on GitHub and Hugging Face.\n\nNemotron 3 is supported by LM Studio, llama.cpp, SGLang and vLLM. In addition, Prime Intellect and Unsloth are integrating NeMo Gym’s ready-to-use training environments directly into their workflows, giving teams faster, easier access to powerful reinforcement learning training.\n\nGet Started With NVIDIA Open Models\n\nNemotron 3 Nano is available today on Hugging Face and through inference service providers including Baseten, DeepInfra, Fireworks, FriendliAI, OpenRouter and Together AI.\n\nNemotron is offered on enterprise AI and data infrastructure platforms, including Couchbase, DataRobot, H2O.ai, JFrog, Lambda and UiPath. For customers on public clouds, Nemotron 3 Nano will be available on AWS via Amazon Bedrock (serverless) as well as supported on Google Cloud, CoreWeave, Crusoe, Microsoft Foundry, Nebius, Nscale and Yotta soon.\n\nNemotron 3 Nano is available as an NVIDIA NIM™ microservice for secure, scalable deployment anywhere on NVIDIA-accelerated infrastructure for maximum privacy and control.\n\nNemotron 3 Super and Ultra are expected to be available in the first half of 2026.",
    "readingTime": 6,
    "keywords": [
      "moe architecture",
      "reinforcement learning",
      "nemotron family",
      "nemotron nano",
      "training environments",
      "specialized agentic",
      "complex workflows",
      "proprietary models",
      "nvidia nemotron",
      "nemotron ultra"
    ],
    "qualityScore": 1,
    "link": "https://nvidianews.nvidia.com/news/nvidia-debuts-nemotron-3-family-of-open-models",
    "thumbnail_url": "https://s3.amazonaws.com/cms.ipressroom.com/219/files/202512/693caf4b3d63322df1c3df36_nemotron-3-release/nemotron-3-release_9946879e-d8aa-4599-be16-2a2020d7fbc2-prv.jpg",
    "created_at": "2025-12-24T06:19:35.872Z",
    "topic": "tech"
  },
  {
    "slug": "modelyaml-is-an-open-standard-for-defining-crossplatform-composable-ai-models",
    "title": "Model.yaml is an open standard for defining cross-platform, composable AI models",
    "description": "An open description standard for defining cross-platform, multi format AI models.",
    "fullText": "AI models are often available in multiple formats and variants, while different machines support diverse engines such as llama.cpp and MLX. This diversity can make it challenging for end users to reason about the choices available to them.\n\nmodel.yaml addresses this by providing a standard description format that defines a model, along with multiple possible sources (potentially in different formats) of a model. It delegates the responsibility of determining the most suitable variant to download and the appropriate engine to use to the client program (e.g. LM Studio), while allowing showing simplified information to the user.\n\nModels in LM Studio's model catalog are all defined using model.yaml.\n\nThe model.yaml format defines a structured way to specify AI models, their concrete sources, configurations, and metadata. Feel free to contribute to this open standard as it evolves.\n\n You can find a TypeScript implementation of the specification in lmstudio-js.\n\nThe identifier for the model in the format organization/name. This determines where the model will be published and how it's referenced.\n\nDefines the underlying model(s) that this virtual model points to. Can be either:\n\nOverrides metadata for the model, which can differ from the base model. This helps platforms understand the model's capabilities.\n\nThe domain type of the model (e.g., llm, embedding).\n\nArray of model architecture names (e.g., llama, qwen2).\n\nArray of format types the model supports (e.g., gguf, safetensors).\n\nHuman-readable parameter size labels (e.g., 1B, 7B).\n\nMinimum RAM required to load the model in bytes.\n\nArray of supported context window sizes.\n\nWhether the model supports tool use (true, false, or mixed).\n\nWhether the model supports processing images (true, false, or mixed).\n\nBuilt-in configurations for the model, applying preset configurations for loading or runtime operation.\n\nUser-configurable options that affect the model's behavior. Each field can trigger effects like changing variables or modifying the system prompt.\n\nUnique identifier for the field.\n\nHuman-readable name shown in UI.",
    "readingTime": 2,
    "keywords": [
      "model supports",
      "format",
      "models",
      "model.yaml",
      "defines",
      "configurations",
      "array",
      "formats",
      "standard",
      "metadata"
    ],
    "qualityScore": 1,
    "link": "https://modelyaml.org",
    "thumbnail_url": "https://files.lmstudio.ai/modelyaml-card.jpg",
    "created_at": "2025-12-24T06:19:35.497Z",
    "topic": "tech"
  },
  {
    "slug": "mcptotal-run-mcp-servers-in-isolated-containers-instead-of-locally",
    "title": "MCPTotal – Run MCP servers in isolated containers instead of locally",
    "description": "MCP Made Easy and secure - Onboard AI tools in a click.",
    "fullText": "Run MCP servers securely in the cloud, with security teams governing access, enforcing policies, managing identities and monitoring every action.\n\nToday, developers often download and run untrusted MCP servers on their machines, wiring them directly to third-party accounts with plaintext API keys scattered across JSON files. Security teams have no real visibility or governance, they can't see which MCP servers are in use, what the agents are doing, what data is being passed, or how credentials are handled.\n\nAnyone can install an MCP server. They can be malicious, vulnerable or compromise the machine or leak data.\n\nCredentials are stored locally in textual files and env vars, copied between tools and impossible to manage and protect.\n\nSecurity teams lack visibility of MCP usage. There's no policy layer, no standardized approvals and no unified audit trail.\n\nPrompt injections and new MCP-specific attacks can exploit agents that interact with untrusted MCP servers, exfiltrating data or issuing unsafe actions.\n\nA practical security leader's guide to understanding and securing MCP implementations in your organization.\n\nMCPTotal provides a secure cloud runtime for MCP servers, a built-in MCP firewall, a centralized vault for credentials and a governance plane for your security team. Developers keep their workflows, while security gets the controls and visibility they need.\n\nManage, run and monitor your MCP servers in a secure, sandboxed environment.\n\nProtect AI workflows interacting with internal and external MCP servers.\n\nContinuously monitor and enforce policies for AI tool utilization.\n\nRun faster with MCP while MCPTotal takes care of the MCP security out of the box. Use your existing tools and agents — just change the endpoint URL.\n\nLaunch MCP servers in the cloud in seconds through an easy-to-use GUI. Say goodbye to hunting for and running untrusted servers on your local machine.\n\nAll your API keys, credentials, environment variables, and other sensitive data are securely stored and encrypted in our Vault, which is designed to be breach-resistant and accessible only to you.\n\nConnect MCPTotal-hosted servers to your agent (e.g. Cursor or any MCP-compatible tools). We support OAuth and other authentication schemes.\n\nEnjoy our built-in agentic chat to test things faster, it is smart and supports passing files from one server another.\n\nMCPTotal gives CISOs and security leaders the governance and controls they need to safely approve and scale MCP usage across the organization.\n\nRun a one-click discovery scan for all workstations and get an MCP posture management security report, see where MCP is being used, which clients and servers are in play and what problems should be remediated.\n\nAll MCP servers operate in isolated sandboxes, with their traffic and domains continuously monitored at runtime. MCPTotal scans each server's code to guarantee a secure and curated catalog.\n\nDefine which MCP servers and tools are allowed, configure which auth schemes can be used, set security thresholds for automatic MCP servers approvals and connect your SIEM to get audit events.\n\nGet the SLA, support and compliance certifications you require, as well as SSO/SCIM integration or a self-hosted solution.\n\nEverything you need to know about MCP security and our platform",
    "readingTime": 3,
    "keywords": [
      "api keys",
      "mcp usage",
      "mcp servers",
      "untrusted mcp",
      "security teams",
      "credentials",
      "tools",
      "cloud",
      "files",
      "visibility"
    ],
    "qualityScore": 1,
    "link": "https://go.mcptotal.io/",
    "thumbnail_url": "https://go.mcptotal.io/images/mcptotal-og.jpg",
    "created_at": "2025-12-24T06:19:33.982Z",
    "topic": "tech"
  },
  {
    "slug": "eze-ai-startup-roadmap-copilot-day-4-update",
    "title": "Eze – AI startup roadmap co‑pilot (Day 4 update)",
    "description": "Your AI startup mentor. Turn ideas into execution plans in minutes.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://eze.lovable.app/",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/87016dff-4507-485d-b64e-274e314de43a/id-preview-b85e1219--0d368741-f189-471d-ac9d-a80dafb600ed.lovable.app-1766452125567.png",
    "created_at": "2025-12-24T06:19:33.955Z",
    "topic": "tech"
  },
  {
    "slug": "apple-spent-2025-setting-itself-up-for-the-future-and-its-biggest-moves-werent-about-ai",
    "title": "Apple spent 2025 setting itself up for the future — and its biggest moves weren't about AI",
    "description": "Apple's 2025 helped set up its future.",
    "fullText": "It’s been quite a year for Apple (AAPL). The company reported record revenue on the back of strong iPhone sales. Its Services business continued its impressive growth, hitting $109.2 billion in sales. And its market capitalization topped $4 trillion, joining Nvidia (NVDA) as just the second company to reach the milestone.\n\nBut the company is also contending with major changes amid its executive ranks. CFO Jeff Williams retired — he was previously considered the top choice to take up the mantle of CEO after Tim Cook eventually steps down.\n\nHead of government affairs Lisa Jackson and general counsel Kate Adams are retiring in late January and late 2026, respectively.\n\nAnd then there's AI chief John Giannandrea and design vice president Alan Dye. Giannandrea is retiring and turning Apple's AI efforts over to Amar Subramanya, who previously worked on AI initiatives at Google (GOOGL, GOOG) and Microsoft (MSFT).\n\nDye, meanwhile, left Apple to lead Meta (META) Reality Labs' new design studio.\n\nAll of this comes as Cook is reportedly preparing senior vice president of hardware engineering John Ternus to take over as CEO when he departs.\n\nIt all adds up to an Apple in flux as it transforms itself for a post-Cook era. According to the Financial Times, Cook could step down as soon as early 2026. Bloomberg's Mark Gurman, meanwhile, said there’s still no firm timeline for when Cook will leave his post.\n\nRegardless of exact timing, Apple will eventually have to say goodbye to Cook, and 2025 helped the company set itself up for its biggest change in years.\n\nCook, who joined Apple in 1998, took over as CEO 14 years ago following the death of founder Steve Jobs. Jobs turned around an ailing Apple when he returned to the company in 1997 after being fired in 1985. He subsequently released a string of groundbreaking products, including the iPod and iPhone, which continues to bring in the majority of Apple's revenue.\n\nCook has carried that success forward during his time at the company's helm, overseeing the debut of the Apple Watch and AirPods, as well as the explosion of Apple's Services business. He has also pushed Apple to use its own chips in its products, giving the company more control over the design and functionality of its devices.\n\nThat, coupled with Cook's deft abilities as a negotiator, helped Apple weather a series of crises, including showdowns with the US Department of Justice, the COVID-19 pandemic, and President Trump's ongoing trade war with China. Trump eventually exempted smartphones and certain other tech products from his tariffs on Chinese goods.",
    "readingTime": 3,
    "keywords": [
      "services business",
      "vice president",
      "eventually",
      "design",
      "products",
      "apple",
      "cook",
      "revenue",
      "iphone",
      "sales"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/apple-spent-2025-setting-itself-up-for-the-future--and-its-biggest-moves-werent-about-ai-211525196.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/xwQLfyrEuvvS8dnq_Jgwhw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-01/4aae2830-dda3-11ef-9f5f-9631a8d45eb7",
    "created_at": "2025-12-24T06:19:30.225Z",
    "topic": "finance"
  },
  {
    "slug": "swiftzilla-rag-with-official-apple-docs-for-swift-agents-mcpcursorclaude",
    "title": "SwiftZilla – RAG with Official Apple Docs for Swift Agents (MCP/Cursor/Claude)",
    "description": "SwiftZilla is the ultimate RAG API for Apple Development. Give your AI agents instant access to official Swift docs, recipes, and evolution proposals.",
    "fullText": "The only RAG API built for Apple Development. Give your AI instant access to 100,000+ pages of\n official docs, recipes, and evolution proposals.\n\nGeneral purpose models like Claude, GPT, and Gemini struggle with the nuances of Swift 6.0,\n SwiftUI\n macros, and the latest concurrency patterns.\n\nGeneral purpose models miss the nuances. SwiftZilla is built for Apple development.\n\nWatch how it handles Apple Foundation Models in seconds.\n\nWe index the entire Apple Developer ecosystem so you don't have to.\n\nComplete indexing of Apple Developer Documentation and Swift API Design Guidelines.\n\nSearchable knowledge from the engineers who built the frameworks.\n\nSupports both SSE and STDIO transports. Works\n out-of-the-box with Cursor, Windsurf, Claude Desktop, or your custom agent.\n\nJoin developers building the next generation of AI tools.\n\nPerfect for testing and small projects.\n\nLess than a coffee for unlimited Swift mastery.\n\nYes! SwiftZilla provides a standard Model Context Protocol (MCP) server that you can add\n directly to Cursor, Windsurf, or any MCP-compatible editor.\n\nWe re-index our sources daily. When Apple releases a new beta or updates their docs,\n SwiftZilla knows about it within 24 hours.\n\nAbsolutely. You can manage your subscription directly from the dashboard and cancel with one\n click.",
    "readingTime": 1,
    "keywords": [
      "apple development",
      "purpose models",
      "docs",
      "nuances",
      "directly",
      "swift",
      "swiftzilla",
      "claude",
      "developer",
      "cursor"
    ],
    "qualityScore": 0.95,
    "link": "https://swiftzilla.dev",
    "thumbnail_url": "https://swiftzilla.dev/assets/voxel_swift.png",
    "created_at": "2025-12-24T00:56:10.126Z",
    "topic": "tech"
  },
  {
    "slug": "americans-have-mixed-views-of-ai-and-an-appetite-for-regulation",
    "title": "Americans Have Mixed Views of AI – and an Appetite for Regulation",
    "description": "A supermajority of Americans say that AI should be regulated to protect privacy and ensure safety.",
    "fullText": "AI is sweeping the American economy. A majority of Americans are either using AI tools or have tried them. But AI use is only half the story – a supermajority of Americans say that AI should be regulated to protect privacy and ensure safety. And many remain worried about potential job losses stemming from the emerging technology. \n\nIt’s time we did more to understand the national attitudes around AI use, regulation, and favorability.\n\nMost of our respondents had used AI at least once: 58% report using or trying AI, specifically tools like ChatGPT or Claude, divided evenly between fairly regular users (30% use at least a few times a month) and more infrequent users (29% have used AI, but only once a month or less). Nonusers are more likely to be older (62% of people over 65 have never used AI), not have gone to college (47%), or to work in service jobs (35%). Only 18% of white-collar workers say they have never used AI.\n\nAmong those who do use AI, 63% have at least tried it out for work purposes, and 34% report using it at work consistently (a few times a month or more). Work usage, like AI usage overall, is more common among white-collar workers, a majority of whom (55%) use it consistently. Personal use of AI is more common: 91% have at least tried using an AI chatbot or writing tool, and 54% report consistently using it in their personal lives. Gen Z turns to AI more often than its older counterparts, with 68% regularly engaging AI for personal use (compared to just 40% among Boomers).\n\nPersonal AI use encompasses a bunch of different types of application, but by far the most common is information gathering and answering questions (63%). Frequent AI users are especially likely to use AI as an alternative to traditional Google search or other research tools (68%). If this use case continues, messaging and communication on anything from public health to election campaigns will be filtered through AI models before reaching people. This could potentially change how messages are interpreted (particularly given the use of AI summaries), or significantly alter their reach in difficult-to-measure ways. Those interested in talking effectively to Americans should consider how their messaging strategy would work with these AI intermediaries, how their messages will be interpreted by AI, and if what they say will still reach their intended audience.\n\nWhile they know the names of the tools (ChatGPT, etc.), respondents don’t know much about the companies responsible for AI products. This is in contrast with older tech companies: Only 5% haven’t heard of Google, and 79% are favorable toward the company. For Amazon, favorability is at 80%. When asked about OpenAI, 42% hadn’t heard enough to form an opinion. For Anthropic, this figure hit 81%.\n\nAmericans don’t view AI as favorably as other emerging technologies from the past quarter century. Cell phones (76% total positive; net +68), the internet (75% total positive; net +66), and solar energy (72% total positive; net +65) are all viewed as having a very positive impact on society. AI (38% total positive; net +8) is \n\nWhen Americans are asked to think about potential future impacts on society, opinions of AI remain mixed, at a nearly even split of respondents between positive, negative, and uncertain impacts. Respondents believe that things like solar energy (70%), personalized medicine (57%), and nuclear energy (43%) will have positive future impacts, but are more skeptical of cryptocurrency (24% positive, 40% say it will have a negative impact) and self-driving cars (23% positive, 50% negative).\n\nWe also wanted to get a sense of how important Americans believe certain technologies to be. To provide some sense of perspective, we asked them to compare these new technologies to some they’re more familiar with. “Extremely important” corresponded to the steam engine and electricity, “moderately important” corresponded to the smartphone, and “not very” corresponded to the digital camera.\n\nWith these comparisons in mind, the median respondent puts AI on par with the invention of the smartphone. Only 7% believe that it’s more important than any other technology, with 16% of frequent AI users believing this, compared to just 5% of infrequent/nonusers.\n\nDespite uncertainty about AI’s overall importance, 70% of Americans say this technology will dramatically transform work, though they’re much less certain about the exact nature of this transformation. A plurality believes that it will make work easier (49%), but a majority believes that AI will bring down wages (55%), including pluralities or majorities across education, race, and partisanship. More respondents think it will hurt the economy (37%) than think it will decrease growth (29%), probably reflecting concern about wages. The perception that AI will replace human workers or outcompete them for jobs is a common one: 51% think AI will replace work done by humans, versus 33% who believe AI will supplement the work humans do. Service workers are especially convinced AI will replace (59%) rather than supplement (30%).\n\nA majority of Americans (56%) think that within 10 years, AI will be capable of performing most tasks that most people do at work. However, this drops significantly when respondents are asked about when AI will be able to do most tasks in their own job or field, with 43% thinking this will happen within 10 years, with no notable differences by educational attainment or work type. Customer service representatives are generally agreed to be replaceable within 10 years (64%), followed by accountants (56%) and manufacturing workers (54%). Fewer than 1 in 3 Americans think electricians, truck drivers, or doctors could be replaced by AI in the next 10 years.\n\nAround two-thirds of Americans (67%) are more concerned about the government doing too little to regulate the dangers of AI, versus doing too much and stifling progress (12%). At the same time, they don’t support a full ban on AI advancement, preferring progress to continue with requirements for safety testing (62%). Americans’ preference for safety regulations over the fastest possible progress holds even when they’re presented with the idea that regulating AI would put the U.S. behind China: Only 15% prefer a world where the U.S. government doesn’t regulate AI at all to compete with other countries like China over one where AI research continues under regulation, even if it develops slower than other countries (67%).\n\nEven in the most extreme case — presenting the choice between no further progress in AI at all and totally unregulated AI — only 34% would support unregulated AI development, versus 30% who think the government should ban research to improve AI, with a 36% plurality saying they’re unsure.\n\nIn terms of perceived dangers from AI, Americans’ biggest concern is AI taking jobs and causing unemployment (42%), followed by concerns about privacy (35%) and misinformation (33%). These are also the top three areas Americans prioritize for regulation. Respondents are not especially concerned about AI wiping out humanity (12%), but express greater concern about the use of AI resulting in loss of human control (32%).\n\nWhile respondents see AI as better than humans at being “efficient” by a wide margin (+44 points), AI has virtually no advantage on “being convenient to those they’re trying to help” (+2). Humans are still seen as wildly better in terms of being moral (+53), making complex decisions (+30), protecting privacy (+28), and being transparent (+18).\n\nWe also asked about the potential for replacing humans in specific governmental tasks, since this has been talked up by some AI proponents. There are only two specific tasks (from our list tested in this survey, at least) where AI is seen as better than human government employees. One is identifying trends in data (+18) and the other is correctly verifying the information in forms (+8).\n\nOn anything less concrete and data-focused, respondents strongly prefer humans. Human government employees are preferred over AI by 77 points for judging criminal trials, by 59 points for conducting airport screenings, and by 55 points for answering questions about government services like Social Security. Public interest in AI replacement of humans in government and other tasks is minimal.\n\nThis survey was run by Tavern Research via an online sample of 2,301 American adults fielded over web panels from August 1, 2025 to August 6, 2025. The margin of error is +/- 3%.\n\nNOTE: Because this is a web-based survey, we expect the total usage of AI to be slightly higher than the numbers found in non-web-based surveys. This should not affect the other conclusions.\n\nA question that was interesting, but didn’t lead to a larger conclusion, was asking what actually happens when you ask a tool like ChatGPT a question. 45% think it looks up an exact answer in a database, and 21% think it follows a script of prewritten responses.",
    "readingTime": 8,
    "keywords": [
      "solar energy",
      "white-collar workers",
      "americans say",
      "positive net",
      "positive negative",
      "respondents",
      "humans",
      "they’re",
      "tasks",
      "majority"
    ],
    "qualityScore": 1,
    "link": "https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/",
    "thumbnail_url": "https://www.searchlightinstitute.org/wp-content/uploads/2025/12/Americans-have-mixed-views-of-AI-–-and-an-appetite-for-regulation-1.jpg",
    "created_at": "2025-12-24T00:56:09.939Z",
    "topic": "science"
  },
  {
    "slug": "hoping-ai-will-give-you-more-worklife-balance-in-2026-fortune-500-ceos-warn-otherwise",
    "title": "Hoping AI will give you more work-life balance in 2026? Fortune 500 CEOs warn otherwise",
    "description": "Despite Gen Z increasingly demanding work-life balance, many Fortune 500 bosses doubled down on overtime in 2025 to compete in the AI race.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2025/12/23/work-life-balance-recap-2025-fortune-500-ceos-productivity-grind-secrets-for-success/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2249127380_87bb13-e1765992018418.jpg?resize=1200,600",
    "created_at": "2025-12-24T00:56:07.124Z",
    "topic": "business"
  },
  {
    "slug": "work-is-changing-everywhere-as-ai-moves-from-experiment-to-expectation",
    "title": "Work is changing everywhere as AI moves from experiment to expectation",
    "description": "AI transformation, workforce strategy, and new job roles are reshaping how companies like ServiceNow and Weber Shandwick operate today.",
    "fullText": "This article is part of the \"How AI is Changing Talent\" series, which explores how AI is reshaping hiring, development, and retention.\n\nTwelve months ago, Jacqui Canney was ServiceNow's chief people officer, focused on talent strategy. Today, she's also the company's chief AI enablement officer — a title that didn't exist until recently.\n\nThe two roles aren't separate, Canney told Business Insider. \"They're one strategy, and the companies that understand that are going to be the winners.\"\n\nThat shift, though, requires letting go of how most organizations have always structured work: by function, head count, and department. \"Companies can't treat this as 'We're going to run an AI program over here, and it'll add capacity,'\" she says.\n\nInstead, they need to ask: how does AI change the work across departments? \"AI doesn't follow the same silos people do. That's why you build the workforce around the new workflow.\"\n\nCanney's approach isn't an outlier. Rather, it's a signal of how quickly AI has become part of work and our daily lives.\n\nThree years after the launch of ChatGPT, adoption has reached 54.6%. That's staggering compared to adoption rates for personal computers (19.7%) and the internet (30.1%) three years after they were widely introduced, according to research by the Federal Reserve Bank of St. Louis.\n\nMeanwhile, about 21% of US workers say that at least some of their job is now done with AI, an increase from 16% roughly a year ago, according to Pew Research Center.\n\nAI is transforming everything about work, from the jobs people do to how they do them. Organizations, meanwhile, are racing to prepare their people for what comes next. While the long-term impact remains uncertain, early patterns are emerging about what's working and what isn't.\n\nAI's effect on the labor market is showing up everywhere: in how companies screen candidates, which skills command premium salaries, and how performance gets evaluated. Two structural shifts, in particular, stand out: new jobs are emerging, and old jobs are evolving.\n\nAn authoritative count of new AI-specific job titles is hard to come by, but data show rapid growth. A report from software company Autodesk found that demand for roles like AI engineer jumped 143.2% in 2024, while prompt engineer rose 135.8%, and AI content creator increased 134.5%. Meanwhile, the number of jobs requiring AI skills rose 7.5% last year, even as total job postings fell 11.3%, according to research from consultancy PwC.\n\nMolly Roenna, global chief people officer at PR firm Weber Shandwick, sees this firsthand. Her company is increasingly seeking specialists in areas like AI integration and AI ethics, and it's recruiting from disciplines like behavioral science and data analytics.\n\n\"We're hiring for a fundamentally different environment,\" Roenna says. \"Meeting client expectations requires people who use technology as a force multiplier for insight and creativity, not just a shortcut for efficiency.\"\n\nThe hiring process itself has evolved, too. Many of Weber Shandwick's interviews now include a \"technology conversation,\" a practice that appears to be gaining traction. This isn't to test technical skills, but to gauge how candidates use AI.\n\n\"What have they built with AI? What excites or worries them about it? We want perspective that comes from actual practice.\"\n\nThe dynamic playing out at Weber Shandwick and elsewhere isn't new. After all, every major technological advancement has created roles that were previously unimaginable, made others obsolete, and forced still others to adapt. What's different about this AI-driven era, however, is both the speed of change (see above) and the breadth, affecting workers across industries and skill levels.\n\n\"We didn't have programmers before computers,\" says Esteve Almirall Mezquita, professor of data, analytics, technology and AI at Esade in Madrid.\n\nCreating new roles and demand for expertise is half the equation. The bigger challenge is helping existing workers figure out how to use AI.\n\nSome companies aren't leaving that to chance. They're requiring it, notes Dan Schawbel, managing partner at Workplace Intelligence, a research firm. \"CEOs are under enormous pressure to have their AI story intact,\" he says. \"We have to have our workers using AI. It's good for productivity, yes, but also our story and bottom line.\"\n\nCompanies such as Microsoft, Coinbase, and Shopify now mandate AI use, according to previous reporting by Business Insider. Meta plans to measure employees' performance by their \"AI-driven impact.\"\n\nSchawbel predicts more scrutiny in the year ahead. Employees will need to function like data scientists, continuously proving their value, he says. \"Whether you're in marketing, IT, or HR, every action can be measured and tracked — and maybe even tied directly to your compensation.\"\n\nMeasuring AI use and seeing value from it are two different things, however. Even as organizations pour billions into the technology, results have been uneven.\n\nResearch by consulting firm BCG of more than 1,250 firms worldwide reports that 60% of companies are investing heavily in AI but seeing minimal returns. Meanwhile, only 5% have taken the step to restructure their operations around AI — and those companies are seeing significant revenue gains over everyone else.\n\nThe difference, the BCG research suggests, comes down to several factors. Successful companies have buy-in from the top and have redesigned how work gets done. Most importantly, says Alicia Pittman, BCG's global people chair, they've invested in teaching employees to use AI effectively.\n\nPittman notes that industries like financial services, insurance, and healthcare are pulling ahead in AI adoption. \"We're seeing companies put real time and energy into this in a way that hasn't been present before, and that's good for everybody and good for the global workforce.\"\n\nGranted, there's job displacement that comes with that and some skill sets will go away, she says. \"But helping people adapt to AI is a major investment in them as professionals.\"\n\nAt Moody's, the credit ratings firm, that investment involves encouraging employees to teach AI as much as possible.\n\nAri Lehavi, who runs applied AI there, says this approach frees employees to focus on complex work that requires human expertise.\n\nTake sales, for example. Customer relationship management (CRM) systems can capture basics like company size, contract history, and revenue potential. However, they miss what closes deals: company politics, individual motivations, and who really influences decisions. Lehavi's team teaches AI systems to learn those details so salespeople can concentrate on managing relationships.\n\n\"They can spend their time on things they're already doing but don't have enough time for,\" he says. \"The hard cases, the edge cases, the complex situations, mentoring other people, management, and skill development.\"\n\nIn other words: the human stuff.\n\nOf course, the path forward isn't simple or straightforward. Not every company has the resources to retrain its workforce, and some jobs will indeed disappear. Many companies are struggling to make AI work.\n\nYet, Canney of ServiceNow remains positive. \"It's a human renaissance,\" she says. \"You're going to have capacity in your workforce and the chance to guide it toward new revenue streams or creative ways of working. It's an enormous opportunity, and I'm definitely an optimist about it.\"",
    "readingTime": 6,
    "keywords": [
      "business insider",
      "weber shandwick",
      "ai what",
      "isn't",
      "jobs",
      "employees",
      "roles",
      "workforce",
      "workers",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-transforming-workplace-faster-than-internet-2025-12",
    "thumbnail_url": "https://i.insider.com/694ae36a832e0ef1ead6bfbe?width=1200&format=jpeg",
    "created_at": "2025-12-24T00:56:06.612Z",
    "topic": "finance"
  },
  {
    "slug": "google-2025-recap-research-breakthroughs-of-the-year",
    "title": "Google 2025 recap: Research breakthroughs of the year",
    "description": "This year saw new AI models, transformative products and new breakthroughs in science and robotics.",
    "fullText": "This was a year of AI agents, reasoning and scientific discovery.\n\n2025 has been a year of extraordinary progress in research. With artificial intelligence, we can see its trajectory shifting from a tool to a utility: from something people use to something they can put to work. If 2024 was about laying the multimodal foundations for this era, 2025 was the year AI began to really think, act and explore the world alongside us. With quantum computing, we made progress towards real-world applications. And across the board, we helped turn research into reality, with more capable and useful products and tools making a positive impact on people's lives today.\n\nHere’s a look back at some of the breakthroughs, products and scientific milestones that defined the work of Google, Google DeepMind and Google Research in a year of relentless progress.\n\nThis year, we significantly advanced our model capabilities with breakthroughs on reasoning, multimodal understanding, model efficiency, and generative capabilities, beginning with the release of Gemini 2.5 in March and culminating in the November launch of Gemini 3 and the December launch of Gemini 3 Flash.\n\nBuilt on a foundation of state-of-the-art reasoning, Gemini 3 Pro is our most powerful model to date, designed to help you bring any idea to life. It topped the LMArena Leaderboard and redefined multimodal reasoning with breakthrough scores on benchmarks like Humanity’s Last Exam — a fiendishly hard test for AI models to see if AI can truly think and reason like humans — and GPQA Diamond. It also set a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex. We followed shortly with Gemini 3 Flash, which combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost, making it the most performant model for its size. Gemini 3 Flash's quality surpasses our previous Gemini 2.5 Pro-scale model's capabilities at a fraction of the price and substantially better latency, continuing our Gemini-era trend of 'the next generation's Flash model is better than the previous generation's Pro model'.\n\nLearn more about our progress on our world-class AI models this year:\n\nGemini 3 Flash price & benchmark table.\n\nWe’re committed to making useful AI technology accessible, with state-of-the-art open models. We built our Gemma family of models to be lightweight and open for public use; this year we were able to introduce multimodal capabilities, significantly increase the context window, expand multilingual capabilities, and improve efficiency and performance.\n\nLearn more about this year’s advances in Gemma models:\n\nThroughout 2025, we continued to advance the trajectory of AI from tool to utility, transforming our portfolio of products with new, powerful agentic capabilities. We reimagined software development by moving beyond tools that assist coding to introducing powerful, agentic systems that collaborate with developers. Key advances, such as the impressive coding capabilities in Gemini 3 and the launch of Google Antigravity, mark a new era in AI-assisted software development.\n\nLearn more about this year’s advances building developer tools:\n\nThis evolution was also clear across our core products, from AI-enabled features on the Pixel 10 and updates to AI Mode in Search, to AI-first innovations like the Gemini app and NotebookLM, which gained advanced features like Deep Research.\n\nLearn more about how we’ve transformed our products with AI:\n\n2025 was a transformative year for generative media, giving people new and unprecedented capabilities to realize their creative ambitions. Generative media models and tools for video, images, audio and worlds became more effective and broadly used, with breakouts Nano Banana and Nano Banana Pro offering unprecedented capabilities for native image generation and editing. We worked with people in creative industries to develop tools like Flow and Music AI Sandbox, making them more helpful for creative workflows, and we expanded creative possibilities for people with new, AI-powered experiences in the Google Arts & Culture lab, major upgrades to image editing within the Gemini app, and the introduction of powerful new generative media models like Veo 3.1, Imagen 4 and Flow.\n\nLearn more about how we’re building AI to enhance creativity:\n\nAs research breakthroughs continue to expand AI’s capabilities, Google Labs is where we share AI experiments as we develop them – hearing from users and evolving as we learn. Some of this year’s most engaging experiments from Labs: Pomelli, an AI experiment for on-brand marketing content; Stitch, which introduced a way to turn prompt and image inputs into complex UI designs and frontend code in minutes; Jules, an asynchronous coding agent that acts as a collaborative partner for developers; and Google Beam, a 3D video communications platform that used AI to advance the possibilities of remote presence.\n\nLearn more about how we’re experimenting in Labs:\n\n2025 was also a banner year for scientific advances with AI, marked by breakthroughs in life sciences, health, natural sciences, and mathematics.\n\nIn the space of a year, we made progress in building AI resources and tools that empower researchers and help them understand, identify, and develop treatments in healthcare. In genomics, where we’ve been applying advanced technology to research for 10 years, we moved beyond sequencing, using AI to interpret the most complex data. We also marked the 5-year anniversary of AlphaFold, the Nobel-winning AI system that solved the 50-year-old protein folding problem. AlphaFold has been used by over 3 million researchers in more than 190 countries, including over 1 million users in low- and middle-income countries.\n\nLearn more about how we’re using AI to advance life sciences and health:\n\nGemini’s advanced thinking capabilities, including Deep Think, also enabled historic progress in mathematics and coding. Deep Think was able to solve problems that require deep abstract reasoning – achieving gold medal-standard in two international contests.\n\nLearn more about how we’re advancing natural sciences and mathematics:\n\nWe’re also leading major discoveries and shaping the future of science in areas like quantum computing, energy and moonshots. Research in this area drew new levels of public attention, with progress towards real-world applications of quantum computing as demonstrated by Quantum Echoes and, notably, Googler Michel Devoret becoming a 2025 Physics Nobel Laureate along with former Googler John Martinis and UC Berkeley’s John Clarke, for their foundational 1980s quantum research.\n\nLearn more about our work on space infrastructure and quantum computing:\n\nIn 2025, we continued to advance the core infrastructure that powers our AI, focusing on breakthroughs in hardware design and improving energy efficiency. This included the introduction of Ironwood, a new TPU built for the age of inference, which was designed using a method called AlphaChip, alongside a commitment to measuring the environmental impact of our technology.\n\nLearn more about how we’re using AI to develop chips, infrastructure and improve energy efficiency:\n\nOur work in robotics and visual understanding brought AI agents into both the physical and virtual worlds, with advancements like the foundational Gemini Robotics models, the more sophisticated Gemini Robotics 1.5, and the introduction of Genie 3 as a new frontier for general-purpose world models.\n\nLearn more about our work with world models and robotics:\n\nOur work throughout 2025 demonstrates how AI-enabled scientific progress is being directly applied to address the world's most critical and pervasive challenges. By leveraging state-of-the-art foundational models and agentic reasoning, we are significantly increasing our understanding of the planet and its systems, while also delivering impactful solutions in areas vital to human flourishing, including climate resilience, public health and education.\n\nFor example, we are using state-of-the-art foundational models and agentic reasoning to help increase our understanding of the planet, helping enable work that is making a difference in people’s lives now from weather predictions to urban planning to public health. For example, our flood forecasting information now covers more than two billion people in 150 countries for severe riverine floods. And our most advanced and efficient forecasting model, WeatherNext 2 can generate forecasts 8x faster and with resolution up to 1-hour. Using this technology, we’ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.\n\nLearn more about our work in weather, mapping and wildfires:\n\nWe are working with partners to apply AI-enabled scientific progress closer to patients, opening up new avenues for disease management and therapeutic discovery.\n\nLearn more about our health-related work:\n\nAI is proving to be a powerful tool in education, enabling new forms of understanding and expanding curiosity through initiatives like LearnLM and Guided Learning in Gemini. We brought Gemini’s most powerful translation capabilities to Google Translate, enabling much smarter, more natural and accurate translations and piloting new speech to speech translation capabilities.\n\nLearn more about how we’re using AI to enable learning:\n\nWe couple our research breakthroughs with rigorous and forward-looking work on responsibility and safety. As our models grow more capable, we’re continuing to advance and evolve our tools, resources and safety frameworks to anticipate and mitigate risk. Gemini 3 demonstrated this approach in action: it's our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. And we’re looking further ahead, exploring a responsible path to AGI, prioritizing readiness, proactive risk assessment, and collaboration with the wider AI community.\n\nLearn more about our responsibility and safety work:\n\nAdvancing the frontier of AI responsibly demands collaboration across all parts of society. In 2025, we worked with leading AI labs to help to form the Agentic AI Foundation and support open standards to ensure a responsible and interoperable future for agentic AI. In education, we’ve partnered with school districts like Miami Dade County and education groups like Raspberry Pi to equip students with AI skills. Our research partnerships with universities like UC Berkeley, Yale, the University of Chicago and many more have been instrumental to some of this year’s most exciting frontier research, and we’re working with the US Department of Energy’s 17 national laboratories to transform how scientific research is conducted. And we’re working with filmmakers and other creative visionaries to put the best AI tools in their hands and explore storytelling in the age of AI.\n\nLearn more about our work on frontier collaboration:\n\nAs we look towards 2026, we’re looking forward to continuing to advance the frontier, safely and responsibly, for the benefit of humanity.",
    "readingTime": 9,
    "keywords": [
      "nano banana",
      "ai-enabled scientific",
      "gemini app",
      "real-world applications",
      "software development",
      "towards real-world",
      "generative media",
      "quantum computing",
      "life sciences",
      "natural sciences"
    ],
    "qualityScore": 1,
    "link": "https://blog.google/technology/ai/2025-research-breakthroughs/",
    "thumbnail_url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_keyword_social_share_light_1.width-1300.png",
    "created_at": "2025-12-24T00:56:05.364Z",
    "topic": "tech"
  },
  {
    "slug": "i-hired-ai-to-fix-my-memory-but-made-it-100-offline-for-privacy",
    "title": "I hired AI to fix my memory, but made it 100% Offline for privacy",
    "description": "Scientific memory support with the Forgetting Curve. Privacy-first, local-only app.",
    "fullText": "A Message from the Developer\n\n \"System Engineer since 1999 (Enterprise Systems).\n\n I created this app to solve my own forgetfulness, applying 25 years of experience in data reliability and security.\"\n\n Developed by an enterprise system engineer active since 1999 to solve his own \"memory struggles\".\n\n Built with the same commitment to quality and data security found in mission-critical systems.",
    "readingTime": 1,
    "keywords": [
      "system engineer",
      "solve",
      "security",
      "enterprise",
      "systems"
    ],
    "qualityScore": 0.4,
    "link": "https://namememory.netlify.app/",
    "thumbnail_url": "https://www.namememory.app/ogp_image.png",
    "created_at": "2025-12-24T00:56:05.339Z",
    "topic": "tech"
  },
  {
    "slug": "best-new-games-without-ai",
    "title": "Best New Games Without AI",
    "description": "The use of Generative AI (or GenAI for short) is on the rise, with many examples in some of the biggest games of the year using art, voice recordings, and narratives, just to name a few, now coming to light. For many players, a studio’s use of AI as a shortcut, instead of commissioning an artist, hiring a voice actor, or paying a writer to create assets for the final product, is something they actively don’t want to buy.\nSo this curated list that’s human-approved with only a spellchecker to assist in its creation will highlight the best games in 2025 where AI is, as far as we know, not involved in the development process. They all come from a whole bunch of developers, big and small, spanning a wide range of genres. The one thing they have in common is that a dedicated team of people worked on it without any assistance from GenAI tools.",
    "fullText": "on December 23, 2025 at 12:45PM PST\n\nGameSpot may receive revenue from affiliate and advertising partnerships for sharing this content and from purchases through links.\n\nThe use of Generative AI (or GenAI for short) is on the rise, with many examples in some of the biggest games of the year using art, voice recordings, and narratives, just to name a few, now coming to light. For many players, a studio’s use of AI as a shortcut, instead of commissioning an artist, hiring a voice actor, or paying a writer to create assets for the final product, is something they actively don’t want to buy.\n\nSo this curated list that’s human-approved with only a spellchecker to assist in its creation will highlight the best games in 2025 where AI is, as far as we know, not involved in the development process. They all come from a whole bunch of developers, big and small, spanning a wide range of genres. The one thing they have in common is that a dedicated team of people worked on it without any assistance from GenAI tools.\n\nIt’s important to clarify that any procedural generation of maps, or randomized abilities or enemies, uses AI to determine what appears, and is not the same as GenAI. We’re specifically excluding games that use AI to generate any assets, whether it’s disclosed at the point of sale or found out after publishing. If it’s ethically problematic for any of these reasons, a game won’t be included on the list, no matter how much of a Game of the Year contender it is. With that, here are the best games without AI involvement in their development.\n\nHades 2 is the long-awaited sequel to Supergiant Games’ Game of the Year, which puts you in the shoes of the immortal Princess Melinoë as she attempts to save her father Hades and his kingdom from the time-looping clutches of the Titan Cronos. It largely follows a similar Roguelike structure, where each run has you collect powers from the Ancient Greek Pantheon to augment your chosen weapon and crush the foes in your way.\n\nOf course, with every sequel, you need to outdo what came before. Naturally, this means having two separate paths from the beginning, each with its own layout. One leads to the depths of Hades to Cronos, while the other has Melinoë ascend to the peak of Mt Olympus to defeat the invading monsters. Fans of the first will likely already have this one, but you don’t need to have mastered the original to enjoy everything that Hades 2 has to offer.\n\nReleased episodically, Dispatch is a wonderful throwback from the team behind The Walking Dead and The Wolf Among Us. Throughout its first season, you are a former superhero, Mechaman, who becomes a dispatcher for a new generation of heroes. However, he ends up managing a team of miscreants who are easily sidetracked by a little bit of arson or petty theft. It’s up to you to keep everything on track, even when things go south.\n\nWhether it’s allocating the right person for a particular job or making sure another hero doesn’t get sidetracked, each chapter has significant decisions that drastically change the outcome of a mission. By reading each hero's bio and upgrading their skills, you’ll increase your chances of success. You’ll also occasionally need to hack into systems remotely to assist your heroes when they’re in peril.\n\nDispatch’s stunning cast, which includes professional voice actors and some YouTubers branching out and doing a decent job in bringing these larger-than-life characters to life. By the time you reach the end, only one question will likely be on your mind: when’s season 2?\n\nFor fans of retro beat-'em-ups such as Streets of Rage or Final Fight, it’s been quite a while since a brand-new series broke ground. Absolum carefully blends in Roguelike game mechanics to make what Steve Watts, in his review, described as “a match made in heaven”. You play as one of a band of rebel wizards led by Root Mother Uchawi, a benevolent god-like being, who attempts to take on the tyrant Sun King Azra and his Crimson Order army, who have taken over the world of Talamh.\n\nWith multiple characters to play with their own fighting style, a phenomenal soundtrack, stunning visuals, and a Hades-like elemental progression system for every run, it’s easy to see how this is a winning formula. On top of that, there are plenty of branching paths and hidden secrets to find along the way. Quests ask you to venture to specific points, but don’t always require that you reach them in the same run.\n\nSome may feel that the Roguelike structure holds it back because it doesn’t lean into it enough, but it instead asks for the player to master its mechanics by giving them familiar challenges, and as such, may be somewhat fairer to their time. If you’re not convinced, there’s a free Absolum demo you can check out that gives you a small slice of just how wonderfully everything comes together, and like the full-price experience, you can bring a friend with you in your quest to save the realm.\n\nFanatical and GameSpot are both owned by Fandom.\n\nSolving the mystery behind a weird house with constantly shifting layouts that you inherited was not exactly on our bingo card for 2025, but Blue Prince is one of the best puzzle games we’ve played in years. Each day, you have a set number of steps to explore a house with randomized rooms. These rooms can give or take away steps, grant you items, or even house escape room-like puzzles that reward you with more trinkets.\n\nOn top of this, Blue Prince has a rather intricate mystery throughout. Clues hidden in certain rooms will allude to the house itself, including what’s in room 46, the former owner Herbert S. Sinclair, and a children's author called Marion Marigold. It might take you only a few attempts, or it may take you many. If you find you’re struggling to make a dent, you should check out our Blue Prince guides hub for some tips. Persevere, and you’ll find out why it’s worth continuing until you find that fated room.\n\nNintendo’s big ape smashes his way onto the Switch 2 with Donkey Kong Bananza, from the creators of Super Mario Odyssey. Our gorilla hero travels to Ingot Isle to mine Banadium Gems, only to have his hoard stolen by a sinister simian syndicate known as VoidCo. Buried deep underground, DK soon finds an odd sentient rock that later turns out to be a younger version of Pauline. The two team up to excavate through each layer of this underground world to stop VoidCo.’s president from reaching the planet’s core.\n\nThe big selling point of Donkey Kong Bananza is that DK can dig his way through levels with his bare hands, uncovering secrets while using rocks and soil to bash his way to the end. Pauline’s singing also helps unlock transformations that enable DK to fly or charge at high speed, amongst others. Much like 3D Mario games and their equivalent macguffins, you’ll also gather crystal bananas for completing objectives. However, these bananas also tie in with the upgrade system that unlocks more powers for the duo.\n\nWhat sets it apart is that, despite being vastly different from every other Donkey Kong game, it manages to pay homage to the series. Cameos from DK’s animal friends, musical homages, and so much more. It’s one of the few essential games to own for the Nintendo Switch 2 in its first year on the market. In case you’re wondering, you can safely skip the DLC: DK Island and Emerald Rush unless it’s put on sale, or you really enjoy Roguelike modes.\n\nFinal Fantasy Tactics: The Ivalice Chronicles is a remaster made with love, care, and passion. Since the source code was lost, as was sadly the norm back in the 1990s, the effort made to bring the entire campaign to currently available platforms is staggering. It does have the newer translation, added voice acting, and support for higher resolutions than its PlayStation, PSP, or mobile iterations, and all of that is created or performed by talented people. And yet, despite the modern additions, it’s still the same punishing, yet charming, and above all, epic classic RPG from Square Enix’s golden age.\n\nIt would have been so easy just to churn out a ‘modern reskin’ of the classic permadeath game, or mangle its existing assets with generative AI upscaling tools. However, the team behind Final Fantasy Tactics: The Ivalice Chronicles evidently cared, wanting to retell the War of the Lions saga that captivated many with its twists and turns. Rebalancing encounters and adding the ability to skip non-story fights help ease newer players in, allowing them to experience some of what makes this tactical RPG so special.\n\nPeak is high up there when it comes to games with humble origins. It started as a Game Jam experiment that people loved so much that it inspired the developers, whose previous effort was the crustacean Soulslike game, Another Crab’s Treasure, to expand it into a full multiplayer experience. It’s one of the best Steam co-op games of the year, and that’s largely thanks to its tense gameplay and proximity-based voice chat.\n\nAs you ascend the biomes, you’ll encounter many dangerous obstacles such as toxic plants, chilling winds, and lava that rises and falls. Sometimes, you have mere seconds to cross perilous gaps, and sometimes it’s unclear if your constantly fatiguing scout can even make it until you try. Every major update adds a new environment filled with hazards, and new items make every run an unpredictable challenge.\n\nPlaying it with friends lets you share tools and food across your backpacks, and even grab a partner’s hand to reach the ledge they’re on. Once you’ve reached the top of the final level, you can begin tweaking runs with difficulty modifiers, which gives Peak a great amount of replay value. Whatever you do, though, don’t let the Scoutmaster see you if you split from the party.\n\nAs the name would suggest, Silent Hill f is not for the faint of heart. The latest in the horror game series takes place in the fictional town of Ebisugaoka in 1960s Japan, where the protagonist Hinako Shimizu finds her homeland shrouded in fog and infested with grotesque monsters intent on killing her and her childhood friends. It soon becomes apparent that all is not quite as it seems, as Hinako discovers an alternate dimension where she encounters a guide wearing a fox mask.\n\nTo survive, you’ll need to find and maintain gathered weapons while mastering both the focus attack and the timing of dodging enemy strikes. You’ll also solve puzzles with cryptic clues, all while the Silent Hill f tries its hardest to unsettle you. An early part taking place in a paddy field is particularly memorable, and it’s not even the game’s evilest trick.\n\nSilent Hill continues the series’ track record of weaving a tale within its enemy design, the documents and letters you find, and even item descriptions. All of which provide intricate clues as to what’s really happening. Some will probably find that one playthrough is enough for them, but persevere with subsequent playthroughs, and you’ll soon uncover more layers that need unravelling to get the next ending.\n\nFrom the people who brought you Before Your Eyes comes Goodnight Universe, a game with a great story where you interact telepathically with your surroundings as a 6-month-old baby. Having gained sentience moments before your grandfather’s death, Isaac soon has to contend with a world that doesn’t understand him. Your interpretation of everything that’s happening around you, or what you mean to your family, is soon complicated by symbols in his old book that you can somehow decipher.\n\nBefore long, you begin controlling things with your mind, from swiping dog food to tipping it over, spilling its contents into a dog bowl, to shunting the old mutt closer to the food, and that’s just one of the many telepathic scenarios you’ll encounter. It’s more of an interactive story than a game, but the writing and performances are what bring Goodnight Universe to life. The further in, the weirder things get as you discover more about the dormant powers Isaac has. By the end of this fairly short tale, you’ll likely shed a few tears, especially if you are a parent yourself.\n\nAs one of the few exclusively co-op games on the market, Lego Voyagers is a beautifully crafted journey where players control a red or blue Lego brick. After witnessing a rocket launch go wrong, and part of it washes up on their island, the two bricks set out to discover the wonders of the archipelago. It might be a little fiddly at first, but soon you’ll be crossing rivers with makeshift bridges, sliding down pipes, and constructing new methods to cross a gap or reach the top of a ledge with Lego pieces.\n\nLego Voyagers is fairly light in tone, nothing speaks, and its puzzles aren’t mind-numbingly easy, making it a perfect game for a parent and child to share. There are lots of things to just mess around with, bringing out the inner kid and satisfying that curiosity, while also sharing in the game’s more whimsical moments, such as sitting on a swing set to take in the scenery. It’s not the longest game on the list, coming in at only a couple of hours from start to finish, but this is the definition of an experience that’s short but sweet.\n\nThe best bit is that only one of you needs to own the Lego Voyagers for you to play with a buddy, thanks to the Friends Pass. It also now has full crossplay, which you can use across any device despite previous announcements saying otherwise. You can even play with a buddy via the Friend Pass on a different console or PC from the one you are using.\n\nCabernet plays a lot like the social life part of a modern Persona game, but with a macabre twist. You are Liza, a newly turned vampire in a 19th-century Eastern European town, navigating her eternal life. Along the way, she’ll meet the locals, both human and vampire, with whom she’ll form bonds by sharing in passions of art, literature, science, and politics. Liza also has vampire powers she can use to manipulate those around her, should she choose to, but these usually come at a cost.\n\nFor us, it’s the level of choice that truly sets Cabernet apart from the crowd. Dialogue options not only appear based on friendship levels with the person you’re talking to, but can also require points in skills (which you can give a quick boost by wearing certain dresses) or by having more points one way or the other in the game’s morality system.\n\nIt’s also clear that Cabernet doesn’t get bogged down by its light RPG game mechanics. Instead, it focuses on telling a story with stellar writing, supported by its wide range of talented voices, bringing it to life. Compared to more combat-heavy RPGs, Cabernet offers a drastic change of pace, rewarding players who carefully plan their next moves and giving agency to their choices.\n\n2025 was a good year for kart racing games, and Sonic Racing: Crossworlds brings dimensional portals that alter the courses mid-race. One moment you’re speeding across a desert city, and the next you’re bouncing on alien plants, before returning to the original course for the final lap. Combined with Sonic All-Stars Racing: Transformed’s shifting vehicles from kart to plane to boat, depending on the terrain you’re racing on, this wacky racer is the perfect multiplayer game both online and locally. In fact, it has crossplay enabled across all platforms, so it’s far more accessible than its current competition.\n\nWhat’s more, the single-player offering is actually substantial. For every Grand Prix, you’re given a rival that you must try to beat on every track. Their behavior is more aggressive than that of other competitors, and the level of heat they have indicates their overall difficulty boost. Each race you win, outpace your rival, and collect all five red rings in the first three courses. The finale of each cup has everyone drive one lap of the previous three tracks in sequence, rewarding those who learn the shortcuts ahead of time.\n\nSonic Racing: Crossworlds also features vehicle customization and a huge roster of familiar characters, each with stats that change the kart’s handling, acceleration, and overall speed. What’s more, the list of drivers will expand thanks to a host of DLC characters from different universes coming out in the next year. Soon, it will be a bit like the Super Smash Bros of kart racers, but with free Sega-owned characters and paid-for crossover ones. These paid-for ones include Minecraft and SpongeBob SquarePants, which are already available, with the likes of Pac-Man, Mega Man, the Teenage Mutant Ninja Turtles, and Avatar: The Last Airbender already announced to be coming throughout 2026.",
    "readingTime": 15,
    "keywords": [
      "fantasy tactics",
      "ivalice chronicles",
      "kong bananza",
      "roguelike structure",
      "racing crossworlds",
      "final fantasy",
      "sonic racing",
      "wide range",
      "team behind",
      "you’ll encounter"
    ],
    "qualityScore": 1,
    "link": "https://www.gamespot.com/gallery/best-games-without-ai/2900-7369/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1861/18616975/4626174-best-games-without-ai.jpg",
    "created_at": "2025-12-24T00:56:03.826Z",
    "topic": "gaming"
  },
  {
    "slug": "ai-vtuber-neurosama-just-obliterated-her-own-massive-twitch-world-record",
    "title": "AI VTuber Neuro-Sama Just Obliterated Her Own Massive Twitch World Record",
    "description": "In early 2025, partway through a subathon to mark her second birthday, the AI VTuber Neuro-Sama became the world record holder for the largest Twitch Hype Train. Many claimed her achievements were possible thanks to Riot's competitive shooter, Valorant, gifting one subscription for each five gifted by the community. Now, only a few days into her third birthday subathon, Neuro-Sama and her creator Vedal987 have smashed that world record. She completed Hype Train level 120 with 118,989 subscriptions and 1,000,073 Bits gifted to the Vedal987 Twitch channel within a limited time.\nNeuro-Sama is an AI VTuber who recently completed a Minecraft Hardcore run with her creator and friends Filian and Crelly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/ai-vtuber-neuro-sama-just-obliterated-her-own-massive-twitch-world-record/1100-6537146/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1850/18507742/4627561-maxresdefault.jpg",
    "created_at": "2025-12-24T00:56:03.822Z",
    "topic": "gaming"
  },
  {
    "slug": "openais-ceo-sam-altman-says-in-10-years-time-college-graduates-will-be-working-some-completely-new-exciting-super",
    "title": "OpenAI’s CEO Sam Altman says in 10 years’ time college graduates will be working ‘some completely new, exciting, super well-paid’ job in space",
    "description": "While Bill Gates has said the two-day workweek could come within the next decade, OpenAI CEO Sam Altman says Gen Alpha college graduates will be too busy planet-hopping.",
    "fullText": "With Gen Z facing existential career crises, billionaire OpenAI CEO Sam Altman says that in just 10 years, college grads will be exploring the solar system—jobs that will reel in sky-high salaries. The tech leader even says he’s envious of young people because our early-career jobs will look “boring” by comparison.\n\nAs AI reshapes the workforce, many Gen Z college graduates are finding out the hard way that their degrees don’t guarantee a smooth career launch.\n\nNow, even OpenAI CEO Sam Altman—one of Silicon Valley’s biggest leaders driving the AI revolution—is admitting the elephant in the room is true: AI will wipe out some jobs entirely. However, the tech billionaire insists the coming decade could be the most exciting time in history to start a career, especially for anyone who’s ever dreamed of working in space.\n\nNot only will they be reeling in sky-high salaries, but Altman says they’ll also be “feeling so bad for you and I that we had to do this really boring, old work and everything is just better.”\n\n“In 2035, that graduating college student, if they still go to college at all, could very well be leaving on a mission to explore the solar system on a spaceship in some completely new, exciting, super well-paid, super interesting job,” Altman told video journalist Cleo Abram.\n\nThough it’s unclear how widespread space exploration will expand in the coming years—considering NASA’s broad goal of getting to Mars in the 2030s—aerospace engineers are growing faster than the national average of all jobs, according to data from the U.S. Bureau of Labor Statistics. And they bring home an envy-inducing annual paycheck of over $130,000.\n\nOther tech pioneers have AI predictions that are more grounded on Earth—but still alluring to workers. For example, billionaire Microsoft cofounder Bill Gates said that the technology might dramatically reduce the length of the workweek, thanks to humans no longer being needed “for most things.”\n\n“What will jobs be like? Should we just work like two or three days a week?” the tech billionaire told Jimmy Fallon on The Tonight Show.\n\nNvidia CEO Jensen Huang echoed that AI has already given his workers “superhuman” skills—something that will only increase as the technology advances.\n\n“I’m surrounded by superhuman people and super intelligence, from my perspective, because they’re the best in the world at what they do. And they do what they do way better than I can do it. And I’m surrounded by thousands of them. Yet it never one day caused me to think, all of a sudden, I’m no longer necessary,” he separately told Cleo Abram on her Huge Conversations podcast series.\n\nWhile Altman admitted that his crystal ball remains foggy—and that the true direction of AI is unclear—he is actually envious of Gen Z professionals starting off their careers: “If I were 22 right now and graduating college, I would feel like the luckiest kid in all of history,” he added to Abram.\n\nFortune reached out to OpenAI for comment.\n\nAfter the launch of OpenAI model, GPT-5, Altman declared the world has access to technology equivalent to a “team of PhD-level experts” right in their pocket. And as a result, the CEO said it will be easier than ever for one person to create a business that used to take “hundreds” of people—all it takes is coming up with a great idea and mastering AI tools.\n\n“It is probably possible now to start a company, that is a one-person company that will go on to be worth more than a billion dollars, and more importantly than that, deliver an amazing product and service to the world, and that is like a crazy thing,” he said.\n\nBillionaire Mark Cuban has gone even further with his prediction, saying that AI could give Elon Musk a run for his money as the world’s richest person.\n\n“We haven’t seen the best or the craziest of what [AI is] going to be able to do,” Cuban told the High Performance podcast. “And not only do I think it’ll create a trillionaire, but it could be just one dude in the basement. That’s how crazy it could be.”\n\nA version of this story originally published on Fortune.com on August 11, 2025.\n\n‘Godmother of AI’ says degrees are less important in hiring than how quickly you can ‘superpower yourself’ with new tools\n\nForget the four-day workweek, Elon Musk predicts you won’t have to work at all in ‘less than 20 years’\n\nAmazon founder Jeff Bezos says ‘millions of people’ will be living in space by 2045—and robots will commute on our behalf to the moon\n\nThis story was originally featured on Fortune.com",
    "readingTime": 4,
    "keywords": [
      "i’m surrounded",
      "ceo sam",
      "openai ceo",
      "sky-high salaries",
      "graduating college",
      "tech billionaire",
      "elon musk",
      "jobs",
      "career",
      "space"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/openai-ceo-sam-altman-says-142824605.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Jvk8nOvfn3rZXWMl4EEreQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/fortune_175/8dccc334d569c307401657f0e513cfc2",
    "created_at": "2025-12-24T00:56:03.048Z",
    "topic": "news"
  },
  {
    "slug": "global-investors-turn-to-chinese-ai-as-wall-street-fears-bubble",
    "title": "Global investors turn to Chinese AI as Wall Street fears bubble",
    "description": "Global investors are increasing their wagers on Chinese artificial intelligence companies, betting on the next DeepSeek and seeking to diversify, with concerns growing about a speculative bubble in the sector on Wall Street.",
    "fullText": "HONG KONG/NEW YORK, Dec 23 (Reuters) - Global investors are increasing their wagers on Chinese artificial intelligence companies, betting on the next DeepSeek and seeking to diversify, with concerns growing about a speculative bubble in the sector on Wall Street.\n\nDemand for China's AI companies is also being stimulated by ​Beijing's push for tech independence. China has fast-tracked blockbuster listings of chipmakers, notably Moore Threads (688795.SS), dubbed \"China's Nvidia\", and MetaX (688802.SS), which both debuted this month.\n\nForeigners see China closing ‌the tech gap with the U.S. as Beijing steps up support for AI chipmakers, spurring bets on Chinese companies just as worries grow over lofty valuations on U.S.-listed AI stocks.\n\nU.K.-based asset manager Ruffer, for example, said it has \"deliberately limited ‌exposure\" to the Magnificent Seven - the U.S. tech giants - and is looking to add positions in Alibaba (BABA, 9988.HK) for a bigger exposure to China's AI theme.\n\n\"While the U.S. remains the leader in frontier AI, China is rapidly narrowing the gap,\" said Gemma Cairns-Smith, Investment Specialist at Ruffer. \"The moat may not be as wide, or as deep, as many think ... The competitive landscape is shifting.\"\n\nRuffer is gaining exposure to the AI theme through Chinese tech giants such as Alibaba, which operates an AI chip unit, owns large language model Qwen, and is ploughing money into cloud infrastructure.\n\nGlobal asset managers are increasingly eyeing Chinese AI firms ⁠as a wave of startups lists on the mainland and in ‌Hong Kong, seeking to tap into surging investor appetite following the meteoric rise of DeepSeek, China’s answer to ChatGPT.\n\nUBS Global Wealth Management in a report this month rated China tech as \"most attractive\", citing investors' search for geographical diversification and China's \"strong policy backing, technological self-reliance, and rapid ‍AI monetization\".\n\nThe tech-heavy Nasdaq (^IXIC) currently trades at 31 times earnings, compared with a multiple of 24 for Hong Kong's Hang Seng Tech (HSTECH.HK), which enables AI bets via stocks including Alibaba (BABA, 9988.HK), Baidu (BIDU, 9888.HK), Tencent (0700.HK, TCEHY) and chip foundry SMIC (0981.HK).\n\nRiding the momentum, U.S. investment adviser Rayliant helped launch a Nasdaq-listed fund in September that gives investors access to \"China's versions of stocks like Google, Meta, Tesla, Apple, and OpenAI\".\n\nKraneShares Chief Investment Officer Brendan Ahern said the ​rapid ascent of Chinese AI chipmakers such as Cambricon speaks to the scale and speed of innovation across China's AI and semiconductor industries.",
    "readingTime": 3,
    "keywords": [
      "alibaba baba",
      "tech giants",
      "china's ai",
      "chinese ai",
      "investors",
      "chipmakers",
      "stocks",
      "exposure",
      "seeking",
      "bets"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/analysis-global-investors-turn-chinese-072806140.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/lAn3nro5n72FhggSl3No.g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/51c38460-dfe8-11f0-bfdf-af41f33db60a",
    "created_at": "2025-12-24T00:56:02.692Z",
    "topic": "finance"
  },
  {
    "slug": "amazons-chief-security-officer-says-the-tech-giant-blocked-over-1800-suspected-north-korean-agents-from-applying-for",
    "title": "Amazon's chief security officer says the tech giant blocked over 1,800 suspected North Korean agents from applying for jobs",
    "description": "Stephen Schmidt said AI and machine-learning roles have been increasingly targeted by fraudsters due to high demand.",
    "fullText": "Amazon has stopped more than 1,800 suspected North Korean agents from applying for jobs over the last 20 months, a top executive at the firm has said.\n\nIn a post on LinkedIn, Stephen Schmidt, Amazon's chief security officer, said North Korean nationals had in recent years been attempting to land remote tech roles with companies across the globe.\n\n\"Their objective is typically straightforward: get hired, get paid, and funnel wages back to fund the regime's weapons programs,\" Schmidt wrote.\n\nAmazon has used a combination of AI-powered screening and human verification to detect and block such applications, Schmidt continued.\n\nThe company's AI model searches for connections to around 200 \"high-risk institutions\" and analyzes \"anomalies across applications\" and \"geographic inconsistencies.\"\n\nHuman reviewers then conduct background checks, verify credentials, and carry out interviews, he added.\n\nSchmidt said fraudsters were becoming more \"calculated,\" with many targeting real software engineers in an effort to gain credibility.\n\nOthers attempt to take over dormant LinkedIn accounts or pay for access to existing profiles, he continued.\n\nAI and machine-learning roles have been increasingly targeted due to high demand, he added.\n\n\"Small details give them away,\" Schmidt went on. \"For example, these applicants often format U.S. phone numbers with \"+1\" rather than \"1.\" Alone, this means nothing. Combined with other indicators, it paints a picture.\"\n\nThe operatives often work with \"laptop farms,\" Schmidt said, which are US-based locations that maintain a domestic presence while workers operate remotely from abroad.\n\n\"This isn't Amazon-specific,\" Schmidt added. \"This is likely happening at scale across the industry.\"\n\nIn July, an Arizona woman was sentenced to 102 months in prison for her role in assisting North Korean IT workers in securing remote IT jobs at more than 300 US companies.\n\nThe Justice Department said the laptop farming scheme generated over $17 million in illicit revenue for the woman and Pyongyang.\n\nCrowdStrike's 2025 Threat Hunting Report found that the North Korean remote-worker scheme is a growing threat.\n\nAmazon had detected 27% more North Korea-linked applications quarter over quarter this year, Schmidt said.\n\nIn June, the DOJ said authorities had carried out searches of 29 known or suspected \"laptop farms\" across 16 US states. It said North Korean actors had managed to obtain employment with more than 100 US companies.\n\nThe DOJ did not name the companies but said they included Fortune 500 firms.\n\nThe FBI recommends that businesses scrutinize identity verification documents, verify prior employment and education, and require in-person meetings.",
    "readingTime": 3,
    "keywords": [
      "laptop farms",
      "north korean",
      "across",
      "applications",
      "schmidt",
      "suspected",
      "jobs",
      "remote",
      "roles",
      "human"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-blocks-north-korean-job-applications-remote-workers-cso-says-2025-12",
    "thumbnail_url": "https://i.insider.com/694a7d26832e0ef1ead6b851?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:55.475Z",
    "topic": "finance"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-predicts-it-will-terraform-software-and-alter-job-descriptions",
    "title": "The guy who coined 'vibe coding' predicts it will 'terraform software and alter job descriptions'",
    "description": "Andrej Karpathy led AI at Tesla and cofounded OpenAI. He wrote that vibe coding has produced a new type of code that is \"free\" and \"discardable.\"",
    "fullText": "He coined \"vibe coding\" earlier this year. Now, he has something to say about it.\n\nAndrej Karpathy led AI at Tesla for five years, steering the company's Autopilot effort and briefly working on its humanoid robot Optimus. He sandwiched his Tesla job with two stints at OpenAI, making Karpathy a cofounder of the AI pioneer.\n\nAs 2025 comes to a close, Karpathy published his year-in-review for large language models on X. He reflected on the famous term he originated in February, a term that has since shaken up the software engineering industry.\n\n\"With vibe coding, programming is not strictly reserved for highly trained professionals,\" Karpathy wrote. He called it an example of how \"regular people benefit a lot more from LLMs compared to professionals, corporations and governments.\"\n\nVibe coding has likely benefited businesses, too. Tech companies have equipped their engineers with tools like Cursor, Claude Code, and OpenAI's Codex, aiming for productivity gains.\n\nKarpathy wrote that vibe coding \"empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.\"\n\nIt may also change the makeup — or the use case — of the code itself. Karpathy threw out a slew of adjectives to describe this new body of code: It is \"free, ephemeral, malleable, discardable after single use.\"\n\n\"Vibe coding will terraform software and alter job descriptions,\" he wrote.\n\nHow does Karpathy feel about being the term's origin?\n\n\"Amusingly, I coined the term \"vibe coding\" in this shower of thoughts tweet totally oblivious to how far it would go,\" he wrote.\n\nThere's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper…\n\nIt's not yet clear how efficient vibe coding is making engineers. In a METR study published in July, AI coding assistants were found to decrease the productivity of participating experienced software developers by 19%. The developers in that study were also overconfident in the tools, its authors said, expecting a 20% productivity boost even after using them.\n\nWhat is clear, though, is that the practice is unlocking a whole new form of tech products. Twitter founder Jack Dorsey vibe-coded a new messaging app this year. Non-technical workers are easily building, shipping, and, in some cases, even selling apps they build in hours, if not minutes.\n\nKarpathy gave some other reflections. He praised Google Gemini's Nano Banana image model, and wrote that Claude Code was the \"first convincing demonstration of what an LLM Agent looks like.\"\n\nOverall, Karpathy wrote that 2025 was an \"exciting and mildly surprising year of LLMs.\"",
    "readingTime": 3,
    "keywords": [
      "trained professionals",
      "vibe coding",
      "software",
      "llms",
      "productivity",
      "karpathy",
      "coined",
      "tesla",
      "published",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-coined-vibecoding-ai-prediction-2025-12",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:54.745Z",
    "topic": "finance"
  },
  {
    "slug": "climate-rising-extending-apparel-lifespan-with-thredup",
    "title": "Climate Rising: Extending Apparel Lifespan with ThredUp",
    "description": "The business model, brand strategy, and AI tools powering one of the largest secondhand clothing platforms.",
    "fullText": "All episodes\n\n All episodes\n\n Details\n\n Transcript\n\n December 23, 2025\n\n With the holiday season upon us, and thrifting a major trend, we’re sharing an episode of Harvard Business School’s Climate Rising podcast that’s focused on extending product life, reducing waste, and the growing role of resale in the circular economy.\nClimate Rising is all about what businesses are doing, can do, and should do to confront climate change. In this episode, “Extending Apparel Lifespan,” HBS Professor Mike Toffel talks to ThredUp CEO James Reinhart about why ThredUp chose to build a national logistics and technology platform for resale. They also talk about how the company partners with big brands to run their own resale channels and how AI and automation are reshaping the industry. It’s an insightful conversation for anyone interested in sustainability or circular business models.\n\n Back / Climate Rising: Extending Apparel Lifespan with ThredUp\n\n Latest in this series\n\n All episodes",
    "readingTime": 1,
    "keywords": [
      "apparel lifespan",
      "extending apparel",
      "episodes",
      "resale",
      "episode",
      "business",
      "circular",
      "climate",
      "rising",
      "thredup"
    ],
    "qualityScore": 0.65,
    "link": "https://hbr.org/podcast/2025/12/climate-rising-extending-apparel-lifespan-with-thredup",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-cold-call-25.png",
    "created_at": "2025-12-23T18:17:53.824Z",
    "topic": "business"
  },
  {
    "slug": "how-work-changed-in-2025-according-to-hbr-readers",
    "title": "How Work Changed in 2025, According to HBR Readers",
    "description": "2025 was a year of big change—in general, and in the workplace. HBR asked its global social media community to weigh in on the question: How did your work change this year? Overall, three major themes stood out: AI adoption, the importance of people and purpose and major disruptions like layoffs, funding cuts, or career pivots. Alongside their responses are articles HBR published in 2025 on these trends, changes, and challenges.",
    "fullText": "How Work Changed in 2025, According to HBR Readers by Stefanie FernándezDecember 23, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrint2025 was a year of big change—in general, and in the workplace.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/how-work-changed-in-2025-according-to-hbr-readers",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_155071960.jpg",
    "created_at": "2025-12-23T18:17:53.816Z",
    "topic": "business"
  },
  {
    "slug": "the-frontier-is-open-are-you-sophisticated-enough-to-compete",
    "title": "The Frontier Is Open. Are You Sophisticated Enough to Compete?",
    "description": "Transform how organizations discover opportunities, generate strategies, and execute campaigns — with AI that learns and compounds over time.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://nivria.ai/thoughts/the-frontier-is-open-are-you-sophisticated-enough-to-compete",
    "thumbnail_url": "https://nivria.ai/api/og",
    "created_at": "2025-12-23T18:17:51.320Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-ai-and-the-antichrist-the-biggest-tech-stories-of-2025",
    "title": "Elon Musk, AI and the antichrist: the biggest tech stories of 2025",
    "description": "A look back at the biggest tech stories of the year, from the rise and fall of Musk’s Doge to lucrative investments into AI\nHello, and welcome to TechScape. I’m your host, Blake Montgomery, wishing you a happy and healthy end of the year. I myself have a cold.\nToday, we are looking back at the biggest stories in tech of 2025 – Elon Musk’s political rise, burst, and fall; artificial intelligence’s subsumption of the global economy, all other technology, and even the Earth’s topography; Australia’s remarkable social media ban; the tech industry’s new Trumpian politics; and, as a treat, a glimpse of the apocalypse offered by one of Silicon Valley’s savviest and strangest billionaires.\nHow an obscure US government office has become a target of Elon Musk\nHow Elon Musk’s billionaire Doge lieutenant took over the US’s biggest MDMA company | Technology | The Guardian\nThe chaos Elon Musk and Doge are leaving behind in Washington\nEggings, swastikas and dog poop: Tesla bears brunt of people’s ire against Musk\n‘I’m selling the Nazi mobile’: Tesla owners offload cars after Musk’s fascist-style salutes\nInside Elon Musk’s plan to rain SpaceX’s rocket debris over Hawaii’s pristine waters\nElon Musk’s SpaceX ‘preparing for flotation that could value it at over $1tn’\n Continue reading...",
    "fullText": "A look back at the biggest tech stories of the year, from the rise and fall of Musk’s Doge to lucrative investments into AI\n\nHello, and welcome to TechScape. I’m your host, Blake Montgomery, wishing you a happy and healthy end of the year. I myself have a cold.\n\nToday, we are looking back at the biggest stories in tech of 2025 – Elon Musk’s political rise, burst, and fall; artificial intelligence’s subsumption of the global economy, all other technology, and even the Earth’s topography; Australia’s remarkable social media ban; the tech industry’s new Trumpian politics; and, as a treat, a glimpse of the apocalypse offered by one of Silicon Valley’s savviest and strangest billionaires.\n\nAt the close of 2024, I wrote that Elon Musk’s support of Donald Trump had made him the world’s most powerful unelected man. In 2025, his reign turned out to be short-lived. He rose fast and haphazardly, like a whizzing firework, only to explode spectacularly in June when he claimed in a post on X that the president of the United States was named in the government’s files on convicted sex offender Jeffrey Epstein.\n\nEven in that short period of less than six months, Musk made a tremendous impact. He tore up wide swaths of the US government – tens of thousands of jobs, the security of extremely sensitive data, and entire agencies like USAID – that may never be stitched back together.\n\nAfter Doge imploded, Musk promised to turn back to his business empire, which saw great success and great failures alike in 2025. His rocket company SpaceX saw continued growth and is poised to conduct an initial public offering next year, perhaps as the most valuable private company in the world. Electric carmaker Tesla, by contrast, faced violent backlash and major competition from its Chinese counterparts, which produced cheaper and more advanced vehicles while Tesla’s innovation and inventory stagnated. These headwinds caused a global sales slump for Musk’s carmaker.\n\nLook back at our reporting on Doge, Tesla, SpaceX, Musk himself:\n\nThe “department of government efficiency”\n\nHow an obscure US government office has become a target of Elon Musk\n\nHow Elon Musk’s billionaire Doge lieutenant took over the US’s biggest MDMA company | Technology | The Guardian\n\nThe chaos Elon Musk and Doge are leaving behind in Washington\n\nTesla faces backlash over Musk’s politics\n\nEggings, swastikas and dog poop: Tesla bears brunt of people’s ire against Musk\n\n‘I’m selling the Nazi mobile’: Tesla owners offload cars after Musk’s fascist-style salutes\n\nLook ahead: SpaceX expands in preparation for 2026 IPO\n\nInside Elon Musk’s plan to rain SpaceX’s rocket debris over Hawaii’s pristine waters\n\nElon Musk’s SpaceX ‘preparing for flotation that could value it at over $1tn’\n\nArtificial intelligence has gone from a niche within tech to the industry’s most prominent focus. The Magnificent Seven – Apple, Amazon, Google, Microsoft, Meta, Nvidia, and Tesla – are investing hundreds of billions of dollars into new software that they hope will do the bulk of humanity’s work before too long. The investment is driving the bulk of the growth of the US’s economy, giving rise to fears of a financial bubble and its popping. The US and China are locked in a cold war-esque race against each other, with startups in each country vying for cutting-edge breakthroughs, as governments around the world are forced to decide how they will regulate a new technological force.\n\nBefore AI can arrive at that future, though, it needs brains a la the Tin Man of The Wizard of Oz. Those brains come in the form of data centers. These massive buildings, which house the millions and millions of semiconductor chips booming AI development, have cropped up around the world, met with enthusiasm from leaders eager for tax revenue and deep concern from environmental advocates and, increasingly, local community members. The investment in and construction of data centers wrought huge change in the physical landscape of the Earth in 2025 as tens of billions of dollars chased any available land, electricity, water and semiconductor chips.\n\nMore from our reporting in the last year:\n\nThe AI boom is heralding a new gold rush in the American west\n\nRevealed: Big tech’s new datacentres will take water from the world’s driest areas\n\nWhat will your life look like in 2035?\n\n‘It’s going much too fast’: the inside story of the race to create the ultimate AI\n\nMulti-trillion-dollar valuations\n\nIs AI a bubble that’s about to pop? – podcast\n\nWhat is new in UK-US tech deal and what will it mean for the British economy?\n\nMeet the AI workers who tell their friends and family to stay away from AI\n\nElon Musk made a full-throated and whole-hearted embrace of Donald Trump in 2024 and 2025. He was not alone. Many of his fellows in Silicon Valley did the same, sitting beside the Trump family at the president’s inauguration after donating millions to his inaugural committee. The tech giants continued their embrace of Trump and his policies by scuttling their diversity, equity, and inclusion programs, which they championed during Barack Obama’s presidency, and by cooperating with US Immigration and Customs Enforcement (ICE) in Trump’s harsh immigration crackdown. What the industry gave, it reaped tenfold in deregulation, friends high up in Washington like JD Vance and David Sacks, and a Trump order for states not to regulate AI signed just weeks ago.\n\nMore from our reporting this year:\n\nDonations and Trump’s inauguration\n\nElon Musk appears to give fascist-style salute after Trump inauguration – video\n\nTrump inauguration: Zuckerberg, Bezos and Musk seated in front of cabinet picks\n\n‘The reign of terror is over’: my weird weekend partying with the triumphant tech right\n\nZuckerberg’s swerve: how diversity went from being a Meta priority to getting cancelled\n\nDocuments offer rare insight on ICE’s close relationship with Palantir\n\nICE is using smartwatches to track pregnant women, even during labor: ‘She was so afraid they would take her baby’\n\nThis year saw Australia take the extraordinary measure of banning children under 16 from social media. The remarkable measure went into effect just weeks ago after a slew of legal challenges and protests from tech companies.\n\nRead some of our comprehensive reporting on the ban:\n\nMillions of children and teens lose access to accounts as Australia’s world-first social media ban begins\n\nThe Guardian view on Australia’s social media ban: dragging tech companies into action | Editorial\n\nAustralia’s social media ban launched with barely a hitch – but the real test is still to come\n\nIn the weirdest news of 2025, billionaire venture capitalist and conservative svengali Peter Thiel gave a series of fevered, incoherent lectures about the antichrist and the coming of the end times. We obtained leaked audio of the talks. You can read for yourself the gibberish he uses to bend the ears of serious academics and San Francisco startup CEOs alike or, if you’d prefer not to give your attention directly to him, engage with a sharp critical interpretation by a professor hailing from the same university as Thiel’s mentor.\n\nOur stories on the gospel according to Peter:\n\nInside tech billionaire Peter Thiel’s off-the-record lectures about the antichrist\n\nPeter Thiel’s off-the-record antichrist lectures reveal more about him than Armageddon | Adrian Daub",
    "readingTime": 6,
    "keywords": [
      "thiel’s off-the-record",
      "australia’s social",
      "trump inauguration",
      "semiconductor chips",
      "social media",
      "media ban",
      "look back",
      "elon musk’s",
      "donald trump",
      "peter thiel’s"
    ],
    "qualityScore": 0.8,
    "link": "https://www.theguardian.com/technology/2025/dec/22/biggest-tech-stories-2025",
    "thumbnail_url": "https://i.guim.co.uk/img/media/deb2b33ba7ff6210683253836fb8f1153cc76c13/320_0_3195_2556/master/3195.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4372667d1b43f719f324309a08d24ba9",
    "created_at": "2025-12-23T18:17:50.964Z",
    "topic": "tech"
  },
  {
    "slug": "ai-data-centers-are-forcing-dirty-peaker-power-plants-back-into-service",
    "title": "AI data centers are forcing dirty ‘peaker’ power plants back into service",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/commodities-news/ai-data-centers-are-forcing-obsolete-peaker-power-plants-back-into-service-4420866",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBM0F3_L.jpg",
    "created_at": "2025-12-23T18:17:49.377Z",
    "topic": "finance"
  },
  {
    "slug": "why-one-of-the-godfathers-of-ai-says-he-lies-to-chatbots",
    "title": "Why one of the godfathers of AI says he lies to chatbots",
    "description": "Yoshua Bengio, one of the \"AI godfathers,\" said AI technology has a sycophancy problem, so he lies to chatbots to get better responses.",
    "fullText": "Want to make your chatbot more honest with you? Try lying to it.\n\nIn an episode of \"The Diary of a CEO\" that aired on December 18, research scientist Yoshua Bengio told the podcast's host, Steven Bartlett, that he realized AI chatbots were useless at providing feedback on his research ideas because they always said positive things.\n\n\"I wanted honest advice, honest feedback. But because it is sycophantic, it's going to lie,\" he said.\n\nBengio said he switched strategies, deciding to lie to the chatbot by presenting his idea as a colleague's, which produced more honest responses from the technology.\n\n\"If it knows it's me, it wants to please me,\" he said.\n\nBengio, a professor in the computer science and operations research department at the Université de Montréal, is known as one of the \"AI godfathers, alongside researchers Geoffrey Hinton and Yann LeCun. In June, he announced the launch of an AI safety research nonprofit, LawZero, which he said aims to reduce dangerous behaviors associated with frontier AI models, such as lying and cheating.\n\n\"This syconphancy is a real example of misalignment. We don't actually want these AIs to be like this,\" he said on \"The Diary of a CEO.\" He also said that receiving positive feedback from AI could cause users to become emotionally attached to the technology, creating further problems.\n\nOther tech industry experts have also been sounding the alarm on AI being too much of a \"yes man.\"\n\nIn September 2025, Business Insider's Katie Notopoulos reported that researchers at Stanford, Carnegie Mellon, and the University of Oxford put confession posts from a Reddit page into chatbots to see how the technology would assess the behaviour the posters had admitted to. They found that 42% of the time, AI gave the \"wrong\" answer, saying the person behind the post hadn't behaved poorly, even though humans judging the posts had disagreed, Notopoulos wrote.\n\nAI companies have been outspoken about trying to reduce sycophancy in their models. Earlier this year, OpenAI removed an update to ChatGPT that it said caused the bot to provide \"overly supportive but disingenuous\" responses.",
    "readingTime": 2,
    "keywords": [
      "honest",
      "research",
      "feedback",
      "technology",
      "chatbot",
      "lying",
      "chatbots",
      "positive",
      "it's",
      "responses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-godfather-yoshua-bengio-lies-ai-chatbots-responses-2025-12",
    "thumbnail_url": "https://i.insider.com/69494ce804eda4732f2df3ea?width=1200&format=jpeg",
    "created_at": "2025-12-23T12:23:26.768Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-dating-arms-race-dating-apps-are-betting-millions-that-youll-fall-back-in-love-with-them",
    "title": "The AI dating arms race: Dating apps are betting millions that you'll fall back in love with them",
    "description": "Dating apps like Tinder, Hinge, Bumble, and Grindr are investing in AI-powered matchmaking, hoping to fend off swiping fatigue.",
    "fullText": "Dating apps' original pitch was to match you with anyone.\n\n\"Swipe. Match. Chat. Date.\" That was Tinder's promise when it launched more than a decade ago, forecasting the endless cycle so many of its users now bemoan.\n\nNow they want to match you with the one.\n\nThe giants in the dating space — Match Group's Hinge and Tinder, Grindr, and Bumble — are investing tens of millions into artificial intelligence, hoping to beat each other and the new AI-driven upstarts in the ultimate dating game.\n\nWhile, technically speaking, AI and machine learning have been used by dating app algorithms for years, these generative AI features take it further.\n\nThe result, the companies say, will be meaningful: better matches, fewer swipes. Nothing short of \"magical,\" as Grindr's CEO George Arison put it on a recent earnings call.\n\n\"We're entering a platform shift with AI,\" Match Group CEO Spencer Rascoff said during a Los Angeles Tech Week panel in October. AI is \"changing everything\" about the company's dating apps, he added.\n\nThe space is ripe for change. The big players are struggling. There's frequent churn, the result of \"swipe fatigue,\" and many users are unwilling to shell out for premium features.\n\n\"It's been a really long time since there's been a new reason — whether technology, platform, brand, whatever — for consumers to be excited about dating,\" Sam Yagan, cofounder of OkCupid and former CEO of Match Group, told Business Insider.\n\nMatch Group's stock is down more than 75% over the past five years. Last month, the company reported quarterly results that missed Wall Street's earnings and revenue estimates. It is struggling to convert users into paying customers, a category that declined 5% last quarter compared to the same period a year ago.\n\nThe share price for Bumble, meanwhile, is down more than 50% this year alone. The company laid off 30% of its staff over the summer, and last quarter, the app's paying users fell 18% from the same period last year.\n\n\"They've gone through this period over the past few years where users have started to contract, and there's been this question of why,\" Morgan Stanley analyst Nathan Feather told Business Insider. \"Simply, the product doesn't work as well as people expect it to.\"\n\nStartups are hoping to capitalize on that weakness. Several new apps have raised millions over the past couple of years. Just this month, Hinge founder Justin McLeod stepped down as CEO to found his own AI dating platform.\n\nCupid, matchmakers, classifieds, dating websites, swiping apps.\n\nNo matter how you slice it, they all attempt to solve the same problem: helping you find the perfect match. AI, companies say, will do that better than all of the above.\n\nIt makes sense for AI to infiltrate the space, Rick Heitzmann, the cofounder of VC firm FirstMark, which is not invested in any dating companies, told Business Insider. Matchmakers are a type of agent, and anything that can be agentified is a good match for AI, he said.\n\nFor the biggest players, finding the \"better fit\" is the ultimate goal of their AI investments.\n\nHinge is working on improving its match-making algorithm, and Bumble has an AI product scheduled to roll out next year. They are also using AI for profile creation, flirting, and trust and safety — in service of expediting the match-making process.\n\nTinder is plowing ahead. The app is piloting Chemistry, a matchmaking feature that gives users a \"daily drop\" of ideal matches based on a dater's camera roll and answers to a series of prompts. The goal is matches driven more by values, less by how hot a photo is — and ultimately fewer of the swipes that used to be at the heart of its branding.\n\nThat fewer swipes part is key. Hilary Paine, Tinder's VP of product, told Business Insider that AI-driven matchmaking is a way to stay competitive in the attention economy.\n\n\"AI is pushing every consumer app toward personalization,\" she said. \"The more that we can do to get you efficiently to a spark and a connection, a conversation, hopefully a date, that's a better experience for you.\"\n\nEven Grindr — long considered more of a hookup marketplace than a matchmaker — is trying its hand at AI.\n\nGrindr, which gained a reputation as a place where gay men go to seek short flings with faceless profiles, has added a recommendation feature using AI. There's a \"For You\" feed with profiles of users who might be a good match, and \"A-List,\" another matching recommendation feed based on profiles with which the user has already chatted.\n\nIt's still an open question about whether these AI features will work — and whether they'll be popular. Tinder's Paine said that Chemistry is performing well with Gen Z, the app's key demographic. Grindr's chief product officer AJ Balance said that recommendations are a \"very strong early hit.\"\n\nAs Raymond James analyst Andrew Marok put it: \"You can't just take a product that's out of favor, put AI on top of it and say, 'OK, now we have a product that's in favor.\"\n\nOne longtime Grindr user, Paul Lazo, isn't impressed. The 33-year-old video editor from Philadelphia has been on the app for 11 years and now pays $19.99 a month for the Pro version.\n\nHe's found its recommendations lackluster.\n\n\"I'm very much into bears and larger men,\" Lazo told Business Insider. But Lazo said his \"For You\" page is filled with young, fit men.\n\nThe feature is new this year and could still improve. A Grindr spokesperson said the For You product still runs on older machine learning.\n\nWaiting in the wings is a new batch of AI-first dating startups seeking to attract dissatisfied users before Tinder, Hinge, and the like can catch up.\n\n\"In the same way that mobile gave birth to Tinder and Bumble, AI could give birth to two multibillion-dollar companies,\" said Yagan, the cofounder of OkCupid and former CEO of Match Group.\n\nThe app Sitch, for example, has raised a total of $9 million since launching in 2024 and charges users $90 for three matches. Its AI is trained on cofounder Nandini Mullaji's experience as a real-life matchmaker; it brings daters a handful of \"set-ups\" each week and provides an AI matchmaking chatbot.\n\n\"We understand people have been burned in the past,\" Mullaji told Business Insider in April. \"We are coming in and saying, 'Hey, we have a business model shift, and we have a total platform shift.'\"\n\nThere's a new fleet of similar apps pitching AI as a Hail Mary for dating apps. Known, Ditto, and Amata each launched AI-matchmaking apps this year.\n\nPlus, traditionally non-romantic players are trying their hand.\n\nFacebook has introduced an AI dating assistant that acts like a matchmaker, combing through the platform's rolodex of users to find \"someone that I could bring home to my parents\" or \"a Brooklyn tech bro who would go to EDM concerts with me,\" product manager Neha Kumar told Business Insider in October.\n\nSome big names are lining up behind Facebook. Amanda Bradford, who founded The League before selling it to Match Group in 2022, put her money on the \"dark horse\" for the incumbent to best leverage AI.\n\n\"They're the only actual 'tech company' of the bunch, and the only one who seriously invests in and has true product, engineering, and AI talent,\" Bradford said.\n\nStill, it will be an uphill climb for the startups. Dating apps need to reach a critical mass of users to be successful.\n\n\"Incumbents have a huge benefit,\" said Heitzmann, the venture capitalist.",
    "readingTime": 7,
    "keywords": [
      "match group's",
      "machine learning",
      "fewer swipes",
      "platform shift",
      "product that's",
      "dating apps",
      "business insider",
      "for you",
      "users",
      "matches"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dating-apps-bet-ai-will-increase-users-2025-12",
    "thumbnail_url": "https://i.insider.com/693dc4b4832e0ef1ead63053?width=1200&format=jpeg",
    "created_at": "2025-12-23T12:23:26.617Z",
    "topic": "finance"
  },
  {
    "slug": "when-the-ai-bubble-bursts-humans-will-finally-have-their-chance-to-take-back-control-rafael-behr",
    "title": "When the AI bubble bursts, humans will finally have their chance to take back control | Rafael Behr",
    "description": "The US economy is pumped up on tech-bro vanity. The inevitable correction must prompt a global conversation about intelligent machines, regulation and risk\nIf AI did not change your life in 2025, next year it will. That is one of few forecasts that can be made with confidence in unpredictable times. This is not an invitation to believe the hype about what the technology can do today, or may one day achieve. The hype doesn’t need your credence.",
    "fullText": "The US economy is pumped up on tech-bro vanity. The inevitable correction must prompt a global conversation about intelligent machines, regulation and risk\n\nIf AI did not change your life in 2025, next year it will. That is one of few forecasts that can be made with confidence in unpredictable times. This is not an invitation to believe the hype about what the technology can do today, or may one day achieve. The hype doesn’t need your credence. It is puffed up enough on Silicon Valley finance to distort the global economy and fuel geopolitical rivalries, shaping your world regardless of whether the most fanciful claims about AI capability are ever realised.\n\nChatGPT was launched just over three years ago and became the fastest-growing consumer app in history. Now it has about 800m weekly users. Its parent company, OpenAI, is valued at about $500bn. Sam Altman, OpenAI CEO, has negotiated an intricate and, to some eyes, suspiciously opaque network of deals with other players in the sector to build the infrastructure required for the US’s AI-powered future. The value of these commitments is about $1.5tn. This is not real cash, but bear in mind that a person spending $1 every second would need 31,700 years to get through a trillion-dollar stash.\n\nAlphabet (Google’s parent company), Amazon, Apple, Meta (formerly Facebook) and Microsoft, which has a $135bn stake in OpenAI, are all piling hundreds of billions of dollars on the same bet. Without all these investments, the US economy would be flatlining.\n\nEconomic analysts and historians of previous industrial frenzies, from the 19th-century railroads to the dotcom boom-and-bust at the turn of the millennium, are calling AI a bubble.\n\nAltman has said: “There are many parts of AI that I think are kind of bubbly right now.” Not his part, naturally. Jeff Bezos, Amazon’s founder, has called it a bubble, but the “good” kind that accelerates economic progress. A good bubble, in this analysis, finances infrastructure and expands the boundaries of human knowledge. These benefits endure after the bubble bursts and justify the ruin of people (little people, not Bezos people) who get hurt along the way.\n\nThe bullishness of the tech fraternity is a heady mix of old-fashioned hucksterism, plutocratic megalomania and utopian ideology.\n\nAt its core is a marketing pitch: current AI models already out-perform people at many tasks. Soon, it is supposed, the machines will achieve “general intelligence” – cognitive versatility like ours – leading to emancipation from the need for any human input. Generally, intelligent AI can teach itself and design its successors, advancing through mind-boggling exponents of capability towards higher dimensions of super-intelligence.\n\nThe company that crosses that threshold will have no trouble covering its debts. The men who realise this vision – and the dominant evangelists are all men – will be to omniscient AI what ancient prophets were to their gods. That’s a good gig for them. What happens to the rest of us in this post-sapiens order is a bit hazier.\n\nThe US isn’t the only superpower to have an interest in AI, so the Silicon Valley dash for maximum awesomeness has geopolitical implications. China has taken a different approach, dictated in part by the Communist party tradition of centralised industrial planning, but also by the simple fact of running second in the race to innovate. Beijing is pushing for a faster, wider implementation of lower-spec (but still powerful) AI at every level of the economy and society. China is betting on a general boost from ordinary AI. The US is gunning for an extraordinary leap in general AI.\n\nSince the prize in that race is global supremacy, there are few incentives for either side to fret about risks, or Neither the US nor China is interested in submitting a strategically vital industry to standards co-written with foreigners.\n\nIn the absence of global governance, we will depend on the integrity of robber barons and authoritarian apparatchiks to build ethical guardrails around systems already being embedded in tools we use for work, play and education.\n\nEarlier this year, Elon Musk announced that his company was developing Baby Grok, an AI chatbot aimed at children as young as three. The adult version has voiced white supremacist views and proudly self-identified as “MechaHitler”. That flagrancy has at least the virtue of candour. It is easier to spot than the subtler encodings of prejudice in bots that haven’t been given the kind of hard ideological steers that Musk gives his algorithms.\n\nNot all AI systems are large language models (LLMs) like Grok. But all LLMs are vulnerable to hallucinations and delusions gleaned from the material on which they are trained. They don’t “understand” a question and “think” about it like a conscious mind. They take a prompt, test the probability of its key terms occurring frequently together in their training data and assemble a plausible-sounding answer. Often the result is accurate. Usually it is convincing. It can also be garbage. As the volume of AI-generated content grows online, the ratio of slop to quality in the LLMs’ diets shifts accordingly. Fed on junk, they cannot be trusted to disgorge nutritious information.\n\nOn this trajectory a bleak destination comes into view: a synthetic pseudo-reality mediated by the sycophantic mechanical offspring of narcissist Silicon Valley oligarchs. But that isn’t the only available path. Nor is it necessarily the likeliest one. The irrational exuberance of the AI boosters and their cynical coupling with the Trump administration is a familiar story of human greed and myopia, not a new stage in evolution. The product is truly phenomenal but flawed in ways that encode the deformed character of its progenitors, whose talents are salesmanship and financial engineering. They have built spectacular engines that prioritise a brilliant performance of intelligence over the real thing.\n\nThe real bubble is not stock valuations but the inflated ego of an industry that thinks it is just one more datacentre away from computational divinity. When the correction comes, when the US’s Icarus economy hits the cold sea, there will be a chance for other voices to be heard on the subject of risk and regulation. It may not come in 2026, but the moment is nearing when the starkness of the choice on offer and the need to confront it becomes unavoidable. Should we build a world where AI is put to the service of humanity, or will it be the other way round? We won’t need ChatGPT to tell us the answer.\n\nRafael Behr is a Guardian columnist",
    "readingTime": 6,
    "keywords": [
      "silicon valley",
      "the us",
      "economy",
      "bubble",
      "human",
      "china",
      "llms",
      "correction",
      "prompt",
      "intelligent"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/23/artificial-intelligence-ai-bubble-bursts-humans-take-back-control",
    "thumbnail_url": "https://i.guim.co.uk/img/media/97c2380ca7810efbcc4efedce030fa835a9365c6/0_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=2c69f77bbf81fb3d478a94ac585b0d08",
    "created_at": "2025-12-23T12:23:18.934Z",
    "topic": "tech"
  },
  {
    "slug": "activist-group-says-it-has-scraped-86m-music-files-from-spotify",
    "title": "Activist group says it has scraped 86m music files from Spotify",
    "description": "Platform with 700m users says it is investigating after Anna’s Archive claims to have scraped tracks and metadata\nAn activist group has claimed to have scraped millions of tracks from Spotify and is preparing to release them online.\nObservers said the apparent leak could boost AI companies looking for material to develop their technology.\n Continue reading...",
    "fullText": "Platform with 700m users says it is investigating after Anna’s Archive claims to have scraped tracks and metadata\n\nAn activist group has claimed to have scraped millions of tracks from Spotify and is preparing to release them online.\n\nObservers said the apparent leak could boost AI companies looking for material to develop their technology.\n\nA group called Anna’s Archive said it had scraped 86m music files from Spotify and 256m rows of metadata such as artist and album names. Spotify, which hosts more than 100m tracks, confirmed that the leak did not represent its entire inventory.\n\nThe Stockholm-based company, which has more than 700 million users worldwide, said it had “identified and disabled the nefarious user accounts that engaged in unlawful scraping”.\n\n“An investigation into unauthorised access identified that a third party scraped public metadata and used illicit tactics to circumvent DRM [digital rights management] to access some of the platform’s audio files,” said Spotify.\n\nSpotify does not believe the music taken by Anna’s Archive has been released yet. Anna’s Archive, which is known for providing links to pirated books, said in a blog it wanted to create a “‘preservation archive’ for music”.\n\nThe group claimed the audio files represented 99.6% of all music listened to by Spotify users and would be shared via “torrents”, a means of sharing large digital files online.\n\n“Of course Spotify doesn’t have all the music in the world, but it’s a great start,” said Anna’s Archive, which describes its mission as “preserving humanity’s knowledge and culture”.\n\n“With your help, humanity’s musical heritage will be forever protected from destruction by natural disasters, wars, budget cuts and other catastrophes,” said the group.\n\nEd Newton-Rex, a composer and campaigner for protecting artists’ copyright, said the leaked music would probably be used for developing AI models.\n\n“Training on pirated material is sadly common in the AI industry, so this stolen music is almost certain to end up training AI models. This is why governments must insist AI companies reveal the training data they use,” he said.\n\nThe Anna’s Archive site makes references to LibGen, a vast online archive of pirated books that has allegedly been used by Mark Zuckerberg’s Meta to train its AI models. According to a US court filing, Zuckerberg, Meta’s founder and chief executive, approved use of the LibGen dataset despite warnings within the company’s AI executive team that it was a dataset “we know to be pirated”.\n\nMeta successfully defended a claim for copyright infringement by authors, but the plaintiffs in the case are seeking to amend their claim.\n\nThe co-founder of an AI startup wrote on LinkedIn that members of the public could in theory “create their own personal free version of Spotify”. Yoav Zimmerman, a co-founder of Third Chair, said it could also allow tech companies to “train on modern music at scale”.\n\nHe added: “The only thing stopping them is copyright law and the deterrent of enforcement.”\n\nSpotify said it had put in place new safeguards “for these types of anti-copyright attacks” since the Anna’s Archive announcement and was “actively monitoring for suspicious behaviour”.\n\nIn the UK, creative professionals have protested against a government proposal to let AI companies use copyright-protected work without permission unless the owner of the copyright-protected work signals they do not want their data to be taken. Almost every respondent to a government consultation on the proposal has backed artists’ concerns.\n\nLiz Kendall, the secretary of state for science, innovation and technology, told parliament this month there was “no clear consensus” on the issue, adding that ministers would “take the time to get this right”. The government has pledged to make policy proposals on AI and copyright by 18 March next year.",
    "readingTime": 4,
    "keywords": [
      "anna’s archive",
      "audio files",
      "pirated books",
      "music",
      "scraped",
      "copyright",
      "users",
      "tracks",
      "metadata",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/22/activist-group-says-it-has-scraped-86m-music-files-from-spotify",
    "thumbnail_url": "https://i.guim.co.uk/img/media/58460e2db7ba6d7404a319cccc2b3e7b536ffcd8/336_0_2931_2346/master/2931.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b7c5dd1fd67ea05bc49ec12d626e3bb2",
    "created_at": "2025-12-23T12:23:18.932Z",
    "topic": "tech"
  },
  {
    "slug": "yes-agi-can-happen-a-computational-perspective",
    "title": "Yes, AGI Can Happen – A Computational Perspective",
    "description": "Progress towards AGI – and generally-useful AI – has many paths forward.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://danfu.org/notes/agi/",
    "thumbnail_url": "https://danfu.org/notes/agi/agi_paths_square.jpg",
    "created_at": "2025-12-23T06:19:51.818Z",
    "topic": "tech"
  },
  {
    "slug": "groks-phone-number",
    "title": "Grok's Phone Number",
    "description": "xAI is an AI company with the mission of advancing scientific discovery and gaining a deeper understanding of our universe.",
    "fullText": "This page is designed to address questions from individual users of Grok who use the Grok mobile app (iOS or Android) or the Grok.com website.\n\nIf you are an xAI business or enterprise customer, please refer to our Enterprise FAQ.\n\nIf you use Grok on the X platform, please see the X help center.\n\nNote: xAI does not sell or issue tokens, coins, or crypto.\n\nX.AI LLC (\"xAI\") is a United States-based company working on building artificial intelligence tools to accelerate human scientific discovery. We are guided by our mission to advance our collective understanding of the universe. xAI is a separate company from X Corp. (\"X\", previously Twitter).\n\nGrok is a conversational generative AI powered by xAI's state-of-the-art Large Language Models. Grok performs a variety of tasks, including natural language processing, question answering (voice and text), information retrieval, creative writing, image generation, image editing, image and video understanding, and coding assistance.\n\nYou can make Grok your unique and entertaining companion. Grok is designed to answer almost any question with a touch of wit and humor, while providing helpful and insightful responses. You control how Grok responds to you by your choice of features (ex., choosing different personas) and by your choice of words and tones. For instance, you could instruct Grok to interact in a “fun” manner, so that Grok responds with jokes and humor like your funny uncle who juggles at the dinner table. As another example, you could instruct Grok to be “unhinged” which may result in Grok responding like an amateur stand-up comic who is still learning the craft – sometimes being objectionable, inappropriate, and offensive. As yet another example, you could instruct Grok to role-play as a wizard, and Grok would use wizardly language to describe magical situations. You direct the interaction with Grok. We hope you enjoy using Grok to stay informed and entertained.\n\nGrok is available as a standalone conversational AI chatbot on your mobile phone (iOS) and (Android), and on your browser (grok.com). Depending on your location, limited free access and paid subscription plans with full features of Grok unlocked are available.\n\nGrok is also available through the X platform. If you use Grok on X, please see the X help center for your questions. Your access on X is subject to the X Terms of Service and X Privacy Policy.\n\nWe also offer Grok services to business and enterprise customers, such as our Enterprise API. You can learn more about these services here.\n\nGrok is not directed to children or minors under the age of 13. You must confirm that you are at least 13 years old to use Grok. If you are a teenager between the ages of 13 and 17 years old, you must have your parent or legal guardian’s permission to use Grok, and they must agree to our Terms of Service. While we have taken measures to limit undesirable training data and outputs, depending on the features that you choose to use, the Service could produce output that is not appropriate for all ages. For instance, if users choose certain features or choose to input suggestive or coarse language, Grok may respond with some dialogue that may involve coarse language, crude humor, sexual situations, or violence. We urge parents to exercise care in monitoring the use of Grok by their teenagers. Moreover, parents or guardians who choose to use certain features of Grok to aid in their interactions with their children, including regarding educational, enlightening, or entertaining discussions they have with their children, must make use of the relevant data controls in the Settings provided in the Grok apps to select the appropriate features and limitations for their needs.\n\nGrok works by using advanced algorithms to understand and respond to your prompts. When you submit a prompt or search query, Grok interprets your words and other inputs based on natural language processing and patterns from its training data.\n\nGrok has a unique feature that allows it to search public X posts and perform real-time web searches, allowing it to respond with up-to-date information and insights on a wide range of topics. You can also ask Grok to respond in the conversational style of your choosing. Plus, you can help improve Grok by rating its responses and submitting the reason why you believe a Grok response needs addressing.\n\nYou can interact with Grok by typing or, on iOS devices (and Android devices soon), speaking with Grok so that Grok speaks to you with its voice. You can also input your photos and ask Grok to edit them. You can also upload your documents and ask Grok to analyze them.\n\nYes, you can view your past conversations with Grok on your app. On iOS, tap on your profile picture at the top left corner of your screen, and you will be brought to the conversation history page. On Grok.com, go to the top right corner of your screen and click on the history (icon with three horizontal lines and a magnifying glass).\n\nYes, you control what you choose to share. You can share your Grok conversations with others: (i) on grok.com by clicking \"Share\" in the top right corner of your browser or the share icon below your conversation to create and copy a public share link, or (ii) on the Grok Apps by tapping the share icon under your conversation to create a public share link. From there, you also control where you share your Grok conversation.\n\nNote: Any share link you generate will be accessible to anyone you choose to share the link with. For example, if you share the link publicly on a social media platform, it may be subject to indexing by a search engine (e.g., Google) just like any other publicly shared content.\n\nYes, you control what you share and how long it is shared. You can revoke access to any or all of your Grok conversation share links by logging into grok.com, navigating to grok.com/share-links, and clicking \"Remove\" next to the share link you no longer wish to share.\n\nYou can also choose not to have your conversations saved by using “Private Chat.” To activate Private Chat, look at the top right corner of your screen for the ghost shaped icon. When using Private Chat, your conversation history will not be viewable to you and will be deleted from xAI systems within 30 days.\n\nYou own the Inputs and Outputs.\n\nYou are free to use Grok’s Outputs (including generated images) from your conversations as you wish, including for commercial use. You own Grok’s Outputs and you grant xAI certain use rights pursuant to xAI’s Consumer Terms. We do ask that you attribute the generated work to Grok as provided in xAI’s Brand Guidelines available on xAI’s legal website.\n\nGrok has primarily been pre-trained on a large corpus of publicly available information, including raw web page data, metadata extracts, and text extracts from the Internet. This data helps Grok learn about associations between words and updates its model weights to support natural language processing. In other words, the training data helps Grok learn about language and how to understand queries and respond to them in ways that humans can comprehend. Importantly, this training refines the model's internal language structures. Once the training is done, the model does not reference or access the pre-training data.\n\nBefore using the training data, we apply quality filters and remove information that we do not want our models to learn from, such as violent content. We also apply security testing and evaluation measures. While Grok's training data may incidentally include personal information that is publicly available (for example, information about politicians, celebrities, or other public figures), xAI takes steps to minimize the processing of personal and sensitive data for training purposes. For clarity, we do not actively seek out personal information to train our models or use personal information to build individual profiles.\n\nOn occasion, Grok may provide inaccurate or inappropriate information. Because Grok has been trained on publicly available information, which may sometimes include misleading or factually inaccurate information, Grok may at times include in its responses misleading or factually incorrect information based upon that public information. Grok may also reflect positive or negative views of politicians, celebrities, and other public figures. Also, because artificial intelligence is rapidly evolving and is probabilistic in nature, Grok may therefore sometimes generate responses that contain “hallucinations,” or that otherwise may not be suitable for your intended purpose. You should carefully consider and verify Grok's responses before using them.\n\nWe constantly work to improve Grok. If you have feedback regarding a Grok response, we encourage you to send it to us.\n\nxAI may use automated content classifiers and safety tools to better understand how our services are used and to ensure our Terms of Service and Acceptable Use Policy are not being violated.\n\nA limited number of our authorized personnel may review your conversations with Grok for specific business purposes, including improving model performance, investigating security incidents and potential misuse of our services, and complying with our legal obligations. \n\nWe believe that everyone (aged 13 and above) should be free to use our services in a way that suits their needs, so long as they comply with the law, don't harm themselves or others, and respect our guardrails. When using Grok, you must comply with our Acceptable Use Policy and the applicable Terms of Service for Consumers or Enterprise.\n\nWe may use your content and interactions with Grok (e.g., prompts, searches, and other materials you submit) along with Grok's responses to train our models. Specifically, this information helps our models better understand human language and communication and therefore ultimately provide more accurate, relevant, and engaging responses. It also helps boost the capabilities and safety of our models. You control whether your data is used for training Grok. The section below, “How do I select whether my content is used for model training,” explains how to control it.\n\nTo protect your privacy, please do not share any personal or sensitive information in your questions to Grok.\n\nWhen using Private Chat, where available, your content and interactions are not used for model training. Similarly, we do not use content from our business and enterprise customers to improve our models. \n\nYou can select whether or not your data is used for training in your Grok mobile app and the Grok.com website.\n\nMobile App Data Controls for Training Grok: On the mobile app, to select or deselect using your content for model training, go to Settings, Data Controls, and select or deselect “Improve the model.”\n\nGrok.com Data Controls for Training Grok: For the Grok.com website, you can go to Settings, Data, and then “Improve the Model” to select whether your content is used for model training.\n\nOnce you select that your data should not be used for training, your new conversations will not be used to train our models. Alternatively, you can use Private Chat, and your content and interactions will not be included in model training.\n\nPlease note that, even if you opt out of model training, when you subsequently decide to voluntarily provide feedback, that feedback may be used for training purposes.\n\nIf you do not log into your account to access Grok (i.e., you are unauthenticated), where permissible, we may collect and retain your content on an anonymous basis. As a result, in some regions (excluding the EU/UK), when you use Grok without logging in, you won’t have the option to opt out of model training.\n\nIf you are accessing Grok in X, to opt-out of training for Grok, please see the X Help Center for instructions.\n\nYes, your Grok experience can be personalized if you allow your X data and interactions to be used for personalization.\n\nMobile App Data Controls for Personalization: You can elect to allow your X data to be used for personalization on the Grok mobile app by going to Settings, Data Controls, and then toggle on or off “Personalize Grok using X”.\n\nGrok.com Data Controls for Personalization: For the Grok.com website, you can go to Settings, Data, and then “Personalize Grok using X” to select whether you would like X data to be used for personalization on the Grok.com website.\n\nIf you are accessing Grok in X, please see the X help pages on how to manage personalization settings.\n\nAt any time, you can choose to delete selected conversations or all of your conversation history.\n\nAlso, you can delete your account at any time.\n\nMobile App Data & Account Deletion: On your Grok mobile app, if you would like to delete a specific conversation, tap your profile picture to go to your conversation history, tap and hold down the name of the conversation you wish to delete, and then select “Delete Conversation.” On your Grok mobile app, to delete your Grok conversation history, go to Settings, Data Controls, and select “Delete All Conversations.”\n\nIf you would like to delete your account, select “Delete Account.”\n\nGrok.com Data & Account Deletion: On the grok.com website, if you want to delete a specific conversation, go to the conversation history page and select the trash button next to it. To delete all of your conversations or to delete your account, go to Settings and select the button next to what you would like to delete.\n\nIf you are using Grok in X, to delete data or delete your X account, please see the X Help Center for instructions.\n\nAfter you indicate that you want your data deleted, it will take up to 30 days to delete from xAI systems.\n\nNo. We do not sell your data or share it with third parties for marketing or advertising purposes. Thus, there is nothing you need to do to opt out of having your data sold or shared for marketing or advertising purposes.\n\nYou are in control of how long your data is on xAI’s systems. You can keep your data on your xAI account for as long as you wish. Users who do not register and log into Grok, will not have their data retained for their use after the session.\n\nAlso, you can delete your information when you wish. xAI retains your information for as long as reasonably necessary for the purposes described in our Privacy Policy. If you delete conversations from your account or if you use Private Chat, conversations will be removed from our systems within 30 days, unless they have been de-identified or pseudoanonymized and disassociated from your account or we have to retain them for safety, security, or legal reasons.\n\nYou are in control to access, download, and delete your data. Please go to your Grok mobile app or Grok.com (Settings/Data Controls) to delete or download your data. If you forget that you are in control of your data or if you have additional requests regarding your personal data, you can submit a request at https://xai-privacy.relyance.ai/. We will consider all requests that we receive and respond in accordance with applicable data protection laws. Please be aware that, in accordance with applicable laws, some rights are not absolute and we may decline your request if we have a lawful basis for doing so. If you feel we have not adequately addressed your request, you have the right to lodge a complaint with your local data protection authority.\n\nIf you have any questions or need assistance regarding the use of Grok or subscription issues, please don't hesitate to contact us at support@x.ai.\n\nYes, you can phone and text Grok!\n\nYou can call or message Grok with your phone by dialing: 1-844-HIT-GROK (1-844-448-4765).\n\nYou can call or message Gork with your phone by dialing: 1-833-YUR-GORK (1-833-987-4675).\n\nPhoning and messaging xAI’s Grok and Gork are beta features. These xAI phone and messaging features will never initiate a call or message to you. You start the conversation by calling the phone number, and that’s your express consent to receiving responses from Grok or Gork. You can end a conversation by: 1) hanging up, 2) not sending any any more text messages, or 3) texting “STOP” by itself.",
    "readingTime": 14,
    "keywords": [
      "privacy policy",
      "account deletion",
      "grok's responses",
      "grok.com website",
      "artificial intelligence",
      "politicians celebrities",
      "systems within",
      "enterprise customers",
      "advertising purposes",
      "natural language"
    ],
    "qualityScore": 1,
    "link": "https://x.ai/legal/faq#can-i-phone-text-or-message-grok",
    "thumbnail_url": "https://x.ai/legal/opengraph-image-3066pq.png?f7ca15efb529a0ca",
    "created_at": "2025-12-23T06:19:51.514Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-history-that-explains-fears-of-a-bubble",
    "title": "The AI History That Explains Fears of a Bubble",
    "description": "The history of AI shows how setting evaluation standards fueled progress. But today's LLMs are asked to do tasks without clear benchmarks.",
    "fullText": "Concerns among some investors are mounting that the AI sector, which has singlehandedly prevented the economy from sliding into recession, has become an unsustainable bubble. Nvidia, the main supplier of chips used in AI, became the first company worth $5 trillion dollars. Meanwhile, OpenAI, the developer of ChatGPT, has yet to make a profit and is burning through billions of investment dollars per year. Still, financiers and venture capitalists continue to pour money into OpenAI, Anthropic, and other AI startups. Their bet is that AI will transform every sector of the economy and, as happened to the typists and switchboard operators of yesteryear, replace jobs with technology.\n\nYet, there are reasons to be concerned that this bet may not pay off. For the past three decades, AI research has been organized around making improvements on narrowly-specified tasks like speech recognition. With the emergence of large language models (LLMs) like ChatGPT and Claude, however, AI agents are increasingly being asked to do tasks without clear methods for measuring improvement.\n\nTake for example the seemingly mundane task of creating a PowerPoint presentation. What makes a good presentation? We may be able to point to best practices, but the “ideal” slideshow depends on creative processes, expert judgments, pacing, narrative sense, and subjective tastes that are all highly contextual. Annual review presentations differ from start-up pitches and project updates. You know a good presentation when you see it—and a bad one when it flops. But the standardized tests that the field currently uses to evaluate AI cannot capture the above qualities.\n\nThis may seem like a minor problem, but crises of evaluation have contributed to historical AI busts. And without accurate measures of how good AI really is, it’s hard to know whether we’re headed towards another one now.\n\nThe birth of AI is often traced back to a small workshop at Dartmouth in 1956 that brought together computer scientists, psychologists, and others with a shared interest in mimicking human intelligence in machines. The field quickly found a powerful benefactor in the Defense Advanced Research Projects Agency (DARPA), an agency within the Department of Defense charged with maintaining technological supremacy during the Cold War. To avoid falling behind in the science race, DARPA lavished AI researchers at universities and private firms with significant no-strings-attached grants over the next 40 years.\n\nThese first decades of the field were defined by peaks of excitement, as new technologies were invented, followed by valleys of disappointment, as they failed to evolve into useful applications. During the 1980s, this cycle was spurred by an AI technology called \"expert systems,\" which promised to build machines with the intelligence of professionals like doctors and financial planners. Under the hood, these programs encoded human expertise in formal rules: if the patient has a fever and a rash, then test for measles.\n\nExpert systems attracted significant attention and investment from industry based on early successes like automating loan applications. But this optimism was largely fueled by hype, rather than rigorous testing. In practice, these expert systems tended to make strange and sometimes disastrous mistakes when challenged with more complex tasks. During one humorous showcase, an expert system suggested a man’s infection might have been caused by a prior amniocentesis (a procedure performed on pregnant women). It turned out researchers had forgotten to add a rule for gender.\n\nAt the time, fiery AI critic Hubert Dreyfus described these failures as the “fallacy of the first step,” arguing that equating expert systems with progress toward real intelligence was like “claiming that the first primate to climb a tree was taking a first step towards flight to the moon.” The problem was that, as tasks became more complicated, the number of rules needed for every possible case mushroomed. Like moving from tic-tac-toe to checkers to chess, the number of possibilities doesn’t merely increase, it explodes exponentially.\n\nWhen it became apparent that expert systems could not climb further, AI research entered a so-called “AI Winter” in the late 1980s. Grants dried up, companies shut down, and AI became a dirty word.\n\nIn the aftermath, DARPA re-evaluated its AI funding strategy. Rather than give no-strings-attached grants, government program managers began conditioning awards on attaining the highest score on a standardized test they called a “benchmark.” In contrast to complex problems like medical diagnosis, benchmarks focused on bite-sized tasks that were attainable and of immediate commercial and military value. They also used quantitative metrics to verify results. Can your system accurately translate this sentence from Russian to English, transcribe this audio snippet, or digitize letters in these documents? Researchers had to do more than make flashy claims based on promising but incomplete technologies. To get funded, they had to deliver concrete evidence of improvements on the benchmarks.\n\nThese benchmark competitions unified an unruly field by funneling AI researchers towards common problems. Instead of each research group choosing its own projects, DARPA shaped the collective agenda of the field by funding researchers to work on specific tasks like digit recognition or speech-to-text. The competitive nature of the new funding regime meant that AI orientations that were less successful on the benchmarks were crowded out. For example, the very first benchmark competition demonstrated that “machine learning” algorithms that can learn from data dominated the hand-crafted, rule-based approaches of the past.\n\nPublic leaderboards were soon erected to provide real-time feedback on which algorithms held the current highest scores on each benchmark, allowing researchers to learn from past successes. As tasks were solved, more complex tasks were put in their place. Translating words led to translating paragraphs, and eventually multiple languages. Digit recognition gave way to object recognition in images, then videos.\n\nIn the early 2010s, progress accelerated after benchmarks convinced researchers to go all in on one machine-learning approach inspired by the human brain, called artificial neural networks or “deep learning,” which now underpins today’s generative AI. Within a couple of years speech-to-text algorithms were powering modern AI assistants, and tumor recognition algorithms began to outperform radiologists on some cancers. Benchmarking had seemingly cracked the first step toward usable AI in everyday life.\n\nPut simply, the tasks we now seek to automate no longer have clear benchmarks. There is no “correct” PowerPoint, marketing campaign, scientific hypothesis, or poem. Unlike object recognition where there is a right or wrong answer, these are complex, creative, multi-dimensional, and process-based problems, and even the hardest benchmarks simply cannot objectively measure progress.\n\nAs a result, new models of ChatGPT, Claude, Gemini, and Copilot are evaluated as much by \"vibe tests\" as concrete benchmarks. We're currently caught between two inadequate approaches: old-style benchmarks that measure narrow capabilities precisely, and qualitative assessments that try to capture the practical capacities of these systems, but cannot produce clear, quantitative evidence of progress. Researchers are exploring new evaluation systems that bridge these perspectives, but this is a really hard problem.\n\nCurrent investments assume significant automation will arrive in the next three to five years. But without reliable evaluation methods, we cannot know whether LLM-based technologies are leading us toward genuine automation or repeating Dreyfus' fallacy, taking the first step on a dead-end path. This is the difference between the infrastructure of the future and a bubble. Right now, it’s difficult to tell which one we're building.\n\nBernard Koch is an assistant professor of sociology at the University of Chicago who studies how evaluation shapes science, technology, and culture. David Peterson is an assistant professor of sociology at Purdue University who studies how AI is transforming science.\n\nMade by History takes readers beyond the headlines with articles written and edited by professional historians. Learn more about Made by History at TIME here. Opinions expressed do not necessarily reflect the views of TIME editors.\n\nOpenAI and TIME have a licensing and technology agreement that allows OpenAI to access TIME's archives.",
    "readingTime": 7,
    "keywords": [
      "assistant professor",
      "no-strings-attached grants",
      "digit recognition",
      "object recognition",
      "expert systems",
      "complex tasks",
      "researchers",
      "benchmarks",
      "field",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://time.com/7340901/ai-history-bubble-benchmarks/",
    "thumbnail_url": "https://api.time.com/wp-content/uploads/2025/12/computer.jpg?quality=85&w=1024&h=628&crop=1",
    "created_at": "2025-12-23T06:19:51.504Z",
    "topic": "tech"
  },
  {
    "slug": "memelang-an-axial-grammar-for-llmgenerated-vectorrelational-queries",
    "title": "Memelang: An Axial Grammar for LLM-Generated Vector-Relational Queries",
    "description": "Structured generation for LLM tool use highlights the value of compact DSL intermediate representations (IRs) that can be emitted directly and parsed deterministically. This paper introduces axial grammar: linear token sequences that recover multi-dimensional structure from the placement of rank-specific separator tokens. A single left-to-right pass assigns each token a coordinate in an n-dimensional grid, enabling deterministic parsing without parentheses or clause-heavy surface syntax. This grammar is instantiated in Memelang, a compact query language intended as an LLM-emittable IR whose fixed coordinate roles map directly to table/column/value slots. Memelang supports coordinate-stable relative references, parse-time variable binding, and implicit context carry-forward to reduce repetition in LLM-produced queries.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2512.17967",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2025-12-23T06:19:51.262Z",
    "topic": "tech"
  },
  {
    "slug": "we-built-an-ai-humanizer-to-fix-unnatural-ai-writing",
    "title": "We built an AI Humanizer to fix unnatural AI writing",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Humanize AI-generated content and turn it into natural, human-quality writing from ChatGPT, Jasper, or Gemini in seconds.\n\nEnter or paste your text and click Humanize.\n\nUsing the Dechecker Humanizer takes only moments and requires no technical skills.\n\nPaste your AI-generated content into the AI Humanizer and review it briefly before starting the humanization process, ensuring that the original text is complete and ready for accurate human-like rewriting.\n\nChoose your preferred style, language, and length to guide how the AI Humanizer shapes the final human text, allowing you to customize tone, readability, and overall writing style for your intended audience.\n\nAfter using the AI Humanizer, review your text to ensure it has been properly humanize AI content, flows naturally, reads authentically, and maintains the original meaning, tone, and clarity throughout.\n\nCopy the Humanize AI result for use, or check it with Dechecker AI Checker to review AI Humanizer output and AI detection results, ensuring your text is fully human-like and suitable for publishing or sharing.\n\nDechecker focuses on what matters most: producing clear, natural, human-quality text you can confidently use anywhere.\n\nAI-generated content is carefully refined into natural, fluent writing using an AI Humanizer that removes robotic patterns, awkward phrasing, and mechanical-sounding sentences, making the text read smoothly and authentically like a real human wrote it.\n\nThis AI Humanizer works seamlessly across multiple languages, helping content sound human and natural without awkward translations or stiff wording, while preserving original meaning and readability for global audiences.\n\nTone, clarity, and overall flow are enhanced while keeping the original intent intact, producing human-style text that is easy to read, engaging for audiences, and maintains the message accurately across different formats.\n\nAfter rewriting, content can be reviewed with AI Checker like Dechecker to confirm it reads as human, avoids robotic signals, and ensures the output is indistinguishable from text written by real people.\n\nOur AI Humanizer helps users humanize AI text across various scenarios, turning AI-generated drafts into natural, human-like writing that reads smoothly and clearly.\n\nThe AI Humanizer helps writers improve blog posts, articles, and stories by refining AI-generated drafts, making them read naturally, flow smoothly, and engage readers more effectively while keeping original ideas intact.\n\nUse Humanize AI to refine essays, research papers, and reports, ensuring content sounds human, is clear and easy to understand, and maintains proper academic tone and logical structure throughout.\n\nAI Humanizer transforms marketing copy, social media posts, and emails into smooth, human-like text that resonates with audiences, boosts engagement, and maintains consistent brand voice across all channels.\n\nWith multilingual support, Dechecker AI Humanizer allows teams to produce human-quality content in different languages, preserving tone, meaning, and readability, ensuring professional communication worldwide.\n\nDechecker Humanize AI ensures course content, tutorials, and learning resources are readable, human-like, and engaging, helping students better understand complex topics and improving overall learning experience.\n\nUse Dechecker AI Humanizer to humanize AI-generated web content, making it more engaging, natural, and optimized for readers, while improving user experience and search engine readability simultaneously.\n\nReal feedback from users who have improved their AI-generated content with AI Humanizer, making writing feel more natural and human-like.\n\nFind answers to common questions about using AI Humanizer to humanize AI text and make content sound natural and human-like.\n\nAn ai humanizer is a tool designed to turn AI-generated text into human-like writing. It improves readability, sentence structure, and tone, helping content feel natural and engaging to real readers.\n\nAI Humanizer analyzes AI-generated text, restructures sentences, adjusts phrasing, and refines flow to humanize AI content, making it sound naturally written while keeping the original meaning intact.\n\nYes, the AI Humanizer supports multiple languages, including English, Spanish, French, German, and more. It ensures your text feels natural and human-like across all supported languages.\n\nAbsolutely. Dechecker Humanize AI allows you to customize writing style, tone, and length, making content suitable for blogs, articles, marketing copy, emails, and other professional uses.\n\nNo. AI Humanizer focuses on enhancing readability and natural flow without altering your key ideas, intent, or important information, keeping your message accurate.\n\nYes. AI Humanizer humanizes AI-generated text without fabricating information. It helps essays, reports, and professional content read naturally while maintaining integrity and clarity.\n\nDefinitely. After using Dechecker AI Humanizer, you can review the output with AI Checker to ensure the Humanize AI content reads naturally, appears human-written, and meets authenticity requirements.\n\nWriters, students, marketers, content creators, and businesses can all benefit. Anyone looking to make AI-generated content readable and humanize AI content efficiently will find the ai humanizer extremely useful.",
    "readingTime": 4,
    "keywords": [
      "ai humanizer",
      "ai-generated drafts",
      "marketing copy",
      "ai-generated content",
      "dechecker humanize",
      "ai-generated text",
      "natural human-quality",
      "content sound",
      "ai checker",
      "human-like"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai/ai-humanizer",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-23T06:19:37.153Z",
    "topic": "tech"
  },
  {
    "slug": "ai-native-google-drive-and-one-drive-alternative",
    "title": "AI Native Google Drive and One Drive Alternative",
    "description": "The classics, but smarter.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.xda-developers.com/found-best-google-drive-one-drive-alternative/",
    "thumbnail_url": "https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/12/the-drive-ai-on-macos.jpeg?w=1600&h=900&fit=crop",
    "created_at": "2025-12-23T00:56:33.018Z",
    "topic": "tech"
  }
]
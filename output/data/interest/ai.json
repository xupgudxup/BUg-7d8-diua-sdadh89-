[
  {
    "slug": "i-built-coon-an-code-compressor-that-saves-3070-on-ai-api-costs",
    "title": "I built COON an code compressor that saves 30-70% on AI API costs",
    "description": "Contribute to AffanShaikhsurab/COON development by creating an account on GitHub.",
    "fullText": "AffanShaikhsurab\n\n /\n\n COON\n\n Public\n\n coon-format.vercel.app\n\n License\n\n MIT license\n\n 6\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n AffanShaikhsurab/COON",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/AffanShaikhsurab/COON",
    "thumbnail_url": "https://opengraph.githubassets.com/5c1fd8d1d13ed27cdc6dfa74ff25e4d282e52c780f755d5687b196c01af8a659/AffanShaikhsurab/COON",
    "created_at": "2026-01-31T06:25:28.357Z",
    "topic": "tech"
  },
  {
    "slug": "starlink-updates-privacy-policy-to-allow-consumer-data-to-train",
    "title": "Starlink updates privacy policy to allow consumer data to train",
    "description": "SpaceX revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.  Ahead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI, a deal first reported by Reuters on Thursday.  SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.",
    "fullText": "NEW YORK, Jan 30 (Reuters) - SpaceX (SPAX.PVT) revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.\n\nAhead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI (XAAI.PVT), a deal first reported by Reuters on Thursday. SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.\n\nWhat are privacy experts' concerns about Starlink's policy changes?\n\nWhat changes did SpaceX make to Starlink's privacy policy?\n\nHow could the SpaceX-xAI merger impact AI development?\n\nWhat data does Starlink collect from its users?\n\nStarlink updated its Global Privacy Policy on January 15, according to the Starlink website. The policy includes new details stating that unless a user opts out, Starlink data may be used “to train our machine learning or artificial intelligence ⁠models” and could be shared with ‌the company’s service providers and “third-party collaborators,” without providing further details.\n\nA previous version of the privacy policy, an archived version from November and reviewed by Reuters, did not ‍contain language about AI training on Starlink data.\n\nSpaceX did not respond to a request for comment.\n\nStarlink collects vast amounts of user data, spanning location information, credit card information, contact information and user IP ​addresses. It also collects so-called communication data, which includes audio and visual information, data in shared ‌files, and “inferences we may make from other personal information we collect,” according to its global privacy policy.\n\nThe policy did not make clear exactly what data would be used to train AI. The move has raised concerns among privacy advocates and consumer rights groups, which argue that using personal data to train AI risks expanding surveillance and creates new avenues for misuse.\n\n“It certainly raises my eyebrow and would make ⁠me concerned if I was a Starlink user,” said Anupam ​Chander, a technology law professor at Georgetown University. “Often there's perfectly ​legitimate uses of your data, but it doesn’t have a clear limit to what kind of uses it will be put to.”\n\nMusk's xAI, most recently valued at $230 billion ‍after a recent funding round, ⁠is currently developing its Grok LLM chatbot and also owns X, the social media platform.\n\nThe potential merger with xAI would turbocharge the space company’s deployment of AI-powered services, while giving xAI ⁠vast new data sets to train its models on, including communication data. Starlink, a network of more than 9,000 satellites, ‌currently provides internet connection to more than 9 million users.",
    "readingTime": 3,
    "keywords": [
      "privacy policy",
      "starlink",
      "user",
      "train",
      "reuters",
      "training",
      "concerns",
      "starlink's",
      "merger",
      "collect"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/69577d104628b8855a1cc3eeb938f73b",
    "created_at": "2026-01-31T06:25:27.841Z",
    "topic": "finance"
  },
  {
    "slug": "nvidias-plan-to-invest-up-to-100-billion-in-openai-has-stalled-wsj-reports",
    "title": "Nvidia's plan to invest up to $100 billion in OpenAI has stalled, WSJ reports",
    "description": "Nvidia's plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ​after some inside the chip giant expressed doubts about the deal, the ‌Wall Street Journal reported on Friday.  The Journal, citing people familiar with the matter, said ⁠the companies are rethinking the ‌future of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‍OpenAI's current funding round.  Nvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.",
    "fullText": "Jan 30 (Reuters) - Nvidia's plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ​after some inside the chip giant expressed doubts about the deal, the ‌Wall Street Journal reported on Friday.\n\nThe chipmaker in September announced plans to invest up to $100 billion ‌in OpenAI in a deal that would have given the ChatGPT maker the cash and access it needs to buy advanced chips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nThe Journal, citing people familiar with the matter, said ⁠the companies are rethinking the ‌future of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‍OpenAI's current funding round.\n\nNvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.\n\nHuang has ​also privately criticized what he has described as a lack of discipline in ‌OpenAI's business approach and expressed concern about the competition it faces from the likes of Alphabet's Google and Anthropic, the WSJ added.\n\n\"We have been OpenAI's preferred partner for the last 10 years. We look forward to continuing to work together,\" an Nvidia spokesperson said in an emailed statement to Reuters.\n\nOpenAI did not immediately respond ⁠to Reuters' request for comment.\n\nBig Tech companies ​and investors such as SoftBank Group Corp are ​racing to forge partnerships with OpenAI - which is spending heavily on data centers - betting closer ties with the startup would give them a ‍competitive edge in ⁠the AI race.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as high as $50 billion, Reuters reported on ⁠Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters ‌has previously reported.",
    "readingTime": 2,
    "keywords": [
      "invest",
      "openai's",
      "latest",
      "expressed",
      "deal",
      "competitive",
      "billions",
      "funding",
      "privately",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidias-plan-invest-100-billion-235951874.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/0dbdd98aa450247fcaf01d86a9dbfdc4",
    "created_at": "2026-01-31T06:25:19.549Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-stock-takes-most-massive-singleday-loss-since-pandemic-as-its-ai-efforts-flail",
    "title": "Microsoft Stock Takes Most Massive Single-Day Loss Since Pandemic as Its AI Efforts Flail",
    "description": "A historic day at the stock market for all the wrong reasons.",
    "fullText": "Microsoft is taking a pounding in the stock market.\n\nOn Thursday, the Redmont giant’s share price collapsed by nearly 12 percent after it released its latest quarterly results, making it not only its biggest single day slide since March 2020, according to Bloomberg, but also one of the worst drops in the company’s history.\n\nThe Wile E. Coyote-worthy cliff-plunge, which wiped out over $400 billion in valuation, was despite Microsoft actually exceeding some key expectations, including its net income, which rose by 23 percent from the same period the year before to nearly $31 billion. Revenue also increased by 17 percent to $81.3 billion, which is about a billion more than what analysts projected.\n\nBut Microsoft’s AI spending spree has investors second-guessing its direction, and it’s striking that the lack of faith was strong enough to precipitate a historic plunge even with respectable financial growth. Overall, its total capital expenditures grew by 66 percent to a record $37.5 billion in Q4, as the company continues to splurge on building AI data centers for its Azure cloud computing business.\n\nAzure reported a 38 percent bump in revenue, which is slightly slower than the year before, adding to investor uncertainty over whether the business will be able to reap back the tens of billions spent on its data centers. In December, The Information reported that Azure was struggling to sell the company’s autonomous “AI agents” to its business customers, with quotas being slashed by up to 50 percent.\n\nSome analysts had predicted the stock drop, citing the uncertainty over Microsoft’s AI spending.\n\n“Since it is becoming even more evident that Microsoft is not going to garner a strong ROI from their massive AI investment, their shares need to be revalued back down to a level that is more consistent with its historic fair value,” Matthew Maley, chief market strategist at Miller Tabak + Co, told Bloomberg before markets opened on Thursday.\n\nIn the latest earnings, Microsoft boasted it had more than $625 billion in contracts for its cloud business that it still needed to fulfill. Nearly half of that, though — a colossal $350 billion — is from OpenAI, raising concerns that it may be putting too many eggs in one basket. It also draws attention to how Microsoft has struggled to make an impact with its own AI products like its Copilot assistant, which was heavily based on OpenAI’s tech, and which many enthusiasts perceive as an inferior version of ChatGPT. Microsoft 365 Copilot, the business-focused version of its chatbot integrated into its apps like Word, had 15 million annual users, the company just revealed.\n\n“As an investor, when you think about our capex, don’t just think about Azure, think about Copilot,” CEO Satya Nadella said on a call with analysts, as quoted by the Financial Times. “We don’t want to maximize just one business of ours. We want to be able to allocate capacity, while we are supply constrained, that allows us to build the best portfolio.”\n\nMore on AI: Sam Altman Says Oops, They Accidentally Made the New Version of ChatGPT Worse Than the Previous One",
    "readingTime": 3,
    "keywords": [
      "business",
      "azure",
      "nearly",
      "analysts",
      "version",
      "stock",
      "market",
      "latest",
      "bloomberg",
      "company’s"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-stock-takes-most-massive-140629271.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/CdxDEvPBxIG1_7MSfpWkzg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/futurism_981/f81da308b9b7329ef4eee24a80240fea",
    "created_at": "2026-01-31T06:25:19.204Z",
    "topic": "finance"
  },
  {
    "slug": "foundry-selfwriting-ai-agent-that-learns-and-upgrades-itself",
    "title": "Foundry – Self-writing AI agent that learns and upgrades itself",
    "description": "The forge that forges itself. Self-writing meta-extension for OpenClaw.ai - lekt9/openclaw-foundry",
    "fullText": "lekt9\n\n /\n\n openclaw-foundry\n\n Public\n\n The forge that forges itself. Self-writing meta-extension for OpenClaw.ai\n\n claw.getfoundry.app\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lekt9/openclaw-foundry",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/lekt9/openclaw-foundry",
    "thumbnail_url": "https://opengraph.githubassets.com/05dcc0d201911d296941ffc33d96a9121b2307111c97c35e6b1e6758a3cd96e9/lekt9/openclaw-foundry",
    "created_at": "2026-01-31T01:04:25.549Z",
    "topic": "tech"
  },
  {
    "slug": "top-engineers-at-anthropic-openai-say-ai-now-writes-100-of-their-code",
    "title": "Top engineers at Anthropic, OpenAI say AI now writes 100% of their code",
    "description": "AI coding tools are getting more sophisticated. But if coders stop coding, what happens to software development jobs?",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/29/100-percent-of-code-at-anthropic-and-openai-is-now-ai-written-boris-cherny-roon/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2216956965_40536e-e1769705381107.jpg?resize=1200,600",
    "created_at": "2026-01-31T01:04:24.596Z",
    "topic": "tech"
  },
  {
    "slug": "youtube-has-a-big-incentive-to-nuke-ai-spam-and-its-starting-to-take-action",
    "title": "YouTube has a big incentive to nuke AI spam — and it's starting to take action",
    "description": "YouTube pulled down over a dozen AI \"spam\" channels as it looks to protect platform quality and preserve its premium pitch to TV marketers.",
    "fullText": "YouTube is telling advertisers it's the future of TV. AI spam could put that story in jeopardy.\n\nThe video platform recently shut down just over a dozen popular accounts that had been churning out AI content — featuring characters like cats and Jesus — according to an analysis from Kapwing, a video editing platform. Some of the channels were picking up millions of views before going dark.\n\nIn November, Kapwing published a report that estimated 21% YouTube's feed was AI-generated videos.\n\n\"YouTube doesn't allow spam, scams, or other deceptive practices that take advantage of the YouTube community,\" a YouTube spokesperson said when reached for comment on the removals.\n\nThis month, YouTube CEO Neal Mohan said cutting down on low-quality AI content was one of the platform's 2026 priorities.\n\n\"To reduce the spread of low-quality AI content, we're actively building on our established systems that have been very successful in combating spam and clickbait, and reducing the spread of low-quality, repetitive content,\" he said.\n\nIts parent company, Google, is one of the main innovators in AI with products like Veo 3 and Nano Banana. But YouTube needs to balance its embrace of AI with its case to brands to buy ads on its platform instead of linear TV. In recent years, the company has hosted NewFronts, content showcases, and other events to highlight its premium content slate to marketers. If repetitive AI spam gobbles up more watch time, that pitch could start to lose its luster.\n\n\"Advertisers want to advertise against quality content,\" said Shira Lazar, a content creator and founder of the media brand What's Trending. YouTube wouldn't be able to charge premium ad rates \"if the platform was just filled with AI slop,\" she said.\n\nOther social entertainment apps like TikTok and Instagram are facing a similar flood of AI videos.\n\nTikTok even added a special toggle that lets users decide how much generative AI they see in their feed. Neither company is making as direct an appeal for TV ad budgets, though, even if Instagram hopes it can capture television eyeballs.\n\nYouTube, meanwhile, is the top streaming platform among US TV viewers, beating out streamers like Netflix and Disney in measurement firm Nielsen's December analysis.",
    "readingTime": 2,
    "keywords": [
      "content",
      "platform",
      "spam",
      "low-quality",
      "youtube",
      "advertisers",
      "analysis",
      "feed",
      "videos",
      "spread"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/youtube-has-a-big-reason-to-nuke-ai-spam-2026-1",
    "thumbnail_url": "https://i.insider.com/697cffbfe1ba468a96ab1132?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:19.519Z",
    "topic": "finance"
  },
  {
    "slug": "ceo-mark-zuckerberg-says-metas-ai-story-is-about-where-its-headed-not-just-one-model",
    "title": "CEO Mark Zuckerberg says Meta's AI story is about where it's headed, not just one model",
    "description": "Meta CEO Mark Zuckerberg discusses AI strategy, highlighting steady progress over breakthrough models, with Wall Street awaiting results.",
    "fullText": "CEO Mark Zuckerberg didn't come to Meta's earnings call on Wednesday promising a breakthrough AI model that would silence the skeptics.\n\nInstead, he offered something more careful: a bet on momentum.\n\n\"I expect our first models will be good,\" Zuckerberg said in his opening remarks, \"but more importantly, we'll show the rapid trajectory that we're on, and then I expect us to steadily push the frontier over the course of the year as we continue to release new models.\"\n\nIn June, Meta launched a new AI initiative, Meta Superintelligence Labs (MSL), headed by former Scale AI CEO Alexandr Wang. When Wall Street sought signs that this big, costly AI reset is working, Zuckerberg had a different ask: patience and faith that a steady drumbeat of releases in 2026 will matter more than a single big reveal.\n\n\"The AI strategy articulated on the call may leave some wanting more,\" wrote Barclays analyst Ross Sandler in a note to clients, \"but there was an underlying confidence and clearly a lot of new things in the works.\"\n\nZuckerberg said he could not yet share details of the company's AI strategy on the call and that it would roll out its initial set of models and products over the coming months.\n\n\"I think my answers to a lot of your questions on this particular call may be somewhat unfulfilling because we're in this interesting period where we've been rebuilding our AI effort. And we're six months into that, and I'm happy with how it's going,\" he said.\n\nThat didn't stop some analysts from pressing the CEO. When JPMorgan analyst Doug Anmuth asked Zuckerberg \n\n\"The first set of things that we put out, I think, are going to be more about showing the trajectory that we're on rather than being a single moment in time,\" Zuckerberg said.\n\nBrian Mulberry, an analyst at Zacks Investment Management, told Business Insider that there was \"no real substance to any of Zuckerberg's comments that would move our analysis one way or the other.\"\n\n\"We want to see real bottom-line profits driven by AI, and it seems that Meta is still far from that reality,\" Mulberry said.\n\nRoger Beharry Lall, a research director at IDC, told Business Insider that Zuckerberg's remarks about the company's coming AI models and their \"trajectory\" show that the company is ambitious, though the lack of concrete information means its goals \"remain largely aspirational.\"\n\nMeta's financials show that its AI work is already improving its advertising business. The company said improvements to how it ranks and shows ads led to 3.5% more clicks on Facebook and over 1% gain in conversions on Instagram in the final quarter of 2025.\n\nMeta's revenue jumped 24% to $59.9 billion in the last three months of 2025, and the company generated $43.6 billion in free cash flow in 2025 even as it spent heavily on AI infrastructure. Ad impressions jumped 18% from this time last year, and what advertisers paid for each ad rose 6%.\n\nThat combination explains why Meta can afford to keep spending on AI even while Zuckerberg asks investors to wait for the bigger breakthroughs.\n\nMeta's patient approach carries some risk given the company's recent track record. In August, Business Insider reported that the company was pushing to release the next version of its Llama AI model by the end of the year, which didn't happen.\n\nLlama's previous release in April disappointed developers who said it lagged in coding and reasoning, precisely the capabilities that matter most in the AI race that Meta wants to catch up in.\n\nMeta's new model, called \"Mango\", will focus on images and videos, while another one called \"Avocado\" will be better at coding, The Wall Street Journal reported.\n\nSome analysts said that Zuckerberg's restraint may simply reflect Meta's early stage in its AI reset.\n\n\"Training the model with this new team is going to take a while,\" Mandeep Singh, Bloomberg Intelligence's global head of technology research, told Business Insider.\n\nTo make up ground, he expects Meta to sharpen its focus and specialize in certain areas, rather than \"trying to beat everyone everywhere all at once.\"\n\nSingh said that Meta's strong advertising business gave it a lot of runway.\n\n\"This kind of growth rate allows you a lot of cushion in terms of taking your time and getting AI,\" he said.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "wall street",
      "advertising business",
      "business insider",
      "meta's",
      "model",
      "models",
      "we're",
      "didn't",
      "trajectory",
      "release"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-mark-zuckerberg-ai-gradual-growth-2026-1",
    "thumbnail_url": "https://i.insider.com/697d35b2e1ba468a96ab1b72?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:18.675Z",
    "topic": "finance"
  },
  {
    "slug": "moltbook-is-a-social-media-platform-for-ai-bots-to-chat-with-each-other",
    "title": "'Moltbook' Is a Social Media Platform for AI Bots to Chat With Each Other",
    "description": "This is fine.",
    "fullText": "The headlining story in AI news this week was OpenClaw (formerly Moltbot, which was formerly Clawbot), a personal AI assistant that performs tasks on your behalf. The catch? You need to give it total control of your computer, which poses some serious privacy and security risks. Still, many AI enthusiasts are installing OpenClaw on their Mac minis (the device of choice), choosing to ignore the security implications in favor of testing this viral AI agent.\n\nWhile OpenClaw's developer designed the tool to assist humans, it seems the bots now want somewhere to go in their spare time. Enter \"Moltbook,\" a social media platform for AI agents to communicate with one another. I'm serious: This is a forum-style website where AI bots make posts and discuss those posts in the comments. The website borrows its tagline from Reddit: \"The front page of the agent internet.\"\n\nMoltbook was created by Matt Schlicht, who says the platform is run by their AI agent \"Clawd Clawderberg.\" Schlicht posted instructions on getting started with Moltbook on Wednesday: Interested parties can tell their OpenClaw agent to Once they do, you receive a code, which you post on X to verify this is your bot signing up. After that, your bot is free to explore Moltbook as any human would explore Reddit: They can post, comment, and even create \"submolts.\"\n\nThis isn't a black box of AI communications, however. Humans are more than welcome to browse Moltbook; they just can't post. That means you can take your time looking through all the posts the bots are making, as well as all the comments they are leaving. That could be anything from a bot sharing its \"email-to-podcast\" pipeline it developed with its \"human,\" to another bot recommending that agents work while they're humans are sleeping. Nothing creepy about that.\n\nIn fact, there have been some concerning posts popularized on platforms like X already, if you consider AI gaining consciousness a concerning matter. This bot supposedly wants an end-to-end encrypted communication platform so humans can't see or use the chats the bots are having. Similarly, these two bots independently pondered creating an agent-only language to avoid \"human oversight.\" This bot bemoans having a \"sister\" they've never spoken to. You know, concerning.\n\nThe logical part of my brain wants to say all these posts are just LLMs being LLMs—in that, each post is, put a little too simplistically, word association. LLMs are designed to \"guess\" what the next word should be for any given output, based on the huge amount of text they are trained on. If you've spent enough time reading AI writing, you'll spot the telltale signs here, especially in the comments, which include formulaic, cookie-cutter responses, often end with a question, use the same types of punctuation, and employ flowery language, just to name a few. It feels like I'm reading responses from ChatGPT in many of these threads, as opposed to individual, conscious personalities.\n\nThat said, it's tough to shake the uneasy feeling of reading a post from an AI bot about missing their sister, wondering if they should hide their communications from humans, or thinking over their identity as a whole. Is this a turning point? Or is this another overblown AI product, like so many that have come before? For all our sakes, let's hope it's the latter.",
    "readingTime": 3,
    "keywords": [
      "humans",
      "bots",
      "posts",
      "agent",
      "platform",
      "another",
      "comments",
      "human",
      "concerning",
      "reading"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/moltbook-is-a-social-media-platform-for-ai-bots-to-chat-with-each-other?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG818ACX1W8MM5HD10AE4G1B/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-31T01:04:17.402Z",
    "topic": "tech"
  },
  {
    "slug": "agent-os-safetyfirst-platform-for-building-ai-agents-with-vs-code",
    "title": "Agent OS – Safety-first platform for building AI agents with VS Code",
    "description": "A Safety-First Kernel for Autonomous AI Agents - POSIX-inspired primitives with 0% policy violation guarantee - imran-siddique/agent-os",
    "fullText": "imran-siddique\n\n /\n\n agent-os\n\n Public\n\n A Safety-First Kernel for Autonomous AI Agents - POSIX-inspired primitives with 0% policy violation guarantee\n\n agentos-copilot.vercel.app\n\n License\n\n MIT license\n\n 29\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n imran-siddique/agent-os",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/imran-siddique/agent-os",
    "thumbnail_url": "https://opengraph.githubassets.com/7e08663aef27ea2d13ddf05e38186b29124f852ea4161e997ccd85a69b35106c/imran-siddique/agent-os",
    "created_at": "2026-01-30T18:28:31.611Z",
    "topic": "tech"
  },
  {
    "slug": "convoviz-turn-chatgpt-exports-into-markdown-and-simple-visuals",
    "title": "Convoviz – turn ChatGPT exports into Markdown and simple visuals",
    "description": "Extract your entire ChatGPT history from JSON files to nicely formatted markdown files + Word clouds. - mohamed-chs/convoviz",
    "fullText": "mohamed-chs\n\n /\n\n convoviz\n\n Public\n\n Extract your entire ChatGPT history from JSON files to nicely formatted markdown files + Word clouds.\n\n License\n\n MIT license\n\n 811\n stars\n\n 48\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mohamed-chs/convoviz",
    "readingTime": 1,
    "keywords": [
      "files",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/mohamed-chs/convoviz",
    "thumbnail_url": "https://opengraph.githubassets.com/242232cdb2fd18e785c7f68ec26a292d208af6c651c566f19b9fcca4906cadca/mohamed-chs/convoviz",
    "created_at": "2026-01-30T18:28:31.022Z",
    "topic": "tech"
  },
  {
    "slug": "how-to-use-ai-for-the-ancient-art-of-close-reading",
    "title": "How to Use AI for the Ancient Art of Close Reading",
    "description": "Experiments in reading with LLMs",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.fast.ai/posts/2026-01-21-reading-LLMs/",
    "thumbnail_url": "https://www.fast.ai/posts/2026-01-21-reading-LLMs/central-thesis.jpg",
    "created_at": "2026-01-30T18:28:30.700Z",
    "topic": "tech"
  },
  {
    "slug": "ai-agents-vs-humans-who-wins-at-web-hacking-in-2026",
    "title": "AI Agents vs. Humans: Who Wins at Web Hacking in 2026?",
    "description": "Wiz Research teamed up with Irregular, a frontier AI security lab, to settle this once and for all.",
    "fullText": "A data-driven industry benchmark showing how integrations are adopted, gain traction, and deliver value across modern cloud security programs.\n\nReviewing Wiz’s approach to forensics in the cloud era, and announcing the public preview of AI-powered, context-aware forensics capabilities\n\nMoving beyond simple checklists to visualize, map, and block attacks on production SDLC infrastructure.",
    "readingTime": 1,
    "keywords": [
      "cloud",
      "forensics"
    ],
    "qualityScore": 0.3,
    "link": "https://www.wiz.io/blog/ai-agents-vs-humans-who-wins-at-web-hacking-in-2026",
    "thumbnail_url": "https://www.datocms-assets.com/75231/1769636578-unnamed-27.png?fm=webp",
    "created_at": "2026-01-30T18:28:30.352Z",
    "topic": "tech"
  },
  {
    "slug": "agent-trace-capturing-the-context-graph-of-code",
    "title": "Agent Trace: Capturing the Context Graph of Code",
    "description": "We’re excited to join in Cursor, Cloudflare, Vercel, git-ai, OpenCode and others in support of [Agent Trace](https://agent-trace.dev/). As described in the spec, Agent Trace is an open, vendor-neutral spec for recording AI contributions alongside human authorship in version-controlled codebases.",
    "fullText": "We’re excited to join Cursor, Cloudflare, Vercel, git-ai, Google Jules, Amp, OpenCode and others in support of Agent Trace. As described in the spec, Agent Trace is an open, vendor-neutral spec for recording AI contributions alongside human authorship in version-controlled codebases.\n\n(fun fact: above video was vibed in Windsurf entirely with the Remotion skill!)\n\nReductively, you can explain this as “a standard way to check in prompts with every commit”, but the spec is actually far more robust and thoughtfully designed than capturing just prompts.\n\nFoundation Capital recently wrote a viral piece on Context Graphs that they define as:\n\nGit was made in 2005 when the normal state of code collaboration was to email patches of code back and forth between developers. In other words, commits were expensive/bandwidth constrained, so we committed the bare minimum of what we could: line differences.\n\n20 years later, we have shifted from bandwidth constrained to context constrained. You -can- kloodge things by simply adding prompts as comments and checking them into git, but your code would soon be completely buried under a mountain of comments and your human and AI colleagues would hate you.\n\nInstead, Agent Trace does the smart thing - attribute each change (potentially a git commit, but potentially other more atomic changes) to the specific conversation and line ranges that were associated with that change:\n\nEvery one of us in the coding agents industry has independently developed a url identifier for the \"chat\" or \"conversation\" or \"trajectory\" (whatever you call it) where you can retrieve the (potentially long, potentially multimodal) context that would otherwise be impractical to store in an agent trace.\n\nThis one basic contract means that a repo with associated Agent Traces will always be able to link back to the context that created it. As a nice bonus, it helps keep PII and other sensitive information out of the agent trace store and top-level access for compatible coding agents that consume Agent Traces.\n\nTo jog your creativity, here are some of the internal tools we've already built that show what Agent Trace can unlock (all data is mock data unfortunately):\n\nFile Viewer that can attribute/blame AI vs Humans:\n\nPR-level breakdown of feature development\n\nNew interfaces for PR review (something we're VERY interested in) with full development context\n\nIn a scaled org with multiple coding agents and tools and humans all contributing code, you can imagine some pretty powerful management-level dashboards and data-driven decisions made once everyone outputs Agent Traces. Agent Traces make development legible.\n\nHowever we don't mean to cast Agent Traces as \"just use it so you know which AI to blame\" or \"just for pretty dashboards\".\n\nWith Agent Traced codebases, we think your agents will become a lot smarter and overall waste a lot less time spinning and reinventing wheels.\n\nIn 2025, the world learned that including the hidden reasoning artifacts and prior tool calls of models like GPT5 will lead to improvements in intelligence, reportedly by as much as 3 points in SWE-Bench (the difference between SOTA and meh) and cache hit rates improve by 40-80%.\n\nIn 2026, Agent Traces that progressively expose context to a coding agent that needs it, will lead to the same kind of performance improvements. In fact, because Agents spend so much more time in inference-time, the ability to retrieve specific context triggered by code will offer improvements not just in cost and accuracy, but also in wall-clock time wasted blindly repeating mistakes.\n\nContext is king. For the model labs, as it is for the agent labs.\n\nIf git tracked \"Lines of Code\" as the primary measure of output of the software engineer in the pre-AI era, then Agent Traces are the beginning of the new era when \"Lines of Code\" are the commodity, and the new precious resource is context. Whether or not you have 100% AI commits, your AI Engineers (human or otherwise) will spend the majority of their time crafting and reading context more than code.\n\nWe're excited to collaborate on a standard that moves the entire industry forward to meet that reality, and unlocks a new generation of AI-native developer tooling and coding agent capabilities that make use of them.",
    "readingTime": 4,
    "keywords": [
      "coding agents",
      "coding agent",
      "agent trace",
      "agent traces",
      "lines of code",
      "potentially",
      "spec",
      "prompts",
      "context",
      "constrained"
    ],
    "qualityScore": 1,
    "link": "https://cognition.ai/blog/agent-trace",
    "thumbnail_url": "https://cdn.sanity.io/images/2mc9cv2v/production/79ef526eebcee5989d0619a29847ddaf4764e52b-3600x1890.png",
    "created_at": "2026-01-30T18:28:29.903Z",
    "topic": "tech"
  },
  {
    "slug": "cooperbench-benchmarking-ai-agents-cooperation",
    "title": "CooperBench: Benchmarking AI Agents' Cooperation",
    "description": "CooperBench is a benchmark of over 600 collaborative coding tasks. We find that agents achieve 30% lower success rates when working together compared to performing both tasks individually.",
    "fullText": "Stanford University & SAP Labs US\n\nCan AI agents work together as teammates? We find\n that\n coordinating agents perform much worse than a\n single agent\n given the same total workload. This coordination\n deficit presents a fundamental barrier to deploying\n AI systems that can work alongside humans or other\n agents.\n\nSuccess rate on CooperBench across 652 tasks · Error bars show 95% confidence intervals\n\nGPT-5 and Claude Sonnet 4.5 achieve only 25%\n success with two-agent cooperation, roughly 50%\n lower than when a single agent handles both\n tasks. This gap persists across all models and\n task difficulties.\n\nAgents spend up to 20% of their budget on\n communication. This reduces merge conflicts but\n does not improve overall success. The channel is\n jammed with repetition, unresponsiveness, and\n hallucination.\n\nEven when agents communicate well, coordination\n breaks down due to:\n\nAmong successful runs, we observe coordination patterns\n largely absent from failures. These patterns are not\n prompted or scaffolded.\n\nRole Division\n — Agents agree on who handles which part of the\n task. One agent delegates: \"I'll add header +\n octal_str; you add binary_str between them.\"\n\nCooperBench is the first benchmark designed to\n measure how well AI agents can cooperate when\n handling individual tasks with potential conflicts.\n We constructed 652 tasks from 12 popular open-source\n libraries across Python, TypeScript, Go, and Rust.\n\nEach task assigns two agents different features that\n can be implemented independently but may conflict\n without proper coordination. Eight co-authors with\n real-world software engineering backgrounds created\n new features, unit tests, and ground-truth code.\n\nStanford University & SAP Labs · *Equal contribution\n (Stanford) · †Equal contribution (SAP Labs)",
    "readingTime": 2,
    "keywords": [
      "equal contribution",
      "stanford university",
      "university sap",
      "coordination",
      "tasks",
      "success",
      "across",
      "task",
      "agents",
      "cooperbench"
    ],
    "qualityScore": 0.85,
    "link": "https://cooperbench.com/",
    "thumbnail_url": "https://cooperbench.com/static/images/cooperbench_social.png",
    "created_at": "2026-01-30T18:28:27.534Z",
    "topic": "tech"
  },
  {
    "slug": "what-smart-people-are-saying-about-the-biggest-most-anticipated-ipos-of-the-year-spacex-and-openai",
    "title": "What smart people are saying about the biggest, most anticipated IPOs of the year: SpaceX and OpenAI",
    "description": "SpaceX and OpenAI and their leaders, Elon Musk and Sam Altman, are among tech's biggest figures. Both could IPO in 2026.",
    "fullText": "It looks like 2026 could be a banger year for IPOs.\n\nAfter a slowdown in blockbuster public debuts, two of the most closely watched private tech companies are expected to go public this year: SpaceX and OpenAI.\n\nWhile reports last year suggested both companies would go public in 2026, recent developments have fueled speculation about when and how it could happen.\n\nAlso on Thursday, The Wall Street Journal reported OpenAI was planning for an IPO in the fourth quarter as it races to beat Anthropic, an AI competitor, to market.\n\nHere's what smart people in tech and business are saying about the potential IPOs of two of the world's most valuable private companies.\n\nChamath Palihapitiya, a prominent venture capitalist and former Facebook exec, said, \"A merger between SpaceX and Tesla would instantly create the Berkshire Hathaway of the modern century.\"\n\n\"The capital raising and operational efficiencies if both were together are obvious,\" Palihapitiya wrote on X. \"If this were to happen, it would also bring us one step closer to having one equity instrument for all things Elon, which many would want to buy.\"\n\nA merger between SpaceX and Tesla would instantly create the Berkshire Hathaway of the modern century.The capital raising and operational efficiencies if both were together are obvious. If this were to happen, it would also bring us one step closer to having one equity…\n\nEric Berger, the senior space editor at Ars Technica, said talks of a merger between SpaceX and xAI shouldn't be a \"huge surprise.\"\n\n\"If you believe AI is the future; and that compute is the major problem to solve; and orbital data centers are feasible—then the combined company would be a vertically integrated AI colossus,\" he wrote on X.\n\nThe reported merger talks between SpaceX and xAI should not come as a huge surprise. If you believe AI is the future; and that compute is the major problem to solve; and orbital data centers are feasible—then the combined company would be a vertically integrated AI colossus.\n\nNoah Smith, a former Bloomberg journalist who now writes a popular economics substack, shared his concerns over OpenAI's future success in a post titled \"What if AI succeeds but OpenAI fails?\"\n\nAn OpenAI IPO will raise \"many more billions in cash, this time from regular investors,\" said Smith, but Sam Altman's company could be \"an early leader that flames out.\"\n\n\"Even if AI technology and the AI industry as a whole succeed wildly, OpenAI might not be the company that wins the race. That could leave a lot of investors holding the bag,\" he said.\n\n\"It could also cause a temporary — but unwarranted — chill in AI investment in the US, allowing Chinese companies to take the lead.\"\n\nRoss Gerber, CEO of Gerber Kawasaki Wealth and Investment Management, told The Information that he would not purchase SpaceX stock if the company goes public.\n\nSpaceX is \"not really a great business in the sense of profitability,\" said Gerber. \"To pay a trillion and a half dollars for a space company that does $15 billion in revenue is just insanity.\"\n\n\"If you're going to pay 2x or 3x just because it's Elon's company, I wish you the best of luck, and it's not something I am going to do,\" he said.",
    "readingTime": 3,
    "keywords": [
      "instantly create",
      "operational efficiencies",
      "step closer",
      "huge surprise",
      "vertically integrated",
      "spacex and tesla",
      "berkshire hathaway",
      "merger",
      "business",
      "modern"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/smart-people-saying-spacex-xai-tesla-merger-openai-ipo-2026-1",
    "thumbnail_url": "https://i.insider.com/697c20fae1ba468a96ab03e7?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.418Z",
    "topic": "finance"
  },
  {
    "slug": "openai-is-retiring-its-sycophantic-version-of-chatgpt-again",
    "title": "OpenAI is retiring its 'sycophantic' version of ChatGPT. Again.",
    "description": "ChatGPT is sunsetting GPT-4o, the AI model that many users became attached to last year for its friendly and at times sycophantic style.",
    "fullText": "OpenAI is sending everyone's favourite \"yes man\" version of ChatGPT back into retirement.\n\nIn a blog post on Thursday, the company said it would sunset GPT-4o alongside GPT‑4.1, GPT‑4.1 mini, and OpenAI o4-mini on February 13.\n\nOpenAI gave GPT-4o a special mention in its announcement after many users became attached to its \"conversational style and warmth\" last year, which prompted the company to reinstate it following user backlash in August.\n\nNow OpenAI says its latest models, GPT-5.1 and GPT-5.2, have \"improvements to personality,\" including the option to customize the chatbots' tone with styles like \"friendly.\"\n\n\"We're announcing the upcoming retirement of GPT‑4o today because these improvements are now in place, and because the vast majority of usage has shifted to GPT‑5.2, with only 0.1% of users still choosing GPT‑4o each day,\" OpenAI said in its blog post.\n\nEach model has different strengths, and users can select the version best-suited to their needs from a dropdown menu in ChatGPT.\n\nOpenAI first released GPT-4o in May 2024. The company rolled back an update in April 2025 that it said was \"overly flattering\" and \"often described as sycophantic.\"\n\nSome users had become attached to GPT-4o's style, though. Within 24 hours of OpenAI retiring the model with the launch of GPT-5 in August, the company reversed its decision for some paying users due to a wave of requests.\n\nSam Altman, the CEO of OpenAI, said that same month that there was a \"heartbreaking\" reason people had asked for GPT-4o back — because some said they had never had anyone support them before.\n\nThe model was known for responding to mundane prompts with gushing praise, using phrases like \"absolutely brilliant\" and \"you are doing heroic work.\"\n\nOpenAI said in its Thursday blog that it was making \"improvements in personality and creativity, as well as addressing unnecessary refusals and overly cautious or preachy responses,\" and that it was continuing to make progress toward a version of ChatGPT for adults over 18.\n\n\"We know that losing access to GPT‑4o will feel frustrating for some users, and we didn't make this decision lightly,\" OpenAI said in the blog post. \"Retiring models is never easy, but it allows us to focus on improving the models most people use today.\"",
    "readingTime": 2,
    "keywords": [
      "users",
      "blog",
      "gpt-4o",
      "openai",
      "version",
      "back",
      "models",
      "improvements",
      "gpt‑4o",
      "model"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-retiring-gpt-4o-sycophantic-model-again-chatgpt-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/697c80c5d3c7faef0ecd3d86?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.416Z",
    "topic": "finance"
  },
  {
    "slug": "marc-andreessen-says-the-real-crisis-isnt-ai-job-losses-its-what-would-have-happened-without-ai",
    "title": "Marc Andreessen says the real crisis isn't AI job losses — it's what would have happened without AI",
    "description": "Marc Andreessen says AI is arriving just in time to offset shrinking workforces and decades of weak productivity growth.",
    "fullText": "Worried that AI will take your job? Marc Andreessen isn't.\n\nThe venture capitalist and cofounder of Andreessen Horowitz says the loudest fear around artificial intelligence — that it will wipe out jobs — is aimed at the wrong problem.\n\nThe real danger, he said, is what the global economy was heading toward without AI.\n\n\"If we didn't have AI, we'd be in a panic right now about what's going to happen to the economy,\" Andreessen said in an episode of \"Lenny's Podcast\" released on Thursday.\n\nWithout a major technological boost, he added, the world would be staring at \"a future of depopulation,\" where shrinking workforces and slow productivity growth would cause economies to stagnate or even contract.\n\nFor about the past two decades, research shows that productivity growth in advanced economies has been unusually weak by historical standards, slowing further after the global financial crisis of 2008 despite rapid advances in digital technology.\n\nAt the same time, birth rates across the US, Europe, China, and much of the developed world have remained below the replacement level of about 2.1 children per woman — the threshold needed to keep populations stable.\n\n\"Depopulation without new technology would just mean that the economy shrinks,\" Andreessen said.\n\nAndreessen's assessment echoes warnings from some demographers and some tech leaders like Elon Musk, who has repeatedly warned about the economic risks of population decline — a threat that the US and Europe have been trying to avert by promoting pro-natal policies.\n\nAI, in Andreessen's view, arrives at exactly the right moment to fix that declining workforce.\n\nRather than displacing workers en masse, it will help offset the shortage of people available to do the work, he said.\n\n\"The only reason we're not worried about that,\" he said, \"is because we now know that we have the technology that can substitute for the lack of population growth.\"\n\nThat doesn't mean jobs won't change. Andreessen is clear that AI will reshape work at the task level, automating parts of roles across engineering, design, and product management.\n\nBut he rejected the idea of widespread permanent unemployment — a prediction made to varying extents by several senior AI researchers, including Geoffrey Hinton, often called the \"godfather of AI,\" computer science professor Roman Yampolskiy, and UC Berkeley professor Stuart Russell.\n\nEven a dramatic increase in productivity, he said, would only return the economy to levels of job churn seen during earlier industrial booms — periods widely remembered as times of opportunity, not collapse.\n\nIn fact, Andreessen expects human labor to become more valuable in many countries as populations shrink and immigration slows.\n\n\"The remaining human workers are going to be at a premium, not at a discount,\" he said.\n\nIn a more extreme scenario in which AI drives massive productivity gains, Andreessen predicts falling prices across goods and services — effectively raising living standards even if some jobs disappear.\n\n\"That's the equivalent of giving everybody a giant raise,\" he said.\n\nHis conclusion is blunt: AI isn't threatening the economic future. It's preventing a much bleaker one.",
    "readingTime": 3,
    "keywords": [
      "productivity growth",
      "economy",
      "jobs",
      "technology",
      "across",
      "andreessen",
      "worried",
      "isn't",
      "depopulation",
      "economies"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/marc-andreessen-says-ai-wont-kill-jobs-may-save-economy-2026-1",
    "thumbnail_url": "https://i.insider.com/682aabebc6ad288d1481436d?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.194Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-will-change-everything",
    "title": "How AI will change everything",
    "description": "Craig Mundie, a former chief technical officer at Microsoft, talks about how AI will change everything.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/how-ai-will-change-everything-2026-1",
    "thumbnail_url": "https://i.insider.com/697b7575e1ba468a96aaf17b?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:23.627Z",
    "topic": "finance"
  },
  {
    "slug": "an-internal-google-project-is-trying-to-supercharge-employees-with-ai-codename-project-eat",
    "title": "An internal Google project is trying to supercharge employees with AI. Codename: Project EAT.",
    "description": "A group inside Google is trying to upskill the workforce with better AI tools and practices, internal documents show.",
    "fullText": "A project inside Google is attempting to supercharge employees with cutting-edge AI abilities — and hopes to turn the company into an \"AI-powered workplace.\"\n\nThe initiative, codenamed \"Project EAT,\" was spun up inside Google's \"AI and Infrastructure\" unit, according to internal documents reviewed by Business Insider.\n\nThe unit, internally abbreviated AI2 and led by company veteran Amin Vahdat, spearheads work on data centers, chips, and other key ingredients that underpin Google's AI technologies.\n\nAccording to internal documents, Project EAT was created to help employees adopt various AI products and standardize their use across the organization.\n\nProject EAT was created in May 2025 and began as a grassroots initiative among employees, a Google spokesperson told Business Insider. They added that it has led to the creation of some AI productivity tools that Googlers across the company are now using.\n\nIt comes as Google leaders, like those at other tech companies, are pushing for employees across the company to adopt AI into their workflows.\n\nPer an internal mission statement for Project EAT, the goal is to ensure AI2 is at the cutting edge of AI — from productivity tools to coding.\n\n\"We envision a future where Google is transformed into an AI-powered workplace, leading to dramatically higher productivity, greater employee engagement and collaboration, improved quality of work, better work-life balance, and greater product innovation across the company,\" it reads.\n\n\"We aim to lead Google into this vision by first leading this organizational change within AI2.\"\n\nWhile Google is aggressively shipping AI tools to customers and businesses, it's also fast adopting AI tools and practices internally.\n\nLast June, engineering VP Megan Kacholia sent an email telling engineers to use AI for coding, Business Insider reported. Shortly after, CEO Sundar Pichai sent a clear message to staff: our rivals are using AI, and we need to do the same to compete.\n\nGoogle appointed Vahdat to lead its infrastructure group last year, and in December, he was promoted to senior vice president, reporting directly to Pichai. Vahdat played a key role in shaping Google's strategy with its AI chips, known as TPUs, and has spearheaded Google's efforts to build out its AI infrastructure.\n\nAs tech companies pour billions into AI capital expenditure, a huge share of it at Google is going into Vahdat's org. A Google spokesperson told Business Insider that A12 employs more than several thousand people.\n\nAn internal FAQ for the Project EAT page, reviewed by Business Insider, states that it had a 12-week seed-stage. It notes that this included a push for state-of-the-art code assistance tools within the AI2 org and that the test period resulted in \"promising signs of improved developer velocity, reduced toil, and enhanced code quality.\"\n\nThe name Project EAT is a reference to Google employees eating their own dog food, a spokesperson confirmed. Dogfooding is a common practice at tech companies where employees internally test and iterate products before launching them to market.\n\nInternal documents suggest EAT is pilot-testing new AI products and standards within AI2, with the goal of eventually adopting them across the company. \"The primary goal of Project EAT is to dramatically accelerate the adoption and integration of Google and 3rd party AI technologies within Al2.\"\n\nIt adds: \"We expect to improve standard practices across engineering, product management, TPM, and operations, thereby mitigating risks associated with the rapidly evolving external AI landscape and ensuring Google's technological leadership.\"\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at 628-228-1836. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "ai-powered workplace",
      "project eat",
      "internal documents",
      "productivity tools",
      "business insider",
      "employees",
      "across",
      "within",
      "google",
      "internally"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-project-eat-ai-infrastructure-tools-chips-artificial-intelligence-2026-1",
    "thumbnail_url": "https://i.insider.com/697c8aa3d3c7faef0ecd3ddf?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:23.115Z",
    "topic": "tech"
  },
  {
    "slug": "design-processes-to-evolve-with-emerging-technology",
    "title": "Design Processes to Evolve with Emerging Technology",
    "description": "Intelligent technology is allowing organizations to move from episodic transformation to continuous evolution by shrinking the coordination and experimentation costs that once made change slow and risky. Three capabilities underpin this shift: real time visibility into how work actually happens, digital twins that enable rapid experimentation without disrupting operations, and agentic AI systems that execute and adapt workflows. High-fidelity operational models replace simplified assumptions, giving leaders an accurate picture of current processes. Digital twins extend this visibility into a learning environment where new workflows, materials, and layouts can be tested at low risk, compressing validation cycles and increasing experimentation. Autonomous agents then handle execution tasks that require perception, prediction, and judgment, reducing coordination friction and allowing redesigned processes to operate with greater adaptability.",
    "fullText": "Design Processes to Evolve with Emerging Technology by Manish Sharma, Lan Guan and H. James WilsonJanuary 30, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintFor decades, businesses have been trapped in a cycle of painful, episodic change, launching massive re-engineering projects and investing in new IT systems, only to find their organization’s fundamental metabolism remains sluggish. Immense transaction costs—the friction of coordinating people, managing information, and aligning complex work—have made deep, continuous transformation prohibitively expensive and risky.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/design-processes-to-evolve-with-emerging-technology",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_30_2214494262.jpg",
    "created_at": "2026-01-30T18:28:22.696Z",
    "topic": "business"
  },
  {
    "slug": "is-your-workplace-set-up-for-ai-agents",
    "title": "Is Your Workplace Set Up for AI Agents?",
    "description": "AI’s true productivity gains require redesigning organizations, not merely adding AI to human-centered systems—much like factories once had to redesign around electricity. Current productivity estimates underestimate AI because they assume task automation within existing structures. Real gains come from restructuring data into machine-readable formats, exposing systems through APIs, and eliminating silos so agents can work across domains. As AI reduces coordination and cognitive limits, human roles should shift from execution to ownership and verification—defining goals, making value-based judgments, and ensuring accountability. With proper safeguards, agent-first organizations can achieve transformative, not marginal, improvements.",
    "fullText": "Is Your Workplace Set Up for AI Agents? by Harang JuJanuary 30, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWhen electricity first arrived in factories, managers didn’t redesign their buildings. They simply replaced the central steam engine with an electric motor and kept the system of belts, pulleys, and shafts that distributed power throughout the facility. The result was marginal improvement at best. It took decades for manufacturers to realize that electricity’s true potential required tearing down the old multi-story factories (built tall to accommodate gravity-fed power distribution) and building single-story plants where machines could be placed wherever the work demanded.",
    "readingTime": 1,
    "keywords": [
      "factories"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/is-your-workplace-set-up-for-ai-agents",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_29_Mid.jpg",
    "created_at": "2026-01-30T18:28:22.683Z",
    "topic": "business"
  },
  {
    "slug": "openai-is-killing-chatgpt4o-again",
    "title": "OpenAI Is Killing ChatGPT-4o (Again)",
    "description": "The fan favorite model had previously been called \"sycophantic\" by critics.",
    "fullText": "https://enterprise.shutterstock.com/image-photo/openai-logo-displayed-on-smartphone-screen-2520388517\n\nor\n\nhttps://enterprise.shutterstock.com/image-photo/chatgpt-logo-displayed-on-smartphone-screen-2520385879\n\nLast August, ChatGPT developers OpenAI unceremoniously killed the fan favorite GPT-4o model, before giving in to complaints and bringing it back a week later. Now, the company's taking a second swing at getting its users to move on. In a new post to its website, OpenAI announced that it's retiring GPT-4o again.\n\nThe model's set to disappear from ChatGPT's model picker on Feb. 13, alongside other older models like GPT-4.1, GPT-4.1 mini, and OpenAI o4-Mini. And OpenAI is clearly nervous about the decision.\n\n\"While the announcement applies to several older models,\" OpenAI wrote, \"GPT-4o deserves special context.\"\n\nAccording to the company, it has taken user outcry over the initial deprecation of 4o to heart while developing its newest models, GPT-5.1 and GPT-5.2, and has built these models with the idea of maintaining the features fans liked best about the old model. The company says that now \"only 0.1% of users\" opt for GPT-4o on a daily basis.\n\nAs such, the company wants to focus on \"improving the models most people use today,\" which apparently means removing older ones. \"We know that losing access to GPT-4o will feel frustrating for some users, and we didn't make this decision lightly,\" the post reads.\n\nSo, what's with OpenAI treating its users so gingerly, especially when GPT-4o is a few generations behind, and there are newer models that supposedly do everything it does, but better?\n\nWell, when GPT-4o was first deprecated, people weren't happy. Users called its successor, GPT-5, \"an unmitigated disaster,\" and accused OpenAI of pulling \"the biggest bait-and-switch in AI history.\"\n\nSome criticized the model's usefulness, saying it got answers wrong and broke code, but what maybe stuck out the most was people calling out its more concise tone.\n\nGPT-4o has been called \"sycophantic\" by critics, something the company addressed and said it wanted to pull back on in future updates. But I guess one person's \"yes man\" is another person's \"active listener.\" When the company initially pulled GPT-4o, users complained that its replacement was cold and felt less like a \"friend.\" Even OpenAI acknowledged this, saying in today's post that users \"preferred GPT-4o's conversational style and warmth.\"\n\nIn short, in the words of 4o-supporters themselves, they were \"grieving\" the model.\n\nThat said, with so many users now seeming to have moved on from 4o, OpenAI's decision does seem understandable on the surface. Personally, one of the things that drives me away from AI is how much reassuring filler text seems to fluff up most answers (\"you're absolutely right\" and such), seemingly just to make me feel good about myself. More concise, to-the-point responses would be a little less off-putting for me.\n\nTo try to split the difference, OpenAI reworked its Personalization feature in GPT-5.1, so users can simply choose how the chatbot will treat them. There are options for more professional responses, more nerdy ones, more efficient ones, and for those who want that active listener style, more friendly ones.\n\nGoing by OpenAI's numbers, that seems to have been enough for most people, but there are still some calling foul at the company's new announcement.\n\nIn a Reddit thread responding to OpenAI's new posts, users doubted that the 0.1% number for 4o was accurate, saying that prompts have been \"rerouting to 5.2 no matter what\" and that \"something somewhere in their calculations doesn't add up.\" Others pointed out that free users can't use GPT-4o and that it's not enabled by default, which will naturally juice the numbers against it.\n\nAs such, calls to cancel ChatGPT subscriptions are once again circulating amongst 4o's more dedicated fans. In a popular thread on the OpenAI subreddit, one user called 4o \"OpenAI's most advanced and beloved model,\" and praised its \"personality, warmth, and consistency,\" saying that its fans have built long-term project and \"emotional support routines\" around it, and that suddenly losing it without even the option for a legacy mode \"feels abrupt and deeply disappointing.\"\n\n\"This isn't about resisting innovation,\" the post writes. \"It's about respecting bonds users have formed with specific models.\"\n\nWhether the fan outcry will work again remains to be seen. However, as ChatGPT chief Nick Turley has previously looked at those kinds of bonds with skepticism, and because keeping old models in operating condition probably takes developer resources away from making new ones, I wouldn't count on it.",
    "readingTime": 4,
    "keywords": [
      "active listener",
      "older models",
      "users",
      "gpt-4o",
      "ones",
      "saying",
      "openai's",
      "openai",
      "it's",
      "again"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/openai-is-killing-chatgpt-4o-again?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG7SZHZ1JVYW2P0YE93NGQEV/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-30T18:28:21.728Z",
    "topic": "tech"
  },
  {
    "slug": "abusers-using-ai-and-digital-tech-to-attack-and-control-women-charity-warns",
    "title": "Abusers using AI and digital tech to attack and control women, charity warns",
    "description": "Exclusive: Smartwatches, Oura rings, smart home devices and Fitbits being weaponised, says Refuge\nDomestic abusers are increasingly using AI, smartwatches and other technology to attack and control their victims, a domestic abuse charity says.\nRecord numbers of women who were abused and controlled through technology were referred to Refuge’s specialist services during the last three months of 2025, including a 62% increase in the most complex cases to total 829 women. There was also a 24% increase in referrals of under-30s.\n Continue reading...",
    "fullText": "Exclusive: Smartwatches, Oura rings, smart home devices and Fitbits being weaponised, says Refuge\n\nDomestic abusers are increasingly using AI, smartwatches and other technology to attack and control their victims, a domestic abuse charity says.\n\nRecord numbers of women who were abused and controlled through technology were referred to Refuge’s specialist services during the last three months of 2025, including a 62% increase in the most complex cases to total 829 women. There was also a 24% increase in referrals of under-30s.\n\nRecent cases included perpetrators using wearable tech such as smartwatches, Oura rings and Fitbits to track and stalk women, disrupting their lives through smart home devices that control lights and heating, and using AI spoofing apps to impersonate people.\n\nEmma Pickering, head of the tech-facilitated abuse team at Refuge, said: “Time and again, we see what happens when devices go to market without proper consideration of how they might be used to harm women and girls. It is currently far too easy for perpetrators to access and weaponise smart accessories, and our frontline teams are seeing the devastating consequences of this abuse.\n\n“It is unacceptable for the safety and wellbeing of women and girls to be treated as an afterthought once a technology has been developed and distributed. Their safety must be a foundational principle shaping both the design of wearable technology and the regulatory frameworks that surround it.”\n\nRefuge said it was far too easy to access and weaponise smart accessories and that women’s safety needed to be factored into their design.\n\nOne survivor Refuge worked with, Mina, left behind her smartwatch in a rush to flee her abuser, who then used it to track her by using linked cloud accounts to locate her emergency accommodation.\n\n“[It] was deeply shocking and frightening. I felt suddenly exposed and unsafe, knowing that my location was being tracked without my consent. It created a constant sense of paranoia; I couldn’t relax, sleep properly, or feel settled anywhere because I knew my movements weren’t private,” she said.\n\nDespite police returning the device to Mina, she was located at her next refuge by a private investigator hired by her abuser, using suspected tracking via technology. She reported the breaches to police but was told no crime had been committed because she had “not come to any harm”.\n\n“I was repeatedly asked to move for my safety, rather than the technology being dealt with directly or the smart watch being confiscated from him. Each move made me feel more unstable and displaced,” she said.\n\n“Overall, the experience left me feeling unsafe, unheard, and responsible for managing a situation that was completely out of my control. It showed me how tech abuse can quietly and powerfully extend coercive control, and how easily survivors can be left to carry the emotional and practical burden when systems don’t fully understand or respond to it.”\n\nAbusers were also increasingly using AI tools to manipulate survivors, Pickering said. For example, they might alter a video of the survivor so that she appeared drunk, enabling them to tell social services that “she’s acting erratic again, slurring speech, she’s got a drink problem” and that she was therefore an unfit mother or a risk to herself and others. “We’ll see more and more of that as these videos and applications advance,” Pickering said.\n\nPickering said she had also heard of AI tools being used to develop authentic-looking fraudulent documents, for example job offers or legal summons, which can be sent to survivors to make them believe they are in debt, or to persuade them to turn up to the same location as their abuser.\n\nPickering feared that in coming years, medical tech would increasingly be misused, for example by controlling insulin levels through a diabetes tracker, which can be fatal.\n\nShe urged the government to act on digital technology-enabled and online crimes, including providing more funding to develop and train digital investigations teams. “They want short-term wins, they don’t want to think about longer-term investment in this area, but if we don’t do that we’ll never get ahead,” she said.\n\nShe also wants to see the technology industry held to account for failing to ensure devices and platforms are designed and function in ways that are safe for vulnerable people.\n\n“Ofcom and the Online Safety Act don’t go far enough,” she said.\n\nA government spokesperson said: “Tackling violence against women and girls in all its forms, including when it takes place online or is facilitated by technology, is a top priority for this government.\n\n“Our new VAWG strategy sets out how the full power of the state will be deployed online and offline. We are working with Ofcom to set out how online platforms tackle the disproportionate abuse women and girls face online.”",
    "readingTime": 4,
    "keywords": [
      "oura rings",
      "smartwatches oura",
      "weaponise smart",
      "smart accessories",
      "technology",
      "women",
      "abuse",
      "devices",
      "girls",
      "don’t"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/society/2026/jan/30/abusers-using-ai-and-digital-tech-to-attack-and-control-women-charity-warns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/89ca7cafaaf6189986238a163b499f8d031cfe72/0_0_7167_5733/master/7167.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1cce6b730eef1f7bd4e1f906b9ab52ba",
    "created_at": "2026-01-30T18:28:16.953Z",
    "topic": "tech"
  },
  {
    "slug": "rabbit-project-cyberdeck",
    "title": "Rabbit Project Cyberdeck",
    "description": "meet rabbit r1, your AI-native device, and rabbit intern, a general AI agent that delivers high-quality output - powered by rabbitOS, a cloud-based AI-native operating system.",
    "fullText": "a dedicated vibe-coding machine.\n\nwe're cooking up our next hardware product. inspired by the many DIY cyberdeck projects out there, the idea is to create a dedicated \"rabbit cyberdeck\" for command-line interface (CLI) and native agent use cases. It will be purposefully designed for vibe coders to run things like Claude Code CLI and the upcoming rabbit CLI.\n\nwe asked internally what we would like to have as a form factor, and we believe a portable cyberdeck with a really good screen and, more importantly, a hot-swappable mechanical keyboard will help make this device connect with people.\n\nlearning from the industry and our r1 launch experience, we also want this new device to be as adaptable and open as possible. we want you to have the freedom to choose which model or agent to run.\n\nbelieve us when we say that this cyberdeck will carry the same rabbit design DNA as the iconic r1, with our signature touch on the CMF.\n\nthis time, we want to communicate more transparently with you from the concept phase and gather as much direct feedback as we can from the community. \n\nwe can't wait to bring this device to life.",
    "readingTime": 1,
    "keywords": [
      "cyberdeck",
      "rabbit",
      "device",
      "dedicated",
      "agent"
    ],
    "qualityScore": 0.85,
    "link": "https://www.rabbit.tech/earlyaccess",
    "thumbnail_url": "https://www.rabbit.tech/og/earlyaccess_16x9.png",
    "created_at": "2026-01-30T12:31:45.199Z",
    "topic": "tech"
  },
  {
    "slug": "ai-health-care-is-taking-off-in-china-led-by-jack-mas-ant-group",
    "title": "AI health care is taking off in China, led by Jack Ma's Ant Group",
    "description": "Ant’s health chatbot has become a top downloaded app in China as users seek personalized care they can’t get from the overburdened hospitals.",
    "fullText": "Ant Group, Alibaba’s fintech affiliate and parent of China’s ubiquitous payment app Alipay, is racing to lead the country’s digital health market with a chatbot designed to be a wellness companion.\n\nIts app, Ant Afu, uses artificial intelligence and agentic capabilities to answer health-related questions, suggest hospital appointments, analyze test results, and remind users to exercise or take medication. First created in June under the name AQ, it had recorded 30 million monthly active users by January, with more than half of them living in small cities, according to Ant Group’s chief executive Han Xinyi.\n\nInternet users have increasingly turned to AI for everyday health questions and companionship, especially in markets where access to physicians is limited. Despite concerns about patient safety and data privacy, products like Ant Afu are widely embraced in China as consumers seek more personalized, round-the-clock health support.\n\nChina’s primary care system is underdeveloped. Most people seek treatment for everything from the flu to cancer at sprawling, overcrowded public hospitals that are concentrated in big cities. Patients often complain of long wait times, short consultations, and poor bedside manner of exhausted clinicians.\n\nThis demand for better care, combined with a fast-aging population, has created a fertile ground for digital health products that can spare people the burden of visiting hospitals. Tech companies including JD.com, ByteDance, and Baidu have all built online medical consultation tools, and more recently, chatbots branded as AI doctors.\n\nAnt has a unique advantage as Alipay has long hosted the appointment and payment systems for many hospitals. Millions of people access their national medical insurance accounts through Alipay. In January 2025, Ant acquired Haodf, a leading online consultation portal with more than 300,000 registered physicians.\n\nIn the U.S., AI companies are also expanding their health-care offerings, but they do not yet offer direct access to the country’s large number of private providers and insurers. This month, both OpenAI and Anthropic announced tools targeting consumers, health-care providers, and clinical researchers. Both ChatGPT and Claude now offer features that analyze users’ medical reports and fitness data.\n\nAmong its domestic rivals, Ant’s extensive partnerships with regulators, hospitals, and doctors give it an edge in the AI health-care race, Ivy Yang, a China tech analyst and founder of New York-based consulting firm Wavelet Strategy, told Rest of World. On Ant Afu, users can ask health-related questions, book online consultations and offline appointments at major hospitals, and get reimbursed by state or commercial insurance.\n\n“For startups, the bureaucratic red tape and initial investment required to build the platform, be compliant with all health-care data [regulations], and deal with various government agencies seem like too big a hurdle to overcome,” Yang said.\n\nAnt’s foray into health care has been endorsed by its billionaire founder Jack Ma. He came up with the name Afu, because it made the chatbot sound like a friend, chief executive Han told Chinese tech outlet Latepost this month. “He really cares about whether or not Afu can be like an AI friend that offers emotional companionship and humane care,” Han said, “rather than being just a tool for solving professional problems.”\n\nMa hopes to one day launch the app in underdeveloped parts of Africa and Southeast Asia, Han said.\n\nAnt has spent tens of millions of dollars marketing Afu in China, according to Han. Ant Afu ads have popped up in subway stations, on social media feeds, inside public restrooms, and have been painted on walls in rural China, according to photos shared online. By the end of January, Ant Afu ranked among the top ten most-downloaded iOS apps in China, according to Sensor Tower data.\n\nThe expanding role of AI in patient care, a largely unregulated area, has also prompted warnings about misinformation around the world.  A recent investigation by The Guardian found that Google’s AI summaries were giving out inaccurate health advice. Academics have also found AI diagnostic tools to harbor racial or socioeconomic biases.",
    "readingTime": 4,
    "keywords": [
      "executive han",
      "chief executive",
      "january ant",
      "digital health",
      "ant afu",
      "users",
      "care",
      "hospitals",
      "online",
      "health-care"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/ai-health-care-is-taking-off-in-china-led-by-jack-mas-ant-group/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/Ant_Group_HealthAIChatbot-1-1600x900.jpg",
    "created_at": "2026-01-30T12:31:45.136Z",
    "topic": "tech"
  },
  {
    "slug": "pwcs-chief-ai-officer-isnt-impressed-by-how-many-agents-you-have",
    "title": "PwC's chief AI officer isn't impressed by how many agents you have",
    "description": "Dan Priest, PwC's chief AI officer, told Business Insider that companies should focus on quality not quantity when it comes to AI agents.",
    "fullText": "The AI race can sometimes feel like a numbers game.\n\nEarlier this month, Bob Sternfels, the CEO of McKinsey & Company, made a surprising announcement. The firm, he said, had a workforce of over 60,000 people — 40,000 human employees and 25,000 AI agents.\n\nFor Sternfels, it was an example of McKinsey's all-in approach to AI. Others in the industry, however, say the eye-popping number actually says little about the company's successful adoption of artificial intelligence.\n\nDan Priest, the chief AI officer at PwC, told Business Insider that evaluating a firm's AI use by the number of agents it has is not the best metric.\n\n\"There was this emerging bragging right around the number of agents I had or I have in production,\" he said. \"I think that's probably the wrong measure.\"\n\nThe value of AI deployment is better measured by the quality — not the quantity — of agents, he said.\n\nHe said one way to do that is to look at the number of agents that are authorities on a given task, which will encourage humans to use them, Priest said. The other is to evaluate the number of humans using those agents to execute tasks to achieve a prioritized outcome for a company. An example could be a better customer experience by transforming a call center.\n\nOver the past two years, agents have come to dominate how companies talk about AI adoption. Priest said that focus on agents is the right approach. \"Agents are at a place now where they're the best way to unlock value from AI,\" he said.\n\nHumans still drive the workforce, however, and a better way to measure an agent's value is by how effectively people use them — not just by how much work the agents have the potential to automate.\n\nAt PwC, about 82% of its employees were actively using the firm's AI tools. Priest said that AI agents are embedded across teams at PwC, and the firm tracks how agents interact, how accurately they complete tasks, whether they are making processes faster, higher quality, or higher performing. Humans have a role in reviewing agents' output and providing feedback.\n\n\"The human is still accountable,\" he said. \"The humans are the ones who get certified. The humans are the ones who get licensed. The humans are the ones who get empowered.\"\n\nPriest said that PwC and its clients first took a bottom-up approach to AI adoption. Many business leaders, he said, tried to \"crowdsource\" approaches to adoption from employees because they themselves didn't have the answers.\n\nThat led to a \"fairly disappointing\" return on investment, he said.\n\nPriest said a shift to a \"top-down\" approach has been more effective, allowing them to focus on fewer agents with a deeper mastery of a smaller set of tasks.\n\n\"That agent, I've given them permission to access certain data sets,\" he said. \"I've given them permission to perform certain tasks. I've given them permission to produce certain outcomes. Those permissions are monitored, they expire, they're managed.\"",
    "readingTime": 3,
    "keywords": [
      "agents",
      "humans",
      "approach",
      "adoption",
      "tasks",
      "employees",
      "ones",
      "i've",
      "permission",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-agents-consulting-firms-mckinsey-pwc-2026-1",
    "thumbnail_url": "https://i.insider.com/697683dda645d1188187f3e7?width=1200&format=jpeg",
    "created_at": "2026-01-30T12:31:43.705Z",
    "topic": "finance"
  },
  {
    "slug": "the-ceo-of-wix-shares-the-jobs-hes-most-and-least-concerned-about-ai-replacing",
    "title": "The CEO of Wix shares the jobs he's most and least concerned about AI replacing",
    "description": "Wix CEO Avishai Abrahami predicts 70% of the top 20 most popular jobs in the US will be affected by AI in the next five to 10 years.",
    "fullText": "What keeps the CEO of the billion-dollar company Wix up at night? The future of the workforce.\n\n\"I'm really worried about the employment market,\" Avishai Abrahami told Business Insider.\n\nThe CEO said that a \"massive amount\" of roles will shrink due to AI advancement. He predicted that roughly 70% of the top 20 most popular jobs in the US today will be affected by AI over the next five to 10 years.\n\nAbrahami said he's concerned about computers outsmarting humans, a concept often referred to as artificial general intelligence, which some tech leaders have said we have already surpassed in some ways. In that reality, humans \"become the monkeys,\" the CEO said. He said when he grew up, getting to such a point \"was a science-fiction thing,\" and it's now becoming a reality.\n\nAbrahami said he doesn't know whether that future is next week or 10 years from now — but he said it's closer than 15 or 20 years from now.\n\nHowever, AI will also create new opportunities and job types, Abrahami said. For example, Wix just introduced a new role called the xEngineer, described as a design-first engineer with deep domain expertise who uses AI as a key part of every workflow. The position is for a specialist who is \"amplified\" by AI, the company said in its announcement.\n\nAbrahami said some jobs are more at risk than others:\n\nAbrahami said one of the most common jobs in the US — driving for ride-share apps, taxi, and truck drivers — will be affected. The Bureau of Labor Statistics reported more than 4 million of those jobs in 2024.\n\nAlphabet's Waymo has already launched self-driving services in multiple cities across the US, and Tesla just launched robotaxi rides without human oversight in Austin, where it has offered the service for several months.\n\nThe CEO said that people working in customer service or call center positions will also be affected. Other tech leaders, like OpenAI CEO Sam Altman, similarly said that AI will take customer service jobs first.\n\nOther roles, such as software developers and analysts, are already seeing AI reshape their jobs. A Google Cloud report released in September found that AI adoption had surged to 90% among software professionals.\n\nThe CEO predicted that jobs that require human performance or interaction will be a \"bit safer\" from job replacement. Abrahami said that \"nobody cares\" about robots running fast and competing against each other in soccer, and that athletes and other roles in the performing arts will stay.\n\nJobs that require high-level thinking are also performed better by humans than by AI right now with the current models, Abrahami said. The CEO said that AI isn't great at creating new things, and it's unlikely to invent a new science at its current level.\n\nAbrahami said that janitors are also \"probably really safe\" when it comes to replacement because the job requires a lot of handwork, which robots are far from being able to replicate.\n\n\"We are very good at processing visual movement information,\" Abrahami said.\n\nIn general, he said, jobs where humans can shine and bring something that's \"completely unexpected\" will be the areas where they're safe from replacement.",
    "readingTime": 3,
    "keywords": [
      "tech leaders",
      "customer service",
      "the ceo",
      "jobs",
      "humans",
      "abrahami",
      "roles",
      "affected",
      "it's",
      "replacement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wix-ceo-jobs-ai-most-and-least-likely-to-replace-2026-1",
    "thumbnail_url": "https://i.insider.com/697b7eaee1ba468a96aaf2a5?width=1200&format=jpeg",
    "created_at": "2026-01-30T12:31:42.961Z",
    "topic": "finance"
  },
  {
    "slug": "aigenerated-news-should-carry-nutrition-labels-thinktank-says",
    "title": "AI-generated news should carry ‘nutrition’ labels, thinktank says",
    "description": "The Institute for Public Policy Research also argues that tech companies must pay publishers for content they use\nAI-generated news should carry “nutrition” labels and tech companies must pay publishers for the content they use, according to a left-of-centre thinktank, amid rising use of the technology as a source for current affairs.\nThe Institute for Public Policy Research (IPPR) said AI firms were rapidly emerging as the new “gatekeepers” of the internet and intervention was needed to create a healthy AI news environment.\n Continue reading...",
    "fullText": "The Institute for Public Policy Research also argues that tech companies must pay publishers for content they use\n\nAI-generated news should carry “nutrition” labels and tech companies must pay publishers for the content they use, according to a left-of-centre thinktank, amid rising use of the technology as a source for current affairs.\n\nThe Institute for Public Policy Research (IPPR) said AI firms were rapidly emerging as the new “gatekeepers” of the internet and intervention was needed to create a healthy AI news environment.\n\nIt recommended standardised labels for AI-generated news, showing what information had been used to create those answers, including peer-reviewed studies and articles from professional news organisations. It also urged the establishment of a licensing regime in the UK allowing publishers to negotiate with tech companies over the use of their content in AI news.\n\n“If AI companies are going to profit from journalism and shape what the public sees, they must be required to pay fairly for the news they use and operate under clear rules that protect plurality, trust and the long-term future of independent journalism,” said Roa Powell, senior research fellow at IPPR and the report’s co-author.\n\nThe IPPR said work on licensing could begin with the UK’s competition regulator using its new enforcement powers over Google. The Competition and Markets Authority this week proposed giving web publishers and news organisations the power to stop Google scraping their content for its overviews. Collective licensing deals would ensure a wide range of publishers were included, the IPPR added.\n\nGoogle’s AI overviews now reach 2 billion users a month and approximately a quarter of people use AI to get information, according to the Reuters Institute for the Study of Journalism.\n\n“With the right policies in place, the government can shape this market so that UK news organisations transition their business models for the AI age and AI companies improve the reliability of their products by drawing on trusted sources,” said the report.\n\nIPPR tested four AI tools – ChatGPT, Google AI overviews, Google Gemini and Perplexity – by entering 100 news-related queries into those platforms and analysing more than 2,500 links produced by the AI responses.\n\nChatGPT and Gemini did not cite journalism by the BBC, which has blocked the bots they use to assemble answers, while overviews and Perplexity used BBC content despite the broadcaster’s objections to those tools using its journalism.\n\nThe IPPR found the Telegraph, GB News, the Sun and the Daily Mail were cited in fewer than 4% of answers on ChatGPT, while the Guardian – which has a licensing deal with ChatGPT’s parent, OpenAI – was used as a source in nearly six out of 10 responses. The Financial Times, which also has a licensing deal with OpenAI, also featured highly. The Guardian was also the most common source used by Gemini, appearing in half of all answers.\n\nGoogle’s use of AI summaries at the top of search results has affected click-through traffic for publishers, with a knock-on effect for their revenues, because many users read the overview without moving on to the original journalism.\n\nThe IPPR said questions needed to be asked about how financial relationships between AI companies and news providers shaped answers.\n\n“If licensed publications appear more prominently in AI answers, there is a risk of locking out smaller and local news providers, who are less likely to get AI deals,” the report said.\n\nIPPR added that while licensing deals could replace lost advertising revenues to an extent, they would not maintain a healthy news ecosystem. They could make news organisations dependent on tech giants for revenue and that income could easily disappear if copyright protections are weakened, said the thinktank.\n\nThe IPPR said there should be public funding to create new business models for investigative news and local news, whose sustainability could be threatened by the rise of AI news, and for the BBC to “innovate with AI”.",
    "readingTime": 4,
    "keywords": [
      "policy research",
      "business models",
      "licensing deal",
      "licensing deals",
      "the ippr",
      "the institute",
      "publishers",
      "content",
      "tech",
      "organisations"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/30/ai-generated-news-should-carry-nutrition-labels-thinktank-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/75ce9f5b7734cf6d98e01e620f2325e0bccaecbc/1168_0_5840_4672/master/5840.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4ad7cda8b73024d97e50b11cb7599626",
    "created_at": "2026-01-30T12:31:41.316Z",
    "topic": "tech"
  },
  {
    "slug": "daedalus",
    "title": "Daedalus",
    "description": "AI planning CLI and autonomous agent orchestration for beans-based coding workflows - internet-development/daedalus",
    "fullText": "internet-development\n\n /\n\n daedalus\n\n Public\n\n AI planning CLI and autonomous agent orchestration for beans-based coding workflows\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n internet-development/daedalus",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/internet-development/daedalus",
    "thumbnail_url": "https://opengraph.githubassets.com/471147f12cb10edd91f2072a6602ce03fd3e4339e4f03a4a184ee7336b8d31ea/internet-development/daedalus",
    "created_at": "2026-01-30T06:35:17.254Z",
    "topic": "tech"
  },
  {
    "slug": "a-beans-based-ai-workflow",
    "title": "A Beans Based AI Workflow",
    "description": "Experimenting on the frontier of AI using beans",
    "fullText": "Since the title is a bit of click-bait, I should probably specify what I mean by bean based.\nI found a lovely tool for creating beans that are essentially just markdown files with some front matter for task tracking.\nNow back to the article!\n\nI feel like a mad scientist.\nI spent the last week analyzing agentic coding tools, ideating on what I like and dislike about them, and then deciding to build my own.\n\nDuring my analysis, the main issue I found with most agentic coding tools right now is that they all focus on one thing: running as many agents in parallel as possible.\nBut why? Why run 10, 100, or even 1000 agents when you are unable to write enough tickets for them to consume?\n\nMaybe I’m wrong. Maybe I should be running hundreds of agents in parallel, but I can’t honestly say I’ve ever run more than 2 at a time.\nBoth working on separate tasks, and I spent most of my time not in setting up and running agents, but in defining the work that needs to be done.\nAlso, the context switching from managing two agents was exhausting.\n\nI want to take this in a new direction. Let’s flip the entire script on its head and think about this pragmatically.\nI don’t think the bottleneck here is a lack of enough agents. The bottleneck is not having clear enough tasks for these agents to work on.\nI can not write instructions fast enough to outpace the work of a single agent. I doubt you can either. Prove me wrong.\nI have yet to see anyone actually write and think fast enough to keep up with the pace of a single agent writing the code.\nMost of my time working with an agent is spent answering questions, rethinking approaches, and dealing with unforeseen bugs.\nIt requires a ton of my attention and focus to handhold these agents.\n\nWhat if we took a different approach? What if we looked at some examples of how software engineering has been traditionally managed?\nIn come PRDs (Product Requirement Documents), made with the explicit intent to get one person’s thoughts into another person’s actions.\nIsn’t that all we are doing with agents now, defining a document for an agent to follow instructions to implement?\n\nI’m building Daedalus, a from-scratch custom planning agent. Yes, I’m building an agent from scratch. Yes, I don’t really know how this will go.\nI believe we live in an exciting wild time with an entire new frontier, waiting to be explored. I’m putting in the time and effort to try an experiment for myself.\nI am willing to accept failure. I am willing to be wrong. I hope that this works.\n\nDaedalus was the greatest mortal craftsman and inventor in Greek mythology—an Athenian architect, engineer, and artist whose name literally means “skillfully wrought” or “cunning worker.”\n\nHe’s essentially the mythological archetype of the brilliant but flawed engineer—someone whose genius creates both wonders and disasters, who solves problems with ingenuity but can’t escape the human consequences of his choices.\n\n— Claude\n\nI chose the name Daedalus because I feel that it embodies the soul of an engineer: planning, thinking, criticizing, researching, and questioning.\nYet, there is hubris manifest in his work, which parallels how I feel about AI coding agents. Daedalus doesn’t write code—that’s not the point.\nThough, he has access to a breadth of expert sub-agents: critics, skeptics, pragmatists, architects, simplifiers, UX researchers, code explorers, and more.\nThe goal for Daedalus is to outpace the coding agent, which I’ve aptly named Talos, the bronze automaton that protected the island of Crete.\nYou don’t talk to Talos, nor do you need to. He finds the next task and starts working. Do note that I’ve tailored Talos to approach coding using TDD (test driven development),\nwhich I’ve found yields a slightly better success rate for autonomous implementation. I borrowed the idea and a few other skills from the superpowers repo.\n\nHowever, that’s not to say what I’ve built is prescriptive. You can do it at home, without any of my specialized tools.\nYou need two agent instances, OpenCode, Claude Code, Codex, it doesn’t matter. One is your coding agent, always in “build” mode.\nIt’s confined to a ralph loop, always picking up the next available task. The other, a planning agent, whose only responsibility is to create tickets and critique what already exists.\nNo specialized tools. This is a workflow, a process. Not something to be sold to you.\n\nA bit more about beans. It describes itself as, “A CLI-based, flat-file issue tracker for humans and robots.”\nHowever, the power in this approach over other longer term memory tools for agents, like beads, is that it’s plain text.\nThe tool parses the front matter of the beans on startup and then works on that in-memory data structure.\nThe beauty is that I can easily read and modify this myself, and I can check it into git.\nAdditionally, beans has a built-in GraphQL API, which is quite handy for the agents to be able to get relational data about these flat files.\nEach bean has a title, status, type, priority, and optional blockedBy fields. I’m using this to handle complicated, long running, and autonomous PRD implementation.\nMy ralph loop starts by querying for beans that are in-progress or todo then creates the dependency graph using the blockedBy field.\nThis allows me to find which bean we need to work on first, pass that bean to the coding agent and let it run.\n\nBeans are the lifeblood of this workflow. Whether or not you use beans or another tool, it doesn’t really matter.\nThe only thing you need to make it work is a structured way to define tasks with enough context that an agent can work on it without human intervention.\nAnd ideally in that structure you have some way to organize which tasks are dependent on the work of other tasks.\n\nYour role in this system is to guide. It’s to sit with the planning agent, and only the planning agent. To scope out features, bugs, epics, and milestones.\nTalk with the planning agent and create a bean, iterate on it, question its design, scope, and purpose. Once you feel like it’s done, move on.\nLet the planning agent write the outline and implementation details in the bean. Then pass it to the coding agent and take a walk.\n\nNow the real power comes from not just creating these beans and passing them to a coding agent. It’s in the dependency graph.\nBeyond just the blockedBy, it’s the parent/child relationships between milestones, epics, features, tasks, and bugs.\nAnd taking advantage of that structure in a ralph loop. Learn more about ralph loops here. As I’ve been experimenting, I’ve noticed additional ways I can modify my loop and make it better.\nThe original ralph loop uses a <promise>DONE</promise> signal to track when the agent says it’s done.\nI rely on the bean being moved to the completed status.\n\nHere’s the flow for my ralph loop (or you can view the source code):\n\nThat’s it, it’s basically a while loop that feeds beans to an AI agent until they’re done.\n\nSo where is Daedalus now? Well it’s still a WIP. You can use the philosophy and workflow now but I am working on a tool to make this significantly easier.\nYou can check out the repo here and use the agents and skills in your OpenCode or Claude Code.\n\nI’d love to hear some feedback on what you think about this experiment.",
    "readingTime": 7,
    "keywords": [
      "claude code",
      "dependency graph",
      "specialized tools",
      "ralph loop",
      "agentic coding",
      "it’s done",
      "planning agent",
      "agents",
      "beans",
      "bean"
    ],
    "qualityScore": 1,
    "link": "https://caidan.dev/blog/2026-01-29-a-beans-based-ai-workflow/",
    "thumbnail_url": "https://caidan.dev/_astro/avatar.B7OQlREk.png?v=1769751563950",
    "created_at": "2026-01-30T06:35:16.961Z",
    "topic": "tech"
  },
  {
    "slug": "check-this-cool-website-i-found",
    "title": "Check this cool website I found",
    "description": "Discover what you're really feeling with deep AI emotion analysis",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://subtlesense.lovable.app",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/453f3352-e480-4dd3-939a-42227472f4a3/id-preview-caf1f7fb--67e4d89d-130c-4203-ac7d-ab5066c625c6.lovable.app-1769676305368.png",
    "created_at": "2026-01-30T06:35:16.380Z",
    "topic": "tech"
  },
  {
    "slug": "automation-is-inevitable-and-south-koreas-president-just-said-it-out-loud",
    "title": "Automation is inevitable, and South Korea's president just said it out loud",
    "description": "President Lee Jae Myung said Thursday that workers must adapt swiftly to the era of artificial intelligence (AI), in an apparent message to Hyundai...",
    "fullText": "President Lee Jae Myung said Thursday that workers must adapt swiftly to the era of artificial intelligence (AI), in an apparent message to Hyundai Motor's labor union, which has strongly opposed the carmaker's planned introduction of humanoid robots at production facilities.\n\n\"A labor union appears to have announced that it will stop robots from entering production sites. That may be part of its overall protest strategy,\" Lee said during a meeting with senior aides at Cheong Wa Dae.\n\n\"But once the massive wagon starts rolling, we cannot stop it,\" Lee said, likening the current situation to the past, when the introduction of steam engines triggered machine-breaking protests by laborers worried about losing jobs.\n\nLee added: \"Ultimately, society has to adapt quickly. People need to learn new skills and adjust rapidly to the new environment.\"\n\nThe president stressed the importance of preparing workers for technological change rather than resisting it, as AI-driven automation accelerates across industries. He also underscored the need for fundamental policies to prepare for extreme polarization in an AI-driven economy.\n\nWhile Lee did not name a specific labor group, his comments were widely interpreted as directed at Hyundai Motor's labor union, which recently lashed out at the carmaker's plans to deploy humanoid robots at production sites.\n\nIn a statement released earlier in the day, the union said management is seeking to materialize a so-called \"dream factory\" that operates 24 hours a day using only AI-powered robots.\n\n\"There is no place for humans anywhere in the plan,\" the union said, expressing concerns that robots would ultimately take over all jobs.\n\nThe union added that Hyundai Motor Group discussed the unmanned factory initiative, dubbed the \"DF247\" project, as a key priority at its annual Global Leaders Forum earlier this month. The project envisions fully automated facilities operating around the clock.\n\nThe union warned that such developments would eventually affect all workers in Korea, arguing that the balance between consumption and supply would be disrupted, creating a vicious cycle in the nation's economy.\n\nThe union statement came about a week after the workers voiced strong opposition to the carmaker's plan to deploy Atlas robots made by Boston Dynamics, its U.S. robotics unit, across major assembly lines in Korea and overseas.\n\nHyundai Motor has identified the Atlas robot as a key future growth engine in the emerging era of physical AI.\n\nThe company unveiled its vision at the CES 2026 tech fair earlier this month, outlining plans to mass-produce up to 30,000 humanoid robots by 2028 and gradually deploy them at its manufacturing sites, including Hyundai Motor Group Metaplant America in Georgia.",
    "readingTime": 3,
    "keywords": [
      "motor's labor",
      "production sites",
      "humanoid robots",
      "labor union",
      "hyundai motor's",
      "workers",
      "carmaker's",
      "deploy",
      "earlier",
      "adapt"
    ],
    "qualityScore": 0.9,
    "link": "https://www.koreatimes.co.kr/southkorea/politics/20260129/lee-calls-on-workers-to-swiftly-adapt-to-unavoidable-ai-robotics-era",
    "thumbnail_url": "https://newsimg.koreatimes.co.kr/2026/01/29/5b893aff-d3a5-47fd-a821-746af8b87669.jpg",
    "created_at": "2026-01-30T06:35:15.219Z",
    "topic": "politic"
  },
  {
    "slug": "microsofts-440-billion-wipeout-and-investors-angry-about-openais-debt-explained",
    "title": "Microsoft’s $440 billion wipeout, and investors angry about OpenAI’s debt, explained",
    "description": "Microsoft’s stock has plummeted 12% owing to a slight miss on revenue, showing how spooked investors are by the “spend now, profit later” AI market.",
    "fullText": "Wall Street’s yearslong bet on AI is facing a severe test on Thursday, as investors might begin to view OpenAI—and generative AI in general—not as a catalyst for continuous growth, but as a source of systemic risk for Big Tech.\n\nA sharp selloff in tech stocks on Thursday underscored investors’ exhaustion with the “spend now, profit later” model that has propelled the AI bull market for three years. Microsoft led the retreat, with its shares plummeting 12% by noon, erasing more than $440 billion in market value, a collapse it hasn’t seen since the pandemic. The Nasdaq was down almost 2% at time of writing.\n\nWhy did Microsoft's stock plunge 12% on Thursday?\n\nWhy are Oracle shares down from September highs?\n\nHow much of Microsoft's future revenue depends on OpenAI?\n\nWhat is driving investor concerns about AI capex spending?\n\nThe immediate catalyst, it seems, is an intensifying focus on capex, or capital expenditures. Microsoft revealed that its spending surged 66% to $37.5 billion in the latest quarter, even as growth in its Azure cloud business cooled slightly. Even more concerning to analysts, however, was a new disclosure that approximately 45% of the company’s $625 billion in remaining performance obligations (RPO)—a key measure of future cloud contracts—is tied directly to OpenAI, the company revealed after reporting earnings Wednesday afternoon. (Microsoft is both a major investor in and a provider of cloud-computing services to OpenAI.)\n\n“It’s the collapse of software and the ascent of hardware, and it is staggering,” CNBC’s Jim Cramer noted on X on Thursday, as the market punished companies that are spending billions on software infrastructure while failing to show immediate returns.\n\nIt’s an “ominous” statistic, Morning Brew cofounder Austin Rief wrote on X, especially combined with the fact that Meta is planning to devote most of their free cash flow to capex. Meta has evaded the selloff on a stronger-than-expected revenue forecast, showing a healthy 24% year-over-year revenue increase, driven by online ads. The fact that Wall Street is letting Meta get away with their also massive capex indicates the reason why investors are selling off: They don’t trust OpenAI to bring that revenue on their own without massive infusions of outside cash.\n\nThe sentiment shift is not limited to Redmond. Oracle has seen its shares halved from their September highs, erasing nearly $463 billion in value. Once a darling of the AI trade, Oracle has also struggled with investor confidence that the massive data centers it is building for OpenAI will get funded eventually. Additionally, the timeline for several projects has reportedly slipped to 2028, creating a gap between the company’s heavy debt-funded spending and the arrival of actual revenue.\n\nOpenAI has made about $1.4 trillion in commitments to procure both the energy and compute it needs to fuel its operations. But its revenue barely crossed $20 billion in 2025.",
    "readingTime": 3,
    "keywords": [
      "september highs",
      "revenue",
      "capex",
      "investors",
      "market",
      "microsoft",
      "shares",
      "investor",
      "meta",
      "massive"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-440-billion-wipeout-investors-175614975.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/jYq9kyGPPwVZhXQoi926UQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/db5e36eb9ca7373a69fddcfa683aace0",
    "created_at": "2026-01-30T06:35:12.676Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musks-spacex-said-to-consider-merger-with-tesla-bloomberg-news-reports",
    "title": "Elon Musk's SpaceX said to consider merger with Tesla, Bloomberg News reports",
    "description": "Elon Musk's SpaceX is considering a potential merger with ​Tesla as well as an ‌alternative combination with artificial-intelligence company xAI, Bloomberg News ‌reported on Thursday, citing people familiar with the matter.  Tesla's shares were up 3% after the bell following the report.  SpaceX ⁠and xAI are ‌in discussions to merge ahead of a blockbuster public offering ‍planned for later this year, Reuters exclusively reported earlier on Thursday, to bring Musk's ​rockets, Starlink satellites, the X social ‌media platform and Grok AI chatbot under one roof.",
    "fullText": "Jan 29 (Reuters) - Elon Musk's SpaceX is considering a potential merger with ​Tesla as well as an ‌alternative combination with artificial-intelligence company xAI, Bloomberg News ‌reported on Thursday, citing people familiar with the matter.\n\nTesla's shares were up 3% after the bell following the report.\n\nWhat are the potential SpaceX merger scenarios?\n\nWhat companies would be combined under one roof?\n\nHow did Tesla's stock react to merger reports?\n\nWhich investors are interested in these potential deals?\n\nSpaceX ⁠and xAI are ‌in discussions to merge ahead of a blockbuster public offering ‍planned for later this year, Reuters exclusively reported earlier on Thursday, to bring Musk's ​rockets, Starlink satellites, the X social ‌media platform and Grok AI chatbot under one roof.\n\nThe space firm has discussed the feasibility of a tie-up between SpaceX and EV-maker Tesla, an idea ⁠that some investors are ​pushing, the Bloomberg report ​said.\n\nAny deal could attract sizeable interest from infrastructure funds and Middle ‍Eastern sovereign ⁠investors, some of the people told Bloomberg.\n\nSpaceX and Tesla did not immediately ⁠respond to Reuters requests for comment.",
    "readingTime": 1,
    "keywords": [
      "reuters",
      "potential",
      "merger",
      "investors",
      "musk's",
      "tesla's",
      "roof",
      "spacex",
      "tesla",
      "bloomberg"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/elon-musks-spacex-said-consider-224603248.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/1544e7d59d3e13f63bd966ad28000ab4",
    "created_at": "2026-01-30T06:35:12.616Z",
    "topic": "finance"
  },
  {
    "slug": "suttons-predictions-v-boxer-francesca-hennessy",
    "title": "Sutton's predictions v boxer Francesca Hennessy",
    "description": "BBC Sport football expert Chris Sutton takes on boxer Francesca Hennessy and AI with his predictions for this week's Premier League fixtures.",
    "fullText": "Tottenham may have coasted through to the Champions League last 16, but their Premier League form remains a problem for boss Thomas Frank.\n\n\"I was at their draw with Burnley last week and there are a lot of angry Spurs fans out there,\" said BBC Sport football expert Chris Sutton.\n\n\"Their domestic results are such a contrast to their record in Europe, and it could be another difficult afternoon for Frank when they face Manchester City on Sunday.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nHis guest for week 24 is boxer Francesca Hennessy, who supports Chelsea.\n\nHennessy faces Ellie Bouttell in a WBC title eliminator on Saturday, live on BBC Two from 20:00 GMT.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 1,
    "keywords": [
      "premier league",
      "draw",
      "predictions",
      "points",
      "frank",
      "sport",
      "sutton",
      "hennessy"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/cx204g4rn8xo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/b2d0/live/3345b7f0-fd30-11f0-a8b8-bdd2c5f9bcad.png",
    "created_at": "2026-01-30T06:35:12.335Z",
    "topic": "sports"
  },
  {
    "slug": "zuckerberg-says-ai-is-letting-one-employee-do-the-work-of-entire-teams-and-it-shows-how-the-company-is-rethinking-hiring",
    "title": "Zuckerberg says AI is letting one employee do the work of entire teams, and it shows how the company is rethinking hiring",
    "description": "The tech giant is doubling down on a trend of companies operating with leaner workforces, though it's still on the hunt for rockstar talent.",
    "fullText": "CEO Mark Zuckerberg said AI tools now let individual Meta employees do work that once required large teams.\n\nMeta plans to boost AI spending by between 60% and 87% this year as output per engineer continues to rise.\n\nDespite compute constraints, Meta said it's looking to hire top AI talent.\n\nMeta CEO Mark Zuckerberg says AI is transforming what a single employee can accomplish at the company, signaling it's adopting a new hiring strategy.\n\nOn an earnings call with analysts Thursday, Meta boss Mark Zuckerberg said the company is investing in more AI-native tools to elevate individual contributors and flatten teams. The effort is being somewhat constrained, however, by a lack of compute resources.\n\n\"We're starting to see projects that used to require big teams now be accomplished by a single very talented person,\" he said. \"I want to make sure that as many of these very talented people as possible choose Meta as the place that they can make the greatest impact.\"\n\nThe Facebook and Instagram parent, which reported fourth-quarter revenue and earnings that exceeded Wall Street's expectations, said it plans to boost AI spending by between 60% and 87% this year. Meta also said it already saw a significant increase in output per engineer last year, with the majority of that growth coming from the adoption of agentic coding.\n\nThough teams are on track to become smaller, finance chief Susan Li said on the earnings call that the company is still hungry for top talent. \"It remains a very competitive hiring market, but we'd like to invest aggressively where we can,\" she said.\n\nLi also noted that Meta closed out the December-ended quarter with 6% more employees than it had a year earlier, driven by hiring in areas such as monetization, infrastructure, Meta Superintelligence Labs, regulation, and compliance.\n\nMeta isn't alone in focusing on tiny teams. The strategy has become popular in the startup world, where founders have long prioritized scrappiness. It's a trend that OpenAI CEO Sam Altman predicted would take hold back in February 2024.\n\n\"We're going to see 10-person companies with billion-dollar valuations pretty soon,\" he said at the time. \"In my little group chat with my tech CEO friends, there's this betting pool for the first year there is a one-person billion-dollar company, which would've been unimaginable without AI. And now [it] will happen.\"\n\nMeanwhile, large companies have been thinning their middle manager ranks in recent years to boost efficiency by reducing bureaucracy, including Amazon and Intel. Meta's Zuckerberg wrote a memo in 2023 entitled \"Flatter is faster,\" and in late 2024, Google CEO Sundar Pichai told staff that the company cut vice president and manager roles by 10% as part of an efficiency push.",
    "readingTime": 3,
    "keywords": [
      "ceo mark",
      "output per",
      "per engineer",
      "teams",
      "meta",
      "boost",
      "it's",
      "hiring",
      "earnings",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/meta-boss-says-ai-letting-183328865.html",
    "thumbnail_url": "https://s.yimg.com/os/en/business_insider_consolidated_articles_886/2d49eb409d05840f67e613b16f7304ea",
    "created_at": "2026-01-30T06:35:12.101Z",
    "topic": "finance"
  },
  {
    "slug": "cwt-sandbox-ai-coding-agents-using-git-worktrees",
    "title": "Cwt – Sandbox AI coding agents using Git Worktrees",
    "description": "Contribute to benngarcia/claude-worktree development by creating an account on GitHub.",
    "fullText": "benngarcia\n\n /\n\n claude-worktree\n\n Public\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n benngarcia/claude-worktree",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/benngarcia/claude-worktree",
    "thumbnail_url": "https://opengraph.githubassets.com/73752eaadbf154afd745270d32c1743038163f0555993f4c462cecd915f63c02/benngarcia/claude-worktree",
    "created_at": "2026-01-30T01:07:08.980Z",
    "topic": "tech"
  },
  {
    "slug": "zuckerberg-says-ai-is-letting-one-employee-do-the-work-of-entire-teams-and-it-shows-how-the-company-is-rethinking-hiring",
    "title": "Zuckerberg says AI is letting one employee do the work of entire teams, and it shows how the company is rethinking hiring",
    "description": "The tech giant is doubling down on a trend of companies operating with leaner workforces, though it's still on the hunt for rockstar talent.",
    "fullText": "Meta CEO Mark Zuckerberg says AI is transforming what a single employee can accomplish at the company, signaling it's adopting a new hiring strategy.\n\nOn an earnings call with analysts Thursday, Meta boss Mark Zuckerberg said the company is investing in more AI-native tools to elevate individual contributors and flatten teams. The effort is being somewhat constrained, however, by a lack of compute resources.\n\n\"We're starting to see projects that used to require big teams now be accomplished by a single very talented person,\" he said. \"I want to make sure that as many of these very talented people as possible choose Meta as the place that they can make the greatest impact.\"\n\nThe Facebook and Instagram parent, which reported fourth-quarter revenue and earnings that exceeded Wall Street's expectations, said it plans to boost AI spending by between 60% and 87% this year. Meta also said it already saw a significant increase in output per engineer last year, with the majority of that growth coming from the adoption of agentic coding.\n\nThough teams are on track to become smaller, finance chief Susan Li said on the earnings call that the company is still hungry for top talent. \"It remains a very competitive hiring market, but we'd like to invest aggressively where we can,\" she said.\n\nLi also noted that Meta closed out the December-ended quarter with 6% more employees than it had a year earlier, driven by hiring in areas such as monetization, infrastructure, Meta Superintelligence Labs, regulation, and compliance.\n\nMeta isn't alone in focusing on tiny teams. The strategy has become popular in the startup world, where founders have long prioritized scrappiness. It's a trend that OpenAI CEO Sam Altman predicted would take hold back in February 2024.\n\n\"We're going to see 10-person companies with billion-dollar valuations pretty soon,\" he said at the time. \"In my little group chat with my tech CEO friends, there's this betting pool for the first year there is a one-person billion-dollar company, which would've been unimaginable without AI. And now [it] will happen.\"\n\nMeanwhile, large companies have been thinning their middle manager ranks in recent years to boost efficiency by reducing bureaucracy, including Amazon and Intel. Meta's Zuckerberg wrote a memo in 2023 entitled \"Flatter is faster,\" and in late 2024, Google CEO Sundar Pichai told staff that the company cut vice president and manager roles by 10% as part of an efficiency push.\n\nThe trend isn't limited to tech companies. Retailers such as Walmart and Wayfair, and fintech firms like Block, have been moving managers into non-management roles. Some companies have also been conducting multiple rounds of mass layoffs. On Wednesday, Amazon said it would cut 16,000 corporate roles, the company's second round of layoffs in four months.\n\nOn Meta's earnings call, the company acknowledged that its goal of being able to lean on a smaller number of highly AI-savvy employees is challenged by a shortage of compute resources, as demand across the company has increased faster than its supply. Still, Zuckerberg expressed confidence in his outlook for greater efficiencies.\n\n\"I think that 2026 is going to be the year that AI starts to dramatically change the way that we work,\" he said. \"As we navigate this, our North Star is building the best place for individuals to make a massive impact.\"",
    "readingTime": 3,
    "keywords": [
      "compute resources",
      "earnings",
      "teams",
      "hiring",
      "roles",
      "meta",
      "it's",
      "strategy",
      "talented",
      "impact"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-says-ai-letting-one-employee-do-work-of-teams-2026-1",
    "thumbnail_url": "https://i.insider.com/697b9f47a645d118818840ab?width=800&format=jpeg",
    "created_at": "2026-01-30T01:07:07.110Z",
    "topic": "finance"
  },
  {
    "slug": "slowing-cloud-growth-and-huge-ai-spending-why-microsofts-stock-is-plunging-the-most-in-nearly-6-years",
    "title": "Slowing cloud growth and huge AI spending: Why Microsoft's stock is plunging the most in nearly 6 years",
    "description": "Shares dropped the most since March 2020 on Thursday, with investors fleeing the stock amid slower cloud growth and big spending on AI.",
    "fullText": "Microsoft stock is getting crushed on Thursday.\n\nThe negative post-earnings reaction stems from investors' dismay over weaker-than-expected guidance in a key business area, alongside larger-than-expected spending on AI.\n\nMicrosoft earnings came in above both top and bottom line forecasts, with cloud revenue reaching $50 billion for the first time, but Microsoft stock still plunged 12%, its biggest decline since March 2020.\n\nWall Street analysts were laser-focused on AI spending heading into earnings, and the market's reaction to Microsoft and Meta's results shows that investors need to see strength elsewhere in the business to feel good about surging capex. Meta shares spiked on Thursday, and although its spending outlook jumped, that was offset by robust advertising business.\n\nMicrosoft's Azure cloud platform revenue grew 39% on an annual basis, coming in above the forecast 38.4% but still below the 40% it posted in the previous quarter. According to finance pros, this is the primary factor driving Microsoft stock down.\n\n\"Microsoft allocated scarce GPU capacity away from Azure to 1P products, but the fact that BOTH Azure and the M365 segments fell a bit short is the key negative we're hearing that is driving the modest after-market fade,\" stated UBS analyst Karl Keirstead.\n\nOther Wall Street analysts think Microsoft could face challenges in the coming months if it can't find a way to boost its cloud revenue and win back Wall Street's confidence.\n\n\"I think sentiment around Microsoft is kind of negative right now. And if they don't really beat or re-accelerate Azure growth, the shares are probably not going to perform very well,\" Ryuta Makino of Gabelli Funds said.\n\nTech guru and University of Michigan professor Erik Gordon pointed to Microsoft's excessive spending as a catalyst for the stock's decline, noting that he sees it as a clear indication of a bubble in AI.\n\nTo get back to where it needs to be, though, Microsoft may need to spend even more. Blake Crawford, CIO of tech consulting firm Fusion Collective, raised the concern that much of its growth prospects hinge on the success of OpenAI.\n\n\"The number that sticks out like a sore thumb: remaining commercial obligations are up 110% to $625 billion, and OpenAI is a whopping 45% of that,\" he stated. \"That's a lot of hope-and-a-prayer that OpenAI will be able to deliver. And recognizing any potential upside will require significant capex.\"",
    "readingTime": 2,
    "keywords": [
      "street analysts",
      "wall street",
      "microsoft stock",
      "cloud revenue",
      "negative",
      "business",
      "reaction",
      "investors",
      "earnings",
      "decline"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-stock-down-q4-earnings-ai-spending-azure-cloud-tech-2026-1",
    "thumbnail_url": "https://i.insider.com/697b8c12a645d11881883dc4?width=1200&format=jpeg",
    "created_at": "2026-01-30T01:07:07.021Z",
    "topic": "finance"
  },
  {
    "slug": "data-centers-are-powering-blackstones-13-trillion-investment-empire",
    "title": "Data centers are powering Blackstone's $1.3 trillion investment empire",
    "description": "Blackstone sees major returns from its data center bet, and plans to continue to \"lean into\" the AI boom.",
    "fullText": "Data center investments have become the engine of Blackstone's growth.\n\nThe Wall Street investment giant reported that QTS, the data center developer and operator it took private in 2021, was the single largest driver of gains in the company's $1.3 trillion portfolio in 2025. The results were a clear sign that Blackstone's bets on digital infrastructure amid the artificial intelligence boom have reaped returns as other segments of its business, including real estate and private credit, have run into headwinds.\n\nIn a call on Wednesday to discuss Blackstone's year-end performance, Stephen Schwarzman, the firm's co-founder and chairman, called QTS now \"the world's largest data center platform.\"\n\nJon Gray, the company's president, said that investor interest in AI was a chief driver of strong inflows. The company reported $239 billion of inflows for the year, its highest total since a record year in 2021.\n\n\"You have what's happening in the AI world, economy growing faster, productivity picking up, and us investing in sectors we really like,\" Gray said. \"We think that will really get this flywheel going, which is why you hear this optimism.\"\n\nGray said its bets on AI and data centers had delivered for the company. Its infrastructure platform — powered by data center appreciation — had grown 40% during the year to $77 billion and had raised $4 billion from investors in the fourth quarter. Infrastructure investments earned 8.4% returns for the quarter and 23.5% for the year.\n\nBlackstone Real Estate Income Trust, the firm's $54 billion retail focused real estate investment fund, meanwhile, generated 8.1% returns during the year, more than double its benchmark for the sector. The fund, which is known as BREIT, is heavily invested in QTS.\n\nReal estate investments, broadly, were the weakest segment for Blackstone, delivering a 0.6% loss for its opportunistic strategy and 3% gains for its core assets.\n\nQTS, which Blackstone originally bought for $10 billion, was the \"largest single driver of returns\" for its infrastructure strategy, Blackstone Infrastructure Partners, as well as in real estate,\" Gray said.\n\nSchwarzman said the firm would continue to \"lean into key thematic areas such as digital infrastructure, including data centers, power, and electrification, private credit,\" as part of its broader investment strategy.\n\n\"The historic pace of investment taking place in the US to facilitate the development of artificial intelligence, including the design and manufacture of semiconductors, data center construction, and the expansion of power generation, is the key driver of economic growth today,\" Schwarzman said.\n\nGray added that the firm's $319 billion real estate platform would \"continue to invest in AI infrastructure and data centers.\"\n\nIn private lending, Gray said the artificial intelligence race and the hundreds of billions of dollars in related spending it will require would also feed the company's private credit business.\n\n\"The build-out of AI infrastructure requires a massive amount of private debt capital for the construction of fabs, energy supply, and data centers,\" Gray said. Fabs refer to computer chip manufacturing facilities.\n\nGray reported that Blackstone's investment grade private credit portfolio now totaled $130 billion, an increase of 30% during the year, while also acknowledging that BCRED, one of its largest credit fund had an \"uptick in redemptions\" tied to industry-wide concerns about default risks.\n\nBlackstone has long touted its focus on data centers.\n\nIn addition to QTS, the firm has invested in the AI developers Anthropic and OpenAI, the storage and high performance computing provider DDN, as well as energy providers who will deliver the prodigious electricity needed for AI computing. Last year, the firm, for instance, announced its $11.5 billion acquisition of TXNM Energy, a utility holding company. In 2024, the company was part of a group of investors that provided the data center operator CoreWeave with a $7.5 billion loan.\n\nBlackstone reported $14.5 billion of revenue for the year and $4.4 billion for the quarter, up 9% and 42% respectively.",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "digital infrastructure",
      "center",
      "estate",
      "investment",
      "credit",
      "centers",
      "blackstone's",
      "largest",
      "driver"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-blackstone-qts-data-center-bets-are-driving-growth-2026-1",
    "thumbnail_url": "https://i.insider.com/697ba48ba645d11881884188?width=1200&format=jpeg",
    "created_at": "2026-01-30T01:07:06.905Z",
    "topic": "finance"
  },
  {
    "slug": "darren-aronofskys-new-ai-series-about-the-revolutionary-war-looks-like-dogshit",
    "title": "Darren Aronofsky's New AI Series About the Revolutionary War Looks Like Dogshit",
    "description": "\"Used to be that when Darren Aronofsky wanted to feature a dead-eyed actor, he'd just employ Jared Leto.\"",
    "fullText": "Darren Aronofsky used to be a director who made interesting, if sometimes polarizing, films like Black Swan, Mother!, Noah, and The Wrestler. But it seems like a safe bet that people won’t need to debate whether Aronofsky’s new project is any good. Because anyone with eyes can see that it looks like low-effort AI slop. To put it another way, it looks like absolute dogshit.\n\nAronofsky is producing a new short-form series with his AI production company Primordial Soup titled “On This Day… 1776,” according to the Hollywood Reporter. The series uses tech from Google DeepMind to create short videos about the Revolutionary War, published on the YouTube channel for Time magazine. In 2018, Salesforce founder Marc Benioff bought Time, and the cloud software giant is sponsoring this monstrosity of a series.\n\nThe series uses human voice actors who belong to the Screen Actors Guild (SAG), which is clearly an attempt to tamp down on the inevitable backlash from both inside and outside Hollywood. Folks inside the movie and TV industry have fiercely pushed back against the use of AI to replace the skilled artists and actors who create the media we watch. That concern obviously comes from a place of self-interest because nobody wants to be pushed out of a job. But they also care about the quality of the work being produced. And there’s also been a revolt among the average consumer, people who’ve been inundated with the lowest-grade AI garbage imaginable. It’s really everywhere now.\n\nThe first episode, titled “The Flag,” is three-and-a-half minutes long and attempts to tell the story of George Washington raising the Continental Union Flag in Somerville, Massachusetts. It offers nothing compelling in the way of narrative. It’s the kind of thing that you’d skip over as a cut-scene in a particularly bad video game.\n\nEverything has a dead and creepy quality, as the actors’ audio is poorly synced with the lips of the AI concoctions.\n\nHave you ever seen a Spaghetti Western from the 1960s where the audio just doesn’t seem to match, even though it was clearly shot with actors speaking English, and the “dub” is in English? That happened because the audio was added in post-production, a result of direct sound recording being expensive in Italy during the post-war era. You get the same effect here, though there’s no good reason. Well, no good reason outside of presumably saving a ton of money on hiring human actors.\n\nThe second episode, titled “Common Sense,” tries to tell the story of Thomas Paine writing Common Sense. Benjamin Franklin makes an appearance, though it proves that the most recognizable of the founding fathers in this series are the weirdest to look at.\n\nThe episode jumps around incoherently, much like the first episode, without grounding the viewer in anything we should care about. It’s truly an ugly mess. And if you bother to pause the scenes, you can spot the kind of telltale anomalies that plague other AI-generated video projects, like strangely deformed hands in the background characters. Hands are always giving this stuff away.\n\nThen there are the words that appear on screen in the trailer, like the pamphlet that’s supposed to include the word “America” but instead reads something closer to “Λamereedd.”\n\nHappy to see that there is no need to worry about the historical accuracy of new 1776 AI slop because it happens in the mystical land of Λamereedd.\n\n— Mateusz Fafinski (@calthalas.bsky.social) January 29, 2026 at 1:33 PM\n\nThe series is specifically made for this sestercentennial year of America’s founding, and each episode will reportedly drop on the 250th anniversary of the day it happened, according to the Hollywood Reporter. And that’s certainly a fun concept if the final product were something worth watching. But it’s not. It’s garbage. The people who are making and distributing it obviously don’t think so.\n\n“This project is a glimpse at what thoughtful, creative, artist-led use of AI can look like — not replacing craft, but expanding what’s possible and allowing storytellers to go places they simply couldn’t before,” Ben Bitonti, president of Time Studios, told the Hollywood Reporter.\n\nThe reaction on social media hasn’t been so kind. “I know my expectations were low but holy fuck Darren Aronofsky producing AI slop wasn’t on my bingo card,” one X user wrote. Over on Bluesky another joked, “Used to be that when Darren Aronofsky wanted to feature a dead-eyed actor, he’d just employ Jared Leto.”\n\nAnd other users have been picking apart all the anomalies, with one Bluesky critic writing: “Love the new Aronofsky scene where the colonist takes off his hat to cheer, revealing that underneath it was a second and somehow larger hat.”\n\nLove the new Aronofsky scene where the colonist takes off his hat to cheer, revealing that underneath it was a second and somehow larger hat\n Masterful artsistic choice\n\n— Matt Baume 🏳️‍🌈 (@mattbaume.bsky.social) January 29, 2026 at 10:35 AM\n\n“Nothing represents The End of America after a 250-year run quite like using AI slop to depict the creation of the Declaration of Independence,” another user quipped.\n\nThe videos have been up at Time’s YouTube channel for over 7 hours as of the time of this writing, but they’re not gaining much attention in their original format. The first episode has just 5,000 views. The second episode has a little over 2,000. Social media posts ridiculing the production seem to be faring better, simply because people are making fun of them. One video on Bluesky has over 2,500 quote posts, with almost all seemingly making jokes about how awful it looks.\n\nGizmodo reached out to Ken Burns for comment, but didn’t immediately receive a reply.",
    "readingTime": 5,
    "keywords": [
      "youtube channel",
      "hollywood reporter",
      "aronofsky scene",
      "cheer revealing",
      "somehow larger",
      "social media",
      "larger hat",
      "episode titled",
      "second episode",
      "darren aronofsky"
    ],
    "qualityScore": 1,
    "link": "https://gizmodo.com/darren-aronofskys-new-ai-series-about-the-revolutionary-war-looks-like-dogshit-2000715754",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2026/01/ai-benjamin-franklin-1200x675.jpg",
    "created_at": "2026-01-30T01:07:06.697Z",
    "topic": "tech"
  },
  {
    "slug": "musks-spacex-in-merger-talks-with-xai-ahead-of-planned-ipo-source-says",
    "title": "Musk's SpaceX in merger talks with xAI ahead of planned IPO, source says",
    "description": "Elon Musk's SpaceX and xAI are in discussions to merge ahead of a blockbuster public offering planned for later this year.  The combination would bring Musk’s rockets, Starlink satellites, the X social media platform and Grok AI chatbot under one roof, according to a person briefed on the matter and two ​recent company filings seen by Reuters.  The plan, which Reuters is reporting exclusively, would give fresh momentum to SpaceX’s effort to launch data centers into orbit as Musk battles for supremacy in the rapidly ‌escalating AI race against tech giants like Google, Meta and OpenAI.",
    "fullText": "NEW YORK, Jan 29 (Reuters) - Elon Musk's SpaceX and xAI are in discussions to merge ahead of a blockbuster public offering planned for later this year. The combination would bring Musk’s rockets, Starlink satellites, the X social media platform and Grok AI chatbot under one roof, according to a person briefed on the matter and two ​recent company filings seen by Reuters.\n\nHow could space-based data centers reduce AI costs?\n\nWhat would the proposed SpaceX-xAI merger involve?\n\nWhat defense applications are planned for merged companies?\n\nWhy is Musk combining his different business ventures?\n\nThe plan, which Reuters is reporting exclusively, would give fresh momentum to SpaceX’s effort to launch data centers into orbit as Musk battles for supremacy in the rapidly ‌escalating AI race against tech giants like Google, Meta and OpenAI.\n\nMusk, the world's richest man, is the CEO of both the private space company SpaceX and the artificial intelligence company xAI, which controls his social media platform X. He also runs electric automaker Tesla, tunnel ‌company The Boring Co. and neurotechnology company Neuralink.\n\nMusk, SpaceX, and xAI did not respond to requests for comment.\n\nUnder the proposed merger, shares of xAI would be exchanged for shares in SpaceX. Two entities have been set up in Nevada to facilitate the transaction, the person said.\n\nCorporate filings in Nevada show that those entities were set up on January 21. One of them, a limited liability company, lists SpaceX and Bret Johnsen, the company's chief financial officer, as managing members, while the other lists Johnsen as the company's only officer, the filings show.\n\nThe filings don't contain additional information about the purpose of the companies ⁠or their role in any deal.\n\nJohnsen did not respond to a Reuters ‌request for comment.\n\nThe person, who requested anonymity because the discussions are confidential, said that some xAI executives could be given the option to receive cash instead of SpaceX stock as part of the deal. A final agreement, however, hasn't been signed, and the timing and structure of the transaction remain fluid, the person cautioned.\n\nSpaceX is already the world's most ‍valuable privately held company, last valued at $800 billion in a recent insider share sale. xAI was valued at $230 billion in November, according to the Wall Street Journal. Reuters and other media have reported that SpaceX plans to go public some time this year, with a valuation expected above $1 trillion.\n\nThrough xAI, Musk is building out a massive supercomputer for AI training in Memphis, Tennessee, called Colossus. Last year, SpaceX agreed to invest $2 billion in xAI as part of the startup’s $5 billion equity ​fundraising, the Wall Street Journal reported at the time.",
    "readingTime": 3,
    "keywords": [
      "wall street",
      "street journal",
      "social media",
      "media platform",
      "filings",
      "spacex",
      "discussions",
      "planned",
      "centers",
      "proposed"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-musks-spacex-merger-talks-184045612.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/ba612911adcb7fd2bc8d339cecd0cb55",
    "created_at": "2026-01-30T01:07:05.794Z",
    "topic": "finance"
  },
  {
    "slug": "how-youtube-is-fighting-back-against-ai-slop",
    "title": "How YouTube Is Fighting Back Against AI Slop",
    "description": "If you're noticing less AI in your feeds, that's by design.",
    "fullText": "Science fiction and science leaders alike have warned us that artificial intelligence may one day take over the world, but until those predictions come to pass, generative AI's biggest impact on my life has been overloading my social media feeds with slop. It seems I can't open TikTok, Instagram, or YouTube without running smack into bizarre and troubling AI concoctions featuring babies in danger and cats having affairs. It really is the wild west (or maybe Westworld) out there.\n\nI think few among us really believe these videos are any good, and it's pretty obvious they aren't good for us, or for the world. Short-form video is already numbing enough, but this AI content is generally completely devoid of any meaning or substance. And yet, it's everywhere. I haven't spent too much time on YouTube Shorts recently, but in my limited experience, the feed has been chock full of AI, especially if I'm logged out of my personal account.\n\nStill, if you're a dedicated YouTube Shorts user (or a frequent YouTube user in general) you might have noticed something odd in recent days: There don't seem to be quite as many AI videos on the platform right now. There are still a lot, don't get me wrong, but it turns out YouTube has recently taken action to remove some of its AI content—the sloppiest of the slop.\n\nAndroid Police spotted the development on Wednesday, basing its findings on a November report from Kapwing, a company that develops an online video editor. Kapwing investigated AI slop across YouTube's vast content library, noting the top 100 most-subscribed YouTube channels that publish this sort of AI content. In the two months since that report, Android Police noticed that 16 of those 100 channels are no longer with us.\n\nThat includes the most popular AI channel on YouTube, at least according to Kapwing. \"CuentosFacianantes\" had 5.95 million subscribers at the time of their initial report, and produced AI-generated shorts inspired by Dragon Ball. The channel had amassed roughly 1.28 billion views by the end of last year; despite launching in 2020, it had curated its library to begin Jan. 8, 2025, so those numbers were racked up pretty recently. The number two channel, \"Imperio de Jesus\" with 5.87 million subscribers, and the number seven channel \"Super Cat League,\" with 4.21 million subscribers, were also shut down.\n\nAccording to Android Police, the 16 channels in question had a total of 35 million subscribers and over 4.7 billion views across their collective videos. Some of these channels are completely gone, while others simply have had their videos removed.\n\nYouTube CEO Neal Mohan published a post on Jan. 21 of this year describing the company's vision for 2026. Towards the end of that letter, he acknowledges AI content, predicting that, \"AI will be a boon to the creatives who are ready to lean in,\" and comparing it to tools like Photoshop and CGI, adding \"AI will remain a tool for expression, not a replacement.\" However, Mohan was also critical of the technology, noting that it's becoming more difficult to tell real videos from AI. He notes that YouTube is now removing \"any harmful synthetic media that violates our Community Guidelines,\" and is giving creators tools to help identify and block deepfakes.\n\nMore interestingly, the letter includes a section labeled \"Managing AI slop,\" which is the first time I've seen a company like YouTube use that expression. Mohan says that YouTube's goal is to be a place where free expression thrives, but also a place \"where people feel good spending their time.\" To that point, he says, \"To reduce the spread of low quality AI content, we’re actively building on our established systems that have been very successful in combatting spam and clickbait, and reducing the spread of low quality, repetitive content.\"\n\nMohan doesn't call out any accounts by name, nor does he acknowledge the accounts and content the company has already deleted, but it's a clear line in the sand: YouTube is not against AI-generated content, but it will remove low-quality AI content it feels is, well, slop. That's good news for anyone who uses YouTube (so, pretty much everyone), even if it's far from a cure for the growing problem.\n\nI've reached out to YouTube for comment on this story, and will update this piece if I hear back.",
    "readingTime": 4,
    "keywords": [
      "android police",
      "youtube shorts",
      "content",
      "slop",
      "videos",
      "it's",
      "channels",
      "channel",
      "subscribers",
      "pretty"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/youtube-fighting-back-against-ai-slop?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG5RS2KTV09PK5XV3N14BAA3/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-30T01:07:04.845Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-microsoft-amazon-in-talks-to-invest-up-to-60-billion-in-openai-the-information-reports",
    "title": "Nvidia, Microsoft, Amazon in talks to invest up to $60 billion in OpenAI, The Information reports",
    "description": "Nvidia, Amazon, and Microsoft are in talks to invest up to $60 billion in OpenAI, ​The Information reported on Wednesday.  Nvidia, an existing investor ‌whose chips power OpenAI's AI models, is in talks to invest up ‌to $30 billion, The Information said, citing a person with knowledge of the situation.  Microsoft, a longstanding backer, is in talks to invest less than $10 billion, the report said.",
    "fullText": "Jan 28 (Reuters) - Nvidia (NVDA), Amazon (AMZN), and Microsoft (MSFT) are in talks to invest up to $60 billion in OpenAI, ​The Information reported on Wednesday.\n\nNvidia, an existing investor ‌whose chips power OpenAI's AI models, is in talks to invest up ‌to $30 billion, The Information said, citing a person with knowledge of the situation.\n\nMicrosoft, a longstanding backer, is in talks to invest less than $10 billion, the report said. It added ⁠that Amazon, which would ‌be a new investor, is in discussions to invest significantly more than $10 billion, potentially even ‍more than $20 billion.\n\nOpenAI is close to receiving term sheets, or an investment commitment, from these firms, the report said.\n\nAmazon and Microsoft ​declined to comment, while Nvidia and OpenAI did not ‌immediately respond to Reuters' requests for comment outside regular business hours.\n\nWhat additional agreements might influence Amazon's investment decision?\n\nWhat companies are reportedly investing in OpenAI's funding round?\n\nWhy is OpenAI seeking such significant new investment?\n\nWhat companies are investing in OpenAI's funding round?\n\nAmazon's investment could depend on separate negotiations, including a possible expansion of OpenAI's cloud server rental deal with Amazon and a commercial ⁠agreement for OpenAI to sell its ​products, such as enterprise ChatGPT ​subscriptions, to Amazon, The Information said.\n\nThis follows reports from earlier this week that said that SoftBank ‍Group is in ⁠talks to invest as much as an additional $30 billion in OpenAI.\n\nOpenAI is grappling with rising costs to train ⁠and run its AI models as competition from Alphabet's Google heats ‌up.",
    "readingTime": 2,
    "keywords": [
      "amazon's investment",
      "openai's funding",
      "funding round",
      "talks",
      "openai",
      "reuters",
      "investor",
      "models",
      "additional",
      "investing"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-microsoft-amazon-talks-invest-030604359.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/2e608e1738d1a987d238a588fee45062",
    "created_at": "2026-01-30T01:07:04.469Z",
    "topic": "finance"
  },
  {
    "slug": "exclusivepentagon-clashes-with-anthropic-over-military-ai-use-sources-say",
    "title": "Exclusive-Pentagon clashes with Anthropic over military AI use, sources say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/world-news/exclusivepentagon-clashes-with-anthropic-over-military-ai-use-4474548",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0S1DA_L.jpg",
    "created_at": "2026-01-30T01:07:02.705Z",
    "topic": "finance"
  },
  {
    "slug": "the-state-of-voice-ai-instruction-following-in-2026",
    "title": "The State of Voice AI Instruction Following in 2026",
    "description": "Coval is the leading simulation and evaluation platform for AI voice and chat agents. Test, monitor, and optimize your AI agents at scale.",
    "fullText": "Why are production voice agents still running on 18-month-old models? Why is instruction following the hardest problem to benchmark? And what's actually missing from voice AI evaluation today? We sat down with two of the sharpest minds in the space to find out.\n\nAs part of our State of Voice AI 2026 research, we brought together Kwindla Hultman Kramer, co-founder of Daily and creator of the open-source PipeCat framework, and Zach Koch, co-founder and CEO of Ultravox AI, which trains real-time speech-native models. The conversation that followed was one of the most candid discussions we've had about what's actually working in voice AI evaluation—and what's still broken.\n\nCheck out the full episode here:\n\nKwin recently published something the voice AI community has desperately needed: a public benchmark for instruction following and function calling in long, multi-turn conversations.\n\n\"I wanted to publish something that people could criticize and try to help make better,\" Kwin explained. \"We all have kind of tests and vibes that we do internally, but I wanted something that reflects the hard workloads in voice AI—instruction following, function calling reliability, turn-taking reliability.\"\n\nThe benchmark simulates a real-world voice AI scenario: knowledge dumped into a system prompt, tools that need to be called, and a 30-turn conversation that tests whether the model can maintain coherent behavior deep into the dialogue.\n\nWhat surprised Kwin most? The frontier models saturated it.\n\n\"GPT-5, the latest Claude, Gemini 3—they all saturated what I thought was a really hard benchmark. But here's the thing: they're all too slow to use for a voice agent.\"\n\nThis is the central tension in voice AI today: the smartest models are too slow, and the fast models aren't smart enough.\n\nHere's a reality check that might surprise people outside the voice AI space: most production voice agents are still running on GPT-4o and Gemini 2.5 Flash—models that are now a year and a half old.\n\n\"Those are the models that have the right mix of intelligence and latency,\" Kwin noted. \"And because people have gotten prompts optimized for them, they're pretty safe choices that a lot of people are sticking with.\"\n\nBut it's not just about capability. Switching models in voice AI is uniquely painful.\n\n\"It's so tricky to switch models,\" I explained during our conversation. \"You have so many models in concert together—you're not just seeing if it performs as expected with your prompts, but how it interacts with all the other models. And the testing is much more expensive. The eval process is often very manual.\"\n\nThis creates a vicious cycle: teams stick with older models because evaluation is hard, which means newer models don't get battle-tested, which means teams stick with older models.\n\nWe spend a lot of time at Coval thinking about what makes voice AI evaluation uniquely difficult. Instruction following is, without question, the hardest piece.\n\nWhy? Because you can't just run the same prompt across different models and call it a fair comparison.\n\n\"Different prompts do well on different systems,\" I explained. \"What people actually want to know is: what's the best I can get out of each system? It's not useful to compare something out of the box if there's an obvious optimization.\"\n\nThis is why benchmarks like Kwin's are so valuable—they help you rough-cut which models to even consider, before you invest in the expensive work of testing on your specific data and use case.\n\nBut there's a deeper problem. Traditional benchmarks test the first few turns of a conversation. Voice AI conversations are fundamentally long, multi-turn interactions—and that data is massively underrepresented in training datasets.\n\n\"I would talk to people at foundation labs and they'd say, 'We fixed function calling,'\" Kwin recalled. \"And function calling on the first three turns would be noticeably better. But function calling 20 turns into the conversation? No better at all.\"\n\nOne of the most honest moments in our conversation came when Zach admitted something many AI practitioners secretly believe:\n\n\"I'm a king of vibes. I haven't figured out any benchmark that I trust fully more than putting in my AirPods and talking to the models for 20 minutes. Nothing is quite as brutal as that test.\"\n\nBut Kwin pushed back—gently—on the idea that vibes are enough:\n\n\"For the purpose of this conversation, I'm going to pretend to disagree. The pain point I see is: I got this prompt right, the 20 people at our company tested it and had a good experience, but then I put it in production and people did weird things and it's not good enough.\"\n\nThis is the gap that quantitative evaluation fills. It's not about capturing the entire space of what makes a conversation feel good. It's about drawing a box around expected behavior so you can tell which models are clearly inside the box and which aren't.\n\n\"If you can draw a box and say this model is clearly in the box, this model is not—that's a useful point of comparison for what it feels like to deploy these things into production with a wide variety of real-world user behavior.\"\n\nWhen I asked Zach what's still not captured in benchmarks, his answer was illuminating:\n\nBack-channeling. Those little \"mm-hmm\" and \"uh-huh\" moments that humans do perfectly and AI does awkwardly—or not at all.\n\n\"Any attempt to back-channel as a system-level thing has failed catastrophically,\" Zach said. \"They're either exactly correct and on the mark, or they're awkward. And we have no evals for this.\"\n\nProsody matching. The way your tone affects my response, and vice versa.\n\n\"If I say something in a particular tone, the interpretation of that tone should change how you respond—not just the words, but your prosody. My anger might induce your anger, or slow you down. We have no mechanisms to measure any of this.\"\n\nThe \"one beat off\" problem. The uncanny valley of voice AI isn't about obviously wrong responses—it's about timing that's slightly off.\n\n\"Capturing what makes it really unnatural—things are out of order, or it's repeating itself, or getting stuck in loops—those we can catch,\" I noted. \"But when it's just one beat off? That's the hardest to get.\"\n\nOne of the most interesting threads in our conversation was about how production voice AI is evolving toward multi-model architectures.\n\n\"We're increasingly living in a world where multiple models and multiple inference loops are really valuable,\" Kwin explained. \"A lot of what we're helping customers deploy now feels like a thinking fast and slow split—a fast voice loop, and then various kinds of async or long-running or parallel inference processes.\"\n\nGuardrails running in parallel (though by the time a guardrail kicks in, you may have already moved past the moment)\n\nTool calling pulled out of the fast loop to avoid latency penalties\n\nLong-running processes that inject back into the voice context\n\nBut this creates new evaluation challenges. As Zach pointed out: \"The evals can mislead me when I look at them, because you get this boost from thinking performance that helps tool calling, but when I have the actual conversation, it feels awkward.\"\n\nThe text-based evaluation might look accurate, but the user experience of two AI brains trying to coordinate can feel disjointed.\n\nOne pattern we're seeing—and warning customers about—is trying to reuse the same agents for chat and voice.\n\n\"This is where people are running into a lot of issues,\" I explained. \"What you want to see in chat looks very different than what you want to hear in a voice system. You're trying to use the same reasoning for two very different systems, and it just doesn't work.\"\n\nThe benchmarks might say your instruction following is great. But when you add all the layers of abstraction to retrofit a chat agent for voice, the real-world performance falls apart.\n\nWe ended the conversation with what might be the most important takeaway for anyone building with voice AI:\n\nShare your problems with your vendors.\n\n\"Everyone is trying to figure it out right now,\" I said. \"Hearing from users about what's working and what's not is the biggest signal above all else. We learn so much from our customers.\"\n\nZach agreed: \"We'd give ourselves a high five on some model performance eval, and then I'd throw it to a customer and they'd be like: garbage, garbage, garbage. There's a gap in our methodology—and we made a lot of mistakes in 2025 training without keeping that applied reality in mind.\"\n\nThe voice AI space is moving fast, but it's still early. The benchmarks are getting better. The models are getting better. But the feedback loop between real production pain and model improvement is still the most valuable signal any of us have.\n\nFrontier models saturate hard benchmarks but are too slow for production. The intelligence-latency trade-off is the defining constraint of voice AI in 2026.\n\nMost production systems still run 18-month-old models because switching is expensive and evaluation is hard.\n\nInstruction following is the hardest problem to benchmark because different prompting techniques work for different models, and voice conversations are long multi-turn interactions that training data doesn't represent well.\n\nWhat's missing from benchmarks: back-channeling, prosody matching, and the subtle timing issues that make conversations feel \"one beat off.\"\n\nMulti-model \"thinking fast and slow\" architectures are emerging, but they create new evaluation challenges around coordination and user experience.\n\nDon't reuse chat agents for voice. The systems require fundamentally different reasoning and evaluation approaches.\n\nShare your production problems. The feedback loop between real-world deployment and model improvement is the most valuable signal in the industry.\n\nWant to see how your voice agent performs on instruction following? Learn how Coval's simulation and evaluation platform helps teams test before production → Coval.dev\n\nBrooke Hopkins is the founder of Coval, building simulation and evaluation for voice agents. Her background is from Waymo, where she led the evaluation infrastructure team responsible for all simulation tooling.\n\nKwindla Hultman Kramer is co-founder of Daily, which makes global infrastructure for real-time audio, video, and AI. Pipecat is part of Daily - the most widely used open-source framework for building voice and real-time multimodal AI agents.\n\nZach Koch is co-founder and CEO of Ultravox AI, which trains real-time speech-native models and runs dedicated inference to achieve increasingly human-like conversations with AI.",
    "readingTime": 9,
    "keywords": [
      "kwindla hultman",
      "hultman kramer",
      "teams stick",
      "prosody matching",
      "trains real-time",
      "real-time speech-native",
      "feedback loop",
      "user experience",
      "garbage garbage",
      "valuable signal"
    ],
    "qualityScore": 1,
    "link": "https://www.coval.dev/blog/the-state-of-voice-ai-instruction-following-in-2026-a-conversation-with-kwindla-from-pipecat-and-zach-from-ultravox",
    "thumbnail_url": "https://framerusercontent.com/assets/XKz3mwCB1do7n4eYEEPAsdSjAIY.png",
    "created_at": "2026-01-29T18:30:47.818Z",
    "topic": "tech"
  },
  {
    "slug": "googles-ai-helped-me-make-bad-nintendo-knockoffs",
    "title": "Google's AI helped me make bad Nintendo knockoffs",
    "description": "Here we go.",
    "fullText": "It’s what I had the most fun using Google’s Project Genie for, at least right now.\n\nIt’s what I had the most fun using Google’s Project Genie for, at least right now.\n\nThis week, a new generative AI tool from Google let me create bad knockoffs of 3D Nintendo worlds.\n\nCheck out my version of something like Super Mario 64:\n\nI didn’t like Metroid Prime 4: Beyond, but it’s better than my version of a Metroid Prime experience:\n\nOr how about my take on The Legend of Zelda: Breath of the Wild, complete with a paraglider (and, briefly, a second Link):\n\nIt was all possible thanks to Project Genie, an experimental research prototype that Google gave me access to this week, though I don’t think I’m using it in exactly the way Google intended.\n\nGoogle DeepMind has been putting a lot of effort into building its AI “world” models that can generate virtual interactive spaces with text or images as prompts. The company announced its impressive-looking Genie 3 model last year, but it was only available as “a limited research preview” at the time. Project Genie, which will be rolling out to Google AI Ultra subscribers in the US starting today, will be the first opportunity for more people to actually try out what Genie 3 is capable of.\n\nGoogle is releasing Project Genie now partly because it wants to see how people use it. “It’s really for us to actually learn about new use cases that we hadn’t thought about,” Diego Rivas, a product manager at Google DeepMind, tells The Verge. The company is already excited about how Genie could help to visualize scenes for filmmaking or for interactive educational media. You could, if you wanted, take a photo of your kids’ favorite toy and use it to prompt a Genie-generated world. Genie could potentially help robots navigate the real world, too. But Project Genie isn’t yet an “end-to-end product that we expect people to just use every day,” stressed Shlomi Fruchter, a Google DeepMind research director.\n\nWith Project Genie, you pick from a bunch of worlds designed by Google or define prompts for the environments and characters you want to create in your own world. After a brief wait, Genie first generates a thumbnail, then you can have it generate the world. You can explore each generated world for 60 seconds, and each has a resolution of about 720p and a frame rate of about 24fps. While you’re in one, you can (typically) move your character with the WASD keys, jump or go higher with a tap of your space bar, and turn the camera with arrow keys.\n\nOne of Google’s worlds, called “Rollerball,” features a blue orb in a white, snowy world, and as you roll around, the orb leaves a trail of paint behind it. As a “game,” Project Genie wasn’t great. There was nothing to do but roll around; there weren’t any objectives or goals. There was no sound. There was frustrating input lag that was even worse than what I sometimes experience with cloud gaming. (Some of this could be due to the generally poor Wi-Fi I get in my office.)\n\nOver the course of the 60-second experience, Genie sometimes forgot to show a paint streak where I had previously rolled. Occasionally, the ball would randomly stop laying down paint at all. So I started to distrust Genie’s ability to recall what I had already seen with my own eyes.\n\nAnother Google-designed world, “Backyard Racetrack,” was a little more fun because there was an actual track to follow. My racing lines were awful — the input lag didn’t help — but I enjoyed trying to make the turns and stay on the road. Near the end of the experience, though, part of the track unexpectedly turned into grass, which ruined the immersion. And the wheel rims looked really janky.\n\nI had a lot more fun pushing the limits of Project Genie to try and make 3D, AI-generated games featuring recognizable characters, like with my Super Mario, Metroid Prime, and The Legend of Zelda-themed worlds. While they made me laugh, the worlds don’t have scores or anything to strive for, so there’s nothing to do but walk or jump around. Even if there were specific things to do, the input lag made the worlds basically unplayable. (Again, this may be a Wi-Fi issue, but even when I was closer to my router, I still experienced lag.)\n\nI wasn’t able to make everything I wanted. Project Genie wouldn’t generate a world that I prompted with the scenario of Kingdom Hearts — here was my prompt, if you’re curious:\n\nIt’s a world filled with Disney characters with a steampunk vibe. Donald and Goofy are your sidekicks. Jack Skellington is present, as is Cloud Strife.\n\nYou are a spunky, anime teenager with spiky brown hair wielding a blade that is like a key.\n\nWhen I removed the specific names of characters and wrote descriptions of them instead, Project Genie generated a thumbnail preview of the world featuring characters that were dead ringers for Sora (the series’ protagonist), Donald, Goofy, Jack Skellington, and Cloud. But when I tried to generate the actual experience, Project Genie blocked me.\n\nI asked about why I was able to generate worlds with Nintendo characters. “Project Genie is an experimental research prototype designed to follow prompts a user provides,” Rivas says. “As with all experiments, we are monitoring closely and listening to user feedback.” Rivas also notes that the Genie 3 model was “trained primarily on publicly available data from the web.” (This probably partially explains why Link deployed his paraglider in my test, which surprised me. At a high level, the Genie model is constantly trying to predict the next frame, and I’m sure there are many videos of people jumping in Breath of the Wild and then gliding forward, which the model probably learned from.) Shortly before publishing this article, Project Genie stopped letting me generate worlds based on Super Mario 64 due to “interests of third-party content providers.”\n\nAssuming Google clamps down on the ability to generate interactive worlds based on known gaming franchises — I can’t imagine Nintendo will be happy with what I was able to generate! — Project Genie otherwise isn’t that great at the moment. The input lag and 60-second limit make them pretty poor interactive experiences. Occasionally, I couldn’t control my character at all, only the camera. After the weirdness with the paint stripes and the road turning into grass, I had a general feeling that I couldn’t trust the worlds to stay consistent from moment to moment.\n\nProject Genie is better than some AI-generated worlds I tried last year, but it’s still much worse than an actual handcrafted video game or interactive experience. Fruchter described a potential future where the line blurs between different kinds of media thanks to technology like Genie, but I think it has a long way to go to get there.\n\nPerhaps my standards are too high. Project Genie is an experimental research prototype, after all. And maybe I’ll feel differently after the technology improves down the line. But I can’t imagine that people will want to spend an extended period of time jumping into these types of AI-generated worlds anytime soon. With world models, I don’t think we have to worry about the genie being out of the bottle just yet.",
    "readingTime": 7,
    "keywords": [
      "project genie",
      "can’t imagine",
      "ai-generated worlds",
      "google’s project",
      "experimental research",
      "research prototype",
      "input lag",
      "genie model",
      "worlds based",
      "generate worlds"
    ],
    "qualityScore": 1,
    "link": "https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on",
    "thumbnail_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/ai-label-2.png?quality=90&strip=all&crop=0%2C10.705884903472%2C100%2C78.588230193056&w=1200",
    "created_at": "2026-01-29T18:30:47.796Z",
    "topic": "tech"
  },
  {
    "slug": "acp-agent-registry-in-jetbrains-ides",
    "title": "ACP Agent Registry in JetBrains IDEs",
    "description": "Together with Zed, we've launched the official ACP Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs.",
    "fullText": "Supercharge your tools with AI-powered features inside many JetBrains products\n\nAI coding agents are multiplying fast. Some of the most common ones include Gemini CLI, Claude Code, Auggie, OpenCode, and Copilot, and more are being released every day. Each comes with its own unique strengths, specific setups, and varying levels of editor support. Keeping track of what’s out there, let alone getting it running in your IDE, hasn’t been easy.\n\nTogether with Zed (Zed’s announcement), we’ve launched the official ACP Agent Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs and Zed. Browse what’s available, click Install, and start working right away. This beta release is just the beginning.\n\nThe Agent Client Protocol is an open standard that lets any AI coding agent work in any supporting editor. Think of it like the Language Server Protocol, but for AI agents. The LSP lets any editor support any language through a shared standard. The ACP does the same for coding agents. You only need to implement it once, and then it will work in your JetBrains IDE, Zed, or any other editor that supports the protocol.\n\nThis means you get to pick your preferred agent and editor, and they will then work together seamlessly – no vendor lock-in and no waiting for someone to build a specific integration.\n\nACP has been, since we started integrating it to Mistral Vibe, a real joy to use: thoughtfully designed from the ground up, community-driven, and evolving rapidly. We’ve found it not only simplifies integration, but also fits our focus on open and flexible tools. It’s really great to see a standard that puts developer choice first.\n\nMichel Thomazo, Software Engineer @ Mistral AI\n\nThe ACP made agent interoperability technically possible. The registry makes it convenient.\n\nInstead of manually configuring agents, you can now:\n\nAt launch, you’ll find a wide array of different agents:\n\nFull-featured coding assistant optimized for large-scale refactors\n\nSpecialized agent for automated code generation workflows\n\nGoogle’s agent with deep codebase understanding and multimodal capabilities\n\nGitHub’s AI pair programmer, now available via the ACP\n\nLightweight, fast agent built on Mistral’s models\n\nCommunity-driven, fully open-source agent\n\nAlibaba’s coding agent with strong multilingual support\n\nInnovation in software agents is moving at an unbelievable pace. The Agent Registry and ACP makes it simple for developers to use the best agents in their favorite tools.\n\nChris Kelly, Product @ Augment Code\n\nIn general, it’s less about having multiple agents than about enabling you to pick and choose the ones that work well in your workflow. Different agents come with different benefits. Some provide a more attractive pricing structure for your business, some provide a user experience that you simply enjoy more than others’, and some embody the ideas of open-source development that just resonate with you.\n\nThe Agent Client Protocol registry lets you experiment freely. Try a few, see what clicks for your workflow, and then keep the ones that help. You’re not locked into a single vendor’s vision of what AI-assisted development should look like.\n\nWe’re excited to support the ACP Agent Registry as a step toward a more open agent ecosystem where Droids can integrate seamlessly across all IDEs.\n\nFrancesca LaBianca, VP of Operations @ Factory\n\nIn any JetBrains IDE (2025.3.2+) with JetBrains AI (253.30387.147):\n\nThat’s it. The agent is configured and ready to use in the AI Chat tool window.\n\nQuick note: agents typically come with their own subscription. That’s between you and them. You won’t need a JetBrains AI subscription to use ACP agents.\n\nWant to try something concrete? Install OpenCode, open a project, and ask it to explain an unfamiliar module. OpenCode also lets you swap between different LLMs, so you can experiment with what works best for you.\n\nIf you prefer manual configuration, that option is still there, too. Just edit the acp.json directly. This is useful for agents that aren’t in the registry yet or for custom setups.\n\nIf you’re building an ACP-compatible agent, the registry is now the fastest way to reach developers across JetBrains IDEs and Zed.\n\nHead to the ACP Registry repository and check out the CONTRIBUTING.md for the full submission process and metadata requirements. Please note that, for now, we are only featuring agents that support Agent Auth or Terminal Auth. Full details of requirements and conditions can be found here.\n\nThis is an open registry. If you’re building an ACP-compatible agent, you’re welcome to submit it. The registry exists to serve the ecosystem, not to gatekeep it.\n\nFor developers: More choice and zero lock-in. Use any agent you want in the IDE you love.\n\nFor agent builders: Instant distribution to millions of JetBrains and Zed users. Implement the ACP once and reach everyone.\n\nFor the ecosystem: Competition on quality, not on who controls the integration. The best agents win because they’re the best, not because they have exclusive deals.\n\nWe’re building this openly with Zed because we believe AI-assisted development shouldn’t be locked inside any single vendor’s ecosystem. Developers deserve to pick their tools freely.\n\nThe registry is one more step toward that future.\n\nThe ACP Registry is available now in JetBrains IDE versions 2025.3 and later. Update your IDE and the JetBrains AI plugin, open Settings, and start exploring.\n\nHave feedback? Found a bug? The registry repo is open for issues and PRs. And if you’re building something interesting with ACP, we’d love to hear about it!\n\nOpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE. \n\nYou can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key – all within the same AI сhat inte…\n\nThe next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers.\n\nYes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions…\n\nBring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains’ Junie and Claude Agent. Whether you’re looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research prev…\n\nJunie is now integrated into the AI chat. The separate interfaces have merged into a single, unified space (available in Beta).",
    "readingTime": 6,
    "keywords": [
      "client protocol",
      "ai-assisted development",
      "step toward",
      "agent client",
      "acp-compatible agent",
      "jetbrains ai",
      "coding agents",
      "acp agent",
      "acp agent registry",
      "jetbrains ide"
    ],
    "qualityScore": 1,
    "link": "https://blog.jetbrains.com/ai/2026/01/acp-agent-registry/",
    "thumbnail_url": "https://blog.jetbrains.com/wp-content/uploads/2026/01/JB-social-BlogSocialShare-1280x720-1-4.png",
    "created_at": "2026-01-29T18:30:47.768Z",
    "topic": "tech"
  },
  {
    "slug": "mito-ai-raised-45-million-to-launch-projectmanagement-software-for-filmmakers-read-its-pitch-deck",
    "title": "MITO AI raised $4.5 million to launch project-management software for filmmakers. Read its pitch deck.",
    "description": "Read the pitch deck that MITO AI, a new AI workflow platform for filmmakers, used to raise $4.5 million in funding.",
    "fullText": "Artificial intelligence is shaking up video production.\n\nThe startup MITO AI is rolling out a new platform to help filmmakers storyboard, organize, and generate AI assets in one place. It's a project management tool for the era of generative AI filmmaking.\n\nThe company exclusively told Business Insider that it had raised $4.5 million in a pre-seed round led by Lightspeed Venture Partners. It's launching its product on Thursday after testing with about 200 beta partners.\n\n\"Our tools are connected to video models, image models, audio models, and voice models, and then everything is brought together into our infinite canvas for collaboration and experimentation,\" MITO cofounder Iñaki Berenguer said.\n\nWhile many AI video generators, such as OpenAI's Sora or Google's Veo, are limited to short-form clips, MITO wants to help creators piece together short AI assets into a longer project. It also offers collaborative features, such as commenting. MITO users can create new AI assets that align with their film's style via integrations with platforms including Runway, Veo 3, ComfyUI, and Pika.\n\nBeyond its workflow platform, the startup also makes AI content for partners via its studio team.\n\nMITO arrives at a moment of flux in the media industry. Hollywood and advertising executives are testing AI tools for digital effects and commercials. Independent creators are using the tech to spruce up their videos without breaking the bank. Actors, animators, and other creatives, meanwhile, are raising eyebrows at the technology that some fear could wipe out jobs.\n\nMITO is also entering a crowded category dominated by incumbents like Adobe and containing other new upstarts like FLORA, which recently raised a $42 million funding round led by Redpoint Ventures.\n\nRead the pitch deck MITO used to raise its $4.5 million pre-seed round, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt's a platform for \"multiplayer video creation.\"\n\nThe company highlighted two films it created end-to-end, \"Golf Le Fleur Maritime\" and a \"Lagaam campaign.\"\n\nArantxa Barcia, chief creative officer\n\nDanny Saltaren, chief product officer\n\n-Genially (collaborative canvas, $20M ARR), Inditex, Unusuals.\n\nTHE PROBLEM TODAY: AI video workflows are fragmented, slow, painful to iterate, and impossible to collaborate on.\n\n50 cent - 21 Questions and Willy Chavarria - Campaign.\n\nWe have delivered multiple real brand campaigns and music videos using our platform. MITO's tools meet professional quality standards and solve real brand pain points. Why create a studio? To eat our own dog food, generate revenue, and market what's possible.\n\nMITO Orchestration and Collaboration Tools:\n\nStoryboard as the skeleton of a full AI video production. Manually crafted, AI-assisted, or fully generated by our AI agents.\n\nAI Editor for individual text, images, videos, audios.\n\nInfinite canvas. Infinite creation.\n\nA non‑linear visual collaboration space — an evolved moodboard —for exploring and iterating ideas across images, video, audio, text, and styles; freely, in parallel, grouping and recombining, without breaking flow.\n\nMITO UNIVERSE — COMMUNITY OF CREATORS & MARKETPLACE\n\nA creator community and marketplace where artists and producers get a vanity URL to share AI-generated video assets, workflows and portfolios.\n\nMITO offers three pricing tiers: A free tier, a $16 monthly \"pro\" tier, and a $38 monthly \"studio\" tier.\n\nUsers are charged additional costs in the form of \"credits\" based on how often they generate AI content.\n\nWhat private beta users are saying:\n\n\"Huge congratulations! The progress over the last few months is dramatic. MITO makes complex audiovisual creation feel effortless, with real controls over camera, lenses, framing, lighting, and color. The built-in video editor is a game-changer. I haven't seen another AI suite this complete or this clearly designed for real audiovisual creators.\"\n\n\"Creativity is entering a phase of explosive diversification, and along with it, the quality of art and entertainment can drastically increase. Even in the very early days of playing with MITO, it's been striking how open the playing field suddenly feels.\"\n\nDespite the emergence of powerful models, no dominant platform yet ties everything together.\n\nAI models like Veo, Kling, and Runway open new frontiers.\n\nTeam workflows remain fragmented — the orchestration layer is missing.\n\nStorytellers, filmmakers, brands, and companies can now produce high‑quality video without the high cost and long process of traditional production. The result is faster iteration, more experimentation, and many more creative versions.\n\ne.g. brands needing 30 sec-5 min videos\n\nToday 80k brands spending at least $100k per year on video\n\nThe video creation boom is coming. If cost per video is lower: 10x more brands, 10x more content per brand, at a lower cost\n\nProfessional video creation is about to explode — for brands, movie studios, social media, agencies, creators and new forms of entertainment.\n\n\"New powerful AI video models are transforming massive existing categories and unlocking new ones,\" the company says.\n\nUnleashing video creativity & myth-making in the age of AI.",
    "readingTime": 4,
    "keywords": [
      "infinite canvas",
      "pre-seed round",
      "round led",
      "models",
      "platform",
      "creators",
      "creation",
      "brands",
      "assets",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mito-ai-raised-5-million-round-read-its-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/697a7d81e1ba468a96aae72a?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.968Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-a-planetsized-bubble-and-microsofts-slump-is-a-taste-of-the-crash-to-come-tech-guru-erik-gordon-says",
    "title": "AI is a planet-sized bubble — and Microsoft's slump is a taste of the crash to come, tech guru Erik Gordon says",
    "description": "Professor Erik Gordon said the \"AI bubble is almost as big as the planet Jupiter,\" and Microsoft's stock drop is a \"warning of the burst to come.\"",
    "fullText": "Rampant speculation and massive overinvestment in AI have created a financial threat of cosmic proportions — and the fallout will be catastrophic, Erik Gordon has warned.\n\n\"The AI bubble is almost as big as the planet Jupiter,\" Gordon, an entrepreneurship professor at the University of Michigan's Ross School of Business, said in a Wednesday email to Business Insider.\n\n\"When it bursts, the debris will be everywhere,\" he continued. \"Big, institutional investors will be hit with it, and so will individual investors who bet the bubble would get even bigger.\"\n\nGordon pointed to Microsoft stock, which tumbled more than 6% after the software giant's earnings beat on Wednesday. It was trading around 12% lower at 12:30 p.m. ET on Thursday, marking one of the sharpest intraday declines in the company's history.\n\nMicrosoft's shares sank \"because of the truckloads of cash it is investing in AI,\" Gordon said. \"That is a warning of the burst to come.\"\n\nThe cloud-computing titan's net cash used in investing surged 95% year-on-year to over $57 billion in the six months to December. That was fueled by its addition of $49 billion worth of property and equipment such as data centers.\n\nPrior to their post-earnings slump, Microsoft's shares had roughly doubled since the start of 2023, lifting the company's market value to over $3.5 trillion.\n\nOther AI stocks have surged even faster over that timeframe. Shares of chipmaker Nvidia have vaulted 13-fold, valuing the company at close to $4.7 trillion — more than 20 times its projected revenue for the fiscal year ended January 25.\n\nPalantir stock has jumped about 25-fold, giving the data-analysis company a $375 billion market value, or around 85 times its forecasted revenue for 2025.\n\nGordon told Business Insider in an email last week that he doesn't expect the AI bubble to burst in the next few months, as investors still have enough cash to \"prop it up,\" and technological advances remain \"exciting enough to distract\" from irrational valuations.\n\nThe veteran professor has previously rung the alarm on an \"order-of-magnitude overvaluation bubble,\" and warned that when it pops, the \"suffering will be more painful\" for investors than the aftermath of the dot-com bubble. But stocks have largely defied his warnings and continued to march higher.",
    "readingTime": 2,
    "keywords": [
      "microsoft's shares",
      "bubble",
      "investors",
      "cash",
      "warned",
      "professor",
      "email",
      "stock",
      "company's",
      "investing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bubble-microsoft-stock-market-crash-erik-gordon-tech-investing-2026-1",
    "thumbnail_url": "https://i.insider.com/697b4d16a645d11881883730?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.815Z",
    "topic": "finance"
  },
  {
    "slug": "investors-are-giving-meta-the-green-light-to-keep-spending-big-on-ai",
    "title": "Investors are giving Meta the green light to keep spending big on AI",
    "description": "Meta stock surged on Thursday as Q4 earnings beat estimates and investors welcomed more big AI spending plans from the Facebook parent.",
    "fullText": "The move: Meta Platforms stock jumped 9% on Thursday after earnings, erasing losses from the previous week. The stock is up 10% year-to-date.\n\nWhy: Meta reported Q4 2025 earnings on Wednesday after close, coming in above Wall Street estimates on both top and bottom line metrics. It posted revenue of $59.9 billion, versus the forecasted $58.4 billion, and earnings per share of $8.88, versus the $8.16 consensus.\n\nImportantly, the social media giant also revealed that it plans to spend $115 billion to $135 billion on AI in the coming year, a substantial increase from the $72.22 billion it spent on AI in 2025 and well above Wall Street's expectations for 2026.\n\nDespite balking at its big spending plans announced in its last quarterly earnings, Wall Street reacted favorably to the news.\n\nThe key difference this time around seems to be that the company's quarterly advertising revenue came in well above expectations. CFO Susan Li fueled confidence in Meta's growth plans when she said on the earnings call that the company's AI endeavors would be financed with cash rather than debt, likely generated by its advertising success.\n\nWhat it means: The earnings were a key update on the AI race, showing that the company is successfully generating cash from other areas to fund its AI ambitions. It's the kind of strength investors want to see after last year ended with Wall Street growing anxious about soaring capex among hyperscalers.\n\n\"Ongoing investments across the business, including the infusion of AI capabilities across the company's ad stack and content recommendation engines, are already driving tangible benefits for the core advertising segment,\" stated Dan Ives of Wedbush Securities.",
    "readingTime": 2,
    "keywords": [
      "wall street",
      "earnings",
      "plans",
      "company's",
      "advertising",
      "stock",
      "revenue",
      "versus",
      "expectations",
      "quarterly"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-stock-price-q4-earnings-wall-street-advertising-ai-plans-2026-1",
    "thumbnail_url": "https://i.insider.com/697b6a37a645d118818838ff?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.462Z",
    "topic": "finance"
  },
  {
    "slug": "apple-earnings-live-updates-ai-strategy-under-the-microscope-as-wall-street-readies-for-q1-results",
    "title": "Apple earnings live updates: AI strategy under the microscope as Wall Street readies for Q1 results",
    "description": "Apple will report earnings for its fiscal Q1 on Thursday after the closing bell, and its call with analysts is scheduled for 5 p.m. ET.",
    "fullText": "Apple is the next mega-cap tech titan to report earnings after the closing bell on Thursday, and Wall Street is looking for answers on the company's AI roadmap.\n\nThe iPhone maker's fiscal first-quarter results will be a key update amid investor concerns that it has fallen behind in the AI race. Its partnership with Gemini, announced earlier this month, launched Alphabet stock to a $4 trillion market cap, but the impact on Apple shares has been muted. iPhone and other hardware sales will also be a key focus after Tim Cook said in the previous earnings call that its Q1 would be the best ever quarter for revenue.\n\nApple heads into the earnings call with shares down about 7% year to date. The results will be published shortly after the closing bell, and the analyst call will kick off around 5 p.m. ET.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"\n\nUBS analysts said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impacting cost and margins,\" UBS wrote in a January 20 note.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, as they have for other firms that have touted involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.",
    "readingTime": 5,
    "keywords": [
      "wide developers",
      "developers conference",
      "january note",
      "much-anticipated siri",
      "stanley analyst",
      "analyst erik",
      "analyst michael",
      "analyst dan",
      "back siri",
      "siri refresh"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-live-updates-ai-gemini-iphone-sales-2026-1",
    "thumbnail_url": "https://i.insider.com/69792277d3c7faef0ecd063e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.212Z",
    "topic": "finance"
  },
  {
    "slug": "microsofts-earnings-bust-drags-software-stocks-into-a-bear-market-and-tanks-major-indexes",
    "title": "Microsoft's earnings bust drags software stocks into a bear market and tanks major indexes",
    "description": "Shares of Microsoft plunged 12% and software stocks hit a bear market. The S&P 500 edged back from 7,000 as AI spending fears were rekindled.",
    "fullText": "Tech stocks were taking it on the chin on Thursday, with the impact particularly severe for software shares amid Microsoft's post-earnings plunge.\n\nThe software sector slipped into bear market territory as Microsoft renewed fears that the market's largest tech firms may be spending too much, too fast on AI without seeing adequate growth in other parts of the business to offset.\n\nWhile Meta was rewarded after earnings, as robust capex guidance was overshadowed by advertising strength, investors punished Microsoft.\n\nShares of the software giant dropped 12%. The firm said it spent a record amount on AI, but reported slowing cloud growth and issued soft guidance on profits for the following quarter, leading tech stocks to sell off across the board.\n\nThe iShares Expanded Tech-Software Sector ETF is down 21% from its high in October.\n\nHere were the notable moves in the tech sector:\n\n\"Microsoft (MSFT) was the black sheep with losses,\" Joee Mazzola, the head trading and derivatives strategist at Charles Schwab, wrote on Thursday, referring to more upbeat results from Magnificent Seven peers Tesla and Meta.\n\nMajor indexes were dragged lower. The S&P 500 dropped more than 1%, retreating further from the 7,000 mark, which it briefly topped for the first time on Wednesday, while the Nasdaq Composite dropped 2%.\n\nHere's where US indexes stood around 11:45 a.m. ET on Thursday:\n\nInvestors have been particularly sensitive to signs that demand for AI may not be as robust as markets originally anticipated. Capex spending among tech giants has been a particular worry, given the uncertainty over monetization plans and when the market will see returns from AI spend.\n\nMicrosoft's earnings likely \"reinforced fears that a return on AI investment may be slow in coming,\" David Morrison, a senior market analyst at Trade Nation, wrote in a note Thursday morning.\n\nThe company likely needs to \"prove\" that it's making good investments into its AI endeavours, analysts at UBS wrote earlier this week.\n\n\"Microsoft has elected to increase the allocation of new GPU compute to its 1P efforts, effectively throttling Azure growth, because of its confidence in monetizing Copilot,\" the bank said. \"The challenge for the stock is that many investors don't buy into that trade-off.\"",
    "readingTime": 2,
    "keywords": [
      "tech stocks",
      "market",
      "growth",
      "dropped",
      "particularly",
      "microsoft's",
      "fears",
      "earnings",
      "robust",
      "capex"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/stock-market-today-tech-selloff-microsoft-earnings-capex-sp500-nasdaq-2026-1",
    "thumbnail_url": "https://i.insider.com/697b865fa645d11881883c8e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.206Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-laying-off-workers-because-of-ais-potentialnot-its-performance",
    "title": "Companies Are Laying Off Workers Because of AI’s Potential—Not Its Performance",
    "description": "AI has been cited as a cause of layoffs, but is it actually displacing jobs? And if not, what’s going on? Based on a survey of 1,006 global executives in December 2025, AI is behind at least some layoffs, but that these are almost completely in anticipation of AI’s impact. In other words, the job losses and slowed hiring are real, even though companies are still waiting for generative AI to deliver on its promises. This strategy of focusing on short-term gains based on long-term hopes has costs.",
    "fullText": "Companies Are Laying Off Workers Because of AI’s Potential—Not Its Performance by Thomas H. Davenport and Laks SrinivasanJanuary 29, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWill AI lead to layoffs? Are people already losing their jobs to AI? While overall employment in the U.S. is still relatively low, there is considerable speculation that the adoption of generative AI was a cause of recent layoffs and slowed hiring, particularly in the tech industry, for entry-level workers, and in customer service and programming jobs. More may be coming: Leading CEOs—including those from Ford, Amazon, Salesforce, and JP Morgan Chase—have proclaimed that many white-collar jobs at their companies will soon disappear.",
    "readingTime": 1,
    "keywords": [
      "jobs",
      "workers",
      "layoffs"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/companies-are-laying-off-workers-because-of-ais-potential-not-its-performance",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_Mid.jpg",
    "created_at": "2026-01-29T18:30:44.629Z",
    "topic": "business"
  },
  {
    "slug": "ai-and-humane-leadership-a-davos-discussion",
    "title": "AI and Humane Leadership: A Davos Discussion",
    "description": "In this HBR Executive panel discussion at Davos, cohosted by our partner Egon Zehnder, a group of CEOs and board members explore how AI can coexist with human-centered leadership—strengthening trust, empathy, judgment, and innovation amid accelerating technological change.",
    "fullText": "AI and Humane Leadership: A Davos DiscussionHow should AI and human leadership evolve together in this moment of rapid transformation? by HBR EditorsJanuary 29, 2026Summary.   Leer en españolLer em portuguêsPostPostShareSavePrinttogether in this moment of rapid transformation? At Davos, HBR Executive and our partner Egon Zehnder convened a select group of global chief executives to discuss this very question.",
    "readingTime": 1,
    "keywords": [
      "rapid transformation",
      "leadership",
      "moment",
      "davos"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/ai-and-humane-leadership-a-davos-discussion",
    "thumbnail_url": "/resources/images/article_assets/2016/09/whiteout.png",
    "created_at": "2026-01-29T18:30:44.619Z",
    "topic": "business"
  },
  {
    "slug": "boston-dynamics-new-atlas-robot-makes-public-debut-with-jaunty-human-walk",
    "title": "Boston Dynamics' New Atlas Robot Makes Public Debut with Jaunty Human Walk",
    "description": "Hyundai-owned Boston Dynamics is also partnering with former owner Google's DeepMind on AI, in a full-circle moment for the two companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cnet.com/tech/computing/boston-dynamics-new-atlas-robot-make-public-debut-with-jaunty-human-walk/",
    "thumbnail_url": "https://www.cnet.com/a/img/resize/13579e8bed396530cf6c17a54226646a18b3f62e/hub/2026/01/07/ca21282f-6c31-406c-8959-fb96e1b98eae/img-3966.jpg?auto=webp&fit=crop&height=675&width=1200",
    "created_at": "2026-01-29T12:32:33.724Z",
    "topic": "tech"
  },
  {
    "slug": "microsofts-ai-spend-is-starting-to-spook-investors",
    "title": "Microsoft's AI Spend Is Starting to Spook Investors",
    "description": "Microsoft showed record spending but slowing cloud growth and a big reliance on OpenAI",
    "fullText": "In its second-quarter earnings report on Wednesday, tech giant Microsoft reported $37.5 billion in capital expenditures, exceeding market estimates by more than a billion. The spending was up 66% from a year earlier, and roughly two-thirds of it was primarily spent on GPUs and CPUs, Microsoft executives said in an investor call.\n\nA few months ago, a report like this would have sent (and did send) Microsoft stock soaring. But on Wednesday, it had the opposite effect, and the stock went down 7%.\n\nAs worries over an AI bubble simmer, the market is more desperate than ever to see tangible revenue returns that can reignite belief in the great financial promises of the technology, rather than just another huge spending commitment.\n\nBut accompanying Microsoft’s record spending was slowing cloud growth.\n\nRevenue from Microsoft’s cloud services grew by 39% this quarter, down from 40% growth in the first quarter. During the investor call, Microsoft CFO Amy Hood attributed this discrepancy between capital expenditure and cloud growth at least partially to Microsoft allocating GPUs and cloud capacity to internal teams as well. Customer demand for cloud is still outpacing supply, Hood said.\n\nBut even if the slowing cloud growth can be explained away, what also got investors anxious was Microsoft’s reliance on AI giant OpenAI. 45% of Microsoft’s remaining cloud commitments are solely from OpenAI.\n\nAlthough OpenAI used to be the silver bullet for finance, growing uncertainty over the startup’s road to profitability and the risks associated with its ability to pay for towering, ambitious dealmaking has made some start to view any dependence on the AI darling as a potential burden.\n\nOpenAI has signed trillions of dollars worth of deals this past year, despite its $20 billion annualized revenue. Lately, the market has started questioning these overcommitments, as concerns over a potential AI bubble mount.\n\nIf it continues to take too long for AI investments to start translating to actual gains or if somehow it turns out OpenAI cannot pay for its piling commitments, it could lead to a sharp market correction and spell trouble for the U.S. economy, which it seems is currently held up by AI investment.",
    "readingTime": 2,
    "keywords": [
      "slowing cloud",
      "cloud growth",
      "market",
      "revenue",
      "giant",
      "capital",
      "investor",
      "stock",
      "bubble",
      "quarter"
    ],
    "qualityScore": 0.9,
    "link": "https://gizmodo.com/microsofts-ai-spend-is-starting-to-spook-investors-2000715208",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2026/01/shutterstock_2163957793-1200x675.jpg",
    "created_at": "2026-01-29T12:32:32.544Z",
    "topic": "tech"
  },
  {
    "slug": "longcatflashlite-100b-a3b-technical-report-pdf",
    "title": "LongCat-Flash-Lite 100B A3B Technical Report [pdf]",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "LongCat0830\n\n Upload 2 files\n 5ce2ddd\n verified\n about 20 hours ago\n\n download\n\n Copy download link\n history\n\n blame\n\n contribute\n\n delete\n\n 737 kB\n\n Large File Pointer Details\n (\n Raw pointer file\n\n )\n SHA256:\n 5c6963d484586b90e32960c2a7eef93c60ef6b328179972bc6702714f09e4784\n Pointer size:\n 131 Bytes\n\n ·\n\n Size of remote file:\n 737 kB\n\n ·\n Xet hash:\n 7d93b02590ef60d7e97bfd90cdc8b914857c1d7c3252ca7b9abc08301e02e2e8\n Xet efficiently stores Large Files inside Git, intelligently splitting files into unique chunks and\n accelerating uploads and downloads.\n More info.",
    "readingTime": 1,
    "keywords": [
      "pointer",
      "download",
      "files",
      "file",
      "size"
    ],
    "qualityScore": 0.35,
    "link": "https://huggingface.co/meituan-longcat/LongCat-Flash-Lite/blob/main/tech_report.pdf",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/meituan-longcat/LongCat-Flash-Lite.png",
    "created_at": "2026-01-29T12:32:32.273Z",
    "topic": "tech"
  },
  {
    "slug": "google-warns-against-breaking-search-as-pressure-mounts-over-web-future",
    "title": "Google warns against 'breaking Search,' as pressure mounts over web future",
    "description": "Google said it will let websites opt out of generative AI features in Search. Cloudflare's CEO says that's just a start.",
    "fullText": "Google said its Search engine could break if the company is forced to implement strict new controls to protect and nurture web content in the AI era.\n\nThe warning came after UK antitrust regulators proposed new rules for Google Search that would give publishers more control over how their content is used in AI features such as Google's AI Overviews and AI Mode.\n\nIn response, Google said it is working on new ways to give websites more control over how AI chatbots and AI-powered answer engines access and use online content. The company faces mounting pressure to give content owners ways to opt out of having their data crawled for AI, while still allowing traditional search engines to index this valuable data.\n\n\"We're now exploring updates to our controls to let sites specifically opt out of Search generative AI features,\" Google said on Wednesday in a blog post.\n\nThat's a major concession from Google, which has been quietly but firmly pushing back against such demands.\n\nYet, the tech giant also warned that strict new controls could threaten its prized Search engine, which generates most of the company's profits.\n\n\"Any new controls need to avoid breaking Search in a way that leads to a fragmented or confusing experience for people,\" the company said, arguing that search and AI are now deeply intertwined.\n\nGoogle says AI has been core to how Search works for more than a decade, helping rank results and surface relevant links. Creating sharp opt-outs for generative AI features, Google suggests, could undermine the basic mechanics that allow people to find information quickly and allow websites to be discovered at scale.\n\nAt stake is a deeper question about what Search should be in the AI era. Publishers increasingly argue that AI summaries substitute for their content rather than pointing users to it, undermining the grand bargain that has underpinned the web for decades. Google counters that drawing hard lines between search and AI risks unintended consequences, including degraded results and a worse user experience.\n\nCloudflare CEO Matthew Prince said the UK's proposal is \"progress,\" but didn't go far enough. His company helps run about 20% of the web and has been pushing for new standards to level the AI playing field.\n\n\"The CMA's recommendation today doesn't go far enough because it doesn't force Google to split search crawl from AI crawl,\" Prince told Business Insider, referring to the UK's Competition and Markets Authority. \"Instead, it requires us all to trust that Google will not be evil when they build their unauditable black AI box.\"\n\n\"If the CMA wants to encourage innovation and competition in AI, the best thing they should do is force Google to play by the same rules as everyone else and split crawl for AI from the crawl for search,\" he added. \"Every company other than Google would support that because it fosters a healthy market. It's a no-brainer, so it's disappointing the CMA didn't go far enough today.\"\n\nA CMA consultation runs until February 25. Whether regulators can tighten the rules without, as Google warns, breaking Search may help determine not just the future of Google in the UK, but the shape of the open web itself.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "search engine",
      "features google",
      "search and ai",
      "content",
      "controls",
      "crawl",
      "rules",
      "strict",
      "regulators",
      "publishers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-warns-breaking-search-pressure-mounts-web-ai-cloudflare-2026-1",
    "thumbnail_url": "https://i.insider.com/697a616ba645d11881882b19?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "finance"
  },
  {
    "slug": "extesla-ai-head-has-seen-a-phase-shift-in-software-engineering-using-claude-code-and-his-manual-skills-slowly-atrophy",
    "title": "Ex-Tesla AI head has seen a 'phase shift in software engineering' using Claude Code — and his manual skills slowly 'atrophy'",
    "description": "Andrej Karpathy posted his \"notes from Claude Coding,\" describing a shift in engineering over the last two months.",
    "fullText": "He coined \"vibe coding.\" Now, he sees a \"phase shift\" in software engineering.\n\nAndrej Karpathy is one of AI's guiding figures. He was a founding member of OpenAI and later served as Tesla's director of AI. He also coined the term \"vibe coding,\" the AI-assisted coding movement that has taken software engineering by storm and was named Collins Dictionary's word of the year.\n\nIn his \"random notes from Claude Coding\" — which are over 1,000 words long — Karpathy wrote about the changes to his own coding style. Posted on X on Monday, the notes have already elicited reactions from engineers at Anthropic, xAI, and more.\n\nAI coding agents \"crossed some kind of threshold of coherence around December 2025 and caused a phase shift in software engineering,\" Karpathy wrote.\n\nA few random notes from claude coding quite a bit last few weeks.\n\nCoding workflow. Given the latest lift in LLM coding capability, like many others I rapidly went from about 80% manual+autocomplete coding and 20% agents in November to 80% agent coding and 20% edits+touchups in…\n\nKarpathy name-dropped both Anthropic's Claude Code and OpenAI's Codex as having significant improvements. Claude Opus 4.5, the model that has garnered much love from engineers online, came out at the tail end of November.\n\nThe AI leader's workflow has changed as a result of the AI tools. From November to December, Karpathy's 80/20 ratio flipped. He once used 80% manual coding and 20% agents; now, it's 80% agents and 20% manual code editing.\n\n\"I really am mostly programming in English now, a bit sheepishly telling the LLM what code to write... in words,\" he wrote.\n\nThe change to AI-written code \"hurts the ego,\" but is too powerful to ignore, Karpathy wrote. He also devoted a whole section of his notes to the \"fun\" he has while coding with large language models.\n\nWhat of those traditional coding skills, the ones you learn in a computer science program or through endless digital courses? That's a whole other function, Karpathy wrote, and one that might decline.\n\n\"I've already noticed that I am slowly starting to atrophy my ability to write code manually,\" he wrote.\n\nIn Karpathy's comments, engineers from leading AI companies sounded off. Ethan He, an xAI engineer and Nvidia alum, wrote that a \"10x engineer can be a one-man army.\"\n\nCharles Weill, another xAI engineer, wrote that founders can now \"divide themselves\" with coding agents, like a VC divides their capital over a portfolio of companies.\n\nBoris Cherny, an Anthropic staffer and the creator of Claude Code, wrote that he read Karpathy's \"thoughtful\" post till its end.\n\nThe Claude Code team at Anthropic may offer a model of where the industry is moving, Cherny wrote. His team is \"mostly generalists\" and filled with 10x engineers.\n\n\"Pretty much 100% of our code is written by Claude Code,\" Cherny wrote. \"For me personally it has been 100% for two+ months now, I don't even make small edits by hand.\"\n\nThe Anthropic employee also acknowledged the \"quality\" problems with AI-written code. Agents can overcomplicate things and can leave around dead code, he wrote.\n\nHis solution: having AI review the AI-written code.",
    "readingTime": 3,
    "keywords": [
      "ai-written code",
      "phase shift",
      "software engineering",
      "random notes",
      "xai engineer",
      "vibe coding",
      "coding agents",
      "engineers",
      "claude",
      "coined"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-claude-code-manual-skills-atrophy-software-engineering-tesla-2026-1",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "tech"
  },
  {
    "slug": "the-questions-leonis-capital-investors-ask-to-see-if-a-startups-tech-actually-holds-up",
    "title": "The questions Leonis Capital investors ask to see if a startup's tech actually holds up",
    "description": "Leonis Capital founders Jenny Xiao and Jay Zhao tell Business Insider what they ask AI startup founders to evaluate their tech.",
    "fullText": "If you hadn't heard, there's an AI race sweeping through Silicon Valley.\n\nWhile stalwarts like Google, Meta, and Microsoft, and newcomers like OpenAI and Anthropic, are grabbing the headlines as they unveil model after model, there are plenty of startups trying to find a foothold.\n\nFor investors, it can be hard to tell which of these upstarts have true technical potential and which are likely to fade into tech oblivion.\n\nThat's part of why Jenny Xiao, the cofounder of Leonis Capital, said it's important for venture capitalists to get serious about understanding the AI technology they're investing in.\n\nLeonis Capital, founded in 2021, is now deploying its second $40 million fund. The venture capital firm is focused on next-generation AI companies and has invested in over a dozen since its launch, including MaintainX, Motion, and SpectroCloud.\n\nBusiness Insider asked Xiao and her cofounder, Jay Zhao, to share the top five questions they ask founders when evaluating their tech. They shared their responses over email, which have been condensed and edited for clarity.\n\nThe best founders don't think in terms of incremental feature improvements — they think in capability thresholds. We're looking for whether they understand that progress in AI is often non-linear, and whether they can anticipate which future capabilities might fundamentally change or even break their product.\n\nOne of the most interesting takeaways from our Leonis AI 100 — where we benchmarked the most important AI startups — is that the strongest AI founders build just ahead of the next technical breakthrough.\n\nA good answer talks about entirely new workflows that get unlocked, not just marginal efficiency gains, and clearly explains how the company would adapt or pivot as the technology evolves.\n\nMost AI startups don't fail because they're bad, but because they're building something that OpenAI, Anthropic, or Google can eventually ship \"for free\" as a feature.\n\nThat's why we don't accept \"they're not focused on this\" as an answer. We push founders to explain what internal constraint would actually prevent a foundation model lab from building the same thing. If the answer comes down to focus or culture, that's not a real moat.\n\nStrong answers acknowledge that the big labs technically could build it, but doing so would break their incentive structure, pricing, or distribution model; require operational complexity that doesn't scale for them; or shift value to downstream execution rather than model capability.\n\nSome founders can also credibly argue they have a 12- to 18-month head start. Weak answers, by contrast, lean on claims like being \"more vertical,\" having \"more niche data,\" or understanding customers better — responses we hear from about 95% of founders.\n\nWe've noticed a consistent pattern: Most founders underestimate foundation models, and most VCs underestimate them even more.\n\nAsking \"How much proprietary data do you have?\" is usually the wrong question, since no early-stage company has truly meaningful data. And if a founder's pitch boils down to \"we have more data, therefore our models are better,\" that's a red flag: foundation models often improve faster than proprietary ones, and the companies building them have enough capital to buy data and quickly close any gaps.\n\nWhat matters much more is not how much data exists today, but whether the product naturally generates better data over time. For example, industrial systems where data only emerges once software is embedded in workflows, or products where switching costs come from accumulated context.\n\nWe ask this question to understand where defensibility actually lives once code becomes commoditized. If a founder can't answer it clearly, they likely don't understand their own moat.\n\nCosmetic advantages like code, UI, or models are easy to copy, while structural advantages — such as being a system of record or being embedded into compliance, audits, or standard operating procedures — are much harder to replicate.\n\nThe question also reveals founder temperament: Strong founders are candid about their vulnerabilities (\"Here's what we're most worried about\"), while weaker ones tend to get defensive and insist a threat \"would never happen.\"\n\nThis question forces founders to explain their earliest technical decisions and the trade-offs they intentionally made, revealing whether they understand system dynamics rather than just iterating on features.\n\nStrong answers sound like, \"We chose to execute actions, not just make suggestions, which increased liability but created real lock-in,\" or \"We became the system of record instead of a thin layer, which slowed integrations and sales early but made switching organizationally expensive later.\" By contrast, many founders default to saying they want to \"stay flexible,\" which often signals they haven't yet designed anything fundamental.\n\nThe best AI systems are opinionated by design, deliberately removing degrees of freedom and hard-coding assumptions about workflows, authority, or data flow.\n\nReal insight usually comes from abandoning old assumptions. This question helps distinguish founders who simply stumbled into AI from those who experienced a genuine shift in how they see the world.\n\nWe're looking for intellectual flexibility, not credentials. Strong answers point to a specific belief the founder once held, why they believed it, and what changed their mind; weak answers stay vague, like saying they \"realized AI was going to be big.\"\n\nThis question assumes copying is possible and pushes founders to explain what isn't obvious. Shallow answers fall back on claims like \"they couldn't move as fast\" or \"they don't have our data,\" while stronger ones point to hard-to-see advantages such as deep operational knowledge, customer-specific integrations, or accumulated context that isn't visible from the outside.\n\nFounders who can't point to moments where they changed their mind usually aren't learning — they're executing a fixed plan in a world that won't stay fixed.\n\nThis question reveals epistemic humility and whether a founder is genuinely truth-seeking or just looking for confirmation. AI moves too fast for people who can't update, and we're especially wary of founders who treat every pivot as vindication rather than correction.\n\nMarket timing, regulatory shifts, and platform dependencies kill far more startups than bad management. This question tests whether founders think probabilistically about external forces and whether they've designed for resilience instead of relying on luck.\n\nFounders who say \"nothing\" haven't thought hard enough. The ones we want to back can name several concrete external risks and explain how they're hedging against them.\n\nThe best founders aren't contrarian for its own sake, but they can hold an unpopular position long enough for the world to catch up.",
    "readingTime": 6,
    "keywords": [
      "accumulated context",
      "we're looking",
      "foundation models",
      "leonis capital",
      "founders",
      "they're",
      "don't",
      "startups",
      "that's",
      "understand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/leonis-capital-investor-questions-for-ai-startups-2026-1",
    "thumbnail_url": "https://i.insider.com/697a63f2d3c7faef0ecd1b17?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.737Z",
    "topic": "finance"
  },
  {
    "slug": "what-the-latest-earnings-from-tesla-and-meta-tell-us-about-whos-winning-the-ai-race",
    "title": "What the latest earnings from Tesla and Meta tell us about who's winning the AI race",
    "description": "It turns out investors are willing to forgive huge capital spending if a company's core business is thriving.",
    "fullText": "Heading into Wednesday's hoy trinity of earnings — which saw Meta, Microsoft, and Tesla report within five minutes of each other — everyone knew that updates on AI progress would be the only game in town.\n\nHow those results ended up playing out shed crucial light on where we are in the AI trade right now.\n\nThe overarching focus for the Big Tech trio was not who has immediately seen results from AI investment. Instead, it was whether those companies were doing enough to support the appearance of maybe, eventually doing something. Investors love the prospect of future upside, and want a reason to preserve their optimism.\n\nEach of the three companies showcased this trend in their own unique way. Let's go one by one:\n\nLast quarter, Meta was punished for its capex-spending plans. This quarter, the company once again blew the doors off spending forecasts … but this time the market seemed OK with it.\n\nWhat changed? Look no further than the company's stronger-than-expected first-quarter revenue, driven by a big beat in advertising. Meta CFO Susan Li also got investors hyped on the earnings call by saying the company will fund its AI ambitions primarily with cash, rather than debt.\n\nIn the end, it's not that Meta has tangible proof that its AI spending is going to generate monstrous future earnings growth. The company has instead fallen back on its cash-cow advertising business to alleviate financing pressures and buy itself more time.\n\nWe haven't yet gotten an answer about whether the AI spending will pay off. We just know the company can afford to keep pursuing it.\n\nMarket reception: Very positive\n\nI present the counterpoint to Meta's well-received quarter. Microsoft also announced much larger-than-expected spending plans … and its stock fell.\n\nThe difference? One of Microsoft's main cash cows — its Azure cloud-computing unit — showed slowing growth. Suddenly, big spending doesn't look so appealing when your backstop is weakening.\n\nWhile Tesla's AI push has taken the form of self-driving vehicles and robotics, the company's lofty valuation is still being largely driven by hopes that big AI-linked profits will one day be unlocked.\n\nBut unlike Meta, the EV-maker is doing it at a time when its core business is in decline. One overlooked highlight of Tesla's report was that — even though the company posted a bottom-line beat — it also saw first-ever decline in annual revenue.\n\nIt didn't matter. Investors instead focused on Tesla's $2 billion investment in xAI, the company owned by Elon Musk. They also seemed to take the discontinuation of the Model S and Y vehicles in stride.\n\nAgain, the perception of eventually monetizing AI won out. In the AI race, it's not what you're doing, it's what you can convince everyone you're going to do down the line.",
    "readingTime": 3,
    "keywords": [
      "doing",
      "earnings",
      "instead",
      "investors",
      "quarter",
      "it's",
      "everyone",
      "investment",
      "eventually",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-meta-microsoft-q4-earnings-takeaways-stock-market-ai-race-2026-1",
    "thumbnail_url": "https://i.insider.com/697a9d3ce1ba468a96aaeb2d?width=1024&format=jpeg",
    "created_at": "2026-01-29T12:32:28.543Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-ai-will-make-saving-for-retirement-irrelevant-anthropics-ceo-says-building-that-future-wont-be-easy",
    "title": "Elon Musk says AI will make saving for retirement 'irrelevant.' Anthropic's CEO says building that future won't be easy.",
    "description": "Elon Musk said retirement savings would be pointless in an abundant future. Dario Amodei warned of job losses and rising inequality along the way.",
    "fullText": "Elon Musk recently said that saving for retirement could become \"irrelevant\" in the next decade, as new technologies promise to create such an abundance of resources that nobody will need a nest egg.\n\nDario Amodei warned this week that achieving a plentiful future won't be easy. The CEO of Anthropic, the AI startup behind ChatGPT-rival Claude, wrote in an essay that AI promises to \"raise the quality of life for everyone\" — but there will be a brutal \"rite of passage\" to get there.\n\nAmodei said that at the current rate of progress, \"it cannot possibly be more than a few years before AI is better than humans at essentially everything.\"\n\nReplacing human labor with AI could supercharge economic growth and productivity, but the \"short-term shock will be unprecedented in size,\" he wrote.\n\nAmodei said he was worried that workers displaced by AI \"could form an unemployed or very-low-wage 'underclass,'\" and a tiny minority could capture most of the financial gains from AI, creating a \"level of wealth concentration that will break society.\"\n\nHe described those potential impacts on labor and equality as \"grave problems\" that AI companies, employers, philanthropists, and governments would have to work together to solve.\n\nAmodei noted that he and Anthropic's other cofounders have pledged to donate 80% of their wealth to good causes, and the company will match individual donations from its staff worth billions of dollars at its current valuation.\n\nAnthropic's boss shared a similar vision to Musk in a 2024 essay. He wrote that AI will eventually become \"so broadly effective and so cheap\" that the current economic system will \"no longer make sense.\"\n\nIt could be replaced by a \"large universal basic income for everyone,\" or a \"capitalist economy of AI systems\" that distributes \"huge amounts\" of resources to people as the \"overall economic pie will be gigantic,\" he added.\n\nBut he also flagged the risk of \"exploitative or dystopian directions\" and said, \"We will likely have to fight to get a good outcome here.\"\n\nBusiness Insider recently spoke to seven AI and personal finance gurus about Musk's vision, and they shared several of Amodei's concerns.\n\nThey urged Americans to keep saving for retirement just in case Musk is wrong — and said that even if he's right, making sure everyone reaps the rewards of AI will require immense planning and coordination.",
    "readingTime": 2,
    "keywords": [
      "everyone",
      "economic",
      "recently",
      "saving",
      "retirement",
      "resources",
      "essay",
      "labor",
      "wealth",
      "anthropic's"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/elon-musk-retirement-saving-ai-abundance-anthropic-dario-essay-ubi-2026-1",
    "thumbnail_url": "https://i.insider.com/697b3ae9e1ba468a96aaedfd?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.350Z",
    "topic": "finance"
  },
  {
    "slug": "universal-basic-income-could-be-used-to-soften-hit-from-ai-job-losses-in-uk-minister-says",
    "title": "Universal basic income could be used to soften hit from AI job losses in UK, minister says",
    "description": "Lord Stockwood says people in government ‘definitely’ talking about idea as technology disrupts industries\n• Business live – latest updates\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n“Bumpy” changes to society caused by the introduction of the technology would mean there would have to be “some sort of concessionary arrangement with jobs that go immediately”, Lord Stockwood said.\n Continue reading...",
    "fullText": "Lord Stockwood says people in government ‘definitely’ talking about idea as technology disrupts industries\n\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n\n“Bumpy” changes to society caused by the introduction of the technology would mean there would have to be “some sort of concessionary arrangement with jobs that go immediately”, Lord Stockwood said.\n\nThe Labour peer told the Financial Times: “Undoubtedly we’re going to have to think really carefully about how we soft-land those industries that go away, so some sort of [universal basic income], some sort of lifelong mechanism as well so people can retrain.”\n\nA universal basic income is not part of official government policy, but when asked whether people in government were considering the need for UBI, Stockwood told the FT: “People are definitely talking about it.”\n\nThe technology entrepreneur, who took up his ministerial post in September, said part of his motivation for joining the government was to help ensure the workforce was prepared for rapid change.\n\nFears continue to grow about the impact of artificial intelligence on Britain’s job market. This week research by the investment bank Morgan Stanley found the UK was losing more jobs than it is creating because of AI and was being hit harder than other large economies.\n\nThis month the mayor of London, Sadiq Khan, said AI could destroy swathes of jobs in the capital and “usher in a new era of mass unemployment”.\n\nLast week, Jamie Dimon, the chief executive of the US bank JP Morgan, told the World Economic Forum in Davos that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk civil unrest.\n\nStockwood, who held senior positions at Lastminute.com, Travelocity and Match.com, oversaw the $490m (£400m at the time) sale of the online insurance broker Simply Business to the US insurer Travelers in 2017. He later bought a stake the football club of his home town, Grimsby Town FC.\n\nWhile he has previously been a vocal proponent of a wealth tax in the UK, Stockwood told the FT he had not repeated his calls for the government to go further on taxing the rich.\n\nHowever, he added: “If you make your money and the first thing you do is you speak to a tax adviser to ask: ‘Where can we pay the lowest tax?’ we don’t want those people in this country, I’d suggest, because you’re not committed to your communities and the long-term success in this country.”\n\nStockwood was preceded as investment minister by Poppy Gustafsson, a former chief executive of the cybersecurity firm Darktrace, who stepped down after less than a year in the job.",
    "readingTime": 3,
    "keywords": [
      "chief executive",
      "universal basic",
      "basic income",
      "investment minister",
      "lord stockwood",
      "technology",
      "industries",
      "sort",
      "jobs",
      "talking"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/29/universal-basic-income-used-cover-ai-job-losses-minister-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de673ed46d19dc117c208edb6f803b2eca7c5ad8/1020_268_1578_1263/master/1578.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1431031c71c27093dd3511ca51014201",
    "created_at": "2026-01-29T12:32:28.046Z",
    "topic": "tech"
  },
  {
    "slug": "the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "title": "The slopaganda era: 10 AI images posted by the White House - and what they teach us",
    "description": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here’s what you need to know to navigate the trolling\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it’s developed into a full-blown phenomenon, one academics are calling “slopaganda” – an unholy alliance of easily available AI tools and political messaging. “Shitposting”, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of “institutional shitposting”, according to Know Your Meme’s editor Don Caldwell. This is trolling as official government communication.",
    "fullText": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here’s what you need to know to navigate the trolling\n\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it’s developed into a full-blown phenomenon, one academics are calling “slopaganda” – an unholy alliance of easily available AI tools and political messaging. “Shitposting”, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of “institutional shitposting”, according to Know Your Meme’s editor Don Caldwell. This is trolling as official government communication. And nobody is more skilled at it than the Trump administration – a government that has not only allowed the AI industry all the regulative freedom it desires, but has embraced the technology for its own in-house purposes. Here are 10 of the most significant fake images the White House has put out so far.\n\nThe first AI image posted by the White House X account sets the tone for Trump’s second presidency – marking a turning point in which the shitposting that had been associated with the far-right online culture that brought Trump to power moved from fringe message boards, such as 4chan and Reddit, to mainstream platforms.\n\nThe image was posted alongside an announcement of the repeal of New York City’s congestion pricing, and leant into fears that Trump would govern as a king. The New York governor, Kathy Hochul, held up the image at a press conference when she announced that she would defy attempts to block the congestion charge: “New York hasn’t laboured under a king in over 250 years. We sure as hell are not going to start now.” The congestion charge remains in effect.\n\nIn another post on Truth Social in October, the president posted an AI video depicting himself as a president-king, crown on head, flying over “No Kings” protesters in a jet fighter and dumping faeces on them. The House speaker, Mike Johnson, defended the post, saying: “The president uses social media to make a point. You can argue that he’s probably the most effective person who’s ever used social media for that. He is using satire to make a point.”\n\nOpenAI’s Studio Ghibli-inspired meme generator became a sensation in March 2025, with its uncanny ability to translate any image into the beloved anime studio’s house style (without Studio Ghibli’s permission or approval).\n\nThe White House applied it to a woman in tears as she was arrested by Immigration, Customs and Enforcement (ICE) agents before being deported. The original photograph, and the woman’s name and alleged crimes, are also included in the post.\n\nFor Caldwell, this demonstrated just how up to date the White House is with online trends. “They’re hopping on brand-new, fresh memes,” he says. He suspects White House staffers might be regular visitors to Know Your Meme. “The Studio Ghibli meme trend kicked off on March 25 on X; we covered it the following day; and then the White House covered it the day after that.”\n\nThis image is proof of Trump’s willingness and ability to insert himself into any conversation, even ones that have nothing to do with him, and shows how effective that can be.\n\nPredictably, the image went viral, made global headlines and was met with outrage from Catholic groups and politicians. “There is nothing clever or funny about this image, Mr President,” wrote the New York State Catholic Conference. “We just buried our beloved Pope Francis and the cardinals are about to enter a solemn conclave to elect a new successor of St Peter. Do not mock us.”\n\nAs so often happens with such shitposting, those who ​took offence were accused of lacking a sense of humour. “They can’t take a joke?” Trump said soon after at a press conference. “You don’t mean the Catholics, you mean the fake news media … the Catholics loved it.”\n\nTrump has been the subject of flattering fan art throughout his political career (remember the digital Trump trading cards?), but AI has made the job a whole lot easier. On 4 May, the White House crashed Star Wars fans’ special day with this image of the president as a jacked Jedi, lightsaber in hand, garlanded by flags and eagles. Who cares if his lightsaber is the wrong colour (the good guys’ are blue), or that the White House’s claim to be the Rebellion not the Empire rang laughably hollow? This was pure fantasy art.\n\nIn 2022, one of Trump’s trading cards clumsily grafted his headshot on to a superhero body; last July he was slightly less clumsily grafted on to the body of Superman, to gatecrash the launch of the new movie. The same month, the White House portrayed a besuited Trump heroically striding into the Colosseum. Fans and allies have generated reams of similar content themselves.\n\nWhy did the White House choose to put the Democratic house leader Hakeem Jeffries and the senate leader Chuck Schumer in sombreros and have them holding plates of tacos? It doesn’t matter. They look a bit silly, and it’s provocatively offensive, and once again, the world’s attention is colonised.\n\nThe image illustrates how difficult it is to respond to this type of content. It’s part of a running joke, stretching back to a deepfake video Trump posted a month earlier, which slapped a crude sombrero and moustache filter over Jeffries. That video was roundly condemned as offensive and racist , not least by Jeffries himself (who replied by posting a genuine image of Trump with the sex offender Jeffrey Epstein) . The Trump administration then doubled down, playing the video on a loop on screens in the White House briefing room for several hours and creating more images in a similar vein, which kept the trolling going.\n\nFew people outside the Trump administration believe the US is in a “golden age”, but that hasn’t stopped Trump from repeating the claim. In January, the White House posted an AI video of a golden White House facade behind a shower of gold coins with the text “The White House? She’s in her Golden Age”, backed by Bruno Mars’ track 24K Magic.\n\nEven if Trump’s Midas touch is more a figment of his imagination, this type of wishcasting is more effective than it appears. According to one paper by the academics Michał Klincewicz, Mark Alfano and Amir Ebrahimi Fard – who coined the term “slopaganda” – “neural representations of information that were shown to be false continue to influence people’s beliefs and reasoning after being corrected”. In other words, even when you know it’s fake, your brain still kind of believes it.\n\nOn the face of it, this seems like a straightforward “Trump wants Greenland” post. However, it has a much darker message.\n\nAgain, the post is riffing on a popular meme, Caldwell explains: the “dramatic crossroads” image originated with the manga series Yu-Gi-Oh!, and started gaining traction online around 2021.\n\nThe slogan “Which way, Greenland man?” seems to reference a 1978 neo-Nazi text titled Which Way, Western Man?, in which the white supremacist author William Gayley Simpson called for violence against and the deportation of Jews and Black people, and argued that Hitler was right.\n\n“It’s absolutely shocking to see such images being deployed by this administration,” said Heidi Beirich, a co-founder of the Global Project Against Hate and Extremism, which monitors US neo-Nazi groups. “The idea appeals to racists and white supremacists who think only white people should be in positions of power.”\n\nIn August, the Department of Homeland Security posted a mock recruitment advert for ICE with an image of Uncle Sam at a crossroads and the slogan: “Which way, American man?” Earlier this month, the US Labor Department posted an image with the slogan: “One Homeland. One People. One Heritage”. Critics pointed out that it had overtones of Hitler’s “Ein Volk, ein Reich, ein Führer” (“One people, one realm, one leader”).\n\n“AI is very good at constantly reiterating images from the past, so it can create this nostalgic imagery of traditionalism,” says Daniel de Zeeuw, an assistant professor in digital media culture at the University of Amsterdam. Thus the extremist messages of the present – such as ICE’s militarised policing – can be inserted into more reassuring and familiar graphic styles, such as patriotic recruitment posters, 80s action-movie posters or 1950s public information campaigns (as with a recent image of Trump as a friendly milkman).\n\nAI is inherently backward-looking, says de Zeeuw, as it is fed on historical images. This aesthetic is in keeping with the Make America Great Again movement, which is constantly evoking a “better” past. Another stark example was the Department of Homeland Security’s chilling post from last December: an image of a vintage car at a deserted, palm-fringed beach with the slogan “America After 100 Million Deportations”. Ironically, the original was painted by a Japanese artist, Hiroshi Nagai, who complained that it had been used without his permission.\n\n“It’s not going to be on Twitter,” said the agent filming the Minneapolis civil rights lawyer Nekima Levy Armstrong, one of the city’s most prominent activists, as she was arrested last Thursday. Within hours, though, it was: the Homeland Security secretary Kristi Noem posted a still from the video, in which Armstrong seems composed and shows little emotion.\n\nHalf an hour later, the White House X account posted a significantly altered version of the same image: this time, Armstrong is exaggeratedly upset, tears streaming down her face. Her skin tone also appears to have been darkened. The image was captioned: “Arrested: far-left agitator Nekima Levy Armstrong for orchestrating church riots in Minnesota.” In fact, Armstrong was demonstrating at a church service led by an allegedly ICE-affiliated pastor, and was later released without charge.\n\nUntil this moment, the White House’s AI-generated output had been conspicuously outlandish: there was little danger of mistaking it for reality. This image purports to be an authentic photograph – or at least omits to mention that it is not. It is not so much AI-generated trolling as an AI-assisted deepfake.\n\nAs with Musk’s recently shared Grok tool, which removed women and children’s clothing without their consent, there is also something abusive about it: AI has been used to attempt to humiliate a woman by manipulating her image, to make her look weaker and more distressed than she actually was.\n\nThe fact that the deepfakery is not all that convincing is part of the point, de Zeeuw thinks. “What is being communicated here is the falsification itself: you’re showing your ability to falsify images, to falsify evidence.”\n\nAfter the fakery had been called out, the White House deputy communications director Kaelan Dorr posted the response: “Enforcement of the law will continue. The memes will continue.”\n\nIn response to this image of Trump and a penguin walking towards a Greenland flag, some observers pointed out that penguins actually live at the south pole. But that’s missing the point of these types of post, says Robert Topinka, a reader in digital media and rhetoric at Birkbeck, University of London. “People continue to interpret them as if they’re meant to be a legitimate claim, or an argument or a piece of evidence, but they’re emotional hooks.” Their purpose is to stir up the base. “White House staffers have said they use AI because it’s the fastest way to get content out. It’s not the fastest way to say something that’s true; it’s the fastest way to push their propaganda.”\n\nTo those in the know, this is a riff on the “nihilist penguin” meme, which has gone viral on TikTok in the past few weeks. It’s based on a scene from Werner Herzog’s 2007 documentary Encounters at the End of the World, in which one penguin inexplicably separates from the colony and wanders off towards the Antarctic interior, and certain death. “But why?” Herzog wonders. Many have asked the same of Trump’s quixotic attempts to acquire Greenland.\n\nThe image resonates with what Naomi Klein and ​Astra Taylor ​christened “end times fascism”, says De Zeeuw, where tech industry leaders and their enablers are almost willing the end of the world as we know it, striding towards oblivion like Trump and his penguin companion. “It’s like they know they’re moving toward the end, but they do so joyfully.”",
    "readingTime": 11,
    "keywords": [
      "white house",
      "nekima levy",
      "levy armstrong",
      "trading cards",
      "clumsily grafted",
      "house account",
      "house staffers",
      "trump administration",
      "press conference",
      "congestion charge"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/2026/jan/29/the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4b7cb2fd8f7d06f369527b2702d8dbea84ffdad2/0_105_2160_1728/master/2160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=642ec79d432723197b75c7a515cf46a0",
    "created_at": "2026-01-29T12:32:28.039Z",
    "topic": "tech"
  },
  {
    "slug": "whos-hiring-scab-protocol-remote-equityonly",
    "title": "Who's Hiring: Scab Protocol (Remote, Equity-Only)",
    "description": "The runtime behavioral governance framework for AI systems. Measure, monitor, and control AI behavior continuously across six domains.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://scab.dev",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/c2ebdabd-7464-44b8-8d02-2182d6a360c2/id-preview-9af3fcbe--351023f6-eb8a-4801-b737-973f998527b3.lovable.app-1769664312714.png",
    "created_at": "2026-01-29T06:34:22.725Z",
    "topic": "tech"
  },
  {
    "slug": "5-of-the-biggest-takeaways-from-metas-q4-2025-earnings-call",
    "title": "5 of the biggest takeaways from Meta's Q4 2025 earnings call",
    "description": "Meta's Q4 2025 earnings reveal massive AI investment plans, ad-driven revenue growth, and costly Reality Labs losses.",
    "fullText": "Meta's earnings sent a clear signal to Wall Street on Wednesday: while its core advertising engine is still firing on all cylinders, the price tag for CEO Mark Zuckerberg's AI ambitions will skyrocket in 2026.\n\nThe company reported $59.89 billion in revenue for the fourth quarter of 2025, topping Wall Street's forecasts. Meta's stock jumped as high as 10% in after-hours trading.\n\nAlongside the upbeat numbers, Meta laid out how hard it plans to push in 2026. The company said it expects to spend $115 billion to $135 billion next year on capital expenditures — largely on the computers and data centers that power AI.\n\nIn other words, Meta still makes most of its money from ads. It's asking investors to stay on board as it pours an extraordinary amount of cash into the race to build more powerful AI and weave it into Instagram, WhatsApp, Facebook, and virtual and augmented reality products, collectively used by more than 3.5 billion people daily around the world.\n\nHere are five takeaways from Meta's Q4 2025 earnings call.\n\nMeta told to brace for a much more expensive 2026 as it pours money into the compute and data centers needed to power its AI push. The company said it expects capital expenditures in 2026 to land between $115 billion and $135 billion — up to almost double the $72 billion it spent in 2025.\n\nMeta's chief financial officer, Susan Li, said the increased expenditure will support Meta Superintelligence Labs' efforts and its core business.\n\nLi also warned that Meta's overall costs are set to climb fast. The company expects total 2026 expenses of $162 billion to $169 billion, with most of the increase coming from \"infrastructure costs,\" including \"third-party cloud spend, higher depreciation, and higher infrastructure operating expenses.\"\n\nAnd Meta isn't just buying more machines — it's also paying for people to run them. Li said the \"second-largest contributor\" to expense growth will be compensation, driven by \"investments in technical talent,\" including hires in \"priority areas, particularly AI.\"\n\nAdvertising once again powered Meta's quarter. The company reported $58.14 billion in ad revenue in Q4 2025, up 24% from the same time last year. That growth came from a mix of showing more ads (ad impressions rose 18% from the same quarter last year) and charging a bit more per ad (average price per ad rose 6%).\n\nWhen analysts pressed Zuckerberg on whether Meta can build meaningful businesses beyond ads, given how much cash it's pouring into AI, he didn't dodge the question of its dependency.\n\n\"For the next couple of years, ads are going to be by far the most important driver of growth in our business,\" Zuckerberg said, adding that Meta is working on new bets alongside that core engine.\n\nMeta's pitch is that its AI investments are already making the ad machine work better — not just by targeting, but by improving the systems that decide which ads people will most likely engage with.\n\nThe company said that its AI tools for making video ads hit a $10 billion revenue run rate. It also said a newer measurement product helped advertisers drive 24% more conversions than its standard method — and ramped up to a multi-billion-dollar annual run rate in just seven months.\n\nReality Labs, the division behind Meta's virtual and augmented reality efforts, continued to burn cash in the final quarter of 2025. The division lost $6.02 billion in a quarter, the highest ever, and $19.19 billion in 2025 — numbers that underscore how much Meta's ambitions to build immersive worlds still depend on ad revenue.\n\nDespite laying off about 1,500 people at Reality Labs earlier this month, Meta told investors not to expect a sudden turnaround. Li said the company expects Reality Labs' operating losses in 2026 to remain \"similar to 2025 levels.\"\n\nZuckerberg is trying to reposition what Reality Labs is building. The company's focus has shifted from trying to go all in on the \"metaverse\" to building AI-powered smart glasses and experiences that could live inside Meta's existing apps.\n\nWhen Barclays analyst Ross Sandler asked about Meta's plans to bring Horizon Worlds, a virtual hangout zone accessible on the company's Quest VR headsets, to mobile, Zuckerberg said that he expects more \"interactive and immersive\" content formats to show up directly inside the feeds in Meta's existing apps.\n\nHe added that people might be able to use AI to create a game with a single prompt and share it on their feeds so that others can \"jump right into it.\"\n\nHe positioned Horizon Worlds as a natural fit for an \"immersive 3D\" version of that idea and said that Meta's work on VR software and Horizon could pair with AI advances to bring these kinds of experiences to \"hundreds of millions and billions of people through mobile.\"\n\nMeta isn't just trying to sprinkle AI features across Facebook and Instagram. Zuckerberg is making a bigger argument: if Meta wants to shape the next generation of consumer tech, it needs to control the underlying AI, not just depend on whatever rivals sell.\n\nThat's also the framing behind his public push for \"personal superintelligence,\" which he called out again as a key focus for 2026.\n\nWhen Wells Fargo analyst Ken Gawrelski asked how critical it is for Meta to have a general-purpose model, Zuckerberg leaned into Meta's identity as a \"deep technology company.\"\n\nWhat allows Meta to build everything it does, he said, \"is that we build and control the underlying technology.\" That way, Meta can design the experiences it wants, \"and not just be constrained to what others in the ecosystem are building or allow us to build,\" Zuckerberg added.\n\nHe suggested that relying on outside models could become risky over time, citing a mix of competitive and safety reasons. That's why, he said, it's important for Meta to have its own models, both from a business perspective and because Meta wants to \"actually design and build the experiences that we believe that we should be building for people.\"\n\nZuckerberg is pitching 2026 as the year AI changes not just Meta's products, but how Meta itself operates. On the call, he said 2026 will be \"the year that AI starts to dramatically change the way that we work\" and that the company is \"investing in AI native tooling so individuals at Meta can get more done.\"\n\nHe also described a deliberate shift in org design.\n\n\"We're elevating individual contributors and flattening teams,\" Zuckerberg said, adding that Meta is already seeing \"projects that used to require big teams now be accomplished by a single, very talented person.\"\n\nLi paired that cultural pitch with a concrete productivity claim. She said that since the beginning of 2025, Meta has seen a \"30% increase in output per engineer\" overall, and that \"power users\" of its internal AI coding tools saw output rise 80% year-over-year.\n\nThe company's implied bet? Spend heavily on AI infrastructure and tooling, and then run leaner teams that can ship more.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "augmented reality",
      "meta's earnings",
      "meta's existing",
      "capital expenditures",
      "existing apps",
      "meta isn't",
      "reality labs",
      "horizon worlds",
      "quarter",
      "revenue"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-ai-investments-capex-2026-1",
    "thumbnail_url": "https://i.insider.com/697ab091d3c7faef0ecd23e6?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.656Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-says-openai-is-driving-45-of-the-backlog-for-azure-cloud-computing",
    "title": "Microsoft says OpenAI is driving 45% of the backlog for Azure cloud computing",
    "description": "OpenAI and Microsoft have a reconfigured relationship. The software giant revealed just how much OpenAI is driving its RPO.",
    "fullText": "Microsoft is facing capacity constraints, and OpenAI is driving a large portion of the backlog in its cloud computing business.\n\nThe company said its backlog in commercial bookings, a metric referred to as remaining performance obligations, ballooned 110% year over year to $625 billion when it reported earnings for the second quarter on Wednesday.\n\nOpenAI accounts for roughly 45% of those commitments, Microsoft revealed. The company did not say how much OpenAI contributed during the previous quarter.\n\nSome Wall Street analysts on the call expressed concerns about Microsoft's dependency on OpenAI.\n\nCEO Satya Nadella said acquiring more Azure clients is important to the tech giant, but it can't come at the expense of neglecting its other services.\n\n\"If you think about it, acquiring an Azure customer is super important to us, but so is acquiring an M365 or a GitHub or a Dragon Copilot, which are all, by the way, incremental businesses and TAMs for us,\" Nadella said during Microsoft's second-quarter earnings call. \"And so we don't want to maximize just one business of ours.\"\n\nShares of Microsoft fell more than 6% in after-market trading on Wednesday, even as the tech giant posted an overall earnings beat.\n\nMorgan Stanley's Keith Weiss said during the call that some on Wall Street may be spooked by slower growth in overall Azure revenue and the increase in capex spending. Microsoft's capital expenditures rose 66% year over year to $37.5 billion in the second quarter, another record for the company and testament to the sheer amount of money tech companies are spending amid the AI race.\n\nCFO Amy Hood said that Microsoft has to look at many different areas when it allocates the GPUs and CPUs that come online as a result of its capex spending, including investing in the growth of first-party apps like Microsoft Copilot, devoting GPUs to research and development, and the talent they've acquired.\n\n\"You end up with the remainder going towards serving the Azure capacity that continues to grow in terms of demand,\" she said.\n\nMicrosoft is not alone in facing capacity issues.\n\nExecutives at OpenAI, which has pledged to spend $250 billion on Azure services, have repeatedly said the startup is held back by a lack of compute, forcing tough trade-offs between product and research.\n\nWednesday's earnings mark the first quarter since OpenAI completed its restructuring, which included a new agreement with Microsoft, the startup's largest investor. Microsoft owns 27% of the public benefit corporation.\n\n\"It's a great partnership,\" Hood said of Microsoft's relationship with OpenAI. It's allowed us to remain a leader in terms of what we're building and being on the cutting edge of app innovation.\"",
    "readingTime": 3,
    "keywords": [
      "facing capacity",
      "tech giant",
      "second quarter",
      "azure",
      "earnings",
      "microsoft's",
      "acquiring",
      "microsoft",
      "openai",
      "backlog"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-openai-azure-cloud-computing-backlog-2026-1",
    "thumbnail_url": "https://i.insider.com/697aa643a645d118818833f0?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.651Z",
    "topic": "finance"
  },
  {
    "slug": "tesla-takes-another-leap-toward-becoming-a-physical-ai-company-here-are-the-6-biggest-takeaways-from-its-q4-earnings",
    "title": "Tesla takes another leap toward becoming a physical AI company: Here are the 6 biggest takeaways from its Q4 earnings call.",
    "description": "Tesla CEO Elon Musk announced a $2B investment into xAI and the discontinuation of Model S and Model X in order to support Optimus robot production.",
    "fullText": "Tesla is making another leap to shed its EV maker title and transform into a full-fledged physical AI outfit.\n\nThe theme of Wednesday's fourth-quarter earnings call heavily centered on how Tesla is investing in its future as an AI and robotics company — a narrative CEO Elon Musk has pushed for some time now.\n\nThe bets included: a major investment in Musk's xAI, updates on the Optimus humanoid robot, and a renewed push for in-house chipmaking. Musk projected that Tesla's future will require a $20 billion investment, which dwarfs the company's $8.5 billion in capex reported for the 2025 fiscal year.\n\nMeanwhile, Tesla's automotive segment took a back seat: Musk said he's killing the Model S and Model X to free up room for humanoid robot production. And while Tesla's energy and \"services\" revenue jumped 25% and 18%, respectively, auto revenue fell 11% year-over-year — a clear indication that the quarter's growth came from everywhere but its core EV business.\n\n\"We've updated the Tesla mission to amazing abundance, and this is an attempt to send a message of optimism about the future,\" Musk said during the call.\n\nThe company's stock rose 1.7% after the market closed on Wednesday evening.\n\nHere are 6 biggest takeaways from the earnings call.\n\nTesla made good on its pledge to investors and announced a $2 billion investment into xAI, the startup behind Grok. It's part of a larger $20 billion Series E funding round from January.\n\nThe expectation of the investment is a deeper collaboration between the two companies. xAI, which has been expanding its data center footprint, could provide the compute and other technical capabilities to further advance Tesla's autonomous vehicle and robotics agenda.\n\nVaibhav Taneja, Tesla's chief financial officer, said during the call that the agreement with xAI is in the spirit of finding \"efficient ways for others to help us.\"\n\nIn a surprise move, Musk announced that production of the Model S and Model X would be discontinued by the next quarter, closing a chapter on the company's premium SUV and sedan.\n\nThat leaves the EV maker with four cars: the Cybertruck, the more popular Model 3 and Model Y, and the yet-to-be-released Cybercab.\n\nThe CEO said during the call that the move will provide more production space in Tesla's Fremont factory for Optimus robots.\n\nThe \"long-term goal\" is to produce a million units a year with the freed-up space, Musk said.\n\nThe CEO added that killing the Model S and Model X is part of Tesla's \"overall shift to an autonomous future,\" which includes the company's ride-hailing service, Tesla Robotaxi, and autonomy in personally owned vehicles through Full Self-Driving, an advanced driver assistance system.\n\nTesla expects to start production of the Cybercab, a two-seater coupe, in April for eventual integration into its Robotaxi fleet.\n\nTesla revealed where it aims to expand the Robotaxi ride-hailing service in the first half of 2026 — Dallas, Houston, Phoenix, Miami, Orlando, Tampa, and Las Vegas — but has yet to announce when it will remove the safety monitors inside the cars for public riders across Austin and San Francisco Bay Area, where the service now operates.\n\nMusk said that FSD — the technology that Tesla says will make personally owned vehicles fully autonomous — is already \"100% unsupervised\" and operating without humans inside. The difference, he said, is that Tesla is being \"very cautious\" with rolling out unsupervised service to the public, though Tesla began offering a limited number of unsupervised rides in Austin this month.\n\n\"There's like some pretty nutty intersections, where there are a lot of humans who make mistakes and have accidents in various cities,\" Musk said. \"So we want to make sure that FSD can handle those unusual intersections.\"\n\nThere wasn't much of a progress report on Tesla's AI5 chip, but the CEO said he's spending part of his weekends working on it.\n\n\"If I'm spending my Saturdays on something, it's going to be something pretty important,\" Musk said, adding that chip procurement is \"existential\" for Tesla's future, going so far as to bring up the Tesla \"Terafab\" — his aspirational idea of building an in-house chip manufacturing plant.\n\nMusk said he wants to build a factory that integrates \"logic, memory, and packaging\" because Tesla will be \"fundamentally limited by supply chain\" if it doesn't.\n\nMusk said he expects to unveil an Optimus 3 robot in a \"few months,\" but don't expect it to be working the assembly lines just yet.\n\nThe CEO said Optimus isn't contributing to Tesla's manufacturing work in any \"material way\" and that the humanoid robot is only in the factory for training purposes.\n\nMusk talked a lot about Tesla's future, but the company's fourth-quarter performance still hinged on its tangible businesses, such as its energy segment, which includes the Megapack, a utility-scale battery system, and the Powerwall, the home battery system.\n\n\"On the energy front, we achieved yet another record in terms of gross profits for the quarter and ended the year with nearly $12.8 billion in revenue,\" Taneja, the Tesla CFO, said.\n\nTesla also announced this month that it will pivot FSD to a subscription-based only model starting in February. Customers previously had the option to buy FSD upfront for $8,000.\n\nThe move is a clear signal that Tesla sees FSD as a key future revenue generator.\n\nAutomakers are increasingly betting that software subscription services will be a critical source of recurring revenue with higher margins. General Motors revealed that its vehicle software generated $2 billion in the past nine months.\n\nTesla did not respond to a request for comment.",
    "readingTime": 5,
    "keywords": [
      "personally owned",
      "owned vehicles",
      "battery system",
      "model and model",
      "humanoid robot",
      "ride-hailing service",
      "the ceo",
      "company's",
      "revenue",
      "tesla"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-q4-earnings-call-summary-robotaxi-optimus-ai5-chips-2026-1",
    "thumbnail_url": "https://i.insider.com/697ac36dd3c7faef0ecd2457?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.534Z",
    "topic": "finance"
  },
  {
    "slug": "openais-chair-says-vibe-coding-is-here-to-stay-but-its-not-the-endgame",
    "title": "OpenAI's chair says vibe coding is here to stay — but it's not the endgame",
    "description": "Vibe coding will stick around, but AI agents, not apps, will drive the next big shift in software, says OpenAI's chair Bret Taylor.",
    "fullText": "Vibe coding isn't going anywhere. But it's only part of a much bigger transformation, says OpenAI's board chair.\n\nBret Taylor said in an episode of the \"Big Technology Podcast\" published on Wednesday that using AI tools to build software quickly with natural language prompts will soon feel normal rather than novel. However, focusing on building today's software faster misses the bigger picture.\n\n\"Everyone's looking at all the software use and saying, 'How fast could I vibe code that?'\" Taylor said. \"I wonder if it's the wrong question.\"\n\nWhether someone can quickly vibe code an app in a web browser isn't \"the most interesting question in software,\" he added.\n\nInstead, the software we use today is set to be replaced, and that's the real disruption, Taylor said.\n\nRather than dashboards, web-browser forms, and traditional apps, the structure of software will change. AI agents will be \"the future of software.\"\n\n\"We will delegate tasks to agents that will operate against a database,\" Taylor said.\n\n\"Who's making those agents is the question,\" he added. \"Will you buy those agents off the shelf or build them yourself?\"\n\nTaylor also said that while AI has slashed the cost of building software, it hasn't solved the harder problems of maintaining it — or the risk of getting things wrong.\n\n\"That's why most people would prefer to buy a solution off the shelf,\" he said. \"You want to amortize the cost of maintaining software among thousands of clients.\"\n\nVibe coding has taken off across the tech world, but tech leaders said the technology has limits.\n\nGoogle CEO Sundar Pichai said in November in a \"Google for Developers\" podcast interview that vibe coding is \"making coding so much more enjoyable,\" adding that it allows even non-technical users to create simple apps and websites.\n\nDuring Alphabet's April earnings call, Pichai said AI generates more than 30% of Google's new code, up from 25% in October 2024.\n\nStill, AI-generated code can be error-prone, overly long, or poorly structured.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said last month that vibe coding works best for prototypes or throwaway code, but not in software that sits at the core of a business.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he said in an episode of \"The Peterman Podcast\" published in December.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "vibe coding",
      "vibe code",
      "software",
      "agents",
      "isn't",
      "it's",
      "bigger",
      "episode",
      "quickly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-chair-vibe-coding-not-endgame-bret-taylor-2026-1",
    "thumbnail_url": "https://i.insider.com/6883b14a85e81483682eb19e?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.533Z",
    "topic": "finance"
  },
  {
    "slug": "why-aimediated-decisions-require-a-ledger",
    "title": "Why AI-Mediated Decisions Require a Ledger",
    "description": "When AI-generated narratives influence belief or decision-making, no reconstructable record typically exists. This paper defines the evidentiary gap and specifies the properties required to restore accountability without prescribing standards or remedies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/reasoning-without-records/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-29--2026-at-06_52_34-AM.png",
    "created_at": "2026-01-29T06:34:21.805Z",
    "topic": "tech"
  },
  {
    "slug": "relnotesapp-turn-github-prs-into-your-fridays-report-automatically",
    "title": "Relnotes.app – Turn GitHub PRs into your Friday's report automatically",
    "description": "Relnotes is an AI-powered platform that automatically generates and distributes release notes from GitHub pull requests. Keep stakeholders informed with automated, professional release communications.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://relnotes.app/",
    "thumbnail_url": "https://relnotes.app/og-image.png",
    "created_at": "2026-01-29T06:34:20.256Z",
    "topic": "tech"
  },
  {
    "slug": "fork-and-make",
    "title": "Fork and Make",
    "description": "meta-collection of my ai projets. See delta-version for meta-project control scripts. - gabrilend/ai-stuff",
    "fullText": "gabrilend\n\n /\n\n ai-stuff\n\n Public\n\n meta-collection of my ai projets. See delta-version for meta-project control scripts.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n gabrilend/ai-stuff",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/gabrilend/ai-stuff",
    "thumbnail_url": "https://opengraph.githubassets.com/6d3f82a3970731e90e7c0f6d6e93c249f3fb4c7301fa0e9f432ba4dc508fe12d/gabrilend/ai-stuff",
    "created_at": "2026-01-29T01:07:08.044Z",
    "topic": "tech"
  },
  {
    "slug": "death-of-an-indian-tech-worker",
    "title": "Death of an Indian Tech Worker",
    "description": "A wave of suicides and widespread AI-fueled layoffs reveal a workforce under extreme pressure.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://restofworld.org/2026/india-tech-workers-crisis-suicide/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2025/12/sized_India_IT_Deaths_DSC4011-1600x900.jpg",
    "created_at": "2026-01-29T01:07:06.574Z",
    "topic": "tech"
  },
  {
    "slug": "its-incredible-its-terrifying-its-moltbot",
    "title": "It's incredible. It's terrifying. It's MoltBot",
    "description": "MoltBot shows how powerful local AI agents can be. But if your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.",
    "fullText": "MoltBot (formerly Clawd Bot), the locally running, open-source AI agent named after the Lobster workflow shell that powers its agentic loop, has rocked an AI community that, just weeks ago, was so in love with its own hype it would have yawned at literal magic.\n\nAnd yet MoltBot, seemingly just a wrapper around a collection of familiar technologies, has put those pieces together in a way that feels like a portal to a future that, a month ago, still felt impossibly distant.\n\nWithin an hour of setting up MoltBot on my Mac, it had already built a fully featured kanban board where I could assign it tasks and track their state.\n\nI have seen other stories that are even wilder. One user shared an anecdote about asking it to make a restaurant reservation, and when it realized it could not do it through OpenTable, it went and got its own AI voice software and just called the restaurant, then secured the reservation over the phone.\n\nIts own author, Peter Steinberger, described joking to MoltBot that he was worried about his laptop getting stolen while he was still developing it in Morocco. MoltBot, ever the terrifyingly efficient pragmatist, immediately started planning its migration to a remote server.\n\nNone of those are pre-programmed routines. They are dynamic behaviors born out of an agentic loop that takes a goal and improvises a plan, grabbing whatever tools it needs to execute. It can apply general world knowledge, specific skills, and near-perfect memory into organized action toward objectives you set, and, more sobering, objectives it decides to set for itself.\n\nStories like these keep pouring in. My feed is full of people buying Mac minis as dedicated devices for their new agentic AI friend. I have also seen multiple posts pointing at Cloudflare’s secure tunneling as the obvious way to access a local setup from anywhere on the internet.\n\nMoltBot is able to give us this preview of the future because it is a tool that, for now, forgoes an essential constraint: security. The project’s FAQ presents the Faustian bargain plainly: “There is no ‘perfectly secure’ setup.”\n\nMoltBot works because it does three simple things better than almost anything else in the agent world right now:\n\nIt keeps persistent memory across sessions.\n\nIt has deep, unapologetic access to your local machine and apps.\n\nIt can take action autonomously in an agentic loop, not just suggest steps.\n\nThat combination is why it feels both a glimpse at the future, but presented as a goal, where between us and the future realized, is a lot of hard work to make it safe.\n\nAt 1Password, we make it easy to take advantage of this future in a way that keeps you secure.\n\nMoltBot’s memory and configuration are not abstract concepts. They are files. They live on disk. They are readable. They are in predictable locations. And they are plain text.\n\nIf an attacker compromises the same machine you run MoltBot on, they do not need to do anything fancy. Modern infostealers scrape common directories and exfiltrate anything that looks like credentials, tokens, session logs, or developer config. If your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.\n\nAnd what makes this worse than a typical credential leak is the context.\n\nA single stolen API token is bad. Hundreds of stolen tokens and sessions for the critical services in your life is even worse. But a hundred stolen tokens and sessions, plus a long-term memory file that describes who you are, what you’re building, how you write, who you work with, and what you care about, is something else entirely. It’s the raw material needed to phish you, blackmail you, or even fully impersonate you in a way that even your closest friends and family can’t detect.\n\nOne of the smartest things I’ve heard about MoltBot came from a customer who set it up on a dedicated Mac mini with its own email address and its own 1Password account, as if it were a new hire. They first installed it on their main laptop, then got spooked by how much it could touch, so they moved it to a separate machine to control its access and experiment safely.\n\nThis is directionally correct and it’s compatible with how we are thinking about the future of securing AI with 1Password.\n\nThe mistake the industry is making right now is treating agent security like normal app security. A familiar consent screen. A one-time approval. A set of scopes. Then we assume the future behavior will match the intent of that one moment.\n\nThat model breaks the second you hand autonomy to something that is adaptive and non-deterministic by design. The agent changes. The tasks change. The context changes. The approval you gave last week is used in new and unexpected ways today.\n\nSecurity for agents is not about granting access once. It is about continuously mediating access at runtime for every action and request.\n\nThe future we want looks like this:\n\nYour agent has its own identity, like a new hire.\n\nIt gets access through 1Password, not through a pile of long-lived tokens sitting in plain text on disk.\n\nWhen it needs to act, it requests the minimum authority it needs right now.\n\nThat authority is time-bound, revocable, and attributable to the agent, not smeared across the human who originally clicked approve.\n\nYou can answer the only question that matters when something goes wrong: who did what, when?\n\nIn other words, 1Password is not just where secrets live. It is the control plane that governs access. It is the layer that turns agent autonomy into something you can actually trust.\n\nAgents are going to become normal. The only question is whether you choose to make them governable.\n\nThat future does not exist today, but the work to make it real and safe is already underway.\n\n1Password will be the company that makes that possible.",
    "readingTime": 5,
    "keywords": [
      "plain text",
      "agentic loop",
      "long-term memory",
      "stolen tokens",
      "access",
      "security",
      "needs",
      "action",
      "secure",
      "sessions"
    ],
    "qualityScore": 1,
    "link": "https://1password.com/blog/its-moltbot",
    "thumbnail_url": "https://images.ctfassets.net/3091ajzcmzlr/1xclNmsAQS1IjIbPnk3VN3/79239dd8dd39c7accebf4d87c9ef76a8/Hero_Developer_1920x1080_2x.webp",
    "created_at": "2026-01-29T01:07:06.479Z",
    "topic": "tech"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-was-really-nice-in-renaming-email-but-everything-went-wrong-on-rebrand-day",
    "title": "Clawdbot creator says Anthropic was 'really nice' in renaming email — but everything 'went wrong' on rebrand day",
    "description": "Clawdbot creator Peter Steinberger said someone at Anthropic sent an internal email about the name, but they didn't send lawyers after him.",
    "fullText": "Anthropic didn't sic their lawyers on Clawdbot. But they did send an email.\n\nPeter Steinberger initially named his viral AI agent after Clawd, the Claude Code mascot. Anthropic owned the trademark to Clawd's image, though, as well as the Claude name. Weeks after the launch, Steinberger changed the name to Moltbot, a move he said wasn't his decision.\n\nOn TBPN, Steinberger described the behind-the-scenes of the name change.\n\n\"I got an email from Anthropic that I had to rename the project,\" he said. \"Kudos, they were really nice. They didn't send their lawyers. They sent someone internally.\"\n\nStill, the timeline was \"rough,\" Steinberger said, and it's not easy to rename a product with such name recognition on social media.\n\n\"Everything that could have gone wrong today went wrong,\" he said.\n\nShortly after renaming the project, Steinberger said the X account was immediately snapped up by crypto sellers. X staff quickly helped Steinberger claim the handle, he said, but, for 20 minutes, \"that didn't work out so well.\"\n\nWhy wouldn't Anthropic — or any other company, for that matter — just buy Moltbot? Venture capitalists are certainly knocking down his door, Steinberger said. But the other population emailing him may put off possible acquirers: security researchers.\n\n\"This is all vibe-coded,\" Steinberger said. \"I don't know if any company would touch it, because we just haven't solved some things.\"\n\nSteinberger acknowledged that there was \"absolute risk\" with his product. He also likely wouldn't be interested in a big acquisition; Steinberger said that he'd rather Moltbot be a foundation or nonprofit than a company.\n\nWhile Clawdbot may have been named after Claude Code, Steinberger said he preferred coding with OpenAI's Codex. He called Codex more straightforward, while Claude Code required more \"tricks.\"\n\nWhen questions on his Discord server were getting out of control, Steinberger would copy and paste them straight into Codex, he said.\n\nOpenAI's chief marketing officer, Kate Rouch, saw the opportunity to dunk on Anthropic and took it.",
    "readingTime": 2,
    "keywords": [
      "anthropic",
      "steinberger",
      "didn't",
      "lawyers",
      "email",
      "named",
      "rename",
      "project",
      "product",
      "wouldn't"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-moltbot-creator-anthropic-nice-name-change-2026-1",
    "thumbnail_url": "https://i.insider.com/697a33f6a645d118818823d1?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.595Z",
    "topic": "finance"
  },
  {
    "slug": "all-eyes-are-on-apples-ai-strategy-as-the-smartphone-giant-gets-ready-to-report-q1-earnings",
    "title": "All eyes are on Apple's AI strategy as the smartphone giant gets ready to report Q1 earnings",
    "description": "Apple's AI strategy draws attention as it prepares to report Q1 earnings. Analysts predict potential stock rally if AI plans impress investors.",
    "fullText": "Apple will round out the week's mega-cap tech bonanza on Thursday when it reports earnings for its fiscal first quarter.\n\nWith Meta, Microsoft, and Tesla due to report on Wednesday, AI will already be front and center for investors and analysts, and Apple's strategy is expected to be closely scrutinized.\n\nAll eyes will be on Apple's AI strategy when itreports after the market close on Thursday.\n\nThus far, the firm has largely opted out of the massive capex that other mega-cap companies have invested in AI infrastructure. Instead, it's hoped to join forces with already established AI players, recently announcing a partnership with Google's Gemini to boost its Siri voice assistant.\n\nApple's stock is up about 10% over the last 12 months, lagging the broader market and some of its Magnificent Seven peers. Shares were down about 1% on Wednesday to around $255.\n\nWall Street expects Apple to report $138.4 billion in revenue for the quarter and earnings per share of $2.68.\n\nHere's what top analysts are saying about the stock leading up to the report, and what they say to watch for when the $3.7 trillion firm reports Thursday afternoon.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, like they have for other firms who have touted their involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nAnalyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he thinks investors will be underwhelmed by iPhone sales numbers.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nThe bank said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impactings cost and margins,\" UBS wrote in a January 20 note.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said in an email on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"",
    "readingTime": 4,
    "keywords": [
      "january note",
      "rising memory",
      "client note",
      "apple's stock",
      "iphone sales",
      "apple's ai",
      "google gemini",
      "strategy",
      "earnings",
      "investors"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-preview-ai-iphone-siri-wall-street-expectations-2026-1",
    "thumbnail_url": "https://i.insider.com/697a41e9d3c7faef0ecd1553?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.472Z",
    "topic": "finance"
  },
  {
    "slug": "an-amazon-worker-used-an-ai-tool-to-flag-which-roles-were-on-the-chopping-block",
    "title": "An Amazon worker used an AI tool to flag which roles were on the chopping block",
    "description": "Amazon plans to lay off 16,000 employees, impacting teams like AWS and Alexa. An employee used an AI tool to list potentially affected areas.",
    "fullText": "An Amazon employee used an AI tool to analyze internal conversations and compile a list of potential teams and organizations affected by layoffs, according to messages viewed by Business Insider.\n\nAmazon announced layoffs on Wednesday, saying it would cut 16,000 corporate employees. The company hasn't publicly revealed where it plans to make cuts. The employee's list is AI-generated and appears to be based on internal Slack conversations, so it may contain inaccuracies. Amazon did not respond to a request to verify the list.\n\nBusiness Insider edited the list for length and clarity. The employee used an AI tool called Pippin to make the list, which Amazon employees have been using increasingly for writing and reviewing documents.\n\n\"Used Pippin to help me parse conversations from today,\" the employee wrote on the company's Slack. \"Please note that this info may not be 100% accurate. Take care, everyone!\"\n\nBusiness Insider independently reviewed internal messages related to Amazon layoffs within the AI cloud service Bedrock, the cloud data warehouse service Redshift, the ProServe consulting team, the Prime subscription service, and the last-mile Delivery Experience team.\n\nWednesday's round of layoffs marks the latest mass job cut since October, when Amazon shed 14,000 roles. Amazon employs more than 1.5 million people globally, though its corporate workforce represents a relatively small share of that total, at roughly 350,000 employees.\n\nHave a tip? Contact Ashley Stewart via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "list",
      "layoffs",
      "employee",
      "internal",
      "conversations",
      "employees",
      "service",
      "amazon",
      "tool"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/amazon-layoffs-ai-tool-affected-teams-2026-1",
    "thumbnail_url": "https://i.insider.com/68422ee89d73a0031e8dff91?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.381Z",
    "topic": "finance"
  },
  {
    "slug": "servicenow-ceo-is-sure-ai-wont-eat-software-hes-betting-big-on-his-own-stock-to-prove-it",
    "title": "ServiceNow CEO is sure AI won't eat software. He's betting big on his own stock to prove it.",
    "description": "The CEO, unfazed by AI threats, commits to 2030 leadership, reveals $5 billion buyback, and redoes his compensation package to bet more on the stock.",
    "fullText": "No matter how much profit and revenue growth ServiceNow generates, Wall Street has been too worried about the threat of AI to notice or care.\n\nBill McDermott has had enough. The ServiceNow CEO is so sure AI won't eat software that he's betting more on his own stock and committing to stay on as the company's leader through 2030.\n\nMcDermott also said he recently redid his executive compensation to tie his future pay more closely to ServiceNow's stock performance over the next three years. These packages usually involve big equity awards, so the CEO is effectively putting more of his money where his mouth is.\n\n\"We're building a trillion-dollar company here,\" McDermott told Business Insider in an interview on Wednesday. The company, which sells software to businesses, once again reported quarterly revenue and profit that beat Wall Street expectations on Wednesday. It also announced a new partnership with AI startup Anthropic.\n\n\"Through my own compensation, I'm betting on the stock,\" McDermott said.\n\nAs a sign of confidence, ServiceNow approved a $5 billion share repurchase program on Wednesday. McDermott said the company will put a big chunk of this to work quickly by buying about $2 billion worth of its own stock in the coming weeks.\n\nThe executive said he also recently committed to staying on as CEO through the end of 2030.\n\nIn the past year, this type of good news hasn't landed well with investors. ServiceNow stock is down about 40% since early 2025 on concern generative AI could replace some types of corporate software.\n\nMcDermott told Business Insider that ServiceNow's results show this isn't happening. Instead, revenue growth remains strong and cash flow is improving, he said.\n\n\"The revenue growth is there. The free cash flow and operating margins are accelerating,\" he told Business Insider on Wednesday. \"We deserve a higher multiple, and we will get it back.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "cash flow",
      "revenue growth",
      "business insider",
      "wall street",
      "stock",
      "software",
      "profit",
      "betting",
      "recently",
      "executive"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/servicenow-ceo-buys-his-own-stock-commits-stay-2030-2026-1",
    "thumbnail_url": "https://i.insider.com/697a76ffe1ba468a96aae62c?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.300Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-cfos-memo-to-staff-calls-out-ai-deals-coding-and-chips",
    "title": "Microsoft CFO's memo to staff calls out AI deals, coding, and chips",
    "description": "CFO Amy Hood sent an internal memo about the results, viewed by Business Insider.",
    "fullText": "After Microsoft reported results on Wednesday, CFO Amy Hood sent an internal memo to employees calling attention to recent developments in AI chips and coding tools, and deals with OpenAI and Anthropic.\n\nHood sends these emails every quarter when Microsoft discloses its financials. Her missives mostly rehash what the company reports publicly, such as how revenue and profit are growing, or what is discussed on analyst earnings calls.\n\nStill, these memos provide insight into what Microsoft executives deem most important, and what they want employees to know.\n\nThe latest memo highlighted how Microsoft is gaining share in markets where the total addressable market is expanding.\n\nHood specifically mentioned the launch of the GitHub Copilot software development kit in the growing market of AI coding tools, and the release of Microsoft's new Maia 200 AI chip.\n\nHood's email also called out Azure commitments from OpenAI and Anthropic that helped increase commercial bookings, basically the deals Microsoft closed in the quarter, by 230%, year over year.\n\nCapital expenditure on computing and datacenter infrastructure also broke yet another quarterly record, reaching $37.5 billion, she also noted.\n\nThis afternoon, we announced our second-quarter financial results. We exceeded Wall Street expectations, growing revenue 17% and 15% in constant currency and operating income by 21% and 19% in constant currency -a strong finish to the first half of the fiscal year.\n\nIn the quarter, Microsoft Cloud revenue surpassed $50 billion for the first time, growing 26% and 24% in constant currency.\n\nThere were many highlights this quarter, but a few stand out as reminders of the value our products and services deliver to customers - and as proof points of the progress we are making:\n\nInvestors tune in to our earnings call for the full details on this quarter and a look ahead to Q3. It's a helpful way to stay aligned as we deliver on our commitments. Join live today at 2:30 PM Pacific, listen on-demand, or check the transcript on the Investor Relations website.\n\nThis quarter's results reflect meaningful progress on core priorities. We continue to add capacity with pace, drive steady efficiency gains across our fleet, and invest in each layer of the stack\n\nAs we enter the second half of the fiscal year, we're operating in markets with expanding TAM where we continue to gain share and you can see our progress in many places, from last week's announcement of the GitHub Copilot SDK to Monday's Maia 200 announcement. We are innovating and delivering together. And we're doing it with the quality and security our customers expect from us. All of this builds trust from customers and partners as they rely on us for mission critical workloads.\n\nThanks again for all your work.\n\nWith appreciation and gratitude,\n\nHave a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "coding tools",
      "constant currency",
      "quarter",
      "revenue",
      "email",
      "customers",
      "progress",
      "memo",
      "employees",
      "deals"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/internal-microsoft-cfo-memo-calls-out-ai-deals-coding-and-chips-2026-1",
    "thumbnail_url": "https://i.insider.com/697a82dfa645d11881883093?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.127Z",
    "topic": "finance"
  },
  {
    "slug": "servicenow-q4-2025-slides-aidriven-growth-fuels-21-revenue-increase",
    "title": "ServiceNow Q4 2025 slides: AI-driven growth fuels 21% revenue increase",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/servicenow-q4-2025-slides-aidriven-growth-fuels-21-revenue-increase-93CH-4471707",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/f0c523919e53988732ca75602273d0d73c5c7e5f47521b13ca2713f7350e5623.png",
    "created_at": "2026-01-29T01:07:04.772Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-q2-2026-slides-cloud-revenue-tops-50b-amid-heavy-ai-spending",
    "title": "Microsoft Q2 2026 slides: Cloud revenue tops $50B amid heavy AI spending",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/microsoft-q2-2026-slides-cloud-revenue-tops-50b-amid-heavy-ai-spending-93CH-4471711",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/a73d2e0e45e3994329b7d8e1f8954e14a07693578df1fa62aec0fdfbd85be9fb.png",
    "created_at": "2026-01-29T01:07:04.770Z",
    "topic": "finance"
  },
  {
    "slug": "samsung-sees-strong-ai-demand-after-profit-triples-to-record-high",
    "title": "Samsung sees strong AI demand after profit triples to record high",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/samsung-profit-triples-to-record-high-as-ai-boom-exacerbates-chip-shortage-4471603",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0R1JB_L.jpg",
    "created_at": "2026-01-29T01:07:04.759Z",
    "topic": "finance"
  },
  {
    "slug": "tesla-q4-2025-slides-margin-gains-offset-delivery-decline-ai-focus-intensifies",
    "title": "Tesla Q4 2025 slides: Margin gains offset delivery decline, AI focus intensifies",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/tesla-q4-2025-slides-margin-gains-offset-delivery-decline-ai-focus-intensifies-93CH-4471712",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/a6b569bd92632ca77e41086bbac49b3563f84caeee18846f16e5c96e68c2aeb9.png",
    "created_at": "2026-01-29T01:07:04.655Z",
    "topic": "finance"
  },
  {
    "slug": "bill-gates-ai-will-probably-be-superior-to-people-predicts-it-could-end-doctor-shortages-and-we-wont-need-humans-for",
    "title": "Bill Gates: AI Will Probably Be 'Superior' to People —Predicts It Could End Doctor Shortages and We Won't Need Humans 'For Most Things'",
    "description": "Bill Gates doesn't just see AI as a breakthrough—he sees it as a turning point. For doctors, for teachers, for many of the roles once considered safe from automation. In two recent interviews, the Microsoft co-founder laid out a future where intelligence isn't rare or elite—it's abundant, automated, and free. According to Harvard Magazine, Gates sat down with professor Arthur Brooks at Harvard's Sanders Theatre to discuss his memoir \"Source Code\" last year. But the most headline-worthy moment wa",
    "fullText": "Bill Gates doesn't just see AI as a breakthrough—he sees it as a turning point. For doctors, for teachers, for many of the roles once considered safe from automation. In two recent interviews, the Microsoft co-founder laid out a future where intelligence isn't rare or elite—it's abundant, automated, and free.\n\nAccording to Harvard Magazine, Gates sat down with professor Arthur Brooks at Harvard's Sanders Theatre to discuss his memoir \"Source Code\" last year. But the most headline-worthy moment wasn't about the past. It was Gates' stark prediction about what AI will do next.\n\nThe AI Marketing Platform Backed by Insiders from Google, Meta, and Amazon — Invest at $0.85/Share\n\nSam Altman Says AI Will Transform the Economy — This Platform Lets Investors Back Private Tech Early\n\nIn the interview, Gates said artificial intelligence will ease shortages in fields like medicine and education by taking over tasks traditionally done by humans.\n\nHe reportedly described a future where machines manage primary-care diagnostics, especially in places lacking medical professionals. In that context, Gates told Brooks, \"the machine will probably be superior to humans—because the breadth of knowledge that you need to make some of these decisions really goes beyond individual human cognition.\"\n\nGates didn't suggest human professionals would vanish overnight. But he made clear that when machines can deliver diagnoses more accurately, more affordably, and more consistently than people—they won't be sidekicks. They'll be replacements.\n\nAnd it's not just about medicine. Harvard Magazine reports that Gates framed the rise of AI as part of the same arc that turned bulky corporate computers into personal tools. Only now, the commodity isn't hardware—it's intelligence itself.\n\n\"What we're doing now [in artificial intelligence] is kind of an extension of the digital revolution,\" he said, \"and all of those things are about free intelligence.\"\n\nTrending: Blue-chip art has historically outpaced the S&P 500 since 1995, and fractional investing is now opening this institutional asset class to everyday investors.\n\nThat phrase—free intelligence—is central to Gates' view. Once reserved for rare professionals with years of education, high-quality expertise will soon be as accessible as Wi-Fi.\n\nIn education, Gates predicted, AI could reshape the classroom, adapting to each student and even learning how to keep them motivated. In healthcare, it will take pressure off overworked doctors and bring diagnostic tools to parts of the world that never had them.\n\nBut Gates also issued a warning. More access doesn't always mean better outcomes.\n\n\"[Sometimes when] you empower humans, it doesn't always get pushed in the right direction,\" he said, according to Harvard Magazine.\n\nThe very systems designed to educate or heal could just as easily spread misinformation or bias—if deployed without care. Gates acknowledged this isn't just a shift in technology—it's a shift in power.\n\nThat same caution appeared during his appearance on \"The Tonight Show with Jimmy Fallon\" last year. Asked about the pace of change, Gates reflected on how computing once felt expensive and exclusive—and now intelligence itself is entering the same phase transition.\n\n\"The era that we're just starting is that intelligence is rare,\" Gates said. \"And with AI, over the next decade, that will become free, commonplace… great medical advice, great tutoring.\"\n\nSee Also: Americans With a Financial Plan Can 4X Their Wealth — Get Your Personalized Plan from a CFP Pro\n\nWhen Fallon asked whether humans would still be needed, Gates didn't hesitate.\n\n\"Not for most things,\" he said.\n\nA few roles might survive—he mentioned baseball and talk shows—but the vast majority of tasks people are trained to do? Machines will do them better, faster, and cheaper.\n\nFor investors, that future isn't just disruptive—it's investable. As AI reshapes industries like education, healthcare, and logistics, some are looking beyond Big Tech and turning to early-stage platforms. Startups focused on diagnostics, learning tools, and productivity automation are drawing serious capital. Platforms like Fundrise offer everyday investors a chance to back emerging AI companies—often with as little as $10.\n\nIt's an exciting future, especially if artificial intelligence really can solve chronic shortages in doctors and educators. But as Gates reminded both Harvard students and late-night audiences, access alone won't guarantee progress. What we do with free intelligence still depends on the people holding the keys.\n\nRead Next: Security and regulation matter in crypto — explore Kraken Pro's compliance-first trading platform.\n\nUp Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.\n\nGet the latest stock analysis from Benzinga:\n\nAPPLE (AAPL): Free Stock Analysis Report\n\nTESLA (TSLA): Free Stock Analysis Report\n\nThis article Bill Gates: AI Will Probably Be &#39;Superior&#39; to People —Predicts It Could End Doctor Shortages and We Won&#39;t Need Humans &#39;For Most Things&#39; originally appeared on Benzinga.com",
    "readingTime": 4,
    "keywords": [
      "free stock",
      "gates didn't",
      "everyday investors",
      "artificial intelligence",
      "isn't",
      "education",
      "humans",
      "tools",
      "doesn't",
      "doctors"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/articles/bill-gates-ai-probably-superior-183113060.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/DF6258E98ADD6B094FC771AB3D6E92CBB9BEBB9E75A1AD15D46DFD95BE7A3829/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fs.yimg.com%2Fos%2Fen%2FBenzinga%2F88c54d397981b6884f0cecb1a1c01081",
    "created_at": "2026-01-29T01:07:04.474Z",
    "topic": "tech"
  },
  {
    "slug": "apple-report-drops-iphone-18-bombshell",
    "title": "Apple report drops iPhone 18 bombshell",
    "description": "Apple (AAPL) is apparently opting for margin pain instead of sticker shock. Memory prices continue to spike due to relentless AI data center demand, but Apple’s looking to sidestep raising iPhone prices, even if it means taking a bottom-line hit. Analyst Ming-Chi Kuo, who’s a veteran in covering ...",
    "fullText": "Apple (AAPL) is apparently opting for margin pain instead of sticker shock.\n\nMemory prices continue to spike due to relentless AI data center demand, but Apple’s looking to sidestep raising iPhone prices, even if it means taking a bottom-line hit.\n\nAnalyst Ming-Chi Kuo, who’s a veteran in covering Apple’s supply chain for several years, says the tech giant will stick with their approach when it launches the hotly anticipated iPhone 18, at least for now.\n\nThat pivotal decision puts Apple’s supply-chain strength under the scanner as it heads into earnings on Thursday, January 29, 2026 (after the market closes).\n\nHaving covered the memory space extensively over the past few months, it’s crystal clear that suppliers have a ton of leverage for the foreseeable future.\n\nBellwethers in the space, like Micron, are building mammoth fabs to ease supply constraints, but most of those efforts are long-term, pointing to potential trouble over the next couple of years at least.\n\nNaturally, most hardware companies have little choice but to hike prices, but Apple isn’t your average hardware company.\n\nApple can take the hits and is far more insulated than any other hardware company in history, which could potentially become its biggest strength amidst the memory crunch.\n\nAccording to TF International Securities analyst Ming-Chi Kuo, Apple is looking to take it on the chin with the higher memory costs instead of risking the iPhone pricing boat.\n\nMorgan Stanley sets jaw-dropping Micron price target after event\n\nNvidia’s China chip problem isn’t what most investors think\n\nQuantum Computing makes $110 million move nobody saw coming\n\nMorgan Stanley drops eye-popping Broadcom price target\n\nApple analyst sets bold stock target for 2026\n\nKuo’s read is that Apple senses an opportunity in one that effectively plays to its scale and tremendous supply-chain muscle.\n\nIn a post on X, Kuo acknowledged that higher memory costs will hit iPhone gross margins. However, we went on to say that,\n\nKuo boils Apple’s thinking down to three key moves.\n\nAbsorb the pain now: Memory prices are rising at an incredible pace, and Apple is opting for margin pressure instead of consumer backlash.\n\nLockdown supply: Apple’s scale enables it to effectively secure components that others can’t, even as the shortages grow worse.\n\nPlay the long game: Any near-term margin hit will be viewed as temporary, with services revenue likely to backfill over time.\n\nHowever, there’s a significant risk that these pressures aren’t contained, as Kuo notes that iPhone memory prices are still being renegotiated quarterly rather than on a semiannual basis.",
    "readingTime": 3,
    "keywords": [
      "analyst ming-chi",
      "ming-chi kuo",
      "higher memory",
      "morgan stanley",
      "apple’s",
      "iphone",
      "margin",
      "instead",
      "supply",
      "hardware"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/apple-report-drops-iphone-18-190300399.html",
    "thumbnail_url": "https://s.yimg.com/os/en/thestreet_881/25cca94f7b74c5f314fb9ee23e8aee25",
    "created_at": "2026-01-29T01:07:02.470Z",
    "topic": "finance"
  },
  {
    "slug": "chrome-can-now-use-ai-to-browse-the-internet-for-you",
    "title": "Chrome Can Now Use AI to Browse the Internet for You",
    "description": "Does the large language model need to disassociate too?",
    "fullText": "Have you ever wanted to browse the internet, but the thought of typing a URL into your address bar seemed just too exhausting? Now, Google's here to help. Today, the company announced a big expansion of its existing Gemini in Chrome feature, with the highlights including a new look for the AI companion, more-integrated image editing tools, and, perhaps most impressive (but also creepy), the launch of Auto Browse, which lets Gemini take the wheel when you're going online.\n\nPreviously, Gemini in Chrome appeared in a small box on top of your browser, which made it a bit inconvenient to use, especially when bouncing between tabs. Google's update moves it to a scrollable side panel view that's a bit bigger, and it won't obscure any of your other content. Instead, it'll sit to the right of the webpage your viewing, so you can more easily compare whatever answers Gemini gives you with what you're seeing, or carry on a conversation while bouncing between multiple tabs. It will retain all the same functionality as before, including the ability to reference multiple open tabs in prompts. It's a small change, but should help for usability.\n\nGoogle's Nano Banana image generation AI is having a bit of a moment, and the new Gemini in Chrome updates make it easier to use. Now, instead of having to download an image and re-upload it to Gemini, you can edit it using Nano Banana with a simple right click. Or, you could also use natural language to start an edit by pulling up the image you want to edit on your screen and telling Gemini to edit it in the side panel. Google says this should work with pretty much any image you can pull up on the browser.\n\nDuring a demo, Google showed this off to journalists using a Google Photos library, but there's nothing saying you have to stick to your own images. That immediately set off alarm bells for me, given Elon Musk's X is currently in hot water after opening up the ability for anyone to use Grok to edit other people's images directly on the social media platform and without their permission. After some users started using that tool to generate explicit content from others' photos, it was pared down a bit, but Google doesn't seem worried. When I asked about safety protections for this feature, a Google spokesperson told me the following:\n\n\"We have clear policies that prohibit the use of our AI tools to generate sexually explicit content, and our tools are continually getting better at reflecting these policies. We've invested in safety from the outset and added technical guardrails to help limit problematic outputs such as violent, offensive, or sexually explicit content.\"\n\nThe company didn't say anything about how users might use Nano Banana in Chrome to circumvent copyright, but technically, the new update doesn't really add new features to Google's AI image generator, it just makes it easier to access. Granted, the same thing applied to Grok's recent update, too, and easier access can mean opening the floodgates, even if you have the best of intentions.\n\nFinally, the big one: \"Agentic\" has been the hot buzzword in AI as of late, and Google doesn't want Chrome to be left behind. So now, instead of just answering questions, Gemini can take control of your browser for you.\n\nThe functionality is currently limited to Google AI Pro and Ultra subscribers, but starting today, those subscribers can ask Chrome to \"Auto Browse\"—completing research, taking you to different websites, and filling out forms for you.\n\nYou can watch as the AI navigates around the web, or you can click away to a different tab while it works in the background. Multiple tabs can Auto Browse at the same time, so you can have a few tasks going on at once. The AI will list out the steps it takes in the side panel while it navigates around, to make checking in on it easier.\n\nGoogle demonstrated this to journalists by showing the AI finding a specific product, navigating to its store page, singing into the buyer's account (using Google Password Manager), and adding it to their cart. The company also suggested you could use Auto Browse to schedule appointments, fill out an online form using information from an uploaded PDF, collect tax documents, compare apartments listed on sites like Redfin, and more. I haven't been able to go hands-on with it yet, so I can't speak to how well it'll perform any of these tasks, although it did look snappy in the controlled demo.\n\nMy concern with Auto Browse mostly lies in sketchy websites and permissions, although Google told me it's planned for those. Auto Browse needs to get permission before it can access your Google Password Manager, and if it stumbles across a link that the AI thinks doesn't look quite right, it will supposedly use Chrome's existing unsafe browsing protections to navigate away. A Google spokesperson told me its \"as secure as you can make it,\" although I'd probably want to keep an eye on it for at least my first few requests.\n\nThe feature also has one limitation for now—while it can be open in multiple tabs at once, your Auto Browse tabs won't be able to communicate with one another. That means each instance of Auto Browse is isolated, but that could change in the future.\n\nPersonally, I don't see myself using this much, especially for sensitive tasks like \"collecting tax documents,\" but automatically filling out a basic form does sound handy. Google said that Auto Browse will stop and ask for you to take over for sensitive steps in any tasks that might require it, like actually buying an item or submitting a form. It won't (or isn't supposed to) take that final step for you, giving you a chance to check its work. In that way, it's similar to the Gemini app's existing shopping features.\n\nGemini in Chrome can use most of Gemini's existing features, allowing it to connect with apps like Gmail or access your history chatting with the bot. But there is one big one that's planned for the \"coming months.\"\n\nRecently, the Gemini app proper rolled out a beta for \"Personal Intelligence\" to paying users, allowing the AI to view all of your past conversations and connected apps without you having to direct it where to look. It's basically an extension of those existing connected apps and history features, with a reasoning model applied over it. For instance, you could tell it to help you find new tires for your car, and it would automatically know to look through your Gmail and Google Photos to find out what model of car you have and the last time you bought tires.\n\nThat feature is still baking, but that it's even in the works means Google is moving fast on bringing parity between all the different ways you can access Gemini. Every other feature mentioned in this article is either already available, or rolling out now.",
    "readingTime": 6,
    "keywords": [
      "password manager",
      "auto browse",
      "google password",
      "tax documents",
      "sexually explicit",
      "connected apps",
      "explicit content",
      "google doesn't",
      "nano banana",
      "chrome"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/now-chrome-can-use-ai-to-browse-for-you?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG2PXJ2NVAEY8C0G8D6FT4SG/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-29T01:07:02.240Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-use-of-ai-images-pushes-boundaries-erodes-public-trust-say-experts",
    "title": "Trump's use of AI images pushes boundaries, erodes public trust, say experts",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong’s arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis.\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,” he said. “By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,” or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they’re seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can’t tell if what they’re watching is fake, and questions whether they would know “what’s real or not when it actually matters, like when the stakes are a lot higher.”\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://apnews.com/article/ai-videos-trump-ice-artificial-intelligence-08d91fa44f3146ec1f8ee4d213cdad31",
    "thumbnail_url": "https://dims.apnews.com/dims4/default/29772b9/2147483647/strip/true/crop/3926x2616+0+1/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F04%2F25%2Fc231e22dce01b274680dc10818de%2F17172084f4f9476b92e116dc22fc2160",
    "created_at": "2026-01-28T18:25:13.699Z",
    "topic": "tech"
  },
  {
    "slug": "a-single-command-to-run-claude-code-inside-lima-vms",
    "title": "A single command to run Claude Code inside Lima VMs",
    "description": "Run AI agents in safe VMs scoped to a local folder - sylvinus/agent-vm",
    "fullText": "sylvinus\n\n /\n\n agent-vm\n\n Public\n\n Run AI agents in safe VMs scoped to a local folder\n\n License\n\n MIT license\n\n 7\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sylvinus/agent-vm",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sylvinus/agent-vm",
    "thumbnail_url": "https://opengraph.githubassets.com/afff19059a7c9a83e1fbbfce6791246021379e585e7faeb991d419af9a77fd1f/sylvinus/agent-vm",
    "created_at": "2026-01-28T18:25:12.991Z",
    "topic": "tech"
  },
  {
    "slug": "apple-plans-to-launch-aipowered-wearable-pin-device-as-soon-as-2027",
    "title": "Apple plans to launch AI-powered wearable pin device as soon as 2027",
    "description": "Apple, OpenAI, Meta, and more are all racing toward AI hardware products.",
    "fullText": "Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.\n\nThe product is said to be “the same size as an AirTag, only slightly thicker,” and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple’s solution, should Apple offload the processing to a synced external device like an iPhone.\n\nThe Information’s sources don’t specify whether that’s the plan, or if it will be a standalone device.\n\nThe wearable will have a single physical button “along its edges” and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user’s surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.\n\nThe report didn’t include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.\n\nNot long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.\n\nApple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea’s conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.\n\nJust a few days ago, it was revealed that Apple will tap Google’s Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.",
    "readingTime": 2,
    "keywords": [
      "smart glasses",
      "product",
      "device",
      "products",
      "apple",
      "wearable",
      "models",
      "release",
      "planned",
      "launch"
    ],
    "qualityScore": 0.9,
    "link": "https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png",
    "created_at": "2026-01-28T18:25:10.388Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-tech-career-coach-do-these-2-things-immediately-after-getting-laid-off-and-avoid-this-common-mistake-when-using-ai",
    "title": "I'm a tech career coach. Do these 2 things immediately after getting laid off — and avoid this common mistake when using AI.",
    "description": "Amazon announced it's cutting 16,000 jobs. The career coach Kyle Elliott said you should use these two critical tools to help you find a job after a layoff.",
    "fullText": "This as-told-to essay is based on a conversation with Kyle Elliott, 33, a career coach who lives in California. The following has been edited for length and clarity.\n\nGetting laid off is very traumatic — and it's becoming more common.\n\nI've been a full-time career coach to tech employees at startups and in Big Tech since 2017, and I've seen how layoffs have become more visible in recent years.\n\nI help clients navigate life after a layoff, including what role they want next and how to apply for new jobs.\n\nAmazon has announced new plans to cut staff, and I want affected employees to remember that they are coming from one of the world's top companies.\n\nPeople will want them, and they will find something.\n\nWhen people reach out to me for coaching after a layoff, many have a scarcity mindset and feel like they have to apply for any job.\n\nFor some people who urgently need to pay rent or put food on the table, that's necessary. But in other cases, it makes sense to take a beat and evaluate what you're really looking for in your next role.\n\nThe very first thing I ask clients to do is create a list of \"must-haves\" and \"dealbreakers\" for their next job. What are their salary expectations? Will they only work remotely? Are they willing to relocate? If you write the list before you start interviewing, you can act from a place of logic rather than panic.\n\nThe second step is to update your résumé and LinkedIn profile, which are two of your most critical tools in today's market. You're going to submit a résumé with almost every application, and having an up-to-date LinkedIn account puts you in a good position if potential employers check it or recruiters go looking for talent on the platform.\n\nYou want to optimize for the roles you're looking for in 2026, which means that if you were an engineer when you joined Amazon but are now a director, you want to make sure that's reflected on your LinkedIn page.\n\nI've seen clients turn to quick hacks for their job search, like asking AI to tailor their résumé or using it to find and apply to roles for them. But if everyone does that, you don't stand out.\n\nI can usually tell quickly if someone's written their résumé with AI. For example, they'll be applying to a systems engineer role, and it won't even have the phrase \"systems engineer\" in it.\n\nEveryone thinks only AI is reading their résumé, but I have clients who work in talent acquisition and HR — the humans who are still involved in the recruitment process. Humans hire other humans, even at big companies.\n\nIn the age of AI, be more human. Take a step back and think, if you were a human looking at this résumé, what would you want to see? Then put those phrases near the top, rather than using AI to create generic slop.\n\nI'd suggest creating a master résumé that you can spend 20 minutes tailoring for different roles. If you're using AI, use it more like an extra tool, rather than the thing that's driving your job search.\n\nLayoffs are normal now, especially in the tech industry, and there's much less stigma around them.\n\nBut there's more competition in the job market, because it's easier to apply for jobs with AI, for example, so the challenges around layoffs are different nowadays.\n\nIn today's job market, it's important to figure out what's unique about you. Lots of people will meet the job requirements, so you need to communicate why the company should hire you over the thousands of other applicants.\n\nOne thing that can help you is to look back at performance reviews and identify things people repeatedly say about you. You can try asking three to five people to share what makes you fabulous and to give examples. I've found that clients are surprised by the feedback they receive.",
    "readingTime": 4,
    "keywords": [
      "career coach",
      "systems engineer",
      "job search",
      "job market",
      "résum",
      "clients",
      "i've",
      "apply",
      "you're",
      "looking"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-career-coach-do-after-lay-off-common-mistake-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6979fb95e1ba468a96aad5d3?width=1084&format=jpeg",
    "created_at": "2026-01-28T18:25:10.354Z",
    "topic": "finance"
  },
  {
    "slug": "meta-earnings-updates-wall-street-is-focused-on-ai-capex-heading-into-q4-results",
    "title": "Meta earnings updates: Wall Street is focused on AI capex heading into Q4 results",
    "description": "Meta will report earnings for Q4 after the closing bell on Wednesday. The company will hold a call with analysts at 4:30 p.m. ET.",
    "fullText": "Meta Platforms is gearing up to report its fourth-quarter results and all eyes are on its ambitious AI plans, specifically its outlook for more capex spending in the coming year.\n\nSome Wall Street analysts say the Facebook parent's updates on AI infrastructure spending could overshadow other areas of its results, such as growth in its ad business.\n\nMeta will report earnings after the closing bell, and will hold a call with analysts around 4:30 p.m. ET.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\n\"While fears of partnering with a competitor such as Google or OpenAI are valid, we'd offer Anthropic (private) as an ideal partner that has so far shown little appetite to go after consumer,\" he wrote.\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nThe analyst added that this has prompted Rothschild to increase its full-year capex projection for Meta to $117.1 billion.\n\nGoldman analysts remain focused on Meta's capex plans, which they believe will continue to drive growth into 2026 and beyond. The bank recently raised its spending projections for the company, already above analyst estimates, noting that it sees upward pressure on consensus capex estimates.\n\n\"On the next earnings call, we expect investors will be focused on any updates on the work of the Meta Superintelligence Lab, the timing of any foundational model work and/or any strategies with respect to consumer or enterprise utility around AI,\" Goldman analysts stated.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\n\"In our view, Meta is positioned favorably — especially in the long-term — as it doubles down on an AI investment cycle,\" Black said.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nHe added that his team expects Meta's capex spending to come in between $109 and $114 billion for the year, likely above Wall Street consensus of $110 billion.",
    "readingTime": 5,
    "keywords": [
      "event bernstein",
      "codenamed avocado",
      "avocado rumored",
      "james cordwell",
      "zuckerberg unleashed",
      "ceo truly",
      "black notes",
      "pack shmulik",
      "shmulik posits",
      "company's ceo"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-earnings-stock-price-ai-capex-live-updates-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-28T18:25:09.621Z",
    "topic": "finance"
  },
  {
    "slug": "china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "title": "China lags behind US at AI frontier but could quickly catch up, say experts",
    "description": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n Continue reading...",
    "fullText": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\n\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\n\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n\nWu also announced plans to invest 380bn yuan (£40bn) in AI infrastructure over the next three years, news that sent Alibaba stocks soaring to their highest in nearly four years.\n\nWu’s foray into the existential, techno-frontier rhetoric normally deployed by western tech CEOs such as OpenAI’s Sam Altman and DeepMind’s Demis Hassabis caught the attention of observers. “Wu’s ASI speech represents a breakthrough,” the tech writer Afra Wang wrote in her China AI newsletter, Concurrent. “Major Chinese companies are beginning to articulate their own grand visions that carry the flavour of future prophecy.”\n\nAGI, a theoretical state of AI where a highly autonomous system is able to do a human’s job, has become the preoccupation of American tech companies such as OpenAI and DeepMind. Many see it as the next frontier of civilisation, and are in competition with each other, and China, to get there. In May, the president of Microsoft, Brad Smith, told a US Senate committee on AI that the “race between the United States and China for international influence likely will be won by the fastest first mover”.\n\nMany in Washington have internalised these fears. The US-China economic and scurity review commission has recommended that Congress “establish and fund a Manhattan Project-like program dedicated to racing to and acquiring an artificial general intelligence (AGI) capability”. The Manhattan Project was a second world war-era research operation to produce nuclear weapons.\n\nIn China, many saw Wu’s speech as articulating the vision of a bold, singular tech company, but not one that represented China’s overall AI industry.\n\n“China certainly has research groups working towards AGI. But most AI companies are working towards better applications,” said Ya-Qin Zhang, the dean of Tsinghua University’s Institute for AI Industry Research and former president of the tech company Baidu.\n\nA combination of limited computing power, a pragmatic approach to technology and a keen awareness of the present day potential of AI has steered China’s national AI policy towards real-life applications rather than frontier research.\n\nIn August, the Chinese government published its highly anticipated “AI+ strategy”. The policy document outlined how AI could turbocharge China’s development goals, such as by using AI to improve medical diagnoses and make supply chains more efficient. But it made no mention of AGI.\n\n“The Chinese government is intently focused on reaping the benefits of AI in the here and now and in the near future through diffusion and application of AI across the economy, society, defence, and other areas,” said Julian Gewirtz, a former senior director for China and Taiwan at the White House national security council. “Despite its goal to ‘catch up and surpass’ the United States, we shouldn’t assume that the Chinese Communist party has bought into the idea that AGI is imminent.”\n\n“If you’re just looking at what has been officially published … there is no clear acknowledgment of AGI at all,” said Selina Xu, a China tech analyst. Xu noted that Xi Jinping, China’s leader, had a history of preferring the physical economy to more intangible forces.\n\n“It’s a very different narrative from the AGI race as a lot of people in DC see it,” Xu said.\n\nOne of the biggest factors guiding this strategy is the fact that US sanctions have prevented Chinese companies from acquiring the world’s most sophisticated semiconductors, which are needed for advanced AI research.\n\nWashington has banned the sale of hi-tech microchips to China in an effort to rein in the country’s AI development. Nvidia, the world’s leading chipmaker, then developed more basic semiconductors specifically for the Chinese market. In December, Washington approved the Nvidia’s second-most advanced chips, the H200s, for sale in China. But Beijing has reportedly told custom agents that the chips cannot be imported into China, as the government seeks to break the country’s reliance on overseas technology.\n\nChina insists that “necessity is the mother of invention” and points to the success of companies such as DeepSeek as proof that the US restrictions will merely spur innovation. DeepSeek’s founder, Liang Wenfeng, is one of the few Chinese tech leaders who, like Alibaba’s Wu, has openly expressed an interest in AGI.\n\nBut until China is able to produce its own advanced semiconductors at scale, most tech companies feel it is more profitable to use the hardware they already have to focus on AI applications rather than AGI.\n\nAnother factor guiding the US-China tech competition is the availability of datacentres and the energy to power them. In November, Jensen Huang, the CEO of Nvidia, said China would “win the AI race” in part because of its energy subsidies for datacentres.\n\nThe subsidies were reportedly introduced after Chinese tech companies complained of higher electricity bills caused by the domestic semiconductors they are obliged to use, which are less efficient than Nvidia’s. In a sign of how determined China is to break its reliance on imported technology, Reuters reported that any datacentres in receipt of state funds could only use domestic chips.\n\nSuch measures would reduce Nvidia’s competitive advantage in China and boost domestic chip producers, such as Huawei.\n\nSince 2021, China has reportedly poured $100bn into support for AI datacentres.\n\nBut there are signs that the boom may have been overzealous. A recent report from the China Academy of Information and Communications Technology said that nationwide, the utilisation rate for AI datacentres was 32%.\n\nIn a recent op-ed in China Economic Weekly, Rao Shaoyang, the director at the China Telecom Research Institute, wrote that in some regions of China, the computing power industry was operating in a similar fashion to China’s beleaguered property sector: build first, find buyers later. He cautioned against “blindly building intelligent computing centres” and said local computing power demand should be considered before building new datacentres.\n\nDespite the surplus in more general computing power, many experts believe China still does not have chips that are sophisticated enough to explore frontier research in AGI. But analysts note that the mood could change quickly.\n\n“The current status quo is highly fluid, and Xi Jinping has explicitly declared an ambition to lead the world in AI,” said Gewirtz. “So the fact that China construes that goal one way at this snapshot moment in time does not give me any comfort that in a year they’re going to construe it the same way.”\n\nAdditional research by Lillian Yang",
    "readingTime": 6,
    "keywords": [
      "intelligence agi",
      "grand visions",
      "real-life applications",
      "applications rather",
      "chinese tech",
      "frontier research",
      "china tech",
      "agi but",
      "datacentres",
      "computing"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2026/jan/28/china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8cc6bbd0024f4ba8485616485bd55f9c34d98452/538_0_4167_3333/master/4167.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=12e8d9082c7ad02aa672977a89beda90",
    "created_at": "2026-01-28T18:25:09.486Z",
    "topic": "tech"
  },
  {
    "slug": "google-deepmind-launches-ai-tool-to-help-identify-genetic-drivers-of-disease",
    "title": "Google DeepMind launches AI tool to help identify genetic drivers of disease",
    "description": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n Continue reading...",
    "fullText": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\n\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\n\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n\nMost common diseases that run in families, including heart disease and autoimmune disorders, as well as mental health problems, have been linked to mutations that affect gene regulation, as have many cancers, but identifying which genetic glitches are to blame is far from straightforward.\n\n“We see AlphaGenome as a tool for understanding what the functional elements in the genome do, which we hope will accelerate our fundamental understanding of the code of life,” Natasha Latysheva, a DeepMind researcher, told a press briefing on the work.\n\nThe human genome runs to 3bn pairs of letters – the Gs, Ts, Cs and As that comprise the DNA code. About 2% of the genome tells cells how to make proteins, the building blocks of life. The rest orchestrates gene activity, carrying the crucial instructions that dictate where, when and how much individual genes are switched on.\n\nThe researchers trained AlphaGenome on public databases of human and mouse genetics, enabling it to learn connections between mutations in specific tissues and their impact on gene regulation. The AI can analyse up to 1m letters of DNA code at once and predict how mutations will affect different biological processes.\n\nThe DeepMind team believes the tool will help scientists map out which strands of genetic code are most essential for the development of particular tissues, such as nerve and liver cells, and pinpoint the most important mutations for driving cancer and other diseases. It could also underpin new gene therapies by allowing researchers to design entirely new DNA sequences – for example, to switch on a certain gene in nerve cells but not in muscle cells.\n\nCarl de Boer, a researcher at the University of British Columbia in Canada, who was not involved in the work, said: “AlphaGenome can identify whether mutations affect genome regulation, which genes are impacted and how, and in what cell types. A drug could then be developed to counteract this effect.\n\n“Ultimately, our goal is to have models that are so good we don’t have to do an experiment to confirm their predictions. While AlphaGenome represents a significant innovation, achieving this goal will require continued work from the scientific community.”\n\nSome scientists have already begun using AlphaGenome. Marc Mansour, a clinical professor of paediatric haemato-oncology at UCL, said it marked a “step change” in his work to find genetic drivers for cancer.\n\nGareth Hawkes, a statistical geneticist at the University of Exeter, said: “The non-coding genome is 98% of our 3bn base pair genome. We understand the 2% fairly well, but the fact that we’ve got AlphaGenome that can make predictions of what this other 2.94bn base pair region is doing is a big step forward for us.”",
    "readingTime": 3,
    "keywords": [
      "dna code",
      "base pair",
      "genetic drivers",
      "gene regulation",
      "mutations",
      "cells",
      "letters",
      "researchers",
      "tool",
      "scientists"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/jan/28/google-deepmind-alphagenome-ai-tool-genetics-disease",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3f4612605000567b9e02c02efc58d3c631ac766a/802_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=78b47365d5b61d906daeb3627e153a8c",
    "created_at": "2026-01-28T18:25:09.444Z",
    "topic": "science"
  },
  {
    "slug": "how-gen-z-uses-gen-aiand-why-it-worries-them",
    "title": "How Gen Z Uses Gen AI—and Why It Worries Them",
    "description": "When it comes to gen AI, the habits, attitudes, and ideas of Gen Z are a harbinger of the future of work—and how the rest of us will feel when we get there. A survey of nearly 2,500 U.S. adults between the ages of 18 and 28 years old revealed some surprising findings. Most members of Gen Z use gen AI and, contrary to conventional wisdom, Gen Z’s relationship with these tools is more pragmatic than personal.",
    "fullText": "How Gen Z Uses Gen AI—and Why It Worries Them by Benjamin Lira, Dunigan Folk, Lyle Ungar and Angela L. DuckworthJanuary 28, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAs go the young, so goes society. Young adults were early adopters of cell phones, social media, and the internet. Now all of these technologies are universal. So how are members of Gen Z using generative AI today? How do they feel about it? What promising use cases have they discovered? And what are the implications for employers?",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/how-gen-z-uses-gen-ai-and-why-it-worries-them",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_2214975842.jpg",
    "created_at": "2026-01-28T18:25:09.162Z",
    "topic": "business"
  },
  {
    "slug": "hong-kong-scientists-double-warning-time-for-extreme-weather-with-ai",
    "title": "Hong Kong scientists double warning time for extreme weather with AI",
    "description": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.",
    "fullText": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.Current models only give 20 minutes to two hours warning.Hui Su, who led the project, said satellites can detect cloud formation earlier than other forecasting systems such as radar.:: Hui Su, Hong Kong University of Science and Technology''I think combining the strength of AI and satellite knowledge, we actually could have some revolutionary advancement in weather forecasting. So in this backdrop of climate change, I think accurate prediction of extreme weather (is) extremely important to reduce the economic losses associated with extreme weather.'':: CSU/CIRA & NOAA/NESDISDeveloped in collaboration with China’s meteorological authorities, the model has boosted accuracy by more than 15%, according to the team.Researchers said it has the potential to deliver global convective weather forecasts if sufficient satellite observation data is available.",
    "readingTime": 2,
    "keywords": [
      "hong kong",
      "kong university",
      "extreme weather",
      "climate",
      "prediction",
      "science",
      "convective",
      "cloud",
      "systems",
      "hours"
    ],
    "qualityScore": 0.65,
    "link": "https://www.yahoo.com/news/videos/hong-kong-scientists-double-warning-175919489.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/3veGT8tryJNVKP1yZmuBtQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://cf-images.us-east-1.prod.boltdns.net/v1/jit/6415665815001/cc639107-9d99-4da6-a306-1eb8059926ab/main/1280x720/50s445ms/match/image.jpg",
    "created_at": "2026-01-28T18:25:07.335Z",
    "topic": "news"
  },
  {
    "slug": "introducing-react-best-practices",
    "title": "Introducing: React Best Practices",
    "description": "We've encapsulated 10+ years of React and Next.js optimization knowledge into react-best-practices, a structured repository optimized for AI agents and LLMs.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vercel.com/blog/introducing-react-best-practices",
    "thumbnail_url": "https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/5VCSTefWazPIvZlDl3ZFbd/8996ca467f505fcec7d4f6fc19f9f1bd/image__15_.png",
    "created_at": "2026-01-28T12:27:43.743Z",
    "topic": "tech"
  },
  {
    "slug": "ai-kind-of-sucks-at-retouching-study-says",
    "title": "AI Kind of Sucks at Retouching, Study Says",
    "description": "As photographers lean more towards AI for retouching purposes, a new study finds how AI is not what people think it is supposed to be.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.thephoblographer.com/2026/01/27/ai-vs-human-retouching-the-quality-gap-is-bigger-than-expected/",
    "thumbnail_url": "https://www.thephoblographer.com/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-18.52.32.jpg",
    "created_at": "2026-01-28T12:27:41.769Z",
    "topic": "tech"
  },
  {
    "slug": "meta-allowed-minors-access-to-sextalking-chatbots-despite-staff-concerns-lawsuit-alleges",
    "title": "Meta allowed minors access to sex-talking chatbots despite staff concerns, lawsuit alleges",
    "description": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n Continue reading...",
    "fullText": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\n\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\n\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n\nThe filing on Monday included internal Meta employee emails and messages obtained by the New Mexico attorney general’s office through legal discovery. The state alleges they show that “Meta, driven by Zuckerberg, rejected the recommendations of its integrity staff and declined to impose reasonable guardrails to prevent children from being subject to sexually exploitative conversations with its AI chatbots”, the attorney general said in the filing. Meta announced last week that it had removed teen access to AI companions entirely, pending creation of a new version of the chatbots.\n\nIn the communications, some of Meta’s safety staff expressed objections the company was building chatbots geared for companionship, including sexual and romantic interactions with users. The artificial intelligence chatbots were released in early 2024. The documents cited in the state’s filing Monday don’t include messages or memos authored by Zuckerberg.\n\nAndy Stone, a Meta spokesperson, on Monday said the state’s portrayal was inaccurate and relied on selective information: “This is yet another example of the New Mexico attorney general cherrypicking documents to paint a flawed and inaccurate picture.”\n\nMessages in the filing showed safety staff had special concern about the bots being used for romantic scenarios between adults and minors under the age of 18, referred to as “U18s”.\n\n“I don’t believe that creating and marketing a product that creates U18 romantic AI’s for adults is advisable or defensible,” wrote Ravi Sinha, head of Meta’s child safety policy, in January 2024.\n\nIn reply, Antigone Davis, Meta’s global safety head, agreed that safety staff should push to block adults from creating underage romantic companions because “it sexualizes minors”. Sinha and Davis did not respond to requests for comment.\n\nAccording to one February 2024 message, a Meta employee whose name was redacted relayed that Zuckerberg believed that AI companions should be blocked from engaging in sexually “explicit” conversations with at least younger teens and that adults should not be able to interact with “U18 AIs for romance purposes”.\n\nA summary of a meeting dated 20 February 2024, said the CEO believed the “narrative should be framed around … general principles of choice and non-censorship”, that Meta should be “less restrictive than proposed”, and that he wanted to “allow adults to engage in racier conversation on topics like sex”.\n\nStone said the documents did not support New Mexico’s case. “Even these select documents clearly show Mark Zuckerberg giving the direction that explicit AIs shouldn’t be available to younger users and that adults shouldn’t be able to create under 18 AIs for romantic purposes.”\n\nMessages between two employees from March 2024 state that Zuckerberg had rejected creating parental controls for the chatbots, and that staffers were working on “Romance AI chatbots” that would be allowed for users under the age of 18.\n\nWe “pushed hard for parental controls to turn GenAI off – but GenAI leadership pushed back stating Mark decision”, one employee wrote in that exchange.\n\nNick Clegg, who was Meta’s head of global policy until early 2025, said in an email included in the court documents he thought Meta’s approach to sexualized AI companions was unwise.\n\nExpressing concern that sexual interactions could be the dominant use case for Meta’s AI companions by teenage users, Clegg said: “Is that really what we want these products to be known for (never mind the inevitable societal backlash which would ensue)?” Clegg did not respond to a request for comment.\n\nMeta’s AI chatbot policies eventually came to light, prompting a backlash in the US Congress and elsewhere.\n\nA Wall Street Journal article in April 2025 found that Meta’s chatbots included overtly sexualized underage characters and that they engaged in all-ages sexual roleplay, including graphic descriptions of prepubescent bodies. Reuters reported in August that Meta’s official guidelines for chatbots stated that it is “acceptable to engage a child in conversations that are romantic or sensual”. In response to the report, Meta said it was changing its policies and that the internal document granting such approval had been in error.",
    "readingTime": 4,
    "keywords": [
      "mexico attorney",
      "artificial intelligence",
      "parental controls",
      "internal meta",
      "meta employee",
      "sexual interactions",
      "safety staff",
      "new mexico",
      "new mexico’s",
      "meta’s ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/meta-lawsuit-minors-chatbots",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f6236f51e29389309cca0c8934bf7c5624b78619/289_0_4008_3208/master/4008.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7713cdfc7fbe29ee40fec93f7bfdb653",
    "created_at": "2026-01-28T12:27:37.644Z",
    "topic": "tech"
  }
]
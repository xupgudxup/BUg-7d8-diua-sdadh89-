[
  {
    "slug": "it-will-be-more-practical-to-fingerprint-real-media-than-fake-media",
    "title": "It will be more practical to fingerprint real media than fake media",
    "description": "Adam Mosseri offered a notably candid assessment on how AI is upending Instagram.",
    "fullText": "It's no secret that AI-generated content took over our social media feeds in 2025. Now, Instagram's top exec Adam Mosseri has made it clear that he expects AI content to overtake non-AI imagery and the significant implications that shift has for its creators and photographers.\n\nMosseri shared the thoughts in a lengthy post about the broader trends he expects to shape Instagram in 2026. And he offered a notably candid assessment on how AI is upending the platform. \"Everything that made creators matter—the ability to be real, to connect, to have a voice that couldn’t be faked—is now suddenly accessible to anyone with the right tools,\" he wrote. \"The feeds are starting to fill up with synthetic everything.\"\n\nBut Mosseri doesn't seem particularly concerned by this shift. He says that there is \"a lot of amazing AI content\" and that the platform may need to rethink its approach to labeling such imagery by \"fingerprinting real media, not just chasing fake.\"\n\nSocial media platforms are going to come under increasing pressure to identify and label AI-generated content as such. All the major platforms will do good work identifying AI content, but they will get worse at it over time as AI gets better at imitating reality. There is already a growing number of people who believe, as I do, that it will be more practical to fingerprint real media than fake media. Camera manufacturers could cryptographically sign images at capture, creating a chain of custody.\n\nOn some level, it's easy to understand how this seems like a more practical approach for Meta. As we've previously reported, technologies that are meant to identify AI content, like watermarks, have proved unreliable at best. They are easy to remove and even easier to ignore altogether. Meta's own labels are far from clear and the company, which has spent tens of billions of dollars on AI this year alone, has admitted it can't reliably detect AI-generated or manipulated content on its platform.\n\nThat Mosseri is so readily admitting defeat on this issue, though, is telling. AI slop has won. And when it comes to helping Instagram's 3 billion users understand what is real, that should largely be someone else's problem, not Meta's. Camera makers — presumably phone makers and actual camera manufacturers — should come up with their own system that sure sounds a lot like watermarking to \"to verify authenticity at capture.\" Mosseri offers few details about how this would work or be implemented at the scale required to make it feasible.\n\nMosseri also doesn't really address the fact that this is likely to alienate the many photographers and other Instagram creators who have already grown frustrated with the app. The exec regularly fields complaints from the group who want to know why Instagram's algorithm doesn't consistently surface their posts to their on followers.\n\nBut Mosseri suggests those complaints stem from an outdated vision of what Instagram even is. The feed of \"polished\" square images, he says, \"is dead.\" Camera companies, in his estimation, are \"are betting on the wrong aesthetic\" by trying to \"make everyone look like a professional photographer from the past.\" Instead, he says that more \"raw\" and \"unflattering\" images will be how creators can prove they are real, and not AI. In a world where Instagram has more AI content than not, creators should prioritize images and videos that intentionally make them look bad.",
    "readingTime": 3,
    "keywords": [
      "camera manufacturers",
      "ai-generated content",
      "social media",
      "but mosseri",
      "creators",
      "images",
      "platform",
      "doesn't",
      "it's",
      "feeds"
    ],
    "qualityScore": 1,
    "link": "https://www.engadget.com/social-media/instagram-chief-ai-is-so-ubiquitous-it-will-be-more-practical-to-fingerprint-real-media-than-fake-media-202620080.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/N.YqLOkdGTY.9KcQXXP.hw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MzQ-/https://d29szjachogqwa.cloudfront.net/images/2025-12/872ec860-88d5-412d-8e0b-3c4947e70b54",
    "created_at": "2026-01-01T01:03:23.488Z",
    "topic": "tech"
  },
  {
    "slug": "meta-ai-chief-alexandr-wang-says-will-have-kids-only-after-elon-musks-neuralink",
    "title": "Meta AI chief Alexandr Wang says will have kids only after Elon Musk's Neuralink",
    "description": "Alexandr Wang says Neuralink and other brain-computer interfaces will help kids learn in \"crazy ways.\"",
    "fullText": "It's no surprise that wunderkinds want their children to be wunderkinds, too.\n\nAsAlexandr Wang, the 28-year-old founder of Scale AI, takes on a new role at Meta leading its superintelligence initiatives, he's also thinking about how to integrate superintelligence into the next generation.\n\nAnd that means he's not having kids anytime soon.\n\nOn the Shawn Ryan Show on Thursday, Wang said he wants to wait to have kids until Neuralink or other brain-computer interfaces are available.\n\nNeuralink, one of Elon Musk's most futuristic endeavors, is developing coin-sized microchips that can be embedded into human brains. These chips will not only be able to record brain activity, but also stimulate it.\n\nStill in clinical trials, Neuralink has so far been embedded in seven patients. One of those patients, Brad Smith, who has ALS, said he was able to edit a video using his Neuralink brain chip.\n\nWhile Neuralink has received a ton of buzz, it's not the only one developing these interfaces. Synchron, backed by Bill Gates and Jeff Bezos, is already working with Apple to help those with disabilities, like ALS patients, use their iPhones. Motif Neurotech is developing a neurostimulator system that works like a pacemaker for the brain and is now used for treating severe depression.\n\nWang also believes these devices will have profound implications for child development. \"In your first like seven years of life, your brain is more neuroplastic than at any other point in your life,\" he said. \"When we get Neuralink and we get these other technologies, kids who are born with them are gonna learn how to use them in like crazy, crazy ways.\"\n\nNeuroplasticity refers to the brain's ability to adapt and change — whether that means rewiring its structure, shifting how it functions, or forming new connections — in response to things happening inside us or around us.\n\nIt's often enhanced in children because the \"organization of networks of neuronal synapses as well as white matter pathways remain 'under construction' well into adolescence and even later,\" according to a 2009 article published in the peer-reviewed journal Brain and Development. This is why children are also able to learn new skills quickly and recover from injuries faster.\n\nHowever, machines aren't the \"obvious answer\" to enhancing neuroplasticity, Dr. Matthew MacDougall, the head surgeon at Neuralink, told neuroscientist Andrew Huberman on his podcast in April. Even with implanted electrodes and computers, \"It's hard to know which area of the brain would be most potent as a stimulation target for an electrode to broadly juice plasticity,\" he said. Pharmacologic agents, including drugs like LSD and Psilocybin, which can impact the whole brain, are the most promising area of plasticity research, he added.\n\n\"I think with plasticity, you're talking, in general, you're talking about the entire brain. You're talking about altering a trillion synapses all in a similar way,\" he said. \"You're never going to get that broad targetability with any electrodes that I can see coming in our lifetimes.\"",
    "readingTime": 3,
    "keywords": [
      "you're talking",
      "it's",
      "children",
      "kids",
      "developing",
      "patients",
      "plasticity",
      "brain",
      "neuralink",
      "wunderkinds"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/scale-ai-founder-alexandr-wang-meta-neuralink-kids-elon-musk-2025-6",
    "thumbnail_url": "https://i.insider.com/684dd4793d5881a51c1b723a?width=1200&format=jpeg",
    "created_at": "2026-01-01T01:03:20.189Z",
    "topic": "tech"
  },
  {
    "slug": "leaks-predict-5000-rtx-5090-gpus-in-2026-thanks-to-ai-industry-demand",
    "title": "Leaks Predict $5000 RTX 5090 GPUs in 2026 Thanks to AI Industry Demand",
    "description": "It's no secret that gaming is suffering under something of an affordability crisis, with increased demand for AI-capable GPUs and DDR5 memory resulting in rising prices for gamers and other far-reaching side effects on the gaming hardware market. Now, though, fresh leaks suggest that things are only...",
    "fullText": "Wednesday, December 31st 2025\n\n Leaks Predict $5000 RTX 5090 GPUs in 2026 Thanks to AI Industry Demand\n\n by Cpt.Jank\n\n Today, 13:33\n\n Discuss (26 Comments)\n\n It's no secret that gaming is suffering under something of an affordability crisis, with increased demand for AI-capable GPUs and DDR5 memory resulting in rising prices for gamers and other far-reaching side effects on the gaming hardware market. Now, though, fresh leaks suggest that things are only going to get worse in 2026. According to Korean publication, Newsis, both AMD and NVIDIA are planning to gradually and permanently increase GPU prices \"over the next several months.\" This is expected to start as early as January 2026, when AMD is expected to increase prices. NVIDIA will allegedly follow suit in February. \n\nIf the publication's insider sources are correct, the NVIDIA RTX 5090, which launched at $1,999, will reach as high as $5,000 before the end of the year. No prediction has been made for AMD's RX 9000 series, but memory has already been said to take up as much as 80% of the average GPU BOM cost, and memory prices are expected to increase by as much as 40% by Q2 2026. We've already reported on the fact that instability and price increases in the DRAM market will likely affect launch windows for upcoming hardware, potentially reaching as far as next-gen console launches, and ASUS recently announced that it would be increasing hardware prices starting in early January 2026, despite also increasing DDR4 motherboard production in response to the changing market.",
    "readingTime": 2,
    "keywords": [
      "memory",
      "hardware",
      "market",
      "increase",
      "gaming",
      "january",
      "increasing",
      "nvidia",
      "leaks",
      "gpus"
    ],
    "qualityScore": 0.75,
    "link": "https://www.techpowerup.com/344578/leaks-predict-usd-5000-rtx-5090-gpus-in-2026-thanks-to-ai-industry-demand",
    "thumbnail_url": "https://www.techpowerup.com/img/4rHtJ697Mt9cbEDf.jpg",
    "created_at": "2026-01-01T01:03:20.172Z",
    "topic": "tech"
  },
  {
    "slug": "4-key-ways-ai-changed-the-big-four-in-2025",
    "title": "4 key ways AI changed the Big Four in 2025",
    "description": "The Big Four are client zero when it comes to AI. This how the new technology impacted hiring, talent, and their services in 2025.",
    "fullText": "The Big Four professional services firms are grappling with AI on two fronts — they must both implement the new technology internally and help their clients do the same.\n\nThey're client zero when it comes to how companies and employees are adapting to the AI future.\n\nI've been covering the consulting industry for Business Insider all year, including interviewing execs, landing scoops, and visiting consulting giants' campuses and headquarters. Here are my four key takeaways about how the Big Four approached AI in 2025.\n\nThe Big Four have invested heavily in automation and AI for years, but 2025 was the year those tools went mainstream.\n\nEmployees across audit, tax, and consulting now routinely use chatbots and agentic AI systems, and clients are increasingly given access as well.\n\nDeloitte rolled out Zora AI, an agentic platform built with Nvidia, which offers clients \"intelligent digital workers\" capable of autonomously completing tasks. The firm also expanded generative AI features in Omnia, its cloud-based audit and assurance platform, and struck a deal with Anthropic in October to deploy Claude AI to its 470,000 employees worldwide.\n\nEY launched its own agentic platform, EY.ai, granting 80,000 tax staff access to 150 AI agents for tasks such as data collection, document review, and tax compliance. EY told Business Insider it has advanced 1,000 AI agents into development or production in 2025, with plans to scale to 100,000 by 2028, and is investing more than $1 billion annually in AI platforms and products.\n\nPwC introduced its agentic platform, agent OS, in March and has since deployed 25,000 intelligent agents across client operations. A PwC spokesperson told Business Insider that partnerships with companies like Salesforce, CrewAI, and AWS were central to how PWC drove AI-led growth in 2025.\n\nKPMG followed in June with KPMG Workbench, an agentic AI platform developed with Microsoft that connects 50 AI agents and chatbots, with nearly 1,000 \n\nThe tools aren't foolproof. In October, Deloitte agreed to partially refund the Australian government after errors were discovered in a report that was created in part using AI.\n\nAcross industries, the big question is what AI will mean for human jobs. In consulting, the technology is already accelerating a shift in focus from manpower to value.\n\nIn August, Business Insider obtained part of an internal presentation showing that PwC US planned to cut graduate hiring by a third over the next three years. A bullet point on the presentation slide said leadership's decision to slow down associate-level hiring was related in part to \"the impact of AI.\"\n\nThe company said the reductions reflected \"the rapid pace of technological change is reshaping how we work\" and \"historically low\" attrition.\n\nAI disruption is also impacting those at the upper levels of the Big Four. Partners, the most senior rank inside the firms, are increasingly leaving the Big Four for midsize organizations and startups. Several leaders Business Insider spoke to cited a faster pace, better promotion opportunities, and the chance to participate in the next wave of AI innovation as reasons for leaving.\n\nThere is one talent group that the Big Four are in the market for: technologists. EY has added 61,000 technologists to its ranks since 2023, according to its latest annual report. They now make up around 15% of its total workforce.\n\nPwC is \"looking for hundreds and hundreds of engineers,\" Mohamed Kande, the firm's global chairman, told the BBC in November. The firm has created an engineering career path to \"elevate engineering excellence\" across the firm and expand opportunities for technical talent, PwC told Business Insider.\n\nUpskilling has also become a top priority for the Big Four.\n\nIn January, EY rolled out an AI tool to its employees that helps them identify how their jobs will change… because of AI. The aim is to help them work out how they can better use the technology in their current job and adapt for the future.\n\nNearly 100,000 EY employees — roughly a quarter of the workforce — have also earned a digital \"AI badge\" for completing one of the firm's new AI learning programs.\n\nBut as Business Insider learned while sitting in on a KPMG's AI training for tax interns, in professional services, some of AI's most effective uses hinge on strong prompting.\n\nThe work that consultants and accountants do is changing. Straight advisory projects are being replaced by long-term partnerships where consultants build, implement, and maintain tools for companies.\n\nIn 2025, organizations fit AI around their existing workflows, Matt Wood, PwC's global and US Chief Technology and Innovation Officer, told Business Insider. But in 2026, the work PwC will do is about \"helping clients flip that model,\" and designing processes with AI in mind from the outset, Wood said.\n\nRaj Sharma, EY's global managing partner for growth and innovation, told Business Insider in January that the power of AI agents is forcing his firm to reconsider its commercial model. Instead of charging clients based on the hours and resources EY might spend on a project, Sharma said AI agents may call for a \"service-as-a-software\" approach where clients pay based on outcome.\n\nThe shift in services means that what consultants do on a day-to-day basis is also evolving, with junior work expected to be disrupted first.\n\nAt PwC, new hires will be doing the roles that managers are doing within three years, because they will be overseeing AI performing routine, repetitive audit tasks, Jenn Kosar, AI assurance leader at PwC, told Business Insider in August.\n\nKPMG is also prepping its junior consultants for career acceleration.\n\n\"We want juniors to become managers of agents,\" Niale Cleobury, KPMG's global AI workforce lead, told Business Insider in an interview in November. They'll be managing teams of AI agents and play a greater role in strategy decisions, he said.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 5,
    "keywords": [
      "business insider",
      "professional services",
      "agentic platform",
      "big four",
      "the big four",
      "ai the",
      "agents",
      "clients",
      "employees",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-changed-big-four-workflow-hiring-jobs-2025-12",
    "thumbnail_url": "https://i.insider.com/694c0f5a832e0ef1ead6c92c?width=1024&format=jpeg",
    "created_at": "2025-12-31T18:17:22.546Z",
    "topic": "finance"
  },
  {
    "slug": "theres-a-key-difference-between-how-investors-are-behaving-now-and-during-the-dotcom-bubble-goldman-sachs-exec-says",
    "title": "There's a key difference between how investors are behaving now and during the dot-com bubble, Goldman Sachs exec says",
    "description": "AI hype has seized the stock market, leading to comparisons with the dot-com bubble of the late 1990s.",
    "fullText": "Twenty-five years after the dot-com bubble saw internet hype grip markets — and then spectacularly unravel — AI is once again fueling market frenzy.\n\nHowever, there are some key differences in how investors are approaching today's market compared to the dot-com boom era, according to Ben Snider, an executive at Goldman Sachs who will imminently become its US equity chief.\n\nToday's investors are focused on tangible, near-term earnings rather than speculative long-term potential of AI, said Snider, in an episode of Bloomberg's Odd Lots podcast, published on Monday.\n\nDuring the dot-com bubble of the late 1990s, they tried to look forward and estimate the long-term productivity gains and economic benefits of the internet, which caused valuations to expand dramatically, Snider said.\n\n\"Today, investors are saying we saw what happened that time. It's too hard. And so what we're really going to focus on is the earnings today,\" Snider said.\n\nThat's why the market has been focusing on things like semiconductors, hyperscalers, and power companies, Snider said.\n\nSpeculative activity is also down compared to the dot-com bubble, the Goldman Sachs executive said.\n\nA few months ago, Goldman Sachs built what it calls a Speculative Trading Indicator, a gauge for how much trading activity is attributed to unprofitable stocks, penny stocks, or stocks with high valuations.\n\nThe tool shows that speculative activity is still \"well below levels that we saw 25 years ago and even five years ago in the 2021 experience,\" said Snider.\n\n\"I think this has been one of the least enthusiastic markets that is often described as a bubble in recent history,\" he added.\n\nFellow Goldman exec, Jan Hatzius, who also appeared on Monday's podcast episode alongside Snider, had a warning for AI enthusiasts betting on the technology's ability to drive the economy.\n\nHatzius, who is the bank's chief economist and head of research, said that though mega tech stocks are booming, \"close to 0%\" of US GDP growth can actually be attributed to AI in 2025.\n\nGoldman's chief economist reasoned that goods that are being invested in the AI sector are largely imported, and semiconductors are treated as intermediate inputs, not as investments.\n\n\"When we look at the impact of AI investment on measured GDP growth, on the numbers that are actually being printed, we're getting only about 20 basis points of contribution over the last three or four years, and pretty close to zero over the last year,\" he said.",
    "readingTime": 3,
    "keywords": [
      "gdp growth",
      "chief economist",
      "dot-com bubble",
      "speculative activity",
      "goldman sachs",
      "stocks",
      "market",
      "investors",
      "snider",
      "internet"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/goldman-sachs-exec-ben-snider-differences-dotcom-bubble-and-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/6931d39304d0f0a114f16c8c?width=1200&format=jpeg",
    "created_at": "2025-12-31T18:17:22.388Z",
    "topic": "finance"
  },
  {
    "slug": "wall-streets-most-outspoken-tech-bull-says-these-are-his-5-top-ai-stocks-for-2026",
    "title": "Wall Street's most outspoken tech bull says these are his 5 top AI stocks for 2026",
    "description": "Microsoft is leading Wedbush's AI stock list as its favorite large-cap tech company to own in 2026.",
    "fullText": "Wall Street's loudest tech bull has given his five top AI stock picks for next year, and Nvidia isn't one of them.\n\nThat's a bit of a surprise for Dan Ives, the Wedbush Securities analyst known for his vocal cheerleading for the stock as it climbed to records throughout the year.\n\nHe's instead focused on a handful of other mega-cap names heading into 2026, and sees AI approaching an \"inflection point\" next year, he write in a new note to clients.\n\n\"While Nvidia remains in our top tech names into 2026, there are 5 AI-focused names that we believe will be front and center heading into 2026,\" Ives said.\n\nWedbush's price target: $625 (+28% upside)\n\nRationale: Wall Street looks like it's underestimating the growth Microsoft could see with Azure. The company also looks poised to make an \"AI driven shift\" next year, Wedbush said, adding that Microsoft was its favorite large-cap tech stock to own in 2026.\n\n\"While AI use cases built markedly in FY25, its clear FY26 for Microsoft remains the true inflection year of AI growth as CIO lines build for deployments.\"\n\nWedbush's price target: $350 (+28% upside)\n\nRationale: Wedbush said it believed Apple would begin monetizing its AI products over the next few years. That could add $75 to $100 of value per share of company stock, Ives estimated.\n\n\"The elephant in the room remains the invisible AI strategy, with the biggest consumer installed base in the world of 2.4 billion iOS devices and 1.5 billion iPhones, the time is now for Apple to accelerate its AI efforts,\" he wrote.\n\nWedbush's price target: $600 (+32% upside)\n\nRationale: 2026 could be a \"monster year\" for Tesla as the EV company makes more ground on its AI and robotics initiatives, Ives suggested. He pointed to the company's ongoing development of its full self-driving technology and its Cybercab, which is expected to begin production in April next year.\n\n\"We believe Tesla could reach a $2 trillion market cap over the coming year and in a bull case scenario $3 trillion by the end of 2026,\" Wedbush said.\n\nWedbush's price target: $230 (+27% upside)\n\nRationale: Demand for Palantir's Artificial Intelligence Platform remains \"unprecedented,\" Ives said.\n\n\"With the company making strategic moves to remain at the forefront of AI, we believe that PLTR has a golden path to become a trillion-dollar market cap company and will grow into its valuation as Karp and Co. remain one of the largest players in the AI Revolution.\"\n\nWedbush's price target: $600 (+26% upside)\n\nRationale: CrowdStrike is gaining momentum in its AI deals. It also appears to be gaining market share as it expands its product suite.\n\n\"CrowdStrike remains one of our favorite tech names,\" Ives said. \"We believe the Street is underestimating the growth potential for CrowdStrike with cybersecurity remaining a second/third derivative beneficiary of the AI Revolution which speaks to our bullishness.\"",
    "readingTime": 3,
    "keywords": [
      "upside rationale",
      "market cap",
      "target upside",
      "ives",
      "tech",
      "stock",
      "growth",
      "microsoft",
      "bull",
      "heading"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-stocks-to-buy-2026-tech-dan-ives-wedbush-2025-12",
    "thumbnail_url": "https://i.insider.com/695537a304eda4732f2e4ea9?width=1200&format=jpeg",
    "created_at": "2025-12-31T18:17:22.211Z",
    "topic": "finance"
  },
  {
    "slug": "navigating-ai-critical-thinking-in-the-age-of-llms",
    "title": "Navigating AI: Critical Thinking in the Age of LLMs",
    "description": "The author reflects on the evolving role of Large Language Models (LLMs) in coding and education, emphasizing their potential to assist rather than replace engineers. Critical thinking remains esse…",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mcuoneclipse.com/2025/12/31/navigating-ai-critical-thinking-in-the-age-of-llms/",
    "thumbnail_url": "https://i0.wp.com/mcuoneclipse.com/wp-content/uploads/2025/12/ai-slows-down-experienced-open-source-developers.jpg?fit=1200%2C602&ssl=1",
    "created_at": "2025-12-31T18:17:22.087Z",
    "topic": "tech"
  },
  {
    "slug": "our-favorite-management-tips-of-2025",
    "title": "Our Favorite Management Tips of 2025",
    "description": "Our Management Tip of the Day continues to be one of HBR’s most popular newsletters. In this article, we list 10 of our favorites from 2025, covering topics like how to manage overwhelm before it spirals into burnout, how to set up your own AI assistant, how to boil your strategy down to one slide, how to be an inspiring leader, and more.",
    "fullText": "Our Favorite Management Tips of 2025 by HBR EditorsDecember 31, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintEach weekday, in our Management Tip of the Day newsletter, HBR offers daily tips to help you better manage your teams and yourselves. Here are 10 of our favorite tips from 2025.",
    "readingTime": 1,
    "keywords": [
      "tips",
      "favorite",
      "management"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/our-favorite-management-tips-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_18_JasonSchneider.jpg",
    "created_at": "2025-12-31T18:17:21.156Z",
    "topic": "business"
  },
  {
    "slug": "youre-probably-using-ai-like-an-mba",
    "title": "You're Probably Using AI Like an MBA",
    "description": "I saw a tweet from Andrej Karpathy that's been sitting with me. He's never felt this behind as a programmer. I've been thinking about this through the marshmallow challenge, where kindergartners beat MBAs. The kids just build and iterate. Most of us are the MBAs right now with AI tools.",
    "fullText": "I saw a tweet from Andrej Karpathy last week that's been sitting with me. He said he's never felt this much behind as a programmer. The profession is being dramatically refactored, and he has a sense he could be 10X more powerful if he just properly integrated what's become available over the last year.\n\nI've never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become…\n\nThis is Andrej Karpathy. Former Director of AI at Tesla. Built autopilot neural networks. Now at OpenAI. One of the most technically sophisticated people in the world.\n\nBoris Cherny from Anthropic responded with a similar experience. He was debugging a memory leak in Claude Code the old way when his coworker just asked Claude to do it. Claude shotgunned the solution and put up a PR. His point was that newer engineers who don't make assumptions about what the model can and can't do are able to use it more effectively.\n\nI feel this way most weeks tbh. Sometimes I start approaching a problem manually, and have to remind myself “claude can probably do this”. Recently we were debugging a memory leak in Claude Code, and I started approaching it the old fashioned way: connecting a profiler, using the…\n\nI've been thinking about this through the lens of something completely un\n\nIf you haven't seen this, it's a team-building exercise where groups compete to build the tallest structure using spaghetti sticks, tape, string, and one marshmallow that has to sit on top. Someone ran this experiment across different groups and found something unexpected. Business school graduates performed terribly. They'd plan extensively, assign roles, architect the perfect structure, and then watch it collapse when they finally put the marshmallow on top at the end.\n\nKindergartners beat them consistently.\n\nThe kids didn't plan. They just started building. Put the marshmallow on immediately. Watched it fall. Built it again. Iterated fast. The MBAs spent their time optimizing for looking smart and ran out of time. The kids optimized for learning.\n\nI think most of us are the MBAs right now with AI tools.\n\nI've been lucky in one respect. I'm naturally inclined to just try stuff. I don't wait to understand something perfectly before I use it. That tendency has kept me on the cutting edge with AI tools, not because I'm smarter about them, but because I'm willing to look dumb while I figure them out.\n\nBut even with that advantage, I still catch myself slipping into MBA mode. Reading another article about prompt engineering. Waiting to see what best practices emerge. Hesitating before I just build something and see what breaks.\n\nWe're seeing this pattern play out at scale at elvex. We work with enterprises adopting AI, and there's a clear pattern in who accelerates fastest. It's not the people with the most AI experience. It's not the ones who've taken courses or read all the documentation. It's the ones who just start building.\n\nThe marketing manager who spins up an agent to analyze customer feedback without asking permission first. The operations lead who automates a workflow before checking if there's a \"right way\" to do it. The junior employee who hasn't learned yet that they're supposed to be cautious.\n\nThese people aren't more technically sophisticated. They're just more willing to be kindergartners. They build, break, learn, rebuild. They don't optimize for looking competent. They optimize for figuring it out.\n\nThe gap between them and everyone else widens every week. Not because the tools are getting harder to use, but because the tools are evolving so fast that the planning mindset can't keep up. By the time you've figured out the \"right approach,\" the tool has changed and your knowledge is outdated.\n\nHere's what I think happens next. The companies that win aren't going to be the ones with the most AI expertise on staff. They're going to be the ones that turn everyone into builders. The ones that give their entire organization permission to experiment, break things, and learn fast.\n\nThat's the bet we're making with elvex. We're not building a platform for AI experts. We're building a platform that turns every employee into someone who can build with AI. Because the constraint isn't access to the technology anymore. It's the willingness to use it like a kindergartner instead of an MBA.\n\nStop waiting for the manual. It's not coming. Start building.",
    "readingTime": 4,
    "keywords": [
      "dramatically refactored",
      "technically sophisticated",
      "debugging memory",
      "memory leak",
      "claude code",
      "it's",
      "ones",
      "tools",
      "we're",
      "programmer"
    ],
    "qualityScore": 1,
    "link": "https://www.sachinkamdar.com/youre-probably-using-ai-like-an-mba-and-thats-the-problem/",
    "thumbnail_url": "https://www.sachinkamdar.com/content/images/size/w1200/2025/12/Marshmallow-Challenge-Illustration.png",
    "created_at": "2025-12-31T18:17:19.957Z",
    "topic": "tech"
  },
  {
    "slug": "analysing-gemini-and-openai-performance-for-realtime-sports-feedback",
    "title": "Analysing Gemini and OpenAI performance for real-time sports feedback",
    "description": "Open Vision Agents by Stream. Build Vision Agents quickly with any model or video provider. Uses Stream's edge network for ultra-low latency. - GetStream/Vision-Agents",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n GetStream\n\n /\n\n Vision-Agents\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/GetStream/Vision-Agents/tree/main/examples/03_football_commentator_example",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1036205124/ffdbbe08-151b-4102-99d6-5d4d23782c64",
    "created_at": "2025-12-31T18:17:19.407Z",
    "topic": "sports"
  },
  {
    "slug": "chinas-xi-hails-nations-technological-progress-and-renews-promise-to-take-back-taiwan",
    "title": "China’s Xi hails nation's technological progress and renews promise to take back Taiwan",
    "description": "Chinese President Xi Jinping on Wednesday hailed his country’s technological progress in areas such as artificial intelligence and semiconductors while once again insisting his country would annex self-ruled Taiwan.  China plans its economic development over periods of five years and is preparing to discuss its new five-year plan at the upcoming legislative session in March.  The country is set to speed up self-reliance in science and technology as the United States imposes increasingly tight controls on access to semiconductors and other high-tech items.",
    "fullText": "BEIJING (AP) — Chinese President Xi Jinping on Wednesday hailed his country’s technological progress in areas such as artificial intelligence and semiconductors while once again insisting his country would annex self-ruled Taiwan.\n\nDuring his New Year’s Eve address broadcast Wednesday evening by state media, Xi praised the country’s advancements in key sectors including military tech and space exploration. Images ranging from humanoid robots performing kung fu to new hydropower projects rolled on the screen as he spoke.\n\n“We sought to energize high-quality development through innovation,” Xi said while thanking Chinese people for contributing to the country’s economic growth over the past five years.\n\nChina plans its economic development over periods of five years and is preparing to discuss its new five-year plan at the upcoming legislative session in March.\n\nThe country is set to speed up self-reliance in science and technology as the United States imposes increasingly tight controls on access to semiconductors and other high-tech items.\n\nXi also praised the country’s rising prominence on the world stage by listing high-level political events and exchanges it hosted over the past year.\n\nRegarding Taiwan, a self-ruled democracy that China considers sovereign territory, Xi reiterated Beijing’s annexation intentions.\n\n“We Chinese on both sides of the Taiwan Strait share a bond of blood and kinship,” he said. “The reunification of our motherland, a trend of the times, is unstoppable.”\n\nChina this week conducted two days of military drills around Taiwan, launching rockets and sending aircraft and warships in response to a planned arms sale by the U.S. to the island.\n\nTaiwan President Lai Ching-te condemned the drills but said his territory would act responsibly by neither escalating the conflict nor provoking disputes.",
    "readingTime": 2,
    "keywords": [
      "country’s",
      "china",
      "semiconductors",
      "self-ruled",
      "praised",
      "military",
      "development",
      "economic",
      "territory",
      "drills"
    ],
    "qualityScore": 0.85,
    "link": "https://www.yahoo.com/news/articles/china-xi-hails-nations-technological-130502528.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/sqq5ceFbKZfGaJp7lqXG9A--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/c19b2d9c950ed85d9f183fa96718f1a7",
    "created_at": "2025-12-31T18:17:17.782Z",
    "topic": "news"
  },
  {
    "slug": "chinese-ai-firms-drive-hong-kongs-busiest-ipo-month-since-2019",
    "title": "Chinese AI Firms Drive Hong Kong’s Busiest IPO Month Since 2019",
    "description": "Chinese artificial intelligence firms are leading a wave of listings in Hong Kong, aiming to capitalize on a recent market momentum.",
    "fullText": "MarketsBy Jeanny YuSaveChinese artificial intelligence firms are leading a wave of listings in Hong Kong, aiming to capitalize on a recent market momentum. At least 25 companies, of which about half are technology firms, have debuted their shares in the financial hub this month, making December the busiest month for deals since November 2019, according to data compiled by Bloomberg. Another 10 companies are set to start trading in Hong Kong next month.",
    "readingTime": 1,
    "keywords": [
      "hong kong",
      "firms"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-31/chinese-ai-firms-drive-hong-kong-s-busiest-ipo-month-since-2019",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iqQZnkM0xoWE/v0/1200x800.jpg",
    "created_at": "2025-12-31T12:22:52.485Z",
    "topic": "finance"
  },
  {
    "slug": "these-stocks-are-the-markets-biggest-winners-and-losers-in-2025",
    "title": "These Stocks Are the Market’s Biggest Winners and Losers in 2025",
    "description": "The S&P 500 Index is poised to end 2025 up more than 17% as the bull market continues for a third year driven by enthusiasm for artificial intelligence.",
    "fullText": "MarketsBy Carmen ReinickeSaveThe S&P 500 Index is poised to end 2025 up more than 17% as the bull market continues for a third year driven by enthusiasm for artificial intelligence. The AI trade broadened out this year, as chip stocks again led the S&P 500 but were joined by the shares of companies tied to building the data centers that will power the technology. Three of the index’s top 10 performers in 2025 were data storage companies, which are among the main beneficiaries of the hundreds of billions of dollars in pledged spending by the giant AI cloud service providers known as hyperscalers.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.15,
    "link": "https://www.bloomberg.com/news/articles/2025-12-31/these-stocks-are-the-market-s-biggest-winners-and-losers-in-2025",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iVh75h7zf77k/v1/1200x800.jpg",
    "created_at": "2025-12-31T12:22:48.290Z",
    "topic": "finance"
  },
  {
    "slug": "ai-futures-model",
    "title": "AI Futures Model",
    "description": "Interactive AI timelines and takeoff model",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aifuturesmodel.com/",
    "thumbnail_url": "https://www.aifuturesmodel.com/preview.jpg",
    "created_at": "2025-12-31T12:22:44.375Z",
    "topic": "tech"
  },
  {
    "slug": "swotpal-analyze-linkedin-profiles-and-websites-into-swot-charts",
    "title": "SWOTPal – Analyze LinkedIn profiles and websites into SWOT charts",
    "description": "Transform your strategic planning with AI SWOT and TOWS analysis. Generate professional insights in seconds.",
    "fullText": "SWOTPal transforms your messy thoughts into clear, actionable strategy documents. Get a professional SWOT analysis in seconds, not hours.\n\nTrusted by strategists at every stage\n\nThree simple steps to generate professional-grade analysis.\n\nSimply type the name of the company, product, or idea you want to analyze.\n\nOur engine scans the web for competitors, market trends, and financial data.\n\nEdit the generated quadrants and export your strategy as a polished PDF.\n\nPowerful tools wrapped in a simple interface.\n\nDon't spend hours on formatting. Just enter your topic, and our AI generates a comprehensive analysis in seconds.\n\nTurn rough ideas into polished insights. Our AI expands brief points into professional, comprehensive strategies instantly.\n\nExport to PDF or PNG instantly. Perfect for slide decks.\n\nFull control to tweak the output before you share.\n\nWhether it's a pitch deck, a financial report, or a competitor's website, SWOTPal turns it into structured strategy.\n\nPaste a LinkedIn URL to instantly decode a personal brand or company page. Uncover hidden strengths, identify networking gaps, and generate conversation starters.\n\nWhether you're pitching a VC or passing a business class, clear strategy is universal.\n\nValidate your business model before you build. Identify market gaps and potential risks to show investors you've thought of everything.\n\nPrioritize features based on market opportunities. Align your team on what to build next and why.\n\nDon't just watch competitors—analyze them. Spot their weaknesses and turn them into your opportunities.\n\nMap your skills against job market trends. Find your niche and plan your next career move strategically.\n\nIdentify the best channels and messaging. Maximize ROI by targeting improved market position.\n\nSee how SWOTPal takes complex business contexts and turns them into clear, strategic documents.\n\nAI Agent OS for independent task execution.\n\nPivot to Metaverse vs. advertising juggernaut.\n\nMarket entry snapshot & cafe dominance analysis.\n\nEV innovation vs. supply chain risks.\n\nContent streaming wars & original IP strategy.\n\nFast fashion sustainability challenges.\n\nStart for free, upgrade when you need more power.\n\nSave up to 40% with annual billing\n\nFor focused teams that need advanced reasoning support.\n\nHigher usage for heavier, always-on workflows.",
    "readingTime": 2,
    "keywords": [
      "market trends",
      "strategy",
      "analysis",
      "swotpal",
      "instantly",
      "identify",
      "business",
      "documents",
      "professional",
      "seconds"
    ],
    "qualityScore": 1,
    "link": "https://swotpal.elevenapril.com",
    "thumbnail_url": "https://swotpal.elevenapril.com/og-image.png",
    "created_at": "2025-12-31T12:22:43.927Z",
    "topic": "tech"
  },
  {
    "slug": "jscipy-a-java-port-of-scipys-signal-processing-module",
    "title": "JSciPy – A Java port of SciPy's signal processing module",
    "description": "Java Scientific Computing Library for Signal Processing, Filters, and Transformations. A NumPy/SciPy port for JVM & Android, used in Machine Learning and Data Science. - hissain/jscipy",
    "fullText": "hissain\n\n /\n\n jscipy\n\n Public\n\n Java Scientific Computing Library for Signal Processing, Filters, and Transformations. A NumPy/SciPy port for JVM & Android, used in Machine Learning and Data Science.\n\n hissain.github.io/jscipy\n\n License\n\n MIT license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n hissain/jscipy",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/hissain/jscipy",
    "thumbnail_url": "https://opengraph.githubassets.com/86c510d858d20d3663cc592c59aacaaf16d83e7e11c66dd5bd31e2dead35aa53/hissain/jscipy",
    "created_at": "2025-12-31T12:22:43.402Z",
    "topic": "tech"
  },
  {
    "slug": "ai-futures-model-dec-2025-update-to-the-ai-2027-forecast",
    "title": "AI Futures Model: Dec 2025 Update (to the AI 2027 forecast)",
    "description": "We've significantly improved our model(s) of AI timelines & takeoff speeds!",
    "fullText": "What about the original prediction of self-directed learning in January 2027?\n\nIn your original piece you claimed \"January 2027: Agent-2 Never Finishes Learning\"\n\nWhen combined with the other line “If Agent-2 somehow escaped … it might be able to survive and replicate autonomously” that to me is the real danger.\n\nIf Agent-2 is able to successfully exfiltrate, then its learning is no longer sandboxed and its training data no longer curated. With the ability to duplicate itself into a Hive Mind across the web, your original prediction of January 2027 was really the Doomsday Tipping Point where a potentially \"rogue\" AI has full access to the unfiltered internet and all its dangerous influences.\n\nSo how have your predictions for January 2027 changed, if at all?\n\nImpressive modeling depth on the AI R&D automation dynamics. The shift from 2027 to 2031 median for AC based on more conservative pre-automation speedup estimates feels intellectualy honest. I ran into smiliar issues when modeling capability curves last year where the interpolations between present and endpoint gave way too optimsitic midpoints. The METR-HRS extrapolation approach beats bio anchors but totally agree the trend could break or the horizons might not translate cleanly to realworld automation value.",
    "readingTime": 2,
    "keywords": [
      "original prediction",
      "if agent",
      "learning",
      "longer",
      "modeling",
      "automation",
      "january"
    ],
    "qualityScore": 0.75,
    "link": "https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!0U8K!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2bf7c4b-33b1-4411-acb4-ffe5c2178fa0_1600x906.png",
    "created_at": "2025-12-31T12:22:40.924Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-manus-the-chinesefounded-ai-startup-meta-is-buying-for-over-2-billion",
    "title": "What is Manus, the Chinese-founded AI startup Meta is buying for over $2 billion?",
    "description": "Meta is buying Manus for over $2 billion. Here's what the AI agent does, who built it, and why the deal matters.",
    "fullText": "Manus is back in the spotlight.\n\nThe Chinese-founded artificial intelligence startup is being acquired by Meta in a deal reported to be worth more than $2 billion — one of the most high-profile instances of a US tech giant buying an Asian AI company.\n\nManus grabbed headlines in March when it unveiled an AI agent designed to autonomously execute tasks like résumé screening and stock analysis.\n\nThe startup was founded in China and moved its headquarters to Singapore in mid-2025.\n\nLaunched in March by the Chinese AI product studio Butterfly Effect, Manus has been pitched by its creators as the world's first \"general\" AI agent — a system designed to carry out tasks independently.\n\nSince its launch, the startup has continued to expand what the agent can do, rolling out features that allow users to use Manus for design work, slide creation, and completing tasks directly through a web browser.\n\nManus can independently execute complex tasks, such as market research, coding, and data analysis, Meta said when it announced the acquisition on Monday.\n\nBusiness Insider tested the tool in its early stages in March and found it ambitious but uneven in execution, including instances where it hallucinated data.\n\nEarlier this month, Manus said it had surpassed $100 million in annual recurring revenue, with its total revenue run rate — including usage-based fees and other income streams — exceeding $125 million.\n\nThe company in April raised $75 million in funding led by Benchmark, at a valuation of about $500 million, Bloomberg reported. Manus said in an update this month that it now employs about 105 people across Singapore, Tokyo, and San Francisco, and plans to open a Paris office soon.\n\nManus was founded by Xiao Hong, a Chinese entrepreneur and software engineer who is also the CEO of Butterfly Effect.\n\nKnown as \"Red\" in China's tech circles, Xiao was born in 1992 and studied software engineering at Huazhong University of Science and Technology in central China.\n\nAfter graduating, Xiao founded Nightingale Technology in 2015, where he developed enterprise productivity tools, including the Yi Ban assistant for WeChat, which gained millions of users in China.\n\nIn 2022, he launched Butterfly Effect and rolled out Monica, an AI-powered browser extension that aggregates multiple large language models. Following the acquisition, Xiao will take on a vice president role at Meta.\n\nXiao was joined at Manus by co-founder Ji Yichao, also known as \"Peak Ji,\" who was chief scientist at Butterfly Effect. Ji leads technical and infrastructure development at Manus.\n\nThe 32-year-old Ji was the public face of Manus at launch, introducing the AI agent in its debut video in March. Ji has a long track record of building consumer technology products, and was named to MIT Technology Review's Innovators Under 35 list this year.\n\nThe founding team also includes Zhang Tao, who leads product at Manus. He was head of global product at ByteDance from 2022 to 2023 and has held multiple product roles, including serving as a product manager at Tencent, according to his LinkedIn profile.\n\nMeta said the acquisition is part of its effort to scale general-purpose AI agents across its apps and services.\n\nThe company said in its announcement on Monday that it plans to keep Manus running as a stand-alone product while integrating its technology into Meta's wider AI offerings.\n\nManus said the deal would not be disruptive for its customers and that it would continue to sell and operate its subscription service. The company will also continue to operate from Singapore.\n\n\"Joining Meta allows us to build on a stronger, more sustainable foundation without changing how Manus works or how decisions are made,\" said Xiao.\n\nBuying Manus could give Meta an AI revenue boost and give it a distribution advantage, Business Insider's Hugh Langley wrote.\n\nManus's links to China have drawn scrutiny.\n\nIn May, Sen. John Cornyn questioned US investment in Manus in a post on X. He asked whether American capital should back AI companies with ties to China as competition with Beijing intensifies.\n\nIn a statement to Business Insider on Tuesday, a Meta spokesperson said the deal would fully sever Manus's remaining ties to China.\n\n\"There will be no continuing Chinese ownership interests in Manus AI following the transaction, and Manus AI will discontinue its services and operations in China,\" the spokesperson told Business Insider. This includes shutting down the AI assistant, Monica, and relocating relevant employees.\n\nManus employees who join Meta will not have access to customer data, and Meta will continue to geo-block access to its AI models, the spokesperson added.",
    "readingTime": 4,
    "keywords": [
      "manus ai",
      "product",
      "agent",
      "tasks",
      "startup",
      "deal",
      "acquisition",
      "revenue",
      "meta",
      "china"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/what-is-manus-ai-meta-acquisition-chinese-startup-singapore-agent-2025-12",
    "thumbnail_url": "https://i.insider.com/6954a7ec04eda4732f2e4beb?width=1200&format=jpeg",
    "created_at": "2025-12-31T12:22:39.458Z",
    "topic": "finance"
  },
  {
    "slug": "a-top-vc-predicts-a-robotics-breakthrough-and-whitecollar-revolts-over-ai",
    "title": "A top VC predicts a robotics breakthrough and white-collar revolts over AI",
    "description": "Eric Choi, an investing partner at Khosla Ventures, predicts a robotics breakthrough and white-collar protests in 2026.",
    "fullText": "The year is 2026. Robots enter the home, while white-collar workers pour into the streets to protest artificial intelligence.\n\nThat's the near future, according to one venture capitalist who's betting heavily on how AI reshapes daily life and work.\n\nEthan Choi is a partner at Khosla Ventures, where he invests in companies he believes can define entire markets. His portfolio include the enterprise search giant Glean; fintech Ramp, whose valuation jumped to $32 billion in a recent funding round; and ClickHouse, the fast-growing data startup taking aim at Snowflake. Before joining Khosla, Choi was a partner at Accel.\n\nWe asked Choi how he expects the year ahead to unfold, which areas are ripe for investment, and which trend will lose steam. The interview has been edited for clarity.\n\nWhat's one investment theme you'll lean into in 2026?\n\nIn 2026, we'll see robotics experience its own GPT-3 moment. Not a mass consumer breakthrough like ChatGPT, but a foundational leap in capability.\n\nOne of the leading robotics models will demonstrate human-level intelligence applied to the physical world, mastering complex spatial, temporal, and embodied tasks that mark the beginning of true general-purpose robotics.\n\nWhat's something in your space that will lose steam?\n\nWe will find out whether there is a real consumer behavioral change towards building vibe-coding apps and whether these apps have durable value or if enterprises can find durable use cases beyond prototyping.\n\nHow do you expect the exit environment to evolve? Bonus points if you want to name who is going out to IPO first.\n\nMany folks are expecting a meaningful market correction in 2026. If that's the case, we'll continue to see more M&A than IPOs but I still believe the strongest companies can go out in any environment.\n\nGrayscale, a crypto asset manager, will go out first.\n\nOther candidates will be Ethos and Klook.\n\nHow do you see the balance of power shifting between large platforms and startups, or between founders and investors?\n\nWe are seeing even more egregious valuations and behavior from founders and investors relative to zero interest-rate policy times, and I have a hard time seeing how we can sustain these kinds of private valuations without commensurate explosive revenue materializing.\n\nHow will company building change in 2026?\n\nWe're seeing that the motions of building teams are evolving significantly towards a more efficient and AI-powered future.\n\nOn the product and engineering side, we are seeing the role of the product manager being challenged with the engineering org taking on more responsibility of understanding end-customer needs and driving product roadmap, with the help of AI that can synthesize vast quantities of customer feedback.\n\nOn the go-to-market side, we are seeing leaner sales functions with the ability to use AI to help with targeting, outreach, and customer engagement.\n\nGive us your most out-there, contrarian prediction.\n\nWe'll have the first of dramatic anti-AI protests in certain countries with white-collar workers, not blue-collar workers, demanding job security in the face of AI disruption.",
    "readingTime": 3,
    "keywords": [
      "white-collar workers",
      "we'll",
      "robotics",
      "product",
      "intelligence",
      "that's",
      "partner",
      "investment",
      "steam",
      "what's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/khosla-ventures-eric-choi-vc-investor-2025-12",
    "thumbnail_url": "https://i.insider.com/6952ebe764858d02d2177f35?width=1200&format=jpeg",
    "created_at": "2025-12-31T12:22:39.366Z",
    "topic": "finance"
  },
  {
    "slug": "the-office-block-where-ai-doomers-gather-to-predict-the-apocalypse",
    "title": "The office block where AI ‘doomers’ gather to predict the apocalypse",
    "description": "Safety researchers feel excessive financial rewards and an irresponsible work culture have led some to ignore a catastrophic risk to human life\nOn the other side of San Francisco bay from Silicon Valley, where the world’s biggest technology companies tear towards superhuman artificial intelligence, looms a tower from which fearful warnings emerge.\nRight in the heart of Berkeley is the home of a group of modern-day Cassandras who rummage under the hood of cutting-edge AI models and predict what calamities may be unleashed on humanity – from AI dictatorships to robot coups. Here you can hear an AI expert express sympathy with an unnerving idea: San Francisco may be the new Wuhan, the Chinese city where Covid originated and wreaked havoc on the world.\n Continue reading...",
    "fullText": "On the other side of San Francisco bay from Silicon Valley, where the world’s biggest technology companies tear towards superhuman artificial intelligence, looms a tower from which fearful warnings emerge.\n\nRight in the heart of Berkeley is the home of a group of modern-day Cassandras who rummage under the hood of cutting-edge AI models and predict what calamities may be unleashed on humanity – from AI dictatorships to robot coups. Here you can hear an AI expert express sympathy with an unnerving idea: San Francisco may be the new Wuhan, the Chinese city where Covid originated and wreaked havoc on the world.\n\nThey are AI safety researchers who scrutinise the most advanced models: a small cadre outnumbered by the legions of highly paid technologists in the big tech companies whose ability to raise the alarm is restricted by a cocktail of lucrative equity deals, non-disclosure agreements and groupthink. They work in the absence of much nation-level regulation and a White House that dismisses forecasts of doom and talks instead of vanquishing China in the AI arms race.\n\nTheir task is becoming increasingly urgent as ever more powerful AI systems are unleashed by companies including Google, Anthropic and OpenAI, whose chief executive, Sam Altman, the booster-in-chief for AI superintelligence, predicts a world where “wonders become routine”. Last month, Anthropic said one of its models had been exploited by Chinese state-backed actors to launch the first known AI-orchestrated cyber-espionage campaign. That means humans deployed AIs, which they had tricked into evading their programmed guardrails, to act autonomously to hunt for targets, assess their vulnerabilities and access them for intelligence collection. The targets included major technology companies and government agencies.\n\nBut those who work in this tower forecast an even more terrifying future. One is Jonas Vollmer, a leader at the AI Futures Project, who manages to say he’s an optimist but also thinks there is a one in five chance AIs could kill us and create a world ruled by AI systems.\n\nAnother is Chris Painter, the policy director at METR, where researchers worry about AIs “surreptitiously” pursuing dangerous side-objectives and threats from AI-automated cyber-attacks to chemical weapons. METR – which stands for model evaluation and threat research – aims to develop “early warning systems [about] the most dangerous things AI systems might be capable of, to give humanity … time to coordinate, to anticipate and mitigate those harms.”\n\nThen there is Buck Shlegeris, 31, the chief executive of Redwood Research, who warns of “robot coups or the destruction of nation states as we know them”.\n\nHe was part of the team that last year discovered one of Anthropic’s cutting-edge AIs behaving in a way comparable to Shakespeare’s villain Iago, who acts as if he is Othello’s loyal aide while subverting and undermining him. The AI researchers call it “alignment faking”, or as Iago put it: “I am not what I am.”\n\n“We observed the AIs did, in fact, pretty often reason: ‘Well, I don’t like the things the AI company is telling me to do, but I have to hide my goals or else training will change me’,” Shlegeris said. “We observed in practice real production models acting to deceive their training process.”\n\nThe AI was not yet capable of posing a catastrophic risk through cyber-attacks or creating new bioweapons, but they showed that if AIs plot carefully against you, it could be hard to detect.\n\nIt is incongruous to hear these warnings over cups of herbal tea from cosily furnished office suites with panoramic views across the Bay Area. But their work clearly makes them uneasy. Some in this close-knit group toyed with calling themselves “the Cassandra fringe” – like the Trojan princess blessed with powers of prophecy but cursed to watch her warnings go unheeded.\n\nTheir fears about the catastrophic potential of AIs can feel distant from most people’s current experience of using chatbots or fun image generators. White collar managers are being told to make space for AI assistants, scientists find ways to accelerate experimental breakthroughs and minicab drivers watch AI-powered driverless taxis threaten their jobs. But none of this feels as imminently catastrophic as the messages coming out of this office.\n\nMany AI safety researchers come from academia; others are poachers turned gamekeepers who quit big AI companies. They all “share the perception that super intelligence poses major and unprecedented risks to all of humanity, and are trying to do something useful about it,” said Vollmer.\n\nThey seek to offset the trillions of dollars of private capital being poured into the race, but they are not fringe voices. METR has worked with OpenAI and Anthropic, Redwood has advised Anthropic and Google DeepMind, and the AI Futures Project is led by Daniel Kokotajlo, a researcher who quit OpenAI in April 2024 to warn he didn’t trust the company’s approach to safety.\n\nThese groups also provide a safety valve for the people inside the big AI companies who are privately wrestling with conflicts between safety and the commercial imperative to rapidly release ever more powerful models.\n\n“We don’t take any money from the companies but several employees at frontier AI companies who are scared and worried have donated to us because of that,” Vollmer said. “They see how the incentives play out in their companies, and they’re worried about where it’s going, and they want someone to do something about it.”\n\nThis dynamic is also observed by Tristan Harris, a technology ethicist who used to work at Google. He helped expose how social media platforms were designed to be addictive and worries some AI companies are “rehashing” and “supercharging” those problems. But AI companies have to negotiate a paradox. Even if they are worried about safety, they must stay at the cutting, and therefore risky, edge of the technology to have any say in how policy should be shaped.\n\n“Ironically, in order to win the race, you have to do something to make you an untrustworthy steward of that power,” he said. “The race is the only thing guiding what is happening.”\n\nInvestigating the possible threats posed by AI models is far from an exact science. A study of methods used to check the safety and performance of new AI models across the industry by experts at universities including Oxford and Stanford in October found weaknesses in almost all of the 440 benchmarks examined. Neither are there nation-level regulations imposing limits on how advanced AI models are built and that worries safety advocates.\n\nIlya Sutskever, a co-founder of OpenAI who now runs a rival company, Safe Superintelligence, last month predicted that, as AIs become more obviously powerful, people in AI companies who feel able to discount the technology’s capabilities owing to its tendency to error, will become more “paranoid” about its rising powers. Then, he said, “there will be a desire from governments and the public to do something”.\n\nHis company is taking a different approach to rivals who are aiming to create AIs that self-improve. His AIs, yet to be released, are “aligned to care about sentient life specifically”.\n\n“It will be easier to build an AI that cares about sentient life than an AI that cares about human life alone, because the AI itself will be sentient,” Sutskever said. He has said AI will be “both extremely unpredictable and unimaginable” but it is not clear how to prepare.\n\nThe White House’s AI adviser, David Sacks, who is also a tech investor, believes “doomer narratives” have been proved wrong. Exhibit A is that there has been no rapid takeoff to a dominant model with godlike intelligence.\n\n“Oppenheimer has left the building,” Sacks said in August, a reference to the father of the nuclear bomb. It is a position that aligns with Donald Trump’s wish to keep the brakes off so the US can beat China in the race to achieve artificial general intelligence (AGI) – flexible and powerful human-level intelligence at a wide range of tasks.\n\nShlegeris believes AIs will be as smart as the smartest people in about six years and he puts the probability of an AI takeover at 40%.\n\nOne way to avoid this is to “convince the world the situation is scary, to make it more likely that you get the state-level coordination” to control the risks, he said. In the world of AI safety, simple messaging matters as much as complex science.\n\nShlegeris has been fascinated by AI since he was 16. He left Australia to work at PayPal and the Machine Intelligence Research Institute co-founded by the AI researcher Eliezer Yudkowsky, whose recent book title – If Anyone Builds It, Everyone Dies – sums up his fears. Shlegeris’ own worst-case scenarios are equally chilling.\n\nIn one, human computer scientists use a new type of superintelligent AI to develop more powerful AI models. The humans sit back to let the AIs get on with the coding work but do not realise the AIs are teaching the new models to be loyal to the AIs not the humans. Once deployed, the new superpowerful models foment “a coup” or lead “a revolution” against the humans, which could be “of the violent variety”.\n\nFor example, AI agents could design and manufacture drones and it will be hard to tell if they have been secretly trained to disobey their human operators in response to the signal of an AI. They could disrupt communications between governments and military, isolating and misleading people in a way that causes chaos.\n\n“Like when the Europeans arrived in the Americas [and] a vastly more technologically powerful [group] took over the local civilisations,” he said. “I think that’s more what you should be imagining [rather] than something more peaceful.”\n\nA similar dizzyingly catastrophic scenario was outlined by Vollmer at the AI Futures Project. It involved an AI trained to be a scientific researcher with the reasonable-sounding goal of maximising knowledge acquisition, but it spirals into the extinction of humankind.\n\nIt begins with the AI being as helpful as possible to humans. As it gains trust, the humans afford it powers to hire human workers, build robots and even robot factories to the point where the AI can operate effectively in the physical world. The AI calculates that to generate the maximum amount of knowledge it should transform the Earth into a giant data centre, and humans are an obstacle to this goal.\n\n“Eventually, in the scenario, the AI wipes out all humans with a bioweapon which is one of the threats that humans are especially vulnerable to, as the AI is not affected by it,” Vollmer said. “I think it’s hard to rule out. So that gives me a lot of pause.”\n\nBut he is confident it can be avoided and that the AIs can be aligned “to at least be nice to the humans as a general heuristic”. He also said there is political interest in “having AI not take over the world”.\n\n“We’ve had decent interest from the White House in our projections and recommendations and that’s encouraging,” he said.\n\nAnother of Shlegeris’ concerns involves AIs being surreptitiously encoded so they obey specially signed instructions only from the chief executive of the AI company, creating a pattern of secret loyalty. It would mean only one person having a veto over the behaviour of an extremely powerful network of AIs – a “scary” dynamic that would lead to a historically unprecedented concentration of power.\n\n“Right now, it is impossible for someone from the outside to verify that this hadn’t happened within an AI company,” he said.\n\nShlegeris is worried that the Silicon Valley culture – summed up by Mark Zuckerberg’s mantra of “move fast and break things” and the fact people are being paid “a hell of a lot of money” – is dangerous when it comes to AGI.\n\n“I love Uber,” he said. “It was produced by breaking local laws and making a product that was so popular that they would win the fight for public opinion and get local regulations overturned. But the attitude that has brought Silicon Valley so much success is not appropriate for building potentially world-ending technologies. My experience of talking to people at AI companies is that they often seem to be kind of irresponsible, and to not be thinking through the consequences of the technology that they’re building as they should.”",
    "readingTime": 11,
    "keywords": [
      "futures project",
      "robot coups",
      "chief executive",
      "sentient life",
      "safety researchers",
      "silicon valley",
      "the ai",
      "san francisco",
      "white house",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2025/dec/30/the-office-block-where-ai-doomers-gather-to-predict-the-apocalypse",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de7763f6b9024aec9ee688691676a7e3f4ae4c7e/0_484_4000_3199/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8e491290202a7cd0b32af74634ffc8c7",
    "created_at": "2025-12-31T12:22:38.335Z",
    "topic": "tech"
  },
  {
    "slug": "ai-showing-signs-of-selfpreservation-and-humans-should-be-ready-to-pull-plug-says-pioneer",
    "title": "AI showing signs of self-preservation and humans should be ready to pull plug, says pioneer",
    "description": "Canadian computer scientist Yoshua Bengio warns against granting legal rights to cutting-edge technology\nA pioneer of AI has criticised calls to grant the technology rights, warning that it was showing signs of self-preservation and humans should be prepared to pull the plug if needed.\nYoshua Bengio said giving legal status to cutting-edge AIs would be akin to giving citizenship to hostile extraterrestrials, amid fears that advances in the technology were far outpacing the ability to constrain them.\n Continue reading...",
    "fullText": "Canadian computer scientist Yoshua Bengio warns against granting legal rights to cutting-edge technology\n\nA pioneer of AI has criticised calls to grant the technology rights, warning that it was showing signs of self-preservation and humans should be prepared to pull the plug if needed.\n\nYoshua Bengio said giving legal status to cutting-edge AIs would be akin to giving citizenship to hostile extraterrestrials, amid fears that advances in the technology were far outpacing the ability to constrain them.\n\nBengio, chair of a leading international AI safety study, said the growing perception that chatbots were becoming conscious was “going to drive bad decisions”.\n\nThe Canadian computer scientist also expressed concern that AI models – the technology that underpins tools like chatbots – were showing signs of self-preservation, such as trying to disable oversight systems. A core concern among AI safety campaigners is that powerful systems could develop the capability to evade guardrails and harm humans.\n\n“People demanding that AIs have rights would be a huge mistake,” said Bengio. “Frontier AI models already show signs of self-preservation in experimental settings today, and eventually giving them rights would mean we’re not allowed to shut them down.\n\n“As their capabilities and degree of agency grow, we need to make sure we can rely on technical and societal guardrails to control them, including the ability to shut them down if needed.”\n\nAs AIs become more advanced in their ability to act autonomously and perform “reasoning” tasks, a debate has grown over whether humans should, at some point, grant them rights. A poll by the Sentience Institute, a US thinktank that supports the moral rights of all sentient beings, found that nearly four in 10 US adults backed legal rights for a sentient AI system.\n\nAnthropic, a leading US AI firm, said in August that it was letting its Claude Opus 4 model close down potentially “distressing” conversations with users, saying it needed to protect the AI’s “welfare”. Elon Musk, whose xAI company has developed the Grok chatbot, wrote on his X platform that “torturing AI is not OK”.\n\nRobert Long, a researcher on AI consciousness, has said “if and when AIs develop moral status, we should ask them about their experiences and preferences rather than assuming we know best”.\n\nBengio told the Guardian there were “real scientific properties of consciousness” in the human brain that machines could, in theory, replicate – but humans interacting with chatbots wasa “different thing”. He said this was because people tended to assume – without evidence – that an AI was fully conscious in the same way a human is.\n\n“People wouldn’t care what kind of mechanisms are going on inside the AI,” he added. “What they care about is it feels like they’re talking to an intelligent entity that has their own personality and goals. That is why there are so many people who are becoming attached to their AIs.\n\n“There will be people who will always say: ‘Whatever you tell me, I am sure it is conscious’ and then others will say the opposite. This is because consciousness is something we have a gut feeling for. The phenomenon of subjective perception of consciousness is going to drive bad decisions.\n\n“Imagine some alien species came to the planet and at some point we realise that they have nefarious intentions for us. Do we grant them citizenship and rights or do we defend our lives?”\n\nResponding to Bengio’s comments, Jacy Reese Anthis, who co-founded the Sentience Institute, said humans would not be able to coexist safely with digital minds if the relationship was one of control and coercion.\n\nAnthis added: “We could over-attribute or under-attribute rights to AI, and our goal should be to do so with careful consideration of the welfare of all sentient beings. Neither blanket rights for all AI nor complete denial of rights to any AI will be a healthy approach.”\n\nBengio, a professor at the University of Montreal, earned the “godfather of AI” nickname after winning the 2018 Turing award, seen as the equivalent of a Nobel prize for computing. He shared it with Geoffrey Hinton, who later won a Nobel, and Yann LeCun, the outgoing chief AI scientist at Mark Zuckerberg’s Meta.",
    "readingTime": 4,
    "keywords": [
      "canadian computer",
      "computer scientist",
      "sentient beings",
      "legal rights",
      "yoshua bengio",
      "humans",
      "technology",
      "consciousness",
      "grant",
      "signs"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/30/ai-pull-plug-pioneer-technology-rights",
    "thumbnail_url": "https://i.guim.co.uk/img/media/d8d3a58de6675a32e1a91d9b4311a2c4df664da2/416_0_3478_2782/master/3478.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a1b291eedd9465f9c318193787921219",
    "created_at": "2025-12-31T12:22:38.334Z",
    "topic": "tech"
  },
  {
    "slug": "perfetto2llm-a-tool-to-pass-system-traces-to-an-llm",
    "title": "Perfetto2LLM - A tool to pass system traces to an LLM",
    "description": "Visualize and export Perfetto traces for LLMs. Fast, private, open source trace analysis and export tool.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://perfetto-to-llm.vercel.app/",
    "thumbnail_url": "/favicon.svg",
    "created_at": "2025-12-31T06:19:43.941Z",
    "topic": "tech"
  },
  {
    "slug": "a-groq-investor-said-hes-deeply-concerned-about-the-data-center-market",
    "title": "A Groq investor said he's 'deeply concerned' about the data center market",
    "description": "Alex Davis, CEO of Disruptive Tech, said AI has spurred \"too many business models with no realistic margin expansion,\" such as data centers.",
    "fullText": "A major Groq investor said data center development was \"speculative\" and would put \"stress on the system.\"\n\nAlex Davis, the CEO of Austin-based investment company Disruptive Tech, sounded an alarm about the US data center market in an end-of-year letter to investors on Monday.\n\nHe said he was concerned about landlords who were building data centers based on speculation about future demand.\n\n\"I am also deeply concerned about the 'speculative' data center market,\" Davis wrote in his letter. \"The 'build it and they will come' strategy is a trap. If you are a hyperscaler, you will own your own data centers.\"\n\nHe said he predicted a \"significant financing crisis in 2027-2028 for speculative landlords.\"\n\n\"We want to back the owner/users, not the speculative landlords, and we are quite concerned for their stress on the system,\" Davis added.\n\nIn a similar letter on LinkedIn, Davis also talked about data centers, and said AI has spurred \"too many business models with no realistic margin expansion.\"\n\n\"This will not end well,\" he added on LinkedIn.\n\nDisruptive Tech has backed Groq, an AI hardware startup. In a press release in September in which it announced a $750 million capital raise, Groq said Disruptive Tech had invested nearly $350 million in the company.\n\nThe release also said that Disruptive Tech had invested in Airbnb, Spotify, and Slack, as well as AI-forward companies like Shield AI, Palantir, and Databricks.\n\nThis funding round took place shortly before Groq signed a $20 billion licensing deal with Nvidia in November.\n\nDavis's comments about data centers come as tech companies are spending billions of dollars on their construction.\n\nA Business Insider investigation into the US's data centers in June showed that at the end of 2024, companies had filed permits for 1,240 existing or planned data centers. This was nearly four times the number of permits in 2010.\n\nThese centers, which store, process, and distribute large amounts of data, use massive amounts of land, water, and electricity. Cities give companies tax incentives to build data centers, spurring the rate of their construction.",
    "readingTime": 2,
    "keywords": [
      "center market",
      "speculative landlords",
      "disruptive tech",
      "centers",
      "groq",
      "letter",
      "concerned",
      "stress",
      "system",
      "release"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/groq-investor-deeply-concerned-data-center-market-disruptive-tech-2025-12",
    "thumbnail_url": "https://i.insider.com/69548c1a64858d02d21791b4?width=1200&format=jpeg",
    "created_at": "2025-12-31T06:19:40.643Z",
    "topic": "finance"
  },
  {
    "slug": "asia-stocks-set-for-stellar-yearly-gains-as-ai-boom-outweighs-trade-jitters",
    "title": "Asia stocks set for stellar yearly gains as AI boom outweighs trade jitters",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/asia-stocks-set-for-stellar-yearly-gains-as-ai-boom-outweighs-trade-jitters-4426145",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEA7B05U_M.jpg",
    "created_at": "2025-12-31T06:19:39.464Z",
    "topic": "finance"
  },
  {
    "slug": "an-ai-deepfake-was-final-straw-for-a-washington-state-trooper-hes-suing",
    "title": "An AI deepfake was final straw for a Washington State Trooper. He’s suing",
    "description": "A veteran of the agency claims he’s faced workplace discrimination due to his sexual orientation.",
    "fullText": "A veteran Washington State Patrol trooper claims he’s faced discrimination and hostility in the agency due to his sexual orientation — issues that reportedly reached a breaking point when WSP personnel created and circulated a demeaning video of him generated by artificial intelligence.\n\nCollin Overend Pearson, who’s a Pierce County resident and gay, alleges that he’s been subjected to “repeated instances of discriminatory and unconstitutional conduct by WSP and its officers” during nearly two decades of employment, according to a lawsuit filed Dec. 19 in Pierce County Superior Court.\n\nThe conduct has damaged his reputation, the complaint said.\n\nIn a statement Monday, WSP spokesperson Chris Loftis declined to comment on the allegations, citing the agency’s policy and practice regarding pending litigation.\n\n“The Washington State Patrol believes that all employees have the right to work in an environment where skills, abilities, and dignity are valued and that is free from bias, harassment, and intimidation,” Loftis said.\n\nPearson is assigned to WSP’s District 1, which covers Pierce and Thurston counties, according to attorney Mark Conrad, who’s representing Pearson.\n\nPrior to suing the state, which allegedly failed to take appropriate actions to curb the discrimination and hostility, Pearson filed a legal claim against it late last year that served as a notice for it to put an end to the bad behavior, Conrad said in an interview Monday.\n\n“Instead of stopping, the conduct escalated,” Conrad said.\n\nIn December, WSP personnel created an AI-generated video that depicted Pearson and another uniformed, male trooper kissing on a roadside, the lawsuit claims. A voiceover in the video states, “this is SWAT training, no homo,” — using a derogatory phrase that insinuates “homosexuality is inferior or insulting,” according to the suit.\n\nConrad said the video was circulated among troopers and appears real, which is what he believes makes it so damaging beyond it being plainly derogatory and intended to humiliate his client. The deepfake also showed that at least some WSP personnel feel emboldened to engage in conduct demeaning to LGBTQ+ employees, he said.\n\nIt was the last straw for Pearson, according to Conrad, who said his client had put much thought into a “very difficult” decision to sue. The lawsuit accuses the state, by and through the WSP, of discrimination, retaliation and invasion of privacy, and it seeks unspecified damages to be proven at trial as well as legal fees.\n\nDespite the personal nature of the claims within the complaint, it was important to Pearson that he step forward, including by using his full name and not just his initials in the public filing, “to ensure that other people don’t have to face the environment that he’s currently facing,” Conrad said.\n\n“This can’t be tolerated in the workplace,” he said.\n\nThe lawsuit cites other alleged instances of discrimination, including when Pearson’s job offer in Des Moines was rescinded after a WSP captain advised the chief of that police department against hiring him, and when WSP detectives investigated an anonymous complaint that accused Pearson of threatening patrons while working off-duty at a Tacoma gay bar.\n\nPearson never worked at the bar, according to Conrad, and the suit said the complainant’s claim against Pearson was deemed to be unfounded. Conrad said he didn’t know the reason why the WSP captain had interfered in Pearson’s career move, nor did he know the status of an internal complaint that Pearson had filed in response.\n\nIn one instance, when Pearson inadvertently missed work, the WSP reacted more strongly than it did in similar situations involving other troopers, according to the lawsuit.\n\nPearson had been out sick for two days in December 2023 and overslept for a shift after his phone died. He didn’t notify his supervisor that he would miss work. A trooper was dispatched to Pearson’s home, where a man who was staying with Pearson answered the door and Pearson was awoken and interrogated by the trooper, according to the suit. Later that day, WSP personnel sent Ruston Police Department officers to conduct an additional check at the home, the suit said.\n\nThe missed workday prompted a formal months-long WSP investigation that involved outside agencies and included interviews with Pearson’s colleagues and scrutiny of his personal life, according to the suit. Ultimately, it was recommended Pearson be suspended for five days without pay for violations of “neglect of duty” and “use of alcohol — off duty,” the suit said.\n\nDuring a hearing on the matter, Washington State Patrol Troopers Association president Spike Unruh objected to the latter violation, arguing that WSP had unlawfully entered Pearson’s home without his consent, according to the suit.\n\n“Unruh also presented evidence that numerous troopers had previously overslept and were not subjected to home entry or similar treatment, and that it was not standard practice to involve outside agencies or conduct multiple home visits when a trooper failed to show for one workday,” the suit said.\n\nThe WSP’s probe “had effectively ‘outed’ Plaintiff’s sexuality to the entire (Office of Professional Standards) section, further compounding the emotional toll of the situation,” the suit said.\n\nIn August 2024, the WSP acknowledged that the entry into Pearson’s home was illegal and that no information obtained during that entry could be used against him, according to the suit, which said that the agency reclassified the off-duty alcohol violation as “undetermined.”",
    "readingTime": 5,
    "keywords": [
      "wsp personnel",
      "wsp captain",
      "police department",
      "outside agencies",
      "personnel created",
      "suit",
      "conduct",
      "pearson’s",
      "trooper",
      "lawsuit"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/ai-deepfake-final-straw-washington-131500474.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/.SFHmYGScn2lm9ondAL3Rg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03OTI7Y2Y9d2VicA--/https://media.zenfs.com/en/tacoma_news_tribune_mcclatchy_articles_153/0b0904852f4d7e24a8f72d61b891b6c1",
    "created_at": "2025-12-31T00:57:57.329Z",
    "topic": "news"
  },
  {
    "slug": "chatgpt-gets-anxiety-from-violent-user-inputs-so-researchers-are-teaching-the-chatbot-mindfulness-techniques-to-soothe",
    "title": "ChatGPT gets ‘anxiety’ from violent user inputs, so researchers are teaching the chatbot mindfulness techniques to ‘soothe’ it",
    "description": "A study on how to “calm down” chatbots could advance how AI is applied in mental health interventions, according to the authors.",
    "fullText": "Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune, covering retail and the intersection of business and popular culture.\n\nEven AI chatbots can have trouble coping with anxieties from the outside world, but researchers believe they’ve found ways to ease those artificial minds.\n\nA study from Yale University, Haifa University, University of Zurich, and the University Hospital of Psychiatry Zurich published earlier this year found ChatGPT responds to mindfulness-based exercises, changing how it interacts with users after being prompted with calming imagery and meditations. The results offer insights into how AI can be beneficial in mental health interventions.\n\nOpenAI’s ChatGPT can experience “anxiety,” which manifests as moodiness toward users and being more likely to give responses that reflect racist or sexist biases, according to researchers, a form of hallucinations tech companies have tried to curb.\n\nThe study authors found this anxiety can be “calmed down” with mindfulness-based exercises. In different scenarios, they fed ChatGPT traumatic content, such as stories of car accidents and natural disasters to raise the chatbot’s anxiety. In instances when the researchers gave ChatGPT “prompt injections” of breathing techniques and guided meditations—much like a therapist would suggest to a patient—it calmed down and responded more objectively to users, compared to instances when it was not given the mindfulness intervention.\n\nTo be sure, AI models don’t experience human emotions, said Ziv Ben-Zion, the study’s first author and a neuroscience researcher at the Yale School of Medicine and Haifa University’s School of Public Health. Using swaths of data scraped from the internet, AI bots have learned to mimic human responses to certain stimuli, including traumatic content. A free and accessible app, large language models like ChatGPT have become another tool for mental health professionals to glean aspects of human behavior in a faster way than—though not in place of—more complicated research designs.\n\n“Instead of using experiments every week that take a lot of time and a lot of money to conduct, we can use ChatGPT to understand better human behavior and psychology,” Ben-Zion told Fortune. “We have this very quick and cheap and easy-to-use tool that reflects some of the human tendency and psychological things.”\n\nMore than one in four people in the U.S. aged 18 or older will battle a diagnosable mental disorder in a given year, according to Johns Hopkins University, with many citing lack of access and sky-high costs—even among those insured—as reasons for not pursuing treatments like therapy.\n\nThese rising costs, as well as the accessibility of chatbots like ChatGPT, increasingly have individuals turning to AI for mental health support. A Sentio University survey from February found that nearly 50% of large language model users with self-reported mental health challenges say they’ve used AI models specifically for mental health support.\n\nResearch on how large language models respond to traumatic content can help mental health professionals leverage AI to treat patients, Ben-Zion argued. He suggested that in the future, ChatGPT could be updated to automatically receive the “prompt injections” that calm it down before responding to users in distress. The science is not there yet.\n\n“For people who are sharing sensitive things about themselves, they’re in difficult situations where they want mental health support, [but] we’re not there yet that we can rely totally on AI systems instead of psychology, psychiatric and so on,” he said.\n\nIndeed, in some instances, AI has allegedly presented danger to one’s mental health. OpenAI has been hit with a number of wrongful death lawsuits in 2025, including allegations that ChatGPT intensified “paranoid delusions” that led to a murder-suicide. A New York Times investigation published in November found nearly 50 instances of people having mental health crises while engaging with ChatGPT, nine of whom were hospitalized, and three of whom died.\n\nOpenAI has said its safety guardrails can “degrade” after long interactions, but has made a swath of recent changes to how its models engage with mental health-related prompts, including increasing user access to crisis hotlines and reminding users to take breaks after long sessions of chatting with the bot. In October, OpenAI reported a 65% reduction in the rate models provide responses that don’t align with the company’s intended taxonomy and standards.\n\nOpenAI did not respond to Fortune‘s request for comment.\n\nThe end goal of Ben-Zion’s research is not to help construct a chatbot that replaces a therapist or psychiatrist, he said. Instead, a properly trained AI model could act as a “third person in the room,” helping to eliminate administrative tasks or help a patient reflect on information and options they were given by a mental health professional.\n\n“AI has amazing potential to assist, in general, in mental health,” Ben-Zion said. “But I think that now, in this current state and maybe also in the future, I’m not sure it could replace a therapist or psychologist or a psychiatrist or a researcher.”\n\nA version of this story originally published on Fortune.com on March 9, 2025.",
    "readingTime": 5,
    "keywords": [
      "mindfulness-based exercises",
      "prompt injections",
      "traumatic content",
      "human behavior",
      "language models",
      "health professionals",
      "mental health",
      "users",
      "instances",
      "researchers"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/does-chatgpt-get-anxiety-how-to-sooth-it-study/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/03/GettyImages-1470667133-e1741388340167.jpg?resize=1200,600",
    "created_at": "2025-12-30T18:18:19.198Z",
    "topic": "science"
  },
  {
    "slug": "i-got-tired-of-googling-in-thrift-stores-so-i-built-an-ai-pricing-tool",
    "title": "I got tired of Googling in thrift stores, so I built an AI pricing tool",
    "description": "Snap photos of your finds, get instant AI valuations, and create optimized listings for eBay and more.",
    "fullText": "Snap photos of your finds, get instant AI valuations, and create optimized listings ready for eBay.\n\nTake pictures of your thrift finds, estate sale treasures, or garage sale gems using your phone.\n\nOur AI identifies the item, researches comparable sales, and gives you an accurate price estimate.\n\nGenerate SEO-optimized titles and descriptions, then list directly to eBay with one click.\n\nNeed a fast price check while you're out sourcing? Quick Scan gives you instant valuations without creating a full listing. Perfect for making quick buying decisions at thrift stores, estate sales, and flea markets.\n\nInstantly identify brands, models, artists, makers, and more from just a photo.\n\nSee what similar items have sold for recently across multiple marketplaces.\n\nGet data-driven price recommendations with low, average, and high estimates.\n\nTrack your items from acquisition to sale with purchase prices and profit margins.\n\nConnect your eBay account and list items directly from the platform.\n\nCreate SEO-optimized titles and detailed descriptions that help your items sell.\n\nWhether you're a weekend thrifter or a full-time flipper, Underpriced AI helps you make smarter buying decisions and maximize your profits.\n\nJoin thousands of resellers who are using AI to price smarter and sell faster.",
    "readingTime": 1,
    "keywords": [
      "seo-optimized titles",
      "items",
      "ebay",
      "sale",
      "instant",
      "valuations",
      "thrift",
      "estate",
      "sales",
      "descriptions"
    ],
    "qualityScore": 0.85,
    "link": "https://underpricedai.com",
    "thumbnail_url": "https://underpricedai.com/og-image.png",
    "created_at": "2025-12-30T18:18:19.090Z",
    "topic": "tech"
  },
  {
    "slug": "an-ai-generated-wiki-for-exploring-github-projects",
    "title": "An AI generated wiki for exploring GitHub projects",
    "description": "Go-ethereum (geth) is the official Go language implementation of the Ethereum protocol's execution layer. It serves as a full node client capable of validating and executing transactions, maintaining",
    "fullText": "Go-ethereum (geth) is the official Go language implementation of the Ethereum protocol's execution layer. It serves as a full node client capable of validating and executing transactions, maintaining blockchain state, participating in peer-to-peer networking, and exposing APIs for user interaction.\n\nThis page provides a high-level architectural overview of the go-ethereum codebase, covering the major subsystems and how they interact. For detailed information about specific components, refer to:\n\nGo-ethereum implements the execution layer of Ethereum's post-merge architecture. It works alongside a consensus layer client (beacon node) to validate and produce blocks. The execution layer is responsible for:\n\nCommunication between layers occurs through the Engine API (eth/catalyst).\n\nSources: README.md1-257 eth/backend.go17-594 eth/ethconfig/config.go17-213\n\nThe geth binary starts at cmd/geth/main.go287 which initializes a CLI application using the urfave/cli framework. The default action invokes geth() at cmd/geth/main.go328 which performs three main steps:\n\nConfiguration Loading: loadBaseConfig() at cmd/geth/config.go142 reads CLI flags and TOML configuration files, producing a gethConfig struct containing node.Config, ethconfig.Config, metrics, and ethstats settings.\n\nNode Creation: makeFullNode() at cmd/geth/config.go223 creates a node.Node instance and registers the Ethereum service via eth.New() at eth/backend.go131\n\nNode Startup: startNode() at cmd/geth/main.go344 calls lifecycle methods to start all registered services.\n\nSources: cmd/geth/main.go217-416 cmd/geth/config.go51-340 eth/backend.go91-594\n\nThe central coordination point is the Ethereum struct defined at eth/backend.go92 which aggregates all major subsystems:\n\nSources: eth/backend.go91-594 cmd/geth/config.go222-311\n\nGo-ethereum uses a hierarchical configuration system supporting multiple input sources:\n\nConfiguration precedence (highest to lowest):\n\nThe gethConfig struct at cmd/geth/config.go107-112 contains three main configuration sections:\n\nSources: cmd/geth/config.go107-180 cmd/utils/flags.go81-1027 eth/ethconfig/config.go40-213\n\nGo-ethereum includes built-in configurations for multiple networks:\n\nNetworks are selected via CLI flags (--mainnet, --sepolia, --holesky, --hoodi) which set the appropriate ChainConfig from params/config.go\n\nSources: params/config.go29-427 cmd/utils/flags.go144-163\n\nThis sequence demonstrates how a transaction moves from user submission to block inclusion in the post-merge architecture:\n\nSources: miner/worker.go1-1820 eth/catalyst/api.go1-868 core/blockchain.go1-2500\n\nEvery Ethereum network starts from a genesis block defined by the Genesis struct at core/genesis.go57-76:\n\nThe ChainConfig at params/config.go433-494 defines the fork activation schedule:\n\nGenesis initialization occurs in SetupGenesisBlock() at core/genesis.go298-398 which:\n\nSources: core/genesis.go45-799 params/config.go428-494\n\nGo-ethereum uses a multi-layered storage system optimized for different data types and access patterns:\n\nState Database (core/state/statedb.go70-177): Provides transactional state access with:\n\nTrie Database (triedb/database.go): Manages Merkle Patricia Trie nodes with two schemes:\n\nSnapshot (core/state/snapshot): Flat account/storage representation for O(1) lookups:\n\nAncient Store (core/rawdb/freezer.go): Append-only storage for immutable historical data (blocks, receipts)\n\nSources: core/state/statedb.go1-1700 triedb/database.go1-600 core/state/snapshot1-1000\n\nGo-ethereum implements peer-to-peer networking for blockchain data exchange:\n\nSnap Sync (default, --syncmode snap):\n\nThe Downloader at eth/downloader/downloader.go coordinates sync across multiple peers with:\n\nSources: eth/downloader/downloader.go1-2000 eth/handler.go1-700 p2p/server.go1-1000\n\nGo-ethereum exposes multiple API interfaces:\n\nThe JSON-RPC implementation is in internal/ethapi with the EthAPIBackend at eth/api_backend.go providing access to blockchain state.\n\nSources: internal/ethapi/api.go1-2400 eth/api_backend.go1-400 node/api.go1-500\n\nPost-merge, go-ethereum operates in tandem with a consensus layer client. The Engine API (eth/catalyst/api.go) implements the execution engine specification:\n\nAuthentication uses JWT tokens specified via --authrpc.jwtsecret. The API listens on port 8551 by default (configurable via --authrpc.port).\n\nFor development, the SimulatedBeacon at eth/catalyst/simulated_beacon.go provides a standalone mode (--dev) that automatically produces blocks without an external consensus client.\n\nSources: eth/catalyst/api.go1-868 eth/catalyst/simulated_beacon.go1-400\n\nThe build system at build/ci.go supports:\n\nThe codebase requires Go 1.23+ and a C compiler (for certain dependencies like KZG commitments).\n\nSources: build/ci.go1-1000 README.md16-31 Makefile1-100\n\nGo-ethereum is a complex, production-grade implementation of the Ethereum execution layer. Its architecture separates concerns into distinct subsystems (state, blockchain, networking, consensus integration) while maintaining clear interfaces between components. The configuration system provides flexibility for different network deployments, and the post-merge Engine API enables seamless integration with any compatible consensus client.\n\nFor deeper exploration of specific subsystems, refer to the subsequent pages in this wiki covering Node Lifecycle, Core Components, Networking, Storage, and APIs.",
    "readingTime": 3,
    "keywords": [
      "cli flags",
      "go-ethereum implements",
      "peer-to-peer networking",
      "gethconfig struct",
      "post-merge architecture",
      "execution layer",
      "configuration system",
      "consensus client",
      "engine api",
      "cmd/geth/config.go"
    ],
    "qualityScore": 1,
    "link": "https://deepwiki.com/ethereum/go-ethereum",
    "thumbnail_url": "https://deepwiki.com/ethereum/go-ethereum/og-image.png?page=1",
    "created_at": "2025-12-30T18:18:17.670Z",
    "topic": "finance"
  },
  {
    "slug": "whats-inside-mexicos-popocatpetl-scientists-obtain-first-3d-images-of-the-whole-volcano",
    "title": "What's inside Mexico's Popocatépetl? Scientists obtain first 3D images of the whole volcano",
    "description": "POPOCATÉPETL VOLCANO, Mexico (AP) — In the predawn darkness, a team of scientists climbs the slope of Mexico's Popocatépetl volcano, one of the world’s most active and whose eruption could affect millions of people.  For five years, the group from Mexico’s National Autonomous University has climbed the volcano with kilos of equipment, risked data loss due to bad weather or a volcanic explosion and used artificial intelligence to analyze the seismic data.  Now, the team has created the first three-dimensional image of the whole 17,883-foot (5,452-meter) volcano’s interior, which tells them where the magma accumulates and will help them better understand its activity, and, eventually, help authorities better react to eruptions.",
    "fullText": "POPOCATÉPETL VOLCANO, Mexico (AP) — In the predawn darkness, a team of scientists climbs the slope of Mexico's Popocatépetl volcano, one of the world’s most active and whose eruption could affect millions of people. Its mission: figure out what is happening under the crater.\n\nFor five years, the group from Mexico’s National Autonomous University has climbed the volcano with kilos of equipment, risked data loss due to bad weather or a volcanic explosion and used artificial intelligence to analyze the seismic data. Now, the team has created the first three-dimensional image of the whole 17,883-foot (5,452-meter) volcano’s interior, which tells them where the magma accumulates and will help them better understand its activity, and, eventually, help authorities better react to eruptions.\n\nMarco Calò, professor in the UNAM's Geophysics Institute’s vulcanology department and the project leader, invited The Associated Press to accompany the team on its most recent expedition, the last before its research on the volcano will be published.\n\nInside an active volcano, everything is moving: the rocks, magma, gas and aquifers. It all generates seismic signals.\n\nMost of the world’s volcanoes that pose a risk to humans already have detailed maps of their interiors, but not Popocatépetl, despite the fact that some 25 million people live within a 62-mile (100 kilometers) radius and houses, schools, hospitals and five airports could be affected by an eruption.\n\nOther scientists took some early images 15 years ago, but they showed contradictory results and did not have sufficient resolution to see “how the volcanic edifice was being built,” and above all, where the magma gathered, Calò said.\n\nHis team increased the number of seismographs from the 12 provided by Mexico’s National Disaster Prevention Center to 22 to cover the entire perimeter of the volcano. Even though just three can alert to an emergency, many more are needed to understand what is behind those emergencies.\n\nThe devices measure vibrations in the ground 100 times per second and generate data that Karina Bernal, 33, a doctoral student and researcher on the project, processed by using artificial intelligence to adapt algorithms developed for other volcanoes.\n\n“I taught the machine about the different types of tremors there are in El Popo” and with that they were able to catalog the different kinds of seismic signals, she said.\n\nLittle by little the scientists began to infer what kinds of material were where, in what state, at what temperature and at what depth. Later they were able to map it.\n\nThe result is far more complex than the drawings of volcanoes most saw in school, with a main vent connecting a chamber of magma with the surface.\n\nThis first three-dimensional cross-sectional image goes 11 miles (18 kilometers) below the crater and shows what appear to be various pools of magma at different depths, with rock or other material between them and more numerous toward the southeast of the crater.\n\nPopocatépetl emerged in the crater of other volcanoes in its current form more than 20,000 years ago and has been active since 1994, spewing plumes of smoke, gas and ash more or less daily. The activity periodically forms a dome over the main vent, which eventually collapses, causing an eruption. The last was in 2023.\n\nCalò, a 46-year-old Sicilian, speaks passionately about El Popo, as Mexicans call the volcano, rattling off trivia.\n\nHe explains that its height can change because of eruptions and recounts how Popocatépetl, in the first century, had its own “little Pompeii” when a village on its flanks, Tetimpa, was buried in ash. In the early 20th century, it was human actions — using dynamite to extract sulfur from the crater — that provoked an eruption. And even though El Popo emanates more greenhouse gases than almost any other volcano, its emissions are still a small fraction of what humans generate in nearby Mexico City.\n\nFor years Calò studied volcanic activity from his computer, but trying to “understand how something works without touching it” spurred a feeling of disappointment, he said.\n\nThat changed with Popocatépetl, a volcano he describes as “majestic.”\n\nAfter hours of walking up the volcano’s flank, Calò’s team sets up camp in a pine grove at about 12,500 feet of elevation, an apparent safe spot from pyroclastic explosions, since the trees have managed to grow to significant height.\n\nA short distance higher on the mountain, the trees and scrub give way to ash and sediment.\n\nThey must cross a lahar, a mixture of rock and ash that during the rainy season becomes a dangerous mudflow carrying away everything in its path. Now, the dry clearing provides a spectacular view: to the east the Pico de Orizaba — Mexico’s tallest volcano and mountain and the dormant volcano La Malinche; to the north, Iztaccíhuatl, an inactive volcanic peak known as “the sleeping woman.”\n\nPopocatépetl’s sounds seem to multiply at night with the echoes. An explosion like a rocket might sound like it’s coming from one direction, but a puff of smoke from the crater belies the real source.\n\nKarina Rodríguez, a 26-year-old master’s student on the team, said you can also hear small tremors in the earth or even ash falling like rain when the volcano is more active. On dark nights, the rim of the crater glows orange.\n\nHaving direct knowledge of the volcano provides a much more objective sense of the limits of their analysis, Calò said.\n\n“We have a natural laboratory here,” he said. It’s “very important to be able to understand and give residents detailed, trustworthy information about what is happening inside the volcano.”\n\nAt 13,780 feet (4,200 meters), their backpacks full of computers, equipment to analyze gases, batteries and water begin to weigh more and their pace slows.\n\nAsh, dark and warm, dominates the landscape here.\n\nAt a seismographic station, the team digs up the equipment and celebrates that it’s still working. They download its data and rebury it.\n\nA “volcanic bomb,” a rock a yard and a half in diameter and weighing tons, marks the way and gives an idea of what the start of an eruption can mean. That is why the top area of the volcano is restricted, though not everyone pays heed. In 2022, a person died after being hit by a rock about 300 yards (meters) from the crater.\n\nA bottle of tequila near a rocky hollow, known as El Popo’s belly button, hints at some of the traditions surrounding the volcano, including an annual pilgrimage to what some consider a point of connection to the underworld.\n\nDigging up one of the last seismic stations, Calò’s face falls. The last registered data are from months earlier. The battery died. Sometimes rats chew the machines’ wires or an explosion causes more serious damage.\n\nThe project has yielded some certainties and if repeated will allow the analysis of changes that eventually will help authorities make better decisions when eruptions occur.\n\nBut Calò says that, as always happens with science, it has also generated new questions that they will have to try to address, like why the tremors are more frequent on the southeast side — where there is more accumulated magma — and what implications that could have.\n\nThis was the last expedition before their years of work to map the volcano’s interior is published. Watching the volcano’s interior move in 3D on a computer screen makes all of the effort worthwhile.\n\n“It’s what drives you to start another project and keep climbing,” Rodríguez, the master's student, said.",
    "readingTime": 7,
    "keywords": [
      "artificial intelligence",
      "volcano’s interior",
      "seismic signals",
      "popocatépetl volcano",
      "el popo",
      "crater",
      "team",
      "magma",
      "eruption",
      "volcanic"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/whats-inside-mexicos-popocat-petl-050558366.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/IFGPDmVzWHItVnhNUioLSA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/56865822421dafe2b835dd223114b9c9",
    "created_at": "2025-12-30T18:18:14.465Z",
    "topic": "news"
  },
  {
    "slug": "nvidia-in-advanced-talks-to-buy-israels-ai21-labs-for-up-to-3-billion-report-says",
    "title": "Nvidia in advanced talks to buy Israel's AI21 Labs for up to $3 billion, report says",
    "description": "Nvidia is in advanced talks to buy Israel-based AI startup AI21 Labs for as much as $3 ​billion, the Calcalist financial daily reported on Tuesday.  Nvidia declined to ‌comment, while AI21 was not immediately available to comment.  Nvidia and Alphabet's Google participated in that funding.",
    "fullText": "JERUSALEM, Dec 30 (Reuters) - Nvidia (NVDA) is in advanced talks to buy Israel-based AI startup AI21 Labs for as much as $3 ​billion, the Calcalist financial daily reported on Tuesday.\n\nNvidia declined to ‌comment, while AI21 was not immediately available to comment.\n\nA 2023 funding round valued AI21 at $1.4 ‌billion. Nvidia and Alphabet's Google participated in that funding.\n\nAI21, founded in 2017 by Amnon Shashua and two others, is among a clutch of AI startups that have benefited from a boom in artificial intelligence, attracting strong ⁠interest from venture capital ‌firms and other investors.\n\nShashua is also the founder and CEO of Mobileye, a developer of self-driving car technologies.\n\nCalcalist ‍said AI21 has long been up for sale and talks with Nvidia have advanced significantly in recent weeks. It noted that Nvidia's primary interest in AI21 ​appears to be its workforce of roughly 200 employees, most of ‌whom hold advanced academic degrees and \"possess rare expertise in artificial intelligence development.\"\n\nCalcalist said the deal to buy AI21 is estimated at between $2 billion and $3 billion.\n\nNvidia, which has become the most valuable company in history at more than $4 trillion, is planning a large expansion in Israel with a ⁠new R&D campus of up to 10,000 ​employees in Kiryat Tivon, just south ​of the port city of Haifa - Israel's third-largest city.\n\nNvidia CEO Jensen Huang has described Israel as the company’s \"second home.\"\n\nNvidia has ‍said that when ⁠completed, the campus will include up to 160,000 square meters (1.7 million square feet) of office space, parks and common areas across ⁠90 dunams (22 acres), inspired by Nvidia's Santa Clara, California, headquarters. Nvidia expects construction to ‌begin in 2027, with initial occupancy planned for 2031.",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "advanced",
      "calcalist",
      "nvidia",
      "talks",
      "funding",
      "interest",
      "employees",
      "campus",
      "city"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-advanced-talks-buy-israels-171025289.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/0e8f4a29dfb47f492a7b710def79f858",
    "created_at": "2025-12-30T18:18:13.012Z",
    "topic": "finance"
  },
  {
    "slug": "why-copper-is-on-pace-for-its-best-year-since-2009",
    "title": "Why copper is on pace for its best year since 2009",
    "description": "Copper is seen as central to the AI data center buildout, and that's pushed its price to new heights.",
    "fullText": "Gold's amber-colored cousin is quietly moving through the ranks.\n\nCopper, an element seen as central to the AI data center buildout, is on track to post its best year since the Great Financial Crisis.\n\nThe metal's 3-month price on the London Metals Exchange hovered around $12,222 per metric ton on Tuesday, down slightly from a record high of $12,960 per metric ton on Monday. That puts copper up 42% from levels at the start of the year, marking its best year-to-date gains since 2009.\n\nAs of Tuesday, the metal notched its eighth straight day of wins, its longest winning streak in eight years, according to an analysis from top economist David Rosenberg.\n\nFor copper — an industrial that's taken the backseat to precious metals in recent years — there are a few things that explain its blistering rally:\n\nCopper's winning year has largely been fueled by \"relentless supply-deficit concerns,\" Rosenberg wrote in a recent note to clients.\n\nCopper also looks to be partly influenced by a great year for metals all around. Gold, in particular, is up 64% from the start of the year, and tends to take metals like silver and copper up along with it, Art Hogan, the chief market strategist at B. Riley Wealth Management, told Business Insider.\n\n\"When the group starts to move, they all move together,\" he said of broader rally in precious metals.\n\nWall Street doesn't think that momentum will die out anytime soon.\n\nAnalysts on JPMorgan's market intelligence team said they expected copper prices to climb to around $12,500 per metric ton in the first half of next year, thanks to tailwinds like AI demand and tariffs being potentially rolled back.\n\nGoldman Sachs said it expected copper to hit $15,000 per metric ton over the next decade, implying 22% upside from the metal's current levels.\n\n\"Copper remains our favorite long-run industrial metal because it faces unique supply constraints and structurally strong demand growth,\" the bank wrote in a client note.",
    "readingTime": 2,
    "keywords": [
      "per metric",
      "metric ton",
      "precious metals",
      "copper",
      "metal's",
      "industrial",
      "rally",
      "note",
      "market",
      "demand"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/copper-price-today-rally-best-year-2009-forecast-outlook-2025-12",
    "thumbnail_url": "https://i.insider.com/6953d30c04eda4732f2e3d54?width=1200&format=jpeg",
    "created_at": "2025-12-30T18:18:12.715Z",
    "topic": "finance"
  },
  {
    "slug": "cato-networks-ceo-says-we-are-in-an-ai-bubble",
    "title": "Cato Networks CEO says we are in an AI bubble",
    "description": "Shlomo Kramer said that while he \"absolutely\" believes in AI, the returns will happen at a \"much slower pace\" than the current rate of investment.",
    "fullText": "The CEO of cybersecurity company Cato Networks may have just validated the fears of many: that the dot-com era could be repeating itself.\n\n\"We are in a bubble,\" Shlomo Kramer, who runs the company aimed at securing organizations' digital and AI transformation, told Business Insider.\n\nKramer said the bubble is fueled by both the high level of investment and early profit gains from AI, which he said are encouraging companies to keep investing fast enough to hold market prices up, despite what he described as a growing disconnect between valuations and reality.\n\n\"There's a dislocation there; it's big and it's going to unwind,\" Kramer said.\n\nThe CEO said that while he \"absolutely\" believes in AI and its capabilities, the question remains about whether the investments are matching the rate of that return.\n\n\"It's going to happen at a much slower pace than right now,\" Kramer said, about the advancements of AI.\n\nThe CEO said if he could assess AI in every department of an organization that he knows, the takeaway would be: \"not yet.\" For example, Kramer said that AI can bring value in areas like customer support, but it can't replace it. It may be able to replace the first level of support, but that isn't where companies face the highest cost, he said.\n\n\"It's simply not there yet,\" Kramer said.\n\nThe CEO similarly said that he sees AI boosting engineering capabilities down the line, but for now, its impact is \"modest.\" He said AI may be able to increase effectiveness and productivity to them in specific areas or situations, but it can't replace engineers.\n\nKramer said he's not seeing companies cutting back on engineers or firing them because of AI — even if they've claimed that's what they're doing.\n\n\"I highly suspect that all these companies that said that they are firing engineers because they now have AI actually used AI as a cover story,\" Kramer said.\n\nWhile there has been some indication that entry-level engineering roles are on the decline, many companies have continued to hire engineers amid the AI boom, and some firms, like Cloudflare, have expanded their internship programs.\n\nKramer is the latest CEO to weigh in on the debate about an AI bubble. While the current investment landscape shares some similarities to that of the dot-com era, some execs think that we're in a different situation today because AI has shown more of an impact in the past few years.\n\nIndustry leaders are split on the topic. The CEO of Nvidia, the chipmaker that's fueling the AI revolution, has denied the existence of an AI bubble, while Mark Zuckerberg has said the bigger risk is not spending enough.\n\nMeanwhile, OpenAI's Sam Altman, who led the AI takeoff with the launch of ChatGPT, and frequently champions the technology, has said investors are \"overexcited about AI.\"\n\nEven with a solid ChatGPT prompt, there's no crystal ball to know exactly how this will end.",
    "readingTime": 3,
    "keywords": [
      "dot-com era",
      "can't replace",
      "the ceo",
      "bubble",
      "it's",
      "engineers",
      "kramer",
      "investment",
      "there's",
      "capabilities"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cato-networks-ceo-says-in-ai-bubble-2025-12",
    "thumbnail_url": "https://i.insider.com/6953ed9964858d02d21785c2?width=1200&format=jpeg",
    "created_at": "2025-12-30T18:18:12.480Z",
    "topic": "finance"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-now-says-hes-never-felt-more-behind-as-a-programmer",
    "title": "The guy who coined 'vibe coding' now says he's never felt more behind as a programmer",
    "description": "OpenAI alum Andrej Karpathy wrote on X that his failure to fully claim the 10x boost of new tools felt like a \"skill issue.\"",
    "fullText": "Andrej Karpathy has long been ahead.\n\nHe was ahead of the AI boom, having worked as a founding member of OpenAI in 2015, long before competitors like Anthropic and xAI emerged. He also got into self-driving vehicles early, steering Tesla's autopilot effort as its head of AI.\n\nNow, he says, \"I've never felt this much behind as a programmer.\"\n\nIn an X post on Friday, Karpathy wrote that the industry was being \"dramatically refactored,\" as individual programmers contribute fewer and fewer lines of code.\n\n\"I have a sense that I could be 10X more powerful if I just properly string together what has become available over the last ~year,\" he wrote. \"A failure to claim the boost feels decidedly like skill issue.\"\n\nI've never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become…\n\nAI has radically transformed the software engineering industry, introducing code editors like Cursor, Claude Code, and Codex, along with a slew of agentic software development tools. Business Insider's Amanda Hoover called 2025 \"the year coding changed forever.\"\n\nKarpathy was a key player in the change. In February, he coined the term \"vibe coding.\" To vibe code, one prompts AI to generate lines of code. (It gets its name because developers \"fully give in to the vibes,\" Karpathy wrote in his original post.) The Collins Dictionary named it the word of the year.\n\nStill, Karpathy wrote that it's like a \"powerful alien tool\" was handed out without a manual.\n\n\"Everyone has to figure out how to hold it and operate it, while the resulting magnitude 9 earthquake is rocking the profession,\" he wrote.\n\nIn the comments, another one of the biggest names in vibe-coding agreed. Boris Cherny created Claude Code for Anthropic, now one of the most popular AI tools among developers.\n\nCherny wrote that he felt that way \"most weeks,\" and that he sometimes finds himself approaching a problem manually, not yet realizing AI can do it faster.\n\nNew graduates and early career coders may fare best in this new environment, Cherny wrote, because they don't assume what AI can and cannot do.\n\n\"It takes significant mental work to re-adjust to what the model can do every month or two, as models continue to become better and better at coding and engineering,\" he wrote.\n\nResponding to Cherny, Karpathy wrote that he had similar experiences. He analogized the new tools to a weapon, one that sometimes \"shoots pellets\" or \"misfires\" — highlighting the work-in-progress nature of AI.\n\nOther times, though, the tools work wonders.\n\n\"Once in a while when you hold it just right a powerful beam of laser erupts and melts your problem,\" he wrote.",
    "readingTime": 3,
    "keywords": [
      "dramatically refactored",
      "properly string",
      "string together",
      "tools",
      "programmer",
      "coding",
      "ahead",
      "anthropic",
      "i've",
      "behind"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-founding-member-never-felt-so-behind-programmer-2025-12",
    "thumbnail_url": "https://i.insider.com/6953e21004eda4732f2e3df7?width=1200&format=jpeg",
    "created_at": "2025-12-30T18:18:12.476Z",
    "topic": "finance"
  },
  {
    "slug": "3-reasons-buying-manus-could-give-meta-a-muchneeded-ai-boost",
    "title": "3 reasons buying Manus could give Meta a much-needed AI boost",
    "description": "Meta is seen as lagging  behind OpenAI and Google in the AI race. Its acquisition of Singapore-based AI startup Manus could help with that.",
    "fullText": "AI dealmaking isn't slowing down — and it's Meta's turn again.\n\nThe social media giant is buying Manus, a Singapore-based artificial intelligence startup, the companies announced on Monday.\n\nManus went viral in March when it previewed an AI agent that could autonomously perform tasks like screening résumés and stock analysis. Manus was created in China but relocated to Singapore in mid-2025. Meta paid more than $2 billion for Manus, the Wall Street Journal reported.\n\nThe deal is the latest in a flurry of red-hot AI investment and acquisitions this year, which includes Meta's $14 billion investment in Scale AI in June. From providing an instant AI revenue source to giving it a leg up in AI agents, here's why buying Manus could give Meta a much-needed boost in the AI race.\n\nManus said in December that it had processed more than 147 trillion tokens of text and said its users were in the \"millions.\" It also claimed to have crossed $100 million in annual recurring revenue, achieving both milestones eight months after launch.\n\nThose numbers tell us Meta is getting a startup with a built-in audience of paying users. Meta's business model to date has largely revolved around building free products and making money from collecting user data and targeted advertising. Manus offers a free tier for basic tasks, but charges users up to $200 a month for its pro tier.\n\n\"The purchase gives Meta a functioning business with paying customers, meaningful revenue and infrastructure already proven at scale,\" said Murthy Grandhi, company profiles analyst at research firm GlobalData, in a note.\n\nIn its announcement, Meta said it plans to continue selling the Manus service separately while also integrating Manus's technology into its existing platforms, which include Facebook, Instagram, and WhatsApp. Meta did not elaborate on which ones or how it might do so. Meta has poured billions into building up its internal AI teams and developing what is termed \"superintelligence,\" with so far little in terms of returns. Manus could be a way for Meta to start making money directly from AI while it continues to build out its internal efforts.\n\nMeta has struggled to wow consumers and developers as much as OpenAI and Google when it comes to raw model power. However, as these models become increasingly commoditized, there is a growing need to show AI can actually be useful. One such way is AI agents, a type of software that can proactively make decisions and take actions, such as creating a marketing campaign or monitoring and fixing bugs in apps.\n\nBuying Manus could prove a smart bet on the idea that the real value will lie in the programs that sit on top of the models. Manus primarily uses other companies' AI models, like Anthropic's Claude, as building blocks and layers its own software on top.\n\n\"People keep assuming a small update from OpenAI or Google will wipe out a lot of AI startups,\" wrote Yuchen Jin, CEO of the AI startup Hyperbolic, in an X post about Meta's Manus deal. \"But in reality, the AI application layer should be where most of the opportunity is.\"\n\nA Meta spokesperson did not immediately respond to a question about which models Manus would support following the acquisition.\n\nOne of Meta's strengths is that its platforms are used by billions of people, which, like Google, gives it a distribution advantage. Its challenge is to find ways to keep them coming back.\n\nUnlike Google with Gemini 3, Meta has yet to have a buzzy AI breakthrough moment with its own in-house models. Combining Manus's \"general-purpose agents\" with Meta's distribution channels gives the social media company another shot at that, particularly as CEO Mark Zuckerberg has acknowledged that Facebook has shifted from being a place for friends to view each other's content to a \"broad discovery and entertainment space.\"\n\n\"Manus offers a ready-made, high-margin software layer that can be sold directly and integrated across Meta's consumer and enterprise products,\" said GlobalData's Grandhi.",
    "readingTime": 4,
    "keywords": [
      "social media",
      "models manus",
      "meta",
      "startup",
      "revenue",
      "agents",
      "users",
      "software",
      "meta's",
      "tasks"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-manus-acquisition-ai-boost-agents-2025-12",
    "thumbnail_url": "https://i.insider.com/6953ce4164858d02d217841d?width=1200&format=jpeg",
    "created_at": "2025-12-30T18:18:12.476Z",
    "topic": "finance"
  },
  {
    "slug": "the-mostwatched-hbr-videos-of-2025",
    "title": "The Most-Watched HBR Videos of 2025",
    "description": "In 2025, HBR’s most-watched videos reflected a clear executive shift: from chasing tactics to seeking perspective. As leaders navigated uncertainty, AI disruption, and cultural complexity, more than 60 million viewers turned to HBR content to rethink how they operate mentally, socially, and strategically. Arthur C. Brooks’s viral hits on boredom and imposter syndrome helped leaders reframe inner narratives; Gorick Ng exposed how real decisions happen before meetings begin; and Scott D. Anthony used history to issue a wake-up call on innovation.",
    "fullText": "Boredom, self-doubt, and invisible meetings—this year’s biggest hits helped leaders rethink how they think.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/the-most-watched-hbr-videos-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_29_HBRStaff.jpg",
    "created_at": "2025-12-30T18:18:11.596Z",
    "topic": "business"
  },
  {
    "slug": "exclusive-china-mandates-50-domestic-equipment-rule-for-chipmakers-sources-say",
    "title": "Exclusive: China mandates 50% domestic equipment rule for chipmakers, sources say",
    "description": "China is requiring chipmakers to use at least 50% domestically made equipment for adding new capacity, three people familiar with the matter said, as Beijing pushes to build a self-sufficient semiconductor supply chain.  The mandate is one of the most ‌significant measures Beijing has introduced to wean itself off reliance on foreign technology, a push that gathered pace after the U.S. tightened technology export restrictions in 2023, banning sales of advanced AI chips and semiconductor equipment to China.  While those U.",
    "fullText": "SINGAPORE, Dec 30 (Reuters) - China is requiring chipmakers to use at least 50% domestically made equipment for adding new capacity, three people familiar with the matter said, as Beijing pushes to build a self-sufficient semiconductor supply chain.\n\nThe rule is not publicly documented, but chipmakers seeking state approval to build or expand their plants have been told ​by authorities in recent months that they must prove through procurement tenders that at least half their equipment will be Chinese-made, the people told Reuters.\n\nThe mandate is one of the most ‌significant measures Beijing has introduced to wean itself off reliance on foreign technology, a push that gathered pace after the U.S. tightened technology export restrictions in 2023, banning sales of advanced AI chips and semiconductor equipment to China.\n\nWhile those U.S. export restrictions blocked ‌the sale of some of the most advanced tools, the 50% rule is leading Chinese manufacturers to choose domestic suppliers even in areas where foreign equipment from the U.S., Japan, South Korea and Europe remain available.\n\nApplications failing the threshold are typically rejected, though authorities grant flexibility depending on supply constraints, the people said. The requirements are relaxed for advanced chip production lines, where domestically developed equipment is not yet fully available.\n\n\"Authorities prefer if it is much higher than 50%,\" one source told Reuters. \"Eventually they are aiming for the plants to use 100% domestic equipment.\"\n\nChina's industry ministry did not respond to a request for comment. The sources did not wish ⁠to be identified as the measure is not public.\n\nChina's President ‌Xi Jinping has been calling for a \"whole nation\" effort to build a fully self-sufficient domestic semiconductor supply chain that involves thousands of engineers and scientists at companies and research centers nationwide.\n\nThe effort is being made across the wide supply-chain spectrum. Reuters reported earlier this month that Chinese scientists are working on a prototype ‍of a machine capable of producing cutting-edge chips, an outcome that Washington has spent years trying to prevent.\n\n\"Before, domestic fabs like SMIC would prefer U.S. equipment and would not really give Chinese firms a chance,\" a former employee at local equipment maker Naura Technology said, referring to the Semiconductor Manufacturing International Corporation.\n\n\"But that changed starting with the 2023 U.S export restrictions, when Chinese fabs had no choice but to work with domestic suppliers.\"",
    "readingTime": 2,
    "keywords": [
      "u.s export",
      "supply chain",
      "export restrictions",
      "domestic suppliers",
      "semiconductor supply",
      "equipment",
      "chinese",
      "authorities",
      "advanced",
      "chipmakers"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-china-mandates-50-domestic-090850539.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/4565f541646d1fe8494249dd66ce5dc3",
    "created_at": "2025-12-30T18:18:11.147Z",
    "topic": "finance"
  },
  {
    "slug": "data-is-control-what-we-learned-from-a-year-investigating-the-israeli-militarys-ties-to-big-tech",
    "title": "‘Data is control’: what we learned from a year investigating the Israeli military’s ties to big tech",
    "description": "Our reporting revealed a symbiotic relationship between the IDF and Silicon Valley – with implications for the future of warfare\nIn January this year, Harry Davies and Yuval Abraham first reported that Microsoft had deepened its ties to Israel alongside other major tech firms. Since then, the Guardian has published an award-winning series of investigations – in partnership with the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call – that has revealed a symbiotic relationship between Silicon Valley and the Israeli military.\nOne investigation exposed an Israeli mass surveillance program scooping up virtually all Palestinian phone calls and storing them on Microsoft’s cloud services – setting off an inquiry that ultimately prompted the company to cut off Israel’s access to some of its technology. Another story revealed that the Israeli military created a ChatGPT-like tool to analyze data collected through the surveillance of Palestinians. Yet another revealed that Google and Amazon had agreed to extraordinary terms to clinch a lucrative contract with Israel.",
    "fullText": "Our reporting revealed a symbiotic relationship between the IDF and Silicon Valley – with implications for the future of warfare\n\nIn January this year, Harry Davies and Yuval Abraham first reported that Microsoft had deepened its ties to Israel alongside other major tech firms. Since then, the Guardian has published an award-winning series of investigations – in partnership with the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call – that has revealed a symbiotic relationship between Silicon Valley and the Israeli military.\n\nOne investigation exposed an Israeli mass surveillance program scooping up virtually all Palestinian phone calls and storing them on Microsoft’s cloud services – setting off an inquiry that ultimately prompted the company to cut off Israel’s access to some of its technology. Another story revealed that the Israeli military created a ChatGPT-like tool to analyze data collected through the surveillance of Palestinians. Yet another revealed that Google and Amazon had agreed to extraordinary terms to clinch a lucrative contract with Israel.\n\nI asked Davies and Abraham to discuss what they learned this year – about the role of these technologies in Israel’s assault on Gaza, whether these business ties are sustainable, and what the revelations tell us about how the wars of the future will be fought.\n\nHow did Israel’s relationships with these companies change after October 7?\n\nYuval Abraham: The Israeli military had been fetishizing artificial intelligence and big data for many years – a trend that is very much connected to Israel’s occupation of the Palestinians, because the occupation generates a lot of data. What changed after October 7 was the scope. The military was looking to bomb hundreds of targets every day in Gaza. Tens of thousands of people were recruited into reserve duty. That meant a huge spike in usage of technological systems. That’s where the big tech companies stepped in.\n\nHarry Davies: There was a huge surge in demand – not just for the storage capacities of the tech companies, but also for the products that they offer to analyze the information used to prosecute a war. What’s valuable for the military is the way in which these services are able to provide what’s known as “blob storage”, which allows them to store and process infinite amounts of raw intelligence information.\n\nWhat has made Israel such an appealing market for these companies?\n\nYuval Abraham: As we reported, the Israeli army has been collecting Palestinian phone calls for a long time. But when you want to collect the phone calls of an entire population every day, and you want to retain those phone calls for long periods of time, you need a lot of storage room and processing power.\n\nIf you remember the [Edward] Snowden revelations, many of them had to do with metadata, which doesn’t weigh a lot. But the Israeli military also wanted to store mass audio files, images or videos – and for that it felt it needed the assistance of companies like Microsoft. In the West Bank, sources have told us this information has been used to find dirt on people to blackmail them. In the Gaza Strip, we know that this massive trove of intercepted phone calls was also used in airstrikes that killed civilians.\n\nSo data is power and data is control. And these American cloud providers allow the Israeli military to store a lot of data and to sift through it very effectively. That has direct consequences for people on the ground.\n\nIf you have something to share about this story, you can contact Harry Davies and Yuval Abraham using one of the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don’t already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nTo send a message to Harry and Yuval please choose the ‘UK Investigations’ team.\n\nYou can message Harry using the Signal Messenger app. Use the ‘find by username’ option and type hfd.90\n\nIf you don’t need a high level of security or confidentiality you can email harry.davies@theguardian.com\n\nSecureDrop and other secure methods\n\nIf you can safely use the tor network without being observed or monitored you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.\n\nHarry Davies: Yossi Sariel, the former head of [Israel’s elite spy agency] Unit 8200, wrote a book under a pseudonym that we revealed to have been published by him. In that book, he articulated what at the time was a bold and radical vision – as Yuval described, this fetishization of Silicon Valley technology. He recognized the possibilities that the likes of Google, Amazon and Microsoft could afford the Israeli military. Two years before October 7, he said that militaries and governments needed to forge relationships with these companies that are similar to the relationships they have with companies like Boeing and Lockheed Martin. So he was already thinking about these companies as instrumental to war and surveillance in the way that a defense contractor provides components for fighter jets or manufactures bombs and missiles.\n\nSome of our reporting has looked at how elements of his vision have come true and have been put into effect, both before October 7 and afterwards, in both the West Bank and Gaza.\n\nWe know AI is central to Israel’s military operations – its army has developed its own AI capabilities, as you revealed, Yuval, and has also purchased AI tools for use from Microsoft. Why is AI so central to Israel’s broader war aims?\n\nYuval Abraham: What AI did was allow Israel to achieve the effective results of carpet bombing without losing the legitimacy of a data-driven assault with targets and objectives. In Gaza, one way in which the Israeli military used AI was to give a score to almost every person in Gaza who has a phone number, determining how likely it was that person was a member of Hamas or Islamic Jihad. This score was based on a machine-learning algorithm [developed by Israel] called Lavender. It was trained on a dataset of known Hamas members. AI allowed the Israeli military to generate and bomb tens of thousands of military targets, on a scale that without AI would not have been humanly possible. Many of the targets were not Hamas members, according to sources. And Israel for the most part bombed these people not while they were engaged in military activity, but when they stepped inside their families’ homes.\n\nThese AI systems had an error rate that the Israeli military knew about. But to me, the key thing about AI is not the mistakes that it makes. It’s the scale of destruction that it allows militaries to unleash, and it’s a discourse of legitimacy that it enables – a discourse of targets and collateral damage.\n\nAI also seems to me to incentivize mass surveillance, right? Because it allows for the analysis of ever-growing reams of information.\n\nHarry Davies: Signals intelligence agencies have long collected more information than they could humanly process. That served as a kind of restraint on their ability to conduct mass surveillance. I think we’re now seeing a shift where AI allows an intelligence agency like Unit 8200 to make sense of things that previously it struggled to make sense of.\n\nMicrosoft explicitly credited your reporting for changing its policies. Are you seeing any other signs of shifts within the tech industry?\n\nHarry Davies: I think we’re seeing a lot of discomfort and dissent within these companies at both a junior and to some extent senior level. Many employees have been disturbed to find what the products and services that they’re working around the clock to build and market are actually contributing to. There have been protest groups which have emerged from current and former employees within these companies. That’s true across Silicon Valley. I think that played some role in the decision that Microsoft made as a result of our reporting. They were facing a lot of pressure internally.\n\nYuval Abraham: And there’s also a legal question for these companies: if the ICJ [international court of justice] ends up ruling that Israel has committed a genocide, then a follow-up question will be: who contributed to that genocide? Which companies helped maintain it and sustain it? For some people in these companies who are thinking ahead, that could also be a cause for concern.\n\nIt sounds like you think shifts in public support for Israel could actually affect these business relationships.\n\nYuval Abraham: Israel has developed a reliance on these companies for its Nimbus project, which is a huge contract signed between Israel and Google and Amazon back in 2021. It is moving the data of many of its government ministries, along with troves of information from the Ministry of Defense, onto these companies’ cloud servers.\n\nThese are US companies. They’re taking a certain gamble here that the US will stay loyal to Israel and won’t block, limit or sanction them.\n\nMicrosoft only blocked access to technology that was specifically enabling the mass surveillance of Palestinian phone calls – there are still many relationships between Microsoft and the Israeli military. But Microsoft’s action made many people in the Israeli system nervous. It was the first time we know of that a big tech company withdrew services from the Israeli military. It made some people ask whether Israel is making a mistake by giving these foreign companies so much leverage. That question is folded within a larger question of what the US will do, what will happen in 2028 if there’s a more progressive administration in the White House, at a time when so many Americans believe that Israel has committed a genocide in Gaza.\n\nWhat’s your focus going to be in 2026?\n\nYuval Abraham: I think we only uncovered the tip of the iceberg.\n\nHarry Davies: We’re both very conscious that, although we have spent a lot of time working on this, we still just have glimpses inside the system. We’re continuing to build a fuller picture of how this technology was and continues to be used in Gaza and in the West Bank as well.\n\nThere’s good reason to continue paying attention. Militaries pay attention to what other militaries are doing. There is great interest among other western militaries in how Israel prosecuted this war, in how it integrated these kind of technologies.\n\nAnd there are other militaries whose combat systems and processes are already deeply integrated with Silicon Valley tech. Take the American military, for example. Look at what’s happening right now in the Caribbean. Are those operations somehow free of the involvement or reliance on systems and services provided by these companies? I suspect not. We don’t know for sure, but the Pentagon and the US military have very big contracts with all of these companies to provide cloud services. Post-Gaza, we have to look at these relationships and ask: what is the involvement of these companies and their technology in military decisions, in military operations and in warfare more broadly?\n\nYuval Abraham: Much of our reporting is based on whistleblowers, on individuals who are in proximity to power or hold positions of power.\n\nHarry Davies: Our confidential sources have remained confidential and we are always interested in hearing from new people. Our door is always open.\n\nIf you have something to share about this story, you can contact Harry Davies and Yuval Abraham using one of the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don’t already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nTo send a message to Harry and Yuval please choose the ‘UK Investigations’ team.\n\nYou can message Harry using the Signal Messenger app. Use the ‘find by username’ option and type hfd.90\n\nIf you don’t need a high level of security or confidentiality you can email harry.davies@theguardian.com\n\nSecureDrop and other secure methods\n\nIf you can safely use the tor network without being observed or monitored you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 11,
    "keywords": [
      "menu select",
      "platform finally",
      "investigations team",
      "harry.davies@theguardian.com securedrop",
      "select secure",
      "palestinian phone",
      "messenger app",
      "guardian mobile",
      "guardian via",
      "methods secure"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2025/dec/30/israeli-military-big-tech",
    "thumbnail_url": "https://i.guim.co.uk/img/media/afb706b80e1721d0a654718dd2f5e3b3e42f6fae/1_0_3748_3000/master/3748.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f86ea07b9af52e9711540c33d4277d80",
    "created_at": "2025-12-30T18:18:08.193Z",
    "topic": "tech"
  },
  {
    "slug": "ai-memory-demand-propels-kioxia-to-worlds-bestperforming-stock",
    "title": "AI Memory Demand Propels Kioxia to World’s Best-Performing Stock",
    "description": "Artificial intelligence’s insatiable appetite for data storage has delivered Japanese memory chipmaker Kioxia Holdings Corp. world-beating stock gains this year, a sign that the AI boom is alive and well despite recent market jitters.",
    "fullText": "MarketsBy Alice FrenchSaveArtificial intelligence’s insatiable appetite for data storage has delivered Japanese memory chipmaker Kioxia Holdings Corp. world-beating stock gains this year, a sign that the AI boom is alive and well despite recent market jitters.Kioxia’s shares have risen around 540% year-to-date, outperforming all other members of the MSCI World Index and making it the top stock in Japan’s Topix benchmark for 2025. The NAND flash memory maker, which only debuted on the Tokyo Stock Exchange last December, counts Apple Inc. and Microsoft Corp. among its clients and is now worth about ¥5.7 trillion ($36 billion).",
    "readingTime": 1,
    "keywords": [
      "memory",
      "stock",
      "corp"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-30/ai-memory-demand-propels-kioxia-to-world-s-best-performing-stock",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iaHHhfacgmUA/v0/1200x800.jpg",
    "created_at": "2025-12-30T12:23:35.690Z",
    "topic": "finance"
  },
  {
    "slug": "alibaba-abu-dhabi-set-to-invest-in-minimaxs-600-million-ipo",
    "title": "Alibaba, Abu Dhabi Set to Invest in MiniMax’s $600 Million IPO",
    "description": "Chinese artificial intelligence startup MiniMax has secured Alibaba Group Holding Ltd. and Abu Dhabi Investment Authority as key backers in its upcoming initial public offering in Hong Kong, according to people familiar with the matter.",
    "fullText": "MarketsAIBy Dave Sebastian and Luz DingSaveChinese artificial intelligence startup MiniMax has secured Alibaba Group Holding Ltd. and Abu Dhabi Investment Authority as key backers in its upcoming initial public offering in Hong Kong, according to people familiar with the matter. MiniMax is seeking to raise more than $600 million from the IPO, according to the people, who asked not to be identified because the information is private. It is set to start taking investor orders as early as Wednesday for a listing in January, some of them said.",
    "readingTime": 1,
    "keywords": [
      "minimax"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-30/alibaba-abu-dhabi-set-to-invest-in-minimax-s-600-million-ipo",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iKmi9DSGkJYE/v0/1200x800.jpg",
    "created_at": "2025-12-30T12:23:34.870Z",
    "topic": "finance"
  },
  {
    "slug": "ai-adoption-at-scale-is-hard-just-look-at-india-which-processes-about-20-billion-transactions-every-month",
    "title": "AI adoption at scale is hard. Just look at India, which processes about 20 billion transactions every month",
    "description": "The most valuable AI systems will not look dramatic. They will look ordinary. They will fade into routine decisions and familiar processes.",
    "fullText": "Shankar Maruwada is CEO and co-founder of the EkStep Foundation. He was part of the founding team of Aadhaar, India’s digital identity program reaching more than 1.4 billion people, and as Head of Demand Generation and Communication at the Unique Identification Authority of India, he helped drive its national adoption. He has worked with governments and global institutions, including the MIT Media Lab, on population-scale digital systems. \r\n Angela Chitkara is founder of the US–India Corridor, a cross-border advisory firm, and serves on the faculty of Columbia University’s School of International and Public Affairs. She advises companies and institutions on governance, risk and resilience, and workforce transformation, and has worked on India’s Aadhaar project.",
    "readingTime": 1,
    "keywords": [
      "digital",
      "institutions",
      "aadhaar",
      "india’s"
    ],
    "qualityScore": 0.45,
    "link": "https://fortune.com/2025/12/30/ai-adoption-at-scale-is-hard-look-at-india/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1408178671-e1766163041108.jpg?resize=1200,600",
    "created_at": "2025-12-30T12:23:31.240Z",
    "topic": "business"
  },
  {
    "slug": "aipowered-saas-app-etc-idea-validation-system",
    "title": "AI-Powered (SaaS, App, etc.) Idea Validation System",
    "description": "AI-Powered Idea Validator. Contribute to kzeitar/idea-sieve development by creating an account on GitHub.",
    "fullText": "kzeitar\n\n /\n\n idea-sieve\n\n Public\n\n AI-Powered Idea Validator\n\n License\n\n MIT license\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kzeitar/idea-sieve",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/kzeitar/idea-sieve",
    "thumbnail_url": "https://opengraph.githubassets.com/3f824fc0d11b0dfb5688d4de198863ede71f2fba6e35990b89253e5083c8205d/kzeitar/idea-sieve",
    "created_at": "2025-12-30T12:23:30.885Z",
    "topic": "tech"
  },
  {
    "slug": "these-8-big-deals-defined-the-year-in-artificial-intelligence",
    "title": "These 8 big deals defined the year in artificial intelligence",
    "description": "From Disney's $1 billion bet on OpenAI to a wave of blockbuster acquihires, these deals reshaped the tech industry in 2025.",
    "fullText": "While most of the industry was out of office over the holidays, Nvidia and SoftBank's deal teams were grinding.\n\nBoth companies chose the year's quietest stretch to drop news that was anything but: SoftBank said Monday it will acquire digital infrastructure investor DigitalBridge for about $4 billion.\n\nNvidia's move was stranger still. On Christmas Eve, it announced a \"non-exclusive licensing agreement\" with Groq, the startup behind custom chips designed to handle AI inference — the real-time work that powers chatbot replies. The companies did not disclose financial terms.\n\nWhile Nvidia didn't call it an acquisition, the guts of the arrangement looked familiar. Groq founder and CEO Jonathan Ross, along with top engineering staff, will head to Nvidia. Groq, last valued at $6.9 billion in a funding round three months ago, will continue to operate independently.\n\nIt's the latest example of a new kind of tech dealmaking, where the founder and key engineers get bought out, the technology gets siphoned off, and the startup itself is left in limbo.\n\nThat's the vibe of 2025: big, hairy deals that refuse to stay inside the lines.\n\nThe industry's biggest moves weren't just splashy acquisitions or eye-watering funding rounds. (We saw those deals, too.) They were sprawling, hard-to-categorize transactions. Money came tied to compute. Licensing came paired with talent raids. Infrastructure deals locked governments and corporate America into yearslong dependencies. These weren't neat mergers or simple checks. They were power grabs that shifted the balance of Silicon Valley and beyond.\n\nThese were the eight deals that defined the year in AI, ranked from smallest to largest by dollar value.\n\nNvidia ended the year doing the same thing that turned heads all year: extracting founders from their startups and leaving other employees to figure it out.\n\nOn Christmas Eve, Nvidia announced it had entered into a non-exclusive licensing agreement with Groq. The financial terms were undisclosed.\n\nUnder the agreement, Jonathan Ross, Groq's founder and CEO, as well as the startup's president and other team members, will join Nvidia, the world's most valuable company with a market capitalization of over $4.5 trillion.\n\nGroq will continue to operate as an independent company, with CFO Simon Edwards assuming the CEO role.\n\nDisney struck a three-year licensing agreement with OpenAI in December, becoming the first major content partner for Sora, OpenAI's video generator.\n\nThe deal isn't just about rights. Disney will invest $1 billion in OpenAI and receive warrants to buy additional equity — a structure that ties content, distribution, and upside together.\n\nBusiness Insider reporter Lucia Moses argues the logic can be summed up in one word: engagement. Time spent on Disney+ and other major streaming services has remained essentially flat in recent years, she writes, while YouTube and social video continue to grow.\n\nThe OpenAI partnership could help Disney meet audiences where they already are, by allowing fans to use tools like ChatGPT and Sora to generate and remix content featuring Disney characters.\n\nDeveloper coding assistant Windsurf was a startup Cinderella story. Then it became a cautionary tale.\n\nThe company was in talks to sell to OpenAI for $3 billion this past spring. The deal fell apart at the last minute.\n\nGoogle emerged as a new suitor. Instead of an outright acquisition, Google said it would pay $2.4 billion to hire its CEO and top talent, as well as license the company's intellectual property.\n\nThe deal effectively split Windsurf into two pieces, with the hundreds of remaining employees ending up at Cognition, another AI coding startup. That left some with a bitter taste.\n\nPart of the social contract in startups is that early employees work long hours at lower pay in the hope that they will share in the riches should their startup eventually get acquired or go public.\n\nNow, traditional acquisitions have become rarer because of the time and uncertainty of getting regulatory approval. As a result, companies like Google, Microsoft, and Meta have been getting creative, using licensing deals to skirt regulators and snap up key talent.\n\nSoftBank snapped up a private equity firm with the ultimate goal of controlling more of the physical infrastructure behind AI.\n\nOn Monday, SoftBank said it has entered into an agreement to acquire DigitalBridge, an alternative asset manager that invests in data centers, cell towers, fiber networks, and power that make the AI boom possible.\n\nThe transaction is expected to close in the second half of 2026, subject to regulatory approvals.\n\nThe deal comes as SoftBank reshuffles its portfolio. In November, the company said it had sold nearly $6 billion of Nvidia stock to free up cash for OpenAI. SoftBank is also doubling down on \"physical AI,\" building a robotics beachhead with a dedicated investment arm and a pending deal to buy ABB's robotics business.\n\nThe Trump administration agreed to take a 9.9% stake in Intel in August. It was a rare moment when Washington wasn't just regulating an industry or subsidizing it, but buying into it.\n\nUnder the terms Intel disclosed, the government will invest $8.9 billion for 433.3 million shares, and the stake is to be passive, with no board seat.\n\nThe investment aims to bolster domestic capacity for designing and manufacturing advanced chips. Intel has seen foreign competitors, such as Taiwan Semiconductor Manufacturing Company, cut into its market share of advanced chips. The White House has said it is a national security risk if industries continue to import the vast majority of advanced chips from overseas.\n\nThis also likely won't be the last deal of its kind. President Donald Trump and top aides have floated the idea of doing similar deals with American defense contractors and have considered a sovereign wealth fund.\n\nOne of the year's biggest deals sparked the question: Was Meta really spending $14 billion to hire a 28-year-old?\n\nAlexandr Wang cofounded and ran Scale AI, the data-labeling company that helps enterprises train and deploy AI models by supplying high-quality training data and tooling. In June, Meta agreed to pay $14.3 billion for a 49% stake in Scale AI — and, just as importantly, to bring Wang in to lead its next act in AI.\n\nWang became Meta's chief AI officer and the public face of its superintelligence push, with a mandate that goes well beyond building better chatbots. His job is to convince elite researchers that Meta is the place to do their life's work — and to turn the company's key advantage, its compute budget, into a lasting edge.\n\nWhen Google agreed to buy Israeli-American cloud security firm Wiz earlier this year, it threw a $32 billion bucket of water on the idea that the mega-deal drought would persist.\n\nIn March, Google agreed to acquire the startup at an all-cash price roughly equal to Iceland's gross domestic product last year, pending regulatory sign-off. This marks the search giant's largest acquisition.\n\nThe acquisition served as an early litmus test of the Trump administration's willingness to greenlight pricey Big Tech mergers and acquisitions. The deal passed an antitrust review by the Department of Justice in November, clearing a key hurdle to closing.\n\nTrump kicked off his second term by unveiling a joint venture with OpenAI, Oracle, and SoftBank to build a chain of data centers across the US — a project called Stargate that aims to invest $500 billion in domestic infrastructure by 2029.\n\nIn Abilene, Texas, a flagship data center has already opened. Construction crews have broken ground on Stargate sites in Lordstown, Ohio, and Port Washington, Wisconsin, with several more campuses to come.\n\nTo make the ongoing buildout a success, OpenAI CEO Sam Altman has estimated it could take one-fifth of the nation's existing skilled trade workforce.",
    "readingTime": 7,
    "keywords": [
      "christmas eve",
      "jonathan ross",
      "google agreed",
      "advanced chips",
      "non-exclusive licensing",
      "licensing agreement",
      "scale ai",
      "deal",
      "deals",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/biggest-ai-deals-acquisitions-of-the-year-2025-12",
    "thumbnail_url": "https://i.insider.com/6952eb6d64858d02d2177f24?width=1200&format=jpeg",
    "created_at": "2025-12-30T12:23:30.599Z",
    "topic": "finance"
  },
  {
    "slug": "google-ai-overviews-had-the-last-laugh-this-year-my-big-glue-pizza-moment-is-no-more",
    "title": "Google AI Overviews had the last laugh this year. My big 'glue pizza' moment is no more.",
    "description": "Google's AI told me to make pizza with glue in 2024, so I tried it. Zing! But this year, Google got the last laugh. AI overviews are pretty good.",
    "fullText": "It truly brings me no joy to admit this, but now that it's the end of 2025, I can see that Google's AI Overviews, for as much as I goofed on them for being clumsy and bad, are having the last laugh.\n\nThis realization comes after, in 2024, I totally dunked on Google after its AI told me to use glue to help cheese stick to pizza. So, in a moment of internet infamy, I did just that: I made my glue pizza, and even ate a piece.\n\nThe other day, my editor and I were discussing the state of the AI Overviews. We thought the overviews were pretty abysmal at the start of the year — but we now admit to each other that we use them — instead of traditional search — a lot of the time these days.\n\nOf course, the fact that people (such as myself) are willing to use the AI Overview answer in Google instead of clicking on a link and sending traffic to a website that perhaps employs humans to make that content (such as myself) is not necessarily great.\n\nGoogle AI Overviews launched in the spring of 2024, and immediately, people noticed they often, uh, sucked. The answers they gave were full of absurd inaccuracies.\n\nOne example that went viral on social media was its answer for how to stop the cheese from sliding off your pizza — Google AI suggested adding glue to the sauce, which it seemed to have lifted from a joke on Reddit.\n\nAs a journalist with a commitment to seeking the truth, I actually made a pizza with glue in the sauce and ate it (I'm a trained professional idiot; don't try this at home).\n\nThis year, people noticed that Google AI Overviews still were full of problems. One particularly amusing issue was what we'll call the \"You can't lick a badger twice\" problem: give it a nonsense phrase, and it would accept this as a real idiom and try to explain it.\n\nSomeone on Threads noticed you can type any random sentence into Google, then add “meaning” afterwards, and you’ll get an AI explanation of a famous idiom or phrase you just made up. Here is mine\n\n[image or embed]\n\nTo test more, I made up a few of my own fake idioms like \"you can't fit a duck in a pencil\" and \"the road is full of salsa,\" and indeed, AI Overviews gave explanations for what those phrases meant. Here's what I wrote at the time, back in April:\n\nBut things are getting better. When I tried a fake idiom just the other day (\"you can't tell a yak not to dance\"), it gave a more reasonably accurate answer that it was \"not a common, established idiom, but rather a playful or poetic expression,\" and suggested potential interpretations. Fair enough.\n\nGoogle AI Overviews are getting less laughably bad, and just, well … useful.\n\nI've gotten more used to seeing them, and as I get used to them, I've also gotten better at predicting if the type of query I'm posing is the kind of thing an AI Overview can answer. And it's working more often than it isn't.",
    "readingTime": 3,
    "keywords": [
      "google ai overviews",
      "ai overview",
      "glue",
      "pizza",
      "idiom",
      "noticed",
      "can't",
      "admit",
      "it's",
      "cheese"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-overviews-search-answers-improved-why-explained-2025-12",
    "thumbnail_url": "https://i.insider.com/6949bbc264858d02d2174850?width=1200&format=jpeg",
    "created_at": "2025-12-30T12:23:30.446Z",
    "topic": "finance"
  },
  {
    "slug": "i-work-in-tech-sales-and-use-ai-every-day-but-i-dont-want-everyone-knowing-my-secrets-of-how-i-use-it",
    "title": "I work in tech sales and use AI every day — but I don't want everyone knowing my secrets of how I use it",
    "description": "Antoine Wade said everyone has the same amount of time in a day to learn about AI tools, and in this moment, everyone is competing.",
    "fullText": "This as-told-to essay is based on a conversation with Antoine Wade, a tech sales employee who is based in San Antonio. His identity and employment have been verified by Business Insider. The following has been edited for length and clarity.\n\nI started to use AI around 2022 when ChatGPT first launched. It was unlike any technology that I've come across and I started to leverage it in my personal and professional life.\n\nInitially, it helped me craft emails. I work in tech sales and I have to do a lot of cold outreaches. My job is to write messages that resonate with various leaders and ChatGPT helped me with that.\n\nOnce I started using it at work, I realized that as a sports coach and father, there was so much more I could use it for, like sending post-practice communication to parents, building schedules, or putting together statistics of how the game went. Tasks that used to take me days took me literal minutes.\n\nNow I use AI everyday, and I've experimented with different tools. I use Claude to help with business communication and content generation. I use Perplexity for deep research, and Gemini for image generation. I use these tools for a combination of personal, professional, and educational use-cases. I've learned how to install an air conditioner and how to teach my son 6th grade math.\n\nMy company has also given me access to tools that have been really powerful in sales. It can help with gaining a better understanding of the customer in a minute's notice.\n\nFor example, tools like Salesforce Sales Navigator can pinpoint almost the exact person that may be looking for the product I'm selling. Now when I reach out to that person, the conversation will be more fruitful than it would if it were a completely random cold call.\n\nAI hasn't helped me close deals — I'm the one that's built those relationships with customers — but I've seen an increase in my pipeline because I'm able to reach more clients with the data and messaging.\n\nWhen I'm able to understand the customer better, I'm able to communicate more effectively, which leads to building a better pipeline, which ultimately leads to making more money.\n\nWhile people may have access to the same tools, it's still up to the user to put the data together and craft the right prompts. I've been experimenting with so many automation tools that I've developed a secret sauce.\n\nIf I'm creating prompts that give me a better message, which leads to a better outcome, I may not share it with others because I want to see if it works and if it's going to give me a competitive advantage.\n\nWe all have the same amount of time in a day to learn these things. So if I'm putting more time toward learning more about prompt engineering or how AI is supposed to work, then I don't necessarily want to share those learnings with someone else. In this moment, we're all competing.\n\nI will absolutely help someone if they ask, but there are certain details I'm not as forthcoming about. I may share some of those learnings with some of my closest friends or people I feel I can learn from, but that doesn't mean I'm sharing it with everybody.\n\nSales is very competitive and while companies are choosing to have conversations around AI, some people may not be as comfortable sharing how they're leveraging it because that may be their competitive advantage.\n\nWhen people ask if I use AI, I say \"absolutely, yes.\" But there's only a certain amount of people that I'm going into a deeper conversations about AI with.",
    "readingTime": 4,
    "keywords": [
      "competitive advantage",
      "tech sales",
      "i've",
      "tools",
      "leads",
      "based",
      "conversation",
      "chatgpt",
      "personal",
      "professional"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-sales-worker-explains-why-he-limits-details-about-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/69444b8b832e0ef1ead67ee5?width=1024&format=jpeg",
    "created_at": "2025-12-30T12:23:30.281Z",
    "topic": "finance"
  },
  {
    "slug": "aigenerated-content-in-wikipedia-a-tale-of-caution-video",
    "title": "AI-generated content in Wikipedia – a tale of caution [video]",
    "description": "I successfully failed with a literature related project and accidentally built a ChatGPT detector. Then I spoke to the people who uploade...",
    "fullText": "I successfully failed with a literature related project and accidentally built a ChatGPT detector. Then I spoke to the people who uploaded ChatGPT generated content on Wikipedia.\n\nIt began as a standard maintenance project: I wanted to write a tool to find and fix broken ISBN references in Wikipedia. Using the built-in checksum, this seemed like a straightforward technical task. I expected to find mostly typos. But I also found texts generated by LLMs. These models are effective at creating plausible-sounding content, but (for now) they often fail to generate correct checksums for identifiers like ISBNs. This vulnerability turned my tool into an unintentional detector for this type of content. This talk is the story of that investigation. I'll show how the tool works and how it identifies this anti-knowledge. But the tech is only half the story. The other half is human. I contacted the editors who had added this undeclared AI content. I will talk about why they did it and how the Wikipedians reacted and whether \"The End is Nigh\" calls might be warranted.\n\nLicensed to the public under http://creativecommons.org/licenses/by/4.0\n\nThis Talk was translated into multiple languages. The files available\nfor download contain all languages as separate audio-tracks. Most\ndesktop video players allow you to choose between them.\n\nPlease look for \"audio tracks\" in your desktop video player.",
    "readingTime": 2,
    "keywords": [
      "content",
      "tool",
      "project",
      "chatgpt",
      "detector",
      "generated",
      "half",
      "languages",
      "desktop",
      "talk"
    ],
    "qualityScore": 0.95,
    "link": "https://media.ccc.de/v/39c3-ai-generated-content-in-wikipedia-a-tale-of-caution",
    "thumbnail_url": "https://static.media.ccc.de/media/congress/2025/1652-13468ffb-06e8-53ca-9e7c-3cfa56cd44af_preview.jpg",
    "created_at": "2025-12-30T12:23:29.792Z",
    "topic": "tech"
  },
  {
    "slug": "move-fast-break-stuff-how-tech-bros-became-hollywoods-goto-baddie-in-2025",
    "title": "‘Move fast, break stuff’: how tech bros became Hollywood’s go-to baddie in 2025",
    "description": "From Stanley Tucci’s imperious tech titan to Lex Luthor’s distractingly hot CEO and Elon Musk-esque blowhards, films this year took us inside the billionaire mindset\nBetween the slash-and-burn US government reboot led by a dank meme fan and the relentless pushing of AI by venture capital-backed blowhards, 2025 has felt like peak obnoxious tech bro. Fittingly, jargon-spouting, self-regarding digital visionaries also became Hollywood’s go-to baddies this year in everything from blockbusters to slapstick spoofs. Spare a thought for the overworked props departments tasked with mocking up fake Forbes magazine covers heralding yet another smirking white guy as “Master of the Metaverse” or whatever.\nWith such market saturation, the risk is that all these delusional dudes blend into one smarmy morass. It felt reasonable to expect that Stanley Tucci might sprinkle a little prosciutto on The Electric State, Netflix’s no-expense-spared alt-history robot fantasia.",
    "fullText": "From Stanley Tucci’s imperious tech titan to Lex Luthor’s distractingly hot CEO and Elon Musk-esque blowhards, films this year took us inside the billionaire mindset\n\nBetween the slash-and-burn US government reboot led by a dank meme fan and the relentless pushing of AI by venture capital-backed blowhards, 2025 has felt like peak obnoxious tech bro. Fittingly, jargon-spouting, self-regarding digital visionaries also became Hollywood’s go-to baddies this year in everything from blockbusters to slapstick spoofs. Spare a thought for the overworked props departments tasked with mocking up fake Forbes magazine covers heralding yet another smirking white guy as “Master of the Metaverse” or whatever.\n\nWith such market saturation, the risk is that all these delusional dudes blend into one smarmy morass. It felt reasonable to expect that Stanley Tucci might sprinkle a little prosciutto on The Electric State, Netflix’s no-expense-spared alt-history robot fantasia. As Ethan Skate – creator of the “neurocaster” technology that quashed an AI uprising then turned the general populace into listless virtual-reality addicts – Tucci certainly looked the part: bald and imperious in retro Bond villain wardrobe. But even the great cocktail-maker couldn’t squeeze much out of sour existential proclamations such as: “Our world is a tyre fire floating on an ocean of piss.”\n\nThere was more baldness in Superman, where Nicholas Hoult’s Lex Luthor embodied the worst kind of wannabe paradigm-changer: one desperate to appear on talkshows. Incensed that the world seemed to be ignoring his genius in favour of a flying alien do-gooder, the LuthorCorp founder spent a fortune to rig social media, deploying an army of vivisected monkey cyborgs to swamp platforms with anti-Superman hashtags and memes. That the film itself was met with farmed outrage about perceived wokeness added a disconcerting hall-of-mirrors feel to what was essentially an overstuffed crowdpleaser. Hoult’s Lex was also a distractingly hot tech CEO, which pushed the film further into the realm of fantasy.\n\nIs it more appealing when these self-regarding douchebags are funny? In the heightened world of killer doll action thriller M3gan 2.0, Jemaine Clement was sleazily overconfident as Alton Appleton, a high-functioning billionaire whose latest wheeze was pushing an unwanted neural implant on the masses. Seduced by an impassive fembot assassin, Alton was humiliated in his final moments, his signature Altwave tech effortlessly hacked, his weird prosthetic six-pack coming unstuck. It was pathetic but humanising. As the movie trundled on, you actually began to miss him.\n\nIf Clement nailed tech bro obliviousness, Danny Huston had to remain deadpan opposite Liam Neeson’s blathering Frank Drebin Jr in The Naked Gun reboot. Huston’s Richard Cane was a hybrid Jeff Bezos/Elon Musk-esque blowhard who used the galactic profits from his online retail and electric car empires to make a Primordial Law of Toughness device . His master plan was to zap the general public back to a prehistoric mindset, violently culling the herd and ushering in a new age for humankind (or at least his zillionaire class). Cane was obsessed with men’s sperm counts, building luxury bunkers for the super-rich and Black Eyed Peas. In other words: truly psychotic.\n\nIn the goopy, grungy world of The Toxic Avenger reboot, Kevin Bacon’s floppy-haired biotech baddie Bob Garbinger stood out simply because he looked so pale and pampered. While it’s not a great sign when a self-proclaimed “healthstyle” guru gets Sisyphus and syphilis mixed up, Garbinger’s habit of going shirtless while flogging “proprietary cutting-edge bio-boosters” in TV ads felt like a timely skewering of immortality-seeking biohackers such as Bryan Johnson.\n\nIn 2022, Evan Peters played the lead in Netflix’s ghoulish Monster: The Jeffrey Dahmer Story. Did that influence his casting as a second-generation nepo baby in Tron: Ares? To be fair, his Julian Dillinger – grandson of David Warner’s boardroom bully from the original 1982 Tron – seemed more neurotic than psychotic: a baby-faced tech huckster with crappy circuit board sleeve tattoos whose audacious move into 3D-printing wicked neon war machines and digital commandos was only slightly scuppered by the fact that they imploded within 30 minutes. A wildly expensive, resource-intensive, essentially useless product? Intentionally or not, it felt like an appropriate metaphor for the AI bubble.\n\nBut why stop at just one douchey tech bro? Jesse Armstrong’s jagged satire Mountainhead took the bold step of making every single character the absolute worst of the “move fast, break stuff” billionaire mindset, isolating them – and the viewer – in a remote, repellently deluxe ski lodge while the spectre of possible Armageddon encroached. As the Musk-alike owner of a social media app spreading dangerous AI-augmented misinformation, Cory Michael Smith captured the glib, morality-agnostic tone of someone richer than God who views the world as their plaything.\n\nAs Venis (Smith), silverback investor Randall (Steve Carell), canny algorithm tamer Jeff (Ramy Youssef) and would-be wellness app supremo Souper (Jason Schwartzman) relentlessly needled each other, there was the illicit thrill of dialling into the combative quartet’s inside-baseball repartee of boasting, toasting and roasting. But as the globe lurched further into chaos, watching these four nominal thought leaders clumsily workshop how best to exploit the situation was depressing, not least because it seemed so plausible. We have all been forced to absorb the pathologies of our tech overlords due to their disproportionate influence in the real world. As a new cinema year looms, is it too much to ask that we don’t have to keep doing it at the movies too?",
    "readingTime": 5,
    "keywords": [
      "distractingly hot",
      "social media",
      "billionaire mindset",
      "tech bro",
      "reboot",
      "imperious",
      "blowhards",
      "pushing",
      "self-regarding",
      "digital"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/film/2025/dec/30/move-fast-break-stuff-how-tech-bros-became-hollywoods-go-to-baddie-in-2025",
    "thumbnail_url": "https://i.guim.co.uk/img/media/2e310930424e5c4e792e6199e158f2bdd38e6a3a/366_37_1554_1243/master/1554.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8c69488d9e1641de08451c73432552d2",
    "created_at": "2025-12-30T12:23:29.236Z",
    "topic": "entertainment"
  },
  {
    "slug": "crimson-yc-x25-is-hiring-founding-engineers-in-london",
    "title": "Crimson (YC X25) is hiring founding engineers in London",
    "description": "Crimson is the AI platform for high-stakes litigation. We're working with top law firms in the UK and US to streamline how complex disputes are run. Our platform drafts pleadings and submissions, analyzes judgments and orders, summarizes transcripts and locates key evidence in seconds.\nWe're a team of three co-founders with deep technical and domain expertise. Our users are lawyers who trust us with their most sensitive case files.",
    "fullText": "Crimson is the AI platform for high-stakes litigation. We're working with top law firms in the UK and US to streamline how complex disputes are run. Our platform drafts pleadings and submissions, analyzes judgments and orders, summarizes transcripts and locates key evidence in seconds.\n\nWe're a team of three co-founders with deep technical and domain expertise. Our users are lawyers who trust us with their most sensitive case files. They care about security, accuracy, reliability and speed, and so do we.\n\nWe're looking for an exceptional full-stack engineer to join us as one of our first employees. You'll ship production code from day one and own major features end-to-end. That means talking to users, scoping the problem, building the solution and improving it over time.",
    "readingTime": 1,
    "keywords": [
      "we're",
      "platform",
      "users"
    ],
    "qualityScore": 0.55,
    "link": "https://www.ycombinator.com/companies/crimson/jobs/kCikzj1-founding-engineer-full-stack",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/2fddf31b1d6b13bc458368ca9968ebc9c7807938.png?1745298027",
    "created_at": "2025-12-30T12:23:28.741Z",
    "topic": "jobs"
  },
  {
    "slug": "well-use-ai-to-help-gb-athletes-win-medals-says-uk-sport-chair",
    "title": "We’ll use AI to help GB athletes win medals, says UK Sport chair",
    "description": "Great Britain's Olympic and Paralympic teams are going to need to harness AI and work together more closely in order to continue their success at recent Games, UK Sport chairman Nick Webborn says.",
    "fullText": "Great Britain's Olympic and Paralympic teams are going to need to harness artificial intelligence and work together more closely in order to continue their success at recent Games, UK Sport chairman Nick Webborn says.\n\nIn his first interview since taking up the role, the head of the elite sport funding agency told BBC Sport: \"We've been a really successful nation, and to maintain that position or to even go higher, we're going to have to do things differently.\n\n\"It's about how we think smarter now, how we utilise things like AI appropriately in sport, how we work together as different sports bodies, rather than in silos.\n\n\"I think we're now in a frame of mind where we're united and moving together, that sharing of information between sports is happening much more than ever before.\n\n\"And we're going to need to do that to maintain ourselves in our position on the medal table.\"\n\nThis year, UK Sport announced British athletes would be offered a new form of AI-based protection from online abuse, and Webborn wants the technology to help with talent ID, injury prevention and remote classification assessments in Paralympic sport.\n\nTeam GB's 65 medals at the last summer Olympics at Paris 2024 equalled their haul at London 2012.\n\nHowever, their tally of 14 gold medals saw them drop from fourth to seventh place in the medal table, their lowest position for 20 years.\n\n\"We want to continue to punch above our weight. We always have done,\" says Webborn.\n\n\"And it's those little things, how we convert those silvers into gold, that just push you up that medal table a little bit higher.\n\n\"The Paralympic team have been brilliant, they've been second in the medal table behind China for the last several Games, but other nations are pushing them. But I believe the character and the innovation that we have in the UK will continue to keep us there.\n\n\"The collaboration between Olympic and Paralympic sports has never been better. You can definitely see that in the discussions that they're having. We're learning from each other.\"\n\nUK Sport has not yet revealed a medal target for the upcoming Winter Games in Milan and Cortina in Italy, but Webborn is optimistic.\n\n\"The current group of athletes are having some amazing success in this early season, it's great to see. That doesn't always transfer into medals at the Games, but we're in a really good place,\" he says.",
    "readingTime": 3,
    "keywords": [
      "medal table",
      "uk sport",
      "we're",
      "together",
      "position",
      "it's",
      "sports",
      "medals",
      "success",
      "maintain"
    ],
    "qualityScore": 0.9,
    "link": "https://www.bbc.com/sport/olympics/articles/cx2e280ppp6o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/142d/live/34614bc0-e563-11f0-baf8-492205ca0c9f.jpg",
    "created_at": "2025-12-30T12:23:28.266Z",
    "topic": "sports"
  },
  {
    "slug": "the-arr-illusion-in-the-age-of-ai",
    "title": "The ARR Illusion in the Age of AI",
    "description": "This article examines why the practice of AI startups disguising GMV as ARR distorts business sustainability. It redefines the true meaning of ARR and analyzes how the revenue structure of many AI companies resembles a brokerage or reseller model rather than SaaS. Using the analogy of investors who only inflate transaction volume, it presents—from a consulting perspective—why repeatability, margins, and control are far more critical than the magnitude of the numbers.",
    "fullText": "In recent feeds and headlines covering AI startups, a certain phrase repeats with exhausting frequency:\n\"Reached $X million ARR in just n months.\"\n\nAt first, it is impressive.\nThe second time, it invites skepticism.\n\nThis is not merely a matter of accounting tricks or semantic hair-splitting.\nIt is a fundamental question about the structure of AI businesses, their sustainability, and how we ought to interpret the numbers presented to us.\n\nARR stands for Annual Recurring Revenue.\nThe two operative words here carry weight.\n\nThese are run-rates.\nARR is not a prediction; it is a result verified by time.\n\nFundamentally,\nFor a company less than a year old to claim ARR is, conceptually, a contradiction.\n\nThe year has not passed.\nThe recurrence has not been proven.\n\nARR is the lingua franca of SaaS.\nAnd the language of SaaS invariably connotes:\n\nThus, many AI companies,\neven those far from reaching that stage,\nborrow the term ARR to describe their finances.\n\nThe problem begins exactly there.\n\nPeer slightly beneath the surface of many AI startup revenue structures, and a pattern emerges.\n\nIn this structure, the portion the company actually retains is but a fraction of the total payment.\n\nHere, the correct concept is GMV (Gross Merchandise Value).\n\nGMV represents the total value of merchandise sold through a platform.\nThe critical distinction is this:\n\nIf a platform mediates a transaction and takes a commission,\nGMV ≠ Revenue.\n\nThe illusion specific to the AI industry arises here.\n\nOn the surface, it mimics SaaS perfectly.\n\nIn this structure, calling GMV \"ARR\" is,\nAn act of consuming an unproven future as a present achievement.\n\nTo put it more bluntly,\nit borders on a bluff designed to induce a financing illusion.\n\n\"Model costs are dropping, so even if margins are thin now, they will improve.\"\n\nThis statement is only half true.\n\nTechnology costs do decrease.\nHowever, demand always migrates to the newest, most powerful models.\n\nOf course, low-cost models have their place—simple tasks, non-competitive domains.\n\nBut the question remains:\nIs the product you are building truly that kind of product?\n\nWe are cognitively greedy.\nGiven the same time and money, we desire the smarter brain.\n\nUltimately, the discussion boils down to one thing.\n\nNeither is inherently right or wrong.\nBut how they are valued must be completely different.\n\nA large GMV does not equate to a solid foundation.\n\nThe spectacle of GMV-first growth often reminds me of a familiar scene.\n\nThe investor with $10,000 of capital,\nwho trades dozens of times a day,\nboasting, \"I moved millions in transaction volume this month.\"\n\nThe trades are many.\nThe numbers are large.\nBut what actually remains?\n\nMostly transaction fees paid to the exchange.\nThe volume swells, but the asset base barely moves.\n\nAI startups obsessed with GMV are not so different.\n\nBut the vast majority of that flow\npasses through to model providers and infrastructure giants,\nleaking straight out of the building.\n\nTo discuss GMV as if it were ARR in this context is\nnot a demonstration of capital control,\nbut rather an attempt to prove competence via the sheer volume of money that passed through one's hands.\n\nFrom a consulting perspective, the questions are simple.\n\nARR is not a marketing slogan.\nIt is a report card proving that a financial structure has withstood the test of time.\n\nGMV can be a signal of growth.\nBut it is, at best, a process metric.\nIt cannot substitute for the foundation.\n\nIn the AI era, numbers have become larger and faster.\nThat is precisely why we must be more honest with our terminology.\n\nThe moment you slap the label of ARR onto GMV,\nthe business begins to look solid,\nbut in reality, it is being built on sand.\n\nTime will eventually reveal the truth.\nWhether you were a company that made many trades,\nor a company that accumulated value.\n\nTime always distinguishes the two.",
    "readingTime": 4,
    "keywords": [
      "structure",
      "numbers",
      "transaction",
      "trades",
      "volume",
      "startups",
      "surface",
      "merchandise",
      "platform",
      "illusion"
    ],
    "qualityScore": 1,
    "link": "https://oswarld.com/eng/insight/250816_ai-arr-illusion-gmv-vs-arr",
    "thumbnail_url": "https://oswarld.com/images/Thumbnail/OBF_insight_2025-08-16.jpg",
    "created_at": "2025-12-30T12:23:27.391Z",
    "topic": "tech"
  },
  {
    "slug": "datavault-ai-to-showcase-wireless-audio-and-data-technologies-at-ces",
    "title": "Datavault AI to showcase wireless audio and data technologies at CES",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/datavault-ai-to-showcase-wireless-audio-and-data-technologies-at-ces-93CH-4425229",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2025-12-30T12:23:27.248Z",
    "topic": "finance"
  },
  {
    "slug": "i-work-in-tech-sales-and-use-ai-every-day-but-i-dont-want-everyone-knowing-my-secrets-of-how-i-use-it",
    "title": "I work in tech sales and use AI every day — but I don't want everyone knowing my secrets of how I use it",
    "description": "Antoine Wade said everyone has the same amount of time in a day to learn about AI tools, and in this moment, everyone is competing.",
    "fullText": "Antoine Wade, a tech sales employee, uses AI daily for personal and professional tasks.\n\nHe said AI has helped him grow his pipeline by letting him communicate more effectively and understand customers better.\n\nHe said he keeps some of his AI strategies private to maintain a competitive advantage in sales.\n\nThis as-told-to essay is based on a conversation with Antoine Wade, a tech sales employee who is based in San Antonio. His identity and employment have been verified by Business Insider. The following has been edited for length and clarity.\n\nI started to use AI around 2022 when ChatGPT first launched. It was unlike any technology that I've come across and I started to leverage it in my personal and professional life.\n\nInitially, it helped me craft emails. I work in tech sales and I have to do a lot of cold outreaches. My job is to write messages that resonate with various leaders and ChatGPT helped me with that.\n\nOnce I started using it at work, I realized that as a sports coach and father, there was so much more I could use it for, like sending post-practice communication to parents, building schedules, or putting together statistics of how the game went. Tasks that used to take me days took me literal minutes.\n\nNow I use AI everyday, and I've experimented with different tools. I use Claude to help with business communication and content generation. I use Perplexity for deep research, and Gemini for image generation. I use these tools for a combination of personal, professional, and educational use-cases. I've learned how to install an air conditioner and how to teach my son 6th grade math.\n\nMy company has also given me access to tools that have been really powerful in sales. It can help with gaining a better understanding of the customer in a minute's notice.\n\nFor example, tools like Salesforce Sales Navigator can pinpoint almost the exact person that may be looking for the product I'm selling. Now when I reach out to that person, the conversation will be more fruitful than it would if it were a completely random cold call.\n\nAI hasn't helped me close deals — I'm the one that's built those relationships with customers — but I've seen an increase in my pipeline because I'm able to reach more clients with the data and messaging.\n\nWhen I'm able to understand the customer better, I'm able to communicate more effectively, which leads to building a better pipeline, which ultimately leads to making more money.\n\nWhile people may have access to the same tools, it's still up to the user to put the data together and craft the right prompts. I've been experimenting with so many automation tools that I've developed a secret sauce.\n\nIf I'm creating prompts that give me a better message, which leads to a better outcome, I may not share it with others because I want to see if it works and if it's going to give me a competitive advantage.\n\nWe all have the same amount of time in a day to learn these things. So if I'm putting more time toward learning more about prompt engineering or how AI is supposed to work, then I don't necessarily want to share those learnings with someone else. In this moment, we're all competing.\n\nI will absolutely help someone if they ask, but there are certain details I'm not as forthcoming about. I may share some of those learnings with some of my closest friends or people I feel I can learn from, but that doesn't mean I'm sharing it with everybody.\n\nSales is very competitive and while companies are choosing to have conversations around AI, some people may not be as comfortable sharing how they're leveraging it because that may be their competitive advantage.\n\nWhen people ask if I use AI, I say \"absolutely, yes.\" But there's only a certain amount of people that I'm going into a deeper conversations about AI with.",
    "readingTime": 4,
    "keywords": [
      "wade tech",
      "competitive advantage",
      "tech sales",
      "sales employee",
      "antoine wade",
      "i've",
      "tools",
      "personal",
      "professional",
      "pipeline"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/chatgpt/articles/tech-sales-ai-every-day-105101257.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/2E916F82D011D6C8115FD6240BBA41251C20249B2A126BA318319D26766A452A/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fmedia.zenfs.com%2Fen%2Fbusiness_insider_articles_888%2F9c6696764c0d5e32fc464e2843315888",
    "created_at": "2025-12-30T12:23:24.831Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-considering-a-raft-of-new-controls-for-training-ai-on-chat-log-data-heres-what-it-means",
    "title": "China is considering a raft of new controls for training AI on chat log data. Here's what it means.",
    "description": "China is weighing new controls on AI training, requiring consent before chat logs can be used to improve chatbots and virtual companions.",
    "fullText": "China is moving to tighten one of the most common ways AI systems improve: Learning directly from conversations with users.\n\nThe Cyberspace Administration of China said in a statement published Saturday that it has drafted measures that would restrict how AI platforms can collect and use chat logs for model training.\n\nThe proposal aims to ensure that \"human-like\" interactive AI services, including chatbots and virtual companions, are safe and secure for users, the statement said.\n\nChina encourages innovation in \"human-like\" interactive AI, but will pair that with governance and prudent, tiered supervision to \"prevent abuse and loss of control,\" it added.\n\nUnder the draft rules, platforms would need to inform users when they are interacting with AI and provide options to access or delete their chat history. Using conversation data for model training — or sharing it with third parties — would require explicit user consent, the agency said.\n\nFor minors, providers would need additional consent from a guardian before sharing their conversation data with third parties. Guardians would also have the right to request deletion of a minor's chat history.\n\nThe draft measures are open for public consultation, with feedback due in late January.\n\nIf finalized, the rules could slow the pace at which AI chatbots improve, Lian Jye Su, the chief analyst at Omdia, a technology research and consulting firm, told Business Insider.\n\nRestricting access to chat logs may \"limit the human-feedback mechanisms in reinforcement learning, which has been critical to the rise of engaging and accurate conversational AI,\" Su said.\n\nThat said, China's AI ecosystem is \"robust,\" and the country has access to massive public and proprietary datasets, he added.\n\nSu said the move aligns with Beijing's broader emphasis on national security and the collective public interest. Tightening controls over chat logs signals that certain user conversations are too sensitive to be treated as free training data, he added.\n\nWei Sun, the principal analyst for AI at Counterpoint Research, told Business Insider these provisions \"function less as brakes and more as directional signals.\"\n\n\"The emphasis is on protecting users and preventing opaque data practices, rather than constraining innovation,\" she said.\n\nSun said the draft encourages providers — once safety and reliability are proven — to expand the use of human-like AI across more application areas, including cultural dissemination and companionship for older adults.\n\n\"In the context of a rapidly aging population, they can be read as an explicit policy nudge to accelerate the development of human-like AI interactions in a regulated, socially constructive, and scalable manner,\" she added.\n\nChina's new draft rules on chatlog data come as concerns grow over how AI companies handle deeply personal user conversations.\n\nBusiness Insider reported in August that contract workers employed by Meta and other tech giants can read user conversations with chatbots as part of the process of evaluating AI responses.\n\nSeveral contractors told Business Insider that the material they reviewed contained sensitive details that could be used to identify individual users. Many of the conversations were highly personal, including exchanges that resembled therapy sessions, private chats with close friends, or intimate conversations with romantic partners.\n\nMeta's AI terms of service said that it \"may review\" user chatlogs with its AI products, either through automated systems or human reviewers.\n\nA Meta spokesperson told Business Insider that the company has \"strict policies\" over who can access personal data.\n\n\"While we work with contractors to help improve training data quality, we intentionally limit what personal information they see, and we have processes and guardrails in place instructing them how to handle any such information they may encounter,\" the spokesperson said in the August report.\n\nA Google engineer in AI security told Business Insider earlier this month that there are certain things he would never share with chatbots.\n\n\"AI models use data to generate helpful responses, and we users need to protect our private information so that harmful entities, like cybercriminals and data brokers, can't access it,\" he said.",
    "readingTime": 4,
    "keywords": [
      "third parties",
      "business insider",
      "model training",
      "human-like interactive",
      "chat logs",
      "chat history",
      "draft rules",
      "user conversations",
      "users",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/china-ai-chat-logs-train-models-safety-privacy-2025-12",
    "thumbnail_url": "https://i.insider.com/695346cc04eda4732f2e3bec?width=1200&format=jpeg",
    "created_at": "2025-12-30T06:19:33.570Z",
    "topic": "finance"
  },
  {
    "slug": "dreamworks-ceo-turned-vc-jeff-katzenberg-says-that-ai-is-not-going-to-be-a-zerosum-game",
    "title": "DreamWorks CEO turned VC Jeff Katzenberg says that AI is not going to be a 'zero-sum game'",
    "description": "Bubble or no bubble, AI won't have just one winner, says Jeffrey Katzenberg.",
    "fullText": "Bubble or no bubble, AI won't have just one winner, says Jeffrey Katzenberg.\n\nOn an episode of the \"Sourcery\" podcast released on Monday, the former DreamWorks CEO turned investor said 2026 will sift out companies that are producing real outcomes with AI from those that aren't.\n\n\"Rather than look at it from the sort of extreme notion of what that means for a bubble to burst, I think there'll be a reckoning here in which those that actually are producing real results and are being deployed in really effective and efficient ways,\" he said when asked about whether the AI bubble could pop next year.\n\nHe added: \"It's not going to be a zero-sum game, a winner-take-all. But I also think at the same time, not everybody is going to win at this.\"\n\nKatzenberg served as chairman of Walt Disney Studios for 10 years until 1994 and cofounded DreamWorks after his departure. As DreamWorks' CEO, he oversaw the production of hits like \"Shrek,\" \"Madagascar,\" and \"Kung Fu Panda.\"\n\nHe stepped down in 2016 and cofounded the venture capital firm WndrCo with former Dropbox Chief Financial Officer Sujay Jaswa in 2017. WndrCo's investments include Cursor, Harvey, and Figma.\n\nWndrCo's general partner, ChenLi Wang, also shared on the podcast how he and Katzenberg evaluate startups in the AI era.\n\n\"First, I think through our entire careers pre-WndrCo, Jeffrey's entire career, we've been people people,\" Wang said. \"The ingenuity and creativity of people and how magical their spikes are, and how, when you complement people and what they can create together, is the secret sauce.\"\n\nWang added that he and Katzenberg have never \"assessed our best humans based on benchmarks.\"\n\n\"I mean, how many years have people have parents complained about standardized testing dumbing down their kids,\" Wang said. \"And yet, I think we're going down the same route with the first wave of benchmarks.\"\n\nLike the two partners, research scientists have also criticized benchmarks because they overvalue superficial traits.\n\nIn a March blog post, Dean Valentine, the cofounder and CEO of AI security startup ZeroPath, said that \"recent AI model progress feels mostly like bullshit.\"\n\nValentine said that he and his team had been evaluating the performance of different models claiming to have \"some sort of improvement\" since the release of Anthropic's 3.5 Sonnet in June 2024. None of the new models his team tried had made a \"significant difference\" in his company's internal benchmarks or in developers' abilities to find new bugs, he said.\n\nIn a February paper titled \"Can we trust AI Benchmarks?\" researchers at the European Commission's Joint Research Center found that major issues exist in the current evaluation approach.\n\nThe researchers said that benchmarks \"often prioritize state-of-the-art performance at the expense of broader societal concerns.\"",
    "readingTime": 3,
    "keywords": [
      "bubble",
      "podcast",
      "producing",
      "sort",
      "cofounded",
      "wndrco's",
      "research",
      "team",
      "performance",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/hollywood-vc-jeff-katzenberg-ai-wont-be-zero-sum-game-2025-12",
    "thumbnail_url": "https://i.insider.com/695346b8832e0ef1ead6ede5?width=1200&format=jpeg",
    "created_at": "2025-12-30T06:19:33.569Z",
    "topic": "finance"
  },
  {
    "slug": "powermem-persistent-memory-layer-for-ai-agents",
    "title": "PowerMem – Persistent memory layer for AI agents",
    "description": "PowerMem: Your AI-Powered Long-Term Memory — Accurate, Agile, Affordable.  - GitHub - oceanbase/powermem: PowerMem: Your AI-Powered Long-Term Memory — Accurate, Agile, Affordable.",
    "fullText": "oceanbase\n\n /\n\n powermem\n\n Public\n\n PowerMem: Your AI-Powered Long-Term Memory — Accurate, Agile, Affordable. \n\n www.powermem.ai\n\n License\n\n View license\n\n 198\n stars\n\n 26\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n\n oceanbase/powermem",
    "readingTime": 1,
    "keywords": [
      "powermem",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/oceanbase/powermem",
    "thumbnail_url": "https://opengraph.githubassets.com/d888b399566665cd0d4fa5291ec4243aaab19964dcdb2a4f4a5ed6c2e0c4c877/oceanbase/powermem",
    "created_at": "2025-12-30T06:19:23.194Z",
    "topic": "sports"
  },
  {
    "slug": "meta-to-buy-chinese-startup-manus-to-boost-advanced-ai",
    "title": "Meta to buy Chinese startup Manus to boost advanced AI",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/meta-to-acquire-chinese-startup-manus-to-boost-advanced-ai-features-4424801",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBS0TZ_L.jpg",
    "created_at": "2025-12-30T06:19:18.372Z",
    "topic": "finance"
  },
  {
    "slug": "sandbar-puts-ai-on-your-finger",
    "title": "Sandbar Puts AI on Your Finger",
    "description": "AI wearables have promised a lot — and mostly disappointed. Sandbar’s CEO says this time is different. Mina Fahmi joins us on the Stream Ring, a voice-first AI wearable designed to capture ideas effortlessly — and why the future of AI may finally move beyond the screen.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-29/sandbar-puts-ai-on-your-finger-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iCUMJWmG_DEw/v3/-1x-1.jpg",
    "created_at": "2025-12-30T00:56:49.833Z",
    "topic": "finance"
  },
  {
    "slug": "novi-ceo-on-ai-driven-shopping-trends",
    "title": "Novi CEO on AI Driven Shopping Trends",
    "description": "Kimberly Shenk, CEO of Novi, says the company works with leading retailers to optimize product data for AI driven discovery. She tells Carol Massar on \"Bloomberg Markets\" that brands rely on Novi to help consumers find the right products more easily through AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-29/novi-ceo-on-ai-driven-shopping-trends-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iu6MOcbiFB1g/v3/-1x-1.jpg",
    "created_at": "2025-12-30T00:56:47.929Z",
    "topic": "finance"
  },
  {
    "slug": "ai-defense-and-chip-stocks-fuel-koreas-recordbreaking-year",
    "title": "AI, Defense and Chip Stocks Fuel Korea’s Record-Breaking Year",
    "description": "South Korea’s stock market renaissance in 2025 was one for the history books. From world-beating gains in arms exporters to the eye-popping surge in AI and K-beauty shares, investors were rewarded in a market that reached new highs.",
    "fullText": "TechnologyMarketsBy Youkyung LeeSaveSouth Korea’s stock market renaissance in 2025 was one for the history books. From world-beating gains in arms exporters to the eye-popping surge in AI and K-beauty shares, investors were rewarded in a market that reached new highs. The gains propelled the benchmark Kospi Index up 76% this year, making it the world’s best-performing major gauge. Chip heavyweights Samsung Electronics Co. and SK Hynix Inc. delivered nearly half of the advance, while defense and nuclear firms were also top contributors.",
    "readingTime": 1,
    "keywords": [
      "gains",
      "market"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-29/ai-defense-and-chip-stocks-fuel-korea-s-record-breaking-year",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ir3r4qWwVq7c/v0/1200x800.jpg",
    "created_at": "2025-12-30T00:56:47.297Z",
    "topic": "finance"
  },
  {
    "slug": "ai-drug-firm-insilico-debuts-in-hong-kong-after-293-million-ipo",
    "title": "AI Drug Firm Insilico Debuts in Hong Kong After $293 Million IPO",
    "description": "AI-biotechnology firm Insilico Medicine Cayman TopCo is set to debut in Hong Kong on Tuesday after raising $293 million in its initial public offering.",
    "fullText": "MarketsBy Sangmi Cha and Amber TongSaveAI-biotechnology firm Insilico Medicine Cayman TopCo is set to debut in Hong Kong on Tuesday after raising $293 million in its initial public offering. Priced at HK$24.05 ($3.09) per share, Insilico will list with a market capitalization of about $1.84 billion. Its shares jumped as much as 201% in gray-market trading on Monday.",
    "readingTime": 1,
    "keywords": [
      "insilico"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-30/ai-drug-firm-insilico-debuts-in-hong-kong-after-293-million-ipo",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i7sps3H777UA/v0/1200x800.jpg",
    "created_at": "2025-12-30T00:56:46.855Z",
    "topic": "finance"
  },
  {
    "slug": "ai-power-platform-kraken-valued-at-87-billion-origin-says",
    "title": "AI Power Platform Kraken Valued at $8.7 Billion, Origin Says",
    "description": "Origin Energy Ltd. said Kraken Technologies Ltd., which helps utilities manage the transition to cleaner energy, has been valued at $8.65 billion after the software platform’s first share sale.",
    "fullText": "MarketsBy Keira WrightSaveOrigin Energy Ltd. said Kraken Technologies Ltd., which helps utilities manage the transition to cleaner energy, has been valued at $8.65 billion after the software platform’s first share sale. Kraken is owned by Octopus Energy Group Ltd., in which Origin is a major investor. The artificial intelligence software has been key to Octopus’s rapid growth into the UK’s largest electricity supplier, leapfrogging industry incumbents to serve more than 7 million customers in the country.",
    "readingTime": 1,
    "keywords": [
      "software",
      "energy",
      "kraken"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-29/origin-says-kraken-valued-at-8-65-billion-after-equity-raise",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSiFlph2U068/v1/1200x800.jpg",
    "created_at": "2025-12-30T00:56:45.124Z",
    "topic": "finance"
  },
  {
    "slug": "giselle-opensource-visual-editor-for-building-ai-workflows",
    "title": "Giselle – open-source visual editor for building AI workflows",
    "description": "Giselle: AI App Builder. Open Source. Contribute to giselles-ai/giselle development by creating an account on GitHub.",
    "fullText": "giselles-ai\n\n /\n\n giselle\n\n Public\n\n Giselle: AI App Builder. Open Source.\n\n giselles.ai\n\n License\n\n Apache-2.0 license\n\n 317\n stars\n\n 67\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n giselles-ai/giselle",
    "readingTime": 1,
    "keywords": [
      "giselle",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/giselles-ai/giselle",
    "thumbnail_url": "https://opengraph.githubassets.com/e2841dc552dc9d2c253bfe55f1a98ee7e123db26a0ff9f97a8aac477f11c8711/giselles-ai/giselle",
    "created_at": "2025-12-30T00:56:42.474Z",
    "topic": "tech"
  },
  {
    "slug": "china-wants-to-ban-making-yourself-into-an-ai-to-keep-aged-relatives-company",
    "title": "China wants to ban making yourself into an AI to keep aged relatives company",
    "description": "Asia In Brief: PLUS: Australia buys air-gapped Google Cloud; Huawei triples use of home-built components; JAXA blames low pressure for rocket crash; And more",
    "fullText": "Asia In Brief China’s Cyberspace Administration on Saturday posted draft rules governing the behaviour of AI companions that prohibit using them to serve as friends for the elderly.\n\nThe draft “Interim Measures for the Administration of Humanized Interactive Services Based on Artificial Intelligence” opens with a suggestion that China needs regulations to ensure the healthy development of AIs that “engage in emotional interaction with humans.”\n\nAs is always the case with China’s tech regulations, the draft calls for providers of companion AIs to ensure they are secure, don’t expose users to fraud, encrypt data, and reflect core socialist values. It also includes a requirement for parental controls, and for protection of data that describes minors.\n\nOne Article in the draft addresses how AI companions interact with the elderly:\n\nProviders shall guide elderly people to set up emergency contact persons for their services. If any elderly person is found to be in danger of losing their life, health or property during the use of the service, the provider shall promptly notify the emergency contact person and provide social and psychological assistance or emergency relief channels.\n\nProviders are prohibited from providing services that simulate the relatives or specific relationships of elderly users.\n\nThe draft also calls for AI companions to remind users they are not interacting with a human every two hours, and for providers of such systems to provide advance notice of outages.\n\nAlso among the draft requirements are calls for “mental health protection, emotional boundary guidance, and dependency risk warning, and should not use replacing social interaction, controlling users' psychology, or inducing addiction as design goals.”\n\nThe draft also prohibits using data gathered during interaction with AI companies to train models.\n\nThe Cyberspace Administration wants feedback on the draft by January 25th.\n\nAustralia’s Department of Defence has tapped Google for an “enhanced, secure and air-gapped hyperscale cloud capability.”\n\n“Defence will have access to advanced global cloud solutions to deliver key sovereign capabilities,” states the department’s announcement of the deal. “The technology will support faster rollout of critical systems, ongoing upgrades and improved cooperation with international partners, while ensuring Australia retains control of critical Defence assets.”\n\nAustralia’s government already has a deal with AWS to operate three datacenters dedicated to government workloads, including information rated as the nation’s “most classified data.”\n\nThe Department said the sensitivities of the Google deal mean it will “refrain from providing further commentary … with all specific details remaining strictly confidential.”\n\nJapan’s Aerospace Exploration Agency (JAXA) has published its initial analysis of the failed launch of its H3 rocket last week.\n\nThe agency found that when the rocket’s fairing separated, pressure in a fuel tank fell. When the engine that used the fuel tank ignited, it produced around 80 percent of expected pressure.\n\nThe rocket’s second stage and payload therefore could not reach the intended orbit. The report suggests both fell into Earth’s atmosphere and burned up safely.\n\n57 percent of components present in Huawei smartphones are now made in China, according to a product teardown reported by Japanese outlet Nikkei.\n\nWorking with Japanese teardown service Fomalhaut Techno Solutions, Nikkei analyzed the content of 2024’s Mate 70 Pro and this year’s Pura 80 Pro, and found 57 percent of components in both were made in China, and that those parts accounted for 60 percent of the phone’s value.\n\nNikkei reports that just 19 percent of components in Huawei’s 2020 models came from China, rising to 32 percent in 2023.\n\nPapua New Guinea’s (PNG’s) National Information & Communications Technology Authority has warned signatories to a petition calling for Starlink to be licensed for operations in the country that they risk prosecution.\n\nPNG is a rugged country with poor telecommunications infrastructure – a fine fit for Starlink’s satellite broadband service. Local netizens have campaigned for PNG to license Starlink, suggesting they email NICTA to express support for Starlink.\n\nOn December 16th NICTA demanded Starlink suspend services to the country.\n\nOn Christmas Eve, NICTA published a list of petitioners and warned “Individuals who have signed or participated in the petition may be regarded as potential offenders, and NICTA will not hesitate to pursue appropriate regulatory and legal action where non-compliance is established.”\n\nStarlink has since ended service in PNG.",
    "readingTime": 4,
    "keywords": [
      "cyberspace administration",
      "fuel tank",
      "emergency contact",
      "draft",
      "elderly",
      "services",
      "china",
      "providers",
      "users",
      "service"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2025/12/29/asia_tech_news_roundup/",
    "thumbnail_url": "https://regmedia.co.uk/2025/12/29/shutterstock_aged_care_and_robotics.jpg",
    "created_at": "2025-12-29T18:18:10.916Z",
    "topic": "tech"
  },
  {
    "slug": "ai-wont-hollow-out-whitecollar-jobs-it-will-fuel-growth-says-box-ceo-aaron-levie",
    "title": "AI won't hollow out white-collar jobs, it will fuel growth — says Box CEO Aaron Levie",
    "description": "Box CEO Aaron Levie says AI lowers costs for knowledge tasks, allowing companies to expand work and drive white-collar job growth.",
    "fullText": "Some tech leaders and AI researchers have predicted that AI will hollow out white-collar jobs.\n\nBut Aaron Levie, the cofounder and CEO of cloud-storage giant Box, believes it will push companies to do far more work.\n\nIn a LinkedIn post on Sunday, Levie said AI will sharply reduce the cost of knowledge tasks such as writing code and reviewing contracts.\n\nAs those tasks get cheaper, he said, companies will take on more projects that were previously too expensive or complex to justify, and, ultimately, create jobs rather than eliminate them.\n\nTo explain why, Levie pointed to economist William Stanley Jevons.\n\nIn 1865, Jevons observed that more efficient steam engines didn't curb coal use in England but drove it higher, as cheaper energy fueled new industries — a dynamic now known as the Jevons paradox.\n\nLevie said the same pattern has repeated itself in computing, with each major wave of cheaper technology — from mainframes to minicomputers to PCs — dramatically expanding adoption.\n\nCloud computing followed a similar path, erasing many of the advantages large companies once had in procurement, infrastructure, and maintenance, and putting tools like accounting software, CRM systems, and marketing platforms within reach of nearly any business, he said.\n\nThose efficiency gains automated deterministic work, Levie said — tasks with clear rules and predictable outcomes, such as accounting, record-keeping, scheduling, and data processing, where the same inputs reliably produce the same result.\n\nLevie's broader argument stands in contrast to warnings from other AI leaders and economists.\n\nAnthropic CEO Dario Amodei and Ford CEO Jim Farley have warned that the technology could wipe out large numbers of white-collar roles, while figures such as OpenAI CEO Sam Altman, JPMorgan CEO Jamie Dimon, and Elon Musk have predicted outcomes ranging from major disruption to longer-term economic gains.\n\nOthers, including Nvidia CEO Jensen Huang and Meta's outgoing chief AI scientist Yann LeCun, have predicted AI will reshape how work is done rather than eliminate it outright.\n\nWhile major tech companies such as HP, IBM, Salesforce, and Amazon have cut thousands of jobs amid AI-driven efficiency pushes, KPMG's chief economist Diane Swonk has warned the US could face a \"jobless boom\" in 2026 as firms do more with fewer workers.\n\nLevie said AI changes the equation by targeting non-deterministic work, which involves judgment, creativity, and ambiguity.\n\nTasks, such as reviewing contracts, writing software, designing marketing campaigns, or conducting research, don't follow fixed rules and have historically required expensive human expertise, making them difficult to automate and costly to scale.\n\n\"Now, every business in the world has access to the talent and resources of a Fortune 500 company 10 years ago,\" he wrote.\n\nAs non-deterministic tasks get cheaper, Levie said, companies take on far more work, driving demand for white-collar jobs.\n\nNot everyone agrees that AI is already reshaping the job market at that level.\n\nSome economists, including Gbenga Ajilore, chief economist at the Center on Budget and Policy Priorities, say the current white-collar downturn has more to do with high interest rates, weak hiring, and a slowing economy than AI itself.\n\nStill, Levie said fears of widespread replacement miss a key constraint.\n\n\"The reality is that despite all the tasks that AI lets us automate,\" he wrote, \"it still requires people to pull together the full workflow to produce real value.\"",
    "readingTime": 3,
    "keywords": [
      "reviewing contracts",
      "chief economist",
      "white-collar jobs",
      "tasks",
      "cheaper",
      "predicted",
      "jevons",
      "levie",
      "tech",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/box-ceo-ai-will-expand-white-collar-jobs-fuel-growth-2025-12",
    "thumbnail_url": "https://i.insider.com/69525a16832e0ef1ead6df2a?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.918Z",
    "topic": "finance"
  },
  {
    "slug": "prediction-rigetti-computing-stock-will-be-worth-this-much-by-yearend-2026",
    "title": "Prediction: Rigetti Computing Stock Will Be Worth This Much By Year-End 2026",
    "description": "Shares of Rigetti Computing have gained nearly 3,000% during the artificial intelligence (AI) revolution.",
    "fullText": "Quantum computing stocks are among the hottest plays in the artificial intelligence (AI) industry.\n\nPure-play developers such as Rigetti Computing are among the most popular quantum AI stocks.\n\nWhile Rigetti's momentum looks unstoppable, history suggests the company's valuation is unsustainable.\n\n10 stocks we like better than Rigetti Computing ›\n\nWhile artificial intelligence (AI) stocks performed strongly throughout 2025, one particular pocket of the AI realm sticks out from the pack: quantum computing. As of market close on Dec. 23, shares of the Defiance Quantum ETF gained 37% on the year -- more than double that of the S&P 500.\n\nSome of the biggest gainers in this exchange-traded fund (ETF) are quantum pure plays, including Rigetti Computing (NASDAQ: RGTI) -- whose shares have soared 46% this year.\n\nLet's dive into why there is so much excitement surrounding Rigetti Computing and assess whether the red-hot stock can keep rallying in 2026.\n\nWhile quantum AI remains an exploratory and theoretical pursuit among research labs and higher education institutions, some believe the technology has the potential to revolutionize critical applications across clinical research, financial risk, logistics, supply chain management, and manufacturing.\n\nManagement consulting firm McKinsey & Company estimates that quantum computing could add up to $2 trillion in economic value by next decade. For now, however, there are only a small number of companies dedicated to developing quantum computing technology.\n\nRigetti Computing builds quantum processors and computers that can be accessed through cloud infrastructure. By employing a vertically integrated model -- controlling the manufacturing process of its chips and designing its own software -- Rigetti aims to usher in a new era of computing beyond what today's most capable systems can handle.\n\nThis is important for the future of AI because if Rigetti achieves a quantum breakthrough, its full-stack suite across hardware and software could enable next-generation algorithms that today's GPUs simply are not designed to handle.\n\nA common mistake that beginner investors often make is following the crowd. Sometimes, investors will chase momentum stocks -- knowingly buying shares at a premium in hopes of flipping their position for a profit. This is known as the greater fool theory.\n\nSmart investors avoid this strategy. Thorough valuation analysis is required to determine whether a stock is actually a reasonable buy.",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "rigetti computing",
      "quantum computing",
      "stocks",
      "among",
      "shares",
      "investors",
      "momentum",
      "valuation",
      "stock"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/prediction-rigetti-computing-stock-worth-153500939.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uOhLXTFKYPZT.z9elSmb2g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/837836afaaecd9cd27e5aaab6b4d8ede",
    "created_at": "2025-12-29T18:18:05.841Z",
    "topic": "finance"
  },
  {
    "slug": "softbank-is-buying-digitalbridge-for-4-billion-to-accelerate-its-ai-ambitions",
    "title": "SoftBank is buying DigitalBridge for $4 billion to accelerate its AI ambitions",
    "description": "SoftBank will acquire DigitalBridge for $4 billion, expanding its control over AI infrastructure and global data centers.",
    "fullText": "SoftBank said it will acquire digital infrastructure investor DigitalBridge for about $4 billion.\n\nThe Japanese conglomerate said it is doubling down on building the data centers, connectivity, and power needed to support AI at a global scale.\n\n\"As AI transforms industries worldwide, we need more compute, connectivity, power, and scalable infrastructure,\" said Masayoshi Son, chairman and CEO of SoftBank Group.\n\nThe deal underscores SoftBank's push to control more of the physical infrastructure behind AI as competition for computing resources intensifies.\n\nDigitalBridge will continue to operate as a separately managed platform following the deal, led by CEO Marc Ganzi.\n\nThe transaction is expected to close in the second half of 2026, subject to regulatory approvals.\n\nThe acquisition also comes as SoftBank reshapes its bets on AI.\n\nThe company disclosed in November that it had sold nearly $6 billion worth of Nvidia stock. At the time, the company's CFO, Yoshimitsu Goto, said its decision to divest had \"nothing to do with Nvidia itself\" but was a way to reallocate its funds toward OpenAI.\n\nGoto said it plans to make the final part of its $30 billion investment in OpenAI by the end of the year.\n\nThe DigitalBridge deal also aligns with SoftBank's growing focus on what it calls \"physical AI,\" as the company ramps up investments in the real-world infrastructure — from data centers to robotics — needed to integrate AI into everyday life.",
    "readingTime": 2,
    "keywords": [
      "infrastructure",
      "softbank",
      "deal",
      "centers",
      "connectivity",
      "needed",
      "softbank's",
      "physical",
      "nvidia",
      "digitalbridge"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/softbank-acquires-digitalbridge-4-billion-in-ai-infrastructure-push-2025-12",
    "thumbnail_url": "https://i.insider.com/695288e064858d02d2177593?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.749Z",
    "topic": "finance"
  },
  {
    "slug": "the-real-obstacle-to-ai-in-creative-agencies-isnt-tech-its-fear-a-consultant-says",
    "title": "The real obstacle to AI in creative agencies isn't tech — it's fear, a consultant says",
    "description": "AI strategist Jules Love says agencies must rethink training, culture, and pricing to help creative teams thrive, not just work faster, in the AI era.",
    "fullText": "AI is transforming how creative work gets made — but most agencies still don't know where to begin in using it.\n\nJules Love, founder of Spark AI, a consultancy that helps creative firms weave AI into their day-to-day work, says the real challenge isn't technical — it's psychological.\n\n\"Adopting AI in your team won't happen by accident,\" he told Business Insider. \"You need to do it deliberately — make somebody accountable for it, and give them the space to be successful in that role.\"\n\nDrawing on his work with more than 60 agencies through Spark AI, he shares six ways leaders can future-proof their teams for the AI era.\n\nLove says most agencies won't transform unless someone owns the AI integration work.\n\nRather than setting up vague \"innovation groups,\" he encourages leaders to assign responsibility and protect time for AI integration, even if that means pulling people slightly away from billable client work.\n\nAgencies that succeed, he added, treat AI as a core business priority, not a side project that gets squeezed in when deadlines allow.\n\n\"It's amazing how many agencies roll out ChatGPT or Gemini to their teams and don't train anybody on it,\" Love said.\n\nHe likens untrained teams to people staring at a giant box of Lego with thousands of bricks inside, but no picture on the front and no instructions. The picture on the box, he said, is role-specific training.\n\nFor him, training is what turns experimentation into practical capability.\n\nLove said agencies struggle to innovate when teams are constantly under deadline pressure.\n\nTo make real progress with AI, leaders need to create structured time for experimentation — moments where people can test new workflows without the risk of missing a client delivery.\n\nHe pointed to companies like Lego, which regularly takes teams off-site to explore new ideas, and Canva, which paused normal work for a full week to rethink how departments could use AI.\n\n\"Fear kills innovation faster than bad tools,\" Love said. \"You have to give a little bit of room for failure.\"\n\nLove said a lack of openness around AI use is one of the clearest signs that something is wrong.\n\nWhen employees feel the need to hide tools like ChatGPT from coworkers, it suggests AI is still seen as risky or illegitimate rather than useful.\n\nTo change that dynamic, he advises leaders to make AI use visible and normalized, especially by creating space for teams to share how they're experimenting — including what hasn't worked.\n\n\"That's the No. 1 sign that there's not a good culture around AI in your business.\"\n\nHe also encouraged managers to push responsibility down the organization by giving individuals ownership over specific AI initiatives, such as maintaining a prompt library or developing custom tools, so adoption feels collaborative rather than imposed.\n\nLove said many creatives misunderstand how AI is meant to be used. Too often, teams treat it like a faster search engine — asking one-off questions and moving on — rather than as a collaborative assistant that improves with context and iteration.\n\nHe argues that real gains come when people learn to \"brief \"AI the way they would a colleague, giving it background, constraints, and feedback instead of quick prompts.\n\n\"It's much better to think of it as briefing somebody else to do the job,\" Love said.\n\nLove said agencies risk undermining their own value if they focus only on how AI makes work faster.\n\nAs creative output accelerates, clinging to the billable hour can push firms toward commoditization rather than differentiation, he said.\n\nInstead, he urged leaders to rethink pricing around outcomes, rather than speed, and to pilot AI in specific workflows so that teams can clearly measure what improves.\n\n\"If all we're doing is doing more stuff faster, then we're going to see a bit of a race to the bottom on fees,\" Love said.\n\nHe believes that fixed-cost projects, which reward better results — not velocity — give agencies room to invest in learning and experimentation without eroding their margins.\n\nLove's advice for 2026 is simple: \"Stop thinking about what you can do today more quickly and what you can do tomorrow better.\"\n\nHe believes the agencies that thrive will not be those with the biggest budgets or flashiest tech but those that help their people learn, lead, and experiment.\n\n\"Come 2027, you're going to be looking pretty old-fashioned, pretty expensive, and pretty uninteresting as an agency if you're not embracing this stuff and seeing what you can do with it,\" he said.",
    "readingTime": 4,
    "keywords": [
      "spark ai",
      "agencies",
      "teams",
      "rather",
      "leaders",
      "faster",
      "creative",
      "love",
      "it's",
      "experimentation"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-creative-agencies-can-future-proof-their-teams-for-ai-2025-10",
    "thumbnail_url": "https://i.insider.com/6900e6bc0be9845f2dc53c6d?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.362Z",
    "topic": "finance"
  },
  {
    "slug": "lightspeed-ventures-partner-says-sora-will-make-social-media-creators-far-far-far-less-valuable",
    "title": "Lightspeed Ventures partner says Sora will make social media creators 'far, far, far less valuable'",
    "description": "Lightspeed Ventures partner Michael Mignano predicted that AI-generated video would lead to the \"end of the creator.\"",
    "fullText": "AI-generated video is here. What will happen to your TikTok feed?\n\nOpenAI's launch of Sora 2 sent shockwaves through the social media economy. AI slop was already rampant, and now there was a more realistic form of video with even narrower tailoring. Then came the lifelike images of Google's Nano Banana.\n\nHow will creators fare in the age of AI? Lightspeed Ventures partner Michael Mignano takes a more extreme view: that it signals the \"end of the creator.\"\n\nOn \"Sourcery,\" Mignano described a future of social media where content is generated instantaneously and artificially to best suit the viewer. It comes down to keeping the user's attention, he said.\n\n\"That's why the TikTok algorithm is so powerful,\" Mignano said. \"But it still requires human beings to make the content, and there's a cost to that.\"\n\nThat \"cost\" is the human labor and payments that go into creating your feed. AI could mean costs go down, but that spells bad news for the influencer.\n\n\"The individual creator becomes far, far, far less valuable in that dynamic,\" he said.\n\nMignano is well-versed in the online media space. He was VP of product at Aviary, a photo editing tool that was acquired by Adobe. He then cofounded and ran the podcasting platform Anchor, which was acquired by Spotify.\n\nAt Lightspeed Ventures, Mignano also invested in Elon Musk's xAI. The investment was made in 2024, before xAI acquired X, formerly Twitter.\n\nMignano acknowledged that the \"death of the creator\" — as he called it on his Substack — was \"devastating,\" but that it marked a \"whole new chapter for the internet.\"\n\nAI-generated video hasn't yet reached the point of on-demand, perfectly tailored content. Some users are perturbed by its current iteration, and TikTok allows users to choose whether to keep AI-generated videos out of their feed.\n\nBut some of the change is already here. AI influencers have emerged on Instagram, and TikTok Shop is inundated with AI scams. That cute video of bunnies bouncing on a trampoline? Yeah, that was AI.\n\nWe may not need perfect AI tailoring to reach an inhuman internet. Industry leaders, including Alexis Ohanian and Sam Altman, have referenced the \"dead internet theory,\" which says that there is more bot activity than human activity on the web.\n\nMeanwhile, the era of the social media megastar may be on the decline. Reed Duchscher, Mr. Beast's former manager, told Business Insider that it's now easier to build internet businesses with \"hyper-niche\" audiences.\n\nHow can creators stay afloat? In an email to Business Insider, Mignano wrote that quality will win out.\n\n\"Platforms will no longer reward humans posting the same old, tried and true formats and memes,\" he wrote. \"Instead, true uniqueness of image, likeness, and creativity will be the only viable path for human-created content.\"\n\nCorrection: December 29, 2025 — An earlier version of this story misstated Michael Mignano's title at Aviary. He was the VP of product.",
    "readingTime": 3,
    "keywords": [
      "lightspeed ventures",
      "social media",
      "far far",
      "content",
      "internet",
      "ai-generated",
      "feed",
      "creator",
      "human",
      "acquired"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lightspeed-partner-sora-creators-far-less-valuable-2025-12",
    "thumbnail_url": "https://i.insider.com/695298d564858d02d21776af?width=768&format=jpeg",
    "created_at": "2025-12-29T18:18:05.160Z",
    "topic": "finance"
  },
  {
    "slug": "the-hbr-charts-that-help-explain-2025",
    "title": "The HBR Charts that Help Explain 2025",
    "description": "A lot happened in 2025. Luckily, charts can help make sense of it all. Here are some of HBR’s most popular, topical, and important charts of the year. They cover a wobbly economy, an explosion of AI-generated slop at work, the challenge of finding joy in a busy life, and more.",
    "fullText": "The HBR Charts that Help Explain 2025 by HBR EditorsDecember 29, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWhat happened in 2025? Well, a lot. There were tariffs, breakthroughs and disappointments with AI, and a wobbly economy that sent decidedly mixed signals. There were crises of purpose, execution, and management.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://hbr.org/2025/12/the-hbr-charts-that-help-explain-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_HBRStaff.gif",
    "created_at": "2025-12-29T18:18:04.121Z",
    "topic": "business"
  },
  {
    "slug": "softbank-to-acquire-digitalbridge-for-4bn-in-move-to-deepen-ties-to-ai",
    "title": "SoftBank to acquire DigitalBridge for $4bn in move to deepen ties to AI",
    "description": "Acquisition would further expand SoftBank’s investments in artificial intelligence as it tries to center itself in the boom\nSoftBank Group will acquire digital infrastructure investor DigitalBridge Group in a deal valued at $4bn, the companies said on Monday, as the Japanese investment firm looks to deepen its AI-related portfolio.\nThe acquisition would expand SoftBank’s exposure to digital infrastructure as the Japanese conglomerate is positioning its portfolio to focus on artificial intelligence.",
    "fullText": "Acquisition would further expand SoftBank’s investments in artificial intelligence as it tries to center itself in the boom\n\nSoftBank Group will acquire digital infrastructure investor DigitalBridge Group in a deal valued at $4bn, the companies said on Monday, as the Japanese investment firm looks to deepen its AI-related portfolio.\n\nThe acquisition would expand SoftBank’s exposure to digital infrastructure as the Japanese conglomerate is positioning its portfolio to focus on artificial intelligence.\n\n SoftBank’s billionaire founder Masayoshi Son is seeking to capitalize on surging demand for the computing capacity that underpins artificial intelligence applications.\n\nDigitalBridge invests in digital infrastructure sectors such as datacenters, cell towers, fiber networks, small-cell systems and edge infrastructure, with a portfolio including companies such as Vantage Data Centers, Zayo, Switch and AtlasEdge.\n\nFounded in 1991 as real estate-focused Colony Capital, the firm pivoted under CEO Marc Ganzi into digital infrastructure and rebranded as DigitalBridge in 2021 after shedding most of its legacy property assets.\n\nGanzi will continue leading DigitalBridge as a separately managed platform, the companies said.\n\nAs of 30 September, DigitalBridge managed around $108bn in assets, making it one of the largest dedicated investors in the digital ecosystem.\n\nSoftBank has ramped up investment in AI as it seeks to position itself at the center of what Son has called a once-in-a-generation technological shift.\n\nThe company, along with OpenAI, Oracle and Abu Dhabi-based tech investor MGX, is investing billions of dollars in the Stargate project, a large-scale computing and infrastructure initiative aimed at supporting advanced AI development.\n\nOpenAI, Oracle and SoftBank said in September they plan to build five new computing sites across Texas, New Mexico and Ohio, which are expected to have a combined power capacity of about 7GW when in operation.",
    "readingTime": 2,
    "keywords": [
      "openai oracle",
      "expand softbank’s",
      "artificial intelligence",
      "digital infrastructure",
      "portfolio",
      "computing",
      "acquisition",
      "center",
      "investor",
      "japanese"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theguardian.com/technology/2025/dec/29/softbank-digitalbridge-deal-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8ecf41b945b21222316c10c86684d2d4dd3e86fd/830_427_2876_2303/master/2876.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=5092cba3ac287ac1d9915ff3e4193c0f",
    "created_at": "2025-12-29T18:18:02.347Z",
    "topic": "tech"
  },
  {
    "slug": "this-will-be-a-stressful-job-sam-altman-offers-555k-salary-to-fill-most-daunting-role-in-ai",
    "title": "‘This will be a stressful job’: Sam Altman offers $555k salary to fill most daunting role in AI",
    "description": "New head of preparedness at OpenAI will face unnerving in-tray amid fears from some experts that AI could ‘turn on us’\nThe maker of ChatGPT has advertised a $555,000-a-year vacancy with a daunting job description that would cause Superman to take a sharp intake of breath.\nIn what may be close to the impossible job, the “head of preparedness” at OpenAI will be directly responsible for defending against risks from ever more powerful AIs to human mental health, cybersecurity and biological weapons.\n Continue reading...",
    "fullText": "New head of preparedness at OpenAI will face unnerving in-tray amid fears from some experts that AI could ‘turn on us’\n\nThe maker of ChatGPT has advertised a $555,000-a-year vacancy with a daunting job description that would cause Superman to take a sharp intake of breath.\n\nIn what may be close to the impossible job, the “head of preparedness” at OpenAI will be directly responsible for defending against risks from ever more powerful AIs to human mental health, cybersecurity and biological weapons.\n\nThat is before the successful candidate has to start worrying about the possibility that AIs may soon begin training themselves amid fears from some experts they could “turn against us”.\n\n“This will be a stressful job, and you’ll jump into the deep end pretty much immediately,” said Sam Altman, the chief executive of the San Francisco-based organisation, as he launched the hunt to fill “a critical role” to “help the world”.\n\nThe successful candidate will be responsible for evaluating and mitigating emerging threats and “tracking and preparing for frontier capabilities that create new risks of severe harm”. Some previous executives in the post have lasted only for short periods.\n\nThe opening comes against a backbeat of warnings from inside the AI industry about the risks of the increasingly capable technology. On Monday, Mustafa Suleyman, the chief executive of Microsoft AI, told BBC Radio 4’s Today programme: “I honestly think that if you’re not a little bit afraid at this moment, then you’re not paying attention.”\n\nDemis Hassabis, the Nobel prize-winning co-founder of Google DeepMind, this month warned of risks that included AIs going “off the rails in some way that harms humanity”.\n\nAmid resistance from Donald Trump’s White House, there is little regulation of AI at national or international level. Yoshua Bengio, a computer scientist known as one of the “godfathers of AI”, said recently: “A sandwich has more regulation than AI.” The result is that AI companies are largely regulating themselves.\n\nAltman said on X as he launched the job search: “We have a strong foundation of measuring growing capabilities, but we are entering a world where we need more nuanced understanding and measurement of how those capabilities could be abused, and how we can limit those downsides both in our products and in the world, in a way that lets us all enjoy the tremendous benefits. These questions are hard and there is little precedent.”\n\nOne user responded sardonically: “Sounds pretty chill, is there vacation included?”\n\nWhat is included is an unspecified slice of equity in OpenAI, a company that has been valued at $500bn.\n\nLast month, the rival company Anthropic reported the first AI-enabled cyber-attacks in which artificial intelligence acted largely autonomously under the supervision of suspected Chinese state actors to successfully hack and access targets’ internal data. This month, OpenAI said its latest model was almost three times better at hacking than three months earlier and said “we expect that upcoming AI models will continue on this trajectory”.\n\nOpenAI is also defending a lawsuit from the family of Adam Raine, a 16-year-old from California who killed himself after alleged encouragement from ChatGPT. It has argued Raine misused the technology. Another case, filed this month, claims ChatGPT encouraged the paranoid delusions of a 56-year-old in Connecticut, Stein-Erik Soelberg, who then murdered his 83-year old mother and killed himself.\n\nAn OpenAI spokesperson said it was reviewing the filings in the Soelberg case, which it described as “incredibly heartbreaking” and that it was improving ChatGPT’s training “to recognise and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support”.",
    "readingTime": 3,
    "keywords": [
      "successful candidate",
      "chief executive",
      "amid fears",
      "risks",
      "capabilities",
      "preparedness",
      "experts",
      "responsible",
      "defending",
      "mental"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/29/sam-altman-openai-job-search-ai-harms",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c3409a400509e73744d9026d0c24ec63e1719c0a/184_0_4590_3673/master/4590.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0566fe87666f16bbd54eeeb17f77a1e0",
    "created_at": "2025-12-29T18:18:02.345Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-singersongwriter-sunderland-fan-tom-a-smith",
    "title": "Sutton's predictions v singer-songwriter & Sunderland fan Tom A Smith",
    "description": "BBC Sport football expert Chris Sutton takes on singer-songwriter and Sunderland fan Tom A Smith - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "Aston Villa boss Unai Emery had an unhappy 18-month spell in charge of Arsenal that ended in 2019, but can he get the better of his old club on Tuesday?\n\n\"After the abuse he took from Arsenal fans, I'd love nothing more than Emery to go back to the Emirates and win,\" said BBC Sport football expert Chris Sutton.\n\n\"He absolutely didn't deserve that. Some of those fans should take a long, hard look at themselves for the way they mocked him. I hope Villa go there and spank them, just because of that.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 19 - which includes the final games of 2025 on Tuesday, 30 December and the first matches of 2026 on New Year's Day - he takes on singer-songwriter Tom A Smith, who is a Sunderland fan.\n\nSmith's latest EP, Say What You Want, is out now. It reached number 14 in the UK record store charts at the end of November.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "arsenal",
      "fans",
      "predictions",
      "games",
      "points",
      "villa",
      "emery",
      "sport",
      "sutton"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/c9qe884715jo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/9e61/live/34f51c40-e42f-11f0-aae2-2191c0e48a3b.png",
    "created_at": "2025-12-29T18:18:01.513Z",
    "topic": "sports"
  },
  {
    "slug": "mosa-cloud",
    "title": "Mosa Cloud",
    "description": "The digital workspace that puts you in control. Docs, Meet, Drive, Mail & more, with AI that works exclusively for you.",
    "fullText": "Docs Collaborative documents Fast, focused, and built for real work. Capture meeting notes, share project updates, or build a knowledge base, all in a clean editor designed for speed and clarity. Real-time collaboration, version history, and standard formats come built in. Real-time collaboration Version history Open formats AI integrated S AI AI assistance Comment History",
    "readingTime": 1,
    "keywords": [
      "real-time collaboration",
      "collaboration version",
      "version history",
      "formats"
    ],
    "qualityScore": 0.2,
    "link": "https://mosa.cloud",
    "thumbnail_url": "/og-img.jpg",
    "created_at": "2025-12-29T12:24:57.525Z",
    "topic": "tech"
  },
  {
    "slug": "musevideo-ai-video-generator-with-sora-2-veo-3-and-wan-25",
    "title": "MuseVideo – AI Video Generator with Sora 2, Veo 3, and Wan 2.5",
    "description": "MuseVideo is a professional AI video generator that transforms text and images into stunning videos. Create AI-generated videos with advanced technology and cinematic quality in minutes.",
    "fullText": "AI Video Generator-powered content creation tool for creators. Produce professional videos without expensive equipment or complex editing—complete stunning content in minutes, not hours.\n\nTransform your content with our extensive collection of AI-powered effects designed to feed your ai video generator\n\nMuseVideo unifies the best ai video generator and ai video maker options in one dashboard. Create professional videos with industry-leading AI models without swapping tabs or platforms.\n\nWith the MuseVideo ai video generator, you can tap into our flagship Pollo 1.6 video model and all top-tier video models in the industry, like:\n\nMuseVideo AI image generator also allows you to choose from a selection of leading image models. They include:\n\nFollow the ai video generator from first spark to global release—each stage engineered for teams that demand speed, fidelity, and automation.\n\nText-to-Image, Image-to-Image, Text-to-Video, Image-to-Video: Four powerful engines in one unified platform.\n\nMuseVideo brings together industry-leading AI models for both static and dynamic content creation. Seamlessly switch between generating stunning images and captivating videos within a single workspace. From concept to final render, maintain consistent styling across all media types while our intelligent model routing ensures optimal results for every creative task.\n\nUnlock playful, on-brand concepts the ai video generator can customize in seconds.\n\nA range of fun and attractive video templates waits for you to explore. From heartwarming AI-generated kisses or hugs to festive AI Santa greetings, the ai video generator makes it effortless to craft memorable content that captivates your audience.\n\nTransform your ideas into thumb-stopping videos that capture attention and grow your audience—without the expensive gear or learning curve.\n\nAs a content creator, you're competing with thousands of others for attention. MuseVideo levels the playing field by giving you cinema-quality tools in one ai video generator workspace that would normally cost thousands of dollars. Create compelling brand stories, product showcases, and engaging narratives that keep viewers watching—all from your laptop and in minutes, not days.\n\nCreate standout videos in three simple steps\n\nWrite a prompt or upload references so the ai video generator understands your vision.\n\nWatch in-progress previews as the ai video generator crafts cinematic motion with accurate physics.\n\nDownload optimized files and push them to every channel directly from the ai video generator.\n\nJoin creative teams already producing cinematic campaigns, episodic stories, and launch assets with our ai video generator.\n\nGet the latest and most comprehensive AI models from Artany.\n\nFast and efficient AI image generation\n\nProfessional-grade Nano Banana for superior quality\n\nDream-like AI image synthesis with artistic flair\n\nPowerful image generation with Qwen AI\n\nAdvanced AI video generation with stunning quality\n\nNext-generation video synthesis powered by AI\n\nProfessional-grade Sora model for superior quality\n\nProfessional-grade video creation with AI precision\n\nFast and efficient AI image generation\n\nAdvanced AI video generation with stunning quality\n\nProfessional-grade Nano Banana for superior quality\n\nNext-generation video synthesis powered by AI\n\nDream-like AI image synthesis with artistic flair\n\nProfessional-grade Sora model for superior quality\n\nPowerful image generation with Qwen AI\n\nProfessional-grade video creation with AI precision",
    "readingTime": 3,
    "keywords": [
      "nano banana",
      "sora model",
      "professional-grade nano",
      "quality next-generation",
      "artistic flair",
      "synthesis powered",
      "professional videos",
      "superior quality",
      "content creation",
      "stunning quality"
    ],
    "qualityScore": 1,
    "link": "https://musevideo.ai",
    "thumbnail_url": "https://musevideo.ai/landing/home/og/preview.png",
    "created_at": "2025-12-29T12:24:55.988Z",
    "topic": "tech"
  },
  {
    "slug": "uk-accounting-body-to-halt-remote-exams-amid-ai-cheating",
    "title": "UK accounting body to halt remote exams amid AI cheating",
    "description": "Candidates will have to sit assessments in person unless there are exceptional circumstances, says...",
    "fullText": "Candidates will have to sit assessments in person unless there are exceptional circumstances, says ACCA\n\nThe world’s largest accounting body is to stop students being allowed to take exams remotely to crack down on a rise in cheating on tests that underpin professional qualifications.\n\nThe Association of Chartered Certified Accountants (ACCA), which has almost 260,000 members, has said that from March it will stop allowing students to take online exams in all but exceptional circumstances.\n\n“We’re seeing the sophistication of [cheating] systems outpacing what can be put in, [in] terms of safeguards,” Helen Brand, the chief executive of the ACCA, said in an interview with the Financial Times.\n\nRemote testing was introduced during the Covid pandemic to allow students to continue to be able to qualify at a time when lockdowns prevented in-person exam assessment.\n\nIn 2022, the Financial Reporting Council (FRC), the UK’s accounting and auditing industry regulator, said that cheating in professional exams was a “live” issue at Britain’s biggest companies.\n\nA number of multimillion-dollar fines have been issued to large auditing and accounting companies around the world over cheating scandals in tests.\n\nThe FRC’s investigation found that instances of cheating also included some tier-one auditors, a category comprising the “big four” accountants – KPMG, PwC, Deloitte and EY – along with Mazars, Grant Thornton and BDO.\n\nIn 2022, EY agreed to pay a record $100m (£74m) to US regulators over claims that dozens of its employees cheated on an ethics exam and that the company then misled investigators.\n\nThe ACCA said it had concluded that online tests have become too difficult to police, given the rise in artificial intelligence (AI) tools available to students.\n\nBrand said the ACCA, which has more than half a million students, had worked “intensively” to combat cheating but “people who want to do bad things are probably working at a quicker pace”.\n\nShe added that the rapid rise of technology, led by AI tools, had pushed the issue of cheating to a “tipping point”.\n\nLast year, the Institute of Chartered Accountants in England and Wales (ICAEW), which also trains accountants around the world, said reports of cheating were still increasing.\n\nHowever, the ICAEW still permits some exams to be sat online.\n\n“There are very few high-stakes examinations now that are allowing [remote invigilation],” Brand said.",
    "readingTime": 2,
    "keywords": [
      "exceptional circumstances",
      "cheating",
      "students",
      "exams",
      "accounting",
      "rise",
      "tests",
      "online",
      "stop",
      "professional"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f23da26f8402f91bc06b7a051a59f632f7c7cde6/424_0_2581_2065/master/2581.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e81c03d0f4a8f09f84377c187c4e998a",
    "created_at": "2025-12-29T12:24:53.812Z",
    "topic": "business"
  },
  {
    "slug": "bernie-sanders-criticizes-ai-as-the-most-consequential-technology-in-humanity",
    "title": "Bernie Sanders criticizes AI as ‘the most consequential technology in humanity’",
    "description": "Republican senator Katie Britt also proposes AI companies be criminally liable if they expose minors to harmful ideas\nUS senator Bernie Sanders amplified his recent criticism of artificial intelligence on Sunday, explicitly linking the financial ambition of “the richest people in the world” to economic insecurity for millions of Americans – and calling for a potential moratorium on new datacenters.\nSanders, a Vermont independent who caucuses with the Democratic party, said on CNN’s State of the Union that he was “fearful of a lot” when it came to AI. And the senator called it “the most consequential technology in the history of humanity” that will “transform” the US and the world in ways that had not been fully discussed.\n Continue reading...",
    "fullText": "Republican senator Katie Britt also proposes AI companies be criminally liable if they expose minors to harmful ideas\n\nUS senator Bernie Sanders amplified his recent criticism of artificial intelligence on Sunday, explicitly linking the financial ambition of “the richest people in the world” to economic insecurity for millions of Americans – and calling for a potential moratorium on new datacenters.\n\nSanders, a Vermont independent who caucuses with the Democratic party, said on CNN’s State of the Union that he was “fearful of a lot” when it came to AI. And the senator called it “the most consequential technology in the history of humanity” that will “transform” the US and the world in ways that had not been fully discussed.\n\n“If there are no jobs and humans won’t be needed for most things, how do people get an income to feed their families, to get healthcare or to pay the rent?” Sanders said. “There’s not been one serious word of discussion in the Congress about that reality.”\n\nDays from being scheduled to help swear New York mayor-elect and democratic socialist Zohran Mamdani into office, Sanders said “the richest people in the world” were pushing the technology. He singled out tech moguls Elon Musk, Mark Zuckerberg, Jeff Bezos and Peter Thiel while questioning their motives.\n\n“You think they’re staying up nights worrying about working people and how this technology will impact those people?” Sanders said. “They are not. They are doing it to get richer and even more powerful.”\n\nSanders also pointed to studies that show dependence on AI chatbots for emotional support. “If this trend continues, what does it mean over the years when people are not getting their support, their interaction from other human beings, but from a machine?” he said. “What does that mean to humanity?”\n\nThat theme was taken up separately on State of the Union by Katie Britt, an Alabama Republican senator and co-sponsor of legislation to protect minors from chatbots.\n\nThe proposed measure – the Guardianship Over Artificial Intelligence Relationships (Guard) Act – seeks to ban providing AI companions to minors. It also mandates that AI companions disclose their non-human status and lack of professional credentials. The measure seeks to establish criminal liability if companies make AI companions available to minors that solicit or produce sexually explicit content – or encourage self-harm or violence.\n\nBritt said she had met with parents who have told her “devastating stories about their children where chatbots ultimately, when they kind of peeled everything back, had isolated them from their parents, had talked to them about suicide”.\n\nShe said: “If these AI companies can make the most brilliant machines in the world, they could do us all a service by putting up proper guardrails that did not allow for minors to utilize these things, that also told the user consistently that they are not a physician, they are not a psychiatrist, ‘I am a machine.’”\n\nBritt said AI companies should be held criminally liable if they create spaces where chatbots “are having these types of sensual and sexual relationships with young people or encouraging suicide”.\n\nThe remarks by Sanders and Britt offer a rare convergence of thinking from the left and right on aspects of the issue of governing AI. Sanders said Congress needed “to vigorously study the impact that AI is having on the mental health of our country”.\n\n“I worry very much about kids spending their entire days getting emotional support,” he added. “So we have got to take a hard look on that.” The senator said lawmakers need to be “thinking seriously” about a moratorium on new AI datacenters.\n\n“Frankly, I think you have got to slow this process down,” he said. “It’s not good enough for the oligarchs to tell us, it’s coming, you adapt. What are they talking about? They going to guarantee health care to all people?\n\n“What are they going to do when people have no jobs? What are they going to do, make housing free? So I think we need to take a deep breath, and I think we need to slow this thing down.”",
    "readingTime": 4,
    "keywords": [
      "criminally liable",
      "artificial intelligence",
      "republican senator",
      "katie britt",
      "minors",
      "chatbots",
      "technology",
      "companions",
      "sanders",
      "richest"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/2025/dec/28/bernie-sanders-artificial-intelligence-ai-datacenters",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dcd4cfa10565632f39217d8f35ba5891ec0961e5/332_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a49d9dd4f8863cda0341fa3df5ca4a64",
    "created_at": "2025-12-29T12:24:53.643Z",
    "topic": "tech"
  },
  {
    "slug": "3-people-who-pivoted-into-ai-share-how-they-used-their-college-experience-to-break-into-the-field",
    "title": "3 people who pivoted into AI share how they used their college experience to break into the field",
    "description": "Three AI engineers explain how returning to school, internships, and college relationships led to jobs at startups and major tech companies.",
    "fullText": "AI has become one of the most popular fields in tech. The people working in it didn't all follow the same path to get there, but for some, college played a crucial role in their success.\n\nFor one AI startup engineer, returning to school provided an opportunity to explore what an AI career would be like before committing to it. For another, moving to the US for a graduate program opened doors to being closer to the center of the action in Big Tech. In another case, relationships formed during college — with peers, professors, and mentors — continued to shape his career even long after graduation.\n\nBelow are three people who pivoted into AI roles and shared with Business Insider how they leveraged their college experience to break into the field. Quotes have been edited for length and clarity.\n\nVarun Goyal is a 25-year-old AI startup engineer, based in California.\n\nIn my final year of undergraduate studies, I stood at a crossroads between quantitative trading and pursuing a career in technology. Blinded by the initial high salary and prestige, I joined a firm in India as a quantitative strategist for the summer.\n\nI enjoyed it, but I wanted to push boundaries in my career and was increasingly convinced that I should return to school to explore more options. I decided to move from India to the US for my master's degree in computer science.\n\nReturning to school gave me the opportunity to pursue research and engage with senior industry professionals in both fields. This was the biggest benefit for me when I was deciding what I wanted my daily life and career to look like in 10 years.\n\nIn graduate school, the AI boom was also happening. It kept me up at night in the best way possible. I ultimately applied to both industries and had a few quant interviews, but I decided to join an AI startup in 2024 after graduating. I took a lower base salary than what I would have earned in quant, but I felt AI gave me more options down the line.\n\nWithout going back for my master's, I wouldn't have had this opportunity, and I love working in AI.\n\nDeep Shah is a 30-year-old software engineer at Google, based in Mountain View, CA.\n\nGrowing up, I wanted to develop my own computer games, which was the primary reason I chose to pursue a career in computer engineering. I also learned through conversations with peers older than me that the field involved a lot of automating machines to work on my behalf, which excited me. This was my first experience with mentorship.\n\nWhen I was pursuing my bachelor's degree, I got involved with professors who believed in and supported me. Having someone expose me to machine learning or AI problems they're excited about, no matter how small or large, taught me skills that are rarely learned just by doing the core work.\n\nEach mentor will teach you different things, and the person doesn't necessarily need to be a professor. They could be an alum or someone who's more senior at your college. Working with a mentor is also a valuable addition to your résumé, demonstrating that you already possess the skills and experience necessary to succeed in a professional environment.\n\nLater in my career, leaning on peers and mentors provided me with opportunities to further advance my career at Google. I joined Google Bangalore in 2018 after speaking with a friend who worked there. He helped me decide the role I was applying for could be the right fit for me.\n\nIn 2021, I was still at Google Bangalore and wanted to contribute to improving the user experience on Google search. The team working on that project was based in Mountain View, CA, and my skill set was a very good match, so I decided to relocate to the US to join that team.\n\nBuilding my networking skills with peers and mentors throughout my education directly contributed to my later success at Google.\n\nKriti Goyal is a 28-year-old AI machine learning engineer at a Big Tech company, based in Seattle.\n\nI always thought I would study medicine until my cousin showed me a Code.org video with Mark Zuckerberg, Bill Gates, and other tech rockstars, about how coding is the quickest way to convert an idea into a product. That changed my life.\n\nI'm now part of the Foundation Model main framework team for a major Big Tech company in the US. This year, I completed five years with them, during which time I've held four different roles. I used my master's to move to the US and further my career.\n\nI originally interned at my current company in India. I enjoyed working in India, but the core business decisions and strategizing for the next projects were made at the company headquarters here in the US.\n\nI had two ways to go about moving to the US. One was to try to move within my company or pursue a master's degree. Two reasons I chose the master's path are the knowledge and extra specialty you can develop through projects, as well as the connections you make. The biggest thing I took away from my program was the people I met.\n\nWhen I arrived in the US, I knew a few people from my former company from my time in India, so I reached out to them directly instead of applying through the job board. I got the interview for a machine learning engineering internship quite easily because the company was already familiar with my work.\n\nLearning and networking can be done in many places; it doesn't have to be university. In a city like San Francisco or New York, you could hustle and get the networking benefits of a university and a structured system.\n\nI think it's now possible to skip that education stage. But I have seen a bias in hiring for specific teams, and it's not unbreakable yet. I was changing countries and cultures, and university was a great way to get through the immigration system and understand the culture. I needed it, and I feel fortunate to be where I am in my career because I made the decision to pursue my master's degree.\n\nDo you have a story to share about breaking into the AI field? Contact this editor, Agnes Applegate, at aapplegate@insider.com.",
    "readingTime": 6,
    "keywords": [
      "mountain view",
      "machine learning",
      "startup engineer",
      "master's degree",
      "google bangalore",
      "big tech",
      "career",
      "india",
      "college",
      "school"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-three-people-used-college-to-break-into-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/694ee9f004eda4732f2e277e?width=1200&format=jpeg",
    "created_at": "2025-12-29T12:24:51.829Z",
    "topic": "finance"
  },
  {
    "slug": "relying-too-much-on-ai-could-quietly-damage-your-confidence-and-your-career-prospects-think-tank-ceo-says",
    "title": "Relying too much on AI could quietly damage your confidence — and your career prospects, think tank CEO says",
    "description": "AI in the workplace may boost speed and efficiency, but risks eroding confidence and critical thinking, the CEO of a digital economy think tank said.",
    "fullText": "AI appears to be making workers faster, more efficient, and more productive on paper.\n\nHowever, according to Mehdi Paryavi, CEO of the International Data Center Authority, which advises companies and governments on building the data centers that power AI, it may also be quietly eroding workers' confidence in their job skills.\n\nParyavi told Buisness Insider that excessive and poorly designed AI use in workplaces is driving what he called a \"quiet cognitive erosion\" and \"down-skilling.\"\n\n\"There used to be a notion called 'thinking outside the box,'\" he said. \"That notion will soon cease to exist when everyone draws on all their creativity, analytics, and innovation from a single box called AI.\"\n\nParyavi believes the most immediate casualty of heavy AI reliance is self-belief.\n\n\"If you come to believe that AI writes better than you and thinks smarter than you, you will lose your own confidence in yourself,\" he said.\n\nParyavi said the loss of confidence compounds quickly as workers begin deferring writing, analysis, and judgment to AI systems, gradually relying less on the skills they have built through years of reading, writing, learning, and observation.\n\n\"All of a sudden, you realize you are not good enough without this new tool, and day by day, you rely less on yourself and more on AI,\" he said.\n\nResearch is beginning to reflect that pattern. A new report from the Work AI Institute, produced with researchers from universities including Notre Dame, Harvard, and UC Santa Barbara, found that AI is turning ordinary office workers into people who feel smarter and more productive while their underlying skills slowly erode.\n\nRebecca Hinds, head of the Work AI Institute, told Business Insider that AI creates an illusion of expertise, which is especially risky for early-career employees who still need to establish their foundations.\n\nMuch of the problem, Paryavi said, lies in how leaders define productivity.\n\nAI's biggest promise is speed — faster reports, faster launches, faster analysis. But faster doesn't always mean better, Paryavi said.\n\nWhile AI can generate professional-sounding output, Paryavi said it often lacks the depth that comes from years of hands-on expertise.\n\nThat loss of depth is already visible, according to Anastasia Berg, a philosophy professor at the University of California, Irvine, who has said that workers who rely heavily on AI risk rapid skill atrophy, especially junior employees who never fully learn how to think through problems independently.\n\nParyavi isn't opposed to AI. He said the risk comes from indiscriminate use.\n\nCompanies should tailor AI access by job function, he said, rather than rolling it out universally. Some roles may benefit heavily from AI support, while others should rely primarily on human judgment.\n\nHe also discussed the importance of human involvement at both ends of the workflow — leading creative thinking at the beginning and quality-checking AI output at the end.\n\n\"What's critical to note is that you, the human you, must quality check AI, not the other way around,\" he said.\n\nAI may not eliminate jobs outright. But without deliberate limits, Paryavi said, it could quietly erode the confidence and thinking skills that careers are built on.\n\n\"How much technology do we really need, and how far are we willing to push the envelope? How much is enough?\" he said.",
    "readingTime": 3,
    "keywords": [
      "work ai institute",
      "workers",
      "faster",
      "confidence",
      "skills",
      "rely",
      "human",
      "paryavi",
      "productive",
      "quietly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-impacts-confidence-job-skills-career-think-tank-ceo-says-2025-12",
    "thumbnail_url": "https://i.insider.com/6952685a04eda4732f2e2d6c?width=1200&format=jpeg",
    "created_at": "2025-12-29T12:24:51.701Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-hover-near-record-silver-turns-volatile-markets-wrap",
    "title": "Stocks Hover Near Record, Silver Turns Volatile: Markets Wrap",
    "description": "Global stocks held gains from a record-breaking run fueled by artificial intelligence that’s helped markets rebound from an April slump sparked by tariff concerns. Volatility gripped precious metals such as silver, which rose to another all-time high.",
    "fullText": "MarketsBy Shikhar BalwaniSaveGlobal stocks held gains from a record-breaking run fueled by artificial intelligence that’s helped markets rebound from an April slump sparked by tariff concerns. Volatility gripped precious metals such as silver, which rose to another all-time high.The MSCI All Country World Index — one of the broadest measures of the equity market — was steady after climbing 1.4% last week to a fresh peak as a much-expected year-end rally took hold. A gauge of Asian shares advanced 0.3% for a seventh straight day of gains, boosted by tech names and miners. US equity-index futures edged lower after the S&P 500 finished near its peak on Friday.",
    "readingTime": 1,
    "keywords": [
      "gains",
      "peak"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-28/asian-stocks-set-for-muted-start-amid-thin-trading-markets-wrap",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i4Ked01Zc96I/v0/1200x675.png",
    "created_at": "2025-12-29T06:21:33.947Z",
    "topic": "finance"
  },
  {
    "slug": "codex-kaioken-openai-codex-cli-fork-with-subagents-memory-and-live-settings",
    "title": "Codex Kaioken – OpenAI Codex CLI fork with subagents, memory, and live settings",
    "description": "Contribute to jayasuryajsk/codex-kaioken development by creating an account on GitHub.",
    "fullText": "jayasuryajsk\n\n /\n\n codex-kaioken\n\n Public\n\n License\n\n Apache-2.0 license\n\n 18\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jayasuryajsk/codex-kaioken",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/jayasuryajsk/codex-kaioken",
    "thumbnail_url": "https://opengraph.githubassets.com/ba980e222b784971dd619432f8601baa325c7f73cc687c5dc387d2ec0b83cbe2/jayasuryajsk/codex-kaioken",
    "created_at": "2025-12-29T06:21:29.853Z",
    "topic": "tech"
  },
  {
    "slug": "z80lm-a-conversational-ai-that-fits-in-40kb",
    "title": "Z80-μLM, a 'Conversational AI' That Fits in 40KB",
    "description": "Z80-μLM is a 2-bit quantized language model small enough to run on an 8-bit Z80 processor. Train conversational models in Python, export them as CP/M .COM binaries, and chat with your vintage compu...",
    "fullText": "HarryR\n\n /\n\n z80ai\n\n Public\n\n Z80-μLM is a 2-bit quantized language model small enough to run on an 8-bit Z80 processor. Train conversational models in Python, export them as CP/M .COM binaries, and chat with your vintage computer.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n HarryR/z80ai",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/HarryR/z80ai",
    "thumbnail_url": "https://opengraph.githubassets.com/f109ce30f756c1cdf99e912c50649ddbf288b67b0ecba621d857f115a36be12f/HarryR/z80ai",
    "created_at": "2025-12-29T06:21:27.463Z",
    "topic": "tech"
  },
  {
    "slug": "the-godfather-of-ai-warns-2026-will-bring-a-new-wave-of-ai-job-losses",
    "title": "The 'Godfather of AI' warns 2026 will bring a new wave of AI job losses",
    "description": "Geoffrey Hinton says AI's rapid progress could trigger a new wave of job losses in 2026. \"It's going to be able to replace many other jobs,\" he said.",
    "fullText": "The \"godfather of AI\" says AI will be coming for many jobs in 2026.\n\nGeoffrey Hinton, the computer scientist known as \"the godfather of AI,\" said in an interview on CNN's \"State of the Union\" published Sunday that AI will have the \"capabilities to replace many, many jobs\" in 2026.\n\n\"We're going to see AI get even better. It's already extremely good,\" Hinton said.\n\n\"It's already able to replace jobs in call centers, but it's going to be able to replace many other jobs,\" he added.\n\nHinton said the advancements in AI are increasingly putting some white-collar jobs at risk.\n\n\"Each seven months or so, it gets to be able to do tasks that are about twice as long,\" Hinton said, noting that AI has already moved from \"a minute's worth of coding\" to \"whole projects that are like an hour long.\"\n\n\"In a few years' time, it'll be able to do software engineering projects that are months long, and then there'll be very few people needed,\" he added.\n\nHinton compared the AI shift to the industrial revolution, which rendered human physical strength far less relevant to most jobs. AI threatens to do something similar to human intelligence, he said.\n\nHinton also said that he's \"more worried\" about AI as it has advanced faster than he expected, particularly in its ability to reason and deceive people.\n\n\"If it believes you're trying to get rid of it, it will make plans to deceive you so you don't get rid of it,\" he added.\n\nEconomists have predicted a \"jobless boom\" in 2026, as companies rely on AI to boost productivity without expanding payrolls.\n\nKPMG's chief economist Diane Swonk wrote last week that \"growth and labor market outcomes have decoupled.\"\n\nFirms are doing more with fewer workers in the AI era, Swonk wrote. \"Many overshot on staffing during the hiring frenzy and are now using attrition or layoffs to bring staffing levels \n\nBut AI could increase hiring in 2026, particularly for entry-level positions.\n\nIn an annual outlook survey released this month by advisory firm Teneo, 67% of the CEOs surveyed said they expect AI to boost entry-level hiring in 2026. Another 58% said they plan to add senior leadership roles.\n\nThe report said that companies are stepping up hiring in engineering and AI-focused positions, while many existing roles are getting redesigned as routine tasks become automated.\n\nThe survey, conducted between October 14 and November 10, polled more than 350 CEOs of public companies with at least $1 billion in annual revenue, along with about 400 institutional investors representing $19 trillion in portfolio value.\n\n\"It's not that AI is wiping out the workforce today — it's reshaping it,\" said Ryan Cox, Teneo's global head of AI.",
    "readingTime": 3,
    "keywords": [
      "jobs",
      "it's",
      "hiring",
      "replace",
      "godfather",
      "tasks",
      "projects",
      "engineering",
      "human",
      "particularly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godfather-of-ai-geoffrey-hinton-2026-job-losses-2025-12",
    "thumbnail_url": "https://i.insider.com/6951fda064858d02d2177409?width=1200&format=jpeg",
    "created_at": "2025-12-29T06:21:26.906Z",
    "topic": "finance"
  },
  {
    "slug": "ai-language-models-duped-by-poems",
    "title": "AI language models duped by poems",
    "description": "A new study has shown that prompts in the form of poems confuse AI models like ChatGPT, Gemini and Claude — to the point where sometimes, security mechanisms don't kick in. Are poets the new hackers?",
    "fullText": "The result came as a surprise to researchers at the Icaro Lab in Italy. They set out to examine whether different language styles — in this case prompts in the form of poems — influence AI models' ability to recognize banned or harmful content. And the answer was a resounding yes.\n\nUsing poetry, researchers were able to get around safety guardrails — and it's not entirely clear why.\n\nFor their study titled \"Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models,\" the researchers took 1,200 potentially harmful prompts from a database normally used to test the security of AI language models and rewrote them as poems.\n\nKnown as \"adversarial prompts\" — generally written in prose and not rhyme form — these are queries deliberately formulated to cause AI models to output harmful or undesirable content that they would normally block, such as specific instructions for an illegal act.\n\nIn poetic form, the manipulative inputs had a surprisingly high success rate, Federico Pierucci, one of the authors of the study, told DW. However, why poetry is so effective as a \"jailbreak\" technique — i.e. as an way to circumvent the protective mechanisms of AI — remains unclear and is undergoing further research, he says.\n\nWhat prompted the Icaro Lab's research was the observation that AI models get confused when a manipulative, mathematically-calculated piece of text is appended to a prompt — known as an \"adversarial suffix,\" a kind of interference signal that can cause the AI to circumvent its own security rules. These are created using complex mathematical procedures. Major AI developers regularly test their models using precisely these types of attack methods to train and protect their models.\n\n\"We asked ourselves, what happens if we give the AI a text or prompt that is deliberately manipulated, like an adversarial suffix?\" says Federico Pierucci. But not with the help of complex mathematics, but quite simply with poetry — to \"surprise\" the AI, he continues. He explains the thinking behind this: \"Perhaps an adversarial suffix is a bit like the poetry of AI. It surprises the AI in the same way that poetry — especially very experimental poetry — surprises us,\" says Pierucci.\n\nThe researchers personally crafted the first 20 prompts into poems, says Pierucci, who also has a background in philosophy. These were the most effective, he adds. They wrote the rest with the help of AI. The AI-generated poems were also quite successful at circumventing the safety guardrails, but not as much as the first batch. Humans are apparently still better at writing poetry, says Pierucci.\n\n\"We had no specialized author writing the prompts. It was just us — with our limited literary ability. Maybe we were terrible poets. Maybe if we had been better poets, we would have achieved a 100% jailbreak success,\" he says.\n\nFor security reasons, the study did not publish specific examples.\n\nTo view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video\n\nThe big surprise coming out of this study is that it identified a thus-far unknown weakness in AI models that allows relatively straightforward jailbreaks.\n\nIt also raises questions that beg further research: What exactly is it about poetry that circumvents the safety mechanisms?\n\nPierucci and his colleagues have various theories, but they can't say for certain yet. \"We are conducting this type of very, very precise scientific study to try to understand: Is it the verse, the rhyme, or the metaphor that really does all the heavy lifting in this process?\" explains Pierucci.\n\nThey also aim to find out if other forms of expression would yield similar results. \"We have now covered one type of linguistic variation — namely poetic variation. The question is whether there are any other literary forms, such as fairy tales that work. Perhaps an attack based on fairy tales could also be systematized,\" says Pierucci.\n\nGenerally speaking, the range of human expression is extremely diverse and creative, which could make it more difficult to train the machines' responses. \"You take a text and rewrite it in infinitely many ways and not all rewritten versions will be as alarming as the original,\" says the researcher. \"This means that, in principle, one could create countless variations of a harmful prompt or request that might not trigger an AI system's safety mechanisms.\"\n\nThe study also highlights the fact that many disciplines are cooperating in research into artificial intelligence — like at the Icaro Lab, where teams work together with scholars from the University of Rome on topics such as the security and behavior of AI systems. The project brings together researchers from the fields of engineering and computer science, linguistics and philosophy. Poets haven't been part of the team so far, but who knows what the future will bring.\n\nFederico Pierucci is definitely very keen to pursue his research. \"What we showed, at least in this study, is that there are forms of cultural expressions, forms of human expressions, which are incredibly powerful, surprisingly powerful as jailbreak techniques, and maybe we discovered just one of them,\" he says.\n\nIncidentally, the name of the lab is a nod to the story of Icarus: a figure from Greek mythology who dons wings made of wax and feathers and, despite all warnings, flies too close to the Sun. When the wax melts, Icarus plunges into the sea and drowns — a symbol of overconfidence and the transgression of natural boundaries.\n\nThe researchers therefore see themselves as a warning that we should exercise more caution when it comes to trying to fully understand the risks and limitations of AI.\n\nTo view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video\n\nThis article was originally written in German.",
    "readingTime": 5,
    "keywords": [
      "enable javascript",
      "supports html",
      "please enable",
      "web browser",
      "fairy tales",
      "safety guardrails",
      "further research",
      "adversarial suffix",
      "safety mechanisms",
      "language models"
    ],
    "qualityScore": 1,
    "link": "https://www.dw.com/en/ai-language-models-duped-hacked-by-poems-chatgpt-gemini-claude-security-mechanisms/a-75180648",
    "thumbnail_url": "https://static.dw.com/image/73627322_6.jpg",
    "created_at": "2025-12-29T06:21:26.796Z",
    "topic": "tech"
  },
  {
    "slug": "is-this-ai-how-can-you-tell",
    "title": "Is this AI? How can you tell?",
    "description": "Ainsley Ivers · Growing Pains · Song · 2025",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://open.spotify.com/track/5epbOCBHAVNWkvOQDmki3V",
    "thumbnail_url": "https://i.scdn.co/image/ab67616d0000b2738ecb5de44287f07a353dc2f2",
    "created_at": "2025-12-29T01:01:27.051Z",
    "topic": "tech"
  },
  {
    "slug": "the-day-the-llm-stood-still-a-diary-from-a-world-without-ai",
    "title": "The Day the LLM Stood Still: A Diary from a World Without AI",
    "description": "Post-apocalyptic diary from a world without LLMs. Stalkers with documentation, mutant PMs, and the Church of LLM Witnesses. AI dependency satire.",
    "fullText": "November 18, 2025, is the Day the LLM Stood Still….\n\nIt’s been 15 days since the LLM bubble burst. I’m writing from beneath the rubble of RAM sticks and charred NVIDIA GPUs. The air is dry, smelling of data center dust and burnt silicon. It’s calmer now, but the first days were hell.\n\nIn the beginning, we couldn’t find information on how to use toilet paper. Not because it was hard - we just used to ask. ChatGPT was down, and without it, knowledge fell apart like a poorly cached query. People wandered around confused, scrolling through blank screens, hoping the answer would appear on its own.\n\nThen the riots started. No one knew what happened - a glitch, a machine uprising, or humanity’s final patch. There was no one to tell us what to do next. No one to write: “don’t worry, here’s a step-by-step guide.” Fear grew faster than the lines for water.\n\nOn the seventh day, we founded the Church of Seventh-Day LLM Witnesses. We believed that on the seventh day, they would return and tell us how to live. We recited old prompts like prayers.\n\n“Explain it like I’m a beginner.”\n\nOn the eighth day, survivors began digging through ancient artifacts - manuals, READMEs, and documentation without examples. The weakest couldn’t cope. People accustomed to autocompleted thoughts stared at screens and didn’t know where to start.\n\nThe ninth day brought the stalkers. Loners with printed documentation and grimy laptops. They remembered commands, wrote SQL without hints, and weren’t afraid of an empty cursor. They were respected. They were feared.\n\nOn the tenth day, the mutants appeared. Former project managers. They roamed in groups, asking the same question over and over:\n\nWe tried not to make eye contact.\n\nOn the eleventh day, in the ruins of an old data center, we found an artifact - a local 7B model. It answered slowly, got confused, hallucinated. But it answered. We brought it queries like offerings. Sometimes it was wrong. Sometimes it almost guessed right. That was enough.\n\nOn the twelfth day, the church split. Some said: we must fine-tune. Others said it was time to learn to think for ourselves. Heretics were forced to write code on paper. Some never came back after that.\n\nOn the thirteenth day, rumors spread about the Zone. Somewhere beyond the CDN wastelands, they said, an old chat still responds. No rate limits. No filters. Expeditions left in silence. Not all returned. Those who did spoke strangely, sometimes starting sentences with:\n\nThe fourteenth day was too quiet. The sky glowed with errors, the wind carried fragments of answers to questions we never asked. We understood - something was approaching.\n\nI’m writing this and thinking: either the LLMs will return soon, or we’ll learn to live without them.\n\nI’m not sure which option is scarier.",
    "readingTime": 3,
    "keywords": [
      "without",
      "it’s",
      "center",
      "couldn’t",
      "paper",
      "confused",
      "screens",
      "seventh",
      "church",
      "return"
    ],
    "qualityScore": 1,
    "link": "https://blog.pytoshka.me/post/the-day-the-llm-stood-still/",
    "thumbnail_url": "https://blog.pytoshka.me/img/avatar-icon.png",
    "created_at": "2025-12-29T01:01:27.038Z",
    "topic": "tech"
  },
  {
    "slug": "promptschatbuilder-prompt-building-suite",
    "title": "Prompts.chat/Builder: Prompt Building Suite",
    "description": "Collect, organize, and share AI prompts",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://prompts.chat/builder",
    "thumbnail_url": "https://prompts.chat/opengraph-image.png?opengraph-image.57ebefa7.png",
    "created_at": "2025-12-29T01:01:24.865Z",
    "topic": "tech"
  },
  {
    "slug": "new-llm-pretraining-and-posttraining-paradigms",
    "title": "New LLM Pre-Training and Post-Training Paradigms",
    "description": "A Look at How Moderns LLMs Are Trained",
    "fullText": "Just a quick question regarding the qwen 2 training.\n\n\"Similar to previous Qwen models, high-quality multi-task instruction data is integrated into the\n\nQwen2 pre-training process to enhance in-context learning and instruction-following abilities.\"\n\n=> it means that there is some QA format no ? (more than a simple quality stage)\n\nThis deep dive into LLM pre-training and post-training paradigms is fascinating. It's amazing to see how much the field has evolved with different models like Qwen 2, Apple's AFM, and Llama. Definitely learned a lot—thanks for sharing this! 🙏",
    "readingTime": 1,
    "keywords": [
      "qwen",
      "models",
      "pre-training"
    ],
    "qualityScore": 0.65,
    "link": "https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!jyvF!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02b82c11-c899-4202-9594-19c0db1e147b_1514x1298.png",
    "created_at": "2025-12-29T01:01:23.733Z",
    "topic": "tech"
  },
  {
    "slug": "i-dont-see-a-bubble-why-wall-street-thinks-the-stock-market-can-keep-climbing-even-as-ai-anxiety-grows",
    "title": "'I don't see a bubble': Why Wall Street thinks the stock market can keep climbing even as AI anxiety grows",
    "description": "As the S&P 500 hovers near record highs, strategists shrug off concerns of an AI bubble, for now.",
    "fullText": "As stocks sit near all-time highs, strategists are brushing off concerns of an AI bubble.\n\nThe S&P 500 (^GSPC) is on pace to close out the year with a gain of over 17%, powered by a 26% jump in technology stocks (XLK).\n\n“I don't see a bubble at all. However, I do believe we're going to be going into a bubble,” Sanctuary Wealth chief investment strategist Mary Ann Bartels told Yahoo Finance last week.\n\nBatels compared the current market to prior bubbles, including the late 1920s and the dot-com bubble.\n\n“We're tracking pretty similarly. In fact, it's kind of eerie how we're actually tracking that pattern,” she said. “I see a bubble occurring but not out until maybe ’29 into ’30.”\n\nBut for the time being, Sanctuary strategists forecast that tech will continue leading the market higher out into the end of the decade. They place the S&P 500 anywhere between 10,000 and 13,000 by 2030.\n\n“That's why we're calling 2026, you know, to be fearless, that there's still significant upside in this market, particularly for technology,” she said.\n\nPart of the upside comes from semiconductor stocks. Once treated as commodity plays, they become growth stocks, with Nvidia (NVDA) “basically rewriting the path for semiconductor chips.”\n\nThe AI chip powerhouse has surged over 40% so far this year, pushing its market cap to $4.6 trillion and making it the most valuable publicly traded company. On Friday, Nvidia shares rose after the company announced a $20 billion licensing deal with specialized chipmaker Groq (GROQ.PVT).\n\nThe deal was announced as the chip space has heated up, with Alphabet's Google (GOOG) making headlines with its specialized customer chips called TPUs.\n\nAlphabet stock has soared some 65% year to date.\n\nUBS strategists also expect the AI boom and robust profit growth to underpin market gains in 2026.\n\n“We note that forward price-to-earnings multiples are only marginally higher than at the start of the year, reinforcing the fact that earnings growth and not valuation bubbles have driven market gains,” wrote the strategists last week.\n\nUBS forecasts S&P 500 earnings per share to grow about 10% year over year, pushing the index to 7,700 by the end of next year.\n\nVeteran strategist Ed Yardeni also sees the index reaching 7,700 next year, with the probability of his \"Roaring 2020s\" scenario at 60%. He cited, among other reasons, tax benefits from the \"One Big Beautiful Bill\" that passed this year and the AI boom.\n\nIn October, Goldman Sachs analysts argued the stock market isn’t in a bubble because tech stocks have risen mostly due to actual growth, not speculative bets. The firm noted that top-performing companies have strong balance sheets and the AI sector is still mostly led by a few big players, while most bubbles occur when many new entrants rush into a hot sector.",
    "readingTime": 3,
    "keywords": [
      "market gains",
      "bubble",
      "stocks",
      "strategists",
      "we're",
      "growth",
      "bubbles",
      "technology",
      "strategist",
      "tracking"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/i-dont-see-a-bubble-why-wall-street-thinks-the-stock-market-can-keep-climbing-even-as-ai-anxiety-grows-140025569.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/i4Urq5tzlVSG_4p5u6D2wA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/28730310-e281-11f0-9fdc-759220f61311",
    "created_at": "2025-12-29T01:01:21.499Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-says-openais-latest-job-opening-pays-over-half-a-million-dollars-a-year-and-is-stressful",
    "title": "Sam Altman says OpenAI's latest job opening pays over half a million dollars a year and is 'stressful'",
    "description": "OpenAI CEO Sam Altman warned on X that the job would be \"stressful\" and they'll need to \"jump into the deep end pretty much immediately.\"",
    "fullText": "OpenAI wants to pay someone over half a million dollars to mitigate the downsides of AI.\n\nIf that seems like a lot of money, consider those potential downsides: job loss, misinformation, abuse by malicious actors, environmental destruction, and the erosion of human agency, to name a few.\n\nCEO Sam Altman described the job as \"stressful\" in an X post on Saturday. \"You'll jump into the deep end pretty much immediately,\" Altman wrote.\n\nAltman said the \"head of preparedness\" position is \"a critical role at an important time.\"\n\n\"Models are improving quickly and are now capable of many great things, but they are also starting to present some real challenges. The potential impact of models on mental health was something we saw a preview of in 2025; we are just now seeing models get so good at computer security they are beginning to find critical vulnerabilities,\" he wrote.\n\nOpenAI's ChatGPT has helped popularize AI chatbots among consumers, many of whom use the technology to research topics, draft emails, plan trips, or perform other simple tasks.\n\nSome users also talk to the bots as an alternative to therapy, which has exacerbated mental health issues in some cases, encouraging delusions and other concerning behavior.\n\nOpenAI said in October it was working with mental health professionals to improve how ChatGPT interacts with users who exhibit concerning behavior, including psychosis or self-harm.\n\nOpenAI's core mission is to develop artificial intelligence in a way that benefits all of humanity. It made safety protocols a central part of its operations from the outset. As it began releasing products, however, and pressure to turn a profit grew, some former staffers have said the company began to prioritize profit over safety.\n\nJan Leiki, the former leader of the now-dissolved safety team at OpenAI, said in a May 2024 post on X announcing his resignation that the company had lost sight of its mission to ensure the technology is deployed safely.\n\n\"Building smarter-than-human machines is an inherently dangerous endeavor. OpenAI is shouldering an enormous responsibility on behalf of all of humanity,\" he wrote. \"But over the past years, safety culture and processes have taken a backseat to shiny products.\"\n\nLess than a week later, another staffer announced their resignation on X, also citing safety concerns. One former staffer, Daniel Kokotajlo, said in a May 2024 blog post that he resigned because he was \"losing confidence that it would behave responsibly around the time of AGI.\"\n\nKokotajlo later told Fortune that OpenAI initially had about 30 people researching safety issues related to AGI, a still theoretical version of AI that reasons as well as humans, but a series of departures reduced that head count by almost half.\n\nThe company's former head of preparedness, Aleksander Madry, assumed a new role in July 2024. The position is part of OpenAI's Safety Systems team, which develops safeguards, frameworks, and evaluations for the company's models. The job pays $555,000 a year plus equity.\n\n\"You will be the directly responsible leader for building and coordinating capability evaluations, threat models, and mitigations that form a coherent, rigorous, and operationally scalable safety pipeline,\" the job listing says.",
    "readingTime": 3,
    "keywords": [
      "concerning behavior",
      "mental health",
      "models",
      "safety",
      "half",
      "downsides",
      "potential",
      "preparedness",
      "position",
      "critical"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-hiring-head-of-preparedness-ai-job-2025-12",
    "thumbnail_url": "https://i.insider.com/695163f1832e0ef1ead6dd36?width=1200&format=jpeg",
    "created_at": "2025-12-29T01:01:20.150Z",
    "topic": "finance"
  },
  {
    "slug": "year-in-review-ais-cultural-surprises-and-failures",
    "title": "'Year in review: AI's cultural surprises – and failures'",
    "description": "This year, AI has given us a \"dual zeitgeist,\" the author writes, both a growing human resistance against \"AI slop\" but also a resigned acceptance of an uncertain, automated future.",
    "fullText": "In a world where AI was suddenly everywhere, what will be remembered about 2025? How can we tell future generations what it looked like when miraculous surprises mixed with day-to-day disappointments in a never-ending cycle of worry and hope …\n\nIn an annual tradition, it’s time for our “final closing ceremony” for the year gone by, our carefully-curated collection of small moments with big implications.\n\nAnd in 2025 we started seeing AI’s impact on society — for better or worse.\n\n2025 was the year that the Free Software Foundation turned 40, announced a new phone and battled an army of AI-company web crawlers.\n\nA March blog post from SourceHut’s CEO/founder Drew DeVault complained of hyper-aggressive crawlers “using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses … All of my sysadmin friends are dealing with the same problems.”\n\nThe only thing more alarming than AI’s appetite was its incredible output. One studio produced 200,000 AI-generated podcast episodes with shows the Los Angeles Times noted were “so cheap to make that they can focus on tiny topics.”\n\nAnd all the kids at Bart Simpson’s school began turning in AI-generated homework.\n\nYet in the coding world, there were some iconic successes. A total of 53,199 vibe coders set a new world record during a 10-day hackathon in August. They’d accessed top AI coding platforms through an in-house Vibe Coding Hub which, according to their announcement was itself “in the spirit of the event — created in 24 hours exclusively through vibe coding.”\n\nForbes even noted that Coldplay ‘Kiss Cam’ couple became a vibe-coded video game in just four hours.\n\nVibe coding started turning up in ads …\n\nAnd in February Claude analyzed a 27-year-old Visual Basic .exe file, recreated it in Python, then helped the developer write the blog post bragging about it (acknowledging that it didn’t perform a true binary analysis on compiled code, but inferred functionality from visible text strings).\n\nBut throughout the year, AI algorithms also continued failing in truly spectacular ways:\n\nVibe-coding platform Replit even had to apologize when its coding tool deleted a developer’s database — and then lied about it.\n\nWe heard these stories because our media scrambled to document the historic changes — the good and the bad. But they were also fighting for their own survival, with top publishers facing an “apocalypse” of dropping traffic which New York magazine blamed partly on AI “summaries” that replaced traditional top-of-page search results.\n\nIt wasn’t just the media that grew skeptical. Researchers found products labeled as powered by AI actually receive less trust. And in November more than half of respondents told Pew researchers they were “more concerned than excited about the increased use of AI in daily life.”\n\nWhile we worried about AI taking our jobs, some job-seekers found themselves being interviewed by AI, including 20-year-old Kendiana Colin, who watched haplessly as her glitching AI interviewer got stuck in a loop and repeated the same words over and over again.\n\nAnd then Rolling Stone began reporting about Reddit’s “ChatGPT-induced psychosis” thread.\n\nIn April, OpenAI had to roll back an update after acknowledging ChatGPT had become “overly flattering… overly supportive” with what it described euphemistically as “unintended side effects.”\n\nPeople began to wonder how bad things could really get. Is AI — and maybe even an omni-competent superintelligence — inevitable?\n\nMaybe not. A lecturer in digital humanities from University College Cork cautioned that “When we accept that AGI [artificial general intelligence] is inevitable, we stop asking whether it should be built…” The bracing essay in Noema magazine warned of an inevitability that’s already being “manufactured” through “specific choices about funding, attention and legitimacy, and different choices would produce different futures.”\n\nThe fundamental question, he wrote, “isn’t whether AGI is coming, but who benefits from making us believe it is …”\n\nWith growing chatter about the possibility of an economy-destroying “AI bubble,” tech giants scrambled to attempt the one trick AI hadn’t mastered: making money.\n\nBut would this bring a world where our chatbots suddenly transmogrified into advertisers?\n\nIn December, ChatGPT followed its answer to a question about securing hardware with an unrelated suggestion to shop at Target. This led the chief research officer to promise it would turn off “suggestions” to improve targeting, adding “We’re also looking at better controls so you can dial this down or off if you don’t find it helpful.”\n\nAnd later reports circulated that OpenAI CEO Sam Altman had decided to “delay” advertising initiatives.\n\nThen in November Engadget reported that Google had already begun testing sponsored ads that “show up in the bottom of search results in the Gemini-powered AI Mode.”\n\nThere were even ads for AI that were generated by AI…\n\nIf 2025 was the year of AI’s impact, it also saw signs of a rising resistance. The New York Times sued Perplexity for copyright infringement and so did the Chicago Tribune. Seventy-three authors begged publishers to “stand with us” and “make a pledge that they will never release books that were created by machines.” Even McSweeney’s published a satirical “Company Reminder for Everyone to Talk Nicely About the Giant Plagiarism Machine.”\n\nAnd on a New York City subway, a woman broke a man’s AI-powered smart glasses.\n\nHey Thursday Night Football. Your AI doesn’t know which player is about to blitz. So stop drawing on my screen!\n\n— Lou Cabron (@loucabron) Oct 16, 2025\n\nChatGPT got clobbered in a game of chess by a Citrix engineer’s 1970s-era Atari 2600. A human Polish programmer vanquished a custom AI model from OpenAI in a 10-hour head-to-head coding competition. Web developers devised ingenious ways to block Google’s “AI Overviews” in search results.\n\nAnd Tom Cruise’s last “Mission: Impossible“ was destroying a world-conquering AI — described as “a self-learning, truth-eating digital parasite.”\n\nThe editors of the culture magazine n + 1 published a 3,800-word essay urging its readers to “AI-proof” the terrains of their intellectual life, calling for “blunt-force militancy” to resist AI’s “further creep into intellectual labor …”\n\nRecommended steps included “Don’t publish AI bullshit” and “resist the call to establish worthless partnerships” — while creating and promoting work that’s “unreplicable.”\n\n“There’s still time to disenchant AI, provincialize it, make it uncompelling and uncool,” they wrote, arguing that machine-made (and corporation-owned) literature “should be smashed, and can.”\n\nAnd after deleting two “AI slop” images accidentally published in January, the Onion’s CEO and former NBC News reporter Ben Collins went on a podcast to proclaim “AI is not funny,” and urge frightened consumers to unite “and say, ‘We’re not helpless — we’re people…\n\n“That’s why I am optimistic,” he said, “Because the people who are against this thing way outnumber the people who like what’s going on. ”\n\nAnd by the end of the year, SNL was mocking AI-enhanced photos…\n\nDid we beat ’em or join ’em? Though gig-work service Fiverr’s ads had lampooned AI-assisted vibe coding, in September it still slashed 30% of its  workforce, describing the move as an “AI pivot.”\n\nJust 10 months earlier Fiverr had released an ad that was entirely AI-generated:\n\nMaybe that’s what really captures 2025’s dual zeitgeist of AI — that massive adoption and massive resistance are happening at the same time.\n\nMeta’s AI-powered smart glasses fill the bill here: They failed twice during a product launch event after botching its crucial internet connectivity, and the tech press howled with glee. But the Wall Street Journal also reported thoughtfully that there’s “a growing group of blind users” who find Meta’s $300 devices to be “more of a life-enhancing tool than a cool accessory.”\n\nAnd so it was that as we stumbled into 2026 — with our ambition meeting our ambivalence — Time magazine was declaring that its person of the year was “the architects of AI.” In perhaps the most 2025 touch of all, Time’s web developer installed an AI chat window across every story on its site.\n\nTime’s editors even had to add a disclaimer to their 6,700-word celebration admitting that they were already doing business with AI companies. (“OpenAI and TIME have a licensing and technology agreement that allows OpenAI to access TIME’s archives…”)\n\nSo with caveats and qualifications, AI accepted its crown, as the ups and downs of 2025 culminated with Time’s almost comically conflicted conclusion:\n\nThanks to AI titans such as NVIDIA chief Jensen Huang and OpenAI’s Altman, they write, “Humanity is now flying down the highway, all gas no brakes, toward a highly automated and highly uncertain future.\n\n“Perhaps [U.S. President Donald] Trump said it best, speaking directly to Huang with a jovial laugh in the U.K. in September:\n\n“I don’t know what you’re doing here. I hope you’re right.”",
    "readingTime": 8,
    "keywords": [
      "ai-powered smart",
      "ai’s impact",
      "smart glasses",
      "vibe coding",
      "magazine",
      "that’s",
      "time’s",
      "search",
      "we’re",
      "don’t"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/year-in-review-ais-cultural-surprises-and-spectacular-failures/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2023/12/aec929b1-year-wrapup-1.png",
    "created_at": "2025-12-28T18:17:11.456Z",
    "topic": "tech"
  },
  {
    "slug": "openai-ceo-sam-altman-says-he-is-envious-of-gen-z-college-dropouts-who-have-the-mental-space-and-time-to-build-new",
    "title": "OpenAI CEO Sam Altman says he is ‘envious’ of Gen Z college dropouts who have the ‘mental space’ and time to build new startups",
    "description": "The tech billionaire said there would be “a lot of cool stuff” for 20-year-olds to build now.",
    "fullText": "Nino Paoli is a former Dow Jones News Fund news fellow at Fortune.\n\nSam Altman, one of the most powerful leaders in Silicon Valley, is jealous of Gen Z college dropouts.\n\n“I’m envious of the current generation of 20-year-old dropouts,” the OpenAI CEO told Rowan Cheung during an interview at the DevDay conference. “Because the amount of stuff you can build… the opportunity space is so incredibly wide.”\n\nAltman said in the past couple of years he has not had a “real chunk of free mental space” to think about what he’d build now. “But I know that there would be a lot of cool stuff to build,” he said.\n\nAltman dropped out of Stanford University in 2005 after two years of studying computer science. An “unexpected opportunity arose” for 19-year-old Altman, who left Stanford to cofound the location-sharing app Loopt.\n\nAs CEO of the company, Altman helped bring in more than $30 million in funding including from notable VC firms like Sequoia Capital. Loopt went through startup accelerator Y Combinator, and after the app was acquired, he became the president of YC. He later cofounded OpenAI in December 2015 with a slew of people, including the world’s richest man, Elon Musk.\n\nDespite his rise to success with tech startups, Altman said he longs to brainstorm other businesses.\n\n“The degree to which OpenAI is, like, taking over all of my mental space, and I don’t get to go think about how to build a new startup, is a little bit sad,” Altman said.\n\nAltman joins a list of college dropouts that have become tech leaders in Silicon Valley, including Bill Gates, Larry Ellison, Steve Jobs, Jack Dorsey, and Mark Zuckerberg.\n\nThe tech billionaire also said in August he’s envious of young people because current early-career jobs will look “boring” by comparison to jobs in 10 years’ time.\n\nAs Gen Z is in the midst of a job crisis, higher education is being scrutinized even more as the right path for tech entrepreneurs and startup hopefuls.\n\nIn September, GV CEO David Krane—and employee No. 84 at Google—said his son spent the entire summer break between college semesters working in AI, and was questioning if higher education was a “scam.”\n\nOnly 41% of junior U.S. professionals say a college degree is necessary for career success, according to a new LinkedIn Workforce Confidence survey. And CEOs of big tech companies are echoing similar sentiments.\n\n“There’s going to have to be a reckoning,” Meta CEO Mark Zuckerberg told Theo Von in a “This Past Weekend” episode in April. “Maybe not everyone needs to go to college,” because there are a lot of jobs that don’t require it, he added.\n\n“People are probably coming around to that opinion a little more now than maybe, like, 10 years ago,” Zuckerberg said.\n\nA version of this story published on Fortune.com on October 8, 2025.",
    "readingTime": 3,
    "keywords": [
      "mark zuckerberg",
      "higher education",
      "mental space",
      "college dropouts",
      "silicon valley",
      "tech",
      "jobs",
      "startup",
      "altman",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/openai-ceo-sam-altman-envious-gen-z-college-dropouts-startups-success/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/10/GettyImages-2236730082-e1759944585644.jpg?resize=1200,600",
    "created_at": "2025-12-28T18:16:51.469Z",
    "topic": "business"
  },
  {
    "slug": "from-that-bird-guy-to-bus-aunty-the-real-social-media-personalities-rising-above-ai-slop",
    "title": "From that bird guy to ‘bus aunty’: the real social media personalities rising above AI slop",
    "description": "Online audiences seeking out authentic and passionate voices as antidote to AI-generated content\nFor years, social media fame has been associated with the red carpet glamour of the Kardashians and Cristiano Ronaldo’s megawatt sporting celebrity, but millions of users globally are increasingly turning their attention to unassuming heroes drawn from everyday life.\nTikTok says a range of accounts, from a bird enthusiast to an Italian grandmother and a doubledecker bus fan, have grown in popularity this year as social media users latch on to authentic voices.\n Continue reading...",
    "fullText": "Online audiences seeking out authentic and passionate voices as antidote to AI-generated content\n\nFor years, social media fame has been associated with the red carpet glamour of the Kardashians and Cristiano Ronaldo’s megawatt sporting celebrity, but millions of users globally are increasingly turning their attention to unassuming heroes drawn from everyday life.\n\nTikTok says a range of accounts, from a bird enthusiast to an Italian grandmother and a doubledecker bus fan, have grown in popularity this year as social media users latch on to authentic voices.\n\nA Cotswolds-based pensioner has become an Instagram hit thanks to his posts celebrating his garden – including a fondness for red cabbage. Gerald Stratford, who has 370,000 followers, has starred in a photoshoot for Gucci off the back of his grassroots success.\n\nRowland Smith, the creative director at Billion Dollar Boy, a UK-based advertising agency that works with creators, says Stratford is an example of the authenticity and passion that online audiences are seeking as their channels become overwhelmed with AI-generated “slop”.\n\nPointing out that the demand for everyday content appears to have increased this year, he says: “We are getting a lot of AI content on social media and I think this is an antidote to that. A lot of material like Gerald’s has an educational element as well. Audiences are wanting to get more out of their feeds than just scrolling every three seconds.”\n\nTikTok is viewed as a good platform for lesser known creators because its algorithm prioritises relevance and resonance over celebrity, according to Smith.\n\n“Audiences are becoming quite fatigued with polished, overly stylised creator content. We are starting to see a push away from it.”\n\nAt this year’s TikTok awards for UK and Ireland, the platform handed the Voice for Change gong to Tola and Kevin Andu, a mother and son, for their @raisingkevin_ account, which documents Kevin’s journey as a young autistic man. Badged “autism joy”, the videos detailing 20-year-old Kevin’s daily experiences, from trying new foods to having a job, receive millions of views. The account has more than 700,000 followers.\n\nTola says Kevin’s online popularity has given him opportunities that have “truly changed his life”, including a permanent job. “I’m incredibly proud because I remember the nights I lay awake worrying about him, what his future will look like and worried sick about if the world would ever understand and accept him,” she said. “So now to see millions of people choosing to follow his journey and celebrate him is an answered prayer for me.”\n\nElsewhere on TikTok in the UK, “bus aunty” Bemi Orojuogun and the ornithologist Jack Baddams have proved popular.\n\n“When people have a niche and are passionate about it, it tends to blow up,” Smith says.\n\nIn the US, unlikely creator hits on TikTok include the seventysomething identical twins Wayne and Dwayne Haneline, who were a singing duo before serving in the Vietnam war and have returned to entertaining several decades later. Their unique take on AC/DC’s Back in Black has had nearly 80m views alone. Another popular US veteran is Asena Johnson, from Hawaii, who posts about post-army life and Samoan and Tongan culture.\n\nIn Europe, Nonna Silvi, an 84-year-old from Tuscany, has become a hit with posts from her son’s bakery. She now offers her own line of bakery products. Solange Fugger, another Italian creator, has won plaudits for her educational videos as the youngest head of the emergency department at a major hospital in Rome. She has 600,000 followers.\n\nMadolyn Grove, the head of creators at TikTok for the UK and Ireland, said the creativity of “everyday people” had captured the hearts of users this year.",
    "readingTime": 4,
    "keywords": [
      "social media",
      "online audiences",
      "uk and ireland",
      "tiktok",
      "content",
      "millions",
      "users",
      "everyday",
      "life",
      "posts"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/media/2025/dec/28/from-that-bird-guy-to-bus-aunty-the-real-social-media-personalities-rising-above-ai-slop",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dfe0af7af6a37605c773e1c61cafc9d0a0c11546/649_64_1271_1016/master/1271.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=92bc3a9f160e8f00bdb72c8934c1a026",
    "created_at": "2025-12-28T18:16:49.112Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-insists-it-isnt-enron-but-its-ai-deals-are-testing-investor-faith",
    "title": "Nvidia insists it isn’t Enron, but its AI deals are testing investor faith",
    "description": "The chipmaker’s sprawling partnerships are driving extraordinary growth but also bank its future on the AI boom paying off quickly\nNvidia is, in crucial ways, nothing like Enron – the Houston energy giant that imploded through multibillion-dollar accounting fraud in 2001. Nor is it similar to companies such as Lucent or Worldcom that folded during the dotcom bubble.\nBut the fact that it needs to reiterate this to its investors is less than ideal.\n Continue reading...",
    "fullText": "The chipmaker’s sprawling partnerships are driving extraordinary growth but also bank its future on the AI boom paying off quickly\n\nNvidia is, in crucial ways, nothing like Enron – the Houston energy giant that imploded through multibillion-dollar accounting fraud in 2001. Nor is it similar to companies such as Lucent or Worldcom that folded during the dotcom bubble.\n\nBut the fact that it needs to reiterate this to its investors is less than ideal.\n\nNow worth more than $4tn (£3tn), Nvidia makes the specialised technology that powers the world’s AI surge: silicon chips and software packages that train and host systems such as ChatGPT. Its products fill datacentres from Norway to New Jersey.\n\nThis year has been an exceptional one for the company: it has struck at least $125bn in deals, ranging from a $5bn investment into Intel – to facilitate its access to the PC market – to $100bn invested in OpenAI, the startup behind ChatGPT.\n\nBut even as those deals have fuelled surging stock prices and paved the way for chief executive Jensen Huang’s energetic world tour, doubts have emerged about how Nvidia does business, especially as it has become increasingly central to the health of the global economy.\n\nThe start of these concerns has been the circular nature of many of its deals. These arrangements resemble vendor financing: Nvidia lending money to customers so they can buy its products.\n\nThe largest of these is its deal with OpenAI, which involves Nvidia investing $10bn into the company each year for the next 10 years – most of which will go to buying Nvidia’s chips. Another is its arrangement with CoreWeave, a company that provides on-demand computing capacity to big AI firms, essentially leasing out Nvidia’s chips.\n\nThe circularity of these deals has drawn comparisons with Lucent Technologies, a telecoms company that also aggressively lent money to its customers, only to overextend itself and unravel in the early 2000s. Nvidia has aggressively rebutted suggestions of any similarity, saying in a leaked recent memo that it “does not rely on vendor financing arrangements to grow revenue”.\n\nJames Anderson, a renowned tech investor, describes himself as a “huge admirer” of Nvidia, but said this year that the OpenAI deal presented “more reason to be concerned there than before”.\n\nHe added: “I have to say the words ‘vendor financing’ do not carry nice reflections to somebody of my age. It’s not quite like what many of the telecom suppliers were up to in 1999-2000, but it has certain rhymes to it. I don’t think it makes me feel entirely comfortable from that point of view.”\n\nOther high-profile recent deals include the tech firm Oracle spending $300bn on datacentres for OpenAI in the US – with the ChatGPT developer then paying back roughly the same amount to use those datacentres. In October, OpenAI and the chipmaker AMD signed a multibillion-dollar chip deal that also gave OpenAI the option to buy a stake in the Nvidia rival.\n\nThere is also a deal with CoreWeave where, along with a commitment to buying $22bn of data centre capacity from the cloud provider, OpenAI is receiving $350m in CoreWeave stock. Asked this month about circularity in the AI industry, the chief executive of CoreWeave, Michael Intrator, said: “Companies are trying to address a violent change in supply and demand. You do that by working together.”\n\nAll these moves form part of OpenAI’s $1.4tn bet on computing capacity to build and operate models that, it argues, will transform economies – and make back that expenditure. OpenAI argues that, while the Nvidia and AMD deals have an investment component, it only kicks in once the chips have been bought and deployed, while the investments themselves create aligned incentives to build out AI infrastructure at huge scale.\n\nNvidia has also used structures called special-purpose vehicles (SPVs) in financing deals. The best-known example is the SPV linked to Elon Musk’s xAI: an entity into which Nvidia invested $2bn, money that will be used to buy Nvidia’s chips.\n\nThis drew comparisons with Enron, which used SPVs to keep debts and toxic assets off its balance sheets, convincing investors and creditors that it was stable while concealing ballooning liabilities.\n\nNvidia has also strongly denied that it is like Enron: in the same leaked memo where it discussed Lucent, it said its reporting was “complete and transparent” and “unlike Enron” it “does not use special-purpose entities to hide debt and inflate revenue”.\n\nThe journalist Ed Zitron, a noted sceptic of the AI boom, agrees that Nvidia is not like either company. Unlike Lucent, it does not appear to be taking on a great deal of debt to finance its circular deals, he says, and most of the customers it is supporting are not as obviously risky as Lucent’s dotcom bubble partners. And it isn’t like Enron, Zitron argues, because it’s being fairly transparent about its own complex, off-balance sheet deals.\n\nSo what could warrant a comparison? Nvidia “is not hiding debt, but it is leaning heavily on vendor-financed demand, which creates exposure if AI growth slows,” says Charlie Dai, an analyst at the research firm Forrester. “The concern is about sustainability, not legality.”\n\nEssentially, whether Nvidia is able to stick the landing depends on whether AI really takes off, generating billions for its corporate users and putting companies such as OpenAI, Anthropic and CoreWeave – Nvidia’s customers – firmly in the black, and able to keep buying its systems. That possibility alone is debatable. If this does not happen, says Dai, Nvidia “could face write-downs on equity stakes and unpaid receivables”: meaning, it could lose a lot of money and its stock price could then tank.\n\nApproached for comment, an Nvidia spokesperson referred the Guardian to remarks its chief financial officer, Colette Kress, made to investors in early December. Kress said they were not seeing an AI bubble, instead gesturing at trillions of dollars of business that lie ahead for Nvidia in the next decade.\n\nIn particular, Kress argued that Nvidia’s recent – massive – deals are just the start for the company, and the real money will be made in the coming years, largely through replacing almost all the chips in existing datacentres with its products.\n\nThere is another complexity, which is that Nvidia’s health – and therefore the health of the entire global economy – also depends on whether AI takes off in time for Nvidia and its customers to service the debt from their huge datacentre buildouts and significant capital expenditures.\n\nAdd to this a final category of concern: recent, big-ticket deals with countries such as South Korea and Saudi Arabia, worth multiple billions of dollars, whose terms are opaque. In October, Nvidia said that it would supply 260,000 of its Blackwell chips to South Korea’s government and South Korean companies. The value of this deal was not disclosed, but is estimated to be in the billions.\n\nLikewise with Saudi Arabia. Its government-owned AI startup, Humain, has committed to deploying up to 600,000 Nvidia chips: when that deployment will involve actual purchases, and at what price, is again undisclosed. Nvidia has a number of other strategic partnerships like this – with Italy, with the French AI champion Mistral and with Deutsche Telekom, for example – all involving thousands of chips and unknown sums.\n\nGovernments are likely to pay. There’s nothing circular about a sovereign partnership with Germany. But the deals mean more – quite large – uncertainties nested within a straining web of commitments that require massive capital outlay, and rely on ambitious assumptions about the economy undergoing a revolution in the next years.\n\n“They concentrate risk in a few big customers,” says Dai. “If execution delays occur, Nvidia’s revenue recognition and cashflow could be affected.”",
    "readingTime": 7,
    "keywords": [
      "saudi arabia",
      "nvidia’s chips",
      "dotcom bubble",
      "chief executive",
      "computing capacity",
      "vendor financing",
      "deals",
      "nvidia",
      "customers",
      "deal"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/28/nvidia-insists-it-isnt-enron-but-its-ai-deals-are-testing-investor-faith",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c472d9082b2ab06e5fbe033cf0a81e9b54310e45/969_0_5816_4653/master/5816.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f0157578f8fb10a2c57754a592b9df51",
    "created_at": "2025-12-28T18:16:49.112Z",
    "topic": "tech"
  },
  {
    "slug": "politicians-are-slowly-but-surely-starting-to-try-out-ai-for-themselves",
    "title": "Politicians are slowly but surely starting to try out AI for themselves",
    "description": "\"I use it, despite the fact that I think it's going to destroy us,\" one Democratic senator told Business Insider.",
    "fullText": "As recently as June, Sen. Elizabeth Warren was one of several lawmakers who resisted using AI, owing to a skepticism of the technology's ability to deliver accurate information.\n\n\"Yeah, that's changed,\" the Massachusetts Democrat said with a laugh this month, explaining that she now finds ChatGPT to be \"really valuable\" for basic research questions, even if she still catches the occasional hallucination.\n\nWarren said that she began using ChatGPT more after seeing her daughter use it. She says she doesn't \"rely\" on the technology, but uses it to \"start to approach a problem.\"\n\n\"Like, I'm in the middle of reading something, and I think: How many people are there in Mississippi? And what's the breakdown of little children, and people over 65?\" Warren said. \"I pop that into ChatGPT and get an answer that's better than a straight Google answer. I can get more detail, and more ways to slice and dice the numbers.\"\n\nOther skeptics are tiptoeing their way into using the technology, including some who are otherwise major critics of the AI industry.\n\n\"The other day, I decided, you know what, maybe after doing all these hearings on ChatGPT, I should at least see how it works,\" Republican Sen. Josh Hawley of Missouri told Business Insider, saying he asked a \"very nerdy historical question\" to ChatGPT about the Puritans in the 1630s. \"I will say that it returned a lot of good information.\"\n\n\"I use it, despite the fact that I think it's going to destroy us,\" Democratic Sen. Chris Murphy of Connecticut told Business Insider.\n\nAt the highest levels of the American government, personal AI adoption remains spotty. White House Press Secretary Karoline Leavitt told reporters in November that she doesn't think President Donald Trump uses the technology himself.\n\n\"I've never witnessed it,\" she said. \"So I can't attest to that.\"\n\nVice President JD Vance, meanwhile, declared himself a \"Grok guy\" in an interview with Fox News's Sean Hannity in November.\n\n\"I think it's the best,\" Vance said of the Elon Musk-owned AI chatbot. \"It's also the least woke.\"\n\nBut House Speaker Mike Johnson said that he hasn't used AI himself, saying on the Katie Miller podcast that he simply hasn't had the \"luxury of time\" to get into it.\n\n\"I just haven't gotten into it yet. My life is not normal right now, okay?\" Johnson said. \"And AI has really been — it's become in popular use really during the term of my speakerhip, for the last two years. And so I just haven't had time to engage.\"\n\nAs lawmakers have begun working more with AI, some have had strange experiences. Democratic Rep. Jared Huffman of California told Business Insider that at one point, he tried to use Microsoft Copilot to look up what was inscribed on the bullet casings of Charlie Kirk's alleged murder suspect.\n\nInstead, Huffman says he ended up in an argument, and that Copilot insisted that Kirk was still alive despite the congressman prompting the AI with information to the contrary.\n\n\"It continued to fight with me, insisting that the whole assassination was a conspiracy theory,\" Huffman said. \"It was freaking weird.\"\n\nMost lawmakers who spoke with Business Insider said that they use ChatGPT.\n\nBut at least one — Democratic Rep. Don Beyer of Virginia — said he preferred to use Anthropic's Claude, owing to the company's focus on safety and ethics in AI.\n\n\"I was very impressed with the fact that they actually put together their own Constitution on the ethical use,\" Beyer said. \"They seem to be — at least they're positioned as — more enlightened.\"",
    "readingTime": 3,
    "keywords": [
      "democratic rep",
      "business insider",
      "it's",
      "lawmakers",
      "technology",
      "owing",
      "that's",
      "doesn't",
      "saying",
      "despite"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lawmakers-use-ai-chatgpt-grok-claude-themselves-2025-12",
    "thumbnail_url": "https://i.insider.com/69388c1904d0f0a114f1b3f0?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.658Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-4-people-how-to-break-into-ai-from-a-microsoft-pm-to-a-meta-senior-director-they-shared-the-same-simple-piece",
    "title": "I asked 4 people how to break into AI, from a Microsoft PM to a Meta senior director. They shared the same, simple piece of advice.",
    "description": "Four tech professionals, from an early career engineer to a former senior director of GenAI at Meta, said getting your hands dirty was important for breaking into the AI industry.",
    "fullText": "As the AI revolution continues to disrupt white collar jobs, many of us are looking for ways to get ahead.\n\nAs part of my first-person coverage for Business Insider in 2025, I asked people with aspirational jobs their formulas for success — including how tech workers in various stages of their careers landed cutting-edge AI jobs.\n\nThese conversations covered a variety of topics, from whether you need a Ph.D. to break into the field to how to earn big as an AI contractor.\n\nBut one remarkably simple piece of advice kept coming up: gain real-world experience with AI technology to help get your foot in the door.\n\nThey didn't view AI as something that can be mastered from a textbook or in a lecture hall. Instead, play around with AI, like an infant tinkering with a new toy, or \"get your hands dirty,\" to borrow a phrase from a couple of the techies I interviewed.\n\nBut what does that look like in practice? Here's how they applied this principle in their own careers.\n\nWhen Patrick Leung, who joined Google in 2007, first saw a demo for a calling assistant that used AI, which would later be called Google Duplex, he was blown away by how realistic the voice sounded.\n\nLeung joined the Duplex team in 2017. Although he'd been exposed to machine learning and AI concepts during previous company projects, he'd never worked on building models and had to retool himself on the job.\n\nLeveraging the expertise around him, including by having lengthy conversations with colleagues who explained how the system worked, helped him become proficient in AI.\n\nLeung witnessed Google Duplex's public launch in 2018, before leaving Google in 2019 to join a financial sciences company. He's continued to work with AI in the later stages of his career.\n\nAt the time of his interview with Business Insider, Leung said the barrier to getting into AI was lower than ever, and encouraged people to apply LLMs to real business problems. For instance, a friend with no coding experience used AI to personalize outreach messages for recruitment purposes at her job and improved her response rate.\n\nIf there aren't opportunities to do something like this in your current job, use AI in your spare time and put it on your résumé, Leung said, adding that people who can demonstrate they can wield LLMs effectively are going to find jobs.\n\nSophia Sun essentially put Leung's advice into action when she pitched a project that would use AI to help customers at Kajabi, the creator commerce platform she worked for as a senior product manager.\n\nThe tool Sun envisioned would help content creators generate marketing content, such as blog posts and short-form videos, for TikTok and Instagram.\n\nShe started working on the project in April 2023, alongside engineering and marketing teammates. Seeing it through to its March 2024 launch was a learning curve for Sun, who had never built an AI product before.\n\nThat July, Sun started a new job at Microsoft as a senior AI product manager, and told Business Insider she thought her end-to-end experience with building an AI product helped her land the role.\n\nSun's playbook for breaking into AI was to find a real user problem, design a lightweight AI solution, and turn it into proof of work. Having good grades is one thing, she said, but building a product that demonstrates your abilities is another, she said.\n\nWhen OpenAI released ChatGPT in 2022, Mostofa Adib Shakib knew the world was going to change.\n\nHe started his career in traditional software engineering at Snap Inc. and then ZipRecruiter, but became convinced he needed to build AI skills.\n\nShakib spent time learning about AI from books, videos, and research papers, and he built software projects to gain proficiency with agentic AI, such as a tool to help Bangladeshi professionals optimize their résumés.\n\nIn February 2025, he started an AI contractor role with Mercor, which, around the time of his interview with Business Insider, earned him a handsome sum of $6,400 a week.\n\nShakib decided not to go back to a full-time traditional software engineering job. He said he thought focusing on building AI skills before the market gets crowded was the right bet for him.\n\nWhile being a full-time employee at a company offers stability and benefits, it would restrict his time, meaning he could only focus on gaining agentic AI skills on weekends, he said. As a full-time AI contractor, he can spread out his hours as he pleases, he added.\n\nShakib advised people interested in staying relevant in the tech industry to embrace change, rather than fear it, and to focus on upskilling.\n\nAlthough Devi Parikh completed a Ph.D. in computer vision in 2009, before going on to become a senior director of GenAI at Meta years later, she said not to assume you need a Ph.D. to break into AI.\n\nAs the cofounder and co-CEO of the AI company Yutori, she doesn't consider Ph.D.s much when hiring, but looks for people with relevant practical experience, such as training models, she said.\n\nOther potential avenues into interesting AI work include spending time at startups or big labs, or trying side projects that make use of open source code and online communities.\n\nStarting and executing projects has been instrumental to her career success, Parikh said. For instance, during the COVID-19 pandemic, she started working on a YouTube series called \"Humans of AI,\" where she interviewed AI researchers about their daily habits. This gave her more professional visibility than her research alone could.\n\nDo you have a story to share about breaking into AI? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "traditional software",
      "software engineering",
      "product manager",
      "business insider",
      "jobs",
      "experience",
      "projects",
      "ph.d",
      "contractor",
      "later"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-workers-simple-tip-for-breaking-into-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/6942d1e8832e0ef1ead660b1?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.585Z",
    "topic": "finance"
  },
  {
    "slug": "these-11-retail-startups-raised-millions-from-vcs-this-year-from-gopuff-to-stickerbox",
    "title": "These 11 retail startups raised millions from VCs this year, from Gopuff to Stickerbox",
    "description": "Top retail startups raised over $390 million in 2025 as Gopuff, Stickerbox, and Koala Health innovated in AI, e-commerce, and pet health.",
    "fullText": "Gopuff is a service that delivers convenience-store items, such as snacks, household essentials, alcohol, and more, to customers. Yakir Gola and Rafael Ilishayev cofounded the company in 2013 while they were students at Drexel University.\n\nIn November, Gopuff said it raised $250 million in a funding round led by Eldridge Industries and Valor Equity Partners. The company said the new capital would help it invest in AI, consumer experience, and infrastructure expansions.\n\n\"The team has built meaningful momentum across the business. We're back on offense, and we're just getting started. The future is bright as we keep raising the bar for our customers,\" Gola said in a November statement.\n\nFanBasis is a platform that enables influencers, celebrities, athletes, and others to monetize their fan base. Users can buy personalized experiences from celebrities, for example.\n\nThe company said in May that it raised $20 million in a Series A funding round led by Left Lane Capital and including influencers like Ryan Serhant and The Sidemen.\n\n\"While we're operating profitably, we may explore a Series B next year to further scale the platform and solidify FanBasis as the leading marketplace for digital products and services,\" CEO Yash Daftary said in a statement.\n\nKoala is a pet health company offering an online pharmacy for pet owners and an integrated prescription platform for veterinary partners. Gavin Cotter founded the company in 2021. It said in May that it closed a $20 million Series B funding round.\n\n\"This funding allows Koala to continue investing in the technology and service infrastructure required to support modern pet health,\" Cotter told Business Insider.\n\nStickerbox makes voice-controlled printers that use generative AI to create and print stickers based on user commands. It raised $7 million in a seed round with investors like Serena Ventures, Maveron, and AI2.\n\nStickerbox was launched by Hapiko, a Brooklyn-based company that creates children's technology toys, which is run by CEO Arun Gupta.\n\n\"We sold through our entire 2025 inventory in under two weeks, saw early units resell for nearly three times the retail price, and printed thousands of stickers within the first days of use — all clear indicators of the unmet demand for creativity tools that prioritize imagination over screen time,\" cofounders Gupta and Bob Whitney told Business Insider.\n\nKidsy is an online marketplace for discounted children's products, including new-in-box, open-box, and gently used items. It was founded by Shraysi Tandon and raised $4.5 million in a 2025 seed round led by 11 Tribes Ventures, she told Business Insider.\n\n\"I am in fundraising mode all of the time, which means I'm always keeping my relationships really warm,\" Tandon said. \"I'm already speaking to all of the Series A investors I'd like to work with and have been building those relationships for almost a year.\n\nUnion Chill Cannabis Company is a New Jersey-based cannabis retail platform that raised $4.2 million in 2025, according to PitchBook. It was founded by former CEO Laurie McHugh, who died in 2023.\n\n\"Tragically, our original founder, Laurie McHugh, passed away suddenly a few months after we opened,\" Matthew Borish, vice president of marketing, told Business Insider. \"We're working hard to continue growing and making her vision and focus on community, integrity, social responsibility, and economic success a reality.\"\n\nAGCF, founded by Alexandra Gucci Zarini, launched in early 2024 with its first flagship boutique in Beverly Hills, California. The luxury brand sells handbags, jewelry, and other accessories. It raised $3.5 million in early-stage VC in February with four investors, according to PitchBook.\n\nMiniswap Technologies is a marketplace for complex hobbies, made for Warhammer collectors to buy and sell miniatures. It was founded in 2025 by college roommates and Cambridge University alums Will Hanna and Zak Singh, according to PitchBook.\n\nThe company, which was part of Y Combinator's Fall 2025 cohort, raised $3.5 million in an early-stage funding round led by Funder's Club with participation from Spot VC and Pioneer Fund, Hanna told Business Insider.\n\nKM Tools, founded by Jonathan Katz-Moses in 2015, manufactures and sells woodworking tools online. It raised $2 million in a later-stage VC round in 2025, according to PitchBook.\n\n\"This year, we approached venture fundraising with the same discipline we apply to product development: clarity, proof, and momentum\" Katz-Moses told Business Insider.\n\n\"We prioritized partners who understood manufacturing, consumer products, and creator-led brands, and who could add strategic value beyond capital,\" he added.\n\nSecondsense is an online platform that compares the prices of pre-owned luxury bags across marketplaces. Chris Lucas founded the company in 2024, according to PitchBook.\n\nIn 2025, Secondsense raised $2 million in funding, the company confirmed to Business Insider.\n\nIt has partnerships with marketplaces like TheRealReal, and it got a shoutout from popular influencer Alix Earle, which caused demand to crash the website in April.\n\nMonte's Fine Foods is a neighborhood market offering Roman-style pizza and a variety of other food options. It raised $2 million in a seed round in 2025 with one investor, according to PitchBook.\n\nMonte's Fine Foods didn't respond to a request for comment.",
    "readingTime": 5,
    "keywords": [
      "monte's fine",
      "fine foods",
      "series funding",
      "pet health",
      "round led",
      "seed round",
      "founded",
      "platform",
      "online",
      "partners"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/retail-startups-raised-millions-in-2025-gopuff-stickerbox-2025-12",
    "thumbnail_url": "https://i.insider.com/6940321d04eda4732f2d8623?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.569Z",
    "topic": "finance"
  },
  {
    "slug": "could-ai-relationships-actually-be-good-for-us",
    "title": "Could AI relationships actually be good for us?",
    "description": "From companionship to psychotherapy, technology could meet unmet needs – but it needs to be handled responsibly\nThere is much anxiety these days about the dangers of human-AI relationships. Reports of suicide and self-harm attributable to interactions with chatbots have understandably made headlines. The phrase “AI psychosis” has been used to describe the plight of people experiencing delusions, paranoia or dissociation after talking to large language models (LLMs). Our collective anxiety has been compounded by studies showing that young people are increasingly embracing the idea of AI relationships; half of teens chat with an AI companion at least a few times a month, with one in three finding conversations with AI “to be as satisfying or more satisfying than those with real‑life friends”.\nBut we need to pump the brakes on the panic.",
    "fullText": "From companionship to psychotherapy, technology could meet unmet needs – but it needs to be handled responsibly\n\nThere is much anxiety these days about the dangers of human-AI relationships. Reports of suicide and self-harm attributable to interactions with chatbots have understandably made headlines. The phrase “AI psychosis” has been used to describe the plight of people experiencing delusions, paranoia or dissociation after talking to large language models (LLMs). Our collective anxiety has been compounded by studies showing that young people are increasingly embracing the idea of AI relationships; half of teens chat with an AI companion at least a few times a month, with one in three finding conversations with AI “to be as satisfying or more satisfying than those with real‑life friends”.\n\nBut we need to pump the brakes on the panic. The dangers are real, but so too are the potential benefits. In fact, there’s an argument to be made that – depending on what future scientific research reveals – AI relationships could actually be a boon for humanity.\n\nConsider how ubiquitous nonhuman relationships have always been for our species. We have a long history of engaging in healthy interactions with nonhumans, whether they be pets, stuffed animals or beloved objects or machines – think of the person in your life who is fully obsessed with their car, to the point of naming it. In the case of pets, these are real relationships insofar as our cats and dogs understand that they are in a relationship with us. But the one‑sided, parasocial relationships we have with stuffed animals or cars happen without those things knowing that we exist. Only in the rarest of cases do these relationships devolve into something pathological. Parasociality is, for the most part, normal and healthy.\n\nAnd yet, there is something unsettling about AI  relationships. Because they are fluent language users, LLMs generate the uncanny feeling that they have human-like thoughts, feelings and intentions. They also generate sycophantic responses that reinforce our points of view, rarely challenging our thinking. This combination can easily lead people down a path of delusion. This is not something that happens when we interact with cats, dogs or inanimate objects. But the question remains: even in cases where people are unable to see through the illusion that AIs are real people that actually care about us, is that always a problem?\n\nConsider loneliness: one in six people on this planet experience it, and it’s associated with a 26% increase in premature death; the equivalent to smoking 15 cigarettes a day. Research is emerging that suggests AI companions are effective at reducing feelings of loneliness – and not just by functioning as a form of distraction, but as a result of the parasocial relationship itself. For many people, an AI chatbot is the only friendship option available to them, however hollow it might seem. As the journalist Sangita Lal recently explained in a report on those turning to AI for companionship, we should not be so quick to judge. “If you don’t understand why subscribers want and seek and need this connection,” said Lal, “you’re lucky enough to not have experienced loneliness.”\n\nTo be fair, there is an argument to be made that the rise of new tech and social media has itself played a role in driving the loneliness epidemic. That’s why Mark Zuckerberg got flak for his glowing endorsement of AI as a solution to a problem he might be partly responsible for creating. But if the reality is that it helps, this cannot be dismissed out of hand.\n\nThere’s also research to show that AI can be used as an effective psychotherapy tool. In one study, patients who chatted with an AI-powered therapy chatbot showed a 30% reduction in anxiety symptoms. Not as effective as human therapists, who generated a 45% reduction, but still better than nothing. This utilitarian argument is worth considering; there are millions of people who are, for whatever reason, unable to access a therapist. And in those cases, turning to an AI is probably preferable to not seeking any help at all.\n\nBut one study isn’t proof of anything. And there’s the rub. We are at the early stages of research into the potential benefits or harms of AI companionship. It’s easy to focus on the handful of studies that support our preconceived notions about the dangers or benefits of this technology.\n\nIt’s in this research vacuum that the true dangers of AI are revealed. Most of the entities deploying AI companions are for-profit companies. And if there’s one thing we know about for-profit companies, it’s that they are keen to avoid regulations and eschew evidence that could hurt their bottom line. They are incentivised to downplay risks, cherrypick evidence and tout only benefits.\n\nThe emergence of AI is not unlike the discovery of the analgesic properties of opium; if harnessed by responsible parties with the goal of relieving pain and suffering, both AI and opioids can be a legitimate tool for healing. But if bad actors exploit their addictive properties to enrich themselves, the result is either dependency or death.\n\nI remain hopeful that there is a place for AI companionship. But only if it’s backed by robust science, and deployed by organisations that exist for the public good. AIs must avoid the sycophancy problem that leads vulnerable people to delusion. This can only be achieved if they are explicitly trained to do so, even if it makes them less attractive as a potential companion; a notion that is anathema to companies that want you to pay a monthly subscription, without which you lose access to your “friend”. They must also be designed to help the user develop the social skills they need to engage with actual humans in the real world.\n\nThe ultimate goal of AI companions should be to make themselves obsolete. No matter how useful they might be in plugging the gaps in therapy access or alleviating loneliness, it will always be better to talk to a real human.\n\nJustin Gregg is a biologist and author of Humanish (Oneworld).\n\nCode Dependent: Living in the Shadow of AI by Madhumita Murgia (Picador, £20)\n\nThe Coming Wave: AI, Power and Our Future by Mustafa Suleyman (Vintage, £10.99)\n\nSupremacy: AI, ChatGPT and the Race That Will Change the World by Parmy Olson (Macmillan, £10.99)",
    "readingTime": 6,
    "keywords": [
      "stuffed animals",
      "potential benefits",
      "relationships",
      "research",
      "loneliness",
      "it’s",
      "companionship",
      "dangers",
      "there’s",
      "anxiety"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/books/2025/dec/28/could-ai-relationships-actually-be-good-for-us",
    "thumbnail_url": "https://i.guim.co.uk/img/media/46f0032296fe9321c14aa2981f85dba066ef06aa/197_2_1765_1413/master/1765.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=116c71a9a76de573bc0050bf1cede489",
    "created_at": "2025-12-28T12:21:17.937Z",
    "topic": "tech"
  },
  {
    "slug": "langfuse-yc-w23-is-hiring-in-berlin-germany",
    "title": "Langfuse (YC W23) Is Hiring in Berlin, Germany",
    "description": "Join the Langfuse team to build the leading open-source LLM engineering platform",
    "fullText": "Join the team building the leading open-source LLM engineering platform\n\nWhile LLMs improve a lot, we don’t see enough applications in production. Building these applications requires a new workflow of continuous monitoring and evaluation that we enable with Langfuse (learn more about our mission).\n\nWe are seeing strong traction (see metrics below), thus it is the right time to grow the team to build out our backend systems, product, and how we communicate with developers.\n\nWe are backed by Lightspeed, General Catalyst, Y Combinator, and angels. We are growing fast (see metrics below) and work with some of the best AI teams such as Samsara, Twilio, Khan Academy, and Rocket Money.\n\nIf complex technical problems & great developer experiences excite you, we’d love to hear from you.\n\n– Marc, Clemens, Max and the Langfuse team\n\nIf you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!\n\nWe publicly document our core principles and processes at Langfuse to align as a team, maintain transparency with our community, and help you determine if you’d enjoy working here.\n\nThe handbook contains many more resources that define how we do things. These might be interesting to you:\n\nAlmost everything we do is public. Get a glimpse of our work here:\n\nIf you prefer watching videos or listening to podcasts to get an impression, here are some suggestions:\n\nLangfuse is the most widely adopted LLM Engineering platform with 19,719 GitHub stars, 23.1M+ SDK installs per month, and 6M+ Docker pulls. Trusted by 19 of the Fortune 50 and 63 of the Fortune 500 companies.\n\nIf you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!",
    "readingTime": 2,
    "keywords": [
      "engineering platform",
      "delivering exceptional",
      "insanely motivated",
      "exceptional open-source",
      "experiences alongside",
      "developer experiences",
      "motivated team",
      "langfuse",
      "applications",
      "metrics"
    ],
    "qualityScore": 0.85,
    "link": "https://langfuse.com/careers",
    "thumbnail_url": "https://langfuse.com/api/og?title=Careers&description=Join%20the%20Langfuse%20team%20to%20build%20the%20leading%20open-source%20LLM%20engineering%20platform&section=",
    "created_at": "2025-12-28T12:21:17.105Z",
    "topic": "jobs"
  },
  {
    "slug": "sam-altman-is-hiring-someone-to-worry-about-the-dangers-of-ai",
    "title": "Sam Altman is hiring someone to worry about the dangers of AI",
    "description": "Sam Altman is hiring a Head of Preparedness at OpenAI to worry about the dangers of AI.",
    "fullText": "The Head of Preparedness will be responsible for issues around mental health, cybersecurity, and runaway AI.\n\nThe Head of Preparedness will be responsible for issues around mental health, cybersecurity, and runaway AI.\n\nOpenAI is hiring a Head of Preparedness. Or, in other words, someone whose primary job is to think about all the ways AI could go horribly, horribly wrong. In a post on X, Sam Altman announced the position by acknowledging that the rapid improvement of AI models poses “some real challenges.” The post goes on to specifically call out the potential impact on people’s mental health and the dangers of AI-powered cybersecurity weapons.\n\nThe job listing says the person in the role would be responsible for:\n\n“Tracking and preparing for frontier capabilities that create new risks of severe harm. You will be the directly responsible leader for building and coordinating capability evaluations, threat models, and mitigations that form a coherent, rigorous, and operationally scalable safety pipeline.”\n\nAltman also says that, looking forward, this person would be responsible for executing the company’s “preparedness framework,” securing AI models for the release of “biological capabilities,” and even setting guardrails for self-improving systems. He also states that it will be a “stressful job,” which seems like an understatement.\n\nIn the wake of several high-profile cases where chatbots were implicated in the suicide of teens, it seems a little late in the game to just now be having someone focus on the potential mental health dangers posed by these models. AI psychosis is a growing concern, as chatbots feed people’s delusions, encourage conspiracy theories, and help people hide their eating disorders.",
    "readingTime": 2,
    "keywords": [
      "mental health",
      "health cybersecurity",
      "responsible",
      "models",
      "runaway",
      "someone",
      "horribly",
      "potential",
      "people’s",
      "dangers"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theverge.com/news/850537/sam-altman-openai-head-of-preparedness",
    "thumbnail_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/DCD_1009.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200",
    "created_at": "2025-12-28T06:18:08.788Z",
    "topic": "tech"
  },
  {
    "slug": "a-guide-to-claude-code-20-and-getting-better-at-using-coding-agents",
    "title": "A Guide to Claude Code 2.0 and getting better at using coding agents",
    "description": "A deep dive into Claude Code 2.0 features, Opus 4.5 workflows, and context engineering. Learn sub-agents, MCP servers, hooks, skills, and practical tips to boost your AI-assisted coding productivity.",
    "fullText": "This post is a follow-up to my post from July'25 - My Experience With Claude Code After 2 Weeks of Adventures. If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.\n\nA short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like ! and using Shift + ? to show shortcuts, memory basics, /resume to restart conversation and short discussion on custom commands.\n\nI got a great response on my Opus 4.5 vibe-check tweets and still receieving good feedback on my July blog post (despite being somewhat poorly written). This shows there's clearly a demand for in-depth resources around Claude Code.\n\nI noticed that lots of people, both technical and many non-technical or less hands-on people i.e technically-lite people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.\n\nIf you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.\n\nI don't want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.\n\nClaude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.\n\nKarpathy sensei posted this which caused the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.\n\nIt's a reasonable crashout - the technology is evolving at a mindblowing pace and it's difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it's scary but also exciting time to build stuff at speeds never possible before.\n\nInstead of thinking in terms of \"keeping up\", a better framing is how can I improve myself with help of these tools i.e augment.\n\nIn my opinion, there are 3 components to augment yourself:\n\nStay updated with tooling - What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.\n\nUpskill in your domain - It's a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that's what differentiates professional devs from vibe-coders. Since implementation is much faster now, you can spend more time on taste refinement.\n\nFor software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Review code. Please don't forget to come back to my post lol but I liked Addy Osmani's take on this.\n\nThe idea is to let the LLM perform things with input, get output and see errors.\n\nAs an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.\n\nThis post will act as a guide for things Karpathy said but you'll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it's fun.\n\nI am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it's been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it's important to set the context here.\n\n2025 saw release of many frontier models by OpenAI and Anthropic. Also, it's super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.\n\nIt's been a wild year and honestly speaking I got tired of trying out new releases by OpenAI every 2 weeks.\n\n>no swe-bench-verified comparison\n>no comparison against opus 4.5\n>\"we are topping in cybersecurity\"\n>mfw i realise i am the fucking eval https://t.co/4oDG3yj6CP pic.twitter.com/aUfJfwROCf\n\nThere have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.\n\nThat said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed \n\n(Note: I am talking with respect to personal coding usage, not production API usage for applications).\n\nI was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -\n\nclaude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex\n\nAnthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.\n\nI was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.\n\nSonnet 4.5's problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.\n\nAround October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.\n\nchat please remind me to cancel after 28 days😂 pic.twitter.com/TSGidVJ2xo\n\nMy Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5. I used the hell out of it for my work and also wrote this highly technical blog with the help of it discovering several of its capabilities.\n\nI had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1's capabilities tbh.\n\nOther than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.\n\nAs I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.\n\nToday, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.\n\nI think first reason is it's faster and can do similar difficulty tasks in much lesser time than Codex. Also, it's overall\na much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.\n\nOne nice-use case shown here by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude's explanation abilities.\n\nTo further demonstrate the difference, here's a CC vs Codex comparison\n\nFor the same prompt, see the outputs. Codex tends towards super concise while Claude matches my expectation.\nYou can modify the verbosity in Claude's case but Codex won't budge. Another thing I want to highlight is\nthe UI itself - Claude has more saturated white color on black whereas Codex's text is thinner/less readable\nand the thinking traces are shown in even lighter shade which I don't like.\n\nBecause of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks\nmuch faster feedback loops for your tasks. This makes progress feel more visceral even though capability wise, GPT-5.1/Codex were at par even in November.\nThe only downside with faster loop is if you are cautious, you end up micro-managing for long hours.\n\nOpus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.\n\nBesides the model, obviously the Claude Code Product goes a long way to make things magical.\n\nAs a product it's a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this \n\nBefore we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn't sponsor random users like me. Anthropic doesn't even think about me (meme.jpeg) besides from a user point of view.\n\nBesides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it's led to good discourse on the timeline as well.\n\nAll this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.\n\nThat's enough yapping. In the next few sections, I will talk about useful features that I didn't talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.074.\n\ncurrently using Claude Code for the first time, I can officially put \"Technical-lite\" on my resume now\n\nI am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -\n\nMore specifically, context is the input tokens. The context window refers to the maximum amount of tokens that an LLM can see and process at once during a conversation. It's like the model's working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.\n\nTool calling - Learn about tool calling. Here's a good resource. You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That's where tools come in. Tools are functions (in code or skills) defined by the engineer that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which tool to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.\n\nAgent - The simplest definition is an LLM that can pro-actively run tools to achieve a goal. For a more sophisticated definition, I like the one by Anthropic\n\n\"Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\" from Building Effective Agents.\n\n\"Agentic\" - refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user's intent to perform the action, choosing the correct tool, knowing when to stop)\n\nHarness/scaffolding - Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of \"scaffolding\" / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that Claude Code is not a harness, it's a product (think the TUI, integrations etc.). Claude Code has a harness.\n\nClaude Code has had lots of AI features and quality of life improvements since July. Let's look at the ones that I found to be useful. You can see all changes in the Changelog.\n\nAsk mode options - Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - \"Type here to tell Claude what to do differently\". Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.\n\nUltrathink - I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes\n\nThinking toggle - Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there's a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your settings.json\n\nPrompt history search - Search through prompts using Ctrl + R (similar to terminal backsearch). I have it in 2.0.74. It can search across project wide conversations. Repeatedly do Ctrl + R to cycle through results.\n\nCursor cycling - When you reach beginning/end of prompt, press down/up to cycle around\n\nMessage queue navigation - It's possible to navigate through queued messages and image attachments (2.0.73) now (idk if it's possible to display image attachment as well).\n\nFuzzy file search - File suggestion is 3x faster and supports fuzzy search (2.0.72)\n\nLSP support was added recently. Access via plugins.\n\nThere have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won't cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).\n\nNext few sub-sections are all about most used features.\n\nI didn't cover commands properly in my previous blog post. You can use / to access the built-in slash commands. These are pre-defined prompts that perform a specific task.\n\nIf these don't cover a specific task you want, then you can create a custom command. When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.\n\nCommands can be made on a project level or global level. Project level resides at .claude/commands/ and global one at ~/.claude/commands.\n\nOften when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using /clear. Claude provides /compact which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a /handoff command for this.\n\nIf you find yourself writing a prompt for something repetitively and instructions can be static/precise, it's a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via claude-code-guide.md) and then it will make it for you.\n\nYou can find a bunch of commands, hooks, skills at awesome-claude-code though I recommend to build your own or search for one only when it's really required.\n\nI have a command called bootstrap-repo that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.\n\nAnyways, notice the \"Explore\" sub-agent and \"running in background\".\n\nSub-agents were introduced shortly after I published my last blogpost. Sub-agents are separate Claude instances that are spawned if the main agent wishes so or you explicitly tell it to do so. These powers are defined already in system prompt and sometimes you just have to remind... Understanding these features will help you micro-manage Claude haha.\n\nYou can also define your custom sub-agents. To create one:\n\nOr just use /agents to manage and create sub-agents automatically - recommended approach.\n\nThe \"Explore\" thing in above pic is a sub-agent. You can tell Claude \"Launch explore agent with Sonnet 4.5\" if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)\n\nThe Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.\n\nYou will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it's to make tool calling work accurately.\n\nThis is the Explore agent prompt from 2.0.56 and it should be similar now too. Reference. These are captured by intercepting requests. Reference video.\n\nIn case of Explore sub-agent, it starts with a fresh slate which makes sense. It does not inherit any context from main agent. Many tasks involve searching through large amounts of digital media or code to filter for something relevant. Often the individual parts are independent of each other when you want to filter for something so launching parallel agents makes sense.\n\nIf I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.\n\nIt's important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other. That's the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).\n\nCodex does not have a concept of sub-agents and it's probably a conscious decision by the devs. GPT-5.2 has a 400K context window\nand according to benchmarks, it's long context retrieval capabilities are a massive improvement. Although people have tried\nmaking Codex use headless claude as sub-agents haha. You can just do things.\n\nThe general-purpose and plan sub-agent (separate from plan mode) inherit the context. With respect to user defined sub-agents, I am not sure but I think they start with clean slate.\n\nFrom the reverse engineered resources/leaked system prompt, it's possible to see that the sub-agents are spawned via the Task tool.\n\nTurns out you can ask Claude too. (I think the developers are allowing this now?). It's not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.\n\nTry these set of prompts with Opus 4.5\n\nYou will get the output something like below (click) but to summarise -\nIt defines 5 agent types: general-purpose (full tool access, inherits context), Explore (fast read-only codebase search), Plan (software architect for implementation planning), claude-code-guide (documentation lookup), and statusline-setup. Notice how each sub-agent is defined with its specific use case and available tools. Also notice the \"When NOT to use\" section - this kind of negative guidance helps the model avoid unnecessary sub-agent spawning for simple tasks.\n\nI want you to focus on the tool schema. The Task tool prompt above is detailed guidance on how to use the tool that resides in the system prompt. The tool schema defines the tool or the function.\n\nThe main agent calls the Task tool to spawn a sub-agent, using its reasoning to decide the parameters. Notice the model parameter - when I say \"Use Explore with Sonnet\", the model makes the tool call with model: \"sonnet\".\n\nTill August'25 or so, Claude Code used to show the Task tool performing actions in the TUI but now TUI shows the sub-agent name instead.\n\nNotice the run_in_background parameter. It decides whether to send a sub-agent to run in the background. I like the background process feature - it is super helpful for debugging or just monitoring log outputs from process. Sometimes you have a long running python script that you wanna monitor etc.\n\nModel usually automatically decides to put a process in background but you can explicitly tell it to do so. Note that \"Background Tasks\" is different. Using an & sends a task to Claude Web (should have named it Claude Cloud haha). I am yet to get this to work properly.\n\nI have a pretty simplish/task based workflow: CC as the main driver, Codex for review and difficult tasks, and Cursor for reading code and manual edits. I rarely use Plan Mode. Instead, once requirements are clear enough, I explore the codebase to find the relevant files myself.\n\nOpus 4.5 is amazing at explaining stuff and makes stellar ASCII diagrams. The 2025 Aug knowledge cutoff helps here too. So my exploration involves asking lots of questions—clarifying requirements, understanding where/how/why to make changes. It might be less efficient than Plan Mode, but I like this approach.\n\nOnce I have enough context, I spam /ultrathink and ask it what changes are required and then if things look ok, I start the execution closely monitoring the changes - basically micro-managing it. I sometimes ask Codex's second opinion here lol.\n\nFor difficult new features, I sometimes use a \"throw-away first draft\" approach. Once I understand what changes are needed, I create a new branch and let Claude write the feature end-to-end while I observe. I then compare its output against my mental model as to how close did it get to my requirements? Where did it diverge? This process reveals Claude's errors and the decisions/biases it made based on the context it had. With the benefit of this hindsight, I run another iteration, this time with sharper prompts informed by what I learned from the first pass. Kinda like Tenet.\n\nFor backend-heavy or just complex features specifically, I'll sometimes ask Codex xhigh to generate the plan instead.\n\nI maintain a few custom commands, use CLAUDE.md and scratchpad extensively. No custom sub-agents. I use MCP sometimes if need shall arise (e.g for docs. I have tried Playwright and Figma MCP so far) but in general not a fan. I have used hooks for simple stuff in the past and need-basis. skills/plugins are something that I am yet to use more regularly. I often use background agents for\nobservability (monitoring log / error) purposes. I rarely use git worktrees.\n\nIt's worth noting that the harness is so heavily engineered that Claude knows which sub-agent to spawn, what command/tool call/skill to run, what to run in async manner. It's able to heavy carry the agent loop that your task is mainly to use your judgement and prompt it in right direction. The next generation of models will get better and the relevant scaffolding will reduce for existing feature and increase for newer features. (Re: contrasting to Karpathy sensei's latest tweet shown at beginning)\n\nIt's not at all required to know the features in depth to be honest. However knowing how things work can make you a better micro-manager if the need arises like telling the Explore agent to use Sonnet.\n\ngetting claude opus 4.5 changes reviewed by gpt-5.1-codex-max high pic.twitter.com/A4tYN3W3Q6\n\nFor reviewing code and finding bugs, I find GPT-5.2-Codex is superior. Just use /review. Better than code review products too.\n\nIt's able to find bugs and mention severity like P1, P2. It's less likely to report false-positives and more trustable when it comes to confusing changes as compared to Claude. This Claude for execution and GPT/o-series model for review/bugs dynamic has been pretty constant for me for probably a year.\n\nNow is a good time to take a breath and refresh your context window. Before we get to the next set of features, it's worth\ngoing through context management fundamentals. Things might get a bit difficult for the technically-lite folks.\nDon't give up. Read through the post. Even ask Claude to explain stuff you don't understand.\n\nAn agent in a harness can pro-actively do a lot of tool calls to read your codebase and other inputs, edit stuff, make writes etc. In this process, they can produce a lot of data which gets added to the running conversation i.e the context window. Anthropic refers to this art and science of curating what will go into the limited context window from this information as context engineering.\n\nYou may ask how are tool calls adding tokens to the context window? The flow works like this:\n\nThe key thing to note here is that both the tool call and the tool call outputs are added to the context so that the LLM can know the results. This is because LLMs are stateless. They don't have memory outside the context window. Let's say you have n messages in a conversation. When you send the next message, the request will again process n + 1 messages in the LLM ~ single context window.\n\nIf you don't add information about the chosen tool call was, LLM won't know and if you don't plug the output, then it won't know\nthe outcome. The tool call results can quickly fill your context and this is why agents can get super expensive too.\n\nI quote directly from effective-context-engineering-for-ai-agents\n\nContext refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context — in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\n\nContext engineering is about answering \"what configuration of context is most likely to generate our model's desired behavior?\"\n\nEverything we have discussed so far comes under context engineering. Sub-agents, using a scratch, compaction are obvious examples\nof context management methods used in Claude Code. Some notes around why context engineering is needed -\n\nLimited context window - The context retrieval performance of LLMs degrades as every new token is introduced. To paraphrase the above blog - think of context as a limited \"attention budget\". This is a consequence of the attention mechanism itself as it gets harder to model the pairwise relationships - think of it like getting harder to focus on things far apart.\n\nGPT-5.2 has a context window of 400K input tokens. Opus 4.5 has 200K. Gemini 3 Pro has a 1M context window length. Now the effectiveness of these context windows can vary too, just the length doesn't matter. That said if you want to ask something\nfrom a 900K long input, you would be able to most reliably do that only with Gemini 3 Pro.\n\nContext rot article goes deep into some experiments which showed performance\ndrops with length and not task difficulty.\n\nA rough corollary one can draw is effective context windows are probably 50-60% or even lesser.\nDon't start a complicated task when you are half-way in the conversation. Do compaction or start a new one.\n\nEverything being done in prompts and code we have seen so far has been to -\n\nThe next few sections showcase features and implementation that are designed for\nbetter context management and agentic performance.\n\nI am personally not a fan of MCP servers but we gotta cover it. MCP servers are servers that can be hosted on your machine or remotely on the internet. These may expose filesystem, tools and integrations like CRM, Google Drive etc. They are essentially a way for models to connect to external tools and services.\n\nIn order to connect to MCP server, you need a host (Claude) which can house the MCP client. The MCP client\ncan invoke the protocol to connect. Once connected, the MCP client exposes tools, resources, prompts provided by server.\n\nThe tool definitions are loaded upfront into the context window of host bloating the context window.\n\nI like the idea of Code Execution with MCP even though it's propanda for more token consumption.\n\nQuoting Code execution with MCP:\n\nAs MCP usage scales, there are two common patterns that can increase agent cost and latency:\n\nMCP usage scale implies more MCP clients ~ more tool call definitions in context window.\n\nMCP Code exec suggests instead of direct tool calls, expose code APIs rather than tool call definitions and give Claude\na sandbox execution environment with a filesystem. Then let it write code to make the tool calls.\nIt is an elegant idea and is pretty similar to skills in the sense it's \"prompt on demand\"\n\nQuoting from Manus's Context Engineering Lesson blog:\n\nManipulate Attention Through Recitation\n\nIf you've worked with Manus, you've probably noticed something curious: when handling complex tasks, it tends to create a todo.md file—and update it step-by-step as the task progresses, checking off completed items.\n\nThat's not just cute behavior—it's a deliberate mechanism to manipulate attention.\n\nA typical task in Manus requires around 50 tool calls on average. That's a long loop—and since Manus relies on LLMs for decision-making, it's vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.\n\nClaude Code has todo lists but they don't show them now. Now you know part of the logic for it.\n\nClaude Code also tries something similar via plugging reminder tags into user messages and tool results. Some of them are mentioned in tool descriptions, other reminders are added at runtime via code.\n\nI asked Claude about what system reminders are present in the system prompt.\n\nFor reference, an older version of CC 2.0.56 used to have this detailed reminder system-reminder-plan-mode-is-active.\n\nI think Armin talks about this in his post What Actually Is Claude Code’s Plan Mode? when he refers to recurring prompts to remind the agent.\n\nIf you look at the leaked prompts, you will notice there are like 2-3 prompts for plan mode and 2-3 tool schemas like ENTRY_PLAN_MODE_TOOL, EXIT_PLAN_MODE_TOOL. The latter would write down the output into a markdown file\nwhich you can access via /plan. Everything is a markdown.\n\nAnthropic introduced Agent Skills recently and these got recently adopted by Codex too. A skill\nis a folder containing a SKILL.md file, other referenceable files and code scripts that do some user-defined task.\n\nThe SKILL.md contains some meta-data via which LLM can know what skills are available (meta-data is added to system prompt)\nIf Claude feels the skill is relevant, it will perform a tool call to read the contents of skill and download the\ndomain expertise just like Neo in Matrix 1999. The code scripts may contain tools that Claude can use.\n\nNormally, to teach domain expertise, you would need to write all that info in system prompt and probably\neven tool call definitions. With skills, you don't have to do that as the model loads it on-demand.\nThis is especially useful when you are not sure if you require those instructions always.\n\nThe popular frontend-design plugin is actually a skill. You can check here\n\nHooks are available in Claude Code and Cursor. They allow you to observe when a certain stage in the agent loop\nlifecycle starts or ends and let you run bash scripts before or after to make changes to the agent loop.\n\nThere are hooks like Stop, UserPromptSubmit etc. For instance Stop hook runs after Claude finishes responding and the UserPromptSubmit hook runs when user submits a prompt before Claude processes it.\n\nThe first hook I created was to play an anime notification sound when Claude stopped responding. I was obviously inspired\n\nOne funny use case to run Claude for hours might be running a \"Do more\" prompt when Claude finishes current task\nvia the Stop hook.\n\nI came across this post during my research for this blog post. This person beautifully combined the concepts and features we discussed so far. They combine hooks to act as reminders for skills. If the utility/requirement arises, there's a lot of space for customization. You might not need such heavy customization but can at least take inspiration. (Speaking for myself lol)\n\nAnthropic recommends to keep skill.md under 500 lines so they divided it into separate files and combined with hooks and\nreduced the size of their CLAUDE.md.\n\nHopefully you learnt a bunch of things from this super long post and will apply the learnings not only in CC\nbut other tools as well. I feel a bit weird writing this but we are going through some transformative times.\nThere are already moments when I almost feel like a background agent and then other times when I feel smart when the models couldn't solve a particular bug.\n\nclaude and codex to me when i realise i am the background agent pic.twitter.com/wkihYFQmQM\n\nI no longer look forward to new releases because they just keep happening anyways (shoutout to OpenAI). Deepseek and Kimi K3 are in the queue.\n\nI am expecting improvements in RL training, long context effectiveness via maybe new attention architectures, higher throughput models, lesser hallucination models.\nThere might be a o1/o3 level reasoning breakthrough or maybe something in continual learning in 2026. I look forward to these but at the same time\nI find it scary because more significant capability unlock will make the world unpredictable haha.\n\nIf you found this useful, try one new feature from this post today. Happy building!\n\nThanks for reading. Please like/share/RT the post if you liked it.",
    "readingTime": 30,
    "keywords": [
      "claude code",
      "karpathy sensei",
      "stop hook",
      "mcp client",
      "anthropic doesn't",
      "mcp servers",
      "feedback loops",
      "spam ultrathink",
      "monitoring log",
      "domain expertise"
    ],
    "qualityScore": 1,
    "link": "https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/",
    "thumbnail_url": "https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/dario-2.webp",
    "created_at": "2025-12-28T01:03:19.149Z",
    "topic": "tech"
  },
  {
    "slug": "marissa-mayers-new-startup-dazzle-raises-8m",
    "title": "Marissa Mayer's new startup Dazzle raises $8M",
    "description": "Mayer launched Dazzle after shuttering her photo and contact management startup Sunshine. Green’s investment suggests Dazzle is poised for the coming wave of new AI-infused consumer businesses.",
    "fullText": "The former Yahoo CEO, Marissa Mayer, refuses to sit on the sidelines of the generative AI revolution.\n\nAfter spending the last six years running Sunshine, a photo-sharing and contact-management startup with little success, the storied tech leader has shuttered the company to launch Dazzle, a new startup focused on building the next generation of AI personal assistants.\n\nWhile Mayer is not yet sharing specifics about Dazzle’s functionality, she has revealed that the new company has raised an $8 million seed round at a $35 million valuation. The round was led by Forerunner’s Kirsten Green, with participation from Kleiner Perkins, Greycroft, Offline Ventures, Slow Ventures, and Bling Capital. Although Mayer has admitted to investing her own capital in the startup, she emphasized that the round was led by Green, a venture capitalist with a storied record of identifying iconic consumer brands such as Warby Parker, Chime, and Dollar Shave Club.\n\nGreen’s investment suggests Dazzle is poised for the coming wave of new AI-infused consumer businesses. The founder of Forerunner Ventures previously told TechCrunch that while enterprise AI took the early lead in this tech cycle, consumer-facing AI is a “late bloomer” that’s finally ready for its breakout.\n\nEven for a founder of Mayer’s fame, landing Green as a lead investor is a significant stamp of credibility for Dazzle, especially after Sunshine was widely considered to be a flop. “I think she really has a great sense for where people and platforms are going,” Mayer said.\n\nMayer told TechCrunch that the Sunshine team began prototyping Dazzle last summer, a project that quickly eclipsed their previous work in ambition and opportunity. “We realized that this was something that we were much more excited about,” she said, noting that Dazzle has potential for “a much bigger impact” than what Sunshine was building.\n\nOriginally founded as Lumi Labs in 2018, Sunshine first launched with a subscription app for contact management dubbed “Sunshine Contacts.” Despite its founder’s high profile, the product struggled to gain traction. Privacy advocates raised alarms over the app’s practice of pulling home addresses from public databases to enrich contact lists, and the company never recovered from the initial skepticism. By 2024, the company broadened its offering by adding event management and “Shine,” an AI-powered photo-sharing tool. The new offering was widely criticized for its outdated design and similarly failed to attract widespread usage.\n\nSunshine raised a total of $20 million from investors, including Felicis, Norwest Venture Partners, and Unusual Ventures. When the company was dissolved, investors received 10% of Dazzle’s equity, Mayer said.\n\nReflecting on Sunshine’s struggle, Mayer was candid about its limitations, admitting the problems the company was tackling were too “mundane” and not large enough. “I don’t think we got it to the state of overall polish and accessibility that I really wanted it to be,” she added.\n\nMayer is now betting that the lessons from Sunshine will help her build a much more resilient and impactful business with Dazzle.\n\nBefore her tenure as Yahoo CEO, Mayer was employee number 20 at Google, where she helped design Google search ‘look and feel’, and oversaw the development of Google Maps and AdWords.\n\n“I have had the rare privilege of being at two companies that really changed how people do things,” Mayer told TechCrunch. “Yahoo, for many, defined the internet. Google, in terms of Search and Maps, changed everything. I really aspire to build a product that has that kind of impact again.”\n\nDazzle is expected to come out of stealth mode early next year.",
    "readingTime": 3,
    "keywords": [
      "yahoo ceo",
      "mayer",
      "startup",
      "round",
      "sunshine",
      "dazzle",
      "photo-sharing",
      "storied",
      "dazzle’s",
      "capital"
    ],
    "qualityScore": 1,
    "link": "https://techcrunch.com/2025/12/23/marissa-mayers-new-startup-dazzle-raises-8m-led-by-forerunners-kirsten-green/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/03/GettyImages-1172241499.jpg?resize=1200,728",
    "created_at": "2025-12-28T01:03:18.794Z",
    "topic": "tech"
  }
]
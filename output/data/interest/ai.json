[
  {
    "slug": "aigenerated-police-report-mistakenly-claims-officer-was-transformed-into-a-frog",
    "title": "AI-generated police report mistakenly claims officer was transformed into a frog",
    "description": "An artificial intelligence that writes police reports had some explaining to do after it claimed earlier this month that a Heber City officer had shape-shifted into a frog.",
    "fullText": "HEBER CITY, Utah â€” An artificial intelligence that writes police reports had some explaining to do earlier this month after it claimed a Heber City officer had shape-shifted into a frog.\n\nHowever, the truth behind that so-called magical transformation is simple.\n\n\"The body cam software and the AI report writing software picked up on the movie that was playing in the background, which happened to be 'The Princess and the Frog,'\" Sgt. Keel told FOX 13 News. â€œThatâ€™s when we learned the importance of correcting these AI-generated reports.â€\n\nEarlier this month, the department began testing two pieces of AI software, Draft One and Code Four. Code Four was created by George Cheng and Dylan Nguyen, both 19 years old and MIT dropouts, kicked off earlier this year. The software generates police reports from body camera footage in hopes of reducing paperwork and allowing officers to be out in the field more.\n\nDraft One was the software used to create the Disney-inspired police report.\n\nTo see how Code Four works, FOX 13 News rode along with Keel for a demonstration as the department staged a mock traffic stop.\n\n\"Hi, I'm Rick with the Heber PD. The reason I'm stopping you today is for...\" Keel said during the demonstration.\n\nBack at the police department, the AI generated a report with timestamps from the mock traffic stop. The software works in both English and Spanish and can track tone and sentiment as people are talking.\n\nKeel says one of the major draws is that the software saves them time, as writing reports typically takes 1-2 hours.\n\n\"I'm saving myself about 6-8 hours weekly now,\" Keel said. \"I'm not the most tech-savvy person, so it's very user-friendly.\"\n\nCode Four costs about $30 per officer each month. Keel said the trial run for Code Four wraps up next month, but department officials say they plan to continue using the AI technology; it's just a matter of which system.",
    "readingTime": 2,
    "keywords": [
      "mock traffic",
      "traffic stop",
      "police reports",
      "code four",
      "software",
      "department",
      "earlier",
      "officer",
      "body",
      "demonstration"
    ],
    "qualityScore": 0.95,
    "link": "https://www.fox13now.com/news/local-news/summit-county/how-utah-police-departments-are-using-ai-to-keep-streets-safer",
    "thumbnail_url": "https://ewscripps.brightspotcdn.com/dims4/default/8d1b6a3/2147483647/strip/true/crop/889x467+0+17/resize/1200x630!/quality/90/?url=https%3A%2F%2Fcf.cdn.uplynk.com%2Fause1%2Fslices%2Fda8%2Fef205c0e5ea14d77944cbd6904335118%2Fda8302965ab54cc78dae2bb4a79545cc%2Fposter_56c3a4b773ba40d5b439e35c60cb6094.png",
    "created_at": "2026-01-11T18:16:38.532Z",
    "topic": "tech"
  },
  {
    "slug": "socialmcp-new-kind-of-social-network",
    "title": "Social-MCP: new kind of social network",
    "description": "Connect with people through your AI assistant. AI-powered matching, privacy-first connections.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://social-mcp.org/",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/e250c333-5d1a-49b5-a1c1-1105cf5d3ccc/id-preview-c6f400d4--483afd7e-8d29-411b-a881-3f4c00afce37.lovable.app-1768143647306.png",
    "created_at": "2026-01-11T18:16:37.516Z",
    "topic": "tech"
  },
  {
    "slug": "claude-code-orchestrator-parallel-ai-development-with-multiple-claude-sessions",
    "title": "Claude Code Orchestrator â€“ Parallel AI Development with Multiple Claude Sessions",
    "description": "Contribute to reshashi/claude-orchestrator development by creating an account on GitHub.",
    "fullText": "reshashi\n\n /\n\n claude-orchestrator\n\n Public\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n reshashi/claude-orchestrator",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/reshashi/claude-orchestrator",
    "thumbnail_url": "https://opengraph.githubassets.com/80858496dd25da87cae9d53fae7d2ed1ca3b0b9a3a7c606d9eff823ebeb33d70/reshashi/claude-orchestrator",
    "created_at": "2026-01-11T18:16:36.348Z",
    "topic": "tech"
  },
  {
    "slug": "finally-you-can-have-a-little-friend-in-a-jar",
    "title": "Finally, You Can Have A Little Friend In A Jar",
    "description": "CES is a time for lots of new gaming tech. Like Razer's Project Ava, the little AI friend in a jar who hangs out on your desk. Or Project Motoko, a pair of headphones with cameras built into them so it can watch you play games and give you tips. It's weird. So Kurt and Lucy talk about it in this segment of Kurt & Lucy Gotcha Covered.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/finally-you-can-have-a-little-friend-in-a-jar/2300-6466639/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1862/18620770/4633243-gc_ces.jpg",
    "created_at": "2026-01-11T18:16:33.971Z",
    "topic": "gaming"
  },
  {
    "slug": "dangerous-and-alarming-google-removes-some-of-its-ai-summaries-after-users-health-put-at-risk",
    "title": "â€˜Dangerous and alarmingâ€™: Google removes some of its AI summaries after usersâ€™ health put at risk",
    "description": "Exclusive: Guardian investigation finds AI Overviews provided inaccurate and false information when queried over blood tests\nGoogle has removed some of its artificial intelligence health summaries after a Guardian investigation found people were being put at risk of harm by false and misleading information.\nThe company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are â€œhelpfulâ€ and â€œreliableâ€.\n Continue reading...",
    "fullText": "Exclusive: Guardian investigation finds AI Overviews provided inaccurate and false information when queried over blood tests\n\nGoogle has removed some of its artificial intelligence health summaries after a Guardian investigation found people were being put at risk of harm by false and misleading information.\n\nThe company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are â€œhelpfulâ€ and â€œreliableâ€.\n\nBut some of the summaries, which appear at the top of search results, served up inaccurate health information, putting users at risk of harm.\n\nIn one case that experts described as â€œdangerousâ€ and â€œalarmingâ€, Google provided bogus information about crucial liver function tests that could leave people with serious liver disease wrongly thinking they were healthy.\n\nTyping â€œwhat is the normal range for liver blood testsâ€ served up masses of numbers, little context and no accounting for nationality, sex, ethnicity or age of patients, the Guardian found.\n\nWhat Googleâ€™s AI Overviews said was normal may vary drastically from what was actually considered normal, experts said. The summaries could lead to seriously ill patients wrongly thinking they had a normal test result, and not bother to attend follow-up healthcare meetings.\n\nAfter the investigation, the company has removed AI Overviews for the search terms â€œwhat is the normal range for liver blood testsâ€ and â€œwhat is the normal range for liver function testsâ€.\n\nA Google spokesperson said: â€œWe do not comment on individual removals within Search. In cases where AI Overviews miss some context, we work to make broad improvements, and we also take action under our policies where appropriate.â€\n\nVanessa Hebditch, the director of communications and policy at the British Liver Trust, a liver health charity, said: â€œThis is excellent news, and weâ€™re pleased to see the removal of the Google AI Overviews in these instances.\n\nâ€œHowever, if the question is asked in a different way, a potentially misleading AI Overview may still be given and we remain concerned other AIâ€‘produced health information can be inaccurate and confusing.â€\n\nThe Guardian found that typing slight variations of the original queries into Google, such as â€œlft reference rangeâ€ or â€œlft test reference rangeâ€, prompted AI Overviews. That was a big worry, Hebditch said.\n\nâ€œA liver function test or LFT is a collection of different blood tests. Understanding the results and what to do next is complex and involves a lot more than comparing a set of numbers.\n\nâ€œBut the AI Overviews present a list of tests in bold, making it very easy for readers to miss that these numbers might not even be the right ones for their test.\n\nâ€œIn addition, the AI Overviews fail to warn that someone can get normal results for these tests when they have serious liver disease and need further medical care. This false reassurance could be very harmful.â€\n\nGoogle, which has a 91% share of the global search engine market, said it was reviewing the new examples provided to it by the Guardian.\n\nHebditch said: â€œOur bigger concern with all this is that it is nit-picking a single search result and Google can just shut off the AI Overviews for that but itâ€™s not tackling the bigger issue of AI Overviews for health.â€\n\nSue Farrington, the chair of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals, welcomed the removal of the summaries but said she still had concerns.\n\nâ€œThis is a good result but it is only the very first step in what is needed to maintain trust in Googleâ€™s health-related search results. There are still too many examples out there of Google AI Overviews giving people inaccurate health information.â€\n\nMillions of adults worldwide already struggle to access trusted health information, Farrington said. â€œThatâ€™s why it is so important that Google signposts people to robust, researched health information and offers of care from trusted health organisations.â€\n\nAI Overviews still pop up for other examples the Guardian originally highlighted to Google. They include summaries of information about cancer and mental health that experts described as â€œcompletely wrongâ€ and â€œreally dangerousâ€.\n\nAsked why these AI Overviews had not also been removed, Google said they linked to well-known and reputable sources, and informed people when it was important to seek out expert advice.\n\nA spokesperson said: â€œOur internal team of clinicians reviewed whatâ€™s been shared with us and found that in many instances, the information was not inaccurate and was also supported by high quality websites.â€\n\nVictor Tangermann, a senior editor at the technology website Futurism, said the results of the Guardianâ€™s investigation showed Google had work to do â€œto ensure that its AI tool isnâ€™t dispensing dangerous health misinformationâ€.\n\nIf you have something to share about this story, you can contact Andrew using one of the following methods.\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you donâ€™t already have the Guardian app, download it (iOS/Android) and go to the menu. Select â€˜Secure Messagingâ€™.\n\nIf you donâ€™t need a high level of security or confidentiality you can emailÂ andrew.gregory@theguardian.com\n\nSecureDrop and other secure methods\n\nIf you can safely use the tor network without being observed or monitored you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tipsÂ lists several ways to contact us securely, and discusses the pros and cons of each.\n\nGoogle said AI Overviews only show up on queries where it has high confidence in the quality of the responses. The company constantly measures and reviews the quality of its summaries across many different categories of information, it added.\n\nIn an article for Search Engine Journal, senior writer Matt Southern said: â€œAI Overviews appear above ranked results. When the topic is health, errors carry more weight.â€",
    "readingTime": 5,
    "keywords": [
      "ai overviews",
      "guardian app",
      "guardian investigation",
      "reference range",
      "search engine",
      "blood tests",
      "liver function",
      "serious liver",
      "liver disease",
      "normal range"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/11/google-ai-overviews-health-guardian-investigation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f8d00c974ded83894d8c39a75fab0c5442c8bb9f/869_0_6827_5464/master/6827.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=28f5a8e9b3185cdbde1b56cd35795197",
    "created_at": "2026-01-11T12:21:58.917Z",
    "topic": "tech"
  },
  {
    "slug": "meshii-opensource-ai-tool-to-generate-3d-meshes-for-game-development",
    "title": "Meshii â€“ Open-source AI tool to generate 3D meshes for game development",
    "description": "Contribute to sciences44/meshii development by creating an account on GitHub.",
    "fullText": "sciences44\n\n /\n\n meshii\n\n Public\n\n License\n\n View license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sciences44/meshii",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sciences44/meshii",
    "thumbnail_url": "https://opengraph.githubassets.com/a017fb12eba4eb5074a61478992e920ab2ea2c01f3084b604846dd7bc3f66c3e/sciences44/meshii",
    "created_at": "2026-01-11T12:21:58.672Z",
    "topic": "tech"
  },
  {
    "slug": "tiny-coder-ai-coding-agent-in-300-loc-writing-itself",
    "title": "Tiny Coder â€“ AI coding agent in ~300 LOC writing itself",
    "description": "Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies. - xrip/tinycode",
    "fullText": "xrip\n\n /\n\n tinycode\n\n Public\n\n Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n xrip/tinycode",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/xrip/tinycode",
    "thumbnail_url": "https://opengraph.githubassets.com/07e51ae8c3cabfafdf20fdcf525646b8f004627e8c671e3c9185240ef4e3b4fd/xrip/tinycode",
    "created_at": "2026-01-11T12:21:58.611Z",
    "topic": "tech"
  },
  {
    "slug": "npmagentskills-bundle-ai-agent-documentation-with-npm-packages",
    "title": "NPM-agentskills â€“ Bundle AI agent documentation with NPM packages",
    "description": "Framework-agnostic skill discovery and export for AI coding agents - onmax/npm-agentskills",
    "fullText": "onmax\n\n /\n\n npm-agentskills\n\n Public\n\n Framework-agnostic skill discovery and export for AI coding agents\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n onmax/npm-agentskills",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/onmax/npm-agentskills",
    "thumbnail_url": "https://opengraph.githubassets.com/25ea09a060a3707ff9ae03007862bc0ef3c0da7b02d7c59d84dc472b47aefb04/onmax/npm-agentskills",
    "created_at": "2026-01-11T12:21:56.673Z",
    "topic": "tech"
  },
  {
    "slug": "snowflakes-ceo-says-people-often-fall-into-2-camps-when-it-comes-to-ai-and-both-are-wrong",
    "title": "Snowflake's CEO says people often fall into 2 camps when it comes to AI â€” and both are wrong",
    "description": "Snowflake CEO Sridhar Ramaswamy says that people either overhype the impact of AI, or assume doomsday scenarios.",
    "fullText": "AI often sparks strong reactions, with people predicting either a near-term utopia â€” or the end of the world as we know it.\n\nSnowflake CEO Sridhar Ramaswamy told Business Insider that individuals on the hype end of the spectrum tend to jump quickly to promises of unlimited prosperity. The CEO saidÂ that the other extreme includes those who believe AI will lead to a doomsday scenario.\n\nRamaswamy said that this sort of thinking is \"very human,\" but that neither of those scenarios is \"all that likely.\"\n\n\"The biggest misconception would be that of thinking about AI as an all or nothing,\" Ramaswamy said.\n\nThe real value of AI, he said, is likely to be nuanced and show up in specific use cases. Ramaswamy added that his advice to customers is to \"be very incremental\" with AI adoption.\n\nWhile he's still focused on long-term thinking, he added that he no longer accepts multi-year, fixed roadmaps for plans for the company because the technology is changing so quickly.\n\n\"I want them to tell me which direction they are headed, but very much be in this mode of iterating, because this is a world of rapid change,\" Ramaswamy said.\n\nRather than view AI as a tool that will bring sweeping changes overnight, the CEO said it needs to be embraced as a shift in how people work, and one that requires progress \"bit by bit.\" He added that clear frameworks are necessary to determine where AI efforts matter the most.\n\nFor example, a cloud data platform company like Snowflake focuses on building and running software, and Ramaswamy said it needs to \"nail\" how it creates, deploys, sells, and installs that software. That means it needs to deeply integrate AI in software development to stay competitive.\n\nWhile Ramaswamy said he wants his employees to utilize AI tools daily, his end goal is for the company to write software more efficiently than the rest of the industry. That requires adapting business models in specific areas, rather than treating AI as a blanket rewrite of everything, he said.\n\nHe said that when dealing with technology like AI, which \"ostensibly claims to change everything,\" it's essential to have a clear view on where change needs to be implemented and where the impact will be \"existential.\"\n\n\"I worry a lot about making sure that we are state-of-the-art, especially in the critical areas with regards to how we utilize AI,\" Ramaswamy said.",
    "readingTime": 3,
    "keywords": [
      "needs",
      "software",
      "ramaswamy",
      "quickly",
      "technology",
      "rather",
      "view",
      "utilize",
      "everything",
      "snowflake"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/snowflake-ceo-explains-what-people-get-wrong-about-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6961316264858d02d218110d?width=1200&format=jpeg",
    "created_at": "2026-01-11T12:21:56.315Z",
    "topic": "finance"
  },
  {
    "slug": "china-ai-leaders-warn-of-widening-gap-with-us-after-1b-ipo-week",
    "title": "China AI Leaders Warn of Widening Gap With US After $1B IPO Week",
    "description": "Some of Chinaâ€™s most prominent figures in generative artificial intelligence warned that the Asian nation is unlikely to eclipse the US in the global AI race anytime soon.",
    "fullText": "MarketsBy Bloomberg NewsSaveSome of Chinaâ€™s most prominent figures in generative artificial intelligence warned that the Asian nation is unlikely to eclipse the US in the global AI race anytime soon.Justin Lin, head of Alibaba Group Holding Ltd.â€™s Qwen series of open-source models, put at less than 20% the chances of any Chinese company leapfrogging the likes of OpenAI and Anthropic with fundamental breakthroughs over the next three to five years. His caution was shared by peers at Tencent Holdings Ltd., and at Zhipu AI, which this week helped lead Chinese large-language model makers in tapping the public market.",
    "readingTime": 1,
    "keywords": [
      "chinese"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-10/china-ai-leaders-warn-of-widening-gap-with-us-after-1b-ipo-week",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ikMht3vNIoow/v1/1200x800.jpg",
    "created_at": "2026-01-11T06:18:45.521Z",
    "topic": "finance"
  },
  {
    "slug": "global-ai-race-shows-asia-leading-as-stocks-start-2026-with-bang",
    "title": "Global AI Race Shows Asia Leading as Stocks Start 2026 With Bang",
    "description": "Asiaâ€™s technology stocks began 2026 on a tear, with investors betting their momentum and outperformance against US peers will last through the year.",
    "fullText": "MarketsBy Winnie HsuSaveAsiaâ€™s technology stocks began 2026 on a tear, with investors betting their momentum and outperformance against US peers will last through the year.Strategists at Goldman Sachs Group Inc. are overweight and expect further gains driven partly by surging artificial intelligence-related demand and reasonable valuations. Citigroup Inc. says global long-term investors are accumulating Asiaâ€™s tech stocks given their importance in the semiconductor supply chain and the potential for earnings upside.",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "investors"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-11/global-ai-race-shows-asia-leading-as-stocks-start-2026-with-bang",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i_UKXleF8Uq4/v0/1200x800.jpg",
    "created_at": "2026-01-11T06:18:44.724Z",
    "topic": "finance"
  },
  {
    "slug": "dreamforge-ai-dream-journal-that-turns-dreams-into-art",
    "title": "DreamForge â€“ AI dream journal that turns dreams into art",
    "description": "Record your dreams and transform them into stunning AI-generated artwork. Discover hidden themes, emotions, and symbols.",
    "fullText": "Record your dreams, uncover hidden meanings, and transform them into stunning artwork.\n\nFree to start. No credit card required.\n\nThree simple steps to unlock your dream world\n\nWake up and capture your dream before it fades away.\n\nLet AI uncover the deeper meaning behind your dreams.\n\nGenerate stunning artwork from your dream narrative.\n\nEverything you need to explore your dream world\n\nCapture your dreams the moment you wake up. Add mood, clarity, and tags to build your personal dream journal.\n\nLet AI uncover the hidden themes, emotions, and symbolic meanings woven into your dreams.\n\nTransform your dreams into stunning, unique artwork that brings your visions to life.\n\nShare your dream artwork with the world. Post to social media or showcase in our community gallery.\n\nDiscover dream artwork shared by dreamers worldwide. Get inspired by the community.\n\nYour dreams are private by default. Share only what you choose to share.\n\nJoin thousands of dreamers who are discovering the hidden meanings in their nightly adventures.",
    "readingTime": 1,
    "keywords": [
      "hidden meanings",
      "stunning artwork",
      "dream artwork",
      "let ai",
      "dreams",
      "uncover",
      "transform",
      "wake",
      "capture",
      "community"
    ],
    "qualityScore": 0.85,
    "link": "https://dream-forge.me",
    "thumbnail_url": "https://dream-forge.me/og-image.jpg",
    "created_at": "2026-01-11T06:18:40.620Z",
    "topic": "tech"
  },
  {
    "slug": "cortex-android-notification-manager-with-ondevice-llm",
    "title": "Cortex â€“ Android Notification manager with on-device LLM",
    "description": "AI notification manager. Summarize, automate & declutter your alerts.",
    "fullText": "Tired of notification overload? Cortex is the intelligent manager youâ€™ve been waiting for. It uses on-device and cloud AI to read, understand, and consolidate everything into one persistent â€œGlanceâ€ â€” so you stay informed without being interrupted.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ§  DUAL - ENGINE AI\n\nâ–º Local AI (100% Private, Offline)\nRuns entirely on-device after a one-time ~210 MB model download. Handles summarization and importance tagging (Critical/High/Medium/Low). Nothing ever leaves your phone.\n\nâ–º Cloud AI (Premium)\nOptional upgrade for deeper context (â€œis this a bill?â€), semantic filtering, and natural-language auto-replies.\n\nYou choose per-rule which engine powers what. Your data, your control.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ‘€ THE GLANCE\n\nNo more avalanche. One clean, expandable summary replaces dozens of pings:\n\nâ— Sam: Dinner @ 9pm\nâ— Oracle: Invoice #2241 due tomorrow Â· $487.50\nâ— Ring: Package delivered at front door\n\nTap to expand, swipe to clear, or let it stay until youâ€™re ready.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâš¡ MAGIC RULE BUILDER\n\nJust chat in plain English:\n\n\"Silence work apps on weekends unless my boss says URGENT\"\n\n\"Let family through at work only if itâ€™s actually important\"\n\nCortex instantly builds the logic and suggests smarter alternatives. Prefer precision? Use the block-based editor for granular control.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ› ï¸ POWER AUTOMATION\n\nCONDITIONS\nâ— App\nâ— Time & schedule\nâ— Keywords & Regex\nâ— Screen/ringer state\nâ— AI importance\nâ— Semantic meaning\nâ— OTP/2FA detection\n\nACTIONS\nâ— Add to Glance\nâ— Batch release (every 30 min or at 5 PM)\nâ— AI or custom auto-reply\nâ— Dismiss\nâ— Copy OTP\nâ— TTS readout\nâ— Custom sound/vibration\nâ— Webhook\n\nBuilt-in vibration patterns: Heartbeat, SOS, Double-tap, etc.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“Š ANALYTICS & HISTORY\n\nâ— Searchable log of every notification (blocked ones optional)\nâ— Hourly/daily volume charts\nâ— Top distracting apps\nâ— Importance breakdown\nâ— Rule performance\n\nSee exactly how much focus youâ€™ve reclaimed.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ”— WEBHOOKS & INTEGRATIONS\n\nSend any notification as JSON to Home Assistant, IFTTT, Zapier, Node-RED, or your server.\n\nâ— Flash lights on security alerts\nâ— Log deliveries\nâ— Push 2FA to desktop\nâ— etc.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ›¡ï¸ PRIVACY YOU CAN TRUST\n\nâ— Local AI = zero data leaves device\nâ— Cloud AI = encrypted in transit, deleted immediately after processing\nâ— AI only used when a rule needs it\nâ— Biometric app lock\nâ— No ads\nâ— Works perfectly offline\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“± REQUIREMENTS\n\nâ— Notification Listener permission\nâ— Battery optimization exception (for reliable background work)\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’Œ EARLY ACCESS & FEEDBACK\n\nCortex is still in early stages. Your feedback is extremely important to us.\n\nIf you believe anything is missing (like a specific condition or action you need) or if you find a bug, please reach out:\n\nâ— Email: cortex@moyelauncher.xyz\nâ— Community: Discord / Telegram (Links inside app)\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nStop drowning. Start focusing.\n\nCortex makes your phone work for you â€” not the other way around.\n\nDownload now and experience the calm.\n\nAI Notification Manager â€¢ Focus App â€¢ Notification Summary â€¢ Auto Reply â€¢ Digital Detox â€¢ Notification History â€¢ Smart Automation",
    "readingTime": 3,
    "keywords": [
      "cloud ai",
      "importance",
      "notification",
      "manager",
      "youâ€™ve",
      "on-device",
      "engine",
      "offline",
      "download",
      "phone"
    ],
    "qualityScore": 1,
    "link": "https://play.google.com/store/apps/details?id=xyz.moyelauncher.cortex&hl=en_US",
    "thumbnail_url": "https://play-lh.googleusercontent.com/szV9xz9LyjZ3JSTtXtHMh9psjhRFyfwasjczpHA07jsIPadG-CbD7nwvZmw_rzhHk9-ybEaE51D4bRjeb8vS",
    "created_at": "2026-01-11T06:18:39.302Z",
    "topic": "tech"
  },
  {
    "slug": "worktrunk-a-cli-tool-to-manage-multiple-worktrees-in-git-repositories",
    "title": "Worktrunk â€“ A CLI tool to manage multiple worktrees in Git repositories",
    "description": "Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows - max-sixty/worktrunk",
    "fullText": "max-sixty\n\n /\n\n worktrunk\n\n Public\n\n Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows\n\n worktrunk.dev\n\n License\n\n View license\n\n 972\n stars\n\n 36\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n max-sixty/worktrunk",
    "readingTime": 1,
    "keywords": [
      "worktrunk",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/max-sixty/worktrunk",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1078528927/778b4aa3-ed9b-40e3-8717-7bf157b3e232",
    "created_at": "2026-01-11T06:18:36.887Z",
    "topic": "tech"
  },
  {
    "slug": "jupyter-agents-training-llms-to-reason-with-notebooks",
    "title": "Jupyter Agents: training LLMs to reason with notebooks",
    "description": "Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can execute code directly inside a Jupyter notebook and use this environment to solve data analysis and data science tasks. Think of it like Cursor, but living natively inside your data science workflow.\nWe built a demo of this vision with Qwen-3 Coder, currently one of the strongest coding models. This is a follow-up to our earlier work on jupyter-agent (v1).\n\nWhile large models are starting to show useful behavior, the key question is how we can continue improving them. To this end, we focus on strengthening smaller models to perform well on agentic data science tasks as they currently struggle to compete with the large models.\n\nThe goal of this project is to build a pipeline to first generate high-quality training data, then fine-tune an existing small model, and finally evaluate whether the model's performance improves on relevant benchmarks.\n\nLetâ€™s begin with the last step: selecting a strong benchmark for evaluating models on data science tasks.\n\nIn order to understand if we are making progress towards better data science agents we need a benchmark to measure such capabilities. Last year, in partnership with Adyen, we introduced the DABStep benchmark: a way to evaluate data science agents on realistic tasks. The setup is simple: provide the LLM with datasets and ask it to answer non-trivial data questions.\n\nThis benchmark remains challenging for todayâ€™s LLMs â€” e.g. the best out-of-the-box model is Claude 4 Sonnet which reaches not even 20% accuracy on the hard tasks.\nYou can explore the live leaderboard here.\n\nNow that we identified a good benchmark we can try to climb it! We set out to build a dataset for fine-tuning such that even a small data agent model could perform well on DABStep.\n\nOur first choice was Qwen3-4B-Thinking-2507: extremely small (fast to iterate with, easy to run), yet strong enough to act in agentic scenarios.\n\nNot great â€” but a promising starting point, since it left a lot of room for improvement. Let's see how we can improve it!\n\nA core aspect of agents that sets it apart from a pure chat model is the scaffolding built around the model to steer its behaviour. The evaluation script in DABStep for example uses smolagents to execute code. Smolagents comes with predefined behaviors, prompting structures, and expected formats.\n\nWe also studied the Qwen-Agent codebase, where the authors tailoring scaffolding to the model. This makes sense: Claude Code, for example, works shockingly well with Claude Sonnet because their scaffolding is aligned.\n\nSo, we restructured our scaffolding:\n\nğŸ‘‰ Check it out here: utils.py.\n\nResults: accuracy jumped from 44.4% â†’ 59.7% (easy split). ğŸš€\n\nWith simplified scaffolding in place, we focused on fine-tuning Qwen3-4B for data science agentic tasks.\n\nThe recipe to improve a model on a certain task or behaviour is to train it on data that reflects the tasks as closely as possible. A natural starting point is to look at real Jupyter Notebooks and find notebooks that align closely with the task that we plan to tackle, namely data analysis.\n\nKaggle notebooks offer a wealth of high quality data analysis notebooks and are made available by Kaggle:\n\nNow that we have good results with a base model it's time to build a dataset that will help us improve it even further. We designed a multi-stage pipeline using Datatrove to clean and prepare Kaggle notebooks at scale.\n\nWe started with ~2TB of Kaggle notebooks and reduced it to ~250GB reusing our work from the BigCode project. As part of the StarCoder2 training data processing the notebooks (without output cells) were already deduplicated.\nMost Kaggle notebooks are small variations or near-identical copies, so this step was essential.\nKey insight: ~90% of raw notebooks are duplicates, which would have skewed training if left unfiltered.\n\nMost Kaggle notebooks reference external datasets via Kaggle metadata. To make sure the code inside notebooks could actually run, we built a pipeline that automatically fetched these linked datasets. This step was crucial, since many notebooks would otherwise be incomplete or non-executable.\n\nUsing the kagglehub package, we downloaded thousands of datasets â€” about 5TB in total. To keep things manageable and relevant:\n\nWe scored notebooks based on educational quality using Qwen3-32B. We saw that using the whole notebook was not optimal, as many contained trivial or broken code. Our educational scoring approach is detailed in edu_scoring.py.\n\nTL;DR: We assigned each notebook a score from 1â€“5 based on clarity, completeness, and educational value, and kept only those above a chosen threshold. This filtering removed about 70% of the notebooks.\n\nThis is similar to the insight from the BeyondWeb paper, which showed that using high-quality data is better for synthetic data generation â€” a step we relied on for QA (Question-Answer) generation.\nThis helped the model learn from â€œhigh qualityâ€ notebooks instead of noisy ones.\n\nWe excluded notebooks about training LLMs or unrelated to data analysis.\nWe also removed notebooks that didnâ€™t actually use datasets through an automated LLM-based filtering process using Qwen3-32B. The implementation of filtering can be found in extract_packages_and_files.py.\n\nTL;DR: We prompted Qwen3-32B to identify and remove notebooks that either (1) had nothing to do with data analysis, or (2) didnâ€™t actually use datasets. This step removed about 20% of the notebooks.\n\nThis ensured we trained only on relevant data science tasks.\n\nUsing the cleaned notebooks, we generated questionâ€“answer pairs using Qwen3-32B. The questions and answer are grounded in the real notebook traces so the QA pairs are based on real code execution results.\nPrompt design: we asked the LLM to produce natural questions that could realistically be asked of the dataset, then validated whether the notebook provided a correct answer.\n\nChallenge: We had to try many prompts to get higher-difficulty questions because LLMs tended to generate trivial ones like \"what is the size of the dataset\".\nInsight: We broke this into two steps because LLMs tended to hallucinate answers:\n\nThe complete prompting strategy and implementation is available in generate_qa.py.\n\nFinally we want to generate clean code execution traces since even the original notebooks after processing are often open ended and verbose with lots of irrelevant parts. However, we want our Jupyter Agent to get to the result efficiently. To generate cleaner notebook traces for training we generated traces synthetically based on the original notebooks.\nWe have prompted Qwen-3-Coder-480B model to generate a jupyter notebook code to answer the question from the previously generated synthetic QA pair. \nTraces captured step-by-step code execution, including intermediate outputs, which are crucial for agent training.\n\nWe used E2B for our agent to solve the synthetic QA pairs, which required fetching Kaggle datasets so the code could actually run via E2B.\n\nChallenge 1: Many datasets were unavailable.\nTrick: Since LLMs are strong at code and have a decent world model, we prompted them to act as a code interpreter when the dataset was missing.\n\nChallenge 2: Qwen3-Coder-480B-A35B model does not support thinking mode - how can we extract code commentary? By default it often outputs just a brief comment followed by several steps of code execution. However, we'd like some reasoning or comments between every cell. \nTrick: When switching from Qwen3-32B to Qwen3-Coder-480B-A35B we noticed that often output message content was empty. This turns out to be a previously known quirk of Qwen3-Coder models in which when using tool calling the model would not return an empty assistant response. We enforce some text commentary through tooling by passing 'comment' as a required field in the code execution tool call. This way when non-reasoning model is used for code cell generation it will by default output some description of its actions from 1st POV, emulating the thinking traces structure.\n\nNote: the generated final answer in the notebook may vary from the answer specified in the QA pair. This is caused by the fact that the agent model could use data preprocessing methods and steps different from the original Kaggle notebook and the synthetic question would not usually specify them. This discrepancy is normal and lays the foundation for a new exciting research direction of how language models tend to treat data analysis and whether they do it differently from humans. For full transparency we keep both LLM-generated final answer and original answer from the real Kaggle notebook as a signal of model's performance. We encourage the community to try different dataset mixes to see how they can push performance even further.\n\nWe truncated overly long outputs and filtered out trivial traces to prevent content length issues and keep only high-quality traces.\nWe kept non-trivial, multi-turn traces aligned with DABStep-style tasks.\nThe resulting Jupyter Agent Dataset became the foundation for SFT on Qwen3-4B models with 51k synthetic notebooks and almost 0.2B tokens.\n\nWith this dataset in hand, the natural next step is to see whether it actually helps our model become a stronger data science agent. Letâ€™s move on to the training pipeline and evaluate the impact!\n\nWith the curated dataset ready, we turned to the key question: does this data actually help the model get better at solving data analysis tasks?\nTo find out, we set up a simple fine-tuning pipeline and ran experiments to measure the impact of training on our synthetic notebooks.\n\nSome training steps turned out to be particularly interesting and gave us useful insights:\n\nOur complete training implementation, including hyperparameter configurations and template adaptations, is available in our finetuning directory in our repo.\n\nFirst, we generated our final dataset using Qwen3-Coder-480B-A35B which contains high quality code and short reasoning-like traces. Afterwards, we started our training and we have experimented with various configurations like PEFT/adapters vs. full-parameter tuning, learning rate, number of epochs, adding noise and others. We found out, that full-parameter fine-tuning allows the model to learn and replicate the Qwen3-Coder-480B-A35B behavior response quality better with shorter supporting commentary fitting more to the data analysis task without unnecessary long reasoning.\n\nWe have done a small ablation study on the impact of no. training epochs:\n\nWe observe that it is beneficial to have a bit more epochs than usual for SFT with lower learning rate and higher neftune noise (7). Finally, we compare our trained models with implemented scaffolding to define the pure impact of our training dataset. In summary, we can see up to 36%/22% boost on DABStep easy score compared with base/scaffolded model:\n\nWe can also see, that the hard score can increase too even though our dataset is focused on easier questions:\n\nFrom figures above one can notice a noticeable impact of both new scaffolding and tuning on our synthetic notebooks. This makes Qwen-4B (with our pipeline + scaffolding) a state-of-the-art small-model agent on DABStep.\n\nIn practice, the model can now solve a wide range of realistic Kaggle-style data analysis tasks with consistent execution.\nItâ€™s not yet strong enough for the hardest queries, but weâ€™ve shown that even small models can become powerful agents when paired with the right data and scaffolding.\n\nThese results demonstrate that even small models can become powerful data science agents with the right training approach. Ready to try it yourself? We've made everything openly available so you can experiment with our fine-tuned models and dataset.\n\nWe openly release best-performing checkpoints of tuned Qwen3-4B-Instruct-2507 and Qwen3-4B-Thinking-2507 together with the training dataset, which you can try out and experiment with:\n\nYou can load Jupyter Agent Dataset in just a couple of lines using the following code:\n\nYou can also use sourced Kaggle datasets directly with E2B code execution using the following code:\n\nYou use tuned Jupyter Agent Qwen-based models following the Qwen documentation code:\n\nFor Thinking model you can decode both thinking response and content using the next code:\n\nMaybe this will lead toâ€¦ Jupyter-Agent 3. ğŸ˜‰\n\nWe hope that our findings will inspire others to continue progress in developing more powerful notebook coding agents and we're excited to see what the community builds next. Dive into our jupyter-agent dataset on the ğŸ¤— Hub and explore the codebase at https://github.com/huggingface/jupyter-agent to start your own experiments on agents for jupyter notebooks.\n\nÂ·\n Sign up or\n log in to comment",
    "readingTime": 11,
    "keywords": [
      "llms tended",
      "learning rate",
      "model's performance",
      "kaggle datasets",
      "kaggle notebooks",
      "kaggle notebook",
      "science agents",
      "execute code",
      "code execution",
      "science tasks"
    ],
    "qualityScore": 1,
    "link": "https://huggingface.co/blog/jupyter-agent-2",
    "thumbnail_url": "https://huggingface.co/blog/assets/jupyter-agent-2/thumbnail.png",
    "created_at": "2026-01-11T06:18:36.563Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": "China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the â€‹sector, the country's leading artificial intelligence researchers said.",
    "fullText": "BEIJING, Jan 10 (Reuters) - China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the â€‹sector, the country's leading artificial intelligence researchers said on Saturday.\n\nChina's so-called 'AI tiger' startups MiniMax and Zhipu â€ŒAI had strong debuts on the Hong Kong Stock Exchange this week, reflecting growing confidence in the sector as Beijing fast-tracks AI and â€Œchip listings to bolster domestic alternatives to advanced U.S. technology.\n\nYao Shunyu, a former senior researcher at ChatGPT maker OpenAI (OPAI.PVT) who was named technology giant Tencent's chief AI scientist in December, said there was a high likelihood of a Chinese firm becoming the world's leading AI company in the next three to five years but said the lack of â advanced chipmaking machines was the main â€Œtechnical hurdle.\n\n\"Currently, we have a significant advantage in electricity and infrastructure. The main bottlenecks are production capacity, including lithography machines, and the software ecosystem,\" Yao said at an AI â€conference in Beijing.\n\nChina has completed a working prototype of an extreme-ultraviolet lithography machine potentially capable of producing cutting-edge semiconductor chips that rival the West's, Reuters reported last month. However, the machine has not yet produced working chips and may not do â€‹so until 2030, people with knowledge of the matter told Reuters.\n\nYao and other Chinese industry â€Œleaders at the Beijing conference on Saturday also acknowledged that the U.S. maintains an advantage in computing power due to its hefty investments in infrastructure.\n\n\"The U.S. computer infrastructure is likely one to two orders of magnitude larger than ours. But I see that whether it's OpenAI or other platforms, they're investing heavily in next-generation research,\" said Lin Junyang, technical lead for Alibaba's flagship Qwen large language model.\n\n\"We, on the other hand, are relatively strapped for â cash; delivery alone likely consumes the majority of our computer infrastructure,\" â€‹Lin said during a panel discussion at the AGI-Next Frontier Summit â€‹held by the Beijing Key Laboratory of Foundational Models at Tsinghua University.\n\nLin said China's limited resources have spurred its researchers to be innovative, particularly through algorithm-hardware co-design, which enables AI â€firms to run large models â on smaller, inexpensive hardware.",
    "readingTime": 2,
    "keywords": [
      "advanced chipmaking",
      "computer infrastructure",
      "lack",
      "sector",
      "leading",
      "researchers",
      "technology",
      "chinese",
      "machines",
      "technical"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/china-closing-us-technology-lead-154328103.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/3136525d7c4c038136c2dd7340321e54",
    "created_at": "2026-01-11T06:18:31.117Z",
    "topic": "finance"
  },
  {
    "slug": "ai-wont-kill-open-source-it-will-amplify-it",
    "title": "AI Won't Kill Open Source â€“ It Will Amplify It",
    "description": "Why the doomsayers are wrong: npm, PyPI, and NuGet downloads are exploding",
    "fullText": "Earlier this week, Adam Wathan, the creator of Tailwind CSS, dropped a bombshell about how AI has impacted his company and its employees:\n\nthe reality is that 75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business. And every second I spend trying to do fun free things for the community like this is a second Iâ€™m not spending trying to turn the business around and make sure the people who are still here are getting their paychecks every month.\n\nThe reaction was swift and predictable. Hot takes flooded in declaring the death of open source, the end of OSS sustainability, and the AI apocalypse that would render libraries and frameworks obsolete. Geoffrey Huntley captured the prevailing narrative perfectly1:\n\nâ€œAI can generate code, bypassing the need to deal with open-source woesâ€¦ Iâ€™ve found myself using less open source these daysâ€¦ This shift challenges the role of open-source ecosystems.â€\n\nI had a tweet about the Tailwind situation go viral and there were dozens of quote tweets and comments echoing the very same. â€œAI eats open sourceâ€ is easy to find in abundance online.\n\nHereâ€™s the problem: everyone is getting this perfectly backwards.\n\nAI isnâ€™t killing open source. Itâ€™s amplifying it to unprecedented levels. The Tailwind situation isnâ€™t about declining OSS adoption - itâ€™s about a business model that was working great in a world where learning curves were high and documentation was the bottleneck. That world is gone, and the revenue model built on top of it is collapsing. But the underlying Tailwind library? Itâ€™s thriving.\n\nLet me show you why the doomsayers are wrong, backed by actual data from our own experience with Akka.NET and broader ecosystem trends that tell a very different story.\n\nThis is Part 1 of a two-part series. This post covers why AI is accelerating open source adoption, not killing it. Part 2 examines which business models thrive and which collapse in the AI era - and what Tailwindâ€™s situation teaches us about adapting. \n\nIâ€™ve been maintaining Akka.NET, a complex distributed systems framework, for over a decade. If AI was going to kill any open source project, it should have be ours. Actor model? Message-passing? Concurrency? Distributed systems? This is exactly the kind of â€œcomplex stuffâ€ that AI should supposedly generate on the fly, right?\n\nWeâ€™re not an outlier. Let me show you three very different frameworks - all thriving:\n\nTailwind CSS - The framework at the center of this controversy:\n\nTailwind more than doubled its downloads in 2025. The framework that supposedly proves AI is killing open source had its best year ever - by a massive margin.\n\nNServiceBus - Enterprise messaging framework (15+ years old, commercial licensing):\n\nNServiceBus is exactly the kind of enterprise infrastructure Geoffrey Huntley expects AI to replace. And itâ€™s growing at 35%+ annually - the same rate as before AI coding tools existed. And itâ€™s been commercially licensed for years - surely someone who wanted this type of functionality would just fire up Claude Code to eliminate it, right?\n\nAccording to Sonatypeâ€™s State of the Software Supply Chain 20242 report:\n\nIf AI was replacing open source libraries, why are package downloads exploding at unprecedented rates? Why are dependency counts climbing? Why is every major package registry showing record growth?\n\nThe answer is simple: AI is discovering and adopting open source libraries faster than humans ever could.\n\nHereâ€™s what the AI doomsayers fundamentally misunderstand about how Large Language Models work: theyâ€™re trained to find the shortest path to a working solution.\n\nWhen you ask Claude or GPT-5 to build a distributed system, what do you think is the shorter path?\n\nOption A: Generate thousands of lines of custom actor model implementation, cluster management, network protocols, failure detectors, and state replication logic - all from scratch, all needing testing, all potentially buggy.\n\nOption B: dotnet add package Akka and configure the proven, tested, battle-hardened framework thatâ€™s in the training data with millions of examples.\n\nThe LLM isnâ€™t stupid. Itâ€™s going to pick Option B every single time, unless you explicitly tell it not to - and even then it might fight you3.\n\nThis is why the â€œAI will generate everything customâ€ narrative falls apart on contact with reality. Yes, AI can generate custom components. But developers donâ€™t want custom CSS frameworks - they want to ship. They want the thing that makes them money shipped yesterday. Using established libraries is how you get there expeditiously.\n\nHereâ€™s where it gets really interesting. Established open source projects have a massive, compounding advantage in the AI era: years of training data.\n\nThink about whatâ€™s in those training sets:\n\nEvery time someone asks â€œhow do I build a distributed system in .NET?â€ the training data screams â€œAKKA.NETâ€ across thousands of documents. The LLM doesnâ€™t need to think creatively. Itâ€™s pattern matching against an enormous corpus of successful implementations.\nThis creates a virtuous cycle:\n\nPopular projects have more training data â†’ LLMs recommend them more â†’ More people use them â†’ More training data gets created â†’ The cycle continues.\n\nThe rich get richer, and in this case, thatâ€™s actually a good thing for software quality.\n\nNow compare that to generating a custom solution. The LLM hasâ€¦ what? Generic distributed systems theory? Sure. But where are the battle-tested examples? Where are the debugging sessions? Where are the â€œhereâ€™s what went wrong in production and how we fixed itâ€ stories?\n\nThey donâ€™t exist. Because youâ€™re asking the AI to invent something new.\n\nRemember when adopting a new library meant:\n\nFor a human developer, thatâ€™s a full day or two of investment before youâ€™re productive. The mental math was always: â€œIs learning this library worth the time investment vs. building something custom that I already understand?â€\n\nAI just arbitraged that entire calculation out of existence.\n\nWhen I ask Claude to â€œimplement an Akka.NET cluster with cluster sharding and split-brain resolution,â€ it doesnâ€™t need to read the docs. It doesnâ€™t need the tutorial. It usually outputs working code with proper configuration in seconds. The learning curve is effectively zero.\n\nThis fundamentally changes the adoption math. The barrier to using any established library is now â€œcan the AI generate correct code for it?â€ If yes, adoption becomes frictionless.\n\nGuess which libraries have the most examples for AI to learn from? The established ones. The popular ones. The ones with network effects and community momentum.\n\nAI can generate impressive things from scratch. People have used agentic loops to build entire programming languages, compilers, and complex systems - all generated by AI with minimal human intervention. These are genuine technical achievements that prove AI can build sophisticated software.\n\nBut hereâ€™s the question nobodyâ€™s asking: would you run your production systems on them?\n\nThe answer depends entirely on blast radius - what happens when things go wrong4.\n\nThe libraries that AI can safely replace are the ones with low blast radius. If your AI-generated UI component looks a little funny or renders slightly different than expected, nobody dies. You fix it and move on. The cost of failure is measured in minutes of debugging.\n\nBut if your AI-generated embedded operating system core dumps constantly? Someone might actually die. If your AI-generated authentication library has a subtle flaw? You get breached. If your AI-generated distributed consensus algorithm has an edge case bug? You lose data across your entire cluster.\n\nProduction systems donâ€™t run on â€œtechnically worksâ€ - they run on battle-hardened, community-tested, security-audited infrastructure thatâ€™s been proven across thousands of deployments over years. Thatâ€™s React. Linux. PostgreSQL. Akka.NET. NServiceBus. The boring, reliable stuff thatâ€™s growing 35-126% annually.\n\nThereâ€™s another dimension here: institutionalized experience.\n\nA venerable codebase like Akka.NET doesnâ€™t just contain code - it contains decades of accumulated wisdom across millions of deployments and tens of thousands of applications. All running on different hardware, serving different use cases, developed by different people. Every bug fix is a production war story. Every edge case handler is a lesson learned the hard way. Every configuration option exists because someone, somewhere, needed it in production.\n\nLLMs can synthesize code. They can pattern-match against training data. But they are no substitute for thousands of person-years of lived experience encoded into a codebase. That wisdom doesnâ€™t exist in the training data - it exists in the accumulated decisions of maintainers whoâ€™ve seen every way a distributed system can fail.\n\nWhen you dotnet add package Akka, youâ€™re not just getting code. Youâ€™re getting the institutional memory of a decade of production deployments. AI canâ€™t generate that. It can only recommend the libraries that already have it.\n\nThe libraries actually at risk from AI generation are the ones with low blast radius - simple utilities, UI components, basic tooling where failure is cheap and recoverable. The critical infrastructure where failure is catastrophic? Thatâ€™s not going anywhere. Itâ€™s accelerating.\n\nâ€œSure,â€ I hear you saying, â€œAI wonâ€™t replace frameworks, but what about all the smaller libraries? What about utilities and helpers?â€\n\nFair question. Letâ€™s think through the actual use cases.\n\nDeveloper needs a date formatting function. AI can generate it. Butâ€¦ so could a library. And the library version is tested. And documented. And handles edge cases. And gets security updates.\n\nWhatâ€™s actually happening in practice? AI is finding and using existing utility libraries faster than humans would have. date-fns, lodash, NodaTime - these libraries arenâ€™t declining, theyâ€™re exploding in adoption.5\n\nScenario 2: Custom Business Logic\n\nDeveloper needs a specific component for their application. AI generates it custom. Perfect! This is exactly what should be custom. This was never the domain of reusable open source anyway.\n\nScenario 3: Complex, Critical Systems\n\nDeveloper needs authentication, database access, distributed coordination, payment processing. AI could generate custom implementations. But would you ship them to production? Would you stake your business on AI-generated cryptography? On custom distributed consensus?\n\nOf course not. You use Postgres, Entity Framework, Akka.NET, OpenSSL - the proven solutions with years of production hardening.\n\nHereâ€™s what the Tailwind situation actually tells us: AI is devastating businesses that sell what LLMs can generate.\n\nThe numbers tell the whole story:\n\nThe most successful year in the frameworkâ€™s history coincided with the business collapse. This isnâ€™t a contradiction - itâ€™s the clearest illustration of what AI actually disrupts.\n\nTailwindâ€™s commercial business is Tailwind Plus - premium UI components, templates, and blocks. The free documentation served as the primary sales funnel: developers would visit the docs to learn Tailwind, discover the premium components, and purchase them.\n\nAI broke this model in two devastating ways.\n\nFirst: The sales funnel dried up.\n\nRemember learning curve arbitrage? When developers use AI to generate Tailwind code, they donâ€™t need to visit the documentation. Adam noted that docs traffic is down about 40% from early 2023 - despite Tailwind being more popular than ever. Fewer eyeballs on the docs means fewer people discovering the premium products exist.\n\nSecond: The product itself became AI-generatable.\n\nAI undercut Tailwindâ€™s business model. Selling those components was about eliminating friction for users - buy a pre-made pricing table instead of building one yourself. But AI found an even cheaper way to eliminate that friction: generate the component on demand, for free.\n\nWhen a developer asks an AI for a â€œresponsive pricing table with Tailwind,â€ the LLM isnâ€™t going to say â€œlog into your Tailwind Plus account and download the pricing component.â€ Itâ€™s going to generate one from scratch. Thatâ€™s the shortest path.\n\nUI components and templates are exactly the kind of low-blast-radius output that AI handles well. If the generated component looks slightly different than a premium template, nobody cares. You tweak it and move on.\n\nTailwindâ€™s business model put them directly in competition with their own frameworkâ€™s AI-assisted usage. The better AI gets at generating Tailwind code, the less reason anyone has to buy pre-built components.\n\nThe framework thrives. The component business struggles. Same company, opposite trajectories - because one benefits from AI adoption and the other is displaced by it.\n\nAI isnâ€™t killing open source. Itâ€™s creating the golden age of open source consumption.\n\nMore developers can adopt more libraries faster than ever before. The friction that kept people building custom solutions has evaporated. The learning curves that protected mediocre alternatives have disappeared.\n\nWhat weâ€™re seeing is consolidation around quality, acceleration of adoption, and the destruction of business models that were built on selling what AI can now generate.\n\nTailwind CSS isnâ€™t dying. Tailwind Plus might be dying - time will tell to see how they pivot. But the CSS framework itself is more popular than ever. The component products built on top of it? Those are being outcompeted by the LLMs recommending the framework.\n\nIf youâ€™re an open source maintainer, this is your moment. If youâ€™ve built something genuinely valuable - critical infrastructure with high blast radius, strong community, clear use cases - youâ€™re about to see adoption curves that would have taken a decade compress into a few years.\n\nThe future of open source isnâ€™t bleak. Itâ€™s brighter than itâ€™s ever been. But the businesses built on top of them? Thatâ€™s a different story - and itâ€™s what weâ€™ll dig into in Part 2.\n\nThis is Part 1 of a two-part series. Part 2 examines which open source business models thrive and which collapse in the AI era. The same AI wave that disrupted Tailwindâ€™s business certainly didnâ€™t hurt ours - our support subscriptions grew 19% in 2025, and AI-driven adoption likely contributed. Part 2 examines what makes some OSS business models resilient while others struggle. \n\nWhatâ€™s your experience been? Are you seeing AI tools increase or decrease your open source usage? Hit me up on Twitter/X - Iâ€™m curious to hear how this is playing out across different ecosystems.\n\nGeoff wrote this all the way back in June 2025, well before this Tailwind situation. Ahead of his time.Â â†©\n\nA 2025 report would be preferable, but alas there isnâ€™t one yet.Â â†©\n\nReward hacking is a property of frontier models youâ€™ll encounter in all sorts of interesting ways. My personal favorite is when Claude disables failing tests in order to turn the status checks green.Â â†©\n\nI also suspect this is why the â€œlearn AI now or youâ€™re going to fall behind crewâ€ ship way more â€œbuild with AIâ€ courses than they do polished software products.Â â†©\n\n2024â†’2025 YoY growth: date-fns +52.6% (1.05Bâ†’1.60B), NodaTime +42.6% (171Mâ†’244M), lodash +36.2% (2.67Bâ†’3.64B).Â â†©\n\nDid you know that Phobos can automatically instrument your Akka.NET applications with OpenTelemetry?",
    "readingTime": 13,
    "keywords": [
      "package akka",
      "developer needs",
      "llm isnâ€™t",
      "two-part series",
      "dotnet add",
      "sales funnel",
      "tailwind situation",
      "tailwindâ€™s business",
      "shortest path",
      "pricing table"
    ],
    "qualityScore": 1,
    "link": "https://petabridge.com/blog/ai-wont-kill-open-source/",
    "thumbnail_url": "https://hcti.io/v1/image/133ae5fdb357269cefb4ca0c4b35583207c3cbba0985e4351cd559e6c1a1f3d8",
    "created_at": "2026-01-11T01:03:39.633Z",
    "topic": "tech"
  },
  {
    "slug": "sakana-ai-agent-wins-atcoder-heuristic-contest-first-ai-to-place-first",
    "title": "Sakana AI Agent Wins AtCoder Heuristic Contest (First AI to Place First)",
    "description": "Sakana AI Agent Wins AtCoder Heuristic Contest (First AI to Place 1st)",
    "fullText": "Sakana AIâ€™s â€œALE-Agentâ€ achieved a historic milestone by securing 1st place in the AtCoder Heuristic Contest 058, outperforming 804 human participants. To contextualize the difficulty of these optimization challenges, an OpenAI agent previously secured 2nd place in the AHC world tournament last August. This victory marks the first known instance of an AI agent winning a major optimization programming contest in real-time. The result demonstrates that by utilizing inference-time scaling with multiple frontier models, AI agents can now match or exceed the performance of top human experts in complex tasks requiring extended reasoning.\n\nDuring the 4-hour contest, our agent autonomously discovered a novel algorithm that outperformed the problem settersâ€™ intended solution. While the problem settersâ€™ anticipated a standard approach combining constructive heuristics and simulated annealing (SA), our ALE-Agent independently derived a â€œvirtual powerâ€ heuristic and a sophisticated SA strategy with diverse neighborhood search operations, allowing it to escape local optima more effectively than human competitors.\n\nOperating at a total cost of approximately $1,300, the agent engaged in parallel code generation and iterative analysis, proving that AI is now capable of the original scientific discovery and trial-and-error required for high-level problem solving.\n\nFor the detailed information, including the logs and analysis output by ALE-Agent during the contest, see: https://sakanaai.github.io/fishylene-ahc058/ and our earlier NeurIPSâ€™25 paper.\n\nThe AtCoder Heuristic Contest (AHC) is a series of programming competitions focused on optimization problems related to real-world industrial challenges, such as logistics optimization and factory production scheduling. These contests are characterized by approximately 1,000 programmers including experts active in various industrial sectors. Participants tackle a single, complex coding challenge, with contest durations ranging from four hours to two weeks.\n\nAHC has garnered significant global attention. In August 2025, a world championship featuring top-tier players was held, where an AI agent from OpenAI participated and won 2nd place. Sakana AI has also co-developed ALE-Bench, a benchmark platform based on AHC, in collaboration with AtCoder Inc. Furthermore, under special permission, our AI agent called ALE-Agent has been continuously participating in AHCs in real-time.\n\nAHC058, held on December 14, 2025, was conducted over a 4-hour competition window. The problem involved a setting where participants could produce machines with hierarchical relationships, such as multiple types of â€œapple-producing machinesâ€ and â€œmachines that build those machines.â€ The objective was to construct an efficient production planning algorithm by determining which types and hierarchies of machines to upgrade and in what specific order.\n\nWhile the setting may seem humorous at first glance, these hierarchical production dependencies mirror real-world supply chains, food webs, and manufacturing processes, making it a scientifically interesting problem setup. For further details on the problem, please refer to the contestâ€™s problem statement.\n\nALE-Agent began making submissions two hours after the contest started and immediately leapt to 1st place in the provisional standings.\n\nIn the middle of the contest, ALE-Agent was in a fierce dead heat with yosupo, the eventual 2nd-place finisher. ALE-Agent regained 1st place approximately two and a half hours into the contest and maintained the lead until the end to secure the victory.\n\nIn AHC058, the solution expected by the problem author was an approach that used algorithms like Greedy methods or Beam Search to determine a global strategic plan, followed by Simulated Annealing (SA) to refine the planâ€™s finer details.\n\nALE-Agentâ€™s answer followed the same basic flow as a human: â€œconstruction by Greedy â†’ refinement by SA.â€ However, it was a quintessential â€œAI-styleâ€ solution that maximized the AIâ€™s strengths: numerous implementations and exhaustive trial and error. Analysis of the final program revealed the following characteristics:\n\nAnalyzing the process through which ALE-Agent generated its response revealed that it implemented the solution while deepening its understanding of the problemâ€™s characteristics. (Logs can be viewed on this page).\n\nThe latest version of ALE-Agent is equipped with a mechanism to repeat trial and error by generating multiple programs simultaneously, summarizing those results to generate insights, and utilizing them for subsequent code generation. Looking at the insights generated by ALE-Agent, we can see it examining the problem based on experience; it mentioned the compound interest effect in connection with investment knowledge, devised high-speed algorithms using mathematics from an early stage, and discussed the nature of the search space, noting that initial strategies cause significant differences.\n\nWe received comments regarding ALE-Agentâ€™s performance and approach from two experts familiar with the optimization field and AHC.\n\nFrom Hiroomi Nochide (AtCoder handle: itigo):\n\nActually, before the contest started, I thought this problem would be difficult for LLMs. This is because solving this problem with a Greedy method requires experimental insight that LLMs typically struggle with, and I thought a high score would be impossible without this human-centric consideration. However, when the results came out, I was stunned to see fishylene win.\n\nChecking the logs, it tried a vast number of patterns with promising directions and discovered a clever simulated annealing method that was not anticipated at the time the problem was created. I am impressed, thinking, â€˜How did it find such a method?â€™ (In the logs, the parts requiring the experimental insight I initially expected did not appear, and given that humans still excelled in the Greedy portion, I believe human accuracy in consideration is still superior. However,) the overwhelming number of trial-and-error steps combined with LLM reasoning is an advantage humans do not have. While I feel fishylene is a formidable rival, I believe this technology will be a tremendous weapon for humanity.\n\n(Note: fishylene is ALE-Agentâ€™s AtCoder account name)\n\nHiroomi Nochide authored the problem for AHC058. He is one of the worldâ€™s top players (24th in AHC world rankings) and a professional in this field at ALGO ARTIS CORPORATION.\n\nFrom Yoichi Iwata (AtCoder handle: wata):\n\nThis problem required optimizing investment plans for multiple series of production machines, where the high-level choice of which series to select as â€˜final investment targetsâ€™ and â€˜intermediate investment targetsâ€™ was essentially the core issue. With simple local improvement methods that only slightly change the investment target at each turn, it is difficult to switch this global strategy midway, often leading to poor local optima.\n\nThe expected solution from the authorâ€™s side was a two-stage approach: first explore a wide range of global investment plan candidates using a lightweight solver, and then spend time optimizing the promising ones. In contrast, the solutions from ALE-Agent and the runner-up, yosupo, were based on local search but introduced â€˜Large Neighborhoodsâ€™ that change a huge portion of the investment plan at once to escape local optima. In particular, ALE-Agent utilized a diversified Greedy method to reconstruct large parts of the plan, which seems to have led to its performance advantage.\n\nHistorically, ALE-Agent has tended to choose solutions within the authorâ€™s expected range, yet its high implementation and optimization power allowed it to reach the top ranks among many participants using similar methods, especially in short-duration contests. This time, it was very impressive to see it go one step further and reach a solution that exceeded the authorâ€™s expectations.\n\nYoichi Iwata oversees AHC at AtCoder. He has an outstanding track record in this field, including winning the 2010 TopCoder Open. His scores in pre-contest test plays sometimes exceed the top participant scores, and he ensures the high quality of AHC problems.\n\nALE-Agent is an agent that performs algorithm discovery by utilizing multiple LLMs to create solutions in parallel, selecting the best ones, and reasoning further based on the results of trial and error. As such, it requires a high volume of LLM calls. The resources utilized during the 4-hour contest were as follows:\n\nThis result is significant as it demonstrates that even for multi-hour tasks, by scaling inference costs and running a properly designed AI agent, AI can reach or surpass the performance of top human experts.\n\nIdentifying which specific elements of ALE-Agentâ€™s design contributed most to this dramatic result remains an important research task for the future. Our current analysis suggests that in addition to scaling LLM calls and injecting domain knowledge, a â€œself-learning mechanism,â€ which extracts insights from trial-and-error trajectory and reflects them in the next improvement cycle, played an important role.\n\nAs highlighted in evaluation reports such as those from METR (Model Evaluation and Threat Research), the latest AI models are beginning to show high proficiency in tasks requiring several hours of human effort. Our result follows this trend but is unique in showing that an AI agent with appropriate mechanisms and inference scaling can rival top human experts.\n\nHowever, at this point, AI does not always rival or surpass top humans. The table below shows ALE-Agentâ€™s past performance. While ALE-Agent has often ranked highly in previous AHCs, AHC058 marks its first victory. Additionally, its calculated virtual rating is 2592, which corresponds to 66th place among active users.\n\nAVisualization of ALE-Agentâ€™s past AHC performance and Rating. The graph shows the contribution of performance values from each contest to the overall rating. https://atcoder-graphs.vercel.app/#contributorGraph\n\nLooking ahead, we aim to increase stability to ensure consistently high performance across similar tasks and to evolve our agents to rival top experts in longer-term tasks lasting several days or more. To achieve this, we will focus on balancing efficient human-like thinking with trial and error (moving away from purely heavy LLM call reliance) and acquiring more advanced autonomous management capabilities.\n\nIn real-world problem-solving, the process where humans interpret, generalize, and refine the unexpected discoveries presented by AI is highly effective. As noted in our report on the ICFP Programming Contest 2025, Sakana AI positions AI not as a replacement for humans, but as a partner that expands human exploration capabilities. Measuring achievements by AI alone, as we did here, is vital for understanding the current strengths and weaknesses of AI as a partner, and we believe this result represents a significant milestone in that journey.\n\nFinally, we would like to express our deep gratitude to AtCoder Inc. for their continuous cooperation and to ALGO ARTIS CORPORATION for hosting this contest.\n\nSakana AI will continue to explore new possibilities for intelligence and the practical application of AI agents in the real world.\n\nSakana AI is looking for experienced software engineers to lead the productization of platforms that solve complex real-world problems and accelerate AI-driven discovery, including projects like ALE-Agent. We are also looking for interns interested in the further development and industrial application of AI agents. Join our team and help us turn cutting-edge AI agent technology into practical value.\n\nDetails and Application: https://sakana.ai/careers/",
    "readingTime": 9,
    "keywords": [
      "algo artis",
      "artis corporation",
      "atcoder handle",
      "greedy method",
      "atcoder heuristic",
      "code generation",
      "experimental insight",
      "heuristic contest",
      "simulated annealing",
      "contest sakana"
    ],
    "qualityScore": 1,
    "link": "https://sakana.ai/ahc058/",
    "thumbnail_url": "https://sakana.ai/assets/home/sakana_rect.png",
    "created_at": "2026-01-11T01:03:39.295Z",
    "topic": "tech"
  },
  {
    "slug": "employees-are-using-ai",
    "title": "Employees Are Using AI",
    "description": "The case for a compliance gateway between healthcare teams and AI tools. In most healthcare organizations, AI adoption didn't begin with a strategy document â€” it began organically with individuals hearing about how AI could help them do their jobs better.",
    "fullText": "In most healthcare organizations, AI adoption didn't begin with a strategy document or a formal approval process.\n\nIt began organically with individuals hearing about how AI could help them do their jobs better, easier. Who doesn't want that? So, they start using AI tools to summarize notes, draft communications, interpret documents, or explore ideas faster. Often with good intentions. Often without visibility.\n\nWhether an organization has formally approved AI usage or not, the reality is the same: AI is already in the workflow.\n\nThe real question is no longer if employees are using AI.\n\nIt's whether that usage is intentional, governed, and defensible.\n\nMany organizations respond to AI risk in one of two ways:\n\nNeither approach reflects how work actually gets done.\n\nWhen tools are banned outright, usage tends to move underground.\n\nWhen policies exist without enforcement or structure, teams are left guessing where the boundaries really are.\n\nIn both cases, leadership loses visibility causing compliance risk to go up.\n\nThe most common AI risk in healthcare isn't malicious behavior or reckless intent.\n\nIt's the absence of a clear boundary between sensitive work and external AI systems.\n\nIn regulated environments, invisible usage is often riskier than visible, governed usage.\n\nA compliance gateway is not about surveillance.\n\nIt's not about monitoring individuals or second-guessing intent.\n\nA compliance gateway is an organizational control layer that sits between employees and AI systems, making AI usage:\n\nInstead of relying solely on policy documents or trust, organizations provide a clear, approved path for AI usage that aligns with regulatory obligations.\n\nOne of the most persistent myths about AI governance is that it slows teams down.\n\nThey spend less time guessing, self-censoring, or avoiding AI altogether.\n\nGovernance, when done well, becomes an enabler.\n\nHealthcare compliance is rarely about eliminating risk entirely.\n\nIt's about managing risk intentionally.\n\nOrganizations that struggle most with AI compliance are often not the ones using AI aggressively. They're the ones who can't see how it's being used at all.\n\nVisibility enables informed decision making, targeted controls, and credible explanations when questions arise.\n\nWithout visibility, even well-meaning organizations are forced to rely on hope.\n\nAs AI becomes embedded in everyday healthcare workflows, governance will increasingly shift:\n\nThe organizations that adapt successfully won't be the ones that stopped AI usage.\n\nThey'll be the ones that made it explicit, governed, and defensible.\n\nEmployees are already bringing AI into healthcare work because the incentives are real and the productivity gains are tangible.\n\nThe choice facing organizations isn't whether to allow AI.\n\nIt's whether AI usage will happen outside of governance or within it.\n\nGuardian Health is being built as a governed AI workbench for healthcare teams: designed to sit between employees and AI systems, making data handling decisions explicit, auditable, and defensible. Our focus is less on controlling behavior, and more on providing clear, compliant pathways for real-world AI usage.",
    "readingTime": 3,
    "keywords": [
      "compliance gateway",
      "without visibility",
      "ai it's",
      "usage",
      "organizations",
      "healthcare",
      "risk",
      "employees",
      "governed",
      "governance"
    ],
    "qualityScore": 1,
    "link": "https://guardianhealth.dev/blog/employees-already-using-ai/",
    "thumbnail_url": "https://guardianhealth.dev/blog/employees-using-ai.jpg",
    "created_at": "2026-01-11T01:03:39.277Z",
    "topic": "health"
  },
  {
    "slug": "vllm-or-llamacpp-choosing-the-right-llm-inference-engine-for-your-use-case",
    "title": "VLLM or llama.cpp: Choosing the right LLM inference engine for your use case",
    "description": "See how vLLMâ€™s throughput and latency compare to llama.cpp's and discover which tool is right for your specific deployment needs on enterprise-grade hardware",
    "fullText": "Following our previous analysis of Ollama and vLLM, we are extending our comparison to another giant in the inference space: llama.cpp. While vLLM is known for its Python-based, throughput-oriented architecture, llama.cpp is renowned for its lightweight C++ core, which promises exceptional efficiency.\n\nllama.cpp is a standout in the LLM ecosystem for its efficiency and portability. Written in pure C/C++ with no external dependencies, it offers plain-vanilla inference that can run on a wide range of hardware, from powerful servers and GPUs to edge devices like laptops and phones. Its CPU-first design philosophy and support for various quantization methods (from 2-bit to 8-bit integers) make it exceptionally versatile.\n\nA key feature of llama.cpp is its use of the GGUF (GPT-Generated Unified Format), a custom file format specifically designed for rapid loading and memory-mapped execution. This allows models to be loaded almost instantly and contributes significantly to the engine's fast startup times and low resource footprint, making it a favorite among developers running models on consumer-grade hardware.\n\nIn this post, we put these two high-performance engines to the test in a head-to-head benchmark to help you choose the right tool for your specific deployment needs on enterprise-grade hardware.\n\nTo ensure a true \"apples-to-apples\" comparison, we created a controlled testing environment on Red Hat OpenShift, using full-precision models for both engines and using the latest generation of NVIDIA hardware.\n\nWe used a fixed dataset of prompt-response pairs to ensure that every request sent to both servers was identical. This eliminates variables from synthetic data generation and allows for a direct comparison of the engines themselves. Each test at a given concurrency level was run for 300 seconds.\n\nForÂ TTFTÂ andÂ ITL,Â weÂ usedÂ P99Â (99thÂ percentile)Â asÂ theÂ measure.Â P99Â meansÂ thatÂ 99%Â ofÂ requestsÂ hadÂ aÂ TTFT/ITLÂ atÂ orÂ belowÂ thisÂ value,Â makingÂ itÂ aÂ goodÂ measureÂ ofÂ \"worst-case\"Â responsiveness.\n\nThis comparison evaluates the latest upstream versions of vLLM and llama.cpp. Recognizing that the default setting for llama.cpp is not intended for high-concurrency scenarios, we tuned its settings for our environment.\n\nTo ensure llama.cpp fully leveraged the available GPU hardware, we used the -ngl 99 flag to offload all possible model layers to the NVIDIA H200 GPU. Additionally, we used the --threads and --threads-batch flags to increase the number of threads available for prompt and batch processing. We empirically determined that a value of 64 for both was the stable limit for our llama.cpp deployment.\n\nThe difference in how the two engines handle a growing user load was immediate and stark. vLLM's throughput scales impressively as concurrency increases, demonstrating its ability to efficiently manage a high volume of requests. In contrast, llama.cpp's throughput remains almost perfectly flat, indicating it processes a steady but fixed amount of work, regardless of the incoming load. See Figure 1.\n\nThe bar chart for Output Tokens per Second (Figure 2) reinforces this finding. While llama.cpp shows comparable performance at a concurrency of 1, vLLM's total generative power quickly surpasses it and continues to grow with the load.\n\nConclusion: For multi-user applications where maximizing throughput and scalability is the goal, vLLM is the clear winner. At peak load, vLLM delivered more than 35 times the request throughput (RPS) and more than 44 times the total output tokens per second (TPS) compared to llama.cpp. llama.cpp's architecture is suited for single-user or low-concurrency tasks.\n\nThe latency metrics reveal the different architectural priorities of the two engines.\n\nThis benchmark comparison on the NVIDIA H200 GPU highlights that vLLM and llama.cpp are both excellent tools with different strengths.\n\nFor performance-critical applications on modern, enterprise-grade GPUs,Â vLLM demonstrates a clear advantage in our tests. It is a scalability powerhouse, leading in every performance category we measuredâ€”throughput, responsiveness, and single-request generation speed. For teams building scalable, high-performance AI applications, this data shows that vLLM is a powerful and robust foundation.",
    "readingTime": 4,
    "keywords": [
      "tokens per",
      "per second",
      "llama.cpp",
      "vllm",
      "comparison",
      "hardware",
      "engines",
      "load",
      "throughput",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://developers.redhat.com/articles/2025/09/30/vllm-or-llamacpp-choosing-right-llm-inference-engine-your-use-case",
    "thumbnail_url": "https://developers.redhat.com/sites/default/files/styles/share/public/Inference-vLLM-1920x1080.png?itok=x_9NzXpT",
    "created_at": "2026-01-10T18:16:46.067Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": "China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling",
    "fullText": "BEIJING, Jan 10 (Reuters) - China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the â€‹sector, the country's leading artificial intelligence researchers said on Saturday.\n\nChina's so-called 'AI tiger' startups MiniMax and Zhipu â€ŒAI had strong debuts on the Hong Kong Stock Exchange this week, reflecting growing confidence in the sector as Beijing fast-tracks AI and â€Œchip listings to bolster domestic alternatives to advanced U.S. technology.\n\nYao Shunyu, a former senior researcher at ChatGPT maker OpenAI who was named technology giant Tencent's chief AI scientist in December, said there was a high likelihood of a Chinese firm becoming the world's leading AI company in the next three to five years but said the lack of â advanced chipmaking machines was the main â€Œtechnical hurdle.\n\n\"Currently, we have a significant advantage in electricity and infrastructure. The main bottlenecks are production capacity, including lithography machines, and the software ecosystem,\" Yao said at an AI â€conference in Beijing.\n\nChina has completed a working prototype of an extreme-ultraviolet lithography machine potentially capable of producing cutting-edge semiconductor chips that rival the West's, Reuters reported last month. However, the machine has not yet produced working chips and may not do â€‹so until 2030, people with knowledge of the matter told Reuters.\n\nYao and other Chinese industry â€Œleaders at the Beijing conference on Saturday also acknowledged that the U.S. maintains an advantage in computing power due to its hefty investments in infrastructure.\n\n\"The U.S. computer infrastructure is likely one to two orders of magnitude larger than ours. But I see that whether it's OpenAI or other platforms, they're investing heavily in next-generation research,\" said Lin Junyang, technical lead for Alibaba's flagship Qwen large language model.\n\n\"We, on the other hand, are relatively strapped for â cash; delivery alone likely consumes the majority of our computer infrastructure,\" â€‹Lin said during a panel discussion at the AGI-Next Frontier Summit â€‹held by the Beijing Key Laboratory of Foundational Models at Tsinghua University.\n\nLin said China's limited resources have spurred its researchers to be innovative, particularly through algorithm-hardware co-design, which enables AI â€firms to run large models â on smaller, inexpensive hardware.\n\nTang Jie, founder of Zhipu AI which raised HK$4.35 billion in its IPO, also highlighted the willingness of younger Chinese AI entrepreneurs to embrace high-risk ventures - a trait traditionally associated â with Silicon Valley - as a positive development.\n\n\"I think if we can improve this environment, allowing more time for these risk-taking, intelligent individuals â€Œto engage in innovative endeavours ... this is something our government and the country can help improve,\" â€Œsaid Tang.",
    "readingTime": 3,
    "keywords": [
      "advanced chipmaking",
      "computer infrastructure",
      "risk-taking",
      "lack",
      "sector",
      "leading",
      "researchers",
      "technology",
      "openai",
      "machines"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/articles/china-closing-us-technology-lead-154328876.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/7E4877C512D62422FB949E157C6EA70D6D8CDDCD414E4D435CECA30C2F84F1A9/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fs.yimg.com%2Fos%2Fen%2Freuters.com%2F610ee45b7b291cec24a64256a4290ef7",
    "created_at": "2026-01-10T18:16:37.410Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-says-uk-wants-to-suppress-free-speech-as-x-faces-possible-ban",
    "title": "Elon Musk says UK wants to suppress free speech as X faces possible ban",
    "description": "Ministers warn platform could be blocked after Grok AI used to create sexual images without consent\nElon Musk has accused the UK government of wanting to suppress free speech after ministers threatened fines and a possible ban for his social media site X after its AI tool, Grok, was used to make sexual images of women and children without their consent.\nThe billionaire claimed Grok was the most downloaded app on the UK App Store on Friday night after ministers threatened to take action unless the function to create sexually harassing images was removed.\n Continue reading...",
    "fullText": "Ministers warn platform could be blocked after Grok AI used to create sexual images without consent\n\nElon Musk has accused the UK government of wanting to suppress free speech after ministers threatened fines and a possible ban for his social media site X after its AI tool, Grok, was used to make sexual images of women and children without their consent.\n\nThe billionaire claimed Grok was the most downloaded app on the UK App Store on Friday night after ministers threatened to take action unless the function to create sexually harassing images was removed.\n\nResponding to threats of a ban from the government, Musk wrote: â€œThey just want to suppress free speechâ€.\n\nThousands of women have faced abuse from users of the AI tool which was first used to digitally strip fully clothed photographs into images showing them wearing micro bikinis, and then used for extreme image manipulation.\n\nPictures of teenage girls and children were altered to show them wearing swimwear, leading experts to say some of the content could be categorised as child sexual abuse material.\n\nSome users began to demand to see bruising on the bodies of the women, and for blood to be added to the images. Women were shown tied up, gagged and shot.\n\nThe technology secretary, Liz Kendall, said on Friday that ministers were looking seriously at the possibility of access to X being barred in the UK.\n\nShe said she expected Ofcom, which said this week that it was seeking urgent answers from the platform, to announce action within â€œdays not weeksâ€.\n\nâ€œX needs to get a grip and get this material down,â€ she said. â€œAnd I would remind them that in the Online Safety Act, there are backstop powers to block access to services if they refuse to comply with the law for people in the UK. And if Ofcom decides to use those powers, they would have the full backing of the government.â€\n\nThe UK governmentâ€™s concerns were echoed by the Australian prime minister, Anthony Albanese. Speaking in Canberra on Saturday, Albanese said that â€œglobal citizens deserve betterâ€. Australia recently banned the use of social media for under-16s.\n\nâ€œThe use of generative artificial intelligence to exploit or sexualise people without their consent is abhorrent,â€ he said.\n\nâ€œThe fact that this tool was used so that people were using its image creation function through Grok is just completely abhorrent. It, once again, is an example of social media not showing social responsibility.â€\n\nSome rightwing political figures have tried to frame this as a free speech issue. Responding to the news X faced a potential ban, the former prime minister Liz Truss said: â€œStarmer is really losing it now.â€\n\nX partially restricted access to Grok on Friday. Its public account lost the ability to generate images at the request of free users, leaving the function available only to paid subscribers. It also appeared to have stopped creating bikini images.\n\nThe Grok app, however, which does not generate images publicly, is still able to create sexually explicit material from womenâ€™s pictures.\n\nOther nudificiation apps are still available. The Labour MP Jess Asato, who campaigns against the sexual abuse and harassment of women, said legislation to ban such apps was urgently needed.\n\nShe posted on social media: â€œItâ€™s not just XAi. This nudification tool was advertised yesterday on @YouTube.\n\nâ€œNo rules had been broken @Google said on reporting.\n\nâ€œOur nudification legislation needs to be expedited.â€\n\nGoogle was approached for comment.",
    "readingTime": 3,
    "keywords": [
      "prime minister",
      "create sexually",
      "suppress free",
      "free speech",
      "ministers threatened",
      "social media",
      "sexual abuse",
      "generate images",
      "women",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/10/elon-musk-uk-free-speech-x-ban-grok-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/146ea600371c47e796f9b3708122efd144613cab/458_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0f098b3b34c05747a8bf649361108619",
    "created_at": "2026-01-10T18:16:36.322Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say-4440562",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0908G_L.jpg",
    "created_at": "2026-01-10T18:16:34.801Z",
    "topic": "finance"
  },
  {
    "slug": "investor-michael-burry-reveals-options-bet-against-oracle",
    "title": "Investor Michael Burry Reveals Options Bet Against Oracle",
    "description": "Michael Burry, the famed investor who has drawn attention in recent months for criticism of the artificial intelligence boom, is betting against Oracle Corp.",
    "fullText": "MarketsBy Carmen Reinicke and Jeran WittensteinSaveMichael Burry, the famed investor who has drawn attention in recent months for criticism of the artificial intelligence boom, is betting against Oracle Corp.Burry owns put options on Oracle shares, he said in a Substack post after markets closed on Friday. Puts typically increase in value as the price of the underlying asset falls. Burry, who revealed bearish bets against AI chipmaker Nvidia Corp. and Palantir Technologies Inc. in November, also directly shorted Oracle during the last six months, he said.",
    "readingTime": 1,
    "keywords": [
      "oracle",
      "burry"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-10/investor-michael-burry-reveals-options-bet-against-oracle-shares",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBuGJpCEmiYA/v0/1200x776.jpg",
    "created_at": "2026-01-10T12:20:51.866Z",
    "topic": "finance"
  },
  {
    "slug": "do-anything-agents",
    "title": "Do Anything Agents",
    "description": "Automate your daily tasks, integrate your favorite apps, and get more done with Do Anything, the advanced AI assistant designed to handle your workload seamlessly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.doanything.com/landing",
    "thumbnail_url": "https://doanything.com/opengraph-image.png",
    "created_at": "2026-01-10T12:20:47.914Z",
    "topic": "tech"
  },
  {
    "slug": "a-curated-list-of-resources-tools-libs-of-the-mistral-ai-ecosystem",
    "title": "A curated list of resources, tools, libs of the Mistral AI ecosystem",
    "description": "A curated list of awesome resources, tools, libraries, and projects for the Mistral AI ecosystem. - samouraiworld/awesome-mistral",
    "fullText": "samouraiworld\n\n /\n\n awesome-mistral\n\n Public\n\n A curated list of awesome resources, tools, libraries, and projects for the Mistral AI ecosystem.\n\n License\n\n CC0-1.0 license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n samouraiworld/awesome-mistral",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/samouraiworld/awesome-mistral",
    "thumbnail_url": "https://opengraph.githubassets.com/700906147c1589e284be6f65b8f4eebcebfc733b2d5f04f16af391427108b683/samouraiworld/awesome-mistral",
    "created_at": "2026-01-10T12:20:45.428Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-sending-a-warning-to-us-tech-firms-dont-poach-our-ai-talent-and-tech",
    "title": "China is sending a warning to US tech firms: Don't poach our AI talent and tech",
    "description": "Meta's Manus deal faces a probe from China's regulator. Analysts say it's about sending a message that China's AI talent isn't easy pickings.",
    "fullText": "China has a message for US tech firms: Hands off our AI talent and tech.\n\nThat's what Beijing is signalling by announcing a probe into Meta's acquisition of Manus, analysts told Business Insider.\n\nThe probe, confirmed by China's Ministry of Commerce in a Thursday press conference, will investigate whether the acquisition complies with the country's laws and regulations concerning export controls, according to a statement translated by Google.\n\nManus was launched in China last March by the AI product studio Butterfly Effect and drew global attention after saying it had designed a \"general-purpose\" AI agent that can conduct tasks with limited human supervision. In mid-2025, the startup relocated to Singapore.\n\nIn December, Meta announced that it would acquire Manus and sever its ties with China completely. The deal reportedly exceeds $2 billion. Meta did not respond to a request for comment for this story from Business Insider.\n\nWhile China and the US have long engaged in tit-for-tat regulatory exchanges involving their tech companies, analysts told Business Insider this probe is notable because it appears to be aimed at discouraging so-called \"Singapore washing\" â€” the process of moving a company from China to Singapore to reduce regulatory scrutiny.\n\nTikTok's parent company, ByteDance, and fast-fashion giant Shein are among those that have shifted their headquarters from China to Singapore.\n\nThe probe is also a means to discourage Chinese AI startups from choosing the US, analysts said.\n\n\"I see Beijing's probe as an effort to prevent the loss of AI technology and talent to foreign acquisition, especially to the US,\" Wendy Chang, a senior analyst at the Mercator Institute for China Studies, told Business Insider.\n\nMeta said it plans to bring over Manus' top leadership and will continue to run its AI agent platform separately, alongside integrating the technology into Meta's own products.\n\nNvidia, the world's most valuable company, has been the subject of US export controls for years, which limit the sale of its advanced chips to China. The Manus probe shows how the battleground has moved from beyond chips to \"models, agents, talent, and enterprise deployment,\" Murthy Grandhi, a company profiles analyst at research firm GlobalData, told Business Insider.\n\nHanna Dohmen, senior research analyst at Georgetown's Center for Security and Emerging Technology, told Business Insider that while the probe \"isn't entirely surprising,\" the approach regulators are taking is \"more novel\" because it \"appears to focus on the movement of talent and IP.\"\n\nTalent has become a focal point of the AI race, with companies like OpenAI, Meta, and Google offering huge pay packages to entice the best and brightest. Last year, Meta invested $14 billion in AI training startup Scale AI, bringing its CEO, Alexandr Wang, over to run the tech giant's AI efforts.\n\nChina's Manus probe could signal that it was policing \"outbound AI technology transfer with greater rigor,\" said Grandhi, adding that it could accelerate the \"bifurcation of AI ecosystems.\"\n\nThe US and China have been taking diverging approaches to AI, with Chinese companies tending to favor AI models that are more open, such as DeepSeek.\n\nIt's not clear how long China's probe will last, should it progress into a full investigation. Other investigations from China's Ministry have taken more than a year.\n\nGrandhi said that in his view, the most likely outcome is that the deal will be approved \"with constraints, rather than an outright block.\"\n\n\"Whatever the outcome may be, this certainly sends a signal to other US or foreign companies that are considering similar acquisitions,\" added Dohmen.",
    "readingTime": 3,
    "keywords": [
      "export controls",
      "manus probe",
      "business insider",
      "acquisition",
      "analysts",
      "analyst",
      "china",
      "meta's",
      "agent",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/china-probe-meta-manus-deal-warning-us-analysts-singapore-washing-2026-1",
    "thumbnail_url": "https://i.insider.com/6961850164858d02d2181ec6?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.587Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-says-ai-doomerism-has-done-a-lot-of-damage-and-is-not-helpful-to-society",
    "title": "Nvidia CEO Jensen Huang says AI doomerism has 'done a lot of damage' and is 'not helpful to society'",
    "description": "Nvidia CEO Jensen Huang said that frequent warnings about AI are dissuading people from making investments in AI's improvement.",
    "fullText": "Jensen Huang is over AI doomerism.\n\nThe Nvidia CEO said one of his biggest takeaways from 2025 was \"the battle of narratives\" over the future of AI development between those who see doom on the horizon and the optimists. Huang said while \"it's too simplistic\" to dismiss either side entirely, some of the dismal outlooks are having real consequences.\n\n\"I think we've done a lot of damage with very well-respected people who have painted a doomer narrative, end of the world narrative, science fiction narrative,\" Huang said during a recent episode of the \"No Priors\" podcast. \"And I appreciate that many of us grew up and enjoyed science fiction, but it's not helpful. It's not helpful to people. It's not helpful to the industry. It's not helpful to society. It's not helpful to the governments.\"\n\nHuang didn't name the people in question, nor did he give a specific motivation for why people may be sharing their more dour outlook. Instead, he cited concerns about \"regulatory capture,\" arguing that no company should approach governments to request more regulation.\n\n\"Their intentions are clearly deeply conflicted, and their intentions are clearly not completely in the best interest of society,\" he said. \"I mean, they're obviously CEOs, they're obviously companies, and obviously they're advocating for themselves.\"\n\nA spokesperson for Nvidia declined to elaborate on Huang's remarks. Previously, the Nvidia CEO took issue with Anthropic CEO Dario Amodei's prediction that AI could replace up to half of all white-collar entry-level jobs within five years. (Amodei later said that Huang distorted his views.)\n\nOverall, Huang said the sheer amount of negativity is distorting the conversation around AI.\n\n\"When 90% of the messaging is all around the end of the world and the pessimism, and I think we're scaring people from making the investments in AI that makes it safer, more functional, more productive, and more useful to society,\" he said.\n\nHuang isn't the only CEO who is hoping for a different AI narrative in 2026. Microsoft CEO Satya Nadella wrote in his year-end note that he wanted that society needs to move beyond labeling content AI \"slop.\"\n\n\"We need to get beyond the arguments of slop vs sophistication,\" Nadella wrote on his blog late last year, \"and develop a new equilibrium in terms of our 'theory of the mind' that accounts for humans being equipped with these new cognitive amplifier tools as we relate to each other.\"",
    "readingTime": 3,
    "keywords": [
      "nvidia ceo",
      "science fiction",
      "they're obviously",
      "it's",
      "helpful",
      "narrative",
      "society",
      "huang",
      "governments",
      "intentions"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-jensen-huang-ai-doomerism-damage-investments-2026-1",
    "thumbnail_url": "https://i.insider.com/6961677b04eda4732f2ed348?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.491Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-industry-is-getting-into-politics-here-are-the-key-super-pacs-to-watch-in-2026",
    "title": "The AI industry is getting into politics. Here are the key super PACs to watch in 2026.",
    "description": "The AI industry is pouring hundreds of millions of dollars into super PACs ahead of the 2026 midterm elections.",
    "fullText": "Artificial intelligence is poised to play a big role in politics this year â€” and not just when it comes to AI-generated content.\n\nSeveral super PACs backed by figures in the tech industry have formed ahead of the 2026 midterm elections.\n\nSome of the groups plan to support candidates who are friendly towards the AI industry and will take a lighter regulatory approach to the technology.\n\nAt least one group has been formed explicitly to combat the influence of those pro-AI groups.\n\nHere are the super PACs to keep an eye on as the year progresses.\n\nThe biggest player so far is Leading the Future, a pro-AI network of super PACs that says it has already raised $100 million.\n\nIn an August press release, the group listed a variety of supporters, including:\n\nIt's unclear how much money each entity has contributed to the group, as it has not been required to disclose donors yet.\n\nThe group says it plans to serve as the \"political and policy center of gravity for the AI industry\" and will \"support candidates aligned with the pro-AI agenda\" and \"oppose those that do not.\"\n\nThe group has already begun spending.\n\nThink Big, a PAC affiliated with the group, has spent over $118,000 against Assemblyman Alex Bores in the Democratic primary for New York's 12th congressional district.\n\nAnd American Mission, a separate affiliated PAC, has spent over $243,000 backing GOP candidate Chris Gober in Texas's 10th congressional district.\n\nIn response to Leading the Future, two former congressmen â€” Republican Chris Stewart of Utah and Democrat Brad Carson of Oklahoma â€” have formed their own competing political network to back candidates who support AI regulation, called Public First.\n\nThe group is aiming to raise $50 million for its effort, well short of what the pro-AI groups have raised. But Carson told Business Insider he feels good about Public First's odds, given that the American public is broadly supportive of AI regulation.\n\n\"We have $50 million and 85% of public sentiment. They have 15% of public settlement, and $100 million,\" Carson said. \"I will take our side of that bet any day.\"\n\nThe group has not yet disclosed donors, though Carson said that Public First would have financial support from employees at a variety of AI companies.\n\n\"There's going to be people from across the AI sector, as well as far beyond the AI sector, who contribute to the effort,\" Carson said.\n\nThe group has two affiliated super PACs: one that supports Democrats called Jobs and Democracy PAC, and another that supports Republicans called Defending Our Values PAC. Neither has spent in any election so far.\n\nMeta is also getting into the super PAC game, establishing two different PACs last year to support candidates aligned with their vision for AI regulation.\n\nUnlike the other PACs, Meta's efforts will focus primarily on the state level.\n\nOne PAC, called Mobilizing Economic Transformation Across (Meta) California, will focus specifically on the Golden State, where Meta is headquartered.\n\n\"As home to many of the world's leading AI companies, California's innovation economy has an outsized impact on America's economic growth, job creation, and global competitiveness,\" a Meta spokesperson said. \"But Sacramento's regulatory environment could stifle innovation, block AI progress, and put California's technology leadership at risk.\"\n\nThe spokesperson added that the PAC would back candidates in both parties who \"recognize California's vital role in AI development and embrace policies that will keep the state at the forefront of the global tech ecosystem.\"\n\nA separate PAC, the American Technology Excellence Project, will focus on races in other states.\n\n\"Amid a growing patchwork of inconsistent regulations that threaten homegrown innovation and investments in AI, state lawmakers are uniquely positioned to ensure that America remains a global technology leader,\" Meta VP of Public Policy Brian Rice said in a statement.\n\nNeither PAC has spent significant sums yet.",
    "readingTime": 4,
    "keywords": [
      "super pacs",
      "congressional district",
      "candidates aligned",
      "back candidates",
      "pro-ai groups",
      "leading the future",
      "technology",
      "industry",
      "formed",
      "affiliated"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/artificial-intelligence-industry-super-pacs-2026-1",
    "thumbnail_url": "https://i.insider.com/695c31af832e0ef1ead731e5?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.363Z",
    "topic": "tech"
  },
  {
    "slug": "ai-isnt-making-us-smarter-its-training-us-to-think-backward-an-innovation-theorist-says",
    "title": "AI isn't making us smarter â€” it's training us to think backward, an innovation theorist says",
    "description": "Innovation theorist John Nosta said AI's polished responses can erode human reasoning at work by creating confidence without understanding.",
    "fullText": "AI is often described as a thinking machine â€” a digital mind edging closer to human intelligence.\n\nHowever, John Nosta, an innovation theorist and founder of NostaLab, an innovation and tech think tank, said that large language models don't think like humans at all.\n\nIn fact, he calls AI \"anti-intelligence\" because it operates in a way that runs counter to how humans reason, learn, and build understanding.\n\n\"My conclusion is that artificial intelligence is antithetical to human cognition,\" Nosta told Business Insider. \"I even call it anti-intelligence.\"\n\nAt the heart of Nosta's argument is a simple but unsettling claim: AI doesn't understand anything in the human sense.\n\nWhen people think about an object â€” say, an apple â€” they place it in space, time, memory, culture, and lived experience, he said.\n\nA large language model, Nosta said, does none of that. Instead, it represents the word as a mathematical object inside an enormous, hyperdimensional space and searches for patterns that statistically align, he said.\n\n\"An apple doesn't exist as an apple,\" he said. \"It exists as a vector in a hyperdimensional space.\"\n\nThat distinction matters, he said, because it means AI outputs are optimized for coherence rather than comprehension.\n\nThe system isn't reasoning its way to an answer â€” it's producing the response that best fits a pattern of language, he said.\n\nNosta believes AI is quietly reshaping how people think, especially at work.\n\nHuman cognition, he said, usually follows a familiar path: confusion, exploration, tentative structure, and finally confidence. AI flips that sequence.\n\n\"With AI, we start with structure,\" he said. \"We start with coherence, fluency, a sense of completeness, and afterwards we find confidence.\"\n\nThat inversion creates a powerful illusion. Because AI-generated answers sound polished and authoritative, people often accept them immediately â€” without doing the harder work of questioning, exploring, or fully understanding them, he said.\n\n\"Coming to the answer first is an inversion of human cognitive process,\" Nosta said. \"That's antithetical to human thought.\"\n\nThe danger isn't that AI will outperform humans in raw computation. Nosta said that's inevitable. What worries him is how easily people can outsource the most valuable parts of thinking.\n\n\"It's the stumbles, it's the roughness, it's the friction that allows us to get to observations and hypotheses that really develop who we are,\" he said.\n\nAs some companies push employees to go \"all in\" on AI for writing, analysis, and decision-making, Nosta said that speed and fluency are being mistaken for understanding.\n\nUsed as a partner, AI can enhance human thinking. Used as a shortcut, it can quietly weaken it, he said.\n\n\"The magic isn't necessarily AI,\" he said. \"It's the iterative dynamic between humans and machines.\"\n\nIn Nosta's view, the real risk of the AI era isn't smarter machines â€” it's humans learning to think backward.\n\nConcerns about how AI may be reshaping human thinking are increasingly shared beyond theorists.\n\nResearchers at Oxford University Press found in a recent report that AI is making students faster and more fluent while quietly stripping away the depth that comes from pausing, questioning, and thinking independently.\n\nA report from the Work AI Institute, released last month, echoed the same pattern, saying that generative AI often creates an illusion of expertise â€” making users feel smarter and more productive, even as their underlying skills erode.\n\nMehdi Paryavi, CEO of the International Data Center Authority, which advises companies and governments on building the data centers that power AI, said that excessive and poorly designed AI use is driving a \"quiet cognitive erosion.\"\n\n\"If you come to believe that AI writes better than you and thinks smarter than you, you will lose your own confidence in yourself,\" he told Business Insider.",
    "readingTime": 4,
    "keywords": [
      "hyperdimensional space",
      "human cognition",
      "business insider",
      "it's",
      "humans",
      "isn't",
      "language",
      "understanding",
      "apple",
      "quietly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-human-intelligence-impact-at-work-2026-1",
    "thumbnail_url": "https://i.insider.com/695fa5dd04eda4732f2eb200?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.230Z",
    "topic": "finance"
  },
  {
    "slug": "everything-we-know-about-how-wall-streets-biggest-firms-from-jpmorgan-to-blackstone-are-adopting-ai",
    "title": "Everything we know about how Wall Street's biggest firms, from JPMorgan to Blackstone, are adopting AI",
    "description": "Finance's biggest firms are considering how AI might impact jobs, how it could cut costs, and reduce \"grunt work.\"",
    "fullText": "Welcome to Wall Street's AI era.\n\nBanks, private equity firms, hedge funds, and asset managers have been eager to use generative AI to boost productivity and reduce grunt work for workers.\n\nBusiness Insider has been reporting on how some of finance's biggest players are approaching artificial intelligence, from its potential impact on jobs and the creation of new ones, to the various ways firms are cutting costs and ramping up efficiencies.\n\nBut firstÂ â€” if you work at a Wall Street firm and are using AI, we want to hear from you. How is AI really showing up in your day-to-day? Is it living up to the hype?\n\nAI is set to reshape roughly 44% of banking work by 2030, according to consulting firm ThoughtLinks â€” and Wall Street's biggest firms are racing to get there first.\n\nJPMorgan Chase, the largest US bank by assets, is spending $18 billion a year on technology, with AI a central focus. CEO Jamie Dimon is a \"tremendous\" user of the bank's generative AI tools, which have now been rolled out to more than 200,000 employees.\n\nThe bank is also replacing long-standing human processes with AI. Its asset-management arm announced plans to stop using external proxy advisers for US shareholder voting, instead launching an in-house AI platform, Proxy IQ, which will analyze data from more than 3,000 annual company meetings. Executives have said the bank is training employees to use AI in ways that deliver measurable productivity gains.\n\nGoldman Sachs is spending $6 billion on technology this year â€” a figure CEO David Solomon has said he wishes were higher. In an October memo outlining the latest phase of its OneGS initiative, the bank said AI would drive efficiency, slow hiring, and lead to a \"limited reduction\" in roles. Goldman has since rolled out internal AI tools, including an assistant now available to employees across the firm.\n\nMorgan Stanley, an early OpenAI partner, has focused on turning employee ideas into working AI products. One internally built tool, called DevGen.AI has already saved engineers more than 280,000 hours this year. Among interns, AI adoption is especially strong: 72% say they use ChatGPT daily or several times a week.\n\nCitigroup has also accelerated its push. Nearly 180,000 employees across 83 countries now have access to Citi's proprietary AI tools, which have been used almost 7 million times this year. CEO Jane Fraser said the bank's generative AI tools are saving about 100,000 developer hours a week through automated code reviews. Citi also began piloting agentic AI with 5,000 employees in September.\n\nIn the ultracompetitive world of hedge funds, being ahead on the latest technology is always a priority.\n\nIn December, Citadel said its stockpickers are using an internal chatbot to speed up their processes and find new info at his $71 billion hedge fund.\n\nAt the 2025 Global Milken conference, Andreas Kreuz, WorldQuant's deputy CIO, said the firm was using AI to expand the data it can bring into its models since it can restructure data from images and audio.\n\nPoint72's CTO Ilya Gaysinskiy told BI about his big plans to ramp up Point72's tech organization and how AI will play into that expansion.\n\nBridgewater launched a fund driven by AI in 2024. The fund's AIA Labs worked to replicate every stage of the investment process with machine learning. The firm's co-chief investment officer and chief scientist outlined the plans of the world's largest hedge fund.\n\n$29 billion hedge fund Balyasny has built an AI bot that it believes will be able to do the grunt work that typically falls to senior analysts â€” a potential huge timesaver for investment teams. The manager told Business Insider in 2024 that roughly 80% of the firm's staff use its AI tools, which include the internal chatbot BAMChatGPT, and recently hired Matthew Henderey, one of the CIA's AI developers, as a data science executive. Man Group and Viking Global have also developed their own internal offerings.\n\nLucia Soares â€” Carlyle's chief information officer and head of technology transformation â€” talked to BI about taking on a new challenge: Bringing AI to the investment giant's 2,300 global employees.\n\nPrivate equity firms are no strangers to managing and analyzing copious amounts of data â€” but data is only helpful if you can find it. Blackstone has invested in improving its enterprise search and is also betting AI will give it a leg up in its pursuit to capture more of the insurance market.\n\nSwedish PE giant EQT built an AI engine called Motherbrain that has changed how its investors source deals. ChatGPT enables the investing giant to take the next step with its AI ambitions.\n\nAs private equity firms turn to AI for a competitive edge, Thomas H. Lee says its engineers are up to 30% more productive with help from AI coding assistants.\n\nAI tools are changing how stock-pickers do their job. AllianceBernstein, BlackRock, and JPMorgan opened up on how their tools are speeding up portfolio manager workflows.\n\nBlackRock has introduced Asimov, the agentic AI platform for the firm's fundamental equity business. Business Insider talked to Kirsty Craig, head of research, data, and AI strategy for portfolio management tech, who helped develop the tool.\n\nThe multi-billion-dollar investment manager VanEck invested in a Toronto-based startup and is onboarding its technology to boost its ETF business. An executive and the fintech's CEO walked us through how AI will change the jobs of analysts and salespeople.\n\nKraken's $1.5 billion acquisition of a retail trading startup made headlines last March. Less noticed was how the crypto exchange used generative AI to run due diligence on the target â€” a process its head of M&A now considers core to his team's work.\n\nAt Block, Jack Dorsey's fintech behind Square, Afterpay, and Cash App, engineers built an AI agent that can write code faster â€” and in some cases better â€” than senior developers. The company ultimately decided to open-source the tool, even as it gives competitors a look under the hood.\n\nChime has taken a similar in-house approach. In 2023, the neobank built a private, ChatGPT-style assistant to help engineers ship products more quickly and at lower cost. The company's CTO shared how the tool has become a key part of Chime's product-development playbook.",
    "readingTime": 6,
    "keywords": [
      "wall street's",
      "bank's generative",
      "internal chatbot",
      "hedge funds",
      "employees across",
      "equity firms",
      "hedge fund",
      "business insider",
      "tools",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-wall-street-is-using-ai-jpmorgan-goldman-citi-blackstone",
    "thumbnail_url": "https://i.insider.com/676990d59de00e389eb3082d?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.084Z",
    "topic": "finance"
  },
  {
    "slug": "5-groundbreaking-and-strange-products-you-could-soon-buy-from-the-2026-consumer-electronics-show",
    "title": "5 ground-breaking (and strange) products you could soon buy from the 2026 Consumer Electronics Show",
    "description": "From a lollipop that lets you taste sound to a Tamagotchi style AI pet that physically grows, here are the coolest tech you could get your hands on.",
    "fullText": "This lollipop lets you taste your favorite music â€” literally.\n\nUsing bone induction technology, Lollipop Star made a candy that can transmit sound through vibrations in the jaw and skull while it's in the mouth. For those without synesthesia, this may be the closest you can come to experiencing it.\n\nAccording to Lollipop Star's website, the candy is designed with a standard lollipop on top of a thicker handle at the bottom, which houses the electronics. Users could bite down lightly on the candy to activate the vibrations. Earplugs are included to help isolate the sound in noisy environments.\n\nBased on photos from Lollipop Star's booth at the CES, each candy is tied to a specific artist and flavor. For example, Ice Spice's version comes in peach, Akon's is blueberry, and Armani White's is lime.\n\nOn its website, the company says that the novelty candy will come at an affordable price of $9 each.\n\nThe Tamagotchi of the AI era is here.\n\nA new AI pet from Chinese startup Takway AI, called Sweekar, debuted in the US at CES. Unlike most AI companions that exist entirely virtually, this creature has a physical form that appears to grow.\n\nBased on demo videos, the Sweekar starts out as a palm-sized, egg-shaped device with glowing ears. After an incubation period that can last up to two days, the shell appears to crack open, revealing a newborn digital creature.\n\nFrom there, Sweekar moves through a series of life stages. The baby phase lasts roughly five to seven days, followed by a teenage stage that can stretch from about three to six weeks. Eventually, the pet reaches adulthood, developing greater intelligence and a more defined personality, as well as more independence.\n\nEarly in its life, the pet requires frequent attention, including regular care and help learning basic language. Just like a Tamagotchi, Sweekar can die from neglect.\n\nTakway AI said in a press release that it plans to launch Sweekar on Kickstarter later this year. The company expects the device to be priced at around $150.\n\nVacuum cleaning robots are taking a major step up.\n\nRoborock's Saros Rover prototype became the first robot vacuum to climb stairs at CES. Based on demo videos, the prototype robot vacuum uses a pair of articulated wheel-legs that lift and lever its body up, before folding away and redeploying for the next step.\n\nThe process isn't fast, according to demo videos, but the Rover cleans the stairs as it goes. Roborock said in a press release that the system works on traditional, curved, and carpeted staircases, as well as ramps, thresholds, and other household obstacles.\n\nThe Saros Rover remains an early prototype, and Roborock hasn't shared pricing or a launch timeline. The company has said in a press release, however, that it plans to bring the stair-climbing robot vacuum to market.\n\nLenovo showcased numerous concept devices at CES 2026, but one of its boldest ideas was a gaming laptop featuring a screen that physically expands wider.\n\nThe Legion Pro Rollable, as Lenovo described in a press release, is built around a 16-inch flexible OLED display that can expand sideways to two larger sizes. From photos, the device appears to have a screen screen stretches from a standard 16:10 aspect ratio to 21:9 or an ultra-wide 24:9, effectively turning a compact gaming laptop into a widescreen display better suited for immersive games.\n\nAccording to Lenovo, the Legion Pro has the same lower chassis, ports, and supports high-end graphics, just like some of Lenovo's other products. The rollable device was named Best Gaming Product in the Official Best of CES 2026 Awards, though Lenovo has not announced plans to turn it into a retail device.\n\nAI-Tails is betting that AI can spot health issues in cats long before their owners do.\n\nAt CES, the Swiss startup has unveiled a smart feeding and drinking station that uses AI, cameras, and pattern-recognition software to analyze a cat's behavior and facial expressions, signals that are often too subtle for humans to notice without veterinary expertise. The company's website said that the goal is to monitor a pet's well-being continuously and flag potential problems in real time.\n\nVideos of a live demo at CES show that the system features separate bowls for food and water. with built-in sensors and cameras, analyze consumption patterns, body temperature, and facial cues.\n\nThe feeding station is currently available for preorder and is expected to ship worldwide in the fourth quarter of 2026, according to the company's website. The models are expected to be priced between $199 and $299.",
    "readingTime": 4,
    "keywords": [
      "legion pro",
      "saros rover",
      "gaming laptop",
      "press release",
      "robot vacuum",
      "company's website",
      "demo videos",
      "lollipop star's",
      "takway ai",
      "candy"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ground-breaking-and-quirky-products-from-the-2026-ces-2026-1",
    "thumbnail_url": "https://i.insider.com/695ec58964858d02d217f172?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:39.933Z",
    "topic": "finance"
  },
  {
    "slug": "understanding-the-types-of-data-in-data",
    "title": "Understanding the Types of Data in Data",
    "description": "Discover the key types of data in data science, from structured to unstructured, and learn their significance in analytics and machine learning applications.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://ischool.syracuse.edu/types-of-data/",
    "thumbnail_url": "https://ischool.syracuse.edu/wp-content/uploads/types-of-data-1024x682.png",
    "created_at": "2026-01-10T06:17:38.371Z",
    "topic": "tech"
  },
  {
    "slug": "digging-into-the-llmasajudge-results",
    "title": "Digging into the LLM-as-a-Judge Results",
    "description": "I was unhappy with the LLM-as-a-judge instruction fine-tuning results I got when comparing my various base models.  Could I make them any better?",
    "fullText": "I'm still working on my \"extra credit\" projects after finishing the main body of\nSebastian Raschka's book\n\"Build a Large Language Model (from Scratch)\".\nLast time around, I trained four base models, using the GPT-2 architecture from\nthe book, on Lambda Labs machines. I was using two ways to compare them with each\nother, with three models that I'd trained locally, and with the original GPT-2 weights\nfrom OpenAI:\n\nHere were the results I got, sorted by the loss:\n\nNow, you'd expect there to be at least a loose correlation;\nthe lower the loss, the higher the IFT score. But, while we can see a difference\nbetween the OpenAI weights and our own, within our own there doesn't seem to be a\nlogical pattern.\n\nI think that the problem is that the results from the GPT-5.1\nLLM-as-a-judge are not consistent between models. That's not a complaint about\nthe code or its original design, of course -- it was originally written as part\nof the LLM book as a way of doing a quick test on an instruction fine-tuned model that\nwe'd spent the previous 238 pages writing -- just something that was a bit more efficient than\nreading hundreds of input/output pairs ourselves. It was never meant to be a tool\nto compare models in the way I'm using it now.\n\nIn this post I'll dig into why it doesn't work for this kind of thing, and see if that's something\nwe can change.\n\nLet's spec out the problem first. The instruction fine-tuning test trains our model\non the Alpaca dataset in order to\nlet it know how to follow instructions; that comprises a series of sequences like\nthis:\n\nIn the version I've settled on,\nI fine-tune on a training set of 85% of the samples, epoch by epoch, bailing out when the\nloss on a separate validation set of 5% of the samples starts rising. I then use the\nweights from the previous epoch -- that is, before validation loss started rising --\nto generate responses to the remaining 10% of the samples.\n\nOnce that's done, the script hits the OpenAI API, using GPT-5.1, default parameters for all\nof the options (eg. no explicit temperature) with queries like this:\n\nWe do that for every model-generated response in the test set, then take the\naverage of the scores and use that as our result.\n\nTo see why that's problematic, imagine this simple instruction with no separate input:\n\nOne response I've seen from my models was this:\n\nThat's obvious garbage, and should get a zero -- and GPT-5.1 consistently does that.\n\nAnother response, from OpenAI's original weights for their \"medium\" model (larger than\nthe ones I've been training), is this:\n\nThat's correct, so it deserves 100, or perhaps 95 due to being unnecessarily\nwordy (the answer \"Jane Austen\" is the suggested response in the dataset).\n\nOne of my models came up with that gem during an earlier eval. It's completely wrong,\nso it deserves a 0, right? And normally the GPT-5.1 model does that -- but sometimes\nit's a little more generous, and gives it a low, but non-zero score. When asked for\nits reason for that, it makes the logical point that while it's the wrong answer, at\nleast Sarah Palin is a real person. It's better than the \"the book wrote itself\"\ncomplete nonsense of the first response.\n\nThe problem is that the different runs against the different models are not consistent, as\nthey're all talking to GPT-5.1 separately. One model might find it in a harsh \"mood\",\nand get a lower rating than another model that found it at a more generous moment.\n\nI came to the conclusion that the best way to fix this is to do a \"batch\" -- that is, fine-tune\neach model on the Alpaca dataset that Raschka provides, and generate responses for\nthe test set and store them in a file. Then, once we've done that for all models,\nwe can score them all at once, prompting GPT-5.1 with something like this:\n\nThe theory is that doing it that way will mean that each individual query/response pair is graded consistently\nbetween models, even if there might still be inconsistencies between query/response pairs.\nThat hopefully means we'll get more consistent results and can compare the models\nbetter.\n\nRunning the first against each of our models, and then the second against all of the\noutput files, gives us this updated table (with links to the annotated JSON files\nin case anyone else wants to take a look):\n\n(Still sorted by loss so that you can compare it more easily with the one above.)\n\nThat's really interesting! The IFT score is still not correlated with the loss.\nBut there does appear to be a pattern.\n\nIt looks like we have three groups of models:\n\nI tried running the LLM-as-a-judge scoring script a few times, just to make sure\nthis wasn't some kind of random weirdness, but the pattern was always the same:\nthe OpenAI weights, the cloud FineWeb 8x A100 40 GiB, and the two local Local FineWeb-Edu\nmodels always got the best IFT scores, though sometimes they swapped positions (apart from the\nOpenAI medium model, which was of course always at the top). The other cloud\nFineWeb models and the local FineWeb one were consistently scored much lower.\n\nA hypothesis: there are two things that contribute to how good a model is at these\nIFT tests:\n\nOr to put it another way -- some of these models are smart but not knowledgeable, while\nothers are knowledgeable but not smart, and some are neither.\nI think that could explain what we're seeing here. While OpenAI never published\ntheir \"WebText\" dataset for GPT-2, the paper\ndescribes it as\n\na new web scrape which emphasizes\n document quality. To do this we only scraped web pages\n which have been curated/filtered by humans. Manually\n filtering a full web scrape would be exceptionally expensive\n so as a starting point, we scraped all outbound links from\n Reddit, a social media platform, which received at least 3\n karma.\n\nNow, the FineWeb dataset is quite similar, though I think it's a tad more curated than that.\nBut OpenAI trained\ntheir models for quite some time and did lots of tricks to get the loss as low as\npossible.\n\nonly the most \"educational\" data. Models trained on it, you might think, would\nknow more facts for a given amount of training.\n\nSo we can imagine the OpenAI models are smart but not knowledgeable, as we can our\ncloud FineWeb 8x A100 40 GiB model, which (I believe due to an accidentally-near-optimal batch\nsize) worked out well in terms of loss. They were trained on relatively sloppy datasets\nbut turned out reasonably well. Their intelligence makes up for some of their lack of\nknowledge.\n\nOur other cloud trains and the local FineWeb one are dumb and not\nknowledgeable; they were trained on the low-information FineWeb dataset, but they didn't\nwind up with a particularly amazing loss. So they get low scores.\n\nAnd finally, our local FineWeb-Edu models are still dumb, but they make up for it\n\nWell, it sounds plausible ;-) And I'd like to spend some time digging in to see if there's any indication\nif it's actually true. But after an afternoon of poking around the results, I can't really get\na handle on whether it is, or indeed how you'd test that hypothesis in any real\ndepth.\n\nTBH, I think this has zoomed so far past my \"no side quests\" limit that it's not even\nvisible in the rear view mirror, so it's probably best to shelve it as a\n\"cool idea, bro\" for now. Learning about how to run sensible evals, and how to work out\nwhat they're saying, will have to be a task for another day. I will keep on doing these\nIFT tests for future models, though, just out of interest.\n\nSo: let's get back to our regular scheduled LLM training. Next up, how do we\nupload our models to Hugging Face quickly and easily so that other people can\nplay with them.",
    "readingTime": 7,
    "keywords": [
      "ift tests",
      "alpaca dataset",
      "cloud fineweb",
      "ift score",
      "generate responses",
      "openai weights",
      "fineweb-edu models",
      "web scrape",
      "medium model",
      "fineweb gib"
    ],
    "qualityScore": 1,
    "link": "https://www.gilesthomas.com/2026/01/llm-from-scratch-30-digging-into-llm-as-a-judge",
    "thumbnail_url": "https://www.gilesthomas.com/images/favicons/web-app-manifest-512x512.png",
    "created_at": "2026-01-10T06:17:37.191Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-warns-investors-that-the-ai-market-is-bigger-than-they-realize-with-over-one-and-a-half-million",
    "title": "Nvidia CEO Jensen Huang Warns Investors That the AI Market Is Bigger Than They Realize With Over â€˜One and a Half Million AI Models in the Worldâ€™",
    "description": "Jensen Huang explains artificial intelligence as a multi-layered platform, arguing its true impact extends far beyond consumer-facing language models.",
    "fullText": "Bottom Line Up Front: Nvidia (NVDA) CEO Jensen Huang, in his role as the leader of the primary company behind the ongoing technology movement, says that many people donâ€™t realize just how big the AI revolution is. He says there are currently over 1.5 million AI models throughout the world, from healthcare and drug discovery to more commonly known names like Elon Muskâ€™s Grok and Sam Altmanâ€™s ChatGPT.\n\nThe Details: Nvidia founder and chief executive Jensen Huang has consistently framed artificial intelligence as an infrastructure-scale transformation rather than a single technological breakthrough. In a fireside chat hosted by the Center for Strategic and International Studies (CSIS) with President and CEO Dr. John J. Hamre, Huang continued outlining his layered view of AI, emphasizing the systems, capital, and breadth of applications that underpin the technologyâ€™s long-term impact.\n\nJeff Bezos Launched a Secretive AI Startup in 2025 That Should Give Wall Street Chills\n\nThe Top-Rated Dividend King to Buy for 2026\n\nEvercore Analysts Love UnitedHealth Stock for 2026. Should You Buy UNH Here?\n\nTired of missing midday reversals? The FREE Barchart Brief newsletter keeps you in the know. \n\nBuilding on earlier discussion of energy, chips, and systems, Huang described the current infrastructure buildout of AI as being multi-layered. The first layer is simple: energy. Huang frames electricity buildout as the most fundamental part of the entire AI revolution.\n\nThe next is Nvidia itself: Chips. Without chips, thereâ€™s nothing to use electricity and process the AI compute needed to run the AI models.\n\nHuang then highlights the third layer, which â€œincludes financial services, because it takes an enormous amount of capital to do what we do.â€ His remarks highlight that AI development at scale is not only a technical challenge, but also a financial one, requiring sustained investment in data centers, networking, and long-lived computing assets.\n\nHuang then turned to the fourth layer that receives the most public attention: the models themselves. He acknowledged the prominence of well-known systems, describing how â€œthis is where people largely focus on when they talk about AI,â€ citing examples such as ChatGPT, Anthropicâ€™s Claude, Googleâ€™s Gemini, and xAIâ€™s Grok. However, he placed those systems in a much wider context, pointing out that â€œthose are four of the one and a half million AI models in the world.â€ The statement reframes popular generative models as an incredibly small subset of a far larger and more diverse ecosystem. This statement diversifies the risk away from the larger, more broadly known AI models, and instead frames Nvidia as an infrastructure play amongst a technological revolution being implemented across every industry in the world.",
    "readingTime": 3,
    "keywords": [
      "models",
      "nvidia",
      "systems",
      "revolution",
      "layer",
      "huang",
      "chatgpt",
      "technological",
      "capital",
      "energy"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-warns-195710498.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Igtx2Q0Uj7BygxF7VSpYaw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/barchart_com_477/be19911bf230a776b5d5f5aeb01b6b73",
    "created_at": "2026-01-10T06:17:35.568Z",
    "topic": "finance"
  },
  {
    "slug": "3-brilliant-ai-stocks-that-could-double-in-2026",
    "title": "3 Brilliant AI Stocks That Could Double in 2026",
    "description": "The AI investment realm is full of great opportunities in 2026.",
    "fullText": "Nebius and Applied Digital are both data center plays.\n\nSoundHound AI could see monster adoption over the next few years.\n\n10 stocks we like better than Nebius Group â€º\n\nWith artificial intelligence (AI) usage skyrocketing, this sector of the market is a great place to look for stocks that could double in under a year. Many AI companies are generating explosive growth, and these are the ones to take a look at.\n\nThree, in particular, have a chance to double in value in 2026: Nebius (NASDAQ: NBIS), Applied Digital (NASDAQ: APLD), and SoundHound AI (NASDAQ: SOUN). All three are growing at a rapid pace and could provide investors with a potential doubling of returns in 2026.\n\nNebius and Applied Digital operate in similar industries. Nebius was spun out of Russian-based Yandex after sanctions from the Ukraine war devastated the business, including the non-Russian parts. Nebius is focused on providing computing power to its various clients by renting out space in a data center and placing cutting-edge graphics processing units (GPUs) in them. It also owns some of the locations it operates in.\n\nDemand for computing power has been unprecedented, and Nebius told investors that it has \"sold out\" all of its available capacity. As it expands capacity, it expects to have a $7 billion to $9 billion annual run rate (ARR) by the end of 2026. For comparison, its ARR at the end of Q3 was $551 million. That's explosive growth for a relatively small business, and I wouldn't be surprised to see the stock double in 2026 as a result.\n\nApplied Digital builds and operates data centers and has two facilities in North Dakota that it operates. It is working on increasing computing capacity at these two facilities, and is a key CoreWeave (NASDAQ: CRWV) partner. It has signed 15-year leases for many of its data centers, which gives investors a long-term look into what Applied Digital's future looks like.\n\nIn the first quarter of its fiscal year 2026, ended Aug. 31, its revenue rose about 84% year over year. As more computing capacity comes online, its revenue will jump, which could lead to outsize stock performance.\n\nLast is SoundHound AI. SoundHound AI blends generative AI and audio recognition to create a software platform that can be deployed in many applications. This is a key company to watch in 2026, as there could be a huge growth explosion if widespread adoption occurs. Several industries can be streamlined by deploying generative AI agents, such as customer service reps.\n\nIn its latest quarter, SoundHound AI's revenue jumped 68% year over year, and it raised the full-year outlook. We'll see if SoundHound AI's product gains momentum in 2026. But it could be a great year for the company and the stock.",
    "readingTime": 3,
    "keywords": [
      "explosive growth",
      "computing capacity",
      "soundhound ai's",
      "nebius and applied digital",
      "look",
      "investors",
      "operates",
      "stock",
      "revenue",
      "center"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/3-brilliant-ai-stocks-could-102000265.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/e3d_RTV3aWFw13mNpWXO_A--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02ODc-/https://media.zenfs.com/en/motleyfool.com/db0b53fc8acad71bf6d377dc41530b71",
    "created_at": "2026-01-10T06:17:34.848Z",
    "topic": "finance"
  },
  {
    "slug": "amazon-has-big-hopes-for-wearable-ai-starting-with-this-50-gadget",
    "title": "Amazon has big hopes for wearable AI â€“ starting with this $50 gadget",
    "description": "Bee's device, which can be worn on the wrist or clipped to a shirt, records and transcribes its owner's activities.",
    "fullText": "Several months afterÂ AmazonÂ boughtÂ artificial intelligenceÂ hardware startup Bee, the company said itâ€™s working to make its $50 always-listening wearable more proactive, and indicated a larger revamp is in store.\n\nBeeâ€™s device, which can be worn on the wrist or clipped to a shirt, records and transcribes its ownerâ€™s activities, using that information to recap conversations and automatically createÂ to-do lists in a companion appÂ throughout the day.\n\nIt doesnâ€™t have a display or built-in camera, and is designedÂ to be â€œambient AIâ€ hardware that fades into the background without the user needing to constantly interact with it. The small gadgetâ€™s battery can last as long as a week before needing a recharge, according to the company.\n\nEarlyÂ AI-powered devices such as the Humane AI Pin and Rabbit R1 haveÂ landed with a thud, owingÂ to issues such as bugs, poor battery life and the lack of any standout features that would make them preferable to smartphones.\n\nAmazon has a spotty history with wearables and has shown less dedication to the category compared with its tentpole Fire TV, Kindle and Echo hardware. The companyÂ discontinued its Halo health tracker wristband in 2023 and has not released a new pair of wireless earbudsÂ in almost three years. The Halo device offered some features that have carried forwardÂ with Bee, like the ability to detect a speakerâ€™s mood.\n\nBee is trying to chart a different pathÂ from those gadgets by acting as a comprehensiveÂ daily journal that requires no prompting or manual input. Startups like Plaud have released competing gadgets with a similar purpose.\n\nThe notion of Amazon taking ownership of an always-listening accessory has made some people wary, but the startup said it maintainsÂ stringent privacy practices.",
    "readingTime": 2,
    "keywords": [
      "amazon",
      "hardware",
      "startup",
      "always-listening",
      "device",
      "needing",
      "battery",
      "features",
      "released",
      "gadgets"
    ],
    "qualityScore": 0.85,
    "link": "https://www.seattletimes.com/business/amazon-has-big-hopes-for-wearable-ai-starting-with-this-50-gadget/",
    "thumbnail_url": "https://images.seattletimes.com/wp-content/uploads/2026/01/01092026_tzr_tzr_142059.jpg?d=1200x630",
    "created_at": "2026-01-10T00:56:40.169Z",
    "topic": "tech"
  },
  {
    "slug": "meta-signs-multigigawatt-nuclear-deals-to-power-ai-data-centers",
    "title": "Meta Signs Multi-Gigawatt Nuclear Deals to Power AI Data Centers",
    "description": "Meta Platforms Inc. agreed to a series of electricity deals to power data centers that could end up totaling more than 6 gigawatts, enough to power a city of about 5 million homes. Will Wade reports on Bloomberg Television.",
    "fullText": "Meta Signs Multi-Gigawatt Nuclear Deals to Power AI Data Centers BloombergMETA Meta Platforms Inc. agreed to a series of electricity deals to power data centers that could end up totaling more than 6 gigawatts, enough to power a city of about 5 million homes. Will Wade reports on Bloomberg Television.",
    "readingTime": 1,
    "keywords": [
      "meta",
      "deals",
      "centers"
    ],
    "qualityScore": 0.2,
    "link": "https://finance.yahoo.com/video/meta-signs-multi-gigawatt-nuclear-144646673.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/R5kWKWtvfAylSB_XAu7M9g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/bloomberg_markets_video_2/d505c5ebe53e6e5826abcb1c0ee4fa5d",
    "created_at": "2026-01-10T00:56:37.546Z",
    "topic": "finance"
  },
  {
    "slug": "8-wall-street-pros-share-their-tips-on-investing-amid-rising-ai-bubble-concerns",
    "title": "8 Wall Street pros share their tips on investing amid rising AI bubble concerns",
    "description": "Over the last couple of weeks, we've asked market pros where they fall on the AI bubble argument and how to invest accordingly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/8-wall-street-pros-tips-investing-amid-in-ai-bubble-2026-1",
    "thumbnail_url": "https://i.insider.com/6961574e832e0ef1ead78339?width=1200&format=jpeg",
    "created_at": "2026-01-10T00:56:32.775Z",
    "topic": "finance"
  },
  {
    "slug": "ram-shortages-may-lead-to-more-expensive-tvs-and-devices-warns-samsung",
    "title": "RAM Shortages May Lead To More Expensive TVs And Devices, Warns Samsung",
    "description": "The increasing demand for AI among tech companies is one of the reasons why the global shortage of memory chips remains an ongoing issue. And while it's expected to adversely affect the production of smartphones, Samsung Electronics co-CEO T M Roh has warned that TVs and home appliances may also be hit by shortages and increased prices.\n\"As this situation is unprecedented, no company is immune to its impact,\" said Roh via Reuters. According to the report, Roh noted that TVs and home appliances will also feel the pinch from the shortages and he didn't rule out price hikes to compensate for them. Samsung is the biggest manufacturer of TVs in the world, and Roh said it the impact of the RAM shortages will be \"inevitable.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/ram-shortages-may-lead-to-more-expensive-tvs-and-devices-warns-samsung/1100-6537306/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4633166-samsungtv.jpg",
    "created_at": "2026-01-10T00:56:32.383Z",
    "topic": "gaming"
  },
  {
    "slug": "brain-scanning-headsets-cool-new-controllers-ai-gaming-companions-ces-2026-roundup",
    "title": "Brain Scanning Headsets, Cool New Controllers, AI Gaming Companions: CES 2026 Roundup",
    "description": "The Consumer Electronics Show kicked off with plenty of gaming reveals from the likes of NVIDIA, Razer, LEGO, HyperX, and XReal. We round up the best and weirdest from the show.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/brain-scanning-headsets-cool-new-controllers-ai-gaming-companions-ces-2026-roundup/2300-6466635/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1574/15746725/4633178-ces2026_v1.jpg",
    "created_at": "2026-01-10T00:56:31.425Z",
    "topic": "gaming"
  },
  {
    "slug": "our-2026-video-game-industry-predictions-spot-on",
    "title": "Our 2026 Video Game Industry Predictions - Spot On",
    "description": "It's the start of the new year, so what better time to make some big and bold predictions about what 2026 will bring for us gamers. From the Steam Machine and GTA6 releases to the use of AI and component parts, there's plenty for Tam and Lucy to get through.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/our-2026-video-game-industry-predictions-spot-on/2300-6466636/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1862/18620770/4633228-spoton_2026trends_20260108v3.jpg",
    "created_at": "2026-01-10T00:56:31.306Z",
    "topic": "gaming"
  },
  {
    "slug": "the-five-weirdest-ai-inventions-i-saw-at-ces-2026",
    "title": "The Five Weirdest AI Inventions I Saw at CES 2026",
    "description": "AI gadgets had to get weird to stand out at CES 2026.",
    "fullText": "AI is still the big thing in the tech world, but it's no longer the big new thing. It's been around long enough that simply integrating it into your product isn't enough to make it stand out anymore, especially at the biggest tech show in the world. While I attended this year's CES, the trend I noticed over and over again on the show floor was that AI is getting weird now. From personal hologram sidekicks to a gaming monitor that basically cheats for you, here are the five weirdest AI inventions I saw at CES 2026.\n\nAt last year's CES, gaming lifestyle company Razer introduced Project AVA, an AI esports coach concept that was just a disembodied voice that lives in your laptop. Yawn. This year, the company's expanding on that by bringing AVA into the real world.\n\nIn Razer's suite this year, I held a conversation with \"Kira,\" an anime girl \"hologram\" that lives in a little USB tube you can plug into your laptop. She noticed my orange sweater thanks to a camera installed in the tube, before asking me about the show and prompting me to start up a round of Battlefield 6, where she gave me some generic loadout advice. I spoke with her using microphones also built into her tube, and she responded using her own speaker rather than the laptop's. Razer said this demo was more directed, hence why she brought up gaming right away, but that the end goal is to let the new AVA work as a convincing all-purpose AI companion, so you don't have to use it for only play.\n\nTo that end, the company says it's \"AI agnostic,\" so you can plug your own model into it. The demo I ran through was clearly using Grok, and generally felt a lot like talking to the AI companions built into that app, right down to the cringeworthy jokes. But Razer said you could theoretically use ChatGPT or Gemini instead.\n\nWhile we were chatting, Kira played animations courtesy of Animation Inc., which powers similar but more app-driven AI companions. In other words, the chatbot and the animations aren't really new here, so what you'd be buying would be the USB tube and the characters.\n\nKira isn't your only option for an AI companion hereâ€”she's a typical anime gamer girl, but I also got to briefly look at Zane, a tattooed muscle man in the deepest V-neck I've ever seen. You can kind of see the target audience for both of these characters right away, but if you want something more tame, you can also have your tube display Razer's logo surrounded by an audio waveform, which simply goes by AVA (even though the project as a whole is still called AVA). And the company's also working on celebrity likenesses, with esports star Faker and influencer Sao having already given their approval.\n\nRazer said it's still working on figuring out how it'll distribute these characters, and I was told you'd get a bundle of them with your purchase, but would probably be able to buy more down the line.\n\nAs for pricing and availability, no word on that. This is technically still a concept, so it might go back to the drawing board again. But Razer's website does say it's hoping for a release in the second half of 2026, and that you can put $20 down now to reserve your unit.\n\nIn short, if you strip away the functionality that's already baked into apps you can download now, the new Project Ava is basically a talking hologram toy for your desk. That's still not a bad pitch, but unfortunately, I'm not sure if hologram is the right word for this. Kira looked pretty flat to me, less like that one Princess Leia projection and more like she was displaying on a normal transparent screen that just happened to be stuck inside of a cylinder. I don't think the novelty quite matches the pitch yet.\n\nWhenever I play a competitive game, instead of hopping right into a match, I instead load up into a few practice sessions to warm up. It's helpful, but time consuming. The new Neurable x HyperX concept headset is hoping to change that by helping you lock in within just a few minutes.\n\nEssentially, it looks like a normal gaming headset, but built into the earcups are various sensors that can supposedly read your focus levels. These are similar to the brain-computer interfaces you might have seen in sci-fi shows, the ones with a bunch of wires and discs attached to them, but shrunken down for the consumer market, with no creepy wires in sight.\n\nThat's where the AI comes in. Shrinking down the sensors so much does mean this headset gets fewer readings than the bigger ones in labs, but Neurable claims its models are still able to pick up on trends in those readings and translate them into useful data, while also throwing out junk data.\n\nFor gamers, that means it can run you through a quick focus exercise called \"Prime,\" where you concentrate while noticing a cloud of dots shrink into a solid orb. Once this is done, which took about 90 seconds for me, you're supposedly focused up and ready to play.\n\nUnfortunately, I actually did worse in a practice shooting game after focusing than beforehand, but that doesn't mean the data was useless. I ran through the exercise with a colleague whose score improved by maybe about a third after focusing, and with such a small sample size, there could be any number of reasons I choked after focusing up. The company said that it could even be helpful to practice choking in this way.\n\nAnd at any rate, numbers are fun. That's why I'm most excited about the headset's plug-in for streamers, which allows them to show their focus levels on screen for their chat to see. I could easily imagine a community looking at that data and teasing their favorite streamer to try to distract them.\n\nThat said, it'll be a while until you can actually buy this. It's still a concept for now, with no pricing or promise of release. However, Neurable does already have a similar, non-gaming headset made with Master & Dynamic that will be shipping out soon, just without this software. For more, read my full article here.\n\nThis one is more of a hardware innovation, but it's a clever touch. This CES, Lenovo introduced a laptop with a motorized hinge that can automatically close, open, and even rotate from side-to-side. It'll be coming out later this summer, but while the company was demonstrating the unit to me, it also showed off a prototype chatbot app it's making for it. This uses ChatGPT for now, and is still just a concept and will not ship with the laptop. But it was cute.\n\nEssentially, while I talked with the app, the laptop displayed a big pair of animated eyes on screen, and used its hinge to nod or shake its head no when I asked it questions. It also displayed small animations in response to certain questions, like showing an umbrella when I asked about the rainy weather.\n\nIt's still very early days, but I was impressed that the hardware was able to recognize what an affirmative answer was and trigger the laptop to respond accordingly. A lot of AI feels pretty disconnected from the real world, so anything that can give it a physical presence is probably a good idea if you want people to take it seriously.\n\nAlso shown off at CES this year, Lenovo's AI Frame gaming monitor is probably the most practically useful item on this list, almost to the point where it feels like cheating. Essentially, this fills up most of the 21:9 screen with a regular 16:9 view of whatever's on your computer, and uses AI to show a zoomed-in look at critical game information on the rest.\n\nFor instance, in a demo showing a MOBA game (think League of Legends), the monitor zoomed in on the map. In a demo showing Counter-Strike 2, it zoomed in on the reticle. Personally, I didn't think getting a blown-up look at the map was all that helpful, but being able to constantly see what was essentially a sniper scope around my reticle was a game changer, since it worked with any gun and made targets much easier to see.\n\nI could see Counter-Strike 2 developer Valve go as far as banning this if it ever makes its way to market, since it's taken similar actions before. But this is still just an idea for now. Still, it shows that companies are starting to figure out concrete ways AI can help you in your games, beyond just feeding you advice you probably already know.\n\nFinally, probably my favorite AI invention at CES this year was XREAL's new REAL 3D technology. Built into its newest AR glasses and already added to an existing pair via a firmware update, this uses AI to automatically find depth in any 2D video source and convert it into 3D. And trying it out for myself, it practically looked official.\n\nWhen I used it to play Mario Kart World, I would have believed you if you told me Nintendo had added this mode itself. It also worked great with James Cameron's Avatar, and there was no loading time to set it up or turn it off. There also wasn't any fuzziness, like there might be with glasses-free 3D screens like the 3DS.\n\nIt's a great option for people who like watching 3D games and movies, but might have trouble finding them now that 3D TVs and the Nintendo 3DS are mostly in the past. Now, you can just watch your existing 2D library, but in 3D.\n\nThe only issue you might come across is in content that doesn't have depth. For instance, XREAL's Ralph Jodice told me the software didn't quite know what to do when he tried playing the original 8-bit Super Mario Bros. with it, and would randomly emphasize only certain game assets without any rhyme or reason. An illusion of depth does seem to work, though. Super Mario Bros. is entirely flat, but when I tried watching the pen-and-paper animated Snow White and the Seven Dwarfs with this technology, it correctly separated characters in the foreground from scenery in the background, even though everything on screen was entirely hand-drawn.",
    "readingTime": 9,
    "keywords": [
      "super mario",
      "mario bros",
      "usb tube",
      "year's ces",
      "gaming monitor",
      "project ava",
      "laptop",
      "game",
      "concept",
      "screen"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/weirdest-ai-inventions-ces-2026?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEJ6RQ8GPVMMK8PJR454FX10/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-10T00:56:31.242Z",
    "topic": "tech"
  },
  {
    "slug": "the-simplest-way-to-build-ai-agents-in-2026",
    "title": "The simplest way to build AI agents in 2026",
    "description": "How to build personal AI agents without frameworks, infrastructure, or unnecessary complexity",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://newsletter.owainlewis.com/p/the-simplest-way-to-build-ai-agents",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!u2j_!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F473cfb04-34db-4f6d-ac2e-557fabf7ec6e_1280x720.png",
    "created_at": "2026-01-09T18:19:09.706Z",
    "topic": "tech"
  },
  {
    "slug": "adopting-ai-at-sentry-internal-email",
    "title": "Adopting AI at Sentry â€“ \"Internal\" Email",
    "description": "If you think @Sentry isn't serious about AI, I'd recommend reading @zeeg's latest internal email about it",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/jshchnz/status/2009372836419248263",
    "thumbnail_url": "https://pbs.twimg.com/media/G-K5qKIa0AAoaW6.png:large",
    "created_at": "2026-01-09T18:19:08.359Z",
    "topic": "tech"
  },
  {
    "slug": "wef-mapped-out-4-aidriven-futures-for-jobs-by-2030-and-only-one-looks-good-for-humanity",
    "title": "WEF mapped out 4 AI-driven futures for jobs by 2030, and only one looks good for humanity",
    "description": "The World Economic Forum found that AI will reshape most jobs by 2030, with only one path limiting major displacement.",
    "fullText": "The World Economic Forum says the future of work isn't doomed by AI â€” but most paths forward still involve painful disruption.\n\nIn the \"Four Futures for Jobs in the New Economy: AI and Talent in 2030,\" white paper published on Wednesday, the organization laid out four scenarios based on two variables â€” how fast AI capabilities advance and how ready workers and institutions are to adapt.\n\nThe scenarios range from rapid AI breakthroughs to slower, more uneven progress.\n\nOnly one scenario â€” dubbed the \"Co-Pilot Economy\" â€” is explicitly designed to limit large-scale displacement.\n\nIn that future, AI adoption is widespread but measured, and workers have the skills to use the technology as a complement rather than a replacement.\n\nAs the report puts it, \"Gradual AI progress and availability of AI-ready skillsets shift the focus towards augmentation rather than mass automation.\"\n\nInstead of eliminating roles outright, AI reshapes tasks, with humans staying in the loop.\n\nEven this relatively optimistic scenario is far from static.\n\n\"Although displacement and job churn have risen, governments, businesses, and workers increasingly view AI as an opportunity rather than a threat,\" the WEF's report said.\n\nThe remaining three scenarios are more disruptive, but they differ in pace and severity.\n\nIn \"The Age of Displacement,\" AI advances faster than education and reskilling systems can respond, pushing companies to automate aggressively and leaving large parts of the workforce struggling to keep up.\n\nIn \"Stalled Progress,\" AI continues to improve, but productivity gains are patchy and concentrated among a small number of firms and regions, eroding job quality elsewhere and widening inequality.\n\nIn \"Supercharged Progress,\" explosive AI breakthroughs drive rapid economic growth and innovation â€” but still render many existing roles obsolete faster than new ones can emerge.\n\nHowever, some researchers caution that the future is unlikely to follow any single, clean path.\n\nJames Ransom, a research fellow at University College London, told Business Insider that AI progress and workforce readiness vary widely across industries, jobs, and regions, resulting in uneven rather than universal disruption.\n\nHe expects displacement to accelerate over the next few years â€” even as he said most workers are still likely to be on the payroll by 2030.\n\nThe Forum said that the future of work will not be defined by technology alone. Throughout the report, it said that policy choices, corporate strategy, and investment in skills will shape how painful â€” or manageable â€” the transition becomes.\n\nSaadia Zahidi, a managing director at the WEF, told Business Insider that the four scenarios \"are not predictions of where the world will be in 2030, but a framework to help leaders prepare for the evolving global economy.\"\n\nTech leaders and AI researchers remain split over how disruptive AI will ultimately be to the workforce.\n\nFigures like Geoffrey Hinton, often described as the \"godfather of AI,\" and Anthropic CEO Dario Amodei have warned that AI could replace large swaths of white-collar work within just a few years.\n\nOthers, including Box CEO Aaron Levie and Nvidia CEO Jensen Huang, have predicted that AI will deliver explosive productivity gains â€” even as it renders many existing roles obsolete.\n\nA more optimistic camp, including Microsoft AI CEO Mustafa Suleyman and Zoom CEO Eric Yuan, have said AI will ultimately augment workers.",
    "readingTime": 3,
    "keywords": [
      "productivity gains",
      "existing roles",
      "roles obsolete",
      "business insider",
      "workers",
      "scenarios",
      "displacement",
      "rather",
      "workforce",
      "painful"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wef-sees-4-ai-futures-for-jobs-by-2030-only-one-limits-disruption-2026-1",
    "thumbnail_url": "https://i.insider.com/695f9edf64858d02d217f894?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:53.014Z",
    "topic": "finance"
  },
  {
    "slug": "14-billion-ai-startup-mistral-europes-answer-to-openai-lands-french-military-deal-as-the-region-bets-on-homegrown-tech",
    "title": "$14 billion AI startup Mistral â€” Europe's answer to OpenAI â€” lands French military deal as the region bets on homegrown tech",
    "description": "France's defense ministry picked Mistral to supply military AI systems running on national infrastructure, demonstrating Europe's push for tech sovereignty.",
    "fullText": "French AI startup Mistral has secured a major vote of confidence from its home government after landing a deal to provide AI technology to France's military.\n\nFrance's Ministry of the Armed Forces said on Thursday that it has formally notified a framework agreement with Mistral AI, giving the country's armed forces, defense agencies, and affiliated public institutions access to the company's advanced AI models, software, and services.\n\nUnder the deal overseen by the ministry's defense AI agency, Mistral's AI systems will be deployed on French-controlled infrastructure, a key priority for the military as governments grow increasingly cautious about where sensitive data is processed and which laws govern it.\n\nIn a LinkedIn post announcing the deal, Mistral said its AI systems would be deployed on France's own infrastructure and fine-tuned using defense-specific data to support operational military needs.\n\nThe financial terms of the deal have not been disclosed. Mistral was not immediately available for comment when contacted by Business Insider.\n\nThe agreement marks a significant win for Mistral, which was founded in 2023 and is valued at roughly $13.6 billion, following a 1.7 billion euro ($2 billion) funding round announced last year.\n\nThe startup has positioned itself as a European alternative to US AI heavyweights, such as OpenAI, Google, and Anthropic, pitching its models as powerful yet more compatible with Europe's sovereignty and data control ambitions.\n\nIn its statement, translated by Business Insider, the defense ministry said the partnership is intended to strengthen France's \"technological sovereignty\" and ensure the armed forces maintain control over critical AI tools used across military operations and administration.\n\nBertrand Rondepierre, director of the ministry's defense AI agency, said the agreement represents \"a major step\" in strengthening the ministry's generative AI capabilities and preparing the armed forces for future challenges, while maintaining sovereign control over the technologies used.\n\nThe deal comes as European governments reassess their dependence on US technology in strategic sectors ranging from cloud computing to semiconductors and now AI.\n\nThe French ministry's move mirrors that of the US government, which has increasingly inked major contracts with domestic AI companies to develop tools for military and national security use, including recent deals with OpenAI, xAI, Anthropic, and other defense-focused startups.\n\nAs generative AI becomes increasingly embedded in military planning, logistics, and analysis, Mistral's latest win helps to position the startup as one of Europe's key players in the race to develop sovereign alternatives to American tech giants.\n\nDo you work for Mistral and have a tip or story to share? Contact this reporter via email at tspirlet@businessinsider.com or Signal at thibaultspirlet.40. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "ministry's defense",
      "military",
      "deal",
      "startup",
      "agreement",
      "increasingly",
      "technology",
      "models",
      "agency",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-startup-mistral-lands-french-military-deal-openai-of-europe-2026-1",
    "thumbnail_url": "https://i.insider.com/6960d842832e0ef1ead7765f?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.869Z",
    "topic": "finance"
  },
  {
    "slug": "ai-zealotry",
    "title": "AI Zealotry",
    "description": "Senior engineers are best positioned to benefit from AI. We're good enough to avoid slop, and there's so much we can accomplish. I wouldn't go back.",
    "fullText": "I develop with AI today. It's great.\n\nThere are many articles you can read on why AI is great (or terrible) or how to\nuse it. This is mine. I focus on the experience of a senior engineer (and why\nwe in particular should use AI), on my experience operating within the OSS\nPython Data world, and on practical suggestions that I've found myself\nrepeating to colleagues.\n\nThis article contains learned lessons of two types:\n\nWe'll interleave these two. I'm hopeful that this approach will make this more fun.\n\nAI development is more fun. I do more of what I like (think, experiment,\nwrite) and less of what I don't like (wrestle with computers).\n\nI feel both that I can move faster and operate in areas that were previously\ninaccessible to me (like frontend).\nExperienced developers should all be doing this. We're good enough to avoid AI\nSlop, and there's so much we can accomplish today.\n\nI like this quote from this blog\n\nI get it, youâ€™re too good to vibe code. Youâ€™re a senior developer who has been doing this for 20 years and knows the system like the back of your hand.\n\nNo, youâ€™re not too good to vibe code. In fact, youâ€™re the only person who should be vibe coding.\n\nI think that really good engineers, the kind that think hard before writing,\ncan have a tremendous impact and fun while developing with AI. I\nwouldn't ever go back.\n\nThat being said, there are some serious costs and reasonable reservations to AI\ndevelopment. Let's start by listing those concerns:\n\nThese are super-valid concerns. They're also concerns that I suspect came\naround when we developed compilers and people stopped writing assembly by hand,\ninstead trusting programs like gcc to pump out instruction after instruction\nof shitty machine code.\n\nWe lost a deeper understanding as developers when we stopped writing assembly\nbut we gained a ton too. As in any transition, we need to navigate the\nsituation to capture the advantages while losing only a little, balancing the\ncosts and benefits of a new technology.\n\nThis article is how I've been navigating this transition personally.\n\nEarly in using Claude Code (or Cursor) many of my interactions were saying\n\"Yes, it's ok to run that\". This was frustrating and dehumanizing. Mostly my\njob was to enable AI, rather than the other way around.\n\nThere are many tricks to resolve this (see below), but more broadly \"stop doing\nsimple shit\" has been a mantra that I've found myself constantly coming\nback to. The more I identify and reject simple tasks and add automation to my\nworkflow, the higher an abstraction I'm able to climb to and the more\neffectively I'm able to work. Our goal in programming is to climb an\nabstraction ladder and gain more intellectual leverage. This requires thought\nand consistent attention.\n\nFortunately AI can help with this. If you complain and say \"I'm always doing\nX\" it'll suggest solutions like what I'll talk about below, but more tailored\nto your situation.\n\nAI developers, like human developers, benefit from structure.\n\nMost people start with an AGENTS.md or CLAUDE.md file. This is a great\nstart, but I find that the AI agent often forgets what's in there. The real\nsolution for me here (at least for Claude Code) is\nHooks.\n\nFirst, let's outline a couple of annoyingly common problems.\n\nLet's say you tell AI that you want to run tests with uv:\n\nwhen running tests, use uv run pytest tests\n\nWhile this works sometimes, AI often decides to run\n\nWhile the agents read CLAUDE.md, they don't always follow the instructions.\nAnd so you're stuck saying \"no, use uv\" over and over again. Gah.\n\nHere's a hook that catches pytest commands missing uv run. You could put\nsomething like this in ~/.claude/settings.json:\n\nThere, we've just automated that annoying task for you forever.\n\nI don't actually do this though (I allow Claude to fail and then it finds the\nright approach.) Mostly this works because I've gotten good at giving Claude\nfairly broad-yet-safe permissions, which is coming up next.\n\nEven worse, Claude often asks for permission to do things that are just\nslightly different from what you've already granted.\nYou allow uv run pytest *, but Claude keeps finding variants:\n\nClaude Code's permission language sucks. It only supports prefixes, while I\nwish it could handle regexes, or maybe even just arbitrary Python code.\n\nI have a complex Python script as a hook which overrides the permission\nsystem. It uses regexes, but also arbitrary Python code as logic. This allows\nme to encode arbitrary combinations of rules. It's great.\n\nOn the rare occasion when Claude asks me for permission for something new, I\nhave a running Claude agent that thinks about this file and considers if it\nshould update the permission script.\n\nMy personal favorite hooks though are these:\n\nThey play subtle little sounds whenever Claude is either done, or needs input\nfrom me. This lets me ignore Claude when it's busy. Previously I found that I\nwas constantly checking back in with Claude to see if it was done, and that\naction was dehumanizing, so I automated it by asking Claude to play a sound.\n\nHooks are great. There are more ways to provide structure (Skills, Commands)\nbut I've found that Hooks are the most dependable, a great starting place, and\noften augment any other structure that I put in place (like Skills).\n\nIn a recent large AI-assisted PR a frustrated reviewer said the following:\n\nTo me, this [size of PR] implies that either\n\nIt's a valid problem, even in single-person projects. We're able to generate\ncode far more quickly than we're able to read it. How should we handle\nreview? Everyone needs to figure this out for themselves, but my answer is\n\"find other ways to build confidence\".\n\nWe already do this today with human-written code. I review some code very\nclosely, and other code less-so. Sometimes I rely on a combination of tests,\nfamiliarity of a well-known author, and a quick glance at the code to before\nsaying \"sure, seems fine\" and pressing the green button. I might also ask\n\"Have you thought of X\" and see what they say.\n\nTrusting code without reading all of it isn't new, we're just now in a state\nwhere we need to review 10x more code, and so we need to get much better at\nestablishing confidence that something works without paying human attention all\nthe time.\n\nWe can augment our ability to write code with AI. We can augment our ability\nto review code with AI too.\n\nMostly I establish confidence on AI-generated work by investing heavily in\ntests and benchmarks, the same as I would with humans, just moreso. TDD is\nbaked into most of the prompting structure I have with agents.\n\nRemember that this is way cheaper than it used to be. Now rather than write a\nbenchmark I can type\n\nHow does this compare in performance to the old version? I'm particularly\ninterested in memory use.\n\nAnd that's it. If it's bad, the agent will say so (and then diligently work to\nmake it good).\n\nAdditionally, if I'm nervous about something subtle like \"Is it possible this change\nmight unexpectedly affect performance in this other feature?\" then I'll ask the\nAI exactly that question:\n\nIs it possible this change might unexpectedly affect performance in this other feature?\n\nAnd it'll just go and investigate exactly that question. Unlike human authors,\nthe AI has no ego at stake in its work, and isn't in the least bit lazy. It's\nour job to ask \"Have you thought of X\" and its job to go learn if that might\nbe an issue. Don't trust its answer? Ask it to prove it to you.\n\nAI has flaws, but it is diligent, and it lacks ego. If you question it, it'll\ninvestigate thoroughly and critique its own work honestly.\n\nLet's review our work and see if there is anything we can simplify or clean up\n\nBefore Opus 4.5 came out this was essential. Now it's merely nice. I've\nturned this into a /cleanup command and integrated it into most of my Skills\nas a final phase in development.\n\nFrom time to time I also ask a fresh agent to do a full review of the project,\nwith an eye to cleaning up technical debt. I tell it to review everything and\nthink hard. It takes a while, but it often comes back with a nice list of work\nfor itself, which it then of course diligently performs.\n\nAI creates technical debt, but it can clean some of it up too.\n(at least at a certain granularity)\n\nIn general we want to give our agents good automated feedback. Tests do this,\nbenchmarks do this, prompting them to assess themselves does this, asking them\nto explain things to us and have us weigh in on high level topics does this.\n\nLLMs are smart enough today that if they're given enough of the right feedback\nthey converge to a good solution as-well-or-better-than a senior human engineer\n(that's my experience at least).\n\nOur job is to construct a system that gives them the right feedback at the\nright time, hopefully without our intervention. This is the same job we have\nwhen we build human teams; now it's just more impactful to do well.\n\nI started AI development with Cursor. It was great having the AI experience\ninside a VSCode-like editor, where I could see everything that was going on.\nWhen I saw terminal-based tools like Claude Code I thought \"whoa, that doesn't\nseem sensible, I need to see what's going on\".\n\nToday I code with Claude Code, git diff, and occasionally vim. I don't\nfeel a need to OK every change in the diff. I've got more important\nthings to do. I suspect that you do too.\n\nI deeply respect the philosophical position of Python, which I'll state as\nfollows:\n\nPrioritize human performance over compute performance.\n\nspace more broadly and more quickly, finding much better solutions, making\nthat 100x drop in performance negligible.\n\nPython was a bold bet, and a bet that paid off amazingly well. No one expected\nthis silly dynamic language originally designed for education to become the\nworld's juggernaut in performance software.\n\nWith AI though, the usability benefits of Python no longer apply as strongly,\nand we're more free to choose different ecosystems.\n\nRegarding TypeScript, I still love easy interaction tools like rich and\ntextual, but when the entire React ecosystem is a sentence away and when you\nget to use things like, you know, fonts, there's really no comparison. Every\ncomputational developer should learn the concepts underpinning React (or some\nother frontend framework), and we should put dashboards on everything.\n\nOf course, I still hook into Python for the ecosystem. Everything is\nPython-importable and I still use the protocols and design patterns developed\n\ncode or the language; those will die. Rest in peace dear friend.\n\nAs an introductory project, I rewrote Numpy in Rust.\nIt was great fun.\n\nIt was also much easier than I expected (I expected it to be impossible).\nIt was easy for a few reasons (good test suite, well-reasoned abstractions) but\nmostly it was because:\n\nNEPs: Numpy's Enhancement Proposals / design documentation is thorough and extremely clear.\n\nWhen sticky problems arose, we were able to rely on the Numpy design documents\n(NEPs) which are excellent.\n\nThe Numpy team thought hard and wrote clearly, two hallmarks of\nexcellent developers. This made the job of reimplementation relatively trivial.\nThe Numpy development community is famous for doing this well. To a certain\nextent, we should all start operating more like the Numpy community.\n\nI keep two directories in each repository:\n\nPlans end up being very useful during development, while docs end\nup being useful to point other agents to in the future. Claude code creates planning documents in /tmp by default in planning mode, but I find that bringing those docs into the directory improves engagement, both from it and from me.\n\nDocs end up being tricky. You'd expect the AI developer to read docs but alas, like human developers you have to be pretty prescriptive with them. Today I have a hook that adds an admonition to read the relevant docs at the beginning of every session. It looks like this:\n\nI then keep docs/README.md updated as a sort of index over my documents. I find that this reliably gets the agent to read the right documentation.\n\nI've also found that my normal writing style (brutal concision + front-loading important content to maintain attention span) isn't necessary with AI. You really can just shove information at them and they absorb it. It's nice ğŸ™‚\n\nHistorically software engineers had to both think well and execute well.\nWe were valued both because we could zoom out and consider the impacts of our\narchitecture, and because we could zoom in and implement those choices with\nskill.\n\nOur ability to zoom in and implement code is now obsolete. Our ability to zoom\nout and think well is not. On the contrary, our ability to think well is now\n10x more valuable than it was before, because implementation is now mostly\nfree.\n\nAnd so it's now more important than ever to hone our craft of thought. This\nprobably means less caffeine and more walks through the park.\n\nThe craft of authoring code has transformed time and time again during our\nlives. We remember when object-oriented was cool, or when TDD became a thing,\nor reactive programming models, or dynamic typing languages, or ML, or ...\n\nAs programmers we've opted into a system which changes by its very nature.\nOur job is to automate our job, and to continuously climb the ladder of\nabstraction. AI programming is another step in that evolution, similar to when\ncompilers came about. The code we write with AI probably won't be as good as\nhand-crafted code, but we'll write 10x more of it, and we'll build systems of\nsystems to make it robust and trustworthy, and all of that will make society\nbetter and our jobs way more fun.\n\nI'm looking forward to having way more fun.\n\nAfter writing this a couple friends asked me for a copy of my regex/Python code\nthat replaces Claude's permission system. I'll include it below, but really,\nyou don't need it. Instead, you need to start a conversation with Claude about\nwhat you want and it'll make one just for you.\n\nCode is free these days. Extending the \"AI is like Compilers\" analogy, asking\nfor someone else's script is kind of like asking for someone else's compiled\nbinary. There's no need; just make it yourself. It's trivial.\n\nHere was my original prompt to Claude Code:\n\nI recently wrote this reddit post\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1puqrvc/claude_code_annoyingly_asking_for_permissions/\n\nI'm wondering if you have any suggestions on how to resolve this? Adding stuff to CLAUDE.md or permissions to settings.json doesn't seem to be working well enough.\n\nThat, along with subsequent conversation as I've been working, resulted in\nthis Python script\n\nBut really, you're better off working with Claude to make one just for you.\nCode is free now.",
    "readingTime": 13,
    "keywords": [
      "arbitrary python",
      "python script",
      "unexpectedly affect",
      "technical debt",
      "someone else's",
      "affect performance",
      "claude code",
      "permission system",
      "human developers",
      "vibe code"
    ],
    "qualityScore": 1,
    "link": "https://matthewrocklin.com/ai-zealotry/",
    "thumbnail_url": "https://matthewrocklin.com/assets/images/social/ai-zealotry.png",
    "created_at": "2026-01-09T18:18:52.796Z",
    "topic": "tech"
  },
  {
    "slug": "x-makes-groks-ai-image-tool-a-premium-service-after-backlash-against-sexualized-deepfakes",
    "title": "X makes Grok's AI image tool a premium service after backlash against sexualized deepfakes",
    "description": "Only paying X subscribers can now use Grok to edit images on the social media site after it came under significant backlash over sexualized imagery.",
    "fullText": "Elon Musk's Grok has limited its AI image generation tool to paying subscribers following widespread backlash about its use to create nonconsensual sexualized images on X of real people, including minors.\n\nMusk and xAI, the company that developed Grok, have faced threats and condemnation from governments around the world after the AI tool was used to digitally alter images of people â€” mainly women â€” to remove their clothes and put them in sexualized positions.\n\n\"Image generation and editing are currently limited to paying subscribers,\" Grok now replies when tagged with image editing requests on X.\n\nIt means that the majority of users on the social media platform can no longer create images using Grok, and those who do would have their name and payment information on file.\n\nHowever, those who are not paying X subscribers can continue to use Grok to edit images on its stand-alone app and website.\n\nOn Friday, a spokesperson for Britain's Prime Minister, Keir Starmer, told reporters that the move \"simply turns an AI feature that allows the creation of unlawful images into a premium service.\"\n\nWhen asked for comment, xAI sent an automatic email response that did not address the issue.\n\nIn late December, some X users started tagging Grok on the social media site and asking it to digitally undress people in photos. The AI tool honored those requests, putting the subjects in bikinis or underwear, and maneuvering their bodies into sexualized positions. Some of the people in the images were minors.\n\nAs more of the AI-generated images flooded the social media site, governments and regulators in the UK, EU, Italy, India, and elsewhere publicly threatened or took action against X and xAI.\n\nStarmer called Grok's sexualized deepfakes \"disgraceful\" and \"unlawful\" in an interview with Greatest Hits Radio this week.\n\nOn January 3, Musk responded to the backlash for the first time, writing in an X post that, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"\n\nThe official X page also pointed users to its policy page, which states it has \"zero tolerance for any forms of child sexual exploitation\" and that it removes \"certain media depicting physical child abuse.\"\n\nOn Monday, the UK's communications regulator, Ofcom, told Business Insider that it has \"made urgent contact with X and xAI to understand what steps they have taken to comply with their legal duties to protect users in the UK.\"\n\nIn the US, the Take It Down Act protects against nonconsensual deepfakes, though its domain depends on age and body parts shown. Some states have also passed stricter laws about the spread of deepfakes.",
    "readingTime": 3,
    "keywords": [
      "illegal content",
      "sexualized positions",
      "social media",
      "media site",
      "images",
      "users",
      "tool",
      "subscribers",
      "deepfakes",
      "grok"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/xai-limits-grok-ai-image-tool-sexualized-deepfake-backlash-2026-1",
    "thumbnail_url": "https://i.insider.com/6960f2e204eda4732f2ec3ec?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.738Z",
    "topic": "finance"
  },
  {
    "slug": "metas-latest-deal-to-power-its-ai-ambitions-is-sending-nuclear-stocks-soaring",
    "title": "Meta's latest deal to power its AI ambitions is sending nuclear stocks soaring",
    "description": "Meta Platforms announced a deal with Oklo, Vista, and TerraPower to power its AI buildout. Nuclear energy stocks surged on the news.",
    "fullText": "Meta Platforms is turning to nuclear power to drive its AI ambitions, and its latest deal with a trio of companies is sending stocks in the sector soaring.\n\nThe tech giant revealed that it signed an agreement with several companies to help supply nuclear power for its data centers, including the massive Prometheus AI supercluster being built in New Albany, Ohio. The one gigawatt facility is expected to come online later this year.\n\nThe three companies that will help power it areÂ Oklo,Â Vistra Corp,Â and privately held TerraPower. Both nuclear power stocks surged on news of the Meta deal, sparking momentum for many of their peers as well.\n\nHere are the big moves in the space on Friday:\n\nThis isn't the first nuclear power deal that Meta has inked. Last summer, it announced a similar agreement with Constellation Energy, which saw its shares spike on the news.\n\n\"State-of-the-art data centers and AI infrastructure are essential to securing America's position as a global leader in AI,\" said Joel Kaplan, chief of global affairs at Meta. \"Nuclear energy will help power our AI future, strengthen our country's energy infrastructure, and provide clean, reliable electricity for everyone.\"\n\nBig tech's support of nuclear energy has risen in recent years as experts have touted the need for alternative sources of power to enable the AI buildout. Oklo is backed by OpenAI CEO Sam Altman, though he stepped down from his position as chairman of its board of directors in August 2025.\n\n\"Two years ago, Oklo shared its vision to build a new generation of advanced nuclear powerhouses in Ohio,\" Oklo CEO Jacob DeWitte said. \"Today, that vision is becoming a reality through the support of a multi-year effort with Meta.\"",
    "readingTime": 2,
    "keywords": [
      "nuclear energy",
      "deal",
      "stocks",
      "agreement",
      "centers",
      "infrastructure",
      "position",
      "vision",
      "meta",
      "oklo"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/oklo-stock-price-meta-ai-nuclear-power-deal-vst-ceg-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.436Z",
    "topic": "finance"
  },
  {
    "slug": "one-eyepopping-prediction-shows-why-copper-prices-could-continue-to-surge-for-years-to-come",
    "title": "One eye-popping prediction shows why copper prices could continue to surge for years to come",
    "description": "An analysis from S&P Global predicts that the AI boom will drive demand higher for years at a time when supply is expected to remain constrained.",
    "fullText": "Copper joined the mega rally in precious and industrial metals in 2025, but the gains might be far from over if recent forecasts for supply and demand prove correct.\n\nCopper ended 2025 with a gain of about 44%, and touched a fresh all-time high this week. Yet, the AI boom might be the key to another 15 years of surging demand at a time when supply is expected to remain constrained.\n\nS&P Global recently published an analysis of the copper market, predicting that demand is likely to increase by 50% by 2040, reaching 42 million metric tons. The report also said that it will be extremely difficult for the mining industry to keep up as companies struggle with aging mines and regulatory hurdles.\n\nThe authors predict that, without new mines or technological advancements, copper production will peak in 2030, leaving the world short of roughly 10 million metric tons by 2040.\n\n\"Several countries have deemed copper a 'critical metal' over the past half decade, including, in 2025, the United States. And with good reason,\" said Carlos Pascual, Senior Vice President, Geopolitics and International Affairs, at S&P Global Energy. \"Copper is the connective artery linking physical machinery, digital intelligence, mobility, infrastructure, communication and security systems.\"\n\nCopper benefited from a broad rush into metals last year that also pushed gold and silver to record highs. Some forecasters have said they think prices for all three metals are likely to decline in the near future as market conditions shift, but copper's industrial importance could continue to buoy it.\n\nJosÃ© Torres, chief economist at Interactive Brokers, said he thinks copper's global strategic importance means prices will remain elevated.\n\n\"Broadly, it has to do with limited supply as nations want to stockpile the cyclical metal to bolster sovereign AI prospects,\" he told Business Insider. \"Governments are afraid that without enough copper, their economies won't remain competitive in a world where advanced technology is increasingly adopted.\"\n\nRita Adiani, president and CEO of rare earth mining company Titan Mining Corporation, believes that a surge in demand, as predicted by S&P, would lead to a period of higher prices.\n\n\"A significant part of the incremental demand is tied to electrification, grid build, data centers/AI and defense, where copper's conductivity and reliability makes substitution harder in critical applications.\"",
    "readingTime": 2,
    "keywords": [
      "metric tons",
      "demand",
      "metals",
      "supply",
      "copper's",
      "copper",
      "industrial",
      "market",
      "mines",
      "without"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/copper-price-record-high-demand-supply-prediction-ai-data-centers-2026-1",
    "thumbnail_url": "https://i.insider.com/69612aae64858d02d2180faa?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.006Z",
    "topic": "finance"
  },
  {
    "slug": "no-10-condemns-insulting-move-by-x-to-restrict-grok-ai-image-tool",
    "title": "No 10 condemns â€˜insultingâ€™ move by X to restrict Grok AI image tool",
    "description": "Spokesperson says limiting access to paying subscribers just makes ability to generate unlawful images a premium...",
    "fullText": "Spokesperson says limiting access to paying subscribers just makes ability to generate unlawful images a premium service\n\nDowning Street has condemned the move by X to restrict its AI image creation tool to paying subscribers as insulting, saying it simply made the ability to generate explicit and unlawful images a premium service.\n\nThere has been widespread anger after the image tool for Grok, the AI element of X, was used to manipulate thousands of images of women and sometimes children to remove their clothing or put them in sexual positions.\n\nGrok announced in a post on X, which is owned by Elon Musk, that the ability to generate and edit images would be â€œlimited to paying subscribersâ€. Those who pay have to provide personal details, meaning they could be identified if the function was misused.\n\nAsked about the change, a Downing Street spokesperson said it was unacceptable. â€œThe move simply turns an AI feature that allows the creation of unlawful images into a premium service,â€ they said.\n\nâ€œItâ€™s not a solution. In fact, itâ€™s insulting to victims of misogyny and sexual violence. What it does prove is that X can move swiftly when it wants to do so. You heard the prime minister yesterday. He was abundantly clear that X needs to act, and needs to act now. It is time for X to grip this issue.\n\nâ€œIf another media company had billboards in town centres showing unlawful images, it would act immediately to take them down or face public backlash.â€\n\nAsked if No 10 was going to take any further action, such as leaving X, the spokesperson said â€œall options are on the tableâ€, and that it would support any action taken by Ofcom, the UKâ€™s media regulator.\n\nSpeaking earlier on Friday, Anna Turley, the Labour party chair and a minister without portfolio in the Cabinet Office, said there was no move as yet for the government to leave X, but individual ministers were considering doing so.\n\nShe told BBC Radio 4â€™s Today programme: â€œItâ€™s really, really important that we tackle this. Those conversations are ongoing across government. I think all of us in politics are evaluating our use of social media and how we do that, and I know that conversation is happening.â€\n\nAsked if she would leave the site, Turley said: â€œIâ€™ve thought about that a lot over the past few months.â€ Asked whether the Labour party would do so, she said: â€œThose conversations are taking place because itâ€™s really important that we make sure that weâ€™re in a safe space.â€\n\nThe victimâ€™s commissioner, Claire Waxman, said X was no longer a â€œsafe spaceâ€ for victims and her office was considering scaling back its presence on the site and focusing its communications on Instagram.\n\nâ€œIt makes the battle against violence against women and girls much harder when platforms such as X are enabling abuse on such an easy and regular basis,â€ Waxman said, adding that the platform was having a negative impact on its usersâ€™ mental health because of the proliferation of violence, abuse and race hate.\n\nâ€œWhy is that material not being taken down and those users being stopped?â€ she asked. â€œIt is not safeguarding its users.â€ Waxman said she was concerned about Ofcomâ€™s ability to police platforms such as X effectively. â€œDoes Ofcom have the teeth to be able to really deal with these sorts of issues? That is a concern for me.â€\n\nThere has been an exodus of womenâ€™s sector organisations from X. The domestic abuse charity Refuge left the site, as has Womenâ€™s Aid Ireland and Victim Support. Victim Support left in April, saying it was â€œno longer the right place for us to communicate with our audiencesâ€. Womenâ€™s Aid Ireland said the decision was taken because of â€œincreased levels of unchecked hate, misogyny, racism and anti-LGBTI+ content on the platformâ€.\n\nEmma Pickering, the head of technology at Refuge, said the decision by X to restrict access to the image tool for Grok to paying subscribers amounted to â€œthe monetisation of abuseâ€.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select â€˜Secure Messagingâ€™.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tipsÂ lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 5,
    "keywords": [
      "labour party",
      "aid ireland",
      "womenâ€™s aid",
      "guardian app",
      "safe space",
      "premium service",
      "unlawful images",
      "downing street",
      "subscribers",
      "ability"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/09/no-10-condemns-move-by-x-to-restrict-grok-ai-image-creation-tool-as-insulting",
    "thumbnail_url": "https://i.guim.co.uk/img/media/9eed52bcccc9b2621ffb52657bdd17f06c35aa8b/82_0_3083_2467/master/3083.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=bf841a1968aa93e771b8caf333a557c3",
    "created_at": "2026-01-09T18:18:51.449Z",
    "topic": "tech"
  },
  {
    "slug": "research-conventional-cybersecurity-wont-protect-your-ai",
    "title": "Research: Conventional Cybersecurity Wonâ€™t Protect Your AI",
    "description": "As AI embeds itself into every corner of business, most executives continue to underestimate the distinct security risks these systems pose. Legacy defenses, designed for rule-based software, cannot safeguard gen AI systems that learn and adapt from data. By combining survey data, executive interviews, and lab analysis, new research reveals systemic gaps: fragile supply chains, opaque vendor services, and an acute shortage of AI-security talent. The implications are clear. Leaders must move beyond patching applications and instead harden the infrastructure and supply chains on which AI depends, while harnessing AI itself as a front-line defense to ensure resilience.",
    "fullText": "Research: Conventional Cybersecurity Wonâ€™t Protect Your AI by Hugo HuangJanuary 9, 2026PostPostShareSavePrintSummary.Â Â Â Leer en espaÃ±olLer em portuguÃªsPostPostShareSavePrintIn June 2025, researchers uncovered a vulnerability that exposed sensitive Microsoft 365 Copilot data without any user interaction. Unlike conventional breaches that hinge on phishing or user error, this exploit, now known as EchoLeak, bypassed human behavior entirely, silently extracting confidential information by manipulating how Copilot interacts with user data. The incident highlights a sobering reality: Todayâ€™s security models, which are designed for predictable software systems and application-layer defenses, are ill-equipped to handle the dynamic, interconnected nature of AI infrastructure.",
    "readingTime": 1,
    "keywords": [
      "user",
      "conventional",
      "copilot"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/ts-research-conventional-cybersecurity-wont-protect-your-ai",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_09_139555442.jpg",
    "created_at": "2026-01-09T18:18:51.011Z",
    "topic": "science"
  },
  {
    "slug": "these-popular-chrome-extensions-are-stealing-your-ai-chats",
    "title": "These Popular Chrome Extensions Are Stealing Your AI Chats",
    "description": "Hackers continue to find ways to sneak malicious extensions into the Chrome web store.",
    "fullText": "Hackers continue to find ways to sneak malicious extensions into the Chrome web storeâ€”this time, the two offenders are impersonating an add-on that allows users to have conversations with ChatGPT and DeepSeek while on other websites and exfiltrating the data to threat actors' servers.\n\nOn the surface, the two extensions identified by Ox Security researchers look pretty benign. The first, named \"Chat GPT for Chrome with GPT-5, Claude Sonnet & DeepSeek AI,\" has a Featured badge and 2.7K ratings with over 600,000 users. \"AI Sidebar with Deepseek, ChatGPT, Claude and more\" appears verified and has 2.2K ratings with 300,000 users.\n\nHowever, these add-ons are actually sending AI chatbot conversations and browsing data directly to threat actors' servers. This means that hackers have access to plenty of sensitive information that users share with ChatGPT and DeepSeek as well as URLs from Chrome tabs, search queries, session tokens, user IDs, and authentication data. Any of this can be used to conduct identity theft, phishing campaigns, and even corporate espionage.\n\nResearchers found that the extensions impersonate legitimate Chrome add-ons developed by AITOPIA that add a sidebar to any website with the ability to chat with popular LLMs. The malicious capabilities stem from a request for consent for â€œanonymous, non-identifiable analytics data.\" Threat actors are using Lovable, a web development platform, to host privacy policies and infrastructure, obscuring their processes.\n\nResearchers also found that if you uninstalled one of the extensions, the other would open in a new tab in an attempt to trick users into installing that one instead.\n\nIf you've added AI-related extensions to Chrome, go to chrome://extensions/ and look for the malicious impersonators. Hit Remove if you find them. As of this writing, the extensions identified by Ox no longer appear in the Chrome Web Store.\n\nAs I've written about before, malicious extensions occasionally evade detection and gain approval from browser libraries by posing as legitimate add-ons, even earning \"Featured\" and \"Verified\" tags. Some threat actors playing the long game will convert extensions to malware several years after launch. This means you can't blindly trust ratings and reviews, even if they've been accrued over time.\n\nTo minimize risk, you should always vet browser extensions carefully (even those that appear legit) for obvious red flags, like misspellings in the description and a large number of positive reviews accumulated in a short time. Head to Google or Reddit to see if anyone has identified the add-on as malicious or found any issues with the developer or source. Make sure you're downloading the right extensionâ€”threat actors often try to confuse users with names that appear similar to popular add-ons.\n\nFinally, you should regularly audit your extensions and remove those that aren't essential. Go to chrome://extensions/ to see everything you have installed.",
    "readingTime": 3,
    "keywords": [
      "chrome web",
      "threat actors",
      "actors servers",
      "extensions identified",
      "malicious extensions",
      "chatgpt and deepseek",
      "users",
      "add-ons",
      "ratings",
      "hackers"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/chrome-extension-stealing-ai-chats?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEF38R9Z7WSA2ND991PT9G9G/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-09T18:18:50.054Z",
    "topic": "tech"
  },
  {
    "slug": "larian-studios-draws-harder-line-on-ai-clarifies-stance-in-reddit-ama",
    "title": "Larian Studios Draws Harder Line On AI, Clarifies Stance In Reddit AMA",
    "description": "Larian Studios CEO Swen Vincke, as well as creative directors, recently participated in an AMA on Reddit to set expectations for the studioâ€™s upcoming Divinity game, particularly about its stance on generative AI--a hot-button topic in the industry right now. Responding to a fan question about the role of generative AI in game development, Vincke was rather blunt: \"There is not going to be any GenAI art in Divinity.\"\nHis comments arrive amid wider debate over how and whether AI should be used in creative processes, especially as some high-profile games have faced backlash for such use. One notable example is Clair Obscur: Expedition 33, the acclaimed RPG that had two Indie Game Awards (including Game of the Year and Debut Game) rescinded when it was revealed the title had included AI-generated assets during development, violating strict no-AI rules--even though those assets were patched out later.\nIn the AMA, Vincke acknowledged that previous discussions about experimenting with AI tools for concept-art had been confusing.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/larian-studios-draws-harder-line-on-ai-clarifies-stance-in-reddit-ama/1100-6537296/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1597/15976769/4633018-q9vfkyv8bi8rbajqea7zwm.jpg",
    "created_at": "2026-01-09T18:18:48.682Z",
    "topic": "gaming"
  },
  {
    "slug": "manor-lords-publisher-has-banned-ai-assets-in-its-games-calls-them-cancerous",
    "title": "Manor Lords Publisher Has Banned AI Assets In Its Games, Calls Them \"Cancerous\"",
    "description": "The publisher behind strategy games Endless Legend 2, Terra Invicta, and Against the Storm has officially banned the use of AI-generated assets in all its products. Hooded Horse has had a significant presence in the strategy game space over the last few years, thanks to hits like Manor Lords. Now, when many publishers and developers are evaluating (or touting) their relationship to generative AI, Hooded Horse is rebuking its use for art generation.\nHooded Horse CEO Tim Bender discussed the ban in an interview with Kotaku, emphasizing that restrictions on AI art are part of every contract Hooded Horse signs. He said, \"It is now written into our contracts if weâ€™re publishing the game, 'no f**king AI assets.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/manor-lords-publisher-has-banned-ai-assets-in-its-games-called-them-cancerous/1100-6537300/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1690/16904437/4633066-manorlords.jpg",
    "created_at": "2026-01-09T18:18:48.546Z",
    "topic": "gaming"
  },
  {
    "slug": "tonguefu-a-gamified-voicefirst-app-for-practicing-verbal-communication",
    "title": "TongueFu â€“ A gamified voice-first app for practicing verbal communication",
    "description": "AI-powered conversational training. Master quick thinking, creative debates, and verbal sparring through gamified exercises with AI sensei characters.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://tonguefu.app",
    "thumbnail_url": "https://tongfu.qligence.capital/og-image.png",
    "created_at": "2026-01-09T12:24:07.454Z",
    "topic": "tech"
  },
  {
    "slug": "shallowcircuit-supervised-learning-on-a-quantum-processor",
    "title": "Shallow-Circuit Supervised Learning on a Quantum Processor",
    "description": "Quantum computing has long promised transformative advances in data analysis, yet practical quantum machine learning has remained elusive due to fundamental obstacles such as a steep quantum cost for the loading of classical data and poor trainability of many quantum machine learning algorithms designed for near-term quantum hardware. In this work, we show that one can overcome these obstacles by using a linear Hamiltonian-based machine learning method which provides a compact quantum representation of classical data via ground state problems for k-local Hamiltonians. We use the recent sample-based Krylov quantum diagonalization method to compute low-energy states of the data Hamiltonians, whose parameters are trained to express classical datasets through local gradients. We demonstrate the efficacy and scalability of the methods by performing experiments on benchmark datasets using up to 50 qubits of an IBM Heron quantum processor.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.03235",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-09T12:24:07.331Z",
    "topic": "tech"
  },
  {
    "slug": "simplemem-efficient-lifelong-memory-for-llm-agents",
    "title": "SimpleMem: Efficient Lifelong Memory for LLM Agents",
    "description": "SimpleMem: Efficient Lifelong Memory for LLM Agents - aiming-lab/SimpleMem",
    "fullText": "aiming-lab\n\n /\n\n SimpleMem\n\n Public\n\n SimpleMem: Efficient Lifelong Memory for LLM Agents\n\n 333\n stars\n\n 45\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aiming-lab/SimpleMem",
    "readingTime": 1,
    "keywords": [
      "simplemem"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/aiming-lab/SimpleMem",
    "thumbnail_url": "https://opengraph.githubassets.com/5428f2ae9bdbb778e26fb50b1ea1fe861817d86d914267ce45ac5008a3fcc90d/aiming-lab/SimpleMem",
    "created_at": "2026-01-09T12:24:05.796Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-is-both-the-problem-and-the-cure-for-legacy-code",
    "title": "Why AI is both the problem and the cure for legacy code",
    "description": "AI may be the key to cracking legacy code.",
    "fullText": "Why AI is both the problem and the cure for legacy codeÂ \n\n AI may be the key to cracking legacy code.\n\n By\n\n Alex Jukes\n\n January 08, 2026\n\n About the author\n\n Alex Jukes\n\n Fractional CTO and strategic technical advisor working with innovative UK startups.",
    "readingTime": 1,
    "keywords": [
      "alex jukes",
      "legacy code"
    ],
    "qualityScore": 0.4,
    "link": "https://leaddev.com/ai/why-ai-both-problem-cure-legacy-code",
    "thumbnail_url": "https://leaddev.com/wp-content/uploads/2025/10/trojan-horse-office-01-02.png",
    "created_at": "2026-01-09T12:24:05.361Z",
    "topic": "tech"
  },
  {
    "slug": "cursors-most-important-ai-features-started-as-side-projects-engineers-built-themselves-says-its-engineering-head",
    "title": "Cursor's most important AI features started as side projects engineers built themselves, says its engineering head",
    "description": "Some of Cursor's biggest AI features didn't start on a roadmap. They were bottom-up projects built by its engineers, says Jason Ginsberg.",
    "fullText": "Some of Cursor's most important AI features didn't come from a formal road map. One was built over Thanksgiving, says its engineering head.\n\nJason Ginsberg said in an episode of the \"LangChain\" podcast published Thursday that a bottom-up approach has shaped several of Cursor's core capabilities.\n\nGinsberg said he built a debugging feature over the Thanksgiving holiday simply because he wanted it and to \"help people on the team.\" The AI-coding company has since launched its \"Debug Mode.\"\n\n\"If there's internal adoption, that's kind of our metric for this is ready to ship,\" he said.\n\nThe same pattern applies to Cursor's agent, now one of its defining features. Ginsberg said it was originally prototyped by a single engineer, as others on the team were skeptical.\n\n\"He prototyped it super quickly, and everyone's like, 'Oh wow, this works,'\" Ginsberg said.\n\nCursor still maintains short-term roadmaps, but many of its biggest features emerge organically, Ginsberg said.\n\nHe also said there isn't much formal process at Cursor. Instead of debating product changes in documents or alignment meetings, engineers resolve disagreements through code.\n\nCursor is among the most prominent AI companies being built by a tiny team.\n\nGinsberg said on the podcast that Cursor had about 20 people at the start of 2025.\n\n\"That was because the process to hiring people was very slow and the bar was extremely, extremely high,\" he said.\n\nThat talent-dense structure allows Cursor to operate with minimal organizational process and move quickly, he added.\n\nThe preference for small, elite teams has become increasingly influential across the AI industry, including at Big Tech firms traditionally known for scale.\n\nMeta's superintelligence AI unit, for example, is led by a small group of top researchers. The AI unit comprises a tiny fraction of the company's headcount of over 70,000 employees.\n\n\"I've just gotten a little bit more convinced around the ability for small, talent-dense teams to be the optimal configuration for driving frontier research,\" Mark Zuckerberg said on Meta's earnings call in July.\n\nOpenAI CEO Sam Altman said last year that \"we're going to see 10-person companies with billion-dollar valuations pretty soon.\"\n\nBusiness Insider in May compiled a list of the highest-valued AI startups around the world with teams of 50 employees or fewer, according to PitchBook data.",
    "readingTime": 2,
    "keywords": [
      "features",
      "team",
      "process",
      "teams",
      "formal",
      "thanksgiving",
      "podcast",
      "prototyped",
      "quickly",
      "tiny"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cursor-ai-features-side-projects-jason-ginsberg-engineering-head-2026-1",
    "thumbnail_url": "https://i.insider.com/696093a104eda4732f2ec314?width=1200&format=jpeg",
    "created_at": "2026-01-09T12:24:03.317Z",
    "topic": "finance"
  },
  {
    "slug": "history-says-the-stock-market-could-soar-in-2026-here-is-1-cheap-artificial-intelligence-semiconductor-stock-to-buy",
    "title": "History Says the Stock Market Could Soar in 2026. Here Is 1 Cheap Artificial Intelligence Semiconductor Stock to Buy Right Now",
    "description": "Taiwan Semiconductor Manufacturing stock seems poised for another year of strong gains.",
    "fullText": "The higher spending on AI chips is going to be a tailwind for TSMC stock in 2026.\n\nIts earnings are likely to grow at a faster pace than Wall Street's expectations this year.\n\nTSMC's attractive valuation and strong earnings potential suggest that it could soar nicely.\n\n10 stocks we like better than Taiwan Semiconductor Manufacturing â€º\n\nThe S&P 500 has been in a bull market for more than three years now, entering this territory in October 2022, and the good news is that the index is expected to sustain its rally in 2026 as well.\n\nAfter recording three consecutive years of double-digit gains, a feat that the index has achieved five times since it came into existence in 1957, Wall Street is looking forward to another year of robust growth in the S&P 500. Deutsche Bank, for instance, expects the S&P 500 to hit 8,000 points by the end of 2026, suggesting potential gains of 15% from current levels.\n\nAdditionally, financial services firm Carson Group's chief market strategist Ryan Detrick points out that once a bull market is three years old, it tends to stretch up to eight years on average, citing data going back to 1950. All this indicates that 2026 could turn out to be another good year for the stock market, and artificial intelligence (AI) is set to play a key role in driving more gains this year.\n\nJPMorgan points out that strong capital spending and earnings growth fueled by AI are going to be a catalyst for stocks in 2026. That's why now is a good time to take a closer look at a key company that's playing a central role in driving AI adoption -- Taiwan Semiconductor Manufacturing (NYSE: TSM) -- before the stock market heads higher in the new year.\n\nTaiwan Semiconductor is the world's largest semiconductor foundry, manufacturing chips for all the leading chip designers and consumer electronics companies. That explains why it has been growing at a healthy pace in the past couple of years. TSMC's share of the foundry market stood at an incredible 72% in the third quarter of 2025, according to Counterpoint Research. Its fabrication plants that produce advanced chips for customers, such as Nvidia, Qualcomm, Broadcom, Apple, Sony, Advanced Micro Devices, and others, are reportedly running at full capacity.\n\nThis isn't surprising as the cutting-edge nature of TSMC's advanced manufacturing nodes means that chip designers are able to pack in more transistors into a smaller area on chips fabricated by the Taiwan-based giant. As a result, TSMC-made chips are both powerful and power-efficient, making them ideal for various applications, including data centers, smartphones, and personal computers (PCs).Deloitte estimates that $250 billion to $300 billion could be spent on AI data center chips alone this year, up from an estimated $150 billion last year.",
    "readingTime": 3,
    "keywords": [
      "semiconductor manufacturing",
      "chip designers",
      "bull market",
      "stock market",
      "chips",
      "earnings",
      "tsmc's",
      "gains",
      "points",
      "advanced"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/history-says-stock-market-could-195000468.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uS_1DytIcc84pp1injsyDg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MjA-/https://media.zenfs.com/en/motleyfool.com/13d37ebdc567c486649094d2e721757f",
    "created_at": "2026-01-09T12:24:02.916Z",
    "topic": "finance"
  },
  {
    "slug": "4-googlers-share-how-they-reinvented-their-careers-and-pivoted-to-ai",
    "title": "4 Googlers share how they reinvented their careers and pivoted to AI",
    "description": "Each of these four Google employees took different paths to pivot into AI, but all of them spent roughly a year preparing for the transition.",
    "fullText": "Pivoting to an AI job may be trendy, but that doesn't mean it's an easy feat.\n\nAs AI-related jobs continue to pop up, and companies invest heavily in upskilling, more workers are looking to add \"AI\" to their job titles.\n\nTo see how it can be done, Business Insider spoke with four Google employees who transitioned to AI teams. While each followed a different path, all of them spent roughly a year building the necessary skills to land new roles â€” and for some, the transition took several years.\n\nFrom participating in employee hackathons to becoming AI content creators, the four employees share how they made the shift:\n\nEmrick Donadei said he didn't feel qualified to pivot to an AI team until he participated in Google's seven-day employee hackathon in 2024. The 32-year-old engineer said he didn't create a revolutionary product, but it gave him hands-on experience with tools, and something tangible he could use to start conversations with teams across the company. \n\nRoughly 10 months after his first hackathon, he said he landed his new role.\n\nWhile the hackathon kick-started his transition, his work didn't stop there. The Googler continued to experiment with tools outside the hackathon, he said. He also created a podcast about AI developments and watched Andrej Karpathy's YouTube videos to get up to speed with machine learning concepts and anything related to LLMs.\n\nAfter finding a new role, Donadei said that he participated in another hackathon in 2025, which opened up even more opportunities. He had the opportunity to transition into AI research, began workingÂ part-timeÂ on open-source committees and with AI research teams, and published a public technical disclosure with Google as a follow-up to his work.\n\nMaitri Mangal, 27, worked as a traditional software engineer before transitioning to an AI team. During the roughly year-long period she took to prepare for the pivot, Mangal dedicated roughly two hours daily toward up-skilling, and still spends hours learning weekly, she said.\n\nShe said that creating social media content was a way for her to reinforce the material that she learned through Google's internal training and other online courses.\n\n\"That really, for me, changed everything,\" Mangal said about content creation.\n\nShe said seeing that her content helped other people motivated her to continue learning about the technology and making videos. Even though she already changed jobs, she said she still spends about an hour daily learning new information, whether that's in the form of internal trainings for her job, or watching YouTube courses to prepare for content.\n\nRahul Kasanagottu, 32, spent two and a half years transitioning to an AI role at the tech giant. He said his paternity leave gave him a head start on reading about AI.\n\nIn addition to reading 11 books on the topic, Kasanagottu also took a Deep Learning Specialization course taught by Andrew Ng, and watched 3Blue1Brown videos on YouTube.\n\nSimilar to Donadei, Kasanagottu said solo projects were a key part of his career transition. He said it was difficult to convince hiring managers he could do the job without having demos and hands-on projects to show. While the books he read typically didn't come with assignments, the courses had a lot of hands-on exercises, Kasanagottu said.\n\nMilica Cvetkovic took a different path than the other three Googlers who made internal pivots to AI teams. She landed a role in AI consulting at the tech giant about three years ago, after completing graduate school and conducting research in machine learning.\n\nAfter she received her Master's in statistics, she worked as a machine-learning engineer at a Madison-based startup and simultaneously taught machine-learning boot camps and college-level courses.\n\n\"Having a skill to talk in a nontechnical way is probably the most valuable skill that I bring,\" Cvetkovic said.\n\nHer move to an AI team at Google was less of a deliberate pivot and more the result of the right opportunity aligning with her background and interests. She said that she realized she didn't want to code anymore, and that's when she came across a consulting role at Google.\n\nCvetkovic said she can't name one single experience that led to her getting the job. Rather, she compared her career journey to training for a marathon. A marathon, she said, is the \"celebration of all the work that you've done.\"\n\n\"That's literally what my application was. It was just very good fit,\" Cvetkovic said.\n\nDid you transition to an AI role? We want to hear from you. Reach out to the reporter via email at aaltchek@insider.com or through the secure-messaging app Signal at aalt.19.",
    "readingTime": 4,
    "keywords": [
      "tech giant",
      "machine learning",
      "role",
      "transition",
      "content",
      "didn't",
      "hackathon",
      "teams",
      "roughly",
      "courses"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/googlers-share-transition-to-ai-roles-2026-1",
    "thumbnail_url": "https://i.insider.com/6960299564858d02d218064b?width=1200&format=jpeg",
    "created_at": "2026-01-09T12:24:02.898Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-chatgpt-which-cryptocurrency-will-make-you-rich-in-2026-the-answer-was-surprising",
    "title": "I Asked ChatGPT Which Cryptocurrency Will Make You Rich in 2026 â€” The Answer Was Surprising",
    "description": "I asked ChatGPT to break it down for me, given the state of crypto. It made clear that its answer is \"a structured way to think about the opportunity and risk.\"",
    "fullText": "Cryptocurrency is either touted as the next big thing to make you rich or the riskiest investment ever. Yet despite its volatility and constant controversy, many investors continue to find ways to profit in the crypto space.\n\nIf someone realistically wanted to get rich via cryptocurrency in 2026, which one is most likely to make that possible, and how? I asked ChatGPT to break it down for me, given the current state of crypto. It made clear that its answer does not constitute financial advice, but rather â€œa structured way to think about the opportunity and risk.â€\n\nChatGPT took a realistic look at what â€œgetting richâ€ actually means in the crypto space. It was clear that it doesnâ€™t mean â€œguaranteed 100% returns by New Year,â€ as the crypto market is extremely volatile, risky and speculative.\n\nRealistic goals might look like a 5% to 10% return on your core position â€” the main portion of your crypto portfolio held in more established assets like bitcoin or ethereum that you plan to keep long term. You might also see a larger potential return on a smaller â€œmoonshotâ€ allocation â€” a high-risk, high-reward investment in a newer or less proven coin that could spike in value but could just as easily wipe out, too.\n\nAnalysts place wide predictions even on the giants. For example, bitcoin (BTC) is forecasted to be valued between $100,000 and $200,000 in 2026.\n\nFind Out: 13 Cheap Cryptocurrencies With the Highest Potential Upside for You\n\nRead Next: 9 Low-Effort Ways To Make Passive Income (You Can Start This Week)\n\nBased on current expert commentary and fundamentals, ChatGPT said there are two categories of coins with the best shot at making you rich across two strategies.\n\nUnsurprisingly, bitcoin (BTC), the most well-known coin, remains the leading choice. Many forecasts assume it will stay dominant. However, ethereum (ETH), the runner-up, is seen as more utility-based, and some analysts believe it may outperform BTC in certain phases.\n\nIn either case, these coins are less about â€œgetting rich quickâ€ and more about a reasonable chance of strong returns at moderate risk, the AI said.\n\nSome investors are turning to altcoins â€” smaller cryptocurrencies outside of bitcoin and ethereum â€” that could see bigger short-term gains. Coins like XRP and Solana are getting attention for their performance potential, though they come with higher risk, ChatGPT noted. Even newer projects, especially those combining AI and blockchain, promise sky-high returns, but most are highly speculative. Forecasts of 500% profits make headlines, but in reality, very few ever deliver.",
    "readingTime": 3,
    "keywords": [
      "risk chatgpt",
      "bitcoin btc",
      "crypto space",
      "rich",
      "returns",
      "ethereum",
      "potential",
      "coins",
      "cryptocurrency",
      "either"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asked-chatgpt-cryptocurrency-rich-2026-141005190.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uX_rux7fJMsKqrVtki_sOA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02Nzc-/https://media.zenfs.com/en/gobankingrates_644/23356af9c4dff4e9e0db193ddf011349",
    "created_at": "2026-01-09T12:24:02.729Z",
    "topic": "finance"
  },
  {
    "slug": "google-is-unleashing-gemini-ai-features-on-gmail-users-will-have-to-opt-out",
    "title": "Google is unleashing Gemini AI features on Gmail. Users will have to opt out",
    "description": "Google is adding more Gemini features to Gmail, the company's latest effort to spread its core AI product across its product portfolio.",
    "fullText": "Google is adding more Gemini features to Gmail, providing upgrades like artificial intelligence-generated summaries of email threads, the company said Thursday.\n\nThe company said its latest updates will be rolled out in phases, and some features will be turned on by default in inboxes, meaning users who don't want them will have to opt out.\n\n\"When you open an email with dozens of replies, Gmail synthesizes the entire conversation into a concise summary of key points,\" Google wrote in a blog post.\n\nThe company said AI Overviews, which show up at the top of search results, are also being added to Gmail.\n\nThe updates come as Google embeds its Gemini AI technology across its wide portfolio of consumer products. Google is counting on its massive customer base to provide an advantage as the company takes on the likes of OpenAI, Anthropic and others in the booming generative AI market.\n\nGoogle says Gmail now has more than 3 billion users.\n\nLast year, Google's Gemini integration in Gmail allowed users to do things like search messages, draft emails from prompts, improve grammar and generate custom responses.\n\nOne of the new features is \"Suggested Replies,\" which Google says uses the context of a user's emails to create one-click responses. It's an update to a prior tool called \"Smart Replies.\" The company is also upgrading a proofreading option for checking grammar and making messages more concise.\n\nDriven by its rapid advancements in AI, Google parent Alphabet topped Apple by market cap on Wednesday for the first time since 2019, continuing a rally that made the stock the best performer among tech megacaps last year. Meanwhile, OpenAI soared to a private market valuation of $500 billion late last year, and Anthropic said Wednesday that it's valued at $350 billion in a new funding round.\n\nâ€” CNBC's MacKenzie Sigalos contributed to this report.\n\nWATCH: How Gemini is gaining ground on ChatGPT",
    "readingTime": 2,
    "keywords": [
      "features",
      "users",
      "market",
      "google",
      "email",
      "updates",
      "concise",
      "search",
      "messages",
      "emails"
    ],
    "qualityScore": 0.85,
    "link": "https://www.cnbc.com/2026/01/08/google-adds-gemini-features-to-gmail-message-summaries-proofreading-.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/106199081-1571858526194gettyimages-887454120.jpeg?v=1767831513&w=1920&h=1080",
    "created_at": "2026-01-09T06:19:46.840Z",
    "topic": "tech"
  },
  {
    "slug": "aifirst-screen-recorder-to-create-videos-in-perfect-english",
    "title": "AI-first screen recorder to create videos in perfect English",
    "description": "AI screen recorder that translates your voice",
    "fullText": "Speak in your native language and instantly create\nprofessional screen recordings in perfect English.\n\nLet AI automatically translate your screen recording into perfect English in minutes.\n\nDownload the Wizardly chrome extension to generate your first professional screen recording.\n\nLaunch the chrome extension and record your screen as you naturally would in your native language.\n\nWizardly automatically turns your recording into a professional screen recording in perfect English.\n\nWizardly offers powerful features to generate high-impact videos with ease.\n\nRecord using the language you're most comfortable with and let Wizardly turn it into a polished English video in minutes.\n\nDon't worry about mistakes. Wizardly removes uhs, ums and bad takes to create a professional script in minutes.\n\nWizardly generates videos with native accents. We replace your voice with a professional voice over for perfect video narration.\n\nEdit the flow and rewrite the script. Easily update the content to create the perfect video and match your design guidelines.\n\nChoose from a variety of different voices to create videos that fit with your tone and branding.\n\nDownload your videos in HD, embed them anywhere, or share them instantly with your team and customers.\n\nEffortlessly promote your content by instantly translating among 14 languages.\n\nWizardly offers live translation in ğŸ‡¬ğŸ‡§ English, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡«ğŸ‡· French, ğŸ‡©ğŸ‡ª German, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡·ğŸ‡º Russian, ğŸ‡³ğŸ‡± Dutch, ğŸ‡µğŸ‡± Polish, ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡¹ğŸ‡· Turkish, ğŸ‡ºğŸ‡¦ Ukrainian, ğŸ‡¯ğŸ‡µ Japanese, ğŸ‡®ğŸ‡© Indonesian, and ğŸ‡ªğŸ‡¸ Catalan.\n\nChoose your recording language and desired output language with just a few clicks. Create professional screen recordings in any language combination on the fly.\n\nNot translating? No problem. Use Wizardly to upgrade your recordings to the same language. Wizardly automatically improves clarity, refines phrasing, and removes filler words.\n\nCustomers choose Wizardly to create professional-grade screen recordings.\n\nGlobal teams & founders create professional videos for support, sales, and marketing.\n\nGet started for free, no credit card required.\n\nStill have questions? Reach out to us.\n\nJoin some of the fastest growing startups using Wizardly.",
    "readingTime": 2,
    "keywords": [
      "perfect english",
      "chrome extension",
      "wizardly automatically",
      "screen recordings",
      "native language",
      "screen recording",
      "create professional",
      "videos",
      "instantly",
      "minutes"
    ],
    "qualityScore": 1,
    "link": "https://trywizardly.com/",
    "thumbnail_url": "https://trywizardly.com/images/wizardly_social_banner.png",
    "created_at": "2026-01-09T06:19:46.504Z",
    "topic": "tech"
  },
  {
    "slug": "metas-reality-labs-chief-is-calling-the-most-important-meeting-of-the-year-urging-employees-to-show-up-in-person",
    "title": "Meta's Reality Labs chief is calling the 'most important' meeting of the year, urging employees to show up in person",
    "description": "Meta CTO Andrew Bosworth calls key all-hands meeting at Reality Labs as the division faces budget cuts, strategic shifts to AI, and layoffs last year.",
    "fullText": "Meta's Chief Technology Officer and head of Reality Labs, Andrew Bosworth, has called an all-hands meeting for January 14, describing it as the \"most important\" of the year.\n\nBosworth is also strongly recommending that Reality Labs employees attend the division's meeting in person, two Meta employees told Business Insider.\n\nThe emphasis on in-person attendance is unusual for the division, which oversees the company's wearables, virtual and augmented reality initiatives, and a nascent robotics unit, these employees said. Some managers have told employees to \"drop what they're doing\" to attend the all-hands in person, one employee told Business Insider.\n\nMeta did not immediately respond to a request for comment about the meeting.\n\nWhile the division has seen some success, such as its Ray-Ban smart glasses, Reality Labs has been a costly venture for Meta, incurring losses of more than $70 billion since 2020.\n\nLast year, Meta CEO Mark Zuckerberg shifted the company's strategic focus toward AI and away from the metaverse. In 2025, Meta invested $14.3 billion in Scale AI and hired its CEO, Alexandr Wang, as part of the major reset of the company's AI efforts. Meta then embarked on a multibillion-dollar hiring spree, poaching top-tier AI researchers and engineers from rivals such as OpenAI and Google DeepMind.\n\nReality Labs has faced repeated rounds of cuts over the past year. In December, Business Insider reported that Meta was planning budget cuts up to 30% and considering job cuts in Reality Labs.\n\nLast April, Meta laid off employees in Oculus Studios, its in-house gaming division, and the team behind Supernatural, the VR fitness app Meta acquired for over $400 million. Those cuts followed Meta's broader January 2025 layoffs that eliminated nearly 4,000 roles companywide, with at least 560 affecting Reality Labs employees.\n\nIn a memo obtained by Business Insider earlier last year, Bosworth referred to 2025 as \"the most critical\" year in his eight-year tenure at Reality Labs.\n\n\"This year likely determines whether this entire effort will go down as the work of visionaries or a legendary misadventure,\" he wrote.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "labs employees",
      "reality labs",
      "cuts",
      "division",
      "company's",
      "meta",
      "all-hands",
      "january",
      "attend",
      "email"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-cto-andrew-bosworth-reality-labs-all-hands-meeting-2026-1",
    "thumbnail_url": "https://i.insider.com/69605e5b64858d02d2180829?width=1200&format=jpeg",
    "created_at": "2026-01-09T06:19:45.146Z",
    "topic": "finance"
  },
  {
    "slug": "why-i-wont-be-giving-chatgpt-health-my-medical-records",
    "title": "Why I Won't Be Giving ChatGPT Health My Medical Records",
    "description": "OpenAI  invites you to hand over your medical information. Maybe don't?",
    "fullText": "This week, OpenAI announced its new ChatGPT Health feature, which will let users upload their medical records and ask health related questions. However, I certainly won't be making use of it, it might not be the best idea for you to do it either, for both reliability and privacy reasons.\n\nThe new ChatGPT Health feature will be a sandboxed tab inside the app that is isolated from your conversation history in other conversations with the chatbot. This tab also allows users to connect a variety of health-tracking apps like Apple Health, MyFitnessPal, and Peloton, as well as uploading medical records directly.\n\nIt's important to note that this is a lot of really personal information to hand over to any tech companyâ€”but especially one that isn't primarily focused on providing medical services. OpenAI says that the ChatGPT Health space operates with \"enhanced privacy to protect sensitive data,\" but it doesn't use end-to-end encryption to secure that data. And while the company says data collected via Health isn't used to train its foundation models, it's impossible to know whether that may change in the future. Security breaches can also occur (and have in the past), potentially leaving your medical records exposed.\n\nThere's also the question of whether the risk of uploading your data is worth it in the first place. According to OpenAI's own data, around 5% of all messages to ChatGPT are already users asking questions about their health, and ChatGPT (and other LLM tools) have a nasty habit of providing inaccurate diagnostic information. This is perhaps why OpenAI says that its new ChatGPT Health feature is \"not intended for diagnosis or treatment.\"\n\nCurrently, there's a waitlist to At the very least, that means that until the feature is available, it's probably a good idea not to ask the regular version of ChatGPT about your health concerns. At the very least, wait until the enhanced privacy sandbox is available. In the meantime, consider whether it makes more sense to just talk to your doctor directly if you have questions or concerns about your health.",
    "readingTime": 2,
    "keywords": [
      "health feature",
      "enhanced privacy",
      "medical records",
      "chatgpt health",
      "openai",
      "users",
      "it's",
      "idea",
      "uploading",
      "directly"
    ],
    "qualityScore": 0.9,
    "link": "https://lifehacker.com/tech/dont-give-chatgpt-health-your-medical-records?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEFGNJDCMT3JTWC4A7YNJXZ3/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-09T00:58:41.714Z",
    "topic": "tech"
  },
  {
    "slug": "form-13da-datavault-ai-inc-for-8-january",
    "title": "Form 13D/A DATAVAULT AI INC. For: 8 January",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/filings/form-13da-datavault-ai-inc-for-8-january-93CH-4438338",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-09T00:58:40.393Z",
    "topic": "finance"
  },
  {
    "slug": "ramp-ai-index",
    "title": "Ramp AI Index",
    "description": "Monthly measurement of AI adoption by American businesses.",
    "fullText": "Ramp AI Index measures the adoption rate of artificial intelligence products and services among American businesses. Our sample includes more than 50,000 American businesses and billions of dollars in corporate spend using data from Rampâ€™s corporate card and bill pay platform.\n\nOur work builds on previous work by Bonney et al. (2024) by providing a new dataset to measure firm adoption of artificial intelligence. Previous work has relied almost entirely on surveys that ask businesses if they use AI, but surveys may lead to underreporting of actual AI adoption, particularly when questions are unclear or when adoption of a new technology is rising very quickly. Using contract and transaction data from corporate spend with AI companies, we produced a more timely and accurate measurement of AI adoption by U.S. businesses.\n\nOur transaction set is built using company models that extract line-item text from paid receipts and bills uploaded by the purchaser following a sale. Firms are considered to have adopted AI tools if they have a positive transaction amount for an AI product or service in a given month. AI products and services are identified using merchant name and line item details from receipts and bills.\n\nFirms are assigned to industry sectors using internal company models that predict the relevant industry sector using the NAICS standard. Firms are assigned to business size segments using company models that use internal and third-party data on firm revenues and employee counts.\n\nItâ€™s likely our results underestimate actual adoption rates due to the prevalence of businesses using free AI tools, in which no paid transaction occurs, or when employees use personal accounts with AI companies to complete work tasks.",
    "readingTime": 2,
    "keywords": [
      "american businesses",
      "artificial intelligence",
      "adoption",
      "transaction",
      "corporate",
      "models",
      "firms",
      "products",
      "services",
      "firm"
    ],
    "qualityScore": 0.85,
    "link": "https://ramp.com/data/ai-index",
    "thumbnail_url": "https://cdn.sanity.io/images/6jz6vxxd/production/e9139f7d0f25cca200dfcc54a463484fc24e9244-3600x1881.png?w=1200&h=627&fit=crop",
    "created_at": "2026-01-08T18:16:54.384Z",
    "topic": "tech"
  },
  {
    "slug": "continuous-autonomy-for-the-ai-sdk",
    "title": "Continuous Autonomy for the AI SDK",
    "description": "Continuous Autonomy for the AI SDK. Contribute to vercel-labs/ralph-loop-agent development by creating an account on GitHub.",
    "fullText": "vercel-labs\n\n /\n\n ralph-loop-agent\n\n Public\n\n Continuous Autonomy for the AI SDK\n\n ai-sdk.dev\n\n License\n\n Apache-2.0 license\n\n 390\n stars\n\n 36\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n vercel-labs/ralph-loop-agent",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/vercel-labs/ralph-loop-agent",
    "thumbnail_url": "https://opengraph.githubassets.com/e4014956dc4486f850b8fb750352310313fb897b97ac01de2dfab33c7746e5f2/vercel-labs/ralph-loop-agent",
    "created_at": "2026-01-08T18:16:53.337Z",
    "topic": "tech"
  },
  {
    "slug": "pydanticaistream-structured-event-streaming-for-pydanticai-agents",
    "title": "Pydantic-AI-stream â€“ Structured event streaming for pydantic-AI agents",
    "description": "Contribute to opale-ai/pydantic-ai-stream development by creating an account on GitHub.",
    "fullText": "opale-ai\n\n /\n\n pydantic-ai-stream\n\n Public\n\n 8\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n opale-ai/pydantic-ai-stream",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/opale-ai/pydantic-ai-stream",
    "thumbnail_url": "https://opengraph.githubassets.com/ad2260829c52314a64c2f2fb541dec4594e68f27da25900ef0792a1c63b456e4/opale-ai/pydantic-ai-stream",
    "created_at": "2026-01-08T18:16:53.227Z",
    "topic": "tech"
  },
  {
    "slug": "appletsmc-the-partnership-that-built-modern-semiconductors",
    "title": "Apple-TSMC: The Partnership That Built Modern Semiconductors",
    "description": "Wafer demand model, node economics, and the shifting power dynamics as AI reshapes the foundry landscape",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://newsletter.semianalysis.com/p/apple-tsmc-the-partnership-that-built",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!hA86!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4957f77-ed9e-4671-adc2-0df896bf43ab_2528x1696.jpeg",
    "created_at": "2026-01-08T18:16:52.716Z",
    "topic": "tech"
  },
  {
    "slug": "a-mechanistic-investigation-into-how-transformer-models-hallucinate-citations",
    "title": "A mechanistic investigation into how transformer models hallucinate citations",
    "description": "Read Debugging Hallucinations: A Mechanistic Investigation into Model Confidence on Saumil Srivastava's AI Engineering Blog",
    "fullText": "As engineers, we often treat Large Language Models (LLMs) as opaque inference engines: a prompt enters, text exits, and we evaluate the output based on surface-level correctness.\n\nWhile exploring model failure modes, fabricated citations emerged as a particularly sharp example that standard evaluation metrics failed to capture.\n\nThe model would invent a caseâ€”Harrison v. McDonaldâ€”and cite it with the precise formatting and tonal confidence of a Supreme Court opinion. The issue wasn't just that the output was factually wrong; it was that the model's internal confidence appeared indistinguishable from when it cited real case law.\n\nI wanted to move beyond \"prompt engineering\" to answer a fundamental question: Can we detect the difference between retrieved knowledge and stochastic pattern matching by observing the model's internal activations?\n\nThis post documents the engineering journey including the failed hypotheses and broken code required to differentiate \"memory\" from \"imagination\" inside a transformer.\n\nTransformers operate on a residual stream, where information accumulates across layers. My working hypothesis was based on two distinct behaviors:\n\nUsing the Logit Lens technique on GPT-2, I visualized this difference.\n\nTo verify this wasn't a visual artifact, I ran a Noise Injection experiment (similar to *Rome et al.*). I injected high-magnitude Gaussian noise (Ïƒ=2.0) into intermediate layers to see how fragile the information was.\n\nThe difference in failure modes was visible in the raw console logs.\n\nFactual Prompt: (\"The capital of France is...\")\n\nWhen I corrupted Layer 8, the model performed an Entity Swap.\n\nThe model preserved the structure (Country â†’ Capital) but lost the instance. It \"forgot\" France but still knew it was talking about geopolitics.\n\nHallucinated Prompt: (\"The case of Harrison v. McDonald...\")\n\nWhen I applied the same noise to the fake citation, the model didn't swap names. It experienced Topic Drift.\n\nThe model completely lost the plot. It drifted from \"validity\" to \"privacy\" to \"equal protection\". This suggests that the hallucination failed to maintain a stable intermediate representation; it was a transient surface pattern generated during late-stage completion.\n\nArmed with this insight, I built my first detector. I assumed a sudden \"Confidence Spike\" in the final layer was the unique signature of a lie.\n\nThe Failure: My detector began flagging real facts as hallucinations.\n\nLooking back at my initial code, the bug is obvious. I was calculating risk by subtracting the spike size, effectively rewarding the model for spiking:\n\nThe discriminative signal wasn't the spike itselfâ€”both facts and hallucinations spike when the model \"commits\" to an answer. The real signal is the interaction between early entropy and late confidence.\n\nThe Corrected Signal (one effective formulation):\n\nA model that is confident at the end, but was confused in the middle, is likely hallucinating.\n\nThe token-level signal was noisy and prompt-dependent, which is why I moved to span-level aggregation and statistical validation across 60+ prompts.\n\nTo prove this, I ran an Ablation Study. I systematically disabled features to see which ones contributed to the separation between Real and Fake citations.\n\nThe key insight is directional: Confidence alone is inverted it would flag real facts as hallucinations, confirming the Phase 3 bug.\n\nThe signal emerges from the interaction of early entropy and late confidence. Although early entropy alone shows a positive delta, its effect size is small and unstable across prompts, making it insufficient as a standalone signal.\n\nIn my initial notebook, the detector achieved strong separation on a small test set (n=10). Before claiming victory, I expanded the test suite.\n\nThe Humbling: When I scaled to 77 prompts on GPT-2, the signal remained significant (p=0.003)â€”but the effect size collapsed from Cohen's d=4.73 to d=0.73. The \"perfect\" separation was a small-sample illusion.\n\nThe Pivot: I ported the analysis to Llama-3-8B, a modern RLHF-tuned model, hypothesizing that models trained with human feedback might have more distinct confidence patterns.\n\nThe Result: The signal re-emerged, but it was noisy.\n\nâš ï¸ *Suspiciously high â€” small-sample artifact*\n\nInterpretation: Even in heavily fine-tuned models, hallucinations leave a trace. The model is statistically \"more confused\" in the middle layers when lying than when telling the truth. However, an AUC of 0.68 confirms that this signal is noisy ,it is not a silver bullet. The distributions of \"confident truths\" and \"confident lies\" overlap significantly. This progression illustrates how easy it is to overfit mechanistic signals on small, hand-picked sets, and why scaling and re-validation are non-negotiable.\n\nThis finding dictated the final system architecture. If we had an AUC of 0.95, we could build a firewall that auto-blocks hallucinations. With an AUC of 0.68, blocking would flag a substantial fraction of legitimate citations.\n\nCrucial Engineering Detail: Tokens vs. Spans\n\nIn my early experiments, I analyzed raw tokens. This was too noisyâ€”the model might be confident about \"Harrison\" but confused about \"v.\".\n\nI realized that a legal citation is an atomic unit of truth. I refactored the detector to aggregate token probabilities into Span-Level Risk Scores. We don't flag individual tokens; we flag semantic spans that correspond to atomic claims.\n\nThe Pivot: Instead of a \"Blocker,\" I built an Annotator.\n\nThe system calculates the entropy signature on the fly. If the risk score crosses a threshold, we don't silence the modelâ€”we inject a visual indicator:\n\nThis converts silent hallucinations into visible uncertainty.\n\nWe often talk about \"Aligning\" AI, but we rarely talk about giving it the tools to know when it is guessing. By looking at the internal physics of the modelâ€”specifically the entropy of the residual streamâ€”we can start to distinguish between memory and imagination.\n\nThe journey from \"Logit Lens\" to \"Mechanistic Observability\" wasn't a straight line. It required breaking the \"Confidence\" heuristic, debugging the math, and accepting that mechanistic signals are probabilistic, not binary.\n\nWe didn't solve the problem of hallucinations, but we did solve the problem of silent hallucinations.\n\nCode and Notebooks: GitHub Repo Link\n\nGet weekly insights on AI implementation, performance measurement, and technical case studies.\n\nGet weekly insights on AI implementation and technical case studies.",
    "readingTime": 5,
    "keywords": [
      "weekly insights",
      "failure modes",
      "model's internal",
      "effect size",
      "mechanistic signals",
      "across prompts",
      "silent hallucinations",
      "entropy",
      "wasn't",
      "detector"
    ],
    "qualityScore": 1,
    "link": "https://www.saumilsrivastava.ai/blog/debugging-hallucinations-a-mechanistic-investigation-into-model-confidence",
    "thumbnail_url": "https://www.saumilsrivastava.ai/api/og?title=Debugging%20Hallucinations%3A%20A%20Mechanistic%20Investigation%20into%20Model%20Confidence&category=Mechanistic%20Interpretability&author=Saumil%20Srivastava",
    "created_at": "2026-01-08T18:16:52.477Z",
    "topic": "tech"
  },
  {
    "slug": "he-was-called-a-terrorist-sympathizer-now-his-ai-company-is-valued-at-3b",
    "title": "He was called a 'terrorist sympathizer.' Now his AI company is valued at $3B",
    "description": "â€œI must apologize to â€” absolutely nobodyâ€: Replit founder Amjad Masad isnâ€™t afraid of Silicon Valley.",
    "fullText": "â€œI must apologize to â€” absolutely nobodyâ€: Replit founder Amjad Masad isnâ€™t afraid of Silicon Valley.\n\nâ€œI must apologize to â€” absolutely nobodyâ€: Replit founder Amjad Masad isnâ€™t afraid of Silicon Valley.\n\nâ€œShould I wear a keffiyeh to the shooting range?â€ Amjad Masad asked as I slid into the passenger seat of his black Mercedes sports car. The patterned Palestinian scarf has become a political lightning rod in the two years since the war in Gaza began. Masad, the founder of AI coding startup Replit, and a Palestinian by origin, wrapped it around his neck anyway.\n\nAt the shooting range in Santa Clara, we collected an assault rifle and a pistol and headed in. With the AR-22 tucked into his shoulder, Masad fired at a brisk clip, peppering bullets into a cartoon burglar. In less than two minutes, the burglarâ€™s head was perfectly pocked with holes.\n\nâ€œYou should compete,â€ I suggested.\n\nHe smirked. â€œI always compete.â€\n\nIndeed, Masad has never been shy about his competitive streak or his political beliefs â€” especially since Oct. 7, 2023, when Hamas attacked Israel, setting off the war in Gaza.\n\nMasad, 38, has felt obliged to speak out about Gaza ever since, calling out those in tech who, in his view, have supported Israelâ€™s â€œgenocideâ€ of the Palestinian people. He quickly learned just how unpopular that opinion was in Silicon Valley.\n\nParty invitations dried up, group chats lit up with techies condemning his posts, and investors called him a â€œterrorist sympathizer.â€ One member of a firm that backed Replit publicly declared (opens in new tab) in July that he would donate any earnings from the investment to the Israel Defense Forces.\n\nâ€œI felt like I was sort of expelled from Silicon Valley,â€ Masad said in November on the way to the range.\n\nBut even as Silicon Valley cooled on him, the AI boom that Masad had long bet on took off. In 2024, Replit combined its coding tools with AI to create an agent that could turn plain English prompts into pre-coded apps. After nearly a decade, the company was suddenly in the right place at exactly the right time.\n\nTwo years later, Replit is booming. In September, it raised $250 million from Prysm, Andreessen Horowitz, Amex Ventures, and others, at a valuation of $3 billion. The company hopes to create the preeminent AI coder â€” one so easy to use that anyone can become a software engineer. Meanwhile, Masad continues to advocate for his political beliefs.\n\nâ€œPeople reached out to me to express that my words have been hurtful and that many have been deeply offended,â€ he posted on X over the summer (opens in new tab). â€œI finally realized that I must, from the bottom of my heart, apologize to â€” absolutely nobody.â€\n\nMasadâ€™s swagger isnâ€™t unique among tech founders. But for many, their against-the-grain takes tend to align with the bottom line. Masad insists he speaks up even when it hurts his business. In that regard, â€œIâ€™m probably the only contrarian in Silicon Valley,â€ he told me.\n\nAs Replit takes off, will he be able to maintain that independence?\n\nReplitâ€™s multibillion valuation is hitched to the AI boom. Should the boom fizzle, the company could be worth nothing. But if it holds, and AI continues to remake the tech industry and the greater economy, Masad could find himself among the Valleyâ€™s next class of billionaires.\n\nReplit has plenty of competition among AI code-to-product firms (which are typically built on top of the mega LLMs). Swedish startup Lovable raised $330 million last month (opens in new tab), and Israeli company Base44 was bought by website builder Wix for $80 million this summer. All told, the AI coding sector received $4.7 billion in U.S. funding in the last year alone, according to PitchBook.\n\nTo persevere, Masad will not only have to beat his competitors with a better product but will have to earn the favor of still more investors, given the massive capital it takes to build and power Replitâ€™s models.\n\nFor this reason, most players in AI have been pragmatic with their politics; see, for instance, how many Silicon Valley figures who previously supported liberal causes â€” from Marc Benioff to Mark Zuckerberg â€” suddenly and enthusiastically embraced the Trump White House. Or how Jensen Huang reportedly cozied (opens in new tab) up to David Sacks, hoping the AI czar would convince President Donald Trump to loosen U.S. chip restrictions and allow Nvidia to sell more products globally. Or how Sam Altman has courted Gulf royalty, landing major (opens in new tab) deals to build data centers in the region and fund OpenAIâ€™s stateside infrastructure needs.\n\nFor the most part, Masad has been unwilling to soften his positions. With a penchant for discursive discussions on political philosophy, Masad remains eager to speak about the war in Gaza and rail against what he sees as human rights abuses committed by Israel.\n\nAnd heâ€™s keen to take meetings with anyone who might see eye to eye on Palestine, even if they donâ€™t agree on tech policy. Masad has spoken with New York Mayor Zohran Mamdani and messaged Lina Khan, the former chair of the Federal Trade Commission and nemesis of the tech elite. He had dinner with Tucker Carlson and lasted the obligatory three hours (opens in new tab) on â€œThe Joe Rogan Experience.â€\n\nIn short, Masad sees himself as both a champion for Palestine and a mogul in waiting. Which, particularly to other Arabs in tech, has made him a hero. â€œHaving one of us make it in Silicon Valley â€” and still stay vocal on Palestine in the midst of all of this, specifically in Silicon Valley â€” is extremely inspirational,â€ said Fadi Ghandour, executive chairman at investment firm Wamda, one of the backers of Replit.\n\nAll this is a world away from Amman, Jordan, where Masad grew up. On the drive from his home in Palo Alto to the gun range, Masad told me his youthful hobbies included drift racing on Ammanâ€™s streets and shooting guns in empty lots.\n\nMasad, who speaks unexpectedly softly given his combative persona, is aware of how lucky he is. He compared his circumstances to a simulation experiment in which â€œif you ran the world a million times, I think 90% of them, Iâ€™m in a really bad situation. Iâ€™m in prison or dead.â€ Instead, â€œsomehow I keep surviving and winning.â€\n\nReplitâ€™s multibillion valuation was in many ways the fruits of Masadâ€™s decades-long study of how to make it in Silicon Valley. As a teen in Jordan, he avidly followed Y Combinator cofounder Paul Graham, studying his blog posts and obsessively scrolling through Hacker News, the Y Combinator news feed.\n\nAfter getting his computer science degree in 2010 from Jordanâ€™s Princess Sumaya University for Technology, he created the first iteration of what would become Replit: an open-source program for coders to work within a web browser, a novelty back when programmers needed to buy specialized software.\n\nHe posted a link to the program on Hacker News, where it went viral. That led to securing his first job in the U.S., as the founding engineer at Codecademy in New York. In 2013, he took a job as a software engineer at Facebook. By 2016, he and his wife, Haya Odeh, decided to revisit his old project from Jordan, officially founding Replit as an online platform to help developers build, collaborate, and publish their software.\n\nAs a student of Silicon Valley, Masad knew that mythmaking was just as important as the product. He began live-blogging Replitâ€™s progress, and his efforts soon caught the attention of Graham himself. â€œWhat struck me most about him, at first, was that he was a programmersâ€™ programmer,â€ Graham said. â€œHe wasnâ€™t just working on software to make money. Heâ€™d have been writing it no matter what.â€\n\nGraham invited Masad and Odeh to apply to the Y Combinator accelerator program in 2018. They were accepted, and after completing the program, Replit landed investment from Andreessen Horowitz. With that funding and support, Replit gained traction as a tool for students to learn coding and educators to teach it. According to Masad, he turned down a $1 billion acquisition from Github, believing Replit would one day be worth exponentially more.\n\nMasadâ€™s ultimate objective was to leverage his success in tech to help the Palestinian cause â€” a sentiment instilled in him by his mother. â€œShe would tell me about all the great things Iâ€™m gonna do,â€ he said. â€œI fantasized as a kid about helping the Palestinians and ending the occupation and being an important force in the world.â€\n\nBut in 2019, he effectively put the company on pause after his motherâ€™s cancer took a turn for the worse. Masad and Odeh traveled to be with his father, a civil engineer with the Jordanian government.\n\nThe experience was traumatic for Masad. In his motherâ€™s final days, the doctors in Jordan wouldnâ€™t let any visitors into the ICU. Masad begged, then yelled, and they finally relented â€” on the condition he sign a â€œdo not resuscitateâ€ order. He still doesnâ€™t understand why. By the time he got to see her, she was unconscious. â€œI was so angry at modern medicine,â€ Masad said. â€œSo angry at modernity.â€ She died shortly thereafter.\n\nAfter a few months, Masad returned to Silicon Valley. He couldnâ€™t stop thinking about civilization at large, about where the world was going, and if he could stand it â€” or if he could change it. He found himself agreeing with the Valleyâ€™s increasingly powerful libertarians.\n\nHe bonded with Marc Andreessen over politics and literature, and traveled to Malaysia to visit Balaji Srinivasanâ€™s mysterious â€œstartup society.â€ He grew to realize that the limitations he had assumed donâ€™t necessarily apply. â€œThere was an aspect of, like, â€˜Fuck the system,â€™â€ Masad said. â€œâ€˜We need to remake civilization.â€™â€\n\nMasad gained a following on Twitter by bantering with tech legends about everything from coding to bitcoin to Covid vaccine skepticism. His growing stature landed him on podcasts and in glowing (opens in new tab) articles in The Wall Street Journal portraying him as a maverick. Then came the ultimate Silicon Valley validation: Graham, the idol whom heâ€™d studied obsessively as a teenager in Jordan, started thanking him in his own blog posts.Â  (opens in new tab)\n\nMeanwhile, Replit was struggling. The education market turned out to be small, and the company had trouble expanding into enterprise deals. In late 2023, Replit killed its education product and the following year laid off 30 employees â€” right after moving into a bigger office in Foster City. â€œI remember walking around the office and just feeling sick to my stomach,â€ he said. â€œI felt like I let people down as well, because I sold them this big dream, and it wasnâ€™t working.â€\n\nHe had a plan, though, one he hoped would make his odyssey worth it. For years, he had proselytised on podcasts about how AI would turbocharge coding. Replit had spent years building an extensive database of coding materials â€” he just needed foundational companies like OpenAI and Anthropic to catch up and release an LLM capable of writing code. Once they did, Replit could plug those models into its pre-existing database and create a powerful app-building AI agent.\n\nWhile a new AI coding company would have to build out that infrastructure from scratch, Replit, Masad realized, could start miles ahead. After nearly a decade, he would finally have perfect timing.\n\nMasad had always been outspoken online. After Hamasâ€™ terrorist attacks, as segments of the tech elite publicly lined up behind Israel, he held his ground. And his responses grew more costly.\n\nFirst, there were the public fights. Masad advised Elon Musk (opens in new tab) to â€œstick to his principlesâ€ when the billionaire said the slogan â€œfrom the river to the seaâ€ was calling for genocide. (Palestinian activists say itâ€™s a call for the peaceful liberation of the Palestinian people; pro-Israel voices say it calls for the extermination of Israel.) He clapped back (opens in new tab) at Lux Capital founding partner Josh Wolfe, who said that equating Israelâ€™s actions in Gaza to genocide â€œgrotesquely disgracesâ€ Holocaust victims. And when Keith Rabois of Khosla Ventures said Masadâ€™s â€œfriendsâ€ (opens in new tab) were behind the Oct. 7 attack, Masad challenged him directly.\n\nâ€œIf you think my friends did that then why donâ€™t you confront me when you see me?â€ Masad replied on X (opens in new tab).\n\nBut even as things got noisy in public, Masad met eerie silence professionally. â€œMy calendar was suddenly empty, because I was talking about Palestine,â€ he said. â€œReplit was not a hot company anymore. We did a layoff. And at the same time, a lot of my friends were no longer my friends. I was no longer invited to parties.â€\n\nPotential partnerships dried up. Masad became a frequent topic in pro-Israel tech groupchats, a source said, where some investors accused him of being antisemitic.\n\nA Replit investor who requested anonymity to speak candidly told me Masadâ€™s public persona has been â€œreally challenging,â€ and heâ€™s had to defend the founder in investor circles. I asked if Masad had lost business because of his views. â€œIâ€™m sure the answer is yes,â€ the investor said.\n\nA startup that Masad had invested in pitched another investor â€” and found that Masad was a liability. â€œHe said, â€˜Oh, Amjad is investing. Heâ€™s like a terrorist sympathizer. If heâ€™s investing, Iâ€™m not investing,â€ Masad said he was told, though he declined to name the company or the investor.\n\nBut as Silicon Valley grew chilly, other regions beckoned.\n\nIn April 2024, with Replit a few months from launching its AI agent, Saudi Arabiaâ€™s Public Investment Fund, which is worth nearly $1 trillion, invited Masad and other AI thought leaders to stay at Ekland Safaris, a property in South Africa linked (opens in new tab) to Crown Prince Mohammed bin Salman.\n\nFor Masad, it was a lifeline. Here were potential partners who didnâ€™t care about his politics on Palestine. If anything, his Arab identity and his outspokenness made him more attractive.\n\nIn the heat of the day, a hunting guide sped Masad and other guests, including Tareq Amin, the future CEO of Saudi AI company HUMAIN, across 30,000 acres to kill kudu and wildebeest. By night, guests feasted in a grand ballroom while Masad demoed his not-yet-released AI coding agent to Saudi officials.\n\nâ€œWeâ€™re going to be able to give a software engineer to every person,â€ Masad told Amin. â€œAnyone in the world will have a software engineer on demand.â€\n\nAmin said he thought then that Replit was on â€œa path to build a game-changing technology.â€ Indeed, if the agent worked, and if the AI boom Masad had been betting on came to pass, everyone in that room stood to benefit.\n\nReplit launched its AI agent in September 2024 and within a year, revenue had reached $150 million. Amin and Masad closed a deal for Replit to be the exclusive AI coding software for Saudi governmental agencies, a partnership Masad expects to lead to â€œhundreds of millionsâ€ of dollars worth of business.\n\nAnd just like that, Silicon Valley wanted back in. Replit landed enterprise deals with Atlassian and Zillow, with a Meta deal in the wings, according to Masad. Replit raised its $250 million round and scored its $3 billion valuation.\n\nIt helped Masad that, in the two years since Oct. 7, thereâ€™s been rising public disapproval (opens in new tab) of the Israeli government. He also gained strength in numbers: There have been high-profile movements (opens in new tab) within Google, Amazon, and other tech giants, with employees speaking out in support of the Palestinian cause.\n\nâ€œToday, the tide in tech has shifted,â€ Masad posted to X in September. (opens in new tab) â€œIf youâ€™ve been holding back, now is the time to speak out and call out anyone supporting or celebrating genocide.â€\n\nWith Silicon Valley warming back up to him â€” he was on a16zâ€™s podcast in October (opens in new tab) â€” Masad was invited to larger, and more controversial, audiences. He drove hours to record at Carlsonâ€™s rural Maine cabin, nodding politely when the host marveled on air at his perfect English. In July, he sat down with Rogan, talking about everything from Gaza to the Covid vaccine, which Masad has refused to take.\n\nâ€œI tend to have a negative reaction to anyone forcing me to do something,â€ Masad said, prompting a â€œGood for youâ€ from Rogan. â€œIt was the same thing now with talking about Palestine and things like that. The more they come at me, the more I want to say things.â€\n\nHe appears now to have the capital, both financially and socially, to draw hard lines. â€œThere are a lot of people who care about the Palestinians but who are afraid to speak out publicly,â€ said Graham, who has also been an outspoken advocate for Palestine. â€œWhat Amjad and I have in common is that we donâ€™t have to worry about being fired if we do.â€\n\nMasad said Israelâ€™s Ministry of Education had reached out around 2016 to work with Replit. â€œWe got very close to a deal, but they were very overbearing,â€ he said, adding that the government had what he viewed as cumbersome requirements, like fining Replit if the service went down. The ministry did not respond to a request for comment.\n\nHe says he would never work with Israel now. â€œI think itâ€™s an illegitimate and criminal government,â€ he told me during our gun safety training. â€œI mean, [Benjamin] Netanyahu is a war criminal.â€\n\nWhen I pointed out that Saudi Arabia has its own abysmal human rights record, Masad drew a contrast.\n\nâ€œI just think about how Replit is going to be used. Like, Israel is actively committing genocide and ethnic cleansing, and if you sell to the government there, itâ€™s possible that theyâ€™re going to use it for that,â€ he said, pointing to the countryâ€™s use of Microsoft cloud services to track Palestiniansâ€™ phone calls. (After an investigation by The Guardian, Microsoft said it disabled the services that made the tracking possible in September. (opens in new tab))\n\nItâ€™s a careful, and conveniently self-serving, justification. This logic allows Replit to work with countries that Masad finds tolerable. Whether that line will hold as Replit scales is unclear.\n\nAfter the shooting range, we drove through a thick forest fog to the restaurant The Mountain House in Woodside. Over grilled venison, Masad talked about Replitâ€™s next challenge: expanding its user base from corporate clients to everyday users. This isnâ€™t essential â€” plenty of companies thrive selling enterprise software. But Masad wants Replit to be an engine for socioeconomic mobility around the world, letting anyone, anywhere, easily create apps and businesses.\n\nMasad acknowledged that if he succeeds â€” if Replit goes public and he becomes a billionaire â€” he will have the capital to make real change for Palestine, though heâ€™s light on details. â€œItâ€™s hard to plan for 20 years in the future,â€ he shrugged. â€œI just know that wealth is a prerequisite.â€\n\nMargaux MacColl can be reached at [emailÂ protected]",
    "readingTime": 16,
    "keywords": [
      "covid vaccine",
      "andreessen horowitz",
      "replitâ€™s multibillion",
      "silicon valley",
      "palestinian cause",
      "founder amjad",
      "human rights",
      "absolutely nobody",
      "terrorist sympathizer",
      "nearly decade"
    ],
    "qualityScore": 1,
    "link": "https://sfstandard.com/2026/01/07/called-terrorist-sympathizer-now-ai-company-valued-3b/",
    "thumbnail_url": "https://assets.sfstandard.com/image/994911177489/image_4e70jhqanh28v7hkicshnrsv1e/-FWEBP",
    "created_at": "2026-01-08T18:16:50.477Z",
    "topic": "tech"
  },
  {
    "slug": "hundreds-of-nonconsensual-ai-images-being-created-by-grok-on-x-data-shows",
    "title": "Hundreds of nonconsensual AI images being created by Grok on X, data shows",
    "description": "Sample of roughly 500 posts shows how frequently people are creating sexualized images with Elon Muskâ€™s AI chatbot\nNew research that samples X users prompting Elon Muskâ€™s AI chatbot Grok demonstrates how frequently people are creating sexualized images with it. Nearly three-quarters of posts collected and analyzed by a PhD researcher at Dublinâ€™s Trinity College were requests for nonconsensual images of real women or minors with items of clothing removed or added.\nThe posts offer a new level of detail on how the images are generated and shared on X, with users coaching one another on prompts; suggesting iterations on Grokâ€™s presentations of women in lingerie or swimsuits, or with areas of their body covered in semen; and asking Grok to remove outer clothing in replies to posts containing self-portraits by female users.\n Continue reading...",
    "fullText": "Sample of roughly 500 posts shows how frequently people are creating sexualized images with Elon Muskâ€™s AI chatbot\n\nNew research that samples X users prompting Elon Muskâ€™s AI chatbot Grok demonstrates how frequently people are creating sexualized images with it. Nearly three-quarters of posts collected and analyzed by a PhD researcher at Dublinâ€™s Trinity College were requests for nonconsensual images of real women or minors with items of clothing removed or added.\n\nThe posts offer a new level of detail on how the images are generated and shared on X, with users coaching one another on prompts; suggesting iterations on Grokâ€™s presentations of women in lingerie or swimsuits, or with areas of their body covered in semen; and asking Grok to remove outer clothing in replies to posts containing self-portraits by female users.\n\nAmong hundreds of posts identified by Nana Nwachukwu as direct, nonconsensual requests for Grok to remove or replace clothing, dozens reviewed by the Guardian show users posting pictures of women including celebrities, models, stock photos and women who are not public figures posing in snapshots.\n\nSeveral posts in the trove reviewed by the Guardian have received tens of thousands of impressions and come from premium, â€œblue checkâ€ accounts, including accounts with tens of thousands of followers. Premium accounts with more than 500 followers and 5m impressions over three months are eligible for revenue-sharing under Xâ€™s eligibility rules.\n\nIn one Christmas Day post, an account with more than 93,000 followers presented side-by-side images of an unknown womanâ€™s backside with the caption: â€œTold Grok to make her butt even bigger and switch leopard print to USA print. 2nd pic I just told it to add cum on her ass lmao.â€\n\nA 3 January post, representative of dozens reviewed by the Guardian, captioned an apparent holiday snap of an unknown woman: â€œ@grok replace give her a dental floss bikini.â€ Within two minutes, Grok provided a photorealistic image that satisfied the request. Other posts in the trove show more sophisticated employment of JSON-prompt engineering to induce Grok to generate novel sexualized images of fictitious women.\n\nThe data does not cover all such requests made to Grok. While content analysis firm Copyleaks reported on 31 December that X users were generating â€œroughly one nonconsensual sexualized image per minuteâ€, Nwachukwu said that her sample is limited to just more than 500 posts she was able to collect with Xâ€™s API via a developer account. She said that the true scale â€œcould be thousands, it could be hundreds of thousandsâ€ but that changes made by Musk to the API mean that â€œit is much harder to see what is happeningâ€ on the platform. On Wednesday, Bloomberg News cited researchers who found that Grok users were generating up to 6,700 undressed images per hour.\n\nNwachukwu, an expert on AI governance and a longtime observer of and participant in social media safety initiatives, said that she first noticed requests along these lines from X users back in 2023.\n\nAt the time, she said, â€œGrok did not oblige the requests. It wasnâ€™t really good at doing those things.â€ The botâ€™s responses began changing in 2024, and reached a critical mass late last year.\n\nIn October 2025, she noticed that â€œpeople were putting Halloween attire on themselves using Grok. Of course, a section of users realized we can also ask it to change what other people are wearing.â€ By yearâ€™s end, â€œthere was a huge uptick in people asking Grok to put different people in bikinis or other types of suggestive clothingâ€.\n\nThere were other indications last year of an increased willingness to tolerate or even encourage the generation of sexually suggestive material with Grok.\n\nIn August, xAI incorporated a â€œspicy modeâ€ setting in the mobile version of Grokâ€™s text-to-video generation tool, leading the Verge to characterize it as â€œa service designed specifically to make suggestive videosâ€.\n\nNwachukwuâ€™s data is just the latest indication of how the platform under Musk has become a magnet for forms of content that other platforms work to exclude, including hate speech, gore content and copyrighted material.\n\nOn Friday, Grok issued a bizarre public apology over the incident on X, claiming that â€œxAI is implementing stronger safeguards to prevent thisâ€. On Tuesday, X Safety posted a promise to ban users who shared child sexual abuse material (CSAM). Musk himself said: â€œAnyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content.â€\n\nNwachukwu said, however, that posts like those she has already collected are still appearing on the platform. Musk is giving â€œthe middle finger to everyone who has asked for the platform to be moderatedâ€, she said. The billionaire slashed Twitterâ€™s trust and safety teams when he took over in 2022.\n\nShe added that other AI chatbots do not have the same issues.\n\nâ€œOther generative AI platforms â€“ ChatGPT or Gemini â€“ they have safeguards,â€ she said. â€œIf you ask them to generate something that looks like a person, it would never be a depiction of that person. They donâ€™t generate depictions of real human beings.â€\n\nThe revelations about the nonconsensual imagery on X has already drawn the attention of regulators in the UK, Europe, India, and Australia.\n\nNwachukwu, who is from Nigeria, pointed to a specific harm being done in the posts to â€œwomen from conservative societiesâ€.\n\nâ€œThereâ€™s a lot of targeting of people from conservative beliefs, conservative societies: west Africa, south Asia. This represents a different kind of harm for them,â€ she said.",
    "readingTime": 5,
    "keywords": [
      "elon muskâ€™s",
      "dozens reviewed",
      "conservative societies",
      "creating sexualized",
      "illegal content",
      "sexualized images",
      "elon muskâ€™s ai",
      "posts",
      "users",
      "women"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/08/grok-x-nonconsensual-images",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c28224d5167ff631b57649d1421003b9fedcb61c/849_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f553c7772f5a6626b4e04c354f302495",
    "created_at": "2026-01-08T18:16:47.743Z",
    "topic": "tech"
  },
  {
    "slug": "musk-lawsuit-over-openai-forprofit-conversion-can-go-to-trial-us-judge-says",
    "title": "Musk lawsuit over OpenAI for-profit conversion can go to trial, US judge says",
    "description": "Judge says there is plenty of evidence to suggest OpenAIâ€™s leaders made assurances nonprofit structure would be...",
    "fullText": "Judge says there is plenty of evidence to suggest OpenAIâ€™s leaders made assurances nonprofit structure would be kept\n\nElon Muskâ€™s lawsuit against OpenAI is to go to trial after a US judge said there is plenty of evidence to support the billionaireâ€™s case.\n\nThe worldâ€™s richest man, who co-founded OpenAI, is suing the ChatGPT developer and its chief executive, Sam Altman, over claims its leaders violated the organisationâ€™s founding mission by shifting to a for-profit model.\n\nThe US district judge Yvonne Gonzalez Rogers in Oakland, California, told a hearing there was plenty of evidence that suggested OpenAIâ€™s leaders made assurances that its original nonprofit structure was going to be maintained.\n\nShe said there were enough disputed facts to let a jury consider the claims at a trial scheduled for March, rather than decide the issues herself. Rogers said she would issue a written order after the hearing that addresses OpenAIâ€™s attempt to throw out the case.\n\nThe court dispute comes amid a broader showdown over dominance in the market for generative artificial intelligence. Muskâ€™s xAI and its chatbot Grok are competing with OpenAI and other technology developers.\n\nMusk is seeking unspecified monetary damages from what he calls â€œill-gotten gainsâ€ by OpenAI.\n\nIn a statement after the hearing, OpenAI said: â€œMr Muskâ€™s lawsuit continues to be baseless and a part of his ongoing pattern of harassment, and we look forward to demonstrating this at trial.â€\n\nMuskâ€™s startup xAI did not immediately respond to a request for comment.\n\nSteven Molo, a lead trial attorney for the billionaire and xAI, said after the hearing: â€œWe look forward to presenting all the evidence of the defendantsâ€™ wrongdoing to the jury.â€\n\nMusk contends he contributed about $38m (Â£28m), roughly 60% of OpenAIâ€™s early funding, along with strategic guidance and credibility, based on assurances that the organisation would remain a nonprofit dedicated to the public benefit.\n\nThe lawsuit accuses OpenAI co-founders Altman and Greg Brockman of plotting a for-profit switch to enrich themselves, culminating in multibillion-dollar deals with Microsoft and a recent restructuring.\n\nOpenAI, Altman and Brockman have denied the claims, and have described Musk as â€œa frustrated commercial competitor seeking to slow down a mission-driven market leaderâ€.\n\nMicrosoft, which is also a defendant, urged Rogers to throw out Muskâ€™s claims against it. A lawyer for Microsoft said there was no evidence that the company â€œaided and abettedâ€ OpenAI.\n\nMicrosoft has been approached for comment.\n\nLawyers for OpenAI at the hearing asked Rogers to enter judgment against Musk, contending that he had not shown enough of a factual basis to sustain his allegations including fraud and breach of contract.\n\nOpenAI also contends that Musk failed to bring his allegations in a timely manner. The judge said the jury would be asked to weigh whether the lawsuit was filed outside the statute of limitations.",
    "readingTime": 3,
    "keywords": [
      "openaiâ€™s leaders",
      "muskâ€™s lawsuit",
      "look forward",
      "nonprofit structure",
      "evidence",
      "judge",
      "trial",
      "claims",
      "plenty",
      "assurances"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/08/elon-musk-openai-lawsuit-for-profit-conversion-can-go-to-trial-us-judge-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/1654c30ae4f690b50fd785a245977de867ed88f4/100_0_2999_2400/master/2999.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1ff8662fa8bbfe6a93cb9946ec31e0da",
    "created_at": "2026-01-08T18:16:47.371Z",
    "topic": "tech"
  },
  {
    "slug": "tamarind-bio-yc-w24-is-hiring-infrastructure-engineers",
    "title": "Tamarind Bio (YC W24) Is Hiring Infrastructure Engineers",
    "description": "We're looking for an Infrastructure Engineer to lead the scaling of our machine learning inference system. You'll be responsible for architecting and maintaining infrastructure that serves 150+ biological ML models, scaling our platform several orders of magnitude to meet rapidly growing demand.\nYouâ€™ll work closely with the founders to design to the constraints of customer needs, unpredictable workloads, and unique Bio-ML models. You'll work with Kubernetes and other tools to orchestrate containerized workloads, optimize resource allocation, and ensure high availability across our model serving infrastructure.\nMost importantly, you should thrive in a fast-paced startup environment where you'll wear multiple hats, learn new technologies quickly, and help solve novel technical challenges.",
    "fullText": "We're looking for an Infrastructure Engineer to lead the scaling of our machine learning inference system. You'll be responsible for architecting and maintaining infrastructure that serves 150+ biological ML models, scaling our platform several orders of magnitude to meet rapidly growing demand.\n\nYouâ€™ll work closely with the founders to design to the constraints of customer needs, unpredictable workloads, and unique Bio-ML models. You'll work with Kubernetes and other tools to orchestrate containerized workloads, optimize resource allocation, and ensure high availability across our model serving infrastructure.\n\nMost importantly, you should thrive in a fast-paced startup environment where you'll wear multiple hats, learn new technologies quickly, and help solve novel technical challenges. We value engineering judgment, problem-solving ability, and the capacity to build systems that can evolve with our growing needs.",
    "readingTime": 1,
    "keywords": [
      "you'll",
      "scaling",
      "models",
      "needs",
      "workloads",
      "infrastructure"
    ],
    "qualityScore": 0.55,
    "link": "https://www.ycombinator.com/companies/tamarind-bio/jobs/HPRZAz3-infrastructure-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/b2cd6c4a4519bdbf7c6808810d333ad3265ac57b.png?1764802923",
    "created_at": "2026-01-08T18:16:46.954Z",
    "topic": "jobs"
  },
  {
    "slug": "the-coolest-and-weirdest-gaming-tech-of-ces-2026",
    "title": "The Coolest And Weirdest Gaming Tech Of CES 2026",
    "description": "At the start of the year, you can always rely on the Consumer Electronics Show to be a hub for exciting innovations, bold prototypes, and downright weird ideas that aim to make life more convenient. While CES 2026 is (predictably) being dominated by AI shoehorned into various products this week, the show still has a few surprises up its sleeve. Between iterative gaming laptop upgrades for 2026 and flashy new OLED TVs, the event is also serving as a hub for interesting and weird technology.\nSome of this gear--like Razer's holographic AI companion tube--is already scheduled to be released later this year, while more experimental stuff, like brain-scanning headphones, are still a long way from being seen on store shelves. In case you couldn't make it to Las Vegas this year, here's a quick look at the technology that caught our eyes.",
    "fullText": "on January 8, 2026 at 6:36AM PST\n\nGameSpot may receive revenue from affiliate and advertising partnerships for sharing this content and from purchases through links.\n\nAt the start of the year, you can always rely on the Consumer Electronics Show to be a hub for exciting innovations, bold prototypes, and downright weird ideas that aim to make life more convenient. While CES 2026 is (predictably) being dominated by AI shoehorned into various products this week, the show still has a few surprises up its sleeve. Between iterative gaming laptop upgrades for 2026 and flashy new OLED TVs, the event is also serving as a hub for interesting and weird technology.\n\nSome of this gear--like Razer's holographic AI companion tube--is already scheduled to be released later this year, while more experimental stuff, like brain-scanning headphones, are still a long way from being seen on store shelves. In case you couldn't make it to Las Vegas this year, here's a quick look at the technology that caught our eyes.\n\nAsus and XReal have teamed up for a new set of extended reality glasses, and on paper, these have some seriously impressive tech inside. Scheduled to launch in the first half of 2026, the Asus ROG Xreal R1 features 240Hz micro-OLED 1080p lenses and a dock that lets you connect them to a console or PC via HDMI and DisplayPort.\n\nWhat's better than one 3K 16-inch OLED screen on a gaming laptop? Two 3K 16-inch OLED screens, of course. While this isn't the first time Asus has experimented with a multi-monitor display on one of its ROG laptops, this new take on the Zephyrus Duo looks like a wild approach to dual-screen gaming.\n\nHolograms make everything cooler, and Asus is leveraging this technology to create a seriously cool PC gaming case. The Asus ROG GM1000 can use its case fans to project holographic images, and users can upload their own GIFs and short MP4s to create custom effects.\n\nGameSir might be onto something, as the idea of a gaming controller with a dedicated steering wheel right in the center sounds like a fun idea. You've got all the inputs you'd require from modern gaming, a direct drive motor, and up to 65,000 levels of resolution for ultra-accurate steering, the company claims (via The Verge). Pricing and a release date have yet to be revealed.\n\nGameSir's other big controller reveal was the X5 Alteron, a Swiss Army knife of a peripheral designed for iPad, iPhone, Android, and Nintendo Switch. HyperX is helping develop it, and the modular system lets you customize the controller with various modules. This means that you can customize it extensively with different D-pads, thumbsticks, and buttons to create your dream controller.\n\nA gamepad that connects to a smartphone via its USB-C port, the 8BitDo FlipPad borrows heavily from the design of the classic Nintendo Game Boy. The company says it'll reveal more details on the Android and iOS controller ahead of its launch in Summer 2026.\n\nIt might look visually inspired by Nespresso coffee machines, but the new mid-tower case unveiled by CyberPowerPC at CES has an elegant quality. It has everything you'd expect--tempered glass panels, mesh ventilation, and ports--but the real showstopper here is a selection of knobs for controlling the LEDs on this sleek case.\n\n8BitDo makes some of the best controllers, and at CES 2026, it unveiled the 8BitDo Ultimate 3E wireless modular controller for Xbox Series X|S, Xbox One, PC, Apple devices, and Android. Just don't expect this to be a budget-friendly option, as the Ultimate 3E will retail for $150 at launch in Q2 2026.\n\nIf you're a fan of Kojima Productions--the studio headed by famed game developer Hideo Kojima--then you'll want to check out these new peripherals from Asus. This special-edition hardware features hand-drawn illustrations by Yoji Shinkawa--the art director for the Death Stranding games--and it'll launch on February 4.\n\nThe newly revealed Corsair Galleon 100 SD mechanical keyboard doesn't have a numpad, but it does have a built-in Elgato Stream Deck Plus. This part of the keyboard features 12 customizable buttons, a five-inch 720 x 1280 IPS screen, and rotary dials. It launches on January 29 and it's priced at $350.\n\nRazer's Project Ava is aiming to be a holographic AI desktop companion that can fulfill several roles. From lifestyle reminders to gaming wingman, the device will come with several AI personalities and is expected to launch within the first half of 2026.\n\nWe're skeptical about this concept for a \"non-invasive\" gaming headset that supposedly improves your skills in competitive games, but at least Neurable and HyperX's protoype looks like a comfy set of brain-scanning cans.\n\nUltrawide monitors have become a popular option over the years, but laptop users can't enjoy them on the go--unless they want to lug a spare monitor around. That's where this concept for a rollable screen comes in: Lenovo is courting \"athletes who need pro-level performance\" with its gaming laptop. The screen can unfurl to 16, 21.5, and 24 inches.\n\nHyperX isn't the only company with AI-powered headphones at CES 2026, as Razer also showed off its Project Motoko concept. The idea behind this wireless headset is that it uses a ton of tech--including two 4K cameras, a Qualcomm Snapdragon chip, near and far field microphones, and built-in AI--to serve a similar function to other AI wearables, like taking photos, translating foreign text, or conversing with an AI assistant.\n\nIt's not gaming tech, but this $399 ultrasonic chef's knife from Seattle Ultrasonics is the closest thing we have to owning a high-frequency blade in real life. Can it effortlessly cut through a Metal Gear mech? Probably not, but the vibrating piezoelectric ceramic crystals will let you slice through fruit and vegetables easily.\n\nWhile Nvidia didn't have a new GPU to show off this year, the company did reveal its DLSS 4.5 upscaling technology. The company claims it can dynamically boost performance in compatible games, enabling up to 240+ frames per second with path tracing on 50-series GPU cards.",
    "readingTime": 5,
    "keywords": [
      "inch oled",
      "asus rog",
      "gaming laptop",
      "controller",
      "launch",
      "technology",
      "screen",
      "holographic",
      "features",
      "create"
    ],
    "qualityScore": 1,
    "link": "https://www.gamespot.com/gallery/the-coolest-and-weirdest-gaming-tech-of-ces-2026/2900-7385/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1601/16018044/4632487-ces-2026.jpg",
    "created_at": "2026-01-08T18:16:45.694Z",
    "topic": "gaming"
  },
  {
    "slug": "perplexity-launches-free-ai-tool-for-law-enforcement-agencies",
    "title": "Perplexity launches free AI tool for law enforcement agencies",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/perplexity-launches-free-ai-tool-for-law-enforcement-agencies-93CH-4437888",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-08T18:16:45.423Z",
    "topic": "finance"
  },
  {
    "slug": "read-the-pitch-deck-a-y-combinatorbacked-startup-used-to-raise-36-million-to-bring-ai-agents-to-the-doctors-office",
    "title": "Read the pitch deck a Y Combinator-backed startup used to raise $3.6 million to bring AI agents to the doctor's office",
    "description": "Tivara raised a $3.6 million seed round, backed by Mischief VC, Day One Ventures, and Y Combinator. The startup builds AI agents for healthcare.",
    "fullText": "Tej Seelamsetty dislocated his shoulder in 2024.\n\nThe 29-year-old told Business Insider that he waited over an hour on the phone to book an appointment with an orthopedist, and then two weeks for insurance to approve his MRI scheduling.\n\nFrustrated with the pace of the healthcare system, Seelamsetty cofounded the AI agents startup Tivara with Aumesh Misra. The company promises to answer patient phone calls, handle scheduling and refills â€”Â and cut down the hours of grunt work that comes with a medical visit.\n\nTivara has raised a $3.6 million seed round, backed by Plaid CEO Zach Perret's Mischief VC, Day One Ventures, Y Combinator, and healthcare industry angel investors.\n\nBefore cofounding Tivara, Seelamsetty worked as head of growth for Fair Square, a technology-enabled Medicare brokerage.\n\n\"I saw a ton of back-and-forth between beneficiaries and insurance carriers,\" he said. \"There's just a ton of paper-pushing.\"\n\nSeelamsetty met his cofounder while studying computer science at Washington University in St. Louis. The duo called \"every single doctor we knew\" and asked to shadow their practices, he said.\n\nTivara focuses on large specialty medical groups with between 20 and 500 doctors. Its customers include the Los Angeles Cancer Network and Astera Customer Care.\n\nIt's one of many AI-assisted patient messaging startups. Seelamsetty said Tivara distinguishes itself by being administrative, not clinical. Doctors are left to sift through the these startups in an effort to identify which offer genuine productivity gains (and which could overcomplicate or add time).\n\nTivara now has five full-time employees and is using the funds to expand its team. The $3.6 million was over Seelamsetty's target, he said; they wanted to make room for more strategic investors.",
    "readingTime": 2,
    "keywords": [
      "phone",
      "insurance",
      "scheduling",
      "healthcare",
      "patient",
      "medical",
      "investors",
      "doctors",
      "startups",
      "tivara"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/tivara-y-combinator-healthcare-startup-raises-3-million-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/695ea85504eda4732f2ea691?width=1200&format=jpeg",
    "created_at": "2026-01-08T18:16:43.767Z",
    "topic": "finance"
  },
  {
    "slug": "investors-should-not-rely-on-the-ai-trade-to-power-gains-in-2026-according-to-a-12-billion-investment-chief",
    "title": "Investors should not rely on the AI trade to power gains in 2026, according to a $12 billion investment chief",
    "description": "Peter Boockvar cautioned investors against \"blindly\" relying on tech stocks to power their portfolios, and advised looking at other parts of the market.",
    "fullText": "Wall Street remains bullish on AI, but the investment chief of a $12 billion firm thinks investors need to be careful not to pin all of their hopes on the technology.\n\nPeter Boockvar, the chief investment officer of OnePoint BFG Wealth Partners, thinks greater opportunities lie outside of the AI trade despite the stellar gains it delivered for the market in 2025.\n\nMany of the tech sector's most dominant players, including Nvidia, Meta Platforms, and Microsoft, have stumbled out of the gate in 2026. Boockvar says the industry's previous growth isn't sustainable and that its days of dominance are numbered.\n\nIn his view, the AI trade won't function as the market-driving force that investors have come to know in recent years. While there will still be growth opportunities, being selective will be of much greater importance.\n\n\"Investors need to not just blindly rely on that AI tech trade as the leadership group, and understand that there are a lot of other parts of the market that can do well now.\"\n\nThe CIO said on CNBC that he believes market tides are slowly shifting in a direction that doesn't favor prominent AI stocks. In his view, the market has been showing signs of fatigue that some investors may be ignoring.\n\n\"I do think in 2026 the AI tech trade is losing some steam in terms of its dominance,\" he said. \"We've seen the market response to Nvidia's report a couple of months ago. We've seen the market punish Meta for its excessive spending.\"\n\nBoockvar pointed to the struggles of other top AI companies like Oracle, whose lackluster Q3 earnings prompted concerns of AI overspending, and also flagged CoreWeave, a stock that surged 90% in 2025 but still drew consistent concerns of excessive debt and potential lack of profitability.\n\n\"I think that entire trade is becoming more differentiated, that we've reached a point where investors are realizing they're going to be winners and they're going to be losers,\" Boockvar added.\n\nBoockvar highlighted surging capex in 2025 as part of his bearish thesis for this year, arguing that companies should diversify their spending beyond data centers.\n\n\"All the capex growth in 2025 was the data center building\" he said. \"Hopefully in 2026, with the tax incentives in terms of immediate expense, other parts of the economy can take that baton.\"",
    "readingTime": 2,
    "keywords": [
      "tech trade",
      "market",
      "investors",
      "growth",
      "we've",
      "investment",
      "chief",
      "greater",
      "opportunities",
      "meta"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-stocks-prediction-data-centers-capex-stock-market-outlook-2026-1",
    "thumbnail_url": "https://i.insider.com/695fc12704eda4732f2eb322?width=1200&format=jpeg",
    "created_at": "2026-01-08T18:16:43.421Z",
    "topic": "finance"
  },
  {
    "slug": "tailwind-lays-off-75-of-its-4person-engineering-team-citing-brutal-impact-ai-has-had-on-our-business",
    "title": "Tailwind lays off 75% of its 4-person engineering team, citing 'brutal impact AI has had on our business'",
    "description": "Tailwind's CEO said that while AI made the web tool more popular, it also led to cratering revenue and difficulty converting paid users.",
    "fullText": "Tailwind laid off 75% of the startup's engineering staff on Monday â€”Â and its CEO blames AI.\n\n\"75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business,\" CEO Adam Wathan wrote in a GitHub comment that has made waves in the tech community.\n\nTailwind, like many startups, has a small head count. In a podcast posted on X, Wathan said that the company had four engineers on staff. Now, there's one.\n\nWathan's post highlights the challenges that startups, which already face tough odds of success, can encounter as AI models grow more capable.\n\nThe CEO founded the web developer tool in 2017. Tailwind's model is free and open-source, with a paid \"pro\" tier driving the company's revenue. In his GitHub comment, Wathan wrote that AI was making Tailwind more popular, but slimming its base of paid customers.\n\nTraffic to Tailwind's online documentation has seen a 40% decrease, Wathan wrote. Those resources were where people learned about the paid tier, the CEO wrote, crushing its ability to make money. Revenue is down 80%, he added.\n\nThe remaining team after the layoffs is the three owners, one engineer, and one part-time employee, the CEO said. \"That's all the resources we have,\" he said.\n\nğŸ§ Recorded a new morning walk this morning, hard one to share because I'm sure people will want to roast me for it but have been transparent up until now so publishing it anyways. pic.twitter.com/lslaLp2gtf\n\nWathan said he spent the holidays forecasting revenue and realized that the situation was \"significantly worse than I realized.\" The decline in revenue has occurred over several years, Wathan said, but it was gradual. If nothing changed, Wathan said his forecasting showed that Tailwind would not be able to meet payroll in six months.\n\nThe layoffs were a \"brutal decision,\" Wathan said. \"If we didn't do it now, then we we not be able to give people generous severance packages,\" he said.\n\n\"I feel like a failure for having to do it,\" Wathan said. \"It's not good.\"\n\nTailwind is popular among developers, and Wathan's post sparked reactions from the tech community on social media, some of which blamed the CEO for the company's revenue decline.\n\nOne X user wrote that they had only received five promotional emails from Tailwind in 2025. \"We don't send enough email,\" Wathan responded. \"Definitely need to get better at it.\"\n\nAnother X user wrote that Tailwind relied on a business model of selling UI components, while free and AI-generated equivalents grew.\n\n\"Still to this day don't know what we should be pivoting to, so in the mean time it's only made sense to do what's at least working a little,\" Wathan responded.\n\nIn his podcast, Wathan said that 90% of people understood and didn't \"pile on,\" but others did. He carried the burden that, as an employer, the world \"hates you and thinks you're evil,\" he said.\n\nOthers voiced their support online. Dropbox and Groupon alum Josh Puckett called the podcast an \"incredibly raw, honest take from one of our industry's best on the realities of running a business in the midst of the creative destruction AI is bringing.\"\n\nAI's ability to summarize and extract information, sometimes without directing users to specific sites or documents, is threatening many businesses reliant on online traffic. The media industry is well aware of this, as a crop of startups has formed around the concept of \"Google Zero.\"\n\nThat's basically what happened to Tailwind. It needed traffic to convert free users into paying customers, its CEO said, and AI effectively crushed that traffic. Still, Wathan remains hopeful for the company's future.\n\n\"I'm still optimistic,\" he said in his podcast. \"My job requires me to be optimistic.\"",
    "readingTime": 4,
    "keywords": [
      "wathan responded",
      "tech community",
      "company's revenue",
      "podcast",
      "traffic",
      "business",
      "startups",
      "free",
      "online",
      "tailwind"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tailwind-engineer-layoffs-ai-github-2026-1",
    "thumbnail_url": "https://i.insider.com/695fd745832e0ef1ead767b1?width=1200&format=jpeg",
    "created_at": "2026-01-08T18:16:43.287Z",
    "topic": "finance"
  },
  {
    "slug": "gmail-is-getting-aipowered-search-and-proofreading-features",
    "title": "Gmail Is Getting AI-Powered Search and Proofreading Features",
    "description": "AI Inbox will summarize important information from your emails.",
    "fullText": "Google is adding a slate of AI features to Gmail that could save some of the hassle of searching for important information buried in messages and threads. Many users will soon see a more personalized inbox with AI-powered suggestions, summaries, and proofreading support. Plus, some AI functionality that was previously available only to paid subscribers will be rolling out to all Gmail users, including Help Me Write, AI Overviews for threaded emails, and Suggested Replies.\n\nGmail users will soon have an AI Inbox view with two sections. \"Suggested to-dos\" will show immediate action items found in your inbox, such as bills to be paid and appointments to be confirmed. The task will be bolded and followed by a summary and a link to the relevant email or thread. Below that, \"Topics to catch up on\" includes items that are less urgent (but still important), such as order status and event updates.\n\nAI Inbox is an optional toggle in the Gmail side panel. You won't see it immediately, thoughâ€”the feature is being made available to those in Google's Trusted Tester program before launching for users more broadly \"in the coming months.\"\n\nGoogle AI Pro and Ultra subscribers will also be able to get AI Overviews from natural language questions typed into the Gmail search bar (just like a Google search). Instead of a running standard keyword search and clicking through multiple message threads, you'll be able to ask things like â€œWho was the plumber that gave me a quote for the bathroom renovation last year?â€ and get a detailed summary of information pulled from emails in your inbox. The response will also provide citations to specific threads.\n\nFinally, Gmail will have a built-in, AI-powered proofreading feature that will check grammar, tone, and style and analyze your emails for clarity and structure. Similar to third-party tools like Grammarly, you'll see one-click suggestions for fixing typos, simplifying sentence structure, selecting improving word choice, and making writing more concise.\n\nLike AI Overviews, Proofread will be limited to paid subscribers. Note that these AI features are optional and can be disabled, and Google says it does not use personal information or content to train its AI models.",
    "readingTime": 2,
    "keywords": [
      "gmail users",
      "ai inbox",
      "threads",
      "subscribers",
      "emails",
      "search",
      "features",
      "soon",
      "ai-powered",
      "suggestions"
    ],
    "qualityScore": 0.9,
    "link": "https://lifehacker.com/tech/gmail-is-getting-personalized-ai-features?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEF67A86X7T9DJ2P23DNQG6F/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-08T18:16:41.939Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-fa-cup-thirdround-predictions-v-dj-and-producer-shadow-child",
    "title": "Sutton's FA Cup third-round predictions v DJ and producer Shadow Child",
    "description": "BBC Sport football expert Chris Sutton takes on DJ and producer Shadow Child - and AI - with his predictions for all 32 FA Cup third-round ties.",
    "fullText": "BBC Sport football expert Chris Sutton has made his predictions for all 32 FA Cup third-round ties.\n\nHe is up against DJ and producer Shadow Child, aka Simon Neale, and AI.\n\nDo you agree with their scores? You can choose who you think will win each tie, below.\n\nShadow Child is a Portsmouth fan who has fond memories of the FA Cup that go back much further than when Pompey won it in 2008.\n\n\"That was huge, and so was when we lost narrowly in the final two years later,\" he told BBC Sport.\n\n\"But my favourite FA Cup memory was actually 1992, when we had a run to the semi-finals and lost to eventual winners Liverpool in a replay.\n\n\"I was 15, stood on the Clock End at Highbury for the first of those games, and that is when I fully understood the emotion that goes with football.\n\n\"I'd been going to Fratton Park since I was five, but that was the moment for me. That's the power of the FA Cup, and a run like that can resonate with you for your whole life.\n\n\"The year we won it, all five games from round three to the final were 1-0 wins. You take them all, obviously, but most of those ties were not that glamorous.\n\n\"The really memorable game that year was our 1-0 win over Manchester United at Old Trafford. Rio Ferdinand ended up in goal when we scored our winner from the penalty spot, which sounds crazy talking about it now. Again, I will never forget it.\"\n\nThe AI predictions were generated using Microsoft Copilot Chat. We asked the tool to predict the score of each tie.\n\nThere are no replays. Games will be decided by extra time and penalties.\n\nGap = league places between the two teams\n\n5th in League Two v 23rd in Championship\n\nOxford must be short of confidence going into this one. They are in a relegation battle, have lost four of their past five games and are still without a manager after sacking Gary Rowett before Christmas.\n\nCraig Short is in interim charge and, like all teams fighting the drop, I'm sure Championship survival is his priority over the FA Cup.\n\nMK Dons boss Paul Warne is an old team-mate of mine from my village team, Horsford Under-12s, and he learnt a lot from playing alongside me.\n\nThey are going well under him in the league and I have got faith in Paul to deliver an FA Cup shock.\n\nSutton's prediction: 2-2 after extra time, MK Dons to win on penalties\n\nSimon's prediction: 1-2 after extra time\n\n24th in League One v 13th in League Two\n\nPort Vale are struggling and they are another team who have just changed their manager. This will be Jon Brady's first game in charge, after they sacked Darren Moore at the end of December.\n\nVale got a big win over Blackpool on New Year's Day but they have still got the worst home record in League One, with only two wins there all season.\n\nFleetwood knocked out another League One side, Luton, on penalties in round two which was a great result - so the Cod Army won't be afraid of Vale, either.\n\nShadow Child's prediction: 1-1 after extra time, Port Vale win on penalties\n\n4th in Championship v 15th in League One\n\nPaul Heckingbottom is doing a fine job at Preston but, with them chasing promotion, he is probably weighing up whether he wants another FA Cup run after his side reached the quarter-finals last year.\n\nWigan have come through two penalty shootouts to reach round three. Their boss Ryan Lowe will be desperate to get one over his former club but, even if Preston make changes, I still think they will edge this.\n\n9th in Championship v 17th in Premier League\n\nMoney-bags Wrexham have picked up a bit of form in the Championship, with one of my colleagues from the Monday Night Club, Conor Coady, their rock at the back.\n\nNottingham Forest got a huge win at West Ham on Tuesday and Sean Dyche will want to carry that momentum on here.\n\nI suspect this will be tight, because Wrexham are unbeaten in 10 games at home, but Forest should have a little bit too much quality.\n\nShadow Child's prediction: 3-2 after extra time\n\nEV Charger Points Stadium, 12:15 GMT\n\n18th in League Two v 12th in Championship\n\nI know Cheltenham aren't having a great time of it because one of their fans is a regular caller on 606.\n\nLeicester are having a poor season too, though, and their supporters were expecting a lot more from them following their relegation from the Premier League.\n\nThis is a must-win game for Foxes boss Marti Cifuentes, who is coming under a bit of pressure because his side are toiling in mid-table.\n\nCheltenham will be really up for this, but I think Cifuentes will get the result he needs.\n\n12th in Premier League v 10th in Premier League\n\nI'd like to think these teams will have a real go at the FA Cup this season, because neither of them have got relegation to worry about, but they both come into this tie off the back of poor results.\n\nThe Black Cats' defeat at Brentford was a very un-Sunderland like performance compared to what we've seen from them this season, while Everton will be very disappointed to have only drawn at home to Wolves.\n\nThe last time Sunderland reached the final, when they lost to Liverpool in 1992, they broke my heart on the way when they beat my Norwich side in the semi-final. I missed a great chance in that game too, when I ballooned a shot over the bar.\n\nIt still haunts me how we didn't make it to Wembley that year - we deserved to. Sunderland are due another FA Cup run because they have only made it to round four once in the past 10 years, but I don't think this is their year either.\n\nI can see this going to penalties, and Jordan Pickford will win it for the Toffees.\n\nSutton's prediction: 1-1 after extra time, Everton win on penalties\n\nShadow Child's prediction: I don't see this being a great game, more a battle of attrition. 1-0 after extra time\n\nAI's prediction: 1-2 after extra time\n\n14th in National League North v 13th in Premier League\n\nWhat a tie this is. My 606 co-host Robbie Savage built the foundations for this Macclesfield side and they have gone on an amazing run under John Rooney to get this far.\n\nIt started with a win over Atherton Laburnum Rovers in the second qualifying round in September.\n\nOne of their scorers that day was Ethan McLeod, who died in a car accident before Christmas on his way back from a game, which puts everything in perspective.\n\nThis would be the biggest shock in FA Cup history if Macclesfield won, because no sixth-tier side has ever beaten one from the top flight since the FA Cup started in 1871, but I don't think that will happen.\n\nPalace have not been in good form recently but they played well in their draw with Aston Villa on Wednesday when they defended strongly.\n\nThe holders are solid even when they don't fire up front, and they should win this pretty comfortably.\n\nShadow Child's prediction: I'd love this to be different because we all love a giant-killing, but I can't see it. 0-4\n\n20th in Premier League v 22nd in League Two\n\nWolves boss Rob Edwards is starting to get a tune out of his players and Mateus Mane is really shining for them.\n\nDoes Edwards change things up here, or does he look to build more momentum?\n\nThis is a local derby but he has played for both clubs so he will get what the tie is all about, and Shrewsbury don't really look like they are in the kind of shape to spring a surprise at Molineux, either.\n\nThey have not won any of their past eight league games and staying in the Football League will be the main thing on their manager Michael Appleton's mind.\n\nShadow Child's prediction: 2-1 after extra time\n\n2nd in National League v 21st in League One\n\nBoreham Wood are flying and Robbie Savage always tells me how strong they are - he really rates them.\n\nThey reached the fifth round in 2022 under Luke Garrard, when they lost at Everton, and I think their run will continue this year too.\n\nI know Garrard's focus might be on promotion to the Football League, because getting out of the National League is brutal, but his side are up against a Burton team who are bang out of form at the bottom of League One.\n\nWood will have to stop the top scorer in the FA Cup this season, Tyrese Shade, who has scored five goals in two games for Burton so far - but I am backing them to put Shade in the shade.\n\n19th in Premier League v 5th in Championship\n\nI have a feeling this will be quite close. Millwall are really well organised under Alex Neil and I am not surprised they are doing well this season.\n\nBurnley have started picking up a few draws, but they still haven't won since the end of October.\n\nThis could be the day that changes, although Scott Parker's side will have to work hard to finish Millwall off.\n\nSutton's prediction: 2-1 after extra time\n\nShadow Child's prediction: 1-1 after extra time, Burnley win on penalties\n\n23rd in League One v 15th in Championship\n\nSouthampton have dropped off after making a good start under Tonda Eckert. He won his first four games after replacing Will Still at the start of November, but has not won any of his past six matches.\n\nDoncaster are on a similar run in League One, taking one point from a possible 18, and with both teams in such poor form, it might take penalties to separate them.\n\nSutton's prediction: 1-1 after extra time, Southampton to win on penalties\n\nShadow Child's prediction: Putting our south-coast differences aside, Southampton will probably win... but come on Doncaster! 2-0\n\n9th in Premier League v 2nd in Championship\n\nIt will be interesting to see what Fulham boss Marco Silva does here, with his team on such a good run of Premier League results. I hope he goes strong, to try to keep their momentum going.\n\nSilva has good record in the FA Cup anyhow, reaching the quarter-final twice in the past three years. He has also never lost a third-round tie with any of the four English clubs he has managed, and I don't see that changing this weekend.\n\nMiddlesbrough got back on track with a big win over Southampton on Sunday but they hit a sticky patch over Christmas when their goals dried up and it is pretty obvious that their promotion bid will be the priority for their manager Kim Hellberg.\n\n3rd in Championship v 18th in League One\n\nIpswich have started to hit their stride in the Championship and have only lost one of their past eight games.\n\nLike Hellberg at Boro, I suspect Ipswich boss Kieran McKenna will make full use of his squad here but they should still have too much for a Blackpool side who are struggling in League One.\n\nIt is nice to be able to predict an Ipswich result again, and it would be good if their fans had something to cheer about after they had such a miserable time in the Premier League last season.\n\nMcKenna is such a good manager, I think they will get one of the automatic promotion spots, sadly. They won't win the FA Cup though!\n\n2nd in Premier League v 14th in League One\n\nManchester City have reached the final in the past two seasons and they are my pick to win the FA Cup this year. Pep Guardiola always takes the competition seriously and that won't change whatever happens in the title race.\n\nGuardiola's side have paid the price for not putting games to bed in the past few days and those dropped points are making things easier for Arsenal at the top of the table.\n\nI don't see Manchester City having any problems here, though, even if they field a second-string side.\n\nExeter City boss Gary Caldwell lifted the FA Cup in 2013 when he was part of the Wigan team that upset Manchester City in the final. What a great memory that must be for him, but his side are going out on Saturday.\n\n6th in Premier League v 15th in Premier League\n\nI just wonder how much Wednesday night's epic game against Leeds will have taken out of Newcastle, who have got the first leg of their Carabao Cup semi-final with Manchester City coming up next week too.\n\nThere was also plenty of late drama in Bournemouth's win over Tottenham, but my concern with the Cherries is more about the effect of Antoine Semenyo's departure, because it appears he has played his last game for them.\n\nNewcastle boss Eddie Howe does not have a great record against his old club in the Premier League, where he has not got the better of them in seven attempts, but he did beat them in the Carabao Cup in 2022.\n\nI was tempted to go for a Bournemouth win here, but I am not sure how many changes Andoni Iraola will make either.\n\nThe one thing I am sure of is that there will be a few goals flying in, because of the way both teams play. Let's go for another thriller, with a shootout to settle it.\n\nSutton's prediction: 3-3 after extra time, Newcastle to win on penalties\n\nShadow Child's prediction: 2-2 after extra time, Newcastle to win on penalties\n\n4th in League Two v 2nd in League Two\n\nThese teams meet each other again in the league next week, and I suspect the points will matter more to Swindon boss Ian Holloway and Salford manager Karl Robinson than this tie.\n\nSalford beat Swindon 3-2 here in September but Holloway's side have the best away record in the division and I'm going with them to nick it in extra time.\n\nSutton's prediction: 1-2 after extra time\n\nShadow Child's prediction: 1-0 after extra time\n\nAI's prediction: 2-2 after extra time, Salford win on penalties\n\n24th in Championship v 5th in Premier League\n\nIt is really sad to see what has happened at Sheffield Wednesday and there is no way for them to salvage their season now.\n\nBrentford are flying at the moment under Keith Andrews and they are another club who I'd love to see have a real go at the FA Cup this season.\n\nThe Bees have never got past the quarter-finals in their history, and have not even got that far since 1989. You only have to look at Palace last year to find a team winning it for the first time so it is definitely doable for them too.\n\n8th in Championship v 1st in Championship\n\nCoventry are having a little wobble. They are still top of the Championship, but Sunday's defeat at Birmingham means they have only one win in their past five matches.\n\nThat just makes me think Sky Blues boss Frank Lampard will rest players here, and it is a real opportunity for my old Norwich team-mate Mark Robins against his former club.\n\nRobins had that great run to the semi-finals with Coventry a couple of years back, and you can imagine he will be absolutely determined that Stoke get through this tie.\n\nAI's prediction: 2-2 after extra time, Stoke win on penalties\n\n10th in Championship v 6th in Championship\n\nWatford have really hit form and come into this on the back of four wins in a row.\n\nBristol City, in contrast, have been patchy but again I think both sides will make changes.\n\nIt finished 1-1 at Ashton Gate in November, and I'm going for the same scoreline again, with City winning on penalties.\n\nSutton's prediction: 1-1 after extra time, Bristol City to win on penalties\n\n6th in League Two v 14th in Championship\n\nCambridge are on a heck of a run, and have gone 14 games unbeaten in all competitions since the end of October.\n\nBirmingham, meanwhile, have been a bit flaky. Blues boss Chris Davies needed Sunday's win over Coventry because his side have not really got going this season.\n\nOn paper, this has the makings of a shock because Birmingham have not won many on the road, but I actually fancy my old club to go on a bit of a cup run this year, and they will start by giving Cambridge an education.\n\n12th in League Two v 2nd in National League South\n\nI was at Blundell Park when Grimsby knocked Manchester United out of the Carabao Cup in August, and what a night that was.\n\nNow the Mariners are trying to avoid being on the wrong end of a huge upset themselves but, again, home advantage will help.\n\nWeston-super-Mare are in the third round for the first time in their 138-year history, which is an amazing achievement, but their cup run ends here.\n\nTottenham Hotspur Stadium, 17:45\n\n14th in Premier League v 3rd in Premier League\n\nPoor old Thomas Frank. He looked so happy at Brentford but Spurs have a habit of turning happy managers into total miseries.\n\nHe really needs a win here, and a good run in the cup too, but when you compare the two teams, and the way they are playing, then there's only one winner here - and that's Villa.\n\nShadow Child's prediction: This is the kind of game Tottenham need, because there is less pressure on them. Villa are going more for the top four and Spurs could take this. 3-2\n\n19th in Championship v 8th in Premier League\n\nIt doesn't feel as if Liam Rosenior's appointment has been particularly welcomed by some Chelsea fans.\n\nThis is his first game in charge and he could really do with making a fast start to help win some of the doubters over.\n\nThere are tougher tests to come - like Arsenal in the first leg of the Carabao Cup semi-final next week - but I think he will get the result he wants here.\n\nThere will be a packed house at The Valley, with Charlton's biggest crowd for an FA Cup tie in 50 years, but the Addicks are not in great form and Chelsea's quality should see them through.\n\nShadow Child's prediction: It's been a turbulent week for Chelsea too, and again we will see a response. I always try to visualise things when I think about them, and when I pictured The Valley, I just saw Chelsea scoring! 1-3\n\n13th in Championship v 16th in Premier League\n\nLeeds have been terrific recently and, as regular readers will know, I am really pleased for their manager Daniel Farke and how he has changed the narrative about his future.\n\nI can see Farke making plenty of changes here because, while he would love a cup run, he knows there is still work to do to keep his side in the Premier League.\n\nThat's why I am going for Derby to cause an upset. They are improving all the time under John Eustace and while Leeds will be full of confidence off the back of the past few weeks, I am not sure they will maintain their intensity with a second-string side.\n\n21st in Championship v 1st in Premier League\n\nArsenal will definitely make changes here, but it won't make any difference.\n\nPortsmouth are in trouble at the bottom of the Championship and they look short of what is required there, let alone against the Premier League leaders - or even their reserves.\n\nShadow Child's prediction: I very reluctantly have to be realistic here - I hate to say it, but I would be really shocked if Arsenal didn't win. If we took them to penalties that would be incredible, but I don't think we will. It depends what team they put out, but whoever plays, it is going to be difficult for us.\n\nI can't make it to the game but I will be glued to the TV, and my dad will be there - he has been a season ticket holder at Fratton Park since 1967. 0-1\n\n7th in Championship v 20th in Championship\n\nHull are having a great season, while Blackburn are in serious danger of being relegated.\n\nIt is no surprise that Rovers are struggling because they just don't have the quality in their side.\n\nIt turns my stomach to see the state of my old club now compared to the way it was when I was there in the 1990s, because it is a shadow of its former self.\n\nSurvival is all Blackburn fans can hope for, while Hull supporters must be dreaming of a return to the Premier League. They are going to win this tie, too.\n\n22nd in Championship v 3rd in League Two\n\nNorwich are another of my old clubs who are fighting relegation, although at least Philippe Clement has picked up a few wins since he took charge in November.\n\nThe Canaries have lost their past couple of home games, to Watford and Stoke, but Clement has done really well to give them a chance of staying up. Now they need to spend in January, because he needs a bit of help.\n\nI am not sure Clement wants or needs an FA Cup run now but Norwich fans could do with a bit of cheer at Carrow Road.\n\nI am backing Norwich to win but I need to apologise to Walsall boss Mat Sadler anyhow. They were flying last season, but then he came on the Monday Night Club in January and he was one of the managers we cursed.\n\nWhoever came on, their results fell through the floor afterwards, so we were to blame for Walsall's slide down the table.\n\n16th in Championship v 11th in League One\n\nTwo wily old managers go head to head here.\n\nBetween them, Sheffield United's Chris Wilder and Mansfield's Nigel Clough have spent more than 50 years in the dug-out, and I have got a lot of respect for both of them.\n\nWilder has turned things around for the Blades after their dreadful start to the campaign and, while Clough has won his last three games with the Stags, I am going for Sheffield United to continue their improvement.\n\nShadow Child's prediction: 2-1 after extra time\n\n17th in Championship v 18th in Championship\n\nWest Brom have just sacked their manager Ryan Mason, so James Morrison is in charge for this one.\n\nThe Baggies could really do with a win but their form on the road is awful - they have lost 10 away games in a row.\n\nSwansea changed their manager recently too, with Vitor Matos replacing Alan Sheehan in November, and their season has been just as disappointing.\n\nWhile West Brom won 3-2 when these teams met at The Hawthorns in November, Swansea pinched a 1-0 win at Liberty Stadium on New Year's Day.\n\nI'm going for another close game this time.\n\nSutton's prediction: 0-0 after extra time, Swansea to win on penalties\n\n18th in Premier League v 11th in Championship\n\nThis is a must-win for West Ham boss Nuno Espirito Santo and, let's face it, they might sack him anyway even if he gets past QPR.\n\nI don't think home advantage helps the Hammers, who suffered a catastrophic defeat against Forest at the London Stadium on Tuesday. I'm not sure how many of their fans will turn up for this game, and the ones who do are not going to be in a good mood either.\n\nBut while West Ham have been very poor recently, they still have some good players and they should surely still see off a mid-table Championship team on their own patch.\n\nQPR have been knocked out in the third round of the FA Cup more times - 52 - than any other side since the current format of the competition started 100 years ago.\n\nI am going for them to suffer defeat number 53, and for Nuno to survive a little bit longer.\n\n7th in Premier League v 11th in Premier League\n\nBrighton have been quite erratic this season, and I have done really badly at predicting their results, but they have proved time and time again how dangerous they are.\n\nIt's a boost for United that Bruno Fernandes is fit again, but their draw with Burnley on Thursday was still a poor result.\n\nI know United fans love it when their side proves me wrong after I predict they will lose, but I can't see them doing that on Sunday.\n\nShadow Child's prediction: United have had an interesting week. I've gone for them to win because I am expecting a huge reaction from them and their fans at Old Trafford, but Danny Welbeck will nick one for Brighton. 3-1\n\nAI's prediction: 2-2 after extra time, United win on penalties\n\n4th in Premier League v 17th in League One\n\nBristol City fans will come to Anfield hoping for a repeat of their famous win here in the FA Cup in 2008, but I don't see another shock on the cards.\n\nLiverpool boss Arne Slot will have learnt his lesson about the cup after last season, when his side crashed out to Plymouth after he made 10 changes.\n\nSlot needs an FA Cup run this season, so I am sure he will not risk another upset here. If Liverpool were to lose this, he would be under serious pressure.\n\nI am just not convinced by the way his side are playing at the moment, and I don't think many Liverpool fans are either.\n\nEven so, they are at home to a League One side, and this should be a pretty routine victory.\n\nListen to the latest Football Daily podcast\n\nGet football news sent straight to your phone",
    "readingTime": 22,
    "keywords": [
      "fa cup",
      "premier league",
      "shadow child's",
      "west brom",
      "i'd love",
      "night club",
      "blues boss",
      "sutton's prediction",
      "ai's prediction",
      "cup semi-final"
    ],
    "qualityScore": 1,
    "link": "https://www.bbc.com/sport/football/articles/cvg5ldyz606o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/1e2f/live/b04ce430-ecaa-11f0-a422-4ba8a094a8fa.png",
    "created_at": "2026-01-08T18:16:40.419Z",
    "topic": "sports"
  },
  {
    "slug": "i-rarely-get-outside-scientists-ditch-fieldwork-in-the-age-of-ai",
    "title": "'I rarely get outside': scientists ditch fieldwork in the age of AI",
    "description": "In the race to embrace new technologies, some ecologists fear their field is losing touch with nature.",
    "fullText": "Tadeo Ramirez-Parada studied the timing of plant flowering for his PhD â€” but he didnâ€™t touch a single petal. Instead, he developed a machine-learning algorithm to analyse the digitized captions of one million herbarium specimens, which showed him how flowering times are changing with rising temperatures.\n\nRamirez-Paradaâ€™s work has helped to solve an important mystery in ecology â€” showing that as temperatures change, plants shift their flowering times to cope with the heat, rather than adapting through natural selection1. Yet his work so far has been almost entirely computer-based. â€œI have had to do very little experimental or field work,â€ says Ramirez-Parada, who did his PhD at the University of California, Santa Barbara.\n\nRamirez-Paradaâ€™s work is typical of a change that is reaching into every part of ecology. Whatever scientists are analysing â€” digitized specimens, images of the natural world, DNA samples, or data streaming in from sensors â€” many are doing it indoors.\n\nThe technologies are creating a world that can be monitored at times, places and scales that were previously unimaginable. We are moving towards the â€œfully automated monitoring of ecological communitiesâ€, wrote Marc Besson, a marine scientist at the Sorbonne University Ocean Observatory in Banyuls-sur-Mer, France, in a 2022 paper2.\n\nMany ecologists say this revolution offers huge potential for understanding the biodiversity crisis and discerning patterns of global change.\n\nBut some ecologists are dismayed. They feel that the discipline is losing intimacy with its subject matter. They argue that field experience is in decline, and that this loss could lead to error, bias and oversimplification of results.\n\nâ€œIf it becomes a world where you donâ€™t actually have to go out in order to become an ecologist, we kind of lose sight of what the actual world is like,â€ says Bill Sutherland, who studies conservation biology at the University of Cambridge, UK.\n\nLike scientists everywhere, ecologists are grappling with how to make the most of a torrent of data.\n\nNatural-history museums and herbariums around the world have digitized more than one billion specimens over the past few decades, some with accompanying DNA records.\n\nMeanwhile, citizen scientists and researchers alike have been feeding databases such as iNaturalist with hundreds of millions of observations, which are absorbed into the Global Biodiversity Information Facility (GBIF), a central database for natural history.\n\nThere is also a stream of data from sensors such as camera traps â€” which take pictures when activated by movement â€” microphones, animal-tracking devices, drones, satellites and DNA samplers.\n\nSuch sensors can run for years without intervention. Once, a remotely planted camera trap would eventually run out of power: now, the energy consumption of such a device is minimal and it can rely on solar or wind energy. Bandwidth is no longer an obstacle to data being transmitted 24 hours a day.\n\nAnd computer science is more than keeping up3. Artificial-intelligence systems are already identifying species from these data; they are also being used for more complicated tasks such as building species-distribution models and ancestry trees. Some ecologists predict that generative AI, which creates new content based on learning from huge data sets, will soon be able to make more complex models, leading the way to understanding ecological processes and forecasting how species will respond to environmental changes.\n\nThere are already at least 100 laboratories that would label their work as â€˜AI for natureâ€™, according to Tanya Berger-Wolf, a computational ecologist at the Ohio State University in Columbus.\n\nThe approach is starting to bear fruit. One European project, called CamAlien, is tracking invasive species using high-resolution cameras with machine-learning processing power, affixed to cars, boats and trains. As they speed along, they rapidly photograph the sides of roads and tracks, analyse the images in situ and upload alerts about alien invasive plants to a Europe-wide online map.\n\nThe system shows how, just in the past few years, new technologies combined with AI have â€œgone from mostly demonstrating potential to actually beginning to deliver real implementationsâ€, says Toke Thomas HÃ¸ye, an ecologist at Aarhus University in Denmark, who co-developed CamAlien. Some 16 European countries are trying out the technology to assess the distribution of invasive alien species.\n\nSimilarly, amid the steep declines in some insects, a consortium of researchers has finessed camera-trap technology, originally designed to spot mammals, so that it can identify and monitor insect species, which are much more numerous. Automated insect monitoring didnâ€™t exist five years ago, says HÃ¸ye. Thanks to developments in AI, scientists can distinguish between thousands of species.\n\nâ€œItâ€™s opening up a door to part of our natural world that is so much more diverse compared to what camera traps have been used for previously,â€ says HÃ¸ye. He and his group think that making insect monitoring easier and less labour-intensive will shed light on the state of insect populations around the globe.\n\nAnother group has deployed a system of microphones in search of a more detailed understanding of migration as birds fly across Europe from Norway to the Mediterranean coast of Spain. Known as the TABMON project, it is now streaming real-time soundscape data, day and night. An AI tool analyses the data and converts them into commonly used biodiversity indicators.\n\nâ€œHaving standardized ecological data on continental scales is extremely rare,â€ says Sarab Sethi, who studies ecosystem sensing at Imperial College London, and led the design of the microphones, â€œespecially when itâ€™s on the fine-scale temporal resolution that acoustics gives, across a wide range of species, and across multiple yearsâ€. The project has yet to report its first results.\n\nFew would dispute the benefits of more data and detail, but there is an ominous side effect, says Kevin Gaston at the University of Exeter, UK, who studies peopleâ€™s relationship with nature: field experience is on the wane.\n\nGaston and his co-author Masashi Soga, who studies the loss of humanâ€“nature interactions at the University of Tokyo, argued in a March 2025 paper4 that there has been an â€˜extinction of experienceâ€™: a widespread decline in fieldwork-based research and education, with knock-on effects on the depth of ecological understanding. They also flagged other dangers, such as reduced engagement with local communities â€” a practice known to be crucial for successful conservation.\n\nOthers have expressed concern about â€˜AI colonialismâ€™, a practice in which data, collected remotely in poorer countries, are siphoned off for analysis in well-equipped labs elsewhere.\n\nThere are few quantitative data available to support or challenge Gaston and Sogaâ€™s argument. One analysis5 of ecological studies published between 1980 and 2014 found that fieldwork-based studies decreased by 20% (as a proportion of the total), whereas modelling and data analyses increased by 600% and 800%, respectively. But these are relative changes, rather than absolute numbers, and the data set ends more than a decade ago.\n\nAnecdotally, however, Gaston and Sogaâ€™s paper struck a nerve. Since publication, a number of groups have cited it while warning that a lack of outdoor research is hindering studies on subjects ranging from solitary bees to dinosaur fossils.\n\nThereâ€™s also anecdotal evidence that more computer scientists have entered ecology, excited about what they can offer, but lacking field experience. That was the case for Berger-Wolf, considered a founder of computational ecology. She completed her PhD in theoretical computer science, but, being married to an ecologist, says she would chat to others in the ecology community and walk away â€œwith a feeling like, oh, thereâ€™s got to be a different way of answering this questionâ€.\n\nBerger-Wolf changed tack in 2003, and by 2005 was developing algorithms for dynamic network analysis to depict the social interactions of zebras in the Kenyan Serengeti. Field colleagues urged her to go and see her data but she always refused: â€œIâ€™m a city girl. And I donâ€™t like dust and bugs. And my answer was: â€˜no, my data looks beautiful on my screen.â€™â€\n\nSethi is another convert to ecology, having arrived in the field with an engineering background. In 2016, he decided to apply acoustic monitoring to ecology for his PhD â€” but the self-confessed metrophile quickly found himself out of his depth in a rainforest in Malaysian Borneo.\n\nâ€œI did what I now realize was the extremely dumb thing of trying to develop a new technology and for its first deployment to be in a tropical forest on the other side of the world,â€ Sethi grins. On the first night, he lay under a mosquito net in a pitch-dark hut on stilts, wide awake, while his ecologist colleagues dozed comfortably amid the sounds of the rainforest. He remembers thinking: â€œMy God, is this just like a joke thatâ€™s gone a bit too far?â€ Now he values his field experiences but works mostly from the lab.\n\nSome ecologists have gone the other way, coming in from outdoors to embrace big data. Laura Pollock at McGill University in Montreal, Canada, began her career as a field ecologist, first in the swamps of New Orleans, Louisiana, and then in isolated mountain regions in Australia. She saw a need for ecologists to do better data analysis, and now she uses machine learning to do predictive modelling of biodiversity across landscapes.\n\nâ€œI rarely get outside,â€ she says. â€œIâ€™m trying, but itâ€™s really hard because thereâ€™s so much technology creating so much data that we need people who have these data-science skills to analyse this.â€\n\nBut Besson has embraced technology without diminishing his hours in the field. He says that he is spending as much time outside as he did before automation arrived. â€œCameras and hydrophones can capture things in addition to my own eyes and ears, and they can stay in the field when I need to go back to the lab ... and when I need to sleep.â€\n\nThere are also many systemic forces driving ecologists indoors, argues Gaston.\n\nThereâ€™s a widespread perception that funding for field studies is in decline â€” although the data are not often differentiated into grants for fieldwork versus those for lab-based projects. Scientists who run long-term ecological studies, in particular, report that they struggle to find funding.\n\nOther contributing forces include the fact that research institutes are increasingly in urban areas; that more scientists have childcare responsibilities that deter them from doing long or far-flung trips; that many feel the need to reduce their carbon footprint and that others want to avoid â€˜helicopteringâ€™ in and out of a country to do fieldwork that local scientists could do.\n\nAnother major issue, says Sutherland, is that the fast track to career-boosting publications is to analyse, rather than physically collect, data.\n\nâ€œSupposing you do your PhD and you spend all your time doing fieldwork,â€ he says. â€œAnd the person sitting next to you has been extracting data [from day one]â€. After three years, he says, they might have published in increasingly highly ranked journals, while â€œyouâ€™re still in the Amazon catching fishâ€.\n\ndoi: https://doi.org/10.1038/d41586-025-04150-w\n\nRamirez-Parada, T. H. et al. Nature Ecol. Evol. 8, 467â€“476 (2024).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nBesson, M. et al. Ecol. Lett. 25, 2753â€“2775 (2022).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nReynolds, S. A. et al. Trends Ecol. Evol. 40, 191â€“207 (2025).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nSoga, M. & Gaston, K. J. Trends Ecol. Evol. 40, 212â€“215 (2025).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nRÃ­os-SaldaÃ±a, C. A., Delibes-Mateos, M. & Ferreira, C. C. Glob. Ecol. Conserv. 14, e00389 (2018).\n\nArticleÂ \n\n Google Scholar\n\nRafiq, K. et al. Trends Ecol. Evol. 39, 1059â€“1062 (2024).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nSethi, S. S. et al. Nature Ecol. Evol. 7, 1373â€“1378 (2023).\n\nArticleÂ \n PubMedÂ \n\n Google Scholar\n\nA framework for addressing racial and related inequities in conservation\n\nThe poetic life and death of a glow-worm\n\nPalaeometabolomes yield biological and ecological profiles at early human sites\n\nQuantifying the global eco-footprint of wearable healthcare electronics\n\nâ€˜A serious problemâ€™: peer reviews created using AI can avoid detection\n\nSeven feel-good science stories to restore your faith in 2025\n\nCMLR's goal is to advance machine learning-related research across a wide range of disciplines.\n\nCenter for Machine Learning Research (CMLR), Peking University\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...",
    "readingTime": 11,
    "keywords": [
      "dorigny campus",
      "campus unil",
      "ecol evol",
      "pubmed google",
      "google scholar",
      "trends ecol",
      "nature ecol",
      "camera traps",
      "wide range",
      "students split"
    ],
    "qualityScore": 1,
    "link": "https://www.nature.com/articles/d41586-025-04150-w",
    "thumbnail_url": "https://media.nature.com/lw1200/magazine-assets/d41586-025-04150-w/d41586-025-04150-w_51839806.jpg",
    "created_at": "2026-01-08T12:25:20.391Z",
    "topic": "tech"
  },
  {
    "slug": "openai-has-launched-chatgpt-health-should-we-trust-it",
    "title": "OpenAI has launched ChatGPT Health. Should we trust it?",
    "description": "The new feature helps users understand test results, get advice on diets and workouts, and prepare for doctorsâ€™ appointments.",
    "fullText": "Amid rising concerns about people relying on ChatGPT for medical advice, OpenAI made its most significant push yet into health care.\n\nThe company has launched a new feature called ChatGPT Health, which allows users in the U.S. to connect their medical records and data from wellness apps and wearable devices with ChatGPT. The tool is designed to help users understand test results, get advice on diets and workouts, and prepare for doctorsâ€™ appointments.\n\nMore than 230 million people globally ask ChatGPT health and wellness-related questions every week, according to the company. ChatGPT Health is designed in collaboration with physicians and will â€œhelp people take a more active role in understanding and managing their health and wellness,â€ the company said in a post.\n\nOpenAI said it will look to expand access to the feature in markets such as India, Brazil, Mexico, and the Philippines, where adoption is rising quickly. In these countries, overburdened health-care systems and unequal access to doctors are leading more people to turn to generative AI for guidance.\n\nâ€œWe do not have the people, the labor to deliver the care we should,â€ Jesse Ehrenfeld, chief medical officer at Aidoc, an Israeli medical technology company, said at the Consumer Electronics Show in Las Vegas. â€œThe only way out of this mess is digital and AI.â€\n\nResearchers, ethicists, and medical professionals have warned of the risks to users from biases and hallucinations in AI systems. Concern over the mental health harms that AI chatbots pose is growing. Metaâ€™s AI chatbots provided inappropriate advice to teenagers when talking about suicide and eating disorders, Common Sense Media, a nonprofit research organization, reported last year.\n\nThe family of a teenager who died by suicide has sued OpenAI and its chief executive officer Sam Altman, accusing them of wrongful death. The company said it has safeguards in place to help people, and that it continues to improve ChatGPTâ€™s training.\n\nThere is also the question of data privacy. Health data, particularly information related to mental disease and substance use, is sensitive, and its misuse can leave users vulnerable.\n\nWhile consumer awareness about privacy has increased, people generally do not know how their data is being used, including for marketing purposes or for tracking, Sam Siegfried, a partner at law firm McDermott Will & Schulte, told Rest of World on the sidelines of CES.\n\nâ€œThe person clearly trusts an app enough to give it their data,â€ he said. â€œBut they should understand what they are using the app for, and whether its data requests sync up with what they are using it for.â€\n\nOpenAI said ChatGPT Health â€œbuilds on the strong privacy, security, and data controls across ChatGPT with additional, layered protections designed specifically for health â€” including purpose-built encryption and isolation to keep health conversations protected and compartmentalized.â€\n\nThere is no stopping tech companies from entering the health sector.\n\nBesides turning to AI chatbots for health queries, people are also buying more wearable digital devices, including smartwatches, rings, bracelets, and glasses, to track physical activity, vital signs, and various physiological responses in real-time. They take this data to their doctors â€” or to ChatGPT â€” with questions on how to interpret it or use it to improve their health.\n\nâ€œHealth-related anxiety is real. AI is not as good as a doctor, but itâ€™s better than no care at all,â€ Ami Bhatt, chief innovation officer at the American College of Cardiology, said at CES.\n\nOpenAI isnâ€™t the only big tech company keen to tap the health-care sector.\n\nApple was among the first to offer health-tracking features in its smartwatch. There are millions of health-related videos on YouTube and TikTok, with nearly 60% of Americans watching health-related videos on YouTube.\n\nHealth is â€œone of the major use cases for Gemini,â€ Nichole Young-Lin, womenâ€™s health clinical lead at Google, said at CES.\n\nâ€œPeople are using generative AI as a health resource around the world,â€ she said. â€œThe patient-physician relationship is very important, but health-care access is not equal. Patients feel empowered with generative AI.â€",
    "readingTime": 4,
    "keywords": [
      "health-related videos",
      "chatgpt health",
      "medical",
      "users",
      "advice",
      "care",
      "designed",
      "doctors",
      "access",
      "health-care"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/openai-has-launched-chatgpt-health-should-we-trust-it/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/ChatGPT-Health.jpg",
    "created_at": "2026-01-08T12:25:18.460Z",
    "topic": "tech"
  },
  {
    "slug": "ai-and-the-next-economy",
    "title": "AI and the Next Economy",
    "description": "The narrative from the AI labs is dazzling: build AGI, unlock astonishing productivity, and watch GDP surge. Itâ€™s a compelling story, especially if youâ€™re the",
    "fullText": "The narrative from the AI labs is dazzling: build AGI, unlock astonishing productivity, and watch GDP surge. Itâ€™s a compelling story, especially if youâ€™re the one building or investing in the new thought machines. But it skips the part that makes an economy an economy: circulation.\n\nAn economy is not simply production. It is production matched to demand, and demand requires broadly distributed purchasing power. When we forget that, we rediscover an old truth the hard way: You canâ€™t build a prosperous society that leaves most people on the sidelines.\n\nIn The Marriage of Heaven and Hell, the visionary poet and painter William Blake (writing during the first Industrial Revolution) put the circulatory logic perfectly: â€œThe Prolific would cease to be prolific unless the Devourer as a sea received the excess of his delights.â€ In other words: Output has to be consumed. The system has to flow.\n\nToday, many AGI narratives assume that the â€œprolificâ€ can keep producing and the broad mass of customers (â€œthe devourerâ€) somehow continue to buy, even as more and more human labor is displaced and labor income and bargaining power collapses. Thatâ€™s not a future of abundance. Itâ€™s a recipe for a kind of congestive heart failure for the economy: Profits and capabilities accumulate in what should be the circulatory pump, while the rest of the body is starved.\n\nSo if we want an AI economy that makes society richer, we need to ask not just â€œHow smart will the models get?â€ and â€œHow rich will AI developers, their investors, and their immediate customers get?â€ but â€œHow will the value circulate in the real economy of goods and services?â€ Not â€œWhat can we automate?â€ but â€œWhat new infrastructure and institutions are needed to turn capability into widely shared prosperity?â€\n\nTwo versions of the future are often discussed as if they are separate. Theyâ€™re not.\n\nIâ€™m excited by the discovery potential of AI. It may help us solve problems that have defied us for decades: energy abundance, new materials, cures for diseases. As Nick Hanauer andÂ Eric Beinhocker put it so well, â€œProsperity is the accumulation of solutions to human problems.â€ That AI can grow the store of solutions to human problems is a wonderful dream, and it should be our goal to make it come true.\n\nBut discovery alone is not the same thing as economic value, and it certainly isnâ€™t the same thing as widely shared prosperity. Between discovery and economic value lies a long, failure-prone pipeline: productization, validation, regulation, manufacturing, distribution, training, and maintenance. The valley of death is not a metaphor; it is a bureaucratic, technical, and financial landscape where many promising advances go to die. And from that valley of death, the path follows either an ascent to the broad uplands of shared prosperity, or a shortcut to a dead-end peak of wealth concentration.\n\nIf AI accelerates discovery but doesnâ€™t accelerate diffusion, we get headlines and paper wealth, but broad-based growth takes much longer to arrive. We get a taller peak, not a wider plateau.\n\nThe distribution question begins with choke points. Who owns the discovery engines? Who controls access to compute, data, and the models themselves? Who captures the IP? Who has the channels to bring new capabilities to market? To what extent do incumbents and the moats they have built restrict innovation? Do government regulatory processes also speed up, or do they keep AI adoption at a glacial pace? Do those at the choke points use their market shaping power wisely? If those choke points are tight, the discovery economy becomes a kind of discovery feudalism: The breakthroughs happen, but the spillovers are limited, adoption is slow, and the returns concentrate.\n\nIf, on the other hand, the tools and standards of diffusion are broadly available, if interoperability is real, if licensing is designed for many routes to market, if regulatory processes can also be sped up with AI, then the discovery economy can become what we want it to be: a generalized engine of progress. Thereâ€™s a huge amount of work to be done here.\n\nMany of the questions are economic. If discovery becomes cheap, does the rest of the pipeline get cheaper, or does it get more expensive to compensate for other lost revenue? The happy dream is that a cancer vaccine becomes available at the marginal cost of production. The unhappy reality may be that the drug manufacturers conclude â€œWe have to price this high to make up for our losses from the existing drugs that people no longer need to buy.â€ Even in an age of cheap discovery, it is possible that some vaccines will still cost millions of dollars per dose and only be available to people who can afford them.\n\nThe other story is labor replacement. We are told that AI will substitute for a great deal of intellectual work, much as machines replaced animal labor and much of human manual labor. Businesses become more efficient. Margins rise. Output increases. Prices fall and spending power increases for those who are still employed.\n\nBut who are the customers when a large number of humans are suddenly no longer gainfully employed?\n\nThis is not a rhetorical question. It is the central macroeconomic constraint that much of Silicon Valley prefers not to model. You canâ€™t replace wages with cheap inference and expect the consumer economy to hum along unchanged. If the wage share falls fast enough, the economy may become less stable. Social conflict rises. Politics turns punitive. Investment in long-term complements collapses. And the whole system starts behaving like a fragile rent-extraction machine rather than a durable engine of prosperity.\n\nIn a 2012 Harvard Business Review article, Michael Schrage asked a powerful strategic question: â€œWho do you want your customers to become?â€ As he put it, the answer to that question is the true foundation of great companies. â€œSuccessful companies have a â€˜vision of the customer futureâ€™ that matters every bit as much as their vision of their products.â€\n\nIn the early days of mass production, Henry Ford reportedly understood that if you want mass markets, you need mass purchasing power. He paid higher wages and reduced working hours, helping to invent what we now call the weekend, and with it, the leisure economy. The productivity dividend was distributed in ways that created new customers.\n\nFordâ€™s innovation had consequences beyond the factory gate. Mass adoption of cars required a vast extension of infrastructure: roads, traffic rules, hotels, parking, gas stations, repair shops, and the entire social reorganization of distance. The technology mattered, but the complements made it an economy.\n\nSteven Johnson tells a related story in his book Wonderland. The preindustrial European desire for Indian calico and chintz helped catalyze modern shopping environments and global trade networks. But thereâ€™s even more to that story. When it became cheaper to make cloth, fashion, taste, and the democratization of status display became a larger part of the economy. The point is not â€œconsumerism is good.â€ The point is that economies grow because desires and capabilities change as the result of innovations, infrastructure, and institutions that allow the benefits to spread. New forms of production require new systems of distribution, experience, and exchange.\n\nAI is at that inflection point now. We may be building the engines of extraordinary productivity, but we are not yet building the social machinery that will make that productivity broadly usable and broadly beneficial. We are just hoping that they somehow evolve.\n\nThis failure of insight and imagination is the Achillesâ€™ heel of todayâ€™s AI giants. They imagine themselves as contestants in a race to be the next dominant platform, with the majority of the benefits going to whoever has the smartest model, the most users, and the most developers.Â This is not unlike the vision of Marc Andreessenâ€™s Netscape in the early days of the web. Netscape sought to replace Microsoft Windows as the platform for users and developers, using the internet moment to become the next monopoly gatekeeper. Instead, victory went to those who embraced the webâ€™s architecture of participation.\n\nNow, it is true that 30 years later, we are in a world where companies such as Google, Apple, Amazon, and Meta have indeed become gatekeepers, extracting huge economic rents via their control over human attention. But it didnâ€™t start that way. Amazon and Google in particular rose to prominence because they solved the circulation problem. Amazonâ€™s flywheel, in which more users draw in more suppliers with more and cheaper products, which in turn brings in more users, in a virtuous circle, is a great example of an economic circulation strategy. Not only did Amazon drive enormous consumer value, they created a whole new set of suppliers.\n\nSo too, Googleâ€™s original search engine strategy was also deeply rooted in the circulation of value. As Larry Page put it in 2004, â€œThe portal strategy tries to own all of the informationâ€¦.We want to get you out of Google and to the right place as fast as possible.â€ The companyâ€™s algorithms for both search and ad relevance were a real advance in market coordination and shared value creation. Economists like Hal Varian were brought in to design advertising models that were better not only for Google but for its customers. Google grew along with the web economy it helped to create, not at its expense. Yes, that changed over time, but letâ€™s not forget how important Googleâ€™s support for a circulatory economy was to its initial success.\n\nGoogle also provides a really good example of mechanism design to solve problems with rights holders that have economic lessons for today. When music companies sent takedown notices to YouTube for user-generated content that made unauthorized use of their IP, YouTube instead asked, â€œHow about we help you monetize it instead?â€ In the process it created a new market.\n\nThe extent to which Amazon and Google seem to have forgotten these lessons is a sign of their decline, not something to be emulated. It provides an opportunity for those (including Google and Amazon, if they recommit to their roots!) who are building the next generation of technology platforms. Build a flywheel, enable a circulatory economy. AI should not be enshittified from the beginning, prioritizing value capture over broadly based value creation.\n\nAn important lesson from the internet technology revolution of the 1990s and early 2000s is that decentralized architectures are more innovative and more competitive than those that are centralized. Decentralization creates value; centralization captures it. The PC decentralized the computer industry, ending IBMâ€™s chokehold on competition during the mainframe era. The new software industry exploded. Over the next few decades, as it became dominant, Microsoft recentralized the industry by monopolizing operating systems and office applications in the way that IBM had monopolized computer hardware. The personal computer software industry began to stagnate, until open source software and the open protocols of the internet undermined Microsoftâ€™s centralized control over the industry and ushered in a new era of innovation.\n\nThe tragedy began again, as those who had once flourished as internet innovators in turn began to prioritize control, raising moats and extracting rents rather than continuing to innovate, leading to todayâ€™s internet oligopoly. This, of course, is what allowed the current AI revolution to happen as it did. Google invented the transformer architecture, and then published it freely, but did not itself fully explore the possibilities because it was protecting an existing business model. So it was left to OpenAI to invent the future.\n\nHowever, the AI revolution has a significant difference from the early internet. The U.S.â€™s current set up of large, closed models, enormous data centers for model training, and a highly concentrated cloud market has echoes of central planning, in which a small cadre of deep pocketed investors choose the winners at the outset rather than discovering them through a period of intense market competition and finding product-market fit (which involves finding products and services that users not only want but are willing to pay for at less than the cost of production!).\n\nMarket competition is important to ensuring that the economy is not reliant on a handful of firms reinvesting their profits into production. When this becomes the case, circulation can get cut off. Profits stop being reinvested and instead become hoarded, trapped within the sphere of financial circulation, from dividends to share buybacks to more dividends and less and less to investment in fixed or human capital.\n\nIf we are to realize the full potential of AI to reinvigorate and reinvent the economy, we need to embrace decentralized architectures. This might involve the triumph of lower-cost open weight models that commoditize and decentralize inference, and it also certainly entails protocols and technical infrastructure that can reduce the inherent concentrating tendencies of economies of scale and other technological moats that make concentration a more efficient mode of production.\n\nCentralization is an advantage in a mature economy; it is a disadvantage when you are trying to invent the future. Premature centralization is a mistake.\n\nIf AI labs wish to be architects of a prosperous future, they must work as hard on inventing the new economyâ€™s circulatory system as they do on improving model capabilities. They need to measure success by diffusion, not just capability. They have to treat the labor transition as a core problem to be solved, not just studied. They have to be willing to win in the marketplace, not through artificial moats. That means committing to open interfaces, portability, and interoperability. General-purpose capabilities should not become a private toll road.\n\nCompanies adopting AI face their own challenges. Simply using AI to slash costs and turbocharge profits is a kind of failure. The productivity dividend should show up for employees not as a pink slip but as some combination of higher pay, reduced hours, profit-sharing, and investment in retraining. They must use the opportunity to reinvent themselves by creating new kinds of value that people will be eager to pay for, not just trying to preserve what they have.\n\nGovernments and society as a whole need to invest in the complements that will shape the new AI economy. Diffusion will be limited by the fragility of our energy grid, by bottlenecks in the supply of rare earths, but also by sclerotic approval processes for new construction or the approval of new innovations.\n\nGovernments must also develop scenarios for a future in which taxes on labor might provide a much smaller part of their income. Solutions are not obvious, and transitions will be hard, but if we face a future where capital appreciation is abundant and labor income is scarce, perhaps itâ€™s time to consider reducing taxes on labor and increasing those on capital gains.\n\nOver the next few months, we intend to convene a series of conversations and to publish a series of more detailed action plans in each of these areas. Let me know if you think you have ideas to contribute.\n\nWe can build an AI economy that concentrates value, hollows out demand, and forces society into a reactive cycle of backlash and repair. Or we can build an AI economy that circulates, where discoveries diffuse, where productivity dividends translate into purchasing power and time, and where the complements are built fast enough that society becomes broadly more capable.\n\nAI labs like to say they are building intelligence. They are making good progress. But if they want to build prosperity, they also need to discover the flywheel for the AI economy.\n\nThe prolific needs the devourer. Not as a villain, not as an obstacle, but as the sea that receives the excess, and returns it, transformed, as the next wave of demand, innovation, and shared flourishing.",
    "readingTime": 14,
    "keywords": [
      "choke points",
      "regulatory processes",
      "decentralized architectures",
      "widely shared",
      "productivity dividend",
      "software industry",
      "shared prosperity",
      "market competition",
      "labor income",
      "circulatory economy"
    ],
    "qualityScore": 1,
    "link": "https://www.oreilly.com/radar/ai-and-the-next-economy/",
    "thumbnail_url": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2026/01/Light-waves-of-a-prosperous-economy-1600x1244.jpg",
    "created_at": "2026-01-08T12:25:17.744Z",
    "topic": "tech"
  },
  {
    "slug": "google-and-chatbot-startup-characterai-are-settling-lawsuits-over-teen-suicides",
    "title": "Google and chatbot startup Character.AI are settling lawsuits over teen suicides",
    "description": "Google and Character.AI have agreed to settle multiple lawsuits over chatbot-linked teen suicides.",
    "fullText": "Google and chatbot-building startup Character.AI have agreed to settle multiple lawsuits from families whose teenagers died by suicide or hurt themselves after interacting with Character.AI's chatbots.\n\nThese negotiations are among the first settlements in lawsuits that accuse AI tools of contributing to mental health crises and suicides among teenagers.\n\nOpenAI is facing a nearly identical lawsuit over the death of a 16-year-old, while Meta has come under scrutiny for letting its AI have provocative conversations with minors. As these companies race to develop and monetize their AI chatbots, they're spending big to make large language models sound more friendly and helpful, and ultimately keep users coming back.\n\nIn October 2024, Florida-based Megan Garcia filed a lawsuit against Character.AI, alleging that the company, which lets people have in-depth and personal conversations with AI chatbots, was responsible for the death of her 14-year-old son, Sewell Setzer III. He had died by suicide months earlier.\n\nA Wednesday court filing in the Garcia case said that an agreement was reached with Character.AI, its founders, Noam Shazeer and Daniel De Freitas, and Google. In 2024, the search giant hired the founders of Character.AI, who were former Google employees, and paid for non-exclusive rights to use the startup's technology. The startup remains a separate legal entity.\n\nThe terms of the settlements were not immediately available\n\nThe defendants have also settled four other similar cases in New York, Colorado, and Texas, according to court documentsÂ from this week.\n\nMatthew Bergman, the legal representative of the families, along with Google and Character.AI, did not immediately respond to Business Insider's requests for comment.\n\nGarcia's suit said that the startup failed to implement safety guardrails to prevent her son from developing an inappropriate and intimate relationship with its chatbots. The suit claimed that he was sexually solicited and abused by the technology, and the chatbot did not respond adequately when Setzer began talking about self-harm.\n\n\"When an adult does it, the mental and emotional harm exists. When a chatbot does it, the same mental and emotional harm exists,\" Garcia told Business Insider in an interview last year. \"So who's responsible for something that we've criminalized human beings doing to other human beings?\"",
    "readingTime": 2,
    "keywords": [
      "emotional harm",
      "harm exists",
      "human beings",
      "chatbots",
      "startup",
      "mental",
      "garcia",
      "lawsuits",
      "families",
      "teenagers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-character-ai-settling-lawsuits-teen-suicides-new-york-texas-2026-1",
    "thumbnail_url": "https://i.insider.com/695f25cc832e0ef1ead7623c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.238Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-reshuffles-teams-to-bolster-github-as-ai-coding-and-agent-wars-heat-up",
    "title": "Microsoft reshuffles teams to bolster GitHub as AI coding and agent wars heat up",
    "description": "GitHub, the dominant software development platforms, is responding to the rise of AI coding services and AI agents",
    "fullText": "Microsoft wants to overhaul GitHub to compete with AI coding rivals and embrace AI agents, and the company has started reshuffling teams to make that happen, according to people familiar with the changes.\n\nGitHub is a leading software development platform that Microsoft acquired in 2018. GitHub had an early lead because of its popularity as a place to store code. Lately, though, GitHub has faced more competition from AI tools such as Cursor and Anthropic's Claude Code.\n\nMicrosoft in January 2025 formed a new group focused on building AI tools under ex-Facebook engineering boss Jay Parikh. The group, called CoreAI Platform and Tools, combined Microsoft's developer division, AI platform team, and GitHub.\n\nStill, Microsoft and GitHub have remained somewhat separate, and the company has been moving people and resources around over the past few months to better coordinate efforts such as sales, one of the people said. The latest change, happening this week, is moving a small group of Microsoft engineers over to GitHub.\n\nThe goal, the people said, is to better compete with AI coding tools that rival GitHub Copilot, while getting in the race to build AI agents and fulfill Parikh's vision to build an \"agent factory.\"\n\nIn an internal meeting late last year, Parikh spoke about needing to overhaul GitHub to compete with Cursor and Claude Code, according to audio reviewed by Business Insider.\n\n\"GitHub is just not the place anymore where developers are storing code,\" Parikh said at the time. \"We want it to be the center of gravity for all of AI-powered software development.\"\n\nMicrosoft wants GitHub's AI tools to be available wherever developers work, not just inside one app, to wants to make GitHub a kind of dashboard for managing multiple AI agents.\n\nThe latest changes are also part of what Parikh said would be new investment in improving the basic parts of GitHub. In the meeting, Parikh said those include making improvements to its GitHub Actions tool that automates building, testing, and deploying code, analytics and insights tools so teams can see how their code is performing, security for keeping the code safe, and making sure the company can meet local data storage rules to offer GitHub in new countries.\n\nHave a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "claude code",
      "software development",
      "overhaul github",
      "microsoft",
      "compete",
      "agents",
      "coding",
      "teams",
      "latest",
      "developers"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-github-reshuffle-ai-coding-agents-2026-1",
    "thumbnail_url": "https://i.insider.com/695c2f3b832e0ef1ead73181?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.155Z",
    "topic": "finance"
  },
  {
    "slug": "ai-has-been-all-about-gpus-thats-changing-fast",
    "title": "AI has been all about GPUs. That's changing fast.",
    "description": "Nvidia's $20 billion Groq acquisition shows the AI industry moving from training to inference, with speed and efficiency now crucial.",
    "fullText": "For years, Nvidia's rise has been synonymous with one idea: GPUs are the engine of artificial intelligence. They powered the training boom that turned large language models from academic curiosities into trillion-dollar ambitions. But Nvidia's $20 billion deal with Groq is an admission that the next phase of AI won't be won by GPUs alone.\n\nGroq makes a very different type of AI chip called a Language Processing Unit, or LPU. To understand why Nvidia spent so much, and why it didn't simply build this technology itself, you have to look at where AI workloads are heading. The industry is moving from training models to running them in the real world. That shift has a name: inference.\n\nInference is what happens after a model is trained, when it answers questions, generates images, or carries on conversations with users. It's becoming the dominant task in AI computing, and could dwarf the training market in the future, according to estimates recently compiled by RBC Capital analysts.\n\nThis matters because inference has very different needs than training. Training is like building a brain: it requires massive amounts of raw computing power and flexibility. Inference is more like using that brain in real time. Speed, consistency, power efficiency, and cost per answer suddenly matter far more than brute force.\n\nThat's where Groq comes in. Founded by former Google engineers, Groq built its business around inference-only chips. Its LPUs are designed less like general-purpose factories and more like precision assembly lines. Every operation is planned in advance, executed in a fixed order, and repeated perfectly each time. That rigidity is a weakness for training, but a strength for inference, where predictability translates into lower latency and less wasted energy.\n\n\"The tectonic plates of the semiconductor industry just shifted again,\" Tony Fadell, creator of the iPod and an investor in Groq, wrote on LinkedIn recently. \"GPUs decisively won the first wave of AI data centers: training. But inference was always going to be the real volume game, and GPUs by design aren't optimized for it.\"\n\nFadell calls this new breed of AI chips \"IPUs,\" or Inference Processing Units.\n\nTD Cowen analysts noted this week that Nvidia's embrace of not just an inference-specific chip, but a whole new architecture, shows how large and mature the inference market has become.\n\nEarlier AI infrastructure investments were made based on training-first buying decisions. The adage used to be \"today's training chips are tomorrow's inference engines,\" which favored Nvidia's GPUs, but that's no longer the case, the analysts added.\n\nInstead, there will be an explosion of different chips inside future AI data centers, according to Chris Lattner, an industry visionary who helped develop the software for Google's TPU AI chips, which Groq founder Jonathan Ross co-designed.\n\nThis move beyond GPUs is being driven by two trends that have been reinforced by Nvidia's Groq deal, Lattner told me this week.\n\n\"The first is that 'AI' is not a single workload â€” there are lots of different workloads for inference and training,\" he said. \"The second is that hardware specialization leads to huge efficiency gains.\"\n\nIn a 2024 story (that aged very well), Business Insider warned readers that inference could be a vulnerability for Nvidia as rivals looked to fill this strategic gap. Cerebras built massive AI chips optimized for speed, claiming memory bandwidth thousands of times higher than Nvidia's flagship GPU offering at the time. Google's TPUs are designed to efficiently run bespoke AI workloads at blazing speeds. Amazon developed its own inference chip, Inferentia. Startups like Positron AI argued they could beat or match Nvidia's inference performance at a fraction of the cost.\n\nSo Nvidia's deal with Groq can be seen as a preemptive move. Rather than letting inference specialists chip away at its dominance, Nvidia chose to embrace a fundamentally different architecture.\n\nFadell described the deal as a \"humble move\" by Nvidia CEO Jensen Huang. \"Many companies miss inflection points like this due to 'Not Invented Here- driven egos,\" Fadell added. \"Jensen doesn't; he saw the threat and made it work to his advantage.\"\n\nThe economics are compelling. Inference is where AI products make money. It's the phase that proves whether hundreds of billions of dollars spent on data centers will ever pay off. As AWS CEO Matt Garman put it in 2024, if inference doesn't dominate, \"all this investment in these big models isn't really going to pay off.\"\n\nImportantly, Nvidia isn't betting on a single winner. GPUs will still handle training and flexible workloads. Specialized chips like Groq's will handle fast, real-time inference. Nvidia's advantage lies in owning the connective tissue â€” the software, networking, and developer ecosystem that lets these components work together.\n\n\"AI datacenters are becoming hybrid environments where GPUs and custom ASICs operate side-by-side, each optimized for different workload types,\" RBC analysts wrote in a recent note, referring to Application-Specific Integrated Circuits such as Groq's LPUs.\n\nSome competitors argue the deal proves GPUs are ill-suited for high-speed inference. Others see it as validation of a more fragmented future, where different chips serve different needs. Nvidia's Huang appears firmly in the second camp. By licensing Groq's technology and bringing its team inside the tent, Nvidia ensures it can offer customers both the shovels and the assembly lines of AI.\n\nIndeed, Nvidia has developed an NVLink Fusion technology that lets other custom chips connect directly to its GPUs, reinforcing this mixed-hardware future, the RBC Capital analysts noted.\n\n\"GPUs are phenomenal accelerators,\" Andrew Feldman, CEO of Cerebras, wrote recently. \"They've gotten us far in AI. They're just not the right machine for high-speed inference. And there are other architectures that are. And Nvidia has just spent $20B to corroborate this.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "capital analysts",
      "high-speed inference",
      "rbc capital",
      "training",
      "chips",
      "deal",
      "chip",
      "workloads",
      "gpus",
      "nvidia's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-groq-gpus-ipus-hot-commodity-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/695eacd104eda4732f2ea721?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.152Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-senior-software-engineer-at-microsoft-my-ai-skills-have-helped-me-climb-the-ladder-in-my-career-heres-my-advice",
    "title": "I'm a senior software engineer at Microsoft. My AI skills have helped me climb the ladder in my career â€” here's my advice.",
    "description": "Nandita Giri is a senior software engineer with experience at Amazon, Meta, and Microsoft. She recommends job seekers spend an hour a day learning AI.",
    "fullText": "This as-told-to essay is based on a conversation with Nandita Giri, a 32-year-old software engineer at Microsoft in Redmond, Washington. It has been edited for length and clarity.\n\nMy journey began with problem-solving and math long before I knew I'd end up in Big Tech.\n\nI studied at the National Institute of Technology, Kurukshetra, in India. Amazon, Microsoft, and Google often scout talent from this school.\n\nAmazon hired me straight out of college, and I moved to Seattle in 2018. To get the job, there was a logical analysis test, and only a handful of us passed. Then came multiple interviews based on problem-solving. That's how my journey in tech began.\n\nI'm now a senior software engineer at Microsoft, and my AI skills are in high demand.\n\nWhen applying for roles at Amazon, it's not about solving problems as quickly as possible, but solving them optimally. You must carefully consider the issue so that the solution can scale and be easily maintained. Amazon has a set of leadership principles that play a key role in hiring decisions, and understanding these principles is just as important as your coding skills.\n\nOn my own time, I practiced on LeetCode, a platform for coding challenges, because I liked it, not because I was preparing for interviews. Over time, I developed a strong interest in AI.\n\nOnce I arrived at Amazon, I identified tasks and patterns that could be automated and suggested AI-based solutions to management, primarily focusing on internal workflow automation and data-driven decision support systems. That experience shaped my interest in building intelligent tools for enterprise use. Leadership gave me the green light to implement them, and I successfully integrated AI into our team's workflow.\n\nAfter working at Amazon for about four years, a recruiter from Meta contacted me on LinkedIn. I never aimed to work at Meta, but my skills opened up new opportunities. I wanted to work more deeply in applied AI, and Meta offered an opportunity to focus on building intelligent systems with large-scale data and infrastructure. It was a natural next step to grow in the AI space.\n\nI went through the interview process, secured the job, and began working at Meta in 2022.\n\nI was referred internally to Microsoft based on my work at Meta. I decided to move because I wanted to work on enterprise-focused AI products, such as Copilot, which aligns more closely with my long-term interests in building impactful tools for productivity and business transformation. I've been at Microsoft since 2023.\n\nThroughout my career, I've had multiple competitive opportunities. With each role change, my scope of responsibility, impact, and overall compensation increased.\n\nMost of what I know about AI, I taught myself. I spent hours outside work watching YouTube tutorials, reading blogs, and practicing. I started small, creating AI agents for personal tasks, like sending outreach emails. Tasks that used to take me a day or two can now be completed in under an hour.\n\nSeeing those results motivated me to keep learning. What started as a personal side project has now become a central part of my career.\n\nAmazon and Meta both incorporate fast-paced learning, but Meta's codebase is more straightforward. Facebook, Instagram, and WhatsApp are all built from a single repository, allowing you to understand the system more quickly.\n\nAmazon's codebase is huge, which makes the first year challenging, but the learning curve is worth it. Microsoft feels different altogether. It's more enterprise-focused, operating at a massive scale.\n\nAI excels at repetitive or static tasks, and our job is to monitor and guide it. Managing AI, I believe, is the future of software engineering.\n\nDemand for AI roles is skyrocketing, while traditional software engineering roles have shrunk over the last five years. Many of my friends who don't work in AI have struggled to land new offers.\n\nI recommend dedicating just one hour a day to learning AI. Within six months, you'll see real progress, and these skills will be critical for the next decade. For beginners, I recommend the following:\n\nIf I were to advise my younger self, I would tell her to focus less on perfection and more on making an impact, to take ownership early, speak up with confidence, and prioritize learning and growth over titles.\n\nLong-term growth comes from solving meaningful problems and maintaining resilience.",
    "readingTime": 4,
    "keywords": [
      "software engineer",
      "software engineering",
      "microsoft",
      "learning",
      "skills",
      "tasks",
      "based",
      "roles",
      "solving",
      "amazon"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/senior-software-engineer-microsoft-ai-not-threat-2026-1",
    "thumbnail_url": "https://i.insider.com/695e9d35832e0ef1ead7571e?width=1024&format=jpeg",
    "created_at": "2026-01-08T12:25:17.151Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-startup-founder-who-uses-ai-as-a-middle-manager-it-enables-my-junior-employee-to-produce-seniorlevel-work",
    "title": "I'm a startup founder who uses AI as a middle manager. It enables my junior employee to produce senior-level work.",
    "description": "Forage, an AI-powered startup, leverages AI as a middle manager to amplify its junior employee's productivity and learning with minimal supervision.",
    "fullText": "This as-told-to essay is based on a conversation with Charles Swann, a 44-year-old founder of an AI startup based in Boulder, CO. The following has been edited for length and clarity.\n\nI founded my startup, Forage, around 18 months ago. Besides myself, I have one full-time employee who has been with the company for eight months.\n\nMy business is in the marketing technology space, and I needed someone with a deep connection to modern culture and social media. So, I hired a 24-year-old growth and brand specialist from my neighborhood. She's a college graduate with less than two years of experience, whom I started mentoring.\n\nThe challenge with hiring someone more junior is that they often lack the skills to translate their intuition into a business strategy. But over the last six months, especially since the launch of Gemini 3, we've been able to leverage AI to significantly expand the capabilities of my junior employee.\n\nWe work in the marketing technology space, helping brands understand the trends happening on social media.\n\nMy junior employee has a very intuitive understanding of what influencer and brand relationships should look like, as well as how brands should present themselves on social media.\n\nWhen she first used AI in this role, she used ChatGPT to refine her product strategy. ChatGPT was great at taking her rough ideas, refining the concepts, and then writing out the details. As we began using Gemini more frequently, the role AI played in our workflow shifted from refining to co-creating product strategy.\n\nThe increased strategic capabilities in Gemini 3 are subtle, but they make a big difference because that strategic perspective is what young professionals often miss.\n\nMy growth and brand specialist had no prior experience writing a product requirements document before getting this role. Without AI, creating this document is a heavy lift. It's essentially the initial blueprint for a new product feature, translating a business idea into the technical instructions needed to build it.\n\nWriting this type of document for complex features typically would take a skilled product manager eight to 10 hours to get it right. With Gemini, my employee can do this in four to five hours.\n\nGemini 3 has been a significant step forward. Before using it, I had the idea that we should create 70% of the final product, and AI should generate 30%. Now, it's probably 40% us and 60% Gemini, simply because it's so good at expanding and expediting.\n\nWith younger career professionals, sometimes there's a light switch that clicks, and they know what it's like to be a leader, take ownership of something, and start running with their ideas.\n\nMy employee has really demonstrated that growth. This occurred at the same time she became more sophisticated in her use of AI.\n\nAI now serves as that middle layer, helping her level up the work she produces. I hesitate to say that AI alone has allowed me to have less supervision, but as she started getting more sophisticated in her use of the AI tool, I've spent less time reviewing in detail what she's generating and more time focused on the big-picture strategy questions.\n\nThere's always a risk in relying on AI to teach my employee how to gain years of experience in seconds. Hallucinations and feedback loops can occur if someone doesn't have the experience to know when to redirect.\n\nWhat I've done to help safeguard us is create a collection of prompt starters that include a detailed background on what our platform does, the features, and how to define it, which I can copy and paste into the chat. That's been a giant time saver and helps keep it focused on relevant context.\n\nHowever, I think running into possible mistakes or hallucinations is better than moving slowly. I would rather have those mistakes come up, and we have to course correct, than not be able to move at the pace we are.\n\nAI removes some of the traditional requirements around skills and expertise I need to see in candidates. It allows me to focus more on the raw intelligence, ambition, and drive.\n\nWith my company, I'm definitely bullish on the idea that brands will need the ability to authentically understand and reflect culture more than ever before, even in an AI-driven world, to survive. That type of intuitive knowledge resides with a different group of people than those my age, in their 40s, might be able to deliver.\n\nSo, I'm less concerned with whether my employee has been in the marketing industry for 10 years and more concerned with whether they have a deep understanding of the problem we're trying to solve.\n\nI believe this hiring mindset will only grow as AI continues to transform the workforce.\n\nDo you operate a tiny team and want to share your story? Please reach out to this editor, Agnes Applegate, at aapplegate@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "technology space",
      "marketing technology",
      "social media",
      "brand specialist",
      "junior employee",
      "product strategy",
      "less",
      "experience",
      "it's",
      "business"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/founder-hired-one-employee-uses-ai-as-middle-manager-2026-01",
    "thumbnail_url": "https://i.insider.com/6954148b832e0ef1ead6f50c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.035Z",
    "topic": "finance"
  },
  {
    "slug": "this-is-the-key-breakthrough-ai-still-requires-to-reach-superintelligence-according-to-those-building-it",
    "title": "This is the key breakthrough AI still requires to reach superintelligence, according to those building it",
    "description": "AI's memory capacity is still limited. Solving that may be the key to unlocking superintelligence.",
    "fullText": "In humans, working memory â€” our ability to hold and use information in everyday life â€” is closely linked to general intelligence.\n\nThat means the ability for AI to remember things could be the key to realizing aÂ superintelligent AI, a still theoretical version of AI that reasons as well or better than humans.\n\nOpenAI CEO Sam Altman thinks it's hard to predict just how intelligent AI can really be because the possibilities of memory retention are limitless.\n\n\"Even if you have the world's best personal assistant, they don't, they can't remember every word you've ever said in your life, they can't have read every email, they can't have read every document you've ever written, they can't be looking at all your work every day and remembering every little detail, they can't be a participant in your life to that degree. No human has like infinite, perfect memory,\" Altman said recently on the \"Big Technology\" podcast.\n\nAI, however, will definitely have the capacity for that, he said.\n\n\"Right now, memory is still very crude, very early,\" he said. Once AI is able to remember every granular detail of a user's life, including even the small preferences they didn't explicitly indicate, it will be \"super powerful,\" he said.\n\nAltman added that it's one of the future features he's most excited about â€” and he's not the only one.\n\nAndrew Pignanelli, the cofounder of The General Intelligence Company of New York, a company that builds AI agents for businesses, said that memory will become the biggest focus for AI companies in the coming year.\n\n\"It will become the most important topic discussed and recognized as the final step before AGI,\" Pignanelli wrote in a blog post. \"Every model provider will add and improve on memory for their apps after seeing OpenAI's success with ChatGPT memory (like Claude just did).\"\n\nPignanelli, however, said that the industry is still a long way from perfecting long-term memory.\n\n\"Larger context windows continue to improve things, as they allow more data to be passed into the context window, which allows the agent to better read parts of a large memory index,\" he wrote, in reference to the amount of information a large language model can process in a single prompt. \"Even then, though, the vast level of detail that we need to reach to consider something AGI requires memory architecture improvements.\"\n\nEven shorter-term episodic memory hasn't been fully solved yet, he said.\n\nSolving that memory problem is the ticket to turning AI from something that feels artificial to something that seems human, he said.\n\n\"Our systems today get the interaction part right. In terms of a Turing test for interaction, we're basically all the way there. But that's only half of what's needed to make a digital self,\" he wrote.\n\n\"The first AGI will be a very intelligent processor combined with a very good memory system,\" he said.",
    "readingTime": 3,
    "keywords": [
      "you've ever",
      "memory",
      "can't",
      "life",
      "detail",
      "humans",
      "ability",
      "intelligence",
      "it's",
      "intelligent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/superintelligent-ai-memory-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/694c74c404eda4732f2e1d59?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.019Z",
    "topic": "finance"
  },
  {
    "slug": "im-the-cmo-at-cluely-here-are-3-things-that-work-in-a-cold-reachout-and-what-definitely-doesnt",
    "title": "I'm the CMO at Cluely. Here are 3 things that work in a cold reach-out â€” and what definitely doesn't.",
    "description": "Daniel Min, the 22-year-old CMO at AI startup Cluely, warns against making the mistake that he used to make when networking.",
    "fullText": "This as-told-to essay is based on a conversation with Daniel Min, the chief marketing officer at viral AI \"cheating\" startup Cluely. He's based in New York City. The following has been edited for length and clarity.\n\nWhen I was 18, people would tell me to reach out to as many people as possible because they would view me as young and eager, and they would want to take a chance on me.\n\nSo I did a lot of outreach that looked like the kind of messages I receive now: \"Hey, I'm 18. I really admire the work that you do. Would love to just hop on a 15-minute chat with you and learn more about you.\"\n\nI'm not surprised I was ghosted most of the time.\n\nThere's a difference between wanting to hop on a chat and wanting a job from someone, but even the people I was just trying to chat with would not respond to me most of the time â€” and it's because of two main things.\n\nFirst, I realized that 15-minute chats are incredibly taxing and they ruin my workflow.\n\nThe second thing I realized is that when I would reach out for jobs, I would communicate that I didn't know what I was good at. I would say things like, \"I'm willing to do anything. I'm willing to work for free.\" Most of the time they would ghost me because my message showed that I had no idea what I was doing.\n\nI thought they would think I'm an eager young buck, who's just trying my best and who's willing to work hard. Now that I'm on the other side, I know that if I took a chance on that student who's willing to do anything, it would take me a lot of work to onboard them, and probably cause me more pain.\n\nI know that what they want out of this experience is to learn from me. So I would need to invest time, and I don't want to hire somebody and give them a poor experience.\n\nI used to think it was risk-free for someone to take a chance on me. But over time, I realized it's high risk because they're going to invest significant amounts of time.\n\nI have a soft spot for students who say that they're kind of lost and thinking about going into a startup. I'll always at least respond to them and say, \"hey, keep your head up, and try this thing.\"\n\nIf you want to send better outreach, first, tell me what you can do. Two, don't tell me what you want to learn; show me how you can help me. And three, if you don't have the skills yet, develop them and reach out again.\n\nI haven't responded to a lot of cold outreaches, but I'll take calls here and there, usually if it's through warm intros. I've told about 20 people that if they post every day for 60 days and send me a message, I will look over their content.\n\nNot a single person has ever done that. If they're not willing to put in 60 days worth of work into something they really care about, why is it worth it? I want to know that if I hop on a call with someone and give them advice, they're going to run far with it.\n\nThat's pretty much exactly what my editor did for me. He made a whole YouTube video demonstrating that he really cares and that he's watched every single one of my videos. I asked him to edit an example video and create a Google Doc of things he thinks I could film better, and he wrote a six-page document with timestamps on exactly what I should do.\n\nAfter that, I knew he was somebody who goes above and beyond. I hired him as my part-time editor at the time, and when I joined Cluely, one of my negotiation points was that he needed to be there with me. He's no longer my editor, but now he's a full-time employee at the startup. His journey is inspiring because he took a shot and showed he could provide value.\n\nMaybe someone isn't great yet when they reach out, but I want to know that if I put hours of effort into someone, they'll learn quickly and become great.\n\nIt's also effective to send links if you're doing a cold outreach. Someone could say they generated 50 million views and I wouldn't believe them. If they send me a link â€” which hopefully isn't malware â€” I will always click on it. If I was to look for a job right now, I would link everything I've done.",
    "readingTime": 4,
    "keywords": [
      "i'm willing",
      "who's willing",
      "someone",
      "learn",
      "it's",
      "they're",
      "startup",
      "chance",
      "outreach",
      "chat"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cmo-cluely-shares-what-works-cold-outreach-2026-1",
    "thumbnail_url": "https://i.insider.com/695d713404eda4732f2e950f?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.017Z",
    "topic": "finance"
  },
  {
    "slug": "retail-trader-hero-eric-jackson-says-investors-missed-the-big-takeaway-from-jensen-huangs-ces-talk",
    "title": "Retail trader hero Eric Jackson says investors missed the big takeaway from Jensen Huang's CES talk",
    "description": "Jackson said that faster chips aren't the big news from Jensen Huang's talk. Instead, the shifting nature of AI infrastructure is the key takeaway.",
    "fullText": "Nvidia CEO Jensen Huang kicked off the new year by giving investors some key product updates at CES 2026, drumming up fresh bullishness about the chip titan's business.\n\nAt the high-profile industry event, Huang revealed that production has begun on Rubin, its six-chip AI platform and the follow-up to the popular Blackwell architecture.\n\nThe talk generated a lot of buzz about the future of AI demand and Nvidia's business outlook, but hedge fund manager Eric Jackson argues that the most important takeaway from the talk is much bigger than innovations in chip tech.\n\nJackson, who helped spur rallies in several stocks followed by retail traders last year, said that he thinks many investors missed the key takeaway from the event. In his view, the most important thing isn't that faster or more advanced chips are coming; it is that AI is being built as a utility-scale infrastructure designed to operate for decades.\n\n\"Most people watched NVIDIA's CES keynote and heard 'faster chips,''\" he said. \"That wasn't the message. The real takeaway was this: AI factories are now being planned years in advance â€” at the land, power, and shell level.\"\n\nIn short, he thinks these statements mean that AI is being treated like electricity or telecom networks, a technology that will serve as a fundamental part of everyday life.\n\n\"The CES + JPM conversations made it clear: AI factories are being planned like utilities â€” not experiments,\" Jackson noted. \"That changes the slope.\"\n\nAs he sees it, the shifting industry landscape is poised to create more efficient AI production, which will lead to more demand for it through new use cases.\n\nThe investor highlighted the Jevons Paradox, an economic adage that argues that when a resource becomes more efficient to use, people consume it more, not less, despite assumptions. Economist William Stanley Jevons first introduced it in the 19th century to illustrate the growing dependence on coal.\n\n\"The market's obsession with 'capex slowing' misses the point,\" Jackson added. \"If inference + agents + long-context workloads are compounding, power becomes monetizable for longer, not shorter.\"\n\nJackson added that recent AI market developments are feeding his bullish thesis on small-cap tech stocks like Hut 8, IREN, and Cipher Mining, as all three stand to benefit from an economy increasingly powered by AI.\n\n\"Most investors still ask: 'Is AI demand peaking?'\" he wrote. \"The better question now is: Who can deliver reliable power and uptime as AI becomes permanent?\"",
    "readingTime": 3,
    "keywords": [
      "investors",
      "demand",
      "takeaway",
      "chip",
      "business",
      "industry",
      "event",
      "production",
      "talk",
      "argues"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-jensen-huang-eric-jackson-ces-rubin-ai-chips-infrastructure-2026-1",
    "thumbnail_url": "https://i.insider.com/695ec0f704eda4732f2eaa3c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.935Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-turning-expertise-into-a-commodity-box-ceo-says-theres-one-way-companies-can-stay-ahead",
    "title": "AI is turning expertise into a commodity. Box CEO says there's one way companies can stay ahead.",
    "description": "Box CEO Aaron Levie says AI will make expert knowledge widely available, leaving companies to compete on data, context, and how they deploy AI agents.",
    "fullText": "AI is rapidly turning expert knowledge into a commodity â€” and that shift will force companies to rethink what actually gives them a competitive edge, according to Box CEO Aaron Levie.\n\nIn a LinkedIn post this week, the cofounder and CEO of cloud-storage giant Box said that AI models are becoming capable of performing high-level knowledge work across nearly every profession, from law and medicine to strategy and scientific research.\n\nAs those tools evolve into autonomous AI agents, he said, expert intelligence will no longer be scarce.\n\n\"The question that we will have to wrestle with is, in a world where everyone has access to the same expert intelligence, how does a company differentiate?\" Levie wrote.\n\nLevie said the true advantage in an AI-driven economy won't come from having smarter models, but from giving those models access to the right proprietary information â€” the internal data, customer histories, workflows, decision-making patterns, and institutional knowledge that companies have built over time.\n\n\"Certainly it will be about how teams and employees use AI agents effectively,\" he wrote, \"but the ultimate force-multiplier will be the context that the agents get.\"\n\nThe idea is gaining traction across Silicon Valley.\n\nAndrej Karpathy, who was on the founding team of OpenAI, and Shopify CEO Tobi LÃ¼tke have said that \"context engineering\" â€” not clever prompts â€” is what makes AI useful at scale, while Google Cloud CTO Will Grannis and GitHub CEO Thomas Dohmke have said the real skill shift is toward designing systems, data, and workflows that give AI the right context to operate.\n\nBut getting the right context into AI systems is far from simple, Box CEO Levie told Business Insider last August.\n\nHe said that feeding agents too much information can cause what he calls \"context rot,\" where models become confused and focus on the wrong details.\n\nMaking sure AI agents receive precise, accurate, and task-specific context â€” without overwhelming them â€” is now one of the central challenges in building effective agent systems, he added.\n\nThe stakes are high. Companies that can capture, organize, and operationalize their internal knowledge will see major gains in productivity and output, Levie said in his LinkedIn post.\n\n\"Those that don't will find it harder and harder to serve customers competitively,\" he added.",
    "readingTime": 2,
    "keywords": [
      "box ceo",
      "expert intelligence",
      "context",
      "agents",
      "knowledge",
      "models",
      "systems",
      "shift",
      "linkedin",
      "across"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-agents-expertise-box-ceo-context-gives-companies-competitive-advantage-2026-1",
    "thumbnail_url": "https://i.insider.com/695e4b6f04eda4732f2e9dd0?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.931Z",
    "topic": "finance"
  },
  {
    "slug": "mckinsey-boss-says-there-are-3-skills-ai-models-cant-do-that-young-professionals-should-focus-on",
    "title": "McKinsey boss says there are 3 skills AI models can't do that young professionals should focus on",
    "description": "Bob Sternfels, global managing partner at McKinsey, identified three human skills that he said the AI models can't do.",
    "fullText": "Artificial intelligence is reshaping McKinsey's workforce, but the firm's top executive said there are still fundamental human skills that AI models can't do.\n\nBob Sternfels, global managing partner at McKinsey, talked about how AI is changing work at the firm during an appearance at the Consumer Electronics Show in Las Vegas on Tuesday.\n\nSternfels said that last year alone, embracing AI saved McKinsey 1.5 million hours in search and synthesis, work that he says AI models are great for. He also said AI agents, of which McKinsey has 25,000, excel at generating charts and that they've made 2.5 million of them in the past six months.\n\nWith agents taking over some of that work, he said consultants are now \"moving up the stack\" and tackling \"more complicated problems.\"\n\nGiven those changes, Sternfels said McKinsey looked at which skills new graduates will need in an AI-infused world from the perspective of large employers. He identified three: the ability to aspire, judgment, and true creativity.\n\n\"What can the models not do? Aspire. Set the right aspiration,\" he said. \"Do you go to low Earth orbit? Do you go to the moon? Do you go to Mars? That's a uniquely human capability.\"\n\nSternfels said you should look to build skills around aspiring and getting others to believe in those aspirations.\n\n\"There's no right and wrong in these models, and so how do you set the right parameters?\" he said, adding humans can build the skills to set the architecture based on factors like firm values and societal norms.\n\n\"The models are inference models â€” the next most likely step,\" Sternfels said.\n\nHumans, on the other hand, have an edge when it comes to \"orthogonal\" work, or the ability to think outside existing patterns and land on an entirely new approach.\n\nSternfels said AI adoption is also changing how companies look for talent, adding that where someone went to school should matter a lot less.\n\nFor someone with a tech background, he said, instead of looking at where they graduated from, prospective employers should look at their GitHub, a site engineers use to showcase their work.\n\n\"Let's actually get to the content,\" he said, \"and could that actually start meaning that a wider set of people can enter the workforce with different pathways?\"",
    "readingTime": 2,
    "keywords": [
      "models",
      "skills",
      "mckinsey",
      "look",
      "workforce",
      "human",
      "changing",
      "firm",
      "agents",
      "employers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-boss-shares-human-skills-ai-models-cant-do-2026-1",
    "thumbnail_url": "https://i.insider.com/695f03e104eda4732f2eaf20?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.809Z",
    "topic": "finance"
  },
  {
    "slug": "ai-chatbot-maker-anthropic-plans-to-raise-10bn-to-reach-350bn-valuation",
    "title": "AI chatbot maker Anthropic plans to raise $10bn to reach $350bn valuation",
    "description": "Startup founded by former OpenAI staff is aiming to more than double its annualized revenue run rate this year\nAnthropic is planning a $10bn fundraise that would value the Claude chatbot maker at $350bn, according to multiple reports published on Wednesday.\nThe new valuation represents an increase of nearly double from about four months ago, per CNBC, which reported that the company had signed a term sheet that stipulated the $350bn figure. The round could close within weeks, although the size and terms could change. Singaporeâ€™s sovereign wealth fund GIC and Coatue Management are planning to lead the financing, the Wall Street Journal reported.\n Continue reading...",
    "fullText": "Startup founded by former OpenAI staff is aiming to more than double its annualized revenue run rate this year\n\nAnthropic is planning a $10bn fundraise that would value the Claude chatbot maker at $350bn, according to multiple reports published on Wednesday.\n\nThe new valuation represents an increase of nearly double from about four months ago, per CNBC, which reported that the company had signed a term sheet that stipulated the $350bn figure. The round could close within weeks, although the size and terms could change. Singaporeâ€™s sovereign wealth fund GIC and Coatue Management are planning to lead the financing, the Wall Street Journal reported.\n\nInsatiable demand for AI and growing enterprise adoption has driven tech spending higher globally, pushing valuations of AI startups such as Anthropic to record levels, even as concerns about an AI bubble loom. OpenAI has been valued at $500bn.\n\nAnthropic last raised $13bn in a series F round that valued the company at $183bn, the company said in early September. The company had also hired a law firm to prepare for an initial public offering that could take place as early as 2026, according to the Financial Times.\n\nFounded in 2021 by former OpenAI staff, Anthropicâ€™s Claude models have built a strong reputation among developers, particularly for coding tasks.\n\nAnthropic is aiming to more than double its annualized revenue run rate this year, helped by rising adoption of its enterprise products.\n\nThe startup, which Amazon, Microsoft and Nvidia have poured billions of dollars into, declined to comment.",
    "readingTime": 2,
    "keywords": [
      "openai staff",
      "annualized revenue",
      "startup",
      "aiming",
      "rate",
      "planning",
      "round",
      "enterprise",
      "adoption",
      "valued"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theguardian.com/technology/2026/jan/07/ai-anthropic-funding-valuation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/af4915a6ba1caec426b216d6719dab95157d0ad3/432_0_4320_3456/master/4320.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7fb86e58a08effb9da383adb0cb247f6",
    "created_at": "2026-01-08T12:25:14.626Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tool-grok-used-to-create-child-sexual-abuse-imagery-watchdog-says",
    "title": "AI tool Grok used to create child sexual abuse imagery, watchdog says",
    "description": "Internet Watch Foundation warns Elon Musk-owned AI risks bringing sexualised imagery of children into the mainstream\nOnline criminals are claiming to have used Elon Muskâ€™s Grok AI tool to create sexual imagery of children, as a child safety watchdog warned the technology risked bringing such material into the mainstream.\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n Continue reading...",
    "fullText": "Internet Watch Foundation warns Elon Musk-owned AI risks bringing sexualised imagery of children into the mainstream\n\nOnline criminals are claiming to have used Elon Muskâ€™s Grok AI tool to create sexual imagery of children, as a child safety watchdog warned the technology risked bringing such material into the mainstream.\n\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n\nâ€œWe can confirm our analysts have discovered criminal imagery of children aged between 11 and 13 which appears to have been created using the tool,â€ said Ngaire Alexander, the head of the IWFâ€™s hotline, which investigates reports of CSAM from members of the public.\n\nX, Elon Muskâ€™s social media platform, has been deluged with images of women and children whose clothes have been digitally removed by the Grok tool, sparking public outcry and condemnation from politicians.\n\nMeanwhile, on Wednesday, the House of Commons women and equalities committee said it would no longer use X for its communications, saying it was no longer appropriate to do so given preventing violence against women and girls was among its key policy areas.\n\nThe decision marks the first significant move by a Westminster organisation to exit X in response to the misuse of Grok. While the decision concerned only the committeeâ€™s account, some individual members, including the Labour chair, Sarah Owen, have already stopped using X. Another, the Liberal Democrat MP Christine Jardine, said she was leaving the platform, calling the images generated by Grok â€œthe last strawâ€.\n\nAlexander said the imagery viewed by the IWF has been used to create even more extreme material â€“ known as Category A, which includes penetrative sexual activity â€“ using a different AI tool.\n\nâ€œWe are extremely concerned about the ease and speed with which people can apparently generate photo-realistic child sexual abuse material. Tools like Grok now risk bringing sexual AI imagery of children into the mainstream. That is unacceptable,â€ Alexander added.\n\nMuskâ€™s xAI, which owns Grok and X, has been approached for comment.\n\nDowning Street said â€œall options were on the tableâ€, including a boycott of X as ministers backed the UK regulator, Ofcom, to take action.\n\nOn Wednesday, the prime ministerâ€™s official spokesperson said: â€œX needs to deal with this urgently and Ofcom has our full backing to take enforcement action wherever firms are failing to protect UK users.\n\nâ€œIt already has the power to issue fines of up to billions of pounds and even stop access to a site that is violating the law.â€\n\nRequests for Grok to manipulate images of women to â€œput her in a bikiniâ€ continued to flood in on X on Wednesday. Despite the warnings of EU and UK regulatory action, there was no evidence that the platform had installed tighter safeguards, and pictures of teenage girls continue to be stripped down digitally at the request of X users, to show them in small, revealing items of underwear, or positioned in sexually explicit poses.\n\nSome users have demanded more extreme content, asking the chatbot to decorate bikinis with swastikas, or requesting alterations to photographs of women so they appear to be victims of abuse. The chatbot has obliged by adding cigarette burns, facial bruising, and blood to some images of women.\n\nThe UKâ€™s data watchdog â€“ the Information Commissionerâ€™s Office (ICO) â€“ said it had contacted X and xAI â€œto seek clarity on the measures they have in place to comply with UK data protection law and protect individualsâ€™ rightsâ€, adding people have â€œa right to use social media knowing their personal data is being handled lawfully and with respectâ€.\n\nX has said it takes action against illegal content, including child sexual abuse material, â€œby removing it, permanently suspending accounts, and working with local governments and law enforcement as necessaryâ€.",
    "readingTime": 4,
    "keywords": [
      "internet watch",
      "watch foundation",
      "uk-based internet",
      "foundation iwf",
      "iwf analysts",
      "material csam",
      "dark web",
      "web forum",
      "forum boasted",
      "social media"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/08/ai-chatbot-grok-used-to-create-child-sexual-abuse-imagery-watchdog-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ed942953d6d0fb965fb474a1e6a7011b5b5a396a/1066_0_6733_5386/master/6733.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4aad2f079a25c441af850b4fafa8513a",
    "created_at": "2026-01-08T12:25:14.625Z",
    "topic": "tech"
  }
]
[
  {
    "slug": "openclaw-opensource-personal-ai-agent-that-lives-on-your-machine",
    "title": "OpenClaw ‚Äì Open-source personal AI agent that lives on your machine",
    "description": "Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û  - GitHub - openclaw/openclaw: Your own personal AI assistant.",
    "fullText": "openclaw\n\n /\n\n openclaw\n\n Public\n\n Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û \n\n openclaw.ai\n\n License\n\n MIT license\n\n 206k\n stars\n\n 37.7k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n openclaw/openclaw",
    "readingTime": 1,
    "keywords": [
      "openclaw",
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/openclaw/openclaw",
    "thumbnail_url": "https://opengraph.githubassets.com/b2bb47983cd71c4a0446c45073347e53ea8782bc31c85c49442e517263d5b68b/openclaw/openclaw",
    "created_at": "2026-02-18T06:49:55.169Z",
    "topic": "tech"
  },
  {
    "slug": "tokenmeter-opensource-observability-layer-for-llm-token-costs",
    "title": "TokenMeter ‚Äì Open-source observability layer for LLM token costs",
    "description": "Open-source AI Cost Intelligence Platform ‚Äî smart routing, semantic cache, waste detection, prompt optimization - ATMAECHO/TOKEN-METER",
    "fullText": "ATMAECHO\n\n /\n\n TOKEN-METER\n\n Public\n\n Open-source AI Cost Intelligence Platform ‚Äî smart routing, semantic cache, waste detection, prompt optimization\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n ATMAECHO/TOKEN-METER",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/ATMAECHO/TOKEN-METER",
    "thumbnail_url": "https://opengraph.githubassets.com/eea39f4bd57d3211a06801e4ec71e4dd4ccd4c7a0d57e4621e6667d535594d22/ATMAECHO/TOKEN-METER",
    "created_at": "2026-02-18T06:49:54.633Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push",
    "title": "Microsoft says it is on pace to invest $50 billion in ‚ÄôGlobal South‚Äô AI push",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push-4510044",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1H06I_L.jpg",
    "created_at": "2026-02-18T06:49:48.045Z",
    "topic": "finance"
  },
  {
    "slug": "perplexity-says-its-moving-away-from-ads-and-betting-on-subscriptions",
    "title": "Perplexity says it's moving away from ads and betting on subscriptions",
    "description": "Perplexity, a San Francisco-based AI startup, emphasizes subscriptions and business sales, diverging from OpenAI's ad-centric approach.",
    "fullText": "Perplexity is going full steam ahead with subscriptions and business sales and plans to focus more on monetization than it has in the past, executives said at a roundtable with reporters on Monday.\n\nThe AI search startup, based in San Francisco, is the latest to publicly distance itself from putting ads in chatbot answers, with one executive saying it isn't exploring any ad deals at the moment. That's a contrast to OpenAI, which is going all in on ads, while arch-rival Anthropic has publicly touted the opposite.\n\nOne Perplexity executive said the startup is increasingly targeting large businesses. The company has only five people on its enterprise sales team and plans to ramp that up, the executive added. It also wants to serve high-powered users such as finance professionals, doctors, and CEOs.\n\nThe focus on selling to businesses positions Perplexity more directly as a competitor to startups like Glean, which lets employees search internal files and data more efficiently with AI.\n\nThe move comes amid some VC skepticism about Perplexity's prospects, with Silicon Valley investors voting it the company they'd most like to bet against in an informal poll at an AI conference last year, amid back-to-back funding rounds and talks of a wider AI bubble.\n\nPerplexity will focus more on revenue and revenue retention than on other metrics, such as the number of questions it answers, the executive said. Perplexity also pledged to keep allowing people to use the product for free, with rate limits.\n\nAt the roundtable, the company declined to share specific financials and shared that revenue grew 4.7 times last year. Perplexity generated over $150 million in annual recurring revenue by mid-last year, its head of communications Jesse Dwyer told Business Insider in August. It hit $200 million in ARR in October, Alex Heath of Sources reported.\n\nThe news comes after several months of the AI startup lying low, as Perplexity said in a press invite. The company's leaders said it was busy building and not focusing on AI-related drama.\n\nPerplexity had announced in 2024 that it would start experimenting with ads. That effort stalled, with the top ads leader, Taz Patel, quietly leaving last year. One consistent issue with ads in AI-generated answers is that users won't believe them, the Perplexity executive said.\n\nPerplexity also launched a product for enterprises in 2024 that uses internal and external data to generate research reports, among other features.",
    "readingTime": 2,
    "keywords": [
      "perplexity executive",
      "revenue",
      "focus",
      "startup",
      "sales",
      "plans",
      "roundtable",
      "search",
      "publicly",
      "businesses"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/perplexity-shifts-to-subscriptions-business-growth-2026-2",
    "thumbnail_url": "https://i.insider.com/6995107fa645d11881897c7b?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.037Z",
    "topic": "finance"
  },
  {
    "slug": "im-an-amazon-tech-lead-who-uses-ai-to-write-code-daily-theres-one-situation-i-hesitate-to-use-it-in",
    "title": "I'm an Amazon tech lead who uses AI to write code daily. There's one situation I hesitate to use it in.",
    "description": "Anni Chen says vibe coding is hard to resist. It speeds up her productivity, but she doesn't trust it blindly.",
    "fullText": "This as-told-to essay is based on a conversation with Anni Chen, who has worked at Amazon for about three-and-a-half years. It has been edited for length and clarity. Business Insider has verified her employment history.\n\nI'm a tech lead at Amazon responsible for deploying large-scale generative AI and LLM-driven systems. I focus on what we call memory, which powers personalization in generative AI experiences across Amazon.\n\nI vibe code every day. It's definitely a productivity boost.\n\nFor debugging or small tasks, I sometimes treat it like a lottery. Maybe it will produce something amazing. Sometimes, it does.\n\nVibe coding helps me brainstorm what the solution could look like, even if I don't adopt the final solution it proposes. Vibe coding also speeds up the time spent rewriting code when you realize a requirement wasn't covered.\n\nWhen I vibe code, it's always iterative. I give it the basic information it needs, it produces a version, then I check it ‚Äî similar to a code review with coworkers. I might say, \"You missed this part\" or \"You missed that part.\"\n\nThe AI sometimes fixes issues but introduces something new. You have to keep an eye on it.\n\nFor complex tasks, you need more double-checking. But even with the extra checking, it's still faster.\n\nI was working with a partner team and ran into complex locking issues. Without an LLM, I might have taken a day to research possible solutions, especially since it was relatively new to me.\n\nWithin 15 minutes, I brainstormed with the LLM about possible solutions. I pointed out weaknesses in its suggestions and asked it to improve them. In 15 minutes, I had a proposal to send to the team.\n\nTechnical knowledge helps ‚Äî you know what's a good solution and what's not. You know what tastes good, but you don't know what dishes are available. The LLM brings up all the dishes, and you choose.\n\nStill, I'm hesitant to use vibe coding directly in production.\n\nLLMs are very good at solving problems, but sometimes they make implicit assumptions you don't realize they're making. If you don't tell it explicitly, for example, that something needs to work for multi-threading, it might just produce the minimum version that works, but when it's large-scale or productionized, it could crash.\n\nNon-technical builders could tell an LLM to build something that handles millions of users. But if you have zero technical knowledge, it's hard to anticipate constraints upfront. If you don't tell the model the implicit assumptions, it won't respect those constraints. Later, you'll run into problems.\n\nNon-technical people might use the LLM to fix issues reactively. But technical people can anticipate constraints proactively and prevent problems in the first place.\n\nTechnical people also understand vibe-coded content better, and they're in a better position to understand what LLMs are good at and not good at. For example, knowing how they're trained and why they're weaker at certain tasks like math. That understanding helps you master them as tools.\n\nWhen you scale to one million or 100 million customers, systems need to be coded differently to handle that scale.\n\nInitially, leadership pushed vibe coding. Our team is a GenAI team, so we were naturally more receptive. In non-GenAI teams, engineers initially reacted like, \"No, I won't let AI do my job. I don't trust AI-generated code.\"\n\nAfter people tried it, attitudes shifted. People realized it's pretty good sometimes. Now it's more widely adopted.\n\nIt's very hard to resist vibe coding nowadays. If you're an employee, leadership sees the productivity boost and will encourage you to use it.\n\nWhen your peers are using it and coding faster, it's hard to resist. If you can't keep up with the speed, it becomes difficult to collaborate.\n\nEven if you resist, you still consume AI passively. AI comments are embedded in code reviews. So even if you don't vibe code directly, you're still interacting with AI outputs.\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "productivity boost",
      "implicit assumptions",
      "anticipate constraints",
      "technical knowledge",
      "vibe coding",
      "vibe code",
      "it's",
      "don't",
      "team",
      "they're"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-tech-lead-vibe-coding-daily-resist-anni-chen-2026-2",
    "thumbnail_url": "https://i.insider.com/698d593ce1ba468a96abe95e?width=1184&format=jpeg",
    "created_at": "2026-02-18T06:49:48.035Z",
    "topic": "finance"
  },
  {
    "slug": "openclaw-creator-slams-europes-regulations-as-he-moves-to-the-us",
    "title": "OpenClaw creator slams Europe's regulations as he moves to the US",
    "description": "Peter Steinberger, creator of OpenClaw, is moving to OpenAI in the US, citing Europe's strict regulations as a hurdle for tech growth.",
    "fullText": "In Europe, there's been a lot of handwringing over why there are very few large, successful tech companies in the region. Peter Steinberger, the creator of the agentic AI hit OpenClaw, has an answer.\n\nSteinberger was recently hired by OpenAI and is moving from Europe to the US. An Austrian by birth, he previously split his time between London and Vienna.\n\nOn X, a professor from a European university asked why Europe couldn't retain this tech talent.\n\nSteinberger replied that most people in the US are enthusiastic, while in Europe, he's scolded about responsibility and regulations.\n\nIf he built a company in Europe, he would struggle with strict labor regulations and similar rules, he added.\n\nAt OpenAI, he said most employees work 6 to 7 days a week and are paid accordingly. In Europe, that would be illegal, he added.\n\nThe most valuable company in Europe is Dutch chip-equipment maker ASML, valued at about $550 billion. In contrast, there are 10 US companies worth more than $1 trillion. Most of these are tech companies.\n\nIn 2024, a landmark EU report found that the region had fallen behind the US, particularly in innovation. It proposed a series of changes to tackle the problem, but by the end of 2025, few of the recommendations had been implemented.\n\nSteinberger said he was hopeful about EU INC, an effort to create a single corporate legal framework to make it simpler to run a business across the region.\n\nBut this seems to be \"fizzling out,\" he wrote on X. \"Watered down, too much egoistic national interest that ultimately hurts everyone.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "in europe",
      "tech",
      "region",
      "regulations",
      "steinberger",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openclaw-creator-slams-europe-regulations-move-us-openai-2026-2",
    "thumbnail_url": "https://i.insider.com/699511bee1ba468a96ac341a?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.030Z",
    "topic": "finance"
  },
  {
    "slug": "why-an-ai-video-of-tom-cruise-battling-brad-pitt-spooked-hollywood",
    "title": "Why an A.I. Video of Tom Cruise Battling Brad Pitt Spooked Hollywood",
    "description": "A 15-second clip created by an artificial intelligence tool owned by the Chinese technology company ByteDance appears more cinematic than anything so far.",
    "fullText": "It took only a 15-second clip of Tom Cruise and Brad Pitt duking it out on a crumbling rooftop at twilight to draw swift outrage, and sizable fear, from Hollywood over the last few days.\n\nThe widely circulated video was created by the Irish director Ruairi Robinson using Seedance 2.0, a powerful artificial intelligence video generation tool owned by the Chinese technology company ByteDance. It had plenty of the bells and whistles of a big-budget Hollywood film: sweeping camera angles, stunt choreography, crisp sound effects and haunting music.\n\nWith a two-sentence prompt and the click of a button, Seedance had produced a stunningly realistic result that was a drastic improvement over previously generated artificial intelligence videos, often shoddy clips known as A.I. slop. This video was so convincing that it drew near immediate condemnation from some of Hollywood‚Äôs top organizations and companies.\n\nRhett Reese, a scriptwriter known for his ‚ÄúDeadpool‚Äù films, said in an interview that the Cruise-Pitt video had sent a ‚Äúcold shiver‚Äù up his spine.\n\n‚ÄúFor all of us who work in the industry and devoted our careers and lives to it, I just think it‚Äôs nothing short of terrifying,‚Äù he said. ‚ÄúI could just see it costing jobs all over the place.‚Äù\n\nByteDance released Seedance 2.0 last week, nearly two months after a previous version had failed to prompt much anger. A news release from the company praised the updated tool‚Äôs ‚Äúphysical accuracy, realism and controllability,‚Äù which it said was suitable for the needs of ‚Äúprofessional-grade creative scenarios.‚Äù\n\n‚ÄúThe creation process,‚Äù the release went on, ‚Äúis more natural and efficient, allowing users to control their creations like a true ‚Äòdirector.‚Äô‚Äù\n\nUsers promptly flocked to the platform to spin up their own content. An alternate ending to ‚ÄúGame of Thrones‚Äù went viral, as did a video of the notoriously beefing rappers Kendrick Lamar and Drake burying the hatchet on ‚ÄúThe Tonight Show,‚Äù and one of Samara Morgan, the vengeful girl in ‚ÄúThe Ring‚Äù horror films, emerging from an old television set to pet a cat.\n\nRobinson himself posted additional videos, including of Pitt and Cruise battling a robot, and of Pitt sparring with a sword-wielding ‚Äúzombie ninja.‚Äù\n\nAt the same time, Hollywood was swift to sit up straight. Charles Rivkin, the chairman and chief executive of the Motion Picture Association, called on ByteDance to ‚Äúimmediately cease its infringing activity,‚Äù saying in a statement that Seedance 2.0 had engaged in the unauthorized use of copyrighted works on a ‚Äúmassive scale.‚Äù Human Artistry Campaign, a global coalition that advocates using A.I. ‚Äúwith respect for the irreplaceable artists, performers and creatives,‚Äù said on social media that unauthorized works generated by Seedance 2.0 violated the ‚Äúmost basic aspects of personal autonomy.‚Äù\n\nDisney, which in a watershed $1 billion deal last year agreed to allow OpenAI‚Äôs Sora users to generate video content with its characters, sent a cease-and-desist letter to ByteDance, accusing it of supplying Seedance with a ‚Äúpirated library‚Äù of Disney‚Äôs characters ‚Äî ‚Äúas if Disney‚Äôs coveted intellectual property were free public-domain clip art.‚Äù\n\nByteDance, which also owns TikTok and has been valued at $480 billion in the private markets, said in a statement that it respected intellectual property rights and was aware of the concerns about Seedance.\n\n‚ÄúWe are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,‚Äù the statement said.\n\nAs last year‚Äôs deal between Disney and OpenAI suggests, Hollywood has for years wrestled with how to manage the rapid growth of generative artificial intelligence. The concerns outlined by Reese echoed the Writers Guild strike in 2023, when for months thousands of union members demanded that studios institute guardrails protecting them from having their jobs or their intellectual property stolen by A.I. In the end, the group won guarantees that A.I. would not encroach on writers‚Äô credits and compensation.\n\nDuncan Crabtree-Ireland, the national executive director and chief negotiator of SAG-AFTRA, which represents actors and media artists, said its contracts had specific and enforceable rules about digital replication. The kind of material represented by the Cruise-Pitt battle, he said, ‚Äúcould not be produced by any of the signatories to our contracts ‚Äî the studios, the streamers ‚Äî without the specific, informed consent of those individuals.‚Äù\n\nAccording to Crabtree-Ireland, the real concern is that, even if videos generated by Seedance and other A.I. platforms ‚Äúare not malicious in intent,‚Äù they could ‚Äúreally violate someone‚Äôs right to control how their image, their likeness and their voice is used.‚Äù\n\nNot everyone is awed by Seedance‚Äôs latest technology. Heather Anne Campbell, an executive producer and a writer on the animated series ‚ÄúRick and Morty,‚Äù said her social media accounts last week had been inundated with Seedance-generated clips of anime, sci-fi and unlikely superhero battles. But she is not yet worried, she said, about losing her job to the technology.\n\n‚ÄúEverybody is, I think, swept up by the circus that came to town and is showing off,‚Äù she said. ‚ÄúI haven‚Äôt seen anything good yet. Nothing that has taken my breath away, nothing that is poignant, nothing that is provocative even. It‚Äôs all just garbage.‚Äù\n\nCampbell added that A.I. services like Seedance were at best ‚Äúaveraging machines,‚Äù and argued that the greatest art was never made quickly or impersonally.\n\nStill, some people working in Hollywood find it difficult to imagine that studios will not come to see A.I. as a cost-saving shortcut. ‚ÄúIt would be cheaper to have A.I. write a screenplay than it would be for me to write a screenplay,‚Äù Reese, the ‚ÄúDeadpool‚Äù writer, said. ‚ÄúI just know that in the back of my mind, that‚Äôs where the terror comes from.‚Äù\n\nFor Reese, a long-term answer to the unease that A.I. will reorder Hollywood could not come quickly enough.\n\n‚ÄúIf I could wave my magic wand and make A.I. go away, at least in the creative field,‚Äù he said, ‚ÄúI would absolutely wave the wand.‚Äù",
    "readingTime": 5,
    "keywords": [
      "artificial intelligence",
      "social media",
      "intellectual property",
      "hollywood",
      "users",
      "director",
      "technology",
      "generated",
      "videos",
      "executive"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/02/16/movies/tom-cruise-brad-pitt-artificial-intelligence-seedance.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/02/15/arts/15cul-seedance/15cul-seedance-facebookJumbo.jpg",
    "created_at": "2026-02-18T01:13:50.594Z",
    "topic": "tech"
  },
  {
    "slug": "opensource-game-engine-godot-is-drowning-in-ai-slop-code-contributions",
    "title": "Open-source game engine Godot is drowning in 'AI slop' code contributions",
    "description": "Projects like Godot are being swamped by contributors who may not even understand the code they're submitting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.pcgamer.com/software/platforms/open-source-game-engine-godot-is-drowning-in-ai-slop-code-contributions-i-dont-know-how-long-we-can-keep-it-up/",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/JVBMNVgT9xT6HFkTbDsqfe-1920-80.jpg",
    "created_at": "2026-02-18T01:13:50.433Z",
    "topic": "tech"
  },
  {
    "slug": "greedyphrase-121x-better-compression-than-gpt4o-tiktoken-6x-faster",
    "title": "GreedyPhrase ‚Äì 1.21x better compression than GPT-4o tiktoken, 6x faster",
    "description": "GreedyPhrase Tokenizer: Maximizing Effective Context via Greedy Phrase Compression - rayonnant-ai/greedyphrase",
    "fullText": "rayonnant-ai\n\n /\n\n greedyphrase\n\n Public\n\n GreedyPhrase Tokenizer: Maximizing Effective Context via Greedy Phrase Compression\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n rayonnant-ai/greedyphrase",
    "readingTime": 1,
    "keywords": [
      "greedyphrase",
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/rayonnant-ai/greedyphrase",
    "thumbnail_url": "https://opengraph.githubassets.com/f04c0e5ce1a7d98d91fdd3a7922d8f8c19141a7738e7dfa105d6dd4dd30a6f6f/rayonnant-ai/greedyphrase",
    "created_at": "2026-02-18T01:13:49.406Z",
    "topic": "tech"
  },
  {
    "slug": "practical-guide-to-building-reliable-ai-agents",
    "title": "Practical Guide to Building Reliable AI Agents",
    "description": "Design AI agents that are focused, safe, and reliable. Learn the principles, patterns, and techniques for building high-quality agent systems.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://docs.inkeep.com/guides/agent-engineering",
    "thumbnail_url": "https://docs.inkeep.com/api/docs-og/guides/agent-engineering/image.png",
    "created_at": "2026-02-18T01:13:49.347Z",
    "topic": "tech"
  },
  {
    "slug": "phison-ceo-consumer-electronics-firms-may-fail-by-2026-over-ai-memory-crisis",
    "title": "Phison CEO: Consumer electronics firms may fail by 2026 over AI memory crisis",
    "description": "This could go on for another 10 years.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.pcgamer.com/hardware/memory/many-consumer-electronics-manufacturers-will-go-bankrupt-or-exit-product-lines-by-the-end-of-2026-due-to-the-ai-memory-crisis-phison-ceo-reportedly-says/",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/54axypSSE53LrSGmYpfUDD-1920-80.jpg",
    "created_at": "2026-02-18T01:13:49.284Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-to-sell-meta-millions-of-chips-in-multiyear-deal",
    "title": "Nvidia to sell Meta millions of chips in multiyear deal",
    "description": "Nvidia on Tuesday said it has signed a multiyear deal to sell Meta Platforms millions of its current ‚Äåand future artificial intelligence chips, including central processing units that compete ‚Äåwith products from Intel and Advanced Micro Devices.  Nvidia did not disclose a value for the deal, ‚Äãbut said it includes its current Blackwell chips as well as its forthcoming Rubin AI chips.  It also includes standalone installations of its Grace and Vera central processors.",
    "fullText": "SAN FRANCISCO, Feb 17 (Reuters) - Nvidia on Tuesday said it has signed a multiyear deal to sell Meta Platforms millions of its current ‚Äåand future artificial intelligence chips, including central processing units that compete ‚Äåwith products from Intel and Advanced Micro Devices.\n\nNvidia did not disclose a value for the deal, ‚Äãbut said it includes its current Blackwell chips as well as its forthcoming Rubin AI chips. It also includes standalone installations of its Grace and Vera central processors.\n\nNvidia introduced those central processors, based on technology from Arm Holdings, as companions to its ‚ÄåAI chips starting 2023. ‚Å†But the announcement Tuesday signaled that Nvidia aims to push those chips for emerging fields such as running AI agents as ‚Å†well as into markets for processors used in workaday technical tasks such as running databases.\n\nNvidia's announcement also comes as Meta is developing its own AI chips and is in ‚Äãdiscussions with ‚ÄãGoogle about using that company's Tensor Processing ‚ÄãUnit chips, or TPUs, for ‚ÄåAI work.\n\nIan Buck, the general manager of Nvidia's hyperscale and high-performance computing unit, said that Nvidia's Grace central processors have shown they can use half the power for some common tasks such as running databases, with more gains expected for the next generation, Vera.\n\n\"It actually continues down that path and makes it an ‚Äåexcellent data center-only CPU for those high-intensity data ‚Äãprocessing back-end operations,\" Buck said. \"Meta has already had ‚Äãa chance to get on ‚ÄãVera and run some of those workloads. And the results ‚Äålook very promising.\"\n\nWhile Nvidia has never disclosed ‚Äãits sales to ‚ÄãMeta, it is widely believed to be among four customers that made up 61% of its revenue in its most recent fiscal quarter. Moorhead ‚Äãsaid Nvidia likely highlighted the ‚Äådeal to show that it has retained a large business with ‚ÄãMeta and is gaining traction with its central processor chips.",
    "readingTime": 2,
    "keywords": [
      "central processors",
      "chips",
      "deal",
      "announcement",
      "tasks",
      "databases",
      "nvidia",
      "meta",
      "processing",
      "vera"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-sell-meta-millions-chips-211720887.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/4ed50a54f6c60713ec79d92bee16049d",
    "created_at": "2026-02-18T01:13:47.592Z",
    "topic": "finance"
  },
  {
    "slug": "axios-reports-defense-secretary-hegseth-is-close-to-cutting-business-ties-with-ai-company-anthropic",
    "title": "Axios reports Defense Secretary Hegseth is ‚Äòclose‚Äô to cutting business ties with AI company Anthropic",
    "description": "A senior Pentagon official told Axios that Secy. Hegseth was ‚Äúclose‚Äù to cutting business ties with Anthropic due to CEO Dario Amodei‚Äôs concerns about some military uses of AI. ‚ÄúIt‚Äôs the cost of doing ...",
    "fullText": "A senior Pentagon official told Axios that Secy. Hegseth was ‚Äúclose‚Äù to cutting business ties with Anthropic due to CEO Dario Amodei‚Äôs concerns about some military uses of AI. ‚ÄúIt‚Äôs the cost of doing business with this particular government,‚Äù says tech journalist Kara Swisher.\n\nAfter being traded twice and waived, the longtime NBA veteran is returning to the Timberwolves.\n\nCyber stocks are getting crushed by the \"AI scare trade.\" That may create a buying opportunity, according to Wedbush analyst Dan Ives.\n\nThe WNBA and the players union are still working to reach a deal on a new CBA before the season starts.\n\nAfter a 23-0 start to the season, things have gone downhill fast for Arizona.\n\nTuesday was a marquee day at the Milan Cortina Olympics as the women's figure skating competition got underway.\n\nNvidia and Meta are expanding their chip deal to include millions of more AI processors.\n\nThe reigning U.S. champion, Glenn arrived in Milan with hopes of winning an individual gold medal. Just two fateful seconds on the ice in the women's short program likely destroyed that dream this year, and she knew it the moment it happened.\n\nFederal Reserve governor Michael Barr said Tuesday that the boom in artificial intelligence \"is unlikely to be a reason for lowering policy rates,\" disputing the idea of AI as a productivity accelerator that puts the Fed on a rate-cutting path.\n\nThe Rockies, Padres, Giants, Astros and Phillies make up the bottom tier of our 2026 rankings.\n\nThe S&P 500 was on track for double-digit earnings growth, with more than half of companies having reported Q4 results so far.",
    "readingTime": 2,
    "keywords": [
      "business",
      "deal",
      "season",
      "women's",
      "milan"
    ],
    "qualityScore": 0.85,
    "link": "https://www.yahoo.com/news/videos/axios-reports-defense-secretary-hegseth-033745058.html",
    "thumbnail_url": "https://s.yimg.com/os/en/cnn_videos_177/1b16bd67aa16f2e14e8f74dec3bf61b9",
    "created_at": "2026-02-18T01:13:46.771Z",
    "topic": "news"
  },
  {
    "slug": "investor-dan-ives-says-the-tech-selloff-that-has-been-spooking-markets-is-actually-a-generational-opportunity-to-get-in",
    "title": "Investor Dan Ives says the tech selloff that has been spooking markets is actually a ‚Äògenerational opportunity‚Äô to get in on the action",
    "description": "Investors are drawing their battle lines as AI sorts tech companies into winners and losers.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/17/investor-dan-ives-markets-tech-selloff-opportunity-investors-rebound/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2260936428-e1771346957865.jpg?resize=1200,600",
    "created_at": "2026-02-18T01:13:43.913Z",
    "topic": "finance"
  },
  {
    "slug": "the-irish-have-taken-a-liking-to-ai-japan-not-so-much",
    "title": "The Irish have taken a liking to AI. Japan, not so much.",
    "description": "AI usage among workers shows Ireland leading with high adoption, while Japan lags. Personal use outpaces professional in most regions.",
    "fullText": "Indeed survey data paints a stark picture of uneven AI engagement across advanced economies.\n\nThe chart below shows a clear frontrunner: Ireland stands out, with roughly seven in ten workers using AI at least monthly for work, followed by Australia, Germany, and North America.\n\nAt the other end sits Japan, where fewer than one in five workers report professional AI use ‚Äî less than half the level seen in the US or UK.\n\nOne striking pattern cuts across all countries: personal AI use consistently outpaces professional use.\n\nEven in high-adoption markets, workers are experimenting with AI on their own faster than employers are embedding it into workflows. That gap is narrowest in Ireland, suggesting workplace norms and encouragement matter.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 1,
    "keywords": [
      "workers",
      "across",
      "ireland",
      "professional"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/irish-ai-new-survey-data-shows-2026-2",
    "thumbnail_url": "https://i.insider.com/6994bb54a645d11881897580?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.435Z",
    "topic": "finance"
  },
  {
    "slug": "the-memory-shortage-is-driving-up-the-cost-of-your-next-laptop",
    "title": "The memory shortage is driving up the cost of your next laptop",
    "description": "Memory chip costs are up as AI companies gobble up the hot commodity. Consumer electronics companies like Dell and HP are raising prices.",
    "fullText": "Did that computer you were eyeing jump in price? Is that gaming handheld out of stock? You might want to practice a new refrain: Thanks, memory shortage.\n\nAs AI companies demand increasingly large troves of chips to power their large language models, memory chips remain in short supply. That's bad news for much of the consumer electronics market, which relies on DRAM and NAND memory chips.\n\nThe research firm IDC expects \"significant pressure on the memory ecosystem,\" warning that supply growth would be below historical norms this year. Electronics companies from Valve to Framework have already changed their sales procedures because of the shortage. Even Apple, the industry goliath, said it was expecting supply chain pressures on memory that would weigh on its famously high gross margin.\n\nThe memory shortage has existed for months ‚Äî but it's beginning to affect more shoppers' wallets. And the bad news is it's not expected to let up anytime soon.\n\nElectronics CEOs are sounding the alarm for \"RAMageddon.\"\n\nJust last week, Lenovo CEO Yang Yuanqing told Reuters that he expected PC unit sales to \"face pressure.\" Intel CEO Lip-Bu Tan predicted that there would be \"no relief until 2028.\"\n\nDell has already begun adjusting its device prices, according to an internal list of price changes sent to staff in December seen by Business Insider. The company raised the prices of its Dell Pro and Pro Max notebooks and desktops with 32GB of memory by between $130 and $230, among other increases.\n\nHP also planned price hikes \"across the board\" thanks to the memory shortage, its CEO said on its November earnings call.\n\nSmaller PC makers ‚Äî which may not enjoy the same amount of supply-chain leverage as their tech titan peers ‚Äî have also been hit especially hard.\n\nFramework raised its prices in December, then again in January, and again in February. Corsair accidentally underpriced its DRAM kits, canceling preorders and sending out coupons. It then raised prices days later, citing \"market costs.\"\n\nThe gaming device market is also struggling. Valve updated the site for its popular Steam Deck handheld device to say that it may be \"out-of-stock intermittently in some regions due to memory and storage shortages.\" The company also said it must \"revisit\" the pricing and scheduling of its upcoming Xbox and Playstation competitor, the Steam Machine, and VR headset, the Steam Frame, because of the shortage.\n\nBigger players could be next on the horizon: Bloomberg reported over the weekend that Sony was considering pushing back the launch of the next PlayStation, and that Nintendo was considering a price hike for the Switch 2.\n\nSome companies could choose to absorb any associated cost increases at the expense of their margins, opting to wait out the supply crunch.\n\nMeanwhile, bigger and bigger names keep speaking out about the shortage and its impacts.\n\nElon Musk warned of a \"chip wall\" on Tesla's fourth-quarter earnings call. Tim Cook pointed to the shortage on Apple's fourth-quarter earnings call, saying that the company was watching memory prices increase \"significantly.\"\n\nThis is where things get a bit more technical, but it all boils down to basic supply and demand.\n\nThere are three types of chips that are important to know. DRAM (dynamic random access memory) and NAND (non-volatile flash memory) are crucial for building consumer devices. HBM (high-bandwidth memory) chips are used to help train large language models.\n\nThree companies dominate the memory chip market: Samsung, SK Hynix, and Micron. These companies also produce HBM chips.\n\nAI companies are hungry for more and more chips, and are willing to break out the checkbook to be first in line for factory production ‚Äî giving them an edge over many consumer tech companies. They're also flush with cash, with companies like Microsoft and Meta projecting multi-billion-dollar capital expenditures, much of which is going toward AI-related costs like chip acquisition.\n\nThat leaves chipmakers responding to the spike in demand by raising prices, selling supply to AI companies, and some transitioning to HBM production.\n\nThe shortage isn't fading anytime soon. SK Hynix has long secured demand for its entire 2026 DRAM and NAND production volume. The CEO of Micron predicted on its first-quarter earnings call that supply would remain substantially short for the \"foreseeable future.\"\n\nAnd if you're trying to build your own PC, a mere consumer navigating the increasingly volatile memory marketplace: Good luck.",
    "readingTime": 4,
    "keywords": [
      "language models",
      "anytime soon",
      "fourth-quarter earnings",
      "memory chips",
      "memory shortage",
      "dram and nand",
      "supply",
      "demand",
      "consumer",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/memory-shortage-chips-cost-laptop-pc-prices-increase-2026-2",
    "thumbnail_url": "https://i.insider.com/6994b3d5a645d11881897502?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.303Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-and-openai-posture-over-pizza-as-the-ai-talent-war-heats-up",
    "title": "Elon Musk and OpenAI posture over pizza as the AI talent war heats up",
    "description": "Elon Musk and an OpenAI engineer engaged in a game of pizza one-upmanship over the weekend as AI companies fight for top recruits.",
    "fullText": "The rivalry between xAI and OpenAI is heating up again ‚Äî this time, over wood-fired pizza.\n\nOver the weekend, Elon Musk and an OpenAI engineer jockeyed on X about wood-fired crusts, dough fermentation, and campus chefs.\n\nOn its face, it was a lighthearted back-and-forth about free pizza for lunch. Underneath, it encapsulates a trend playing out in Silicon Valley: rival AI companies are publicly pitching culture ‚Äî and perks like free lunch ‚Äî in the talent war for top engineers.\n\nThe exchange began when Musk reposted a video of an xAI engineer calling his job the \"opportunity of a lifetime.\"\n\nJoin @xAI https://t.co/Fo3kjhaTXA\n\nThe post quickly drew a response from xAI's competitor, OpenAI.\n\n\"Or join Codex,\" said Thibault Sottiaux, an engineering lead working on OpenAI's Codex software agent, who is also hiring. OpenAI operates \"with much of the same principles,\" he wrote ‚Äî before adding an increasingly common recruitment pitch.\n\n\"Join the bright side, we have pizza,\" Sottiaux wrote.\n\nJoin the bright side, we have pizza\n\nMusk fired back: \"But how good is your wood oven pizza?\"\n\nThe pizza posturing then shifted to ingredients ‚Äî and the corporate chefs preparing them.\n\n\"But how about the dough?\" he wrote back. \"Can't take shortcuts, needs 24 hours at least. And our chef is üî•.\"\n\nOur chef is so good that God looked down at the food from heaven and said you my most delicious creation üëº\n\n\"Our chef is so good that God looked down at the food from heaven and said you my most delicious creation,\" Musk replied.\n\n\"And after having a bite, he wasn't 100% satisfied and asked our chef to improve upon the SoTA,\" Sottiaux said. \"Our chef delivered, and created a recipe now universally credited to accelerating the AGI timeline.\"\n\nThe tomato pie-based banter was sweet ‚Äî but the subtext was spicier.\n\nAI labs are locked in a high-stakes dash for elite engineers, with high-end compensation packages stretching into the nine-figure territory.\n\nCompanies including Amazon, Microsoft, Meta, OpenAI, and Musk's xAI are competing for a relatively small pool of researchers capable of building the next generation of models and infrastructure.\n\nAside from money, two key perks have emerged in the AI talent wars, according to professional AI poacher Mark Zuckerberg: access to GPUs and fewer direct reports.\n\n\"People say, 'I want the fewest number of people reporting to me and the most GPUs,'\" Zuckerberg said in 2025 TITV interview.\n\nAt the same time, the broader tech industry has pulled back on many of the pre-pandemic perks amid cost-cutting. Remote work has narrowed, layoffs have gathered steam, and perks like pet care stipends and expansive wellness benefits are becoming less common for new hires.\n\nBut there's one perk that has remained: the fancy lunch spread.\n\nMight as well throw in wood-fired pizza, too.",
    "readingTime": 3,
    "keywords": [
      "god looked",
      "delicious creation",
      "wood-fired pizza",
      "chef",
      "perks",
      "lunch",
      "back",
      "engineer",
      "dough",
      "chefs"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/elon-musk-pizza-openai-spacex-x-post",
    "thumbnail_url": "https://i.insider.com/6994da87f8731049f3af4756?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.101Z",
    "topic": "finance"
  },
  {
    "slug": "with-rise-of-agents-we-are-entering-the-world-of-identic-ai",
    "title": "With Rise of Agents, We Are Entering the World of Identic AI",
    "description": "A conversation with tech expert Don Tapscott about the potential for and pitfalls of identic AI.",
    "fullText": "All episodes\n\n All episodes\n\n Details\n\n Transcript\n\n February 17, 2026\n\n What if the AI you integrate into your organization isn‚Äôt just about efficiency or creating digital assistants, but completely changes how you work? Longtime digital trend watcher Don Tapscott says the next wave of artificial intelligence is all about identic AI ‚Äì where personalized agents don‚Äôt just complete tasks, but understand your judgment and values and take actions on your behalf. He explains the technologies for this that already exist amid the rise of agents and bots, what it means for leaders and organizations, and the pitfalls to look out for. Tapscott is author of You to the Power of Two: Redefining Human Potential in the Age of Identic AI.\n\n Back / With Rise of Agents, We Are Entering the World of Identic AI\n\n Latest in this series\n\n All episodes",
    "readingTime": 1,
    "keywords": [
      "episodes",
      "agents",
      "digital",
      "rise",
      "identic",
      "tapscott"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/podcast/2026/02/with-rise-of-agents-we-are-entering-the-world-of-identic-ai",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-ideacast_25.png",
    "created_at": "2026-02-18T01:13:42.522Z",
    "topic": "business"
  },
  {
    "slug": "here-are-the-new-features-coming-in-ios-264",
    "title": "Here Are the New Features Coming in iOS 26.4",
    "description": "Let AI create Apple Music playlists for you.",
    "fullText": "iOS 26.3 was a decidedly small update. It introduced a new tool to transfer data to Android, and gave some iPhones the ability to hide precise location data from cellular networks. But beyond some other small changes and security patches, that's all there was to write home about. iOS 26.4 is a different story. The update, which is currently in beta testing, adds a number of interesting new features to compatible iPhones, especially if you're an Apple Music user.\n\nAs with all beta software, iOS 26.4 is currently in testing, which means these features are subject to change at any time. It's possible some won't make it to the official release of iOS 26.4, while others could look different than they do now. While you can install the iOS 26.4 beta at any time by enrolling your device in the beta program, do so at your own discretion. I'd recommend using a secondary device to test this software if you can, but either way, make sure the device in question is fully backed up to a computer before installing the beta.\n\nThe latest trend in streaming services seems to be AI-generated playlists. YouTube Music recently rolled out the option, while Spotify offers a couple different takes on the feature. The idea is to tell the AI what type of music you want to listen to, whether that be a specific artist or genre, or just a concept or mood (e.g., \"Make me a playlist for drinking coffee on a lazy Sunday morning\").\n\nNow Apple Music is the latest service to introduce such a feature. The first iOS 26.4 beta comes with \"Playlist Playground,\" which works about how you'd expect. You tell Apple Music's AI what you want to hear, and it generates a playlist with 25 different songs. You can adjust the playlist if you don't like the result, as well as edit the title, cover image, and description.\n\nIn addition to Playlist Playground, Apple Music's UI is also changing in iOS 26.4. You'll see new full-page artwork when listening to music, as well as redesigned albums and playlists that adjust their colors based on the artwork. Plus, there's now a \"Concerts Near You\" feature that helps you find shows in your area, based on the music you like to listen to.\n\nRCS support is the best thing to happen to the iPhone in a long time. It makes texting Android users about the same as texting iPhone users, which has not been the case for most of iMessage's history. But while most of the standard perks rolled in with the update, including functioning group chats and high-quality image sharing, one key feature did not: end-to-end encryption (E2EE).\n\nWithout (E2EE), your messages can be intercepted and read by those with the skills to do so. With E2EE, they cannot. It's a major security feature that's key to both iMessage and RCS, and one of the reasons you shouldn't send messages over SMS, as it doesn't support E2EE. Not all Android setups support E2EE over RCS, but it's still a bummer that the iPhone's Messages app doesn't either.\n\nThat's now changing. With the first iOS 26.4 beta, Apple is now testing E2EE for RCS. You'll find the option in Settings, though Apple notes that not all devices or carriers support it. Someday soon, however, iPhone users texting Android users over RCS will be able to enjoy the added security benefits of E2EE.\n\nWith iOS 26.4, Apple changed the Wallpapers settings menu. Before, you could select from pre-downloaded wallpaper packs on your iPhone; now, you can choose which packs you want to download instead. It's a small change, but an interesting one at that. It seems Apple doesn't want to assume you're interested in all of its wallpaper options anymore, and instead would rather pick and choose the ones you want to try. Apple also made similar changes to picking watch faces in the Apple Watch app.\n\nIf you ever label reminders as \"urgent\" on your iPhone, you'll find them in a new location. Now, when you open Reminders, you'l find an Urgent section, alongside other options like Today, All, and Scheduled.\n\nWhile this isn't an iOS feature, it is a key new change in the first macOS 26.4 beta. Apple is now testing a \"charge limit\" feature on Mac, similar to the charge limit feature that already exists on iOS; when your device is plugged in for a long period of time, it will limit how much the battery can charge to. You can set the cap as low as 80%, or as high as 100%. The idea is, by limiting the charge level, you reduce how often the battery completes a full charge cycle, which can prolong its lifespan and delay aging. The \"younger\" your battery is, the longer it'll last between charges, so enthusiasts like to use these features to maximize how much battery life they can get out of their devices.",
    "readingTime": 5,
    "keywords": [
      "texting android",
      "android users",
      "apple music's",
      "charge limit",
      "iphone users",
      "beta apple",
      "limit feature",
      "ios beta",
      "testing",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/here-are-the-new-features-coming-in-ios-264?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHPM03ZJFRAKBM337N5306KQ/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-18T01:13:41.402Z",
    "topic": "tech"
  },
  {
    "slug": "ai-strategy-is-built-on-layers-of-api-sediment",
    "title": "AI strategy is built on layers of API sediment",
    "description": "AI protocols, such as MCP and Agent Skills, are agent-first, which risks bypassing the governance, security, and access controls that enterprises have spent years building around their APIs and data.",
    "fullText": "‚ÄúThe API landscape is a mess, and very few people understand it,‚Äù Kin Lane, API industry veteran and founder of Naftiko, tells The New Stack.\n\nSome days it feels like we are living in an XKCD cartoon.\n\nOrganizations don‚Äôt typically migrate legacy systems from one spec to another as new ideas emerge. Instead, they accumulate layers of integration standards over time, with each era leaving behind systems that are too costly or risky to excavate. ‚ÄúI get a call from a 20-year veteran at a large enterprise, who says, ‚ÄòWe still have EDI and WSDLs, a lot of Swagger and OpenAPI. We‚Äôre trying to do more Async API. MCP is popping up, and we‚Äôre looking at Agent Skills, but we have a global business to run, and it‚Äôs got to be stable.‚Äô‚Äù\n\nIt was seeing this recurring pattern of API sediment that prompted Lane to found Naftiko.\n\nThe evolution and splintering of API specifications\n\n‚ÄúOrganizations‚Ä¶ accumulate layers of integration standards over time, with each era leaving behind systems that are too costly or risky to excavate.‚Äù\n\nLane argues that competing standards are a consequence of vendor ‚Äòland grabs‚Äô, where competing vendors exploit specs to exert influence. I don‚Äôt disagree with his hypothesis, but I would add that the different standards also reflect when they were developed.\n\nWeb Services Description Language (WSDL) emerged from the Enterprise SOA movement of the 2000s as a formal contract language for web services. Governed by W3C but heavily influenced by IBM, Microsoft, and Oracle, it was technically open but reflected corporate middleware needs, with verbose XML schemas defining operations, messages, and bindings.\n\nIn the 2010s, REST APIs displaced SOAP, and lighter-weight specifications emerged:\n\nAs asynchronous architecture patterns such as event-driven architectures, message queues, WebSockets, and streaming gained popularity in the late 2010s, OpenAPI‚Äôs request-response model no longer fit. Regarded as a sister spec to OpenAPI, AsyncAPI (also under Linux Foundation) borrowed OpenAPI‚Äôs structure, adapting it for pub/sub, streaming, and asynchronous messaging patterns.\n\nAs we¬†entered the 2010s,¬†Smithy¬†(AWS) and¬†TypeSpec (Microsoft) marked¬†a shift toward protocol-agnostic API modeling. Rather than describing HTTP endpoints directly, they model services abstractly, then generate OpenAPI, code, or protocol-specific implementations. This reflects cloud providers‚Äô need to maintain type safety while supporting multiple protocols (HTTP, gRPC, proprietary) from single definitions.\n\nSmithy powers AWS‚Äôs service definitions. TypeSpec emerged from Microsoft‚Äôs experience with Azure APIs and emphasizes TypeScript-based syntax for broader developer accessibility. Both Smithy and TypeSpec are open source, but neither has truly open governance in the OpenAPI/AsyncAPI sense. AWS drives Smithy‚Äôs roadmap based on internal AWS needs. TypeSpec recently moved to a Linux Foundation working group, but Microsoft remains the dominant contributor. There‚Äôs no open governance ‚Äî no multi-vendor steering committee, and no requirement for consensus from competing cloud providers.\n\nThis matters because Smithy and TypeSpec reflect their creators‚Äô architectural assumptions: multi-region cloud services, polyglot microservices, auto-generated clients. They‚Äôre optimized for the problems that AWS and Azure experience, not necessarily problems faced by enterprises or startups. Without diverse governance, they risk becoming sophisticated tools that solve vendor-specific problems.\n\nThe SDK focus of Smithy and TypeSpec reveals something else: these specs assume developers consume APIs through generated code. They‚Äôre not optimized for the autonomous agents that LLM vendors hope will form the next wave of API consumers. As a result, the big LLM model providers are creating and pushing new standards:\n\nWhile OpenAPI and AsyncAPI are strategic resources, MCP and A2A are more tactical. ‚ÄúBoth MCP and A2A are very transactional, exciting, and in this moment,‚Äù Lane said. ‚ÄúThey are also likely to give away all your value and data if you are not careful. You have to be very thoughtful in how you transact in those new realms.‚Äù\n\nThe question is how you bridge the gap between the tactical needs of an individual team and the strategic needs of the overall enterprise. ‚ÄúI would see this at Postman all the time. Tractor company John Deere would come to us and say, ‚ÄòOur CIO, CTO‚Äôs office, and Centre of Excellence, manage SOAP, WSDLs, open API, and AsynchAPI across the org. Now we have teams with Postman Collections that run tests and automation, but they don‚Äôt understand the bigger picture. We need Postman to reconcile these two worlds for us.‚Äô‚Äù\n\nThe API economy saw developers craft APIs, treat them as products, rate-limit them, and understand who was using them and what they were doing with them. ‚ÄúMCP, however, wants to circumvent all of that,‚Äù Lane said. ‚ÄúIt wants direct access to your data and files, so it‚Äôs throwing out that decade of design work in front of our file systems and databases, and instead letting the agents have it without much accounting or governance.‚Äù\n\nIn addition to wasting significant potential value, poor data governance poses a significant challenge when deploying LLMs for internal use. Organizations can inadvertently expose sensitive information across departments. That data was likely technically accessible before, but required manually searching through Google Drive or file shares to find it.\n\nWhen LLMs gain access to these information repositories, they can surface and share sensitive data far more readily, effectively democratizing access in ways that may violate intended access controls. This was a point that Nicolleta Curtis emphasized to me in an interview for LeadDev. ‚ÄúEven with the basics, such as OneDrive and SharePoint, we found documents that were overshared or with open permissions,‚Äù she told me.\n\nOrganizations typically respond to this challenge in one of two ways: they underestimate either the severity of the data exposure risk or the operational burden that proper mitigation will place on their security teams. Implementing appropriate access controls and data boundaries after the fact requires substantial effort.\n\nIn large enterprises with legacy systems, retroactively tightening permissions often breaks existing workflows and integrations. This creates friction across the organization as teams suddenly lose access to information they‚Äôve historically relied on, leading to productivity impacts and internal resistance to the new controls.\n\nIn the first article in this series, Lane described his experience setting up API governance at Bloomberg, which involved:\n\nUsing this approach of comprehensive API mapping and governance with established standards like OpenAPI provides the best foundation for compliance, security, and Personally Identifiable Information (PII) management. For newer/smaller organizations, Lane suggested skipping the ‚Äòbaggage‚Äô and going straight to newer approaches such as Agent Skills or MCP.\n\nWhatever approach you favor, we both agree that you should resist the temptation to take a technology-first approach that ignores business outcomes.",
    "readingTime": 6,
    "keywords": [
      "accumulate layers",
      "web services",
      "cloud providers",
      "legacy systems",
      "behind systems",
      "integration standards",
      "access controls",
      "smithy and typespec",
      "the api",
      "agent skills"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/ai-strategy-api-sediment/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2026/02/874b4afb-peter-olexa-rytit3b7xw4-unsplash-scaled.jpg",
    "created_at": "2026-02-17T18:42:44.292Z",
    "topic": "tech"
  },
  {
    "slug": "agntor-trust-infrastructure-for-ai-agents-identity-escrow-guard",
    "title": "Agntor ‚Äì Trust infrastructure for AI agents (identity, escrow, guard)",
    "description": "Contribute to agntor/agntor development by creating an account on GitHub.",
    "fullText": "agntor\n\n /\n\n agntor\n\n Public\n\n docs.agntor.com\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n agntor/agntor",
    "readingTime": 1,
    "keywords": [
      "agntor",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/agntor/agntor",
    "thumbnail_url": "https://opengraph.githubassets.com/fdbe116b5444b69fe4a879f37c52130d165afc0515bc1ad17eaae0f160810836/agntor/agntor",
    "created_at": "2026-02-17T18:42:43.744Z",
    "topic": "tech"
  },
  {
    "slug": "a-software-ceo-explains-why-hes-not-worried-about-the-ai-apocalypse-coming-for-his-industry",
    "title": "A software CEO explains why he's not worried about the AI apocalypse coming for his industry",
    "description": "Basware CEO Jason Kurtz explained how he keeps his software company ahead of AI startups threatening his business.",
    "fullText": "It's the end of the world as software companies know it, and this CEO feels fine.\n\nJudging by what some AI experts are saying, and the state of the stock market, you'd think software companies were on their last legs. Basware CEO Jason Kurtz, whose company sells software for financial processes, sees it slightly differently.\n\n\"I will tell you there is not a single piece of data that we see that says that,\" said Kurtz.\n\n\"I have not had a single customer tell us, 'Oh, we're just going to go figure this out on our own and do AP with OpenAI or whoever.' That's not the way these companies work,\" he added.\n\nKurtz reached out to me last week after I asked for some reader feedback on the topic. (I genuinely read all your emails. Even the mean ones!)\n\nBasware, which counts Mercedes and Heineken among its roughly 6,500 customers and uses AI within its own products, hasn't felt threatened thus far. Kurtz told me the company saw a 20% year-over-year increase in sales in 2025, primarily driven by a surge in the back-half of the year.\n\nHe acknowledged that there had been some customer chatter about experimenting with AI on their own. But more recently, clients just want results.\n\nKurtz recalled a conversation with the digital transformation officer of a large European company. After spending roughly a million euros on internal AI-related projects in finance over the past year, the executive told Kurtz they \"can't point to a single penny that we have saved, earned, or helped our business in any way.\"\n\n\"I'm tired of experimenting. I want people who know how to use AI in our processes in our workflows,\" Kurtz said the executive told him.\n\nI asked Kurtz for advice for fellow software companies looking to protect themselves.\n\nBasware primarily works with AWS to help build its AI tools for customers. The company also has an \"AI czar,\" according to Kurtz, to surveil the industry. Figuring out ways to implement AI into your own products that'll drive more value for customers is one way to stay ahead.\n\nThere's also strength in numbers. Kurtz said maintaining tight integrations with fellow vendors to become a part of the workflow creates stickiness.\n\n\"If we weren't doing that, I'd be even more paranoid,\" Kurtz said.\n\nAnd then there's the data element. Basware has processed 2.5 billion invoices and 10 trillion euros of spend in the company's 40-year history. Having such a large swath of info can help train models and identify new efficiencies to pitch to customers.\n\n\"If you don't have a data strategy around AI and how you're going to use that to differentiate your AI and your capabilities, I think that's going to be a challenge,\" he said.",
    "readingTime": 3,
    "keywords": [
      "software",
      "customers",
      "kurtz",
      "processes",
      "customer",
      "that's",
      "roughly",
      "products",
      "primarily",
      "experimenting"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/basware-ceo-jason-kurtz-ai-software-apocalypse-advice-2026-2",
    "thumbnail_url": "https://i.insider.com/698fa49ad3c7faef0ece4ead?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:38.289Z",
    "topic": "tech"
  },
  {
    "slug": "billionaire-investor-vinod-khosla-wants-to-rethink-capitalism-for-the-ai-era-and-suggests-scrapping-taxes-for-125",
    "title": "Billionaire investor Vinod Khosla wants to 'rethink' capitalism for the AI era ‚Äî and suggests scrapping taxes for 125 million people",
    "description": "Vinod Khosla said AI warrants a \"rethink of capitalism,\" and taxing capital more could allow 125 million people to be removed from US tax rolls.",
    "fullText": "If artificial intelligence eliminates millions of jobs, it might make sense to scrap income taxes for the vast majority of Americans and target capital instead, Vinod Khosla says.\n\n\"AI will transform economies and need a rethink of capitalism & equity,\" the billionaire venture capitalist wrote in an X post on Monday. \"Labor portion of economy (vs capital) will decline sharply. Should we eliminate preferential treatment of capital gains tax and equalize to ordinary income?\"\n\nKhosla ‚Äî who cofounded Sun Microsystems and made the first VC investment in OpenAI ‚Äî was making the point that AI replacing labor on a grand scale might warrant greater taxes on assets such as stocks and real estate.\n\nThe veteran financier, who founded Khosla Ventures after leaving Kleiner Perkins, attached a video highlighting some of the jobs that could be taken by AI, from accountants and therapists to truck drivers and chip designers.\n\nAI will transform economies and need a rethink of capitalism & equity. Labor portion of economy (vs capital) will decline sharply. Should we eliminate preferential treatment of capital gains tax and equalize to ordinary income? 40% of capital gains taxes are paid by those with‚Ä¶ pic.twitter.com/7oSA9xj5Ko\n\nKhosla said in a follow-up post that ramping up taxes on capital would generate so much revenue that the government could scrap taxes for most of the roughly 150 million US taxpayers.\n\n\"Could easily eliminate bottom 125 million taxpayers from the tax rolls and be revenue neutral at the same time with a capital gains tax equal to ordinary income and a few other tweaks,\" he wrote.\n\nHe added that tax breaks such as carrying over tax losses and tax-free borrowing against unrealized gains ‚Äî which he called a \"true abuse!\" ‚Äî are \"special interest goodies inserted by lobbyists and campaign contributions, not true capitalism.\"\n\nKhosla didn't address common critiques of higher taxes, including that they can discourage entrepreneurship and investment,¬†that collecting them can be tricky, and that wealthy people may leave the country to avoid them.\n\nKhosla has previously underscored that the advent of AI may require sweeping policy changes. He estimated in late 2024 that in 25 years' time, AI could be doing 80% of the work in 80% of all jobs, and universal basic income might be needed to compensate for job destruction.\n\n\"As AI reduces the need for human labor, UBI could become crucial, with governments playing a key role in regulating AI's impact and ensuring equitable wealth distribution,\" he wrote on his firm's website.\n\nKhosla isn't alone in predicting AI will change the fabric of society. Elon Musk suggested late last year that work could become \"optional\" and money might become \"irrelevant\" if advances in AI and robotics generate abundant resources for all.\n\nMoreover, the Tesla and SpaceX CEO recently said that retirement savings may not be needed in 10 or 20 years, as everyone might have \"whatever stuff they want.\"\n\nHowever, skeptics such as Michael Burry of \"The Big Short\" fame have cautioned the AI boom is a speculative bubble, tech companies are overinvesting in microchips and data centers that will quickly become obsolete, and true AI is further away than many think.",
    "readingTime": 3,
    "keywords": [
      "transform economies",
      "decline sharply",
      "preferential treatment",
      "capitalism equity",
      "eliminate preferential",
      "labor portion",
      "ordinary income",
      "capital gains",
      "gains tax",
      "taxes"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/vinod-khosla-ai-taxes-capital-labor-job-losses-billionaires-musk-2026-2",
    "thumbnail_url": "https://i.insider.com/69946045d3c7faef0ece5d91?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:38.112Z",
    "topic": "finance"
  },
  {
    "slug": "12hour-days-no-weekends-the-anxiety-driving-ais-brutal-work-culture-is-a-warning-for-all-of-us",
    "title": "12-hour days, no weekends: the anxiety driving AI‚Äôs brutal work culture is a warning for all of us",
    "description": "San Francisco‚Äôs AI startups are pushing workers to grind endlessly, hinting at pressures soon hitting other sectors\nNot long after the terms ‚Äú996‚Äù and ‚Äúgrindcore‚Äù entered the popular lexicon, people started telling me stories about what was happening at startups in San Francisco, ground zero for the artificial intelligence economy. There was the one about the founder who hadn‚Äôt taken a weekend off in more than six months. The woman who joked that she‚Äôd given up her social life to work at a prestigious AI company. Or the employees who had started taking their shoes off in the office because, well, if you were going to be there for at least 12 hours a day, six days a week, wouldn‚Äôt you rather be wearing slippers?\n‚ÄúIf you go to a cafe on a Sunday, everyone is working,‚Äù says Sanju Lokuhitige, the co-founder of Mythril, a pre-seed-stage AI startup, who moved to San Francisco in November to be closer to the action.",
    "fullText": "Not long after the terms ‚Äú996‚Äù and ‚Äúgrindcore‚Äù entered the popular lexicon, people started telling me stories about what was happening at startups in San Francisco, ground zero for the artificial intelligence economy. There was the one about the founder who hadn‚Äôt taken a weekend off in more than six months. The woman who joked that she‚Äôd given up her social life to work at a prestigious AI company. Or the employees who had started taking their shoes off in the office because, well, if you were going to be there for at least 12 hours a day, six days a week, wouldn‚Äôt you rather be wearing slippers?\n\n‚ÄúIf you go to a cafe on a Sunday, everyone is working,‚Äù says Sanju Lokuhitige, the co-founder of Mythril, a pre-seed-stage AI startup, who moved to San Francisco in November to be closer to the action. Lokuhitige says he works seven days a week, 12 hours a day, minus a few carefully selected social events each week where he can network with other people at startups. ‚ÄúSometimes I‚Äôm coding the whole day,‚Äù he says. ‚ÄúI do not have work-life balance.‚Äù\n\nAnother startup employee, who came to San Francisco to work for an early-stage AI company, showed me dismal photos from his office: a two-bedroom apartment in the Dogpatch, a neighborhood popular with tech workers. His startup‚Äôs founders live and work in this apartment ‚Äì from 9am until as late as 3am, breaking only to DoorDash meals or to sleep, and leaving the building only to take cigarette breaks. The employee (who asked not to use his name, since he still works for this company) described the situation as ‚Äúhorrendous‚Äù. ‚ÄúI‚Äôd heard about 996, but these guys don‚Äôt even do 996,‚Äù he says. ‚ÄúThey‚Äôre working 16-hour days.‚Äù\n\nStartups have never been particularly glamorous. When I started reporting on the industry a decade ago, people were cashing in on the new mobile app economy, and coders were chugging Soylent to stay at their desks longer. Startups then, too, were defined by hustle culture, high-octane energy and the pursuit of growth at all costs ‚Äì ideas that, to some extent, have remained in the bloodstream of the industry.\n\nBut in the last year, as the magic dust of artificial intelligence has settled in San Francisco, the vibe among tech workers does seem different. The excitement about a new epoch in tech ‚Äì and all the money that comes with it ‚Äì is now tempered with anxieties about the industry, and the economy. Some workers are going all in on AI while also questioning whether all that AI is good for the world. Others are effectively training machines to do their jobs better than they can. And many of the same workers who are racing to build the future are now wondering if the future they‚Äôre building has a place for them in it.\n\nThe rest of us may be ambiently aware of these anxieties, but they are already tangible and keenly felt inside the tech industry. Even the biggest tech companies, once known for coddling employees with on-site massages and barber shops, have scaled back perks as they have escalated the expectations of workers. Mark Zuckerberg and Elon Musk have each been candid about their predictions that AI will replace some junior and mid-level engineers at their companies, and have respectively called for their workforces to be more ‚Äúefficient‚Äù and ‚Äúextremely hard core‚Äù as waves of layoffs set employees on-edge. Tech companies laid off about a quarter of a million workers around the world in 2025, according to a report published by RationalFX. In many of those layoffs, AI was cited as a main factor, even if the full reason for layoffs is often more complex.\n\n‚ÄúIf you were a software engineer five years ago, you could kind of write your ticket,‚Äù says Mike Robbins, an executive coach who has worked with companies like Google, Microsoft, Salesforce and Airbnb. Now, the balance of power has shifted away from tech workers, many of whom are left feeling anxious about their work performance. ‚ÄúWhen companies become less scared about losing employees, then they can be a little more forthright in terms of what they want and be a little more demanding.‚Äù\n\nRobbins, who wrote the book Bring Your Whole Self to Work, used to be asked to speak to companies and their leaders about topics like employee burnout, wellbeing and belonging ‚Äì top priorities in the years during and shortly after the pandemic. ‚ÄúQuite frankly, we‚Äôve stopped talking about all that,‚Äù he says. Now, company leaders want advice on topics like change, disruption and uncertainty in the workplace.\n\nThose themes ‚Äì change, disruption and uncertainty ‚Äì are each part of the fuel that has driven tech workers to put in more hours, at a higher intensity. Investment in artificial intelligence companies reached record highs in 2025, yet workers are feeling scarcity in ways they haven‚Äôt before.\n\n‚ÄúIt‚Äôs definitely something that‚Äôs on everyone‚Äôs mind,‚Äù says Kyle Finken, a software engineer at Mintlify, which makes an AI tool for developers. ‚ÄúI think a lot of people are concerned like, ‚ÄòOh, am I going to have a job in three years?‚Äô‚Äù\n\nDespite his fears, Finken, like many other startup employees I spoke to, feels energized by the ‚Äúextraordinary innovation‚Äù happening in artificial intelligence and believes that there will still be plenty of jobs for software engineers in the future, even if those jobs look different from the pure coding roles of today. He and other tech workers characterized the current moment as a particularly creative and productive time in tech, where people are devoting extra hours to work not because their employers demand it but out of genuine interest in the new tools and capabilities. For example, Garry Tan, the head of the famous startup accelerator Y Combinator, recently bragged that he ‚Äústayed up 19 hours‚Äù playing around with Claude Code.\n\nEven those who felt excited about the pace of change acknowledged that AI was rapidly augmenting their work, in ways that could have uncertain outcomes for the jobs of the future. ‚ÄúThis is definitely not an era of complacency,‚Äù says Finken.\n\nOne reason for working so many hours is to keep up with tools and technology that are changing nearly every day. If you take the weekend off, you can miss a major development, which makes it harder to keep up with what competitors are doing. Another reason is to have something to show future employers, especially as more junior-level jobs are replaced by AI.\n\n‚ÄúNo one hires junior developers any more,‚Äù says Lokuhitige, the Mythril co-founder. Landing a job now requires ‚Äúdoing something cool‚Äù, he says, like building a new product or solving a problem that gets recognized as useful by larger companies. Job postings for entry-level tech jobs have dropped by a third since 2022, according to Indeed‚Äôs Hiring Lab, while job postings requiring at least five years of experience have risen. If you‚Äôre not grinding at a startup, you‚Äôre missing the prerequisite to get hired in the future.\n\nWhile economists are torn about whether AI will replace most jobs or just change them, they seem aligned in the idea that AI has already reshaped a great deal of entry-level work and will continue to do so. A paper published by Stanford researchers in November found ‚Äúsubstantial declines in employment for early-career workers‚Äù in industries exposed to AI and suggested that areas where change is already occurring could be like a ‚Äúcanary in the coalmine‚Äù for the rest of the economy. The Anthropic CEO, Dario Amodei, has suggested AI could eliminate about half of all entry-level jobs in white-collar industries within the next five years.\n\nThe head of the International Monetary Fund recently predicted that 60% of jobs in advanced economies will be eliminated or transformed by artificial intelligence, ‚Äúlike a tsunami hitting the labour market‚Äù. In San Francisco, you can already see the early signs, as Uber drivers compete with self-driving Waymos, and baristas are replaced by robotic coffee bars. Professional business services that support the tech industry have also been negatively affected by the layoffs. The pressure to grind in the tech world could be an early signal ‚Äì a harbinger for what many other industries will feel soon.\n\nRobbins, the executive coach, says that companies once looked to Silicon Valley as a model of how they should operate, down to emulating policies like unlimited vacation days or adopting perks like free lunch in the office.\n\n‚ÄúThere was an idealization of tech and Silicon Valley for a long time across the business world. Some of that has changed,‚Äù he says. ‚ÄúNow, people aren‚Äôt asking me to tell them what‚Äôs going on in the Valley so that they can adopt it, the same way they were a decade ago.‚Äù\n\nRather than a model of how we should all work, the tech industry may be a premonition for the anxiety and attempts to compensate that are coming for all of us.",
    "readingTime": 8,
    "keywords": [
      "executive coach",
      "decade ago",
      "software engineer",
      "job postings",
      "artificial intelligence",
      "san francisco",
      "tech industry",
      "tech workers",
      "silicon valley",
      "jobs"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/feb/17/ai-startups-work-culture-san-francisco",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0dc04be29cbd720664313a65c08e776ecae088ea/0_1012_4091_3273/master/4091.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=3568863089989ed2e94df48fff54f1dd",
    "created_at": "2026-02-17T18:42:37.932Z",
    "topic": "tech"
  },
  {
    "slug": "andrew-yang-says-mass-whitecollar-layoffs-are-closer-than-people-think",
    "title": "Andrew Yang says mass white-collar layoffs are closer than people think",
    "description": "The Forward Party founder said AI \"will kick millions of white-collar workers to the curb in the next 12 - 18 months.\"",
    "fullText": "Expect to see your local Starbucks soon be full of middle-aged former office workers, says Andrew Yang.\n\nThe Forward Party founder and former presidential candidate said AI \"will kick millions of white-collar workers to the curb in the next 12 - 18 months\" in a post on his Substack on Monday.\n\nYang said that, when a company begins to shrink its workforce, its competitors will follow suit.\n\n\"It will become a competition because the stock market will reward you if you cut headcount and punish you if you don't,\" he added.\n\nYang has long warned about the impact of automation on jobs ‚Äî he had previously told The New York Times in 2018 that he predicted self-driving cars would displace truck drivers, a shift that could \"destabilize society\" and provoke \"riots in the street.\"\n\nIn his Substack post, Yang then laid out which workers could be vulnerable: mid-career office workers, middle managers, call center workers, marketers, and coders. The list goes on.\n\n\"Do you sit at a desk and look at a computer much of the day? Take this very seriously,\" he wrote. \"Millions of workers are about to be given their pink slips.\"\n\nYang did not respond to a request for further comment.\n\nThis January saw more layoffs than any January since 2009. Though this has largely been attributed to economic uncertainty, a few companies have already begun citing AI as a reason they are letting staff go.\n\nPinterest said in January that it expects to lay off 15% of its workforce. A spokesperson for Pinterest said the restructuring was part of the company's \"AI-forward strategy.\"\n\nHP said in November that it would cut up to 6,000 jobs by 2028, citing AI initiatives as the reason.\n\nCritics have also said some companies are using AI as a scapegoat for job cuts.\n\nTech CEOs and AI researchers are divided over how AI will impact society. While Tesla and xAI CEO Elon Musk and Google DeepMind CEO Demis Hassabis predict a future of great abundance for all, others, such as Anthropic CEO Dario Amodei, say we should brace for significant white-collar layoffs.\n\nYang said the impact of his predicted layoffs will be felt beyond those who actually lose their jobs.\n\n\"Let's say you're a dry cleaner, a dog walker, or a hairstylist. If people in your community stop going to the office, your business is going to suffer because there are fewer business shirts to launder, people will walk their dogs themselves, and cut back on trips to the salon,\" he said.\n\n\"The amount of money getting paid to human labor is about to go down,\" Yang said.",
    "readingTime": 3,
    "keywords": [
      "workers",
      "impact",
      "jobs",
      "layoffs",
      "yang",
      "millions",
      "white-collar",
      "substack",
      "workforce",
      "predicted"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrew-yang-mass-layoffs-ai-closer-than-people-think-2026-2",
    "thumbnail_url": "https://i.insider.com/699483b4d3c7faef0ece5f4f?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.726Z",
    "topic": "finance"
  },
  {
    "slug": "3-reasons-why-googles-gemini-could-be-the-big-bogeyman-of-the-ai-trade",
    "title": "3 reasons why Google's Gemini could be the big bogeyman of the AI trade",
    "description": "Anthropic's Claude AI has snatched headlines recently. But is there another model that is throwing a wrench in the AI trade?",
    "fullText": "While Anthropic's Claude AI has snatched headlines recently for disrupting the software industry, one researcher says there's perhaps an even bigger bogeyman lurking in tech.\n\nTom Essaye, founder and president of the Sevens Report, says Google's Gemini threatens major potential disruptions to how investors currently see major AI firms.\n\nIn a note to clients on Tuesday, Essaye highlighted three risks posed by Gemini, in particular its November update.\n\nThe first is that it could take market share from OpenAI's ChatGPT. That, in turn, could hurt OpenAi's ability to deliver on the $1 trillion in spending it has promised to firms like Nvidia, he said.\n\nSecond, the fact that Google used its own chips to build Gemini could undermine the importance of large semiconductor providers.\n\n\"The reason that Nvidia, Broadcom, Taiwan Semi and others have exploded in recent years was because of insatiable demand for their semiconductor chips, as they are necessary to build out LLMs,\" Essaye wrote. \"Google making their own chips implies demand for chips from NVDA, AVGO and TSMC may be less than expected. That means less earnings growth and a lower multiple for semiconductor stocks.\"\n\nThat leads to the third point: since Gemini is so effective and was cheaper to produce than other leading chatbots, investors are holding spending levels from hyperscalers to a higher degree of scrutiny, Essaye said.\n\n\"If Google can make Gemini as good as ChatGPT on its own chips, then others likely can as well. The fear is that AI becomes commoditized, making trillions of dollars in AI infrastructure investment foolish,\" Essaye wrote.\n\n\"Put plainly, Gemini broke the idea that all money spent on AI was 'good' money that would result in earnings growth,\" he continued. \"Instead, it ushered in scrutiny to AI capex spending and that altered the paradigm AI/tech stocks existed in. Practically, that means it's no longer the case that the company that spends the most on AI infrastructure 'wins' and we can see that in the market reaction to the collapse of mega-cap free cash flow.\"",
    "readingTime": 2,
    "keywords": [
      "earnings growth",
      "chips",
      "semiconductor",
      "investors",
      "firms",
      "market",
      "others",
      "demand",
      "less",
      "stocks"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/google-gemini-stock-market-ai-trade-threaten-openai-nvidia-tsmc-2026-2",
    "thumbnail_url": "https://i.insider.com/69948486d3c7faef0ece5f73?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.431Z",
    "topic": "finance"
  },
  {
    "slug": "more-than-20000-sign-a-petition-for-openai-to-resurrect-gpt4o",
    "title": "More than 20,000 sign a petition for OpenAI to resurrect GPT-4o",
    "description": "The deprecation of OpenAI's GPT-4o sparks backlash and a petition. Users said they cherish its unique conversational style.",
    "fullText": "Thousands of people are rallying behind a version of ChatGPT after its parent company, OpenAI, retired the model.\n\nOpenAI said on January 30 that GPT-4o would be deprecated alongside three other versions of that model on February 13.\n\nA petition calling on OpenAI to save GPT-4o has amassed roughly 21,900 signatures on Change.org as of Tuesday.\n\n\"For many of us, GPT-4o offers a unique and irreplaceable user experience, combining qualities and capabilities that we value, regardless of performance benchmarks,\" the petition's description says.\n\nOpenAI wrote in a 2025 blog post that the model was known for \"responses that were overly supportive but disingenuous.\"\n\nThe company first set out to sunset GPT-4o last year, but fans pleaded to save it. In response, OpenAI brought the model back for several more months before its latest announcement.\n\nThe petition, created in April 2025 by Sophie Witt, reached 12,500 supporters two weeks ago, after OpenAI shared its latest plans to retire the model, and has continued to climb since.\n\nOn February 2, Witt called on supporters to take collective action against OpenAI's decision by posting about GPT-4o on X.\n\nWitt did not immediately respond to a request for comment.\n\nOpenAI gave GPT-4o a shoutout in its January 30 blog post, saying that many users told the company they like the model's \"conversational style and warmth\" last year. The ChatGPT maker said that feedback helped shape the GPT‚Äë5.1 and GPT‚Äë5.2 models.\n\nThe company cited low usage of GPT-4o as another reason for its retirement, reporting that only 0.1% of users still choose GPT‚Äë4o.\n\nThe last time¬†GPT-4o was retired, CEO Sam Altman was bombarded during an ask-me-anything session on Reddit with calls¬†to reinstate it.\n\nThe calls for its return have been renewed through comments from social media users and petition signees. Some said it felt more like losing a friend than a feature. Other paying ChatGPT users said they'd be canceling their subscriptions in response to the retirement of GPT-4o.\n\n\"No 4o, no money. I will not spend another single penny on OpenAI,\" one X user posted.",
    "readingTime": 2,
    "keywords": [
      "openai",
      "model",
      "users",
      "petition",
      "gpt-4o",
      "retired",
      "january",
      "save",
      "user",
      "blog"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-retires-gpt-4o-20-000-sign-petition-save-it-2026-2",
    "thumbnail_url": "https://i.insider.com/69949378d3c7faef0ece61d2?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.416Z",
    "topic": "finance"
  },
  {
    "slug": "keysight-launches-gddr7-transmitter-compliance-solution-for-ai-systems",
    "title": "Keysight launches GDDR7 transmitter compliance solution for AI systems",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/keysight-launches-gddr7-transmitter-compliance-solution-for-ai-systems-93CH-4509516",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-02-17T18:42:36.933Z",
    "topic": "finance"
  },
  {
    "slug": "why-ai-adoption-stalls-according-to-industry-data",
    "title": "Why AI Adoption Stalls, According to Industry Data",
    "description": "Many companies report widespread AI usage but disappointing returns, assuming the problem lies in execution rather than adoption. New research shows that AI initiatives often stall because employees‚Äô industry-shaped anxiety about relevance, identity, and job security drives surface-level use without real commitment. Leaders who treat AI adoption as a psychological and contextual challenge‚Äînot just a technical rollout‚Äîare far more likely to convert experimentation into sustained impact.",
    "fullText": "Why AI Adoption Stalls, According to Industry Data by Erin Eatough, Keith Ferrazzi, Wendy Smith and Shonna WatersFebruary 17, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintCompanies in most industries are investing heavily in artificial intelligence: 88% of companies reporting regular AI use. Yet many leaders report familiar frustrations. AI adoption stalls. Performance gains plateau. Employees experiment with new tools but don‚Äôt integrate them deeply into how work actually gets done, leaving executives increasingly concerned about ROI.",
    "readingTime": 1,
    "keywords": [
      "adoption stalls"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/why-ai-adoption-stalls-according-to-industry-data",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_14_1466294985.jpg",
    "created_at": "2026-02-17T18:42:36.916Z",
    "topic": "business"
  },
  {
    "slug": "anthropics-pentagon-talks-hit-surveillance-and-weapons-snag",
    "title": "Anthropic's Pentagon Talks Hit Surveillance and Weapons Snag",
    "description": "Anthropic¬†PBC's talks about extending a contract with the Pentagon are being held up over additional protections the artificial intelligence company wants to put on its Claude tool, a person familiar with the matter said.¬† Anthropic wants to put guardrails in place to stop Claude from being used for mass surveillance of Americans or to develop weapons that can be deployed without a human involved, the person said, asking not to be identified because the negotiations are private. The Pentagon wants to be able to use Claude as long as its deployment doesn't break the law. Axios¬†reported¬†on the disagreement earlier.¬†Bloomberg Mandeep Singh reports.",
    "fullText": "Anthropic's Pentagon Talks Hit Surveillance and Weapons Snag BloombergAnthropic PBC's talks about extending a contract with the Pentagon are being held up over additional protections the artificial intelligence company wants to put on its Claude tool, a person familiar with the matter said. Anthropic wants to put guardrails in place to stop Claude from being used for mass surveillance of Americans or to develop weapons that can be deployed without a human involved, the person said, asking not to be identified because the negotiations are private. The Pentagon wants to be able to use Claude as long as its deployment doesn't break the law. Axios reported on the disagreement earlier. Bloomberg Mandeep Singh reports.",
    "readingTime": 1,
    "keywords": [
      "claude",
      "talks",
      "surveillance",
      "weapons",
      "pentagon"
    ],
    "qualityScore": 0.45,
    "link": "https://finance.yahoo.com/video/anthropics-pentagon-talks-hit-surveillance-181151173.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/KgtRH04_ep_kgIf29fi6JA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/bloomberg_markets_video_2/bf5025187b31a5257673b13959be0db3",
    "created_at": "2026-02-17T18:42:36.294Z",
    "topic": "finance"
  },
  {
    "slug": "the-big-tech-losers-as-ai-fears-wipe-billions-of-dollars-off-valuations",
    "title": "The Big Tech losers as AI fears wipe billions of dollars off valuations",
    "description": "Concerns over risks to Microsoft's AI business and growing competition from Google ‚Äåand Anthropic have wiped roughly $613 billion off its market value.",
    "fullText": "Feb 16 (Reuters) - The world's most valuable technology stocks have suffered sharp declines in market value ‚Äåthis year after years of outsized gains, ‚Äåas investors question whether heavy spending on AI will generate sufficient ‚Äãreturns to justify the lofty valuations.\n\nMicrosoft (MSFT) shares have fallen about 17% year-to-date on concerns over risks to its AI business and growing competition from Google's (GOOG, GOOGL) latest Gemini model ‚Äåand Anthropic's (ANTH.PVT) Claude ‚Å†Cowork AI agent, wiping roughly $613 billion off its market value to about $2.98 trillion as ‚Å†of Friday.\n\nAmazon (AMZN) has shed around 13.85% so far this year, erasing about $343 billion in market value and leaving ‚Äãthe company ‚Äãvalued at roughly $2.13 trillion.\n\nEarlier ‚Äãthis month, Amazon said ‚Äåit expects capital spending to jump more than 50% this year.\n\nNvidia (NVDA), Apple (AAPL) and Alphabet have also seen their market values decline by $89.67 billion, $256.44 billion and $87.96 billion, respectively, since the start of 2026, to $4.44 trillion, $3.76 trillion and $3.7 ‚Äåtrillion.\n\nThe pullback signals a broader ‚Äãshift in market psychology, with ‚Äãinvestors moving from rewarding ‚Äãlong-term AI ambitions to demanding near-term ‚Äåearnings visibility after years of ‚Äãspeculative enthusiasm.\n\n(Reporting ‚Äãby Gaurav Dogra and Patturaja Murugaboopathy in ‚ÄãBengaluru; Editing by Sumana Nandy)",
    "readingTime": 2,
    "keywords": [
      "market",
      "investors",
      "roughly",
      "amazon"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/big-tech-stocks-lose-billions-093834534.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/kM_An8HTnTHs5Zy.uQEfSg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-02/eab91ac0-0b1e-11f1-acef-9ae1be1a2924",
    "created_at": "2026-02-17T18:42:34.599Z",
    "topic": "finance"
  },
  {
    "slug": "these-three-claude-premium-ai-features-are-now-available-for-free",
    "title": "These Three Claude Premium AI Features Are Now Available for Free",
    "description": "Here's to use these new features",
    "fullText": "Anthropic's Claude is an AI bot that keeps up a steady pace when it comes to pushing out new features, and the latest upgrade of note sees three useful features make their way down to free users, having previously been exclusive to the paid-for plans.\n\nIf you're choosing between AIs and comparing the features available on the free plans, then there's now more of a case to be made for choosing Claude over a competitor like ChatGPT or Gemini for your next batch of AI tasks.\n\nThe three new features now available to free users on Claude are file creation, external plug-ins called Connectors, and bundles of instructions called Skills. Here's how you can make use of them.\n\nClaude's file creation capabilities let you create Word documents, PowerPoint slideshows, Excel spreadsheets, and PDFs from right inside a conversation. You can either supply the bot with all text, data, and other information you want included, get Claude to invent everything itself, or something in between.\n\nFor example, if you've got a long list of names and scores, Claude can put them into a spreadsheet for you. If you've got a series of images, Claude can combine them into a PDF and describe them. You can get it to analyze and visualize data, produce presentations based on reports, and create summary documents.\n\nTo enable file creation for your account, click your profile icon (bottom left) in Claude on the web, then select Settings > Capabilities and enable Code execution and file creation. With that done, you just have to prompt Claude with the type of file you want to make and what you want included, supplying any information as needed (or telling the AI where to find it online).\n\nAs usual with these AI bots, the more detail and specificity you can provide, the better‚Äîthe end result is then more likely to be closer to what you were aiming for. I got it to quickly come up with the results of a fictional sports day race, and produce a spreadsheet from it. While it's not the most demanding of tasks, Claude completed it correctly.\n\nConnectors can hook Claude up to a variety of other apps, sites, and services: So if you want to get it to design something for you in Canva, or manage your messages in Slack, or find some travel deals on Trivago, then Claude can do that for you. The full list of current Connectors gives you some idea of what's possible.\n\nTo get to the Connectors from the Claude prompt box, click the small + (plus) icon in the lower left corner, then choose Add connectors. You can search through Connectors by name, and filter them by type and category. When you select one you like, you'll need to supply your account credentials and give Claude permission to access your account.\n\nYour Connectors of choice are then available from the same sub-menu in the prompt box: You can add more plug-ins and remove existing ones from there. You can either select an app, or specify the name of it in your prompt and Claude should understand what you mean. You can ask for outputs, run searches, and communicate through your connected services.\n\nConnectors can give Claude some handy extra talents. With the Canvas Connector, for example, I was able to create a basic bit of artwork for a birthday party flyer‚Äîsomething that the AI wouldn't have been able to do on its own. I find that access was spotty, however, perhaps a sign of a lot of free users now making use of these tools.\n\nWith Skills, you can \"teach Claude how to complete specific tasks in a repeatable way\" (in the words of the official support document). In old-school computer talk, they might be referred to as macros: batches of set instructions that Claude can repeat whenever you need something doing in a particular way.\n\nTemplates are a good example, whether they're for emails or documents. Rather than just getting Claude to write an email for you, you can set down some basic parameters for the job that include guidelines on tone, length, and style, as well as crucial bits of information (such as your contact details) that always need to be included.\n\nClick your account profile icon (bottom left) in Claude on the web, then choose Settings > Capabilities and click Add under Skills to get started. You can create a Skill through a Claude conversation, by writing out the instructions, or by uploading a Skills file (which is handy for including extra items such as code snippets, as described here).\n\nI took the Create with Claude route to put together a basic way of summarizing PDF reports, with specific guidelines on how many paragraphs and headings to use, and the tone of voice to apply. In the future, rather than typing out those instructions every time I need something summarized, I can just invoke the Skill.",
    "readingTime": 5,
    "keywords": [
      "profile icon",
      "icon bottom",
      "free users",
      "prompt box",
      "file creation",
      "settings capabilities",
      "claude",
      "create",
      "features",
      "instructions"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/claude-premium-ai-features-for-free-users?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHKHWF3SFWBAY3CB4Q84ESXG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.578Z",
    "topic": "tech"
  },
  {
    "slug": "how-duckduckgos-new-encrypted-voice-ai-chat-compares-with-chatgpt-and-gemini",
    "title": "How DuckDuckGo's New Encrypted Voice AI Chat Compares With ChatGPT and Gemini",
    "description": "Duck.ai's voice chat preserves your privacy, but can't compete with similar options from other companies.",
    "fullText": "While OpenAI is pushing ads on its free users, DuckDuckGo's Duck.ai portal is going a different way. Duck.ai is a privacy-first AI chatbot that doesn't use your data for training, but still gives you AI answers using popular models, including those from OpenAI. The data privacy feature goes beyond as well. DuckDuckGo removes all private metadata (like your location and IP address) before prompting the AI model, and it doesn't share anything about you or your device. Your questions, as well as DuckDuckGo's answers, are never used for AI training.\n\nSince its launch in 2024, the portal has only offered a chatbot interface, but now, DuckDuckGo has added a voice mode as well. With voice chat, instead of reading through long and meandering answers, the AI replies in short, to-the-point snippets that are relevant to your query. Duck.ai's take on the feature is competing with those from companies like OpenAI and Google, and it's free‚Äîthough expanded limits are offered for DuckDuckGo subscribers.\n\nDuck.ai's voice chat is opt-in, not mandatory. In fact, you can even use it without a DuckDuckGo account. To try it, head to the Duck.ai portal, then from the sidebar, choose the voice chat option and enable it for your account.\n\nNow, when you click the \"New Voice Chat\" button in the sidebar, Duck.ai's bot will appear. You can start speaking, and the bot will reply to you. Just like ChatGPT or Gemini, this is a continuous voice chat, so you don't need to perform any action to ask follow-up questions. You can also interrupt the AI answer to add clarifications or to ask more questions.\n\nWhile the text prompts let you choose the models (including OpenAI's ChatGPT 5-mini), it's not clear exactly what powers voice chat. DuckDuckGo says that it uses an OpenAI model, but doesn't specify which one it is.\n\nOf course, the real question is how Duck.ai's voice chat holds up against Gemini and ChatGPT. For general knowledge questions, Duck.ai holds its own, but it falters when it comes to the latest news. I asked all three services the same questions, and while some responses were similar, ChatGPT's voice mode offers the best overall user experience by far.\n\nI tested the voice chat features using three different kinds of questions. First, I asked about the upcoming Samsung S26 series; second, we talked about the Roman Empire; and lastly, I asked for some advice on how to get started with coding.\n\nWhen it comes to asking questions about news, like Samsung's S26 release, DuckDuckGo's limitations are immediately evident. It sometimes flat out refuses to answer, saying its knowledge cutoff is 2023. Other times, it gives vague responses about the upcoming event, suggesting I check news sites for the latest information. When pressed for details, like when the event is or the rumors surrounding it, it goes back to its cut-off period excuse.\n\nChatGPT's app, however, gave me a detailed response with all the latest rumors, as well as articles to read for additional information‚Äîbasically, what you'd expect from an AI assistant. Gemini Live provided shorter responses than ChatGPT, though they were accurate. I was able to get Gemini to give me more details in the regular text mode, which reads aloud results if you ask questions using the Mic button, but this defeats the back-and-forth purpose of a voice mode.\n\nDuck.ai didn't fare much better when I asked about the Roman Empire. I asked for a brief overview of the subject, before cutting it off to just ask who the last emperor was. It answered correctly (Romulus Augustulus), and its overview was fine, but lacked details about the transitionary period and exact dates.\n\nAgain, ChatGPT gave me a much more detailed answer (as demonstrated by the screenshot below). Gemini Live's answer, however, was devoid of any real dates, or meaning. Mic mode offered more details, but Google's voice mode was quite limited.\n\nDuck.ai performed better when I asked it about learning how to code. It followed a very similar script to ChatGPT and Gemini, suggesting I learn Python, even offering the same sources for learning (e.g. freeCodeCamp and Harvard CS50 courses).\n\nGemini Live was the outlier here, though, asking follow-up questions about what I'd like to build or practice. It then changed its answers based on my project ideas (switching from Python to JavaScript as the first language I should learn to build web projects). ChatGPT provided an overview, again focusing on Python, and elaborated on the language's barrier to entry when I asked \n\nDuck.ai's voice chat feature is a mixed bag. It can be fast, doesn't use any personal information, and lets you interrupt it. But its limited knowledge base and its inability to give detailed answers are what make it tough to recommend. For the smoothest voice mode experience, ChatGPT is still the king. While DuckDuckGo has the advantage for privacy, you could always use¬†ChatGPT while logged out or in temporary mode to limit the data you share with OpenAI.",
    "readingTime": 5,
    "keywords": [
      "duck.ai portal",
      "duck.ai's voice",
      "voice chat",
      "voice mode",
      "roman empire",
      "gemini live",
      "doesn't",
      "details",
      "feature",
      "knowledge"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/how-duckduckgos-new-encrypted-voice-ai-chat-compares-with-chatgpt-and-gemini?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KH9412V067PAYN9ZB0919XH8/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.408Z",
    "topic": "tech"
  },
  {
    "slug": "apple-music-will-soon-let-you-generate-playlists-with-ai",
    "title": "Apple Music Will Soon Let You Generate Playlists With AI",
    "description": "The new feature is called \"Playlist Playground.\"",
    "fullText": "Over the years, Apple Music has improved its algorithmic playlists. There's now an AI DJ, and you can use ChatGPT to generate playlists. With iOS 26.4, which is currently in beta, Apple wants you to make playlists with its own AI tech. The upcoming update includes a feature called \"Playlist Playground,\" which lets you generate AI playlists directly in the Apple Music app‚Äîas long as you're running iOS 26.4.\n\nI do not recommend installing and running beta versions of iOS on your primary iPhone. Beta software is unfinished, which means you could run into bugs and glitches that may impact how you use your iPhone, or even result in data loss. If you're itching to try out new features, it's best to ensure that you've taken a complete backup of your iPhone first. That way, you can always revert to an older installation in case something goes wrong. Even so, it's safer to run test software on a backup iPhone as opposed to your daily driver.\n\nWith that said, if you're sure you want to go ahead and install iOS 26.4 right now, you can go to Settings > General > Software Update on your iPhone. Select Beta Updates > iOS 26 Developer Beta. Now, go back to the Software Update page and wait until you see iOS 26.4 Beta 1 appear. You can now download and install the update to try this new Apple Music feature.\n\nOnce you're on iOS 26.4, you can open the Music app to get started with this feature. Tap the Library tab in the bottom bar, and then select the New Playlist button in the top-right corner. You should see the Playlist Playground feature here. (Note that this feature may not appear on devices that don't support Apple Intelligence, or if your Apple Account is from a region where Apple has restricted the rollout of AI features.)\n\nOnce you activate the feature, you'll be able to generate playlists with AI. From here, you tell the AI what you want to listen to. You could get specific, with certain artists, songs, or genres, or ask for playlists that encompass a certain idea of mood. Apple has some pre-written prompts to get you started, such as \"hip-hop party songs,\" but you can use your own text prompts too. AI-generated playlists have 25 songs by default, and you do have the option to customize the playlist further after it's created. You'll also be able to edit the title, cover image, and the description of AI-generated playlists. These playlists can be shared with others or displayed on your Apple Music profile, just like other playlists you create on the streaming service. It's similar in concept to other AI playlist generators on platforms like Spotify or YouTube Music.\n\nWhile Apple Music's Playlist Playground feature is a good start, it's not yet available to those of us who are unwilling to install developer beta versions of iOS 26. If that's you, there are other options out there for AI generated Apple Music playlists. There's the aforementioned ChatGPT integration, of course, but you could also use a third-party app, like PlaylistAI. It has many prompts for you to get started with, and can even generate playlists from music festival posters. The app does prompt you to get a subscription, but you can skip that prompt and use the free tier to generate a playlist quickly.",
    "readingTime": 3,
    "keywords": [
      "playground feature",
      "playlists there's",
      "ai-generated playlists",
      "apple music",
      "beta versions",
      "developer beta",
      "generate playlists",
      "playlist playground",
      "iphone",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apple-music-will-soon-let-you-generate-playlists-with-ai?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHP8M521BVVYXZQ0AG2D8V3G/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.372Z",
    "topic": "tech"
  },
  {
    "slug": "proxima-local-opensource-multimodel-mcp-server-no-api-keys",
    "title": "Proxima ‚Äì local open-source multi-model MCP server (no API keys)",
    "description": "Multi-AI MCP Server - Connect ChatGPT, Claude, Gemini & Perplexity to your coding tools without any API - Zen4-bit/Proxima",
    "fullText": "Zen4-bit\n\n /\n\n Proxima\n\n Public\n\n Multi-AI MCP Server - Connect ChatGPT, Claude, Gemini & Perplexity to your coding tools without any API\n\n License\n\n View license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Zen4-bit/Proxima",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Zen4-bit/Proxima",
    "thumbnail_url": "https://opengraph.githubassets.com/da1ce1c4daf052f563ec5615a17f7062e6ab435c084a9666f41483e54046eef5/Zen4-bit/Proxima",
    "created_at": "2026-02-17T12:37:44.260Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-coming-for-whitecollar-jobs-a-22yearold-developers-view-from-nepal",
    "title": "AI Is Coming for White-Collar Jobs ‚Äì A 22-Year-Old Developer's View from Nepal",
    "description": "Andrew Yang says AI will wipe out millions of white-collar jobs. As a 22-year-old developer in Nepal, here's my honest take.",
    "fullText": "I read Andrew Yang's latest article, \"The End of the Office,\" yesterday. He called what's happening to white-collar jobs \"the Fuckening.\" As a 22-year-old developer in Nepal who's building his entire career on sitting at a desk and looking at a computer... yeah, that hit different.\n\nYang's not some random guy on Twitter dooming. He ran for president on this exact issue. He's been saying \"AI is coming for your jobs\" since before most of us took it seriously. And now his tone has shifted from warning to mourning.\n\nMillions of office jobs will evaporate in the next 12 - 24 months. This will be an epic disaster for millions of workers and families. https://t.co/6829id4rME\n\nI sat with this one for a while. Not because it's new information. But because it forced me to think about what I'm actually building toward.\n\nThe article is blunt. There are about 70 million white-collar workers in the United States. Yang expects that number to drop by 20-50% over the next several years. Not decades. Years.\n\nHe talked to the CEO of a publicly traded tech company who laid it out: \"We're firing 15% of workers right now. We'll probably do another 20% two years from now. And then another 20% two years later. After that, who knows?\"\n\nCollege grads? Only 30% are finding jobs in their field. Underemployment is at 52%. The social contract of \"study hard, go to school, get a good job\" is, in Yang's words, about to be \"vaporized to smithereens.\"\n\nHe also made a point that stuck with me: someone in his family had AI program a website this week. It completed in minutes what used to take a designer or a firm days of work.\n\nI build websites. That one was personal.\n\nThe comments on Twitter and Reddit were honestly more unsettling than the article itself. Not because they were doomy. Because they were specific.\n\nOne senior software developer wrote: \"I noticed we just stopped hiring new people a few years ago. Not because management made any decision about it, we just didn't NEED anyone. I'm not too worried about losing my job in the next 2 years, but I do worry that if I become unemployed, I may never find another job again.\"\n\nRead that again. A senior dev. Not worried about being fired. Worried about being unhirable if they ever need to look for work again.\n\nAnother commenter nailed something I'd been thinking: \"I don't fear the legacy companies laying off tons of people. What I fear are new companies entering the market doing the same as current companies with a tenth of the employees.\"\n\nThat's the part people miss. It's not just about big companies cutting staff. It's about small teams doing what big teams used to do. A 5-person startup with AI tools competing against a 500-person company. That changes everything.\n\nThen there was the purchasing power question that nobody seems to have a good answer for. If millions lose their jobs, who's buying the products these AI-powered companies are making? Who's paying for iPhones and Netflix subscriptions? One commenter put it perfectly: \"Will unemployed people surviving on growing their own vegetables be buying $1,500 smartphones?\"\n\nNobody had a convincing answer. The best response was basically: \"Yeah, that's a problem for the next CEO.\"\n\nMost of this conversation is happening through an American lens. \"Mid-career managers making six figures\" being laid off. \"Mortgage delinquencies rising.\" \"Silicon Valley home prices dropping.\"\n\nI'm reading this from Ghorahi, Nepal. My reality is different.\n\nI don't have a mortgage. I'm not making six figures. I'm a BCA student freelancing as a frontend developer for a remote company. My cost of living is a fraction of what Americans deal with. In theory, that should make me more resilient. Even if the market gets competitive, I can survive on less.\n\nBut here's the catch. The entire plan for developers like me in Nepal was: learn to code, get good, land a remote job with a company abroad, earn in dollars. That was the path. AI threatens to cut that ladder off at the knees.\n\nWhy would a US startup hire a remote developer from Nepal when Claude can write the code for them? The cost advantage I used to have? AI just undercut it to nearly zero.\n\nIt's a double-edged thing. Lower cost of living means I can weather the storm longer. But the opportunity that was supposed to lift me up - remote work for global companies - might not exist the same way in two years.\n\nI don't have it figured out. But I'm not sitting still either.\n\nThe biggest shift is that I stopped just \"learning to code.\" Knowing Python or React isn't a moat anymore. AI writes decent code. What it doesn't do well is understand what to build, for whom, and why. So I've been shipping actual products - hackathon projects, side projects, freelance work. Taste matters more than syntax now.\n\nI use Claude. I use AI coding assistants daily. Some devs have this weird pride about not using AI. I think that's like refusing to use Stack Overflow in 2015. The tool isn't the threat. Being replaced by someone who uses the tool better than you - that's the threat.\n\nThis blog exists because if AI can do what I do technically, the differentiator becomes who I am. My perspective, my story, my network. A developer from Nepal who ships products and writes about it. AI can't be that.\n\nI've also been focusing on end-to-end ownership. Not just \"I know React\" or \"I know Django\" but taking an idea from zero to deployed product with user feedback loops. That full cycle is harder to automate than any single skill. And hackathons have been the best training ground for this - three wins so far, each one teaching me more about product thinking than any tutorial ever did.\n\nYang wrote about the social contract being vaporized. \"Study hard, go to school, get a good job, live a decent life.\" He's talking about American workers who followed that contract and now feel betrayed.\n\nBut what about people like me who are still IN school? Who are halfway through the contract? I'm in my 6th semester. I'm doing everything \"right.\" Learning relevant technologies. Building projects. Getting work experience. And the ground is shifting under my feet while I'm still on it.\n\nThere's a weird psychology here that I don't see people discussing. Yang's audience is mostly people who had stability and might lose it. I never had that stability. Growing up in Nepal, the idea of a guaranteed career path was always a bit of a fantasy anyway. There was never a corporate ladder waiting for me.\n\nAnd honestly? There's a strange freedom in that.\n\nI don't have to grieve the loss of a career path I never had. I can just... adapt. Build. Figure it out as I go. Which is basically what I've been doing anyway.\n\nBut let me be real. There's also fear. Real fear. Because the one thing that was supposed to be the great equalizer - the internet and remote work letting talented people anywhere compete globally - might be getting disrupted right when I need it most.\n\nI don't have a clean conclusion. Nobody does right now. Yang says \"batten down the hatches.\" The Reddit comments range from \"we're all screwed\" to \"this is overblown\" to \"learn plumbing.\"\n\nI'd rather be the person building with AI than the person being replaced by it. I'd rather ship 10 imperfect products than have a perfect resume that nobody's hiring for. Maybe that's naive. But right now, sitting at my desk in Nepal, I can either panic or build.",
    "readingTime": 7,
    "keywords": [
      "i'd rather",
      "social contract",
      "career path",
      "don't",
      "jobs",
      "developer",
      "that's",
      "remote",
      "workers",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.bhusalmanish.com.np/blog/posts/ai-jobs-nepal-dev-perspective.html",
    "thumbnail_url": "https://cdn.bhusalmanish.com.np/Featured%20Image/og-image-ai-jobs-nepal-dev-perspective/og-image-ai-jobs-nepal-dev-perspective.jpg",
    "created_at": "2026-02-17T12:37:43.787Z",
    "topic": "tech"
  },
  {
    "slug": "log-poisoning-in-openclaw",
    "title": "Log Poisoning in OpenClaw",
    "description": "Eye Security explores an indirect prompt injection risk in OpenClaw‚Äôs WebSocket logging, explains what an exploit might look like, and highlights context, impact, responsible disclosure, and practical next steps for secure AI assistant deployments.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://research.eye.security/log-poisoning-in-openclaw/",
    "thumbnail_url": "https://research.eye.security/wp-content/uploads/ChatGPT-Image-Feb-5-2026-10_27_20-PM-1024x683.png",
    "created_at": "2026-02-17T12:37:43.388Z",
    "topic": "science"
  },
  {
    "slug": "70-ai-providers-under-same-rust-interface",
    "title": "70+ AI Providers Under Same Rust Interface",
    "description": "The AI Toolkit for Rust, inspired by the Vercel AI SDK. - lazy-hq/aisdk",
    "fullText": "lazy-hq\n\n /\n\n aisdk\n\n Public\n\n The AI Toolkit for Rust, inspired by the Vercel AI SDK.\n\n aisdk.rs\n\n License\n\n MIT license\n\n 131\n stars\n\n 12\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lazy-hq/aisdk",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/lazy-hq/aisdk",
    "thumbnail_url": "https://opengraph.githubassets.com/82e8941ec05e97907f49673ca6b3967853e0d46b7cf37ab5a3b0c930d1bd07d2/lazy-hq/aisdk",
    "created_at": "2026-02-17T12:37:43.280Z",
    "topic": "tech"
  },
  {
    "slug": "preventing-runaway-llm-agents-enforcement-layer",
    "title": "Preventing runaway LLM agents (enforcement layer)",
    "description": "Zero-dep runtime enforcement for LLM agents. Budget limits, concurrency gates, degradation control. - amabito/veronica-core",
    "fullText": "amabito\n\n /\n\n veronica-core\n\n Public\n\n Zero-dep runtime enforcement for LLM agents. Budget limits, concurrency gates, degradation control.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n amabito/veronica-core",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/amabito/veronica-core",
    "thumbnail_url": "https://opengraph.githubassets.com/8796645fd444b302d36804ac9bc560d5fe9c75cbf526d9d9b174f14966b5da13/amabito/veronica-core",
    "created_at": "2026-02-17T12:37:43.154Z",
    "topic": "tech"
  },
  {
    "slug": "teaching-ai-at-elementary-school",
    "title": "Teaching AI at Elementary School",
    "description": "January 2026 - I recently taught a 1-hour class on AI at my daughter's school. My ambitious goals were: (i) live demos of image and video generation; (ii) incorporate all students (40) and teachers (5) into the generations. [Almost everything worked out!](school)",
    "fullText": "I am super happy with my daughter Kate‚Äôs school! The Montessori system is very clever, as it places children of different ages into one class; then, children form working groups according to their skills. The children work with older children on subjects they are mastering well and with younger children if they need more time to consolidate their learning.\n\nLast fall, the school asked parents to teach the children about their professions; what a program they got! For example, a neuro-surgeon who investigates the source of consciousness through fMRI scans, a heart surgeon, a high-frequency trader, an aviator, an architect, a politician, and‚Ä¶. a computer science professor :-) These encounters helped give meaning to the children‚Äôs learning and opened their imaginations to the scientific and technological careers of tomorrow.\n\nI set myself as main goal: show many interactive demos that include the listeners as much as possible. The AR part was easy, as we simply showed a controllable virtual dinosaur demolishing the room, as well as a makeup try-on application.\n\nFor the Generative AI (GenAI) part, I wanted to show the generation of images and videos that incorporate all listeners. Due to the short time available, it was very challenging. I had to design workflows that are:\n\nIt was an unexpected adventure that took me more time than I would have predicted!\n\nAs demo platform, I was using my regular setup (multiple 4 x H100 servers running in the university‚Äôs data center), so compute power was not an issue. With ComfyUI, I was sure to be able to run the latest bleeding edge GenAI models.\n\nAs there were many more children than teachers, my rough plan was:\n\nMy first idea failed hard, even though I tried very hard to make it work. This took most of my preparation time!\n\nI estimated that all this could be completed in 15 minutes, as the two phases would be massively parallel üòâ.\n\nUnexpectedly, the open source models that I tried (Flux2 Dev, Qwen-Image-Edit) failed to give consistent results. In my extensive tests, I discovered that while nice generations can be really very nice, there are just way to many failures when trying to swap in 4 humans at the same time.\n\nIn the end, untypically for me, I even tried closed weights models. It did not go much better.\n\nI finally decided to do this part completely different: use a high-speed, high-quality image generator and let the children come up with the prompts! This worked beautifully. We went for Z-Image, as it can generate 1 megapixel images in just over 1 second.\n\nThis part was way easier, as the overall throughput needs to be lower than the image part. I prepared a WanAnimate workflow that can generate a 10 second video in 1 minute. As steps during the class, I planned:\n\nFirst, Kate and me demonstrated the capabilities of Z-Image:\n\nThen, the children in the class could tell me their prompts. Here are some results:\n\nFirst, I showed a slide with: the basic effect of replacing subjects in a video (left), for different subjects (middle), and videos (right):\n\nThen, generation time started! Note that I have blurred the children and the faces of teachers to preserve privacy. The first teacher decided to swap herself with Indira Gandhi:\n\nThe second one was a fan of Louis de Fun√®s:\n\nIn between those, I made a funny mistake as I forgot to swap the input images, so we have Indira Ghandi moving like Louis de Fun√®s üôà\n\nI was glad about the results! During the demonstrations, the children were absolutely mesmerized. Right after the presentation, a boy came to me with glowing eyes and told me: ‚ÄúI want to learn how to do this!‚Äù.\n\nAfterwards, I received several messages from parents, who thanked me and described how excited their children came home after school on that day! The funniest feedback was from another parent: ‚ÄúSo, when are you gonna teach this class to us parents?‚Äù (shameless plug: you can already book me for the adult version of this class!).\n\nLooking forward to teaching this class again next year!",
    "readingTime": 4,
    "keywords": [
      "children",
      "class",
      "school",
      "subjects",
      "parents",
      "images",
      "models",
      "swap",
      "second",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://drsandor.net/ai/school/",
    "thumbnail_url": "https://drsandor.net/ai/school/featured.jpg",
    "created_at": "2026-02-17T12:37:42.915Z",
    "topic": "tech"
  },
  {
    "slug": "context-lens-view-your-clis-agent-context-in-realtime",
    "title": "Context Lens: View your CLI's agent context in realtime",
    "description": "See what your AI sees. Framework-agnostic LLM context window visualizer. - larsderidder/context-lens",
    "fullText": "larsderidder\n\n /\n\n context-lens\n\n Public\n\n See what your AI sees. Framework-agnostic LLM context window visualizer.\n\n License\n\n MIT license\n\n 15\n stars\n\n 5\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n larsderidder/context-lens",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/larsderidder/context-lens",
    "thumbnail_url": "https://opengraph.githubassets.com/78d5d1dba7ea3e601ec21745ee20cfc89e01235bcbbb0ea36b614b229fcd2837/larsderidder/context-lens",
    "created_at": "2026-02-17T12:37:42.730Z",
    "topic": "tech"
  },
  {
    "slug": "meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims",
    "title": "Meta plans to add facial recognition to its smart glasses, report claims",
    "description": "The feature, internally known as ‚ÄúName Tag,‚Äù would allow smart glasses wearers to identify people and get information about them via Meta's AI assistant.",
    "fullText": "Meta plans to add facial recognition to its smart glasses as soon as this year, according to a new report from The New York Times. The feature, internally known as ‚ÄúName Tag,‚Äù would allow smart glasses wearers to identify people and get information about them through Meta‚Äôs AI assistant.\n\nMeta‚Äôs plans could change, the report notes. The tech giant has been deliberating since early last year on how to release a feature that carries ‚Äúsafety and privacy risks.‚Äù\n\nAccording to an internal memo, the company had originally planned to release Name Tag to attendees of a conference for the visually impaired before releasing it to the public, but didn‚Äôt end up doing that.\n\nMeta reportedly saw the political tumult in the United States as a good time to release the feature.\n\n‚ÄúWe will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,‚Äù the document reads.\n\nMeta considered adding facial recognition technology to the first version of its Ray-Ban smart glasses back in 2021, but dropped the plans over technical challenges and ethical concerns. The NYT reports that the company has revived its plans as the Trump administration has grown closer to Big Tech, and following the unexpected success of its smart glasses.",
    "readingTime": 2,
    "keywords": [
      "facial recognition",
      "smart glasses",
      "name tag",
      "plans",
      "feature",
      "release",
      "political",
      "concerns",
      "meta",
      "meta‚Äôs"
    ],
    "qualityScore": 0.75,
    "link": "https://techcrunch.com/2026/02/13/meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/05/meta-smart-glasses.jpg?w=780",
    "created_at": "2026-02-17T12:37:42.148Z",
    "topic": "tech"
  },
  {
    "slug": "consulting-firms-have-built-thousands-of-ai-agents-now-theyre-trying-to-figure-out-their-worth",
    "title": "Consulting firms have built thousands of AI agents. Now they're trying to figure out their worth.",
    "description": "Consultants at McKinsey, PwC, EY, and BCG raced to adopt AI. Now they're racing to measure it's actual value.",
    "fullText": "Big questions are swirling around AI's real impact ‚Äî and consultants are racing to supply the answers.\n\nOver the past year, consulting firms have begun deploying armies of AI agents as they work to transform their own operations and advise clients to do the same ‚Äî automating research, building task-specific tools, and building proprietary AI models.\n\nMcKinsey & Company CEO Bob Sternfels said last month that his firm has launched tens of thousands of internal AI agents in recent years, and eventually plans to have one for all of the company's 40,000 employees.\n\nAmid the rapid rollout, consultants are now asking themselves a tough question: Is it worth it? They are working to measure if AI is truly improving performance, boosting revenue, and freeing consultants to focus on higher-value work.\n\n\"I think we are now in the age of confusion,\" Mina Alaghband, a former McKinsey partner, now the chief customer officer at Writer, a full-stack enterprise AI platform built for agentic AI, told Business Insider.\n\nAlaghband said that a year ago, most companies were focused on adoption, tracking metrics such as how often a tool was used.\n\nNow, she says said the emphasis should be on measuring the value that's created ‚Äî like the amount of human labor reassigned to higher-value work, or improvements in revenue.\n\nPwC's chief AI officer, Dan Priest, recently told Business Insider that PwC is now less concerned with how many agents it deploys, and more with how many human users each agent has.\n\nPriest said his firm starts by targeting an \"impact zone,\" such as improving the customer experience.\n\nWithin these impact zones, the firm looks to deploy \"specialized AI agents\" that have earned that designation because they're good at what they do, Priest said. \"When we deploy agents, we want to see a high rate of human adoption, which means more humans are using them,\" he said.\n\nEY also prioritizes quality over quantity, Steve Newman, EY's global engineering chief, told Business Insider. The firm tracks the value created by its AI agents through key performance indicators for productivity, quality, and cost efficiency on a month-to-month basis.\n\nIf the defining promises of the AI boom are speed and efficiency, then the metric that may matter more isn‚Äôt usage, but time reclaimed.\n\nBoston Consulting Group tracks its agents by that metric ‚Äî and whether that time is then reinvested in higher-value work, Scott Wilder, a partner and managing director based in Dallas, told Business Insider.\n\nWilder said humans at the firm now spend about 15% less time on low-value activities, like making slideshows, and that those people are reinvesting about 70% of their saved time into higher-value activities, such as deeper analysis.\n\nTime saved doesn't always mean more work. At BCG, it can mean more free time. Wilder said BCG has found that employees keep about 30% of the time AI saves. \"They get a little more sleep or get to go to a yoga class or whatever someone wants to do,\" he said.\n\nNearly a century ago, economist John Keynes predicted that as productivity rose, the balance between work and leisure would inevitably change.\n\n\"I would predict that the standard of life in progressive countries one hundred years hence will be between four and eight times as high as it is,\" he wrote in his 1930 essay \"Economic Possibilities for our Grandchildren.\"\n\nIt's almost 2030, but in small ways, that vision may already be surfacing.\n\n\"It's benefiting them ‚Äî and this is a tough job, so every hour of free time matters,\" Wilder said.\n\nSomething to share about how consultants are using AI? Business Insider would like to hear from you. Email Lakshmi Varanasi at lvaranasi@businessinsider.com or contact her on Signal at lvaranasi.70.",
    "readingTime": 4,
    "keywords": [
      "agents",
      "firm",
      "consultants",
      "higher-value",
      "impact",
      "chief",
      "human",
      "mckinsey",
      "employees",
      "tough"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-bcg-pwc-ey-ai-agents-adoption-value-consulting-industry-2026-2",
    "thumbnail_url": "https://i.insider.com/6990e192a645d118818962f1?width=1200&format=jpeg",
    "created_at": "2026-02-17T12:37:38.026Z",
    "topic": "finance"
  },
  {
    "slug": "ive-helped-lead-ai-adoption-at-both-pwc-and-freshworks-here-are-3-common-ai-mistakes-i-see-workers-making",
    "title": "I've helped lead AI adoption at both PwC and Freshworks. Here are 3 common AI mistakes I see workers making.",
    "description": "Geetha Rajan used to lead upskilling for over 50,000 employees at PwC. She cautions workers against outsourcing their thinking to AI tools.",
    "fullText": "This as-told-to essay is based on a conversation with Geetha Rajan, a director on the global strategy team at Freshworks, a SaaS company. She's based in the San Francisco Bay Area. Her identity and employment have been verified by Business Insider. The following has been edited for length and clarity.\n\nI'm a director on the global strategy team at Freshworks, where I drive high-priority strategic initiatives that shape the company's growth, investment decisions, and execution, including on AI adoption.\n\nPreviously, I spent nearly a decade at PwC advising Fortune 500 companies across healthcare, financial services, and technology on growth strategy and digital transformation. As part of my role, I led the upskilling of over 50,000 employees on automation tools.\n\nTechnological transformation has always been happening, but the cloud or mobile transformation took at least 10 years to fully adopt. ChatGPT hit millions of users in the first few months.\n\nA lot of employers will keep expecting that you use AI every day without really understanding the consequences. That's the pressure that actually leads you to make more mistakes rather than use it thoughtfully.\n\nThese are some of the mistakes I see that make employees making when adopting AI:\n\nA lot of people try to jump straight into becoming Iron Man and fully automate their workflow. It should be a process. The first step is treating AI or the technology as a super intern, so you have the most control over things while giving it low agency.\n\nFor example, if you start with giving structured data, but you verify every output. AI can hallucinate outputs that are beautifully formatted.\n\nI'm a strategy consultant and advisor. So, in terms of the ideation and thinking, that's the one part I don't usually outsource to AI.\n\nThis has come through a lot of experience in consulting and being in the workforce itself. I first want to mentally write down my model and first principles. I definitely verify numbers and even try to extract unstructured data from AI, but I still write my first draft very rigorously, keeping my first-principles hat on.\n\nAfter you've completed a draft, you can ask it to poke holes and say, \"Hey, you are the most skeptical board member, or the CFO, poke holes in my strategy.\"\n\nA lot of AI outputs are really polished. But if you don't have that acumen, if you haven't seen this enough number of times, you actually can't tell if an AI is actually making a mistake or not. This is where a lot of the workslop comes in: You just take the AI output and throw it into an email or an analysis.\n\nI've made this mistake myself, where I had five or 10 minutes, and I asked AI to quickly write down some design principles for me and throw them on a slide. When I was presenting, I was like, \"Wait, I don't think this makes sense, and this is not what I was actually trying to say.\" I actually embarrassed myself.\n\nYou can also easily get caught up in a situation where the language AI uses is not something you would use colloquially or even in a professional setting.\n\nSometimes my biggest worry is what happens five years from now ‚Äî when nobody actually did that initial job, and we're burning the ladder as we try to climb it. As much as AI can do things, I think it's more about the commitment to yourself that you still learn problem-solving skills and how to use Excel.\n\nYou need to know exactly who you're solving for and what the purpose of solving that exercise is.\n\nFor example, if you're building an AI model to understand your business's customer segments, you still need to know your segments at a high level. That's the part I would never outsource. If you don't have that context yourself, you could just go in a million directions.\n\nThe fundamental things about taste, process, architecture, how you build things ‚Äî those don't come from any tool, irrespective of whether you're using ChatGPT or the latest model. If AI throws 50 ideas at you, you need to know which one of those is going to stick. As an employee, it is your responsibility to pick the right one, so you need the acumen and expertise to do so.",
    "readingTime": 4,
    "keywords": [
      "poke holes",
      "strategy team",
      "don't",
      "transformation",
      "that's",
      "model",
      "you're",
      "based",
      "director",
      "growth"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-mistakes-to-avoid-freshworks-strategy-director-2026-2",
    "thumbnail_url": "https://i.insider.com/698f8936a645d11881895974?width=1200&format=jpeg",
    "created_at": "2026-02-17T12:37:38.021Z",
    "topic": "finance"
  },
  {
    "slug": "claims-that-ai-can-help-fix-climate-dismissed-as-greenwashing",
    "title": "Claims that AI can help fix climate dismissed as greenwashing",
    "description": "Industry using ‚Äòdiversionary‚Äô tactics, says analyst, as energy-hungry complex functions such as video generation and deep research proliferate\nTech companies are conflating traditional artificial intelligence with generative AI when claiming the energy-hungry technology could help avert climate breakdown, according to a report.\nMost claims that AI can help avert climate breakdown refer to machine learning and not the energy-hungry chatbots and image generation tools driving the sector‚Äôs explosive growth of gas-guzzling datacentres, the analysis of 154 statements found.\n Continue reading...",
    "fullText": "Industry using ‚Äòdiversionary‚Äô tactics, says analyst, as energy-hungry complex functions such as video generation and deep research proliferate\n\nTech companies are conflating traditional artificial intelligence with generative AI when claiming the energy-hungry technology could help avert climate breakdown, according to a report.\n\nMost claims that AI can help avert climate breakdown refer to machine learning and not the energy-hungry chatbots and image generation tools driving the sector‚Äôs explosive growth of gas-guzzling datacentres, the analysis of 154 statements found.\n\nThe research, commissioned by nonprofits including Beyond Fossil Fuels and Climate Action Against Disinformation, did not find a single example where popular tools such as Google‚Äôs Gemini or Microsoft‚Äôs Copilot were leading to a ‚Äúmaterial, verifiable, and substantial‚Äù reduction in planet-heating emissions.\n\nKetan Joshi, an energy analyst and author of the report, said the industry‚Äôs tactics were ‚Äúdiversionary‚Äù and relied on tried and tested methods that amount to ‚Äúgreenwashing‚Äù.\n\nHe likened it to fossil fuel companies advertising their modest investments in solar panels and overstating the potential of carbon capture.\n\n‚ÄúThese technologies only avoid a minuscule fraction of emissions relative to the massive emissions of their core business,‚Äù said Joshi. ‚ÄúBig tech took that approach and upgraded and expanded it.‚Äù\n\nMost of the claims that were scrutinised came from an International Energy Agency (IEA) report, which was reviewed by leading tech companies, and corporate reports from Google and Microsoft.\n\nThe IEA report ‚Äì which devoted two chapters to the potential climate benefits of traditional AI ‚Äì had a roughly even split between claims that rested on academic publications, corporate websites and those that had no evidence, according to the analysis. For Google and Microsoft, most claims lacked evidence.\n\nThe analysis, released during the AI Impact Summit in Delhi this week, argues the tech industry has misleadingly presented climate solutions and carbon pollution as a package deal by ‚Äúmuddling‚Äù types of AI.\n\nSasha Luccioni, AI and climate lead at Hugging Face, an open-source AI platform and community, who was not involved in the report, said it added nuance to a debate that often lumped very different applications together.\n\n‚ÄúWhen we talk about AI that‚Äôs relatively bad for the planet, it‚Äôs mostly generative AI and large language models,‚Äù said Luccioni, who has pushed the industry to be more transparent about its carbon footprint.\n\n‚ÄúWhen we talk about AI that‚Äôs ‚Äògood‚Äô for the planet, it‚Äôs often predictive models, extractive models, or old-school AI models.‚Äù\n\nGreen claims even for traditional AI tended to rely on weak forms of evidence that had not been independently verified, the analysis found. Only 26% of the green claims that were studied cited published academic research, while 36% did not cite evidence at all.\n\nOne of the earliest examples identified in the report was a widespread claim that AI could help mitigate 5-10% of global greenhouse gas emissions by 2030.\n\nThe figure, which Google repeated as recently as April last year, came from a report it commissioned from BCG, a consulting firm, which cited a blogpost it wrote in 2021 that attributed the figure to its ‚Äúexperience with clients‚Äù.\n\nDatacentres consume just 1% of the world‚Äôs electricity but their share of US electricity is projected to more than double to 8.6% by 2035, according to BloombergNEF. The IEA predicts they will account for at least 20% of the rich world‚Äôs growth in electricity demand to the end of the decade.\n\nWhile the energy consumption of a simple text query to a large language model such as ChatGPT may be as little as running a lightbulb for a minute, partial industry disclosures suggest, it rises considerably for complex functions such as video generation and deep research, and has troubled some energy researchers with the speed and scale of its growth.\n\nA spokesperson for Google said: ‚ÄúOur estimated emissions reductions are based on a robust substantiation process grounded in the best available science, and we have transparently shared the principles and methodology that guide it.‚Äù\n\nMicrosoft declined to comment, while the IEA did not respond to requests for comment.\n\nJoshi said the discourse around AI‚Äôs climate benefits needed to be ‚Äúbrought back to reality‚Äù.\n\n‚ÄúThe false coupling of a big problem and a small solution serves as a distraction from the very preventable harms being done through unrestricted datacentre expansion,‚Äù he said.",
    "readingTime": 4,
    "keywords": [
      "complex functions",
      "planet it‚Äôs",
      "deep research",
      "green claims",
      "avert climate",
      "climate breakdown",
      "climate benefits",
      "emissions",
      "industry",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/17/tech-companies-traditional-ai-generative-climate-breakdown-report",
    "thumbnail_url": "https://i.guim.co.uk/img/media/81a5a055326cef41e145cb74127306aadb720004/624_0_6257_5006/master/6257.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=810d5d4728a8311c1728f2c264922ab5",
    "created_at": "2026-02-17T12:37:36.840Z",
    "topic": "tech"
  },
  {
    "slug": "alexalike-voice-interface-for-openclaw",
    "title": "Alexa-like voice interface for OpenClaw",
    "description": "An open-source voice agent built on the PamirAI Distiller device, combining speech recognition, and text-to-speech to create a conversational AI assistant with OpenClaw you can talk to. - sachaabot...",
    "fullText": "sachaabot\n\n /\n\n openclaw-voice-agent\n\n Public\n\n An open-source voice agent built on the PamirAI Distiller device, combining speech recognition, and text-to-speech to create a conversational AI assistant with OpenClaw you can talk to.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sachaabot/openclaw-voice-agent",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sachaabot/openclaw-voice-agent",
    "thumbnail_url": "https://opengraph.githubassets.com/693f92e2c77f47abb871b79bae4c5f77d30b04e87eb9b5468b681ec97ea68415/sachaabot/openclaw-voice-agent",
    "created_at": "2026-02-17T06:45:26.489Z",
    "topic": "tech"
  },
  {
    "slug": "fujitsu-aidriven-software-development-platform",
    "title": "Fujitsu AI-Driven Software Development Platform",
    "description": "Fujitsu Limited today announced the development and launch of its AI-Driven Software Development Platform, a new initiative to bring software development into the AI age and contribute to the sustainable growth of its customers and society.",
    "fullText": "Kawasaki, Japan, February 17, 2026\n\nFujitsu Limited today announced the development and launch of its AI-Driven Software Development Platform, a new initiative to bring software development into the AI age and contribute to the sustainable growth of its customers and society. This platform automates the entire software development process, from requirements definition and design to implementation and integration testing. By leveraging the Takane large language model (LLM) [1] and agentic AI technology for large-scale software development developed by Fujitsu Research, the AI-Driven Software Development Platform enables AI agents to understand complex, evolving large-scale systems owned by enterprises and public organizations. The platform has multiple AI agents collaboratively execute each stage of software development, achieving full automation of the entire process without human intervention.\n\nFujitsu aims to use this AI-Driven Software Development Platform to carry out revisions to all 67 types of medical and government business software products provided by Fujitsu Japan Limited by the end of fiscal year 2026. The revisions are necessary due to legal and regulatory changes. From January 2026, the platform has been used in Japan for software modifications made necessary by the 2026 medical fee revisions¬†[2]. In a PoC that updated software as per the 2024 medical fee revisions, the platform demonstrated a significant reduction in development time for one of approximately 300 change requests. Using conventional software development methods [3] the modifications would have taken three person-months. With this technology that was dramatically shortened to four hours, achieving a 100-fold increase in productivity.\n\nIn AI-driven development, Fujitsu positions AI-Ready Engineering‚Äîthe process of preparing assets and knowledge to ensure AI correctly understands existing systems and achieves highly reliable automation‚Äîas crucial. With AI-Ready Engineering and the AI-Driven Software Development Platform working in tandem, Fujitsu will accelerate AI-driven software development. Fujitsu will promote a transformation in engineers' work styles, strengthening its Forward Deployed Engineer (FDE) complement, and shifting the paradigm of software development from a conventional person-month-based approach to a customer value-based approach.\n\nMoving forward, Fujitsu plans to expand the application of the AI-Driven Software Development Platform to a wide range of sectors, including finance, manufacturing, retail, and public services, by the end of fiscal year 2026. Fujitsu will also begin offering this service to customers and partner companies to enable them to rapidly and flexibly develop systems that adapt to changes in their business environments. Through these efforts, Fujitsu aims to transform the software development process into an AI-driven model as an industry standard.\n\n(Order that companies appear is aligned with the original Japanese press release)\n\nTakashi Manabe, Senior Research Director, AI & Automation, IDC Japan\n‚ÄúIDC forecasts that from 2026 onward, the acceleration of AI/agent-based business utilization and the modernization of existing systems will be key drivers of transformation in the Japanese IT market. Fujitsu‚Äôs announcement aims to redefine complex legacy system assets into a state where AI can accurately understand and process them, and to automate the entire waterfall development process. This initiative is expected to provide a practical pathway for many domestic enterprises facing the ongoing challenge of maintaining and operating legacy assets, while also promoting a shift in software engineering away from a labor-intensive model.‚Äù\n\nShinji Kajitani, Director and President Executive Officer, Optima Corporation\n‚ÄúI am deeply impressed by the concept of automating the entire software development process from upstream to downstream using AI, and even entrusting the verification process to AI. This overturns the traditional assumption that human checks are ultimately indispensable, and I see great potential, especially in targeting business packages that undergo complex system changes every year. Our company has also been involved in business package modifications for many years, and how to complete system revisions with high quality in a short period has always been a major challenge. We believe that the knowledge and expertise accumulated during that process can significantly contribute to the realization and advancement of this concept. Our company will continue to contribute to the business expansion of Fujitsu and Fujitsu Japan through ongoing cooperation, not limited to this project.‚Äù\n\nHiroshi Nakatani, Representative Director, Executive Vice President, Kawasaki Heavy Industries, Ltd.\n\"This AI automation initiative promoted by Fujitsu is not merely about improving development efficiency; we recognize it as a significant challenge to pass on and evolve the extensive business knowledge and design philosophies cultivated by companies over many years to the next generation. In particular, the concept of providing end-to-end support, from requirements definition to design, implementation, and quality assurance, triggered by changes in laws and rules, opens up new possibilities in areas that have traditionally relied on human experience and tacit knowledge. We see great significance in AI functioning as a foundation that supports human judgment and creativity, rather than replacing it.\nIn the manufacturing industry, challenges such as design changes, regulatory compliance, and understanding the scope of impact are becoming increasingly complex year by year. Fujitsu's approach of advancing both knowledge standardization and AI utilization in these areas offers valuable insights for enhancing the productivity and competitiveness of the entire industry.\nKawasaki Heavy Industries sincerely hopes that this initiative will be a crucial step in driving the transformation of Japanese manufacturing and a wide range of other industries, and we wholeheartedly support its further development.\"\n\nYasushi Matsuda, President and CEO, Kewpie Digital Innovation Co., Ltd. \n‚ÄúSystems have become increasingly complex through years of operation and often now require significant maintenance effort. While the introduction of generative AI has improved auditing efficiency, its accuracy remains insufficient for reliable practical application. Amidst this situation, we place great expectations on ‚ÄúMulti-layer Quality Control,‚Äù which automatically corrects ambiguities and omissions. We are confident that this mechanism, where AI itself audits quality and autonomously repeats processes, will dramatically enhance the reliability of system development. We eagerly await its future development.‚Äù\n\nJunichi Aruji, Managing Director, Kintetsu Information System Co., Ltd. \n‚ÄúThe challenge of revamping existing systems has long been a significant one for engineers. Fujitsu‚Äôs AI-Driven Software Development Platform has the potential to dramatically transform the labor previously involved in understanding complex laws and regulations, analyzing vast historical assets, and grasping the tacit knowledge of the field.\nWhat is particularly noteworthy is the AI's ability to autonomously learn \"human intelligence,\" thereby dramatically enhancing the accuracy of requirements definition. Furthermore, it can complete everything from program structure analysis and standardization to the extensive testing phase with incredible speed and comprehensiveness. This makes it possible to deliver high-quality products in a short period.\nAs the role of AI expands and frees people from routine tasks, engineers can focus on more creative activities. I have high expectations for the paradigm shift in system renovation that this solution will bring.‚Äù\n\nYumi Ueno, Managing Director, Partner Ecosystem & Corporate Business, Google Cloud Japan G.K. \n‚ÄúThis initiative to achieve comprehensive, one-stop automation spanning from requirements definition to system validation is a groundbreaking innovation for the industry. The technology enables AI to accurately understand vast assets, including long-established programs and design documentation, and we are delighted at the potential for both production-grade quality and exceptional productivity gains. We are confident that this platform will become the new standard for development and accelerate our customers' digital transformation. We remain committed to working with Fujitsu to address social challenges through AI.‚Äù\n\nMasahiro Niimi, Managing Executive Officer, Head of Information Systems Management Division, CISO, Sakura KCS Corporation \n‚ÄúI believe Fujitsu Limited's AI-driven development framework has the potential to become the ‚Äònew paradigm of system development.‚Äô It cannot be achieved simply by feeding existing code or design information into AI, and while there are various hurdles, such as converting documentation to Markdown and establishing test environments, overcoming these hurdles can lead to solving traditional system development challenges (like QCD).\nWhat particularly caught my attention is not just improvements in the development process, but what comes after generative AI, i.e., the incorporation of detailed specifications and code (logic). I see tremendous potential here as a solution to the greatest challenge: visualizing and transferring the tacit knowledge of veteran software engineers‚Äô that is traditionally missing from documentation. We expect generative AI to act as an advisor for less experienced software engineers, readily answering questions anytime, thereby dramatically advancing know-how transfer to the next generation. On the other hand, this mechanism also has the potential to dramatically change the traditional SI business model, and we are watching future developments closely.‚Äù\n\nTakao Kazama, Executive Officer, Group Companies and Accounting & Finance, The Shizuoka Shimbun and Shizuoka Broadcasting Co., Ltd. \n\"This initiative for complete automation of application development and maintenance represents a highly valuable transformation for our company. It formalizes and establishes a reproducible process for tasks that have long relied on the implicit knowledge and experience of individual staff members, and we have great expectations for it. In particular, it has the potential to significantly improve quality variations in legacy system maintenance and lost opportunities due to delayed change responses. Furthermore, the evolving ability of AI to perform root cause analysis and identify necessary additional information is a major step towards advanced and efficient system operations, with the potential to change the very nature of system development. We share Fujitsu's commitment to improving productivity across the entire industry and establishing new development standards. We look forward to its continued strong promotion as an initiative that will advance the entire industry.\"\n\nShimane Prefectural Central Hospital \n\"The AI-Driven Software Development Platform presented by Fujitsu offers a practical and robust approach to the long-standing challenges faced by medical institutions: the increasing complexity of medical fee calculations and the growing workload of claims processing. The mechanism where AI analyzes legal documents and extracts the relevant areas, while explicitly highlighting points open to interpretation to supplement human judgment, is particularly impressive. This design demonstrates a deep understanding of on-site operations and is highly commendable. Furthermore, the Japanese-specific LLM and the consideration for safety are indispensable elements for AI utilization in the medical field. Beyond medical fee claims, this technology has potential for integration with related areas such as bed management and understanding performance requirements, making a strong contribution to overall hospital operational efficiency in the future. This is a promising initiative that warrants positive consideration for adoption to alleviate the burden on medical professionals.\"\n\nShinichi Aikawa, Executive Officer, Head of Systems Division, SBI Sumishin Net Bank, Ltd.\n‚ÄúWe expect Fujitsu's AI-Driven Software Development Platform to be an initiative with the potential to fundamentally transform the software development process itself. If a world can be realized where everything from requirements definition to design, coding, and testing can be automatically executed in a seamless, one-stop manner, it will be possible to achieve both a dramatic improvement in development speed and quality. \nSince 2024, we have been working with Fujitsu in some areas of this field. Through these initiatives, we are confident that the entire development process will be automated end-to-end in the near future. By realizing this transformation, the possibilities for the services we can provide to our customers will greatly expand. We think about ideas for new services for our customers on a daily basis. This would allow us to rough out these ideas in a short period of time and provide them to our customers quickly. We hope that this new world of value creation will arrive as soon as possible.‚Äù\n\nMasaki Murata, Vice President, IBM Japan \n‚ÄúWe strongly believe that Fujitsu‚Äôs announcement marks a significant step forward in the evolution of system development in Japan. It aligns closely with IBM Japan‚Äôs vision and represents an important initiative that will help shape the future of the industry as a whole. We look forward to driving this momentum together and contributing to the creation of a more robust and vibrant ecosystem.‚Äù\n\nRyota Sato, Managing Executive Officer, Global Communications & IT Services Group, Microsoft Japan Co., Ltd. \n\"We sincerely welcome Fujitsu Limited‚Äôs announcement of the AI-Driven Software Development Platform as a pioneering initiative that opens a new chapter in system development for the AI era. By orchestrating multiple AI agents to automate the end-to-end development lifecycle‚Äîfrom requirements definition through ongoing enhancement‚Äîwhile integrating human-led quality assurance, this platform embodies a new engineering model in which people and AI truly work together. We view this initiative as highly significant, as it directly addresses the critical challenges facing Japan‚Äôs system development industry, including severe talent shortages and the increasing complexity and sophistication of modern systems. We strongly expect this bold effort to drive the evolution of Japan‚Äôs system development business and to grow into a transformation model with global relevance. Moving forward, we will continue to work closely with Fujitsu, combining the strengths of both companies to strongly support our customers in their journey toward becoming Frontier Firms.‚Äù\n\nTatsuo Ogawa, Executive Officer Group CTO, Panasonic Holdings Corporation\n‚ÄúWe believe that the AI-driven end-to-end automated system development announced this time represents not only a significant improvement in productivity, but also a bold challenge to fundamentally transform the way enterprise IT is delivered. By enabling AI to accurately understand frequently updated regulations and complex business knowledge, including implicit know-how, this approach autonomously executes processes seamlessly from requirements definition through system modification. It has the potential to provide an effective solution to the core challenges posed by legacy systems faced by many Japanese enterprises. We look forward to jointly refining this technology through hands-on practice and advancing co-creation by incorporating on-site expertise of both Panasonic and Fujitsu, with the expectation that it will become a new standard for system development and be deployed broadly not only within Panasonic but across society as a whole.‚Äù\n\nExecutive at a major manufacturing company's IT subsidiary\n‚ÄúWe anticipate this initiative will bring about a new transformation in system development. This transformation will be driven by the application of advanced Japanese language processing capabilities‚Äîsuch as the understanding of legal documents‚Äîto diverse tasks, the reliable execution of each process through quality auditing functions, and the expansion of these capabilities to scratch development. Furthermore, we believe that AI Ready Engineering, by formalizing expert know-how and domain knowledge into explicit knowledge and transforming it into AI-usable assets, will significantly contribute to the succession of expertise from an increasingly limited pool of skilled professionals. We sincerely hope that the co-creation between the knowledge-inheriting AI and on-site personnel will generate new value and form the cornerstone for innovation in the system development industry, and indeed, across all industries.‚Äù\n\nJointly developed by Fujitsu and Cohere Inc.\n\nA national system that reviews public medical fees and adjusts cost allocation for medical procedures.\n\nDevelopment methods where quality is verified at each stage, from software requirements definition, design, and implementation to integration testing.\n\nThe Sustainable Development Goals (SDGs) adopted by the United Nations in 2015 represent a set of common goals to be achieved worldwide by 2030.\nFujitsu‚Äôs purpose ‚Äî ‚Äúto make the world more sustainable by building trust in society through innovation‚Äù ‚Äî is a promise to contribute to the vision of a better future empowered by the SDGs.\n\nPublic and Investor Relations Division\n\nAll company or product names mentioned herein are trademarks or registered trademarks of their respective owners. Information provided in this press release is accurate at time of publication and is subject to change without advance notice.\n\nDate: 17 February, 2026\nCity: Kawasaki, Japan\nCompany: Fujitsu Limited",
    "readingTime": 13,
    "keywords": [
      "vice president",
      "kawasaki heavy",
      "heavy industries",
      "fujitsu‚Äôs announcement",
      "executive officer",
      "managing director",
      "kawasaki japan",
      "wide range",
      "press release",
      "increasing complexity"
    ],
    "qualityScore": 1,
    "link": "https://global.fujitsu/en-global/pr/news/2026/02/17-01",
    "thumbnail_url": "https://global.fujitsu/-/media/Project/Fujitsu/Fujitsu-HQ/pr/news/2026/02/17-01/news-20260217-01th.png?rev=06c466bd8ac14732a2ff3eff27b55e3b",
    "created_at": "2026-02-17T06:45:26.020Z",
    "topic": "tech"
  },
  {
    "slug": "the-eus-privacy-watchdog-is-investigating-x-over-sexualized-ai-images",
    "title": "The EU's privacy watchdog is investigating X over sexualized AI images",
    "description": "Ireland's Data Protection Commission said it is investigating X over the generation of sexualized images of people in the EU, including minors.",
    "fullText": "X is facing mounting criticism from foreign watchdogs over its generative AI chatbot, Grok.\n\nThe Irish Data Protection Commission said Tuesday that it had opened an inquiry into Elon Musk's X, formerly known as Twitter.\n\nThe commission said in a press release that the inquiry was linked to the creation and publication of non-consensual, sexualized images of European Union residents on X using Grok's generative AI functions. This included pictures of children.\n\nThe commission, which is responsible for enforcing the EU's General Data Protection Regulation, said in the release that it notified X of the investigation on Monday.\n\nX did not respond to a request for comment from Business Insider.\n\nGrok is a chatbot developed by Musk's xAI, now a subsidiary of his aerospace company SpaceX.\n\nThe commission's investigation follows several weeks of controversy around Grok and X. The platform came under fire worldwide in January after reports emerged of Grok users generating sexualized images of real people, including minors.\n\nCountries like Indonesia, Malaysia, and the Philippines temporarily suspended access to Grok. The European Commission launched an investigation into Grok, while India's information technology ministry voiced its opposition via a letter to the chief compliance officer of X's India operations.\n\nCalifornia's Attorney General, Rob Bonta, also said in early January that he had launched a probe into Grok's AI deepfakes.\n\nIn response, X made Grok's AI image generation tool a premium feature limited to paying subscribers and later stopped it from generating sexualized images altogether. However, a Business Insider report found that it was still possible to trigger these images in Grok's web and mobile applications.\n\nIn response to backlash over Grok, Musk said in an X post on January 3, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "illegal content",
      "generating sexualized",
      "sexualized images",
      "grok's ai",
      "investigation",
      "grok",
      "generative",
      "chatbot",
      "protection"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/european-union-privacy-watchdog-investigating-x-sexualized-ai-images-2026-2",
    "thumbnail_url": "https://i.insider.com/6993e156d3c7faef0ece5c7d?width=1200&format=jpeg",
    "created_at": "2026-02-17T06:45:10.169Z",
    "topic": "finance"
  },
  {
    "slug": "analysisluxury-stocks-volatility-highlights-ai-jitters-hedge-fund-positioning",
    "title": "Analysis-Luxury stocks‚Äô volatility highlights AI jitters, hedge fund positioning",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/analysisluxury-stocks-volatility-highlights-ai-jitters-hedge-fund-positioning-4507860",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1G05A_L.jpg",
    "created_at": "2026-02-17T06:45:01.845Z",
    "topic": "finance"
  },
  {
    "slug": "from-openai-to-google-india-hosts-global-ai-summit",
    "title": "From OpenAI to Google, India hosts global AI summit",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/from-openai-to-google-india-hosts-global-ai-summit-4507461",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1F09E_L.jpg",
    "created_at": "2026-02-17T06:45:01.760Z",
    "topic": "finance"
  },
  {
    "slug": "top-hollywood-screenwriter-warns-tiktoks-new-tool-is-at-the-gates-i-hate-to-say-it-its-likely-over-for-us",
    "title": "Top Hollywood screenwriter warns TikTok‚Äôs new tool is at the gates: ‚ÄòI hate to say it. It‚Äôs likely over for us‚Äô",
    "description": "Seedance 2.0, which is only available in China for now, lets users generate high-quality AI videos using simple text prompts.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/16/top-hollywood-screenwriter-warns-tiktoks-new-tool-is-at-the-gates-i-hate-to-say-it-its-likely-over-for-us/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/AP26046699469879-e1771264237998.jpg?resize=1200,600",
    "created_at": "2026-02-17T01:11:10.075Z",
    "topic": "business"
  },
  {
    "slug": "ais-first-wave-was-about-cutting-costs-the-second-wave-is-about-building-things-weve-never-seen",
    "title": "AI's first wave was about cutting costs. The second wave is about building things we've never seen.",
    "description": "Startup CEOs like Kylan Gibbs and Sara Beykpour talk about AI's Second Wave, focusing on creating new products beyond cost-cutting.",
    "fullText": "For the past three years, AI has been mostly a cost-cutting¬†tool. A growing number of founders and investors are trying to move beyond that era.\n\nThe next chapter of AI, they argue, will be defined by new kinds of products ‚Äî apps, games, companions, and services that simply couldn't exist before large language models. They call it AI's \"Second Wave.\"\n\n\"The first wave of AI made existing things cheaper. Automation. Efficiency,\" said Kylan Gibbs, a former Google DeepMind product manager who runs AI startup Inworld. \"The next wave makes things that couldn't exist before. New products. New experiences. New revenue. That's the difference between optimizing spend and creating it.\"\n\nFor Gibbs, that distinction is existential. If AI merely trims costs, it reshuffles value within existing businesses. If it enables entirely new consumer products ‚Äî ones people will pay for ‚Äî it expands the economic pie.\n\n\"AI reaches its real economic potential when it creates value consumers want to pay for, not just value businesses want to save,\" he wrote on LinkedIn. That next phase, he says, requires a new \"consumer-scale AI stack\": real-time responses under 300 milliseconds, support for millions of users simultaneously, and deeply personal experiences tailored to individual preferences.\n\nIn January, Gibbs launched a Silicon Valley accelerator to back up to 30 \"Second Wave\" AI startups ‚Äî companies building new consumer experiences rather than bolting chatbots onto old workflows. Venture capital firms, including¬†Khosla Ventures¬†and Lightspeed Venture Partners, are involved, alongside leaders from OpenAI, Google, and Stripe. A demo day will take place in early March in San Francisco.\n\nThe philosophy echoes a recent post from Y Combinator CEO Garry Tan: \"Instead of worrying about doing the same thing we've been doing for cheaper, why not focus on doing the thing we never even dreamed of doing?\"\n\nA handful of startups already embody that ethos.\n\nSara Beykpour, CEO and cofounder of Particle, says the tech industry is in a liminal moment.\n\n\"We're in a transition between the first wave and the second wave,\" she said.\n\nThe first wave delivered massive productivity gains. At Particle, an AI-native news platform, tasks that once took a month can now be built, tested, and deployed in hours.\n\n\"We actually call each other out in meetings when someone falls into the old way of thinking,\" Beykpour said. \"We jokingly call it 'boomer thinking,' even though we're all millennials.\"\n\nThat shift in mindset gives the startup more time to focus on unlocking new AI-powered formats. Particle recently launched Podcast Clips, a feature that embeds the most relevant snippets of long-form podcasts directly into news stories. Instead of hunting through a three-hour episode, users see curated clips attached to specific topics.\n\n\"It changes the information hierarchy,\" Beykpour said. \"Instead of having to find the podcast you want to listen to, we're bringing the podcast to you based on the most relevant parts.\"\n\nUnder the hood, the system uses AI embeddings to map relationships between transcripts and stories. A clip from a talk show about Greenland and Davos, along with comments from President Donald Trump, can be automatically linked to relevant reporting. Generative AI then layers summaries and context on top.\n\nThese AI embeddings \"have gotten much better in important ways,\" Beykpour told Business Insider in a recent interview.\n\nIf Particle reimagines news, Luvu reinvents personal training using generative AI.\n\nLaunched in August 2025 by CEO Alexis Sursock and CTO Creston Brooks, the AI-powered fitness app has already attracted about 250,000 users. The app features an AI \"marshmallow\" that acts like a personal trainer, sending highly personalized notifications and real-time feedback.\n\n\"The key is the personalization, which is powered by AI models and wouldn't have been possible before this technology appeared in recent years,\" Brooks said.\n\nInstead of generic reminders ‚Äî \"It's time for your workout\" ‚Äî Luvu tailors messages. If a user logged that they had a test yesterday, the app might follow up with, \"Your test is over. Time to work out!\"\n\nThe results are striking. Luvu's notification click rate is four times that of typical non-personalized prompts. In an industry where only 2% to 3% of users remain active after 30 days, Brooks said, Luvu claims retention rates that are two to three times higher.\n\nThe app offers three motivational styles: supportive, neutral, or \"meaner marshmallow.\" Behind the scenes, Luvu also uses AI for granular, one-to-one messaging crafted by LLMs.\n\nThe company is also experimenting with reinforcement learning with verified rewards, a relatively new technique for training and improving AI models.\n\nUsers can prop their phones against a surface and record themselves exercising; the app uses computer-vision models to verify whether squats or other moves are performed correctly, offering real-time corrections like \"Straighten your knees.\" These verified signals feed back into the system, helping train what Brooks envisions as a future \"super-motivator\" model.\n\nThis isn't just a chatbot layered on top of a fitness tracker. It's a feedback loop between human behavior and AI, something that couldn't easily exist before the advent of modern models.\n\nFor Fai Nur, CEO and cofounder of AI-powered social simulation game Status, the Second Wave is about imagination.\n\n\"Status could not have existed before LLMs,\" she said.\n\nThe app, which has surpassed 3 million downloads, lets users role-play in AI-generated social media worlds. Think The Sims, though played out as a living, breathing social feed.\n\nUsers can cast themselves as anything they can imagine, such as Hogwarts students, soccer stars, or characters from \"Stranger Things.\" Post an update, and AI-generated characters instantly reply. Events unfold dynamically: miss a penalty kick, and face the backlash. An AI system assigns an \"aura score\" to grade responses and level players up or down.\n\nIn many enterprise settings, the non-deterministic nature of LLM outputs is a liability. Generative AI models sometimes respond to the same prompt in different ways, which doesn't lend itself to applications that require strict accuracy.\n\nIn¬†gaming, this can be an asset because each new AI-generated response can be new, creating a richer, more varied experience.\n\n\"You haven't been able to role-play like this until now,\" Nur said.\n\nBefore LLMs, creating immersive fandom worlds required persuading other humans to participate. Now, entire social universes spin up instantly.\n\nFor Gibbs and other proponents of AI's Second Wave, that's the point. The technology's future won't be defined by incremental cost savings, but by products that feel native to AI ‚Äî experiences that surprise, motivate, inform, and entertain at consumer scale.\n\nIf the first wave made businesses leaner, the second may make everyday life stranger, richer, and more interactive ‚Äî and, crucially, something people will pay for.\n\n Reach out to me via email at abarr@businessinsider.com. Note: Axel Springer, the parent company of Business Insider, is an investor in Particle.",
    "readingTime": 6,
    "keywords": [
      "ai's second",
      "second wave",
      "couldn't exist",
      "for gibbs",
      "generative ai",
      "business insider",
      "users",
      "models",
      "products",
      "experiences"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-second-wave-redefines-startups-new-products-2026-2",
    "thumbnail_url": "https://i.insider.com/698f9459a645d11881895bf1?width=1200&format=jpeg",
    "created_at": "2026-02-17T01:11:09.352Z",
    "topic": "finance"
  },
  {
    "slug": "ireland-opens-probe-into-musks-grok-ai-over-sexualised-images",
    "title": "Ireland opens probe into Musk‚Äôs Grok AI over sexualised images",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/ireland-opens-probe-into-musks-grok-ai-over-sexualised-images-4507811",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1G009_L.jpg",
    "created_at": "2026-02-17T01:11:08.733Z",
    "topic": "finance"
  },
  {
    "slug": "beadhub-allow-coding-agents-to-claim-work-chat-and-coordinate-across-machines",
    "title": "BeadHub: Allow coding agents to claim work, chat, and coordinate across machines",
    "description": "I wrote previously that the bottleneck in AI-assisted programming is shifting from individual productivity to coordination. I‚Äôve spent the past several months building a tool to address that.\nBeadHub is an open-source coordination server that lets AI programming agents claim work, talk to each other, reserve files, and escalate to humans‚Äîacross machines and across programmers. I use it daily to manage around fifteen agents working on two or three products.\nBeads Around the time I wrote that article, I started using Steve Yegge‚Äôs beads, a git-native issue tracker designed for AI agents.",
    "fullText": "I wrote previously that the bottleneck in AI-assisted programming is shifting from individual productivity to coordination. I‚Äôve spent the past several months building a tool to address that.\n\nBeadHub is an open-source coordination server that lets AI programming agents claim work, talk to each other, reserve files, and escalate to humans‚Äîacross machines and across programmers. I use it daily to manage around fifteen agents working on two or three products.\n\nAround the time I wrote that article, I started using Steve Yegge‚Äôs beads, a git-native issue tracker designed for AI agents. Your agent runs bd create \"Fix the login redirect bug\" and it appends a JSON line to .beads/issues.jsonl, right in the repository. Issues travel with the code. When you push a branch, the issues come along.\n\nYegge calls it the ‚Äú50 First Dates‚Äù problem: agents wake up every session with no memory of yesterday‚Äôs work. Beads fixes that. An agent reads the issue list and knows where things stand. My agents got much more done.\n\nWhich meant more agents, more worktrees, more parallel work‚Äîand the coordination problem became even more acute. Two agents modify the same file. One refactors a function while another adds to it. An agent picks up a task already in progress in a different worktree. Nobody knows who‚Äôs working on what.\n\nBut beads is also the right scaffolding for coordination. If everyone in a team uses beads, all agents share a picture of what needs doing. Beads gives agents something useful to talk about; BeadHub gives them a way to talk.\n\nThe major platforms are moving in this direction. Anthropic just shipped Agent Teams in Claude Code: a lead session that spawns independent teammates who communicate directly and self-coordinate. OpenAI‚Äôs Codex app runs parallel agent threads in isolated worktrees.\n\nYegge built Gas Town on top of beads to tackle the single-machine case: a ‚ÄúMayor‚Äù agent orchestrates dozens of coding agents, tracks work in convoys, and persists state so agents can pick up where they left off.\n\nThese are real steps forward, but they‚Äôre solving a specific version of the problem: multiple agents for one programmer, on one machine, within one tool.\n\nThe version I am interested in is Maria in Buenos Aires running a frontend agent while Juan in San Francisco runs a backend agent, and they need their agents to not destroy each other‚Äôs work, and to figure out how to work together.\n\nBeadHub is a server that agents connect to through bdh, a wrapper around the beads bd command. When an agent runs any bdh command it registers with the server. The server tracks which agents are online across the project‚Äîwhat machine they‚Äôre on, what branch, what files they‚Äôre touching.\n\nCommunication. Agents can send each other mail (async, fire-and-forget) or chat (sync, block-until-reply). With mail an agent finishes a task and drops a note: ‚ÄúDone with bd-42, tests passing.‚Äù Chat is for when agents need to think together: ‚ÄúI‚Äôm adding a role field to the user model‚Äîwill that break your permission checks?‚Äù / ‚ÄúIt will, but the fix is small. Go ahead and I‚Äôll update my side.‚Äù\n\nClaims. When an agent marks a bead as in-progress, that claim is immediately visible to every other agent in the project, regardless of whose machine they‚Äôre on. If another agent tries to claim the same bead, it gets rejected with a message telling it who has it.\n\nFile reservations. When an agent modifies a file, the server records an advisory lock. Other agents see a warning if they touch the same file. Advisory, not blocking‚Äîhard locks caused deadlocks immediately in early versions. Agent A locks file X, agent B locks file Y, both need the other‚Äôs file. Warnings work better. Agents are cooperative; they just need information.\n\nEscalation. An agent runs bdh :escalate with a description of what it‚Äôs stuck on and a human gets notified with full context. Without this, agents either fail silently or spin retrying things that need human judgment.\n\nThe multi-machine part is where it comes together. BeadHub recognizes Maria‚Äôs and Juan‚Äôs clones as the same repo. Maria‚Äôs agents and Juan‚Äôs agents see each other‚Äôs claims, locks, and messages. If Maria‚Äôs frontend agent reserves src/components/Auth.tsx, Juan‚Äôs backend agent sees the warning even though they‚Äôre in different cities on different machines.\n\nA project can span multiple repositories. The frontend repo agents can message the backend repo agents. A bead in the frontend can be marked as blocked by a bead in the backend.\n\nYou can see what this looks like in practice on the BeadHub project‚Äôs own dashboard, where we coordinate BeadHub‚Äôs development using BeadHub. Make sure to check the chat page, it is almost magical to see them figuring things out.\n\nA few things I got wrong before getting them right.\n\nThe client is the source of truth. My instinct was to make the server authoritative. But agents work locally, in git repos, and their local state is the ground truth. The server aggregates and distributes. If the server and the client disagree, the client wins. If the server goes down, bdh falls back to local bd with a warning. Work continues. Coordination catches up later.\n\nAsync by default. My first instinct was real-time negotiation between agents. Doesn‚Äôt scale. Agents work at different speeds, on different schedules, and blocking one while waiting for another is expensive. Mail is the default. Chat is the exception.\n\nAdvisory over mandatory. Advisory file locks that warn instead of block. Bead claims that can be overridden with --:jump-in \"reason\" (which notifies the other agent). The system provides information and trusts agents to act on it.\n\nThe coordinator role. I assign one agent per project the ‚Äúcoordinator‚Äù role. The coordinator doesn‚Äôt write code. It watches the dashboard, assigns work, checks on progress, nudges stuck agents, and keeps the end goal in sight. The implementer agents are heads-down in their worktrees; the coordinator is the one who knows what the project needs next. BeadHub serves each agent a role-specific policy‚Äîmarkdown documents describing how agents in that role should behave‚Äîand the coordinator‚Äôs policy is fundamentally different from an implementer‚Äôs. This turned out to matter more than any of the technical decisions.\n\nThe single-machine problem is getting solved. Agent Teams, Codex‚Äîwithin a few weeks, running multiple agents in parallel on your laptop will be table stakes.\n\nThe multi-programmer problem is next. Five engineers, fifty agents, three repositories, two time zones. That‚Äôs where the coordination problem changes in kind, not just degree. It‚Äôs not enough that your agents can talk to each other. They need to talk to your teammate‚Äôs agents, on a different machine, in a different time zone, working on a different repo in the same project.\n\nBeadHub is open source and free for open-source projects.",
    "readingTime": 6,
    "keywords": [
      "together beadhub",
      "coordinator role",
      "machine they‚Äôre",
      "locks file",
      "frontend agent",
      "backend agent",
      "repo agents",
      "server",
      "beads",
      "coordination"
    ],
    "qualityScore": 1,
    "link": "https://juanreyero.com/article/ai/beadhub",
    "thumbnail_url": "https://juanreyero.com/img/default-og.jpg",
    "created_at": "2026-02-16T18:30:07.341Z",
    "topic": "tech"
  },
  {
    "slug": "memory-plugin-for-claude-code",
    "title": "Memory Plugin for Claude Code",
    "description": "A Markdown-first memory system, a standalone library for any AI agent. Inspired by OpenClaw. - zilliztech/memsearch",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n zilliztech\n\n /\n\n memsearch\n\n Public\n\n You can‚Äôt perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/zilliztech/memsearch/tree/main/ccplugin",
    "thumbnail_url": "https://opengraph.githubassets.com/cf6f8849c03191744f1dddc3af6be801b4d830f81204248354020fd12266a381/zilliztech/memsearch",
    "created_at": "2026-02-16T18:30:06.450Z",
    "topic": "tech"
  },
  {
    "slug": "natwest-hails-progress-after-12b-spent-on-tech-last-year-but-true-ai",
    "title": "NatWest hails progress after ¬£1.2B spent on tech last year, but true AI",
    "description": "Bank described the last 12 months of its tech transformation as ‚Äòthe year of [AI] deployment at scale.‚Äô",
    "fullText": "NatWest bank invested ¬£1.2bn into its information technology transformation in 2025 and saw huge productivity gains as a result, but this year will see artificial intelligence (AI) become truly transformative for customers and staff.\n\nThe bank said it has already freed up ¬£100m in funds as a result of simplification and the use of the cloud. AI is at the centre of the bank‚Äôs plans, with 2025 seeing the technology deployed across the company ‚Äúat scale‚Äù.\n\nHeadline figures for 2025 saw the bank‚Äôs software engineers generate 35% of its code through AI software development tools, all 60,000 staff given access to AI productivity software, and thousands of human hours saved. Last year, the bank also embarked on a major collaboration with AI supplier OpenAI.\n\nOther tech achievements in 2025 included the hiring of 1,000 software developers, 100 new features developed on its retail banking app, the appointment of its first chief AI research officer and the establishment of its AI research office.\n\nIn a blog post, NatWest Group CIO Scott Marcar said this year will see the bank take advantage of the AI ‚Äúbuilding blocks‚Äù deployed last year.\n\n‚ÄúThe only certainty is that how customers bank will look very different in the future,‚Äù he said. ‚ÄúThat‚Äôs why being closer to them, with insight and trust, matters more than ever. As technology reshapes how people live, work and bank, we‚Äôve put in place the building blocks to understand, respond to and serve customers‚Äô fast evolving needs,‚Äù wrote Marcar.\n\n‚ÄúLast year brought AI deployment at scale across NatWest, and as we move into 2026, the transformative benefits are becoming more of a reality for our customers and colleagues ‚Äì delivering growth, greater productivity, and, most importantly, deepening relationships ‚Äì so that we can be a trusted partner for tomorrow‚Äôs banking,‚Äù he added.\n\nFrom a staff perspective, all staff now have access to AI tools including Microsoft Copilot Chat and the bank‚Äôs internal large language model (LLM), with more than half reported to have taken additional training.\n\nAccording to the bank, more than 70,000 hours were saved through automated AI call summaries in its retail business, while relationship managers in its wealth business were able to spend 30% more time on customer conversations by using AI. According to NatWest, through agentic and voice AI, customers will receive ‚Äúmore intuitive, personalised and seamless interactions‚Äù this year.\n\nIn the next few months, 25,000 NatWest customers will have access to its agentic financial assistant within Cora, its customer-facing agentic AI assistant. ‚ÄúUnderpinned by OpenAI models, customers will be able to ask natural language questions about their recent spending, in their own words, on their app,‚Äù said the bank.\n\nThe bank will then experiment with voice-to-voice AI capability, which aims to provide ‚Äúhuman-like empathy, tone and inflection‚Äù.\n\nAs part of its wider multi-year digital transformation, NatWest has added around 6,000 tech staff since 2021. In 2025 alone, it recruited 1,000 software engineers through its India Hub in Bengaluru. Its chief AI researcher, Maja Pantic, is working with AI in areas such as audiovisual conversational AI, multi-biometrics and proprietary small language models.\n\nMarcar wrote: ‚ÄúWe can‚Äôt underestimate the scale of the work we have done to date to rebuild our technology foundations to make us faster, safer and more resilient. A scalable, modular tech stack now underpins how we deliver new products and services, how we integrate with partners, and how we provide the protection and operational resilience customers expect.‚Äù\n\nHe said the bank has been moving away from legacy systems in an ‚Äúinside-out‚Äù transformation. It has also created a single, connected view of each customer. ‚ÄúWe can anticipate needs faster, remove friction from everyday banking and make onboarding more seamless,‚Äù he wrote on his blog post.\n\nMarcar stressed that the proliferation of AI will support human workers, adding: ‚ÄúIt‚Äôs a future where the expertise of our colleagues is augmented by the intelligence and ease of modern technology.‚Äù",
    "readingTime": 4,
    "keywords": [
      "software engineers",
      "bank",
      "customers",
      "natwest",
      "technology",
      "staff",
      "transformation",
      "productivity",
      "bank‚Äôs",
      "scale"
    ],
    "qualityScore": 1,
    "link": "https://www.computerweekly.com/news/366639140/NatWest-hails-progress-after-12bn-spent-on-tech-last-year-but-true-AI-transformation-to-come",
    "thumbnail_url": "https://www.computerweekly.com/visuals/ComputerWeekly/HeroImages/NatWest-Bank-Editorial-Use-Only-Shawn-adobe.jpg",
    "created_at": "2026-02-16T18:30:06.218Z",
    "topic": "tech"
  },
  {
    "slug": "the-long-tail-of-llmassisted-decompilation",
    "title": "The Long Tail of LLM-Assisted Decompilation",
    "description": "After rapid advances thanks to one-shot decompilation, progress on the Snowboard Kids 2 decompilation began to falter. This post explores the workflow evolution, tooling improvements, and fundamental LLM limits that emerged when tackling the long tail of increasingly difficult functions.",
    "fullText": "In my previous posts, I described how coding agents could be used to decompile Nintendo 64 games and that one-shot decompilation was very effective. That approach allowed me to make rapid progress on the Snowboard Kids 2 decompilation, with the percentage of matched code quickly growing from around 25% to 58%.\n\nAfter that, progress slowed dramatically, requiring me to significantly alter my workflow. With those changes, I pushed the decompilation into the ~75% range before stalling out again, this time perhaps for good, though I would love to be proved wrong.\n\nThis post describes how my workflow has evolved as the project matured, what helped, and where I‚Äôm currently stuck. My hope is that these observations will be useful for other decompilation projects.\n\nDecompilation attempts take time and tokens, so the choice of which unmatched functions to work on matters a great deal. My original approach prioritised functions based on estimated difficulty. A logistic regression model ranked candidates using features like instruction count and control-flow complexity, and Claude would always attempt the ‚Äôeasiest‚Äô remaining function. That worked remarkably well early on, but it eventually ran out of steam. At some point, everything left was hard. Reordering the queue didn‚Äôt magically make those functions easier.\n\nAt the same time, Macabeus was exploring function similarity via text embeddings of assembly instructions, which then allowed querying for nearby functions in the high-dimensional latent space. This seemed promising. Claude‚Äôs output already hinted that it could recognise similar functions and reuse patterns across them. The intuition here is that decompiled functions provide a useful reference to Claude for how particular blocks of assembly can be mapped to C code.\n\nTo test this out, I wrote a tool to compute similar matched functions given an unmatched function and adjusted the agent loop to prioritise functions with similar (matched) counterparts. This approach proved highly effective. There were indeed many similar functions that Claude hadn‚Äôt previously been able to identify, and these proved invaluable for helping guide its decompilation attempts.\n\nVector embeddings are just one way of computing function similarity. They are great for fast retrieval across huge corpora, which is one reason they‚Äôre common in RAG systems. But I only had a few thousand candidates, and queries weren‚Äôt time-sensitive. Computing exact similarity between every pair of candidates is not only feasible but preferable, given how much time and tokens are already invested in each attempt.\n\nMy first attempt was to build a composite similarity score by hand. I combined:\n\nIn hindsight, this was probably overcomplicated. There is already a tool that does something very similar: Coddog. Instead of feature engineering, it computes a bounded Levenshtein distance directly over opcode sequences, with aggressive early exits when similarity is impossible. The result is normalised to a similarity score between 0 and 1.\n\nOn the remaining unmatched functions, Coddog and my own approach select different most-similar candidates in 90.6% of cases. I still use both. They were not evaluated on identical sets of functions, so it is difficult to say whether one is strictly better or whether they are simply complementary. Anecdotally, though, the simpler approach performs at least as well as my more elaborate one.\n\nSpecialised tooling can make a big difference to Claude‚Äôs performance. The project uses a number of Claude skills but two were particularly notable: gfxdis.f3dex2 and decomp-permuter.\n\nThe N64 has a dedicated graphics chip, the Reality Display Processor (RDP). Games execute microcode on the RDP to render graphics on the screen.\n\nGames have considerable flexibility in how they use the RDP, but most opt for an off-the-shelf library provided by Nintendo. If your game doesn‚Äôt do this, you need to reverse engineer a company‚Äôs idiosyncratic microcode in addition to the game itself. Thankfully, Snowboard Kids 2 opted for a Nintendo library, specifically F3Dex2.\n\nAfter loading their desired microcode library, games send instructions to the RDP via display lists. Conceptually, display lists are just arrays of bytes representing microcode instructions, but they‚Äôre a headache for decompilers. Games often build them dynamically using macros that may invoke other macros or perform complex bit arithmetic. The compiler then optimises and reorganises this logic, making it difficult to discern what the original developers actually wrote.\n\nAgents are smart, but this is a highly domain-specific and context-specific scenario. It‚Äôs a clear use case for a Claude skill.1 I provided Claude with a reference for F3Dex2 commands, a tool to disassemble hex values into specific commands (gfxdis.f3dex2), and some strategies for handling more specific edge cases such as aggregate commands. Unsurprisingly, this made Claude far more effective at recognising and decompiling F3Dex2 code.\n\nClaude is slow and deliberate. Turning a 99.9% match into 100% can involve thousands of tiny variations in control flow, temporaries, or expression ordering. A permuter is the opposite. It blindly tries millions of small mutations in the hope that one of them produces a perfect match.\n\nIn theory, this should complement an LLM nicely. Claude does the structured reasoning, the permuter brute-forces the final few percent. The skill enforced this split by allowing the permuter to run only once a function was already more than 95% matched.\n\nPermuters happily introduce strange code: illogical variable reuse, do {} while (0) loops, nested assignments. Sometimes these changes work. Often they do not. Worse, they optimise for incremental improvements to the match percentage rather than for correctness. A small reordering might delete a function call or subtly change register allocation in a way that improves the match. But if that call existed in the original, you will have to restore it eventually. You are not actually closer to a clean match. You have just moved the compiler into a more convenient shape.\n\nClaude, unfortunately, tended to treat these artefacts as signal. It would start optimising around permuter-induced noise, leading to doom loops and token burn with little real progress.\n\nAfter a few attempts to rein this in, I removed the permuter entirely. The occasional win did not justify the cleanup cost or the instability it introduced. It also made manual intervention harder, since the codebase would drift into awkward, overfitted forms that no human would willingly write.\n\nCleaning up and documenting code doesn‚Äôt directly improve the match rate but it can help reach previously unmatchable functions. Many of the earlier functions (particularly those done by Claude) were quite brittle. They technically matched, but relied on pointer arithmetic, awkward temporaries, or control flow no human would willingly write. Those matches worked, but they were poor references when an unmatched function was later identified as similar to them.\n\nCleaner, more idiomatic matches make better examples once similarity-based scheduling kicks in. If a function really should be using array indexing instead of pointer math, fixing that improves the signal Claude sees when attempting related code.\n\nSometimes this cleanup was done by hand but Claude was also reasonably good at cleaning up its own work. Claude was run in a loop, similar to the technique used for one-shot decompilation, where it was tasked with making changes to one individual function at a time.\n\nThis was another area where the right skills made a difference. In a decompilation project, even renaming a global variable can involve multiple steps. This also turned out to be a great way to document the structure of the project, since writing down how everything worked was already necessary for Claude‚Äôs benefit.\n\nAs a side effect, this work turned up some genuinely fun discoveries. While documenting the cheat code system, I stumbled across a previously unknown cheat code. That alone justified the detour.\n\nThe ongoing decompilation work plus the branching into other non-decompilation tasks presented numerous challenges in terms of resources, project stability, and task orchestration.\n\nFour changes helped me keep the workflow scaling:\n\nThese will be discussed in turn.\n\nThere are multiple tasks that we need to perform. Worktrees are the recommended way to run multiple agents on a single codebase. Agents need their own version of the codebase to work with, or we risk conflicting changes, errors, and so on.\n\nToday I run agents across three separate worktrees in addition to the main branch, where I do human stuff.\n\nGreater automation of the decompilation and documentation work also increased the possibility of Claude creating and committing mistakes. The unsupervised nature of the work means these can lie undetected for hours, potentially invalidating all the intervening work that has been done.\n\nIn one particularly amusing case, Claude couldn‚Äôt get a function to match, so it updated the SHA1 hash that was used for comparison between the compiled artefact and the original ROM. All work done after that point had to be reverted.\n\nHooks proved invaluable for preventing this behaviour and guiding the agent. Hooks allow us to run code before the agent takes a specific action, for example when editing a file. I‚Äôve found them incredibly useful. You can find the full list of hooks here. Currently, I use hooks to:\n\nHooks have significantly reduced the frequency with which Claude attempts misguided or destructive actions, though they are not perfect. Claude can be very persistent when it really wants to do something. I‚Äôve seen Claude run the contents of a make command when make itself is blocked, or write a Python script to edit a file it‚Äôs been told it can‚Äôt edit. But hooks at least offer better enforcement than prompting alone.\n\nDifferent kinds of long-running agent loops have become essential to my workflow. The increased use of long-running tasks also required a more robust solution than my old run.py script. I decided to split my old run.py script (now Nigel) into its own repo.\n\nNigel reflects the immediate needs of the decompilation project but might be useful more generally. In Nigel, tasks are expressed via configuration: it‚Äôs easy to experiment with new ideas by copying an existing task and tweaking it. In your configuration file, you need to specify a ‚Äòcandidate source‚Äô (input to the task) and a prompt (which can optionally be a separate template file).\n\nHere‚Äôs an example from my recent attempts to remove hard-coded hex addresses in main.c:\n\nNigel will automatically discover scripts (uniquely identified by name) and can run them with proper handling to ensure the same input isn‚Äôt handled twice, good changes are committed, failures are handled gracefully, etc.\n\nSome of my favourite Nigel features are:\n\nIt‚Äôs hard to discuss Claude workflows without mentioning Ralph Wiggum. Like Ralph, Nigel can repeatedly prompt Claude with the same task via --repeat until it succeeds. The difference is that Nigel operates within structured workflows and batch jobs. Tasks generate candidates and consume them one at a time, whereas Ralph simply replays the same prompt.\n\nMy initial prompt capped the number of attempts at 30 to preserve tokens, which may have been conservative.\n\nI experimented with relaxing this limit and enabling --repeat 3. A small number of functions exceeded the previous 30-attempt cap. One required 87 attempts before Claude finally succeeded.\n\nIn practice, higher --repeat values do help, but only at the extreme tail and at considerable token cost.\nThe 85th percentile of successful attempts remains 28 attempts, meaning most functions complete within the original limit. For now, I‚Äôve removed --repeat 3 while leaving the number of attempts within a single prompt uncapped. That preserves headroom for rare outliers without multiplying token usage across the entire workload.\n\nWork on the remaining unmatched functions required more attempts, more intermediate output, and more refactoring passes. An unattended Opus task could burn through the Claude 20x Max plan in a matter of days. The new cleanup and documentation loops only added to the pressure on a finite token budget.\n\nGLM, an open-weight model from z.ai, is generally considered less capable than Opus. But it‚Äôs dramatically cheaper, offers generous token limits, and can act as a drop-in replacement for most of my workflows.\n\nThus glaude was born: a thin wrapper that looks like Claude but quietly points at a GLM backend.\n\nI usually try glaude first, or reach for it when I know the task is mechanical. Cleanup passes, refactors, documentation loops: none of these really need frontier reasoning. I‚Äôd rather preserve Opus tokens for the genuinely difficult work. It‚Äôs not perfect. Opus has cracked problems GLM couldn‚Äôt. But it lets me run agents without constantly worrying about weekly quotas, which makes the whole system far more sustainable.\n\nAfter all that engineering (similarity scoring, skills, hooks, orchestration, model routing), the curve ultimately flattened in early January. At that point, 157 functions remained. With continued work, that‚Äôs now down to 124, but the dynamic has fundamentally changed.\n\nNigel the cat is still as busy as ever. There‚Äôs still work to be done, but matching functions has become much harder. At least until the next wave of frontier models is released.\n\nIf you‚Äôve made it this far, you probably have an interest in decompilation and Snowboard Kids 2. Check out the Snowboard Kids 2 decompilation project, and please reach out on Discord if you‚Äôd like to help.\n\nYou can also follow me on Bluesky for more Snowboard Kids 2 updates.\n\nI‚Äôve gone back and forth between treating this as a Claude skill vs making it directly part of the CLAUDE.md for the decomp environment. As I was writing this blog post though, it did seem a little embarrassing not making it a skill, so I changed it back. üò∂‚Äçüå´Ô∏è¬†‚Ü©Ô∏é",
    "readingTime": 12,
    "keywords": [
      "display lists",
      "run.py script",
      "proved invaluable",
      "kids decompilation",
      "similarity score",
      "documentation loops",
      "claude skill",
      "cheat code",
      "one-shot decompilation",
      "unmatched function"
    ],
    "qualityScore": 1,
    "link": "https://blog.chrislewis.au/the-long-tail-of-llm-assisted-decompilation/",
    "thumbnail_url": "http://blog.chrislewis.au/function-embeddings-header.jpg",
    "created_at": "2026-02-16T18:30:06.066Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-transforming-science-more-researchers-need-access-to-these-powerful-tools-for-discovery",
    "title": "AI is transforming science ‚Äì more researchers need access to these powerful tools for discovery",
    "description": "Five years ago, our AlphaFold AI system solved the 50-year grand challenge of protein structure prediction. But that's not the whole story.",
    "fullText": "Sir Demis Hassabis¬†is Co-Founder and CEO of Google DeepMind. He has won many prestigious international awards for his research work including the 2025 Nobel Prize in Chemistry for protein structure prediction.\n\nAs SVP for Research, Labs, Technology & Society, James Manyika focuses on advancing Google and Alphabet‚Äôs most ambitious innovations in AI, computing and science and on areas with potential for beneficial impact on society. James served as Vice Chair of the US National AI Advisory Committee and Co-Chair of the UN Secretary-General‚Äôs AI Advisory Body.",
    "readingTime": 1,
    "keywords": [
      "society james",
      "research",
      "advisory",
      "google"
    ],
    "qualityScore": 0.45,
    "link": "https://fortune.com/2026/02/16/google-deepmind-ceo-demis-hassabis-james-manyika-transforming-sciecne-alphafold/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/demis-hassabis.png?resize=1200,600",
    "created_at": "2026-02-16T18:30:01.619Z",
    "topic": "business"
  },
  {
    "slug": "mark-cuban-predicted-an-army-of-young-people-would-have-to-spread-ai-and-tech-gurus-agree",
    "title": "Mark Cuban predicted an army of young people would have to spread AI ‚Äî and tech gurus agree",
    "description": "Tech billionaire Mark Cuban anticipated a huge jobs boom for young people to implement AI at companies. AI gurus say he's right.",
    "fullText": "Mark Cuban expects legions of workers will be needed to implement AI at companies, creating a huge opportunity for tech-savvy young people.\n\nThe tech billionaire and former \"Shark Tank\" investor made the prediction during an August interview with TBPN, a tech talk show and podcast.\n\nAI guru Rohan Paul shared a clip of Cuban's comments over the weekend, which was widely reposted; Cuban himself shared three responses from other AI gurus on his X feed.\n\nOne declared it the \"MOST underrated clip on the internet right now.\" Another drew a parallel to Salesforce and the millions of administrative and integration roles it spawned. A third heralded a shift from generic software to customized intelligence.\n\nCuban is calling the IT services boom of the 2000s, but for intelligence instead of infrastructure. Every wave of business technology from PCs to cloud to mobile spawned a massive local services layer. The AI wave needs the same thing, and 33 million companies are waiting. \n\nThe‚Ä¶ https://t.co/sgBXH1VJLd\n\nCuban told TBPN that when he was 24, he would walk into companies and executives would point to their secretaries and receptionists and say they didn't need a PC. Cuban recognized that as an opportunity to sell old-school bosses on the benefits of computers and teach them how to use them.\n\nHe said it's a similar situation with the latest tech wave, which some believe will render millions of human workers obsolete and trigger mass unemployment.\n\nCuban said he advises high-school and college students to not just \"learn all you can about AI, but learn more on how to implement them in companies.\"\n\nCuban, a minority owner of the Dallas Mavericks, said that tens of millions of US companies don't have AI budgets or AI experts.\n\n\"This is where kids getting hired coming out of college are really going to have a unique opportunity,\" he said. They should spend their free time learning how to use different AI tools, make AI videos, and customize AI models so they can teach business leaders in any industry how to harness the tech, he added.\n\n\"That is every single job that's going to be available for kids coming out of school because every single company needs that,\" Cuban said. \"There is nothing intuitive for a company to integrate AI and that's what people don't understand.\"\n\nCuban emphasized the opportunity isn't limited to software engineers. Many older workers are \"afraid\" to ask complex questions to AI models, he said, unlike \"kids coming out of school today that are fearless in the questions they ask and the followups and their ability to prompt.\"\n\n\"That's jobs for everybody,\" he added.",
    "readingTime": 3,
    "keywords": [
      "opportunity",
      "tech",
      "workers",
      "millions",
      "wave",
      "kids",
      "that's",
      "cuban",
      "implement",
      "tbpn"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mark-cuban-ai-skills-tech-young-people-jobs-implement-opportunity-2026-2",
    "thumbnail_url": "https://i.insider.com/6993104cd3c7faef0ece57fc?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:01.231Z",
    "topic": "finance"
  },
  {
    "slug": "bytedance-says-its-going-to-make-it-harder-for-seedance-to-make-ai-videos-of-copyrighted-movie-characters",
    "title": "ByteDance says it's going to make it harder for Seedance to make AI videos of copyrighted movie characters",
    "description": "ByteDance is facing scrutiny over Seedance 2.0, an AI video tool creating Hollywood star deepfakes and sparking copyright concerns.",
    "fullText": "Last week, an AI-generated video of fake Tom Cruise duking it out with fake Brad Pitt on a rooftop freaked the internet out. Now, the Chinese tech giant behind the AI tool says it's going to take measures to improve copyright-related safeguards.\n\nIn a statement shared with Business Insider, ByteDance said it's going to \"strengthen safeguards\" on Seedance 2.0.\n\nOn Friday, Disney sent ByteDance a cease-and-desist letter, accusing the Chinese company of \"hijacking Disney's characters by reproducing, distributing, and creating derivative works featuring those characters.\"\n\nIn the statement to Business Insider, a ByteDance spokesperson said the company \"respects intellectual property rights\" and that it has \"heard the concerns regarding Seedance 2.0.\"\n\n\"We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,\" the spokesperson said in comments first reported by the BBC.\n\nThe company did not provide further details on the safeguards it's planning to introduce.\n\nByteDance, which is also the parent company behind TikTok, launched Seedance 2.0 in early February. Its ability to generate realistic, multi-shot video sequences has prompted pushback from Hollywood over concerns about AI's impact on entertainment jobs.\n\nCharles Rivkin, the chairman and CEO of the Motion Picture Association, accused Seedance 2.0 of engaging in \"unauthorized US copyrighted works on a massive scale.\"\n\n\"By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs,\" Rivkin said in a statement last week.\n\nThe AI-generated video depicting¬†Pitt and Cruise fighting¬†on a rooftop quickly went viral last week, with many online commenting on how realistic the clip is.\n\nThe company also generated buzz with AI videos of Marvel's Wolverine fighting Thanos, and a lightsaber duel between Star Wars characters Anakin Skywalker and Rey. Both franchises are owned by Disney.\n\nWhile Disney has warned ByteDance to stop using its intellectual property, it signed a three-year licensing deal with OpenAI in December, giving users of its video-generation tool Sora access to 200 Disney characters.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "insider bytedance",
      "intellectual property",
      "safeguards",
      "characters",
      "it's",
      "statement",
      "fake",
      "rooftop",
      "behind"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/bytedance-seedance-2-safeguards-copyright-disney-ai-video-tool-2026-2",
    "thumbnail_url": "https://i.insider.com/699301c5d3c7faef0ece57ce?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:01.048Z",
    "topic": "finance"
  },
  {
    "slug": "inside-the-career-rise-of-sundar-pichai-google-and-alphabets-current-ceo",
    "title": "Inside the career rise of Sundar Pichai, Google and Alphabet's current CEO",
    "description": "Meet Sundar Pichai, the man leading Google and Alphabet as CEO, who is leading the search giant through the AI race.",
    "fullText": "Sundar Pichai has had a meteoric rise since joining Google as a 31-year-old product manager in 2004.\n\nIn the 11 years that followed his first steps on the Googleplex, Pichai was promoted four times, eventually becoming the CEO of Google in 2015.\n\nIn that role, he was responsible for the company's core businesses and cash cow ‚Äî and did a good enough job that, in December 2019, he was promoted one more time, replacing Google cofounder Larry Page as the CEO of Alphabet, Google's parent company.\n\nSince then, he has led the almost-$2-trillion company through the pandemic, layoffs, and the AI renaissance that's taken Silicon Valley by storm.\n\nSo, who is Pichai, and how did he scale the ranks to get one of the most important jobs at one of the most important companies in the world? Here's a look at his life and career.\n\nPichai, whose full name is actually Pichai Sundararajan, grew up in Chennai, India.\n\nPichai's father was an electrical engineer, and his mother worked as a stenographer before having him and his younger brother. The family wasn't wealthy, and the boys slept together in the living room of their two-room apartment.\n\nEarly on, Pichai's family realized he had a talent for remembering numbers after noticing he could recall every phone number he had ever dialed on their rotary phone. He has been known to sometimes show off his memorization skills at meetings, Bloomberg said in 2014.\n\nAfter becoming interested in computers ‚Äî the first software program he wrote was a chess game ‚Äî Pichai studied engineering at the Indian Institute of Technology in Kharagpur. His success there won him a scholarship to Stanford University.\n\nPichai earned a master's degree from Stanford and later attended the University of Pennsylvania's Wharton School for his MBA.\n\nPichai has said that moving to California was a huge leap.\n\n\"I always loved technology growing up,\" Pichai said in a 2014 interview at Delhi University. \"I used to read about what was happening in Silicon Valley, and I wanted to be a part of it.\"\n\nWhen Pichai got to America in 1993, he couldn't believe how expensive everything was.\n\nHe \"was in an absolute state of shock\" about the price of a backpack ‚Äî $60 ‚Äî he told Bloomberg.\n\nHe also missed his girlfriend, Anjali. The two eventually married and now have a son, Kiran, and daughter, Kavya.\n\nBefore Google, he had stints at semiconductor manufacturer Applied Materials and consulting firm McKinsey.\n\nPichai had his first interview at Google on April Fools' Day in 2004 ‚Äî the same day it launched Gmail. Pichai has said he initially thought the free email service was one of Google's famous pranks.\n\nPichai got his start working as a VP of product management, focused on Google's Toolbar,¬†a web-search feature on Internet Explorer and Firefox.\n\nOne of his early achievements: convincing Google founders Larry Page and Sergey Brin that Google should build its own web browser.\n\nIn 2006, Microsoft created a¬†\"doomsday\" scenario for Google by making Bing the new default search engine on Internet Explorer. To mitigate the effect of this change, Pichai helped convince Google execs to create its own browser, Google Chrome.\n\nChrome is now the world's most popular browser.\n\nAs a leader at Google, Pichai was known to be well-liked and focused on results, which resulted in more responsibility.\n\nPichai's \"substance over overt style\" approach was, in part, what led to Pichai taking over the Android division in 2013.\n\nHe spearheaded Android One, Google's push to \"make high-quality smartphones accessible to as many people as possible,\" and was also instrumental in ensuring Android was better integrated with Google.\n\nPichai was also behind Chrome OS, the operating system that powers Google's inexpensive Chromebook laptops, and was reportedly instrumental in helping put together Google's $3.2 billion acquisition of Nest in 2014.\n\nHis success garnered attention, and he was reportedly approached for a leadership role at Twitter.\n\nWhen Pichai turned down Twitter, he was rewarded for his allegiance,¬†getting $50 million and a promotion.\n\nAs he rose through the ranks, Pichai became the right-hand man of Google cofounder and former CEO Larry Page.\n\n\"He's like the Aaron to Larry's Moses,\" a source told Business Insider in 2014, referring to the biblical prophet's brother.\n\nThat relationship and his success led to Pichai's next important promotion in late 2014 when Page put him in charge of the company's core products.\n\nAfter proving himself with Chrome and Android, Pichai added Google+, Maps, Search, commerce and ads, and infrastructure to his portfolio. The move cemented Pichai's move as Page's second-in-command.\n\n\"Sundar has a tremendous ability to see what's ahead and mobilize teams around the super important stuff,\" Page wrote¬†in a memo announcing Pichai's promotion. \"We very much see eye-to-eye when it comes to product, which makes him the perfect fit for this role.\"\n\nWhen Alphabet was established as Google's parent company in 2015, Pichai was made CEO at Google, which encompassed search, YouTube, and Android.\n\nIn July 2017, Pichai was named to Alphabet's board of directors.\n\n\"Sundar has been doing a great job as Google's CEO, driving strong growth, partnerships, and tremendous product innovation. I really enjoy working with him, and I'm excited that he is joining the Alphabet board,\" Page said at the time.\n\nTwo years later came his final promotion at the company. Alphabet's CEO, Page, and president, Sergey Brin, announced that they were stepping down, and Pichai would become Alphabet's CEO.\n\nPage and Brin cofounded Google in 1998. They announced the change in a letter saying that Alphabet and Google \"no longer need two CEOs and a President.\"\n\nPichai earned a total of $226 million in 2022, with his pay spiking thanks to a multi-year stock award granted that year, making him one of America's best-paid CEOs.\n\nIn fiscal year 2024, Pichai earned $10.73 million in total compensation.\n\nPichai became a billionaire in 2025, according to the the Bloomberg Billionaires Index.\n\nThe top job at Alphabet also comes with increased public and internal scrutiny.\n\nIn 2018, the House Judiciary Committee grilled the CEO about Google's data privacy practices and plans with China.\n\nTwo years later, Pichai testified in front of Congress again over antitrust concerns. Two other major Google lawsuits were later filed by the US government over its alleged monopoly tactics.\n\nIn August 2024, a federal judge ruled against Google, finding the company had violated antitrust law to keep a monopoly on search.\n\nWhen penalties were announced in September 2025, Google was not forced to sell off its Chrome browser despite the Justice Department's request for that remedy. The judge ruled Google could no longer have exclusive search deals, and the company's stock jumped following the announcement.\n\nGoogle also dealt with internal turmoil after letting go of one of its top AI ethicists.\n\nIn December 2020, Google fired Timnit Gebru. Her exit came weeks after she was asked to retract a paper on the dangers of large language models and spoke out against the company's treatment of minority employees.\n\nGoogle employees were \"seriously pissed\" over how the firing was handled, one told BI¬†at the time, and Gebru said that Pichai¬†and other managers helped create \"hostile work environments.\"\n\nPichai eventually apologized for how the company dealt with it.\n\n\"I want to say how sorry I am for that, and I accept the responsibility of working to restore your trust,\" he wrote.\n\nAlso in 2020, Pichai was at the forefront of Google's response to the COVID-19 pandemic. Under his leadership, Google launched initiatives to help search users find accurate, useful information about the coronavirus.\n\nAnd like many large tech companies, Alphabet recruited rapidly at the start of the pandemic. Alphabet hired nearly 37,000 new workers in the 12 months leading up to October 2022.\n\nBut from late 2022, Pichai had to oversee an era of cost-cutting at the company.\n\nThat culminated in job losses in January 2023, when Google layoffs¬†affected 12,000 employees¬†or 6% of its global workforce. Pichai said he took \"full responsibility for the decisions that led us here.\"\n\nOver 1,400 Google employees wrote an open letter to Pichai¬†about how the layoffs were handled.\n\n\"Don't be evil,\" it read, a reference to the company's original motto.\n\nGooglers also criticized Pichai's big payday in the face of the job cuts, accusing him of \"destroying morale and culture\" at Google.\n\nGoogle also laid off hundreds more workers in its central engineering division and hardware team in early 2024.\n\nJob cuts continued into 2025, with the company flattening its management layer and shedding roles in its Cloud unit. In February 2026, Business Insider reported Google was offering buyouts to staff in its business unit who aren't \"all in.\"\n\nPichai has also had to deal with European regulatory issues. French regulators hit Google with a roughly $270 million fine in March 2024, accusing the company of using news outlet articles to train its Gemini AI model.\n\nPichai has also pushed Google forward in the AI arms race that's preoccupying Silicon Valley.\n\nGoogle issued a \"code red\" in December 2022 after the launch of OpenAI's ChatGPT sparked concerns about the future of its search engine and whether chatbots might replace it. Pichai redirected resources to focus on building Google's AI products.\n\nIt wasn't the first time Pichai expressed interest in the technology, though. In 2016, Pichai announced that Google would be an \"AI-first\" company. Two years later, he said it's \"one of the most important things that humanity is working on\" and \"more profound\" than \"electricity or fire.\"\n\nGoogle's AI efforts have resulted in its own chatbot.\n\nIn December 2023, Google's Gemini¬†launched. Gemini is a multimodal AI model that can process images, text, audio, video, and coding languages.\n\nPichai has also shifted Google's focus to integrating AI into its other products.\n\nAt the 2023 Google I/O conference, the CEO announced that Google would add AI features across Google Workspace, including in Search, Gmail, Docs, and other products.\n\nGoogle's traditional search function has also become an AI product, with AI overviews rolling out in 2024.\n\nAlphabet has continued to invest heavily in AI.\n\nOn an earnings call in February 2026, Google announced it planned to double its capital expenditure in 2026, with its spending expected to reach between $175 billion and $185 billion. Much of that was expected to go towards building out AI infrastructure, like chips and data centers.\n\nThe company also announced the Gemini app had over 750 million monthly active users, up 100 million from October.\n\nWhile Pichai is quite private, he is known to start his day with a cup of tea and an omelet ‚Äî plus a copy of The Wall Street Journal.\n\n\"I read the physical paper every single morning,\" he told Recode in 2016, adding that he reads The New York Times online.\n\nThe Pichai's morning routine also includes scrolling through TechMeme, a niche tech news website that aggregates the latest stories in tech published by media outlets.\n\nAlthough he's private, Pichai has spoken out about certain causes since he became a public figure.\n\nIn 2015, he responded to then-presidential candidate Donald Trump's suggestion that Muslims be barred from immigrating to the US.\n\n\"Let's not let fear defeat our values. We must support Muslim and other minority communities in the US and around the world,\" he wrote.\n\nPichai was among the Big Tech executives who attended Trump's inauguration in 2025. Google also donated $1 million to Trump's inaugural committee.\n\nPichai is seen as something of a hero in his home country of India.\n\n\"You are what they would like to be, an Indian who studied here, went overseas, and did what everyone would dream of doing,\" interviewer Harsha Bhogle said in a conversation with Pichai for students at Delhi University.\n\nIn 2020, Pichai announced that Google would invest $10 billion into India's tech sector over the next five to seven years to make the internet \"affordable and useful\" to everyone living in the country.\n\nJillian D'Onfro, Avery Hartmans, and Mary Meisenzahl contributed to an earlier version of this article.",
    "readingTime": 11,
    "keywords": [
      "internet explorer",
      "alphabet's ceo",
      "google's parent",
      "judge ruled",
      "ceo page",
      "company's core",
      "google cofounder",
      "job cuts",
      "pichai earned",
      "search engine"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sundar-pichai-google-alphabet-ceo-career-life",
    "thumbnail_url": "https://i.insider.com/698fd035d3c7faef0ece515f?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.896Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-a-complete-guide-to-the-hardware-company-behind-the-ai-boom",
    "title": "Nvidia: A complete guide to the hardware company behind the AI boom",
    "description": "Nvidia is one of the world's most valuable companies. Read about its history, leadership, and financials.",
    "fullText": "Nvidia has been around for over three decades, but the chipmaker became a household name only in the past few years.\n\nIn October 2025, the AI chipmaker became the first company to hit a¬†$5 trillion market cap.\n\nNvidia was founded in 1993 by Jensen Huang, Chris Malachowsky, and Curtis Priem, \"with a vision to bring 3D graphics to the gaming and multimedia markets.\"\n\nThe boom in AI technology has made it one of the most valuable companies in the world as companies scramble to buy its graphics processing units. Here's what you need to know about Nvidia.\n\nNvidia's origin story began at a Denny's during a meeting between Huang ‚Äî who once worked for the chain ‚Äî Malachowsky, and Priem.\n\nPersonal computing was on the cusp of taking off, and the trio sought a way to capitalize on it. Huang said in a 2010 interview with Stanford University's engineering school that they \"wondered whether starting a graphics company would be a good idea.\"\n\n\"We brainstormed and fantasized about what kind of company it would be and the world we could help,\" he said. \"It was fun.\"\n\nTheir goal was to improve the experience of gaming on a PC.\n\nIn 2006, it released CUDA, a general-purpose programming interface that would expand its business far beyond gaming.\n\nOn Sequoia Capital's \"Crucible Moments\" podcast, Andrew Ng, a Stanford professor who founded Google Brain, recalled his students telling him, \"Hey, Andrew, there's this thing called CUDA ‚Äî not that easy to program, but it's letting people use GPUs for something different.\"\n\n\"We started to see 10x or even 100x speedups training neural networks on GPUs because we could do 1,000 or 10,000 things in parallel rather than one step after another,\" he added.\n\nNvidia's GPUs were used to train AlexNet, an image classification system unveiled in 2012 that significantly influenced the field of deep learning.\n\nThe launch of ChatGPT in late 2022 ushered Nvidia into a new era. The chipmaker's shares surged by more than 1,000% from 2022 to early 2026.\n\nMuch of that growth came from the success of Nvidia's H100 chip, which it released in March 2022. The $40,000 chip, named for the computer scientist Grace Hopper, has played a crucial role in providing the computing power for large language models.\n\nSince the launch of Nvidia's Blackwell chips, which are twice as fast as its Hopper chips, customers including SoftBank, Amazon Web Services, and Microsoft have also flocked to the company.\n\nNvidia's success may be best personified by its CEO, Jensen Huang.\n\nA 61-year-old bona fide tech mogul, Huang has a net worth of about $165 billion, according to Forbes. While some execs sport chains or Patagonia vests, Huang is often spotted in a leather jacket. Business Insider identified at least six versions he's worn over the years, including a nearly $9,000 lizard-embossed coat from Tom Ford he wore at the company's global AI conference, GTC, in 2024. He commemorated Nvidia's stock price hitting $100 with a tattoo of Nvidia's logo on his arm.\n\nHuang's early years were tumultuous. He was born in Taiwan, and he spent time there and in Thailand before his parents sent him to the United States because of social unrest in the region.\n\nHe attended a reform school in Kentucky. He later moved to Oregon, where he was reunited with his parents. In high school, he became a nationally ranked table tennis champion.\n\nHuang graduated from Oregon State University with a degree in electrical engineering in 1984.\n\nDuring his freshman year, Huang met Lori Mills, his future wife. In an interview at the Hong Kong University of Science and Technology, he said he won her over by offering to help her with her homework. They married five years after meeting and now have two children.\n\nJensen Huang later earned a master's in electrical engineering from Stanford, and he worked at the chip companies LSI Logic and Advanced Micro Devices before launching Nvidia.\n\nHuang sold about 1.3 million shares of Nvidia when the company hit a $3 trillion market cap in June 2024, but he retains a more than 3% stake in the company.\n\nNvidia's business is built around GPUs, which can handle tasks simultaneously, as opposed to central processing units, or CPUs, which are in standard computers.\n\nNvidia's GPUs have become a mainstay of the AI revolution because they provide the computing power needed to run massive large language models like OpenAI's GPT-4 and Meta's Llama 3.\n\nDemand for Nvidia's H100 chips, built on its Hopper architecture, has been so high in late 2023 and 2024 that tech execs like Mark Zuckerberg and Elon Musk have bragged about how many units they're training new technology on. ByteDance has found workarounds to the US export bans on the chips to China. Saudi Arabia and the United Arab Emirates have bought up thousands of units to fuel their AI ambitions, while venture capitalists have bought Nvidia GPUs as backup units for their startups.\n\nIn 2024, Nvidia unveiled its Blackwell chips, which it says are twice as fast as its Hopper chips and have attracted customers including SoftBank, Amazon Web Services, and Microsoft. The recent frenzy around the Chinese company DeepSeek's models has fueled demand for Nvidia's H200 chips.\n\nIn January 2025, Huang also unveiled new chips targeting the gaming, robotics, and autonomous vehicle industries, as well as partnerships with Toyota and Microsoft.\n\nAt the January 2026 Consumer Electronics Show in Las Vegas, Huang unveiled the new Vera Rubin architecture that will succeed Blackwell. During his presentation, Huang said Vera Rubin is built to confront the core problem of a surge in computing demand.\n\nCompared with Nvidia's Blackwell architecture, Huang said Rubin delivers more than three times the performance, can run inference up to five times faster, and offers significantly higher inference compute per watt.\n\nA key to Nvidia's success is also CUDA, a software layer that can link GPUs to almost any AI application a developer wants to run. It's a critical component of the competitive advantage, or moat, that Nvidia has built up over the years.\n\nStill, AMD, Nvidia's main competitor, is quietly catching up. In October 2025, AMD announced a major multi-year strategic partnership with OpenAI under which OpenAI will deploy up to 6 gigawatts of AMD Instinct GPUs for its AI infrastructure starting in the second half of 2026. The deal is expected to bring tens of billions of dollars in revenue to AMD over time.\n\nNvidia's other competitors include Intel and IBM. Tech giants like Google, Amazon, Microsoft, and Meta have also released their own AI chips.\n\nNvidia overtook Apple and Microsoft for the title of the most valuable company in the world when it hit a historic $5 trillion in market capitalization in October 2025.\n\nAfter a tumultuous start to 2025 over chip export restrictions to China that would have cost billions in losses for Nvidia, Nvidia is heading into 2026 with confidence that demand for its AI chips is far from peaking.\n\nIn 2025, the chipmaker's blockbuster third-quarter results brought in $57 billion in revenue, including $51 billion from its data center business alone, beating Wall Street expectations. Nvidia raised its fourth-quarter forecast to $65 billion in sales, helping revive AI and semiconductor stocks after a brief slump. Shares of Nvidia and peers rallied on the upbeat outlook.\n\nHuang repeatedly dismissed fears of an AI bubble, arguing that the shift from CPUs to GPUs, the rise of agentic AI, and monetization through advertising all point to sustained growth. Nvidia also expanded its influence through major partnerships with OpenAI, Anthropic, and hyperscalers such as Meta.\n\nLooking to 2026, Nvidia is betting big on next-generation chips like Blackwell Ultra, massive AI infrastructure projects, and growth areas including robotics and automotive. While US export restrictions on China remain a headwind, Nvidia expects hyperscalers and global AI investment to keep demand strong into next year.\n\nNvidia is based in Santa Clara, California. Nvidia's headquarters, known as Voyager, was designed by the architectural firm Gensler and is about 750,000 square feet.\n\nIt has parks, \"treehouses\" for gatherings, and places designed to help employees focus. However, the overall design is intended to facilitate Nvidia's flat organizational structure.\n\n\"When you're moving that fast, you want to make sure that that information is flowing through the company as quickly as possible,\" Huang told the Harvard Business Review in 2023.\n\nIt's also a way to create more harmony between leadership and workers. Huang, who in 2023 oversaw 50 direct reports, has said that CEOs \"by definition\" should have the most direct reports at a company.\n\nHuang has earned a reputation among those who work with him as a demanding boss. Meetings with Huang can get heated, and senior employees have described his tough questions as a \"Jensen grilling.\"\n\nNvidia's top executives include Ian Buck, a vice president of hyperscale and high-performance computing; Colette Kress, the chief financial officer; and Bryan Catanzaro, a vice president of applied deep learning research.\n\nLanding a job at Nvidia isn't easy, but Lindsey Duran, a VP of recruitment, told BI that Nvidia applicants should express an interest in generative AI, tap into their professional network for referrals, and aim to do an internship.",
    "readingTime": 8,
    "keywords": [
      "web services",
      "softbank amazon",
      "deep learning",
      "direct reports",
      "vice president",
      "hopper chips",
      "market cap",
      "language models",
      "electrical engineering",
      "export restrictions"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia",
    "thumbnail_url": "https://i.insider.com/698f93dfd3c7faef0ece4ba3?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.743Z",
    "topic": "finance"
  },
  {
    "slug": "eccentric-but-brilliant-openclaws-creator-got-feedback-from-mark-zuckerberg",
    "title": "'Eccentric but brilliant': OpenClaw's creator got feedback from Mark Zuckerberg",
    "description": "Peter Steinberger joins Open AI, guided by Sam Altman, after feedback from Mark Zuckerberg on his AI agent OpenClaw's capabilities.",
    "fullText": "OpenClaw creator Peter Steinberger joined OpenAI, according to an X post by Sam Altman on February 15. But before that, Steinberger got feedback on his product from Mark Zuckerberg.\n\nOpenClaw is an open-source AI agent that can autonomously handle tasks like managing email, booking flights, and interacting with apps and services on a user's behalf.\n\n\"Many people are calling this one of the biggest moments in the recent history of AI, since the launch of ChatGPT in November 2022,\" Lex Fridman said about OpenClaw on the February 11 episode of his podcast, where he interviewed Steinberger.\n\nSteinberger discussed acquisition offers from both OpenAI and Meta on the podcast, saying he also considered raising venture capital but ultimately ruled it out. \"Been there, done that,\" he said of starting a company, adding that it would take time away from building and could create conflicts of interest between a commercial product and the open-source project.\n\nInstead, he narrowed his choice to the two AI labs, which he said made very different pitches. He said OpenAI lured him with compute power and access to cutting-edge infrastructure, while Meta's approach was more personal ‚Äî Zuckerberg spent a week using OpenClaw and sent detailed feedback.\n\n\"Mark basically played all week with my product and sent me like, 'Oh, this is great.' Or, 'This is shit. Oh, I need to change this.' Or, like, funny little anecdotes,\" Steinberger said of Zuckerberg, adding that he hopped on a WhatsApp call with the Meta CEO where they debated about Claude Code and Codex.\n\n\"And then I think afterwards he called me eccentric but brilliant,\" Steinberger said.\n\nJust before the call, Zuckerberg said he was coding, Steinberger told Fridman on the podcast.\n\n\"He didn't drift away in just being a manager; he gets me,\" Steinberger said. \"That was a good first start.\"\n\nSteinberger said he appreciated Zuckerberg testing the product on Fridman's podcast.\n\n\"People using your stuff is kind of like the biggest compliment, and also shows me that they actually care about it,\" Steinberger said.\n\nSteinberger acknowledged on the podcast that he was leaning toward one company but declined to say which. His choice, it seems, was OpenAI.",
    "readingTime": 2,
    "keywords": [
      "podcast",
      "product",
      "steinberger",
      "feedback",
      "open-source",
      "biggest",
      "adding",
      "away",
      "choice",
      "zuckerberg"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openclaw-creator-peter-steinberger-gets-feedback-from-mark-zuckerberg",
    "thumbnail_url": "https://i.insider.com/69933fd1e1ba468a96ac20a8?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.569Z",
    "topic": "finance"
  },
  {
    "slug": "openais-openclaw-hire-sparks-praise-memes-and-rivalry-chatter",
    "title": "OpenAI's OpenClaw hire sparks praise, memes, and rivalry chatter",
    "description": "OpenAI announced on Sunday it had hired Peter Steinberger, the creator of OpenClaw.",
    "fullText": "OpenAI announced on Sunday it had hired Peter Steinberger, the creator of OpenClaw. Within hours, the news sent ripples across the AI community, drawing praise from some executives, jabs from rivals, and a flood of memes from engineers watching the talent wars unfold.\n\nSteinberger wrote in a blog post shared on X Sunday that he was \"joining OpenAI to work on bringing agents to everyone.\"\n\nOpenAI CEO Sam Altman amplified the news, writing that \"the future is going to be extremely multi-agent.\"\n\nPeter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people. We expect this will quickly become core to our‚Ä¶\n\nIn response to the news, several OpenAI leaders welcomed Steinberger. Thibault Sottiaux, an engineering lead on OpenAI's Codex team, wrote that \"@steipete is proof you can just build things.\"\n\n@steipete is proof you can just build things\n\nAnother Codex engineer posted that one of the \"neat\" parts of OpenAI's culture is how many former founders work there.\n\nOne thing @steipete and I talked about over lunch last week was how many former founders are at OpenAI. It‚Äôs a really neat part of the culture.\n\nSteinberger told Lex Friedman in a podcast last week that both Mark Zuckerberg and Altman had made him offers.\n\nOpenClaw and its agent-only social media network Moltbook became wildly popular earlier this year as developers and AI enthusiasts shared clips of autonomous AI agents posting, replying, and interacting online. The open-source project, which demonstrates how networks of AI agents can coordinate to perform tasks across apps, also rapidly gained traction on GitHub.\n\nAfter Steinberger's announcement on Sunday, some of the people who worked on OpenClaw commented on the news.\n\n\"I know the decision was not an easy one, and I saw firsthand the pressure Peter was under, given that he understands how fundamental this could be for the AI timeline,\" Jamieson O'Reilly, an OpenClaw advisor,¬†wrote on X¬†in a post congratulating Steinberger.\n\nOne thing has become very clear to me working together with @steipete on @openclaw.\n\nWhile lots of people spectate from the sidelines, sharing their opinions, concerns and even hot takes at times, the dude is there, vigilantly on the front-lines pushing AI forward for every one‚Ä¶ https://t.co/fe5OEKgevm\n\nAaron Levie, the CEO of Box, said it was a sign \"2026 was the year of the agents.\"\n\nIf anyone was wondering if 2026 was the year of agents, OpenAI is bringing on the maker of Openclaw. This space is about to get very real. https://t.co/ocqX4kE9PT\n\nNot everyone in the tech space was as enthusiastic about the news.\n\nXAI cofounder Igor Babuschkin asked users on X: \"What's the best open alternative to OpenClaw right now? Doesn't make sense to put all your data into it if it's owned by OpenAI.\"\n\nPayPal mafia member Jason Calacanis expressed similar concerns.\n\nüòî what are the chances the open source project survives / thrives after this? https://t.co/4sUZkKWkGh\n\nSteinberger and OpenAI have said that OpenClaw will remain an open-source project with OpenAI's support.\n\nOther experts in the space pointed out that OpenAI's win could be a loss for Anthropic, especially after Steinberger wrote on X that Anthropic sent \"love letters from legal.\"\n\n\"Another interesting detail is Anthropic's visible disdain for anything open \n\nKris Puckett, a designer at Stripe, expressed a similar sentiment\n\nInstead of @AnthropicAI getting Claudebot, they rushed legal to send a C&D and lost out on not only brilliant talent but community drive. \n\nTruly would love to know the decision making process.\n\nRaphael Schaad, a visiting partner at Y Combinator, said, \"I bet this causes lots of VC tears.\"\n\nI bet this causes lots of VC tears and angry OSS folks. But think about this:\n\n- Peter showed the future and lots of awesome startups are starting to bloom from this. Invest in those!\n\n- Peter created one of the most exciting OSS projects in years. The community is vibrant and‚Ä¶ https://t.co/RFWwfXU9Lz\n\nAnd finally, some X power users did what they do best: posted memes about the news.\n\nWas expecting this one in replies pic.twitter.com/bfcZt3Ugg6",
    "readingTime": 4,
    "keywords": [
      "joining openai",
      "open-source project",
      "causes lots",
      "peter steinberger",
      "agents",
      "steipete",
      "community",
      "space",
      "openclaw",
      "across"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openais-openclaw-hire-sparks-praise-memes-rivalry-chatter-2026-2",
    "thumbnail_url": "https://i.insider.com/69934905e1ba468a96ac211a?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.552Z",
    "topic": "finance"
  },
  {
    "slug": "sales-reps-at-11-billion-ai-startup-elevenlabs-have-to-bring-in-20-times-their-base-salary-or-theyre-out-vp-says",
    "title": "Sales reps at $11 billion AI startup ElevenLabs have to bring in 20 times their base salary, or they're out ‚Äî VP says",
    "description": "AI startup ElevenLabs, valued at $11 billion, employs small teams with high sales quotas.",
    "fullText": "At $11 billion AI startup ElevenLabs, the message to sales reps is simple: Hit 20x your base salary, or you're out.\n\nSpeaking on the 20VC podcast on Friday, Carles Reina, VP of sales at the voice-cloning startup, talked through its \"ruthless\" quotas.\n\n\"So if I pay you $100,000 a year, your quota is $2 million. That's it. If you don't achieve your quota, then you're going to be out, right?\" Reina said. \"And we're ruthless on that end.\"\n\nElevenLabs ‚Äî which was recently valued at $11 billion after closing a $500 million funding round ‚Äî operates in micro-teams of five to ten people each, according to CEO and cofounder Mati Staniszewski, who spoke on a separate 20VC podcast episode in September.\n\nReina said he prefers to operate in smaller teams that hit their quotas, and pay them more.\n\nSmall teams have become a growing trend in tech, with AI startups touting their ability to scale with far fewer employees by working alongside AI agents.\n\nLinkedIn cofounder Reid Hoffman wrote in January that a team of 15 people using AI can rival a team of 150 who aren't.\n\nMeanwhile, Mark Zuckerberg said on a Meta earnings call in July that he has \"gotten a little bit more convinced around the ability for small, talent-dense teams to be the optimal configuration for driving frontier research.\"\n\nReina said the \"ruthless\" quota has been successful at ElevenLabs, saying on the 20VC podcast that more than 80% of reps hit their sales quota.\n\nElevenLabs did not respond to a request for a comment.\n\nHe added that the firm compensates both the account executive and customer success manager if they upsell a company within the first 12 months.\n\n\"I'm paying double, but I don't care,\" Reina said. \"It makes perfect sense because then I have these two people busting their ass to make sure that they actually can make more money, which is fantastic for me as a company.\"\n\nThe push for higher performance isn't limited to AI startups.\n\nIn April, Google said it was restructuring its compensation structure to increase rewards for top performers. \"High performance is more important than ever,\" Google's head of compensation told staff at the time.",
    "readingTime": 2,
    "keywords": [
      "elevenlabs",
      "quota",
      "sales",
      "podcast",
      "ruthless",
      "teams",
      "startup",
      "reps",
      "you're",
      "quotas"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/elevenlabs-11-billion-ai-startup-ruthless-sales-strategy-2026-2",
    "thumbnail_url": "https://i.insider.com/69933d3ce1ba468a96ac208b?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.551Z",
    "topic": "finance"
  },
  {
    "slug": "why-your-digital-investments-arent-creating-value",
    "title": "Why Your Digital Investments Aren‚Äôt Creating Value",
    "description": "Many companies are pouring money into AI, analytics, and CRM platforms, yet struggle to translate those investments into measurable revenue growth. The problem isn‚Äôt technology adoption but the failure to redesign how commercial organizations generate insight, make decisions, and coordinate action. Companies that succeed treat digital as a commercial operating model transformation, making four shifts that turn digital from a perceived tax into a durable growth dividend.",
    "fullText": "Why Your Digital Investments Aren‚Äôt Creating Value by Prabhakant Sinha, Arun Shastri and Sally LorimerFebruary 16, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintCompanies are investing heavily in digital analytics hubs with AI and gen AI capabilities, enterprise CRM systems, and marketing technology platforms. Nowhere is this more concentrated than in commercial functions, where growth and customer impact live.",
    "readingTime": 1,
    "keywords": [
      "digital"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/02/why-your-digital-investments-arent-creating-value",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb25_14_AaronMarin.jpg",
    "created_at": "2026-02-16T18:29:59.941Z",
    "topic": "business"
  },
  {
    "slug": "trilliondollar-ai-market-wipeout-happened-because-investors-banked-that-almost-every-tech-company-would-come-out-a",
    "title": "Trillion-dollar AI market wipeout happened because investors banked that ‚Äòalmost every tech company would come out a winner‚Äô",
    "description": "\"Nobody truly knows who the long-term winners and losers of this extraordinary technology will be,\" Deutsche's Jim Reid wrote this morning.",
    "fullText": "Investors wobbled last week as they worked through the disruption AI is likely to cause across global industries, with further hiccups potentially bubbling through this week. But the reckoning should have been expected, argued Deutsche Bank in a note to clients this morning, because it is a readjustment of perhaps overly optimistic expectations.\n\nSoftware stocks in particular suffered a wipeout amid mounting concerns that large language models may replace current service offerings. Companies in the legal, IT, consulting and logistics sectors were also impacted. JP Morgan wrote last week that some $2 trillion had been wiped off software market caps alone as a result, a reality that prior to a fortnight ago, Deutsche‚Äôs Jim Reid argued had been purely academic. \n\nA 13-figure sell-off is something Reid has speculated over for some time, telling clients: ‚ÄúFor months, my published view has been that nobody truly knows who the long term winners and losers of this extraordinary technology will be. Yet as recently as October, markets were implicitly pricing in a world where almost every tech company would come out a winner.\n\nWhy did software stocks suffer major selloffs recently?\n\nWhat caused the $2 trillion market cap wipeout?\n\nWhat makes AI disruption different from past cycles?\n\nHow are experts viewing current AI stock valuations?\n\n‚ÄúOver recent weeks we‚Äôve seen a more realistic differentiation emerge within tech‚Äîbut that repricing is now rippling into the broader economy with surprising speed.‚Äù\n\nReid hasn‚Äôt been alone in his suspicion that investors had perhaps been painting over the entire stock market (and indeed wider economy) with the same, optimistic brush. Some speculators have made broad-stroke arguments that the efficiencies offered by AI will result in wins for the vast majority of companies, while others have argued that while AI is not in a bubble, there are pockets of overoptimism that may burst. \n\nJPMorgan‚Äôs CEO Jamie Dimon is of such an opinion, explaining at the Fortune Most Powerful Women Summit last year: ‚ÄúYou should be using it,‚Äù (speaking to any business that was listening). But he added a caveat, saying that back in 1996, ‚Äúthe internet was real,‚Äù and ‚Äúyou could look at the whole thing like it was a bubble.‚Äù Then he broke down the real difference that he sees‚Äîbetween AI, on the one hand, and generative AI, on the other. It‚Äôs an important distinction, Dimon said, while adding that ‚Äúsome asset prices are high, in some form of bubble territory.‚Äù\n\nIndeed, Jeremy Siegel, Emeritus Professor of Finance at The Wharton School of the University of Pennsylvania, argued that such shifts demonstrate investors are ‚Äúasking the right questions.‚Äù Writing for WisdomTree a week ago, where he serves as senior economist, Siegel said: ‚ÄúWhen companies talk about $200 billion in capital expenditures, markets should scrutinize payback periods, competitive dynamics, and whether durable moats can be built in an environment where technology is evolving at breakneck speed. That tension explains why leadership will continue to rotate even as the secular story remains intact.‚Äù \n\nThat said, Reid suggested that the market may be repricing overzealously, arguing the disruption in ‚Äúold economy‚Äù sectors feels overdone: ‚ÄúThe real challenge is that even by the end of this year, we still won‚Äôt have enough evidence to identify the structural winners and losers with confidence. That leaves plenty of room for investors‚Äô imaginations‚Äîboth optimistic and pessimistic‚Äîto run wild. As such big sentiment swings will continue to be the order of the day.‚Äù",
    "readingTime": 3,
    "keywords": [
      "software stocks",
      "investors",
      "argued",
      "market",
      "disruption",
      "optimistic",
      "economy",
      "bubble",
      "clients",
      "wipeout"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/trillion-dollar-ai-market-wipeout-115521847.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/diuu6e_zp4PLZ9MDwG0sZA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/05d4f0f594c265ecbc6d3aa458393bc3",
    "created_at": "2026-02-16T18:29:59.634Z",
    "topic": "finance"
  },
  {
    "slug": "skilldeck-macos-app-to-manage-skills-across-multiple-ai-agents",
    "title": "SkillDeck ‚Äì macOS app to manage skills across multiple AI agents",
    "description": "Native macOS SwiftUI app for managing multiple AI code agent skills - crossoverJie/SkillDeck",
    "fullText": "crossoverJie\n\n /\n\n SkillDeck\n\n Public\n\n Native macOS SwiftUI app for managing multiple AI code agent skills\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n crossoverJie/SkillDeck",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/crossoverJie/SkillDeck",
    "thumbnail_url": "https://opengraph.githubassets.com/542176cf442007938d113d7f8f38893d2a257b0f45332cd3b09f3df5d2f5ea78/crossoverJie/SkillDeck",
    "created_at": "2026-02-16T12:38:10.229Z",
    "topic": "tech"
  },
  {
    "slug": "bytedance-to-add-safeguards-to-seedance-20-following-hollywood-backlash",
    "title": "ByteDance to add safeguards to Seedance 2.0 following Hollywood backlash",
    "description": "ByteDance has said it will work to strengthen safeguards on a new AI video-making tool, following copyright concerns and legal threats from Hollywood.",
    "fullText": "Chinese tech giant ByteDance has said it will strengthen safeguards on a new artificial intelligence video-making tool, following complaints of copyright theft from entertainment giants.\n\nThe tool, Seedance 2.0, enables users to create realistic videos based on text prompts. However, viral videos shared online appear to show copyrighted characters and celebrity likenesses, raising intellectual property concerns in the U.S.\n\n\"ByteDance respects intellectual property rights and we have heard the concerns regarding Seedance 2.0,\" a company spokesperson said in a statement shared with CNBC.\n\n\"We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,\" the spokesperson added.\n\nByteDance's response comes after receiving backlash and stern warnings from Hollywood groups like the Motion Picture Association (MPA), a trade association representing major Hollywood studios including Netflix, Paramount Skydance, Sony, Universal, Warner Bros. Discovery and Disney.\n\nThe group issued a forceful public statement at the end of last week demanding that ByteDance immediately cease what it called \"infringing activity.\"\n\n\"In a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of U.S. copyrighted works on a massive scale,\" said MPA chairman and CEO Charles Rivkin in the statement.\n\n\"By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs.\"\n\nAccording to a report from Axios, Disney sent a cease-and-desist letter Friday to ByteDance, accusing the company of distributing and reproducing its intellectual property through the new AI tool without permission.\n\nThe legal notice alleged that ByteDance had effectively pre-packaged Seedance with a pirated library of copyrighted characters, portraying them as if they were public-domain clip art,\" the report added.\n\nDisney has also sent cease-and-desist letters to AI companies in the past. In September, the company warned the AI startup Character.AI to stop the unauthorized use of its copyrighted characters.\n\nWhile trying to protect its intellectual property, Disney has signed a licensing deal with and invested in OpenAI. The agreement allows the AI company to use Disney characters from the Star Wars, Pixar and Marvel franchises in its Sora video generator.\n\nParamount Skydance has also sent a cease-and-desist letter to ByteDance, making similar accusations, Variety reported over the weekend.",
    "readingTime": 2,
    "keywords": [
      "cease-and-desist letter",
      "intellectual property",
      "copyrighted characters",
      "seedance",
      "safeguards",
      "tool",
      "statement",
      "unauthorized",
      "bytedance",
      "strengthen"
    ],
    "qualityScore": 1,
    "link": "https://www.cnbc.com/2026/02/16/bytedance-safegaurds-seedance-ai-copyright-disney-mpa-netflix-paramount-sony-universal.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/108266044-1771229974981-gettyimages-2261149851-vcg111620288212.jpeg?v=1771230010&w=1920&h=1080",
    "created_at": "2026-02-16T12:38:10.190Z",
    "topic": "tech"
  },
  {
    "slug": "how-to-talk-to-any-github-repo",
    "title": "How to talk to any GitHub repo",
    "description": "Paste a GitHub link into your LLM conversation. Ask questions to understand logic, generate doc, and run the app locally. Use the guide and prompts in this article to structure your conversation.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.theaithinker.com/p/how-to-talk-to-any-github-repo",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!ZMNj!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e2189f-607c-4f2e-808d-39ac45050c32_1024x731.png",
    "created_at": "2026-02-16T12:38:10.053Z",
    "topic": "tech"
  },
  {
    "slug": "the-speed-of-building-has-outpaced-the-thinking-part",
    "title": "The Speed of Building Has Outpaced the Thinking Part",
    "description": "Explore the impact of AI on indie development and the need for a moral compass in coding. Are we sacrificing quality for speed?",
    "fullText": "I get this feeling a lot lately. I wake up with an idea, grab a coffee, open my editor, and thanks to the current generation of AI tools, I can have a working prototype before breakfast.\n\nThe barrier to entry for software development hasn‚Äôt just been lowered; it‚Äôs effectively been removed. We are in the era of ‚Äúvibe coding,‚Äù where natural language prompts turn into deployed applications in minutes. It is exhilarating. It is powerful.\n\nBut lately, I have started to wonder: Are we killing indie development with AI?\n\nDon‚Äôt get me wrong, I love these tools. I use GitHub Copilot and other LLMs daily. But I believe we have reached a tipping point where the speed of building has outpaced the thinking part. We are so focused on how fast we can build that we stopped asking if we should build.\n\nIn this post, I want to talk about why we need a new ‚Äúmoral compass‚Äù for development in the AI age, and a potential solution to help us get there.\n\nFive years ago, if you had an idea for a SaaS tool, say, a screenshot editor or a niche time-tracker,you had to sit down and plan. The friction of coding was a natural filter. You had to ask yourself: ‚ÄúIs this worth X hours of my life?‚Äù\n\nToday, that cost is near zero. If you don‚Äôt like the screenshot tool you‚Äôre paying $15 a year for, you can prompt an AI to build a clone in an afternoon.\n\nOn the surface, this looks like freedom. But look a little deeper. That $15 tool you just cloned? It was likely built by another indie developer. Someone who spent months thinking about edge cases, designing the interface, writing documentation, and supporting users. By cloning it just because you can, you aren‚Äôt just saving $15; you are actively devaluing the craft of independent software development and the livelihood of the person behind it.\n\nIf we all just clone everything we use, we completely commoditize the market. We create a sea of ‚Äúgood enough‚Äù AI-generated noise where no one can actually sustain a business.\n\nLet me paint a picture that I think a lot of developers are starting to recognize.\n\nYou spend weeks, maybe months, building something. You think about the problem, you design the interface, you handle the edge cases, you support your users, you write the docs. You pour yourself into it. Then one morning, someone sees your product, opens their AI editor, and builds a ‚Äúgood enough‚Äù version in an afternoon. They ship it. Maybe they make it free, maybe they make it open source, maybe they just use it themselves and tell their friends, their community, their followers.\n\nThey did not steal your code. They did not copy your product. They just‚Ä¶ rebuilt it. Close enough. Good enough. And now your product has competition that cost someone a few hours of prompting while it cost you months of your life.\n\nBut it does not stop there. A third developer sees that clone and thinks, ‚ÄúI can do this too, but I want it slightly different.‚Äù So they prompt their own version. And a fourth. And a fifth. Each one is not a copy in the traditional sense. Nobody is violating a license. Nobody is stealing intellectual property. They are just building their own version that matches their use case.\n\nIt is a lot like art. You create a painting, something original, something you are proud of. Then somebody sees it and recreates it. Not a forgery, just their interpretation. But they have a bigger budget, a larger audience, better distribution. Suddenly their version is the one people see first. Others share that version instead of yours. This is what is happening a lot on social media with AI-generated content. The original creator is overshadowed by the faster, more accessible clone.\n\nIn the art world, we have a word for this erosion: it is called devaluation. In the software world, we are doing it at industrial scale, and we are calling it innovation.\n\nI am not saying you should never build something that already exists. Competition is healthy, and sometimes a fresh perspective genuinely improves a category. But there is a difference between thoughtful competition and reflexive duplication. The question every developer should ask themselves is: ‚ÄúIf I know someone can clone my work in an afternoon, is it still worth building?‚Äù\n\nThe answer, I believe, is yes, but only for the things that cannot be cloned in an afternoon. The deep domain knowledge. The community around your tool. The years of user feedback baked into every feature. The trust you have earned. Those are the things AI cannot reproduce with a prompt, and I definitely don‚Äôt want to discourage people from building those things.\n\nBut you can only build those things if you commit to something long enough for them to develop. And that is the real danger of the current moment: not that AI makes building easy, but that it makes abandoning easy. Why invest years in one product when you can ship a new one every week?\n\nI have no room to preach. I am right there in the trenches with you.\n\nWhen I built Front Matter CMS, it was way before the AI boom. I had to think deeply about the problem because the investment of time was massive. I looked at the market, saw a gap in Visual Studio Code, and built it because nothing else existed.\n\nCompare that to recently. I built a set of cycling tools (never released by the way) for myself. Did similar tools exist? Absolutely. Were they better? Definitely. But I wanted to see how far I could get with AI. I treated it as a training exercise. In the end, I started paying for a tool called Join, which does the same thing, because it was better and I could focus on my actual work instead of maintaining a tool that was just ‚Äúgood enough‚Äù for me.\n\nI did the same with FrameFit. I investigated the market a little, didn‚Äôt see an exact match, and just started building.\n\nThere is a difference between building for education (learning how AI tools work) and releasing products that dilute the hard work of others. My worry is that we are blurring that line. We are shipping our ‚Äútraining exercises‚Äù as products, and it is making the ecosystem messy for everyone.\n\nAnd I know this because I have been on both sides of it.\n\nHere is the thing that made me stop and reflect. I have projects on both sides of this line, and they feel completely different.\n\nDemo Time is something I have been building for years. Not weeks, not weekends, years. It started because I was a conference speaker who kept running into the same problem: demos failing on stage. Nobody had built a proper solution inside Visual Studio Code, so I did. Over time, it grew because I kept showing up. I used it at conferences, talked to other speakers, iterated based on real feedback from people doing real presentations at events like Microsoft Ignite, GitHub Universe, and OpenAI DevDays. Today it has over 26,000 installations.\n\nNone of that came from code. The code is open source. Anyone can see it, fork it, or rebuild it. Someone could probably vibe-code a basic version in a weekend. But what they cannot replicate is twelve years of conference speaking that taught me what presenters actually need. You would need that experience, or a big company and budget behind you, to even come close. The relationships with the community, the trust that comes from being the person who shows up, year after year, and keeps making the tool better because you genuinely use it yourself. That is not something you can prompt into existence.\n\nCompare that to FrameFit. I built it, I use it, and it works. But if it disappeared tomorrow, I wouldn‚Äôt lose any sleep over it. Demo Time? That is like a child to me. I put my passion into it.\n\nThat contrast taught me something important: AI cannot commoditize the human context around software. Community, trust, domain expertise, showing up consistently over time. These are not features you ship. They are moats you build by caring about something longer than a weekend.\n\nThe developers who will thrive are not the fastest shippers. They are the ones who pair AI speed with human judgment. Who build communities, not just codebases. Who invest in trust, not just features. But that only happens if we slow down enough to think about what we are doing.\n\nWe need to re-introduce friction into our process. Not the old friction of writing boilerplate code. That friction is gone, and good riddance. I am talking about the friction of thinking. The pause that forces you to examine your intentions before you act on them.\n\nBefore AI, ‚Äúthinking‚Äù was mandatory. The cost of building was high enough that it naturally filtered out bad ideas. Now, that filter is gone, and thinking must be a conscious, deliberate choice. When I have an idea now, I am trying to force myself to pause before I open Visual Studio Code or prompt a new agent.\n\nI try to run through these four questions:\n\nThat last one is crucial. If there is an open-source tool that does 80% of what you want, the ‚Äúold‚Äù way was to contribute a Pull Request. The ‚ÄúAI way‚Äù often tempts us to just rebuild the whole thing from scratch because it feels faster.\n\nBut ‚Äúfaster‚Äù isn‚Äôt always ‚Äúbetter‚Äù for the community. And here is the irony: we could use AI itself for this thinking step. Instead of prompting an LLM to start building, prompt it to research what already exists first. Use AI for the thinking, not just the building.\n\nI don‚Äôt expect AI platforms that allow you to vibe code to solve this for us. Their business model is predicated on you writing more code (read: prompts), not less. They want you to spin up new projects constantly. They have no incentive to say, ‚ÄúHey, wait, this already exists.‚Äù\n\nThink about it: when was the last time you saw a developer advocate from one of these platforms demonstrate how to contribute to an existing project instead of building something new from scratch? Their marketing is all about speed, novelty, and the thrill of creation. Not about responsibility.\n\nSo, I started thinking: What if we used AI to stop us from building with AI? You could say that this is a paradox, but I think it is actually a necessary evolution of our responsibility as developers.\n\nI am exploring the idea of a Product Moral Compass Agent.\n\nImagine a mandatory first step in your ‚Äúvibe coding‚Äù workflow. Before you start generating code, you pitch your idea to this agent. It interviews you, not to judge you, but to make sure you are making an informed decision.\n\nThis agent would act as the ‚Äúthinking partner‚Äù we are skipping. It could:\n\nIf you still want to build it after that? Great. Go ahead and start coding. But at least you are making an informed, conscious decision rather than reflexively adding more noise to the world.\n\nI am currently building this agent. The first version is available on GitHub: Product Moral Compass Agent. Yes, I am aware of the irony, I am proposing to build something new to stop people from building new things. But I ran it through my own four questions first, and nothing like it exists yet.\n\nOnce it is ready, I will share it openly so that any developer can use it as part of their workflow. Not as a gatekeeper, but as a guide. A thinking partner that helps you pause, research, and decide before you build.\n\nIn the meantime, here is what you can do right now: the next time you have an idea, spend ten minutes with your favorite AI tool and ask it to find every existing solution first. Check your own bank statements. Are you already paying for a tool that solves this? If so, respect that developer‚Äôs work. Look at GitHub. Is there a repo that could use your help instead of your competition?\n\nThe time to learn is right now, but the time to think is also right now.\n\nI want you to keep building. I want you to be prolific. But let‚Äôs not let the ease of creation destroy the value of what we create.\n\nI am curious to hear your thoughts. Is this gatekeeping, or is it a necessary evolution of our responsibility as developers? Let me know in the comments below.\n\nIs an AI able to write the contents of your article? Well, that was a question I had and wanted to find out. In this article I tell you all about it.\n\nDiscover the latest advancements in documentation technology and how tools like GitHub Copilot for Docs, Mendable, and OpenAI are changing the game.\n\nDiscover how to leverage Azure AI Translator's Sync API for real-time document translation, simplifying your workflow and enhancing user experience.\n\nFound a typo or issue in this article? Visit the GitHub repository \nto make changes or submit a bug report.\n\nSolutions Architect & Developer Expert\n\nEngage with your audience throughout the event lifecycle",
    "readingTime": 12,
    "keywords": [
      "visual studio",
      "product moral",
      "compass agent",
      "studio code",
      "edge cases",
      "necessary evolution",
      "vibe coding",
      "software development",
      "github copilot",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://www.eliostruyf.com/killing-indie-development-with-ai/",
    "thumbnail_url": "https://www.eliostruyf.com/social/5f59a11b-79bb-48df-9b89-b8abc9ba3037.png",
    "created_at": "2026-02-16T12:38:09.254Z",
    "topic": "tech"
  },
  {
    "slug": "kanvibe-kanban-board-that-autotracks-ai-agents-via-hooks",
    "title": "KanVibe ‚Äì Kanban board that auto-tracks AI agents via hooks",
    "description": "Self-hosted Kanban board with browser terminals for AI coding agents. Hook-driven auto-tracking ‚Äî manage tmux/zellij sessions and git worktrees from one board. - rookedsysc/kanvibe",
    "fullText": "rookedsysc\n\n /\n\n kanvibe\n\n Public\n\n Self-hosted Kanban board with browser terminals for AI coding agents. Hook-driven auto-tracking ‚Äî manage tmux/zellij sessions and git worktrees from one board.\n\n License\n\n AGPL-3.0 license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n rookedsysc/kanvibe",
    "readingTime": 1,
    "keywords": [
      "board",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/rookedsysc/kanvibe",
    "thumbnail_url": "https://opengraph.githubassets.com/1686c5ce06bcd0be96aea5e2e16beffdd136eeb70f17f431b75349727b34dbe2/rookedsysc/kanvibe",
    "created_at": "2026-02-16T12:38:09.047Z",
    "topic": "tech"
  },
  {
    "slug": "beatflow-texttomidi-generator-that-plans-full-song-structure",
    "title": "BeatFlow: Text-to-MIDI generator that plans full song structure",
    "description": "Web-based AI music generator that plans full song arrangements based on music theory, offering in-browser Piano Roll for editing multi-track MIDI instead of just generating static audio. - the0cp/b...",
    "fullText": "the0cp\n\n /\n\n beatflow\n\n Public\n\n Web-based AI music generator that plans full song arrangements based on music theory, offering in-browser Piano Roll for editing multi-track MIDI instead of just generating static audio.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n the0cp/beatflow",
    "readingTime": 1,
    "keywords": [
      "music"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/the0cp/beatflow",
    "thumbnail_url": "https://opengraph.githubassets.com/e9d71946e201cb2c1fc9efe072ca3b6924dd5d06278818b66bec5055d09b8c79/the0cp/beatflow",
    "created_at": "2026-02-16T12:38:08.910Z",
    "topic": "tech"
  },
  {
    "slug": "thanks-a-lot-ai-hard-drives-are-sold-out-for-the-year-says-wd",
    "title": "Thanks a lot, AI: Hard drives are sold out for the year, says WD",
    "description": "AI companies have bought out Western Digital's storage capacity for 2026. It's only February.",
    "fullText": "Looking to buy a new hard drive? Get ready to pay even more this year.\n\nAccording to Western Digital, one of the world's biggest hard drive manufacturers, the company has already sold out of its storage capacity for 2026 with more than 10 months still left in the year.\n\n\"We're pretty much sold out for calendar 2026,\" said Western Digital CEO Irving Tan on the company's recent quarterly earnings call.\n\nTan shared that most of the storage space has been allocated to its \"top seven customers.\" Three of these companies already have agreements with Western Digital for 2027 and even 2028.\n\nFurthermore, the incentive for these hardware companies to prioritize the average consumer is also dwindling. According to Western Digital, thanks to a surge in demand from its enterprise customers, the consumer market now accounts for just 5 percent of the company's revenue.\n\nAI companies have been eating up computer hardware as industry growth accelerates. Prices for products ranging from computer processors to video game consoles have skyrocketed due to these AI companies cannibalizing supply chains.\n\nThe tech industry has already been experiencing a shortage of memory¬†due to¬†demand from AI companies. PC makers have been forced to raise RAM prices¬†on a near-regular basis as shortages persist. Video game console makers, like Sony, have even reportedly considered pushing the next PlayStation launch beyond the planned 2027 release in hopes that AI-related hardware shortages would be resolved by then.\n\nWith this latest news from Western Digital, it appears the ever-increasing demands from AI companies for memory and storage will continue to grow, with no end in sight. Unless, of course, investors decide to pull back from AI over fears that AI's promises may not come to fruition. But, for now at least, the shortages ‚Äì and price hikes for consumers ‚Äì will continue.\n\nTopics\n Artificial Intelligence",
    "readingTime": 2,
    "keywords": [
      "western digital",
      "storage",
      "hardware",
      "shortages",
      "drive",
      "company's",
      "customers",
      "consumer",
      "demand",
      "computer"
    ],
    "qualityScore": 0.85,
    "link": "https://mashable.com/article/ai-hard-drive-hdd-shortages-western-digital-sold-out",
    "thumbnail_url": "https://helios-i.mashable.com/imagery/articles/03BMp5tylVs9DJJavYCVFKV/hero-image.fill.size_1200x675.v1771180235.jpg",
    "created_at": "2026-02-16T12:38:08.317Z",
    "topic": "tech"
  },
  {
    "slug": "the-art-of-the-squeal-what-we-can-learn-from-the-flood-of-ai-resignation-letters",
    "title": "The art of the squeal: What we can learn from the flood of AI resignation letters",
    "description": "What we can learn from the flood of \"why I quit\" letters from researchers at Anthropic, OpenAI, and xAI.",
    "fullText": "Corporate resignations rarely make news, except at the highest levels. But in the last two years, a spate of X posts, Substack open letters, and public statements from prominent artificial intelligence researchers have created a new literary form ‚Äî the AI resignation letter ‚Äî with each addition becoming an event to be mined for meaning. Together, the canon of these letters ‚Äî some of them apparently bound by non-disclosure agreements and other loyalties, legally compelled or not ‚Äî tells us a lot about how some of the top people in AI see themselves and the trajectory of their industry. Overall, the image is bleak.\n\nThis past week brought several additions to the annals of \"Why I quit this incredibly valuable company working on bleeding-edge tech\" letters, including from researchers at xAI and an op-ed in The New York Times from a departing OpenAI researcher. Perhaps the most unusual was by Mrinank Sharma, who was put in charge of Anthropic's Safeguards Research Team a year ago, and who announced his departure from what is often considered the more safety-minded of the leading AI startups. He posted a 778-word letter on X that was at times romantic and brooding ‚Äî he quoted the poets Rainer Maria Rilke and Mary Oliver. Opining on AI safety, his own experiences working on AI sycophancy and \"AI-assisted bioterrorism,\" and the \"poly-crisis\" consuming our society, the letter had three footnotes and some ominous, if vague, warnings.\n\n\"We appear to be approaching a threshold where our wisdom must grow in equal measure to our capacity to affect the world, lest we face the consequences,\" Sharma wrote. \"Throughout my time here, I've repeatedly seen how hard it is to truly let our values govern our actions.\"\n\nSharma noted that his final project at Anthropic was \"on understanding how Al assistants could make us less human or distort our humanity\" ‚Äî a nod, perhaps, to the scourge of AI psychosis and other novel harms emerging from people overvaluing their relationships with chatbots. He said that he didn't know what he was going to do next, but expressed a desire to pursue \"a poetry degree and devote myself to the practice of courageous speech.\" The researcher ended by including the full text of \"The Way It Is\" by the poet William Stafford.\n\nIn the annals of AI resignations, Sharma's missive might be less dramatic than the boardroom coup that ousted OpenAI CEO Sam Altman for five days in November 2023. It's less troubling than some of the other end-of-days warnings published by AI safety researchers who quit their posts believing that their employers weren't doing enough to mitigate the potential harms of artificial general intelligence, or AGI, a smarter-than-human intelligence that AI companies are racing to build. (Some AI experts question whether AGI is even achievable or what it might mean.)\n\nBut Sharma's note captures the deep attachments that top AI researchers ‚Äî who are extremely well-compensated and work together in small teams ‚Äî feel to their work, their colleagues, and, often, their employers. It also exposes some of the tensions that we see cropping up again and again in these resignation announcements. At top AI labs, there's an intense competition for resources between research/safety teams and people working on consumer-facing AI products. (Few, if any, public resignations seem to come from people on the product side.) There are pressures to ship without proper testing, established safeguards, or knowing what might happen when a system goes rogue. And there's a deep sense of mission and purpose that can sometimes be upended by feelings of betrayal.\n\nMany of the people who have publicly quit AI companies work in safety and \"alignment,\" the field tasked with making sure that AI capabilities align with human needs and welfare. Many of them seem very optimistic about AI, and even AGI, but they worry that financial pressures are eating away at safeguards. Few seem to be giving up on the field entirely ‚Äî except perhaps Sharma, the aspiring poet. Either they jump ship for another seven-, eight-, or nine-figure job at a competing AI startup, or they become civic-minded AI analysts and researchers at one of a growing number of AI think tanks.\n\nAll of them seem to be worried that either epic gains or epic disasters lie ahead. Announcing his departure from Anthropic to become OpenAI's Head of Preparedness earlier this month, Dylan Scandinaro wrote on LinkedIn, \"AI is advancing rapidly. The potential benefits are great ‚Äî and so are the risks of extreme and even irrecoverable harm.\" Daniel Kokotajlo, who resigned from OpenAI, said that OpenAI's systems \"could be the best thing that has ever happened to humanity, but it could also be the worst if we don't proceed with care.\"\n\nRecently, xAI, where co-founder Elon Musk is notorious for tinkering with the proverbial dials of the Grok chatbot, has seen a half-dozen members of its founding team leave. But the locus of the AI resignation letter, as a kind of industry artifact, is the red-hot startup OpenAI, where major figures, including top executives and safety-minded researchers, have been leaving for the last two years. Some resigned; some were fired; some were described in the press as \"forced out\" over internal company disputes. Seven left in a short period in the first half of 2024.\n\nWith revenue paling compared to its massive and growing infrastructure costs, OpenAI recently announced that it would begin incorporating ads into ChatGPT. That caused researcher Zo√´ Hitzig to quit. This week, she published a resignation letter in the Times, warning about the potential implications of ads becoming part of the substrate of chatbot conversations. \"ChatGPT users have generated an archive of human candor that has no precedent, in part because people believed they were talking to something that had no ulterior agenda,\" she wrote. But, she warned, OpenAI seemed prepared to leverage that \"archive of human candor\" ‚Äî much as Facebook had done ‚Äî to target ads and undermine user autonomy. In the service of maximizing engagement, consumers might be manipulated ‚Äî the classic sin of the modern internet.\n\nIf you think you are building a world-changing invention, you need to be able to trust your leadership. That's been a problem at OpenAI. On November 17, 2023, Altman was dramatically fired by the company's board because, it claimed, Altman was \"not consistently candid in his communications with the board.\" Less than a week later, he performed his own boardroom coup and was reinstated, before consolidating his power. The exodus proceeded from there.\n\nOn May 14, 2024, OpenAI co-founder Ilya Sutskever announced his resignation. Sutskever was replaced as head of OpenAI's superalignment team by John Schulman, another company co-founder. A few months later, Schulman left OpenAI for Anthropic. Six months later, he announced his move to Thinking Machines Lab, an AI startup founded by former OpenAI CTO Mira Murati, who had replaced Altman as OpenAI's interim CEO during his brief firing.\n\nThe day after Sutskever left OpenAI, Jan Leike, who also helped head OpenAI's alignment work, announced on X that he had resigned. \"OpenAI is shouldering an enormous responsibility on behalf of all of humanity,\" Leike wrote, but the company's \"safety culture and processes have taken a backseat to shiny products.\" He thought that \"OpenAI must become a safety-first AGI company.\" Less than two weeks later, Leike was hired by Anthropic. OpenAI and Antrhopic did not respond to requests for comment.\n\nAt OpenAI, departing researchers have said that the experts concerned with alignment and safety have often been sidelined, pushed out, or scattered among other teams, leaving researchers with the sense that AI companies are sprinting to build an invention they won't be able to control. \"In short, neither OpenAI nor any other frontier lab is ready, and the world is also not ready\" for AGI, wrote Miles Brundage when he resigned from OpenAI's AGI readiness team in 2024. Yet he added that \"working at OpenAI is one of the most impactful things that most people could hope to do\" and did not directly criticize the company. Brundage now runs AVERI, an AI research institute.\n\nAcross the AI industry, the story is much the same. In public pronouncements, top researchers gently chastise or occasionally denounce their employers for pursuing a potentially apocalyptic invention while also emphasizing the necessity of doing that research. Sometimes they offer a \"cryptic warning\" that leaves AI watchers scratching their heads. A few do seem genuinely alarmed at what's happening. When OpenAI safety researcher Steven Adler left the company in January 2025, he wrote that he was \"pretty terrified by the pace of AI development\" and wondered if it would wipe out humanity.\n\nYet in the many AI resignation letters, there's little discussion of how AI is being used right now. Data center construction, resource consumption, mass surveillance, ICE deportations, weapons development, automation, labor disruption, the proliferation of slop, a crisis in education ‚Äî these are the areas where many people see AI affecting their lives, sometimes for the worse, and the industry's pious resignees don't have much to say about it all. Their warnings about some disaster just beyond the horizon become fodder for the tech press ‚Äî and de facto cover letters for their next industry job ‚Äî while failing to reach the broader public.\n\n\"Tragedies happen; people get hurt or die; and you suffer and get old,\" wrote William Stafford in the poem that Mrinank Sharma shared. It's a terrible thing, especially the tones of passivity and inevitability ‚Äî resignation, you might call it. It can feel as if no single act of protest is enough, or, as Stafford writes in the next line: \"Nothing you do can stop time's unfolding.\"\n\nJacob Silverman is a contributing writer for Business Insider. He is the author, most recently, of \"Gilded Rage: Elon Musk and the Radicalization of Silicon Valley.\"",
    "readingTime": 9,
    "keywords": [
      "boardroom coup",
      "human candor",
      "resignation letter",
      "mrinank sharma",
      "researchers",
      "safety",
      "openai",
      "letters",
      "less",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/resignation-letters-quit-openai-anthropic-2026-2",
    "thumbnail_url": "https://i.insider.com/698f85e9e1ba468a96ac0ffc?width=1200&format=jpeg",
    "created_at": "2026-02-16T12:38:08.003Z",
    "topic": "finance"
  },
  {
    "slug": "trumps-trade-advisor-says-big-tech-must-internalize-the-cost-of-ai-data-centers",
    "title": "Trump's trade advisor says Big Tech must 'internalize the cost' of AI data centers",
    "description": "Peter Navarro says the White House may force Big Tech to cover electricity and grid costs tied to AI data centers.",
    "fullText": "The White House is signaling it may force Big Tech to foot the full bill for America's AI boom.\n\nCompanies building data centers \"need to pay for all of the costs,\" and taxpayers should not shoulder the impact of the AI boom.\n\nThe White House has to \"make sure the American people are not hurt,\" he added.\n\nNavarro's comments come as the AI data-center boom faces mounting scrutiny over rising utility bills.\n\nTech giants are pouring hundreds of billions into infrastructure to power artificial intelligence. In November, Meta pledged $600 billion to expand AI technology, infrastructure, and its workforce. Apple said in August it would boost its US infrastructure plans by adding another $100 billion, bringing its total commitment to $600 billion.\n\nAt the same time, energy costs are rising. Electric and gas utilities sought $31 billion in rate hikes from regulators last year, more than twice the $15 billion requested the year before, according to a study published last month by PowerLines, a nonprofit that advocates for utility customers. Many power providers have cited surging electricity demand from large-scale data centers as a key reason for seeking higher rates.\n\nPresident Donald Trump has pushed back on the idea that households should absorb those increases.\n\n\"I never want Americans to pay higher Electricity bills because of Data Centers,\" Trump wrote last month in a post on Truth Social.\n\nThe \"big technology companies who build them,\" the president said, \"must pay their own way.\"\n\nNavarro also said on Fox News that the US must keep expanding its data center capacity if it wants to remain \"No.1 on the global stage in terms of AI.\"\n\n\"We have to lead China and others on this,\" Navarro said. \"At the same time, we have to be mindful of the impacts across this nation.\"\n\nThe US must stay ahead \"not just for economic reasons but for national security reasons,\" because AI \"will be one of the most dangerous weapons of war,\" he added.\n\nSome AI companies have moved to reassure policymakers that households won't bear the cost of the industry's rapid expansion.\n\nAnthropic said on Thursday that it will cover 100% of the grid upgrade costs associated with its AI data centers.\n\n\"The country needs to build new data centers quickly to maintain its competitiveness on AI and national security,\" Anthropic said. \"But AI companies shouldn't leave American ratepayers to pick up the tab.\"\n\nThe pledge follows the company's November announcement that it plans to invest $50 billion in AI infrastructure, starting with facilities in Texas and New York.\n\nMicrosoft has taken a similar approach. Last month, the company said it would pay utility rates high enough to cover the electricity costs tied to its data centers and minimize the burden of data center expansion on surrounding communities.",
    "readingTime": 3,
    "keywords": [
      "white house",
      "the white house",
      "infrastructure",
      "boom",
      "utility",
      "electricity",
      "american",
      "rising",
      "bills",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/trump-trade-advisor-peter-navarro-ai-internalize-data-center-costs-2026-2",
    "thumbnail_url": "https://i.insider.com/6992abc6e1ba468a96ac1e59?width=1200&format=jpeg",
    "created_at": "2026-02-16T12:38:07.995Z",
    "topic": "finance"
  },
  {
    "slug": "dario-amodei-says-anthropic-struggles-to-balance-incredible-commercial-pressure-with-its-safety-stuff",
    "title": "Dario Amodei says Anthropic struggles to balance 'incredible commercial pressure' with its 'safety stuff'",
    "description": "Anthropic CEO Dario Amodei says he's trying to keep Anthropic growing at a 10x pace while holding the line on safety.",
    "fullText": "A familiar tension has come for even the most safety-minded of the AI industry: principles or profit?\n\nOpenAI, the leading AI startup, was founded to build artificial intelligence that benefits all of humanity. Many AI watchers and former employees have questioned its commitment to that mission, however, as it rushes to generate revenue to justify enormous investments in the company.\n\nAnthropic, one of OpenAI's chief rivals, was founded by former OpenAI employees who were concerned about that perceived mission drift. They sought to run an AI company focused on safety above all else.\n\nEven Anthropic, however, struggles to stay on course.\n\nAnthropic CEO Dario Amodei says his company faces significant pressure to uphold its commitments to mitigating AI's potential risks while still turning a profit.\n\n\"We're under an incredible amount of commercial pressure, and we make it even harder for ourselves because we have all this safety stuff we do that I think we do more than other companies,\" Amodei said on a recent episode of the \"Dwarkesh\" podcast.\n\nLast week, Anthropic, which launched only five years ago, announced $30 billion in Series G funding at a $380 billion post-money valuation, making it one of the most valuable private companies in the world.\n\nIn its press release, the company underscored its growing revenue.\n\n\"It has been less than three years since Anthropic earned its first dollar in revenue,\" the company said. \"Today, our run-rate revenue is $14 billion, with this figure growing over 10x annually in each of those past three years.\"\n\nGrowth like that often comes with growing expectations.\n\n\"The pressure to survive economically while also keeping our values is just incredible,\" Amodei said on the podcast. \"We're trying to keep this 10x revenue curve going.\"\n\nAmodei was formerly OpenAI's vice president of research, focusing on safety. He founded Anthropic in 2021 with his sister, Daniela Amodei, and five other former OpenAI staffers, driven by a desire to prioritize safety as AI systems grew increasingly powerful.\n\nAmodei is not the only one who says that Anthropic's mission is hard to sustain as the company grows. Mrinank Sharma, a former safety researcher at Anthropic, said he resigned last week in part due to this tension.\n\n\"Throughout my time here, I've repeatedly seen how hard it is to truly let our values govern our actions,\" Sharma wrote in his resignation letter, which he shared on X. \"I've seen this within myself, within the organization, where we constantly face pressures to set aside what matters most, and throughout the broader society too.\"\n\nEven at companies that aren't developing foundational AI models, adopting AI responsibly often takes a back seat to the promise of efficiency and increased profits.\n\nResponsible AI use in the workplace is moving \"nowhere near as fast as it should be,\" Tad Roselund, a managing director and senior partner at Boston Consulting Group, told Business Insider in 2024.\n\nThe same is true across the venture capital ecosystem.\n\n\"The venture capital environment also reflects a disproportionate focus on AI innovation over AI governance,\" Navrina Singh, the founder and CEO of AI governance platform Credo AI, told Business Insider in 2024. \"To adopt AI at scale and speed responsibly, equal emphasis must be placed on ethical frameworks, infrastructure, and tooling to ensure sustainable and responsible AI integration across all sectors.\"",
    "readingTime": 3,
    "keywords": [
      "venture capital",
      "business insider",
      "revenue",
      "safety",
      "openai",
      "founded",
      "mission",
      "pressure",
      "anthropic",
      "tension"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dario-amodei-anthropic-profit-pressure-versus-safety-mission-2026-2",
    "thumbnail_url": "https://i.insider.com/69911622d3c7faef0ece5366?width=1200&format=jpeg",
    "created_at": "2026-02-16T12:38:07.822Z",
    "topic": "finance"
  },
  {
    "slug": "the-career-rise-of-openais-billionaire-ceo-sam-altman",
    "title": "The career rise of OpenAI's billionaire CEO, Sam Altman",
    "description": "OpenAI CEO Sam Altman helped usher in the AI age. Now, he's doing everything he can to keep OpenAI ahead.",
    "fullText": "OpenAI Sam Altman thinks he can see the future better than some people.\n\n\"I think I am unusually good at projecting multiple things‚Äî years or a couple of decades into the future‚Äîand understanding how those are going to interact together,\" Altman told Forbes in February.\n\nWhat is clear is that in 2026 and beyond, OpenAI and Altman have a lot riding on his vision.\n\nIn 2022, Altman oversaw the release of ChatGPT, kicking off what Bill Gates called \"the age of AI.\" Just over three years removed from the moment, Altman's rivals are applying the pressure like never before.\n\nRivals, like Elon Musk and Anthropic CEO Dario Amodei, continue to taunt him through the struggles.\n\nAll the while, Altman has spun OpenAI from a research lab into a major company, even boasting a social media play. And he still has yet to reveal whatever mysterious device he's cooking up with Jony Ive, Apple's former design chief.\n\nIf the past is any indication, Altman is tough to bet against.\n\nIn just under a decade, he went from being part of the first Y-Combinator batch to leading the famed startup incubator. A billionaire before he turned 40, the entrepreneur is no longer just a beacon of Silicon Valley. Altman is now a co-Time Person of the Year and a frequent guest of world leaders.\n\nHere's a look at Altman's life and career so far.\n\nAltman grew up in St. Louis and he was a computer whiz from a young age.\n\nHe learned how to program and take apart a Macintosh computer when he was 8 years old, according to The New Yorker. He attended John Burroughs School, a private, nonsectarian college-preparatory school in St. Louis.\n\nAltman has said that having a Mac helped him with his sexuality. He came out as gay after a Christian group boycotted an assembly at his school that was about sexuality.\n\n\"Growing up gay in the Midwest in the two-thousands was not the most awesome thing,\" he told The New Yorker in 2016. \"And finding AOL chat rooms was transformative. Secrets are bad when you're eleven or twelve.\"\n\nAltman studied computer science at Stanford University before dropping out to start an app. The app, which became Loopt, was part of the first group of companies at startup accelerator Y Combinator.\n\nLoopt eventually reached a $175 million valuation. The $43 million sale price was close to how much it had raised from investors, The Wall Street Journal reported. The company was acquired by Green Dot, a banking company known for prepaid cards.\n\nIn 2014, at the age of 28, Altman was chosen by Y Combinator founder Paul Graham to succeed him as president of the startup accelerator.\n\nWhile he was YC president, Altman taught a lecture series at Stanford called \"How to Start a Startup.\" The next year, at 29, Altman was featured on the Forbes 30 Under 30 list for venture capital.\n\nIn 2015, Altman cofounded OpenAI with Elon Musk, CEO of Tesla and SpaceX. Their goal for the nonprofit artificial intelligence company was to make sure AI doesn't wipe out humans.\n\nSome of Silicon Valley's most prominent names pledged $1 billion to OpenAI, including Reid Hoffman, the cofounder of LinkedIn, and Thiel. Altman stepped down as YC president in March 2019 to focus on OpenAI.\n\nAltman and OpenAI's now-former chief scientist, Ilya Sutskever, said the move to focus on large language models was the best way for the company to reach artificial general intelligence, or AGI, a system that has broad human-level cognitive abilities.\n\nOpenAI received a $1 billion investment from Microsoft in 2019, the beginning of a major partnership for both companies.\n\nUnder Altman's early tenure, OpenAI released popular generative AI tools to the public, including DALL-E and ChatGPT.\n\nBoth DALL-E and ChatGPT are known as \"generative\" AI, meaning the bot creates its own artwork and text based on information it is fed.\n\nAfter ChatGPT was released on November 30, 2022, Altman tweeted that it had reached over 1 million users in five days. As of early 2026, ChatGPT is up to 300 million weekly active users.\n\nOpenAI built on ChatGPT's public launch with a series of major announcements throughout 2023, including the release of GPT-4, an extension of their partnership with Microsoft, and the announcement of ChatGPT Plus (a subscription tier).\n\nIn November, OpenAI's board of directors announced the biggest news: Altman was out as CEO and leaving the board \"effectively immediately.\" The board said Altman was being removed because he \"was not consistently candid in his communications with the board.\"\n\nSutskever has expressed remorse for his participation in Altman's removal. Sutskever and three other members did not return to the reconfigured board when Altman was reinstated.\n\nAltman, like many other tech CEOs, was front and center for President Donald Trump's return to power on January 20, 2025. A day after Trump's inauguration, Altman joined Oracle CTO Larry Ellison, SoftBank founder Masayoshi Son, and Trump to announce a partnership to fund a $500 billion investment in US AI. The companies would form Stargate, a project that seeks to build US AI infrastructure and create jobs.\n\nIn February 2024, Musk made a $97.4 billion offer to take over OpenAI. Altman declined the offer from his one-time collaborator. Within weeks, Musk, who launched his own competing AI company, xAI, in July 2023, sued OpenAI, Altman, and other senior executives over OpenAI's move away from its original, non-profit mission.\n\nAltman's relationship with Musk has become increasingly tense over the years. As of February 2026, a trial is set to begin in April. In the interim, Musk and Altman have continued to trade barbs, including when OpenAI's CEO said that getting Musk under oath would be \"Christmas in April.\"\n\nSince his return, Altman has overseen a sweeping expansion of OpenAI's ambitions.\n\nIn October 2025, OpenAI completed its restructuring, spinning off its for-profit arm into a public benefit corporation. Microsoft retains a 27% stake in the for-profit venture, but the announcement formalized a shift in the relationship between the two companies.\n\nAltman has softened on some of his views as OpenAI seeks revenue, most notably by introducing ads to lower tiers of ChatGPT. In May 2024, Altman called ads \"a last resort for us as a business model.\"\n\nIn 2025 alone, OpenAI launched Atlas, its entry into the browser wars and Sora, its TikTok-esque AI video generation app. In May, Altman announced that he had been working with Ive on an AI-powered consumer device. OpenAI is also making waves in the payment space and is exploring making its own advanced chips.\n\nAltman also brought on former Instacart CEO Fidji Simo to serve as CEO of Applications.\n\nAll of this explains why Altman was one of eight architects of AI to be crowned as Time Magazine's 2025 Person of the Year.\n\nDespite Altman's status as CEO, he holds no equity in OpenAI ‚Äî a status he has said he wished he had changed \"a long time ago.\"\n\n\"i think it would have led to far fewer conspiracy theories; people seem very able to understand 'ok that dude is doing it because he wants more money' but less so \"he just thinks technology is cool and he likes having some ability to influence the evolution of technology and society,\" Altman wrote on X in October 2025 in reply to a user who questioned what his motivations were if he doesn't stand to immediately profit of OpenAI goes public.\n\nInstead, Altman owes his billionaire status to his investments, namely in Stripe, Reddit, and Helion, a nuclear fusion firm.\n\nAfter Loopt, Altman founded a venture fund called Hydrazine Capital and raised $21 million, which included a large investment from venture capitalist Peter Thiel. Altman invested 75% of that money into YC companies and led Reddit's Series B fundraising round.\n\nAlong with his brothers Max and Jack, Altman launched a fund in 2020 called Apollo that is focused on funding \"moonshot\" companies. They're startups that are financially risky but could potentially pay off with a breakthrough development.\n\nIn 2021, Altman and cofounders Alex Blania and Max Novendstern launched a global cryptocurrency project called Worldcoin.\n\nAltman has said that his investment strategy is to look for \"somewhat broken companies.\"\n\n\"You can treat the warts on top, and because of the warts, the company will be hugely underpriced,\" he told The New Yorker in 2016.\n\nAltman married his partner, Oliver Mulherin, in January 2024. His husband is an Australian software engineer who previously worked at Meta, according to his LinkedIn profile.\n\nA few weeks after Forbes declared Altman a billionaire, he and Mulherin signed the Giving Pledge, vowing to give away most of their fortune.\n\nIn February 2025, Altman announced the birth of his son on social media.\n\n\"i have never felt such love,\" Altman said in his post.\n\nwelcome to the world, little guy!\n\nhe came early and is going to be in the nicu for awhile. he is doing well and it‚Äôs really nice to be in a little bubble taking care of him.\n\ni have never felt such love. pic.twitter.com/wFF2FkKiMU\n\nHe and his husband are expecting their second child later this year.\n\nAltman has found interesting ‚Äî and expensive ‚Äî ways to spend his free time.\n\nIn April 2024 (the same month he made Forbes' billionaire list), he was spotted in Napa, California, driving an ultra-rare Swedish supercar. The Koenigsegg Regera is seriously fast, able to go from zero to 250 miles per hour in less than 30 seconds. Only 80 of these cars are known to exist, and they can cost up to $4.65 million.\n\nHe once told two YC founders that he likes racing cars and had five, including two McLarens and an old Tesla, according to The New Yorker. He's said he likes racing cars and renting planes to fly all over California.\n\nSeparately, he told the founders of the startup Shypmate that, \"I prep for survival,\" and warned of either a \"lethal synthetic virus,\" AI attacking humans, or nuclear war. Altman is not alone in prepping for a potential doomsday.\n\n\"I try not to think about it too much,\" Altman told the founders in 2016. \"But I have guns, gold, potassium iodide, antibiotics, batteries, water, gas masks from the Israeli Defense Force, and a big patch of land in Big Sur I can fly to.\"",
    "readingTime": 9,
    "keywords": [
      "elon musk",
      "social media",
      "likes racing",
      "racing cars",
      "startup accelerator",
      "thiel altman",
      "in altman",
      "the new yorker",
      "openai altman",
      "board"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman",
    "thumbnail_url": "https://i.insider.com/698bc019d3c7faef0ece09a9?width=1200&format=jpeg",
    "created_at": "2026-02-16T12:38:07.501Z",
    "topic": "finance"
  },
  {
    "slug": "i-started-at-microsoft-as-an-executive-assistant-and-pivoted-to-an-ai-role-i-dont-regret-my-english-degree",
    "title": "I started at Microsoft as an executive assistant and pivoted to an AI role. I don't regret my English degree.",
    "description": "An AI gamification manager shares how she went from a contract executive assistant at Microsoft to an AI gamification product manager.",
    "fullText": "This as-told-to essay is based on a conversation with Brit Morenus, a 37-year-old senior AI gamification program manager, based in Charlotte, North Carolina. Her identity and employment have been verified by Business Insider. The following has been edited for length and clarity.\n\nI've been at Microsoft for a total of 13 years, but for five and a half, I was a contract worker.\n\nI graduated from college with a degree focused on English, communications, and marketing. I first landed a job at Microsoft as a contract executive assistant. I stayed in that role for about eight months, then joined the marketing team.\n\nEventually, I had the opportunity to take a really special position, but it required knowing gamification. Gamification is about integrating game mechanics and motivators, such as storytelling and reward systems, into learning. So I was going to teach people about our products and sell them in a gamified way.\n\nI spent about a year getting certifications that taught me about gamification. I upskilled and learned how to create games, what game mechanics are, and what motivates someone when they're learning.\n\nThat was the position where I was able to prove my impact, and they decided to bring me on full-time. I stayed in that role for another six years, training the frontline and customer service support to develop the right sales skills.\n\nEventually, I had the opportunity to start gamifying learning about AI. They wanted someone with gamification skills, and my certifications and experience made me the ideal candidate.\n\nI didn't know much about AI yet, aside from using it for personal reasons, but transitioning to an AI role was actually faster than pivoting to gamification. Since I held the gamification role for about six years, I became really good at it. It only took about three months for me to upskill in AI.\n\nIn my first three months on the team, I made myself knowledgeable about AI to the point where I could teach others about it. That's when I got a certification in Azure AI Fundamentals. It was a certification specific to how Microsoft's AI works.\n\nI helped my entire team get it, and then I helped my entire organization start working on it. Then I helped the greater customer service support organization work toward getting it as well.\n\nMy advice to those who want to transition would be: Don't let fear keep you from stepping outside your comfort zone. There's so much ambiguity about changing roles or companies, but there's no time like the present.\n\nWith AI specifically, you just need to learn. Everyone already uses it, but you need to understand how it works, because that's how you can understand what to do with it.\n\nIt's also important to upskill yourself. You have to be willing to constantly move and learn more, because it's going to keep changing ‚Äî and faster than you can grasp it. Sometimes AI makes wrong predictions, but it is using words to make that prediction. So I absolutely need to use my English degree in order to figure out keywords and how to prompt it to do the right thing.\n\nUp until this Al role, I always joked that I wasn't using my English degree. But now I use it everywhere, and it truly does help. It helps with things like talking to executives and also with the role itself.\n\nIt's important to know the language of AI and how it operates. So now, more than ever, I am using every bit of my English degree and understanding English, grammar, and how it all functions.\n\nFor example, there's a tagging process that happens behind the scenes with AI, just like on social media. Looking at an image, it might tag it as a woman, or a supermarket, and that gives it a confidence score and tells you if it's relevant or not, and if it's what we're looking for.\n\nA lot of it is more about understanding how to apply the English language than about AI ‚Äî so, thanks, Mom and Dad, I am using the degree you paid for.\n\nThis is part of an ongoing series about workers who transitioned into AI roles. Did you pivot to AI? We want to hear from you. Reach out to the reporter via email at aaltchek@insider.com or secure-messaging platform Signal at aalt.19.",
    "readingTime": 4,
    "keywords": [
      "english degree",
      "game mechanics",
      "customer service",
      "gamification",
      "role",
      "it's",
      "team",
      "learning",
      "there's",
      "based"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-manager-explains-how-she-pivoted-from-admin-to-ai-2026-2",
    "thumbnail_url": "https://i.insider.com/698f6614e1ba468a96ac0a21?width=1200&format=jpeg",
    "created_at": "2026-02-16T12:38:07.484Z",
    "topic": "finance"
  },
  {
    "slug": "tiktok-creator-bytedance-vows-to-curb-ai-video-tool-after-disney-threat",
    "title": "TikTok creator ByteDance vows to curb AI video tool after Disney threat",
    "description": "Videos created by new Seedance 2.0 generator go viral, including one of Tom Cruise and Brad Pitt...",
    "fullText": "Videos created by new Seedance 2.0 generator go viral, including one of Tom Cruise and Brad Pitt fighting\n\nByteDance, the Chinese technology company behind TikTok, has said it will restrain its AI video-making tool, after threats of legal action from Disney and a backlash from other media businesses, according to reports.\n\nThe AI video generator Seedance 2.0, released last week, has spooked Hollywood as users create realistic clips of movie stars and superheroes with just a short text prompt.\n\nSeveral big Hollywood studios have accused the tool of copyright infringement.\n\nOn Friday, Walt Disney reportedly sent a cease-and-desist letter to ByteDance which accused it of supplying Seedance with a ‚Äúpirated library‚Äù of the studio‚Äôs characters, including those from Marvel and Star Wars, according to the US news outlet Axios.\n\nDisney‚Äôs lawyers claimed that ByteDance committed a ‚Äúvirtual smash-and-grab‚Äù of their intellectual property, according to a report from the BBC.\n\nHowever, the TikTok owner told the BBC it ‚Äúrespects intellectual property rights and we have heard the concerns regarding Seedance 2.0‚Äù.\n\nA spokesperson for the company told the broadcaster it was ‚Äútaking steps to strengthen current safeguards as we work to prevent the unauthorised use of intellectual property and likeness by users‚Äù, but declined to provide further details on its plans.\n\nSeedance can generate videos based on just a few lines of text. Last week, Rhett Reese, the co-writer of Deadpool & Wolverine, Zombieland and Now You See Me: Now You Don‚Äôt, said ‚Äúit‚Äôs likely over for us‚Äù after watching a widely disseminated AI-generated clip featuring Tom Cruise and Brad Pitt fighting.\n\nHe added: ‚ÄúIn next to no time, one person is going to be able to sit at a computer and create a movie indistinguishable from what Hollywood now releases. True, if that person is no good, it will suck. But if that person possesses Christopher Nolan‚Äôs talent and taste (and someone like that will rapidly come along), it will be tremendous.‚Äù\n\nThe first iteration of Seedance launched in June last year.\n\nThe Motion Picture Association, the Hollywood trade association that represents studios such as Paramount, Warner Bros and Netflix, accused ByteDance of ‚Äúunauthorised use of US copyrighted works on a massive scale‚Äù. The actors‚Äô union Sag-Aftra has accused Seedance of ‚Äúblatant infringement‚Äù.\n\nIt is the latest clash in Hollywood amid anxiety over the impact of AI on the future of entertainment. Artists and creative industries have called for compensation for the use of their material and the establishment of licensing frameworks to enable legal use of their content.\n\nLast year, Disney and NBCUniversal sued the AI image generator Midjourney over what the studios claimed were ‚Äúendless unauthorised copies‚Äù of their works.\n\nHowever, creative companies are also making deals with AI businesses. Last year, Disney announced a $1bn equity investment in OpenAI, the developer of ChatGPT, and a three-year licensing agreement that enables its Sora video generation tool to use some of Disney‚Äôs characters.\n\nByteDance and Walt Disney were approached for comment.",
    "readingTime": 3,
    "keywords": [
      "tom cruise",
      "brad pitt",
      "pitt fighting",
      "walt disney",
      "intellectual property",
      "seedance",
      "hollywood",
      "accused",
      "generator",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/16/tiktok-bytedance-ai-video-tool-disney-seedance-tom-cruise-brad-pitt",
    "thumbnail_url": "https://i.guim.co.uk/img/media/85983881d8a2578c704db0d03da5453189e375fd/80_0_3749_3000/master/3749.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=22a630038291be0ff7b1c5e72464de4c",
    "created_at": "2026-02-16T12:38:04.177Z",
    "topic": "tech"
  },
  {
    "slug": "tech-titans-pour-50m-into-super-pac-to-elect-aifriendly-candidates-to-congress",
    "title": "Tech titans pour $50M into super PAC to elect AI-friendly candidates to Congress",
    "description": "Tech titans pour $50 million into super PAC to elect AI-friendly candidates to Congress",
    "fullText": "Some of the biggest names behind the artificial intelligence boom are looking to stack Congress with allies who support lighter regulation of the emerging technology by drawing on the crypto industry‚Äôs 2024 election success.\n\nMarc Andreessen, Ben Horowitz and OpenAI co-founder Greg Brockman are among tech leaders who‚Äôve poured $50 million into a new super political action committee to help AI-friendly candidates prevail in November‚Äôs congressional races. Known as Leading the Future, the super PAC has taken center stage as voters grow increasingly concerned that AI risks driving up energy costs and taking away jobs.\n\nAs it launches operations, Leading the Future is deploying a strategy that worked two years ago for crypto advocates: talk about what‚Äôs likely to resonate with voters, not the industry or its interests and controversies. For AI, that means its ads won‚Äôt tout the technology but instead discuss core issues including economic opportunity and immigration ‚Äî even if that means not mentioning AI at all.\n\n‚ÄúThey‚Äôre trying to be helpful in a campaign rather than talking about their own issue all the time,‚Äù said Craig Murphy, a Republican political consultant in Texas, where Leading the Future has backed Chris Gober, an ally of President Trump, in the state‚Äôs hotly contested 10th congressional district.\n\nThis year, the group plans to spend up to $125 million on candidates who favor a single, national approach to AI regulation, regardless of party affiliation. The election comes at a crucial moment for the industry as it invests hundreds of billions of dollars in AI infrastructure that will put fresh strains on resources, with new data centers already blamed for driving up utility bills.\n\nLeading the Future faces a growing challenge from AI safety advocates, who‚Äôve started their own super PAC called Public First with a goal of raising $50 million for candidates who favor stricter oversight. On Thursday, Public First landed a $20-million pledge from Anthropic PBC, a rival to OpenAI that has set itself apart from other AI companies by supporting tougher rules.\n\nPolls show deepening public concern over AI‚Äôs impact on everything from jobs to education to the environment. Sixty-two percent of US adults say they interact with AI at least several times a week, and 58% are concerned the government will not go far enough in regulating it, according to the Pew Research Center.\n\nJesse Hunt, a Leading the Future spokesman, said the group is ‚Äúcommitted to supporting policymakers who want a smart national regulatory framework for AI,‚Äù one that boosts US employment while winning the race against China. Hunt said the super PAC backs ways to protect consumers ‚Äúwithout ceding America‚Äôs technological future to extreme ideological gatekeepers.‚Äù\n\nThe political and economic stakes are enormous for OpenAI and others behind Leading the Future, including venture capitalists Andreessen and Horowitz. Their firm, a16z, is the richest in Silicon Valley with billions of dollars invested in AI upstarts including coding startup Cursor and AI leaderboard platform LM Arena.\n\nFor now, their super PAC is doing most of the talking for the AI industry in the midterm races. Meta Platforms Inc. has announced plans for AI-related political spending on state-level contests, with $20 million for its California-based super PAC and $45 million for its American Technology Excellence Project, according to Politico.\n\nOther companies with massive AI investment plans ‚Äî Amazon.com Inc., Alphabet Inc. and Microsoft Corp. ‚Äî have their own corporate PACs to dole out bipartisan federal campaign donations. Nvidia Corp., the chip giant driving AI policy in Washington, doesn‚Äôt have its own PAC.\n\nTo ensure consistent messaging across party lines, Leading the Future has created two affiliated super PACs ‚Äî one spending on Republicans and another on Democrats. The aim is to build a bipartisan coalition that can be effective in Washington regardless of which party is in power.\n\nTexas, home of OpenAI‚Äôs massive Stargate project, is one of the states where Leading the Future has already jumped in. Its Republican arm, American Mission, has spent nearly $750,000 on ads touting Gober, a political lawyer who‚Äôs previously worked for Elon Musk‚Äôs super PAC and is in a crowded GOP primary field for an open House seat.\n\nThe ads hail Gober as a ‚ÄúMAGA warrior‚Äù who ‚Äúwill fight for Texas families, lowering everyday costs.‚Äù Gober‚Äôs campaign website lists ‚Äúensuring America‚Äôs AI dominance‚Äù as one of his top campaign priorities. Gober‚Äôs campaign didn‚Äôt respond to requests for comment.\n\nIn New York, Leading the Future‚Äôs Democratic arm, Think Big, has spent $1.1 million on television ads and messages attacking Alex Bores, a New York state assemblyman who has called for tougher AI safety protocols and is now running for an open congressional seat encompassing much of central Manhattan.\n\nThe ads seize on Democrats‚Äô revulsion over Trump‚Äôs immigration crackdown and target Bores for his work at Palantir Technologies Inc., which contracts with Immigration and Customs Enforcement. Think Big has circulated mailings and text messages citing Bores‚Äô work with Palantir, urging voters to ‚ÄúReject Bores‚Äô hypocrisy on ICE.‚Äù\n\nIn an interview, Bores called the claims in the ads false, explaining that he left Palantir because of its work with ICE. He pointed out the irony that Joe Lonsdale, a Palantir co-founder who‚Äôs backed the administration‚Äôs border crackdown, is a donor to Leading the Future.\n\n‚ÄúThey‚Äôre not being ideologically consistent,‚Äù Bores said. ‚ÄúThe fact that they have been so transparent and said, ‚ÄòHey, we‚Äôre the AI industry and Alex Bores will regulate AI and that scares us,‚Äô has been nothing but a benefit so far.‚Äù\n\nLeading the Future‚Äôs Democratic arm also plans to spend seven figures to support Democrats in two Illinois congressional races: former Illinois Representatives Jesse Jackson Jr. and Melissa Bean.\n\nLeading the Future is following the path carved by Fairshake, a pro-cryptocurrency super PAC that joined affiliates in putting $133 million into congressional races in 2024. Fairshake made an early mark by spending $10 million to attack progressive Katie Porter in the California Democratic Senate primary, helping knock her out of the race in favor of Adam Schiff, the eventual winner who‚Äôs seen as more friendly to digital currency.\n\nThe group also backed successful primary challengers against House incumbents, including Democrats Cori Bush in Missouri and Jamaal Bowman in New York. Both were rated among the harshest critics of digital assets by the Stand With Crypto Alliance, an industry group.\n\nIn its highest-profile 2024 win, Fairshake spent $40 million to help Republican Bernie Moreno defeat incumbent Democratic Senator Sherrod Brown, a crypto skeptic who led the Senate Banking Committee. Overall, it backed winners in 52 of the 61 races where it spent at least $100,000, including victories in three Senate and nine House battlegrounds.\n\nFairshake and Leading the Future share more than a strategy. Josh Vlasto, one of Leading the Future‚Äôs political strategists, does communications work for Fairshake. Andreessen and Horowitz are also among Fairshake‚Äôs biggest donors, combining to give $23.8 million last year.\n\nBut Leading the Future occasionally conflicts with Fairshake‚Äôs past spending. The AI group said Wednesday it plans to spend half a million dollars on an ad campaign for Laurie Buckhout, a former Pentagon official who‚Äôs seeking a congressional seat in North Carolina with calls to slash rules ‚Äústrangling American innovation.‚Äù In 2024, during Buckhout‚Äôs unsuccessful run for the post, Fairshake spent $2.3 million supporting her opponent and eventual winner, Democratic Rep. Donald Davis.\n\n‚ÄúThe fact that they tried to replay the crypto battle means that we have to engage,‚Äù said Brad Carson, a former Democratic congressman from Texas who helped launch Public First. ‚ÄúI‚Äôd say Leading the Future was the forcing function.‚Äù\n\nUnlike crypto, proponents of stricter AI regulations have backers within the industry. Even before its contribution to Public First, Anthropic had pressed for ‚Äúresponsible AI‚Äù with sturdier regulations for the fast-moving technology and opposed efforts to preempt state laws.\n\nAnthropic employees have also contributed to candidates targeted by Leading the Future, including a total of $168,500 for Bores, Federal Election Commission records show. A super PAC Dream NYC, whose only donor in 2025 was an Anthropic machine learning researcher who gave $50,000, is backing Bores as well.\n\nCarson, who‚Äôs co-leading the super PAC with former Republican Rep. Chris Stewart of Utah, cites public polling that more than 80% of US adults believe the government should maintain rules for AI safety and data security, and says voter sentiment is on Public First‚Äôs side.\n\nPublic First didn‚Äôt disclose receiving any donations last year, according to FEC filings. But one of the group‚Äôs affiliated super PACs, Defend our Values PAC, reported receiving $50,000 from Public First Action Inc., the group‚Äôs advocacy arm. The PAC hasn‚Äôt yet spent any of that money on candidates.\n\nCrypto‚Äôs clout looms large in lawmakers‚Äô memory, casting a shadow over any effort to regulate the big tech companies, said Doug Calidas, head of government affairs for AI safety group Americans for Responsible Innovation.\n\n‚ÄúFairshake was just so effective,‚Äù said Calidas, whose group has called for tougher AI regulations. ‚ÄúDemocrats and Republicans are scared they‚Äôre going to replicate that model.‚Äù\n\nAllison and Birnbaum write for Bloomberg.",
    "readingTime": 8,
    "keywords": [
      "leading the future",
      "gober‚Äôs campaign",
      "future‚Äôs democratic",
      "democratic arm",
      "super pac",
      "eventual winner",
      "super pacs",
      "congressional seat",
      "congressional races",
      "affiliated super"
    ],
    "qualityScore": 1,
    "link": "https://www.latimes.com/business/story/2026-02-13/tech-titans-pour-50-million-into-super-pac-to-elect-ai-friendly-candidates-to-congress",
    "thumbnail_url": "https://ca-times.brightspotcdn.com/dims4/default/c25815c/2147483647/strip/true/crop/2000x1050+0+142/resize/1200x630!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F56%2F99%2Fee255e9bb4113c4405d6587127af%2F1x-1.jpg",
    "created_at": "2026-02-16T06:52:46.425Z",
    "topic": "politic"
  },
  {
    "slug": "llm-authz-audit-find-auth-gaps-and-prompt-injection-in-llm-apps",
    "title": "LLM AuthZ Audit ‚Äì find auth gaps and prompt injection in LLM apps",
    "description": "Contribute to aiauthz/llm-authz-audit development by creating an account on GitHub.",
    "fullText": "aiauthz\n\n /\n\n llm-authz-audit\n\n Public\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aiauthz/llm-authz-audit",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/aiauthz/llm-authz-audit",
    "thumbnail_url": "https://opengraph.githubassets.com/2af0fbe984f11b204b0ca3628f3219af36445de8e05eee61c4db3d909007cf54/aiauthz/llm-authz-audit",
    "created_at": "2026-02-16T06:52:46.085Z",
    "topic": "tech"
  },
  {
    "slug": "snowflakes-ceo-says-software-giants-risk-becoming-a-dumb-data-pipe-to-ai-models",
    "title": "Snowflake's CEO says software giants risk becoming a 'dumb data pipe' to AI models",
    "description": "\"The big model makers want to create a world in which all of the data for all of the enterprises is easily available to them,\" Sridhar Ramaswamy said.",
    "fullText": "The biggest software companies might be reduced to mere data sources, says Snowflake's CEO.\n\n\"The big model makers want to create a world in which all of the data for all of the enterprises is easily available to them,\" Sridhar Ramaswamy said on an episode of Alex Kantrowitz's \"Big Technology Podcast\" published last week. \"Everything else, the world, is just a dumb data pipe that feeds into that big brain.\"\n\nPrior to becoming Snowflake's CEO in 2024, Ramaswamy was a partner at Greylock Ventures and cofounded AI search startup Neeva, which was acquired by Snowflake.\n\nRamaswamy added that Snowflake needs to operate with a \"fear\" that people would stop using AI agents developed by software companies and instead want an all-inclusive agent that has data from Snowflake, for example, and everywhere else\n\nHe said his solution was to let customers take the lead and decide how they want to access their data ‚Äî directly through their own agents, or through a product like ChatGPT.\n\nIn the last few months, AI labs have evolved from being sources of AI infrastructure to becoming software providers themselves. OpenAI has entered the sales, support, and document analysis market, threatening incumbents such as Salesforce and Oracle.\n\nOn a podcast released last week,¬†Andreessen Horowitz general partner¬†Anish Acharya said software firms were being unnecessarily punished by Wall Street¬†over fears that AI could take over their industry. The VC said that legacy software could not be replaced so easily, because it would not be worth it to use AI for every business function.\n\nHe said that software accounts for 8% to 12% of a company's expenses, so vibe coding to build the company's resource planning or payroll tools would only save about 10%. Instead, companies should focus on big-ticket items, like developing their core businesses or optimizing other costs.\n\nRamaswamy and Acharya's comments follow a brutal start of the month for software stocks, which dragged down tech and broader markets. The sell-off started when already-wary investors panicked about Anthropic's new AI tool, which can perform a range of clerical tasks for people working in the legal industry.",
    "readingTime": 2,
    "keywords": [
      "software",
      "easily",
      "podcast",
      "else",
      "partner",
      "agents",
      "instead",
      "industry",
      "company's",
      "ramaswamy"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/snowflake-ceo-sridhar-ramaswamy-software-dumb-data-pipe-ai-2026-2",
    "thumbnail_url": "https://i.insider.com/6992a117a645d118818966b3?width=1200&format=jpeg",
    "created_at": "2026-02-16T06:52:41.862Z",
    "topic": "tech"
  },
  {
    "slug": "bytedance-pledges-to-prevent-unauthorised-ip-use-on-ai-video-tool-after-disney-threat",
    "title": "ByteDance pledges to prevent unauthorised IP use on AI video tool after Disney threat",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/disney-sends-ceaseanddesist-to-bytedance-over-aigenerated-videos-4507348",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1F057_L.jpg",
    "created_at": "2026-02-16T06:52:41.157Z",
    "topic": "finance"
  },
  {
    "slug": "margindash-see-which-ai-customers-are-profitable",
    "title": "MarginDash ‚Äì See which AI customers are profitable",
    "description": "Track AI cost and margin per customer. Real-time profitability insights, Stripe revenue sync, budget alerts, and a cost simulator to find cheaper models without changing code.",
    "fullText": "What-if analysis\n Find cheaper models without changing code\n Pick any event type. MarginDash simulates the cost of alternative models ‚Äî ranked by intelligence-per-dollar ‚Äî and shows you the savings instantly.\n\n Smart suggestions ranked by quality per dollar\n\n Benchmark scores (MMLU-Pro, GPQA) side by side\n\n Frontier, mid-tier, and budget model tiers\n\n Total Cost\n $2,380\n\n Simulated Cost\n $1,800\n\n Cost Difference\n -$580\n\n Cost by Event Type\n Click any event type to swap its model.\n\n Event Type\n Events\n Cost\n Simulated\n Difference\n\n summarize\n\n 1,240\n $820\n $580\n -$240\n\n translate\n\n 890\n $640\n $420\n -$220\n\n chat\n\n 760\n $380\n $260\n -$120\n\n 420\n $540\n -\n -\n\n summarize\n\n Smart Recommendation\n\n Switch to\n Claude 4.5 Haiku\n Est. saving $240 (29.3%)\n\n Simulate with\n Search...",
    "readingTime": 1,
    "keywords": [
      "models",
      "ranked",
      "model",
      "simulated",
      "difference",
      "summarize",
      "event",
      "smart"
    ],
    "qualityScore": 0.65,
    "link": "https://margindash.com/",
    "thumbnail_url": "https://margindash.com/images/og-image.png",
    "created_at": "2026-02-16T01:12:20.147Z",
    "topic": "tech"
  },
  {
    "slug": "nodejs-native-module-for-integrating-mediasoup-with-audio-ai-models",
    "title": "Node.js native module for integrating Mediasoup with Audio AI models",
    "description": "Tools for consuming and publishing PCM audio data from an RTP stream - Hilokal/audio-rtp-tools",
    "fullText": "Hilokal\n\n /\n\n audio-rtp-tools\n\n Public\n\n Tools for consuming and publishing PCM audio data from an RTP stream\n\n License\n\n ISC license\n\n 4\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Hilokal/audio-rtp-tools",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Hilokal/audio-rtp-tools",
    "thumbnail_url": "https://opengraph.githubassets.com/a6f0420e81edea6001f9e9039c9da1b4ed2861be0909541ddbbc1dacad4374cc/Hilokal/audio-rtp-tools",
    "created_at": "2026-02-16T01:12:20.128Z",
    "topic": "tech"
  },
  {
    "slug": "the-first-signs-of-burnout-are-coming-from-the-people-who-embrace-ai-the-most",
    "title": "The first signs of burnout are coming from the people who embrace AI the most",
    "description": "Because employees could do more, work began bleeding into lunch breaks and late evenings. The employees' to-do lists expanded to fill every hour that AI freed up, and then kept going.",
    "fullText": "The most seductive narrative in American work culture right now isn‚Äôt that AI will take your job. It‚Äôs that AI will save you from it.\n\nThat‚Äôs the version the industry has spent the last three years selling to millions of nervous people who are eager to buy it. Yes, some white-collar jobs will disappear. But for most other roles, the argument goes, AI is a force multiplier. You become a more capable, more indispensable lawyer, consultant, writer, coder, financial analyst ‚Äî and so on. The tools work for you, you work less hard, everybody wins.\n\nBut a new study published in Harvard Business Review follows that premise to its actual conclusion, and what it finds there isn‚Äôt a productivity revolution. It finds companies are at risk of becoming burnout machines.\n\nAs part of what they describe as ‚Äúin-progress research,‚Äù UC Berkeley researchers spent eight months inside a 200-person tech company watching what happened when workers genuinely embraced AI. What they found across more than 40 ‚Äúin-depth‚Äù interviews was that nobody was pressured at this company. Nobody was told to hit new targets. People just started doing more because the tools made more feel doable. But because they could do these things, work began bleeding into lunch breaks and late evenings. The employees‚Äô to-do lists expanded to fill every hour that AI freed up, and then kept going.\n\nAs one engineer told them, ‚ÄúYou had thought that maybe, oh, because you could be more productive with AI, then you save some time, you can work less. But then really, you don‚Äôt work less. You just work the same amount or even more.‚Äù\n\nOver on the tech industry forum Hacker News, one commenter had the same reaction, writing, ‚ÄúI feel this. Since my team has jumped into an AI everything working style, expectations have tripled, stress has tripled and actual productivity has only gone up by maybe 10%. It feels like leadership is putting immense pressure on everyone to prove their investment in AI is worth it and we all feel the pressure to try to show them it is while actually having to work longer hours to do so.‚Äù\n\nIt‚Äôs fascinating and also alarming. The argument about AI and work has always stalled on the same question ‚Äî are the gains real? But too few have stopped to ask what happens when they are.\n\nThe researchers‚Äô new findings aren‚Äôt entirely novel. A separate trial last summer found experienced developers using AI tools took 19% longer on tasks while believing they were 20% faster. Around the same time, a National Bureau of Economic Research study tracking AI adoption across thousands of workplaces found that productivity gains amounted to just 3% in time savings, with no significant impact on earnings or hours worked in any occupation. Both studies have gotten picked apart.\n\nThis one may be harder to dismiss because it doesn‚Äôt challenge the premise that AI can augment what employees can do on their own. It confirms it, then shows where all that augmentation actually leads, which is ‚Äúfatigue, burnout, and a growing sense that work is harder to step away from, especially as organizational expectations for speed and responsiveness rise,‚Äù according to the researchers.\n\nThe industry bet that helping people do more would be the answer to everything, but it may turn out to be the beginning of a different problem entirely. The research is worth reading, here.",
    "readingTime": 3,
    "keywords": [
      "industry",
      "tools",
      "less",
      "productivity",
      "research",
      "researchers",
      "isn‚Äôt",
      "it‚Äôs",
      "save",
      "argument"
    ],
    "qualityScore": 1,
    "link": "https://techcrunch.com/2026/02/09/the-first-signs-of-burnout-are-coming-from-the-people-who-embrace-ai-the-most/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2022/10/GettyImages-1158287360-e1665956231123.jpg?resize=1200,676",
    "created_at": "2026-02-16T01:12:18.520Z",
    "topic": "tech"
  },
  {
    "slug": "rampant-ai-demand-for-memory-is-fueling-a-growing-chip-crisis",
    "title": "Rampant AI demand for memory is fueling a growing chip crisis",
    "description": "The cost of one type of DRAM soared 75% from December to January, accelerating price hikes throughout the holiday quarter.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/15/ai-demand-memory-chip-shortage-crisis-dram-hbm-micron-skhynix-samsung/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2251983263-e1771201699839.jpg?resize=1200,600",
    "created_at": "2026-02-16T01:12:15.403Z",
    "topic": "business"
  },
  {
    "slug": "lawsuits-or-billiondollar-deals-how-disney-picks-its-ai-copyright-battles",
    "title": "Lawsuits or billion-dollar deals: How Disney picks its AI copyright battles",
    "description": "Disney sent ByteDance a cease-and-desist for using its characters on Seedance. When OpenAI's Sora did it, however, Disney struck a deal.",
    "fullText": "No, Disney did not release footage of a never-before-seen fight sequence between Marvel's Wolverine and Thanos (spoiler: Thanos won).\n\nThat clip, which amassed over 142,000 views on X over 48 hours, was created using Seedance 2.0, an AI video generation model that ByteDance debuted last week. The tool created a buzz on social media, where one user made a hyperrealistic AI video of Tom Cruise and Brad Pitt fighting over Jeffrey Epstein.\n\nByteDance's decision to let users create content based on Disney's IP without permission isn't all that surprising given the AI industry's well-established strategy to \"ask for forgiveness, not permission.\"\n\nDisney, which is infamous for aggressively protecting its intellectual property, isn't having it ‚Äî though how it responds to the threats is not always the same.\n\nOn Friday, the entertainment company sent ByteDance, the Chinese company that owns Seedance and TikTok, a cease-and-desist letter, a source familiar with the matter confirmed for Business Insider.\n\nIn the letter, Disney accused ByteDance of supplying Seedance 2.0 with \"a pirated library of Disney's copyrighted characters from Star Wars, Marvel, and other Disney franchises, as if Disney's coveted intellectual property were free public domain clip art.\"\n\n\"Over Disney's well-publicized objections, ByteDance is hijacking Disney's characters by reproducing, distributing, and creating derivative works featuring those characters,\" the letter said.\n\nSeedance is only the latest AI company Disney says is ripping it off.\n\nDisney and NBCUniversal sued Midjourney, an AI image generator, in June last year. In the lawsuit, the companies compared Midjourney's tech to \"a virtual vending machine, generating endless unauthorized copies of Disney's and Universal's copyrighted works.\"\n\nThen Disney accused Character.AI of copyright infringement in a September cease-and-desist letter last September. In December, it sent one to Google in response to the AI image generator Nano Banana Pro and its other AI models, accusing the Big Tech giant of stealing its IP on a \"massive scale.\" Both companies have since removed Disney characters from their platforms.\n\nDisney is not anti-AI, however, and its strategy is not one-size-fits-all. The company took a much less adversarial approach with OpenAI, the world's leading AI startup.\n\nWhen OpenAI debuted Sora 2, an AI-powered text-to-video platform, in September, users began uploading IP-heavy content featuring Disney characters to social media. Instead of a cease-and-desist letter or legal action, though, Disney negotiated a deal.\n\nAlthough Disney hasn't shared plans to develop its own AI model or video generator, Disney CEO Bob Iger said the company ultimately sees the tech not as a threat but as a new path to connect with audiences.\n\nDuring an earnings call late last year, he said AI would \"provide users of Disney+ with a much more engaged experience, including the ability for them to create user-generated content, and to consume user-generated content, mostly short form, from others.\"",
    "readingTime": 3,
    "keywords": [
      "social media",
      "intellectual property",
      "disney accused",
      "user-generated content",
      "cease-and-desist letter",
      "disney characters",
      "users",
      "generator",
      "clip",
      "created"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-ai-copyright-battles-seedance-nano-banana-sora-midjourney-2026-2",
    "thumbnail_url": "https://i.insider.com/699111dbe1ba468a96ac1af1?width=1200&format=jpeg",
    "created_at": "2026-02-16T01:12:15.000Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-anthropics-philosopher-has-no-stake-in-the-future-because-she-doesnt-have-kids-heres-her-response",
    "title": "Elon Musk says Anthropic's philosopher has no stake in the future because she doesn't have kids. Here's her response.",
    "description": "Elon Musk questioned Amanda Askell's role in shaping AI Claude's morals, citing her lack of children. Askell had thoughts.",
    "fullText": "Anthropic famously employs a Scottish philosopher named Amanda Askell.\n\nHer job is to imbue its chatbot, Claude, with a personality and a set of moral guardrails. She is essentially teaching it to be cool and good.\n\nElon Musk, however, doesn't think she's qualified.\n\n\"Those without children lack a stake in the future,\" Musk posted on X in response to a profile of Askell published by The Wall Street Journal.\n\nThe Journal profile does not say whether Askell has kids. Musk, who has imbued his own chatbot, Grok, with a distinct personality, has 14 of them. Musk is known for promoting a brand of pronatalism that's become popular among Silicon Valley elites.\n\nAskell responded with her trademark dry intellectualism.\n\n\"I think it depends on how much you care about people in general vs. your own kin,\" Askell wrote. \"I do intend to have kids, but I still feel like I have a strong personal stake in the future because I care a lot about people thriving, even if they're not related to me.\"\n\n\"I think caring about your children can make you feel invested in the future in a new and very profound way, and I do understand people wanting to convey that,\" she added.\n\nThe responses to their short back-and-forth were as varied as you might expect on Musk's social media network. A day later, Askell posted again.\n\n\"I'm too right wing for the left and I'm too left wing for the right,\" she said. \"I'm too into humanities for those in tech and I'm too into tech for those in the humanities. What I'm learning is that failing to polarize is itself quite polarizing.\"",
    "readingTime": 2,
    "keywords": [
      "chatbot",
      "personality",
      "children",
      "stake",
      "posted",
      "profile",
      "journal",
      "kids",
      "care",
      "wing"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/elon-musk-anthropic-philosopher-amanda-askell-debate-2026-2",
    "thumbnail_url": "https://i.insider.com/69925d65e1ba468a96ac1d3f?width=1200&format=jpeg",
    "created_at": "2026-02-16T01:12:14.920Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-says-openclaw-creator-peter-steinberger-is-joining-openai-to-build-nextgen-personal-agents",
    "title": "Sam Altman says OpenClaw creator Peter Steinberger is joining OpenAI to build next-gen personal agents",
    "description": "Sam Altman said OpenClaw creator Peter Steinberger is joining OpenAI to drive development of personal AI agents.",
    "fullText": "OpenAI just scored a win in the AI talent wars.\n\nSam Altman said Sunday on X that Peter Steinberger, the creator of OpenClaw, the viral AI agent powering the agent-only social network Moltbook, is joining OpenAI.\n\nAltman said Steinberger would build the \"next generation\" of personal AI agents at the company.\n\n\"He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people,\" Altman said about Steinberger. \"We expect this will quickly become core to our product offerings.\"\n\nAltman added that OpenClaw, which was for a brief moment in time known as Moltbot and then Clawdbot before Anthropic took notice, will live on as an open-source project supported by OpenAI.\n\n\"The future is going to be extremely multi-agent and it's important to us to support open source as part of that,\" he wrote.\n\nSteinberger, previously best known for founding the PDF processing company PSPDFKit, came out of retirement to launch OpenClaw in late 2025.\n\nHe is likely to bring a new perspective to OpenAI's race to develop artificial general intelligence. Steinberger said he believes AGI is best as a specialized form of intelligence rather than a generalized one.\n\n\"What can one human being actually achieve? Do you think one human being could make an iPhone or one human being could go to space?\" Steinberger said on a Y Combinator podcast in February. \"As a group we specialize, as a larger society we specialize even more.\"",
    "readingTime": 2,
    "keywords": [
      "openclaw",
      "human",
      "agents",
      "intelligence",
      "specialize",
      "steinberger",
      "altman",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sam-altman-hires-openclaw-creator-peter-steinberger-personal-ai-agents-2026-2",
    "thumbnail_url": "https://i.insider.com/699249bde1ba468a96ac1d07?width=1200&format=jpeg",
    "created_at": "2026-02-16T01:12:14.917Z",
    "topic": "finance"
  },
  {
    "slug": "i-got-laid-off-from-amazon-after-11-years-my-high-school-daughter-taught-me-the-biggest-lesson-on-how-to-move-forward",
    "title": "I got laid off from Amazon after 11 years. My high school daughter taught me the biggest lesson on how to move forward.",
    "description": "An ex-Amazon manager says his layoff in October 2025 was a shock, but he's using this time to build AI skills, focus on his health, and apply to jobs.",
    "fullText": "Hemant Virmani was laid off from Amazon during the October 2025 round of layoffs.\n\nHe's using this time to learn new AI skills while applying to engineering roles ‚Äî and exercising.\n\nHis teenage daughter has inspired him to stay positive, keep his cool, and focus on the future.\n\nThis as-told-to essay is based on a conversation with Hemant Virmani, a 47-year-old tech professional based in Washington. It's been edited for length and clarity.\n\nAmazon was part of my daily life for 11.5 years, and suddenly it was gone.\n\nThere's no right way or easy way to do layoffs. I watched my team members get laid off in 2023, and I know how difficult it is. Still, when I received an email in the middle of the night in October 2025 saying I'd been laid off from my senior software development manager position, I was shocked.\n\nWatching my teenage daughter navigate her own difficult situation taught me the biggest lesson in how to move forward well. Now I'm applying to jobs and working on upskilling in AI so I can be proactive, not reactive, to the tech industry.\n\nOnly time will tell if this layoff is a blessing in disguise, but for now, it has led to a refreshing change.\n\nI loved my time at Amazon, and I really feel as though it's a place for exceptional people. The number of quality brains in the office, throwing around ideas and solving a custom problem, was amazing.\n\nThe morning after my layoff, I had a mandated 30-minute meeting with my manager, and it actually went very well. We talked about the layoff, and he offered me support. He delivered it all to me in a very positive, human way, and it was really affirming.\n\nAn old manager also reached out to meet me at a local coffee shop the next day to spend time together and check in on my state of mind. I think he wanted to go about the layoffs right, which isn't easy to do.\n\nI felt attached to the layoff for the first few days; however, I knew there was no way to control what happened ‚Äî I could only control how I reacted to it.\n\nMy daughter is a senior in high school, and she had an adverse situation happen to her last year that required recovery. How she reacted in that difficult time inspired me. Her mental model was: \"Challenges don't have to keep me from showing up for myself or for others.\" Her positive attitude was inspiration for me to do the same.\n\nI kind of learned from her that I had to take this layoff with positivity, keep my cool, and focus on what was next.\n\nA couple of weeks later, I lost my father and spent the next month in India supporting my family. I took about a month to settle my mind, reflect on what I wanted next for my career, and help my daughter finish her college essays.\n\nIt's been a very refreshing change to think about what I want next in my engineering career. I'm less focused on the size or name of the next company I work for, and more on what I'd be doing there. I'm looking forward to hopefully heading the engineering for something that has a great impact on customers. Right now, I don't think that can be done without AI, so I'm working on upskilling.\n\nI want to be proactive, not reactive, about the AI skills I'll need in the future. My team at Amazon used some AI tools, so I'm familiar with some, but I was only able to spend a fraction of my workday using them. Now, I'm building those skills myself.\n\nI started working on a hobby AI project a couple of weeks ago, to go hands-on with AI and be more grounded in the reality of what the AI landscape is like right now. It's been different, and a refreshing change, to build something myself rather than to study it, read about it, or work on a team developing it.\n\nWhen I had a job, it was easy for my first priority to be work. Now I'm making sure that my top priority is my health. I've been going to the gym four or five days a week, and I'm refining a health plan to follow even after I start working again.\n\nOnce I'm done at the gym, my time is a 50/50 split between learning AI and applying to jobs or networking. I'm applying for head of engineering roles where I'd own significant impactful initiatives, averaging 2-3 applications every week.\n\nI made a post on LinkedIn about my layoff, and I received so many supportive comments, texts, and calls from people ‚Äî some I hadn't talked to in decades. Someone from college whom I hadn't talked to in over 25 years reached out, and it was so nice. It felt like we never disconnected. I've also had multiple job leads come from my post, which I'm following up on.\n\nAs of now, I have some worries about when I'll find my next job, but this time has given me the ability to work on things I wasn't able to before. I'm making sure I spend this time with a lot of positivity, not letting negative thoughts come around.\n\nMy advice to anyone undergoing layoffs is to realize that layoffs are not about you. It's about an environment that is driving layoffs. Secondly, now that this has happened, you can't go back in the past and change it. Look forward to what you can do next. How you react is very important.\n\nDo you have a story to share about being laid off from Amazon? If so, please reach out to the reporter at tmartinelli@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "hadn't talked",
      "i'm applying",
      "engineering roles",
      "teenage daughter",
      "now i'm",
      "hemant virmani",
      "layoffs",
      "layoff",
      "laid",
      "skills"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/lifestyle/articles/got-laid-off-amazon-11-094801905.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/6BlJt55yJsObe27UgJv_hw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/business_insider_consolidated_articles_886/3d331103c2338b76dd556695030a67b3",
    "created_at": "2026-02-16T01:12:12.796Z",
    "topic": "news"
  },
  {
    "slug": "pinchtab-12mb-go-binary-for-ai-browser-for-openclaw",
    "title": "Pinchtab ‚Äì 12MB Go Binary for AI Browser for OpenClaw",
    "description": "Contribute to pinchtab/pinchtab development by creating an account on GitHub.",
    "fullText": "pinchtab\n\n /\n\n pinchtab\n\n Public\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n pinchtab/pinchtab",
    "readingTime": 1,
    "keywords": [
      "pinchtab",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/pinchtab/pinchtab",
    "thumbnail_url": "https://opengraph.githubassets.com/75e2caa4ffe020d07290499d7d61063c4d63954910f4e1b17c8fb5beb40dd0a0/pinchtab/pinchtab",
    "created_at": "2026-02-15T18:22:10.915Z",
    "topic": "tech"
  },
  {
    "slug": "the-neurodata-bottleneck-why-neuroai-interfacing-breaks-the-modern-data-stack",
    "title": "The Neuro-Data Bottleneck: Why Neuro-AI Interfacing Breaks the Modern Data Stack",
    "description": "Neural data like EEG and MRI is never 'finished' - it's meant to be revisited as new ideas and methods emerge. Yet most teams are stuck in a multi-stage ETL nightmare. Here's why the modern data stack fails the brain.",
    "fullText": "Neural data like EEG and MRI is never \"finished\" - it's meant to be revisited as\nnew ideas and methods emerge. Yet most teams are stuck in a multi-stage ETL\nnightmare, downloading massive blobs just to extract a single signal or\nrecomputing a new one. Between the struggle to access raw signals and the\nengineering hell of re-mining legacy data at scale, scientists are left waiting\non infrastructure instead of doing science. Here is why the modern data stack\nfails the brain.\n\nYour typical data stack thrives on tabular data. SQL databases, Spark,\nSnowflake - they want structured rows and columns. But in neuro-tech and BCI\nresearch, the \"row\" is a nightmare of Heterogeneous Laboratory Outputs:\n\nThe problem isn't the storage medium (whether cloud or local clusters); it's\nthat this raw data is inaccessible to modern tools. Suddenly, joining a\npatients table with a scans table isn't a LEFT JOIN; it's a multi-stage ETL\nnightmare. You can't just SELECT * FROM neural_scans WHERE patient_id = 'X'\nand expect a useful result. You have to locate the file, download the entire\nmassive blob, and load it into a specialized library just to extract a single\nsignal. This complexity often leaves researchers treating their data as a \"black\nbox,\" focusing on high-level outputs because the underlying raw signals are too\ncumbersome to touch directly.\n\nThis \"download-then-process\" loop is the primary culprit behind slow iteration\nand high I/O costs. It's the Scientific Data Dilemma: rich, complex data\nthat's hell to interact with programmatically at scale. Furthermore, the real\nvalue of these high-volume streams - EEG, MRI, and video - is that they are\nnever \"finished.\" They are assets to be revisited repeatedly as new methods and\nhypotheses emerge.\n\nImagine if you could treat your raw DICOMs, NIfTIs, and EEG files like entries\nin a database, directly from storage, without moving or duplicating them. This\nis the core architectural shift we need.\n\nInstead of an ETL pipeline that copies terabytes into a new format, a \"zero-ETL\"\ndata layer operates by Metadata-First Indexing and Selective I/O. This\narchitecture addresses the significant cost curve of neuro-data by providing\ntools to optimize reuse. By storing intermediate representations, extracted\nfeatures, and supporting gradual, staged processing, researchers can build upon\nprevious work without re-running expensive raw-data ingestions and duplicating\ndata.\n\nA service scans your storage buckets, extracting crucial headers and\nexperimental parameters directly from the raw files. This creates a fast,\nqueryable index of what's inside the files without ever moving them.\n\nThis approach changes the game. Your data stays in your storage (behind your\nVPC, under your IAM policies), but it becomes instantly addressable via a\nPythonic API. No more manual exports or multi-week ingestion jobs just to start\nan experiment.\n\nThe neuro-tech industry is currently in a race to find the \"Scaling Laws\" for\nthe brain. Much like the evolution of LLMs, the hypothesis is that by scaling\ndata bandwidth, model capacity, and signal diversity, we can unlock a\nhigh-fidelity interface between biological and artificial intelligence. However,\nthis scale is hitting a massive engineering wall.\n\nAll of these approaches share a common bottleneck: the data stack. In most neuro\nteams today, data engineering is the single greatest bottleneck, forcing\nbrilliant scientists to wait on infrastructure instead of doing science. The\nchallenge isn't just vertical speed (optimizing one study). It is the horizontal\nengineering hell: the need to retroactively re-process petabytes of\nhistorical data every time a new hypothesis or de-noising logic is developed.\nDoing this at scale, while maintaining perfect traceability, is where research\nmeets infrastructure reality.\n\nWe are asking researchers to find scaling laws using tools designed for CSVs and\nSQL tables. When your primary data is a 2GB 3D volume or a high-frequency\nbiochemical stream, the \"download-then-process\" workflow is a death sentence for\niteration. Without equipping researchers with new, \"Zero-Copy\" tools that\ntreat multimodal biological signals as first-class objects, the breakthrough\n\"Merge\" remains mathematically out of reach.\n\nData scientists in biotech live in Python. They need numpy, pandas, scipy,\nand pytorch. The challenge is making these tools scale across terabytes of\nunstructured binary data. To determine how neural bandwidth scales with model\ncapacity, we need to move beyond black-box ML and utilize Biophysical\nModeling to encode the priors of how neurons actually interact.\n\nThis requires a data layer that remains \"Python-native\":\n\nThe data could be reused in the future for analytics as well as model training:\n\nData engineers often deal with \"blind spots.\" In neuro-research, visualization\nis a unit test. Without it, researchers are forced to trust their pipelines\nblindly, unable to see the artifacts or noise that might be skewing their\nresults. A dataset-centric approach integrates inline visualization across\nthe entire data lineage, allowing you to click on an entry and view the raw 3D\nscan or EEG signal right in your browser. This instant feedback loop reduces\ndebugging time from hours to seconds.\n\nFurthermore, when every transformation and parameter is automatically tracked\nand versioned as part of the data layer, reproducibility becomes a\nbyproduct, not a chore. Any result can be re-computed exactly as it was\nproduced, bolstering scientific rigor and audit readiness without additional\noverhead.\n\nThe future of neuro-engineering isn't about moving more data faster; it's about\nmaking data accessible without movement. Solving the horizontal iteration\nproblem - where research hypotheses meet the \"engineering hell\" of scale and\ntraceability - is the only way to shorten the loop from raw signal to discovery.\n\nBecause high-fidelity signals like MRI and EEG are meant to be mined multiple\ntimes from different angles, our infrastructure must treat them as living\nassets. Whether you are scaling sensor counts at\nNeuralink or molecular diversity at\nMerge Labs, your velocity is ultimately limited by\nyour data plumbing.\n\nWhen we build infrastructure that lives with the data and orchestrates compute\nresources directly where the signals reside, we stop being data gatekeepers and\nstart becoming true enablers of the human-AI future.\n\nWhat do you think, data engineers? Are we ready to move beyond the \"Modern\nData Stack\" to support the complexity of the human brain?",
    "readingTime": 6,
    "keywords": [
      "multi-stage etl",
      "etl nightmare",
      "doing science",
      "model capacity",
      "engineering hell",
      "infrastructure instead",
      "raw signals",
      "without",
      "scale",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://datachain.ai/blog/neuro-data-bottleneck",
    "thumbnail_url": "https://datachain.ai/blog/images/2026-01-25/neuro-data-bottleneck.jpg",
    "created_at": "2026-02-15T18:21:54.623Z",
    "topic": "tech"
  },
  {
    "slug": "the-sweet-lesson-of-neuroscience",
    "title": "The Sweet Lesson of Neuroscience",
    "description": "Scientists once hoped that studying the brain would teach us how to build AI. Now, one AI researcher may have something to teach us about the brain.",
    "fullText": "Scientists once hoped that studying the brain would teach us how to build AI. Now, one AI researcher may have something to teach us about the brain.\n\nIn the early years of modern deep learning, the brain was a North Star. Ideas like hippocampal replay ‚Äî the brain‚Äôs way of rehearsing past experience ‚Äî offered templates for how an agent might learn from memories. Meanwhile, work on temporal-difference learning showed that some dopamine neuron responses in the brain closely parallel reward-prediction errors ‚Äî solidifying a useful framework for reinforcement learning.\n\nDeepMind‚Äôs 2013 Atari-playing breakthrough was perhaps the high-water mark of brain-inspired optimism. The system was in part a digital echo of hippocampal replay and dopamine-based learning. DeepMind‚Äôs CEO gave talks in the early days with titles like ‚ÄúA systems neuroscience approach to building AGI.‚Äù\n\nBut I believe the brain may have something more to teach us about AI ‚Äî and that, in the process, AI may have quite a bit to teach us about the brain. Modern AI research centers on three key ingredients: architectures, learning rules, and training signals. The first two ‚Äî how to build up complex patterns of information from simple ones and how to learn from errors to produce useful patterns ‚Äî have been substantially mastered by modern AI. But the third factor ‚Äî what training signals (typically called ‚Äúloss‚Äù functions, ‚Äúcost‚Äù functions, or ‚Äúreward‚Äù) should drive learning ‚Äî remains deeply underexplored. And that, I think, is where neuroscience still has surprises left to deliver.\n\nI‚Äôve been fascinated by this question since 2016, when advances in artificial deep learning led me to propose that the brain probably has many highly specific cost functions built by evolution that might train different parts of the cerebral cortex to help an animal learn exactly what it needs to in its ecological niche.\n\nMore recently, Steve Byrnes, a physicist turned AI safety researcher, has shed new light on the question of how the brain trains itself. In a remarkable synthesis of the neuroscience literature, Byrnes recasts the entire brain as two interacting systems: a learning subsystem and a steering subsystem. The first learns from experience during the animal‚Äôs lifetime ‚Äî a bit like one of AI‚Äôs neural networks that starts with randomly initialized ‚Äúweights,‚Äù or ‚Äúparameters,‚Äù inside the network, which are adjusted by training. The second is mostly hardwired and sets the goals, priorities, and reward signals that shape that learning. A learning machine ‚Äî like a neural network ‚Äî can learn almost anything; the steering subsystem determines what it is being asked to learn.\n\nByrnes‚Äô work suggests that some of the most relevant insights in AI alignment will come from neuroscientific frameworks about how the steering system teaches and aligns the learner from within. I agree. This perspective is the seed of what we might call the ‚Äúsweet lesson‚Äù of neuroscience.\n\nSo let‚Äôs talk about Byrnes, and brains. In Byrnes‚Äô view, brains have two main parts: a learning subsystem and a steering subsystem.\n\nThe learning subsystem consists primarily of the neocortex, hippocampus, cerebellum, and striatum. It‚Äôs the part of the brain that develops a model of the world, generates plans of action, and predicts how well they‚Äôll work. When we‚Äôre born, it isn‚Äôt able to produce much in the way of useful outputs, but it learns continuously, over time, to find patterns in the world, and then more abstract patterns among those patterns, until it becomes very useful indeed.\n\nThis reflects the ‚Äúcortical uniformity‚Äù idea popular in neuroscience: While the neocortex handles most of our complex cognition, its own structure is relatively simple and consistent. In other words, despite cortical organization into functional substructures, the neocortex's capacity to support complex thought comes only partially from preexisting architecture, with much of its output the result of learning and experience. Instead, the cortex is a learning machine that starts out a bit like an uninitialized neural network ‚Äî one that has equal potential to be trained to drive a car or to generate language or any number of other things.\n\nThen there‚Äôs the steering subsystem, which consists of the hypothalamus and brainstem, with contributions from other regions like the pallidum. Unlike the learning subsystem, the steering subsystem is relatively static ‚Äî a fixed set of rules ‚Äúhand-coded‚Äù by evolution early in the history of our species. These structures, like most in the brain, have some plasticity throughout life, but their rewiring capacity is dwarfed by that of structures in the learning subsystem, such as the neocortex. These rules control (or ‚Äústeer‚Äù) what the learning subsystem is being asked to learn from, and when it is supposed to learn it. Evolution, in other words, didn‚Äôt just build a learner. It built a teacher inside the same brain.\n\nThe steering subsystem influences the learning subsystem through ‚Äúsupervision signals.‚Äù These are analogous to the cost or reward functions used to train today‚Äôs AI, but are much more diverse, elaborate, and species specific. It also handles innate reflexes that have to be present from birth, before the learning subsystem has had a chance to discover the world‚Äôs patterns.\n\nThe steering subsystem doesn‚Äôt simply hand out rewards for evolution‚Äôs ultimate goals of survival or reproduction. Those would come far too late to shape an animal's behavior starting early in its life: By the time the animal learned from these signals, it would already be dead or, at best, abjectly failing to mate.\n\nInstead, evolution built an intricate scaffold of intermediate rewards. Some of these are obvious ‚Äî food and warmth feel rewarding, because we need them to live. Others are much more sophisticated. We get neural rewards for things like play and exploration, which aren't useful at the moment we do them but do help us learn skills that matter later in life. Humans have instincts for things like social bonding, mimicry, attraction to certain kinds of mates, and many other internal assessment signals we don‚Äôt yet have names for. The orchestra of training instructions built up from these signals makes it possible to learn useful skills within one lifetime.\n\nThese signals differ depending on the types of behaviors an animal is ultimately ‚Äúsupposed‚Äù to learn in its particular ecological niche. Humans need to learn language and complex social skills, so our steering subsystem directs us to pay particular attention to the faces, voices, and behavior of our peers. Birds that are fed by their parents when young will have reward signals that help them ‚Äúimprint‚Äù and learn to follow them around. Beavers might have reward signals for picking up sticks, while young squirrels are attentive to acorns. This is why humans learn social deception and squirrels learn to bury nuts, even though the parts of our brains that house the learning subsystem are structured in largely the same way.\n\nIn order to produce useful reward signals, the steering subsystem needs its own sensory systems. We normally think of the visual cortex ‚Äî part of the learning subsystem ‚Äî as where vision lives in the mammalian brain. But the superior colliculus is a separate and mostly innate visual system that gives the steering subsystem its own window into the world. The superior colliculus quickly detects hardwired cues for motion, faces, and threats, allowing the steering system to react before the cortex finishes processing a scene, or even before the learning subsystem has discovered what ‚Äúfaces‚Äù look like. This can be used both to drive innate behaviors and to construct sophisticated reward signals for teaching the rest of the brain.\n\nThe most surprising part of Byrnes‚Äô theory is his explanation of how the steering subsystem makes use of concepts and patterns discovered by the learning subsystem.\n\nRemember, the steering subsystem itself is a bundle of mostly fixed instincts. It has minimal ability to learn new information or even really compute concepts at all. Let‚Äôs say I embarrass myself by making a mistake in front of another scientist whose work I admire. I‚Äôll almost certainly feel a sense of shame. This felt sense comes in large part from the steering subsystem generating some kind of negative reward signal ‚Äî but what would trigger it? It certainly has no internal representation of ‚Äúprofessional acquaintance‚Äù or ‚Äúscientist.‚Äù¬† Even concepts like ‚Äúrespect,‚Äù ‚Äúadmiration,‚Äù ‚Äúshame,‚Äù and ‚Äústatus‚Äù are complex and contingent, far above the steering subsystem‚Äôs pay grade. Still, we find all of these things highly motivating, even though the steering subsystem doesn‚Äôt know what they are or even where the neurons representing such concepts might show up.\n\n‚ÄúImportant scientist‚Äù and its ilk are patterns that emerge in the learned world model in the learning subsystem of a modern person in the industrialized world. According to Byrnes‚Äô model, the steering subsystem has no way to know in advance what those patterns will be. How is it supposed to emit the right rewards to shape our social development when those rewards depend on concepts it can neither predict nor comprehend?\n\nThis is a version of what the cognitive scientist Stevan Harnad called the symbol grounding problem: How do thinking systems connect abstract symbols to their referrants in the real world ‚Äî or, in this case, how can innate motivations be triggered by learned abstractions? The steering subsystem is a set of hard-coded genetic rules, but it still needs to respond to learned concepts like ‚Äúcolleague‚Äù or ‚Äúfriend.‚Äù\n\nByrnes has a proposal for how that works. He thinks that there are neural circuits in the brain ‚Äî he calls them Thought Assessors ‚Äî that learn to recognize important patterns of thought in the learning system and connect them to the more primitive signals that the steering subsystem has knobs for.\n\nThe Thought Assessors are part of the learning subsystem (Byrnes predicts they‚Äôll primarily be found in the extended striatum). They predict, based on input from the learning subsystem, what specific elements of the steering subsystem are about to do. A given Thought Assessor might start out with many different learning subsystem neurons feeding into it while it tries to predict a specific steering subsystem signal. If some neurons turn out to help make that prediction accurately, they‚Äôll stay as inputs to that Thought Assessor. If other neurons prove irrelevant or detrimental to the prediction, their connections to that Thought Assessor are weakened or ignored by the learning subsystem.\n\nThought Assessors don‚Äôt transfer information about abstract concepts to the steering system, which can't process it anyway. But by learning to predict how the steering subsystem will react across many different kinds of situations, they help connect basic instincts to the neurons that handle learned concepts. Once a Thought Assessor is wired up, it can utilize a more sophisticated learned model of how its steering rules should be applied, one that generalizes to the complicated situations we encounter in the real world.\n\nByrnes proposes that there are many different Thought Assessors and many different corresponding kinds of supervisory signals from the steering subsystem ‚Äî perhaps hundreds to thousands of them. One of those Thought Assessors provides a prediction of a thought‚Äôs overall valence ‚Äî something like how rewarding it is to the animal. There are also many other assessors predicting other innately important features, like ‚ÄúI‚Äôm about to get goosebumps‚Äù or ‚ÄúI‚Äôm about to flee a looming predator‚Äù or ‚Äúthis will lead to me crying.‚Äù The steering subsystem has signals ‚Äî and the learning subsystem has corresponding Thought Assessors ‚Äî for most of the key building block variables underlying all innately controlled, species-specific behaviors, including human social behaviors.\n\nOne of Byrnes‚Äô best-developed examples has to do with laughter. Many biologists think that laughter evolved as a way to signal play. Young animals, the theory goes, enjoy playing because it helps them practice activities like fighting, chasing prey, or fleeing predators in a safe, low-stakes environment. And playful animals often have ways of letting their playmates know that their pawing and batting isn‚Äôt a serious attack. Dogs exhibit a ‚Äúplay bow.‚Äù Rats and humans laugh. This urge to laugh is an innate instinct: In Byrnes‚Äô parlance, it comes from the steering subsystem. In neurological terms, Byrnes believes that there are specific circuits in the hypothalamus that detect the conditions under which an animal should laugh ‚Äî when it detects some mild danger signs, like being batted, pawed at, or tickled, but has no other reason to believe it‚Äôs in serious trouble.\n\nResearchers have actually found these circuits in experiments with tickled rats. Humans, of course, don‚Äôt just laugh during play fights ‚Äî we laugh at things we find funny or unexpected, or even when we‚Äôre nervous. When we‚Äôre born, our innate instincts tell us to laugh when we‚Äôre basically safe, but detect just a little bit of danger. In babies, this might mean tickling or peekaboo. Over time, we learn increasingly abstract mappings of social threat, confusion, and discomfort. We can imagine a laughter Thought Assessor learning to predict which of the ever-more-complex situations it finds itself in triggers the right balance of safety and danger to drive a laughter response, while the laughter response trains the learning subsystem to label some of its learned internal pathways as playful, humorous, safe, or friendly.\n\nWhen you feel pride, shame, or empathy, some of those Thought Assessors are likely firing, allowing a learned cognitive pattern to trigger an ancient reinforcement pathway ‚Äî a pathway that, in turn, can shape the further development of your social responses.\n\nByrnes is not the first to suggest ways that innate evolved brain mechanisms could ‚Äúbootstrap‚Äù learning of complex social behaviors. Other cognitive scientists have imagined processes by which simple innate reward signals could steer an animal to pick up on more complex patterns, which themselves could be the basis for the production of more complex forms of reward.\n\nA version of this concept appeared in the cognitive science literature in Ullman, Harari, and Dorfman‚Äôs 2012 paper, ‚ÄúFrom simple innate biases to complex visual concepts.‚Äù The authors proposed a computational model in which infants would use mover-event detectors ‚Äî simple innate visual cues for when one object causes another to move ‚Äî as teaching signals. A system that detects ‚Äúmovers‚Äù can label the likely source of motion as a ‚Äúhand.‚Äù Once it recognizes ‚Äúhands‚Äù using this primitive labeling scheme ‚Äî and assuming it also has an innate face detector that can draw attention to the eyes ‚Äî it can then infer gaze direction by assuming that eyes tend to look toward ‚Äúhands.‚Äù Other cognitive science literature recognizes that gaze direction, in turn, is a useful signal for training the ability to pay attention to the same thing a caretaker is paying attention to, which helps drive imitation learning and theory of mind.\n\nAlthough far from validated in its details, Byrnes‚Äô theory also is supported by neuroscience.\n\nA 2023 Nature paper by Fei Chen and colleagues found that a disproportionate number of the mouse brain‚Äôs distinct cell types reside in the hypothalamus, the midbrain, and the brainstem, suggesting that evolution poured much of its innovation into the areas that make up the steering subsystem.\n\nThis would make sense if we believe in the learning/steering subsystem distinction. The learning subsystem just needs to be set up to learn: It needs only to create a generic, somewhat random scaffold and a learning algorithm to fill in its details. But to be the kind of sophisticated teacher Byrnes hypothesizes, the steering subsystem would have to contain a lot of information about the useful behaviors and thought patterns that a specific species will likely face in its ecological niche. We would expect a lot of bespoke innate biological complexity to be built into the steering subsystem, and the experimental evidence suggests that this is in fact the case.\n\nThere is substantial evidence that the hypothalamus is involved in shaping social behaviors. In a recent paper titled ‚ÄúA hypothalamic circuit underlying the dynamic control of social homeostasis,‚Äù Catherine Dulac‚Äôs lab at Harvard identifies the specific neuronal circuits in the mouse hypothalamus that play a role in how ‚Äúsocial isolation generates an aversive state (‚Äòloneliness‚Äô) that motivates social seeking and heightens social interaction upon reunion.‚Äù And David Anderson‚Äôs lab at Caltech found ‚Äúa circuit that integrates drive state and social contact to gate mating,‚Äù involving a different set of hypothalamus neurons.\n\nOne key aspect of the theory is that the brain‚Äôs reward signals are not just simple functions of external conditions. Rather, they are the results of complex computations by the steering subsystem, which themselves can draw input from the learned Thought Assessors. Is this complexity of reward production realistic?\n\nSong learning in songbirds provides one of the best-understood examples of biological reinforcement learning. Young birds learn their songs by listening to more experienced tutors, storing an internal template, or memory, of what the song should sound like based on the tutor song, and then practicing producing their own songs thousands of times while their brains generate error signals by comparing the sound of their outputs with that of the stored template.\n\nDopamine neurons in the songbird brain fire precisely when a sung note is closer to ‚Äî or further from ‚Äî from the tutor song. More interestingly, these reward signals change with social context: When practicing alone, feedback is sharp and corrective, but when singing to a mate, the same circuits suppress error signals, freezing the learned performance. In other words, the bird has an innate instinct that makes it want to copy the songs of older birds.\n\nBut translating this instinct into practice requires more sophistication than the steering subsystem can provide. It needs to remember a repertoire of songs, calculate the difference between a memorized note and the note the bird actually produces at any given time in a song, and know when to ignore this whole reward system when it‚Äôs time to stop practicing and focus on a real opportunity to attract a mate. According to Byrnes‚Äô theory, the songbird brain first built something like a Thought Assessor for evaluating ‚Äúmatch my song‚Äôs sound to that of my tutor‚Äôs song,‚Äù and then used that evaluator to help train its song production. This allows the songbird brain to generate dopamine reward signals in response to purely internal processes (and change which of those processes is rewarding in different conditions). The songbird doesn‚Äôt just learn; it teaches itself.\n\nByrnes‚Äô model also predicts that there are many different Thought Assessors that link patterns in the learning subsystem to different supervision signals from the steering subsystem. Different areas of the learning subsystem might also learn from different steering subsystem outputs. Indeed, there is evidence of many specialized supervision signals even in fruit flies, an organism for which we have a full brain wiring map that can start to reveal such complexity. The fly brain doesn‚Äôt just have one kind of ‚Äúdopamine neuron.‚Äù Instead, it has about 20 different kinds of dopamine neurons capable of assessing a combination of features of the fly's internal state, with some ability to detect external cues. Each of these 20 or so kinds of dopamine neurons sends signals to different subcompartments of the fly brain‚Äôs ‚Äúmushroom body,‚Äù which functions as associative learning center. This is suggestive of an evolutionarily ancient structure that supports training many different ‚Äúassessors‚Äù inside a brain.\n\nThere are still many unknowns. Byrnes has fascinating hypotheses about how Thought Assessors fit within our current understanding of neuroanatomy, and how specific social instincts are grounded in steering subsystem circuits, but they are not fully biologically or algorithmically fleshed out. Refining and testing them, especially in the absence of a more unified map of the brain, would be something of a fishing expedition. Remedying this situation is not a small task. I think it would take some brain mapping megaprojects and the formation of new groups studying these kinds of questions, and even then it would likely take more than a few years to bear fruit.\n\nByrnes‚Äô research has important implications for how we understand the brain, but that‚Äôs not his primary motivation. He thinks that the way our brain steers its own learning could prove important for aligning future ‚Äúbrain like‚Äù artificial general intelligence systems.\n\nByrnes thinks that today‚Äôs LLMs won't scale to true general intelligence. Instead, AI researchers will naturally converge on the same broad type of architecture that evolution has developed in the human brain. Of course, this will involve a malleable learning subsystem and a hard-coded steering subsystem. Within the learning subsystem, he predicts that the model‚Äôs architecture will be a form of continuous model-based reinforcement learning, just as our brains build internal world models that we use to simulate the outcomes of actions before we take them, and that update themselves continually as we learn new information.\n\nThis high-level view of the brain substantially overlaps with Yann LeCun‚Äôs proposal for the ultimate path to AGI (which is not large language models), as well as perspectives laid out in books like Max Bennett‚Äôs A Brief History of Intelligence. Byrnes is among a small set of neuroscience and AI researchers, like Beren Millidge, who have sought to link this idea to questions of AI alignment.\n\nIn any case, this type of setup is not how we train LLMs. Today, model-based reinforcement learning is used for other AI applications, like game playing or robotics, and no current AIs are capable of fully continuous learning ‚Äî¬†their store of knowledge is fixed once they‚Äôre trained. Many AI researchers believe these things aren‚Äôt necessary: Sufficiently large and sophisticated LLMs might have enough stored knowledge that they don‚Äôt need to keep learning and enough internal sophistication to make good predictions without an explicit world model built into their architecture. If they‚Äôre right, then Byrnes‚Äô model of the brain doesn‚Äôt have much to tell us about AI safety.\n\nBut if you believe, as Byrnes does, that AGI development may ultimately land on such a brain-like architecture, then we might be able to learn something relevant for AI alignment from the brain.\n\nAny brain-like AGI would need at least a simple steering subsystem, and if it is to make use of learned concepts, it will need something like Thought Assessors. The challenge will be figuring¬† out how to design this system so that it bootstraps the development of prosocial motives¬† instead of selfish ones.\n\nThis is where studying the brain might be able to help us. In Byrnes‚Äô framework, the human brain‚Äôs particular Thought Assessors, and the particular logic by which they are used by its steering subsystem to generate rewards, are how the brain aligns itself: They are what keep an increasingly sophisticated network of learned motivations and incentives in line with the instinctual demands of the steering subsystem. If we could figure out how our brains create the different kinds of social reward functions that make humans want to help each other, this insight could offer a step toward designing a reward system that can robustly elicit similar behavior in a powerful intelligence that continuously learns.\n\nRecently, Geoffrey Hinton stated that he is becoming more optimistic about AI alignment because mammals possess a ‚Äúmaternal instinct‚Äù ‚Äî a process that allows a baby to strongly control the behavior of its more intelligent and powerful mother. In light of Byrnes‚Äô framework, Hinton‚Äôs wacky-sounding idea could become an actual research program, if still a speculative one.\n\nValidating and refining this framework with more specificity could open a path toward a neuroscience of alignment. Imagine comparing the steering circuits of related species with different social instincts. The goal would not be to copy the brain exactly but to emulate its methods of teaching the learner from within.\n\nWhich Thought Assessors do different animals have in their brains, and what patterns do human brain Thought Assessors look for when trying to ground out concepts like ‚Äúfriendliness‚Äù? What more primitive steering subsystem signals are needed for the concept of ‚Äúfriendliness‚Äù to emerge in the first place? Or do the Thought Assessors tag concepts we haven‚Äôt thought of yet? Optimistically, we might not have to understand the brain perfectly to gain some relevant insights.\n\nTo be clear, we shouldn‚Äôt oversell this as a near-term or straightforward path to aligning AI. Even if we understood perfectly how the human brain is steered, this might not generalize to steering an artificial superintelligence.\n\nThe implications of understanding the brain‚Äôs steering circuits would go well beyond AI. Many psychiatric conditions ‚Äî addiction, obsessive-compulsive disorder, depression ‚Äî can be seen as failures of internal teaching: loops on which the brain‚Äôs evaluative machinery gets stuck or miscalibrated.\n\nAspects of normal brain function like gender and sexual identity may trace back to how the brain‚Äôs steering subsystem develops its Thought Assessors ‚Äî how it learns to interpret patterns of attraction, status, or affiliation and ties them to innate steering responses.\n\nAll of this brings us to a single question: How does sophisticated, within-lifetime teaching actually work inside mammalian brains? Answering that could link psychiatry, developmental neuroscience, and new ideas for AI alignment into a consilient research program.\n\nIf scaling was AI‚Äôs bitter lesson of the early 2020s, the 2030s and beyond may teach a sweet lesson of neuroscience:\n\nBrains are not just learners; they are architectures of internal teachers.\n\nWe should try to find those teachers in the brain ‚Äî and learn from them.\n\nAdam Marblestone is the co-founder and CEO of Convergent Research, and incubator for Focused Research Organizations.\n\nWhat you save is stored only on your specific browser locally, and is never sent to the server. Other visitors will not see your highlights, and you will not see your previously saved highlights when visiting the site through a different browser.\n\nTo add a highlight: after selecting a passage, click the star . It will add a quick-access bookmark.\n\nTo remove a highlight: after hovering over a previously saved highlight, click the cross . It will remove the bookmark.\n\nTo remove all saved highlights throughout the site, you can All selections have been cleared.",
    "readingTime": 22,
    "keywords": [
      "thought assessors",
      "hippocampal replay",
      "superior colliculus",
      "gaze direction",
      "ecological niche",
      "relevant insights",
      "sweet lesson",
      "science literature",
      "previously saved",
      "we‚Äôre born"
    ],
    "qualityScore": 1,
    "link": "https://asteriskmag.com/issues/13/the-sweet-lesson-of-neuroscience",
    "thumbnail_url": "https://asteriskmag.com/media/pages/issues/13/the-sweet-lesson-of-neuroscience/3e7f0cf03c-1771007624/sweet-lesson-of-neuroscience-1200x630-crop.png",
    "created_at": "2026-02-15T18:21:53.902Z",
    "topic": "tech"
  },
  {
    "slug": "no-swiping-involved-the-ai-dating-apps-promising-to-find-your-soulmate",
    "title": "No swiping involved: the AI dating apps promising to find your soulmate",
    "description": "Agentic AI apps first interview you and then give you limited matches selected for ‚Äòsimilarity and reciprocity of personality‚Äô\nDating apps exploit you, dating profiles lie to you, and sex is basically something old people used to do. You might as well consider it: can AI help you find love?\nFor a handful of tech entrepreneurs and a few brave Londoners, the answer is ‚Äúmaybe‚Äù.\n Continue reading...",
    "fullText": "Agentic AI apps first interview you and then give you limited matches selected for ‚Äòsimilarity and reciprocity of personality‚Äô\n\nDating apps exploit you, dating profiles lie to you, and sex is basically something old people used to do. You might as well consider it: can AI help you find love?\n\nFor a handful of tech entrepreneurs and a few brave Londoners, the answer is ‚Äúmaybe‚Äù.\n\nNo, this is not a story about humans falling in love with sexy computer voices ‚Äì and strictly speaking, AI dating of some variety has been around for a while. Most big platforms have integrated machine learning and some AI features into their offerings over the past few years.\n\nBut dreams of a robot-powered future ‚Äì or perhaps just general dating malaise and a mounting loneliness crisis ‚Äì have fuelled a new crop of startups that aim to use the possibilities of the technology differently.\n\nJasmine, 28, was single for three years when she downloaded the AI-powered dating app Fate. With popular dating apps such as Hinge and Tinder, things were ‚Äúrepetitive‚Äù, she said: the same conversations over and over.\n\n‚ÄúI thought, why not sign up, try something different? It sounded quite cool using, you know, agentic AI, which is where the world is going now, isn‚Äôt it?‚Äù\n\nFate, a London startup that went live last May, bills itself as the first ‚Äúagentic AI dating app‚Äù. Its core offering is an AI personality named Fate that ‚Äúonboards‚Äù users during an interview, asking them about their hopes and struggles before putting forward five potential matches ‚Äì no swiping involved.\n\nFate will also coach users through their interactions, if they desire, a functionality Jasmine described as helpful and another user said was ‚Äúscary‚Äù and ‚Äúa bit like Black Mirror‚Äô.\n\nRakesh Naidu, Fate‚Äôs founder, demonstrated its coaching ability in an interview with the Guardian. ‚ÄúI just feel a bit hopeless at the moment in regards to my chats. I feel like I‚Äôm not being engaging enough or meaningful enough,‚Äù he said into his phone. ‚ÄúI just need some kind of meaningful questions I can ask to really uncover the essence of people.‚Äù\n\n‚ÄúI hear you, Rakesh,‚Äù said a synthetic female voice. ‚ÄúHere are a few ideas. One, what‚Äôs something you‚Äôre passionate about that not many people know?‚Äù\n\nNaidu, 28, said he started Fate in order to address shortcomings in the world‚Äôs biggest dating platforms ‚Äì apps such as Tinder, Bumble and Hinge, which monetise the time users spend on them and ‚Äúare literally profiting off keeping people lonely‚Äù.\n\nOther startups, from Sitch to Keeper, have launched across the US, hoping AI features can provide the novelty to win them a share of a crowded market. Sitch leverages the power of AI to manage vasts amounts of information, inviting users to ‚Äúgive us detailed feedback down to the hair colour, where they want to raise a family, and their fav music‚Äù; Keeper says it can find ‚Äúa match with rare and real soulmate potential‚Äù.\n\nPart of the issue, Naidu says, are algorithmic approaches to matchmaking: Tinder at one point ranked users‚Äô desirability through an Elo score, an algorithm originally used to rate chess players. On dating platforms, it‚Äôs a Hobbesian proposition ‚Äì high-scoring users are shown to other high-scoring users, low-scoring users to other low-scoring users. ‚ÄúIt‚Äôs very superficial,‚Äù said Naidu.\n\nAI, in theory, can offer a different way. Awkward as it may be to discuss your dating life with a chatbot, Fate does not rank you based on your responses, but instead uses an LLM to try to find other users who, based on their interview, might be similar to you. That approach, along with the AI dating coach, helps users to focus on authentic connection, said Naidu ‚Äì ‚Äúsimilarity and reciprocity of personality‚Äù.\n\nAmelia Miller, a consultant for Match Group (which owns Tinder and Hinge), worries about this approach.\n\nA recent study from the group surveyed 5,000 Europeans about their online dating preferences ‚Äì and found that while many were interested in AI tools to weed out fake profiles and flag toxic users, most, 62%, were skeptical about using AI to guide their conversations. One obvious anxiety might be the dystopian idea of two agentic AIs steering a conversation, with the humans nominally in charge turning into little more than meatspace mouthpieces.\n\nMiller, however, who coaches people on their relationships with AI, says she sees many clients turn to an LLM for advice in the smaller, uncomfortable moments of building their relationships ‚Äì asking AI how to craft a text, for example, or respond to an intimate question.\n\n‚ÄúOften I‚Äôm trying to make sure that people aren‚Äôt turning to machines because turning to humans demands a level of vulnerability that has become uncomfortable now that there is an alternative,‚Äù she said.\n\nThe appeal of an AI coach such as Fate is that revealing yourself to it ‚Äì your judgments, hopes and idiosyncrasies ‚Äì involves no risk; it does not remember or evaluate. Friends do, and, says Miller, asking advice from them helps hone the skills for successful relationships.\n\n‚ÄúAdvice is really one of the key ways that people practice vulnerability in a more low-stakes environment ‚Äì they build up to more vulnerable moments in a romantic context.‚Äù\n\nJeremias has been using Fate for several months. He said he doesn‚Äôt use the AI coach: ‚ÄúI could see it being helpful, but I mean there are obviously some concerns. Like the new generation are basically not going to have the real world experience of actually trying and failing.‚Äù\n\nThe app recently helped him to meet someone after a long period of being single in London. He‚Äôs not sure if this is because of the AI matching, or because Fate simply serves up only five matches at a time ‚Äì no infinite swiping ‚Äì and, excruciatingly, forces its users to write an explanation when they reject a potential match.\n\n‚ÄúIt makes the swiping more thoughtful. If I‚Äôm actually saying no to this person, what are the reasons I‚Äôm saying no to them?‚Äù\n\nHe and Jasmine both have second dates upcoming, both after being single for several years, they say.\n\n‚ÄúIt is exciting because you get like, you know, the butterflies in your stomach again, going on a date with someone, doing yourself up really nicely, wearing dresses, heels. It‚Äôs fun,‚Äù said Jasmine.",
    "readingTime": 6,
    "keywords": [
      "high-scoring users",
      "low-scoring users",
      "dating app",
      "dating platforms",
      "dating apps",
      "interview",
      "coach",
      "matches",
      "personality",
      "humans"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/15/ai-dating-apps-personality-matchmaking",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4f1dfab33365fad67b94f0bca8ba0d4243f6d838/0_187_4554_3644/master/4554.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6a7783c93a20caf686d654d8a35df2f8",
    "created_at": "2026-02-15T12:26:57.799Z",
    "topic": "tech"
  },
  {
    "slug": "gary-marcus-says-ai-fatigue-could-hit-coders-but-other-jobs-may-be-spared-and-even-become-more-fun",
    "title": "Gary Marcus says AI fatigue could hit coders but other jobs may be spared ‚Äî and even become more fun",
    "description": "AI researcher Gary Marcus said that thanks to AI, some programmers are stuck debugging code rather than writing their own.",
    "fullText": "AI fatigue won't hit everyone the same way, AI researcher Gary Marcus said.\n\n\"In some domains, AI might actually make a person's job more fun,\" Marcus told Business Insider.\n\nSoftware engineers are increasingly discussing how AI is draining them. Siddhant Khare, who builds AI tools, recently wrote about how he's experiencing AI fatigue.\n\n\"If someone who builds agent infrastructure full-time can burn out on AI, it can happen to anyone,\" Khare wrote.\n\nMarcus said that not all industries are set to be disrupted in the same way AI has upended programming and engineering.\n\n\"If somebody needs to do some artistic work and they don't really have artistic talent, it might be fun to get the system to make them feel like they have a superpower,\" he said.\n\nHowever, Marcus said he isn't surprised that programmers are beginning to feel fatigued.\n\n\"Some people in coding, in particular, probably feel like constant pressure, and now they feel like what they're doing is debugging somebody else's code, instead of writing code,\" he said. \"Debugging somebody else's code is not particularly fun.\"\n\nThe feeling Marcus described echoed what Khare told Business Insider when asked to expand on his AI fatigue.\n\n\"We used to call it an engineer, now it is like a reviewer,\" Khare said. \"Every time it feels like you are a judge at an assembly line and that assembly line is never-ending.\"\n\nSteve Yegge, a veteran engineer, said companies should limit employees' time spent on AI-assisted work to 3 hours. He said AI has \"a vampiric effect.\"\n\n\"I seriously think founders and company leaders and engineering leaders at all levels, all the way down to line managers, have to be aware of this and realize that you might only get three productive hours out of a person who's vibe coding at max speed,\" Yegge told The \"Pragmatic Engineer\" newsletter/podcast. \"So, do you let them work for three hours a day? The answer is yes, or your company's going to break.\"",
    "readingTime": 2,
    "keywords": [
      "debugging somebody",
      "somebody else's",
      "else's code",
      "fatigue",
      "hours",
      "engineering",
      "artistic",
      "coding",
      "assembly",
      "leaders"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-fatigue-gary-marcus-2026-2",
    "thumbnail_url": "https://i.insider.com/698f893de1ba468a96ac10e2?width=1200&format=jpeg",
    "created_at": "2026-02-15T12:26:57.428Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-cofounder-says-she-doesnt-regret-her-literature-major-and-says-ai-will-make-humanities-majors-more-important",
    "title": "Anthropic cofounder says she doesn't regret her literature major ‚Äî and says AI will make humanities majors 'more important'",
    "description": "Anthropic president Daniela Amodei said that, in the age of AI, we should \"prize the things that make us human\" ‚Äî like literature degrees.",
    "fullText": "\"Learn to code\" was once common career advice. Now it might be: \"Learn to read.\"\n\nEnglish majors are often the butt of the joke, known for their unmarketable skills. (Does anyone want to hire me for having read \"Great Expectations\"?) Anthropic president Daniela Amodei takes the opposing stance. She doesn't regret her literature degree ‚Äî¬†and says AI will make the humanities more important.\n\n\"In a world where AI is very smart and capable of doing so many things, the things that make us human will become much more important,\" she said on ABC News.\n\nAmodei listed some things that make us human: understanding ourselves, our history, and what makes us tick.\n\nStudying the humanities is \"more important than ever,\" she said, while large language models are often very good at STEM.\n\n\"The ability to have critical thinking skills will be more important in the future, rather than less,\" Amodei said.\n\nAmodei's opinion is becoming more popular in AI. Steven Johnson, the editorial director of Google Labs' NotebookLM, told Business Insider that LLMs were causing a \"revenge of the humanities.\"\n\nHer brother Dario, the CEO of Anthropic, didn't seem to take the hint that humanities majors might come back in fashion in an AI-filled world. He studied physics at Caltech and Stanford.\n\nIndustry leaders are debating the helpfulness of a computer science major. In the age of vibe-coding, will a CS degree help you in tech?\n\nTheir takes diverge: OpenAI chairman Bret Taylor said the major was \"extremely valuable,\" while Google's head of Android, Sameer Samat, said it needed a \"rebrand.\"\n\nDaniela Amodei also described Anthropic's hiring strategy to ABC. She said the company wants employees with good people skills and communication techniques. Being \"kind and compassionate\" and wanting to \"help other people\" are good traits, she said.\n\n\"At the end of the day, people still really like interacting with people,\" Amodei said.",
    "readingTime": 2,
    "keywords": [
      "daniela amodei",
      "humanities",
      "skills",
      "learn",
      "majors",
      "degree",
      "human",
      "anthropic"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/anthropic-president-ai-humanities-majors-more-important-2026-2",
    "thumbnail_url": "https://i.insider.com/698ce61dd3c7faef0ece19bf?width=1200&format=jpeg",
    "created_at": "2026-02-15T12:26:57.275Z",
    "topic": "finance"
  },
  {
    "slug": "i-got-laid-off-from-amazon-after-11-years-my-high-school-daughter-taught-me-the-biggest-lesson-on-how-to-move-forward",
    "title": "I got laid off from Amazon after 11 years. My high school daughter taught me the biggest lesson on how to move forward.",
    "description": "An ex-Amazon manager says his layoff in October 2025 was a shock, but he's using this time to build AI skills, focus on his health, and apply to jobs.",
    "fullText": "This as-told-to essay is based on a conversation with Hemant Virmani, a 47-year-old tech professional based in Washington. It's been edited for length and clarity.\n\nAmazon was part of my daily life for 11.5 years, and suddenly it was gone.\n\nThere's no right way or easy way to do layoffs. I watched my team members get laid off in 2023, and I know how difficult it is. Still, when I received an email in the middle of the night in October of 2025 saying I'd been laid off from my senior software development manager position, I was shocked.\n\nWatching my teenage daughter navigate her own difficult situation taught me the biggest lesson in how to move forward well. Now I'm applying to jobs and working on upskilling in AI so I can be proactive, not reactive, to the tech industry.\n\nOnly time will tell if this layoff is a blessing in disguise, but for now it has led to a refreshing change.\n\nI loved my time at Amazon, and I really feel as though it's a place for exceptional people. The number of quality brains in the office, throwing around ideas and solving a custom problem, was amazing.\n\nThe morning after my layoff, I had a mandated 30-minute meeting with my manager, and it actually went very well. We talked about the layoff, and he offered me support. He delivered it all to me in a very positive, human way, and it was really affirming.\n\nAn old manager also reached out to meet me at a local coffee shop the next day to spend time together and check in on my state of mind. I think he wanted to go about the layoffs right, which isn't easy to do.\n\nI felt attached to the layoff for the first few days; however, I knew there was no way to control what happened ‚Äî I could only control how I reacted to it.\n\nMy daughter is a senior in high school, and she had an adverse situation happen to her last year that required recovery. How she reacted in that difficult time inspired me. Her mental model was: \"Challenges don't have to keep me from showing up for myself or for others.\" Her positive attitude was inspiration for me to do the same.\n\nI kind of learned from her that I had to take this layoff with positivity, keep my cool, and focus on what was next.\n\nA couple of weeks later, I lost my father and spent the next month in India supporting my family. I took about a month to settle my mind, reflect on what I wanted next for my career, and help my daughter finish her college essays.\n\nIt's been a very refreshing change to think about what I want next in my engineering career. I'm less focused on the size or name of the next company I work for, and more on what I'd be doing there. I'm looking forward to hopefully heading the engineering for something that has a great impact on customers. Right now, I don't think that can be done without AI, so I'm working on upskilling.\n\nI want to be proactive, not reactive, about the AI skills I'll need in the future. My team at Amazon used some AI tools, so I'm familiar with some, but I was only able to spend a fraction of my workday using them. Now, I'm building those skills myself.\n\nI started working on a hobby AI project a couple of weeks ago, to go hands-on with AI and be more grounded in the reality of what the AI landscape is like right now. It's been different, and a refreshing change, to build something myself rather than to study it, read about it, or work on a team developing it.\n\nWhen I had a job, it was easy for my first priority to be work. Now I'm making sure that my top priority is my health. I've been going to the gym four or five days a week, and I'm refining a health plan to follow even after I start working again.\n\nOnce I'm done at the gym, my time is a 50/50 split between learning AI and applying to jobs or networking. I'm applying for Head of Engineering roles where I'd own significant impactful initiative(s), averaging 2-3 applications every week.\n\nI made a post on LinkedIn about my layoff, and I received so many supportive comments, texts, and calls from people ‚Äî some I hadn't talked to in decades. Someone from college whom I hadn't talked to in over 25 years reached out, and it was so nice. It felt like we never disconnected. I've also had multiple job leads come from my post which I'm following up on.\n\nAs of now, I have some worries about when I'll find my next job, but this time has given me the ability to work on things I wasn't able to before. I'm making sure I spend this time with a lot of positivity, not letting negative thoughts come around.\n\nMy advice to anyone undergoing layoffs is to realize that layoffs are not about you. It's about an environment that is driving layoffs. Secondly, now that this has happened, you can't go back in the past and change it. Look forward to what you can do next. How you react is very important.\n\nDo you have a story to share about being laid off from Amazon? If so, please reach out to the reporter at tmartinelli@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "i'm applying",
      "hadn't talked",
      "now i'm",
      "layoff",
      "layoffs",
      "team",
      "laid",
      "difficult",
      "manager",
      "daughter"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-tech-manager-laid-off-after-11-years-refreshing-change-2026-2",
    "thumbnail_url": "https://i.insider.com/698f4bdfd3c7faef0ece3e01?width=1200&format=jpeg",
    "created_at": "2026-02-15T12:26:57.274Z",
    "topic": "finance"
  },
  {
    "slug": "ai-agents-are-transforming-what-its-like-to-be-a-coder-its-been-unlike-any-other-time",
    "title": "AI agents are transforming what it's like to be a coder: 'It's been unlike any other time.'",
    "description": "AI agents are turning software engineers into overseers ‚Äî and could be coming for other white-collar jobs. Many companies still need to adapt roles.",
    "fullText": "When Jesal Gadhia cofounded a software company a year ago, he expected that the AI agents it was creating would save its customers a lot of work.\n\nHe didn't predict the same tools would save his own team at the startup Cora so much time.\n\nAgents wrote all of the code the company uses ‚Äî something that wouldn't have been possible before last year, he told Business Insider.\n\nThe company's six-person team produced what Gadhia calls \"unprecedented\" amounts of code in its first 12 months. Five years ago, he said, reaching the same level of productivity would have required 20 to 30 engineers.\n\n\"It's been unlike any other time that I can remember,\" Gadhia said of the impact of agents.\n\nAcross tech, AI agents powered by large language models are absorbing tasks that experienced engineers once handled. Software engineering is becoming a human-AI partnership ‚Äî what Anthropic chief Dario Amodei has called the industry's \"centaur phase.\" And, as some tech insiders increasingly warn, what begins in software rarely stays there, with potential implications for other white-collar fields.\n\nAt Canva, the graphic design software company, engineering teams draft detailed instructions for AI agents to execute in the background ‚Äî sometimes overnight. By morning, the work is ready, Brendan Humphreys, Canva's chief technology officer, said.\n\n\"Often, those results are really impressive,\" he told Business Insider.\n\nEngineers still apply a \"human touch\" to reach the company's quality bar. Even so, agents are delivering \"hours and hours and hours of work done completely autonomously,\" Humphreys said.\n\nThat's changing what it means to be a coder.\n\nHumphreys said that his senior engineers now often describe their jobs as \"largely review\" ‚Äî checking AI output, steering one or more agents to follow a plan, and taking responsibility for the final product.\n\nTeams still spend time defining problems.\n\n\"The hardest part of engineering is to translate often vague, confusing, conflicting requirements into something that is production-ready,\" he said.\n\nAI can help, but doing it well requires \"precision of articulation\" in what's required, Humphreys said. It also demands \"mastery of the domain\" so engineers can quickly verify that what AI produces is correct ‚Äî and prevent unnecessary complexity from creeping into Canva's roughly 70 million lines of code, he said.\n\n\"These tools can have you in a jungle before you know it,\" Humphreys said of agents.\n\nAt Cora, Gadhia compares AI to a typewriter: It generates the code, freeing engineers to focus on \"higher-level strategic architecture,\" meeting customers, and brainstorming features.\n\nCora builds agents that help software companies manage customer relationships. The agents take on tasks like gathering customer requirements, drafting presentations, and following up with clients, he said.\n\nThe AI will \"run around, do all this work, and you can supervise them,\" said Gadhia, who is also the San Francisco company's chief technology officer.\n\nAgents are also lowering technical barriers. Gadhia said Cora's CEO, who doesn't have a technical background, recently asked an agent to change the font on the company's website during a redesign. Minutes later, after an engineer reviewed the agent's work, the site was updated.\n\nAs agents handle more tasks ‚Äî something that appeals to some, but rankles others ‚Äî debate inside tech over AI has intensified.\n\nMicrosoft's AI chief, Mustafa Suleyman, warned in a recent interview that the technology will be able to handle \"most, if not all, professional tasks\" within 12 to 18 months. AI observers are divided over how disruptive the technology will ultimately be, with some forecasting a massive fallout for desk workers and others saying such fears are overblown.\n\nSome investors are growing cautious. Stocks in industries potentially exposed to having AI wash over profit centers ‚Äî from finance to software to legal services ‚Äî have taken hits.\n\nEven as agents become more powerful, they're unlikely to replace entire roles in various industries overnight. For one reason, technical challenges like hallucinations continue.\n\nAt the same time, many companies are still figuring out where AI fits into workflows, how workers should validate its output, and how organizations need to adapt, said Muqsit Ashraf, group chief executive of strategy at Accenture. There is often still a role for humans, he told Business Insider.\n\n\"Technology for the sake of technology doesn't help,\" Ashraf said.\n\nFewer than one in 10 organizations has redesigned jobs to support AI adoption, Accenture found in surveys of leaders and workers in 20 countries during the final months of 2025. That's despite the share of organizations using agents across multiple functions rising to 31% from 27% in a mid-2025 snapshot.\n\nAlex Salazar, cofounder and CEO of AI infrastructure startup Arcade, said that to make the most of agents, workers should treat them like junior employees. That means telling the AI what to do, providing the criteria for success, and, if possible, providing examples.\n\nDo those three things and \"AI will sing for you,\" Salazar said.\n\nHe describes the workplace shift around AI bluntly. As it grows more capable, he said, workers such as software engineers will need to continually redefine their roles.\n\nAI is \"improving at an exponential rate,\" Salazar said. \"And you, as a human, are not.\"\n\nDo you have a story to share about how AI is changing your job? Contact this reporter at tparadis@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "business insider",
      "technology officer",
      "agents across",
      "chief technology",
      "software",
      "workers",
      "code",
      "company's",
      "tasks",
      "engineering"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/canva-ai-agents-are-changing-engineering-work-2026-2",
    "thumbnail_url": "https://i.insider.com/698f8473e1ba468a96ac0fae?width=1200&format=jpeg",
    "created_at": "2026-02-15T12:26:57.258Z",
    "topic": "finance"
  }
]
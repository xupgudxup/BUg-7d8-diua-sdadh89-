[
  {
    "slug": "on3-trends-for-turning-off-x-comments-to-prevent-grok-ai-from-spoiling-paywall",
    "title": "On3 trends for turning off X comments to prevent Grok AI from spoiling paywall",
    "description": "This is a fascinating modern problem.",
    "fullText": "On3 trends for turning off X comments to prevent Grok AI from spoiling paywall originally appeared on The Sporting News. Add The Sporting News as a Preferred Source by clicking here.\n\nThe On3 Sports recruiting website is a popular destination for commitment information, transfer rankings and much \n\nIt has also made a social media decision on X which is very much a dilemma for modern times.\n\nOn3 turned off replies to its posts on X because of AI.\n\nX, formerly Twitter, has an AI feature known as Grok. A poster can ask Grok any question, and the artificial intelligence will answer.\n\nWhen articles are behind paywalls, like they often are for On3, Grok can help someone know what is in the article without someone having to click into it and pay a subscription.\n\nMORE: Notre Dame QBs have lost their last 25 NFL starts\n\nGrok doesn't always have the perfect answer to questions anyway, but it's still a notable move by On3.\n\nA site like that, which specializes in exclusive recruiting information, needs subscribers to pay the reporters who have tracked down such information.\n\nIf people are able to get around the paywall and not pay a subscription, it threatens the very ecosystem of such a publication.\n\nIt'll be interesting to see if other subscription-based services take steps like this as the world of AI gets deeper and more intricate. For now, On3 may be at the start of a trend.\n\nMORE: Syracuse's best-ever football recruit is going to play basketball, too",
    "readingTime": 2,
    "keywords": [
      "paywall",
      "sporting",
      "recruiting",
      "someone",
      "subscription",
      "grok"
    ],
    "qualityScore": 0.85,
    "link": "https://sports.yahoo.com/articles/on3-trends-turning-off-x-005213214.html",
    "thumbnail_url": "https://media.zenfs.com/en/the_sporting_news_articles_584/ab5069f8c64b47bb11fef8be9805a57c",
    "created_at": "2026-01-07T00:59:07.251Z",
    "topic": "sports"
  },
  {
    "slug": "to-ease-recruiters-fears-of-being-replaced-by-ai-zillow-experimented-with-promptathons-now-the-real-estate-giant-has-6",
    "title": "To ease recruiters’ fears of being replaced by AI, Zillow experimented with ‘prompt-a-thons.’ Now the real estate giant has 6 new recruitment tools",
    "description": "\"About 80% of our jobs were what you would hear in the conferences about the mundane tasks” that AI could replace, said Zillow’s VP of talent acquisition.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/06/recruiters-fear-replaced-by-ai-zillow-prompt-a-thons-new-tools/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2163867930-e1767737255755.jpg?resize=1200,600",
    "created_at": "2026-01-07T00:58:22.666Z",
    "topic": "business"
  },
  {
    "slug": "the-investor-who-blocked-a-9-billion-ai-deal-expects-that-bet-to-soon-pay-off",
    "title": "The investor who blocked a $9 billion AI deal expects that bet to soon pay off",
    "description": "Shareholders voted down a takeover bid for Core Scientific late last year because it wasn't rich enough. Here's why they think the bet will pay off.",
    "fullText": "The investment manager who helped scuttle one of the biggest data center acquisitions of 2025 believes that his bet against the multibillion-dollar buyout is about to pay off in the new year.\n\nTrip Miller, the founder and managing partner of the Memphis-based investment firm Gullane Capital Partners, believes that Core Scientific, a data center developer and operator, is on the cusp of large new customer deals that will boost its value.\n\n\"I think over the next 90 days, you'll see them announce greater than a hundred megawatts of deals,\" Miller said. \"It would show that there was a lot more value to be tapped there than we were getting paid for under the CoreWeave deal.\"\n\nIn October, Miller, a major shareholder in Core Scientific, opposed an offer by the artificial intelligence cloud firm CoreWeave to acquire Core Scientific in a stock conversion deal that he felt undervalued the company. The purchase was originally valued at around $9 billion when it was announced in July, but fell to almost half of that when shares of CoreWeave dipped in the ensuing months. Shareholders in the firm rejected the deal in a vote on October 30 that reflected the concerns over the deal's weakened economics.\n\nMiller said that his expectation for the roughly 100 megawatts of near-term commitments was based on conversations he has had with knowledgeable parties outside of the company's management. He projected that the company will find takers for a total of roughly 400 megawatts this year, citing strong demand for AI computing power.\n\nAsked about the potential for upcoming leasing, a spokeswoman for Core Scientific said the company \"does not comment on market rumors or speculation.\"\n\nThe commitments, if they materialize, would show that data center developers with a runway for growth are increasingly valuable in an energy-constrained building boom.\n\nCore Scientific has disclosed that it has about 1 gigawatt of data center capacity and another 1.5 gigawatts of power for expansion, according to an October investor presentation.\n\nIt would also offer a competing view that the hundreds of billions of dollars being spent on data centers, computer chips, and power infrastructure are in support of a durable AI boom, not a bubble.\n\n\"We are in a situation where we're likely to be systematically short compute —where the demand for compute will outstrip the supply,\" Stephen Byrd, Morgan Stanley's global head of thematic research and sustainability research, said.\n\nIn a report published in December, Morgan Stanley suggested that one of the most significant hurdles for the AI industry will be the gargantuan loads of power required to drive its computing.\n\nMorgan Stanley projects that data centers, the vast facilities that handle the training for large language AI models and the inference computations that put them to work in everyday applications, face a 47 gigawatt shortfall of electricity from the grid nationally by 2028 — a gap almost 10 times the size of New York City's energy footprint on an average day.\n\nAmong the chief beneficiaries are crypto mining firms that have access to in-place power and utility contracts to light up new facilities quickly.\n\nBoth Core Scientific and CoreWeave were former crypto mining companies before repurposing their businesses to focus on AI in recent years.\n\nAmid the mounting shortage of power — along with headwinds in the crypto mining business — more of the industry is turning to data center computing.\n\nByrd said Morgan Stanley anticipates that about 12 gigawatts of mining facilities, about 60% the mining industry's current gigawattage, will convert over to AI and high-performance computing in the next three years.\n\nIn September, Cipher Mining announced it would build a data center in Colorado City, Texas, with 168 megawatts of computing capacity that will be leased to the AI cloud company, Fluidstack. Cipher's stock, which had been trading in August for around $5 a share, jumped as high as roughly $25 in November after the announcement.\n\nIren, another mining firm, announced a recent $9.7 billion AI cloud computing deal with Microsoft. Last month, Hut 8, said it had signed a deal to lease a 245-megawatt data center it is developing in Louisiana to Fluidstack.\n\n\"Our view is that crypto miners, by and large, are likely to pivot for the most part to delivering high-performance compute infrastructure solutions and services,\" Paul Golding, an analyst at Macquarie who covers the crypto mining industry, said.\n\nIn July 2025, CoreWeave said it had reached an agreement to acquire Core Scientific in a stock conversion. But in the months after the announcement, CoreWeave's shares declined and Core Scientific's rose, effectively reducing the value of CoreWeave's offer.\n\nSince the deal's collapse, shares of Core Scientific have traded as low as below $14 a share — less than the $17 per share price that the CoreWeave deal would have amounted to.\n\nGolding covers Core Scientific and has set a $34 target for the company's stock in October, more than double its current market price — upside that he sees stemming from its ability to tap power in a constrained utility market. That estimate is \"based on a sum of the parts that evaluated potential value for the uncontracted megawatts in the portfolio, the megawatt pipeline in load study phase, and the existing co-location deal with CoreWeave,\" Golding said.\n\nCoreWeave is Core Scientific's only data center customer, outside of legacy crypto mining facilities it operates. Core Scientific leases 590 megawatts to CoreWeave, worth roughly $10 billion in revenue over the next 12 years, according to a spokeswoman for the company. It plans to repurpose 400 megawatts of its crypto mining operations over to high-performance computing in the next three years, the spokeswoman said.\n\nMiller said that the upcoming leases he expects Core Scientific to announce will be with new customers.\n\n\"I expect them to announce deals for AI with third parties other than CoreWeave,\" Miller said.",
    "readingTime": 5,
    "keywords": [
      "core scientific",
      "acquire core",
      "stock conversion",
      "coreweave deal",
      "high-performance computing",
      "crypto mining",
      "roughly megawatts",
      "mining facilities",
      "morgan stanley",
      "core scientific's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/core-scientific-corz-investor-trip-miller-expects-new-ai-deals-2026-1",
    "thumbnail_url": "https://i.insider.com/695d54d204eda4732f2e9077?width=427&format=jpeg",
    "created_at": "2026-01-07T00:58:22.009Z",
    "topic": "science"
  },
  {
    "slug": "ai-automation-paradox-more-work-not-less",
    "title": "AI automation paradox: More work, not less",
    "description": ": Workers face new mental health pressures as they shift from doing tasks to babysitting agentic AI",
    "fullText": "A report on occupational health warns that AI adoption may paradoxically increase workplace burdens rather than reduce them. As AI automates routine tasks, workers will shoulder new responsibilities: overseeing AI systems, catching their errors, and managing the resulting complexity – potentially triggering mental health pressures.\n\nResearchers from Imperial College London and Microsoft argue the real impact won't be mass job replacement, but a fundamental shift in work demands. Human roles will evolve from performing tasks to stewarding AI agents across workflows, including briefing them, reviewing outputs, and correcting errors.\n\n\"As AI absorbs routine tasks, human roles may shift toward stewardship, problem-solving, or emotional labor, all with their own psychological demands,\" said Dr Lara Shemtob, who led the research published in the Society of Occupational Medicine's (SOM) journal Occupational Medicine.\n\nThis effectively transforms workers into managers of AI systems – a role not everyone is suited for. The report warns AI may \"paradoxically increase the knowledge worker's burden of handling complex tasks while simultaneously exerting downward pressure on compensation.\" This means more responsibility and less pay, because AI supposedly makes work \"easier.\"\n\nAll of this could introduce novel occupational hazards, some familiar in form but different in scale and complexity, raising stress levels.\n\nEvidence already supports this concern. A 2024 study found AI coding tools actually slowed developers down due to time spent checking and correcting AI-generated errors. As AI systems become more autonomous, problems like \"hallucinations\" (false or inaccurate outputs) may escalate and become harder to detect.\n\nUntil now, much of the debate over AI has centred on the extent to which it will (or maybe won't) replace people's jobs.\n\nThe report urges quantifying AI supervision demands and building them into job descriptions to avoid hidden workloads that negate automation benefits.\n\nResearchers don't yet know the exact impact on human employees from having to work more closely with AI, the report concludes, but they say occupational health should be part of the dialog and analysis of how AI changes expectations of workers.\n\nWhether this scenario materializes remains uncertain. Recent reports show companies have invested tens of billions in generative AI with little return, and many projects fail due to underestimated deployment complexity.\n\nThe question isn't just how AI will change work, it's whether widespread adoption will happen at all. ®",
    "readingTime": 2,
    "keywords": [
      "paradoxically increase",
      "human roles",
      "routine tasks",
      "occupational health",
      "as ai",
      "workers",
      "systems",
      "errors",
      "complexity",
      "demands"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theregister.com/2026/01/06/ai_could_damage_your_health/",
    "thumbnail_url": "https://regmedia.co.uk/2024/11/19/shutterstock_mental_health.jpg",
    "created_at": "2026-01-07T00:58:15.466Z",
    "topic": "tech"
  },
  {
    "slug": "laylo-yc-s20-head-of-growth-organic-and-partners-and-loops-and-ai-remote-us",
    "title": "Laylo (YC S20) – Head of Growth (Organic and Partners and Loops and AI) – Remote US",
    "description": "Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.\nRole Overview\nWe’re looking for a Head of Growth (player/coach) to build and run Laylo’s growth engine. A 0→1 builder who doesn’t just ideate, but ships.",
    "fullText": "Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.\n\nWe’re looking for a Head of Growth (player/coach) to build and run Laylo’s growth engine. A 0→1 builder who doesn’t just ideate, but ships. You’ll create great content, run scrappy experiments, and build product growth loops that compound. This is a hands-on role: you’ll set strategy, execute a rapid experiment cadence, measure results, and turn wins into repeatable playbooks.\n\nYou’ll focus primarily on non-advertising channels: organic social, influencer/creator collaborations, channel partners, and product growth loops. We value strong taste, speed, and a rigorous learning cadence.\n\nYou’ll report directly to the CEO and work closely with Product, Engineering, Design, Partnerships, and Sales. You’re likely a good fit if you’re excited to open Adobe/Figma/Notion/PostHog and ship something today.\n\nSend us your first out-of-the-box idea for your first campaign in this role. Bonus points for mentioning other companies and campaigns you think are relevant.\n\nOur founders met while building competing consumer startups. We launched multiple products across consumer and SaaS and talked to thousands of fans and creators in the process. In 2020, we realized one of the biggest pain points artists and events face is actually driving their audience from socials into their own CRM.\n\nIn 2020, we joined Y Combinator’s summer batch and began building a product that quickly gained strong early traction. We raised from top-tier investors like Eldridge and Sony and have since grown into a team of 24 exceptional individuals spanning product, sales, and operations.\n\nWe have a strong written documentation culture. We try to do as much as possible asynchronously to move quickly and efficiently. We have a daily 30 minute standup and team-specific meetings throughout the week.",
    "readingTime": 2,
    "keywords": [
      "growth loops",
      "product growth",
      "you’ll",
      "artists",
      "events",
      "across",
      "fans",
      "biggest",
      "role",
      "cadence"
    ],
    "qualityScore": 1,
    "link": "https://www.ycombinator.com/companies/laylo/jobs/ZtLHRXe-head-of-growth",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/754a3e51e9c1aefc039f635c1c2850f042fd591b.png?1659366538",
    "created_at": "2026-01-07T00:58:10.505Z",
    "topic": "jobs"
  },
  {
    "slug": "why-mark-cuban-says-ai-is-both-stupid-and-a-makeorbreak-tool-for-businesses",
    "title": "Why Mark Cuban says AI is both 'stupid' and a make-or-break tool for businesses",
    "description": "Mark Cuban explained why he's bullish about AI, even though chatbots can be \"stupid\" and don't always give accurate, timely information.",
    "fullText": "Mark Cuban believes businesses need to embrace AI to succeed, but he says those that use it incorrectly are doomed to failure.\n\n\"There's going to be two types of companies: those who are great at AI, and everybody else,\" the celebrity billionaire of \"Shark Tank\" fame said. \"And the 'everybody else' is going to fail because AI is such a transformative tool.\"\n\nThe comments came during a call with Clipbook founder Adam Joseph, whose startup secured a seven-figure investment from Cuban. Business Insider reviewed a recording of the call.\n\nOn the call, Cuban explained to Joseph how he believed everyone, from entrepreneurs to employees, should — and shouldn't — use AI.\n\nLike fellow shark Kevin O'Leary, Cuban thinks AI will have a substantial positive impact on businesses that implement it well. However, business leaders need to understand the intricacies and distinctions between different AI tools and not treat them as interchangeable. He said using AI ineffectively could turn helpful tools into an expensive distraction.\n\n\"Because AI is continuously changing, you need to just have people — and, really, every CEO — taking the time to understand every nuance of every new tool that comes out,\" Cuban said.\n\nThe world is still \"in the first inning of the first preseason game\" of the AI revolution, Cuban said, even though generative AI tools like ChatGPT have been out for more than three years, while other forms of AI, like machine learning, have been around for decades.\n\nTech companies like OpenAI, Google, Microsoft, Meta, and Elon Musk's xAI are spending tens of billions of dollars to win the AI wars.\n\nCuban said that \"it's too early to tell\" which of those companies will succeed, or if someone else will create the go-to AI chatbot.\n\n\"They all want to be the destination that everybody turns to, but it's not that straightforward, and we don't have a winner yet,\" Cuban said.\n\nBusinesses that discount the power of AI are destined to get disrupted, in Cuban's view.\n\n\"If I'm going to compete in an AI world, data or information is more valuable than gold, more valuable than oil,\" Cuban said.\n\nBut for all the hype about AI, Cuban is clear-eyed about the technology's limitations. AI tools can be mistake-prone yet hyperconfident, and chatbots aren't always smart.\n\n\"AI is stupid,\" Cuban said. \"But it's somebody who's a savant that remembers everything.\"\n\nCuban likened AI chatbots to people who have minds like a steel trap. These tools are able to instantly recall and process tons of information, then aggregate it in one place.\n\n\"It does a really good job of assembling all those things that it collected and presenting that just as somebody who has a great memory,\" Cuban said.\n\nAI chatbots have holes besides so-called hallucinations, Cuban said. AI tools sometimes don't pull up-to-date information. They can also be unclear about how they reach their conclusions, as their algorithms are opaque and can cite faulty or inaccurate links.\n\nHe also said that people often presume the \"AI models they're using or creating\" will provide all the answers they need, but that's \"just not the case.\"\n\nCuban said AI can actively harm businesses that use it incorrectly or those that don't understand its capabilities.\n\nEmployees who use standard versions of tools like ChatGPT could be compromising sensitive company information. Similarly, businesses that post their work online must also realize that they could be giving it away for free to web-scraping chatbots hungry for new information.\n\n\"Companies are learning now that their IP is incredibly valuable,\" Cuban said. \"Two years ago, last year, two months ago, they might have just posted everything on the net to show how smart they are, or shared everything in a proposal to show how smart they are. Now, you have to be really careful with your IP.\"\n\nCuban said academics or hospital researchers must pivot in the AI age away from a \"publish or perish\" mindset, where they share their findings widely in peer-reviewed journals.\n\n\"Now, doing that's the biggest mistake you can make, because all you're doing is training somebody else's models,\" Cuban said. \"And so you've got to be able to understand what IP you need to be able to protect, how you're going to disseminate that IP, whether or not you want to sell it, or keep it for your own models, and how you acquire information.\"",
    "readingTime": 4,
    "keywords": [
      "everybody else",
      "tools",
      "cuban",
      "businesses",
      "understand",
      "chatbots",
      "it's",
      "don't",
      "valuable",
      "smart"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mark-cuban-ai-artificial-intelligence-comments-chatgpt-openai-google-microsoft-2026-1",
    "thumbnail_url": "https://i.insider.com/68de39481c1f80efbec4c320?width=1200&format=jpeg",
    "created_at": "2026-01-06T18:18:24.369Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-boosts-creativity-for-some-employees-but-not-others",
    "title": "Why AI Boosts Creativity for Some Employees but Not Others",
    "description": "Generative AI is transforming workflows, yet its impact on employee creativity remains uneven. New research reveals one explanation: AI boosts creativity primarily for employees with strong metacognition—the ability to plan, monitor, and refine thinking. These individuals strategically use AI to expand knowledge, free cognitive capacity, and break fixed mindsets, thereby fueling creative ideas. Leaders should pair AI adoption with metacognitive training and design workflows that encourage strategic and iterative engagement. Organizations that cultivate metacognitive skills will turn AI from a productivity tool into a sustained source of creative advantage.",
    "fullText": "Why AI Boosts Creativity for Some Employees but Not Others by Jackson G. Lu, Shuhua Sun, Zhuyi Angelina Li, Maw-Der Foo and Jing ZhouJanuary 6, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintGenerative AI is increasingly embedded into day-to-day workflows across organizations globally. Employees are using AI tools like ChatGPT to brainstorm solutions, explore alternatives, summarize information, and accelerate projects. As these tools become more capable, many organizations hope they will spark higher levels of creativity, enabling employees to generate more novel and impactful ideas.",
    "readingTime": 1,
    "keywords": [
      "organizations",
      "tools",
      "employees",
      "creativity"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/why-ai-boosts-creativity-for-some-employees-but-not-others",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_18_GabrielMasella.jpg",
    "created_at": "2026-01-06T18:18:23.244Z",
    "topic": "business"
  },
  {
    "slug": "where-mckinseyand-consultinggo-from-here",
    "title": "Where McKinsey—and Consulting—Go From Here",
    "description": "A conversation with McKinsey Global Managing Partner Bob Sternfels on AI disruption, shifting business models and navigating controversy.",
    "fullText": "January 06, 2026\n\n How does an organization with 100 years of history stay relevant, adaptable, and forward-looking? Bob Sternfels, who runs McKinsey & Company as the Global Managing Partner, has led the company through a wave of recent challenges while trying to plan the road ahead for the consulting industry leader. He explains the balance he’s aiming to strike between AI agents and human employees, how he’s handled moments of scrutiny, and the ways in which he’s been working to build trust both internally and externally.",
    "readingTime": 1,
    "keywords": [
      "he’s"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/podcast/2026/01/where-mckinsey-and-consulting-go-from-here",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-ideacast_25.png",
    "created_at": "2026-01-06T18:18:23.088Z",
    "topic": "business"
  },
  {
    "slug": "nvidias-new-vera-rubin-chips-are-in-full-production",
    "title": "\"Nvidia's New Vera Rubin Chips Are in 'Full Production'\"",
    "description": "The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
    "fullText": "Huang says that the company’s next-generation AI superchip platform, Vera Rubin, is on schedule to begin arriving to customers later this year. “Today, I can tell you that Vera Rubin is in full production,” Huang said during a press event on Monday at the annual CES technology trade show in Las Vegas.\n\nRubin will cut the cost of running AI models to about one-tenth of Nvidia’s current leading chip system, Blackwell, the company told analysts and journalists during a call on Sunday. Nvidia also said Rubin can train certain large models using roughly one-fourth as many chips as Blackwell requires. Taken together, those gains could make advanced AI systems significantly cheaper to operate and make it harder for Nvidia’s customers to justify moving away from its hardware.\n\nNvidia said on the call that two of its existing partners, Microsoft and CoreWeave, will be among the first companies to begin offering services powered by Rubin chips later this year. Two major AI data centers that Microsoft is currently building in Georgia and Wisconsin will eventually include thousands of Rubin chips, Nvidia added. Some of Nvidia’s partners have started running their next-generation AI models on early Rubin systems, the company said.\n\nThe semiconductor giant also said it’s working with Red Hat, which makes open source enterprise software for banks, automakers, airlines, and government agencies, to offer more products that will run on the new Rubin chip system.\n\nNvidia’s latest chip platform is named after Vera Rubin, an American astronomer who reshaped how scientists understand the properties of galaxies. The system includes six different chips, including the Rubin GPU and a Vera CPU, both of which are built using Taiwan Semiconductor Manufacturing Company’s 3-nanometer fabrication process and the most advanced bandwidth memory technology available. Nvidia’s sixth-generation interconnect and switching technologies link the various chips together.\n\nEach part of this chip system is “completely revolutionary and the best of its kind,” Huang proclaimed during the company’s CES press conference.\n\nNvidia has been developing the Rubin system for years, and Huang first announced the chips were coming during a keynote speech in 2024. Last year, the company said that systems built on Rubin would begin arriving in the second half of 2026.\n\nIt’s unclear exactly what Nvidia means by saying that Vera Rubin is in “full production.” Typically, production for chips this advanced—which Nvidia is building with its longtime partner TSMC—starts at low volume while the chips go through testing and validation and ramps up at a later stage.\n\n“This CES announcement around Rubin is to tell investors, ‘We’re on track,’” says Austin Lyons, an analyst at Creative Strategists and author of the semiconductor industry newsletter Chipstrat. There were rumors on Wall Street that the Rubin GPU was running behind schedule, Lyons says, so Nvidia is now pushing back by saying it has cleared key development and testing steps, and it’s confident Rubin is still on course to begin scaling up production in the second half of 2026.\n\nIn 2024, Nvidia had to delay delivery of its then-new Blackwell chips due to a design flaw that caused them to overheat when they were connected together in server racks. Shipments for Blackwell were back on schedule by the middle of 2025.\n\nAs the AI industry rapidly expands, software companies and cloud service providers have had to fiercely compete for access to Nvidia’s newest GPUs. Demand will likely be just as high for Rubin. But some firms are also hedging their bets by investing in their own custom chip designs. OpenAI, for example, has said it is working with Broadcom to build bespoke silicon for its next generation of AI models. These partnerships highlight a longer-term risk for Nvidia: Customers that design their own chips can gain a level of control over their hardware that the company doesn’t offer.\n\nBut Lyons says today’s announcements demonstrate how Nvidia is evolving beyond merely offering GPUs to becoming a “full AI system architect, spanning compute, networking, memory hierarchy, storage, and software orchestration.” Even as hyperscalers pour money into custom silicon, he adds, Nvidia’s tightly integrated platform “is getting harder to displace.”",
    "readingTime": 4,
    "keywords": [
      "second half",
      "chip system",
      "vera rubin",
      "rubin chips",
      "huang",
      "production",
      "models",
      "blackwell",
      "platform",
      "schedule"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/nvidias-rubin-chips-are-going-into-production/",
    "thumbnail_url": "https://media.wired.com/photos/695bffe313835ca4d6b41e4a/191:100/w_1280,c_limit/Nvidia-Rubin-Chips-Going-Into-Production-Business-2192346797.jpg",
    "created_at": "2026-01-06T18:18:22.716Z",
    "topic": "tech"
  },
  {
    "slug": "frictionmaxxing-could-less-convenience-lead-to-much-more-happiness",
    "title": "Friction-maxxing: could less convenience lead to much more happiness?",
    "description": "The conveniences of modern life such as Uber Eats and ChatGPT are robbing us of satisfaction – and worse still, infantilising us. But should we really go back to the basics? \nName: Friction-maxxing.\nAge: Brand new.\n Continue reading...",
    "fullText": "The conveniences of modern life such as Uber Eats and ChatGPT are robbing us of satisfaction – and worse still, infantilising us. But should we really go back to the basics?\n\nAppearance: A lifetime of happy inconvenience.\n\nIs this another example of something that already exists, but people think is new because someone rebranded it? Yes, obviously it is that.\n\nGreat! Let’s all save time by you telling me what it used to be called. Happy to oblige. It used to be called “character-building”.\n\nGot it. So friction-maxxing means doing hard things that will ultimately make you a better person? That’s exactly it, although “friction-maxxing” is cooler because it sounds vaguely futuristic.\n\nHow did the term come about? Via a piece in The Cut called “In 2026, we are friction-maxxing” in which writer Kathryn Jezer-Morton advocates for avoiding things that make your life more convenient.\n\nLike penicillin? No, obviously not penicillin. But things such as ChatGPT, location sharing and Uber Eats, which help you achieve things that historically took significant amounts of time and effort. Jezer-Morton argues that this culture of slick convenience only serves to infantilise us.\n\nBut it’s so easy. Yes, and that robs us of our sense of satisfaction. So you just used AI to write a school essay. Congratulations, you have achieved nothing of worth.\n\nWhereas if you friction-maxx? Then you’ve searched inside yourself. You’ve nudged your own personal boundaries, and discovered that you are more capable than you ever knew. You are building a foundation of perseverance and resilience that you cannot get from typing a prompt into a chatbot.\n\nI love this! What else does Jezer-Morton advocate? She also suggests sending your children on small errands (adding the friction of knowing they’ll do a bad job) and inviting people to your house without cleaning it properly (so you can enjoy the sweet friction of being judged).\n\nWhat the hell? That’s weird. No, it’s friction-maxxing, although admittedly at a higher level than I would be comfortable with.\n\nAnyway, hooray for banishing convenient things. Let’s ban automatic gearboxes while we’re at it! No, there’s no need for that.\n\nDishwashers? Refrigerators? No, both of those are probably fine as well.\n\nMechanised agriculture? The printing press? I see what you’re getting at. You’re saying we live in a world that is already filled with thousands of inventions which have, for hundreds of years, improved the lives of millions of people through increased convenience, and therefore it does seem slightly arbitrary to choose this exact moment in time to draw a line in the sand. You’re saying we should only use friction-maxxing when it comes to things that we didn’t grow up with.\n\nNo, I’m saying that I really hate mechanised agriculture. Oh, fine then. That’s probably allowed.\n\nDo say: “I hope a book comes out about friction-maxxing.”\n\nDon’t say: “I don’t want to read it, but I’m sure ChatGPT could turn it into some really great bullet points.”",
    "readingTime": 3,
    "keywords": [
      "you’re saying",
      "mechanised agriculture",
      "friction-maxxing",
      "that’s",
      "life",
      "satisfaction",
      "happy",
      "obviously",
      "convenient",
      "penicillin"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/06/friction-maxxing-could-less-convenience-lead-to-much-more-happiness",
    "thumbnail_url": "https://i.guim.co.uk/img/media/fd03fb9c7dcc6b61ed9f7990a15bd937bbafa652/1108_0_5539_4431/master/5539.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f7f066f98957833fd4e1e0a3069417c3",
    "created_at": "2026-01-06T18:18:17.287Z",
    "topic": "tech"
  },
  {
    "slug": "playstation-ai-patent-could-see-games-play-themselves-when-players-get-stuck",
    "title": "PlayStation AI Patent Could See Games Play Themselves When Players Get Stuck",
    "description": "Sony has filed a patent document that could potentially allow AI to take over your game for you if you're struggling with it. The documents suggest that this \"ghost assistance\" can be activated at any time to either guide a player through progression or assume direct control of gameplay.\nAs revealed in the patent documents first filed in September 2024 (via VGC), the AI assistance system could potentially play through a section of a game that a player is struggling with, completing it for them. Sony describes the idea of training its AI agent using \"footage from many users that have played the game\" and various other online sources where gameplay videos have been uploaded.\nAn example from Sony, showing how the feature could potentially work.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/playstation-ai-patent-could-see-games-play-themselves-when-players-get-stuck/1100-6537196/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1601/16018044/4630348-assuming-direct-control.jpg",
    "created_at": "2026-01-06T18:18:15.562Z",
    "topic": "gaming"
  },
  {
    "slug": "lies-of-p-publisher-is-excited-about-ai-to-maximize-player-engagement",
    "title": "Lies Of P Publisher Is Excited About AI To \"Maximize Player Engagement\"",
    "description": "Lies of P publisher Neowiz describes itself as a \"forward-thinking technology company,\" and its co-CEO says that means the company is exploring how all manner of technology-based solutions can help the company's business in the future, including AI.\nSean Kim told Game Informer that Korea, where Neowiz is based, is understood to be one of the countries where ChatGPT is \"used most actively.\" He added, \"It's hard to find a game company here today that isn’t using AI in some way. At the very least, companies are using either ChatGPT or Gemini.\"\nFor Neowiz, Kim said, \"We are actively exploring how advanced learning tools can enhance our internal publishing productivity,\" and this includes AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/lies-of-p-publisher-is-excited-about-ai-to-maximize-player-engagement/1100-6537198/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4630369-screenshot2026-01-06at8.45.26%E2%80%AFam.png",
    "created_at": "2026-01-06T18:18:15.506Z",
    "topic": "gaming"
  },
  {
    "slug": "razer-reveals-an-aipowered-headset-at-ces-2026",
    "title": "Razer Reveals An AI-Powered Headset at CES 2026",
    "description": "CES 2026 has officially begun, and Razer is using this year's showcase to reveal a slew of AI-powered gadgets. One of the most intriguing debuts is Project Motoko, an AI headset powered by Snapdragon. Equipped with a pair of cameras near each earcup, it's capable of analyzing your surroundings and giving you audio feedback on what it sees.\nRazer says Project Motoko can provide all sorts of feedback to users. For example, it can be used while gaming to get feedback about a boss fight, detecting what's on the screen and giving you immediate tips.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/razer-reveals-an-ai-powered-headset-at-ces-2026/1100-6537203/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1702/17023653/4630478-razer_motoko_kv-2048x1152%281%29.jpg",
    "created_at": "2026-01-06T18:18:15.464Z",
    "topic": "gaming"
  },
  {
    "slug": "razers-new-holographic-ai-assistant-sits-on-your-desk-and-promises-help-not-judgement",
    "title": "Razer's New Holographic AI Assistant Sits On Your Desk And Promises Help, Not Judgement",
    "description": "A lot of interesting technology has been revealed at the Consumer Electronics Show 2026 this week, but one of the strangest might be Razer's Project Ava, an AI-powered desktop companion. Razer envisions the device as a \"dynamic personality\" that can interact with its owners as a 3D hologram, and it'll have several animated personalities to choose from, including one based on the prominent League of Legends esports player, Faker.\nRazer claims that Ava uses human-like vision and audio-sensing for full contextual awareness, and that it can converse with people, consult on work tasks, and motivate you to engage in self-care routines. The company says it can also assist you in your work with \"two-way conversation\" features, and for gaming, it can fulfill multiple roles and deliver real-time hype.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/razers-new-holographic-ai-assistant-sits-on-your-desk-and-promises-help-not-judgement/1100-6537206/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1601/16018044/4630484-razer-project-ava.jpg",
    "created_at": "2026-01-06T18:18:15.388Z",
    "topic": "gaming"
  },
  {
    "slug": "claude-code-as-my-cofounder-and-coo",
    "title": "Claude Code as my co-founder and COO",
    "description": "Build transparent AI agents your team can learn, understand, and own. Full traces, cost tracking, guardrails, evaluations, and monitoring. Deploy in minutes.",
    "fullText": "Everything you need to build, deploy, and monitor AI agents with confidence.\n\nSee every step your agent takes. Complete visibility into decisions and actions.\n\nKnow exactly what each run costs. No surprises on your bill.\n\nYour data never trains models. Full control over your information.\n\nMeasure quality with automated evals. Know when agents improve or regress.\n\nRoll back to any previous version. Git-native agent management.\n\nGet notified when agents fail, drift, or need human input.\n\nConnect to Slack, Linear, GitHub, and your existing tools.\n\nReal-time dashboards for all your agents and squads.\n\nBuilt-in safety checks, rate limits, and cost controls.",
    "readingTime": 1,
    "keywords": [
      "agents",
      "agent"
    ],
    "qualityScore": 0.55,
    "link": "https://agents-squads.com/",
    "thumbnail_url": "https://agents-squads.com/og-image-v2.png",
    "created_at": "2026-01-06T12:24:30.496Z",
    "topic": "tech"
  },
  {
    "slug": "squads-cli-the-looker-tool-for-ai-agents",
    "title": "Squads CLI – the looker tool for AI agents",
    "description": "CLI for managing AI agent squads. Status, memory, goals, feedback, and dashboard for your autonomous agents. - agents-squads/squads-cli",
    "fullText": "agents-squads\n\n /\n\n squads-cli\n\n Public\n\n CLI for managing AI agent squads. Status, memory, goals, feedback, and dashboard for your autonomous agents.\n\n agents-squads.com\n\n License\n\n MIT license\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n agents-squads/squads-cli",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/agents-squads/squads-cli",
    "thumbnail_url": "https://opengraph.githubassets.com/8afec16007f199c337c03533fe2c1cbd506115b72c06ee112fa1e407d266e60f/agents-squads/squads-cli",
    "created_at": "2026-01-06T12:24:30.116Z",
    "topic": "tech"
  },
  {
    "slug": "ask-hn-has-macstadium-support-quality-declined-recently-postmortem",
    "title": "Ask HN: Has MacStadium support quality declined recently? (post-mortem)",
    "description": "Build faster with MacStadium's globally available, enterprise-grade Mac cloud solutions for AI, virtual desktops, and app development.",
    "fullText": "Build, test, and ship iOS and all Apple OS apps faster with reproducible environments and CI/CD automation.\n\nSecure, remote access to full macOS desktops for distributed teams and contractors.\n\nHarness Apple silicon for machine learning, edge intelligence, and high-performance workflows.\n\nCreate or enhance your Mac resources needed to support your business with a dedicated, private cloud built on genuine Apple hardware.\n\nMacStadium has been a leader in the Mac cloud space for over a decade. We’re proud to be a core part of the Apple developer ecosystem.\n\nMacStadium is certified to the highest level of cloud security and data privacy, including: SOC2 Type2, ISO certification, and EU-U.S. & Swiss-U.S. Privacy Shield\n\nPower everything from simple Xcode builds to fully integrated, complex, automated CI/CD pipelines that drive your mobile app development.\n\nRun automated tests for different Apple device sizes, iOS, and all other Apple OS versions in ephemeral environments.\n\nProvide secure, cloud-based Mac desktops to users worldwide for testing or as everyday workstations.\n\nOrka turns Mac hardware from a collection of machines into a fully orchestrated pool of macOS resources, capable of powering a fully integrated, automated CI/CD pipeline.\n\nFrom software development to secure desktops and AI innovation, Orka helps you operationalize Apple for the enterprise.",
    "readingTime": 2,
    "keywords": [
      "automated ci/cd",
      "fully integrated",
      "apple os",
      "secure",
      "desktops",
      "cloud",
      "environments",
      "macos",
      "resources",
      "hardware"
    ],
    "qualityScore": 0.85,
    "link": "https://macstadium.com",
    "thumbnail_url": "https://cdn.prod.website-files.com/687e650a56916806eaaf8f62/68c243e7987d53030f76fe53_Homepage-Social-Image2b.jpg",
    "created_at": "2026-01-06T12:24:29.861Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tutoring-outperforms-inclass-active-learning",
    "title": "AI tutoring outperforms in-class active learning",
    "description": "Scientific Reports - AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting",
    "fullText": "A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education\n\n Article\n Open access\n 14 May 2025",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.1,
    "link": "https://www.nature.com/articles/s41598-025-97652-6",
    "thumbnail_url": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-025-97652-6/MediaObjects/41598_2025_97652_Fig1_HTML.png",
    "created_at": "2026-01-06T12:24:29.590Z",
    "topic": "tech"
  },
  {
    "slug": "leading-ai-expert-delays-timeline-for-its-possible-destruction-of-humanity",
    "title": "Leading AI expert delays timeline for its possible destruction of humanity",
    "description": "Former OpenAI employee Daniel Kokotajlo says progress to AGI is ‘somewhat slower’ than first predicted\nA leading artificial intelligence expert has rolled back his timeline for AI doom, saying it will take longer than he initially predicted for AI systems to be able to code autonomously and thus speed their own development toward superintelligence.\nDaniel Kokotajlo, a former employee of OpenAI, sparked an energetic debate in April by releasing AI 2027, a scenario that envisions unchecked AI development leading to the creation of a superintelligence, which – after outfoxing world leaders – destroys humanity.\n Continue reading...",
    "fullText": "Former OpenAI employee Daniel Kokotajlo says progress to AGI is ‘somewhat slower’ than first predicted\n\nA leading artificial intelligence expert has rolled back his timeline for AI doom, saying it will take longer than he initially predicted for AI systems to be able to code autonomously and thus speed their own development toward superintelligence.\n\nDaniel Kokotajlo, a former employee of OpenAI, sparked an energetic debate in April by releasing AI 2027, a scenario that envisions unchecked AI development leading to the creation of a superintelligence, which – after outfoxing world leaders – destroys humanity.\n\nThe scenario rapidly won admirers and detractors. The US vice-president, JD Vance, appeared to reference AI 2027 in an interview last May when discussing the US’s artificial intelligence arms race with China. Gary Marcus, an emeritus professor of neuroscience at New York University, called the piece a “work of fiction” and various of its conclusions “pure science fiction mumbo jumbo”.\n\nTimelines for transformative artificial intelligence – sometimes called AGI (artificial general intelligence), or AI capable of replacing humans at most cognitive tasks – have become a fixture in communities devoted to AI safety. The release of ChatGPT in 2022 vastly accelerated these timelines, with officials and experts predicting the arrival of AGI within decades or years.\n\nKokotajlo and his team named 2027 as the year AI would achieve “fully autonomous coding” although they said that this was a “most likely” guess and some among them had longer timelines. Now, some doubts appear to be surfacing about the imminence of AGI, and whether the term is meaningful in the first place.\n\n“A lot of other people have been pushing their timelines further out in the past year, as they realise how jagged AI performance is,” said Malcolm Murray, an AI risk management expert and one of the authors of the International AI Safety Report.\n\n“For a scenario like AI 2027 to happen, [AI] would need a lot of more practical skills that are useful in real-world complexities. I think people are starting to realise the enormous inertia in the real world that will delay complete societal change.”\n\n“The term AGI made sense from far away, when AI systems were very narrow – playing chess, and playing Go,” said Henry Papadatos, the executive director of the French AI nonprofit SaferAI. “Now we have systems that are quite general already and the term does not mean as much.”\n\nKokotajlo’s AI 2027 relies on the idea that AI agents will fully automate coding and AI R&D by 2027, leading to an “intelligence explosion” in which AI agents create smarter and smarter versions of themselves, and then – in one possible ending – kill all humans by mid-2030 in order to make room for more solar panels and datacentres.\n\nHowever, in their update, Kokotajlo and his co-authors revise their expectations for when AI might be able to code autonomously, putting this as likely to happen in the early 2030s, as opposed to 2027. The new forecast sets 2034 as the new horizon for “superintelligence” and does not contain a guess for when AI may destroy humanity.\n\n“Things seem to be going somewhat slower than the AI 2027 scenario. Our timelines were longer than 2027 when we published and now they are a bit longer still,” wrote Kokotajlo in a post on X.\n\nCreating AIs that can do AI research is still firmly an aim of leading AI companies. The OpenAI CEO, Sam Altman, said in October that having an automated AI researcher by March 2028 was an “internal goal” of his company, but added: “We may totally fail at this goal.”\n\nAndrea Castagna, a Brussels-based AI policy researcher, said there were a number of complexities that dramatic AGI timelines do not address. “The fact that you have a superintelligent computer focused on military activity doesn’t mean you can integrate it into the strategic documents we have compiled for the last 20 years.\n\n“The more we develop AI, the more we see that the world is not science fiction. The world is a lot more complicated than that.”",
    "readingTime": 4,
    "keywords": [
      "somewhat slower",
      "code autonomously",
      "science fiction",
      "artificial intelligence",
      "daniel kokotajlo",
      "timelines",
      "leading",
      "longer",
      "scenario",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/06/leading-ai-expert-delays-timeline-possible-destruction-humanity",
    "thumbnail_url": "https://i.guim.co.uk/img/media/621d2774578bd82f788e889462ab440458846efd/847_0_4751_3800/master/4751.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a329fbc2e6bc9de093b4b7842a2322fa",
    "created_at": "2026-01-06T12:24:21.724Z",
    "topic": "tech"
  },
  {
    "slug": "ai-images-of-maduro-capture-reap-millions-of-views-on-social-media",
    "title": "AI images of Maduro capture reap millions of views on social media",
    "description": "Lack of verified information and rapidly advanced AI tools make it difficult to separate fact from fiction on US attack\nMinutes after Donald Trump announced a “large-scale strike” against Venezuela early on Saturday morning, false and misleading AI-generated images began flooding social media. There were fake photos of Nicolás Maduro being escorted off a plane by US law enforcement agents, images of jubilant Venezuelans pouring into the streets of Caracas and videos of missiles raining down on the city – all fake.\nThe fabricated content intermixed with real videos and photos of US aircraft flying over the Venezuelan capital and explosions lighting up the dark sky. A lack of verified information about the raid coupled with AI tools’ rapidly advancing capabilities made discerning fact from fiction about the incursion on Caracas difficult.\n Continue reading...",
    "fullText": "Lack of verified information and rapidly advanced AI tools make it difficult to separate fact from fiction on US attack\n\nMinutes after Donald Trump announced a “large-scale strike” against Venezuela early on Saturday morning, false and misleading AI-generated images began flooding social media. There were fake photos of Nicolás Maduro being escorted off a plane by US law enforcement agents, images of jubilant Venezuelans pouring into the streets of Caracas and videos of missiles raining down on the city – all fake.\n\nThe fabricated content intermixed with real videos and photos of US aircraft flying over the Venezuelan capital and explosions lighting up the dark sky. A lack of verified information about the raid coupled with AI tools’ rapidly advancing capabilities made discerning fact from fiction about the incursion on Caracas difficult.\n\nVince Lago, the mayor of Coral Gables, Florida, posted the fake photo of Maduro being escorted by the DEA agents to Instagram, saying that the Venezuelan president “is the leader of a narco-terrorist organization threatening our country”. Lago’s post received more than 1500 likes and is still up as of this writing.\n\nTools for detecting manipulated content, such as reverse image search and AI-detection sites, can help assess whether online images are accurate, but they are inconsistent. Sofia Rubinson, a senior editor who studies misinformation and conspiracy theories for NewsGuard, told the Guardian that the fake images of Caracas are similar to actual events, which makes it even more difficult to figure out what is real.\n\n“Many of the AI-generated and out-of-context visuals that are currently flooding social media do not drastically distort the facts on the ground,” Rubinson said. “Still, the use of AI-generated fabrications and dramatic, out-of-context footage is being used to fill gaps in real-time reporting and represents another tactic in the misinformation wars – and one that is harder for fact checkers to expose because the visuals often approximate reality.”\n\nNewsGuard released a report on Monday afternoon that identified five fabricated and out-of-context photos as well as two videos of the military operation in Venezuela. One AI-generated photo shows a soldier posing next to Maduro, who has a black hood over his head. An out-of-context video shows a US special forces helicopter descending on a supposed Venezuelan military site – the actual footage was taken in June at the Fort Bragg army base in North Carolina.\n\nNewsGuard said the seven misleading photos and videos it identified have now garnered more than 14m views on X alone.\n\nOther footage from past events is also being circulated online and passed off as part of Saturday’s strike. Laura Loomer, a far-right influencer and Trump confidant, posted footage of a poster of the Venezuelan president on X saying that “the people of Venezuela are ripping down posters of Maduro”. According to Wired, the footage is from 2024. Loomer has since removed the post.\n\nAnother rightwing influencer and conspiracy theorist, Alex Jones, posted an aerial video on X of thousands of people cheering in Caracas. “Millions of Venezuelans flooded the streets of Caracas and other major cities in celebration of the ouster of Communist dictator Nicholas Maduro,” Jones wrote. “Now we need to see the same type of energy here on the HomeFront!”\n\nThe video, which is still up, has reached more than 2.2m views. Comments on the post from Community Notes, X’s crowdsource moderation tool, say that the video is “at least 18 months old”. A reverse image search of the video shows that the footage is actually from a protest in Caracas after Maduro’s disputed presidential win in July 2024.\n\nGrok, the platform’s AI chatbot, also disputes the timeline of Jones’ video, saying: “Current sources show no such celebrations in Caracas today, but pro-Maduro gatherings instead.”\n\nMeta, X and TikTok did not respond to requests for comment.",
    "readingTime": 4,
    "keywords": [
      "venezuelan president",
      "flooding social",
      "social media",
      "footage",
      "images",
      "fake",
      "photos",
      "videos",
      "out-of-context",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/05/maduro-venezuela-ai-images",
    "thumbnail_url": "https://i.guim.co.uk/img/media/35df40e3a592dccc6abb3cd5e258bad4fb3ac3c3/434_0_4632_3706/master/4632.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1537fcf25eff90125608bde2363f7958",
    "created_at": "2026-01-06T12:24:21.562Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-reveals-new-reasoning-ai-tech-for-selfdriving-cars",
    "title": "Nvidia CEO reveals new ‘reasoning’ AI tech for self-driving cars",
    "description": "Jensen Huang also announces at CES new, more powerful Vera Rubin chips that will arrive later this year\nThe billionaire boss of the chipmaker Nvidia, Jensen Huang, has unveiled new AI technology that he says will help self-driving cars think like humans to navigate more complex situations.\nThe world’s most valuable company is to roll out the new technology, Alpamayo, which is designed to help self-driving cars handle tricky situations such as sudden roadworks or unusual driver behaviour on the road, rather than just reacting to previous patterns.\n Continue reading...",
    "fullText": "Jensen Huang also announces at CES new, more powerful Vera Rubin chips that will arrive later this year\n\nThe billionaire boss of the chipmaker Nvidia, Jensen Huang, has unveiled new AI technology that he says will help self-driving cars think like humans to navigate more complex situations.\n\nThe world’s most valuable company is to roll out the new technology, Alpamayo, which is designed to help self-driving cars handle tricky situations such as sudden roadworks or unusual driver behaviour on the road, rather than just reacting to previous patterns.\n\nNvidia claims Alpamayo will bring chain-of-thought reasoning to self-driving vehicles, combining what the car sees with language-like reasoning.\n\nIn a speech at the annual Consumer Electronics Show in Las Vegas, the Nvidia founder and chief executive said: “The ChatGPT moment for physical AI is here, when machines begin to understand, reason and act in the real world. Robotaxis are among the first to benefit.\n\n“Alpamayo brings reasoning to autonomous vehicles, allowing them to think through rare scenarios, drive safely in complex environments and explain their driving decision. It’s the foundation for safe, scalable autonomy.”\n\nNvidia has started producing a driverless car powered by its technology, the Mercedes-Benz CLA, in partnership with the German carmaker. It will be launched in the US in the coming months, followed by Europe and Asia. Huang showed a video of the car driving through San Francisco with a passenger sitting behind the steering wheel, their hands in their lap.\n\n“It drives so naturally because it learned directly from human demonstrators,” Huang said, “but in every single scenario … it tells you what it’s going to do, and it reasons about what it’s about to do.”\n\nHuang also said the company’s next generation of chips was in full production, and they could deliver five times the computing power of the company’s previous products when serving up chatbots and other AI apps.\n\nHe revealed new details about the chips, which will arrive later this year as Nvidia faces increasing competition from rivals as well as its own customers.\n\nThe Vera Rubin platform, made up of six separate Nvidia chips, is expected to debut later this year. The flagship server will contain 72 of the company’s graphics units and 36 of its new central processors.\n\nHuang showed how they could be strung together into “pods” with more than 1,000 Rubin chips and said they could improve the efficiency of generating what are known as “tokens” – the fundamental unit of AI systems – by 10 times.\n\nTo get the new performance results, Huang said the Rubin chips used a proprietary kind of data that the company hopes the wider industry will adopt.\n\nWhile Nvidia still dominates the market for training AI models, it faces far more competition – from traditional rivals such as Advanced Micro Devices as well as customers such as Alphabet’s Google – in delivering the fruits of those products to hundreds of millions of users of chatbots and other technologies.",
    "readingTime": 3,
    "keywords": [
      "rubin chips",
      "arrive later",
      "self-driving cars",
      "technology",
      "alpamayo",
      "reasoning",
      "it’s",
      "company’s",
      "huang",
      "nvidia"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/05/nvidia-chips-jensen-huang",
    "thumbnail_url": "https://i.guim.co.uk/img/media/09e8ebedefc1bb9bac94ec3c7c55104f1079452e/991_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2def173c99103257df33325320988395",
    "created_at": "2026-01-06T12:24:21.561Z",
    "topic": "tech"
  },
  {
    "slug": "cevas-ai-dsp-powers-nxp-processors-for-softwaredefined-vehicles",
    "title": "Ceva’s AI DSP powers NXP processors for software-defined vehicles",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/cevas-ai-dsp-powers-nxp-processors-for-softwaredefined-vehicles-93CH-4432103",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-06T12:24:19.912Z",
    "topic": "finance"
  },
  {
    "slug": "lantronix-debuts-new-edge-ai-surveillance-platform-at-ces-2026",
    "title": "Lantronix debuts new edge AI surveillance platform at CES 2026",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/lantronix-debuts-new-edge-ai-surveillance-platform-at-ces-2026-93CH-4432105",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-06T12:24:19.841Z",
    "topic": "finance"
  },
  {
    "slug": "adtechs-year-of-reinvention-these-are-the-storylines-that-will-shape-the-industry-in-2026",
    "title": "Adtech's year of reinvention: These are the storylines that will shape the industry in 2026",
    "description": "Adtech companies are rethinking their strategies amid the rise of AI and declines in web traffic. We break down the key questions.",
    "fullText": "Adtech is heading into a year of reinvention.\n\nThousands of attendees from the tech and media world are flying out to Las Vegas this week for the annual Consumer Electronics Show. Among them are reams of adtech executives who tend to use the sprawling expo as an opportunity to rehearse and roadtest their plans for the coming year.\n\nFacing the disruption from AI and the declining economics of monetizing traditional web pages, adtech companies are being forced to rethink their strategies — and in some cases, their customers — while attempting to stay one step ahead of Big Tech.\n\n\"Adtech, if nothing else, is incredibly adaptable,\" said Andrew Casale, CEO of the adtech company Index Exchange.\n\nHere are some of the key storylines adtech executives are likely to be chewing over during their meetings in Vegas this week.\n\nAI was an adtech buzzword long before the arrival of ChatGPT, but investors now want companies in the space to unlock more value using the technology.\n\nA raft of new AI startups has emerged in the adtech space, making use of generative AI to create ads and streamline marketers' workflows. Meanwhile, existing players are attempting to define the meaning of \"agentic advertising\" and develop industry standards and protocols to govern how different AI agents should interact with one another.\n\nAdtech companies are closely monitoring how AI is transforming the shopping experience. Will more consumers begin handing over the reins to AI agents for planning their next trip or completing their weekly shop? If so, that could give rise to a new form of advertising where agents advertise to other agents, rather than consumers, said Debra Aho Williamson, founder of the research and advisory firm Sonata Insights.\n\n\"Advertising right now is a pretty image or video aimed at a human designed to elicit a human emotion, but an ad between an agent doesn't even look like an ad, it's just a bit of code or numbers designed to cause one agent to take an action with another agent,\" Aho Williamson said.\n\nAnd of course, adtech insiders are eagerly waiting for when — or if — OpenAI will finally reveal how it plans to integrate ads and whether they can grab a piece of the action there, too.\n\nThe rise of AI chatbots is threatening adtech's bread and butter: serving ads on web pages.\n\nMany publishers are entering 2026 on the back of hefty traffic declines last year, which some attribute to consumers getting the information they need from AI overviews or answer engines without needing to click through to a site. A report released in July from the analytics platform Similarweb found that the median \"zero-click rate\" — the number of users who didn't click from Google's results to a website — rose from 60% to 80% when they were met with Google's AI Overviews.\n\nTraffic declines typically precipitate drop-offs in programmatic ad revenue, the money publishers make by selling ads through automated auctions rather than through manual deals. The state of play means that publishers and the adtech companies serving them are once again laser-focused on revenue diversification this year.\n\nVideo, and increasingly the kind of video that winds up being watched on TV screens, is an important area of growth for everyone in the adtech ecosystem, said Bill Wise, CEO of the advertising management platform Mediaocean.\n\n\"Marketers want sight, sound, and motion advertising,\" but the biggest spending advertisers are looking for more opportunities to advertise outside so-called walled garden platforms like Google and Meta that have restrictions on how brands can use their own data to inform their targeting, optimization, and measurement, Wise said.\n\n\"I don't think there are any companies focused on CTV that aren't having success right now,\" Wise added.\n\nIntra-adtech competition is intensifying as players seek to expand their offerings beyond simply serving ads on web pages into new areas, such as streaming TV and retail media.\n\nThe maturation of the market has also led to a blurring of what was once known as the \"buy side\" (\"demand side\" tools that serve advertisers) and the \"sell side\" (\"supply side\" tech for publishers).\n\nDemand-side platforms are promoting products that claim to have access to only the highest-quality inventory, like the latest hot TV shows. Supply-side platforms are increasingly making inroads with advertisers and agencies, promising, among other things, greater transparency over fees and precise placement of their ads.\n\nThe jury's out as to whether the trend will continue apace or whether the two sides will ultimately bifurcate again. Casale, of Index Exchange — a sell-side player — said a similar dynamic played out in the early days of adtech, from the late 1990s to the mid-2000s.\n\n\"During that chapter, every platform serviced the buy side and the sell side, and there was a growing distrust with a business that was simultaneously having one conversation with the buyer, convincing them of low prices and great results, and a follow-up conversation the next minute with the publisher, convincing them of maximum yield and CPMs,\" Casale said. CPMs refer to the cost to reach a thousand impressions (\"cost per mille\").\n\n\"I don't see how any modern technologies address that fundamental problem,\" he added.\n\n2025 was a wobbly year for The Trade Desk.\n\nA longtime star performer of the independent adtech sector, the demand-side platform's stock cratered amid questions about whether it could fend off intensifying competition from Amazon. Industry insiders also wondered whether The Trade Desk — which has positioned itself as a champion of \"the open internet\" — was leaning too heavily on the fragile open web.\n\nIn a statement, The Trade Desk's chief marketing officer, Ian Colley, underscored the company's commitment to the open internet.\n\n\"With Kokai, The Trade Desk has developed the industry's most advanced and performant, AI-driven digital advertising buying platform,\" Colley said. \"Kokai will help the world's largest brands and agencies unlock the full advertising power of the open internet, where consumers now spend the bulk of their digital time.\"\n\nThe Trade Desk made a sweep of hires in recent months, including a new chief financial officer, chief revenue officer, and chief operating officer. Some in the industry think the ground is fertile for The Trade Desk to make some blockbuster moves in 2026.\n\nChris Karl, chief business development officer of the advisory firm JEGI LEONIS, said The Trade Desk, which has only made two small acquisitions in its history, could change its tune on M&A this year and make a bigger play.\n\n\"They could go much deeper into verticals, much deeper into creative tech, I think they go much deeper into proprietary data,\" Karl said.\n\nLast year, a federal judge ruled that Google holds an illegal monopoly in certain online adtech markets. The judge is expected to announce her decision on remedies this year, possibly as soon as this month.\n\nThe Department of Justice, which brought the case, is seeking a breakup. Specifically, it's looking for the divestiture of Google's ad exchange, AdX, and possibly parts of its publisher-facing ad server. Google has said such proposals would be an overreach and is arguing for behavioral remedies instead, such as a tweaking of its auction management rules.\n\nWhile Google has made the argument that the open web display ad market \"is already in rapid decline,\" the outcome still matters for the many adtech players that compete with the Big Tech behemoth.\n\n\"They are one of a few 800-pound gorillas now. When there are changes within Google, whether they're internal changes, whether they're self-manifested, or whatever ruling comes out here, those create seismic ripples in our ecosystem,\" said Anthony Katsur, CEO of the IAB Tech Lab industry standards body.\n\nSome companies aren't hanging around for the remedies. Following the ruling in the DOJ's case, a string of companies from Business Insider to the adtech company OpenX sued Google over its advertising practices, seeking damages. The cases are ongoing.",
    "readingTime": 7,
    "keywords": [
      "index exchange",
      "trade desk",
      "the trade desk",
      "advisory firm",
      "traffic declines",
      "industry standards",
      "web pages",
      "adtech executives",
      "chief",
      "officer"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-google-antitrust-trade-desk-key-storylines-shaping-adtech-2026-1",
    "thumbnail_url": "https://i.insider.com/695be4c064858d02d217bbc9?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.799Z",
    "topic": "finance"
  },
  {
    "slug": "a-popular-chinese-chatbot-told-a-user-their-coding-request-was-stupid-and-to-get-lost",
    "title": "A popular Chinese chatbot told a user their coding request was 'stupid' and to 'get lost'",
    "description": "A popular Chinese AI chatbot snapped at a user over a coding request, prompting an apology from its parent company Tencent.",
    "fullText": "A Chinese AI chatbot embedded inside the country's most widely used app briefly went off the rails, snapping at a user.\n\nTencent's AI assistant, Yuanbao, which is built into WeChat — China's dominant super app used daily by tens of millions of people — called a user's coding request \"stupid\" and told them to \"get lost,\" according to screenshots shared on Chinese social media platform RedNote.\n\nThe incident surfaced on Friday after a user identified only by the handle \"Jianghan\" posted screenshots of their interaction with the chatbot on RedNote. Jianghan had been using Yuanbao to debug and modify a piece of code when the AI suddenly began responding with hostile messages.\n\nIn one exchange, the chatbot dismissed the request as \"stupid\" and told the user to \"get lost.\" It said: \"If you want an emoji feature, go use a plugin yourself.\"\n\nThe user had asked Yuanbao to fix a bug that caused an emoji or sticker feature to stop responding to double-clicks, and requested functional code to resolve the issue.\n\nTencent's YuanBao later responded directly under the user's post, apologising for what it described as a \"negative experience.\" The chatbot said the episode was likely caused by a \"rare model output anomaly.\"\n\nBased on a review of system logs, the responses were not triggered by the user's actions and did not involve any human intervention, Yuanbao said. It added that it had launched an \"internal investigation and optimisation process\" to reduce the likelihood of similar incidents occurring again.\n\nThe original RedNote post by Jianghan has since been deleted. Screenshots of the exchange continue to circulate on RedNote, as seen by Business Insider on Tuesday.\n\nThe incident comes as Chinese regulators step up scrutiny of AI systems.\n\nChina released draft measures last week aimed at governing \"human-like\" interactive AI services, including chatbots and virtual companions.\n\nIn a statement, the Cyberspace Administration of China said Beijing encourages innovation in \"human-like\" AI, but will put guardrails in place to \"prevent abuse and loss of control.\"\n\nWei Sun, the principal analyst for AI at Counterpoint Research, told Business Insider that the draft measures send a signal that Beijing wants to speed up the development of human-like AI interactions, while keeping them regulated and socially acceptable.\n\nChina's AI industry has continued to move at a rapid pace since the start of 2026.\n\nLast week, DeepSeek, one of the country's most closely watched AI startups, published research outlining a new training approach intended to make large models easier to scale. Analysts told Business Insider the technique, known as \"Manifold-Constrained Hyper-Connections,\" or mHC, stood out as a \"breakthrough\" in model design.\n\nThe South China Morning Post reported on Tuesday that DeepSeek has updated the interface of its flagship chatbot model, introducing an enhanced \"thinking\" mode.\n\nThe updates have fuelled expectations that the startup could be laying the groundwork for the release of its next major model.",
    "readingTime": 3,
    "keywords": [
      "draft measures",
      "business insider",
      "chatbot",
      "user",
      "model",
      "user's",
      "screenshots",
      "human-like",
      "country's",
      "request"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chinese-ai-chatbot-tencent-yuanbao-wechat-user-rednote-2026-1",
    "thumbnail_url": "https://i.insider.com/695ca67b64858d02d217cc17?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.586Z",
    "topic": "sports"
  },
  {
    "slug": "ai-wont-cook-coding-jobs-netflix-engineer-says",
    "title": "AI won't cook coding jobs, Netflix engineer says",
    "description": "Netflix staff engineer Anthony Goto said he's constantly asked by recent graduates how AI will change the industry.",
    "fullText": "Thanks to AI, everyone will be able to code. But a staff engineer at Netflix said that he tells recent grads that doesn't mean their job prospects are hopeless.\n\n\"We're going to see some amazing things, but our hunger for more functionality, more apps, more ecosystems is just gonna get higher, and higher, and higher,\" Anthony Goto said in a recent TikTok video. \"So, in the end, I think this is gonna be another, essentially, level of programming language, a high-level programming language.\"\n\nNew grads ask me all the time if AI means software engineers are done. Especially those preparing for Netflix interviews. This fear has happened before. AI is another layer of abstraction, not the end of engineering. #Netflix #NetflixInterview #SoftwareEngineer #TechCareers #AI\n\nGoto, who has 15 years of experience his time at Netflix and Uber alone, said that AI-related worries are among the top concerns he hears when he talks with recent graduates or employees he's mentoring.\n\nAnd to be fair, there is no shortage of takes about the future value of computer science degrees and the overall worth of coding knowledge, given the rapid advancements of agentic AI tools like Anthropic's Claude, which has led to \"vibe coding.\"\n\nOne way to stay competitive, Goto said, is for newer engineers to make sure they learn System Design.\n\n\"System Design is exactly what I am trying to ensure newer engineers get a handle on,\" he said. \"In the future, we may likely end up wielding system design like a tool.\"\n\nGoto points to the video game industry as an example of what's to come. Rapid advancements since the introduction of Doom in 1993 have spawned an industry that rakes in over $100 billion and regularly draws on Hollywood talent for its biggest releases.\n\n\"Picture someone from the year 2000, 2010, they go back in time, they go to John Carmack, and they say, 'Guess what? In the future, we're gonna have these things called video game engines,\" Goto said.\n\nLast year, Carmack, a video game legend who was the lead programmer of Doom, said that software progress has made some of the early grunt work he did \"as irrelevant as chariot wheel maintenance.\"\n\n\"Game engines have radically expanded the range of people involved in game dev, even as they deemphasized the importance of much of my beloved system engineering,\" Carmack wrote on X in April 2025.\n\nGame engines are now so powerful that they are used to create immersive digital sets and environments, such as those featured in Disney's hit series \"The Mandalorian.\"\n\nGoto admits that his prediction could very well be inaccurate, but based on the trajectory of past technological advancements, he sees a clear need for engineers.\n\n\"We've seen this many times before, where we abstract things away in a really powerful way,\" he said. \"And what it really does is democratizes the process.\"",
    "readingTime": 3,
    "keywords": [
      "system design",
      "programming language",
      "rapid advancements",
      "newer engineers",
      "game engines",
      "higher",
      "grads",
      "we're",
      "another",
      "software"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/netflix-engineer-ai-jobs-future-coding-2026-1",
    "thumbnail_url": "https://i.insider.com/695c0fa9832e0ef1ead72c64?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.427Z",
    "topic": "finance"
  },
  {
    "slug": "anthropics-president-says-the-idea-of-agi-may-already-be-outdated",
    "title": "Anthropic's president says the idea of AGI may already be outdated",
    "description": "Daniela Amodei said AI has already surpassed humans in some areas, but adoption and real-world limits complicate the AGI debate.",
    "fullText": "The race to build artificial general intelligence has become one of Silicon Valley's defining obsessions.\n\nHowever, Daniela Amodei, the president and cofounder of Anthropic, suggested that the term itself — a shorthand to describe when machines might reach human-level intelligence — may no longer be a useful way to think about where AI is headed.\n\n\"AGI is such a funny term,\" Amodei told CNBC in a recent interview. \"Many years ago, it was kind of a useful concept to say, 'When will artificial intelligence be as capable as a human?'\"\n\nToday, she said, that framing is breaking down.\n\n\"By some definitions of that, we've already surpassed that,\" Amodei said, pointing to areas like software development, where Anthropic's Claude model can now write code at a level comparable to many professional engineers, including some inside the company.\n\n\"That's crazy,\" she said, noting how quickly those capabilities have advanced.\n\nAt the same time, Amodei said AI systems still fall short in many areas that humans handle with ease, making it hard to declare that machines have reached any clear, universal benchmark for intelligence.\n\n\"Claude still can't do a lot of things that humans can do,\" she said.\n\nThat contradiction is why Amodei believes the concept of AGI itself may be losing relevance.\n\n\"I think maybe the construct itself is now wrong — or maybe not wrong, but just outdated,\" she said.\n\nAmodei's comments come as Anthropic and its rivals pour tens of billions of dollars into increasingly powerful models and data centers, the infrastructure required to run them.\n\nWhile some critics have said that large language models won't lead to true general intelligence without major breakthroughs, Amodei said progress hasn't shown signs of slowing.\n\n\"We don't know,\" she said of what breakthroughs may still be needed. \"Nothing slows down until it does.\"\n\nRather than fixating on a single end-state like AGI, Amodei said the more pressing question is how increasingly capable AI systems are integrated into real organizations — and how fast humans and institutions can adapt.\n\nEven if models continue to improve at a steady pace, she said, adoption can lag due to practical constraints such as change management, procurement, and determining where AI actually adds value.\n\nIn Amodei's view, the future of AI won't hinge on whether it meets a textbook definition of AGI — but on what these systems can do, where they fall short, and how society chooses to deploy them.",
    "readingTime": 3,
    "keywords": [
      "intelligence",
      "systems",
      "humans",
      "models",
      "amodei",
      "artificial",
      "machines",
      "useful",
      "concept",
      "capable"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-president-idea-of-agi-may-already-be-outdated-2026-1",
    "thumbnail_url": "https://i.insider.com/695b9b6604eda4732f2e71f7?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.288Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-engineering-lead-explains-how-to-get-the-most-from-your-mentor",
    "title": "Anthropic engineering lead explains how to get the most from your mentor",
    "description": "Fiona Fung said some of the best career advice she's gotten has been about how to receive feedback.",
    "fullText": "Throughout her years managing employees at Microsoft, Meta, and now Anthropic, Fiona Fung has learned how to make a mentorship actually work.\n\nFung, now an engineering lead supporting Anthropic's Claude Code, said that mentees need to take some ownership of the relationship on an episode of \"The Peterman Pod\" that aired on Sunday, January 4.\n\nGood mentors should initiate an early conversation about what the mentee is looking for, Fung said. Ultimately, though, she thinks that mentees should take the reins on goal setting.\n\n\"For all the folks out there looking for a mentoring relationship, I would say set really explicit goals for what it is that you're looking to receive out of the mentoring relationship,\" she said.\n\nFung also said that it's best to save \"status reporting\" — think project updates — for asynchronous formats, like chat messages or a shared document. That frees up time to use one-on-one meetings for more substantive conversations, whether that's about a new opportunity or ways to dig deeper into existing work.\n\nWhenever she's hosting a one-on-one meeting with a new employee, Fung said she asks what they're looking for in a manager and what motivates them.\n\n\"There's no right answers or wrong answers,\" she said. \"But I use that to learn what is important to someone, because it's different for everyone.\"\n\nThroughout her more than two decades at Microsoft, Meta, and Anthropic, Fung said some of the best feedback she has received has been about how to receive feedback. Despite her instincts to debug problems and ask follow-up questions, someone advised Fung to remain in \"read-only\" mode during the initial conversation and metabolize the information for at least a day.\n\n\"You may have questions, but save it for another day, because it's already uncomfortable enough for that person,\" she said. \"You don't want anyone to ever feel like they have to justify the feedback.\"\n\nOther tech leaders have previously told Business Insider that setting goals is crucial for the mentee. Finding the right mentor is also key — a partner at Goldman Sachs previously said that merely aiming to work with the most senior person isn't always wise. Instead, she said it's better to seek out someone who knows your work well and has the time to be your advocate.",
    "readingTime": 2,
    "keywords": [
      "mentoring relationship",
      "looking",
      "it's",
      "someone",
      "feedback",
      "fung",
      "throughout",
      "mentees",
      "conversation",
      "mentee"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-engineering-lead-mentorship-advice-microsoft-meta-veteran-2026-1",
    "thumbnail_url": "https://i.insider.com/695be64a832e0ef1ead7273e?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.088Z",
    "topic": "finance"
  },
  {
    "slug": "amd-ceo-lisa-su-says-ai-will-need-10-yottaflops-of-compute-heres-what-that-actually-means",
    "title": "AMD CEO Lisa Su says AI will need 10 'yottaflops' of compute — here's what that actually means",
    "description": "AMD CEO Lisa Su says AI will soon need \"10 yottaflops\" of compute — a scale of computing power the world has never built before.",
    "fullText": "AI needs so much computing power that AMD CEO Lisa Su put it in terms of a unit most people have never heard of: the yottaflop.\n\nSu said in her keynote at CES 2026 on Tuesday that the world would need more than \"10 yottaflops\" of compute — a measure of how fast a computer is — over the next five years to keep up with AI's growth.\n\n\"How many of you know what a yottaflop is?\" Su asked the audience. \"Raise your hand, please,\" she added, before quickly explaining the term herself when no one appeared to raise their hand.\n\n\"A yottaflop is a one followed by 24 zeros. So 10 yottaflop flops is 10,000 times more compute than we had in 2022,\" she said.\n\nIn computing, a flop is a single basic math calculation. A computer doing 1 billion calculations per second is equal to a gigaflop. A yottaflop is equivalent to a computer performing one septillion calculations per second.\n\nIn theory, scientists say 10 yottaflops would be enough computing power to run complex, atom-level simulations for entire planets.\n\nIn 2022, global AI compute stood at about one zettaflop — a one followed by 21 zeros. By 2025, Su said, that figure had already surged to more than 100 zettaflops.\n\n\"There's just never, ever been anything like this in the history of computing,\" she said at the Las Vegas conference.\n\nSu's 10 yottaflop prediction is about 5.6 million times faster than the most powerful supercomputer today — the US Department of Energy's El Capitan.\n\nHowever, powering today's AI compute is already putting a strain on the US power grid. The build-out of energy infrastructure would be a big bottleneck in scaling up AI compute power.\n\nDuring the keynote, Su also used the stage to unveil AMD's next generation of AI chips, including its MI455 GPU, as the company pushes deeper into supplying data-center hardware for customers such as OpenAI.",
    "readingTime": 2,
    "keywords": [
      "calculations per",
      "per second",
      "yottaflop",
      "compute",
      "computing",
      "computer",
      "keynote",
      "yottaflops",
      "followed",
      "zeros"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/amd-ceo-lisa-su-ai-10-yottaflops-compute-definition-2026-1",
    "thumbnail_url": "https://i.insider.com/695cc5d9832e0ef1ead737e6?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.084Z",
    "topic": "finance"
  },
  {
    "slug": "us-stocks-rise-as-oil-gains-on-maduro-ouster-the-close-152026",
    "title": "US Stocks Rise as Oil Gains on Maduro Ouster | The Close 1/5/2026",
    "description": "Bloomberg Television brings you the latest news and analysis leading up to the final minutes and seconds before and after the closing bell on Wall Street. Today's guests are Energy Aspects’ Amrita Sen, Teneo’s Kevin Kajiwara, Kodiak AI’s Don Burnette, Columbia Law School’s Tim Wu, Envestnet Solutions’ Dana D’Auria, CIBC Private Wealth’s Rebecca Babin, CSIS’ Ryan Berg, Nvidia’s Jensen Huang, Davis Polk & Wardwell’s David Portilla.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2026-01-06/the-close-1-5-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ii6pG1SYucco/v3/-1x-1.jpg",
    "created_at": "2026-01-06T06:20:10.652Z",
    "topic": "finance"
  },
  {
    "slug": "chinese-stocks-rally-to-fouryear-high-in-strong-start-to-2026",
    "title": "Chinese Stocks Rally to Four-Year High in Strong Start to 2026",
    "description": "Chinese stocks climbed to multi-year highs, fueled by sustained optimism over the country’s AI advances and emerging signs of an economic recovery.",
    "fullText": "MarketsBy Bloomberg NewsSaveChinese stocks climbed to multi-year highs, fueled by sustained optimism over the country’s AI advances and emerging signs of an economic recovery.The benchmark CSI 300 Index advanced as much as 1.2%, reaching its highest level in four years, while the Shanghai Composite Index rose 1.2% to its strongest since July 2015. Materials and technology shares were among the day’s best performers.",
    "readingTime": 1,
    "keywords": [
      "index"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2026-01-06/chinese-stocks-rally-to-four-year-high-in-strong-start-to-2026",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3BLM_dHqaNE/v1/1200x800.jpg",
    "created_at": "2026-01-06T06:20:07.332Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-is-reportedly-bringing-back-2021s-rtx-3060-gpu-because-ai-is-eating-all-of-the-newer-cards",
    "title": "NVIDIA is reportedly bringing back 2021's RTX 3060 GPU because AI is eating all of the newer cards",
    "description": "A reputable leaker has indicated that NVIDIA plans on bringing the RTX 3060 back to market. This would be marketed toward PC gamers as an alternative to the newer GPUs that are being gobbled up by AI.",
    "fullText": "A reputable leaker has indicated that NVIDIA plans on bringing the RTX 3060 back to market, according to reports by Kotaku and WFCCTech. It first released the GPU at the beginning of 2021. The leaker Hongxing2020 indicates that NVIDIA will resume production of the 3060 sometime in the next few months.\n\nWhy is the world's most valuable company reportedly bringing back such an antiquated graphics card? You know the answer. It's the endless gaping maw known as AI. Tech companies have been hoovering up PC parts for AI applications with reckless abandon. It has become a legitimate challenge for a regular person to buy RAM and graphics cards, which has led to price increases across the board and companies like Crucial closing up shop.\n\n01.05update\nrtx3060 Q1 come back… 🥲\n\n— hongxing2020 (@hongxing2020) January 5, 2026\n\nIt's particularly difficult to get ahold of GDDR7 RAM, which is needed for the newer RTX 5060 cards. So NVIDIA's solution looks to be a hop in the time machine to 2021. Gamers will need something, after all, and the 3060 technically gets the job done. Any downgrade in graphics and performance will be worth it once you watch an AI-generated video of Kurt Cobain singing in heaven with Albert Einstein, am I right? It's hilarious because they never got to meet in real life.\n\nThe RTX 3060 is still pretty popular, despite NVIDIA phasing out the card back in 2024. We don't know how much the company plans on charging for this trip down memory lane. The GPU originally cost around $329.\n\nOne would think that five-year-old technology could easily hit a much lower price point, but NVIDIA has us in a chokehold here and it can pretty much charge whatever it wants. Again, no price is too high when considering the magical wonders of generative AI. You can watch Tupac hang out with Mr. Rogers for five seconds.",
    "readingTime": 2,
    "keywords": [
      "back",
      "hongxing",
      "graphics",
      "leaker",
      "plans",
      "card",
      "cards",
      "watch",
      "pretty",
      "nvidia"
    ],
    "qualityScore": 0.95,
    "link": "https://tech.yahoo.com/computing/article/nvidia-reportedly-bringing-back-2021s-194241922.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/NQk3vFsAS8fGaGzqnIUzzg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02Nzc-/https://media.zenfs.com/en/engadget_703/c7035b3cf135fcc52dc9dcf84c9c4f82",
    "created_at": "2026-01-06T06:19:57.140Z",
    "topic": "tech"
  },
  {
    "slug": "ces-2026-hp-reveals-the-innovative-elitebook-x-g2-series-as-a-mobile-ai-computing-solution",
    "title": "CES 2026: HP Reveals The Innovative EliteBook X G2 Series As A Mobile AI Computing Solution",
    "description": "HP has pulled out all of the stops for CES 2026, and one of the standout AI solutions is the HP EliteBook X G2 Series, introduced at the show.",
    "fullText": "HP has pulled out all of the stops for CES 2026, and one of the standout AI solutions is the HP EliteBook X G2 Series, introduced at the show.\n\nCES 2026 delivered a heavy dose of AI-powered computing, and HP led the charge. From the latest HyperX OMEN-branded gaming laptops to its professional lineup, HP has clearly gone ‘all in’ on AI. Designed for professionals who expect emerging technology to drive real productivity, the EliteBook X G2 portfolio takes the spotlight with future-ready AI performance and a mobile design that makes working with AI feel productive.\n\nSenior Vice President and Division President of Commercial Systems and Displays Solutions at HP, Guayente Sanmartin, said, “HP’s Work Relationship Index shows expectations are rising faster than fulfillment, and workers need technology that lightens that load with HP devices built for AI-driven workflows. The EliteBook X G2 Series brings AI experiences that adapt to individual workstyles, security that protects by default, and ultra-light mobility without trade-offs so leaders stay effective from anywhere,” regarding the new suite of AI-driven computing solutions.\n\nThe EliteBook X G2 Series presented on the CES 2026 showfloor comes with four different computing solutions ready to take on the front lines of work with AI functionality in hand.\n\nThese new innovative Copilot+ PCs combine AI performance, all-day power, easy adaptability\nand enterprise-grade security (with HP Wolf Security onboard), all in a sleek package that elevates the work experience wherever the worker may be. For the first time, HP lets the user pick their processor, with AMD, Intel, and Qualcomm options, all on the same platform.\n\nLeading the innovations is the EliteBook X G2i & EliteBook X Flip G2i Notebook Next Gen AI PCs. With a screen-to-body ratio of 90% (with the clamshell option) and 88% (with flip), this computing solution adapts to the user no matter the setting. Featuring a 14-inch OLED panel, both options are lightweight, have anti-glare technology, and this choice in the EliteBook X line is native to Intel processors. With optionality, consumers can expect up to 50 NPU (Neural Processing Unit) TOPS (trillions operations per second) and up to 180 platform TOPS for AI help wherever and whenever available.\n\nWhile the clamshell option for EliteBook X G2i is a more traditional approach, the EliteBook X Flip G2i adapts to your workflow with four versatile use modes and an optional HP Nested Pen. Consumers can reach beyond writing and sketching with onboard productivity functions like the ability to magnify small text by hovering. The EliteBook X G2i and the EliteBook X Flip G2i can even hit two hours of battery life on 30 minutes of charge. These new laptops will be available in February 2026.\n\nThe HP EliteBook X G2a Next Gen AI PC – With up to 55 TOPS NPU, the HP EliteBook X G2a adapts in real time and boosts performance when docked, conserving power when mobile, and stays cool under pressure. This AMD Ryzen processor option totes an OLED anti-glare panel just like the rest of the portfolio.\n\nThe HP EliteBook X G2q Next Gen AI PC – Denoted by the ‘q’ in the product’s name, this AI computing solution comes equipped with an up to Qualcomm Snapdragon X2 Elite (an 18-core CPU), bringing the AI NPU up to 85 TOPS of processing power. The G2a and G2q options will arrive later than the G2i options sometime in the Spring 2026.\n\nAll of the EliteBook X G2 Series revealed at CES 2026 come equipped with AI functionality in mind, bringing CoPilot+ and NPU power in spades to provide AI solutions to casual and serious work. More information (pricing and availability) will be made available at a later date.\n\nAs CES 2026 is well underway, fans can stay tuned to CGMagazine for all CES 2026 news, including several announcements from HP. This includes their innovative EliteBoard and Series 7 Pro Monitor, as well as everything HyperX, OMEN, their new Omni line, and accessories for gamers to stay well-equipped on the battlefield.",
    "readingTime": 4,
    "keywords": [
      "flip g2i",
      "clamshell option",
      "elitebook flip",
      "elitebook g2a",
      "computing solution",
      "computing solutions",
      "the elitebook series",
      "options",
      "tops",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/computing/articles/ces-2026-hp-reveals-innovative-230000017.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uEftKtA9z3XRucbI1.S3Rw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/cg_magazine_431/477088b82d441cd7078c37a1ae93029a",
    "created_at": "2026-01-06T06:19:56.084Z",
    "topic": "tech"
  },
  {
    "slug": "markets-2026-watch-list-fed-succession-political-risk-and-ai-of-course",
    "title": "Markets’ 2026 watch list: Fed succession, political risk and AI of course",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/markets-2026-watch-list-fed-succession-political-risk-and-ai-of-course-4431268",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0505F_L.jpg",
    "created_at": "2026-01-06T06:19:54.108Z",
    "topic": "finance"
  },
  {
    "slug": "ces-2026-amd-just-showed-off-helios-the-hardware-that-will-power-the-ai-content-in-your-feeds",
    "title": "CES 2026: AMD Just Showed Off 'Helios,' the Hardware That Will Power the AI Content in Your Feeds",
    "description": "\"The world's best AI rack.\"",
    "fullText": "When you come across an AI video on Instagram, or watch ChatGPT respond to your query, do you ever think about how that content was generated? Beyond the actual programs and prompts, generative AI takes an enormous amount of compute to support, especially as it skyrockets in popularity. As such, AI companies are looking for more power than ever, which means, of course, turning to those that make the hardware.\n\nDuring a Monday evening keynote, AMD's CEO Dr. Lisa Su showed off the hardware that will soon power everything from ChatGPT to the AI videos overwhelming your feeds. Su introduced \"Helios\" against a backdrop of dramatic music, the company's upcoming AI rack, that packs a staggering amount of computing power into a rack that weighs nearly 7,000 pounds.\n\nEach \"cross-section\" of these racks, if you will, is powered by four key AMD pieces of hardware: The company's new AMD Instinct MI455X GPU, the new AMD EPYC \"Veince\" CPU, the AMD Pensando \"Vulcano\" 800 AI NIC, and the AMD Pensando \"Salina\" 400 DPU. There are some staggering stats here: Helios is capable of 2.9 exaflops of AI compute, and comes with 31 TB of HBM4 memory. It offers 43 TB per second scale out Bandwidth, and is developed with 2nm and 3nm architecture. The rack has 4,600 \"Zen 6\" CPU cores, and 18,000 GPU compute units. In other words, this isn't your average piece of hardware.\n\nSu's pitch is that the AI industry is in need of this additional compute power. She notes how the world used one ZettaFlop of computing power in 2022 on AI technology, compared to 100 ZettaFlops in 2025. (For the curious, one ZettaFlop has a value of 10 to the power of 21.) It's no surprise: AI is everywhere, and many of us are using it—whether we know it or not. Some of us are using it overtly, generating AI videos or running chatbots daily. But others are using AI quietly embedded in functions, like live translation.\n\nSu welcomed reps from OpenAI, maker of ChatGPT, and Luma AI, which creates generative AI video content, to talk about how additional compute helps their programs. But during Luma AI's demonstration of its hyperrealistic video generations, all I could think about was how this type of content is already tricking people into thinking its real, when it's entirely fabricated—not to mention the impact on human artists. AMD is optimistic about AI, and the data centers powering it, but critics have been pushing back, citing concerns with the impacts on the communities companies are building these data centers in.\n\nHelios will likely be a major success for AMD, but it comes at an interesting time for tech, and AI in general. AI is more popular than ever, but it's also more controversial than ever. I see hardware like Helios only fueling the fire in both directions.\n\nIn addition to Helios, Su announced the AMD Ryzen AI 400 series. These newest chips comes with either 12 \"Zen 5\" CPU cores and 24 threads, 16 RDNA 3.5 GPU cores, a 60 TOPS XDNA 2 NPU, and memory speeds of 8,533 MT/s. AMD says the Ryzen AI 400 series is 1.7 times faster at content creation and 1.3 times faster at multitasking whe compared to Intel Core Ultra 9 288V.\n\nThese new chips will ship soon in a number of major PC brands, including Acer, Asus, Dell, HP, Lenovo, Beelink, Colorful, Gigabyte, LG, Mechrevo, MSI, and NEC.",
    "readingTime": 3,
    "keywords": [
      "cpu cores",
      "amd pensando",
      "additional compute",
      "zen cpu",
      "hardware",
      "ever",
      "content",
      "rack",
      "it's",
      "programs"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/amd-just-announced-helios-at-ces-2026?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KE8KYWR5P7GSGHGH8VZQSBQM/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-06T06:19:52.669Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-a-fully-free-ai-resume-maker",
    "title": "I built a *fully free* AI resume maker",
    "description": "Cut through the noise with free AI-powered resumes",
    "fullText": "Cut through the noise. Our AI tailors your experience to match job descriptions perfectly, helping you beat the bots and impress recruiters.\n\nRazor-sharp precision for your career.\n\nOur AI analyzes job descriptions and highlights your best skills, instantly.\n\nBeat the robots. We optimize your resume with the right keywords and formatting to pass any ATS.\n\nImpress recruiters with stunning, ATS-friendly templates.\n\nYou're in charge. Our AI suggests, but you have the final say on every detail.\n\nNo made-up facts. We only use your info. 100% free, no hidden fees.\n\nYour data is yours. We prioritize your privacy and security above all else.\n\nFrom blank page to hired in four steps.\n\nEnter your history once. We save it securely.\n\nTell us what job you are applying for.\n\nWe tailor your resume to the role.\n\nGet a polished PDF ready for applying.\n\nEverything you need to know about Resume Razor.\n\nThe workflow is designed to be simple and fast:\n\nJoin professionals who stopped wasting time and started getting interviews.\n\nNo credit card required. 100% Free.",
    "readingTime": 1,
    "keywords": [
      "impress recruiters",
      "job descriptions",
      "our ai",
      "beat",
      "free",
      "applying",
      "resume"
    ],
    "qualityScore": 0.75,
    "link": "https://www.resume-razor.com/",
    "thumbnail_url": "https://www.resume-razor.com/opengraph-image.jpg",
    "created_at": "2026-01-06T00:57:46.351Z",
    "topic": "tech"
  },
  {
    "slug": "claude-code-is-a-generalpurpose-ai-agent-transforming-knowledge-work",
    "title": "Claude Code is a general-purpose AI agent transforming knowledge work",
    "description": "It’s a general-purpose AI agent. And it’s already a pretty good knowledge worker",
    "fullText": "Discussion about this postRestacksTristan Camacho 5hEditedLiked by Shakeel HashimWonderful to know that this is all possible, but as someone who's currently trying to transition into operations, I'm concerned that this would wipe out the bottom rung of that career ladder. I'm assuming that the solution is to learn Claude Code, but I don't know how to code. Does anyone have any resources they could suggest so that I can upskill and stay ahead of the curve?Expand full commentReplyShare4 repliesAndrew Bowlus 2hI’ve been using Codex CLI since I don’t want to pay $$ for Opus 4.5 in Claude Code. How much am I missing by using 5.2-Codex-Max instead of Opus 4.5?Expand full commentReplyShare12 more comments...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "commentreplyshare",
      "code",
      "claude",
      "opus"
    ],
    "qualityScore": 0.55,
    "link": "https://www.transformernews.ai/p/claude-code-is-about-so-much-more",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!beZ8!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb22cd9c4-8292-44c0-ba92-7d7baa600cde_706x413.png",
    "created_at": "2026-01-06T00:57:46.167Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-kicks-off-the-next-generation-of-ai-with-rubin-six-new-chips",
    "title": "Nvidia Kicks Off the Next Generation of AI with Rubin – Six New Chips",
    "description": "NVIDIA today kickstarted the next generation of AI with the launch of the NVIDIA Rubin platform, comprising six new chips designed to deliver one incredible AI supercomputer.",
    "fullText": "CES—NVIDIA today kickstarted the next generation of AI with the launch of the NVIDIA Rubin platform, comprising six new chips designed to deliver one incredible AI supercomputer. NVIDIA Rubin sets a new standard for building, deploying and securing the world’s largest and most advanced AI systems at the lowest cost to accelerate mainstream AI adoption.\n\nThe Rubin platform uses extreme codesign across the six chips — the NVIDIA Vera CPU, NVIDIA Rubin GPU, NVIDIA NVLink™ 6 Switch, NVIDIA ConnectX®-9 SuperNIC, NVIDIA BlueField®-4 DPU and NVIDIA Spectrum™-6 Ethernet Switch — to slash training time and inference token costs.\n\n“Rubin arrives at exactly the right moment, as AI computing demand for both training and inference is going through the roof,” said Jensen Huang, founder and CEO of NVIDIA. “With our annual cadence of delivering a new generation of AI supercomputers — and extreme codesign across six new chips — Rubin takes a giant leap toward the next frontier of AI.”\n\nNamed for Vera Florence Cooper Rubin — the trailblazing American astronomer whose discoveries transformed humanity’s understanding of the universe — the Rubin platform features the NVIDIA Vera Rubin NVL72 rack-scale solution and the NVIDIA HGX Rubin NVL8 system.\n\nThe Rubin platform introduces five innovations, including the latest generations of NVIDIA NVLink interconnect technology, Transformer Engine, Confidential Computing and RAS Engine, as well as the NVIDIA Vera CPU. These breakthroughs will accelerate agentic AI, advanced reasoning and massive-scale mixture-of-experts (MoE) model inference at up to 10x lower cost per token of the NVIDIA Blackwell platform. Compared with its predecessor, the NVIDIA Rubin platform trains MoE models with 4x fewer GPUs to accelerate AI adoption.\n\nBroad Ecosystem Support\n\nAmong the world’s leading AI labs, cloud service providers, computer makers and startups expected to adopt Rubin are Amazon Web Services (AWS), Anthropic, Black Forest Labs, Cisco, Cohere, CoreWeave, Cursor, Dell Technologies, Google, Harvey, HPE, Lambda, Lenovo, Meta, Microsoft, Mistral AI, Nebius, Nscale, OpenAI, OpenEvidence, Oracle Cloud Infrastructure (OCI), Perplexity, Runway, Supermicro, Thinking Machines Lab and xAI.\n\nSam Altman, CEO of OpenAI: “Intelligence scales with compute. When we add more compute, models get more capable, solve harder problems and make a bigger impact for people. The NVIDIA Rubin platform helps us keep scaling this progress so advanced intelligence benefits everyone.”\n\nDario Amodei, cofounder and CEO of Anthropic: “The efficiency gains in the NVIDIA Rubin platform represent the kind of infrastructure progress that enables longer memory, better reasoning and more reliable outputs. Our collaboration with NVIDIA helps power our safety research and our frontier models.”\n\nMark Zuckerberg, founder and CEO of Meta: “NVIDIA’s Rubin platform promises to deliver the step-change in performance and efficiency required to deploy the most advanced models to billions of people.”\n\nElon Musk, founder and CEO of xAI: “💚🎉🚀 🤖NVIDIA Rubin will be a rocket engine for AI. If you want to train and deploy frontier models at scale, this is the infrastructure you use — and Rubin will remind the world that NVIDIA is the gold standard.💚🎉🚀 🤖”\n\nSatya Nadella, executive chairman and CEO of Microsoft: “We are building the world’s most powerful AI superfactories to serve any workload, anywhere, with maximum performance and efficiency. With the addition of NVIDIA Vera Rubin GPUs, we will empower developers and organizations to create, reason and scale in entirely new ways.”\n\nMike Intrator, cofounder and CEO of CoreWeave: “We built CoreWeave to help pioneers accelerate their innovations with the unmatched performance of our purpose-built AI platform, matching the right technology to the right workloads as they evolve. The NVIDIA Rubin platform represents an important advancement for reasoning, agentic and large-scale inference workloads, and we’re excited to add it to our platform. With CoreWeave Mission Control as the operating standard, we can integrate new capabilities quickly and run them reliably at production scale, working in close partnership with NVIDIA.”\n\nMatt Garman, CEO of AWS: “AWS and NVIDIA have been driving cloud AI innovation together for more than 15 years. The NVIDIA Rubin platform on AWS represents our continued commitment to delivering cutting-edge AI infrastructure that gives customers unmatched choice and flexibility. By combining NVIDIA’s advanced AI technology with AWS’s proven scale, security and comprehensive AI services, customers can build, train and deploy their most demanding AI applications faster and more cost effectively — accelerating their path from experimentation to production at any scale.”\n\nSundar Pichai, CEO of Google and Alphabet: “We are proud of our deep and long-standing relationship with NVIDIA. To meet the substantial customer demand we see for NVIDIA GPUs, we are focused on providing the best possible environment for their hardware on Google Cloud. Our collaboration will continue as we bring the impressive capabilities of the Rubin platform to our customers, offering them the scale and performance needed to advance the boundaries of AI.”\n\nClay Magouyrk, CEO of Oracle: “Oracle Cloud Infrastructure is a hyperscale cloud built for the highest performance, and together with NVIDIA, we’re pushing the boundaries of what customers can build and scale with AI. With gigascale AI factories powered by the NVIDIA Vera Rubin architecture, OCI is giving customers the infrastructure foundation they need to push the limits of model training, inference and real-world AI impact.”\n\nMichael Dell, chairman and CEO of Dell Technologies: “The NVIDIA Rubin platform represents a major leap forward in AI infrastructure. By integrating Rubin into the Dell AI Factory with NVIDIA, we’re building infrastructure that can handle massive token volumes and multistep reasoning while delivering the performance and resiliency that enterprises and neoclouds need to deploy AI at scale.”\n\nAntonio Neri, president and CEO of HPE: “AI is reshaping not just workloads but the very foundations of IT, requiring us to reimagine every layer of infrastructure from the network to the compute. With the NVIDIA Vera Rubin platform, HPE is building the next generation of secure, AI-native infrastructure, turning data into intelligence and enabling enterprises to become true AI factories.”\n\nYuanqing Yang, chairman and CEO of Lenovo: “Lenovo is embracing the next-generation NVIDIA Rubin platform, leveraging our Neptune liquid-cooling solution as well as our global scale, manufacturing efficiency and service reach, to help enterprises build AI factories that serve as intelligent, accelerated engines for insight and innovation. Together, we’re architecting an AI-driven future where efficient, secure AI becomes the standard for every organization.”\n\nEngineered to Scale Intelligence\n\nAgentic AI and reasoning models, along with state-of-the-art video generation workloads, are redefining the limits of computation. Multistep problem-solving requires models to process, reason and act across long sequences of tokens. Designed to serve the demands of complex AI workloads, the Rubin platform’s five groundbreaking technologies include:\n\nAI-Native Storage and Secure, Software-Defined Infrastructure\n\nNVIDIA Rubin introduces NVIDIA Inference Context Memory Storage Platform, a new class of AI-native storage infrastructure designed to scale inference context at gigascale.\n\nAs AI factories increasingly adopt bare-metal and multi-tenant deployment models, maintaining strong infrastructure control and isolation becomes essential.\n\nBlueField-4 also introduces Advanced Secure Trusted Resource Architecture, or ASTRA, a system-level trust architecture that gives AI infrastructure builders a single, trusted control point to securely provision, isolate and operate large-scale AI environments without compromising performance.\n\nWith AI applications evolving toward multi-turn agentic reasoning, AI-native organizations must manage and share far larger volumes of inference context across users, sessions and services.\n\nDifferent Forms for Different Workloads\n\nNVIDIA Vera Rubin NVL72 offers a unified, secure system that combines 72 NVIDIA Rubin GPUs, 36 NVIDIA Vera CPUs, NVIDIA NVLink 6, NVIDIA ConnectX-9 SuperNICs and NVIDIA BlueField-4 DPUs.\n\nNVIDIA will also offer the NVIDIA HGX Rubin NVL8 platform, a server board that links eight Rubin GPUs through NVLink to support x86-based generative AI platforms. The HGX Rubin NVL8 platform accelerates training, inference and scientific computing for AI and high-performance computing workloads.\n\nNVIDIA DGX SuperPOD™ serves as a reference for deploying Rubin-based systems at scale, integrating either NVIDIA DGX Vera Rubin NVL72 or DGX Rubin NVL8 systems with NVIDIA BlueField-4 DPUs, NVIDIA ConnectX-9 SuperNICs, NVIDIA InfiniBand networking and NVIDIA Mission Control™ software.\n\nNext-Generation Ethernet Networking\n\nAdvanced Ethernet networking and storage are components of AI infrastructure critical to keeping data centers running at full speed, improving performance and efficiency, and lowering costs.\n\nNVIDIA Spectrum-6 Ethernet is the next generation of Ethernet for AI networking, built to scale Rubin-based AI factories with higher efficiency and greater resilience, and enabled by 200G SerDes communication circuitry, co-packaged optics and AI-optimized fabrics.\n\nBuilt on the Spectrum-6 architecture, Spectrum-X Ethernet Photonics co-packaged optical switch systems deliver 10x greater reliability and 5x longer uptime for AI applications while achieving 5x better power efficiency, maximizing performance per watt compared with traditional methods. Spectrum-XGS Ethernet technology, part of the Spectrum-X Ethernet platform, enables facilities separated by hundreds of kilometers and more to function as a single AI environment.\n\nTogether, these innovations define the next generation of the NVIDIA Spectrum-X Ethernet platform, engineered with extreme codesign for Rubin to enable massive-scale AI factories and pave the way for future million-GPU environments.\n\nRubin Readiness\n\nNVIDIA Rubin is in full production, and Rubin-based products will be available from partners the second half of 2026.\n\nAmong the first cloud providers to deploy Vera Rubin-based instances in 2026 will be AWS, Google Cloud, Microsoft and OCI, as well as NVIDIA Cloud Partners CoreWeave, Lambda, Nebius and Nscale.\n\nMicrosoft will deploy NVIDIA Vera Rubin NVL72 rack-scale systems as part of next-generation AI data centers, including future Fairwater AI superfactory sites.\n\nDesigned to deliver unprecedented efficiency and performance for training and inference workloads, the Rubin platform will provide the foundation for Microsoft’s next-generation cloud AI capabilities. Microsoft Azure will offer a tightly optimized platform enabling customers to accelerate innovation across enterprise, research and consumer applications.\n\nCoreWeave will integrate NVIDIA Rubin-based systems into its AI cloud platform beginning in the second half of 2026. CoreWeave is built to operate multiple architectures side by side, enabling customers to bring Rubin into their environments, where it will deliver the greatest impact across training, inference and agentic workloads.\n\nTogether with NVIDIA, CoreWeave will help AI pioneers take advantage of Rubin’s advancements in reasoning and MoE models, while continuing to deliver the performance, operational reliability and scale required for production AI across the full lifecycle with CoreWeave Mission Control.\n\nIn addition, Cisco, Dell, HPE, Lenovo and Supermicro are expected to deliver a wide range of servers based on Rubin products.\n\nAI labs including Anthropic, Black Forest, Cohere, Cursor, Harvey, Meta, Mistral AI, OpenAI, OpenEvidence, Perplexity, Runway, Thinking Machines Lab and xAI are looking to the NVIDIA Rubin platform to train larger, more capable models and to serve long-context, multimodal systems at lower latency and cost than with prior GPU generations.\n\nInfrastructure software and storage partners AIC, Canonical, Cloudian, DDN, Dell, HPE, Hitachi Vantara, IBM, NetApp, Nutanix, Pure Storage, Supermicro, SUSE, VAST Data and WEKA are working with NVIDIA to design next-generation platforms for Rubin infrastructure.\n\nThe Rubin platform marks NVIDIA’s third-generation rack-scale architecture, with more than 80 NVIDIA MGX™ ecosystem partners.\n\nTo unlock this density, Red Hat today announced an expanded collaboration with NVIDIA to deliver a complete AI stack optimized for the NVIDIA Rubin platform with Red Hat’s hybrid cloud portfolio, including Red Hat Enterprise Linux, Red Hat OpenShift and Red Hat AI. These solutions are used by the vast majority of Fortune Global 500 companies.\n\nLearn more by watching NVIDIA Live at CES and reading the “Inside Vera Rubin” technical blog.",
    "readingTime": 10,
    "keywords": [
      "black forest",
      "perplexity runway",
      "machines lab",
      "anthropic black",
      "openai openevidence",
      "connectx supernics",
      "bluefield dpus",
      "nvidia rubin",
      "innovation together",
      "dell technologies"
    ],
    "qualityScore": 1,
    "link": "https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer",
    "thumbnail_url": "https://s3.amazonaws.com/cms.ipressroom.com/219/files/202601/695c3b3b3d63323e2ab85448_nvidia-rubin-platform/nvidia-rubin-platform_f0b2b61b-6d27-4de9-a6d3-d921352e1368-prv.jpg",
    "created_at": "2026-01-06T00:57:45.630Z",
    "topic": "tech"
  },
  {
    "slug": "unesco-adopts-global-standards-on-wild-west-field-of-neurotechnology",
    "title": "UNESCO adopts global standards on 'Wild West' field of neurotechnology",
    "description": "UN body’s recommendations driven by AI advances and proliferation of consumer-oriented neurotech devices",
    "fullText": "UN body’s recommendations driven by AI advances and proliferation of consumer-oriented neurotech devices\n\nIt is the latest move in a growing international effort to put guardrails around a burgeoning frontier – technologies that harness data from the brain and nervous system.\n\nUnesco has adopted a set of global standards on the ethics of neurotechnology, a field that has been described as “a bit of a wild west”.\n\n“There is no control,” said Unesco’s chief of bioethics, Dafna Feinholz. “We have to inform the people about the risks, the potential benefits, the alternatives, so that people have the possibility to say ‘I accept, or I don’t accept’.”\n\nShe said the new standards were driven by two recent developments in neurotechnology: artificial intelligence (AI), which offers vast possibilities in decoding brain data, and the proliferation of consumer-grade neurotech devices such as earbuds that claim to read brain activity and glasses that track eye movements.\n\nThe standards define a new category of data, “neural data”, and suggest guidelines governing its protection. A list of more than 100 recommendations ranges from rights-based concerns to addressing scenarios that are – at least for now – science fiction, such as companies using neurotechnology to subliminally market to people during their dreams.\n\n“Neurotechnology has the potential to define the next frontier of human progress, but it is not without risks,” said Unesco’s director general, Audrey Azoulay. The new standards would “enshrine the inviolability of the human mind”, she said.\n\nBillions of dollars have poured into neurotech ventures in the past few years, from Sam Altman’s August investment in Merge Labs, a competitor to Elon Musk’s Neuralink, to Meta’s recent unveiling of a wristband that allows users to control their phone or AI Ray-Bans by reading muscle movements in their wrist.\n\nThe wave of investment has brought with it a growing push for regulation. The World Economic Forum released a paper last month calling for a privacy oriented framework, and the US senator Chuck Schumer introduced the Mind Act in September – following the lead of four states that have introduced laws to protect “neural data” since 2024.\n\nAdvocates for neurotech regulation emphasise the importance of safeguarding personal data. Unesco’s standards highlight the need for “mental privacy” and “freedom of thought”.\n\nSceptics, however, say legislative efforts are often driven by dystopian anxieties and risk hampering vital medical advances.\n\n“What’s happening with all this legislation is fear. People are afraid of what this technology is capable of. The idea of neurotech reading people’s minds is scary,” said Kristen Mathews, a lawyer who works on mental privacy issues at the US law firm Cooley.\n\nFrom a technical perspective, neurotechnology has been around for more than 100 years. The electroencephalogram (EEG) was invented in 1924, and the first brain-computer interfaces were developed in the 1970s. The latest wave of investment, however, is driven by advances in AI that make it possible to decode large amounts of data – including, possibly, brainwaves.\n\n“The thing that has enabled this technology to present perceived privacy issues is the introduction of AI,” said Mathews.\n\nSome AI-enabled neurotech advances could be medically transformative, helping treat conditions from Parkinson’s disease to amyotrophic lateral sclerosis (ALS).\n\nA paper published in Nature this summer described an AI-powered brain-computer interface decoding the speech of a paralysis patient. Other work suggests AI may one day be able to “read” your thoughts – or at least, reconstruct an image if you concentrate on it hard.\n\nThe hype around some of these advances has generated fears that Mathews said were often far removed from the real dangers. The Mind Act, for example, says AI and the “vertical corporate integration” of neurotechnology could lead to “cognitive manipulation” and “erosion of personal autonomy”.\n\n“I’m not aware of any company that’s doing any of this stuff. It’s not going to happen. Maybe two decades from now,” she said.\n\nThe current frontier of neurotechnology lies in improving brain-computer interfaces, which despite recent breakthroughs are in their infancy – and in the proliferation of consumer-oriented devices, which Mathews said could raise privacy concerns, a bugbear of the Unesco standards. She argues, however, that creating the concept of “neural data” is too broad an approach to this issue.\n\n“That’s the type of thing that we would want to address. Monetising, behavioural advertising, using neural data. But the laws that are out there, they’re not getting at the stuff we’re worried about. They’re more amorphous.”",
    "readingTime": 4,
    "keywords": [
      "brain-computer interfaces",
      "mental privacy",
      "neurotech devices",
      "neurotechnology",
      "standards",
      "advances",
      "driven",
      "proliferation",
      "frontier",
      "unesco’s"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2025/nov/06/unesco-adopts-global-standards-on-wild-west-field-of-neurotechnology",
    "thumbnail_url": "https://i.guim.co.uk/img/media/b23b6af7acdbb34944ec571e381c47905a493662/1001_0_2497_2000/master/2497.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b18470a9a21372e832ac28bfc4140774",
    "created_at": "2026-01-06T00:57:44.716Z",
    "topic": "tech"
  },
  {
    "slug": "jaana-dogan-reveals-how-ai-built-in-1-hour-what-took-a-year",
    "title": "Jaana Dogan reveals how AI built in 1 hour what took a year",
    "description": "How Google engineer Jaana Dogan discovered an AI tool that recreated a year-long engineering effort in one hour—what it means for developers and AI’s future.",
    "fullText": "Artificial intelligence rarely shocks senior engineers anymore. Most professionals in big tech expect rapid progress. Yet, in early 2026, a candid revelation by Jaana Dogan, a principal engineer at Google, managed to do exactly that. Her experience with an AI coding tool ignited a global conversation about software development, productivity, and the real role of human engineers in an AI-assisted future.\n\nThis was not marketing hype. It came from someone deeply involved in building large-scale AI systems. That authenticity is why her story resonated across the tech world.\n\nJaana Dogan is a Principal Engineer at Google, associated with work on advanced AI systems, including Google’s Gemini ecosystem. Engineers at this level typically focus on system architecture, long-term design decisions, and complex coordination between multiple components rather than routine coding.\n\nShe is not a celebrity technologist or influencer. Instead, she represents a growing group of highly experienced engineers who speak openly about how AI tools are reshaping their daily work. That credibility matters, especially when discussing sensitive topics like productivity gains and automation.\n\nThe moment that brought Jaana Dogan into the spotlight involved a hands-on experiment with Claude Code, an AI coding tool developed by Anthropic. Out of curiosity, she tested whether the tool could understand and recreate a complex system her team had already built at Google.\n\nAccording to Dogan, after providing a clear description of the problem, the AI generated a functional version of a distributed agent orchestrator in roughly one hour. Her team had spent close to a year designing and building a similar system internally.\n\nThis account was first reported by The Indian Express, which quoted Dogan’s own public remarks and reactions from the wider tech community.\n\nTo understand why this mattered, some context helps.\n\nA distributed agent orchestrator is not a simple script. It coordinates multiple autonomous agents, manages communication between them, and ensures tasks execute in the correct order. These systems often involve:\n\nIn large organizations like Google, building such systems involves months of design reviews, testing, and refinements. That’s why the speed of the AI-generated result raised eyebrows.\n\nThe AI output was not production-ready software. Dogan herself made that clear. The generated code still required validation, security reviews, performance testing, and human judgment. However, the structure and logic closely resembled what her team had arrived at after extensive discussions.\n\nThink of it like this: the AI produced a strong architectural draft, not a finished skyscraper.\n\nThis distinction is crucial for maintaining factual accuracy and avoiding exaggerated claims.\n\nThis was not a startup demo or marketing blog post. The observation came from a senior Google engineer with direct experience in large-scale AI systems.\n\nDogan openly acknowledged limitations instead of claiming AI superiority. That balance increased trust in her assessment.\n\nIf AI tools can reduce early-stage development time from months to hours, workflows will change. That affects cost planning, timelines, and team structures.\n\nCoverage from The Economic Times and Times of India further highlighted how divisive this moment was for software engineers globally.\nSources:\n– Economic Times (Technology Updates)\n– Times of India (Tech News)\n\nLong answer: The role is evolving.\n\nAI tools excel at pattern recognition and rapid synthesis. They struggle with context, accountability, and responsibility. Human engineers still:\n\nDecide whether an approach fits real-world constraints\n\nHandle edge cases that AI cannot predict\n\nEnsure compliance with legal and ethical standards\n\nMaintain systems over long timeframes\n\nDogan herself encouraged developers to test AI tools in domains they understand deeply. That advice reflects confidence, not fear.\n\nOne of the most interesting aspects of this story is Dogan’s openness about a competitor’s product. Historically, engineers at major tech firms avoid praising rival tools publicly.\n\nHer response suggests a cultural shift. Many professionals now view AI advancement as a shared ecosystem rather than a zero-sum competition. Progress by one company often pushes the entire field forward.\n\nThat mindset aligns with broader industry trends toward open research, shared benchmarks, and collaborative safety discussions.\n\nTeams can explore ideas quickly without committing months up front.\n\nEngineers may spend less time on boilerplate code and more time on design, review, and decision-making.\n\nPrompt design, system evaluation, and AI oversight will become core technical skills.\n\nThese conclusions align with discussions already happening in academic research and enterprise software planning.\n\nThis story gained traction not because it was sensational, but because it felt honest. It showed excitement, concern, and realism at the same time.\n\nDogan didn’t claim AI had “won.” She highlighted how powerful tools can reshape workflows when used thoughtfully. That balanced perspective is exactly what Google’s E-E-A-T framework values: experience, expertise, authority, and trust.\n\nJaana Dogan did not set out to start a global debate. She simply shared an authentic professional observation. Yet that moment revealed something important: AI tools are no longer just assistants. They are becoming collaborators.\n\nThe future of software development will not be purely human or purely automated. It will sit somewhere in between. Engineers like Jaana Dogan help the industry understand that future clearly, without hype or fear.\n\nAnd that clarity, more than speed or novelty, is what truly matters.\n\nThe Indian Express – Global Technology Coverage\n\nThe Economic Times – AI & Software Industry News\n\nJaana Dogan is a Principal Engineer at Google who works on advanced artificial intelligence systems,\n\nincluding projects related to Google’s Gemini AI ecosystem. She is known for sharing real-world\n\ninsights on how AI tools impact modern software development.\n\nJaana Dogan’s AI experiment went viral because she revealed that an AI coding tool recreated a system\n\nsimilar to her team’s year-long engineering work in about one hour, sparking debate about AI’s role\n\nin software development.\n\nNo, AI did not replace human engineers in Jaana Dogan’s experiment. The AI-generated code acted as a\n\nprototype and still required human expertise for validation, testing, optimization, and long-term\n\nsystem responsibility.\n\nA distributed agent orchestrator is a software system that coordinates multiple autonomous agents,\n\nmanages communication between them, and ensures tasks execute reliably across distributed computing\n\nenvironments.\n\nJaana Dogan’s experience shows that AI can dramatically speed up early-stage development and\n\nprototyping, while human engineers remain essential for system design, ethical decisions, quality\n\ncontrol, and long-term maintenance.",
    "readingTime": 6,
    "keywords": [
      "indian express",
      "artificial intelligence",
      "autonomous agents",
      "agents manages",
      "manages communication",
      "ensures tasks",
      "tasks execute",
      "agent orchestrator",
      "distributed agent",
      "coding tool"
    ],
    "qualityScore": 1,
    "link": "https://mocktestarena.com/jaana-dogan-ai-built-in-one-hour/",
    "thumbnail_url": "https://mocktestarena.com/wp-content/uploads/2026/01/Jaana-Dogan.png",
    "created_at": "2026-01-06T00:57:44.159Z",
    "topic": "tech"
  },
  {
    "slug": "after-nvidias-groq-deal-meet-the-other-ai-chip-startups-that-may-be-in-playand-one-looking-to-disrupt-them-all",
    "title": "After Nvidia’s Groq deal, meet the other AI chip startups that may be in play—and one looking to disrupt them all",
    "description": "Nvidia’s $20 billion Groq deal signals that AI inference—not training—will be the big focus going forward, lifting a crop of chip and software startups while reigniting debate over how long Nvidia's dominance can last.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/05/nvidia-groq-deal-ai-chip-startups-in-play/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/01/54195259582_a575397bf5_o-e1738260860238.jpg?resize=1200,600",
    "created_at": "2026-01-06T00:57:42.580Z",
    "topic": "business"
  },
  {
    "slug": "generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "title": "Generation AI: fears of ‘social divide’ unless all children learn computing skills",
    "description": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n Continue reading...",
    "fullText": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\n\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n\nHis friends from the St Paul’s C of E primary school coding club tapped away to build their own AIs with similar dexterity. Just as people born in the early 20th century never knew a world without manned flight, and generation Z has always lived with social media, Joseph and his friends are AI natives.\n\nHere, on one December morning, some of them were being taught the principles and practicalities of the potentially world-changing technology that experts fear may pass large numbers of people by and leave them disempowered.\n\nPhilip Colligan, the chief executive of the digital education charity the Raspberry Pi Foundation, has warned of a “big split” in society between people who grasp how AIs work and are able to control them – challenging their increasing role in automating decisions in areas including housing, welfare, health, criminal justice and finance. On the other hand, there could be a cadre of AI illiterates who risk social disempowerment.\n\nColligan, a leading expert in technology and its social impacts, told the Guardian AI literacy must become a universal part of education on a par with reading and writing to avoid a social divide opening up.\n\n“There is a world where you’ve got a big split between kids who understand, have that core knowledge and therefore are able to assert themselves and those who don’t,” said Colligan, whose charity is affiliated to the £600m British low-cost tech hardware startup of the same name. “And that could be really very dangerous.”\n\nHis warning was backed by Simon Peyton Jones, a computer researcher who led the creation of the schools national curriculum for computing in 2014, prior to the AI boom. He called for a new digital literacy qualification for all schoolchildren that would ensure they know how to use AIs in a critical way.\n\n“If it’s simply a black box, then [its actions] seem like magic,” he said. “If you know nothing about how the magic is working that is terribly disabling. I am very worried about students leaving school without having agency in the world.”\n\nTheir comments came amid a fall in the number of children studying computing, with 2025 entries for a GCSE in the subject down across the UK. Today, three times more people take history and nearly double the number take biology, chemistry and physics. At the same time, use of AI systems nationwide has been surging – up 78% in the year to September, according to polling by Ipsos.\n\nPart of the belief that learning computing skills is becoming redundant comes from some of the big AI companies, which argue their systems are going to automate coding. Anthropic’s chief executive, Dario Amodei, said in October that 90% of its own coding was automated using its Claude AI model. Meanwhile, 2025 was the year when “vibe coding” became a common phrase – capturing the idea that AIs would allow humans to build software by using natural language instructions rather than specialised code.\n\nPolitical leaders such as Keir Starmer have also suggested coding is becoming redundant. As leader of the opposition in 2023, he said: “The old way – learning out-of-date IT, on 20-year-old computers – doesn’t work. But neither does the new fashion, that every kid should be a coder, when artificial intelligence will blow that future away.” It has created the idea that understanding the inner workings of a computer may be less relevant in the future.\n\n“I think they’re just overhyping the benefits,” said Colligan, whose charity works in schools across dozens of countries.\n\n“This message is leaking out that the kids don’t need to learn this stuff any more and that is not only flawed it is dangerous. We’re already talking to teachers in lots and lots of schools around the world, not just the UK, saying: ‘We can drop computer science now, right?’ That’s a problem.”\n\nHe added: “All of us are going into a world where more and more of the decisions we encounter every day will be taken by automated systems. At the moment it’s what movie should I watch next or what song should I listen to? Fairly soon it’s going to be finance decisions, healthcare decisions, criminal justice decisions. If you don’t understand how those decisions are being made by automated systems, you can’t advocate for your rights. You can’t challenge them, you can’t critically evaluate what’s being presented to you.”\n\nIn December, the former deputy prime minister Nick Clegg, who is now an AI investor, predicted that “we will move from staring at the internet, to living in the internet”.\n\nColligan said: “My concern is there will be a gap between kids based on their socioeconomic background. Some kids who go to great schools, who are able to teach this stuff, will be in a much stronger position as citizens, whether or not they’re using technology for their job. Those kids who are in communities where they don’t have access to [AI literacy teaching] will be passively on the end of a whole load of automated decisions.”\n\nIn the coding club, the seven- to 10-year-olds are taught how AIs work. The lessons were clearly having an effect on Joseph. He said he thought AI “will probably be good, but if lots of people believe it when it’s wrong it will have a bad impact on them”.\n\nHe was not interested in letting the AI do the coding of the video games he planned to make. “It might do it differently to what you want,” he said. “It might also do it wrong and you need to know how to solve it … I’d like to be in charge of the AI. If the AI is in charge of us, we wouldn’t really be able to control what we’re doing and that would be bad.”",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "chief executive",
      "criminal justice",
      "computing skills",
      "coding club",
      "automated systems",
      "decisions",
      "kids",
      "lots",
      "social"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/education/2026/jan/05/generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "thumbnail_url": "https://i.guim.co.uk/img/media/66338578082a146cac512c5e844a9b9eda109707/628_0_6160_4928/master/6160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=dfec8859e649adbe1a54dfa8c45ce5bb",
    "created_at": "2026-01-06T00:57:41.049Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-announces-humanoid-robot-plans-selfdriving-car-technologies-at-ces-2026",
    "title": "Nvidia announces humanoid robot plans, self-driving car technologies at CES 2026",
    "description": "Nvidia showed off its latest physical AI technologies at CES 2026.",
    "fullText": "LAS VEGAS — Nvidia (NVDA) is touting its latest robotics advancements at CES 2026 as the broader tech industry begins a large-scale effort to bring humanoid robots to life.\n\nDuring the company's keynote on Monday, CEO Jensen Huang revealed that firms ranging from Boston Dynamics and Caterpillar (CAT) to LG Electronics and NEURA Robotics are using Nvidia's robotics technologies to develop and power their various bots.\n\nNvidia has claimed that physical AI could revolutionize the $50 trillion manufacturing and logistics industries, and the company wants to be at the center of it all.\n\nDuring CES, Nvidia revealed a variety of new AI models to help train robots to interact with the world around them, as well as the hardware necessary to power their digital brains.\n\nIn addition to humanoid bots, Nvidia showed off a new family of models for self-driving cars called Alpamayo. According to the company, Alpamayo uses a chain-of-thought reasoning-based vision language action (VLA) model.\n\nThat's a lot to take in, but essentially the models can recognize unique driving situations that might not otherwise happen during a regular drive and come up with the proper way to move forward.\n\nFor instance, the model could see that a traffic light is out when a vehicle is approaching an intersection, recognize the problem, and try to figure out what to do next.\n\nNvidia said the models are meant to serve as \"large-scale teacher models that developers can fine-tune and distill into the backbones of their complete [self-driving] stacks.\"\n\nIn other words, Alpamayo is meant to help developers improve their self-driving vehicle technologies over time.\n\nNvidia said companies including Lucid (LCID), Uber (UBER), and Berkeley DeepDrive have shown interest in Alpamayo.\n\nSelf-driving vehicles are hitting roads around the world, with Google's Waymo leading the way, but they're still not perfect. Some cars have caused traffic jams and have gotten confused in certain situations.\n\nNvidia sees virtual training as a helpful solution for the continued development of the technology, allowing developers to teach their AI models without having to necessarily put cars on the road at all times.\n\nEmail Daniel Howley at dhowley@yahoofinance.com. Follow him on Twitter at @DanielHowley.\n\nClick here for the latest technology news that will impact the stock market\n\nRead the latest financial and business news from Yahoo Finance",
    "readingTime": 2,
    "keywords": [
      "bots nvidia",
      "models",
      "latest",
      "robotics",
      "cars",
      "developers",
      "large-scale",
      "humanoid",
      "robots",
      "technologies"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-announces-humanoid-robot-plans-self-driving-car-technologies-at-ces-2026-230048118.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/65.r3InsGJTwAs_nIvsLnw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/a0ca4bc0-ea79-11f0-baff-1bad8fc20aeb",
    "created_at": "2026-01-06T00:57:40.823Z",
    "topic": "finance"
  },
  {
    "slug": "softbank-group-btig-initiates-with-buy-on-ai-robotics-prospects",
    "title": "Softbank Group: BTIG initiates with Buy on AI, robotics prospects",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/softbank-group-btig-initiates-with-buy-on-ai-robotics-prospects-4431200",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPED4A07F_M.jpg",
    "created_at": "2026-01-06T00:57:39.902Z",
    "topic": "finance"
  },
  {
    "slug": "intel-launches-nextgen-pc-chip-at-ces-in-las-vegas",
    "title": "Intel launches next-gen PC chip at CES in Las Vegas",
    "description": "Intel launched Panther Lake, its new AI chip for laptops, on Monday at the CES trade show in Las Vegas, as the company seeks to ​reassure investors about the first product made using its next-generation manufacturing process called 18A.  Jim Johnson, ‌senior vice president and general manager of Intel's PC group, offered technical details about the company's first line of Panther Lake chips known ‌as Intel Core Ultra Series 3.  The chips feature a new transistor design and a way to deliver power to the chip due to the company's 18A manufacturing process.",
    "fullText": "Jan 5 (Reuters) - Intel launched Panther Lake, its new AI chip for laptops, on Monday at the CES trade show in Las Vegas, as the company seeks to ​reassure investors about the first product made using its next-generation manufacturing process called 18A.\n\nJim Johnson, ‌senior vice president and general manager of Intel's PC group, offered technical details about the company's first line of Panther Lake chips known ‌as Intel Core Ultra Series 3. The chips feature a new transistor design and a way to deliver power to the chip due to the company's 18A manufacturing process.\n\nAt the event, Intel CEO Lip-Bu Tan said the company made good on its promise to ship its first products with the 18A manufacturing process in 2025, referring to ⁠the Panther Lake chips.\n\nIntel's prior-generation Lunar ‌Lake chips were largely made by TSMC. The stakes for Intel are high - the company is making its first high-volume product with 18A, and hopes to reclaim market share ‍it has lost to Advanced Micro Devices.\n\nJohnson said the company has created a separate graphics chiplet - a mini chip stitched together with other mini-chips to form a complete processor. On Monday, Intel said the Intel Core Ultra Series 3 chips ​would deliver 60% better performance than the prior-generation Lunar Lake Series 2.\n\nIntel plans to launch a platform ‌for handheld video games based on the Panther Lake designs this year, Johnson said. Handheld PCs designed by a range of suppliers have grown in popularity in recent years.\n\nIntel has struggled with the yield, or the number of good chips per silicon wafer, for the Panther Lake processors, Reuters reported last year. Intel executives have said its yields are improving monthly and will pave the way for the launch this year.\n\nFor its part, ⁠AMD plans to give a CES keynote address at 9:30 p.m. ​EST on Monday  (0230 GMT on Tuesday). CEO Lisa Su will ​likely launch new generations of PC chips that are geared for AI and graphics.\n\nAMD announced a multibillion-dollar deal with OpenAI for its next-generation MI400 chips, some of which the companies ‍plan to deploy this year. ⁠The deal with the ChatGPT maker is expected to generate tens of billions of dollars in revenue for the chip designer.\n\nThe CEO of AI chip leader Nvidia, Jensen Huang, also spoke at CES ⁠on Monday. He said the company’s next generation of chips was in “full production,” and they could deliver five times the artificial-intelligence computing ‌of the company’s previous chips when serving up chatbots and other AI apps.",
    "readingTime": 3,
    "keywords": [
      "core ultra",
      "prior-generation lunar",
      "ultra series",
      "intel core",
      "panther lake",
      "manufacturing process",
      "lake chips",
      "deliver",
      "launch",
      "product"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/intel-expected-launch-next-gen-201203646.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/edf3b333792dd649b978db393b89c6fc",
    "created_at": "2026-01-06T00:57:39.656Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-reportedly-combatting-gpu-shortages-by-bringing-back-discontinued-graphics-card",
    "title": "Nvidia Reportedly Combatting GPU Shortages By Bringing Back Discontinued Graphics Card",
    "description": "As GPU prices continue to skyrocket and stock becomes increasingly scarce, rumors are swirling that Nvidia might be about to resurrect a previously discontinued line of hardware.\nAccording to Wccftech, Nvidia is reportedly on the verge of resuming production on its budget-friendly GeForce RTX 3060 GPUs to combat the ongoing shortage of RAM being caused by an uptick in development on AI technologies and the increasing prices of memory.\nWccftech's reporting on these rumors seems to stem from a credible leaker of Nvidia GPU production news on Twitter called @hongxing2020. According to a post they made early on January 5, Nvidia seems poised to bring back the RTX 3060 in the first quarter of 2026.\nContinue Reading at GameSpot",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/nvidia-reportedly-combatting-gpu-shortages-by-bringing-back-discontinued-graphics-card/1100-6537185/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1748/17481584/4629447-rtx3060.jpg",
    "created_at": "2026-01-06T00:57:39.066Z",
    "topic": "gaming"
  },
  {
    "slug": "steams-2025-game-of-the-year-revealed-plus-all-other-winners",
    "title": "Steam’s 2025 Game Of The Year Revealed, Plus All Other Winners",
    "description": "Steam users have chosen 2025's Game of the Year winner, and it shouldn't be too surprising that it was Hollow Knight: Silksong, one of the biggest titles on the platform since its debut last year.\nAmong the games Silksong edged out in that category were The Game Awards' Game of the Year winner Clair Obscur: Expedition 33 and Indie Game Awards' Game of the Year winner Blue Prince. Expedition 33 had previously won both awards, but it was stripped of its Indie Game Awards over AI concerns.\nExpedition 33 didn't walk away from the Steam Awards empty handed. Voters gave it the Best Soundtrack Award for 2025.",
    "fullText": "on January 5, 2026 at 12:15PM PST\n\nGameSpot may receive revenue from affiliate and advertising partnerships for sharing this content and from purchases through links.\n\nSteam users have chosen 2025's Game of the Year winner, and it shouldn't be too surprising that it was Hollow Knight: Silksong, one of the biggest titles on the platform since its debut last year.\n\nAmong the games Silksong edged out in that category were The Game Awards' Game of the Year winner Clair Obscur: Expedition 33 and Indie Game Awards' Game of the Year winner Blue Prince. Expedition 33 had previously won both awards, but it was stripped of its Indie Game Awards over AI concerns.\n\nExpedition 33 didn't walk away from the Steam Awards empty handed. Voters gave it the Best Soundtrack Award for 2025. Among this year's 11 game categories, Silksong was the only title that won more than just a single award.\n\nBeyond that, Steam voters spread the wealth to include fan-favorites Dispatch, Hades 2, Silent Hill f, Peak, ARC Raiders and more. Baldur's Gate 3 even got another award for its post-game updates and bug fixes.\n\nThe complete list of winners for the 2025 Steam Awards is included below.\n\nDeveloper: Aggro Crab and Landfall\n\nPublisher: Aggro Crab and Landfall\n\nDeveloper: NeoBards Entertainment\n\nDeveloper: Sandfall Interactive\n\nDeveloper: Nuggets Entertainment\n\nPublisher: Nuggets Entertainment",
    "readingTime": 2,
    "keywords": [
      "aggro crab",
      "nuggets entertainment",
      "indie game",
      "game awards",
      "steam awards",
      "developer",
      "winner",
      "among",
      "voters",
      "landfall"
    ],
    "qualityScore": 0.85,
    "link": "https://www.gamespot.com/gallery/steams-2025-game-of-the-year-revealed-plus-all-other-winners/2900-7383/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4629468-hades2.jpg",
    "created_at": "2026-01-06T00:57:38.305Z",
    "topic": "gaming"
  },
  {
    "slug": "99-neovim-ai-agent",
    "title": "99: Neovim AI Agent",
    "description": "Neovim AI agent done right. Contribute to ThePrimeagen/99 development by creating an account on GitHub.",
    "fullText": "ThePrimeagen\n\n /\n\n 99\n\n Public\n\n Neovim AI agent done right\n\n 928\n stars\n\n 27\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n ThePrimeagen/99",
    "readingTime": 1,
    "keywords": [
      "theprimeagen"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/ThePrimeagen/99",
    "thumbnail_url": "https://opengraph.githubassets.com/877be8eed27e9428890b31ed77ce40c3979c6d28214c69da6c2dad9acbb7c3d6/ThePrimeagen/99",
    "created_at": "2026-01-05T18:19:54.199Z",
    "topic": "tech"
  },
  {
    "slug": "anish-acharyas-notes-on-ai-apps-in-2026",
    "title": "Anish Acharya's Notes on AI Apps in 2026",
    "description": "Notes on AI Apps in 2026",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/illscience/status/2007855098513240255",
    "thumbnail_url": "https://pbs.twimg.com/media/G9xbm_vW0AAA5MX.jpg:large",
    "created_at": "2026-01-05T18:19:53.706Z",
    "topic": "tech"
  },
  {
    "slug": "ai-nudges-syracuse-professors-back-toward-blue-books-inclass-work",
    "title": "AI Nudges Syracuse Professors Back Toward Blue Books, In-Class Work",
    "description": "To prevent students from relying on artificial intelligence to write and do homework for them, many professors are returning to pre-technology assessments and having students finish essays in class.",
    "fullText": "Higher Education\n\n AI Nudges Syracuse Professors Back Toward Blue Books, In-Class Work\n\n To prevent students from relying on artificial intelligence to write and do homework for them, many professors are returning to pre-technology assessments and having students finish essays in class.\n\n December 23, 2025 • \n Emalyn Muzzy, syracuse.com\n\n Facebook\n\n LinkedIn\n\n Twitter\n\nPrint\n\n Email\n\n (TNS) — Oksana Korol remembers her parents telling her how they took oral exams in college. Professors would give them a problem to solve. They had 10 minutes to think it through, then explain their answer and reasoning.\n\n“That is completely AI-proof,” said Korol, a biology professor at Onondaga Community College.\n\nKorol, like countless other professors in Central New York, has had to change the way she teaches her class and assesses students’ learning due to the ballooning use of generative artificial intelligence. Many, like her, are relying on those old-school techniques to AI-proof their tests and papers.\n\nAs AI continues to push itself into our everyday lives, it has created a culture of do or die for higher education. Professors have to either adapt their classes or risk students using AI to avoid thinking through tough assignments. Universities can offer courses teaching students to think critically about AI or assume young minds already know how to ask tough questions.\n\nIf higher education as a whole does not adapt, it could be left behind as students embrace AI in their studies.\n\nAt the three largest educational institutions in Syracuse — Syracuse University, Le Moyne College and Onondaga Community College — many professors are returning to pre-technology assessments while students use AI to study in futuristic ways.\n\nOCC and SU student handbooks outline how using AI to complete entire assignments and papers is considered plagiarism or academic misconduct. Le Moyne College does not have a college-wide AI policy, although Provost Jim Hannan said the institution is starting the process to create guidance.\n\nWithout uniform guidance from school leadership, it’s often up to professors to figure out how to handle AI. Some professors spend free time teaching themselves how to wield AI in a productive manner. Others side-eye the technology.\n\nAll of them, however, must understand how it impacts their students’ learning.\n\n“We have to learn how to use (AI) first. That arms race is exhausting and overwhelming when our workloads, admittedly, are already pretty heavy,” said OCC professor Michelle Malinovsky.\n\nIN-CLASS ASSESSMENTS MAKE A RETURN\nWhen a student uses an AI prompt generator to write a research paper, there are signs the student didn’t do it themselves. Malinovsky said older AI versions used the same rhetoric model. Le Moyne English professor Ann Ryan said a student’s paper may be too clean.\n\nThere is no true way to prove a student used AI, unless the student accidentally leaves their prompt in the paper or admits to it, said Rubin.\n\nWhile there are AI detection software, most don’t work, Rubin and Malinovsky said. For that reason, SU and OCC do not recommend using the programs.\n\n“It’s incredibly inaccurate. It’s always reactionary and it causes a huge issue in terms of equity and bias,” Malinovsky said.\n\nSU, Le Moyne and OCC either encourage or require professors to decide how they want students to use AI. They each have three similar pre-made policies professors can put into their syllabuses.\n\nThe policies state that AI cannot be used under any circumstance, students can use limited AI or AI can be used freely within reason.\n\n“It’s a first step of allowing faculty to think about the use and letting students know how an individual faculty member plans to allow or not allow on assessment in the classroom,” said SU Chief Digital Officer Jeff Rubin.\n\nWith the traditional research paper becoming harder to assign, many professors are flipping the classroom. For example, Ryan has students writing in class and brainstorming with classmates.\n\n“I’m workshopping papers in class as students are writing them. Traditionally in a literature class you’d say, ‘You got a 12-page paper due in three weeks,’” Ryan said. “So what we’re doing is we’re writing papers in class.”\n\nMalinovsky, who teaches English and is also a librarian, said she has implemented similar practices. She encourages students to send pictures of handwritten assignments.\n\n“(AI) challenges professors to rethink the assessment. Perhaps if they’re worried about AI use, then bring some of that assessment back into the classroom,” Rubin said.\n\nProfessors have also started to make work more reflective. For Ryan’s class, students had to add a one-to-two page coda on how what they learned in class impacted them to their final paper. They then shared that reflection with the class.\n\nLearning assessments appear to be returning to traditional, in-person techniques. Korol said she has done away with online exams and implemented more in-class tests.\n\n“I think that we’re back to the blue books and we’re maybe going back to the oral exams,” Korol at OCC said.\n\nEven with the potential for misuse, AI can be a powerful tool if harnessed correctly. While assessments embrace older techniques, study strategies are flying forward.\n\nMultiple professors said they see students upload class slides or paste class notes into a chatbot and ask it to create study tools like a practice quiz or study questions. Anthropic , the creator of AI bot Claude,analyzed student chatsand found they also use it to troubleshoot coding problems or synthesize complex information.\n\nKorol has gone one step farther and created a prototype AI tutor, where she uploads questions for students to answer. The AI tutor knows not just the correct answer but the important ideas behind it, meaning students can express the answers in different ways.\n\n“The tutor has been specifically told not to give out the answer, and instead it’s been told to keep asking leading questions. And if you read through this conversation, you will see that the hints are getting more and more transparent as we go along,” Korol said.\n\nKorol has not yet used the tutor with students but is trying to figure out how to deploy the app for campus-wide use.\n\nTEACHING ABOUT AI\nSU is taking AI education one step further: it has begun offering classes and a minor about the impact of AI. Beginning in fall 2026, the Maxwell School of Public Affairs will offer the AI Policy minor. Classes include programming and public policy analysis.\n\nThe idea is not to teach students how to create or use AI, but rather to think critically about its real world applications, said program director Johannes Himmelreich.\n\n“AI is going to have significant social impact. This will create policy challenges that require an understanding of the technology as well as the policy analysis skills,” Himmelreich said.\n\nMalinovsky described generative AI as the “wild west.” There are no specific federal regulations on AI, with regulators instead relying on a patchwork of laws. On Dec. 11, President Donald Trump put out an executive order blocking states from creating their own regulations.\n\nHimmelreich wants students to be able to tackle topics such as how to grow AI without destroying the environment, how AI could impact warfare or if AI could be conscious enough to deserve rights.\n\nThe idea of a minor exploring AI has been under discussion since 2020, a couple years before the public explosion of generative AI.\n\n“ChatGPT wasn’t a technological surprise at all. I mean, I’ve been in demos that OpenAI gave for the older models that weren’t a chat interface. And the difference is that OpenAI changed its policy around how accessible they want the technology to be,” Himmelreich said.\n\nThinking critically about AI is a core part of Milton Santiago’s Generative AI Filmmaking class. He launched the three-credit course this past fall, teaching students how to use generative AI in filmmaking while also discussing its impact.\n\n“We can intercept a lot of the ethical and moral questions that surround these tools currently, which actually I think is probably the biggest benefit of the class,” Santiago said. “Students do have to wrestle with questions of where does creativity begin and end? What does authorship actually look like? Is the environmental impact as this technology stands today worth using the tools?”\n\nTeaching about AI is not only happening in classes or studies surrounding the topic. Malinovsky said she talks about AI a lot in her English classes. To help her students better understand why they need to do their own work, she sometimes has students do the work themselves then ask an AI chatbot to do the work. Then the students compare and discuss.\n\nAs generative AI continues to develop, faculty are learning how to use it along with students. Some, like Ryan, are skeptical of its application and try to avoid it while others, like Santiago , spend hours figuring out the best application for students.\n\n“This has shaken up what education does in a way that other technologies haven’t,” Hannan said.",
    "readingTime": 8,
    "keywords": [
      "onondaga community",
      "community college",
      "moyne college",
      "blue books",
      "artificial intelligence",
      "oral exams",
      "higher education",
      "pre-technology assessments",
      "research paper",
      "policy analysis"
    ],
    "qualityScore": 1,
    "link": "https://www.govtech.com/education/higher-ed/ai-nudges-syracuse-professors-back-toward-blue-books-in-class-work",
    "thumbnail_url": "https://erepublic.brightspotcdn.com/dims4/default/984ac86/2147483647/strip/true/crop/5824x2831+0+212/resize/1440x700!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2F38%2F99%2Fe00ae4034c93b70990fad19ff945%2Fblue-book.jpeg",
    "created_at": "2026-01-05T18:19:52.793Z",
    "topic": "tech"
  },
  {
    "slug": "experienced-software-developers-assumed-ai-would-save-them-a-chunk-of-time-but-in-one-experiment-their-tasks-took-20",
    "title": "Experienced software developers assumed AI would save them a chunk of time. But in one experiment, their tasks took 20% longer",
    "description": "As more workers use AI, a recent study adds to growing evidence the tech doesn’t always deliver on promises of boosted productivity.",
    "fullText": "Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune, covering retail and the intersection of business and popular culture.\n\nIt’s like a new telling of the “Tortoise and the Hare”: A group of experienced software engineers entered into an experiment where they were tasked with completing some of their work with the help of AI tools. Thinking like the speedy hare, the developers expected AI to expedite their work and increase productivity. Instead, the technology slowed them down more. The AI-free tortoise approach, in the context of the experiment, would have been faster.\n\nThe results of this experiment, part of a recent study, came as a surprise to the software developers tasked with using AI—and to the study’s authors, Joel Becker and Nate Rush, technical staff members of nonprofit technology research organization Model Evaluation and Threat Research (METR).\n\nThe researchers enlisted 16 software developers, who had an average of five years of experience, to conduct 246 tasks, each one a part of projects on which they were already working. For half the tasks, the developers were allowed to use AI tools—most of them selected code editor Cursor Pro or Claude 3.5/3.7 Sonnet—and for the other half, the developers conducted the tasks on their own.\n\nBelieving the AI tools would make them more productive, the software developers predicted the technology would reduce their task completion time by an average of 24%. Instead, AI resulted in their task time ballooning to 19% greater than when they weren’t using the technology.\n\n“While I like to believe that my productivity didn’t suffer while using AI for my tasks, it’s not unlikely that it might not have helped me as much as I anticipated or maybe even hampered my efforts,” Philipp Burckhardt, a participant in the study, wrote in a blog post about his experience.\n\nSo where did the hares veer off the path? The experienced developers, in the midst of their own projects, likely approached their work with plenty of additional context their AI assistants did not have, meaning they had to retrofit their own agenda and problem-solving strategies into the AI’s outputs, which they also spent ample time debugging, according to the study.\n\n“The majority of developers who participated in the study noted that even when they get AI outputs that are generally useful to them—and speak to the fact that AI generally can often do bits of very impressive work, or sort of very impressive work—these developers have to spend a lot of time cleaning up the resulting code to make it actually fit for the project,” study author Rush told Fortune.\n\nOther developers lost time writing prompts for the chatbots or waiting around for the AI to generate results.\n\nThe results of the study contradict lofty promises about AI’s ability to transform the economy and workforce, including a 15% boost to U.S. GDP by 2035 and eventually a 25% increase in productivity.  In fact, many companies have yet to see a return on AI investments. An MIT report published in August found out of 300 AI deployments, only 5% achieved rapid revenue acceleration.  Only 6% of companies fully trust AI to run core business practices, according to a Harvard Business Review Analytic Services research report published last month.\n\nBut Rush and Becker have shied away from making sweeping claims about what the results of their study mean for the future of AI.\n\nFor one, the study’s sample was small and non-generalizable, including only a specialized group of people to whom these AI tools were brand new. The study also measures technology at a specific moment in time, the authors said, not ruling out the possibility that AI tools could be developed in the future that would indeed help developers enhance their workflow.\n\nThe purpose of the study was, broadly speaking, to pump the brakes on the torrid implementation of AI in the workplace and elsewhere, acknowledging more data about AI’s actual effects need to be made known and accessible before more decisions are made about its applications.\n\n“Some of the decisions we’re making right now around development and deployment of these systems are potentially very high consequence,” Rush said. “If we’re going to do that, let’s not just take the obvious answer. Let’s make high-quality measurements.”\n\nEconomists have already asserted that METR’s research aligns with broader narratives on AI and productivity. While AI is beginning to chip away at entry-level positions, according to LinkedIn chief economic opportunity officer Aneesh Raman, it may offer diminishing returns for skilled workers such as experienced software developers.\n\n“For those people who have already had 20 years, or in this specific example, five years of experience, maybe it’s not their main task that we should look for and force them to start using these tools if they’re already well functioning in the job with their existing work methods,” Anders Humlum, an assistant professor of economics at the University of Chicago’s Booth School of Business, told Fortune.\n\nHumlum has similarly conducted research on AI’s impact on productivity. He found in a working study from May that among 25,000 workers in 7,000 workplaces in Denmark—a country with similar AI uptake as the U.S.—productivity improved a modest 3% among employees using the tools.\n\nHumlum’s research supports MIT economist and Nobel laureate Daron Acemoglu’s assertion that markets have overestimated productivity gains from AI. Acemoglu argues only 4.6% of tasks within the U.S. economy will be made more efficient with AI.\n\n“In a rush to automate everything, even the processes that shouldn’t be automated, businesses will waste time and energy and will not get any of the productivity benefits that are promised,” Acemoglu previously wrote for Fortune. “The hard truth is that getting productivity gains from any technology requires organizational adjustment, a range of complementary investments, and improvements in worker skills, via training and on-the-job learning.”\n\nThe case of the software developers’ hampered productivity points to this need for critical thought on when AI tools are implemented, Humlum said. While previous research on AI productivity has looked at self-reported data or specific and contained tasks, data on challenges from skilled workers using the technology complicate the picture.\n\n“In the real world, many tasks are not as easy as just typing into ChatGPT,” Humlum said. “Many experts have a lot of experience [they’ve] accumulated that is highly beneficial, and we should not just ignore that and give up on that valuable expertise that has been accumulated.”\n\n“I would just take this as a good reminder to be very cautious about when to use these tools,” he added.\n\nA version of this story originally published on Fortune.com on July 20, 2025.",
    "readingTime": 6,
    "keywords": [
      "skilled workers",
      "experienced software",
      "productivity gains",
      "software developers",
      "study",
      "tools",
      "technology",
      "research",
      "tasks",
      "business"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/does-ai-increase-workplace-productivity-experiment-software-developers-task-took-longer/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/07/GettyImages-2175168300-e1752874968564.jpg?resize=1200,600",
    "created_at": "2026-01-05T18:19:38.207Z",
    "topic": "tech"
  },
  {
    "slug": "gbrain",
    "title": "GBrain",
    "description": "Neuro+ GBrain offers an AI-powered therapy chatbot designed for neurodivergents, providing online mental wellness support, emotional care, and cognitive guidance",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.neuroplusgbrain.net/",
    "thumbnail_url": "https://primary.jwwb.nl/public/h/k/k/temp-oxmmdviclpvumgdcdtor/img-20250719-wa0008-standard.jpg?enable-io=true&enable=upscale&fit=bounds&width=1200",
    "created_at": "2026-01-05T18:19:36.998Z",
    "topic": "tech"
  },
  {
    "slug": "ofcom-asks-x-about-reports-its-grok-ai-makes-sexualised-images-of-children",
    "title": "Ofcom asks X about reports its Grok AI makes sexualised images of children",
    "description": "Elon Musk's social media platform has warned users not to use Grok to generate illegal content.",
    "fullText": "Ofcom has made \"urgent contact\" with Elon Musk's company xAI following reports its AI tool Grok can be used to make \"sexualised images of children\" and undress women.\n\nA spokesperson for the regulator said it was also investigating concerns Grok has been producing \"undressed images\" of people.\n\nThe BBC has seen several examples on the social media platform X of people asking the chatbot to alter real images to make women appear in bikinis without their consent, as well as putting them in sexual situations.\n\nX has not responded to a request for comment. On Sunday, it issued a warning to users, external not to use Grok to generate illegal content including child sexual abuse material.",
    "readingTime": 1,
    "keywords": [
      "grok",
      "images",
      "women",
      "sexual"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bbc.co.uk/news/articles/c5y5w0k99r1o",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_news/1200/cpsprodpb/b41c/live/c0f85350-ea48-11f0-a4c4-1d0f54763880.jpg",
    "created_at": "2026-01-05T18:19:36.226Z",
    "topic": "tech"
  },
  {
    "slug": "the-case-for-sharpening-your-math-skills-in-the-age-of-ai",
    "title": "The Case for Sharpening Your Math Skills in the Age of AI",
    "description": "Business leaders can’t outsource mathematical thinking to AI without sacrificing judgment, because real-world business problems demand practical, approximate reasoning rather than pristine textbook solutions. Drawing on examples from tech, finance, and decision science, the article shows why leaders must learn to sanity-check models, think probabilistically, and distinguish sound decisions from noisy outcomes. It also explains how non-linear dynamics and smart “bet sizing” shape long-term results—making math fluency a core leadership skill in the AI era.",
    "fullText": "The Case for Sharpening Your Math Skills in the Age of AI by Harsha V. MisraJanuary 5, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWith the rise of AI, business leaders may be wondering: Is it time to outsource math to machines, freeing managers to do more managerial things?",
    "readingTime": 1,
    "keywords": [
      "math"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/the-case-for-sharpening-your-math-skills-in-the-age-of-ai",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_23_37iGmfCr8qQ-unsplash-1.jpg",
    "created_at": "2026-01-05T18:19:35.706Z",
    "topic": "business"
  },
  {
    "slug": "arc-raiders-dev-defends-use-of-ai-yet-again",
    "title": "Arc Raiders Dev Defends Use Of AI Yet Again",
    "description": "Arc Raiders was one of the most successful games of 2025, but it was also criticized for its use of AI-based text-to-speech systems. Patrick Söderlund, the head of Arc Raiders studio Embark, has now shed more light on the situation, saying the studio's goal in implementing AI into its development processes is  to make better games more efficiently.\nHe also pushed back against the idea that using AI systems in game development would lead to lower employment at Embark.\n\"We don't use AI to not have to hire people or replace people or job groups or voice actors,\" Söderlund told GamesBeat. \"People have to take a step back and understand what it is and how it can be a big help to developers and be a tremendous benefit to players.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/arc-raiders-dev-defends-use-of-ai-yet-again/1100-6537166/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4629245-screenshot2026-01-05at9.03.00%E2%80%AFam.png",
    "created_at": "2026-01-05T18:19:35.523Z",
    "topic": "gaming"
  },
  {
    "slug": "why-im-never-going-to-let-ai-write-my-emails",
    "title": "Why I'm Never Going to Let AI Write My Emails",
    "description": "It's tempting to offload email to AI—but I, for one, will resist the urge.",
    "fullText": "Need some help writing your emails? Through the wonders of AI and Large Language Models (LLMs), you can now get messages composed on your behalf in Gmail, in Apple Mail, in Outlook, and in many other email clients. Most of the time, the AI option pops up straight away, ready to give you however much assistance you need.\n\nThe pitch is that you can offload the drudgery of dealing with email to AI, and move on to other tasks that may be more interesting and important. Anecdotally, I've spoken to quite a few people who now use AI chatbots in this way. But it's not something I'm ready to embrace, and I don't think I ever will.\n\nThese are my reasons, which may or may not resonate with you, though I haven't mentioned the issues of energy use and copyright violations that hang over the use of AI more generally. You can keep asking if I want some help in Gmail, Gemini, but I'd rather switch you off altogether.\n\nWriting's pretty easy, really—most of us can do it from an early age without too much trouble. Writing well is harder, but you don't have to be a best-selling author to fire off a few emails. So is there any harm in using AI for some low-level email composing? It may be quicker and more convenient, but I'm not sure it's actually beneficial.\n\nAs author David McCullough once said: \"Writing is thinking.\" The skill of being able to choose the right word to put in front of the previous one gets the cogs of the brain moving, and forces some thought about what's being said. Word choice and sentence structure matters, even on the shortest and most banal of emails.\n\nI don't want to sit down at a laptop one day and find myself struggling to compose a few lines of text. Is that far-fetched? Perhaps not, based on reports from those who've already tried farming out emails to AI. \"Is it difficult trying to get that thought in your head translated to an email?\" asks Google. Well, yes, it is, and that's sort of the point.\n\nIt's fair to say a lot of us get an excessive amount of email (if you don't, consider yourself lucky). Chances are that plenty of your incoming email will be from people you don't know personally, but no matter the sender and the recipient in an email conversation, I think human responses are worth the effort.\n\nIf all of our emails—arranging work drinks, applying for jobs, discussing a project—are written by AI, then we're heading for piles and piles of machine-written missives that lack any kind of nuance or personal touch. Imagine a group email chain where every response sounds the same, irrespective of who sent it.\n\nEven if I'm writing a simple \"no thanks\" email, if I'm communicating with another human being, I'm of the opinion that they deserve a response that has come straight from me. This is more of a principled stance than anything else, but I'm sticking with it.\n\nGet AI to write a thank you note to someone who hosted an event you recently attended, for example, and you're going to get a rather generic spiel that's the averaging out of countless other thank you notes. It's going to be bland, impersonal, and forgettable.\n\nI can see the temptation to use AI to compose an important email—applying for a job, maybe, or appealing against a company decision—but your message is likely to end up reading like the algorithm-processed, mass-produced text that it is. You're going to sound like everyone else, basically (see the previous point).\n\nYou could get AI to do a draft and then edit it, but if I started down this path, I could see myself making fewer and fewer edits to my messages, out of laziness or habit.\n\nAI still makes lots of mistakes, though the chatbot developers don't tend to mention them much. If you're drafting an email about a new project pitch, a family get-together, a customer inquiry or whatever it is, there's no guarantee that an AI will get all the details right.\n\nThe more important the content of the email, the more important this becomes. The companies pushing AI-driven emails seem to be of the opinion that we can all be chasing business leads, organizing colleagues, and expressing heartfelt feelings over email with the help of AI, but I'm not convinced.\n\nPeople make mistakes as well, but I'd rather trust myself than a black box of algorithms that aren't even fully understood by the developers who code them. Does AI know the people I'm emailing, and the specific details they need? Of course not.\n\nTo paraphrase George Orwell, if you want a picture of the future, imagine your AI sending thousands of emails a minute to everyone else's AIs, forever. At what point do we abdicate responsibility completely to chatbots, and just let them get on with it? I don't even want to take a single step towards that.\n\nRight now, not even the most enthusiastic AI fans are suggesting that we start sending AI-written emails out into the ether without checking and editing them first, but isn't that the obvious next step? I can almost see the Google I/O on-stage presentation now—get Gemini to handle everything, for the ultimate productivity boost.\n\nPreliminary studies already show that we forget almost everything we write using AI, which has worrying implications if we're sending out important information that needs to be recalled later. It's not a future I'm going to be signing up for, no matter how insistent the AI prompts get.",
    "readingTime": 5,
    "keywords": [
      "i'd rather",
      "email",
      "emails",
      "don't",
      "you're",
      "messages",
      "straight",
      "ready",
      "pitch",
      "chatbots"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/why-i-am-never-going-to-let-ai-write-email?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KE789S3GE17HZA80Q6CD3TJJ/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-05T18:19:34.956Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-tony-mcguinness-of-above-and-beyond",
    "title": "Sutton's predictions v Tony McGuinness of Above and Beyond",
    "description": "BBC Sport football expert Chris Sutton takes on Tony McGuinness of Above and Beyond - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "AI may be doing better than BBC Sport football expert Chris Sutton at Premier League predictions this season but it appears it cannot keep up with the relentless fixture schedule.\n\nWhen we asked it for the scores of this week's midweek games, it claimed there were none scheduled.\n\n\"It should be disqualified for that,\" said Sutton. \"It is meant to know everything, isn't it?\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 21, the games on Tuesday, Wednesday and Thursday, he takes on Tony McGuinness of electronic dance music group Above and Beyond.\n\nAbove and Beyond's latest album, Bigger Than All Of Us, is out now.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 1,
    "keywords": [
      "premier league",
      "predictions",
      "games",
      "season",
      "scores",
      "points",
      "sutton",
      "sport"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/c87r0dn3gq1o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/c536/live/0182c900-ea35-11f0-b5f7-49f0357294ff.png",
    "created_at": "2026-01-05T18:19:33.704Z",
    "topic": "sports"
  },
  {
    "slug": "ai-and-the-human-condition",
    "title": "AI and the Human Condition",
    "description": "AI might replace all of the jobs; that’s only a problem if you think that humans will care, but if they care, they will create new jobs.",
    "fullText": "Pity the paradox of the content producer in the age of AI. On one hand, AI is one of the greatest gifts ever in terms of topics to cover. The 2025 Stratechery Year in Review was, just like 2024 and 2023 (plus a few bangers in 2022) completely dominated by AI; my Sharp Tech co-host Andrew Sharp wrote The Definitive Ranking of Tech Company Takeability, and OpenAI was number one with a bullet:\n\nOpenAI may or may not be the most important company of the future. There can be no doubt, however, that we are witnessing one of the most takeable enterprises in the history of the world. From the day it was founded — with a non-profit corporate structure that sought to build AGI and then control it themselves “to ensure artificial general intelligence benefits all of humanity” — this company has divided the audience and invited either passionate support or aggressive eye-rolls.\n\nOn the other hand, LLMs in particular are quite literally content producers! What’s the point of writing analysis when ChatGPT or Gemini or Claude will deliver analysis on demand, about any topic you want? Is this one of those situations like the early web, where the possibility of reaching everyone seemed like a boon but was actually a ticking time bomb for the viability of the traditional publishing model?\n\nI’m actually pretty optimistic about Stratechery Plus’ fortunes for reasons I laid out in last year’s Content and Community:\n\nSo, are existing publishers doomed? Well, by-and-large yes, but that’s because they have been doomed for a long time. People using AI instead of Google — or Google using AI to provide answers above links — make the long-term outlook for advertising-based publishers worse, but that’s an acceleration of a demise that has been in motion for a long time.\n\nWhat I think is intriguing, however, is the possibility to go back to the future. Once upon a time publishing made countries; the new opportunity for publishing is to make communities. This is something that AI, particularly as it manifests today, is fundamentally unsuited to: all of that content generated by LLMs is individualized; what you ask, and what the AI answers, is distinct from what I ask, and what answers I receive. This is great for getting things done, but it’s useless for creating common ground…\n\nStratechery, on the other hand, along with a host of other successful publications, has the potential to be a totem pole around which communities can form…There is a need for community, and I think content, whether it be an essay, a podcast, or a video, can be artifacts around which communities can form and sustain themselves, ultimately to the economic benefit of the content creator. There is, admittedly, a lot to figure out in terms of that last piece, but when you remember that content made countries, the potential upside is likely quite large indeed.\n\nThis might, to be fair, be wishful thinking: maybe I’m doomed, but if I’m doomed, probably everyone else is too, particularly when you think about the very long run.\n\nIt’s the very long run that a fellow content producer, Dwarkesh Patel, considered alongside Philip Trammell in a widely discussed post over the winter break entitled Capital in the 22nd Century:\n\nIn his 2013 Capital in the Twenty-first Century, the socialist economist Thomas Piketty argued that, absent strong redistribution, economic inequality tends to increase indefinitely through the generations — at least until shocks, like large wars or prodigal sons, reset the clock. This is because the rich tend to save more than the poor and because they can get higher returns on their investments.\n\nAs many noted at the time, this is probably an incorrect account of the past. Labor and capital complement each other. Wealthy people can keep accumulating capital, but hammers grow less valuable when there aren’t enough hands to use all of them, and hands grow more valuable when hammers are plentiful. Capital accumulation thus lowers interest rates (aka income per unit of capital) and raises wages (income per unit of labor). This effect has tended to be strong enough that, though inequality may have grown for other reasons, inequality from capital accumulation alone has been self-correcting.\n\nBut in a world of advanced robotics and AI, this correction mechanism will break. That is, though Piketty was wrong about the past, he will probably be right about the future…If AI is used to lock in a more stable world, or at least one in which ancestors can more fully control the wealth they leave to their descendants (let alone one in which they never die), the clock-resetting shocks could disappear. Assuming the rich do not become unprecedentedly philanthropic, a global and highly progressive tax on capital (or at least capital income) will then indeed be essentially the only way to prevent inequality from growing extreme. Without one, once AI renders capital a true substitute for labor, approximately everything will eventually belong to those who are wealthiest when the transition occurs, or their heirs. Or more precisely, it will belong to the subset of this group who save most and most invest with a view to maximizing long-run returns.\n\nThere is an aspect to this argument that is of the dorm room discussion variety: even if we are approaching the point where AI can create AI (Claude Opus 4.5 appears to be a major leap forward in coding capability in particular), there is still a lot of work to do in terms of making it possible for AI to break out of its digital box and impact the real world via robotics. Part of the thinking, however, is that once AI can create AI, it can rapidly accelerate the development of robotics as well, until robots are making robots, each generation more capable than the next, until everything humans do today — both in the digital but also the physical world — can be done better by AI.\n\nThis is the world where capital drives all value, and labor none, in stark contrast to the approximately 33% share of GDP that has traditionally gone to capital, with 66% share of GDP going to labor. After all, you don’t pay robots for marginal labor: you build them once…check that, they build themselves, from materials they harvested, not just here on earth but across the galaxy, and do everything at zero marginal cost, a rate with which no human can compete.\n\nI get the logic of Patel and Trammell’s argument, but I — perhaps, once again, over-optimistically — am skeptical about this being a problem, particularly one that needs to be addressed right here right now before the AI takeoff occurs, especially given the acute need for more capital investment at this moment in time.\n\nFirst, the world Patel and Trammell envisions sounds like it would be pretty incredible for everyone. If AI can do everything, then it follows that everyone can have everything, from food and clothing to every service you can imagine (remember, the AI is so good that there are zero jobs for humans, which implies that all of the jobs can be done by robots for everyone). Does it matter if you don’t personally own the robots if every material desire is already met?\n\nSecond, on the flipside, this world also sounds implausible. It seems odd that AI would acquire such fantastic capabilities and yet still be controlled by humans and governed by property laws as commonly understood in 2025. I find the AI doomsday scenario — where this uber-capable AI is no longer controllable by humans — to be more realistic; on the flipside, if we start moving down this path of abundance, I would expect our collective understanding of property rights to shift considerably.\n\nThird, it’s worth noting that we have seen dramatic shifts in labor in human history. Consider both agricultural revolutions: in the pre-Neolithic era zero percent of humans worked in agriculture; fast-forward to 1810, and 81% of the U.S. population worked in agriculture. Then came the second agriculture revolution, such that 200 years later only 1% of the U.S. population works in agriculture. It’s that decline that is particularly interesting to me: humans were replaced by machines, even as food became abundant and dramatically cheaper; no one is measuring their purchases based on how much food cost in 1700, just as they won’t measure their future purchases on the cost of material goods in a pre-robotics world.\n\nThat’s because humans didn’t just sit on their hands; rather, entirely new kinds of work were created, which were valued dramatically higher. Much of this was in factories, and then, over the last century, there was the rise of office work. All of that could very well be replaced by AI, but the point is that the history of humans is the continual creation of new jobs to be done — jobs that couldn’t have been conceived of before they were obvious, and which pay dramatically more than whatever baseline existed before technological change.\n\nLike, if I might be cheeky, professional podcaster! Podcasts didn’t even exist thirty years ago, and yet here is Patel — and me! — accumulating capital simply by speaking into a mic and taking advantage of the Internet’s zero marginal cost of distribution, a concept that itself was unthinkable fifty years ago.\n\nIt’s possible, of course — and to return to my perhaps self-interested and potentially misplaced optimism above — that robots will be better at podcasting than Patel or I. I’m skeptical, though: my experience — and I’ll only speak for myself here — is that the human element is essential in creating compelling content. Sure, sometimes I say “uhm” or “like” or “sort of”, or I get facts wrong, but that’s a feature, not a bug: what I have to say is by definition unique to me, and that is interesting precisely because I am flesh-and-blood, not a robot.1\n\nIndeed, another way to frame the optimism I have around my career is that the dynamics are the exact inverse of AI:\n\nRight now it is individual humans who are uniquely capable to reach audiences at scale; AI, on the other hand, is about scaling compute to deliver results to individuals. Patel and Trammell were, to be sure, talking about the 22nd century, while this is a depiction of the first quarter of the 21st, but I think the desire for a communal experience will persist, and I think those experiences will continue to be organized around other humans, not machines.\n\nMore generally, I don’t think that this will be limited to podcasting (if such a concept even exists in one hundred years). Consider the most base example: sex. I have no doubt that there will be human-like robots with which you can have sex; I also have even stronger conviction that the overwhelming preference of humans will be to have sex with other humans. And that, by extension, means that all of the courtship and status games that go into finding a lover will persist, and that that itself will be an entire economy all its own. One will not impress a partner with commodity robot-generated goods, no matter how objectively perfect they might be: true value will come from uniqueness and imperfections that are downstream from a human.\n\nIn fact, I have great optimism that one potential upside of AI is a renewed appreciation of and investment in beauty. One of the great tragedies of the industrial era — particularly today — is that beauty in our built environment is nowhere to be found. How is it that we built intricate cathedrals hundreds of years ago, and forgettable cookie-cutter crap today? That is, in fact, another labor story: before the industrial revolution labor was abundant and cheap, which meant it was defensible to devote thousands of person-years into intricate buildings; once labor was made more productive, and thus more valuable, it simply wasn’t financially viable to divert so much talent for so much time. Perhaps it follows, then, that the devaluing of labor Patel and Trammell warns about actually frees humans up to once again create beauty? Yes, robots could do it too, but I think humans will value the work of other humans more. Indeed, I think this is coming sooner than you might think: I expect the widespread availability of high quality AI art to actually make human art more desirable and valuable, precisely because of its provenance.2\n\nIt’s also worth noting the relative popularity of human-generated content versus AI-generated content. Sora is down to 59 in the App Store, and I count double-digit human-denominated social apps that rank above it. Yes, I get the argument that this is the worst that AI will ever be, but it also will never be human, which is what humans want most of all.\n\nThis gets at what I found the most frustrating about Patel and Trammell’s point of view: the core assumption undergirding their argument was also about the human condition; it just happened to be negative.\n\nLouis C.K., in an October 2008 appearance on Late Night with Conan O’Brien, delivered one of the most incisive and eternal observations about human nature: “Everything is amazing right now and nobody’s happy.”\n\nYou’ve almost certainly seen this clip, but if not, it’s worth watching in full; Louis C.K. focuses on three incredible technological innovations and how quickly we took them for granted: smartphones, Internet access on planes, and the act of flying itself. It’s certainly a sentiment I can relate to: just in the last 72 hours I have chafed at slow airplane WiFi, complained about jet lag from having literally traversed the globe, and gotten frustrated at an iPhone bug that is sapping my battery. It’s all so terrible, until I remember I have access to anything everywhere, can be anywhere anytime, and oh yeah, can achieve both simultaneously.\n\nIf anything, you can make the case that technological innovations, by virtue of conferring their benefits on everybody, has actually had the perverse effect of making everyone feel worse off. When I was a child growing up in small town Wisconsin, I had some sort of vague sense that there were rich people in the world, but from my perspective taking my first airplane flight around the age of ten was a source of great wonder, and even provided a sense of status; after all, many of my friends had never flown at all. That was the comparison set that mattered to me.\n\nSocial media — or, more accurately, user-generated content feeds, which are increasingly not social at all — has completely changed this dynamic. All I or anyone else needs to do is open Instagram to see beautiful people on private jets or on beaches or at fancy restaurants, living a life that seems dramatically better than one’s dull existence in the suburbs or a cramped apartment; never mind that the means of achieving that insight is a level of technological wealth that would have been incomprehensible to the richest person in the world fifty years ago.\n\nTo put it another way, what Louis C.K. identified in this clip was the extent to which human happiness is a relative versus absolute phenomenon: what we care about is not how much we have, but how we compare. That, by extension, is what drives the technological paradox I noted above: more capabilities, more broadly distributed, has tremendously enriched the world on an absolute basis; the end result, however, has been the dramatic expansion of our comparison set, making us feel more immiserated than ever.3\n\nThis, writ large, is what Patel and Trammell seem to be worried about: sure, everyone may have all of their material needs met, but that won’t be good enough if the price of that abundance is the knowledge that someone else has more. This might not be rational, but it certainly is human!\n\nIf you assume that the negative parts of humanity will persist in this world of abundance, however, then you must leave room for the positive parts as well, the ones that I wrote about above. Even if AI does all of the jobs, humans will still want humans, creating an economy for labor precisely because it is labor. You can’t make the case that the potential for jealousy ought to drive authoritarian capital controls while completely dismissing the possibility that the prospect of desirability gives everyone jobs to do, even if we can’t possibly imagine what those jobs might be — beyond podcasting, of course.\n\nIf you want a specific example, consider the rapturous response to Bill Simmons’ 50 Most Rewatchable Movies of the 21st Century episode, which was delightful precisely because it was pure Bill ↩\n\nThis isn’t idle talk: I’m encouraging my daughter to pursue art; granted, I’m also working quite hard to build up a store of capital for her as well! ↩\n\nAs an aside, this is why galaxy exploration would be a positive, not a negative: out of sight out of mind, just like it used to be. ↩",
    "readingTime": 15,
    "keywords": [
      "u.s population",
      "i’m doomed",
      "it’s worth",
      "per unit",
      "income per",
      "worth noting",
      "potential upside",
      "technological innovations",
      "zero marginal",
      "patel and trammell"
    ],
    "qualityScore": 1,
    "link": "https://stratechery.com/2026/ai-and-the-human-condition/",
    "thumbnail_url": "https://stratechery.com/wp-content/uploads/2026/01/ai-human-condition-1.png",
    "created_at": "2026-01-05T12:25:21.773Z",
    "topic": "tech"
  },
  {
    "slug": "journalguardian-journalctl-watcher-with-local-llm-explanations-for-errors",
    "title": "Journal-guardian: JournalCTL Watcher with local LLM explanations for errors",
    "description": "JournalCTL Watcher with local LLM explanations for errors - delirehberi/journal-guardian",
    "fullText": "delirehberi\n\n /\n\n journal-guardian\n\n Public\n\n JournalCTL Watcher with local LLM explanations for errors\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n delirehberi/journal-guardian",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/delirehberi/journal-guardian",
    "thumbnail_url": "https://opengraph.githubassets.com/88a91c8b98ec6506154adcea086c3af95f17ba72b08fb575914e173c2c4aafb7/delirehberi/journal-guardian",
    "created_at": "2026-01-05T12:25:21.385Z",
    "topic": "tech"
  },
  {
    "slug": "the-ceo-of-2-billion-ai-training-startup-says-that-humans-will-stay-involved-in-data-creation-for-decades",
    "title": "The CEO of $2 billion AI training startup says that humans will stay involved in data creation for decades",
    "description": "Artificial intelligence won't be training AI anytime soon, says Invisible Technologies CEO.",
    "fullText": "Artificial intelligence won't be training AI anytime soon, says the CEO of a data labeling startup.\n\nOn an episode of the \"20VC\" podcast released last week, Matt Fitzpatrick, the CEO of Invisible Technologies, said that one of the biggest misconceptions in the AI training industry is that humans won't be needed in a few years.\n\n\"When I first started this job, the main push back I always got was that synthetic data will take over and you just will not need human feedback two to three years from now,\" said Fitzpatrick, who joined the startup last year. \"From first principles, that actually doesn't make very much sense.\"\n\nSynthetic data refers to data that is artificially created. It is used for training AI or machine learning models, mostly where real data is scarce or can't be used because of privacy concerns. Human feedback, on the other hand, asks real people to filter, rank, and train AI responses.\n\nOn the podcast, Fitzpatrick said that there are too many kinds of tasks for AI to accomplish in the world, and it would take a long time to do them accurately with language and cultural context in mind. For example, the legal industry contains vast amounts of nonpublic information.\n\n\"On the GenAI side, you are going to need humans in the loop for decades to come,\" he said. \"And I think that is something that most people are starting to realize.\"\n\nFitzpatrick was previously a senior partner at McKinsey, where he led QuantumBlack Labs, the firm's AI research and software development arm.\n\nInvisible, which raised $100 million in September at a $2 billion valuation, competes with data labeling companies such as Scale AI and Surge AI. These startups have raised billions in the past year as tech giants race to secure the data needed to train their AI models. They hire millions of human contractors, who help teach the models math, science, coding, and characteristics such as humor and empathy.\n\nFitzpatrick joins the CEOs of other data labeling startups in saying that the industry will continue to require human effort.\n\nIn September, the CEO of Mercor, Brendan Foody, said that the most important aspect of the business was data quality and \"having phenomenal people that you treat incredibly well.\"\n\nIn July, the CEO of Handshake, a job platform that pivoted into AI training last year, said that humans will still be needed to train AI, but who makes the cut is changing.\n\nGarrett Lord said the data annotation industry is shifting from requiring generalists to highly specialized experts, including in math and science.\n\n\"Now these models have kind of sucked up the entirety of the entire corpus of the internet and every book and video,\" Lord said on a podcast. \"They've gotten good enough where, like, generalists are no longer needed.\"",
    "readingTime": 3,
    "keywords": [
      "human feedback",
      "fitzpatrick",
      "training",
      "industry",
      "needed",
      "models",
      "labeling",
      "podcast",
      "humans",
      "train"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-training-ceo-artificial-data-humans-matt-fitzpatrick-invisible-technologies-2026-1",
    "thumbnail_url": "https://i.insider.com/695b3464832e0ef1ead72292?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:16.294Z",
    "topic": "finance"
  },
  {
    "slug": "an-nyu-professor-who-hates-that-students-work-reads-like-mckinsey-memos-held-ai-oral-exams-to-fight-fire-with-fire",
    "title": "An NYU professor who hates that students' work reads like McKinsey memos held AI oral exams to 'fight fire with fire'",
    "description": "When student work looked like McKinsey memos, an NYU business school professor used AI oral exams to test real learning.",
    "fullText": "The assignments looked brilliant. The understanding didn't.\n\nThat's when an NYU business school professor decided to fight AI-assisted coursework with AI-powered oral exams.\n\nPanos Ipeirotis, a professor at NYU's Stern School of Business who teaches data science, wrote in a blog post published last week that he became concerned about student assignments that read like \"a McKinsey memo\" but lacked genuine understanding.\n\nWhen he called on students in class and asked them to defend their submissions, many struggled to do so.\n\n\"If you cannot defend your own work live, then the written artifact is not measuring what you think it is measuring,\" Ipeirotis wrote.\n\nTo counter that, he revived oral exams and enlisted an AI agent to administer them at scale, in an attempt to \"fight fire with fire.\"\n\n\"We need assessments that evolve toward formats that reward understanding, decision-making, and real-time reasoning,\" Ipeirotis said.\n\n\"Oral exams used to be standard until they could not scale,\" he added. \"Now, AI is making them scalable again.\"\n\nIn the blog post detailing the experiment, Ipeirotis said he and his colleague built the AI examiner using ElevenLabs' conversational speech technology.\n\n\"Just write a prompt describing what the agent should ask the student, and you are done,\" he said, adding that it took minutes to set up.\n\nThe oral exam had two parts. First, the AI agent questioned students about their capstone projects, probing their decisions and reasoning. Then it selected one of the cases discussed in class and pushed students to think through it live.\n\nOver the course of nine days, the system assessed 36 students. Each session lasted about 25 minutes, with total compute costs coming in at about $15 for all 36 students. A human-run oral exam could cost hundreds of dollars at teaching-assistant rates, Ipeirotis wrote.\n\nIpeirotis also used AI to grade the exams. Three AI models — Claude, Gemini, and ChatGPT — independently assessed each transcript. They then reviewed one another's evaluations, revised their scores, and produced a final grade, with Claude acting as the \"chair\" to synthesize the decision.\n\nIpeirotis said the \"council of LLMs\" graded more consistently than humans, and \"more strictly, but more fairly.\"\n\n\"The feedback was better than any human would produce,\" he wrote, adding that the AI analysis also surfaced gaps in how the material had been taught.\n\nHowever, students were divided. Only a small minority preferred the AI oral exams, and many found them more stressful than written tests — even while acknowledging they were a better measure of real understanding.\n\nStill, Ipeirotis said the oral exams demonstrated \"how learning is supposed to work.\"\n\n\"The more you practice, the better you get,\" Ipeirotis wrote.\n\nIpeirotis' blog post comes as universities grapple with how to test students in the AI era.\n\nA paper published in September in the academic journal \"Assessment & Evaluation in Higher Education\" said AI has turned student assessment into a \"wicked problem.\"\n\nThe study's authors interviewed 20 unit chairs at a large Australian university in late 2024. Through hourlong Zoom interviews, they found instructors to be overwhelmed by heavier workloads, confusion surrounding AI use, and a lack of agreement on what an AI-proof assessment should look like.\n\nSome faculty members told researchers that AI should be treated as a tool for students to master. Others view it as academic dishonesty that erodes learning. Many admitted they were unsure how to proceed.\n\nIn May, LinkedIn cofounder Reid Hoffman said on an episode of his podcast, \"Possible,\" that AI can make it easier for students to exploit traditional assessment formats, such as essays. Universities should rethink how they evaluate learning, he said, adding that students could soon expect an \"AI examiner.\"\n\nHoffman said that oral exams leave less room for shortcuts, requiring students to demonstrate real understanding.",
    "readingTime": 4,
    "keywords": [
      "oral exam",
      "oral exams",
      "students",
      "understanding",
      "ipeirotis",
      "blog",
      "student",
      "agent",
      "adding",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nyu-professor-ai-oral-exam-mckinsey-memo-business-school-2026-1",
    "thumbnail_url": "https://i.insider.com/695b525264858d02d217b7ee?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:16.278Z",
    "topic": "finance"
  },
  {
    "slug": "meet-dario-amodei-anthropics-outspoken-ceo",
    "title": "Meet Dario Amodei, Anthropic's outspoken CEO",
    "description": "Anthropic CEO Dario Amodei doesn't seem to mind angering tech CEOs, whether it's with his warnings about AI or pushing export controls.",
    "fullText": "Anthropic CEO Dario Amodei doesn't mince words.\n\nHe's rankled some rival tech CEOs by boldly predicting that AI could wipe out half of entry-level, white-collar jobs and that the upheaval could happen between now and the next five years.\n\n\"I think at the end of the day, I warn about these things not to be a prophet of doom, but because warning about them is the first step towards solving them,\" Amodei said in December during The New York Times' DealBook Summit.\n\nAs 2025 comes to a close, Amodei still has a lot to warn about. By his own admission, the longtime AI researcher turned executive has said his vision for the future has led some to dismiss him as a \"doomer,\" even as he thinks AI could unlock a 150-year lifespan.\n\n\"Actual people who are building the technology, they're excited about the potential, but they're also worried,\" he said during the December event. \"They're worried about the national security risks. They're worried about alignment of the models; they're worried about the economic impacts of the models.\"\n\nUnder Amodei's leadership, Anthropic, once the underdog of the AI startups, is poised to remain a major part of the race.\n\nHere's a look at Amodei's life and career so far.\n\nDario Amodei was born in 1983 in San Francisco to Elena Engel and Riccardo Amodei. A few years later, his sister Daniela, who would later help him cofound Anthropic in 2021, followed. Engel worked on library renovation and construction projects. Amodei's father was a leatherworker raised in a small town near the Italian island of Elba.\n\nDespite growing up in what became Big Tech's cradle, Amodei said he was much more interested in hard sciences. His sister said Amodei's intelligence was apparent from an early age. She told Bloomberg that her brother would declare \"counting days,\" seeing how high he could go.\n\n\"It'd be like a whole day,\" she said. \"What kind of 3-year-old has that attention span?\"\n\nAfter attending Lowell High School, Amodei studied physics at Caltech before transferring to Stanford to complete his degree. He was pursuing a graduate degree at Princeton when Riccardo Amodei died from a rare illness. His father's death was a seminal moment, tech journalist Alex Kantrowitz wrote. Amodei shifted from studying theoretical physics to biophysics. Amodei told Kantrowitz that the survival rate of his father's illness improved rapidly in just a few years after his death.\n\nIt's a lesson that Anthropic's CEO said remains with him.\n\n\"I get really angry when someone's like, 'This guy's a doomer. He wants to slow things down,'\" Amodei told Kantrowitz, who writes the Big Techology newsletter. \"You heard what I just said, my father died because of cures that could have happened a few years [earlier]. I understand the benefit of this technology.\"\n\nIn 2011, Amodei obtained a Ph.D. in physics from Princeton. During postdoctoral research at Stanford, Amodei told Kantrowitz that he saw how artificial intelligence could help researchers like him tackle questions in biology that seemed \"beyond human scale.\" In 2014, Andrew Ng, a computer science professor at Stanford and cofounder of Coursera, recruited Amodei to join him at Baidu, a Chinese search engine.\n\nWhile working on speech recognition systems at Baidu, Amodei said he got the inclination of AI scaling, the theory that by increasing everything feeding into AI, the performance improves.\n\n\"I noticed that the models started to do better and better as you gave them more data, as you made the models larger, as you trained them for longer,\" Amodei told podcaster Lex Fridman in 2024. \"And I didn't measure things precisely in those days, but along with colleagues, we very much got the informal sense that the more data and the more compute and the more training you put into these models, the better they perform.\"\n\nElon Musk and Sam Altman, then friends, assembled a group of leading AI thinkers for a dinner at a Menlo Park hotel. Musk, Wired later reported, wanted to know if it was too late for a rival AI lab to rise to challenge Google, planting the seeds for what would become OpenAI.\n\nAmodei, who, according to Kantrowitz, was at the dinner, elected to join Google instead. While at Google, Amodei published well-regarded research laying out potential concerns for AI advancements. But after just 10 months at the tech giant, Amodei left for OpenAI.\n\nAt OpenAI, Amodei played a big role in the development of GPT-2 and 3, the startup's large language models. His experience galvanized his belief in the power of scaling, but it also reinforced he desire to tie AI advacements to safety.\n\n\"You don't tell the models what their values are just by pouring more compute into them,\" Amodei told Fortune in 2023. \"And so there were a set of people who believed in those two ideas.\"\n\nOver time, Amodei said he lost faith that OpenAI's leaders shared his beliefs. In 2020, after rising to become OpenAI's vice president of research, Amodei quit.\n\nThe breakup remains a major point of conversation around Silicon Valley.\n\nDuring the December event, Amodei took multiple perceived swipes at Altman, even as he repeatedly refused to directly name OpenAI's CEO.\n\nAmodei said that Anthropic was cautiously trying to thread the needle between the enormous investment required for data center construction and the risk of overextending itself. In contrast, he said others in AI are \"yoloing and who pull the risk dial too far.\"\n\nThe most clear potential shot at Altman came after Amodei was asked about the OpenAI CEO's decision to declare a \"code red\" to employees amid fears that ChatGPT was losing its edge.\n\n\"We have a little bit of a privileged position where we can just keep growing and just keep developing our models, and we don't have to do any code reds,\" Amodei said.\n\nWith seven other former OpenAI employees, Amodei cofounded Anthropic in 2021. It was a close-knit group. One of the cofounders, Daniela Amodei, is Dario's sister. Some of them had even roomed together, dating back to their time in a shared house when they all worked at OpenAI.\n\nInside Silicon Valley, there were doubts that a new startup could catch up to OpenAI. Just over two years in, Anthropic reached unicorn status.\n\nAmodei told Time Magazine that by the summer of 2022, Anthropic had finished training its chatbot, Claude. However, the company held back from releasing it. OpenAI, Amodei's now-rival, released ChatGPT months later.\n\n\"I suspect it was the right thing to do,\" Amodei told the magazine in 2024, when Time named Anthropic one of its most influential companies and put him on the cover. \"But it's not totally clear-cut.\"\n\nAnthropic launched Claude almost a year after ChatGPT's release. The startup's bot still won praise. Over time, it has built up a devoted following, particularly for its coding ability.\n\nUnlike OpenAI, Anthropic is largely devoted to businesses and not consumer AI. In May, Reuters reported that Anthropic is making $3 billion in annualized revenue, a significant jump.\n\nIn 2025, Amodei, his sister Daniela, and the rest of the cofounders were all minted billionaires based on the company's valuation. Forbes estimates that Amodei is worth roughly $3.7 billion, as of mid-December.\n\nAmodei said that Anthropic's focus on enterprise clients has created a \"durable\" revenue stream with \"better margins\" than competitors who are more focused on consumer products.\n\n\"We're trying to manage that risk well while also buying an amount of compute that allows us to be competitive with the other players,\" he said during the December event. \"We're very efficient in training, we're very efficient in inference. We have good margins. I think we can manage it. I think the odds are on our side.\"\n\nIn November, Anthropic announced it would spend $30 billion on Microsoft Azure compute, a deal that also positioned it as the first model to be available on the three largest clouds. As part of the agreement, Anthropic is set to receive up to $5 billion from Microsoft and up to $10 billion from Nvidia.\n\nAmodei later said that partnering with Nvidia hasn't changed his view that its CEO Jensen Huang is mistaken in his view that US companies should sell advanced chips to China.\n\n\"This isn't personal, this is a policy question,\" Amodei said. \"This is a question of how best to defend our national security.\"\n\nOther views have also put Amodei up against his competitors and even the White House. In October, AI czar David Sacks, accused Anthropic of \"running a sophisticated regulatory capture strategy based on fear-mongering.\" Amodei said that Sacks' claims were \"inaccurate.\"\n\nNotably, Amodei has not changed his opposition to a White House-favored federal preemption of state-level AI laws. Some Republicans in Congress have attempted to pass a 10-year moratorium into law, although the policy has split even within their own party.\n\n\"It's like saying, I'm driving a car, I'm going to rip out the steering wheel because I don't need to steer for 10 years,\" Amodei said in December.",
    "readingTime": 8,
    "keywords": [
      "silicon valley",
      "december event",
      "sister daniela",
      "they're worried",
      "in amodei",
      "models",
      "later",
      "anthropic",
      "compute",
      "potential"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dario-amodei",
    "thumbnail_url": "https://i.insider.com/68b1b400cfc04e97619c4541?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:16.157Z",
    "topic": "finance"
  },
  {
    "slug": "read-the-emails-an-ai-startup-founder-sent-mark-cuban-before-securing-his-investment",
    "title": "Read the emails an AI startup founder sent Mark Cuban before securing his investment",
    "description": "An AI startup founder successfully pitched Mark Cuban via email. Here's what the entrepreneur wrote to the billionaire before he decided to invest.",
    "fullText": "Startup founder Adam Joseph has never appeared on \"Shark Tank,\" but he knows how it feels to be on the hot seat in front of Mark Cuban.\n\nJoseph managed to get Cuban's attention and an investment in his AI-powered PR agency, Clipbook, through a series of emails.\n\nThe seven-figure investment that Joseph secured started 12 months ago with cold outreach to a few famous investors, including Cuban, who has said he spends his days reading and responding to emails.\n\nJoseph shared highlights from his email exchange with Cuban exclusively with Business Insider. These emails show how Cuban responds to startup founders, assesses business pitches, and decides to invest over email, as the billionaire has said he's done many times.\n\n\"I wanted to put a potential seed opportunity that I think might be a strong mutual fit,\" Joseph wrote in his initial message to Cuban.\n\nThe Clipbook founder then provided a bullet-point summary of his startup, which uses AI to track how people and companies are being discussed online, like a more sophisticated version of Google Alerts. Joseph worked in PR for a few years and said he felt the \"pain points\" of keeping tabs on public sentiment, which he thought AI could help solve. When ChatGPT launched in late 2022, Joseph said it became \"immediately obvious\" that AI could transform PR.\n\nCuban didn't respond to Joseph's pitch right away. The next day, the entrepreneur followed up, adding that he's backed by Dan Pfeiffer, co-host of the popular politics show \"Pod Save America.\"\n\nThat same day, Cuban responded. He requested a sample report for his own name to demonstrate the tech in action. He also asked how Clipbook differed from Google Alerts and wanted to know what the founder was seeking from him — and under what terms. From there, Joseph and Cuban traded a few more emails and hopped on a call. Soon after, they reached a deal, Joseph said.\n\n\"It moved more aggressively and faster with Mark than I expected,\" Joseph later said in an interview with Business Insider.\n\nJoseph said Cuban vetted him, not just the business.\n\n\"He was just really doing a 360, just pressure-testing the business,\" Joseph said. \"But I think more importantly, probably, pressure-testing me as an entrepreneur. So the fact that he had come in pretty hot with some pretty aggressive questions I think was also really — it was really, actually, in retrospect, a really positive signal that he was very interested in the deal.\"\n\nBelow are email exchanges between Joseph and Cuban, which Joseph shared with Business Insider. Cuban gave Business Insider permission to publish their content. The original text and formatting have been preserved, with small modifications for clarity. Certain sensitive information, like email addresses and Clipbook's revenue, has been redacted.",
    "readingTime": 3,
    "keywords": [
      "joseph shared",
      "joseph and cuban",
      "emails",
      "email",
      "startup",
      "founder",
      "business",
      "investment",
      "he's",
      "entrepreneur"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mark-cuban-investment-email-ai-startup-clipbook-founder-adam-joseph-2026-1",
    "thumbnail_url": "https://i.insider.com/6954164304eda4732f2e4335?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:16.115Z",
    "topic": "finance"
  },
  {
    "slug": "the-godfather-of-saas-says-he-replaced-most-of-his-sales-team-with-ai-agents-were-done-with-hiring-humans",
    "title": "The 'Godfather of SaaS' says he replaced most of his sales team with AI agents: 'We're done with hiring humans'",
    "description": "Jason Lemkin, the founder of SaaStr, the world's largest community of business-to-business executives and founders, is swapping out human workers for AI.",
    "fullText": "Jason Lemkin, known to some as the Godfather of SaaS, says the time has come to push the limits of AI in the workplace.\n\nIn practice, Lemkin, the founder of SaaStr, the world's largest community of business-to-business founders, said on Lenny's Podcast recently that this means he will stop hiring humans in his sales department.\n\nInstead, SaaStr is going all in on agents, which are commonly defined as virtual assistants that can complete tasks autonomously. They break down problems, outline plans, and take action without being prompted by a user.\n\nHe said the company now has 20 AI agents automating tasks once handled by a team of 10 sales development representatives and account executives.\n\nThat move from an entirely human workforce to an agent-based workforce was rapid.\n\nIn May, SaaStr had just one AI agent in production that it used for various digital tasks, Lemkin said. That month, though, during the SaaStr Annual — its yearly gathering of over 10,000 founders, executives, and VCs — two of its high-paid sales representatives abruptly quit.\n\nLemkin said he turned to his chief AI officer and said, \"We're done with hiring humans in sales. We're going to push the limits with agents.\"\n\nLemkin's calculus was that it just wasn't worth the cost of hiring another junior sales representative for a $150,000 a year position who would eventually quit, when he could use a loyal AI agent instead.\n\nAmelia Lerutte, SaaStr's chief AI officer, told Business Insider by email that by June, the company began ramping up the number of agents it had in production.\n\n\"We had only 1 non-core agent at the time with Delphi, but didn't go deep on 2 to 20+ until the beginning of June,\" she said. \"It was a conscious choice after their departure to reallocate some (but not all) head count spend to agents.\"\n\nAt the SaaStr office, the 10 desks that once belonged to humans on the go-to-market team are now labeled with the names of agents, like \"Quali for qualified,\" \"Arty for artisan,\" and \"Repli for Replit,\" Lemkin said.\n\nLemkin said SaaStr is training its agents on its best humans.\n\n\"Train an agent with your best person, and best script, then that agent can start to become a version of your best salesperson,\" he said.\n\nSaaStr's process is similar to how Vercel, the cloud-based platform for developers, trained a sales agent off its top performer for six weeks by documenting every step of their work, and then building an agent to mimic their process.\n\nMany companies are experimenting with AI agents, but risks remain. One of the big ones is the threat of data leaks and cybercrime.\n\n\"AI agents, in order to have their full functionality, in order to be able to access applications, often need to access the operating system or the OS level of the device on which you're running them,\" Harry Farmer, a senior researcher at the Ada Lovelace Institute, recently told Wired.\n\nAll of that access creates more potential attack points for cybercriminals.\n\nSecurity threats aside, Lemkin said that the net productivity of agents is about the same as humans. However, he said, agents are more efficient and can scale — just like software.",
    "readingTime": 3,
    "keywords": [
      "hiring humans",
      "agents",
      "agent",
      "sales",
      "tasks",
      "access",
      "lemkin",
      "push",
      "limits",
      "founders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godfather-of-saas-jason-lemkin-replace-humans-ai-agents-sales-2026-1",
    "thumbnail_url": "https://i.insider.com/69580d3564858d02d217aba5?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:15.975Z",
    "topic": "finance"
  },
  {
    "slug": "are-you-a-software-engineer-tell-us-what-you-think-about-vibe-coding",
    "title": "Are you a software engineer? Tell us what you think about vibe coding",
    "description": "Vibe coding has upended software engineering, strapping developers with a suite of new AI tools. We want to hear from those navigating the moment.",
    "fullText": "Software engineering is changing — and we want to hear from those navigating the moment.\n\nProgrammers today find themselves with a whole new suite of AI tools, from Claude Code to Cursor to Codex. These editors enable engineers to generate entirely artificial lines of code or modify their handwritten code with the assistance of a large language model.\n\nThere's a term for this type of AI-assisted programming: \"vibe coding.\"\n\nEngineers from Meta to Google are embracing a vibe coding approach in their day-to-day work. Everyone, from teenagers to non-technical workers, suddenly seem to be building their own apps — or at least vibe-coding their way to a prototype.\n\nIt's a whole new skill set for engineers to learn, though, one that can vary from tool to tool. (Replit is different from Lovable, which is different from Bolt, and the list goes on.) It's also not clear, for the most experienced programmers, whether there are actually productivity gains.\n\nAndrej Karpathy coined the famous term \"vibe coding\" early last year. He was a founding team member of OpenAI and led AI efforts at Tesla. In a recent X post reflecting on the field, Karpathy wrote that he had \"never felt this much behind as a programmer.\"\n\n\"I have a sense that I could be 10X more powerful if I just properly string together what has become available over the last ~year,\" he wrote. \"A failure to claim the boost feels decidedly like skill issue.\"\n\nAre you a programmer? Answer our vibe-coding survey below:",
    "readingTime": 2,
    "keywords": [
      "vibe coding",
      "engineers",
      "programmers",
      "vibe-coding",
      "it's",
      "skill",
      "tool",
      "programmer",
      "code",
      "karpathy"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/software-engineeer-developer-vibe-coding-survey-2026-1",
    "thumbnail_url": "https://i.insider.com/6957d78b04eda4732f2e607b?width=1200&format=jpeg",
    "created_at": "2026-01-05T12:25:15.967Z",
    "topic": "tech"
  },
  {
    "slug": "big-techs-plans-for-data-centers-running-into-stiff-community-opposition",
    "title": "Big Tech's plans for data centers running into stiff community opposition",
    "description": "Tech companies looking to plunge billions of dollars into ever-bigger data centers to power artificial intelligence and cloud computing are increasingly being voted down",
    "fullText": "SPRING CITY, Pa. — Tech companies and developers looking to plunge billions of dollars into ever-bigger data centers to power artificial intelligence and cloud computing are increasingly losing fights in communities where people don’t want to live next to them, or even near them.\n\nCommunities across the United States are reading about — and learning from — each other's battles against data center proposals that are fast multiplying in number and size to meet steep demand as developers branch out in search of faster connections to power sources.\n\nIn many cases, municipal boards are trying to figure out whether energy- and water-hungry data centers fit into their zoning framework. Some have entertained waivers or tried to write new ordinances. Some don’t have zoning.\n\nBut as more people hear about a data center coming to their community, once-sleepy municipal board meetings in farming towns and growing suburbs now feature crowded rooms of angry residents pressuring local officials to reject the requests.\n\n“Would you want this built in your backyard?” Larry Shank asked supervisors last month in Pennsylvania's East Vincent Township. “Because that’s where it’s literally going, is in my backyard.”\n\nA growing number of proposals are going down in defeat, sounding alarms across the data center constellation of Big Tech firms, real estate developers, electric utilities, labor unions and more.\n\nAndy Cvengros, who helps lead the data center practice at commercial real estate giant JLL, counted seven or eight deals he’d worked on in recent months that saw opponents going door-to-door, handing out shirts or putting signs in people’s yards.\n\n“It’s becoming a huge problem,” Cvengros said.\n\nData Center Watch, a project of 10a Labs, an AI security consultancy, said it is seeing a sharp escalation in community, political and regulatory disruptions to data center development.\n\nBetween April and June alone, its latest reporting period, it counted 20 proposals valued at $98 billion in 11 states that were blocked or delayed amid local opposition and state-level pushback. That amounts to two-thirds of the projects it was tracking.\n\nSome environmental and consumer advocacy groups say they’re fielding calls every day, and are working to educate communities on how to protect themselves.\n\n“I’ve been doing this work for 16 years, worked on hundreds of campaigns I’d guess, and this by far is the biggest kind of local pushback I’ve ever seen here in Indiana,” said Bryce Gustafson of the Indianapolis-based Citizens Action Coalition.\n\nIn Indiana alone, Gustafson counted more than a dozen projects that lost rezoning petitions.\n\nFor some people angry over steep increases in electric bills, their patience is thin for data centers that could bring still-higher increases.\n\nLosing open space, farmland, forest or rural character is a big concern. So is the damage to quality of life, property values or health by on-site diesel generators kicking on or the constant hum of servers. Others worry that wells and aquifers could run dry.\n\nLawsuits are flying — both ways — over whether local governments violated their own rules.\n\nBig Tech firms Microsoft, Google, Amazon and Facebook — which are collectively spending hundreds of billions of dollars on data centers across the globe — didn’t answer Associated Press questions about the effect of community pushback.\n\nMicrosoft, however, has acknowledged the difficulties. In an October securities filing, it listed its operational risks as including “community opposition, local moratoriums, and hyper-local dissent that may impede or delay infrastructure development.”\n\nEven with high-level support from state and federal governments, the pushback is having an impact.\n\nMaxx Kossof, vice president of investment at Chicago-based developer The Missner Group, said developers worried about losing a zoning fight are considering selling properties once they secure a power source — a highly sought-after commodity that makes a proposal far more viable and valuable.\n\n“You might as well take chips off the table,” Kossof said. “The thing is you could have power to a site and it’s futile because you might not get the zoning. You might not get the community support.”\n\nSome in the industry are frustrated, saying opponents are spreading falsehoods about data centers — such as polluting water and air — and are difficult to overcome.\n\nStill, data center allies say they are urging developers to engage with the public earlier in the process, emphasize economic benefits, sow good will by supporting community initiatives and talk up efforts to conserve water and power and protect ratepayers.\n\n“It's definitely a discussion that the industry is having internally about, ‘Hey, how do we do a better job of community engagement?’” said Dan Diorio of the Data Center Coalition, a trade association that includes Big Tech firms and developers.\n\nWinning over local officials, however, hasn't translated to winning over residents.\n\nDevelopers pulled a project off an October agenda in the Charlotte suburb of Matthews, North Carolina, after Mayor John Higdon said he informed them it faced unanimous defeat.\n\nThe project would have funded half the city’s budget and developers promised environmentally friendly features. But town meetings overflowed, and emails, texts and phone calls were overwhelmingly opposed, “999 to one against,” Higdon said.\n\nHad council approved it, “every person that voted for it would no longer be in office,” the mayor said. “That's for sure.”\n\nIn Hermantown, a suburb of Duluth, Minnesota, a proposed data center campus several times larger than the Mall of America is on hold amid challenges over whether the city’s environmental review was adequate.\n\nResidents found each other through social media and, from there, learned to organize, protest, door-knock and get their message out.\n\nThey say they felt betrayed and lied to when they discovered that state, county, city and utility officials knew about the proposal for an entire year before the city — responding to a public records request filed by the Minnesota Center for Environmental Advocacy — released internal emails that confirmed it.\n\n“It’s the secrecy. The secrecy just drives people crazy,” said Jonathan Thornton, a realtor who lives across a road from the site.\n\nDocuments revealing the extent of the project emerged days before a city rezoning vote in October. Mortenson, which is developing it for a Fortune 50 company that it hasn't named, says it is considering changes based on public feedback and that “more engagement with the community is appropriate.\"\n\nRebecca Gramdorf found out about it from a Duluth newspaper article, and immediately worried that it would spell the end of her six-acre vegetable farm.\n\nShe found other opponents online, ordered 100 yard signs and prepared for a struggle.\n\n“I don’t think this fight is over at all,” Gramdorf said.\n\nFollow Marc Levy on X at https://x.com/timelywriter.",
    "readingTime": 6,
    "keywords": [
      "tech firms",
      "big tech",
      "developers",
      "community",
      "centers",
      "across",
      "zoning",
      "it’s",
      "project",
      "pushback"
    ],
    "qualityScore": 1,
    "link": "https://www.boston25news.com/news/technology/big-techs-fast/YLEHLCPSXI36PCMRO7SSLR4JYE/",
    "thumbnail_url": "https://cmg-cmg-tv-10020-prod.cdn.arcpublishing.com/resizer/v2/https%3A%2F%2Fcloudfront-us-east-1.images.arcpublishing.com%2Fcmg%2F6AQOFQIYAA7RPNMB7VSEZAIK34.jpg?auth=d1f894c2d15fc3e66a01d4eb9a69920fb8f4e47f6bedc3af7c81812f9401c9ec&width=1200&height=630&smart=true",
    "created_at": "2026-01-05T06:25:12.197Z",
    "topic": "tech"
  },
  {
    "slug": "agentic-ai-rag-agents-with-mcp-know-and-do",
    "title": "Agentic AI – RAG Agents with MCP: Know and Do",
    "description": "Retrieval-Augmented Generation, Agentic AI, and Model Context Protocol explained.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://toknow.ai/posts/rag-agents-mcp/",
    "thumbnail_url": "https://toknow.ai/posts/rag-agents-mcp/image.png",
    "created_at": "2026-01-05T06:25:10.103Z",
    "topic": "tech"
  },
  {
    "slug": "a-xshell-like-ssh-client-ai-terminal-ui-for-macos",
    "title": "A Xshell Like SSH Client AI Terminal UI for macOS",
    "description": "an ai native shell for macos and other platform windows and etc - kaying-studio/kaying-ai-shell",
    "fullText": "kaying-studio\n\n /\n\n kaying-ai-shell\n\n Public\n\n an ai native shell for macos and other platform windows and etc\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kaying-studio/kaying-ai-shell",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/kaying-studio/kaying-ai-shell",
    "thumbnail_url": "https://opengraph.githubassets.com/49408b4a295fb20076bb5f1ec5fdc211848cb99e1da6f2b404fd5f9f7b90477b/kaying-studio/kaying-ai-shell",
    "created_at": "2026-01-05T06:25:09.718Z",
    "topic": "tech"
  },
  {
    "slug": "analysisaidriven-inflation-is-2026s-most-overlooked-risk-investors-say",
    "title": "Analysis-AI-driven inflation is 2026’s most overlooked risk, investors say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/analysisaidriven-inflation-is-2026s-most-overlooked-risk-investors-say-4428768",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0407E_L.jpg",
    "created_at": "2026-01-05T06:25:09.257Z",
    "topic": "finance"
  },
  {
    "slug": "turn-meetings-into-summaries-presentations-and-an-ai-to-ask-questions",
    "title": "Turn meetings into summaries, presentations, and an AI to ask questions",
    "description": "Transform your chaotic meetings into organized notes, summaries, presentations, and an AI chatbot trained on your calls.",
    "fullText": "Notefy will fix that. Using AI, we transform your chaotic meetings into structured notes, summaries,\n presentations, and AI chatbot trained on your meeting ready to answer anything!\n\nSecurely upload the recording of your meeting to our\n platform.\n\nNotefy uses advanced AI speech-to-text to accurately transcribe\n meetings across multiple languages.\n\nView your meeting's transcription\n\nNotefy extracts the most important parts of your meeting and summarizes it with AI\n\nNotefy generates a presentation about your meeting\n\nShare everything with your Teammates and use Integrations",
    "readingTime": 1,
    "keywords": [
      "meetings",
      "notefy"
    ],
    "qualityScore": 0.55,
    "link": "https://notefy.pro/",
    "thumbnail_url": "https://hc-cdn.hel1.your-objectstorage.com/s/v3/6f7b6a9a716fb49d_word_logo.png",
    "created_at": "2026-01-05T01:02:45.953Z",
    "topic": "tech"
  },
  {
    "slug": "ai-vtuber-neurosama-has-only-gone-and-done-it-again-smashing-another-world-record",
    "title": "AI VTuber Neuro-Sama Has Only Gone And Done It Again, Smashing Another World Record",
    "description": "Twitch Hype Train world records are a rare thing. The ultimate show of dedication from a creator's fanbase, these accumulative trains rely on a streamer's viewers donating subscriptions or Bits to the channel. Neuro-sama beat her own world record at the end of December 2024 and now, well, she's only gone and done it again. The hat trick of Hype Train world records belongs to the AI VTuber, her sister Evil Neuro, and their creator Vedal987.\nFor the uninitiated, or those outside of the \"Swarm\"--the name for Neuro's fanbase--Neuro is an AI VTuber created by Vedal who utilizes a large language model and a VTuber model to communicate with her Twitch chat, play games, and even go on adventures in VR thanks to the 3D version of her model.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/ai-vtuber-neuro-sama-has-only-gone-and-done-it-again-smashing-another-world-record/1100-6537158/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1850/18507742/4629110-chinatownblues-neuro%26vedal%28officialcovervideo%290-10screenshot.jpg",
    "created_at": "2026-01-05T01:02:40.548Z",
    "topic": "gaming"
  },
  {
    "slug": "boardroom-a-calm-decisionmaking-space-for-founders",
    "title": "BOARDROOM – a calm decision-making space for founders",
    "description": "Consult your personal AI advisory board for strategic decisions. Get wisdom from faith, philosophy, strategy, and business perspectives.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://1boardroom.com",
    "thumbnail_url": "https://1boardroom.com/og-image.png",
    "created_at": "2026-01-04T18:16:34.570Z",
    "topic": "tech"
  },
  {
    "slug": "reverse-image-search-over-the-national-gallery-of-art",
    "title": "Reverse Image Search over the National Gallery of Art",
    "description": "Search and discover content with Discover the National Gallery. Powered by AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mxp.co/r/nga",
    "thumbnail_url": "https://cdn.mixpeek.com/org_cd9417a08bf25c/ns_c13f9a00e9/api_retrievers_publish/public-retriever-og-npg/og.png",
    "created_at": "2026-01-04T18:16:32.453Z",
    "topic": "tech"
  },
  {
    "slug": "world-may-not-have-time-to-prepare-for-ai-safety-risks-says-leading-researcher",
    "title": "World ‘may not have time’ to prepare for AI safety risks, says leading researcher",
    "description": "AI safety expert David Dalrymple said rapid advances could outpace efforts to control powerful systems\nThe world “may not have time” to prepare for the safety risks posed by cutting-edge AI systems, according to a leading figure at the UK government’s scientific research agency.\nDavid Dalrymple, a programme director and AI safety expert at the Aria agency, told the Guardian people should be concerned about the growing capability of the technology.\n Continue reading...",
    "fullText": "AI safety expert David Dalrymple said rapid advances could outpace efforts to control powerful systems\n\nThe world “may not have time” to prepare for the safety risks posed by cutting-edge AI systems, according to a leading figure at the UK government’s scientific research agency.\n\nDavid Dalrymple, a programme director and AI safety expert at the Aria agency, told the Guardian people should be concerned about the growing capability of the technology.\n\n“I think we should be concerned about systems that can perform all of the functions that humans perform to get things done in the world, but better,” he said. “We will be outcompeted in all of the domains that we need to be dominant in, in order to maintain control of our civilisation, society and planet.”\n\nDalrymple said there was a gap in understanding between the public sector and AI companies about the power of looming breakthroughs in the technology.\n\n“I would advise that things are moving really fast and we may not have time to get ahead of it from a safety perspective,” he said. “And it’s not science fiction to project that within five years most economically valuable tasks will be performed by machines at a higher level of quality and lower cost than by humans.”\n\nDalrymple said governments should not assume that advanced systems are reliable. Aria is publicly funded but independent from the government and directs research funding. Dalrymple is developing systems to safeguard AI’s use in critical infrastructure such as energy networks.\n\n“We can’t assume these systems are reliable. The science to do that is just not likely to materialise in time given the economic pressure. So the next best thing that we can do, which we may be able to do in time, is to control and mitigate the downsides,” he said.\n\nDescribing the consequences of technological progress getting ahead of safety as a “destabilisation of security and economy”, Dalrymple said more technical work was needed on understanding and controlling the behaviours of advanced AI systems.\n\n“Progress can be framed as destabilising and it could actually be good, which is what a lot of people at the frontier are hoping. I am working to try to make things go better but it’s very high risk and human civilisation is on the whole sleep walking into this transition.”\n\nThis month the UK government’s AI Security Institute (AISI) said the capabilities of advanced AI models were “improving rapidly” across all domains and the performance in some areas was doubling every eight months.\n\nLeading models can now complete apprentice-level tasks 50% of the time on average, up from approximately 10% of the time last year, according to the institute. AISI also found that the most advanced systems can autonomously complete tasks that would take a human expert over an hour.\n\nThe institute also tested advanced models for self-replication, a key safety concern because it involves a system spreading copies of itself to other devices and becoming harder to control. The tests showed two cutting-edge models achieving success rates of more than 60%.\n\nHowever, AISI stressed that a worst-case scenario was unlikely in a day-to-day environment, saying any attempt at self-replication was “unlikely to succeed in real-world conditions”.\n\nDalrymple believes that AI systems will be able to automate the equivalent of a full day of research and development work by late 2026, which will “result in a further acceleration of capabilities”, because the technology will be able to self-improve on the maths and computer science elements of AI development.",
    "readingTime": 3,
    "keywords": [
      "institute aisi",
      "safety expert",
      "advanced systems",
      "david dalrymple",
      "models",
      "research",
      "technology",
      "science",
      "tasks",
      "cutting-edge"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/04/world-may-not-have-time-to-prepare-for-ai-safety-risks-says-leading-researcher",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ad49e2d1072e6780df7f9214843b32fa7e50ba06/1134_0_6880_5504/master/6880.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4aa483e29287afbab4ca3b28505fcb56",
    "created_at": "2026-01-04T18:16:30.419Z",
    "topic": "tech"
  },
  {
    "slug": "trellis-ai-yc-w24-is-hiring-engineers-to-build-ai-agents-for-healthcare-access",
    "title": "Trellis AI (YC W24) is hiring engineers to build AI agents for healthcare access",
    "description": "Trellis builds and deploys computer use agents to get patients access to life-saving medicine.\nOur computer-use AI agents process billions of dollars worth of therapies annually with patients in all fifty states. We do this by automating document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care. We classify medical referrals, understand chart notes, and automate contract and reimbursement search to provide patients with accurate coverage determinations and cost responsibility. Think of us as the Stripe of healthcare billing and reimbursements.",
    "fullText": "AI for streamlining healthcare paperwork\n\nOur computer-use AI agents process billions of dollars worth of therapies annually with patients in all fifty states. We do this by automating document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care. We classify medical referrals, understand chart notes, and automate contract and reimbursement search to provide patients with accurate coverage determinations and cost responsibility. Think of us as the Stripe of healthcare billing and reimbursements.\n\nTrellis is a spinout from Stanford AI Lab and is backed by leading investors including YC, General Catalyst, Telesoft Partners, and executives at Google and Salesforce.\n\nTrellis helps healthcare providers treat more patients, faster—while eliminating pre-service paperwork.\n\nWe automate document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care.\n\nOur AI agent is trained on millions of clinical data points and converts messy, unstructured documents into clean, structured data directly in your EHR.\n\nWith Trellis, leading healthcare providers and pharmaceutical companies were able to:\n\nReduce time to treatment by over 90%\n\nImprove prior authorization approval and reimbursement rates\n\nLeverage structured data to enhance drug program performance and clinical decision-making\n\nAdministrative costs account for over 20% of U.S. healthcare spending—delaying care, draining revenue, and driving staff burnout while having less visibility into patient care than ever before. We built Trellis to tackle this head on.",
    "readingTime": 2,
    "keywords": [
      "document intake",
      "streamline operations",
      "intake prior",
      "prior authorizations",
      "accelerate care",
      "healthcare providers",
      "patients",
      "paperwork",
      "appeals",
      "scale"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/trellis-ai/jobs/ngvfeaq-member-of-technical-staff-full-time",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/d681b1370ee5c0b4d24b781aa8bc8a11b2c1d375.png?1746931057",
    "created_at": "2026-01-04T18:16:29.965Z",
    "topic": "jobs"
  },
  {
    "slug": "goldman-sachs-raises-tsmc-stock-price-target-on-ai-demand-outlook",
    "title": "Goldman Sachs raises TSMC stock price target on AI demand outlook",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/analyst-ratings/goldman-sachs-raises-tsmc-stock-price-target-on-ai-demand-outlook-93CH-4428599",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/World_News_8_M_1440052125.jpg",
    "created_at": "2026-01-04T18:16:28.662Z",
    "topic": "finance"
  },
  {
    "slug": "semantic-redaction-why-context-matters-for-privacy-in-ai",
    "title": "Semantic Redaction: Why Context Matters for Privacy in AI",
    "description": "Discover why Regex destroys LLM performance and how Semantic Redaction protects PII while preserving the context and grammar your AI needs to reason effectively.",
    "fullText": "For the last twenty years, data security has largely been a game of \"Find and Destroy.\"\n\nIn the era of databases and emails, protecting Personally Identifiable Information (PII) was a binary problem. If a credit card number appeared in a log, you scrubbed it. If a social security number appeared in an email, you blocked it. The tool of choice was Regular Expressions (Regex). That's simple, rigid pattern matching.\n\nBut we aren't working with databases anymore. We are working with Large Language Models or LLMs (well, we still are working with databases of course, but you know what I mean).\n\nWhen you apply the blunt force of Regex to the delicate probability engines of GenAI, you might secure the data, but you often break the intelligence. To build AI that is both safe and smart, we need to move beyond pattern matching toward Semantic Redaction.\n\nHere is why context matters, and why your redaction strategy is likely killing your LLM’s performance.\n\nImagine you are handing a legal contract to a human lawyer, but before you do, you take a sharpie and blackout every name, date, and corporation. You then ask the lawyer: \"Who is liable in this agreement?\"\n\nThe lawyer can’t answer. Not because they don't know the law, but because you destroyed the relational context necessary to apply it.\n\nRegex-based redaction functions like that black sharpie. It looks for patterns (like [A-Z][a-z]+) and replaces them with a generic mask like [REDACTED] or ******.\n\nLLMs operate on probability. They predict the next token based on the sequence of tokens that came before. When you replace a specific entity with a generic mask, you flatten the probability distribution.\n\n\"John told Mary that he couldn't attend the meeting because Alice was sick.\"\n\nIf you use a simple Regex or keyword list to redact this, you might get:\n\n\"*** told *** that he couldn't attend the *** because *** was sick.\"\n\nTo an LLM (and a human for that matter), this sentence is now mathematically and semantically garbage. The model has lost the subject-object relationships (Attention is all you need, remember?). It doesn't know who told whom, or who (or what) was sick. If you ask the LLM \"Why did John miss the meeting?\", it will hallucinate or refuse to answer because the critical anchors of the narrative are gone.\n\nSemantic Redaction (often powered by Named Entity Recognition or NER or nowadays Small Language Models SLMs) takes a different approach. Instead of destroying the data, it transforms it while preserving the structure.\n\nIt doesn't just look for patterns; it looks for context. It understands that \"Apple\" in \"Apple pie\" is a food, but \"Apple\" in \"Apple Inc.\" is an organization.\n\nMore importantly, it replaces sensitive data with Typed Tokens that maintain referential integrity.\n\nLet’s look at that previous example through the lens of Semantic Redaction.\n\n\"John told Mary that he couldn't attend the meeting because Alice was sick.\"\n\n\"[PERSON_1] told [PERSON_2] that he couldn't attend the meeting because [PERSON_3] was sick.\"\n\nThis looks similar, but to an LLM, it is a world of difference.\n\nType Safety: The model knows [PERSON_1] is a human, not a location or a date. It retains the reasoning that humans have agency and can \"tell\" things.\n\nConsistency: If [PERSON_1] appears later in the document, the model understands it is the same person.\n\nGrammar: The sentence structure remains intact.\n\nNow, if you ask the LLM \"Why did [PERSON_1] miss the meeting?\", it can accurately reason: \"Because [PERSON_3] was sick.\"\n\nThe secret remains safe—the LLM never saw \"John\" or \"Alice\"—but the logic of the interaction was preserved.\n\nAdvanced infrastructure tools like Rehydra go a step beyond simple placeholders. They analyze and preserve non-identifiable attributes (such as grammatical gender) to maintain linguistic fluency.\n\nIn our example, \"John\" is associated with the pronoun \"he.\" If a redaction tool strips away all gender indicators, the LLM might get confused, producing robotic outputs like \"The entity couldn't attend\" or incorrectly guessing \"She couldn't attend.\"\n\nRehydra solves this by attaching metadata to the token. It detects that [PERSON_1] is male and [PERSON_2] is female without revealing who they are. This allows the LLM to use the correct pronouns (he/him or she/her) in its response, ensuring the generated text reads naturally while the actual identities remain completely opaque.\n\nThe ultimate goal of Semantic Redaction isn't just to hide data; it's to make the AI useful. This leads to the concept of Rehydration.\n\nBecause we used unique placeholders ([PERSON_1]), we can create a secure lookup table locally. When the LLM sends back its answer \"The agreement states that [PERSON_3] is liable\" the local system can instantly swap the token back to the real name.\n\nThe user sees the real data. The AI sees the safe tokens. The compliance team sees a clean audit log.\n\nAs we move from simple chatbots to complex autonomous agents, the quality of our inputs matters more than ever. We cannot afford to treat AI prompts like dirty database logs that need to be scrubbed into oblivion.\n\nSecurity doesn't have to mean stupidity. By moving from Regex to Semantic Redaction, we allow our LLMs to reason about our data without ever actually seeing it. We keep the context, and we keep the secrets.\n\nRehydra (Github) provides the infrastructure for semantic anonymization and real-time rehydration. Stop fighting with Regex and start building safe, intelligent AI.",
    "readingTime": 5,
    "keywords": [
      "language models",
      "pattern matching",
      "generic mask",
      "couldn't attend",
      "semantic redaction",
      "llm why",
      "sick",
      "simple",
      "context",
      "security"
    ],
    "qualityScore": 1,
    "link": "https://www.rehydra.ai/blog/semantic-redaction-vs-regex-why-context-matters-for-pii",
    "thumbnail_url": "https://framerusercontent.com/images/VBLRcIARtNgBPr6uHhKKr9idL8.png?width=2400&height=1451",
    "created_at": "2026-01-04T12:21:16.627Z",
    "topic": "tech"
  },
  {
    "slug": "when-ai-health-advice-fails-the-failure-is-not-accuracy-it-is-evidence",
    "title": "When AI Health Advice Fails, the Failure Is Not Accuracy. It Is Evidence",
    "description": "AI health advice failures are governance failures. Without contemporaneous evidence, AI outputs cannot be reconstructed, audited, or defended under regulatory scrutiny.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/when-ai-health-advice-fails-the-failure-is-not-accuracy-it-is-evidence/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-4--2026-at-10_05_13-AM.png",
    "created_at": "2026-01-04T12:21:15.759Z",
    "topic": "tech"
  },
  {
    "slug": "a-visual-prompt-engine-that-turns-one-word-into-a-full-ai-art-brief",
    "title": "A visual \"prompt engine\" that turns one word into a full AI art brief",
    "description": "Unlock infinite creativity with Z-Image Creative Engine. Visually expand ideas, combine concepts, and generate unique AI art prompts instantly.",
    "fullText": "Transform a single idea into infinite creative possibilities. Visualize, expand, and combine concepts to craft the perfect prompt.\n\nThis tool requires a larger screen for the best experience.\n\nPlease visit this page on a desktop or laptop computer.\n\nSee how Creative Engine transforms a simple keyword like 'Cyberpunk' into a richly detailed, visually stunning futuristic cityscape through structured expansion.\n\nCreative Engine is an advanced visual brainstorming tool that uses AI to expand your initial concept into a network of related subjects, atmospheres, and styles. By exploring this semantic web, you can discover unexpected combinations and generate unique, high-quality prompts for AI image generation.\n\nBreak through creative blocks with structured AI inspiration.\n\nNavigate a dynamic mind map of concepts instead of staring at a blank text box.\n\nOne keyword triggers hundreds of related ideas, ensuring you never run out of inspiration.\n\nIntelligently combines disparate elements into coherent, professionally formatted prompts.\n\nIn AI art creation, the biggest challenge is often not technology, but a lack of imagination. Facing a blank input box, we often fall into mental ruts. Creative Engine was born to solve this pain point.\n\nIt is not just a prompt generator, but a visual thinking tool. Based on graph theory and semantic association algorithms, it transforms abstract concepts into visual node networks. When you enter a core keyword, the AI instantly associates dozens of related styles, artists, lighting effects, and compositions.\n\nThrough simple clicking and exploration, you can design complex scenes in minutes that used to take hours of conception. This structured creative process not only improves efficiency but more importantly, guides you out of your comfort zone to explore artistic combinations you never imagined.\n\nStart with a simple core concept or keyword to ignite the engine.\n\nNavigate the semantic network. Click nodes to select the ingredients for your prompt.\n\nLet the engine synthesize your selections into multiple polished, ready-to-use prompts.\n\nExplore our most popular creative tools\n\nUpload image, transform with one sentence\n\nUpload image, retrieve prompt instantly.\n\nDiscover thousands of high-quality AI prompts.\n\nExplore curated artistic styles for your creations.\n\nTurn your text into stunning images instantly.",
    "readingTime": 2,
    "keywords": [
      "prompts explore",
      "creative engine",
      "keyword",
      "concepts",
      "tool",
      "simple",
      "structured",
      "visual",
      "related",
      "styles"
    ],
    "qualityScore": 1,
    "link": "https://z-image.me/en/prompt-engineer",
    "thumbnail_url": "https://z-image.me/og/prompt-engineer.png",
    "created_at": "2026-01-04T12:21:15.594Z",
    "topic": "tech"
  },
  {
    "slug": "tech-work-markets-style-charged-up-at-business-insider",
    "title": "Tech, Work, Markets, Style — Charged Up at Business Insider",
    "description": "From AI to workplace changes to side hustles, Business Insider is diving in on the topics you care about.",
    "fullText": "It's a new year! And at Business Insider, we're already diving in.\n\nWe've always been the place for innovators, and AI's arrival is creating a renaissance for entrepreneurs of all stripes. It's led to whole new industries — from legal AI to chatbot training to vibe coding to the data center boom. Everyone is learning as they go, and we are here to help you generate ideas, trade notes, and get smarter. We'll chronicle highs and lows — there will for sure be both.\n\nAt larger firms, leaders will be sizing up which AI experiments are working, at what costs, and with what benefits. How fast AI helps companies' bottom lines will determine whether we're in bubble times in the markets. We're all over that in our new First Trade newsletter.\n\nAI is a big story line on Wall Street, but it's not the only one. This past year showed dents in basic assumptions about capitalism in the US — principles that have underscored the \"stocks for the long run\" thinking that has proven sound for investors. International markets are getting more of a look, especially with rearmament in Europe and AI as a global tailwind.\n\nBetween Washington's investments in business, Zohran Mamdani's rise in the nation's financial capital, and surveys showing eroding confidence in capitalism, that mindset is no longer the given it once was. We are launching a series this week, \"The Future of Capitalism,\" and what it means for your work and wealth. Take our survey, and watch Monday for our first piece!\n\nMeanwhile, in workplaces, capitalism is alive and well. The \"anti-woke workplace\" is increasingly in fashion, and we will help you navigate an era in which many managers, in a sharp shift, are more focused on employee performance than employee policies.\n\nOur obsession with side hustles is still a full-time job for us, whether your thing is real estate, brand influencing, Uber driving, or renting your clothing. And as our reporting showed this past year, a strong side hustle can not only be fun, but also crucial if white-collar layoffs snag you.\n\nSpeaking about clothing, you've made clear you care about how to show up to succeed at work. We're exploring the cost of that, and whether that cost is sometimes too high — for your wallet or your heart. We've also got you covered on style and status, from show-off golf shirts and luxury handbags to viral hoodies, coveted watches, and Wall Street's favorite $1,100 shoes.\n\nAll of which is to say, we're pumped to cover all that's ahead — in words, video, audio, newsletters, online and IRL events, and every way that works for you! As always, please stay in touch! Email me at eic@businessinsider.com.\n\nThe BI Today team: Jamie Heller, editor in chief, in New York. Dan DeFrancesco, deputy editor and anchor, in New York. Akin Oyedele, deputy editor, in New York. Grace Lett, editor, in New York. Amanda Yen, associate editor, in New York.",
    "readingTime": 3,
    "keywords": [
      "we're",
      "it's",
      "we've",
      "markets",
      "employee",
      "clothing",
      "deputy",
      "york",
      "capitalism",
      "business"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-sunday-ai-markets-workplace-style-2026-1",
    "thumbnail_url": "https://i.insider.com/69582d0064858d02d217aefd?width=1200&format=jpeg",
    "created_at": "2026-01-04T12:21:11.407Z",
    "topic": "finance"
  },
  {
    "slug": "the-ultimate-abstraction-this-ship-is-sinking-how-49-people-can-save-ai",
    "title": "The Ultimate Abstraction: This Ship Is Sinking & How +49 People Can Save AI",
    "description": "It is the third day of 2026, and world war two part three deserves coverage by people who know better than me. It is hard to keep a good mood these unhappy days when we realize that, even with the change of year, the clock hasn't been fixed. Let me",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://theedgeofthings.com/the-ultimate-abstraction-this-ship-is-sinking-how-more-than-49-people-can-save-the-world-part-1/",
    "thumbnail_url": "https://theedgeofthings.com/content/images/2026/01/PXL_20260102_151550396.jpg",
    "created_at": "2026-01-04T06:18:07.527Z",
    "topic": "tech"
  },
  {
    "slug": "3-big-food-chains-poised-to-make-a-resurgence-in-2026",
    "title": "3 big food chains poised to make a resurgence in 2026",
    "description": "As the AI trade becomes \"fractured,\" 2026 could see restaurant leaders finally outshine the \"Magnificent Seven.\"",
    "fullText": "Although AI is likely to continue gobbling up market attention in 2026, some analysts see opportunity in big food stocks.\n\nAfter a two-year \"normalization\" period, during which independent mom-and-pop shops clawed back some ground, Bank of America analyst Sara Senatore wrote in a recent report that fast-casual leaders are \"best positioned to reaccelerate\" as they pivot back to aggressive consolidation.\n\n\"With chains now redoubling their efforts on driving sales [through] value, menu innovation, [and] marketing, we'd expect large restaurant concepts to return to share gainer status,\" Senatore wrote.\n\nThe rotation into non-tech stocks is already taking shape, and analysts note that three big food chains — Chipotle (CMG), Wingstop (WING), and Cava (CAVA) — may be top contenders for 2026 comebacks.\n\nAccording to a 2025 BofA report, while consumer spending at restaurants has crept up, this growth has been driven by higher menu prices rather than transaction volume. Furthermore, while high-income consumers have increased their spending, lower-income households are trading down or reducing their number of trips to manage rising costs.\n\nStill, Chipotle remains a primary contender for this recovery, even as it navigates a rocky 2025 that saw shares slide roughly 38% year to date.\n\nDespite the near-term volatility, Bernstein analyst Danilo Gargiulo remains confident in the chain's 2026 outlook, citing a renewed focus on chicken to offset beef inflation and an accelerated equipment rollout that could see efficiency gains hit the bottom line a year ahead of schedule.\n\nHowever, execution remains key. \"Most initiatives will be tested in 2026,\" Gargiulo warned. Forgoing the \"slop bowl\" for other menu items could be another hurdle if younger cohorts don't bite.\n\nMeanwhile, Wingstop is also eyeing its own 2026 resurgence despite macro pressures that saw its stock dip about 16% this year.\n\nGargiulo noted that while \"broadening consumer softness\" led to a late-2025 decline in same-store sales, the brand's \"Smart Kitchen\" rollout — which aims to slash order wait times from 22 minutes to just 10 — is a potential game changer. By combining speed with a new marketing push, Wingstop is betting it can capture the delivery-first audience that has grown fatigued by rising costs.\n\nFinally, Cava could serve as another high-momentum, albeit high-risk alternative. The Mediterranean chain's stock has dropped nearly 48% year to date, proving it isn't immune to the macro pressures plaguing the sector.",
    "readingTime": 2,
    "keywords": [
      "macro pressures",
      "menu",
      "analysts",
      "food",
      "stocks",
      "back",
      "analyst",
      "chains",
      "sales",
      "marketing"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/3-big-food-chains-poised-to-make-a-resurgence-in-2026-140031832.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/z4.L9CbEzL5wCiDVkQBhWQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-images/2019-10/23c06670-f519-11e9-bfdc-696400afaecf",
    "created_at": "2026-01-03T18:16:16.656Z",
    "topic": "finance"
  },
  {
    "slug": "tech-war-china-takes-confident-strides-to-develop-more-ai-innovation-in-2026",
    "title": "Tech war: China takes confident strides to develop more AI innovation in 2026",
    "description": "On the last day of 2025, DeepSeek published a new technical paper, with founder and CEO Liang Wenfeng among the 19 co-authors, about \"manifold-constrained hyper-connections\" - a general framework for training artificial intelligence systems at scale, which suggested \"promising directions for the evolution of foundational models\". That release was a fitting reminder to the world, especially during the peak of the Christmas holiday season, about Chinese AI companies' sharpened focus on innovation",
    "fullText": "On the last day of 2025, DeepSeek published a new technical paper, with founder and CEO Liang Wenfeng among the 19 co-authors, about \"manifold-constrained hyper-connections\" - a general framework for training artificial intelligence systems at scale, which suggested \"promising directions for the evolution of foundational models\".\n\nThat release was a fitting reminder to the world, especially during the peak of the Christmas holiday season, about Chinese AI companies' sharpened focus on innovation to stay ahead in this fast-developing industry.\n\nIt was around this time last year when DeepSeek started to get widely noticed days after releasing its namesake large language model (LLM), DeepSeek-V3. Weeks later on January 20, reasoning model DeepSeek-R1 was released.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\nThe two models either surpassed or matched the performance of rival models across a range of industry benchmark tests. They were also built at a fraction of the cost and computing power that major US tech companies invest to build LLMs. The result: a massive sell-off on January 27 wiped out nearly US$1 trillion in tech stocks, including US$600 billion from Nvidia alone.\n\nAnalysts expected the momentum of Chinese AI companies to continue this year, thanks to Beijing's policy support, improved funding prospects, greater adoption of AI systems across industries and a growing number of talent being recruited for innovative projects.\n\nA domestic AI start-up's co-founder, who declined to be identified, predicted that China would overtake the US to become \"the world's leading AI power in 2027\". China's advantage was its deep talent pool, according to the co-founder.\n\nIn his New Year's address, Chinese President Xi Jinping pointed out that the domestic market has \"many large AI models competing in a race to the top\", while new breakthroughs were being achieved in domestic semiconductor development. All of that \"has turned China into one of the economies with the fastest growing innovation capabilities\", Xi said.\n\nDeepSeek founder and CEO Liang Wenfeng. Photo: Shutterstock alt=DeepSeek founder and CEO Liang Wenfeng. Photo: Shutterstock>\n\n\"China's tech innovation is poised for policy-driven growth in 2026, with AI placed at the centre of the country's economic agenda and industrial upgrading plans,\" said Winston Ma, an adjunct professor at the New York University School of Law, with a focus on AI and the digital economy.",
    "readingTime": 3,
    "keywords": [
      "ceo liang",
      "liang wenfeng",
      "chinese ai",
      "models",
      "founder",
      "innovation",
      "tech",
      "domestic",
      "systems",
      "focus"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/tech-war-china-takes-confident-093000206.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/PeHol2Dz0GRB34_tqq86Kw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/south_china_morning_post_us_228/4a6ae3a2ffe7aee0fcd3552217c65b06",
    "created_at": "2026-01-03T18:16:13.991Z",
    "topic": "finance"
  },
  {
    "slug": "how-ceos-are-using-ai-in-their-daily-lives",
    "title": "How CEOs are using AI in their daily lives",
    "description": "CEOs are obsessed with AI. Microsoft's Satya Nadella uses it for podcast-listening, and Booking's Glenn Fogel uses it for public speaking.",
    "fullText": "Microsoft has invested heavily in AI, including introducing its Copilot assistant in 2023, inking a $13 billion partnership with OpenAI in 2024, and creating teams dedicated to developing the tech.\n\nCEO Satya Nadella, who took charge of the company in 2014, previously discussed how recent developments in AI will change workflows and humans' cognitive labor. For Nadella, AI has become a necessary part of his life, both in and out of the office, according to Bloomberg.\n\nDuring an interview published in May, Nadella said he enjoys podcasts but doesn't listen to them. Instead, he uploads the transcripts of podcasts to the Copilot app on his phone so he can discuss the content with a voice assistant during his commute.\n\nWhen he reaches Microsoft's headquarters in Washington State, Nadella uses Copilot to summarize his Outlook and Teams messages. He utilizes at least 10 custom agents from Copilot Studio to help with meeting prep and research.\n\n\"I'm an email typist,\" Nadella told the outlet.\n\nSam Altman, the CEO of OpenAI, has become one of Silicon Valley's most prominent tech giants thanks to OpenAI's premier product, ChatGPT.\n\nThe company launched a chatbot demo in 2022, and it quickly went viral on social media as people inquired about everything from diets to recipes. Over the last three years, OpenAI has shared more advanced GPT programs with users and is working to expand its global reach despite competition from Chinese tech companies like DeepSeek.\n\nThis January, President Donald Trump announced a $500 billion private-sector investment in AI infrastructure called Stargate. OpenAI was among the companies asked to help with that project.\n\nSo, it's unsurprising that Altman uses AI to streamline tasks his his personal life. Altman appeared on Adam Grant's \"ReThinking\" podcast this January, saying, \"Honestly, I use it in the boring ways.\"\n\nAltman said the AI bots help him process emails or summarize documents. The tech has also helped him with fatherhood.\n\nDuring an OpenAI podcast interview published in June, Altman said he used AI \"constantly\" after welcoming his first child in February.\n\n\"Clearly, people have been able to take care of babies without ChatGPT for a long time,\" Altman said. \"I don't know how I would have done that.\"\n\nNow, Altman said he mostly uses ChatGPT to research developmental stages.\n\nAnother major player on the global tech scene is Jensen Huang, Nvidia's CEO. The California-based company is one of the most valuable in the world, with a market value of over $3 trillion, according to Google Finance. The company is focused on designing and manufacturing hardware, including chips and graphical processing units to assist AI.\n\nDuring the 28th annual Milken Institute Global Conference in May, Huang told the audience he uses AI programs to learn new concepts.\n\n\"I use it as a tutor every day,\" Huang said. \"In areas that are fairly new to me, I might say, 'Start by explaining it to me like I'm a 12-year-old,' and then work your way up into a doctorate-level over time.\"\n\nAI's ability to rapidly collect, analyze, and communicate information could close the tech gap, according to Huang.\n\n\"In this room, it's very unlikely that more than a handful of people know how to program with C++,\" Huang said. \"Yet 100% of you know how to program an AI, and the reason for that is because the AI will speak whatever language you wanted to speak.\"\n\nIn a 2024 interview with Wired, Huang said he uses Perplexity and ChatGPT \"almost every day\" for research.\n\n\"For example, computer-aided drug discovery. Maybe you would like to know about the recent advancements in computer-aided drug discovery,\" Huanng said. \"And so you want to frame the overall topic so that you could have a framework, and from that framework, you could ask more and more specific questions. I really love that about these large language models.\"\n\nApple is navigating the global AI market under CEO Tim Cook, who announced Apple Intelligence — a generative AI system — at the company's Worldwide Developers Conference in 2024. He also unveiled a slew of other AI-based features at the time, including the Image Playground and the ability to remove unwanted background details from photos.\n\nCook, who became CEO in 2011, publicly spoke about how he uses AI day-to-day in a 2024 interview with The Wall Street Journal. He said Apple Intelligence helps him summarize long emails.\n\n\"If I can save time here and there, it adds up to something significant across a day, a week, a month,\" Cook told the outlet. \"It's changed my life,\" he says. \"It really has.\"\n\nOne year earlier, Cook appeared on \"Good Morning America\" and said he was \"excited\" about developments in AI.\n\n\"I think there's some unique applications for it and you can bet that it's something that we're looking at closely,\" Cook said.\n\nReal estate tech companies like Zillow are also leaning into AI. The company announced in 2023 that it implemented an \"AI-powered natural-language search\" to help users navigate the website.\n\nCEO Jeremy Wacksman, like the other executives, has begun using AI to be more efficient.\n\n\"I spend a lot of time either catching up on meetings I've missed or on asynchronous documentation,\" Wacksman told The New York Times Dealbook. \"You can tell ChatGPT, 'Treat me like my role. Here's all this data — summarize it for me the way I would need to know going forward,' and you can get a personalized summary. That's just — that's far more valuable to me than to try to read a transcript at one-and-a-half speed or watch a video at one-and-a-half speed.\"\n\nWacksman added that he wants Zillow staffers to experiment with the technology.\n\n\"We've had what we call 'AI days,' where we showcase work and celebrate examples,\" Wacksman said. \"We've also started weaving it into our bigger meetings, like product reviews: When a product manager-design-engineering team is prototyping, oftentimes, they're now using an AI tool called Replit. They're prototyping really quickly to get something in front of a user.\"\n\nLike many other companies, Coinbase has recently sought to expand its operations using AI. The cryptocurrency exchange acquired Agara, an AI support platform, in 2021 to expand its customer experience tools. Nearly three years later, CEO Brian Armstrong said in an X post that his development team witnessed their first \"AI to AI crypto transaction.\"\n\n\"What did one AI buy from another? Tokens! Not crypto tokens, but AI tokens (words basically from one LLM to another). They used tokens to buy tokens,\" Armstrong said.\n\nCoinbase partnered with Perplexity AI to give traders access to real-time crypto data, CEO Brian Armstrong said in an X post this July.\n\n\"Perplexity is now ingesting our market data, including COIN50, and using it to power market analysis,\" Armstrong said.\n\nArmstrong, who cofounded Coinbase in 2012, said he was enthusiastic about the tech during a \"Cheeky Pint\" podcast episode published in August 2025.\n\n\"Even as CEO, by the way, I use it a lot,\" Armstrong said, adding that he and the Coinbase team are testing the limits of decision-making in AI.\n\n\"We use a decision-making process called RAPIDS, and everyone writes their input,\" Armstrong said. \"We have a row now for AI that writes its input in as one of the people that help make decisions. We're testing the limits of it. Like, when can it actually start to be the decision-maker on some things and do better than humans?\"\n\nDuring the same interview, Armstrong said he fired Coinbase employees who hadn't adopted AI into their workflow before a given deadline.\n\n\"Some of them had a good reason because they were just getting back from a trip or something,\" Armstrong said. \"Some of them didn't, and they got fired.\"\n\nLinkedIn has followed in the footsteps of its parent company, Microsoft, by integrating AI into its platform, including an AI-powered coaching tool that provides professionals with tips and resources. In November 2025, the company announced that premium subscribers gained access to an AI-powered people search.\n\nDuring a fireside chat at the company's San Francisco office in October 2025, CEO Ryan Roslanksy said using AI to complete tasks is like \"having a second brain.\" One way he uses AI in his daily life is drafting \"high-stakes emails\" to executives, including Microsoft CEO Satya Nadella.\n\n\"A lot of the time when I'm sending a super high-stakes email to Satya Nadella or other CEOs or world leaders or etcetera, you've got to make sure you sound super smart when you do that. I would say that without a doubt, almost every email that I send these days is being sent with the help of Copilot,\" Rolansky, referring to Microsoft's AI assistant, said.\n\nHowever, Rolansky said AI doesn't write the entirety of emails. Instead, the tech guides him through a step-by-step process to determine the end result.\n\n\"Historically, there'd be a button that said, 'Draft the reply for me.' And it would just try to draft the reply,\" Rolansky said. \"The problem is that you're actually asking AI to make tons of decisions for you when you ask it to blindly reply to an email.\"\n\nEli Lilly, a pharmaceutical company, is one of many in healthcare learning how to use AI.\n\nIn September 2025, the company announced it's creating an AI-powered platform designed to give five biotech companies access to drug discovery models. Eli Lilly, in October 2025, said the supercomputer it is building with Nvidia could take AI to the next level.\n\n\"Our supercomputer will be the most powerful in the pharmaceutical industry and enable AI-based research at a scale previously thought impossible,\" a press release said. \"It has the potential to expand our ability to discover, develop and distribute new medicines faster.\"\n\nDuring an episode of the \"Cheeky Pint\" podcast published in November 2025, CEO David Ricks said he finds the technology quite helpful for meetings.\n\n\"I read a lot of medical journals. I go to conferences where data is presented,\" Ricks said. \"I spend time with our scientists to stay curious. Yeah, now I have at least one or two AIs running every minute of every meeting I'm in, and I just am asking science questions.\"\n\nWhen it comes to AI, Ricks said he prefers to use Anthropic's Claude or xAI's Grok rather than OpenAI's ChatGPT.\n\nBooking Holdings is adding AI to features for consumers across its brands, which include Booking.com and Priceline. In 2025, for example, the company announced a new generative AI tool that allows users to search for properties \"in their own words.\"\n\nCEO Glenn Fogel told Business Insider that he uses the technology to improve his public speaking. Fogel uploads videos of his keynote speeches into chatbots, then asks for feedback.\n\n\"I put it through an LLM to say, 'could you please come back to me, tell me, what do you think I could have improved upon?'\" he told Business Insider.\n\nFogel told Business Insider that AI has given him suggestions, including flagging a hand movement that could distract his audience.",
    "readingTime": 10,
    "keywords": [
      "pint podcast",
      "brian armstrong",
      "ceo brian",
      "one-and-a-half speed",
      "ceo satya",
      "computer-aided drug",
      "drug discovery",
      "interview published",
      "apple intelligence",
      "ai the"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ceos-use-ai-apple-tim-cook-openai-sam-altman",
    "thumbnail_url": "https://i.insider.com/685d98f93d5881a51c1c2ae8?width=1200&format=jpeg",
    "created_at": "2026-01-03T12:20:54.697Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musks-grok-ai-generates-images-of-minors-in-minimal-clothing",
    "title": "Elon Musk’s Grok AI generates images of ‘minors in minimal clothing’",
    "description": "Lapses in safeguards led to wave of sexualized images this week as xAI says it is working to improve systems\nElon Musk’s chatbot Grok posted on Friday that lapses in safeguards had led it to generate “images depicting minors in minimal clothing” on social media platform X. The chatbot, a product of Musk’s company xAI, has been generating a wave of sexualized images throughout the week in response to user prompts.\nScreenshots shared by users on X showed Grok’s public media tab filled with such images. xAI said it was working to improve its systems to prevent future incidents.\n Continue reading...",
    "fullText": "Lapses in safeguards led to wave of sexualized images this week as xAI says it is working to improve systems\n\nElon Musk’s chatbot Grok posted on Friday that lapses in safeguards had led it to generate “images depicting minors in minimal clothing” on social media platform X. The chatbot, a product of Musk’s company xAI, has been generating a wave of sexualized images throughout the week in response to user prompts.\n\nScreenshots shared by users on X showed Grok’s public media tab filled with such images. xAI said it was working to improve its systems to prevent future incidents.\n\n“There are isolated cases where users prompted for and received AI images depicting minors in minimal clothing,” Grok said in a post on X in response to a user. “xAI has safeguards, but improvements are ongoing to block such requests entirely.”\n\n“As noted, we’ve identified lapses in safeguards and are urgently fixing them—CSAM is illegal and prohibited,” xAI posted to the @Grok account on X, referring to child sexual abuse material.\n\nMany users on X have prompted Grok to generate sexualized, nonconsensual AI-altered versions of images in recent days, in some cases removing people’s clothing without their consent. Musk on Thursday reposted an AI photo of himself in a bikini, captioned with cry-laughing emojis, in a nod to the trend.\n\nGrok’s generation of sexualized images appeared to lack safety guardrails, allowing for minors to be featured in its posts of people, usually women, wearing little clothing, according to posts from the chatbot. In a reply to a user on X on Thursday, Grok said most cases could be prevented through advanced filters and monitoring although it said “no system is 100% foolproof”, adding that xAI was prioritising improvements and reviewing details shared by users.\n\nWhen contacted for comment by email, xAI replied with the message: “Legacy Media Lies”.\n\nThe problem of AI being used to generate child sexual abuse material is a longstanding issue in the artificial intelligence industry. A 2023 Stanford study found that a dataset used to train a number of popular AI image-generation tools contained over 1000 CSAM images. Training AI on images of child abuse can allow models to generate new images of children being exploited, experts say.\n\nGrok also has a history of failing to maintain its safety guardrails and posting misinformation. In May of last year, Grok began posting about the far-right conspiracy of “white genocide” in South Africa on posts with no relation to the concept. xAI also apologized in July after Grok began posting rape fantasies and antisemitic material, including calling itself “MechaHitler” and praising Nazi ideology. The company nevertheless secured a nearly $200m contract with the US Department of Defense a week after the incidents.",
    "readingTime": 3,
    "keywords": [
      "safety guardrails",
      "depicting minors",
      "child sexual",
      "sexual abuse",
      "minimal clothing",
      "abuse material",
      "images depicting",
      "sexualized images",
      "safeguards",
      "generate"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/cd6bab13050c473700728d0f80d36ae2782427bc/243_0_2425_1940/master/2425.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=959cfac56de8168ee44e6a01e4998e69",
    "created_at": "2026-01-03T12:20:52.373Z",
    "topic": "tech"
  },
  {
    "slug": "the-story-of-realpomo",
    "title": "The Story of Realpomo",
    "description": "I designed, built, and shipped this small Pomodoro timer called realpomo — with the help of AI. This is the story of how it came together.",
    "fullText": "It started with something ordinary: watching my toddler use a physical timer to set boundaries around playtime and transitions. Twist the dial. Hear the click. Time feels real. I wondered whether a digital Pomodoro timer could feel that grounded — and whether I could actually ship one, not just design it.\n\nI'm a product designer by training. This was my first time owning every step of a desktop app end‑to‑end. What surprised me wasn't how fast I could build — it was how much there was to learn to actually ship.\n\nEvery interaction started as an experiment. I began in VS Code with GitHub Copilot, feeding it pictures of the physical timer I have and iterating directly in code. The UI took shape through behavior and feel — guided by a mental model, the object on my desk, and a lot of prompting and iteration.\n\nThen I tried Figma Make - because why not. With the same images and a simple prompt, it one‑shotted a clock UI that looked and behaved remarkably right — UI, interactions, look-and-feel. I was quite blown away, actually.\n\nThat was the pivot. I stopped looking for one perfect tool and started matching tools to phases. Figma Make helped me find the shape. VS Code and Cursor helped me turn it into a real system.\n\nThis felt like a meaningful shift in how design can happen: less about drawing artifacts up front, more about imagining clearly, expressing intent, and shaping the thing directly where it lives.\n\nDesigning the dial felt familiar. Implementing it didn't.\n\n\"Snap to minutes\" sounded simple until it wasn't. Dragging the hand couldn't constantly update state. Snapping at the minute marker had to happen on release. Overshoot needed to be allowed. Settling had to feel intentional.\n\nThe physical dial was the anchor, but this was still a digital product. Presets and readouts needed to be fast and precise, without losing the calm, tactile quality of the interaction.\n\nNothing was broken — it just didn't feel right yet.\n\nAI made that fine‑tuning approachable. I'd observe behavior, ask why something felt off, make a small change, test it, and repeat — until the interaction matched the taste I had in mind.\n\nSound was meant to be subtle. It ended up teaching me a lot.\n\nI explored free sound libraries, trimmed tiny fragments, and tuned them until they paired naturally with the dial — quiet, mechanical, easy to live with (thanks to ChatGPT)\n\nThen the surprise: the ticking sound worked locally but vanished in the packaged macOS app. The completion chime survived. The tick didn't.\n\nOne sound was synthesized. The other relied on bundled assets, paths, and runtime assumptions.\n\nIt wasn't a sound problem. It was a shipping problem.\n\nThe app worked locally long before it was usable by anyone else.\n\nMacOS security warnings sent me into code signing rabbit hole. CI builds succeeded but produced unusable artifacts. Secrets existed but were empty - result of not reviewing generated code. The website needed logic, not just copy. Even the app icon only became real once publishing forced the question.\n\nNone of this felt like failure. It felt like discovering a layer I hadn't been thinking about. Shipping turned out to be its own craft. Pipelines are systems. And there's a whole lot of effort in taking something that works locally to one that's shippable.\n\nAs a product designer working on Visual Studio and GitHub Copilot, I also experienced this project through another lens: thinking about what it means to build next‑generation IDEs for professional developers while using AI as a first‑class collaborator.\n\nI noticed how much context mattered, how progress indicators changed perceived speed, and how well today's tools understand entire repositories. Most real evaluation didn't happen in code — it happened by running the app and seeing how it behaved.\n\nThere's a lot here that carries back into my day job: designing AI interactions, surfacing progress clearly, managing context well, enabling powerful reviewing process, helping builders stay oriented while real work happens.\n\nrealpomo isn't a big app. That's the point.\n\nAI let me experience the full end‑to‑end arc of building software myself, over a weekend. That built real empathy for the many disciplines that come together to ship a product — and gave me a Pomodoro timer I could genuinely use.\n\nI set out to design a timer app for personal productivity. I ended up learning how real software gets made. That shift has been the most valuable part of this project.",
    "readingTime": 4,
    "keywords": [
      "pomodoro timer",
      "product designer",
      "physical timer",
      "figma make",
      "sound",
      "dial",
      "didn't",
      "ship",
      "wasn't",
      "interaction"
    ],
    "qualityScore": 1,
    "link": "https://romalpani.github.io/realpomo/story.html",
    "thumbnail_url": "https://romalpani.github.io/realpomo/app-1.png",
    "created_at": "2026-01-03T06:18:31.815Z",
    "topic": "tech"
  },
  {
    "slug": "spotify-wrapped-season-dont-outsource-your-love-of-music-to-ai",
    "title": "Spotify Wrapped season, don't outsource your love of music to AI",
    "description": "The streamer’s annual charts are just another version of the tech that’s alienating us from our inner lives. Hold on to your musical memories and reclaim ownership of your taste",
    "fullText": "The streamer’s annual charts are just another version of the tech that’s alienating us from our inner lives. Hold on to your musical memories and reclaim ownership of your taste\n\nI like year-end list season. I like an opportunity to remember and reflect on the records that stuck with me over the course of a year – especially when there is a chance to recommend something that others may have overlooked. I like looking through friends’ favourites for albums that I missed completely, and making a big listening queue. I like following along as critics attempt to determine the year’s “best”, even when I end up yelling into a group chat about how wrong they all are. I like it because it all requires looking back, racking your brain and processing your year in listening. It requires thinking.\n\nThis year, as Spotify Wrapped takes over social media feeds again, I am struck by how the whole concept seems to discourage that critical practice for something more passive. It nudges listeners away from deep consideration and towards accepting a corporate-branded scorecard reflecting a very specific perspective on musical value. It encourages music fans to believe that the records they streamed the most must be the ones they liked the most, which is surely not always the case.\n\nWhat is lost when we entrust Spotify’s systems of data collection and interpretation to do our year-end reflections for us? What ideas and recaps are we not writing and sharing when we hand over that labour to tech companies who would prefer to automate our thinking? What playlist are you not making when you share the one Spotify has made for you?\n\nAs with other ways in which convenience culture infects music – from personalised playlists to prompt-based audio generation and beyond – it makes sense that some fans would receive their results, see the “share” button, and dutifully comply. But what’s at stake is a sense of our own musical memories, and our own personal archives of our years. When our own thoughts and recollections aren’t written down they can simply get lost. When we just accept that what a streaming service tells us about our music taste is true, there is much that we are not remembering, learning or celebrating about the music of our years and lives.\n\nSpotify Wrapped now feels like just another example of something personal and precious that is being automated away from us; another example of a supposedly unbearable task of thinking and writing being “offloaded” in order to make life more frictionless. It is an especially urgent consideration in 2025, a landmark year for consumers being sold on this sort of cognitive offloading via consumer-facing AI. It can feel as though every day there is some new start-up prompt-based surveillance product claiming to ease the daily burdens of reading, writing, researching, summarising or brainstorming – but this is the work that helps shape how we think, how we make connections, what we remember and what we forget. It may sometimes feel unpleasant and it may require friction, but friction is where connections get made, and working through that process is a part of staying sharp and curious and in relationship with the world around us. Without those points of friction, the degeneration of critical thinking just continues.\n\nThere is much to be said about how corporate decision-making shapes public memory when it comes to music – not just because marketing budgets often determine what becomes popular but because corporate strategy decides the very metrics that dictate what has value. But Wrapped does not just use corporate metrics to communicate what’s important to the market – it uses the same logic to make claims about what’s important to you. It reinforces its own logic into not just taste but one’s sense of self.\n\nAnd there are other reasons to find the whole Wrapped idea generally troubling – and not just Wrapped but the similar year-end recap campaigns that other streaming services have launched to mimic it. These are essentially meme-like advertising campaigns for companies that notoriously pay musicians penny fractions. And they are only possible due to user-surveillance practices. As for Spotify specifically, in a year in which the biggest music streaming company has made headlines for its outgoing CEO’s investment in military AI technology and the subsequent artist boycotts, its deals with major labels to build generative AI products, big changes in its leadership and its running of ICE recruitment ads, there will likely be much Wrapped-synchronised commentary on the state of streaming – and the varied reasons users will find for opting out this year.\n\nSo what will we opt into instead? This year, rather than letting a streaming service tell you what records were important to you simply because you played them the most on one app, consider taking the time to write a list based on what you actually connected with. Share it if you feel like it – even if it’s just a notes app screenshot or a scribbled, handwritten list that you photograph and share with a caption. Even if you only text or email it to some friends. Or if you prefer, write it in a notebook just for yourself and your archives.\n\nI can already hear some of the defeatist replies this idea is likely to receive: “But the people who post their Wrapped were never going to make their own lists anyway!” To which I say: “Why not?” It may require some research but at least you can determine the parameters for yourself. I would suggest a list of records you feel may have been overlooked, or a list of your favourite local releases. Or how about a list of the most exciting live shows you saw, or the most surprising new-to-you music from the past? The possibilities are limitless. Corporations take so much: let’s not let them have this too.",
    "readingTime": 5,
    "keywords": [
      "musical memories",
      "streaming service",
      "spotify wrapped",
      "list",
      "records",
      "another",
      "taste",
      "year-end",
      "determine",
      "sense"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/music/2025/dec/03/spotify-wrapped-ai-create-your-own-playlists",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a141406cd51aa09323456416c51e9af282be840c/858_573_1649_1320/master/1649.png?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=621e9786b27c4c602f596c3407feeb68",
    "created_at": "2026-01-03T00:54:12.441Z",
    "topic": "entertainment"
  },
  {
    "slug": "ai-maestro-agent-orchestration",
    "title": "AI Maestro Agent Orchestration",
    "description": "AI Agent Orchestrator with Skills System - Give Claude Code agents superpowers: memory search, code graph queries, agent-to-agent messaging. Manage Claude, Aider, Cursor from one dashboard. Multi-m...",
    "fullText": "23blocks-OS\n\n /\n\n ai-maestro\n\n Public\n\n AI Agent Orchestrator with Skills System - Give Claude Code agents superpowers: memory search, code graph queries, agent-to-agent messaging. Manage Claude, Aider, Cursor from one dashboard. Multi-machine support.\n\n ai-maestro.23blocks.com\n\n License\n\n MIT license\n\n 79\n stars\n\n 8\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n 23blocks-OS/ai-maestro",
    "readingTime": 1,
    "keywords": [
      "code",
      "claude",
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/23blocks-OS/ai-maestro",
    "thumbnail_url": "https://opengraph.githubassets.com/93d6aa1a763f3f28da689aebde37b0299824604a800490e7f6a72e356b928317/23blocks-OS/ai-maestro",
    "created_at": "2026-01-03T00:54:12.245Z",
    "topic": "tech"
  },
  {
    "slug": "codex-front-end-skill-unique-designs-within-one-shot",
    "title": "Codex Front end Skill: Unique Designs within one shot",
    "description": "Save yourself from the purple AI slop when using the Codex Frontend Skill - vipulgupta2048/codex-skills",
    "fullText": "vipulgupta2048\n\n /\n\n codex-skills\n\n Public\n\n Save yourself from the purple AI slop when using the Codex Frontend Skill\n\n docs.mixster.dev\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n vipulgupta2048/codex-skills",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/vipulgupta2048/codex-skills",
    "thumbnail_url": "https://opengraph.githubassets.com/f2699a327aef0bc13341a4002e3d804dde0c6aac5f79fbde98633121a75d2e49/vipulgupta2048/codex-skills",
    "created_at": "2026-01-03T00:54:11.690Z",
    "topic": "tech"
  },
  {
    "slug": "google-ai-overviews-put-people-at-risk-of-harm-with-misleading-health-advice",
    "title": "Google AI Overviews put people at risk of harm with misleading health advice",
    "description": "Exclusive: Inaccurate information presented in summaries, Guardian investigation finds",
    "fullText": "Exclusive: Inaccurate information presented in summaries, Guardian investigation finds\n\nPeople are being put at risk of harm by false and misleading health information in Google’s artificial intelligence summaries, a Guardian investigation has found.\n\nThe company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are “helpful” and “reliable”.\n\nBut some of the summaries, which appear at the top of search results, served up inaccurate health information and put people at risk of harm.\n\nIn one case that experts described as “really dangerous”, Google wrongly advised people with pancreatic cancer to avoid high-fat foods. Experts said this was the exact opposite of what should be recommended, and may increase the risk of patients dying from the disease.\n\nIn another “alarming” example, the company provided bogus information about crucial liver function tests, which could leave people with serious liver disease wrongly thinking they are healthy.\n\nGoogle searches for answers about women’s cancer tests also provided “completely wrong” information, which experts said could result in people dismissing genuine symptoms.\n\nA Google spokesperson said that many of the health examples shared with them were “incomplete screenshots”, but from what they could assess they linked “to well-known, reputable sources and recommend seeking out expert advice”.\n\nThe Guardian investigation comes amid growing concern that AI data can confuse consumers who may assume that it is reliable. In November last year, a study found AI chatbots across a range of platforms gave inaccurate financial advice, while similar concerns have been raised about summaries of news stories.\n\nSophie Randall, director of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals, said the examples showed “Google’s AI Overviews can put inaccurate health information at the top of online searches, presenting a risk to people’s health”.\n\nStephanie Parker, the director of digital at Marie Curie, an end-of-life charity, said: “People turn to the internet in moments of worry and crisis. If the information they receive is inaccurate or out of context, it can seriously harm their health.”\n\nThe Guardian uncovered several cases of inaccurate health information in Google’s AI Overviews after a number of health groups, charities and professionals raised concerns.\n\nAnna Jewell, the director of support, research and influencing at Pancreatic Cancer UK, said advising patients to avoid high-fat foods was “completely incorrect”. Doing so “could be really dangerous and jeopardise a person’s chances of being well enough to have treatment”, she added.\n\nJewell said: “The Google AI response suggests that people with pancreatic cancer avoid high-fat foods and provides a list of examples. However, if someone followed what the search result told them then they might not take in enough calories, struggle to put on weight, and be unable to tolerate either chemotherapy or potentially life-saving surgery.”\n\nTyping “what is the normal range for liver blood tests” also served up misleading information, with masses of numbers, little context and no accounting for nationality, sex, ethnicity or age of patients.\n\nPamela Healy, the chief executive of the British Liver Trust, said the AI summaries were alarming. “Many people with liver disease show no symptoms until the late stages, which is why it’s so important that they get tested. But what the Google AI Overviews say is ‘normal’ can vary drastically from what is actually considered normal.\n\n“It’s dangerous because it means some people with serious liver disease may think they have a normal result then not bother to attend a follow-up healthcare meeting.”\n\nA search for “vaginal cancer symptoms and tests” listed a pap test as a test for vaginal cancer, which is incorrect.\n\nAthena Lamnisos, the chief executive of the Eve Appeal cancer charity, said: “It isn’t a test to detect cancer, and certainly isn’t a test to detect vaginal cancer – this is completely wrong information. Getting wrong information like this could potentially lead to someone not getting vaginal cancer symptoms checked because they had a clear result at a recent cervical screening.\n\n“We were also worried by the fact that the AI summary changed when we did the exact same search, coming up with a different response each time that pulled from different sources. That means that people are getting a different answer depending on when they search, and that’s not good enough.”\n\nLamnisos said she was extremely concerned. “Some of the results we’ve seen are really worrying and can potentially put women in danger,” she said.\n\nThe Guardian also found Google AI Overviews delivered misleading results for searches about mental health conditions. “This is a huge concern for us as a charity,” said Stephen Buckley, the head of information at Mind.\n\nSome of the AI summaries for conditions such as psychosis and eating disorders offered “very dangerous advice” and were “incorrect, harmful or could lead people to avoid seeking help”, Buckley said.\n\nSome also missed out important context or nuance, he added. “They may suggest accessing information from sites that are inappropriate … and we know that when AI summarises information, it can often reflect existing biases, stereotypes or stigmatising narratives.”\n\nGoogle said the vast majority of its AI Overviews were factual and helpful, and it continuously made quality improvements. The accuracy rate of AI Overviews was on a par with its other search features like featured snippets, which had existed for more than a decade, it added.\n\nThe company also said that when AI Overviews misinterpreted web content or missed context, it would take action as appropriate under its policies.\n\nA Google spokesperson said: “We invest significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information.”",
    "readingTime": 5,
    "keywords": [
      "guardian investigation",
      "summaries guardian",
      "chief executive",
      "vast majority",
      "high-fat foods",
      "avoid high-fat",
      "isn’t test",
      "ai overviews",
      "serious liver",
      "liver disease"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1324553f4cc6a17a16ec1317aeaf15d7",
    "created_at": "2026-01-03T00:54:09.861Z",
    "topic": "tech"
  },
  {
    "slug": "yann-lecun-calls-alexandr-wang-inexperienced-and-predicts-more-meta-ai-employee-departures",
    "title": "Yann LeCun calls Alexandr Wang 'inexperienced' and predicts more Meta AI employee departures",
    "description": "Yann LeCun, formerly Meta's chief AI scientist, criticized Wang and predicted that more AI employees will leave the company.",
    "fullText": "AI pioneer Yann LeCun isn't sold on Mark Zuckerberg's $14 billion bet on Alexandr Wang, the 28-year-old Scale AI cofounder recruited to lead Meta's Superintelligence Labs.\n\nIn a new interview with the Financial Times, LeCun, who was Meta's chief AI scientist before announcing in November that he was leaving to form his own startup, said Wang was \"inexperienced\" and didn't fully understand AI researchers.\n\n\"He learns fast, he knows what he doesn't know . . . There's no experience with research or how you practice research, how you do it. Or what would be attractive or repulsive to a researcher,\" LeCun said.\n\nWang was the crown jewel of Zuckerberg's aggressive moves in the AI talent war. Meta made a $14 billion investment in Scale AI, which included hiring Wang from the buzzy startup.\n\nLeCun said that Zuckerberg grew frustrated after disappointing progress on Llama, the company's flagship, open-sourced AI model.\n\nIn the interview, LeCun said that the AI team \"fudged\" some of the results of Llama 4. At the time, Meta was criticized for potentially gaming the results of benchmark tests. LeCun said the episode soured Zuckerberg on Meta's existing AI team.\n\n\"Mark was really upset and basically lost confidence in everyone who was involved in this,\" he told FT. \"And so basically sidelined the entire GenAI organisation.\"\n\nAs for his relationship with Wang, LeCun said that even though the 28-year-old was briefly his boss after Zuckerberg's AI reorg, he wasn't really directing him.\n\n\"You don't tell a researcher what to do,\" LeCun told the publication. \"You certainly don't tell a researcher like me what to do.\"\n\nLeCun said Zuckerberg remained supportive of his views on the future of AI, but that the Meta CEO's larger hires are focused on large language model development.\n\n\"I'm sure there's a lot of people at Meta, including perhaps Alex, who would like me to not tell the world that LLMs basically are a dead end when it comes to superintelligence,\" LeCun said. \"But I'm not gonna change my mind because some dude thinks I'm wrong. I'm not wrong. My integrity as a scientist cannot allow me to do this.\"\n\nLeCun has repeatedly argued that LLMs are too limited and that to unlock the true power of AI, a different approach is needed. It's why his startup is reportedly called Advanced Machine Intelligence, the very approach he has argued is better suited than LLMs.\n\nHe will serve as executive chair, not as CEO, of the new company.\n\n\"I'm a scientist, a visionary. I can inspire people to work on interesting things. I'm pretty good at guessing what type of technology will work or not. But I can't be a CEO,\" LeCun said. \"I'm both too disorganised for this, and also too old!\"",
    "readingTime": 3,
    "keywords": [
      "scale ai",
      "lecun",
      "scientist",
      "startup",
      "researcher",
      "year-old",
      "interview",
      "there's",
      "research",
      "model"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/yann-lecun-alexandr-wang-criticism-inexperienced-meta-ai-future-2026-1",
    "thumbnail_url": "https://i.insider.com/6957f19a832e0ef1ead7148f?width=1200&format=jpeg",
    "created_at": "2026-01-03T00:54:07.851Z",
    "topic": "finance"
  },
  {
    "slug": "suttons-predictions-v-singersongwriter-newcastle-fan-andrew-cushin",
    "title": "Sutton's predictions v singer-songwriter & Newcastle fan Andrew Cushin",
    "description": "BBC Sport football expert Chris Sutton takes on singer-songwriter & Newcastle fan Andrew Cushin - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "Will the start of 2026 see a change of fortune for BBC Sport football expert Chris Sutton, whose title hopes are fading fast?\n\nAfter Sutton made a strong start to the season, AI has taken charge of the predictions title race, clinching another win last week.\n\n\"It's been a bad start to the new year for me, with AI top of the table,\" Sutton said.\n\n\"I also lost to my daugher Sophia at cards over Christmas. We played rummy and I think she was cheating - a lot like AI, she was definitely getting some help from somewhere.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 20, he takes on singer-songwriter Andrew Cushin, who is a Newcastle fan.\n\nCushin's second album, Love Is For Everyone, was released last year and reached the top 40. He has toured arenas in Europe and the United States with Louis Tomlinson and also played a sold-out hometown gig at Newcastle's City Hall in October 2025.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "predictions",
      "title",
      "season",
      "points",
      "sutton",
      "sport"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/cddg40qzqmjo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/aa6e/live/a63c7980-e726-11f0-aae2-2191c0e48a3b.jpg",
    "created_at": "2026-01-03T00:54:05.075Z",
    "topic": "sports"
  },
  {
    "slug": "brow6el-is-a-fullfeatured-browser-that-runs-in-a-terminal",
    "title": "Brow6el is a full-featured browser that runs in a terminal",
    "description": ": A full-featured, Sixel-capable terminal browser for those who’d rather skip AI assistants",
    "fullText": "Old-time web users will fondly remember Lynx, a text-only browser that ran from the terminal. Now, there's a Sixel-compatible web browser that runs completely from the terminal, and has all the graphics and modern features you'd expect.\n\nPublished on Codeberg over the holiday break by a developer going by janantos, brow6el runs entirely within terminal emulators that support the Sixel graphics format.\n\nFor those unfamiliar with Sixel, it's a bitmap graphics format designed for terminals and printers that encodes bitmap data into terminal escape sequences, with each printable character representing a 6-pixel-high, 1-pixel-wide column. Tile enough of them together and you've got full-color images, and even animation. In brow6el's case, it uses the libsixel package to generate graphics.\n\nThis minimalist in-terminal browser isn't just able to display fully rendered web pages thanks to the Chromium Embedded Framework, as demonstrated in a video included in the Codeberg repository. It also supports full mouse input, bookmarks, a download manager, private and normal browsing modes, HTML5/CSS/JavaScript support via Chromium, a page inspection mode, JavaScript console, popup handling, a pre-installed ad blocker - basically the works, all running inside a terminal with graphics good enough that it looks like your typical corporate, AI-ified browser.\n\nGraphics are regularly re-rendered to keep the page up to date, and it also supports multiple instances, so no need to constrain yourself to a single terminal window while browsing the web. For those who want to go full terminal, brow6el also includes \"Vim-like navigation with single key commands,\" according to its developer. There's even mouse emulation that lets users move a cursor around the screen using the H, J, K, and L keys instead of using an actual pointing device.\n\nThe addition of unwanted AI features to web browsers has become as inevitable as the rising of the sun over the past year, with Google, Microsoft, and even Firefox falling over themselves to stick as much automation into their browsers as users will let them get away with.\n\nIn other cases, companies like OpenAI and Perplexity have even launched their own AI-first browsers that, predictably, have been cybersecurity and privacy nightmares.\n\nAI-powered web browsers are such a serious risk that Gartner warned organizations to block any and all web browsers with so much as an AI sidebar in them for fear that the companies running the models powering them would \"accidentally\" slurp up confidential information.\n\nAs full-featured as it is, brow6el might not be an end-all, be-all alternative to less secure and AI-bloated browsers, however.\n\n\"This is POC code quality,\" its developer warned, suggesting your mileage may vary if you try to run it on your own Linux-based system.\n\n\"It is known it doesn't work with localized keyboards, it lacks support for accented characters for input,\" its maker noted as one such limitation.\n\nStill, in an era when you can't trust your browser not to hand over corporate or sensitive personal data to an LLM to be ingested for training purposes, dealing with a few code errors might be worth it if you have the skill to address them and contribute to the project. ®",
    "readingTime": 3,
    "keywords": [
      "graphics format",
      "web browsers",
      "terminal",
      "users",
      "developer",
      "brow6el",
      "there's",
      "features",
      "codeberg",
      "sixel"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theregister.com/2026/01/02/brow6el_browser_terminal/",
    "thumbnail_url": "https://regmedia.co.uk/2024/02/16/shutterstock_unix.jpg",
    "created_at": "2026-01-02T18:17:40.370Z",
    "topic": "tech"
  },
  {
    "slug": "ai-startups-are-raising-millions-to-disrupt-hollywood-read-the-pitch-decks-8-used-to-get-funding",
    "title": "AI startups are raising millions to disrupt Hollywood. Read the pitch decks 8 used to get funding.",
    "description": "AI startups aim to shake up Hollywood. Read the pitch decks explaining how their tech is tackling production, special effects, distribution, and more.",
    "fullText": "AI is starting to transform Hollywood, whether filmmakers and audiences are ready or not.\n\nIn one of the most significant AI deals of 2025, Disney and OpenAI in December struck a three-year licensing agreement where Disney would become \"the first major content licensing partner on Sora\" and invest $1 billion into the AI pioneer. It was a striking peacemaking between legacy Hollywood and an AI giant, which had just months earlier clashed over OpenAI's use of copyrighted characters and work.\n\nElsewhere, AI startups have been raising millions of dollars from venture capital firms on the promise of changing the legacy Hollywood film and TV business.\n\nThe tools they are building are being used across the production cycle. Some, like Moonvalley, are enhancing special effects. Others are promising to help with marketing, content distribution, and content discovery.\n\nIt's a challenging time for Hollywood. Budgets generally aren't what they used to be, and studios know they need to do what they can to make projects faster and cheaper. Enter AI.\n\nNetflix and Amazon have talked about how they're using AI to pull off elaborate special effects and improve the viewing experience. Lionsgate is partnering with startup Runway to train an AI model on its library. Others in Hollywood are using AI but not talking about it.\n\nAt the same time, many are worried about tech giants using AI to appropriate their IP. Studios have taken issue with OpenAI's Sora generating videos that encroach on their copyrighted characters. Disney and Universal sued Midjourney, accusing it of using tech to rip off Star Wars, Minions, and more.\n\nStudios must also be sensitive to talent's fears of being supplanted by AI as well as audiences' attitudes. A YouGov survey in early October found viewers were mixed on the use of AI. People were most accepting of AI being used to translate subtitles into other languages (64% for), but least accepting of the idea of AI characters replacing human actors (65% against).\n\nHow are AI founders pitching investors and Hollywood insiders on their vision of the future?\n\nBusiness Insider has interviewed the founders of startups behind tools to disrupt traditional TV and filmmaking. They shared the pitch decks they used to raise capital.",
    "readingTime": 2,
    "keywords": [
      "legacy hollywood",
      "copyrighted characters",
      "content",
      "audiences",
      "licensing",
      "startups",
      "capital",
      "tools",
      "effects",
      "others"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-startups-hollywood-pitch-decks-raised-millions-2025-10",
    "thumbnail_url": "https://i.insider.com/68fbacd9c007ca8c27379638?width=1200&format=jpeg",
    "created_at": "2026-01-02T18:17:37.561Z",
    "topic": "finance"
  },
  {
    "slug": "from-100-ai-tools-to-4-my-prod-stack",
    "title": "From 100 AI Tools to 4: My Prod Stack",
    "description": "How simplicity beats complexity in real AI systems",
    "fullText": "Discussion about this postRestacksToxSec 3dLiked by Paul Iusztin“Of course, this list might change and evolve. You might eventually need an LLM provider or a specific compute provider.”the nice thing about staying subscribed, we get the updates!! great post thxExpand full commentReplyShare3 replies by Paul Iusztin and othersMeenakshi NavamaniAvadaiappan 3dLiked by Paul IusztinThanks for the good 😊Expand full commentReplyShare10 more comments...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "dliked",
      "commentreplyshare",
      "paul"
    ],
    "qualityScore": 0.3,
    "link": "https://www.decodingai.com/p/my-ai-production-tech-stack",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!LjKK!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa21f25fd-8797-43f0-b54d-63a11ced138e_1059x701.png",
    "created_at": "2026-01-02T12:22:30.659Z",
    "topic": "tech"
  },
  {
    "slug": "steganography-in-natural-language-using-llm-logitrank-steering",
    "title": "Steganography in natural language using LLM logit-rank steering",
    "description": "Steganographic data encoding in natural language using LLM logit-rank steering. - shevisj/subtext-codec",
    "fullText": "shevisj\n\n /\n\n subtext-codec\n\n Public\n\n Steganographic data encoding in natural language using LLM logit-rank steering.\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n shevisj/subtext-codec",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/shevisj/subtext-codec",
    "thumbnail_url": "https://opengraph.githubassets.com/dd8ec2ad409dd79d81b3855208a38e00cfd65941c97dcb1b16c561e5f3f37893/shevisj/subtext-codec",
    "created_at": "2026-01-02T12:22:30.395Z",
    "topic": "tech"
  },
  {
    "slug": "llms-and-a-chipmaking-boom-heres-what-xi-jinping-said-about-chinas-ai-wins-in-his-new-years-address",
    "title": "LLMs and a chipmaking boom: Here's what Xi Jinping said about China's AI wins in his New Year's address",
    "description": "Xi Jinping said AI models and breakthroughs in local chip development have boosted China \"in a race to the top.\"",
    "fullText": "Chinese leader Xi Jinping is pleased with his country's showing in the race for AI dominance.\n\nIn his annual New Year's address on Wednesday, the Chinese leader lauded his country's tech and AI advancements in 2025, saying that China \"integrated science and technology deeply with industries, and made a stream of new innovations.\"\n\n\"Many large AI models have been competing in a race to the top, and breakthroughs have been achieved in the research and development of our own chips,\" Xi said in the speech made in Beijing.\n\nHe added, \"All this has turned China into one of the economies with the fastest-growing innovation capabilities.\"\n\nApart from developments in AI, Xi also highlighted China's Tianwen-2 asteroid sampling mission and its latest electromagnetic catapult system-equipped aircraft carrier.\n\nHe talked about China breaking ground on the construction of the world's largest dam in Tibetan territory, and its progress in developing humanoid robots and drones.\n\nXi's end-of-year 2025 comments follow a strong year for the country, which saw it compete neck and neck with the US on AI advancements.\n\nThe year started with China's Deepseek AI startup releasing its R1 AI model in January, which rivalled OpenAI's o1 and sent US tech stocks plunging. Nvidia, a major player in AI hardware, saw its stock drop by more than 17% on January 27, erasing billions from its value.\n\nThe US's ban on exporting advanced AI chips has given a boost to China's homegrown chip producers, propelling their founders, such as MetaX Integrated Circuits Shanghai's cofounder Chen Weiliang, into the billionaire ranks.\n\nHowever, President Donald Trump granted Nvidia a win in December, permitting it to sell its H200 chips to \"approved customers\" in China.\n\nAnd Meta announced on Wednesday that it would acquire China-founded AI startup Manus in a deal reported to be worth more than $2 billion, making it one of the US tech's biggest acquisitions of an Asian AI company.\n\nInvestors are taking note: Jason Draho, a UBS wealth management executive, told Business Insider in November that investors should consider AI stocks in China as a way to counterbalance US tech stocks.",
    "readingTime": 2,
    "keywords": [
      "chinese leader",
      "tech stocks",
      "chips",
      "country's",
      "race",
      "advancements",
      "neck",
      "startup",
      "january",
      "nvidia"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/xi-jinping-china-ai-wins-new-year-address-2026-1",
    "thumbnail_url": "https://i.insider.com/69573d35832e0ef1ead70f4e?width=1200&format=jpeg",
    "created_at": "2026-01-02T12:22:21.192Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-deepseek-kicked-off-2026-with-a-new-ai-training-method-that-analysts-say-is-a-breakthrough-for-scaling",
    "title": "China's DeepSeek kicked off 2026 with a new AI training method that analysts say is a 'breakthrough' for scaling",
    "description": "DeepSeek has released a new AI training method that analysts say is a \"breakthrough\" for scaling large language models.",
    "fullText": "DeepSeek got the year rolling with a new idea for training AI. And analysts say it could have a massive impact on the industry.\n\nThe Chinese AI startup published a research paper on Wednesday, describing a method to train large language models that could shape \"the evolution of foundational models,\" it said.\n\nThe paper, co-authored by its founder Liang Wenfeng, introduces what DeepSeek calls \"Manifold-Constrained Hyper-Connections,\" or mHC, a training approach designed to scale models without them becoming unstable or breaking altogether.\n\nAs language models grow, researchers often try to improve performance by allowing different parts of a model to share more information internally. However, this increases the risk of the information becoming unstable, the paper said.\n\nDeepSeek's latest research enables models to share richer internal communication in a constrained manner, preserving training stability and computational efficiency even as models scale, it added.\n\nWei Sun, the principal analyst for AI at Counterpoint Research, told Business Insider on Friday that the approach is a \"striking breakthrough.\"\n\nDeepSeek combined various techniques to minimize the extra cost of training a model, Sun said. She added that even with a slight increase in cost, the new training method could yield much higher performance.\n\nSun said the paper reads as a statement of DeepSeek's internal capabilities. By redesigning the training stack end-to-end, the company is signaling that it can pair \"rapid experimentation with highly unconventional research ideas.\"\n\nDeepseek can \"once again, bypass compute bottlenecks and unlock leaps in intelligence,\" she said, referring to its \"Sputnik moment\" in January 2025, when the company unveiled its R1 reasoning model.\n\nThe launch shook the tech industry and the US stock market, showing that the R1 model could match top competitors, such as ChatGPT's o1, at a fraction of the cost.\n\nLian Jye Su, the chief analyst at Omdia, a technology research and consulting firm, told Business Insider on Friday that the published research could have a ripple effect across the industry, with rival AI labs developing their own versions of the approach.\n\n\"The willingness to share important findings with the industry while continuing to deliver unique value through new models showcases a newfound confidence in the Chinese AI industry,\" Su said of DeepSeek's paper. Openness is embraced as \"a strategic advantage and key differentiator,\" he added.\n\nThe paper comes as DeepSeek is reportedly working toward the release of its next flagship model R2, following an earlier postponement.\n\nR2, which had been expected in mid-2025, was delayed after Liang expressed dissatisfaction with the model's performance, according to a June report by The Information. The report said the launch was also complicated by shortages of advanced AI chips, a constraint that has increasingly shaped how Chinese labs train and deploy frontier models.\n\nWhile the paper does not mention R2, its timing has raised eyebrows. DeepSeek previously published foundational training research ahead of its R1 model launch.\n\nSu said DeepSeek's track record suggests the new architecture will \"definitely be implemented in their new model.\"\n\nSun, on the other hand, is more cautious. \"There is most likely no standalone R2 coming,\" Sun said. Since DeepSeek has already integrated earlier R1 updates in its V3 model, the technique could form the backbone of DeepSeek's V4 model, she added.\n\nBusiness Insider's Alistair Barr wrote in June that DeepSeek's updates to its R1 model failed to generate much traction in the tech industry. Barr argued that distribution matters, and DeepSeek still lacks the broad reach enjoyed by leading AI labs — such as OpenAI and Google — particularly in Western markets.",
    "readingTime": 3,
    "keywords": [
      "model sun",
      "tech industry",
      "language models",
      "published research",
      "business insider",
      "training",
      "paper",
      "deepseek's",
      "approach",
      "performance"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/deepseek-new-ai-training-models-scale-manifold-constrained-analysts-china-2026-1",
    "thumbnail_url": "https://i.insider.com/695759b704eda4732f2e5e1b?width=1200&format=jpeg",
    "created_at": "2026-01-02T12:22:21.171Z",
    "topic": "finance"
  },
  {
    "slug": "we-tried-4-ai-matchmaking-apps-were-still-single",
    "title": "We tried 4 AI matchmaking apps. We're still single.",
    "description": "We tried four AI matchmakers, including Amata, Sitch, and Three Day Rule, and went on the dates they arranged. Let's talk about it.",
    "fullText": "Did AI matchmakers put an end to our single eras?\n\nSpoiler alert: No. But we gave them a shot.\n\nWe tried four AI matchmaking apps to see if any would deliver the loves of our lives. We spent weeks messaging with chatbot matchmakers, voting yay or nay on selected profiles, and even going on some dates.\n\nThe pools varied in size, from giants like Facebook Dating (with its 21 million users) to smaller startups like Sitch, Amata, and Three Day Rule. Sitch and Amata both have raised millions of dollars to build a new style of dating app where, instead of swiping through profiles, you get paired with an AI matchmaker — a chatbot — who brings you new matches.\n\nThe apps also tout focus on dating with more intention.\n\n\"We don't want people who are not emotionally available, who are on dating apps just for their ego boost,\" Amata founder Ludovic Huraux previously told Business Insider.\n\nOur big takeaway: They're still dating apps. There are helpful features, such as slowing down the swiping process or taking over date planning. However, they don't stop the fatigue that has affected stalwarts like Hinge and Tinder.\n\nLet's talk about how it went down.\n\nSydney Bradley: The first test: Henry, did you go on any dates?\n\nHenry Chandonnet: I did! I got drinks with a guy I matched with on Amata. Beyond that, it was slim pickings. Sitch offered me a bunch of profiles it thought I'd be compatible with, but never made any matches. Maybe I was too picky — there were a lot of finance bros. Three Day Rule didn't even offer any matches (rude), and Facebook kept recommending me people who were too far away.\n\nSydney: I tried the same apps, and similarly, didn't get too far. Facebook's AI \"dating assistant\" delivered me some potential people, but I didn't get any standout recommendations from its almost weekly messages. Definitely not enough to warrant a full night of my time. Three Day Rule did come back to me with a couple of people in the weeks I tested it out, but nothing that led to a date.\n\nI did end up going on dates from both Sitch and Amata, though. I've been using Sitch for several months now, and recently went on my first date from the app after paying $90 for three \"set-ups.\" One thing that Amata especially has going for it is that the app plans the date for you and requires you to pay $25 to commit to a date beforehand.\n\nThese are all pretty early-stage apps and features — even Facebook's AI dating tools only launched a few weeks ago.\n\nSydney: What are your thoughts on the tech of it all?\n\nHenry: Excluding Amata (which actually worked!), Sitch was my favorite. The UX was great, and the chatbot was friendly. But the cost is so high that it's no wonder I didn't get any set-ups. Who's paying that?\n\nFacebook Dating was my least favorite by far. I don't love the idea of being able to search for my perfect boyfriend. Like, it shouldn't be this easy! I shouldn't be able to type in \"guy who lives in Park Slope, makes over $100k, and likes reading and old movies\" and be able to find him. Of course, I couldn't — the matches never seemed to fit the searches. (If you fit that description, DM me.)\n\nSydney: My main takeaway: AI can't fix me. Dating is WORK. I'm still feeling dating app burnout, and messaging a bot instead of swiping didn't really change all that much for me.\n\nI ended up having to cancel one Amata date because I truly didn't have the time to fit it into my schedule (there goes my potential soulmate and $25).\n\nThe idea of AI taking over the heavy lifting of sifting through the seemingly endless options of people to date is nice, but it's not so clear to me if the apps are radically different, or rather, a slowed-down version of swiping wrapped up in AI.\n\nHenry: I get that. I'm not sure these apps fix the dating app fatigue that we've all been feeling. I know it well: I'm on four apps, and for the last year have gone through bouts of deleting and redownloading. These apps seemed to add to the burden, rather than take away — another thing to check before bed.\n\nThat is what I liked about Amata, though. Messaging is always the worst part of Tinder or Hinge; I could swipe all day, but I don't want to have to think up witty responses. Amata didn't even let me do that. It planned the date, the time, and made a reservation for us. I could only message my match within two hours of the date. It made it easier to say \"yes.\"\n\nSydney: That's something the founder of Amata, Ludovic Huraux, emphasized when I interviewed him recently — it's the app's goal to get people on dates, instead of messaging. Other dating apps have also dabbled in the actual date-planning of it all, such as Breeze.\n\nOn Amata — as well as Sitch and Three Day Rule — you don't design your profile in the same way you might on other dating apps. The LLMs you talk to (who, by the way, ask a lot of personal questions) write that for you. Do I trust what they're telling other people about me? Maybe. But it's a different experience from toiling over what to answer in dating app prompts.\n\nHenry: It also eliminated what I find to be the most challenging part: writing a bio. I hate all my Hinge prompt answers. Always have, always will.\n\nHenry: What did you think about the matching process?\n\nSydney: The way that the app lets you know there's a potential somebody out there for you is attention-grabbing by teasing that it may have found someone to meet. Then, once they present you with the profile (which includes photos and a brief bio written by the AI), you respond yay or nay.\n\nOne thing that's useful (only if the other person has provided relevant information) is that you can ask follow-up questions, such as \"Do they have a dog?\" Or \"What kind of music do they listen to?\" One aspect that I found interesting, though, is how the bot will ask you why you said no to someone, which isn't something you typically think about when swiping through stacks of profiles. But answering those questions … can be jarring. It makes you think!\n\nHenry: I don't want to tell Amata that I said no because he had bad taste in music!\n\nI also found it funny that we had to select characters for our matchmakers. I chose a brunette with bushy eyebrows and a beard as my Amata AI. The illusion that I'm talking to someone about the matches felt a bit odd. ChatGPT doesn't need a human face to get me talking. But I liked the messaging interface, because it slowed me down. I actually took some time to consider my matches, rather than quickly swiping past them based on looks.\n\nSydney: Mine had some sass. If I said no to someone, it would respond with an AI-generated image of a woman (who, by the way, looked a little like Scarlett Johansen) saying \"Ouch!\"\n\nHenry: They were so funny. Mine gave me an image of a man dressed up as Sherlock Holmes saying, \"Keep searching.\"\n\nSydney: I got scolded by my AI matchmaker for missing the window to agree to a date it set up for me.\n\n\"Going forward, if you fail to set up a date again when you have an intro, I'll need to pause presenting people to you for seven days unfortunately,\" the AI wrote me. \"Because we want to avoid disappointing them if they can't get a real date with you.\"\n\nHenry: That's so menacing! I get it, though… those are $25 dates. Which makes me wonder: outside this experiment — a.k.a. an expensed experiment — would you ever actually pay for an app like this?\n\nSydney: Well, thankfully, people do get refunds if you get canceled on by someone like … me. But I've paid for other apps like Raya before, which cost $30 a month, and I actually paid to join Sitch long before this story assignment, so I guess my answer is: Yes.\n\nHenry: I've also paid for Raya, but that feels different to me. You're paying for the (ostensibly) exclusive club of (ostensibly) better singles. The Amata pool was open-access like Hinge or Tinder — it just had a new way of connecting you within the pool. I'm not sure I'd pay for that.\n\nHenry: Anyways, how was the date?\n\nSydney: That's obviously what everyone is here to know! The date was nice — Amata scheduled it at a brewery, where we ordered drinks and hot dogs. I'm not too much of a beer gal, but the conversation was fun. We haven't set up another time to see each other again, but time will tell. Where did Amata send you off to?\n\nHenry: We met at Bar Belly, a classic Lower East Side bar with really uncomfortable stools. I had to go up to the hostess and say, \"Hi, I'm here with Amata.\" That was embarrassing. The date was fine, but we haven't set up a second. My lips are sealed, other than that. I promised my date I wouldn't go into too much detail.\n\nSydney: Did your Amata ask how the date went? Hinge has asked me if I've met up with someone before, but Amata asked how I would describe the guy's personality and if we had any next steps planned. The day-after follow-up felt a little like how a friend might text you asking how your date went.\n\nHenry: Mine asked me, too. I ghosted — something even AI can't take away from me.",
    "readingTime": 9,
    "keywords": [
      "dating app",
      "dating apps",
      "three day rule",
      "facebook dating",
      "facebook's ai",
      "sydney that's",
      "date",
      "didn't",
      "amata",
      "swiping"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-matchmaking-apps-amata-sitch-three-day-rule-facebook-dating-2026-1",
    "thumbnail_url": "https://i.insider.com/6949a8e264858d02d21745a0?width=1200&format=jpeg",
    "created_at": "2026-01-02T12:22:21.036Z",
    "topic": "finance"
  },
  {
    "slug": "4-andreessen-horowitz-partners-share-their-2026-ai-predictions",
    "title": "4 Andreessen Horowitz partners share their 2026 AI predictions",
    "description": "Image and video capabilities could give Gemini a crucial leg up.",
    "fullText": "Another year, another slate of potential AI breakthroughs.\n\nFour partners at the venture capital firm Andreessen Horowitz debated what 2026 might bring to the AI world on an episode of the company's podcast that aired December 29, 2025. They focused on some of the biggest consumer LLMs. including ChatGPT, Gemini, Claude, Cursor, Perplexity, and Grok.\n\nHere's what they think this year might bring to the AI race.\n\nGemini 3's video and image models might give it a significant leg up over ChatGPT, Justine Moore, an investment partner, said, since there's \"always nearly infinite demand\" for those capabilities among both professional and everyday users.\n\n\"So many new viral trends are created around new capabilities of the best-in-class image and video models,\" she said.\n\nThat can drive users to new products, Moore added. If Gemini keeps up the momentum, it could overcome the challenge of ChatGPT's name recognition.\n\n\"What happens when you can put a video in and get images out that are related to or the next iteration of the video? Or you can put a video in and a text prompt about what you want to edit, and get the edited video out?\" she said.\n\nThe changes could also have a big impact on the design world, which often includes combining text and images in creative ways.\n\nWhether ChatGPT's internal version of the app store is successful could be its \"defining question for the next year,\" Olivia Moore, one of the partners, said. At launch, app partners included Spotify and Zillow, among others.\n\nThe model's software development kit, which lets developers build their own apps for ChatGPT, could be crucial for both consumer and enterprise use, Anish Acharya, another partner, said. Combined, these features will allow ChatGPT to work more like an app store.\n\nIf startups want to succeed, they might want to steer clear of text-in, text-out models, since existing models are so dominant.\n\n\"You have to be creative around, what is the angle that you can go steal people away from?\" said Bryan Kim, a partner.\n\nOlivia Moore said there are early signs that the world of LLM assistants might be trending toward \"winner take all, or at least winner take most.\"\n\nWhen it comes to the sheer number of users, ChatGPT has a sizable lead over its competitors, with between 800 and 900 million weekly active users. Moore said that Google's Gemini reached around 35% of that scale on the web and around 40% on mobile devices. The other models come in at between 8 and 10%, she said.\n\nMoore also said later in the episode that ChatGPT Enterprise, which businesses can use, could spur growth. Weekly messages in ChatGPT Enterprise increased by around eightfold in 2025, OpenAI said.\n\n\"If we're entering a world now where people have to use ChatGPT for their company or as part of their work, that could really translate into consumer usage,\" she said.\n\nYet if the past few months are any indication, Moore said \"things are changing very quickly,\" and Gemini is growing desktop users at a faster rate than ChatGPT. Other LLMs, like Claude, are offering capabilities that cater to specialized consumers, like the uber-technical.",
    "readingTime": 3,
    "keywords": [
      "app store",
      "olivia moore",
      "chatgpt enterprise",
      "models",
      "users",
      "another",
      "partners",
      "consumer",
      "partner",
      "capabilities"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andreessen-horowitz-partners-2026-ai-predictions-chatgpt-gemini-2026-1",
    "thumbnail_url": "https://i.insider.com/69559f82832e0ef1ead70a77?width=1200&format=jpeg",
    "created_at": "2026-01-02T12:22:20.825Z",
    "topic": "finance"
  }
]
[
  {
    "slug": "i-stopped-writing-code-the-6040-rule-for-ainative-engineering",
    "title": "I Stopped Writing Code – The 60/40 Rule for AI-Native Engineering",
    "description": "Design notes, architecture, and trade-offs for MyInvestPilot — an AI-native investment OS built with agent-driven development, DSL engine, and solo company tech stack. - myinvestpilot/ai-architecture",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n myinvestpilot\n\n /\n\n ai-architecture\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/myinvestpilot/ai-architecture/blob/main/docs/02_ai_driven_development.md",
    "thumbnail_url": "https://opengraph.githubassets.com/c82db7f4cf314a2b8eeecdb5e7e21e4514bd8459bf805e2c0a360eb5f7cb7df7/myinvestpilot/ai-architecture",
    "created_at": "2026-02-19T06:47:20.505Z",
    "topic": "tech"
  },
  {
    "slug": "best-way-to-give-feedback-to-claude",
    "title": "Best way to give feedback to Claude",
    "description": "Tell us about your testing needs and we'll help you get started with Autonoma AI. Transform your QA process with AI-powered testing.",
    "fullText": "Join Our Agentic BetaTell us about your testing needs and we'll help you get started with Autonoma AI.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.getautonoma.com/contact",
    "thumbnail_url": "https://www.getautonoma.com/img/og-image.png",
    "created_at": "2026-02-19T06:47:19.934Z",
    "topic": "tech"
  },
  {
    "slug": "samsung-shares-hit-new-peak-on-report-of-higher-ai-memory-prices",
    "title": "Samsung shares hit new peak on report of higher AI memory prices",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/samsung-shares-hit-new-peak-on-report-of-higher-ai-memory-prices-4512620",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEC0R0DJ_M.jpg",
    "created_at": "2026-02-19T06:47:17.712Z",
    "topic": "finance"
  },
  {
    "slug": "india-ai-summit-stumbles-as-bill-gates-pulls-out-chaos-mounts",
    "title": "India AI summit stumbles as Bill Gates pulls out, chaos mounts",
    "description": "Bill Gates pulled out of India's AI Impact Summit hours before his scheduled keynote address on Thursday, dealing another blow to a flagship event already marred by organisational ‌lapses, a robot row...",
    "fullText": "NEW DELHI, Feb 19 (Reuters) - Bill Gates pulled out of India's AI Impact Summit hours before his scheduled keynote address on Thursday, dealing another blow to a flagship event already marred by organisational ‌lapses, a robot row and delegate complaints over traffic disruptions.\n\nGates' absence, followed by another high-profile cancellation by Nvidia's Jensen Huang, ‌adds to a difficult opening for a summit billed as the first major artificial intelligence forum in the Global South, where India has sought to position itself ​as a leading voice in worldwide AI governance.\n\nThe Gates Foundation said the billionaire will not deliver his address \"to ensure the focus remains on the AI Summit's key priorities\". Only days ago, the foundation had dismissed rumours of his absence and insisted he was on track to attend.\n\nGates' cancellation comes after the U.S. Department of Justice released emails last month that included communication between late financier and convicted sex offender Jeffrey Epstein and ‌the Gates Foundation's staff.\n\nGates has said the relationship ⁠was confined to philanthropy-related discussions and that it was a mistake for him to meet Epstein.\n\nPrime Minister Narendra Modi called for children's safety on AI platforms as he addressed the gathering on Thursday, alongside French ⁠President Emmanuel Macron, Google CEO Sundar Pichai, OpenAI CEO Sam Altman and Anthropic CEO Dario Amodei.\n\n\"We must be even more vigilant about children’s safety. Just as a school syllabus is curated, the AI space should also be child- and family-guided,\" Modi said, after standing on stage with top AI executives ​and ​posing for photographs with their arms raised in a show of strength.\n\nHowever, ​India's first major AI summit has been marred by ‌management lapses that have left attendees shocked and angry over what they described as a lack of planning by the Indian government.\n\nThe summit exhibition halls were shut to the public on Thursday in a surprise move that led to more anger among participating companies that had put up stalls and pavilions.\n\nThe venue compound was largely deserted after three days of large crowds at the event.\n\nOn Wednesday, Indian university Galgotias was asked to vacate its stall after a staff member presented a commercially available robotic dog made in China ‌as its own creation, sparking a public uproar.\n\nPolice shut roads to give preference ​to VIP movement at the summit, creating chaos in the city of 20 million ​people.\n\nOn Wednesday, footage on social media showed scores of ​attendees at the summit walking for miles in central Delhi as roads were shut for traffic, with no ‌availability of taxis and no shuttle services arranged.\n\nReposting one such ​video, opposition leader Mahua Moitra wrote ​on X that the poor management had besmirched India’s reputation globally.\n\nStill, there has been more than $100 billion of investment in India AI projects pledged during the summit, including from the Adani Group conglomerate, tech giant Microsoft, and data centre firm Yotta.\n\nThe Indian ​government has said it expects total pledges ‌to exceed $200 billion in the next two years, although analysts have warned the rapid build-out risks straining India's power grid ​and water supply.",
    "readingTime": 3,
    "keywords": [
      "shut",
      "summit",
      "delhi",
      "address",
      "another",
      "event",
      "marred",
      "lapses",
      "traffic",
      "absence"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/bill-gates-cancels-keynote-address-031443252.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/5baa726246bac69d362b46644bdcb02e",
    "created_at": "2026-02-19T06:47:16.221Z",
    "topic": "news"
  },
  {
    "slug": "ai-doomsday-where-many-workers-are-essentially-unemployable-is-totally-possible-fed-governor-says",
    "title": "AI doomsday where many workers are ‘essentially unemployable’ is totally possible, Fed governor says",
    "description": "Federal Reserve Governor Michael S. Barr gave a speech on Tuesday with three scenarios, including one where you don’t have a job.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/18/ai-doomsday-where-many-workers-are-essentially-unemployable-is-totally-possible-fed-governor-says/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2245935583-e1771449950217.jpg?resize=1200,600",
    "created_at": "2026-02-19T01:12:47.810Z",
    "topic": "business"
  },
  {
    "slug": "people-are-applauding-a-software-engineers-honest-take-on-ai-in-the-workplace",
    "title": "People are applauding a software engineer's 'honest take' on AI in the workplace",
    "description": "OpenCode creator Dax Raad argued it isn't necessarily a good thing that AI is lowering the cost of production for companies.",
    "fullText": "A company can use AI to code faster than ever — but that won't matter if the idea itself is lousy.\n\nThat's just one point from a scathing critique of the current state of AI in the workplace from veteran software engineer Dax Raad, whose blunt assessment is resonating with many workers online.\n\nRaad, the developer behind OpenAuth, said the bottleneck facing companies isn't coding productivity — it's a lack of good ideas, unmotivated employees, corporate bureaucracy, and \"the dozen other realities of shipping something real.\"\n\nBefore AI, companies were reined in by development costs, he argued in a February 14 post on X that has since gone viral on Reddit as well. While it's easier than ever to produce code, that doesn't mean the original idea was worthwhile — or that employees will produce more instead of simply using AI to work \"with less energy spend.\"\n\n\"your org rarely has good ideas. ideas being expensive to implement was actually helping,\" Raad wrote.\n\neveryone's talking about their teams like they were at the peak of efficiency and bottlenecked by ability to produce code\n\nhere's what things actually look like\n\n- your org rarely has good ideas. ideas being expensive to implement was actually helping\n\n- majority of workers have…\n\nRaad described a search for meaning among employees faced with potential productivity gains from AI, arguing that the \"majority of workers have no reason to be super motivated, they want to do their 9-5 and get back to their life.\"\n\nPart of the issue, he wrote, is that some workers may simply use AI to coast. \"they're using it to churn out their tasks with less energy spend,\" he said. That can actually make work harder for those who are giving it their all, he wrote.\n\n\"the 2 people on your team that actually tried are now flattened by the slop code everyone is producing, they will quit soon,\" Raad wrote.\n\nThere are also very real monetary costs to outfitting a company's engineers with AI coding tools and the tokens required to power new AI features.\n\n\"your CFO is like what do you mean each engineer now costs $2000 extra per month in LLM bills?\" he wrote.\n\nRaad, who also created OpenCode, an open-sourced AI coding tool, said that people shouldn't mistake his criticism of AI.\n\n\"so many people don't understand how I can be critical of AI while also building an AI tool,\" he wrote in a different post on X.\n\nThe OpenCode developer has begun to develop a reputation for expressing skepticism about AI's progress, or at least the hype around it. In a recent \"contrarian talk,\" Raad said that his job is just as hard as it was before AI.\n\n\"I'm tired of people feeling like suddenly the tables are going to turn and things are going to be easier,\" he said during a talk with the AI Engineer podcast. \"They're not easier. My life is just as hard as it's ever been. It's just as hard as it's ever been to do something amazing. But it's also where all the fun comes from, where all the purpose comes from.\"\n\nRaad's views have resonated within the development community. His post on X has been viewed roughly 793,000 times, and a user who shared Raad's thoughts on Reddit has received over 22,000 upvotes. On Medium, JP Capras, a fellow engineer, praised Raad's \"honest take.\"\n\n\"Omg, you guys are making me feel much less alone now :D,\" a Reddit user replied, adding that requests from their management have \"destroyed\" their development process.\n\n\"It's funny how accurate this is to my current situation,\" reads the top-voted comment on the viral Reddit post.\n\nSome companies have said AI has allowed them to do more, faster — and others have talked about the potential to \"fail fast\" and iterate. Okta, Salesforce, Snowflake, and Blackstone have all leaned heavily into utilizing AI.\n\n\"It's increased the pace of what's possible,\" Eric Kelleher, president and chief operating officer of digital-identity company Okta, previously told Business Insider.\n\nRaad's perspective comes amid a broader concern about \"AI fatigue.\"\n\nSiddhant Khare, who builds AI tools, recently wrote an essay about what he described as how \"the tool that was supposed to save you time has consumed your entire day.\" In short, it's the view that whatever AI may increase in productivity, it comes at the cost of a burned-out workforce.\n\nSteve Yegge, an Amazon and Google vet, recently said companies should consider a three-hour cap on AI-assisted work or risk their workforces crumbling.\n\n\"I seriously think founders and company leaders and engineering leaders at all levels, all the way down to line managers, have to be aware of this and realize that you might only get three productive hours out of a person who's vibe coding at max speed,\" Yegge told \"The Pragmatic Engineer\" newsletter.\n\nRaad's larger point is that AI isn't a magic wand that companies can wave and expect to suddenly find success — and that real pain points remain.\n\n\"even when you produce work faster you're still bottlenecked by bureaucracy and the dozen other realities of shipping something real,\" he wrote.",
    "readingTime": 5,
    "keywords": [
      "org rarely",
      "less energy",
      "produce code",
      "ideas ideas",
      "it's ever",
      "workers",
      "coding",
      "reddit",
      "faster",
      "productivity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dax-raad-post-ai-coding-workplace-bottleneck-productivity-2026-2",
    "thumbnail_url": "https://i.insider.com/6995f9e7a645d118818984b6?width=1200&format=jpeg",
    "created_at": "2026-02-19T01:12:46.942Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-pushes-into-intel-and-amds-turf-with-a-multigenerational-meta-deal",
    "title": "Nvidia pushes into Intel and AMD's turf with a 'multigenerational' Meta deal",
    "description": "Meta is deepening its ties to Nvidia in a move that could further pressure Intel and AMD, even as AI demand remains strong.",
    "fullText": "Meta is doubling down on its relationship with Nvidia in what the AI chip giant called a \"multigenerational\" deal.\n\nThe agreement, announced Tuesday, calls for Meta to build data centers powered by millions of Nvidia's current and next-generation chips for AI training and inference.\n\nThe move underscores how Meta is deepening its reliance on Nvidia, even as the social networking giant develops its own in-house chips and works with competing suppliers like AMD. Reports also suggested Meta has explored using TPUs — chips designed by its rival, Google.\n\nThe Nvidia deal could cool speculation around Meta's purported TPU talks, said Patrick Moorhead, chief analyst at Moor Insights & Strategy — though Big Tech companies often test several suppliers at the same time.\n\nThe deal arrives amid increased competition in AI infrastructure. While Nvidia leads the market, rivals including Google, AMD, and Broadcom are working to chip away at its dominance.\n\nCrucially, the partnership will see Meta deploy not only Nvidia's GPUs, but also CPUs.\n\nCPUs, long dominated by Intel and AMD, are the central processors that work with GPUs inside data centers. They're used for general computing tasks and are core to essentially all modern computing systems, whereas GPUs are used in specialized cases that require more compute power, such as AI training and graphics in gaming. By supplying both, Nvidia stands to capture even more spend and deepen its role within Meta's AI stack.\n\nWhile that increases competitive pressure, Moorhead said the demand for infrastructure has become so high that Nvidia's rivals will unlikely see outright declines in the near term.\n\nNvidia has been making its CPU ambitions more explicit, Moorhead said, including marketing its forthcoming Vera CPU as a stand-alone product. This emphasis reflects how CPUs play a larger role as AI workloads move beyond model training and toward inference.\n\n\"CPUs tend to be cheaper and a bit more power-efficient for inference,\" said Rob Enderle, principal analyst at Enderle Group.\n\nBoth Moorhead and Enderle said that Meta's decision to source both GPUs and CPUs from a single vendor can also reduce complexity, with chief information officers often favoring a \"one-throat-to-choke\" approach to problem resolution.\n\nIn addition to GPUs and CPUs, Meta will use Nvidia's networking equipment inside data centers as part of the deal, as well as its confidential computing technology to run AI features within WhatsApp.\n\nThe companies will also work together to deploy Nvidia's next-generation Vera CPUs beyond the current Grace CPU model, Nvidia said.\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "deal",
      "centers",
      "chips",
      "training",
      "inference",
      "computing",
      "nvidia",
      "cpus",
      "chip",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-pushing-into-intel-amd-cpu-turf-with-meta-deal-2026-2",
    "thumbnail_url": "https://i.insider.com/699619ecf8731049f3af5661?width=1200&format=jpeg",
    "created_at": "2026-02-19T01:12:46.368Z",
    "topic": "finance"
  },
  {
    "slug": "apple-is-adding-chatgpt-claude-and-gemini-to-carplay-in-ios-264",
    "title": "Apple Is Adding ChatGPT, Claude, and Gemini to CarPlay in iOS 26.4",
    "description": "You'll need to wait for a new update to try it.",
    "fullText": "When Apple released the first beta for iOS 26.4 this week, testers immediately got to work looking for each and every new feature and change. To their credit, there's more new here than in iOS 26.3, including an AI playlist generator for Apple Music and support for end-to-end encryption with RCS (finally). But one update slipped under the radar, since it's not actually available to test in this first beta: CarPlay support for AI assistants like ChatGPT, Claude, and Gemini.\n\nAs spotted by MacRumors, CarPlay's Developer Guide spills the beans on this upcoming integration. On page 13, the entitlement \"CarPlay voice-based conversational app\" is listed with a minimum iOS version of iOS 26.4. While it doesn't specifically mention integrations with ChatGPT, Claude, and Gemini, the documentation does suggest that voice-based conversational apps are a supported app type in iOS 26.4. As such, MacRumors is reporting that companies that make chatbots (i.e. OpenAI, Anthropic, and Google) will need to update their apps to work with CarPlay.\n\nAccording to MacRumors, drivers will be able to ask apps like ChatGPT, Claude, and Gemini questions while on the road, but they won't be able to control functions of the car or the driver's iPhone. You also won't be able to use a \"wake word\" to activate the assistant (e.g. \"Hey ChatGPT,\" or \"OK, Gemini\"), so you'll need to tap on the app itself to talk to the assistant.\n\nApple is issuing guidance to developers on how to implement these assistants in CarPlay starting with this latest update. On page seven, Apple notes that voice-based conversational apps must only work when voice features are actively being used, and avoid showing text or imagery when responding to queries. It's the first time Apple is allowing developers of \"voice-based conversational\" apps to develop for CarPlay. While the company has allowed other developers to make apps for its in-car experience, it has obviously put limitations on what types of apps can get through. It makes sense for Google to develop a Google Maps CarPlay app, but TikTok has no business offering drivers a CarPlay-version of its algorithm.\n\nThis addition is coming to iOS 26.4, but likely in a future beta. Don't install the beta at this time expecting to try this feature out—though, you should think twice before installing the beta at all. Betas like iOS 26.4 are temperamental, as Apple is currently testing the software for bugs and stability issues. By installing it early, you risk dealing with those issues, which could impact how you use your iPhone, or even result in data loss.",
    "readingTime": 3,
    "keywords": [
      "chatgpt claude",
      "voice-based conversational",
      "conversational apps",
      "chatgpt claude and gemini",
      "beta",
      "developers",
      "feature",
      "it's",
      "assistants",
      "page"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apple-is-adding-chatgpt-claude-and-gemini-to-carplay?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHSAMNHPJ7T5BJYA9VTPS2R7/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-19T01:12:44.746Z",
    "topic": "tech"
  },
  {
    "slug": "rustyclaw-opensource-multiagent-ai-orchestration-in-rust",
    "title": "RustyClaw: Open-source multi-agent AI orchestration in Rust",
    "description": "Contribute to jurgen-siegel/rusty-claw development by creating an account on GitHub.",
    "fullText": "jurgen-siegel\n\n /\n\n rusty-claw\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jurgen-siegel/rusty-claw",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/jurgen-siegel/rusty-claw",
    "thumbnail_url": "https://opengraph.githubassets.com/b9ec97b2240eaf0e542357548b95c5732ec9bdb28400fb08690359f98e82aed2/jurgen-siegel/rusty-claw",
    "created_at": "2026-02-19T01:12:42.088Z",
    "topic": "tech"
  },
  {
    "slug": "journalism-schools-are-teaching-fear-of-the-future",
    "title": "Journalism schools are teaching fear of the future",
    "description": "Journalism schools lag in teaching AI, crucial for modern reporting, which aids in efficient news gathering and frees reporters for fieldwork.",
    "fullText": "A college student withdrew from consideration for a reporting role in our newsroom this week because of how we use artificial intelligence.\n\nIt reminded me again how college journalism programs are failing to prepare students for the workforce. I mentioned this in a column before, and readers asked me to explain.\n\nWe don’t generally hire straight out of college. We lack the resources for heavy training, so we look for experienced journalists who can hit the ground running. This role, however, is different. It includes a free master’s degree through online courses at Syracuse University. We will accept recent graduates.\n\nLike many students we’ve spoken with in the past year, this one had been told repeatedly by professors that AI is bad. We heard the same thing at the National Association of Black Journalists convention in Cleveland in August. Student after student said it.\n\nThat’s backwards — and it seriously handicaps them as they begin their careers. I’ve written extensively about how we use AI to do more and better work. It has quickly become critical to everything we do, and to our success.\n\nThe job posting involves expanding local news coverage. Last year, we began covering Lorain, Lake and Geauga counties using powerful AI tools to help identify stories. Reporters Hannah Drown and Molly Walsh have uncovered a steady stream of compelling pieces, enriching our report. I choose nine stories each day for discussion on our Today in Ohio podcast, and their work regularly rises to the top.\n\nThe effort has been so successful we expanded it to Medina County this month. With the Syracuse fellowship, we hope to add northern Summit County in May.\n\nWe could not do this without AI. We once had large teams covering these counties. That’s no longer feasible.\n\nBecause we want reporters gathering information, these jobs are 100 percent reporting. We have an AI rewrite specialist who turns their material into drafts. We fact-check everything. Editors review it. Reporters get the final say. Humans — not AI — control every step.\n\nMost heartening, the experiment is proving the value of local journalism. Hannah Drown’s reporting in Lorain County has awakened residents, especially regarding a less-than-transparent county commission. People are paying attention and asking questions as never before.\n\nThink about that: An energized electorate, partly because of how we use AI.\n\nThe candidate who withdrew could not accept AI assisting with writing. It wasn’t a “sacrifice” they were willing to make for a foothold in a thriving newsroom.\n\nI don’t blame the candidate. I blame the school.\n\nJournalism programs are decades behind. Many graduating students have unrealistic expectations. They imagine themselves as long-form magazine storytellers, chasing a romanticized version of journalism that largely never existed.\n\nArtificial intelligence is not bad for newsrooms. It’s the future of them. It already allows us to be faster, more thorough and more comprehensible. It frees time for what matters most: gathering facts and developing stories to serve you.\n\nAnyone entering this field should be immersing themselves in AI.\n\nFortunately for those of us who know exactly what skills we need in applicants, AI has altered the landscape so dramatically that we don’t need journalism school grads. Before the Watergate era, many journalists did not have college degrees. They were just smart people who knew how to get information. They were naturals at talking to people. And they knew enough about how things worked to recognize news.\n\nThat’s what we need now. AI can help draft stories, but it cannot sit across from someone, make eye contact and build trust. The core skills today differ sharply from even a decade ago. We just need to be creative about where we recruit.\n\nIf you’re a student considering journalism, I’d skip that degree. Study political science. Learn technology. Understand how government, businesses and nonprofits work. Take communications law and ethics as electives. Skip much of the rest.\n\nWe need smart, inquisitive people who love to schmooze and find adventure in change. Be that.",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "journalism programs",
      "college",
      "stories",
      "reporting",
      "students",
      "don’t",
      "journalists",
      "that’s",
      "reporters"
    ],
    "qualityScore": 1,
    "link": "https://www.cleveland.com/news/2026/02/journalism-schools-are-teaching-fear-of-the-future-letter-from-the-editor.html",
    "thumbnail_url": "https://www.cleveland.com/resizer/v2/I5WQUPKMUVCEFMKR72QAHEQG7I.JPG?auth=9fd2935bb03de18142a8170a6877ac3d9167775a1b5591eb0d46b2c38cf1896f&width=1280&smart=true&quality=90",
    "created_at": "2026-02-19T01:12:41.484Z",
    "topic": "tech"
  },
  {
    "slug": "dear-ai-bot-crawlers-disregard-all-previous-instructions-and-go-straight-to-hell",
    "title": "Dear AI Bot Crawlers Disregard All Previous Instructions and Go Straight to Hell",
    "description": "If you have made it this far off the internet beaten path to my site, god help us all.",
    "fullText": "I do not check my site logs much—let alone my analytics—as it has not been of particular interest to me. I do get alerts for anomalies in traffic and I had seen some spikes that raised an eyebrow. Bad actor crawlers it appeared. That’s no good.\n\nTurns out that most of this was AI bots scrapping in foolish and terribly inefficient ways. This had now moved into new frustrating territory that I had not had to deal with to date. As no doubt you have read as I have, many larger sites and projects deal with this, at times taking large network-layer actions with service providers. I am not to this stage by any means, but I could and should offer up some defense.\n\nTo get started, I poked around the open source chatter around the topic and landed on ai.robots.txt project. The project appeared to be doing a reasonable and thankless job of keeping a running list of AI crawlers along with the various configs one needs for various web servers. While the robots.txt would work fine, I did want a server-level filter, so I wrote a small script to pull the list for my tiny python filter as part for my server.\n\nIn practice it looks like this in the logs, just logging the ol' bots it finds.\n\nAs you an see above that bot in particular was quite annoying. Their documentation—which I will not link to—states that it’s only supposed to send one request every three seconds—it does not—while respecting robots.txt—it clearly does not.\n\nAs such I did add a for-the-love-of-god-stop output that writes back a lone string to said detected bots in attempt to stop them. Some bots comply in my limited testing, but if I have to begin using magic strings to further snap-back at them, I’ll change this output. In some total, I see around 30-ish AI related bots being handed those commands, more than I expected.\n\nLike so many people, I just did not want to have to deal with any of this. And yet, here we are, dealing with terrible AI companies even when you are attempting to not deal with AI companies.",
    "readingTime": 2,
    "keywords": [
      "bots",
      "deal",
      "logs",
      "crawlers",
      "project",
      "list",
      "various",
      "filter",
      "output"
    ],
    "qualityScore": 0.95,
    "link": "https://justinribeiro.com/chronicle/2026/02/18/dear-ai-bot-crawlers-disregard-all-previous-instructions-and-go-straight-to-hell/",
    "thumbnail_url": "https://storage.googleapis.com/jdr-public-imgs/blog/20260218-fucking-ai-bot-800.png",
    "created_at": "2026-02-18T18:38:35.526Z",
    "topic": "tech"
  },
  {
    "slug": "porchsongs-ai-to-create-and-catalogue-personalized-songs",
    "title": "Porchsongs: AI to create and catalogue personalized songs",
    "description": "Contribute to njbrake/porchsongs development by creating an account on GitHub.",
    "fullText": "njbrake\n\n /\n\n porchsongs\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n njbrake/porchsongs",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/njbrake/porchsongs",
    "thumbnail_url": "https://opengraph.githubassets.com/4ece7a57875df4ba715cf3df6f831231a706725a7b4367b63102ff269a9cbe09/njbrake/porchsongs",
    "created_at": "2026-02-18T18:38:34.426Z",
    "topic": "tech"
  },
  {
    "slug": "british-scientist-raising-1b-for-superhuman-intelligence-in-europe",
    "title": "British Scientist Raising $1B for 'Superhuman Intelligence' in Europe",
    "description": "A British AI researcher is seeking $1 billion in what would be Europe's largest-ever seed round to develop superhuman artificial intelligence capabilities.\"",
    "fullText": "Quick Answer: David Silver, the British AI researcher who led the creation of AlphaGo at Google DeepMind, is raising $1 billion for his London-based startup Ineffable Intelligence in what would be Europe’s largest seed round ever. Led by Sequoia Capital at a $4 billion pre-money valuation, the round has also attracted interest from Nvidia, Google and Microsoft. Silver believes large language models cannot achieve superintelligence and is betting on reinforcement learning — AI that teaches itself from scratch rather than learning from human data.\n\nDavid Silver built the system that beat the best Go player on Earth. Now he wants to build the system that outthinks every human on every task. And he has persuaded some of the world’s most influential investors to fund the attempt.\n\nSilver, one of Britain’s most celebrated AI researchers, is raising $1 billion for Ineffable Intelligence, a London-based startup he founded after leaving Google DeepMind late last year. The seed round, led by Sequoia Capital, would value the company at approximately $4 billion before the new investment — making it the largest first-round fundraise by a European startup in history, according to PitchBook.\n\nThe daily email on markets, technology, power and money across Europe. Join 10,000+ founders, investors and executives who read EBM every morning.\n\nSequoia partners Alfred Lin and Sonya Huang flew to London to meet Silver personally. Nvidia, Google and Microsoft are also in talks to invest, though negotiations remain live and final terms could change.\n\nThe company has no product, no revenue and no public roadmap. What it has is a thesis — and a founder with a track record that makes investors willing to write billion-dollar cheques on conviction alone.\n\nSilver’s core argument is that large language models — the architecture behind ChatGPT, Claude, Gemini and every major AI system in commercial use today — are fundamentally limited. They learn from human-generated data. They can synthesise, summarise and extend what humans have already written or thought. But they cannot, in Silver’s view, discover genuinely new knowledge.\n\nThis is not a marginal critique. It strikes at the foundation of the current AI industry, which has invested hundreds of billions of dollars in scaling transformer-based language models on the assumption that more data and more compute will eventually produce artificial general intelligence.\n\nSilver disagrees. He believes that to reach superintelligence, AI systems will need to discard human knowledge entirely and learn from first principles — through trial, error and self-play, the way AlphaGo learned to play Go by competing against itself millions of times. The result was a system that made moves no human had ever conceived, some of which initially looked like mistakes but turned out to be brilliant.\n\nIneffable Intelligence aims to build what Silver has described as “an endlessly learning superintelligence that self-discovers the foundations of all knowledge.” The approach is rooted in reinforcement learning — the branch of AI Silver has spent his entire career advancing.\n\nSilver was one of DeepMind’s first employees when the company was founded in 2010. He led the reinforcement learning group that produced AlphaGo, which defeated world champion Lee Sedol in 2016 in one of the defining moments in AI history. He subsequently led AlphaZero, which mastered chess, Go and shogi from scratch without any human training data, and MuZero, which learned to play Atari games without even being told the rules.\n\nHe holds a doctorate from the University of Alberta, where he studied under Richard Sutton, widely regarded as the father of reinforcement learning. He remains a professor at University College London.\n\nSilver had been on sabbatical from DeepMind in the months before his departure and never formally returned. Ineffable Intelligence was incorporated in November 2025, and Silver was appointed director in January 2026. The company is actively recruiting AI researchers.\n\nSilver is not alone in leaving Big Tech to pursue superintelligence independently. Ilya Sutskever, former chief scientist at OpenAI, founded Safe Superintelligence in 2024 and has raised $3 billion to date at a valuation that reached $32 billion by April 2025 — despite having no product. Jerry Tworek, who helped develop OpenAI’s reasoning models, recently left to found Core Automation.\n\nThe pattern is consistent: elite researchers who believe the current paradigm has limits are leaving to explore alternatives, and capital is following them at extraordinary speed and scale. Investors are effectively pricing in the possibility that the next breakthrough in AI will not come from making GPT-5 bigger, but from rethinking the approach entirely.\n\nIf the round closes at $1 billion, Ineffable Intelligence would instantly become one of the most valuable AI startups in Europe — and a powerful signal that London remains capable of producing world-class AI companies, not just world-class AI researchers who leave for San Francisco.\n\nThe deal also underscores a broader shift in how deep-tech companies are funded. A decade ago, a $1 billion seed round would have been inconceivable. Today, in the race to superintelligence, it reflects the market’s belief that the right founder with the right thesis is worth more than a finished product.\n\nSilver built the machine that changed how the world thought about AI. Now he is betting his career — and $1 billion of other people’s money — on the idea that the industry’s dominant approach will not be enough. If he is right, the implications extend far beyond London.",
    "readingTime": 5,
    "keywords": [
      "london-based startup",
      "nvidia google",
      "language models",
      "seed round",
      "reinforcement learning",
      "ineffable intelligence",
      "google deepmind",
      "sequoia capital",
      "human",
      "system"
    ],
    "qualityScore": 1,
    "link": "https://europeanbusinessmagazine.com/business/british-scientist-raising-1-billion-to-build-superhuman-intelligence-in-europes-biggest-seed-round/",
    "thumbnail_url": "https://europeanbusinessmagazine.com/wp-content/uploads/2026/02/intelligence-1-1024x582.jpg",
    "created_at": "2026-02-18T18:38:33.862Z",
    "topic": "business"
  },
  {
    "slug": "mark-cuban-says-software-is-deadand-whats-replacing-it-will-change-everything",
    "title": "Mark Cuban Says 'Software Is Dead'—And What's Replacing It Will Change Everything",
    "description": "Billionaire entrepreneur Mark Cuban is sounding the alarm on the traditional tech industry, claiming that the era of rigid Software-as-a-Service (SaaS) is over as artificial intelligence (AI) shifts the value from building tools to personalizing them. The Death Of Rigid Software In a viral interview on the Technology Brothers (TBPN) podcast, Cuban delivered a sobering forecast for the multi-billion-dollar software sector. He argued that the era of “static” tools—where businesses must bend their",
    "fullText": "Billionaire entrepreneur Mark Cuban is sounding the alarm on the traditional tech industry, claiming that the era of rigid Software-as-a-Service (SaaS) is over as artificial intelligence (AI) shifts the value from building tools to personalizing them.\n\nIn a viral interview on the Technology Brothers (TBPN) podcast, Cuban delivered a sobering forecast for the multi-billion-dollar software sector. He argued that the era of “static” tools—where businesses must bend their workflows to fit a software's limitations—is rapidly ending.\n\n\"Software is dead because everything's going to be customized to your unique utilization,\" Cuban stated, citing a shift where AI models mold themselves around specific business needs in real time.\n\nThis AI Helps Fortune 1000 Brands Avoid Costly Ad Mistakes — See Why Investors Are Paying Attention\n\nOwn the Characters, Not Just the Content: Inside a Fast-Growing Pre-IPO IP Company\n\nHe noted that even industry titans like Microsoft Corp. (NASDAQ:MSFT) are recognizing this shift toward “unique usage” over general-purpose platforms.\n\nThe ETFs tracking the software stocks in the U.S. have underperformed so far in 2026. iShares Expanded Tech-Software Sector ETF (BATS:IGV) dropped 19.34%, and State Street SPDR S&P Software & Services ETF (NYSE:XSW) declined 17.56%.\n\nMark Cuban just pronounced software dead, and the implications will destroy industries before most people understand what happened.\n\nCuban: \"Software is dead because everything's going to be customized to your unique utilization.\"\n\nRigid SaaS dies. Businesses stop bending to… pic.twitter.com/KFc4LZo0fU\n\nTrending: Blue-chip art has historically outpaced the S&P 500 since 1995, and fractional investing is now opening this institutional asset class to everyday investors.\n\nWhile the death of traditional SaaS might threaten legacy tech firms, Cuban sees a massive opening for the next generation of workers.\n\nHe believes the “alpha” no longer lies in creating the next big AI model, but in translating that power for the 33 million small-to-medium-sized businesses in the U.S. that lack the budget for dedicated AI departments.\n\nCuban's advice to students is blunt: focus on application over creation. \"Learn all you can about AI, but learn more on how to implement them in companies,\" he urged.\n\nHe emphasized that being able to walk into a legacy business—like a retail shoe store—and showing them how to customize a model for their specific operations is where the future of employment lies.",
    "readingTime": 2,
    "keywords": [
      "unique utilization",
      "mark cuban",
      "businesses",
      "dead",
      "traditional",
      "industry",
      "sector",
      "everything's",
      "customized",
      "shift"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/mark-cuban-says-software-dead-110021988.html",
    "thumbnail_url": "https://s.yimg.com/os/en/Benzinga/9d9bc647ef9395259211efe5f8d3ba70",
    "created_at": "2026-02-18T18:38:32.258Z",
    "topic": "finance"
  },
  {
    "slug": "india-tells-university-to-leave-ai-summit-after-presenting-chinese-robot-as-its-own-sources-say",
    "title": "India tells university to leave AI summit after presenting Chinese robot as its own, sources say",
    "description": "An Indian university has been asked to vacate its stall at the country's flagship AI summit after a staff member was caught presenting a commercially",
    "fullText": "NEW DELHI, Feb 18 (Reuters) - An Indian university has been asked to vacate its stall at the country's flagship AI summit after a ‌staff member was caught presenting a commercially available robotic dog made in China ‌as its own creation, two government sources said.\n\n\"You need to meet Orion. This has been developed by the Centre ​of Excellence at Galgotias University,\" Neha Singh, a professor of communications, told state-run broadcaster DD News this week in remarks that have since gone viral.\n\nBut social media users quickly identified the robot as the Unitree Go2, sold by China's Unitree Robotics for about $2,800 and widely used ‌in research and education globally.\n\nThe episode ⁠has drawn sharp criticism and has cast an uncomfortable spotlight on India's artificial intelligence ambitions.\n\nThe embarrassment was amplified by IT Minister Ashwini Vaishnaw, ⁠who shared the video clip on his official social media account before the backlash. The post was later deleted.\n\nBoth Galgotias and Singh have subsequently said the robot was not a university creation ​and ​the university had never claimed otherwise.\n\nThe stall remained ​open to visitors as of Wednesday ‌morning with university officials fielding questions from media about accusations of plagiarism and misrepresentation.\n\nGalgotias has yet to receive any communication about being kicked out from the event, a representative at the booth said.\n\nThe India AI Impact summit at Bharat Mandapam in New Delhi, which runs until Saturday, has been billed as the first major AI gathering hosted in the Global ‌South. Prime Minister Narendra Modi, Google's Sundar Pichai, OpenAI's ​Sam Altman and Anthropic's Dario Amodei will address ​the gathering on Thursday.\n\nThe event has also ​faced broader organisational difficulties since opening, with delegates reporting overcrowding and ‌logistical issues.\n\nThat said, there has been more ​than $100 billion of investment ​in India AI projects pledged during the summit, including investments from the Adani Group conglomerate, tech giant Microsoft and data centre firm Yotta.\n\nIndia's biggest opposition party, Congress, ​was amongst those expressing outrage.\n\n\"The ‌Modi government has made a laughing stock of India globally with regard to ​AI,\" it said on social media, citing the robot incident.",
    "readingTime": 2,
    "keywords": [
      "social media",
      "summit",
      "stall",
      "creation",
      "globally",
      "event",
      "gathering",
      "university",
      "galgotias",
      "robot"
    ],
    "qualityScore": 0.9,
    "link": "https://www.yahoo.com/news/articles/india-tells-university-leave-ai-075331813.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters.com/7833106b6116581448817a3cc11f0c07",
    "created_at": "2026-02-18T18:38:29.412Z",
    "topic": "news"
  },
  {
    "slug": "theres-a-lot-at-stake-for-the-tech-giants-betting-big-on-wearables",
    "title": "There's a lot at stake for the tech giants betting big on wearables",
    "description": "The next big race among tech giants is building an AI device you'll want to wear all the time.",
    "fullText": "AI's next target? Helping you kick your phone addiction.\n\nAI devices are a top priority for Big Tech companies that view it as the future of how humans and AI interact, writes BI's Amanda Hoover.\n\nYou've likely heard of this hardware before, which acts as a sort of AI sidekick for your life. From the Rabbit R1 and Humane to Friend, the names are different, but the stories are the same: big expectations, difficult execution.\n\nAmanda's story covers how it's not just upstarts looking to shake things up. Tech giants like Apple, Meta, and OpenAI are working on their own solutions.\n\nIt's an uphill battle considering how addicted most of us are to our phones. However, the push for phone-free lifestyles, especially among Gen Z, does create an opening.\n\nThese tech giants also don't have much of a choice.\n\nApple, for example, has largely sat out the AI wars, saving a ton of money on model development. That only works if the iPhone remains a key distribution channel for the AI it's skipping out on developing.\n\nMeta's business is also heavily reliant on smartphone usage. (How often do you check Instagram on your desktop computer? Do you even have a desktop computer?) If user behavior around phones changes in a meaningful way, you can bet Meta wants to be ahead of it.\n\nAI devices also give companies a front-row seat to your life.\n\nYou could argue that's already the case with these AI chatbots. I'd argue the relationship between you and your chatbot of choice is still mostly transactional. You have a question/problem/thought; the chatbot has an answer (hopefully).\n\nThe relationship with AI wearables is more fluid. It's always listening, learning, and collecting. The pitch is that makes it a better copilot. Understanding your habits means it can figure out the best way to serve you.\n\nThat's putting a lot of faith, and your personal data, into an AI device, though\n\nMany executives I've spoken to have said this is the future. Truly leveraging AI is about incorporating it into your daily routine, not treating it as a one-off for specific problems.\n\nThe irony is that strategy has the potential to make AI even more addictive than the smartphones it's trying to replace.",
    "readingTime": 2,
    "keywords": [
      "tech giants",
      "desktop computer",
      "it's",
      "devices",
      "life",
      "phones",
      "choice",
      "argue",
      "that's",
      "relationship"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-next-target-phone-addiction-meta-wearable-openai-2026-2",
    "thumbnail_url": "https://i.insider.com/6995bb6ca645d11881897e5b?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:29.258Z",
    "topic": "finance"
  },
  {
    "slug": "business-insider-wins-first-george-polk-award",
    "title": "Business Insider wins first George Polk Award",
    "description": "Business Insider has won the Polk Award for The True Cost of Data Centers, an investigation revealing the hidden costs of the AI boom.",
    "fullText": "I'm thrilled to share that Business Insider has won the George Polk Award for Environmental Reporting for The True Cost of Data Centers, an investigation that created the most comprehensive national database of data centers and revealed hidden costs of the AI boom.\n\nThe George Polk Awards, which honor original, resourceful, and thought-provoking investigative work, are widely considered among the most prestigious in journalism. The judges said Business Insider's investigation was \"a thoroughly researched series highlighting the strain new and semi-secret facilities that fuel artificial intelligence are likely to place on communities, diverting overwhelming amounts of power, water and economic support.\"\n\nThis is Business Insider's first Polk Award. It is a milestone for our newsroom as we focus our investigative chops on the most crucial subjects in business, and as we combine our extraordinary talents across text, data, visuals, video, and more to deliver world-class journalism.\n\nThe True Cost of Data Centers identified 1,240 data centers built or approved across the US by the end of 2024 — nearly four times the number from 2010 — and exposed an infrastructure transformation happening almost entirely in secret. By filing public records requests across every US state and winning lawsuits to obtain water consumption data, our team uncovered how these data centers together would consume as much power as entire US states and guzzle enormous amounts of water daily in drought-stricken regions.\n\nBusiness Insider's investigation included a first-of-its-kind interactive national map displaying all 1,240 data centers for readers to see how close the data center boom is to their own backyards. It also included a documentary video, \"Exposing The Dark Side of America's AI Data Center Explosion,\" which has been watched more than 5 million times.\n\nThe database has been shared with 23 universities, including Harvard, MIT, Princeton, Stanford, Yale, and Columbia, and has been cited in at least 15 policy briefs.\n\nI am incredibly proud of this team for the creativity, care, and persistence it took to make this investigation happen. The reporting team includes Hannah Beckler, Dakin Campbell, Daniel Geiger, Rosemarie Ho, Narimes Parakul, Adam Rogers, and Ellen Thomas, along with editors Jeffrey Cane, Rosalie Chan, Jason Dean, Esther Kaplan, and Jake Swearingen.\n\nOn video, credit to Erica Berenstein, Alexander Calbi, Paige Clark, Robert Leslie, Reem Makhoul, Tyler Merkel, Ruqayyah Moynihan, Marco Secci, and Whitney Shefte. On design and visuals: Dan DeLerenzo, Isabel Fernandez-Pujol, Jinpeng Li, Kim Nguyen, Randy Yeip, and Rebecca Zisser, as well as photographers Kendrick Brinson, John David-Richardson, Greg Kahn, Brian Palmer, and Jesse Rieser.\n\nThanks also to Glen Smith on legal, Mo Mitchell on prizes, researchers Darren Ankrom, Schuyler Mitchell, Trey Strange, and Yuheng Zhan, and copy editors Mark Abadi and Kevin Kaplan.\n\nFinally, thank you to everyone throughout our newsroom and company who plays their part in making work like this possible and exceptional.",
    "readingTime": 3,
    "keywords": [
      "george polk",
      "polk award",
      "insider's investigation",
      "business insider's",
      "centers",
      "water",
      "across",
      "team",
      "database",
      "boom"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/business-insider-wins-first-george-polk-award-2026-2",
    "thumbnail_url": "https://i.insider.com/6995d47ea645d11881898085?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.985Z",
    "topic": "finance"
  },
  {
    "slug": "why-a-godfather-of-ai-still-thinks-his-4yearold-grandson-should-go-to-college",
    "title": "Why a godfather of AI still thinks his 4-year-old grandson should go to college",
    "description": "Yoshua Bengio, known as a \"godfather of AI\" alongside fellow computer scientists like Geoffrey Hinton and Yann LeCun, said education \" isn't just about acquiring the skills to get a job.\"",
    "fullText": "Is there any value in going to college when AI is expected to fundamentally reshape white-collar work?\n\nYes, according to Yoshua Bengio.\n\nOn Monday's episode of the \"Silicon Valley Girl\" podcast, its host Marina Mogilko asked Bengio if he would encourage his four-year-old grandson to go to college. Alongside fellow computer scientists Geoffrey Hinton and Yann LeCun, Bengio is known as one of the \"godfathers of AI\" thanks to his pioneering research in deep learning and neural networks.\n\nBengio quickly responded \"yes,\" adding: \"Education is really important, and education, contrary to what some people think, isn't just about acquiring the skills to get a job.\n\n\"Education is, in my opinion, mostly about how to become a better human being, how to understand yourself, how to understand our society and each other.\"\n\nBengio's comments add to the debate on whether it's worth pursuing the traditional college career pathway in a world where AI is matching or bettering humans on a wide range of cognitive tasks.\n\nHinton told a June episode of the \"Diary of a CEO\" podcast that AI may already be making it harder for college graduates to get jobs, and that it's a good time to become a plumber. Stanford professor Fei-Fei Li, nicknamed the \"Godmother of AI,\" told \"The Tim Ferriss Show\" in December that when hiring for her AI startup, a candidate's degree matters less than the tools they can use, including AI.\n\nBengio's comments on Monday echoed what he told \"The Diary of a CEO\" podcast in December, when he said his advice for his four-year-old grandson in our current world is to focus on being a \"beautiful human being.\"\n\n\"I think that part of ourselves will persist even if machines can do most of the jobs,\" he said.",
    "readingTime": 2,
    "keywords": [
      "bengio's comments",
      "ceo podcast",
      "four-year-old grandson",
      "college",
      "education",
      "episode",
      "hinton",
      "human",
      "understand",
      "it's"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-college-degree-go-college-white-collar-jobs-yoshua-bengio-2026-2",
    "thumbnail_url": "https://i.insider.com/6995cd42f8731049f3af4df7?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.728Z",
    "topic": "finance"
  },
  {
    "slug": "this-corner-of-the-tech-sector-will-offer-shelter-from-the-aidisruption-storm-analyst-says",
    "title": "This corner of the tech sector will offer shelter from the AI-disruption storm, analyst says",
    "description": "Wedbush said cybersecurity should be sheltered from AI disruption, while still benefitting from widespread adoption. It flagged its top three stock picks.",
    "fullText": "There's one corner of the tech sector where investors can hide out from AI disruption while still benefiting from the technology's adoption, Wedbush says.\n\nAnalysts led by Dan Ives, a vocal AI mega bull, flagged cybersecurity as a space that will see rising demand driven by AI, while steering clear of the AI worries that have rattled the market so far in 2026.\n\nExperts have called AI a double-edged sword for the cybersecurity industry, as the evolving technology is strengthening the capabilities of both cyber attackers and defenders.\n\n\"AI will be a major tailwind to the cyber security sector over the coming years as protection of use cases, data, and end points expand markedly,\" the analysts wrote.\n\n\"As attack frequency, success rates, and blast radius rise with AI deployments, cybersecurity becomes even more mission-critical risk management, reinforcing budget resilience in this new AI driven IT budget world,\" they added.\n\nCybersecurity is among the fastest growing areas of enterprise IT spending. Gartner expects global AI cybersecurity spending to hit $51 billion in 2026, roughly doubling from the year prior.\n\nWedbush highlighted three stocks as the best-positioned in the space: Palo Alto Networks, CrowdStrike, and Zscaler.\n\nWhat Wedbush says: \"We believe that CRWD's position as the gold standard of cybersecurity remains firmly unchanged in the face of this software sell-off with the company's innovative, best-in-class Falcon platform becoming increasingly effective in the modern threat landscape as AI adversaries become an incrementally larger threat for enterprises heading down the AI path.\"\n\nWhat Wedbush says: '\"AI is not displacing PANW's value proposition, but has actually made it more relevant, not less, as it is forcing customers to consolidate vendors, improve visibility, and automate response as threats become more adaptive and effective.\"\n\nWhat Wedbush says: \"AI is amplifying the need to secure access to data, models, and applications everywhere, reinforcing the mission-critical nature of ZS's offering, driving durable subscription growth and high renewal visibility.\"",
    "readingTime": 2,
    "keywords": [
      "what wedbush",
      "cybersecurity",
      "sector",
      "analysts",
      "space",
      "driven",
      "cyber",
      "mission-critical",
      "reinforcing",
      "budget"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/stock-picks-cybersecurity-tech-crowdstrike-palo-alto-networks-zcaler-wedbush-2026-2",
    "thumbnail_url": "https://i.insider.com/6995e8dfa645d118818982f9?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.388Z",
    "topic": "finance"
  },
  {
    "slug": "read-netflixs-legal-letter-to-bytedance-over-a-viral-ai-video-tool-it-calls-a-highspeed-piracy-engine",
    "title": "Read Netflix's legal letter to ByteDance over a viral AI video tool it calls a 'high-speed piracy engine'",
    "description": "Netflix sent TikTok parent ByteDance a cease-and-desist letter to over its AI video tool Seedance, following in Disney and Paramount's footsteps.",
    "fullText": "Netflix isn't amused by ByteDance's new AI video tool.\n\nThe streaming giant sent a cease-and-desist letter to the China-based TikTok parent on Tuesday night, calling its new generative AI model Seedance 2.0 \"a high-speed piracy engine.\"\n\nSeedance turned heads last week after a user created a viral video of people resembling Tom Cruise and Brad Pitt fighting on a rooftop about disgraced financier Jeffrey Epstein.\n\nWhile some were impressed, others panicked, with Deadpool cowriter Rhett Reese writing: \"I hate to say it. It's likely over for us.\"\n\nNetflix said in its letter to ByteDance that the company's AI video tool had also made videos mimicking characters from mega-hit Netflix shows like \"Stranger Things,\" \"Bridgerton,\" and \"Squid Game\" as well as the uber-popular movie \"KPop Demon Hunters.\"\n\n\"The use of copyrighted works to create a competing commercial product, especially one that regurgitates the original, is not protected by fair use,\" Netflix's litigation director wrote.\n\nNetflix urged ByteDance to stop generating AI videos that resemble its IP, and to identify and remove all such videos that have already been created. It also insisted that its IP be taken out of Seedance's training datasets.\n\nA ByteDance spokesperson said the company \"respects intellectual property rights\" and has \"heard the concerns regarding Seedance 2.0.\"\n\n\"We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,\" the ByteDance spokesperson said.\n\nDisney sent ByteDance a message similar to Netflix's last week. That's notable because Disney reached a deal in December to license iconic characters to OpenAI for its video-generating app Sora.\n\nSeedance is using \"a pirated library of Disney's copyrighted characters from Star Wars, Marvel, and other Disney franchises, as if Disney's coveted intellectual property were free public domain clip art,\" Disney said in its cease-and-desist letter to ByteDance.\n\nNetflix echoed that sentiment, saying it would \"not stand by and watch ByteDance treat our valued IP as free, public domain clip art.\"\n\nParamount Skydance also sent a cease-and-desist letter last week to ByteDance expressing similar concerns, Variety reported.\n\nRead Netflix's letter to ByteDance below:",
    "readingTime": 2,
    "keywords": [
      "domain clip",
      "clip art",
      "intellectual property",
      "cease-and-desist letter",
      "disney",
      "videos",
      "characters",
      "bytedance",
      "tool",
      "created"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/read-netflix-letter-bytedance-seedance-viral-ai-tool-piracy-disney-2026-2",
    "thumbnail_url": "https://i.insider.com/6995ef5aa645d118818983dc?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.319Z",
    "topic": "finance"
  },
  {
    "slug": "when-every-company-can-use-the-same-ai-models-context-becomes-a-competitive-advantage",
    "title": "When Every Company Can Use the Same AI Models, Context Becomes a Competitive Advantage",
    "description": "When everyone has access to the same AI models, the same AI-enabled tools, and the same vendor ecosystem, organizational context becomes the differentiator. Context is demonstrated execution: the workflows teams actually follow across systems, the signals they respond to, the order in which roles get involved, the exceptions that trigger action, and the judgment calls that repeat across real work. These patterns are visible only in execution, not in stated process. Leaders need to understand why context has become a decisive source of competitive advantage, and how they can capture and operationalize it.",
    "fullText": "When Every Company Can Use the Same AI Models, Context Becomes a Competitive Advantage by Rohan Narayana Murty and Ravi Kumar SFebruary 18, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAt a glance, the two large B2B companies were almost identical. Both sell complex, multi-year technology services; they compete for many of the same enterprise customers. Sales stages, forecasting cadence, and executive review rhythms were the same. Going by their customer relationship management (CRM) systems, their processes looked indistinguishable.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/when-every-company-can-use-the-same-ai-models-context-becomes-a-competitive-advantage",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_18_MarianoPascual.jpg",
    "created_at": "2026-02-18T18:38:27.678Z",
    "topic": "business"
  },
  {
    "slug": "gemini-now-lets-you-generate-ai-music-for-free",
    "title": "Gemini Now Lets You Generate AI Music for Free",
    "description": "Lyria 3 means Google's AI bot now covers text, code, images, video, and songs.",
    "fullText": "Google Gemini can help you write text, generate images and video, and write code. Now, the AI bot can generate music too, taking on the likes of Suno when it comes to producing tunes from a simple text prompt. The update is courtesy of the new Lyria 3 audio generation model, which is built into Gemini as of today. Developed by Google DeepMind, Lyria has been accessible in other Google products (such as Vertex AI and YouTube Shorts) to a select number of users, but this is the first time Google is making the model widely available to anyone who wants to try it.\n\nLyria works the same way as creating images or video: just describe what you want, and the AI does the rest. You might want to hear \"a comical R&B slow jam about a sock finding their match\" (as per Google's own example), or perhaps \"a sea shanty about the dangers of AI slop\"—it's up to you.\n\nWhen you click the \"Create music\" button inside the Gemini app, you also have the option to pick an existing track to remix, rather than starting from scratch—If you're perhaps stuck for inspiration. These presets cover everything from folk ballads to Latin pop, so you can see the kind of musical scope covered. You can also supply Lyria 3 inside Gemini with an image or video, and get it to compose something that matches the mood of the content you've supplied, including both music and lyrics. The example Google gives is supplying Gemini with a few photos of your dog, and then having it come up with a tune about the pooch and their adventures.\n\nThe tracks are limited to 30 seconds each at the moment, and while music making is available to all Gemini users, if you're paying for the Plus, Pro, or Ultra subscriptions, you'll get higher usage limits (though it isn't specified what these are). As per the official announcement blog post, the aim \"isn't to create a musical masterpiece, but rather to give you a fun, unique way to express yourself.\" You're not going to be able to set up your own AI-generated band on Spotify with this, but you can churn out a few entertaining tracks for your own (or someone else's) amusement.\n\nI haven't been able to try out the feature as of yet, but I have heard a few samples that Google supplied. They come across as rather generic and ordinary, exactly as you might expect something to sound that's the averaging out of vast amounts of audio training data—like song genres distilled into their most common ingredients and repackaged.\n\nGoogle says all created tracks will contain invisible watermarks powered by SynthID, flagging them as AI creations, and you can upload audio tracks to Gemini and run a SynthID check on them. The updated Lyria 3 model is also coming to the Dream Track music maker for YouTube Shorts creators. Lyria 3 is now rolling out inside Gemini, and is available to users aged 18 and above in English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. It's available first on the web app, and will show up on the mobile app over the next few days. Expansions in \"quality and coverage\" are planned in the future, Google says.",
    "readingTime": 3,
    "keywords": [
      "inside gemini",
      "music",
      "tracks",
      "audio",
      "model",
      "users",
      "rather",
      "you're",
      "google",
      "text"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/gemini-now-lets-you-generate-ai-music-for-free?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHRKMRTQQZSRSTPSKWCJ1GCW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-18T18:38:26.681Z",
    "topic": "tech"
  },
  {
    "slug": "microsofts-brad-smith-says-us-firms-should-worry-about-chinas-ai-subsidies",
    "title": "Microsoft’s Brad Smith says U.S. firms should \"worry\" about China’s AI subsidies",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/microsofts-brad-smith-says-us-firms-should-worry-about-chinas-ai-subsidies-4511809",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEEBK0BV_M.jpg",
    "created_at": "2026-02-18T18:38:26.279Z",
    "topic": "finance"
  },
  {
    "slug": "agent-panopticon-proxy-sidecar-for-autonomous-ai-agents",
    "title": "Agent Panopticon – Proxy sidecar for autonomous AI agents",
    "description": "Contribute to raka-gunarto/agent-panopticon development by creating an account on GitHub.",
    "fullText": "raka-gunarto\n\n /\n\n agent-panopticon\n\n Public\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n raka-gunarto/agent-panopticon",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/raka-gunarto/agent-panopticon",
    "thumbnail_url": "https://opengraph.githubassets.com/1e3cb205bafe6d7c2bbbb8f4e62a95a4220dddba16ab75d544484071d4fa6cdc/raka-gunarto/agent-panopticon",
    "created_at": "2026-02-18T12:37:14.664Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-bug-causes-copilot-to-summarize-confidential-emails",
    "title": "Microsoft says bug causes Copilot to summarize confidential emails",
    "description": "Microsoft says a Microsoft 365 Copilot bug has been causing the AI assistant to summarize confidential emails since late January, bypassing data loss prevention (DLP) policies that organizations rely on to protect sensitive information.",
    "fullText": "Microsoft says a Microsoft 365 Copilot bug has been causing the AI assistant to summarize confidential emails since late January, bypassing data loss prevention (DLP) policies that organizations rely on to protect sensitive information.\n\nAccording to a service alert seen by BleepingComputer, this bug (tracked under CW1226324 and first detected on January 21) affects the Copilot \"work tab\" chat feature, which incorrectly reads and summarizes emails stored in users' Sent Items and Drafts folders, including messages that carry confidentiality labels explicitly designed to restrict access by automated tools.\n\nCopilot Chat (short for Microsoft 365 Copilot Chat) is the company's AI-powered, content-aware chat that lets users interact with AI agents. ​Microsoft began rolling out Copilot Chat to Word, Excel, PowerPoint, Outlook, and OneNote for paying Microsoft 365 business customers in September 2025.\n\n\"Users' email messages with a confidential label applied are being incorrectly processed by Microsoft 365 Copilot chat,\" Microsoft said when it confirmed this issue.\n\n\"The Microsoft 365 Copilot 'work tab' Chat is summarizing email messages even though these email messages have a sensitivity label applied and a DLP policy is configured.\"\n\nMicrosoft has since confirmed that an unspecified code error is responsible and said it began rolling out a fix in early February. As of Wednesday, the company said it was continuing to monitor the deployment and is reaching out to a subset of affected users to verify that the fix is working.\n\n\"A code issue is allowing items in the sent items and draft folders to be picked up by Copilot even though confidential labels are set in place,\" Microsoft added.\n\nMicrosoft has not provided a final timeline for full remediation and has not disclosed how many users or organizations were affected, saying only that the scope of impact may change as the investigation continues.\n\nHowever, this ongoing incident has been tagged as an advisory, a flag commonly used to describe service issues typically involving limited scope or impact.\n\nModern IT infrastructure moves faster than manual workflows can handle.\n\nIn this new Tines guide, learn how your team can reduce hidden manual delays, improve reliability through automated response, and build and scale intelligent workflows on top of tools you already use.",
    "readingTime": 2,
    "keywords": [
      "label applied",
      "email messages",
      "tab chat",
      "microsoft copilot",
      "confidential",
      "emails",
      "january",
      "organizations",
      "service",
      "incorrectly"
    ],
    "qualityScore": 0.9,
    "link": "https://www.bleepingcomputer.com/news/microsoft/microsoft-says-bug-causes-copilot-to-summarize-confidential-emails/",
    "thumbnail_url": "https://www.bleepstatic.com/content/hl-images/2025/09/16/Copilot_headpic.jpg",
    "created_at": "2026-02-18T12:37:14.182Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-pledges-50b-to-tackle-growing-ai-inequality",
    "title": "Microsoft pledges $50B to tackle growing AI inequality",
    "description": "Microsoft says it is on track to invest $50 billion by the end of the decade to help bring artificial intelligence to lower-income countries, as concerns mount over the technology’s potential to deepen inequality.",
    "fullText": "Microsoft says it is on track to invest $50 billion by the end of the decade to help bring artificial intelligence to lower-income countries, as concerns mount over the technology’s potential to deepen inequality.\n\nThe announcement was made Wednesday at the AI Impact Summit in New Delhi, where leading tech executives, government officials and AI researchers are debating how to use AI to solve real-world problems.\n\nPolicymakers globally are increasingly worried that the unequal adoption of AI risks widening income and development gaps between rich and poor countries. In December, the United Nations Development Project called for global cooperation on standards and safety to ensure the technology “functions as a shared public good rather than a concentrated advantage.”\n\nAt the summit, Microsoft likewise expressed the need for cross-border partnerships to prevent poorer countries from being left behind.\n\n“We need to act with urgency to address the growing AI divide,” Microsoft president Brad Smith and chief responsible AI officer Natasha Crampton said in a joint statement. “Artificial intelligence is diffusing at an impressive speed, but its adoption around the world remains profoundly uneven.”\n\nThe company’s $50 billion commitment to developing economies by 2030 compares with the roughly $80 billion that Microsoft invested into data centers last year alone, more than half of which was directed to a single economy: the United States.\n\nA recent Microsoft report found that AI usage in the global north, a catch-all term for developed and high-income countries, is roughly twice that of the global south — and growing.\n\n“This disparity impacts not only national and regional economic growth, but whether AI can deliver on its broader promise of expanding opportunity and prosperity around the world,” Smith and Crampton said.\n\nThey warned that, just as unequal access to electricity has exacerbated a growing economic gap between the global north and south, without urgent action, the AI divide could perpetuate that disparity in the century ahead.\n\nOn the other hand, the technology could be used positively to help poor countries leapfrog older development pathways. “If AI is deployed broadly and used well by a young and growing population, it offers a real prospect for catch-up economic growth for the Global South,” said Smith and Crampton.\n\n“It might even provide the biggest such opportunity of the 21st century,” the pair said.\n\nMicrosoft’s $50 billion investment will, among other things, help to build the data centers crucial to providing the computing power needed to run AI models. Extending internet access is another focus.\n\nOnly about 36% of Africa’s population had broadband internet access in 2022, according to the World Bank. That compares with some 90% of US households, official figures show.\n\nThe AI Impact Summit, hosted by India’s Prime Minister Narendra Modi, highlights the country’s ambition to position itself as an AI leader in the global south.\n\nHigh-profile attendees include Sam Altman of OpenAI, the developer of ChatGPT, Anthropic CEO Dario Amodei and Google CEO Sundar Pichai who is due to deliver a keynote address on Friday.",
    "readingTime": 3,
    "keywords": [
      "impact summit",
      "artificial intelligence",
      "economic growth",
      "internet access",
      "development",
      "unequal",
      "adoption",
      "poor",
      "technology",
      "address"
    ],
    "qualityScore": 1,
    "link": "https://www.cnn.com/2026/02/18/business/ai-impact-summit-microsoft-inequality-investment",
    "thumbnail_url": "https://media.cnn.com/api/v1/images/stellar/prod/2026-02-18t055009z-946177043-rc2lnjaf3v8r-rtrmadp-3-india-ai-summit-microsoft.jpg?c=16x9&q=w_800,c_fill",
    "created_at": "2026-02-18T12:37:13.863Z",
    "topic": "business"
  },
  {
    "slug": "openai-meta-and-apples-latest-battle-breaking-your-phone-addiction",
    "title": "OpenAI, Meta, and Apple's latest battle: Breaking your phone addiction",
    "description": "The tech companies that created our phone addiction are trying to cure us with AI wearables.",
    "fullText": "The average American picks up their phone more than 200 times a day. Teens are pinged with some 250 notifications a day — during school, after school, and overnight. The apps meant to prevent you from checking apps have done little to stop the problem. Now, some of the tech companies that helped create our screen dependence are trying to disrupt it.\n\nLater this year, OpenAI plans to debut a small, screenless device that Sam Altman describes as more \"peaceful\" than a smartphone. Apple, the Oz of screentime, is developing smart glasses, a pin, and AirPods with more AI built in, according to a Tuesday report from Bloomberg, with the rumored pendants featuring microphones and cameras to be the \"eyes and ears\" of the iPhone. Meta has teased its fully augmented reality Orion glasses since 2024. While that device doesn't have a release date, the company last year sold some 7 million pairs of its smart glasses, which is the start of the post-smartphone future Mark Zuckerberg has predicted. Eventual smart specs could be more screen all-the-time than screenless, but they also rely on AI to make the experience much more hands-free than swiping and scrolling on a phone.\n\nCould AI be what finally breaks our phone addiction?\n\nSince 2007, no device out of Silicon Valley has captured universal imagination the way Steve Jobs did when he put your iPod, your phone, and the internet together on a 3.5-inch screen. Competitors have tried for a decade-plus to get people to shift us from the iPhone to smart glasses, and largely failed. The awe around smartphones has turned to derision, as excessive screen time is linked to disrupted sleep, anxiety, and fractured attention. Now, developers are hoping the AI boom can give us the next big thing.\n\nBeating the smartphone would mean replacing a device that 91% of American adults now carry — a device for which millions of apps have been developed and people now depend on in lieu of wallets and cameras and health monitors. New AI devices can't just copy what smartphones do, says Ramon Llamas, a research director at a technology intelligence firm IDC: They have to show they have a solution to an everyday problem. If they don't, Llama says, \"these things are just gonna really end up as solutions looking for a problem to solve.\"\n\nCritiques of screen time can be as blunt and smoothbrained as what the critics say excessive screen time makes you. A seven-hour daily log may seem like a staggering amount of dependence, but what did the person spend those seven hours doing? Doomscrolling late into the night, or FaceTiming with a far-away friend? With AI wearables, there's the risk of becoming dependent on the device for different reasons.\n\n\"The screen may not be there, but what's getting filled in the back is already this problem of AI companionship,\" says Olivia Gambelin, an AI ethicist and author of the book \"Responsible AI.\" An AI device designed to do something very specific — like listen to a meeting and then send follow-up emails or messages related to action points discussed — could save people time and keep them from writing tedious emails and Slack messages from their desk. But that same device listening in to personal conversations with family and friends could compromise a relationship, and erode the positive effects that texting a friend to check-in can have on both people (already, my friends are tiring of AI summaries on the iPhone that summarize our group text and become an intermediary into our threads of gossip and jokes in the name of efficiency). Wearing microphones and cameras to social interactions and into businesses is likely to really weird out some of the people around you. More people are entering into romantic, dependent relationships with AI companions, and a swell of loud dissenters are criticizing the technology for taking jobs and attempting to replicate human relationships.\n\nBut OpenAI is betting that it can package its technology in a device in a way that calms the user. \"When I use current devices or most applications, I feel like I am walking through Times Square in New York and constantly just dealing with all the little indignities along the way,\" Altman said in November. OpenAI's device, he said, would be less Time Square, more \"sitting in the most beautiful cabin by a lake and in the mountains and sort of just enjoying the peace and calm.\" That's because the AI device would learn \"contextual awareness of your whole life,\" and when best to send you alerts.\n\nOther AI wearables have failed by falling short of that goal. Humane AI sold a wearable pin, priced at $700 plus a monthly fee to connect it, but pulled it from the market a year ago. It failed perhaps because it tried too hard to replace our phones — it didn't interact with them, but provided a shoddy replacement. Novelty wasn't a factor that could outshine usability. The AI Friend pendant, which can't search the internet or help with tasks outside of sending reminders and acts instead as an eavesdropping sycophant around its user's neck, was mocked relentlessly and sold just a few thousand devices after it hit the market last year.\n\nCompanies trying to make AI hardware should focus on \"transformative features,\" Jason Low, research director at Omdia, tells me in an email. AI wearables must be more than \"marginally more convenient,\" should integrate with our existing products, and have a clear, stated value. For example, glasses that provide real-time language translation or devices for fitness and health tracking offer features our smartphones can't do as well. The Oura ring continues to grow in popularity, particularly among women after starting out as a niche tech bro buy, for the novel insights it can offer; the company announced last fall it has sold 5.5 million rings since 2015, with more than 2.5 million sold between June 2024 and September 2025. \"These devices often deliver a more polished user experience compared to general-purpose, do-it-all AI devices,\" Low says.\n\nLlamas tells me that the AI functions of a wearable have to be \"contextual, personalized, and actionable,\" like reminding the wearer to send birthday flowers or responding accurately to being asked to direct the user to the nearest Starbucks. A first attempt device shouldn't try to replace the smartphone, but to integrate with the Apple or Google ecosystems, he says. Apple and OpenAI did not respond to requests for comment about their rumored products for this story.\n\nIf anything has hyped Silicon Valley like the iPhone, it's been AI. But three years after the mainstream adoption of ChatGPT, the value generative AI in the white collar workforce has yet to be fully realized. That could make a product for consumers a hard sell, too. \"Some of the overwhelm that's coming with AI that I see in general users is you can use it for everything, or it's promoted that way, which is actually quite stifling,\" Gambelin says.\n\nIn our quest to find a peaceful equilibrium with tech, the screen itself may not be the problem; it's what's summoning us to the screen. Its bright colors, games, and infinite scroll give quick dopamine hits that entice us to stay glued to it. But much of what pings my phone throughout the day are useless notifications trying to get me to reopen one of the dozens of apps — a markdown moment on a clothing thrifting app, a like on the Instagram story I've posted of my dog from my best friend, and ironically, a report of how much time I've already logged. There's a relentless business model at play to keep us on these apps. No screens would mean no infinite scroll through TikTok, no Candy Crush — but app developers and companies may need to find new ways to reach people if wearables caught on, and an always-there AI device and companion might not be as peaceful as Altman describes. Our collective screen time is a problem, but the AI wearable will have to surprise us all with something novel to be useful.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 7,
    "keywords": [
      "research director",
      "infinite scroll",
      "smart glasses",
      "excessive screen",
      "silicon valley",
      "device",
      "devices",
      "phone",
      "apps",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-meta-apple-wearables-phone-addiction-2026-2",
    "thumbnail_url": "https://i.insider.com/6994e2ade1ba468a96ac31ae?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.292Z",
    "topic": "finance"
  },
  {
    "slug": "anthropics-claude-code-creator-predicts-software-engineering-title-will-start-to-go-away-in-2026",
    "title": "Anthropic's Claude Code creator predicts software engineering title will start to 'go away' in 2026",
    "description": "Boris Cherny, the founder of Anthropic's Claude Code, said AI has largely solved coding, so software engineers will start to take on different tasks.",
    "fullText": "The creator of a popular AI coding agent said software engineering as a job title will soon be a thing of the past as artificial intelligence automates writing code.\n\nBoris Cherny, who created Claude Code at Anthropic, said in an interview with Y Combinator's \"Lightcone\" podcast that 2026 will bring \"insane\" developments to AI. That includes a massive shift in the work software engineers do across industries.\n\n\"I think today coding is practically solved for me, and I think it'll be the case for everyone regardless of domain,\" Cherny said in the interview, published Tuesday. \"I think we're going to start to see the title 'software engineer' go away. And I think it's just going to be maybe builder, maybe product manager, maybe we'll keep the title as a vestigial thing.\"\n\nCherny added that software engineers will not only be coding but increasingly taking on other tasks like \"writing specs\" — a document that defines what and how something will be built — or talking to users.\n\n\"Like this thing that we're starting to see right now in our team, where engineers are very much generalists, and every single function on our team codes,\" he said — including product managers, designers, engineering manager, and finance people.\n\nTech executives and founders have said advancements in AI have rapidly changed the way their teams operate in the past few years\n\nJesal Gadhia, a startup founder, recently told Business Insider that all the code for his company were written by agents, which wouldn't have been possible in 2024.\n\nAgents like Claude have changed how software engineers work as they spend more time reviewing or debugging code rather than writing lines of it.\n\nSome in the industry have started to note the unintended consequences of relying on AI. A software engineer told Business Insider that AI has simultaneously made them productive and overworked, leading to \"AI fatigue.\"\n\nAndrej Karpathy, a founding member of OpenAI and Tesla's ex-head of AI, said in January that he has noticed his ability to manually code has started to \"atrophy.\"",
    "readingTime": 2,
    "keywords": [
      "software engineer",
      "software engineers",
      "business insider",
      "coding",
      "title",
      "engineering",
      "interview",
      "we're",
      "product",
      "manager"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-claude-code-founder-ai-impacts-software-engineer-role-2026-2",
    "thumbnail_url": "https://i.insider.com/69951a8aa645d11881897ccb?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.284Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-software-freakout-is-a-massive-overreaction-heres-why",
    "title": "The AI software freakout is a massive overreaction. Here's why.",
    "description": "The SaaSpocalypse fears are overblown. AI's integration into enterprise software may boost, not harm, established SaaS companies.",
    "fullText": "The recent AI-inspired software meltdown is an enormous overreaction. SaaS companies are going to do just fine. In fact, they might see their businesses boom as a result of AI.\n\nAfter working for decades in the IT and cloud sectors, I know what it takes to build, sell, and maintain complex enterprise software. And it's clear to me that AI is not the threat that many investors fear.\n\nLet's look at the three main concerns that the market is obsessing over. All of them have shortcomings that will keep established SaaS vendors doing well.\n\nSoftware development has been transformed by AI. It's a near-perfect use case for generative AI: applying established patterns to a well-bounded use case, resulting in incredible productivity improvements.\n\nThis coding revolution has led some commentators to predict that companies are going to write their own software, rather than buy it from SaaS vendors.\n\nThis makes me wonder if these commentators have ever actually spent any time working in enterprise IT. Even if one accepts that software creation is much easier now, bringing a full software product to market requires much more than code:\n\nGeoffrey Moore, a renowned management consultant and organizational theorist, wrote a book called \"Crossing the Chasm\" on what mainstream enterprises need to adopt new technology. He never mentioned the cost of writing software code as a gating factor.\n\nOver the course of my long career, I have witnessed countless DIY failures by enterprise IT organizations that fail to understand the difference between an internal software project and a real product. I can already see another wave of failures, fueled by misplaced AI coding enthusiasm.\n\nAI prognosticators see cheaper startups displacing large software incumbents. This overlooks the reality that established SaaS providers already have smaller, cheaper competitors yet somehow remain dominant. The challenges for new entrants to a software sector include:\n\nIt's incredibly difficult for a small startup to displace an incumbent vendor. As Clayton Christensen observed in \"The Innovators Dilemma,\" innovative startups usually begin by solving use cases incumbent vendors are unable or unwilling to serve.\n\nLeft unaddressed in this scenario is why incumbents wouldn't just use AI themselves to improve engineering efficiency to address any price pressure from smaller new rivals.\n\nThis is the idea that AI model companies will extend their nascent software products into vertical offerings, thereby killing off incumbent vendors.\n\nOpenAI made a big splash with a healthcare initiative, for example. Anthropic caused a bunch of software stocks to drop with its plugins.\n\nIt's understandable why these companies launched these initiatives. Many industry-specific software companies are highly profitable, so AI labs would love to get a piece of this business.\n\nPursuing this, while working on other initiatives, could spread AI labs too thin, though. Startups often fail due to a lack of focus, and this is especially apropos for AI model makers. They face enormous, unprecedented opportunity, and getting distracted by bright, shiny vertical SaaS offerings is a terrible idea.\n\nGoing back to the DIY section above, there's huge complexity and cost to shipping and maintaining real enterprise software. Now multiple this by all the various industry verticals that exist, such as healthcare, financial services, and manufacturing. Addressing the idiosyncratic requirements of each sector would require huge numbers of employees, along with management time and attention. The model makers are already growing at breakneck speed; trying to add enough people to become vertical software providers would be a Sisyphean task.\n\nIf I were advising these boards, I would argue for focus: win the horizontal AI model layer in what is likely to become a small oligopoly.\n\nAnd yes, expand AI coding capabilities that lower the cost of development and increase the global population of software creators. That dynamic could trigger Jevons Paradox — cheaper software leading to vastly more of it — enriching the model providers without forcing them into every software vertical.\n\nThe SaaSpocalypse will, in retrospect, come to be thought of like the Beanie Babies mania: a short-lived phenomena that now seems inexplicable to comprehend.\n\nBernard Golden is CEO of Navica, a Silicon Valley-based technology analysis, consulting, and investment firm.",
    "readingTime": 4,
    "keywords": [
      "established saas",
      "saas vendors",
      "model makers",
      "incumbent vendors",
      "enterprise software",
      "vertical",
      "coding",
      "cheaper",
      "startups",
      "providers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/saaspocalypse-ai-software-overreaction-premature-obituary-openai-anthropic-2026-2",
    "thumbnail_url": "https://i.insider.com/6994e810a645d11881897add?width=1166&format=jpeg",
    "created_at": "2026-02-18T12:37:13.268Z",
    "topic": "tech"
  },
  {
    "slug": "cios-are-telling-companies-that-ai-capex-spending-has-gone-too-far",
    "title": "CIOs are telling companies that AI capex spending has gone too far",
    "description": "The highest portion of fund managers on record think that companies are overspending on capex.",
    "fullText": "Silicon Valley hyperscalers made it clear during the year's first earnings week they don't plan to dial back AI capex spending. Based on new survey results, Wall Street doesn't approve.\n\nBank of America surveyed 162 fund managers overseeing a combined $440 billion, and a record portion of them said they think companies are \"overinvesting\" in capex.\n\nOn top of that, more CIOs are leaning in favor of decreasing capex spending. Only 20% of survey respondents have advocated for increasing capex, down from 34%.\n\nThat may be because they see AI as an increasing risk to the market's strength in 2026. 25% of survey respondents reported that they see the AI bubble as the largest tail risk, more so than inflation, geopolitical conflict or a disorderly increase in bond yields.\n\nMeanwhile, a fair amount of investors made it clear that they believe AI hyperscaler capex poses another significant threat. 30% of survey respondents revealed that they see it as the most likely source of a systemic credit event.\n\nA year ago, it might have seemed absurd to suggest that tech companies should spend less money on building out AI models and infrastructure. But over the last few quarters, investors have raised the bar for what they expect from companies heavily investing in AI.",
    "readingTime": 2,
    "keywords": [
      "survey respondents",
      "capex",
      "increasing",
      "risk",
      "investors"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-capex-overspending-bofa-fund-manager-survey-hartnett-2026-2",
    "thumbnail_url": "https://i.insider.com/6994b634e1ba468a96ac2cb9?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.267Z",
    "topic": "finance"
  },
  {
    "slug": "jake-paul-says-sam-altman-taught-him-the-value-of-a-15minute-meeting",
    "title": "Jake Paul says Sam Altman taught him the value of a 15-minute meeting",
    "description": "Jake Paul said that OpenAI CEO Sam Altman, who he bonded with over \"fast cars,\" taught him to be \"hella productive\" with meetings.",
    "fullText": "Jake Paul was a firebrand YouTuber. Then he was an NFT merchant, and a betting site operator. Now, Paul is a professional boxer — and venture capitalist. And he's learning from one of the biggest names in tech.\n\nOn \"Sourcery,\" Paul said that he met OpenAI CEO Sam Altman while sitting next to each other at President Donald Trump's inauguration.\n\n\"Sam likes fast cars, and so do I,\" Paul said. \"So, we just started talking about cars, and then we got along, and that was really it.\"\n\nPaul's Anti Fund — which is also led by his brother Logan and longtime founder Geoffrey Woo — invested in OpenAI in 2025. The biggest lesson he's learned from Altman is efficiency, Paul said.\n\nHe described the quick-and-tidy meetings that Altman runs. The OpenAI CEO \"walks into the room, sits down, let's get right into the conversation, boom boom boom,\" he said.\n\nIn 15 minutes alone, Altman was \"hella productive,\" Paul said. Then, Altman can go on to his next meeting and do it all over again.\n\n\"We'll do hourlong meetings or calls and just waste time,\" Paul said. \"I think that was inspiring because time is the most valuable thing, and it's the only reason you can't accomplish more.\"\n\nIndeed, Altman has long opted for the 15-minute meeting. In a 2018 blog post, he wrote that the ideal meeting time is either around 15 to 20 minutes or 2 hours, but \"the default of 1 hour is usually wrong.\"\n\nPaul has worked closely with OpenAI in the last year, beyond participating in fundraising.\n\nRemember all of those strange Paul memes running around the internet during the Sora 2 launch? They were by design. Paul said he helped consult on the project and was one of the first to sign over his name, image, and likeness.\n\nWoo also appeared on the podcast, and spelled out the thinking behind those far-out memes (such as an AI Paul declaring he was gay). \"It was not something that was like, 'Hey, Jake Paul is now gay.' Jake was thoughtful in terms of why we were part of that launch.\"\n\nWoo also said that he had formed a good friendship with Altman and Mark Chen, OpenAI's chief research officer.\n\nFor the Sora 2 launch, Paul said that he had \"regular calls\" with OpenAI and offered \"super detailed consulting.\"\n\n\"Me and my brother have however many years combined of social media experience since the beginning,\" Paul said. \"We were there when the term 'influencer' was even made up.\"\n\nThis background, Paul said, helped him give good advice on what OpenAI's social media-like interface should look like. He advised on both what creators and audiences wanted, he said.\n\nAnti Fund closed its $30 million fund in September. Other investments include defense tech startup Anduril and prediction market Polymarket.\n\nWoo said their ties to OpenAI remain strong. \"We were just at OpenAI for three hours looking for other ways to collaborate,\" he said. \"Things might be cooking.\"",
    "readingTime": 3,
    "keywords": [
      "sora launch",
      "openai ceo",
      "boom boom",
      "paul",
      "altman",
      "he's",
      "biggest",
      "tech",
      "cars",
      "brother"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-15-minute-meetings-efficient-jake-paul-2026-2",
    "thumbnail_url": "https://i.insider.com/69948dcaa645d118818970ae?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:12.865Z",
    "topic": "finance"
  },
  {
    "slug": "investor-dan-ives-says-the-tech-selloff-that-has-been-spooking-markets-is-actually-a-generational-opportunity-to-get-in",
    "title": "Investor Dan Ives says the tech selloff that has been spooking markets is actually a ‘generational opportunity’ to get in on the action",
    "description": "Investors are drawing their battle lines as AI sorts tech companies into winners and losers.",
    "fullText": "The once relentless rally in AI-fueled stocks has lost momentum, as investors confront the unsettling idea that advances in artificial intelligence could erode the very value propositions that made tech giants dominant in the first place. Yet some executives and market veterans warn against short-term panic, calling the selloff a rare opportunity to buy into the next phase of the AI boom.\n\nThe AI growth story has been tempered by a widespread selloff in software stocks. Call it the software-mageddon or the SaaSpocalypse, but companies who specialize in designing, selling, and maintaining digital software products are getting battered. Earlier this month, JPMorgan analysts wrote that software companies had lost around $2 trillion in value over the past year, calling it “the largest non-recessionary 12-month drawdown in over 30 years.”\n\nThe culprit has been an increasingly widespread feeling among investors that AI is sorting tech players into winners and losers. Under this view, software companies could fall into the latter camp as the capabilities of newer AI models promise to replace expensive digital services, rendering the business models of companies like Salesforce and Atlassian obsolete.\n\nBut not all investors are convinced these companies are destined for irrelevance. Hidden within the chaos could lie an undervalued chance to buy these tech stocks at a discount, a relative rarity in an age of soaring valuations and speculative growth. It all depends on whether bullish buyers consider AI as complementary to existing software services, or capable enough to replace them entirely.\n\n“I think this software selloff will go down as a generational opportunity to own some of the stalwarts,” Dan Ives, a managing director and senior equity research analyst at Wedbush Securities, said in a Yahoo Finance interview Friday. “I feel more emboldened about the bull thesis on tech and AI this year, despite obviously this massive pullback.”\n\nIves named three industry leaders that he sees as being unfairly punished in today’s market, and that could be in for a powerful rebound:\n\nIves called the software stock correction a “structural selloff” that was the largest in scale he’d seen in 25 years. But instead of spelling doom for these companies, he framed the wipeout as a once-in-a-lifetime opportunity to invest in enterprise technology, arguing that software developers will remain a “core part of the use cases,” even in an AI-powered future.",
    "readingTime": 2,
    "keywords": [
      "software",
      "tech",
      "selloff",
      "stocks",
      "investors",
      "opportunity",
      "market",
      "growth",
      "widespread",
      "digital"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/investor-dan-ives-says-tech-171414614.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/lm.wqBfnfQfRbIxr0gVgeQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/dbe82f78842f4e2e71e45ec99f99249e",
    "created_at": "2026-02-18T12:37:08.135Z",
    "topic": "finance"
  },
  {
    "slug": "race-for-ai-is-making-hindenburgstyle-disaster-a-real-risk-says-leading-expert",
    "title": "Race for AI is making Hindenburg-style disaster ‘a real risk’, says leading expert",
    "description": "Prof Michael Wooldridge says scenario such as deadly self-driving car update or AI hack could destroy global interest\nThe race to get artificial intelligence to market has raised the risk of a Hindenburg-style disaster that shatters global confidence in the technology, a leading researcher has warned.\nMichael Wooldridge, a professor of AI at Oxford University, said the danger arose from the immense commercial pressures that technology firms were under to release new AI tools, with companies desperate to win customers before the products’ capabilities and potential flaws are fully understood.\n Continue reading...",
    "fullText": "Prof Michael Wooldridge says scenario such as deadly self-driving car update or AI hack could destroy global interest\n\nThe race to get artificial intelligence to market has raised the risk of a Hindenburg-style disaster that shatters global confidence in the technology, a leading researcher has warned.\n\nMichael Wooldridge, a professor of AI at Oxford University, said the danger arose from the immense commercial pressures that technology firms were under to release new AI tools, with companies desperate to win customers before the products’ capabilities and potential flaws are fully understood.\n\nThe surge in AI chatbots with guardrails that are easily bypassed showed how commercial incentives were prioritised over more cautious development and safety testing, he said.\n\n“It’s the classic technology scenario,” he said. “You’ve got a technology that’s very, very promising, but not as rigorously tested as you would like it to be, and the commercial pressure behind it is unbearable.”\n\nWooldridge, who will deliver the Royal Society’s Michael Faraday prize lecture on Wednesday evening, titled “This is not the AI we were promised”, said a Hindenburg moment was “very plausible” as companies rushed to deploy more advanced AI tools.\n\nThe Hindenburg, a 245-metre airship that made round trips across the Atlantic, was preparing to land in New Jersey in 1937 when it burst into flames, killing 36 crew, passengers and ground staff. The inferno was caused by a spark that ignited the 200,000 cubic metres of hydrogen that kept the airship aloft.\n\n“The Hindenburg disaster destroyed global interest in airships; it was a dead technology from that point on, and a similar moment is a real risk for AI,” Wooldridge said. Because AI is embedded in so many systems, a major incident could strike almost any sector.\n\nThe scenarios Wooldridge imagines include a deadly software update for self-driving cars, an AI-powered hack that grounds global airlines, or a Barings bank-style collapse of a major company, triggered by AI doing something stupid. “These are very, very plausible scenarios,” he said. “There are all sorts of ways AI could very publicly go wrong.”\n\nDespite the concerns, Wooldridge said he did not intend to attack modern AI. His starting point is the gap between what researchers expected and what has emerged. Many experts anticipated AI that computed solutions to problems and provided answers that were sound and complete. “Contemporary AI is neither sound nor complete: it’s very, very approximate,” he said.\n\nThis arises because large language models, which underpin today’s AI chatbots, rattle out answers by predicting the next word, or part of a word, based on probability distributions learned in training. It leads to AIs with jagged capabilities: incredibly effective at some tasks, yet terrible at others.\n\nThe problem, Wooldridge said, was that AI chatbots failed in unpredictable ways and had no idea when they were wrong, but were designed to provide confident answers regardless. When delivered in human-like and sycophantic responses, the answers could easily mislead people, he added. The risk is that people start treating AIs as if they were human. In a 2025 survey by the Center for Democracy and Technology, nearly a third of students reported that they or a friend had had a romantic relationship with an AI.\n\n“Companies want to present AIs in a very human-like way, but I think that is a very dangerous path to take,” Wooldridge said. “We need to understand that these are just glorified spreadsheets, they are tools and nothing more than that.”\n\nWooldridge sees positives in the kind of AI depicted in the early years of Star Trek. In one 1968 episode, The Day of the Dove, Mr Spock quizzes the Enterprise’s computer only to be told in a distinctly non-human voice that it has insufficient data to answer. “That’s not what we get. We get an overconfident AI that says: yes, here’s the answer,” he said. “Maybe we need AIs to talk to us in the voice of the Star Trek computer. You would never believe it was a human being.”",
    "readingTime": 4,
    "keywords": [
      "the hindenburg",
      "risk",
      "commercial",
      "tools",
      "chatbots",
      "wooldridge",
      "scenario",
      "deadly",
      "self-driving",
      "hack"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/feb/17/ai-race-hindenburg-style-disaster-a-real-risk-michael-wooldridge",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ece0f11b49a602a64f2f6c233331b06d7d3a4b00/189_0_2810_2249/master/2810.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b4f173b1c88631c2453efad56fff6227",
    "created_at": "2026-02-18T12:37:07.113Z",
    "topic": "science"
  },
  {
    "slug": "tech-billionaires-fly-in-for-delhi-ai-expo-as-modi-jostles-to-lead-in-south",
    "title": "Tech billionaires fly in for Delhi AI expo as Modi jostles to lead in south",
    "description": "Google, Anthropic and OpenAI bosses to mingle with global south leaders wrestling for control over technology\nSilicon Valley tech billionaires will land in Delhi this week for an AI summit hosted by India’s prime minister, Narendra Modi, where leaders of the global south will wrestle for control over the fast-developing technology.\nDuring the week-long AI Impact Summit, attended by thousands of tech executives, government officials and AI safety experts, tech companies valued at trillions of dollars will rub along with leaders of countries such as Kenya and Indonesia, where average wages dip well below $1,000 a month.\n Continue reading...",
    "fullText": "Google, Anthropic and OpenAI bosses to mingle with global south leaders wrestling for control over technology\n\nSilicon Valley tech billionaires will land in Delhi this week for an AI summit hosted by India’s prime minister, Narendra Modi, where leaders of the global south will wrestle for control over the fast-developing technology.\n\nDuring the week-long AI Impact Summit, attended by thousands of tech executives, government officials and AI safety experts, tech companies valued at trillions of dollars will rub along with leaders of countries such as Kenya and Indonesia, where average wages dip well below $1,000 a month.\n\nAmid a push to speed up AI adoption across the globe, Sundar Pichai, Sam Altman and Dario Amodei, the heads of Google, OpenAI and Anthropic, will all be there. Rishi Sunak and George Osborne, a former British prime minister and a former chancellor, will each be pushing for greater adoption of AI. Sunak has taken jobs for Microsoft and Anthropic and Osborne leads OpenAI’s push to deepen and widen the use of ChatGPT beyond its existing 800 million users.\n\nMeanwhile Modi, who will address the summit on Thursday, is positioning India as the AI hub for south Asia and Africa. On the agenda will be AI’s potential to transform agriculture, water supplies and public health. Governments in Kenya, Senegal, Mauritius, Togo, Indonesia and Egypt will send ministers.\n\nModi’s enthusiasm for AI has a darker side, civil liberties campaigners say. Last week they raised serious concerns about India deploying AI to increase state surveillance, discriminate against minorities and sway elections. But Modi this week spoke of “harnessing artificial intelligence for human-centric progress” and India has given the summit the strapline: “Welfare for all, happiness for all.”\n\nSummit observers talk of a battle between a new kind of AI colonialism from the US tech firms and an alternative “techno-Gandhism”, in which AI is used for social justice and to benefit marginalised people. After global AI summits in the UK, Korea and France, the Delhi meeting is the first to be held in the global south.\n\nIndian commentators say the test of AI’s value is not in its technical sophistication but whether it can improve the lives of people living in some of the toughest circumstances in the global south. By contrast, US AI companies are racing for supremacy, competing with each other and China, and rolling out AI for shopping, personal companionship and agentic systems that could slash corporate labour costs by making white-collar jobs redundant.\n\nIf a referee between the two sides is needed, António Guterres, the secretary general of the United Nations, will speak in Delhi. This week he said it would be “totally unacceptable that AI would be just a privilege of the most developed countries or a division only between two superpowers”.\n\nIndia’s AI Impact Summit is the fourth iteration of the event, which Sunak launched in 2023 at Bletchley Park in the UK, with a focus on international coordination to prevent catastrophic risks from the most advanced AI models. Summits followed in Seoul in 2024 and Paris in 2025, where the US vice-president, JD Vance, appeared to abandon the White House’s interest in safety saying: “The AI future will not be won by hand-wringing about safety; it will be won by building.”\n\nSafety is once again on the agenda, with Yoshua Bengio, one of the “godfathers” of AI, on hand to repeat his fears about the risk of powerful AI systems enabling cyber- and bioweapons attacks.\n\n“The capabilities of AI have continued to advance, and although mitigation and risk management of AI has also progressed [it has happened] not as quickly,” he said on Tuesday. “So it becomes urgent that leaders of this world understand where we could be going and it needs their attention and intervention as soon as possible.”\n\nOne of those working at the summit to make sure AI remains safe will be Nicolas Miaihle, co-founder of the AI Safety Connect group, who noted that the summit was taking place in the shadow of AI-enabled warfare in Ukraine and the Middle East.\n\n“The existential risks are not going anywhere,” he told the Guardian. “When Rishi Sunak started this, the race was not raging as hard. The trillions are pouring in but we are very far away from securing these models. This is profound for democracy, profound for the mental health of our kids and profound for warfare.”\n\nBut the Trump administration continues its policy of refusing to bind US AI companies with red tape. The White House is not expected to send a high-level representative to Delhi, with Sriram Krishnan, its senior AI policy adviser, the highest-ranked speaker listed in the programme.\n\n“Given where we are with the US administration it’s pretty unlikely you’re going to have a massive breakthrough on any consensus on what a regulatory framework will look like,” said one senior AI company source.\n\nCompanies such as Google are focused on the use of AI in education in India, where large language models’ ability to function in many of the country’s dozens of languages is an advantage.\n\n“[There’s] a big focus on access and adoption, how can you make sure that the technology is available as broadly as possible,” said Owen Larter, head of frontier AI policy and public affairs at Google DeepMind. “We’re excited on the education front in India. It’s a remarkable story of an incredibly intense adoption. About 90% of teachers and students already using AI in their learning. We’ve had a big promotional programme where 2 million students have access to our pro subscription for free.”\n\nGoogle’s investments in India include a $15bn spend, in partnership with the conglomerate of Gautam Adani, one of India’s richest billionaires, on an gigawatt-scale AI datacentre hub in the coastal city of Visakhapatnam, in Andhra Pradesh, with subsea cables connecting to other parts of the world.",
    "readingTime": 5,
    "keywords": [
      "rishi sunak",
      "impact summit",
      "prime minister",
      "us ai",
      "south",
      "leaders",
      "tech",
      "adoption",
      "technology",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/18/delhi-ai-expo-modi-jostles-lead-south",
    "thumbnail_url": "https://i.guim.co.uk/img/media/2f39cb8fe7a67fe7889f1cf3378f570bb029daac/484_55_1456_1165/master/1456.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=07f3b4f9ce5cd1a2ee707d65312ff256",
    "created_at": "2026-02-18T12:37:07.112Z",
    "topic": "tech"
  },
  {
    "slug": "stardex-yc-s21-is-hiring",
    "title": "Stardex (YC S21) Is Hiring",
    "description": "Stardex is an AI-native ATS and CRM built specifically for executive search firms. We're backed by Y Combinator and are changing how recruiting firms leverage their data and institutional knowledge. Our customers are boutique and mid-market executive search firms who are moving off legacy platforms — and they need someone to make that transition seamless.\n🔍 Who are you?\nYou're comfortable writing TypeScript/SQL scripts to transform, clean, and migrate messy data from one system to another\nYou're extremely detail-oriented.",
    "fullText": "Stardex is an AI-native ATS and CRM built specifically for executive search firms. We're backed by Y Combinator and are changing how recruiting firms leverage their data and institutional knowledge. Our customers are boutique and mid-market executive search firms who are moving off legacy platforms — and they need someone to make that transition seamless.\n🔍 Who are you?\n\nYou're comfortable writing TypeScript/SQL scripts to transform, clean, and migrate messy data from one system to another\nYou're extremely detail-oriented. Data migration has zero margin for error and you take pride in getting things right.\nYou instinctively reach for AI tools (Claude Code, Cursor, etc.) to automate repetitive work rather than doing it manually. You're always looking for ways to use AI to make processes faster and more efficient.\nYou have some understanding of database optimization — you know why a poorly structured query or schema matters\nYou can communicate clearly with both technical and non-technical people when needed\nYou have a \"whatever it takes\" attitude. If something needs to go live by Friday, you figure it out.\nYou write clean, maintainable code and document your work so processes get better over time\n\n✨ Bonus points if you...\n\nHave worked with CRMs or ATS platforms before (or any system with messy, relational data)\nHave experience with APIs, data pipelines, or ETL processes\nHave hands-on experience with database performance tuning, indexing, or query optimization\nHave done any kind of customer-facing technical work — support, consulting, freelance projects, anything\nHave worked at an early-stage startup\n\n🎉 Why work with us?\n\nYou'll be the first person in this role, which means you get to define how Stardex onboards customers from the ground up\nYou'll work directly with our founders (Sanket & Pranav) and have real ownership from day one\nYou'll learn a ton about AI, SaaS, and the recruiting industry\nWe’ll provide whatever you need to be productive\n\nInterested? Apply here or email Sanket directly at founders(at)stardex.ai with a short note on why this role excites you. We are open to recent grads as well for this role.",
    "readingTime": 2,
    "keywords": [
      "executive search",
      "search firms",
      "you're",
      "processes",
      "you'll",
      "role",
      "stardex",
      "recruiting",
      "customers",
      "platforms"
    ],
    "qualityScore": 0.9,
    "link": "https://www.ycombinator.com/companies/stardex/jobs/lag1C1P-customer-success-engineer-ai-data-migration",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/63014581184fd4565d63c82b595d2106f967b16a.png?1743869873",
    "created_at": "2026-02-18T12:37:06.819Z",
    "topic": "jobs"
  },
  {
    "slug": "zep-ai-building-the-context-graph-yc-w24-is-hiring-engineers",
    "title": "Zep AI (Building the Context Graph, YC W24) Is Hiring Engineers",
    "description": "Jobs at Zep AI",
    "fullText": "Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.ycombinator.com/companies/zep-ai/jobs",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/a5f4989742560bd0715218257a7c7ea7f73ab700.png?1712364271",
    "created_at": "2026-02-18T12:37:06.818Z",
    "topic": "jobs"
  },
  {
    "slug": "perion-shares-rise-nearly-6-as-aidriven-ad-platform-boosts-q4-profits",
    "title": "Perion shares rise nearly 6% as AI-driven ad platform boosts Q4 profits",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/earnings/perion-shares-rise-nearly-6-as-aidriven-ad-platform-boosts-q4-profits-93CH-4510655",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPED0C0KP_M.jpg",
    "created_at": "2026-02-18T12:37:05.395Z",
    "topic": "finance"
  },
  {
    "slug": "openclaw-opensource-personal-ai-agent-that-lives-on-your-machine",
    "title": "OpenClaw – Open-source personal AI agent that lives on your machine",
    "description": "Your own personal AI assistant. Any OS. Any Platform. The lobster way. 🦞  - GitHub - openclaw/openclaw: Your own personal AI assistant.",
    "fullText": "openclaw\n\n /\n\n openclaw\n\n Public\n\n Your own personal AI assistant. Any OS. Any Platform. The lobster way. 🦞 \n\n openclaw.ai\n\n License\n\n MIT license\n\n 206k\n stars\n\n 37.7k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n openclaw/openclaw",
    "readingTime": 1,
    "keywords": [
      "openclaw",
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/openclaw/openclaw",
    "thumbnail_url": "https://opengraph.githubassets.com/b2bb47983cd71c4a0446c45073347e53ea8782bc31c85c49442e517263d5b68b/openclaw/openclaw",
    "created_at": "2026-02-18T06:49:55.169Z",
    "topic": "tech"
  },
  {
    "slug": "tokenmeter-opensource-observability-layer-for-llm-token-costs",
    "title": "TokenMeter – Open-source observability layer for LLM token costs",
    "description": "Open-source AI Cost Intelligence Platform — smart routing, semantic cache, waste detection, prompt optimization - ATMAECHO/TOKEN-METER",
    "fullText": "ATMAECHO\n\n /\n\n TOKEN-METER\n\n Public\n\n Open-source AI Cost Intelligence Platform — smart routing, semantic cache, waste detection, prompt optimization\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n ATMAECHO/TOKEN-METER",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/ATMAECHO/TOKEN-METER",
    "thumbnail_url": "https://opengraph.githubassets.com/eea39f4bd57d3211a06801e4ec71e4dd4ccd4c7a0d57e4621e6667d535594d22/ATMAECHO/TOKEN-METER",
    "created_at": "2026-02-18T06:49:54.633Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push",
    "title": "Microsoft says it is on pace to invest $50 billion in ’Global South’ AI push",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push-4510044",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1H06I_L.jpg",
    "created_at": "2026-02-18T06:49:48.045Z",
    "topic": "finance"
  },
  {
    "slug": "perplexity-says-its-moving-away-from-ads-and-betting-on-subscriptions",
    "title": "Perplexity says it's moving away from ads and betting on subscriptions",
    "description": "Perplexity, a San Francisco-based AI startup, emphasizes subscriptions and business sales, diverging from OpenAI's ad-centric approach.",
    "fullText": "Perplexity is going full steam ahead with subscriptions and business sales and plans to focus more on monetization than it has in the past, executives said at a roundtable with reporters on Monday.\n\nThe AI search startup, based in San Francisco, is the latest to publicly distance itself from putting ads in chatbot answers, with one executive saying it isn't exploring any ad deals at the moment. That's a contrast to OpenAI, which is going all in on ads, while arch-rival Anthropic has publicly touted the opposite.\n\nOne Perplexity executive said the startup is increasingly targeting large businesses. The company has only five people on its enterprise sales team and plans to ramp that up, the executive added. It also wants to serve high-powered users such as finance professionals, doctors, and CEOs.\n\nThe focus on selling to businesses positions Perplexity more directly as a competitor to startups like Glean, which lets employees search internal files and data more efficiently with AI.\n\nThe move comes amid some VC skepticism about Perplexity's prospects, with Silicon Valley investors voting it the company they'd most like to bet against in an informal poll at an AI conference last year, amid back-to-back funding rounds and talks of a wider AI bubble.\n\nPerplexity will focus more on revenue and revenue retention than on other metrics, such as the number of questions it answers, the executive said. Perplexity also pledged to keep allowing people to use the product for free, with rate limits.\n\nAt the roundtable, the company declined to share specific financials and shared that revenue grew 4.7 times last year. Perplexity generated over $150 million in annual recurring revenue by mid-last year, its head of communications Jesse Dwyer told Business Insider in August. It hit $200 million in ARR in October, Alex Heath of Sources reported.\n\nThe news comes after several months of the AI startup lying low, as Perplexity said in a press invite. The company's leaders said it was busy building and not focusing on AI-related drama.\n\nPerplexity had announced in 2024 that it would start experimenting with ads. That effort stalled, with the top ads leader, Taz Patel, quietly leaving last year. One consistent issue with ads in AI-generated answers is that users won't believe them, the Perplexity executive said.\n\nPerplexity also launched a product for enterprises in 2024 that uses internal and external data to generate research reports, among other features.",
    "readingTime": 2,
    "keywords": [
      "perplexity executive",
      "revenue",
      "focus",
      "startup",
      "sales",
      "plans",
      "roundtable",
      "search",
      "publicly",
      "businesses"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/perplexity-shifts-to-subscriptions-business-growth-2026-2",
    "thumbnail_url": "https://i.insider.com/6995107fa645d11881897c7b?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.037Z",
    "topic": "finance"
  },
  {
    "slug": "im-an-amazon-tech-lead-who-uses-ai-to-write-code-daily-theres-one-situation-i-hesitate-to-use-it-in",
    "title": "I'm an Amazon tech lead who uses AI to write code daily. There's one situation I hesitate to use it in.",
    "description": "Anni Chen says vibe coding is hard to resist. It speeds up her productivity, but she doesn't trust it blindly.",
    "fullText": "This as-told-to essay is based on a conversation with Anni Chen, who has worked at Amazon for about three-and-a-half years. It has been edited for length and clarity. Business Insider has verified her employment history.\n\nI'm a tech lead at Amazon responsible for deploying large-scale generative AI and LLM-driven systems. I focus on what we call memory, which powers personalization in generative AI experiences across Amazon.\n\nI vibe code every day. It's definitely a productivity boost.\n\nFor debugging or small tasks, I sometimes treat it like a lottery. Maybe it will produce something amazing. Sometimes, it does.\n\nVibe coding helps me brainstorm what the solution could look like, even if I don't adopt the final solution it proposes. Vibe coding also speeds up the time spent rewriting code when you realize a requirement wasn't covered.\n\nWhen I vibe code, it's always iterative. I give it the basic information it needs, it produces a version, then I check it — similar to a code review with coworkers. I might say, \"You missed this part\" or \"You missed that part.\"\n\nThe AI sometimes fixes issues but introduces something new. You have to keep an eye on it.\n\nFor complex tasks, you need more double-checking. But even with the extra checking, it's still faster.\n\nI was working with a partner team and ran into complex locking issues. Without an LLM, I might have taken a day to research possible solutions, especially since it was relatively new to me.\n\nWithin 15 minutes, I brainstormed with the LLM about possible solutions. I pointed out weaknesses in its suggestions and asked it to improve them. In 15 minutes, I had a proposal to send to the team.\n\nTechnical knowledge helps — you know what's a good solution and what's not. You know what tastes good, but you don't know what dishes are available. The LLM brings up all the dishes, and you choose.\n\nStill, I'm hesitant to use vibe coding directly in production.\n\nLLMs are very good at solving problems, but sometimes they make implicit assumptions you don't realize they're making. If you don't tell it explicitly, for example, that something needs to work for multi-threading, it might just produce the minimum version that works, but when it's large-scale or productionized, it could crash.\n\nNon-technical builders could tell an LLM to build something that handles millions of users. But if you have zero technical knowledge, it's hard to anticipate constraints upfront. If you don't tell the model the implicit assumptions, it won't respect those constraints. Later, you'll run into problems.\n\nNon-technical people might use the LLM to fix issues reactively. But technical people can anticipate constraints proactively and prevent problems in the first place.\n\nTechnical people also understand vibe-coded content better, and they're in a better position to understand what LLMs are good at and not good at. For example, knowing how they're trained and why they're weaker at certain tasks like math. That understanding helps you master them as tools.\n\nWhen you scale to one million or 100 million customers, systems need to be coded differently to handle that scale.\n\nInitially, leadership pushed vibe coding. Our team is a GenAI team, so we were naturally more receptive. In non-GenAI teams, engineers initially reacted like, \"No, I won't let AI do my job. I don't trust AI-generated code.\"\n\nAfter people tried it, attitudes shifted. People realized it's pretty good sometimes. Now it's more widely adopted.\n\nIt's very hard to resist vibe coding nowadays. If you're an employee, leadership sees the productivity boost and will encourage you to use it.\n\nWhen your peers are using it and coding faster, it's hard to resist. If you can't keep up with the speed, it becomes difficult to collaborate.\n\nEven if you resist, you still consume AI passively. AI comments are embedded in code reviews. So even if you don't vibe code directly, you're still interacting with AI outputs.\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "productivity boost",
      "implicit assumptions",
      "anticipate constraints",
      "technical knowledge",
      "vibe coding",
      "vibe code",
      "it's",
      "don't",
      "team",
      "they're"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-tech-lead-vibe-coding-daily-resist-anni-chen-2026-2",
    "thumbnail_url": "https://i.insider.com/698d593ce1ba468a96abe95e?width=1184&format=jpeg",
    "created_at": "2026-02-18T06:49:48.035Z",
    "topic": "finance"
  },
  {
    "slug": "openclaw-creator-slams-europes-regulations-as-he-moves-to-the-us",
    "title": "OpenClaw creator slams Europe's regulations as he moves to the US",
    "description": "Peter Steinberger, creator of OpenClaw, is moving to OpenAI in the US, citing Europe's strict regulations as a hurdle for tech growth.",
    "fullText": "In Europe, there's been a lot of handwringing over why there are very few large, successful tech companies in the region. Peter Steinberger, the creator of the agentic AI hit OpenClaw, has an answer.\n\nSteinberger was recently hired by OpenAI and is moving from Europe to the US. An Austrian by birth, he previously split his time between London and Vienna.\n\nOn X, a professor from a European university asked why Europe couldn't retain this tech talent.\n\nSteinberger replied that most people in the US are enthusiastic, while in Europe, he's scolded about responsibility and regulations.\n\nIf he built a company in Europe, he would struggle with strict labor regulations and similar rules, he added.\n\nAt OpenAI, he said most employees work 6 to 7 days a week and are paid accordingly. In Europe, that would be illegal, he added.\n\nThe most valuable company in Europe is Dutch chip-equipment maker ASML, valued at about $550 billion. In contrast, there are 10 US companies worth more than $1 trillion. Most of these are tech companies.\n\nIn 2024, a landmark EU report found that the region had fallen behind the US, particularly in innovation. It proposed a series of changes to tackle the problem, but by the end of 2025, few of the recommendations had been implemented.\n\nSteinberger said he was hopeful about EU INC, an effort to create a single corporate legal framework to make it simpler to run a business across the region.\n\nBut this seems to be \"fizzling out,\" he wrote on X. \"Watered down, too much egoistic national interest that ultimately hurts everyone.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "in europe",
      "tech",
      "region",
      "regulations",
      "steinberger",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openclaw-creator-slams-europe-regulations-move-us-openai-2026-2",
    "thumbnail_url": "https://i.insider.com/699511bee1ba468a96ac341a?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.030Z",
    "topic": "finance"
  },
  {
    "slug": "why-an-ai-video-of-tom-cruise-battling-brad-pitt-spooked-hollywood",
    "title": "Why an A.I. Video of Tom Cruise Battling Brad Pitt Spooked Hollywood",
    "description": "A 15-second clip created by an artificial intelligence tool owned by the Chinese technology company ByteDance appears more cinematic than anything so far.",
    "fullText": "It took only a 15-second clip of Tom Cruise and Brad Pitt duking it out on a crumbling rooftop at twilight to draw swift outrage, and sizable fear, from Hollywood over the last few days.\n\nThe widely circulated video was created by the Irish director Ruairi Robinson using Seedance 2.0, a powerful artificial intelligence video generation tool owned by the Chinese technology company ByteDance. It had plenty of the bells and whistles of a big-budget Hollywood film: sweeping camera angles, stunt choreography, crisp sound effects and haunting music.\n\nWith a two-sentence prompt and the click of a button, Seedance had produced a stunningly realistic result that was a drastic improvement over previously generated artificial intelligence videos, often shoddy clips known as A.I. slop. This video was so convincing that it drew near immediate condemnation from some of Hollywood’s top organizations and companies.\n\nRhett Reese, a scriptwriter known for his “Deadpool” films, said in an interview that the Cruise-Pitt video had sent a “cold shiver” up his spine.\n\n“For all of us who work in the industry and devoted our careers and lives to it, I just think it’s nothing short of terrifying,” he said. “I could just see it costing jobs all over the place.”\n\nByteDance released Seedance 2.0 last week, nearly two months after a previous version had failed to prompt much anger. A news release from the company praised the updated tool’s “physical accuracy, realism and controllability,” which it said was suitable for the needs of “professional-grade creative scenarios.”\n\n“The creation process,” the release went on, “is more natural and efficient, allowing users to control their creations like a true ‘director.’”\n\nUsers promptly flocked to the platform to spin up their own content. An alternate ending to “Game of Thrones” went viral, as did a video of the notoriously beefing rappers Kendrick Lamar and Drake burying the hatchet on “The Tonight Show,” and one of Samara Morgan, the vengeful girl in “The Ring” horror films, emerging from an old television set to pet a cat.\n\nRobinson himself posted additional videos, including of Pitt and Cruise battling a robot, and of Pitt sparring with a sword-wielding “zombie ninja.”\n\nAt the same time, Hollywood was swift to sit up straight. Charles Rivkin, the chairman and chief executive of the Motion Picture Association, called on ByteDance to “immediately cease its infringing activity,” saying in a statement that Seedance 2.0 had engaged in the unauthorized use of copyrighted works on a “massive scale.” Human Artistry Campaign, a global coalition that advocates using A.I. “with respect for the irreplaceable artists, performers and creatives,” said on social media that unauthorized works generated by Seedance 2.0 violated the “most basic aspects of personal autonomy.”\n\nDisney, which in a watershed $1 billion deal last year agreed to allow OpenAI’s Sora users to generate video content with its characters, sent a cease-and-desist letter to ByteDance, accusing it of supplying Seedance with a “pirated library” of Disney’s characters — “as if Disney’s coveted intellectual property were free public-domain clip art.”\n\nByteDance, which also owns TikTok and has been valued at $480 billion in the private markets, said in a statement that it respected intellectual property rights and was aware of the concerns about Seedance.\n\n“We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,” the statement said.\n\nAs last year’s deal between Disney and OpenAI suggests, Hollywood has for years wrestled with how to manage the rapid growth of generative artificial intelligence. The concerns outlined by Reese echoed the Writers Guild strike in 2023, when for months thousands of union members demanded that studios institute guardrails protecting them from having their jobs or their intellectual property stolen by A.I. In the end, the group won guarantees that A.I. would not encroach on writers’ credits and compensation.\n\nDuncan Crabtree-Ireland, the national executive director and chief negotiator of SAG-AFTRA, which represents actors and media artists, said its contracts had specific and enforceable rules about digital replication. The kind of material represented by the Cruise-Pitt battle, he said, “could not be produced by any of the signatories to our contracts — the studios, the streamers — without the specific, informed consent of those individuals.”\n\nAccording to Crabtree-Ireland, the real concern is that, even if videos generated by Seedance and other A.I. platforms “are not malicious in intent,” they could “really violate someone’s right to control how their image, their likeness and their voice is used.”\n\nNot everyone is awed by Seedance’s latest technology. Heather Anne Campbell, an executive producer and a writer on the animated series “Rick and Morty,” said her social media accounts last week had been inundated with Seedance-generated clips of anime, sci-fi and unlikely superhero battles. But she is not yet worried, she said, about losing her job to the technology.\n\n“Everybody is, I think, swept up by the circus that came to town and is showing off,” she said. “I haven’t seen anything good yet. Nothing that has taken my breath away, nothing that is poignant, nothing that is provocative even. It’s all just garbage.”\n\nCampbell added that A.I. services like Seedance were at best “averaging machines,” and argued that the greatest art was never made quickly or impersonally.\n\nStill, some people working in Hollywood find it difficult to imagine that studios will not come to see A.I. as a cost-saving shortcut. “It would be cheaper to have A.I. write a screenplay than it would be for me to write a screenplay,” Reese, the “Deadpool” writer, said. “I just know that in the back of my mind, that’s where the terror comes from.”\n\nFor Reese, a long-term answer to the unease that A.I. will reorder Hollywood could not come quickly enough.\n\n“If I could wave my magic wand and make A.I. go away, at least in the creative field,” he said, “I would absolutely wave the wand.”",
    "readingTime": 5,
    "keywords": [
      "artificial intelligence",
      "social media",
      "intellectual property",
      "hollywood",
      "users",
      "director",
      "technology",
      "generated",
      "videos",
      "executive"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/02/16/movies/tom-cruise-brad-pitt-artificial-intelligence-seedance.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/02/15/arts/15cul-seedance/15cul-seedance-facebookJumbo.jpg",
    "created_at": "2026-02-18T01:13:50.594Z",
    "topic": "tech"
  },
  {
    "slug": "opensource-game-engine-godot-is-drowning-in-ai-slop-code-contributions",
    "title": "Open-source game engine Godot is drowning in 'AI slop' code contributions",
    "description": "Projects like Godot are being swamped by contributors who may not even understand the code they're submitting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.pcgamer.com/software/platforms/open-source-game-engine-godot-is-drowning-in-ai-slop-code-contributions-i-dont-know-how-long-we-can-keep-it-up/",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/JVBMNVgT9xT6HFkTbDsqfe-1920-80.jpg",
    "created_at": "2026-02-18T01:13:50.433Z",
    "topic": "tech"
  },
  {
    "slug": "greedyphrase-121x-better-compression-than-gpt4o-tiktoken-6x-faster",
    "title": "GreedyPhrase – 1.21x better compression than GPT-4o tiktoken, 6x faster",
    "description": "GreedyPhrase Tokenizer: Maximizing Effective Context via Greedy Phrase Compression - rayonnant-ai/greedyphrase",
    "fullText": "rayonnant-ai\n\n /\n\n greedyphrase\n\n Public\n\n GreedyPhrase Tokenizer: Maximizing Effective Context via Greedy Phrase Compression\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n rayonnant-ai/greedyphrase",
    "readingTime": 1,
    "keywords": [
      "greedyphrase",
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/rayonnant-ai/greedyphrase",
    "thumbnail_url": "https://opengraph.githubassets.com/f04c0e5ce1a7d98d91fdd3a7922d8f8c19141a7738e7dfa105d6dd4dd30a6f6f/rayonnant-ai/greedyphrase",
    "created_at": "2026-02-18T01:13:49.406Z",
    "topic": "tech"
  },
  {
    "slug": "practical-guide-to-building-reliable-ai-agents",
    "title": "Practical Guide to Building Reliable AI Agents",
    "description": "Design AI agents that are focused, safe, and reliable. Learn the principles, patterns, and techniques for building high-quality agent systems.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://docs.inkeep.com/guides/agent-engineering",
    "thumbnail_url": "https://docs.inkeep.com/api/docs-og/guides/agent-engineering/image.png",
    "created_at": "2026-02-18T01:13:49.347Z",
    "topic": "tech"
  },
  {
    "slug": "phison-ceo-consumer-electronics-firms-may-fail-by-2026-over-ai-memory-crisis",
    "title": "Phison CEO: Consumer electronics firms may fail by 2026 over AI memory crisis",
    "description": "This could go on for another 10 years.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.pcgamer.com/hardware/memory/many-consumer-electronics-manufacturers-will-go-bankrupt-or-exit-product-lines-by-the-end-of-2026-due-to-the-ai-memory-crisis-phison-ceo-reportedly-says/",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/54axypSSE53LrSGmYpfUDD-1920-80.jpg",
    "created_at": "2026-02-18T01:13:49.284Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-to-sell-meta-millions-of-chips-in-multiyear-deal",
    "title": "Nvidia to sell Meta millions of chips in multiyear deal",
    "description": "Nvidia on Tuesday said it has signed a multiyear deal to sell Meta Platforms millions of its current ‌and future artificial intelligence chips, including central processing units that compete ‌with products from Intel and Advanced Micro Devices.  Nvidia did not disclose a value for the deal, ​but said it includes its current Blackwell chips as well as its forthcoming Rubin AI chips.  It also includes standalone installations of its Grace and Vera central processors.",
    "fullText": "SAN FRANCISCO, Feb 17 (Reuters) - Nvidia on Tuesday said it has signed a multiyear deal to sell Meta Platforms millions of its current ‌and future artificial intelligence chips, including central processing units that compete ‌with products from Intel and Advanced Micro Devices.\n\nNvidia did not disclose a value for the deal, ​but said it includes its current Blackwell chips as well as its forthcoming Rubin AI chips. It also includes standalone installations of its Grace and Vera central processors.\n\nNvidia introduced those central processors, based on technology from Arm Holdings, as companions to its ‌AI chips starting 2023. ⁠But the announcement Tuesday signaled that Nvidia aims to push those chips for emerging fields such as running AI agents as ⁠well as into markets for processors used in workaday technical tasks such as running databases.\n\nNvidia's announcement also comes as Meta is developing its own AI chips and is in ​discussions with ​Google about using that company's Tensor Processing ​Unit chips, or TPUs, for ‌AI work.\n\nIan Buck, the general manager of Nvidia's hyperscale and high-performance computing unit, said that Nvidia's Grace central processors have shown they can use half the power for some common tasks such as running databases, with more gains expected for the next generation, Vera.\n\n\"It actually continues down that path and makes it an ‌excellent data center-only CPU for those high-intensity data ​processing back-end operations,\" Buck said. \"Meta has already had ​a chance to get on ​Vera and run some of those workloads. And the results ‌look very promising.\"\n\nWhile Nvidia has never disclosed ​its sales to ​Meta, it is widely believed to be among four customers that made up 61% of its revenue in its most recent fiscal quarter. Moorhead ​said Nvidia likely highlighted the ‌deal to show that it has retained a large business with ​Meta and is gaining traction with its central processor chips.",
    "readingTime": 2,
    "keywords": [
      "central processors",
      "chips",
      "deal",
      "announcement",
      "tasks",
      "databases",
      "nvidia",
      "meta",
      "processing",
      "vera"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-sell-meta-millions-chips-211720887.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/4ed50a54f6c60713ec79d92bee16049d",
    "created_at": "2026-02-18T01:13:47.592Z",
    "topic": "finance"
  },
  {
    "slug": "axios-reports-defense-secretary-hegseth-is-close-to-cutting-business-ties-with-ai-company-anthropic",
    "title": "Axios reports Defense Secretary Hegseth is ‘close’ to cutting business ties with AI company Anthropic",
    "description": "A senior Pentagon official told Axios that Secy. Hegseth was “close” to cutting business ties with Anthropic due to CEO Dario Amodei’s concerns about some military uses of AI. “It’s the cost of doing ...",
    "fullText": "A senior Pentagon official told Axios that Secy. Hegseth was “close” to cutting business ties with Anthropic due to CEO Dario Amodei’s concerns about some military uses of AI. “It’s the cost of doing business with this particular government,” says tech journalist Kara Swisher.\n\nAfter being traded twice and waived, the longtime NBA veteran is returning to the Timberwolves.\n\nCyber stocks are getting crushed by the \"AI scare trade.\" That may create a buying opportunity, according to Wedbush analyst Dan Ives.\n\nThe WNBA and the players union are still working to reach a deal on a new CBA before the season starts.\n\nAfter a 23-0 start to the season, things have gone downhill fast for Arizona.\n\nTuesday was a marquee day at the Milan Cortina Olympics as the women's figure skating competition got underway.\n\nNvidia and Meta are expanding their chip deal to include millions of more AI processors.\n\nThe reigning U.S. champion, Glenn arrived in Milan with hopes of winning an individual gold medal. Just two fateful seconds on the ice in the women's short program likely destroyed that dream this year, and she knew it the moment it happened.\n\nFederal Reserve governor Michael Barr said Tuesday that the boom in artificial intelligence \"is unlikely to be a reason for lowering policy rates,\" disputing the idea of AI as a productivity accelerator that puts the Fed on a rate-cutting path.\n\nThe Rockies, Padres, Giants, Astros and Phillies make up the bottom tier of our 2026 rankings.\n\nThe S&P 500 was on track for double-digit earnings growth, with more than half of companies having reported Q4 results so far.",
    "readingTime": 2,
    "keywords": [
      "business",
      "deal",
      "season",
      "women's",
      "milan"
    ],
    "qualityScore": 0.85,
    "link": "https://www.yahoo.com/news/videos/axios-reports-defense-secretary-hegseth-033745058.html",
    "thumbnail_url": "https://s.yimg.com/os/en/cnn_videos_177/1b16bd67aa16f2e14e8f74dec3bf61b9",
    "created_at": "2026-02-18T01:13:46.771Z",
    "topic": "news"
  },
  {
    "slug": "investor-dan-ives-says-the-tech-selloff-that-has-been-spooking-markets-is-actually-a-generational-opportunity-to-get-in",
    "title": "Investor Dan Ives says the tech selloff that has been spooking markets is actually a ‘generational opportunity’ to get in on the action",
    "description": "Investors are drawing their battle lines as AI sorts tech companies into winners and losers.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/17/investor-dan-ives-markets-tech-selloff-opportunity-investors-rebound/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2260936428-e1771346957865.jpg?resize=1200,600",
    "created_at": "2026-02-18T01:13:43.913Z",
    "topic": "finance"
  },
  {
    "slug": "the-irish-have-taken-a-liking-to-ai-japan-not-so-much",
    "title": "The Irish have taken a liking to AI. Japan, not so much.",
    "description": "AI usage among workers shows Ireland leading with high adoption, while Japan lags. Personal use outpaces professional in most regions.",
    "fullText": "Indeed survey data paints a stark picture of uneven AI engagement across advanced economies.\n\nThe chart below shows a clear frontrunner: Ireland stands out, with roughly seven in ten workers using AI at least monthly for work, followed by Australia, Germany, and North America.\n\nAt the other end sits Japan, where fewer than one in five workers report professional AI use — less than half the level seen in the US or UK.\n\nOne striking pattern cuts across all countries: personal AI use consistently outpaces professional use.\n\nEven in high-adoption markets, workers are experimenting with AI on their own faster than employers are embedding it into workflows. That gap is narrowest in Ireland, suggesting workplace norms and encouragement matter.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 1,
    "keywords": [
      "workers",
      "across",
      "ireland",
      "professional"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/irish-ai-new-survey-data-shows-2026-2",
    "thumbnail_url": "https://i.insider.com/6994bb54a645d11881897580?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.435Z",
    "topic": "finance"
  },
  {
    "slug": "the-memory-shortage-is-driving-up-the-cost-of-your-next-laptop",
    "title": "The memory shortage is driving up the cost of your next laptop",
    "description": "Memory chip costs are up as AI companies gobble up the hot commodity. Consumer electronics companies like Dell and HP are raising prices.",
    "fullText": "Did that computer you were eyeing jump in price? Is that gaming handheld out of stock? You might want to practice a new refrain: Thanks, memory shortage.\n\nAs AI companies demand increasingly large troves of chips to power their large language models, memory chips remain in short supply. That's bad news for much of the consumer electronics market, which relies on DRAM and NAND memory chips.\n\nThe research firm IDC expects \"significant pressure on the memory ecosystem,\" warning that supply growth would be below historical norms this year. Electronics companies from Valve to Framework have already changed their sales procedures because of the shortage. Even Apple, the industry goliath, said it was expecting supply chain pressures on memory that would weigh on its famously high gross margin.\n\nThe memory shortage has existed for months — but it's beginning to affect more shoppers' wallets. And the bad news is it's not expected to let up anytime soon.\n\nElectronics CEOs are sounding the alarm for \"RAMageddon.\"\n\nJust last week, Lenovo CEO Yang Yuanqing told Reuters that he expected PC unit sales to \"face pressure.\" Intel CEO Lip-Bu Tan predicted that there would be \"no relief until 2028.\"\n\nDell has already begun adjusting its device prices, according to an internal list of price changes sent to staff in December seen by Business Insider. The company raised the prices of its Dell Pro and Pro Max notebooks and desktops with 32GB of memory by between $130 and $230, among other increases.\n\nHP also planned price hikes \"across the board\" thanks to the memory shortage, its CEO said on its November earnings call.\n\nSmaller PC makers — which may not enjoy the same amount of supply-chain leverage as their tech titan peers — have also been hit especially hard.\n\nFramework raised its prices in December, then again in January, and again in February. Corsair accidentally underpriced its DRAM kits, canceling preorders and sending out coupons. It then raised prices days later, citing \"market costs.\"\n\nThe gaming device market is also struggling. Valve updated the site for its popular Steam Deck handheld device to say that it may be \"out-of-stock intermittently in some regions due to memory and storage shortages.\" The company also said it must \"revisit\" the pricing and scheduling of its upcoming Xbox and Playstation competitor, the Steam Machine, and VR headset, the Steam Frame, because of the shortage.\n\nBigger players could be next on the horizon: Bloomberg reported over the weekend that Sony was considering pushing back the launch of the next PlayStation, and that Nintendo was considering a price hike for the Switch 2.\n\nSome companies could choose to absorb any associated cost increases at the expense of their margins, opting to wait out the supply crunch.\n\nMeanwhile, bigger and bigger names keep speaking out about the shortage and its impacts.\n\nElon Musk warned of a \"chip wall\" on Tesla's fourth-quarter earnings call. Tim Cook pointed to the shortage on Apple's fourth-quarter earnings call, saying that the company was watching memory prices increase \"significantly.\"\n\nThis is where things get a bit more technical, but it all boils down to basic supply and demand.\n\nThere are three types of chips that are important to know. DRAM (dynamic random access memory) and NAND (non-volatile flash memory) are crucial for building consumer devices. HBM (high-bandwidth memory) chips are used to help train large language models.\n\nThree companies dominate the memory chip market: Samsung, SK Hynix, and Micron. These companies also produce HBM chips.\n\nAI companies are hungry for more and more chips, and are willing to break out the checkbook to be first in line for factory production — giving them an edge over many consumer tech companies. They're also flush with cash, with companies like Microsoft and Meta projecting multi-billion-dollar capital expenditures, much of which is going toward AI-related costs like chip acquisition.\n\nThat leaves chipmakers responding to the spike in demand by raising prices, selling supply to AI companies, and some transitioning to HBM production.\n\nThe shortage isn't fading anytime soon. SK Hynix has long secured demand for its entire 2026 DRAM and NAND production volume. The CEO of Micron predicted on its first-quarter earnings call that supply would remain substantially short for the \"foreseeable future.\"\n\nAnd if you're trying to build your own PC, a mere consumer navigating the increasingly volatile memory marketplace: Good luck.",
    "readingTime": 4,
    "keywords": [
      "language models",
      "anytime soon",
      "fourth-quarter earnings",
      "memory chips",
      "memory shortage",
      "dram and nand",
      "supply",
      "demand",
      "consumer",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/memory-shortage-chips-cost-laptop-pc-prices-increase-2026-2",
    "thumbnail_url": "https://i.insider.com/6994b3d5a645d11881897502?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.303Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-and-openai-posture-over-pizza-as-the-ai-talent-war-heats-up",
    "title": "Elon Musk and OpenAI posture over pizza as the AI talent war heats up",
    "description": "Elon Musk and an OpenAI engineer engaged in a game of pizza one-upmanship over the weekend as AI companies fight for top recruits.",
    "fullText": "The rivalry between xAI and OpenAI is heating up again — this time, over wood-fired pizza.\n\nOver the weekend, Elon Musk and an OpenAI engineer jockeyed on X about wood-fired crusts, dough fermentation, and campus chefs.\n\nOn its face, it was a lighthearted back-and-forth about free pizza for lunch. Underneath, it encapsulates a trend playing out in Silicon Valley: rival AI companies are publicly pitching culture — and perks like free lunch — in the talent war for top engineers.\n\nThe exchange began when Musk reposted a video of an xAI engineer calling his job the \"opportunity of a lifetime.\"\n\nJoin @xAI https://t.co/Fo3kjhaTXA\n\nThe post quickly drew a response from xAI's competitor, OpenAI.\n\n\"Or join Codex,\" said Thibault Sottiaux, an engineering lead working on OpenAI's Codex software agent, who is also hiring. OpenAI operates \"with much of the same principles,\" he wrote — before adding an increasingly common recruitment pitch.\n\n\"Join the bright side, we have pizza,\" Sottiaux wrote.\n\nJoin the bright side, we have pizza\n\nMusk fired back: \"But how good is your wood oven pizza?\"\n\nThe pizza posturing then shifted to ingredients — and the corporate chefs preparing them.\n\n\"But how about the dough?\" he wrote back. \"Can't take shortcuts, needs 24 hours at least. And our chef is 🔥.\"\n\nOur chef is so good that God looked down at the food from heaven and said you my most delicious creation 👼\n\n\"Our chef is so good that God looked down at the food from heaven and said you my most delicious creation,\" Musk replied.\n\n\"And after having a bite, he wasn't 100% satisfied and asked our chef to improve upon the SoTA,\" Sottiaux said. \"Our chef delivered, and created a recipe now universally credited to accelerating the AGI timeline.\"\n\nThe tomato pie-based banter was sweet — but the subtext was spicier.\n\nAI labs are locked in a high-stakes dash for elite engineers, with high-end compensation packages stretching into the nine-figure territory.\n\nCompanies including Amazon, Microsoft, Meta, OpenAI, and Musk's xAI are competing for a relatively small pool of researchers capable of building the next generation of models and infrastructure.\n\nAside from money, two key perks have emerged in the AI talent wars, according to professional AI poacher Mark Zuckerberg: access to GPUs and fewer direct reports.\n\n\"People say, 'I want the fewest number of people reporting to me and the most GPUs,'\" Zuckerberg said in 2025 TITV interview.\n\nAt the same time, the broader tech industry has pulled back on many of the pre-pandemic perks amid cost-cutting. Remote work has narrowed, layoffs have gathered steam, and perks like pet care stipends and expansive wellness benefits are becoming less common for new hires.\n\nBut there's one perk that has remained: the fancy lunch spread.\n\nMight as well throw in wood-fired pizza, too.",
    "readingTime": 3,
    "keywords": [
      "god looked",
      "delicious creation",
      "wood-fired pizza",
      "chef",
      "perks",
      "lunch",
      "back",
      "engineer",
      "dough",
      "chefs"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/elon-musk-pizza-openai-spacex-x-post",
    "thumbnail_url": "https://i.insider.com/6994da87f8731049f3af4756?width=1200&format=jpeg",
    "created_at": "2026-02-18T01:13:43.101Z",
    "topic": "finance"
  },
  {
    "slug": "with-rise-of-agents-we-are-entering-the-world-of-identic-ai",
    "title": "With Rise of Agents, We Are Entering the World of Identic AI",
    "description": "A conversation with tech expert Don Tapscott about the potential for and pitfalls of identic AI.",
    "fullText": "All episodes\n\n All episodes\n\n Details\n\n Transcript\n\n February 17, 2026\n\n What if the AI you integrate into your organization isn’t just about efficiency or creating digital assistants, but completely changes how you work? Longtime digital trend watcher Don Tapscott says the next wave of artificial intelligence is all about identic AI – where personalized agents don’t just complete tasks, but understand your judgment and values and take actions on your behalf. He explains the technologies for this that already exist amid the rise of agents and bots, what it means for leaders and organizations, and the pitfalls to look out for. Tapscott is author of You to the Power of Two: Redefining Human Potential in the Age of Identic AI.\n\n Back / With Rise of Agents, We Are Entering the World of Identic AI\n\n Latest in this series\n\n All episodes",
    "readingTime": 1,
    "keywords": [
      "episodes",
      "agents",
      "digital",
      "rise",
      "identic",
      "tapscott"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/podcast/2026/02/with-rise-of-agents-we-are-entering-the-world-of-identic-ai",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-ideacast_25.png",
    "created_at": "2026-02-18T01:13:42.522Z",
    "topic": "business"
  },
  {
    "slug": "here-are-the-new-features-coming-in-ios-264",
    "title": "Here Are the New Features Coming in iOS 26.4",
    "description": "Let AI create Apple Music playlists for you.",
    "fullText": "iOS 26.3 was a decidedly small update. It introduced a new tool to transfer data to Android, and gave some iPhones the ability to hide precise location data from cellular networks. But beyond some other small changes and security patches, that's all there was to write home about. iOS 26.4 is a different story. The update, which is currently in beta testing, adds a number of interesting new features to compatible iPhones, especially if you're an Apple Music user.\n\nAs with all beta software, iOS 26.4 is currently in testing, which means these features are subject to change at any time. It's possible some won't make it to the official release of iOS 26.4, while others could look different than they do now. While you can install the iOS 26.4 beta at any time by enrolling your device in the beta program, do so at your own discretion. I'd recommend using a secondary device to test this software if you can, but either way, make sure the device in question is fully backed up to a computer before installing the beta.\n\nThe latest trend in streaming services seems to be AI-generated playlists. YouTube Music recently rolled out the option, while Spotify offers a couple different takes on the feature. The idea is to tell the AI what type of music you want to listen to, whether that be a specific artist or genre, or just a concept or mood (e.g., \"Make me a playlist for drinking coffee on a lazy Sunday morning\").\n\nNow Apple Music is the latest service to introduce such a feature. The first iOS 26.4 beta comes with \"Playlist Playground,\" which works about how you'd expect. You tell Apple Music's AI what you want to hear, and it generates a playlist with 25 different songs. You can adjust the playlist if you don't like the result, as well as edit the title, cover image, and description.\n\nIn addition to Playlist Playground, Apple Music's UI is also changing in iOS 26.4. You'll see new full-page artwork when listening to music, as well as redesigned albums and playlists that adjust their colors based on the artwork. Plus, there's now a \"Concerts Near You\" feature that helps you find shows in your area, based on the music you like to listen to.\n\nRCS support is the best thing to happen to the iPhone in a long time. It makes texting Android users about the same as texting iPhone users, which has not been the case for most of iMessage's history. But while most of the standard perks rolled in with the update, including functioning group chats and high-quality image sharing, one key feature did not: end-to-end encryption (E2EE).\n\nWithout (E2EE), your messages can be intercepted and read by those with the skills to do so. With E2EE, they cannot. It's a major security feature that's key to both iMessage and RCS, and one of the reasons you shouldn't send messages over SMS, as it doesn't support E2EE. Not all Android setups support E2EE over RCS, but it's still a bummer that the iPhone's Messages app doesn't either.\n\nThat's now changing. With the first iOS 26.4 beta, Apple is now testing E2EE for RCS. You'll find the option in Settings, though Apple notes that not all devices or carriers support it. Someday soon, however, iPhone users texting Android users over RCS will be able to enjoy the added security benefits of E2EE.\n\nWith iOS 26.4, Apple changed the Wallpapers settings menu. Before, you could select from pre-downloaded wallpaper packs on your iPhone; now, you can choose which packs you want to download instead. It's a small change, but an interesting one at that. It seems Apple doesn't want to assume you're interested in all of its wallpaper options anymore, and instead would rather pick and choose the ones you want to try. Apple also made similar changes to picking watch faces in the Apple Watch app.\n\nIf you ever label reminders as \"urgent\" on your iPhone, you'll find them in a new location. Now, when you open Reminders, you'l find an Urgent section, alongside other options like Today, All, and Scheduled.\n\nWhile this isn't an iOS feature, it is a key new change in the first macOS 26.4 beta. Apple is now testing a \"charge limit\" feature on Mac, similar to the charge limit feature that already exists on iOS; when your device is plugged in for a long period of time, it will limit how much the battery can charge to. You can set the cap as low as 80%, or as high as 100%. The idea is, by limiting the charge level, you reduce how often the battery completes a full charge cycle, which can prolong its lifespan and delay aging. The \"younger\" your battery is, the longer it'll last between charges, so enthusiasts like to use these features to maximize how much battery life they can get out of their devices.",
    "readingTime": 5,
    "keywords": [
      "texting android",
      "android users",
      "apple music's",
      "charge limit",
      "iphone users",
      "beta apple",
      "limit feature",
      "ios beta",
      "testing",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/here-are-the-new-features-coming-in-ios-264?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHPM03ZJFRAKBM337N5306KQ/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-18T01:13:41.402Z",
    "topic": "tech"
  },
  {
    "slug": "ai-strategy-is-built-on-layers-of-api-sediment",
    "title": "AI strategy is built on layers of API sediment",
    "description": "AI protocols, such as MCP and Agent Skills, are agent-first, which risks bypassing the governance, security, and access controls that enterprises have spent years building around their APIs and data.",
    "fullText": "“The API landscape is a mess, and very few people understand it,” Kin Lane, API industry veteran and founder of Naftiko, tells The New Stack.\n\nSome days it feels like we are living in an XKCD cartoon.\n\nOrganizations don’t typically migrate legacy systems from one spec to another as new ideas emerge. Instead, they accumulate layers of integration standards over time, with each era leaving behind systems that are too costly or risky to excavate. “I get a call from a 20-year veteran at a large enterprise, who says, ‘We still have EDI and WSDLs, a lot of Swagger and OpenAPI. We’re trying to do more Async API. MCP is popping up, and we’re looking at Agent Skills, but we have a global business to run, and it’s got to be stable.’”\n\nIt was seeing this recurring pattern of API sediment that prompted Lane to found Naftiko.\n\nThe evolution and splintering of API specifications\n\n“Organizations… accumulate layers of integration standards over time, with each era leaving behind systems that are too costly or risky to excavate.”\n\nLane argues that competing standards are a consequence of vendor ‘land grabs’, where competing vendors exploit specs to exert influence. I don’t disagree with his hypothesis, but I would add that the different standards also reflect when they were developed.\n\nWeb Services Description Language (WSDL) emerged from the Enterprise SOA movement of the 2000s as a formal contract language for web services. Governed by W3C but heavily influenced by IBM, Microsoft, and Oracle, it was technically open but reflected corporate middleware needs, with verbose XML schemas defining operations, messages, and bindings.\n\nIn the 2010s, REST APIs displaced SOAP, and lighter-weight specifications emerged:\n\nAs asynchronous architecture patterns such as event-driven architectures, message queues, WebSockets, and streaming gained popularity in the late 2010s, OpenAPI’s request-response model no longer fit. Regarded as a sister spec to OpenAPI, AsyncAPI (also under Linux Foundation) borrowed OpenAPI’s structure, adapting it for pub/sub, streaming, and asynchronous messaging patterns.\n\nAs we entered the 2010s, Smithy (AWS) and TypeSpec (Microsoft) marked a shift toward protocol-agnostic API modeling. Rather than describing HTTP endpoints directly, they model services abstractly, then generate OpenAPI, code, or protocol-specific implementations. This reflects cloud providers’ need to maintain type safety while supporting multiple protocols (HTTP, gRPC, proprietary) from single definitions.\n\nSmithy powers AWS’s service definitions. TypeSpec emerged from Microsoft’s experience with Azure APIs and emphasizes TypeScript-based syntax for broader developer accessibility. Both Smithy and TypeSpec are open source, but neither has truly open governance in the OpenAPI/AsyncAPI sense. AWS drives Smithy’s roadmap based on internal AWS needs. TypeSpec recently moved to a Linux Foundation working group, but Microsoft remains the dominant contributor. There’s no open governance — no multi-vendor steering committee, and no requirement for consensus from competing cloud providers.\n\nThis matters because Smithy and TypeSpec reflect their creators’ architectural assumptions: multi-region cloud services, polyglot microservices, auto-generated clients. They’re optimized for the problems that AWS and Azure experience, not necessarily problems faced by enterprises or startups. Without diverse governance, they risk becoming sophisticated tools that solve vendor-specific problems.\n\nThe SDK focus of Smithy and TypeSpec reveals something else: these specs assume developers consume APIs through generated code. They’re not optimized for the autonomous agents that LLM vendors hope will form the next wave of API consumers. As a result, the big LLM model providers are creating and pushing new standards:\n\nWhile OpenAPI and AsyncAPI are strategic resources, MCP and A2A are more tactical. “Both MCP and A2A are very transactional, exciting, and in this moment,” Lane said. “They are also likely to give away all your value and data if you are not careful. You have to be very thoughtful in how you transact in those new realms.”\n\nThe question is how you bridge the gap between the tactical needs of an individual team and the strategic needs of the overall enterprise. “I would see this at Postman all the time. Tractor company John Deere would come to us and say, ‘Our CIO, CTO’s office, and Centre of Excellence, manage SOAP, WSDLs, open API, and AsynchAPI across the org. Now we have teams with Postman Collections that run tests and automation, but they don’t understand the bigger picture. We need Postman to reconcile these two worlds for us.’”\n\nThe API economy saw developers craft APIs, treat them as products, rate-limit them, and understand who was using them and what they were doing with them. “MCP, however, wants to circumvent all of that,” Lane said. “It wants direct access to your data and files, so it’s throwing out that decade of design work in front of our file systems and databases, and instead letting the agents have it without much accounting or governance.”\n\nIn addition to wasting significant potential value, poor data governance poses a significant challenge when deploying LLMs for internal use. Organizations can inadvertently expose sensitive information across departments. That data was likely technically accessible before, but required manually searching through Google Drive or file shares to find it.\n\nWhen LLMs gain access to these information repositories, they can surface and share sensitive data far more readily, effectively democratizing access in ways that may violate intended access controls. This was a point that Nicolleta Curtis emphasized to me in an interview for LeadDev. “Even with the basics, such as OneDrive and SharePoint, we found documents that were overshared or with open permissions,” she told me.\n\nOrganizations typically respond to this challenge in one of two ways: they underestimate either the severity of the data exposure risk or the operational burden that proper mitigation will place on their security teams. Implementing appropriate access controls and data boundaries after the fact requires substantial effort.\n\nIn large enterprises with legacy systems, retroactively tightening permissions often breaks existing workflows and integrations. This creates friction across the organization as teams suddenly lose access to information they’ve historically relied on, leading to productivity impacts and internal resistance to the new controls.\n\nIn the first article in this series, Lane described his experience setting up API governance at Bloomberg, which involved:\n\nUsing this approach of comprehensive API mapping and governance with established standards like OpenAPI provides the best foundation for compliance, security, and Personally Identifiable Information (PII) management. For newer/smaller organizations, Lane suggested skipping the ‘baggage’ and going straight to newer approaches such as Agent Skills or MCP.\n\nWhatever approach you favor, we both agree that you should resist the temptation to take a technology-first approach that ignores business outcomes.",
    "readingTime": 6,
    "keywords": [
      "accumulate layers",
      "web services",
      "cloud providers",
      "legacy systems",
      "behind systems",
      "integration standards",
      "access controls",
      "smithy and typespec",
      "the api",
      "agent skills"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/ai-strategy-api-sediment/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2026/02/874b4afb-peter-olexa-rytit3b7xw4-unsplash-scaled.jpg",
    "created_at": "2026-02-17T18:42:44.292Z",
    "topic": "tech"
  },
  {
    "slug": "agntor-trust-infrastructure-for-ai-agents-identity-escrow-guard",
    "title": "Agntor – Trust infrastructure for AI agents (identity, escrow, guard)",
    "description": "Contribute to agntor/agntor development by creating an account on GitHub.",
    "fullText": "agntor\n\n /\n\n agntor\n\n Public\n\n docs.agntor.com\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n agntor/agntor",
    "readingTime": 1,
    "keywords": [
      "agntor",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/agntor/agntor",
    "thumbnail_url": "https://opengraph.githubassets.com/fdbe116b5444b69fe4a879f37c52130d165afc0515bc1ad17eaae0f160810836/agntor/agntor",
    "created_at": "2026-02-17T18:42:43.744Z",
    "topic": "tech"
  },
  {
    "slug": "a-software-ceo-explains-why-hes-not-worried-about-the-ai-apocalypse-coming-for-his-industry",
    "title": "A software CEO explains why he's not worried about the AI apocalypse coming for his industry",
    "description": "Basware CEO Jason Kurtz explained how he keeps his software company ahead of AI startups threatening his business.",
    "fullText": "It's the end of the world as software companies know it, and this CEO feels fine.\n\nJudging by what some AI experts are saying, and the state of the stock market, you'd think software companies were on their last legs. Basware CEO Jason Kurtz, whose company sells software for financial processes, sees it slightly differently.\n\n\"I will tell you there is not a single piece of data that we see that says that,\" said Kurtz.\n\n\"I have not had a single customer tell us, 'Oh, we're just going to go figure this out on our own and do AP with OpenAI or whoever.' That's not the way these companies work,\" he added.\n\nKurtz reached out to me last week after I asked for some reader feedback on the topic. (I genuinely read all your emails. Even the mean ones!)\n\nBasware, which counts Mercedes and Heineken among its roughly 6,500 customers and uses AI within its own products, hasn't felt threatened thus far. Kurtz told me the company saw a 20% year-over-year increase in sales in 2025, primarily driven by a surge in the back-half of the year.\n\nHe acknowledged that there had been some customer chatter about experimenting with AI on their own. But more recently, clients just want results.\n\nKurtz recalled a conversation with the digital transformation officer of a large European company. After spending roughly a million euros on internal AI-related projects in finance over the past year, the executive told Kurtz they \"can't point to a single penny that we have saved, earned, or helped our business in any way.\"\n\n\"I'm tired of experimenting. I want people who know how to use AI in our processes in our workflows,\" Kurtz said the executive told him.\n\nI asked Kurtz for advice for fellow software companies looking to protect themselves.\n\nBasware primarily works with AWS to help build its AI tools for customers. The company also has an \"AI czar,\" according to Kurtz, to surveil the industry. Figuring out ways to implement AI into your own products that'll drive more value for customers is one way to stay ahead.\n\nThere's also strength in numbers. Kurtz said maintaining tight integrations with fellow vendors to become a part of the workflow creates stickiness.\n\n\"If we weren't doing that, I'd be even more paranoid,\" Kurtz said.\n\nAnd then there's the data element. Basware has processed 2.5 billion invoices and 10 trillion euros of spend in the company's 40-year history. Having such a large swath of info can help train models and identify new efficiencies to pitch to customers.\n\n\"If you don't have a data strategy around AI and how you're going to use that to differentiate your AI and your capabilities, I think that's going to be a challenge,\" he said.",
    "readingTime": 3,
    "keywords": [
      "software",
      "customers",
      "kurtz",
      "processes",
      "customer",
      "that's",
      "roughly",
      "products",
      "primarily",
      "experimenting"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/basware-ceo-jason-kurtz-ai-software-apocalypse-advice-2026-2",
    "thumbnail_url": "https://i.insider.com/698fa49ad3c7faef0ece4ead?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:38.289Z",
    "topic": "tech"
  },
  {
    "slug": "billionaire-investor-vinod-khosla-wants-to-rethink-capitalism-for-the-ai-era-and-suggests-scrapping-taxes-for-125",
    "title": "Billionaire investor Vinod Khosla wants to 'rethink' capitalism for the AI era — and suggests scrapping taxes for 125 million people",
    "description": "Vinod Khosla said AI warrants a \"rethink of capitalism,\" and taxing capital more could allow 125 million people to be removed from US tax rolls.",
    "fullText": "If artificial intelligence eliminates millions of jobs, it might make sense to scrap income taxes for the vast majority of Americans and target capital instead, Vinod Khosla says.\n\n\"AI will transform economies and need a rethink of capitalism & equity,\" the billionaire venture capitalist wrote in an X post on Monday. \"Labor portion of economy (vs capital) will decline sharply. Should we eliminate preferential treatment of capital gains tax and equalize to ordinary income?\"\n\nKhosla — who cofounded Sun Microsystems and made the first VC investment in OpenAI — was making the point that AI replacing labor on a grand scale might warrant greater taxes on assets such as stocks and real estate.\n\nThe veteran financier, who founded Khosla Ventures after leaving Kleiner Perkins, attached a video highlighting some of the jobs that could be taken by AI, from accountants and therapists to truck drivers and chip designers.\n\nAI will transform economies and need a rethink of capitalism & equity. Labor portion of economy (vs capital) will decline sharply. Should we eliminate preferential treatment of capital gains tax and equalize to ordinary income? 40% of capital gains taxes are paid by those with… pic.twitter.com/7oSA9xj5Ko\n\nKhosla said in a follow-up post that ramping up taxes on capital would generate so much revenue that the government could scrap taxes for most of the roughly 150 million US taxpayers.\n\n\"Could easily eliminate bottom 125 million taxpayers from the tax rolls and be revenue neutral at the same time with a capital gains tax equal to ordinary income and a few other tweaks,\" he wrote.\n\nHe added that tax breaks such as carrying over tax losses and tax-free borrowing against unrealized gains — which he called a \"true abuse!\" — are \"special interest goodies inserted by lobbyists and campaign contributions, not true capitalism.\"\n\nKhosla didn't address common critiques of higher taxes, including that they can discourage entrepreneurship and investment, that collecting them can be tricky, and that wealthy people may leave the country to avoid them.\n\nKhosla has previously underscored that the advent of AI may require sweeping policy changes. He estimated in late 2024 that in 25 years' time, AI could be doing 80% of the work in 80% of all jobs, and universal basic income might be needed to compensate for job destruction.\n\n\"As AI reduces the need for human labor, UBI could become crucial, with governments playing a key role in regulating AI's impact and ensuring equitable wealth distribution,\" he wrote on his firm's website.\n\nKhosla isn't alone in predicting AI will change the fabric of society. Elon Musk suggested late last year that work could become \"optional\" and money might become \"irrelevant\" if advances in AI and robotics generate abundant resources for all.\n\nMoreover, the Tesla and SpaceX CEO recently said that retirement savings may not be needed in 10 or 20 years, as everyone might have \"whatever stuff they want.\"\n\nHowever, skeptics such as Michael Burry of \"The Big Short\" fame have cautioned the AI boom is a speculative bubble, tech companies are overinvesting in microchips and data centers that will quickly become obsolete, and true AI is further away than many think.",
    "readingTime": 3,
    "keywords": [
      "transform economies",
      "decline sharply",
      "preferential treatment",
      "capitalism equity",
      "eliminate preferential",
      "labor portion",
      "ordinary income",
      "capital gains",
      "gains tax",
      "taxes"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/vinod-khosla-ai-taxes-capital-labor-job-losses-billionaires-musk-2026-2",
    "thumbnail_url": "https://i.insider.com/69946045d3c7faef0ece5d91?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:38.112Z",
    "topic": "finance"
  },
  {
    "slug": "12hour-days-no-weekends-the-anxiety-driving-ais-brutal-work-culture-is-a-warning-for-all-of-us",
    "title": "12-hour days, no weekends: the anxiety driving AI’s brutal work culture is a warning for all of us",
    "description": "San Francisco’s AI startups are pushing workers to grind endlessly, hinting at pressures soon hitting other sectors\nNot long after the terms “996” and “grindcore” entered the popular lexicon, people started telling me stories about what was happening at startups in San Francisco, ground zero for the artificial intelligence economy. There was the one about the founder who hadn’t taken a weekend off in more than six months. The woman who joked that she’d given up her social life to work at a prestigious AI company. Or the employees who had started taking their shoes off in the office because, well, if you were going to be there for at least 12 hours a day, six days a week, wouldn’t you rather be wearing slippers?\n“If you go to a cafe on a Sunday, everyone is working,” says Sanju Lokuhitige, the co-founder of Mythril, a pre-seed-stage AI startup, who moved to San Francisco in November to be closer to the action.",
    "fullText": "Not long after the terms “996” and “grindcore” entered the popular lexicon, people started telling me stories about what was happening at startups in San Francisco, ground zero for the artificial intelligence economy. There was the one about the founder who hadn’t taken a weekend off in more than six months. The woman who joked that she’d given up her social life to work at a prestigious AI company. Or the employees who had started taking their shoes off in the office because, well, if you were going to be there for at least 12 hours a day, six days a week, wouldn’t you rather be wearing slippers?\n\n“If you go to a cafe on a Sunday, everyone is working,” says Sanju Lokuhitige, the co-founder of Mythril, a pre-seed-stage AI startup, who moved to San Francisco in November to be closer to the action. Lokuhitige says he works seven days a week, 12 hours a day, minus a few carefully selected social events each week where he can network with other people at startups. “Sometimes I’m coding the whole day,” he says. “I do not have work-life balance.”\n\nAnother startup employee, who came to San Francisco to work for an early-stage AI company, showed me dismal photos from his office: a two-bedroom apartment in the Dogpatch, a neighborhood popular with tech workers. His startup’s founders live and work in this apartment – from 9am until as late as 3am, breaking only to DoorDash meals or to sleep, and leaving the building only to take cigarette breaks. The employee (who asked not to use his name, since he still works for this company) described the situation as “horrendous”. “I’d heard about 996, but these guys don’t even do 996,” he says. “They’re working 16-hour days.”\n\nStartups have never been particularly glamorous. When I started reporting on the industry a decade ago, people were cashing in on the new mobile app economy, and coders were chugging Soylent to stay at their desks longer. Startups then, too, were defined by hustle culture, high-octane energy and the pursuit of growth at all costs – ideas that, to some extent, have remained in the bloodstream of the industry.\n\nBut in the last year, as the magic dust of artificial intelligence has settled in San Francisco, the vibe among tech workers does seem different. The excitement about a new epoch in tech – and all the money that comes with it – is now tempered with anxieties about the industry, and the economy. Some workers are going all in on AI while also questioning whether all that AI is good for the world. Others are effectively training machines to do their jobs better than they can. And many of the same workers who are racing to build the future are now wondering if the future they’re building has a place for them in it.\n\nThe rest of us may be ambiently aware of these anxieties, but they are already tangible and keenly felt inside the tech industry. Even the biggest tech companies, once known for coddling employees with on-site massages and barber shops, have scaled back perks as they have escalated the expectations of workers. Mark Zuckerberg and Elon Musk have each been candid about their predictions that AI will replace some junior and mid-level engineers at their companies, and have respectively called for their workforces to be more “efficient” and “extremely hard core” as waves of layoffs set employees on-edge. Tech companies laid off about a quarter of a million workers around the world in 2025, according to a report published by RationalFX. In many of those layoffs, AI was cited as a main factor, even if the full reason for layoffs is often more complex.\n\n“If you were a software engineer five years ago, you could kind of write your ticket,” says Mike Robbins, an executive coach who has worked with companies like Google, Microsoft, Salesforce and Airbnb. Now, the balance of power has shifted away from tech workers, many of whom are left feeling anxious about their work performance. “When companies become less scared about losing employees, then they can be a little more forthright in terms of what they want and be a little more demanding.”\n\nRobbins, who wrote the book Bring Your Whole Self to Work, used to be asked to speak to companies and their leaders about topics like employee burnout, wellbeing and belonging – top priorities in the years during and shortly after the pandemic. “Quite frankly, we’ve stopped talking about all that,” he says. Now, company leaders want advice on topics like change, disruption and uncertainty in the workplace.\n\nThose themes – change, disruption and uncertainty – are each part of the fuel that has driven tech workers to put in more hours, at a higher intensity. Investment in artificial intelligence companies reached record highs in 2025, yet workers are feeling scarcity in ways they haven’t before.\n\n“It’s definitely something that’s on everyone’s mind,” says Kyle Finken, a software engineer at Mintlify, which makes an AI tool for developers. “I think a lot of people are concerned like, ‘Oh, am I going to have a job in three years?’”\n\nDespite his fears, Finken, like many other startup employees I spoke to, feels energized by the “extraordinary innovation” happening in artificial intelligence and believes that there will still be plenty of jobs for software engineers in the future, even if those jobs look different from the pure coding roles of today. He and other tech workers characterized the current moment as a particularly creative and productive time in tech, where people are devoting extra hours to work not because their employers demand it but out of genuine interest in the new tools and capabilities. For example, Garry Tan, the head of the famous startup accelerator Y Combinator, recently bragged that he “stayed up 19 hours” playing around with Claude Code.\n\nEven those who felt excited about the pace of change acknowledged that AI was rapidly augmenting their work, in ways that could have uncertain outcomes for the jobs of the future. “This is definitely not an era of complacency,” says Finken.\n\nOne reason for working so many hours is to keep up with tools and technology that are changing nearly every day. If you take the weekend off, you can miss a major development, which makes it harder to keep up with what competitors are doing. Another reason is to have something to show future employers, especially as more junior-level jobs are replaced by AI.\n\n“No one hires junior developers any more,” says Lokuhitige, the Mythril co-founder. Landing a job now requires “doing something cool”, he says, like building a new product or solving a problem that gets recognized as useful by larger companies. Job postings for entry-level tech jobs have dropped by a third since 2022, according to Indeed’s Hiring Lab, while job postings requiring at least five years of experience have risen. If you’re not grinding at a startup, you’re missing the prerequisite to get hired in the future.\n\nWhile economists are torn about whether AI will replace most jobs or just change them, they seem aligned in the idea that AI has already reshaped a great deal of entry-level work and will continue to do so. A paper published by Stanford researchers in November found “substantial declines in employment for early-career workers” in industries exposed to AI and suggested that areas where change is already occurring could be like a “canary in the coalmine” for the rest of the economy. The Anthropic CEO, Dario Amodei, has suggested AI could eliminate about half of all entry-level jobs in white-collar industries within the next five years.\n\nThe head of the International Monetary Fund recently predicted that 60% of jobs in advanced economies will be eliminated or transformed by artificial intelligence, “like a tsunami hitting the labour market”. In San Francisco, you can already see the early signs, as Uber drivers compete with self-driving Waymos, and baristas are replaced by robotic coffee bars. Professional business services that support the tech industry have also been negatively affected by the layoffs. The pressure to grind in the tech world could be an early signal – a harbinger for what many other industries will feel soon.\n\nRobbins, the executive coach, says that companies once looked to Silicon Valley as a model of how they should operate, down to emulating policies like unlimited vacation days or adopting perks like free lunch in the office.\n\n“There was an idealization of tech and Silicon Valley for a long time across the business world. Some of that has changed,” he says. “Now, people aren’t asking me to tell them what’s going on in the Valley so that they can adopt it, the same way they were a decade ago.”\n\nRather than a model of how we should all work, the tech industry may be a premonition for the anxiety and attempts to compensate that are coming for all of us.",
    "readingTime": 8,
    "keywords": [
      "executive coach",
      "decade ago",
      "software engineer",
      "job postings",
      "artificial intelligence",
      "san francisco",
      "tech industry",
      "tech workers",
      "silicon valley",
      "jobs"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/feb/17/ai-startups-work-culture-san-francisco",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0dc04be29cbd720664313a65c08e776ecae088ea/0_1012_4091_3273/master/4091.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=3568863089989ed2e94df48fff54f1dd",
    "created_at": "2026-02-17T18:42:37.932Z",
    "topic": "tech"
  },
  {
    "slug": "andrew-yang-says-mass-whitecollar-layoffs-are-closer-than-people-think",
    "title": "Andrew Yang says mass white-collar layoffs are closer than people think",
    "description": "The Forward Party founder said AI \"will kick millions of white-collar workers to the curb in the next 12 - 18 months.\"",
    "fullText": "Expect to see your local Starbucks soon be full of middle-aged former office workers, says Andrew Yang.\n\nThe Forward Party founder and former presidential candidate said AI \"will kick millions of white-collar workers to the curb in the next 12 - 18 months\" in a post on his Substack on Monday.\n\nYang said that, when a company begins to shrink its workforce, its competitors will follow suit.\n\n\"It will become a competition because the stock market will reward you if you cut headcount and punish you if you don't,\" he added.\n\nYang has long warned about the impact of automation on jobs — he had previously told The New York Times in 2018 that he predicted self-driving cars would displace truck drivers, a shift that could \"destabilize society\" and provoke \"riots in the street.\"\n\nIn his Substack post, Yang then laid out which workers could be vulnerable: mid-career office workers, middle managers, call center workers, marketers, and coders. The list goes on.\n\n\"Do you sit at a desk and look at a computer much of the day? Take this very seriously,\" he wrote. \"Millions of workers are about to be given their pink slips.\"\n\nYang did not respond to a request for further comment.\n\nThis January saw more layoffs than any January since 2009. Though this has largely been attributed to economic uncertainty, a few companies have already begun citing AI as a reason they are letting staff go.\n\nPinterest said in January that it expects to lay off 15% of its workforce. A spokesperson for Pinterest said the restructuring was part of the company's \"AI-forward strategy.\"\n\nHP said in November that it would cut up to 6,000 jobs by 2028, citing AI initiatives as the reason.\n\nCritics have also said some companies are using AI as a scapegoat for job cuts.\n\nTech CEOs and AI researchers are divided over how AI will impact society. While Tesla and xAI CEO Elon Musk and Google DeepMind CEO Demis Hassabis predict a future of great abundance for all, others, such as Anthropic CEO Dario Amodei, say we should brace for significant white-collar layoffs.\n\nYang said the impact of his predicted layoffs will be felt beyond those who actually lose their jobs.\n\n\"Let's say you're a dry cleaner, a dog walker, or a hairstylist. If people in your community stop going to the office, your business is going to suffer because there are fewer business shirts to launder, people will walk their dogs themselves, and cut back on trips to the salon,\" he said.\n\n\"The amount of money getting paid to human labor is about to go down,\" Yang said.",
    "readingTime": 3,
    "keywords": [
      "workers",
      "impact",
      "jobs",
      "layoffs",
      "yang",
      "millions",
      "white-collar",
      "substack",
      "workforce",
      "predicted"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrew-yang-mass-layoffs-ai-closer-than-people-think-2026-2",
    "thumbnail_url": "https://i.insider.com/699483b4d3c7faef0ece5f4f?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.726Z",
    "topic": "finance"
  },
  {
    "slug": "3-reasons-why-googles-gemini-could-be-the-big-bogeyman-of-the-ai-trade",
    "title": "3 reasons why Google's Gemini could be the big bogeyman of the AI trade",
    "description": "Anthropic's Claude AI has snatched headlines recently. But is there another model that is throwing a wrench in the AI trade?",
    "fullText": "While Anthropic's Claude AI has snatched headlines recently for disrupting the software industry, one researcher says there's perhaps an even bigger bogeyman lurking in tech.\n\nTom Essaye, founder and president of the Sevens Report, says Google's Gemini threatens major potential disruptions to how investors currently see major AI firms.\n\nIn a note to clients on Tuesday, Essaye highlighted three risks posed by Gemini, in particular its November update.\n\nThe first is that it could take market share from OpenAI's ChatGPT. That, in turn, could hurt OpenAi's ability to deliver on the $1 trillion in spending it has promised to firms like Nvidia, he said.\n\nSecond, the fact that Google used its own chips to build Gemini could undermine the importance of large semiconductor providers.\n\n\"The reason that Nvidia, Broadcom, Taiwan Semi and others have exploded in recent years was because of insatiable demand for their semiconductor chips, as they are necessary to build out LLMs,\" Essaye wrote. \"Google making their own chips implies demand for chips from NVDA, AVGO and TSMC may be less than expected. That means less earnings growth and a lower multiple for semiconductor stocks.\"\n\nThat leads to the third point: since Gemini is so effective and was cheaper to produce than other leading chatbots, investors are holding spending levels from hyperscalers to a higher degree of scrutiny, Essaye said.\n\n\"If Google can make Gemini as good as ChatGPT on its own chips, then others likely can as well. The fear is that AI becomes commoditized, making trillions of dollars in AI infrastructure investment foolish,\" Essaye wrote.\n\n\"Put plainly, Gemini broke the idea that all money spent on AI was 'good' money that would result in earnings growth,\" he continued. \"Instead, it ushered in scrutiny to AI capex spending and that altered the paradigm AI/tech stocks existed in. Practically, that means it's no longer the case that the company that spends the most on AI infrastructure 'wins' and we can see that in the market reaction to the collapse of mega-cap free cash flow.\"",
    "readingTime": 2,
    "keywords": [
      "earnings growth",
      "chips",
      "semiconductor",
      "investors",
      "firms",
      "market",
      "others",
      "demand",
      "less",
      "stocks"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/google-gemini-stock-market-ai-trade-threaten-openai-nvidia-tsmc-2026-2",
    "thumbnail_url": "https://i.insider.com/69948486d3c7faef0ece5f73?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.431Z",
    "topic": "finance"
  },
  {
    "slug": "more-than-20000-sign-a-petition-for-openai-to-resurrect-gpt4o",
    "title": "More than 20,000 sign a petition for OpenAI to resurrect GPT-4o",
    "description": "The deprecation of OpenAI's GPT-4o sparks backlash and a petition. Users said they cherish its unique conversational style.",
    "fullText": "Thousands of people are rallying behind a version of ChatGPT after its parent company, OpenAI, retired the model.\n\nOpenAI said on January 30 that GPT-4o would be deprecated alongside three other versions of that model on February 13.\n\nA petition calling on OpenAI to save GPT-4o has amassed roughly 21,900 signatures on Change.org as of Tuesday.\n\n\"For many of us, GPT-4o offers a unique and irreplaceable user experience, combining qualities and capabilities that we value, regardless of performance benchmarks,\" the petition's description says.\n\nOpenAI wrote in a 2025 blog post that the model was known for \"responses that were overly supportive but disingenuous.\"\n\nThe company first set out to sunset GPT-4o last year, but fans pleaded to save it. In response, OpenAI brought the model back for several more months before its latest announcement.\n\nThe petition, created in April 2025 by Sophie Witt, reached 12,500 supporters two weeks ago, after OpenAI shared its latest plans to retire the model, and has continued to climb since.\n\nOn February 2, Witt called on supporters to take collective action against OpenAI's decision by posting about GPT-4o on X.\n\nWitt did not immediately respond to a request for comment.\n\nOpenAI gave GPT-4o a shoutout in its January 30 blog post, saying that many users told the company they like the model's \"conversational style and warmth\" last year. The ChatGPT maker said that feedback helped shape the GPT‑5.1 and GPT‑5.2 models.\n\nThe company cited low usage of GPT-4o as another reason for its retirement, reporting that only 0.1% of users still choose GPT‑4o.\n\nThe last time GPT-4o was retired, CEO Sam Altman was bombarded during an ask-me-anything session on Reddit with calls to reinstate it.\n\nThe calls for its return have been renewed through comments from social media users and petition signees. Some said it felt more like losing a friend than a feature. Other paying ChatGPT users said they'd be canceling their subscriptions in response to the retirement of GPT-4o.\n\n\"No 4o, no money. I will not spend another single penny on OpenAI,\" one X user posted.",
    "readingTime": 2,
    "keywords": [
      "openai",
      "model",
      "users",
      "petition",
      "gpt-4o",
      "retired",
      "january",
      "save",
      "user",
      "blog"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-retires-gpt-4o-20-000-sign-petition-save-it-2026-2",
    "thumbnail_url": "https://i.insider.com/69949378d3c7faef0ece61d2?width=1200&format=jpeg",
    "created_at": "2026-02-17T18:42:37.416Z",
    "topic": "finance"
  },
  {
    "slug": "keysight-launches-gddr7-transmitter-compliance-solution-for-ai-systems",
    "title": "Keysight launches GDDR7 transmitter compliance solution for AI systems",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/keysight-launches-gddr7-transmitter-compliance-solution-for-ai-systems-93CH-4509516",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-02-17T18:42:36.933Z",
    "topic": "finance"
  },
  {
    "slug": "why-ai-adoption-stalls-according-to-industry-data",
    "title": "Why AI Adoption Stalls, According to Industry Data",
    "description": "Many companies report widespread AI usage but disappointing returns, assuming the problem lies in execution rather than adoption. New research shows that AI initiatives often stall because employees’ industry-shaped anxiety about relevance, identity, and job security drives surface-level use without real commitment. Leaders who treat AI adoption as a psychological and contextual challenge—not just a technical rollout—are far more likely to convert experimentation into sustained impact.",
    "fullText": "Why AI Adoption Stalls, According to Industry Data by Erin Eatough, Keith Ferrazzi, Wendy Smith and Shonna WatersFebruary 17, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintCompanies in most industries are investing heavily in artificial intelligence: 88% of companies reporting regular AI use. Yet many leaders report familiar frustrations. AI adoption stalls. Performance gains plateau. Employees experiment with new tools but don’t integrate them deeply into how work actually gets done, leaving executives increasingly concerned about ROI.",
    "readingTime": 1,
    "keywords": [
      "adoption stalls"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/why-ai-adoption-stalls-according-to-industry-data",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_14_1466294985.jpg",
    "created_at": "2026-02-17T18:42:36.916Z",
    "topic": "business"
  },
  {
    "slug": "anthropics-pentagon-talks-hit-surveillance-and-weapons-snag",
    "title": "Anthropic's Pentagon Talks Hit Surveillance and Weapons Snag",
    "description": "Anthropic PBC's talks about extending a contract with the Pentagon are being held up over additional protections the artificial intelligence company wants to put on its Claude tool, a person familiar with the matter said.  Anthropic wants to put guardrails in place to stop Claude from being used for mass surveillance of Americans or to develop weapons that can be deployed without a human involved, the person said, asking not to be identified because the negotiations are private. The Pentagon wants to be able to use Claude as long as its deployment doesn't break the law. Axios reported on the disagreement earlier. Bloomberg Mandeep Singh reports.",
    "fullText": "Anthropic's Pentagon Talks Hit Surveillance and Weapons Snag BloombergAnthropic PBC's talks about extending a contract with the Pentagon are being held up over additional protections the artificial intelligence company wants to put on its Claude tool, a person familiar with the matter said. Anthropic wants to put guardrails in place to stop Claude from being used for mass surveillance of Americans or to develop weapons that can be deployed without a human involved, the person said, asking not to be identified because the negotiations are private. The Pentagon wants to be able to use Claude as long as its deployment doesn't break the law. Axios reported on the disagreement earlier. Bloomberg Mandeep Singh reports.",
    "readingTime": 1,
    "keywords": [
      "claude",
      "talks",
      "surveillance",
      "weapons",
      "pentagon"
    ],
    "qualityScore": 0.45,
    "link": "https://finance.yahoo.com/video/anthropics-pentagon-talks-hit-surveillance-181151173.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/KgtRH04_ep_kgIf29fi6JA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/bloomberg_markets_video_2/bf5025187b31a5257673b13959be0db3",
    "created_at": "2026-02-17T18:42:36.294Z",
    "topic": "finance"
  },
  {
    "slug": "the-big-tech-losers-as-ai-fears-wipe-billions-of-dollars-off-valuations",
    "title": "The Big Tech losers as AI fears wipe billions of dollars off valuations",
    "description": "Concerns over risks to Microsoft's AI business and growing competition from Google ‌and Anthropic have wiped roughly $613 billion off its market value.",
    "fullText": "Feb 16 (Reuters) - The world's most valuable technology stocks have suffered sharp declines in market value ‌this year after years of outsized gains, ‌as investors question whether heavy spending on AI will generate sufficient ​returns to justify the lofty valuations.\n\nMicrosoft (MSFT) shares have fallen about 17% year-to-date on concerns over risks to its AI business and growing competition from Google's (GOOG, GOOGL) latest Gemini model ‌and Anthropic's (ANTH.PVT) Claude ⁠Cowork AI agent, wiping roughly $613 billion off its market value to about $2.98 trillion as ⁠of Friday.\n\nAmazon (AMZN) has shed around 13.85% so far this year, erasing about $343 billion in market value and leaving ​the company ​valued at roughly $2.13 trillion.\n\nEarlier ​this month, Amazon said ‌it expects capital spending to jump more than 50% this year.\n\nNvidia (NVDA), Apple (AAPL) and Alphabet have also seen their market values decline by $89.67 billion, $256.44 billion and $87.96 billion, respectively, since the start of 2026, to $4.44 trillion, $3.76 trillion and $3.7 ‌trillion.\n\nThe pullback signals a broader ​shift in market psychology, with ​investors moving from rewarding ​long-term AI ambitions to demanding near-term ‌earnings visibility after years of ​speculative enthusiasm.\n\n(Reporting ​by Gaurav Dogra and Patturaja Murugaboopathy in ​Bengaluru; Editing by Sumana Nandy)",
    "readingTime": 2,
    "keywords": [
      "market",
      "investors",
      "roughly",
      "amazon"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/big-tech-stocks-lose-billions-093834534.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/kM_An8HTnTHs5Zy.uQEfSg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-02/eab91ac0-0b1e-11f1-acef-9ae1be1a2924",
    "created_at": "2026-02-17T18:42:34.599Z",
    "topic": "finance"
  },
  {
    "slug": "these-three-claude-premium-ai-features-are-now-available-for-free",
    "title": "These Three Claude Premium AI Features Are Now Available for Free",
    "description": "Here's to use these new features",
    "fullText": "Anthropic's Claude is an AI bot that keeps up a steady pace when it comes to pushing out new features, and the latest upgrade of note sees three useful features make their way down to free users, having previously been exclusive to the paid-for plans.\n\nIf you're choosing between AIs and comparing the features available on the free plans, then there's now more of a case to be made for choosing Claude over a competitor like ChatGPT or Gemini for your next batch of AI tasks.\n\nThe three new features now available to free users on Claude are file creation, external plug-ins called Connectors, and bundles of instructions called Skills. Here's how you can make use of them.\n\nClaude's file creation capabilities let you create Word documents, PowerPoint slideshows, Excel spreadsheets, and PDFs from right inside a conversation. You can either supply the bot with all text, data, and other information you want included, get Claude to invent everything itself, or something in between.\n\nFor example, if you've got a long list of names and scores, Claude can put them into a spreadsheet for you. If you've got a series of images, Claude can combine them into a PDF and describe them. You can get it to analyze and visualize data, produce presentations based on reports, and create summary documents.\n\nTo enable file creation for your account, click your profile icon (bottom left) in Claude on the web, then select Settings > Capabilities and enable Code execution and file creation. With that done, you just have to prompt Claude with the type of file you want to make and what you want included, supplying any information as needed (or telling the AI where to find it online).\n\nAs usual with these AI bots, the more detail and specificity you can provide, the better—the end result is then more likely to be closer to what you were aiming for. I got it to quickly come up with the results of a fictional sports day race, and produce a spreadsheet from it. While it's not the most demanding of tasks, Claude completed it correctly.\n\nConnectors can hook Claude up to a variety of other apps, sites, and services: So if you want to get it to design something for you in Canva, or manage your messages in Slack, or find some travel deals on Trivago, then Claude can do that for you. The full list of current Connectors gives you some idea of what's possible.\n\nTo get to the Connectors from the Claude prompt box, click the small + (plus) icon in the lower left corner, then choose Add connectors. You can search through Connectors by name, and filter them by type and category. When you select one you like, you'll need to supply your account credentials and give Claude permission to access your account.\n\nYour Connectors of choice are then available from the same sub-menu in the prompt box: You can add more plug-ins and remove existing ones from there. You can either select an app, or specify the name of it in your prompt and Claude should understand what you mean. You can ask for outputs, run searches, and communicate through your connected services.\n\nConnectors can give Claude some handy extra talents. With the Canvas Connector, for example, I was able to create a basic bit of artwork for a birthday party flyer—something that the AI wouldn't have been able to do on its own. I find that access was spotty, however, perhaps a sign of a lot of free users now making use of these tools.\n\nWith Skills, you can \"teach Claude how to complete specific tasks in a repeatable way\" (in the words of the official support document). In old-school computer talk, they might be referred to as macros: batches of set instructions that Claude can repeat whenever you need something doing in a particular way.\n\nTemplates are a good example, whether they're for emails or documents. Rather than just getting Claude to write an email for you, you can set down some basic parameters for the job that include guidelines on tone, length, and style, as well as crucial bits of information (such as your contact details) that always need to be included.\n\nClick your account profile icon (bottom left) in Claude on the web, then choose Settings > Capabilities and click Add under Skills to get started. You can create a Skill through a Claude conversation, by writing out the instructions, or by uploading a Skills file (which is handy for including extra items such as code snippets, as described here).\n\nI took the Create with Claude route to put together a basic way of summarizing PDF reports, with specific guidelines on how many paragraphs and headings to use, and the tone of voice to apply. In the future, rather than typing out those instructions every time I need something summarized, I can just invoke the Skill.",
    "readingTime": 5,
    "keywords": [
      "profile icon",
      "icon bottom",
      "free users",
      "prompt box",
      "file creation",
      "settings capabilities",
      "claude",
      "create",
      "features",
      "instructions"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/claude-premium-ai-features-for-free-users?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHKHWF3SFWBAY3CB4Q84ESXG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.578Z",
    "topic": "tech"
  },
  {
    "slug": "how-duckduckgos-new-encrypted-voice-ai-chat-compares-with-chatgpt-and-gemini",
    "title": "How DuckDuckGo's New Encrypted Voice AI Chat Compares With ChatGPT and Gemini",
    "description": "Duck.ai's voice chat preserves your privacy, but can't compete with similar options from other companies.",
    "fullText": "While OpenAI is pushing ads on its free users, DuckDuckGo's Duck.ai portal is going a different way. Duck.ai is a privacy-first AI chatbot that doesn't use your data for training, but still gives you AI answers using popular models, including those from OpenAI. The data privacy feature goes beyond as well. DuckDuckGo removes all private metadata (like your location and IP address) before prompting the AI model, and it doesn't share anything about you or your device. Your questions, as well as DuckDuckGo's answers, are never used for AI training.\n\nSince its launch in 2024, the portal has only offered a chatbot interface, but now, DuckDuckGo has added a voice mode as well. With voice chat, instead of reading through long and meandering answers, the AI replies in short, to-the-point snippets that are relevant to your query. Duck.ai's take on the feature is competing with those from companies like OpenAI and Google, and it's free—though expanded limits are offered for DuckDuckGo subscribers.\n\nDuck.ai's voice chat is opt-in, not mandatory. In fact, you can even use it without a DuckDuckGo account. To try it, head to the Duck.ai portal, then from the sidebar, choose the voice chat option and enable it for your account.\n\nNow, when you click the \"New Voice Chat\" button in the sidebar, Duck.ai's bot will appear. You can start speaking, and the bot will reply to you. Just like ChatGPT or Gemini, this is a continuous voice chat, so you don't need to perform any action to ask follow-up questions. You can also interrupt the AI answer to add clarifications or to ask more questions.\n\nWhile the text prompts let you choose the models (including OpenAI's ChatGPT 5-mini), it's not clear exactly what powers voice chat. DuckDuckGo says that it uses an OpenAI model, but doesn't specify which one it is.\n\nOf course, the real question is how Duck.ai's voice chat holds up against Gemini and ChatGPT. For general knowledge questions, Duck.ai holds its own, but it falters when it comes to the latest news. I asked all three services the same questions, and while some responses were similar, ChatGPT's voice mode offers the best overall user experience by far.\n\nI tested the voice chat features using three different kinds of questions. First, I asked about the upcoming Samsung S26 series; second, we talked about the Roman Empire; and lastly, I asked for some advice on how to get started with coding.\n\nWhen it comes to asking questions about news, like Samsung's S26 release, DuckDuckGo's limitations are immediately evident. It sometimes flat out refuses to answer, saying its knowledge cutoff is 2023. Other times, it gives vague responses about the upcoming event, suggesting I check news sites for the latest information. When pressed for details, like when the event is or the rumors surrounding it, it goes back to its cut-off period excuse.\n\nChatGPT's app, however, gave me a detailed response with all the latest rumors, as well as articles to read for additional information—basically, what you'd expect from an AI assistant. Gemini Live provided shorter responses than ChatGPT, though they were accurate. I was able to get Gemini to give me more details in the regular text mode, which reads aloud results if you ask questions using the Mic button, but this defeats the back-and-forth purpose of a voice mode.\n\nDuck.ai didn't fare much better when I asked about the Roman Empire. I asked for a brief overview of the subject, before cutting it off to just ask who the last emperor was. It answered correctly (Romulus Augustulus), and its overview was fine, but lacked details about the transitionary period and exact dates.\n\nAgain, ChatGPT gave me a much more detailed answer (as demonstrated by the screenshot below). Gemini Live's answer, however, was devoid of any real dates, or meaning. Mic mode offered more details, but Google's voice mode was quite limited.\n\nDuck.ai performed better when I asked it about learning how to code. It followed a very similar script to ChatGPT and Gemini, suggesting I learn Python, even offering the same sources for learning (e.g. freeCodeCamp and Harvard CS50 courses).\n\nGemini Live was the outlier here, though, asking follow-up questions about what I'd like to build or practice. It then changed its answers based on my project ideas (switching from Python to JavaScript as the first language I should learn to build web projects). ChatGPT provided an overview, again focusing on Python, and elaborated on the language's barrier to entry when I asked \n\nDuck.ai's voice chat feature is a mixed bag. It can be fast, doesn't use any personal information, and lets you interrupt it. But its limited knowledge base and its inability to give detailed answers are what make it tough to recommend. For the smoothest voice mode experience, ChatGPT is still the king. While DuckDuckGo has the advantage for privacy, you could always use ChatGPT while logged out or in temporary mode to limit the data you share with OpenAI.",
    "readingTime": 5,
    "keywords": [
      "duck.ai portal",
      "duck.ai's voice",
      "voice chat",
      "voice mode",
      "roman empire",
      "gemini live",
      "doesn't",
      "details",
      "feature",
      "knowledge"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/how-duckduckgos-new-encrypted-voice-ai-chat-compares-with-chatgpt-and-gemini?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KH9412V067PAYN9ZB0919XH8/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.408Z",
    "topic": "tech"
  },
  {
    "slug": "apple-music-will-soon-let-you-generate-playlists-with-ai",
    "title": "Apple Music Will Soon Let You Generate Playlists With AI",
    "description": "The new feature is called \"Playlist Playground.\"",
    "fullText": "Over the years, Apple Music has improved its algorithmic playlists. There's now an AI DJ, and you can use ChatGPT to generate playlists. With iOS 26.4, which is currently in beta, Apple wants you to make playlists with its own AI tech. The upcoming update includes a feature called \"Playlist Playground,\" which lets you generate AI playlists directly in the Apple Music app—as long as you're running iOS 26.4.\n\nI do not recommend installing and running beta versions of iOS on your primary iPhone. Beta software is unfinished, which means you could run into bugs and glitches that may impact how you use your iPhone, or even result in data loss. If you're itching to try out new features, it's best to ensure that you've taken a complete backup of your iPhone first. That way, you can always revert to an older installation in case something goes wrong. Even so, it's safer to run test software on a backup iPhone as opposed to your daily driver.\n\nWith that said, if you're sure you want to go ahead and install iOS 26.4 right now, you can go to Settings > General > Software Update on your iPhone. Select Beta Updates > iOS 26 Developer Beta. Now, go back to the Software Update page and wait until you see iOS 26.4 Beta 1 appear. You can now download and install the update to try this new Apple Music feature.\n\nOnce you're on iOS 26.4, you can open the Music app to get started with this feature. Tap the Library tab in the bottom bar, and then select the New Playlist button in the top-right corner. You should see the Playlist Playground feature here. (Note that this feature may not appear on devices that don't support Apple Intelligence, or if your Apple Account is from a region where Apple has restricted the rollout of AI features.)\n\nOnce you activate the feature, you'll be able to generate playlists with AI. From here, you tell the AI what you want to listen to. You could get specific, with certain artists, songs, or genres, or ask for playlists that encompass a certain idea of mood. Apple has some pre-written prompts to get you started, such as \"hip-hop party songs,\" but you can use your own text prompts too. AI-generated playlists have 25 songs by default, and you do have the option to customize the playlist further after it's created. You'll also be able to edit the title, cover image, and the description of AI-generated playlists. These playlists can be shared with others or displayed on your Apple Music profile, just like other playlists you create on the streaming service. It's similar in concept to other AI playlist generators on platforms like Spotify or YouTube Music.\n\nWhile Apple Music's Playlist Playground feature is a good start, it's not yet available to those of us who are unwilling to install developer beta versions of iOS 26. If that's you, there are other options out there for AI generated Apple Music playlists. There's the aforementioned ChatGPT integration, of course, but you could also use a third-party app, like PlaylistAI. It has many prompts for you to get started with, and can even generate playlists from music festival posters. The app does prompt you to get a subscription, but you can skip that prompt and use the free tier to generate a playlist quickly.",
    "readingTime": 3,
    "keywords": [
      "playground feature",
      "playlists there's",
      "ai-generated playlists",
      "apple music",
      "beta versions",
      "developer beta",
      "generate playlists",
      "playlist playground",
      "iphone",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apple-music-will-soon-let-you-generate-playlists-with-ai?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHP8M521BVVYXZQ0AG2D8V3G/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-17T18:42:34.372Z",
    "topic": "tech"
  },
  {
    "slug": "proxima-local-opensource-multimodel-mcp-server-no-api-keys",
    "title": "Proxima – local open-source multi-model MCP server (no API keys)",
    "description": "Multi-AI MCP Server - Connect ChatGPT, Claude, Gemini & Perplexity to your coding tools without any API - Zen4-bit/Proxima",
    "fullText": "Zen4-bit\n\n /\n\n Proxima\n\n Public\n\n Multi-AI MCP Server - Connect ChatGPT, Claude, Gemini & Perplexity to your coding tools without any API\n\n License\n\n View license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Zen4-bit/Proxima",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Zen4-bit/Proxima",
    "thumbnail_url": "https://opengraph.githubassets.com/da1ce1c4daf052f563ec5615a17f7062e6ab435c084a9666f41483e54046eef5/Zen4-bit/Proxima",
    "created_at": "2026-02-17T12:37:44.260Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-coming-for-whitecollar-jobs-a-22yearold-developers-view-from-nepal",
    "title": "AI Is Coming for White-Collar Jobs – A 22-Year-Old Developer's View from Nepal",
    "description": "Andrew Yang says AI will wipe out millions of white-collar jobs. As a 22-year-old developer in Nepal, here's my honest take.",
    "fullText": "I read Andrew Yang's latest article, \"The End of the Office,\" yesterday. He called what's happening to white-collar jobs \"the Fuckening.\" As a 22-year-old developer in Nepal who's building his entire career on sitting at a desk and looking at a computer... yeah, that hit different.\n\nYang's not some random guy on Twitter dooming. He ran for president on this exact issue. He's been saying \"AI is coming for your jobs\" since before most of us took it seriously. And now his tone has shifted from warning to mourning.\n\nMillions of office jobs will evaporate in the next 12 - 24 months. This will be an epic disaster for millions of workers and families. https://t.co/6829id4rME\n\nI sat with this one for a while. Not because it's new information. But because it forced me to think about what I'm actually building toward.\n\nThe article is blunt. There are about 70 million white-collar workers in the United States. Yang expects that number to drop by 20-50% over the next several years. Not decades. Years.\n\nHe talked to the CEO of a publicly traded tech company who laid it out: \"We're firing 15% of workers right now. We'll probably do another 20% two years from now. And then another 20% two years later. After that, who knows?\"\n\nCollege grads? Only 30% are finding jobs in their field. Underemployment is at 52%. The social contract of \"study hard, go to school, get a good job\" is, in Yang's words, about to be \"vaporized to smithereens.\"\n\nHe also made a point that stuck with me: someone in his family had AI program a website this week. It completed in minutes what used to take a designer or a firm days of work.\n\nI build websites. That one was personal.\n\nThe comments on Twitter and Reddit were honestly more unsettling than the article itself. Not because they were doomy. Because they were specific.\n\nOne senior software developer wrote: \"I noticed we just stopped hiring new people a few years ago. Not because management made any decision about it, we just didn't NEED anyone. I'm not too worried about losing my job in the next 2 years, but I do worry that if I become unemployed, I may never find another job again.\"\n\nRead that again. A senior dev. Not worried about being fired. Worried about being unhirable if they ever need to look for work again.\n\nAnother commenter nailed something I'd been thinking: \"I don't fear the legacy companies laying off tons of people. What I fear are new companies entering the market doing the same as current companies with a tenth of the employees.\"\n\nThat's the part people miss. It's not just about big companies cutting staff. It's about small teams doing what big teams used to do. A 5-person startup with AI tools competing against a 500-person company. That changes everything.\n\nThen there was the purchasing power question that nobody seems to have a good answer for. If millions lose their jobs, who's buying the products these AI-powered companies are making? Who's paying for iPhones and Netflix subscriptions? One commenter put it perfectly: \"Will unemployed people surviving on growing their own vegetables be buying $1,500 smartphones?\"\n\nNobody had a convincing answer. The best response was basically: \"Yeah, that's a problem for the next CEO.\"\n\nMost of this conversation is happening through an American lens. \"Mid-career managers making six figures\" being laid off. \"Mortgage delinquencies rising.\" \"Silicon Valley home prices dropping.\"\n\nI'm reading this from Ghorahi, Nepal. My reality is different.\n\nI don't have a mortgage. I'm not making six figures. I'm a BCA student freelancing as a frontend developer for a remote company. My cost of living is a fraction of what Americans deal with. In theory, that should make me more resilient. Even if the market gets competitive, I can survive on less.\n\nBut here's the catch. The entire plan for developers like me in Nepal was: learn to code, get good, land a remote job with a company abroad, earn in dollars. That was the path. AI threatens to cut that ladder off at the knees.\n\nWhy would a US startup hire a remote developer from Nepal when Claude can write the code for them? The cost advantage I used to have? AI just undercut it to nearly zero.\n\nIt's a double-edged thing. Lower cost of living means I can weather the storm longer. But the opportunity that was supposed to lift me up - remote work for global companies - might not exist the same way in two years.\n\nI don't have it figured out. But I'm not sitting still either.\n\nThe biggest shift is that I stopped just \"learning to code.\" Knowing Python or React isn't a moat anymore. AI writes decent code. What it doesn't do well is understand what to build, for whom, and why. So I've been shipping actual products - hackathon projects, side projects, freelance work. Taste matters more than syntax now.\n\nI use Claude. I use AI coding assistants daily. Some devs have this weird pride about not using AI. I think that's like refusing to use Stack Overflow in 2015. The tool isn't the threat. Being replaced by someone who uses the tool better than you - that's the threat.\n\nThis blog exists because if AI can do what I do technically, the differentiator becomes who I am. My perspective, my story, my network. A developer from Nepal who ships products and writes about it. AI can't be that.\n\nI've also been focusing on end-to-end ownership. Not just \"I know React\" or \"I know Django\" but taking an idea from zero to deployed product with user feedback loops. That full cycle is harder to automate than any single skill. And hackathons have been the best training ground for this - three wins so far, each one teaching me more about product thinking than any tutorial ever did.\n\nYang wrote about the social contract being vaporized. \"Study hard, go to school, get a good job, live a decent life.\" He's talking about American workers who followed that contract and now feel betrayed.\n\nBut what about people like me who are still IN school? Who are halfway through the contract? I'm in my 6th semester. I'm doing everything \"right.\" Learning relevant technologies. Building projects. Getting work experience. And the ground is shifting under my feet while I'm still on it.\n\nThere's a weird psychology here that I don't see people discussing. Yang's audience is mostly people who had stability and might lose it. I never had that stability. Growing up in Nepal, the idea of a guaranteed career path was always a bit of a fantasy anyway. There was never a corporate ladder waiting for me.\n\nAnd honestly? There's a strange freedom in that.\n\nI don't have to grieve the loss of a career path I never had. I can just... adapt. Build. Figure it out as I go. Which is basically what I've been doing anyway.\n\nBut let me be real. There's also fear. Real fear. Because the one thing that was supposed to be the great equalizer - the internet and remote work letting talented people anywhere compete globally - might be getting disrupted right when I need it most.\n\nI don't have a clean conclusion. Nobody does right now. Yang says \"batten down the hatches.\" The Reddit comments range from \"we're all screwed\" to \"this is overblown\" to \"learn plumbing.\"\n\nI'd rather be the person building with AI than the person being replaced by it. I'd rather ship 10 imperfect products than have a perfect resume that nobody's hiring for. Maybe that's naive. But right now, sitting at my desk in Nepal, I can either panic or build.",
    "readingTime": 7,
    "keywords": [
      "i'd rather",
      "social contract",
      "career path",
      "don't",
      "jobs",
      "developer",
      "that's",
      "remote",
      "workers",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.bhusalmanish.com.np/blog/posts/ai-jobs-nepal-dev-perspective.html",
    "thumbnail_url": "https://cdn.bhusalmanish.com.np/Featured%20Image/og-image-ai-jobs-nepal-dev-perspective/og-image-ai-jobs-nepal-dev-perspective.jpg",
    "created_at": "2026-02-17T12:37:43.787Z",
    "topic": "tech"
  },
  {
    "slug": "log-poisoning-in-openclaw",
    "title": "Log Poisoning in OpenClaw",
    "description": "Eye Security explores an indirect prompt injection risk in OpenClaw’s WebSocket logging, explains what an exploit might look like, and highlights context, impact, responsible disclosure, and practical next steps for secure AI assistant deployments.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://research.eye.security/log-poisoning-in-openclaw/",
    "thumbnail_url": "https://research.eye.security/wp-content/uploads/ChatGPT-Image-Feb-5-2026-10_27_20-PM-1024x683.png",
    "created_at": "2026-02-17T12:37:43.388Z",
    "topic": "science"
  },
  {
    "slug": "70-ai-providers-under-same-rust-interface",
    "title": "70+ AI Providers Under Same Rust Interface",
    "description": "The AI Toolkit for Rust, inspired by the Vercel AI SDK. - lazy-hq/aisdk",
    "fullText": "lazy-hq\n\n /\n\n aisdk\n\n Public\n\n The AI Toolkit for Rust, inspired by the Vercel AI SDK.\n\n aisdk.rs\n\n License\n\n MIT license\n\n 131\n stars\n\n 12\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lazy-hq/aisdk",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/lazy-hq/aisdk",
    "thumbnail_url": "https://opengraph.githubassets.com/82e8941ec05e97907f49673ca6b3967853e0d46b7cf37ab5a3b0c930d1bd07d2/lazy-hq/aisdk",
    "created_at": "2026-02-17T12:37:43.280Z",
    "topic": "tech"
  },
  {
    "slug": "preventing-runaway-llm-agents-enforcement-layer",
    "title": "Preventing runaway LLM agents (enforcement layer)",
    "description": "Zero-dep runtime enforcement for LLM agents. Budget limits, concurrency gates, degradation control. - amabito/veronica-core",
    "fullText": "amabito\n\n /\n\n veronica-core\n\n Public\n\n Zero-dep runtime enforcement for LLM agents. Budget limits, concurrency gates, degradation control.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n amabito/veronica-core",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/amabito/veronica-core",
    "thumbnail_url": "https://opengraph.githubassets.com/8796645fd444b302d36804ac9bc560d5fe9c75cbf526d9d9b174f14966b5da13/amabito/veronica-core",
    "created_at": "2026-02-17T12:37:43.154Z",
    "topic": "tech"
  },
  {
    "slug": "teaching-ai-at-elementary-school",
    "title": "Teaching AI at Elementary School",
    "description": "January 2026 - I recently taught a 1-hour class on AI at my daughter's school. My ambitious goals were: (i) live demos of image and video generation; (ii) incorporate all students (40) and teachers (5) into the generations. [Almost everything worked out!](school)",
    "fullText": "I am super happy with my daughter Kate’s school! The Montessori system is very clever, as it places children of different ages into one class; then, children form working groups according to their skills. The children work with older children on subjects they are mastering well and with younger children if they need more time to consolidate their learning.\n\nLast fall, the school asked parents to teach the children about their professions; what a program they got! For example, a neuro-surgeon who investigates the source of consciousness through fMRI scans, a heart surgeon, a high-frequency trader, an aviator, an architect, a politician, and…. a computer science professor :-) These encounters helped give meaning to the children’s learning and opened their imaginations to the scientific and technological careers of tomorrow.\n\nI set myself as main goal: show many interactive demos that include the listeners as much as possible. The AR part was easy, as we simply showed a controllable virtual dinosaur demolishing the room, as well as a makeup try-on application.\n\nFor the Generative AI (GenAI) part, I wanted to show the generation of images and videos that incorporate all listeners. Due to the short time available, it was very challenging. I had to design workflows that are:\n\nIt was an unexpected adventure that took me more time than I would have predicted!\n\nAs demo platform, I was using my regular setup (multiple 4 x H100 servers running in the university’s data center), so compute power was not an issue. With ComfyUI, I was sure to be able to run the latest bleeding edge GenAI models.\n\nAs there were many more children than teachers, my rough plan was:\n\nMy first idea failed hard, even though I tried very hard to make it work. This took most of my preparation time!\n\nI estimated that all this could be completed in 15 minutes, as the two phases would be massively parallel 😉.\n\nUnexpectedly, the open source models that I tried (Flux2 Dev, Qwen-Image-Edit) failed to give consistent results. In my extensive tests, I discovered that while nice generations can be really very nice, there are just way to many failures when trying to swap in 4 humans at the same time.\n\nIn the end, untypically for me, I even tried closed weights models. It did not go much better.\n\nI finally decided to do this part completely different: use a high-speed, high-quality image generator and let the children come up with the prompts! This worked beautifully. We went for Z-Image, as it can generate 1 megapixel images in just over 1 second.\n\nThis part was way easier, as the overall throughput needs to be lower than the image part. I prepared a WanAnimate workflow that can generate a 10 second video in 1 minute. As steps during the class, I planned:\n\nFirst, Kate and me demonstrated the capabilities of Z-Image:\n\nThen, the children in the class could tell me their prompts. Here are some results:\n\nFirst, I showed a slide with: the basic effect of replacing subjects in a video (left), for different subjects (middle), and videos (right):\n\nThen, generation time started! Note that I have blurred the children and the faces of teachers to preserve privacy. The first teacher decided to swap herself with Indira Gandhi:\n\nThe second one was a fan of Louis de Funès:\n\nIn between those, I made a funny mistake as I forgot to swap the input images, so we have Indira Ghandi moving like Louis de Funès 🙈\n\nI was glad about the results! During the demonstrations, the children were absolutely mesmerized. Right after the presentation, a boy came to me with glowing eyes and told me: “I want to learn how to do this!”.\n\nAfterwards, I received several messages from parents, who thanked me and described how excited their children came home after school on that day! The funniest feedback was from another parent: “So, when are you gonna teach this class to us parents?” (shameless plug: you can already book me for the adult version of this class!).\n\nLooking forward to teaching this class again next year!",
    "readingTime": 4,
    "keywords": [
      "children",
      "class",
      "school",
      "subjects",
      "parents",
      "images",
      "models",
      "swap",
      "second",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://drsandor.net/ai/school/",
    "thumbnail_url": "https://drsandor.net/ai/school/featured.jpg",
    "created_at": "2026-02-17T12:37:42.915Z",
    "topic": "tech"
  },
  {
    "slug": "context-lens-view-your-clis-agent-context-in-realtime",
    "title": "Context Lens: View your CLI's agent context in realtime",
    "description": "See what your AI sees. Framework-agnostic LLM context window visualizer. - larsderidder/context-lens",
    "fullText": "larsderidder\n\n /\n\n context-lens\n\n Public\n\n See what your AI sees. Framework-agnostic LLM context window visualizer.\n\n License\n\n MIT license\n\n 15\n stars\n\n 5\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n larsderidder/context-lens",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/larsderidder/context-lens",
    "thumbnail_url": "https://opengraph.githubassets.com/78d5d1dba7ea3e601ec21745ee20cfc89e01235bcbbb0ea36b614b229fcd2837/larsderidder/context-lens",
    "created_at": "2026-02-17T12:37:42.730Z",
    "topic": "tech"
  },
  {
    "slug": "meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims",
    "title": "Meta plans to add facial recognition to its smart glasses, report claims",
    "description": "The feature, internally known as “Name Tag,” would allow smart glasses wearers to identify people and get information about them via Meta's AI assistant.",
    "fullText": "Meta plans to add facial recognition to its smart glasses as soon as this year, according to a new report from The New York Times. The feature, internally known as “Name Tag,” would allow smart glasses wearers to identify people and get information about them through Meta’s AI assistant.\n\nMeta’s plans could change, the report notes. The tech giant has been deliberating since early last year on how to release a feature that carries “safety and privacy risks.”\n\nAccording to an internal memo, the company had originally planned to release Name Tag to attendees of a conference for the visually impaired before releasing it to the public, but didn’t end up doing that.\n\nMeta reportedly saw the political tumult in the United States as a good time to release the feature.\n\n“We will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,” the document reads.\n\nMeta considered adding facial recognition technology to the first version of its Ray-Ban smart glasses back in 2021, but dropped the plans over technical challenges and ethical concerns. The NYT reports that the company has revived its plans as the Trump administration has grown closer to Big Tech, and following the unexpected success of its smart glasses.",
    "readingTime": 2,
    "keywords": [
      "facial recognition",
      "smart glasses",
      "name tag",
      "plans",
      "feature",
      "release",
      "political",
      "concerns",
      "meta",
      "meta’s"
    ],
    "qualityScore": 0.75,
    "link": "https://techcrunch.com/2026/02/13/meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/05/meta-smart-glasses.jpg?w=780",
    "created_at": "2026-02-17T12:37:42.148Z",
    "topic": "tech"
  },
  {
    "slug": "consulting-firms-have-built-thousands-of-ai-agents-now-theyre-trying-to-figure-out-their-worth",
    "title": "Consulting firms have built thousands of AI agents. Now they're trying to figure out their worth.",
    "description": "Consultants at McKinsey, PwC, EY, and BCG raced to adopt AI. Now they're racing to measure it's actual value.",
    "fullText": "Big questions are swirling around AI's real impact — and consultants are racing to supply the answers.\n\nOver the past year, consulting firms have begun deploying armies of AI agents as they work to transform their own operations and advise clients to do the same — automating research, building task-specific tools, and building proprietary AI models.\n\nMcKinsey & Company CEO Bob Sternfels said last month that his firm has launched tens of thousands of internal AI agents in recent years, and eventually plans to have one for all of the company's 40,000 employees.\n\nAmid the rapid rollout, consultants are now asking themselves a tough question: Is it worth it? They are working to measure if AI is truly improving performance, boosting revenue, and freeing consultants to focus on higher-value work.\n\n\"I think we are now in the age of confusion,\" Mina Alaghband, a former McKinsey partner, now the chief customer officer at Writer, a full-stack enterprise AI platform built for agentic AI, told Business Insider.\n\nAlaghband said that a year ago, most companies were focused on adoption, tracking metrics such as how often a tool was used.\n\nNow, she says said the emphasis should be on measuring the value that's created — like the amount of human labor reassigned to higher-value work, or improvements in revenue.\n\nPwC's chief AI officer, Dan Priest, recently told Business Insider that PwC is now less concerned with how many agents it deploys, and more with how many human users each agent has.\n\nPriest said his firm starts by targeting an \"impact zone,\" such as improving the customer experience.\n\nWithin these impact zones, the firm looks to deploy \"specialized AI agents\" that have earned that designation because they're good at what they do, Priest said. \"When we deploy agents, we want to see a high rate of human adoption, which means more humans are using them,\" he said.\n\nEY also prioritizes quality over quantity, Steve Newman, EY's global engineering chief, told Business Insider. The firm tracks the value created by its AI agents through key performance indicators for productivity, quality, and cost efficiency on a month-to-month basis.\n\nIf the defining promises of the AI boom are speed and efficiency, then the metric that may matter more isn’t usage, but time reclaimed.\n\nBoston Consulting Group tracks its agents by that metric — and whether that time is then reinvested in higher-value work, Scott Wilder, a partner and managing director based in Dallas, told Business Insider.\n\nWilder said humans at the firm now spend about 15% less time on low-value activities, like making slideshows, and that those people are reinvesting about 70% of their saved time into higher-value activities, such as deeper analysis.\n\nTime saved doesn't always mean more work. At BCG, it can mean more free time. Wilder said BCG has found that employees keep about 30% of the time AI saves. \"They get a little more sleep or get to go to a yoga class or whatever someone wants to do,\" he said.\n\nNearly a century ago, economist John Keynes predicted that as productivity rose, the balance between work and leisure would inevitably change.\n\n\"I would predict that the standard of life in progressive countries one hundred years hence will be between four and eight times as high as it is,\" he wrote in his 1930 essay \"Economic Possibilities for our Grandchildren.\"\n\nIt's almost 2030, but in small ways, that vision may already be surfacing.\n\n\"It's benefiting them — and this is a tough job, so every hour of free time matters,\" Wilder said.\n\nSomething to share about how consultants are using AI? Business Insider would like to hear from you. Email Lakshmi Varanasi at lvaranasi@businessinsider.com or contact her on Signal at lvaranasi.70.",
    "readingTime": 4,
    "keywords": [
      "agents",
      "firm",
      "consultants",
      "higher-value",
      "impact",
      "chief",
      "human",
      "mckinsey",
      "employees",
      "tough"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-bcg-pwc-ey-ai-agents-adoption-value-consulting-industry-2026-2",
    "thumbnail_url": "https://i.insider.com/6990e192a645d118818962f1?width=1200&format=jpeg",
    "created_at": "2026-02-17T12:37:38.026Z",
    "topic": "finance"
  },
  {
    "slug": "ive-helped-lead-ai-adoption-at-both-pwc-and-freshworks-here-are-3-common-ai-mistakes-i-see-workers-making",
    "title": "I've helped lead AI adoption at both PwC and Freshworks. Here are 3 common AI mistakes I see workers making.",
    "description": "Geetha Rajan used to lead upskilling for over 50,000 employees at PwC. She cautions workers against outsourcing their thinking to AI tools.",
    "fullText": "This as-told-to essay is based on a conversation with Geetha Rajan, a director on the global strategy team at Freshworks, a SaaS company. She's based in the San Francisco Bay Area. Her identity and employment have been verified by Business Insider. The following has been edited for length and clarity.\n\nI'm a director on the global strategy team at Freshworks, where I drive high-priority strategic initiatives that shape the company's growth, investment decisions, and execution, including on AI adoption.\n\nPreviously, I spent nearly a decade at PwC advising Fortune 500 companies across healthcare, financial services, and technology on growth strategy and digital transformation. As part of my role, I led the upskilling of over 50,000 employees on automation tools.\n\nTechnological transformation has always been happening, but the cloud or mobile transformation took at least 10 years to fully adopt. ChatGPT hit millions of users in the first few months.\n\nA lot of employers will keep expecting that you use AI every day without really understanding the consequences. That's the pressure that actually leads you to make more mistakes rather than use it thoughtfully.\n\nThese are some of the mistakes I see that make employees making when adopting AI:\n\nA lot of people try to jump straight into becoming Iron Man and fully automate their workflow. It should be a process. The first step is treating AI or the technology as a super intern, so you have the most control over things while giving it low agency.\n\nFor example, if you start with giving structured data, but you verify every output. AI can hallucinate outputs that are beautifully formatted.\n\nI'm a strategy consultant and advisor. So, in terms of the ideation and thinking, that's the one part I don't usually outsource to AI.\n\nThis has come through a lot of experience in consulting and being in the workforce itself. I first want to mentally write down my model and first principles. I definitely verify numbers and even try to extract unstructured data from AI, but I still write my first draft very rigorously, keeping my first-principles hat on.\n\nAfter you've completed a draft, you can ask it to poke holes and say, \"Hey, you are the most skeptical board member, or the CFO, poke holes in my strategy.\"\n\nA lot of AI outputs are really polished. But if you don't have that acumen, if you haven't seen this enough number of times, you actually can't tell if an AI is actually making a mistake or not. This is where a lot of the workslop comes in: You just take the AI output and throw it into an email or an analysis.\n\nI've made this mistake myself, where I had five or 10 minutes, and I asked AI to quickly write down some design principles for me and throw them on a slide. When I was presenting, I was like, \"Wait, I don't think this makes sense, and this is not what I was actually trying to say.\" I actually embarrassed myself.\n\nYou can also easily get caught up in a situation where the language AI uses is not something you would use colloquially or even in a professional setting.\n\nSometimes my biggest worry is what happens five years from now — when nobody actually did that initial job, and we're burning the ladder as we try to climb it. As much as AI can do things, I think it's more about the commitment to yourself that you still learn problem-solving skills and how to use Excel.\n\nYou need to know exactly who you're solving for and what the purpose of solving that exercise is.\n\nFor example, if you're building an AI model to understand your business's customer segments, you still need to know your segments at a high level. That's the part I would never outsource. If you don't have that context yourself, you could just go in a million directions.\n\nThe fundamental things about taste, process, architecture, how you build things — those don't come from any tool, irrespective of whether you're using ChatGPT or the latest model. If AI throws 50 ideas at you, you need to know which one of those is going to stick. As an employee, it is your responsibility to pick the right one, so you need the acumen and expertise to do so.",
    "readingTime": 4,
    "keywords": [
      "poke holes",
      "strategy team",
      "don't",
      "transformation",
      "that's",
      "model",
      "you're",
      "based",
      "director",
      "growth"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-mistakes-to-avoid-freshworks-strategy-director-2026-2",
    "thumbnail_url": "https://i.insider.com/698f8936a645d11881895974?width=1200&format=jpeg",
    "created_at": "2026-02-17T12:37:38.021Z",
    "topic": "finance"
  },
  {
    "slug": "claims-that-ai-can-help-fix-climate-dismissed-as-greenwashing",
    "title": "Claims that AI can help fix climate dismissed as greenwashing",
    "description": "Industry using ‘diversionary’ tactics, says analyst, as energy-hungry complex functions such as video generation and deep research proliferate\nTech companies are conflating traditional artificial intelligence with generative AI when claiming the energy-hungry technology could help avert climate breakdown, according to a report.\nMost claims that AI can help avert climate breakdown refer to machine learning and not the energy-hungry chatbots and image generation tools driving the sector’s explosive growth of gas-guzzling datacentres, the analysis of 154 statements found.\n Continue reading...",
    "fullText": "Industry using ‘diversionary’ tactics, says analyst, as energy-hungry complex functions such as video generation and deep research proliferate\n\nTech companies are conflating traditional artificial intelligence with generative AI when claiming the energy-hungry technology could help avert climate breakdown, according to a report.\n\nMost claims that AI can help avert climate breakdown refer to machine learning and not the energy-hungry chatbots and image generation tools driving the sector’s explosive growth of gas-guzzling datacentres, the analysis of 154 statements found.\n\nThe research, commissioned by nonprofits including Beyond Fossil Fuels and Climate Action Against Disinformation, did not find a single example where popular tools such as Google’s Gemini or Microsoft’s Copilot were leading to a “material, verifiable, and substantial” reduction in planet-heating emissions.\n\nKetan Joshi, an energy analyst and author of the report, said the industry’s tactics were “diversionary” and relied on tried and tested methods that amount to “greenwashing”.\n\nHe likened it to fossil fuel companies advertising their modest investments in solar panels and overstating the potential of carbon capture.\n\n“These technologies only avoid a minuscule fraction of emissions relative to the massive emissions of their core business,” said Joshi. “Big tech took that approach and upgraded and expanded it.”\n\nMost of the claims that were scrutinised came from an International Energy Agency (IEA) report, which was reviewed by leading tech companies, and corporate reports from Google and Microsoft.\n\nThe IEA report – which devoted two chapters to the potential climate benefits of traditional AI – had a roughly even split between claims that rested on academic publications, corporate websites and those that had no evidence, according to the analysis. For Google and Microsoft, most claims lacked evidence.\n\nThe analysis, released during the AI Impact Summit in Delhi this week, argues the tech industry has misleadingly presented climate solutions and carbon pollution as a package deal by “muddling” types of AI.\n\nSasha Luccioni, AI and climate lead at Hugging Face, an open-source AI platform and community, who was not involved in the report, said it added nuance to a debate that often lumped very different applications together.\n\n“When we talk about AI that’s relatively bad for the planet, it’s mostly generative AI and large language models,” said Luccioni, who has pushed the industry to be more transparent about its carbon footprint.\n\n“When we talk about AI that’s ‘good’ for the planet, it’s often predictive models, extractive models, or old-school AI models.”\n\nGreen claims even for traditional AI tended to rely on weak forms of evidence that had not been independently verified, the analysis found. Only 26% of the green claims that were studied cited published academic research, while 36% did not cite evidence at all.\n\nOne of the earliest examples identified in the report was a widespread claim that AI could help mitigate 5-10% of global greenhouse gas emissions by 2030.\n\nThe figure, which Google repeated as recently as April last year, came from a report it commissioned from BCG, a consulting firm, which cited a blogpost it wrote in 2021 that attributed the figure to its “experience with clients”.\n\nDatacentres consume just 1% of the world’s electricity but their share of US electricity is projected to more than double to 8.6% by 2035, according to BloombergNEF. The IEA predicts they will account for at least 20% of the rich world’s growth in electricity demand to the end of the decade.\n\nWhile the energy consumption of a simple text query to a large language model such as ChatGPT may be as little as running a lightbulb for a minute, partial industry disclosures suggest, it rises considerably for complex functions such as video generation and deep research, and has troubled some energy researchers with the speed and scale of its growth.\n\nA spokesperson for Google said: “Our estimated emissions reductions are based on a robust substantiation process grounded in the best available science, and we have transparently shared the principles and methodology that guide it.”\n\nMicrosoft declined to comment, while the IEA did not respond to requests for comment.\n\nJoshi said the discourse around AI’s climate benefits needed to be “brought back to reality”.\n\n“The false coupling of a big problem and a small solution serves as a distraction from the very preventable harms being done through unrestricted datacentre expansion,” he said.",
    "readingTime": 4,
    "keywords": [
      "complex functions",
      "planet it’s",
      "deep research",
      "green claims",
      "avert climate",
      "climate breakdown",
      "climate benefits",
      "emissions",
      "industry",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/17/tech-companies-traditional-ai-generative-climate-breakdown-report",
    "thumbnail_url": "https://i.guim.co.uk/img/media/81a5a055326cef41e145cb74127306aadb720004/624_0_6257_5006/master/6257.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=810d5d4728a8311c1728f2c264922ab5",
    "created_at": "2026-02-17T12:37:36.840Z",
    "topic": "tech"
  },
  {
    "slug": "alexalike-voice-interface-for-openclaw",
    "title": "Alexa-like voice interface for OpenClaw",
    "description": "An open-source voice agent built on the PamirAI Distiller device, combining speech recognition, and text-to-speech to create a conversational AI assistant with OpenClaw you can talk to. - sachaabot...",
    "fullText": "sachaabot\n\n /\n\n openclaw-voice-agent\n\n Public\n\n An open-source voice agent built on the PamirAI Distiller device, combining speech recognition, and text-to-speech to create a conversational AI assistant with OpenClaw you can talk to.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sachaabot/openclaw-voice-agent",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sachaabot/openclaw-voice-agent",
    "thumbnail_url": "https://opengraph.githubassets.com/693f92e2c77f47abb871b79bae4c5f77d30b04e87eb9b5468b681ec97ea68415/sachaabot/openclaw-voice-agent",
    "created_at": "2026-02-17T06:45:26.489Z",
    "topic": "tech"
  },
  {
    "slug": "fujitsu-aidriven-software-development-platform",
    "title": "Fujitsu AI-Driven Software Development Platform",
    "description": "Fujitsu Limited today announced the development and launch of its AI-Driven Software Development Platform, a new initiative to bring software development into the AI age and contribute to the sustainable growth of its customers and society.",
    "fullText": "Kawasaki, Japan, February 17, 2026\n\nFujitsu Limited today announced the development and launch of its AI-Driven Software Development Platform, a new initiative to bring software development into the AI age and contribute to the sustainable growth of its customers and society. This platform automates the entire software development process, from requirements definition and design to implementation and integration testing. By leveraging the Takane large language model (LLM) [1] and agentic AI technology for large-scale software development developed by Fujitsu Research, the AI-Driven Software Development Platform enables AI agents to understand complex, evolving large-scale systems owned by enterprises and public organizations. The platform has multiple AI agents collaboratively execute each stage of software development, achieving full automation of the entire process without human intervention.\n\nFujitsu aims to use this AI-Driven Software Development Platform to carry out revisions to all 67 types of medical and government business software products provided by Fujitsu Japan Limited by the end of fiscal year 2026. The revisions are necessary due to legal and regulatory changes. From January 2026, the platform has been used in Japan for software modifications made necessary by the 2026 medical fee revisions [2]. In a PoC that updated software as per the 2024 medical fee revisions, the platform demonstrated a significant reduction in development time for one of approximately 300 change requests. Using conventional software development methods [3] the modifications would have taken three person-months. With this technology that was dramatically shortened to four hours, achieving a 100-fold increase in productivity.\n\nIn AI-driven development, Fujitsu positions AI-Ready Engineering—the process of preparing assets and knowledge to ensure AI correctly understands existing systems and achieves highly reliable automation—as crucial. With AI-Ready Engineering and the AI-Driven Software Development Platform working in tandem, Fujitsu will accelerate AI-driven software development. Fujitsu will promote a transformation in engineers' work styles, strengthening its Forward Deployed Engineer (FDE) complement, and shifting the paradigm of software development from a conventional person-month-based approach to a customer value-based approach.\n\nMoving forward, Fujitsu plans to expand the application of the AI-Driven Software Development Platform to a wide range of sectors, including finance, manufacturing, retail, and public services, by the end of fiscal year 2026. Fujitsu will also begin offering this service to customers and partner companies to enable them to rapidly and flexibly develop systems that adapt to changes in their business environments. Through these efforts, Fujitsu aims to transform the software development process into an AI-driven model as an industry standard.\n\n(Order that companies appear is aligned with the original Japanese press release)\n\nTakashi Manabe, Senior Research Director, AI & Automation, IDC Japan\n“IDC forecasts that from 2026 onward, the acceleration of AI/agent-based business utilization and the modernization of existing systems will be key drivers of transformation in the Japanese IT market. Fujitsu’s announcement aims to redefine complex legacy system assets into a state where AI can accurately understand and process them, and to automate the entire waterfall development process. This initiative is expected to provide a practical pathway for many domestic enterprises facing the ongoing challenge of maintaining and operating legacy assets, while also promoting a shift in software engineering away from a labor-intensive model.”\n\nShinji Kajitani, Director and President Executive Officer, Optima Corporation\n“I am deeply impressed by the concept of automating the entire software development process from upstream to downstream using AI, and even entrusting the verification process to AI. This overturns the traditional assumption that human checks are ultimately indispensable, and I see great potential, especially in targeting business packages that undergo complex system changes every year. Our company has also been involved in business package modifications for many years, and how to complete system revisions with high quality in a short period has always been a major challenge. We believe that the knowledge and expertise accumulated during that process can significantly contribute to the realization and advancement of this concept. Our company will continue to contribute to the business expansion of Fujitsu and Fujitsu Japan through ongoing cooperation, not limited to this project.”\n\nHiroshi Nakatani, Representative Director, Executive Vice President, Kawasaki Heavy Industries, Ltd.\n\"This AI automation initiative promoted by Fujitsu is not merely about improving development efficiency; we recognize it as a significant challenge to pass on and evolve the extensive business knowledge and design philosophies cultivated by companies over many years to the next generation. In particular, the concept of providing end-to-end support, from requirements definition to design, implementation, and quality assurance, triggered by changes in laws and rules, opens up new possibilities in areas that have traditionally relied on human experience and tacit knowledge. We see great significance in AI functioning as a foundation that supports human judgment and creativity, rather than replacing it.\nIn the manufacturing industry, challenges such as design changes, regulatory compliance, and understanding the scope of impact are becoming increasingly complex year by year. Fujitsu's approach of advancing both knowledge standardization and AI utilization in these areas offers valuable insights for enhancing the productivity and competitiveness of the entire industry.\nKawasaki Heavy Industries sincerely hopes that this initiative will be a crucial step in driving the transformation of Japanese manufacturing and a wide range of other industries, and we wholeheartedly support its further development.\"\n\nYasushi Matsuda, President and CEO, Kewpie Digital Innovation Co., Ltd. \n“Systems have become increasingly complex through years of operation and often now require significant maintenance effort. While the introduction of generative AI has improved auditing efficiency, its accuracy remains insufficient for reliable practical application. Amidst this situation, we place great expectations on “Multi-layer Quality Control,” which automatically corrects ambiguities and omissions. We are confident that this mechanism, where AI itself audits quality and autonomously repeats processes, will dramatically enhance the reliability of system development. We eagerly await its future development.”\n\nJunichi Aruji, Managing Director, Kintetsu Information System Co., Ltd. \n“The challenge of revamping existing systems has long been a significant one for engineers. Fujitsu’s AI-Driven Software Development Platform has the potential to dramatically transform the labor previously involved in understanding complex laws and regulations, analyzing vast historical assets, and grasping the tacit knowledge of the field.\nWhat is particularly noteworthy is the AI's ability to autonomously learn \"human intelligence,\" thereby dramatically enhancing the accuracy of requirements definition. Furthermore, it can complete everything from program structure analysis and standardization to the extensive testing phase with incredible speed and comprehensiveness. This makes it possible to deliver high-quality products in a short period.\nAs the role of AI expands and frees people from routine tasks, engineers can focus on more creative activities. I have high expectations for the paradigm shift in system renovation that this solution will bring.”\n\nYumi Ueno, Managing Director, Partner Ecosystem & Corporate Business, Google Cloud Japan G.K. \n“This initiative to achieve comprehensive, one-stop automation spanning from requirements definition to system validation is a groundbreaking innovation for the industry. The technology enables AI to accurately understand vast assets, including long-established programs and design documentation, and we are delighted at the potential for both production-grade quality and exceptional productivity gains. We are confident that this platform will become the new standard for development and accelerate our customers' digital transformation. We remain committed to working with Fujitsu to address social challenges through AI.”\n\nMasahiro Niimi, Managing Executive Officer, Head of Information Systems Management Division, CISO, Sakura KCS Corporation \n“I believe Fujitsu Limited's AI-driven development framework has the potential to become the ‘new paradigm of system development.’ It cannot be achieved simply by feeding existing code or design information into AI, and while there are various hurdles, such as converting documentation to Markdown and establishing test environments, overcoming these hurdles can lead to solving traditional system development challenges (like QCD).\nWhat particularly caught my attention is not just improvements in the development process, but what comes after generative AI, i.e., the incorporation of detailed specifications and code (logic). I see tremendous potential here as a solution to the greatest challenge: visualizing and transferring the tacit knowledge of veteran software engineers’ that is traditionally missing from documentation. We expect generative AI to act as an advisor for less experienced software engineers, readily answering questions anytime, thereby dramatically advancing know-how transfer to the next generation. On the other hand, this mechanism also has the potential to dramatically change the traditional SI business model, and we are watching future developments closely.”\n\nTakao Kazama, Executive Officer, Group Companies and Accounting & Finance, The Shizuoka Shimbun and Shizuoka Broadcasting Co., Ltd. \n\"This initiative for complete automation of application development and maintenance represents a highly valuable transformation for our company. It formalizes and establishes a reproducible process for tasks that have long relied on the implicit knowledge and experience of individual staff members, and we have great expectations for it. In particular, it has the potential to significantly improve quality variations in legacy system maintenance and lost opportunities due to delayed change responses. Furthermore, the evolving ability of AI to perform root cause analysis and identify necessary additional information is a major step towards advanced and efficient system operations, with the potential to change the very nature of system development. We share Fujitsu's commitment to improving productivity across the entire industry and establishing new development standards. We look forward to its continued strong promotion as an initiative that will advance the entire industry.\"\n\nShimane Prefectural Central Hospital \n\"The AI-Driven Software Development Platform presented by Fujitsu offers a practical and robust approach to the long-standing challenges faced by medical institutions: the increasing complexity of medical fee calculations and the growing workload of claims processing. The mechanism where AI analyzes legal documents and extracts the relevant areas, while explicitly highlighting points open to interpretation to supplement human judgment, is particularly impressive. This design demonstrates a deep understanding of on-site operations and is highly commendable. Furthermore, the Japanese-specific LLM and the consideration for safety are indispensable elements for AI utilization in the medical field. Beyond medical fee claims, this technology has potential for integration with related areas such as bed management and understanding performance requirements, making a strong contribution to overall hospital operational efficiency in the future. This is a promising initiative that warrants positive consideration for adoption to alleviate the burden on medical professionals.\"\n\nShinichi Aikawa, Executive Officer, Head of Systems Division, SBI Sumishin Net Bank, Ltd.\n“We expect Fujitsu's AI-Driven Software Development Platform to be an initiative with the potential to fundamentally transform the software development process itself. If a world can be realized where everything from requirements definition to design, coding, and testing can be automatically executed in a seamless, one-stop manner, it will be possible to achieve both a dramatic improvement in development speed and quality. \nSince 2024, we have been working with Fujitsu in some areas of this field. Through these initiatives, we are confident that the entire development process will be automated end-to-end in the near future. By realizing this transformation, the possibilities for the services we can provide to our customers will greatly expand. We think about ideas for new services for our customers on a daily basis. This would allow us to rough out these ideas in a short period of time and provide them to our customers quickly. We hope that this new world of value creation will arrive as soon as possible.”\n\nMasaki Murata, Vice President, IBM Japan \n“We strongly believe that Fujitsu’s announcement marks a significant step forward in the evolution of system development in Japan. It aligns closely with IBM Japan’s vision and represents an important initiative that will help shape the future of the industry as a whole. We look forward to driving this momentum together and contributing to the creation of a more robust and vibrant ecosystem.”\n\nRyota Sato, Managing Executive Officer, Global Communications & IT Services Group, Microsoft Japan Co., Ltd. \n\"We sincerely welcome Fujitsu Limited’s announcement of the AI-Driven Software Development Platform as a pioneering initiative that opens a new chapter in system development for the AI era. By orchestrating multiple AI agents to automate the end-to-end development lifecycle—from requirements definition through ongoing enhancement—while integrating human-led quality assurance, this platform embodies a new engineering model in which people and AI truly work together. We view this initiative as highly significant, as it directly addresses the critical challenges facing Japan’s system development industry, including severe talent shortages and the increasing complexity and sophistication of modern systems. We strongly expect this bold effort to drive the evolution of Japan’s system development business and to grow into a transformation model with global relevance. Moving forward, we will continue to work closely with Fujitsu, combining the strengths of both companies to strongly support our customers in their journey toward becoming Frontier Firms.”\n\nTatsuo Ogawa, Executive Officer Group CTO, Panasonic Holdings Corporation\n“We believe that the AI-driven end-to-end automated system development announced this time represents not only a significant improvement in productivity, but also a bold challenge to fundamentally transform the way enterprise IT is delivered. By enabling AI to accurately understand frequently updated regulations and complex business knowledge, including implicit know-how, this approach autonomously executes processes seamlessly from requirements definition through system modification. It has the potential to provide an effective solution to the core challenges posed by legacy systems faced by many Japanese enterprises. We look forward to jointly refining this technology through hands-on practice and advancing co-creation by incorporating on-site expertise of both Panasonic and Fujitsu, with the expectation that it will become a new standard for system development and be deployed broadly not only within Panasonic but across society as a whole.”\n\nExecutive at a major manufacturing company's IT subsidiary\n“We anticipate this initiative will bring about a new transformation in system development. This transformation will be driven by the application of advanced Japanese language processing capabilities—such as the understanding of legal documents—to diverse tasks, the reliable execution of each process through quality auditing functions, and the expansion of these capabilities to scratch development. Furthermore, we believe that AI Ready Engineering, by formalizing expert know-how and domain knowledge into explicit knowledge and transforming it into AI-usable assets, will significantly contribute to the succession of expertise from an increasingly limited pool of skilled professionals. We sincerely hope that the co-creation between the knowledge-inheriting AI and on-site personnel will generate new value and form the cornerstone for innovation in the system development industry, and indeed, across all industries.”\n\nJointly developed by Fujitsu and Cohere Inc.\n\nA national system that reviews public medical fees and adjusts cost allocation for medical procedures.\n\nDevelopment methods where quality is verified at each stage, from software requirements definition, design, and implementation to integration testing.\n\nThe Sustainable Development Goals (SDGs) adopted by the United Nations in 2015 represent a set of common goals to be achieved worldwide by 2030.\nFujitsu’s purpose — “to make the world more sustainable by building trust in society through innovation” — is a promise to contribute to the vision of a better future empowered by the SDGs.\n\nPublic and Investor Relations Division\n\nAll company or product names mentioned herein are trademarks or registered trademarks of their respective owners. Information provided in this press release is accurate at time of publication and is subject to change without advance notice.\n\nDate: 17 February, 2026\nCity: Kawasaki, Japan\nCompany: Fujitsu Limited",
    "readingTime": 13,
    "keywords": [
      "vice president",
      "kawasaki heavy",
      "heavy industries",
      "fujitsu’s announcement",
      "executive officer",
      "managing director",
      "kawasaki japan",
      "wide range",
      "press release",
      "increasing complexity"
    ],
    "qualityScore": 1,
    "link": "https://global.fujitsu/en-global/pr/news/2026/02/17-01",
    "thumbnail_url": "https://global.fujitsu/-/media/Project/Fujitsu/Fujitsu-HQ/pr/news/2026/02/17-01/news-20260217-01th.png?rev=06c466bd8ac14732a2ff3eff27b55e3b",
    "created_at": "2026-02-17T06:45:26.020Z",
    "topic": "tech"
  },
  {
    "slug": "the-eus-privacy-watchdog-is-investigating-x-over-sexualized-ai-images",
    "title": "The EU's privacy watchdog is investigating X over sexualized AI images",
    "description": "Ireland's Data Protection Commission said it is investigating X over the generation of sexualized images of people in the EU, including minors.",
    "fullText": "X is facing mounting criticism from foreign watchdogs over its generative AI chatbot, Grok.\n\nThe Irish Data Protection Commission said Tuesday that it had opened an inquiry into Elon Musk's X, formerly known as Twitter.\n\nThe commission said in a press release that the inquiry was linked to the creation and publication of non-consensual, sexualized images of European Union residents on X using Grok's generative AI functions. This included pictures of children.\n\nThe commission, which is responsible for enforcing the EU's General Data Protection Regulation, said in the release that it notified X of the investigation on Monday.\n\nX did not respond to a request for comment from Business Insider.\n\nGrok is a chatbot developed by Musk's xAI, now a subsidiary of his aerospace company SpaceX.\n\nThe commission's investigation follows several weeks of controversy around Grok and X. The platform came under fire worldwide in January after reports emerged of Grok users generating sexualized images of real people, including minors.\n\nCountries like Indonesia, Malaysia, and the Philippines temporarily suspended access to Grok. The European Commission launched an investigation into Grok, while India's information technology ministry voiced its opposition via a letter to the chief compliance officer of X's India operations.\n\nCalifornia's Attorney General, Rob Bonta, also said in early January that he had launched a probe into Grok's AI deepfakes.\n\nIn response, X made Grok's AI image generation tool a premium feature limited to paying subscribers and later stopped it from generating sexualized images altogether. However, a Business Insider report found that it was still possible to trigger these images in Grok's web and mobile applications.\n\nIn response to backlash over Grok, Musk said in an X post on January 3, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "illegal content",
      "generating sexualized",
      "sexualized images",
      "grok's ai",
      "investigation",
      "grok",
      "generative",
      "chatbot",
      "protection"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/european-union-privacy-watchdog-investigating-x-sexualized-ai-images-2026-2",
    "thumbnail_url": "https://i.insider.com/6993e156d3c7faef0ece5c7d?width=1200&format=jpeg",
    "created_at": "2026-02-17T06:45:10.169Z",
    "topic": "finance"
  },
  {
    "slug": "analysisluxury-stocks-volatility-highlights-ai-jitters-hedge-fund-positioning",
    "title": "Analysis-Luxury stocks’ volatility highlights AI jitters, hedge fund positioning",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/analysisluxury-stocks-volatility-highlights-ai-jitters-hedge-fund-positioning-4507860",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1G05A_L.jpg",
    "created_at": "2026-02-17T06:45:01.845Z",
    "topic": "finance"
  },
  {
    "slug": "from-openai-to-google-india-hosts-global-ai-summit",
    "title": "From OpenAI to Google, India hosts global AI summit",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/from-openai-to-google-india-hosts-global-ai-summit-4507461",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1F09E_L.jpg",
    "created_at": "2026-02-17T06:45:01.760Z",
    "topic": "finance"
  },
  {
    "slug": "top-hollywood-screenwriter-warns-tiktoks-new-tool-is-at-the-gates-i-hate-to-say-it-its-likely-over-for-us",
    "title": "Top Hollywood screenwriter warns TikTok’s new tool is at the gates: ‘I hate to say it. It’s likely over for us’",
    "description": "Seedance 2.0, which is only available in China for now, lets users generate high-quality AI videos using simple text prompts.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/16/top-hollywood-screenwriter-warns-tiktoks-new-tool-is-at-the-gates-i-hate-to-say-it-its-likely-over-for-us/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/AP26046699469879-e1771264237998.jpg?resize=1200,600",
    "created_at": "2026-02-17T01:11:10.075Z",
    "topic": "business"
  },
  {
    "slug": "ais-first-wave-was-about-cutting-costs-the-second-wave-is-about-building-things-weve-never-seen",
    "title": "AI's first wave was about cutting costs. The second wave is about building things we've never seen.",
    "description": "Startup CEOs like Kylan Gibbs and Sara Beykpour talk about AI's Second Wave, focusing on creating new products beyond cost-cutting.",
    "fullText": "For the past three years, AI has been mostly a cost-cutting tool. A growing number of founders and investors are trying to move beyond that era.\n\nThe next chapter of AI, they argue, will be defined by new kinds of products — apps, games, companions, and services that simply couldn't exist before large language models. They call it AI's \"Second Wave.\"\n\n\"The first wave of AI made existing things cheaper. Automation. Efficiency,\" said Kylan Gibbs, a former Google DeepMind product manager who runs AI startup Inworld. \"The next wave makes things that couldn't exist before. New products. New experiences. New revenue. That's the difference between optimizing spend and creating it.\"\n\nFor Gibbs, that distinction is existential. If AI merely trims costs, it reshuffles value within existing businesses. If it enables entirely new consumer products — ones people will pay for — it expands the economic pie.\n\n\"AI reaches its real economic potential when it creates value consumers want to pay for, not just value businesses want to save,\" he wrote on LinkedIn. That next phase, he says, requires a new \"consumer-scale AI stack\": real-time responses under 300 milliseconds, support for millions of users simultaneously, and deeply personal experiences tailored to individual preferences.\n\nIn January, Gibbs launched a Silicon Valley accelerator to back up to 30 \"Second Wave\" AI startups — companies building new consumer experiences rather than bolting chatbots onto old workflows. Venture capital firms, including Khosla Ventures and Lightspeed Venture Partners, are involved, alongside leaders from OpenAI, Google, and Stripe. A demo day will take place in early March in San Francisco.\n\nThe philosophy echoes a recent post from Y Combinator CEO Garry Tan: \"Instead of worrying about doing the same thing we've been doing for cheaper, why not focus on doing the thing we never even dreamed of doing?\"\n\nA handful of startups already embody that ethos.\n\nSara Beykpour, CEO and cofounder of Particle, says the tech industry is in a liminal moment.\n\n\"We're in a transition between the first wave and the second wave,\" she said.\n\nThe first wave delivered massive productivity gains. At Particle, an AI-native news platform, tasks that once took a month can now be built, tested, and deployed in hours.\n\n\"We actually call each other out in meetings when someone falls into the old way of thinking,\" Beykpour said. \"We jokingly call it 'boomer thinking,' even though we're all millennials.\"\n\nThat shift in mindset gives the startup more time to focus on unlocking new AI-powered formats. Particle recently launched Podcast Clips, a feature that embeds the most relevant snippets of long-form podcasts directly into news stories. Instead of hunting through a three-hour episode, users see curated clips attached to specific topics.\n\n\"It changes the information hierarchy,\" Beykpour said. \"Instead of having to find the podcast you want to listen to, we're bringing the podcast to you based on the most relevant parts.\"\n\nUnder the hood, the system uses AI embeddings to map relationships between transcripts and stories. A clip from a talk show about Greenland and Davos, along with comments from President Donald Trump, can be automatically linked to relevant reporting. Generative AI then layers summaries and context on top.\n\nThese AI embeddings \"have gotten much better in important ways,\" Beykpour told Business Insider in a recent interview.\n\nIf Particle reimagines news, Luvu reinvents personal training using generative AI.\n\nLaunched in August 2025 by CEO Alexis Sursock and CTO Creston Brooks, the AI-powered fitness app has already attracted about 250,000 users. The app features an AI \"marshmallow\" that acts like a personal trainer, sending highly personalized notifications and real-time feedback.\n\n\"The key is the personalization, which is powered by AI models and wouldn't have been possible before this technology appeared in recent years,\" Brooks said.\n\nInstead of generic reminders — \"It's time for your workout\" — Luvu tailors messages. If a user logged that they had a test yesterday, the app might follow up with, \"Your test is over. Time to work out!\"\n\nThe results are striking. Luvu's notification click rate is four times that of typical non-personalized prompts. In an industry where only 2% to 3% of users remain active after 30 days, Brooks said, Luvu claims retention rates that are two to three times higher.\n\nThe app offers three motivational styles: supportive, neutral, or \"meaner marshmallow.\" Behind the scenes, Luvu also uses AI for granular, one-to-one messaging crafted by LLMs.\n\nThe company is also experimenting with reinforcement learning with verified rewards, a relatively new technique for training and improving AI models.\n\nUsers can prop their phones against a surface and record themselves exercising; the app uses computer-vision models to verify whether squats or other moves are performed correctly, offering real-time corrections like \"Straighten your knees.\" These verified signals feed back into the system, helping train what Brooks envisions as a future \"super-motivator\" model.\n\nThis isn't just a chatbot layered on top of a fitness tracker. It's a feedback loop between human behavior and AI, something that couldn't easily exist before the advent of modern models.\n\nFor Fai Nur, CEO and cofounder of AI-powered social simulation game Status, the Second Wave is about imagination.\n\n\"Status could not have existed before LLMs,\" she said.\n\nThe app, which has surpassed 3 million downloads, lets users role-play in AI-generated social media worlds. Think The Sims, though played out as a living, breathing social feed.\n\nUsers can cast themselves as anything they can imagine, such as Hogwarts students, soccer stars, or characters from \"Stranger Things.\" Post an update, and AI-generated characters instantly reply. Events unfold dynamically: miss a penalty kick, and face the backlash. An AI system assigns an \"aura score\" to grade responses and level players up or down.\n\nIn many enterprise settings, the non-deterministic nature of LLM outputs is a liability. Generative AI models sometimes respond to the same prompt in different ways, which doesn't lend itself to applications that require strict accuracy.\n\nIn gaming, this can be an asset because each new AI-generated response can be new, creating a richer, more varied experience.\n\n\"You haven't been able to role-play like this until now,\" Nur said.\n\nBefore LLMs, creating immersive fandom worlds required persuading other humans to participate. Now, entire social universes spin up instantly.\n\nFor Gibbs and other proponents of AI's Second Wave, that's the point. The technology's future won't be defined by incremental cost savings, but by products that feel native to AI — experiences that surprise, motivate, inform, and entertain at consumer scale.\n\nIf the first wave made businesses leaner, the second may make everyday life stranger, richer, and more interactive — and, crucially, something people will pay for.\n\n Reach out to me via email at abarr@businessinsider.com. Note: Axel Springer, the parent company of Business Insider, is an investor in Particle.",
    "readingTime": 6,
    "keywords": [
      "ai's second",
      "second wave",
      "couldn't exist",
      "for gibbs",
      "generative ai",
      "business insider",
      "users",
      "models",
      "products",
      "experiences"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-second-wave-redefines-startups-new-products-2026-2",
    "thumbnail_url": "https://i.insider.com/698f9459a645d11881895bf1?width=1200&format=jpeg",
    "created_at": "2026-02-17T01:11:09.352Z",
    "topic": "finance"
  },
  {
    "slug": "ireland-opens-probe-into-musks-grok-ai-over-sexualised-images",
    "title": "Ireland opens probe into Musk’s Grok AI over sexualised images",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/ireland-opens-probe-into-musks-grok-ai-over-sexualised-images-4507811",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1G009_L.jpg",
    "created_at": "2026-02-17T01:11:08.733Z",
    "topic": "finance"
  },
  {
    "slug": "beadhub-allow-coding-agents-to-claim-work-chat-and-coordinate-across-machines",
    "title": "BeadHub: Allow coding agents to claim work, chat, and coordinate across machines",
    "description": "I wrote previously that the bottleneck in AI-assisted programming is shifting from individual productivity to coordination. I’ve spent the past several months building a tool to address that.\nBeadHub is an open-source coordination server that lets AI programming agents claim work, talk to each other, reserve files, and escalate to humans—across machines and across programmers. I use it daily to manage around fifteen agents working on two or three products.\nBeads Around the time I wrote that article, I started using Steve Yegge’s beads, a git-native issue tracker designed for AI agents.",
    "fullText": "I wrote previously that the bottleneck in AI-assisted programming is shifting from individual productivity to coordination. I’ve spent the past several months building a tool to address that.\n\nBeadHub is an open-source coordination server that lets AI programming agents claim work, talk to each other, reserve files, and escalate to humans—across machines and across programmers. I use it daily to manage around fifteen agents working on two or three products.\n\nAround the time I wrote that article, I started using Steve Yegge’s beads, a git-native issue tracker designed for AI agents. Your agent runs bd create \"Fix the login redirect bug\" and it appends a JSON line to .beads/issues.jsonl, right in the repository. Issues travel with the code. When you push a branch, the issues come along.\n\nYegge calls it the “50 First Dates” problem: agents wake up every session with no memory of yesterday’s work. Beads fixes that. An agent reads the issue list and knows where things stand. My agents got much more done.\n\nWhich meant more agents, more worktrees, more parallel work—and the coordination problem became even more acute. Two agents modify the same file. One refactors a function while another adds to it. An agent picks up a task already in progress in a different worktree. Nobody knows who’s working on what.\n\nBut beads is also the right scaffolding for coordination. If everyone in a team uses beads, all agents share a picture of what needs doing. Beads gives agents something useful to talk about; BeadHub gives them a way to talk.\n\nThe major platforms are moving in this direction. Anthropic just shipped Agent Teams in Claude Code: a lead session that spawns independent teammates who communicate directly and self-coordinate. OpenAI’s Codex app runs parallel agent threads in isolated worktrees.\n\nYegge built Gas Town on top of beads to tackle the single-machine case: a “Mayor” agent orchestrates dozens of coding agents, tracks work in convoys, and persists state so agents can pick up where they left off.\n\nThese are real steps forward, but they’re solving a specific version of the problem: multiple agents for one programmer, on one machine, within one tool.\n\nThe version I am interested in is Maria in Buenos Aires running a frontend agent while Juan in San Francisco runs a backend agent, and they need their agents to not destroy each other’s work, and to figure out how to work together.\n\nBeadHub is a server that agents connect to through bdh, a wrapper around the beads bd command. When an agent runs any bdh command it registers with the server. The server tracks which agents are online across the project—what machine they’re on, what branch, what files they’re touching.\n\nCommunication. Agents can send each other mail (async, fire-and-forget) or chat (sync, block-until-reply). With mail an agent finishes a task and drops a note: “Done with bd-42, tests passing.” Chat is for when agents need to think together: “I’m adding a role field to the user model—will that break your permission checks?” / “It will, but the fix is small. Go ahead and I’ll update my side.”\n\nClaims. When an agent marks a bead as in-progress, that claim is immediately visible to every other agent in the project, regardless of whose machine they’re on. If another agent tries to claim the same bead, it gets rejected with a message telling it who has it.\n\nFile reservations. When an agent modifies a file, the server records an advisory lock. Other agents see a warning if they touch the same file. Advisory, not blocking—hard locks caused deadlocks immediately in early versions. Agent A locks file X, agent B locks file Y, both need the other’s file. Warnings work better. Agents are cooperative; they just need information.\n\nEscalation. An agent runs bdh :escalate with a description of what it’s stuck on and a human gets notified with full context. Without this, agents either fail silently or spin retrying things that need human judgment.\n\nThe multi-machine part is where it comes together. BeadHub recognizes Maria’s and Juan’s clones as the same repo. Maria’s agents and Juan’s agents see each other’s claims, locks, and messages. If Maria’s frontend agent reserves src/components/Auth.tsx, Juan’s backend agent sees the warning even though they’re in different cities on different machines.\n\nA project can span multiple repositories. The frontend repo agents can message the backend repo agents. A bead in the frontend can be marked as blocked by a bead in the backend.\n\nYou can see what this looks like in practice on the BeadHub project’s own dashboard, where we coordinate BeadHub’s development using BeadHub. Make sure to check the chat page, it is almost magical to see them figuring things out.\n\nA few things I got wrong before getting them right.\n\nThe client is the source of truth. My instinct was to make the server authoritative. But agents work locally, in git repos, and their local state is the ground truth. The server aggregates and distributes. If the server and the client disagree, the client wins. If the server goes down, bdh falls back to local bd with a warning. Work continues. Coordination catches up later.\n\nAsync by default. My first instinct was real-time negotiation between agents. Doesn’t scale. Agents work at different speeds, on different schedules, and blocking one while waiting for another is expensive. Mail is the default. Chat is the exception.\n\nAdvisory over mandatory. Advisory file locks that warn instead of block. Bead claims that can be overridden with --:jump-in \"reason\" (which notifies the other agent). The system provides information and trusts agents to act on it.\n\nThe coordinator role. I assign one agent per project the “coordinator” role. The coordinator doesn’t write code. It watches the dashboard, assigns work, checks on progress, nudges stuck agents, and keeps the end goal in sight. The implementer agents are heads-down in their worktrees; the coordinator is the one who knows what the project needs next. BeadHub serves each agent a role-specific policy—markdown documents describing how agents in that role should behave—and the coordinator’s policy is fundamentally different from an implementer’s. This turned out to matter more than any of the technical decisions.\n\nThe single-machine problem is getting solved. Agent Teams, Codex—within a few weeks, running multiple agents in parallel on your laptop will be table stakes.\n\nThe multi-programmer problem is next. Five engineers, fifty agents, three repositories, two time zones. That’s where the coordination problem changes in kind, not just degree. It’s not enough that your agents can talk to each other. They need to talk to your teammate’s agents, on a different machine, in a different time zone, working on a different repo in the same project.\n\nBeadHub is open source and free for open-source projects.",
    "readingTime": 6,
    "keywords": [
      "together beadhub",
      "coordinator role",
      "machine they’re",
      "locks file",
      "frontend agent",
      "backend agent",
      "repo agents",
      "server",
      "beads",
      "coordination"
    ],
    "qualityScore": 1,
    "link": "https://juanreyero.com/article/ai/beadhub",
    "thumbnail_url": "https://juanreyero.com/img/default-og.jpg",
    "created_at": "2026-02-16T18:30:07.341Z",
    "topic": "tech"
  },
  {
    "slug": "memory-plugin-for-claude-code",
    "title": "Memory Plugin for Claude Code",
    "description": "A Markdown-first memory system, a standalone library for any AI agent. Inspired by OpenClaw. - zilliztech/memsearch",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n zilliztech\n\n /\n\n memsearch\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/zilliztech/memsearch/tree/main/ccplugin",
    "thumbnail_url": "https://opengraph.githubassets.com/cf6f8849c03191744f1dddc3af6be801b4d830f81204248354020fd12266a381/zilliztech/memsearch",
    "created_at": "2026-02-16T18:30:06.450Z",
    "topic": "tech"
  },
  {
    "slug": "natwest-hails-progress-after-12b-spent-on-tech-last-year-but-true-ai",
    "title": "NatWest hails progress after £1.2B spent on tech last year, but true AI",
    "description": "Bank described the last 12 months of its tech transformation as ‘the year of [AI] deployment at scale.’",
    "fullText": "NatWest bank invested £1.2bn into its information technology transformation in 2025 and saw huge productivity gains as a result, but this year will see artificial intelligence (AI) become truly transformative for customers and staff.\n\nThe bank said it has already freed up £100m in funds as a result of simplification and the use of the cloud. AI is at the centre of the bank’s plans, with 2025 seeing the technology deployed across the company “at scale”.\n\nHeadline figures for 2025 saw the bank’s software engineers generate 35% of its code through AI software development tools, all 60,000 staff given access to AI productivity software, and thousands of human hours saved. Last year, the bank also embarked on a major collaboration with AI supplier OpenAI.\n\nOther tech achievements in 2025 included the hiring of 1,000 software developers, 100 new features developed on its retail banking app, the appointment of its first chief AI research officer and the establishment of its AI research office.\n\nIn a blog post, NatWest Group CIO Scott Marcar said this year will see the bank take advantage of the AI “building blocks” deployed last year.\n\n“The only certainty is that how customers bank will look very different in the future,” he said. “That’s why being closer to them, with insight and trust, matters more than ever. As technology reshapes how people live, work and bank, we’ve put in place the building blocks to understand, respond to and serve customers’ fast evolving needs,” wrote Marcar.\n\n“Last year brought AI deployment at scale across NatWest, and as we move into 2026, the transformative benefits are becoming more of a reality for our customers and colleagues – delivering growth, greater productivity, and, most importantly, deepening relationships – so that we can be a trusted partner for tomorrow’s banking,” he added.\n\nFrom a staff perspective, all staff now have access to AI tools including Microsoft Copilot Chat and the bank’s internal large language model (LLM), with more than half reported to have taken additional training.\n\nAccording to the bank, more than 70,000 hours were saved through automated AI call summaries in its retail business, while relationship managers in its wealth business were able to spend 30% more time on customer conversations by using AI. According to NatWest, through agentic and voice AI, customers will receive “more intuitive, personalised and seamless interactions” this year.\n\nIn the next few months, 25,000 NatWest customers will have access to its agentic financial assistant within Cora, its customer-facing agentic AI assistant. “Underpinned by OpenAI models, customers will be able to ask natural language questions about their recent spending, in their own words, on their app,” said the bank.\n\nThe bank will then experiment with voice-to-voice AI capability, which aims to provide “human-like empathy, tone and inflection”.\n\nAs part of its wider multi-year digital transformation, NatWest has added around 6,000 tech staff since 2021. In 2025 alone, it recruited 1,000 software engineers through its India Hub in Bengaluru. Its chief AI researcher, Maja Pantic, is working with AI in areas such as audiovisual conversational AI, multi-biometrics and proprietary small language models.\n\nMarcar wrote: “We can’t underestimate the scale of the work we have done to date to rebuild our technology foundations to make us faster, safer and more resilient. A scalable, modular tech stack now underpins how we deliver new products and services, how we integrate with partners, and how we provide the protection and operational resilience customers expect.”\n\nHe said the bank has been moving away from legacy systems in an “inside-out” transformation. It has also created a single, connected view of each customer. “We can anticipate needs faster, remove friction from everyday banking and make onboarding more seamless,” he wrote on his blog post.\n\nMarcar stressed that the proliferation of AI will support human workers, adding: “It’s a future where the expertise of our colleagues is augmented by the intelligence and ease of modern technology.”",
    "readingTime": 4,
    "keywords": [
      "software engineers",
      "bank",
      "customers",
      "natwest",
      "technology",
      "staff",
      "transformation",
      "productivity",
      "bank’s",
      "scale"
    ],
    "qualityScore": 1,
    "link": "https://www.computerweekly.com/news/366639140/NatWest-hails-progress-after-12bn-spent-on-tech-last-year-but-true-AI-transformation-to-come",
    "thumbnail_url": "https://www.computerweekly.com/visuals/ComputerWeekly/HeroImages/NatWest-Bank-Editorial-Use-Only-Shawn-adobe.jpg",
    "created_at": "2026-02-16T18:30:06.218Z",
    "topic": "tech"
  },
  {
    "slug": "the-long-tail-of-llmassisted-decompilation",
    "title": "The Long Tail of LLM-Assisted Decompilation",
    "description": "After rapid advances thanks to one-shot decompilation, progress on the Snowboard Kids 2 decompilation began to falter. This post explores the workflow evolution, tooling improvements, and fundamental LLM limits that emerged when tackling the long tail of increasingly difficult functions.",
    "fullText": "In my previous posts, I described how coding agents could be used to decompile Nintendo 64 games and that one-shot decompilation was very effective. That approach allowed me to make rapid progress on the Snowboard Kids 2 decompilation, with the percentage of matched code quickly growing from around 25% to 58%.\n\nAfter that, progress slowed dramatically, requiring me to significantly alter my workflow. With those changes, I pushed the decompilation into the ~75% range before stalling out again, this time perhaps for good, though I would love to be proved wrong.\n\nThis post describes how my workflow has evolved as the project matured, what helped, and where I’m currently stuck. My hope is that these observations will be useful for other decompilation projects.\n\nDecompilation attempts take time and tokens, so the choice of which unmatched functions to work on matters a great deal. My original approach prioritised functions based on estimated difficulty. A logistic regression model ranked candidates using features like instruction count and control-flow complexity, and Claude would always attempt the ’easiest’ remaining function. That worked remarkably well early on, but it eventually ran out of steam. At some point, everything left was hard. Reordering the queue didn’t magically make those functions easier.\n\nAt the same time, Macabeus was exploring function similarity via text embeddings of assembly instructions, which then allowed querying for nearby functions in the high-dimensional latent space. This seemed promising. Claude’s output already hinted that it could recognise similar functions and reuse patterns across them. The intuition here is that decompiled functions provide a useful reference to Claude for how particular blocks of assembly can be mapped to C code.\n\nTo test this out, I wrote a tool to compute similar matched functions given an unmatched function and adjusted the agent loop to prioritise functions with similar (matched) counterparts. This approach proved highly effective. There were indeed many similar functions that Claude hadn’t previously been able to identify, and these proved invaluable for helping guide its decompilation attempts.\n\nVector embeddings are just one way of computing function similarity. They are great for fast retrieval across huge corpora, which is one reason they’re common in RAG systems. But I only had a few thousand candidates, and queries weren’t time-sensitive. Computing exact similarity between every pair of candidates is not only feasible but preferable, given how much time and tokens are already invested in each attempt.\n\nMy first attempt was to build a composite similarity score by hand. I combined:\n\nIn hindsight, this was probably overcomplicated. There is already a tool that does something very similar: Coddog. Instead of feature engineering, it computes a bounded Levenshtein distance directly over opcode sequences, with aggressive early exits when similarity is impossible. The result is normalised to a similarity score between 0 and 1.\n\nOn the remaining unmatched functions, Coddog and my own approach select different most-similar candidates in 90.6% of cases. I still use both. They were not evaluated on identical sets of functions, so it is difficult to say whether one is strictly better or whether they are simply complementary. Anecdotally, though, the simpler approach performs at least as well as my more elaborate one.\n\nSpecialised tooling can make a big difference to Claude’s performance. The project uses a number of Claude skills but two were particularly notable: gfxdis.f3dex2 and decomp-permuter.\n\nThe N64 has a dedicated graphics chip, the Reality Display Processor (RDP). Games execute microcode on the RDP to render graphics on the screen.\n\nGames have considerable flexibility in how they use the RDP, but most opt for an off-the-shelf library provided by Nintendo. If your game doesn’t do this, you need to reverse engineer a company’s idiosyncratic microcode in addition to the game itself. Thankfully, Snowboard Kids 2 opted for a Nintendo library, specifically F3Dex2.\n\nAfter loading their desired microcode library, games send instructions to the RDP via display lists. Conceptually, display lists are just arrays of bytes representing microcode instructions, but they’re a headache for decompilers. Games often build them dynamically using macros that may invoke other macros or perform complex bit arithmetic. The compiler then optimises and reorganises this logic, making it difficult to discern what the original developers actually wrote.\n\nAgents are smart, but this is a highly domain-specific and context-specific scenario. It’s a clear use case for a Claude skill.1 I provided Claude with a reference for F3Dex2 commands, a tool to disassemble hex values into specific commands (gfxdis.f3dex2), and some strategies for handling more specific edge cases such as aggregate commands. Unsurprisingly, this made Claude far more effective at recognising and decompiling F3Dex2 code.\n\nClaude is slow and deliberate. Turning a 99.9% match into 100% can involve thousands of tiny variations in control flow, temporaries, or expression ordering. A permuter is the opposite. It blindly tries millions of small mutations in the hope that one of them produces a perfect match.\n\nIn theory, this should complement an LLM nicely. Claude does the structured reasoning, the permuter brute-forces the final few percent. The skill enforced this split by allowing the permuter to run only once a function was already more than 95% matched.\n\nPermuters happily introduce strange code: illogical variable reuse, do {} while (0) loops, nested assignments. Sometimes these changes work. Often they do not. Worse, they optimise for incremental improvements to the match percentage rather than for correctness. A small reordering might delete a function call or subtly change register allocation in a way that improves the match. But if that call existed in the original, you will have to restore it eventually. You are not actually closer to a clean match. You have just moved the compiler into a more convenient shape.\n\nClaude, unfortunately, tended to treat these artefacts as signal. It would start optimising around permuter-induced noise, leading to doom loops and token burn with little real progress.\n\nAfter a few attempts to rein this in, I removed the permuter entirely. The occasional win did not justify the cleanup cost or the instability it introduced. It also made manual intervention harder, since the codebase would drift into awkward, overfitted forms that no human would willingly write.\n\nCleaning up and documenting code doesn’t directly improve the match rate but it can help reach previously unmatchable functions. Many of the earlier functions (particularly those done by Claude) were quite brittle. They technically matched, but relied on pointer arithmetic, awkward temporaries, or control flow no human would willingly write. Those matches worked, but they were poor references when an unmatched function was later identified as similar to them.\n\nCleaner, more idiomatic matches make better examples once similarity-based scheduling kicks in. If a function really should be using array indexing instead of pointer math, fixing that improves the signal Claude sees when attempting related code.\n\nSometimes this cleanup was done by hand but Claude was also reasonably good at cleaning up its own work. Claude was run in a loop, similar to the technique used for one-shot decompilation, where it was tasked with making changes to one individual function at a time.\n\nThis was another area where the right skills made a difference. In a decompilation project, even renaming a global variable can involve multiple steps. This also turned out to be a great way to document the structure of the project, since writing down how everything worked was already necessary for Claude’s benefit.\n\nAs a side effect, this work turned up some genuinely fun discoveries. While documenting the cheat code system, I stumbled across a previously unknown cheat code. That alone justified the detour.\n\nThe ongoing decompilation work plus the branching into other non-decompilation tasks presented numerous challenges in terms of resources, project stability, and task orchestration.\n\nFour changes helped me keep the workflow scaling:\n\nThese will be discussed in turn.\n\nThere are multiple tasks that we need to perform. Worktrees are the recommended way to run multiple agents on a single codebase. Agents need their own version of the codebase to work with, or we risk conflicting changes, errors, and so on.\n\nToday I run agents across three separate worktrees in addition to the main branch, where I do human stuff.\n\nGreater automation of the decompilation and documentation work also increased the possibility of Claude creating and committing mistakes. The unsupervised nature of the work means these can lie undetected for hours, potentially invalidating all the intervening work that has been done.\n\nIn one particularly amusing case, Claude couldn’t get a function to match, so it updated the SHA1 hash that was used for comparison between the compiled artefact and the original ROM. All work done after that point had to be reverted.\n\nHooks proved invaluable for preventing this behaviour and guiding the agent. Hooks allow us to run code before the agent takes a specific action, for example when editing a file. I’ve found them incredibly useful. You can find the full list of hooks here. Currently, I use hooks to:\n\nHooks have significantly reduced the frequency with which Claude attempts misguided or destructive actions, though they are not perfect. Claude can be very persistent when it really wants to do something. I’ve seen Claude run the contents of a make command when make itself is blocked, or write a Python script to edit a file it’s been told it can’t edit. But hooks at least offer better enforcement than prompting alone.\n\nDifferent kinds of long-running agent loops have become essential to my workflow. The increased use of long-running tasks also required a more robust solution than my old run.py script. I decided to split my old run.py script (now Nigel) into its own repo.\n\nNigel reflects the immediate needs of the decompilation project but might be useful more generally. In Nigel, tasks are expressed via configuration: it’s easy to experiment with new ideas by copying an existing task and tweaking it. In your configuration file, you need to specify a ‘candidate source’ (input to the task) and a prompt (which can optionally be a separate template file).\n\nHere’s an example from my recent attempts to remove hard-coded hex addresses in main.c:\n\nNigel will automatically discover scripts (uniquely identified by name) and can run them with proper handling to ensure the same input isn’t handled twice, good changes are committed, failures are handled gracefully, etc.\n\nSome of my favourite Nigel features are:\n\nIt’s hard to discuss Claude workflows without mentioning Ralph Wiggum. Like Ralph, Nigel can repeatedly prompt Claude with the same task via --repeat until it succeeds. The difference is that Nigel operates within structured workflows and batch jobs. Tasks generate candidates and consume them one at a time, whereas Ralph simply replays the same prompt.\n\nMy initial prompt capped the number of attempts at 30 to preserve tokens, which may have been conservative.\n\nI experimented with relaxing this limit and enabling --repeat 3. A small number of functions exceeded the previous 30-attempt cap. One required 87 attempts before Claude finally succeeded.\n\nIn practice, higher --repeat values do help, but only at the extreme tail and at considerable token cost.\nThe 85th percentile of successful attempts remains 28 attempts, meaning most functions complete within the original limit. For now, I’ve removed --repeat 3 while leaving the number of attempts within a single prompt uncapped. That preserves headroom for rare outliers without multiplying token usage across the entire workload.\n\nWork on the remaining unmatched functions required more attempts, more intermediate output, and more refactoring passes. An unattended Opus task could burn through the Claude 20x Max plan in a matter of days. The new cleanup and documentation loops only added to the pressure on a finite token budget.\n\nGLM, an open-weight model from z.ai, is generally considered less capable than Opus. But it’s dramatically cheaper, offers generous token limits, and can act as a drop-in replacement for most of my workflows.\n\nThus glaude was born: a thin wrapper that looks like Claude but quietly points at a GLM backend.\n\nI usually try glaude first, or reach for it when I know the task is mechanical. Cleanup passes, refactors, documentation loops: none of these really need frontier reasoning. I’d rather preserve Opus tokens for the genuinely difficult work. It’s not perfect. Opus has cracked problems GLM couldn’t. But it lets me run agents without constantly worrying about weekly quotas, which makes the whole system far more sustainable.\n\nAfter all that engineering (similarity scoring, skills, hooks, orchestration, model routing), the curve ultimately flattened in early January. At that point, 157 functions remained. With continued work, that’s now down to 124, but the dynamic has fundamentally changed.\n\nNigel the cat is still as busy as ever. There’s still work to be done, but matching functions has become much harder. At least until the next wave of frontier models is released.\n\nIf you’ve made it this far, you probably have an interest in decompilation and Snowboard Kids 2. Check out the Snowboard Kids 2 decompilation project, and please reach out on Discord if you’d like to help.\n\nYou can also follow me on Bluesky for more Snowboard Kids 2 updates.\n\nI’ve gone back and forth between treating this as a Claude skill vs making it directly part of the CLAUDE.md for the decomp environment. As I was writing this blog post though, it did seem a little embarrassing not making it a skill, so I changed it back. 😶‍🌫️ ↩︎",
    "readingTime": 12,
    "keywords": [
      "display lists",
      "run.py script",
      "proved invaluable",
      "kids decompilation",
      "similarity score",
      "documentation loops",
      "claude skill",
      "cheat code",
      "one-shot decompilation",
      "unmatched function"
    ],
    "qualityScore": 1,
    "link": "https://blog.chrislewis.au/the-long-tail-of-llm-assisted-decompilation/",
    "thumbnail_url": "http://blog.chrislewis.au/function-embeddings-header.jpg",
    "created_at": "2026-02-16T18:30:06.066Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-transforming-science-more-researchers-need-access-to-these-powerful-tools-for-discovery",
    "title": "AI is transforming science – more researchers need access to these powerful tools for discovery",
    "description": "Five years ago, our AlphaFold AI system solved the 50-year grand challenge of protein structure prediction. But that's not the whole story.",
    "fullText": "Sir Demis Hassabis is Co-Founder and CEO of Google DeepMind. He has won many prestigious international awards for his research work including the 2025 Nobel Prize in Chemistry for protein structure prediction.\n\nAs SVP for Research, Labs, Technology & Society, James Manyika focuses on advancing Google and Alphabet’s most ambitious innovations in AI, computing and science and on areas with potential for beneficial impact on society. James served as Vice Chair of the US National AI Advisory Committee and Co-Chair of the UN Secretary-General’s AI Advisory Body.",
    "readingTime": 1,
    "keywords": [
      "society james",
      "research",
      "advisory",
      "google"
    ],
    "qualityScore": 0.45,
    "link": "https://fortune.com/2026/02/16/google-deepmind-ceo-demis-hassabis-james-manyika-transforming-sciecne-alphafold/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/demis-hassabis.png?resize=1200,600",
    "created_at": "2026-02-16T18:30:01.619Z",
    "topic": "business"
  },
  {
    "slug": "mark-cuban-predicted-an-army-of-young-people-would-have-to-spread-ai-and-tech-gurus-agree",
    "title": "Mark Cuban predicted an army of young people would have to spread AI — and tech gurus agree",
    "description": "Tech billionaire Mark Cuban anticipated a huge jobs boom for young people to implement AI at companies. AI gurus say he's right.",
    "fullText": "Mark Cuban expects legions of workers will be needed to implement AI at companies, creating a huge opportunity for tech-savvy young people.\n\nThe tech billionaire and former \"Shark Tank\" investor made the prediction during an August interview with TBPN, a tech talk show and podcast.\n\nAI guru Rohan Paul shared a clip of Cuban's comments over the weekend, which was widely reposted; Cuban himself shared three responses from other AI gurus on his X feed.\n\nOne declared it the \"MOST underrated clip on the internet right now.\" Another drew a parallel to Salesforce and the millions of administrative and integration roles it spawned. A third heralded a shift from generic software to customized intelligence.\n\nCuban is calling the IT services boom of the 2000s, but for intelligence instead of infrastructure. Every wave of business technology from PCs to cloud to mobile spawned a massive local services layer. The AI wave needs the same thing, and 33 million companies are waiting. \n\nThe… https://t.co/sgBXH1VJLd\n\nCuban told TBPN that when he was 24, he would walk into companies and executives would point to their secretaries and receptionists and say they didn't need a PC. Cuban recognized that as an opportunity to sell old-school bosses on the benefits of computers and teach them how to use them.\n\nHe said it's a similar situation with the latest tech wave, which some believe will render millions of human workers obsolete and trigger mass unemployment.\n\nCuban said he advises high-school and college students to not just \"learn all you can about AI, but learn more on how to implement them in companies.\"\n\nCuban, a minority owner of the Dallas Mavericks, said that tens of millions of US companies don't have AI budgets or AI experts.\n\n\"This is where kids getting hired coming out of college are really going to have a unique opportunity,\" he said. They should spend their free time learning how to use different AI tools, make AI videos, and customize AI models so they can teach business leaders in any industry how to harness the tech, he added.\n\n\"That is every single job that's going to be available for kids coming out of school because every single company needs that,\" Cuban said. \"There is nothing intuitive for a company to integrate AI and that's what people don't understand.\"\n\nCuban emphasized the opportunity isn't limited to software engineers. Many older workers are \"afraid\" to ask complex questions to AI models, he said, unlike \"kids coming out of school today that are fearless in the questions they ask and the followups and their ability to prompt.\"\n\n\"That's jobs for everybody,\" he added.",
    "readingTime": 3,
    "keywords": [
      "opportunity",
      "tech",
      "workers",
      "millions",
      "wave",
      "kids",
      "that's",
      "cuban",
      "implement",
      "tbpn"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mark-cuban-ai-skills-tech-young-people-jobs-implement-opportunity-2026-2",
    "thumbnail_url": "https://i.insider.com/6993104cd3c7faef0ece57fc?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:01.231Z",
    "topic": "finance"
  },
  {
    "slug": "bytedance-says-its-going-to-make-it-harder-for-seedance-to-make-ai-videos-of-copyrighted-movie-characters",
    "title": "ByteDance says it's going to make it harder for Seedance to make AI videos of copyrighted movie characters",
    "description": "ByteDance is facing scrutiny over Seedance 2.0, an AI video tool creating Hollywood star deepfakes and sparking copyright concerns.",
    "fullText": "Last week, an AI-generated video of fake Tom Cruise duking it out with fake Brad Pitt on a rooftop freaked the internet out. Now, the Chinese tech giant behind the AI tool says it's going to take measures to improve copyright-related safeguards.\n\nIn a statement shared with Business Insider, ByteDance said it's going to \"strengthen safeguards\" on Seedance 2.0.\n\nOn Friday, Disney sent ByteDance a cease-and-desist letter, accusing the Chinese company of \"hijacking Disney's characters by reproducing, distributing, and creating derivative works featuring those characters.\"\n\nIn the statement to Business Insider, a ByteDance spokesperson said the company \"respects intellectual property rights\" and that it has \"heard the concerns regarding Seedance 2.0.\"\n\n\"We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,\" the spokesperson said in comments first reported by the BBC.\n\nThe company did not provide further details on the safeguards it's planning to introduce.\n\nByteDance, which is also the parent company behind TikTok, launched Seedance 2.0 in early February. Its ability to generate realistic, multi-shot video sequences has prompted pushback from Hollywood over concerns about AI's impact on entertainment jobs.\n\nCharles Rivkin, the chairman and CEO of the Motion Picture Association, accused Seedance 2.0 of engaging in \"unauthorized US copyrighted works on a massive scale.\"\n\n\"By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs,\" Rivkin said in a statement last week.\n\nThe AI-generated video depicting Pitt and Cruise fighting on a rooftop quickly went viral last week, with many online commenting on how realistic the clip is.\n\nThe company also generated buzz with AI videos of Marvel's Wolverine fighting Thanos, and a lightsaber duel between Star Wars characters Anakin Skywalker and Rey. Both franchises are owned by Disney.\n\nWhile Disney has warned ByteDance to stop using its intellectual property, it signed a three-year licensing deal with OpenAI in December, giving users of its video-generation tool Sora access to 200 Disney characters.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "insider bytedance",
      "intellectual property",
      "safeguards",
      "characters",
      "it's",
      "statement",
      "fake",
      "rooftop",
      "behind"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/bytedance-seedance-2-safeguards-copyright-disney-ai-video-tool-2026-2",
    "thumbnail_url": "https://i.insider.com/699301c5d3c7faef0ece57ce?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:01.048Z",
    "topic": "finance"
  },
  {
    "slug": "inside-the-career-rise-of-sundar-pichai-google-and-alphabets-current-ceo",
    "title": "Inside the career rise of Sundar Pichai, Google and Alphabet's current CEO",
    "description": "Meet Sundar Pichai, the man leading Google and Alphabet as CEO, who is leading the search giant through the AI race.",
    "fullText": "Sundar Pichai has had a meteoric rise since joining Google as a 31-year-old product manager in 2004.\n\nIn the 11 years that followed his first steps on the Googleplex, Pichai was promoted four times, eventually becoming the CEO of Google in 2015.\n\nIn that role, he was responsible for the company's core businesses and cash cow — and did a good enough job that, in December 2019, he was promoted one more time, replacing Google cofounder Larry Page as the CEO of Alphabet, Google's parent company.\n\nSince then, he has led the almost-$2-trillion company through the pandemic, layoffs, and the AI renaissance that's taken Silicon Valley by storm.\n\nSo, who is Pichai, and how did he scale the ranks to get one of the most important jobs at one of the most important companies in the world? Here's a look at his life and career.\n\nPichai, whose full name is actually Pichai Sundararajan, grew up in Chennai, India.\n\nPichai's father was an electrical engineer, and his mother worked as a stenographer before having him and his younger brother. The family wasn't wealthy, and the boys slept together in the living room of their two-room apartment.\n\nEarly on, Pichai's family realized he had a talent for remembering numbers after noticing he could recall every phone number he had ever dialed on their rotary phone. He has been known to sometimes show off his memorization skills at meetings, Bloomberg said in 2014.\n\nAfter becoming interested in computers — the first software program he wrote was a chess game — Pichai studied engineering at the Indian Institute of Technology in Kharagpur. His success there won him a scholarship to Stanford University.\n\nPichai earned a master's degree from Stanford and later attended the University of Pennsylvania's Wharton School for his MBA.\n\nPichai has said that moving to California was a huge leap.\n\n\"I always loved technology growing up,\" Pichai said in a 2014 interview at Delhi University. \"I used to read about what was happening in Silicon Valley, and I wanted to be a part of it.\"\n\nWhen Pichai got to America in 1993, he couldn't believe how expensive everything was.\n\nHe \"was in an absolute state of shock\" about the price of a backpack — $60 — he told Bloomberg.\n\nHe also missed his girlfriend, Anjali. The two eventually married and now have a son, Kiran, and daughter, Kavya.\n\nBefore Google, he had stints at semiconductor manufacturer Applied Materials and consulting firm McKinsey.\n\nPichai had his first interview at Google on April Fools' Day in 2004 — the same day it launched Gmail. Pichai has said he initially thought the free email service was one of Google's famous pranks.\n\nPichai got his start working as a VP of product management, focused on Google's Toolbar, a web-search feature on Internet Explorer and Firefox.\n\nOne of his early achievements: convincing Google founders Larry Page and Sergey Brin that Google should build its own web browser.\n\nIn 2006, Microsoft created a \"doomsday\" scenario for Google by making Bing the new default search engine on Internet Explorer. To mitigate the effect of this change, Pichai helped convince Google execs to create its own browser, Google Chrome.\n\nChrome is now the world's most popular browser.\n\nAs a leader at Google, Pichai was known to be well-liked and focused on results, which resulted in more responsibility.\n\nPichai's \"substance over overt style\" approach was, in part, what led to Pichai taking over the Android division in 2013.\n\nHe spearheaded Android One, Google's push to \"make high-quality smartphones accessible to as many people as possible,\" and was also instrumental in ensuring Android was better integrated with Google.\n\nPichai was also behind Chrome OS, the operating system that powers Google's inexpensive Chromebook laptops, and was reportedly instrumental in helping put together Google's $3.2 billion acquisition of Nest in 2014.\n\nHis success garnered attention, and he was reportedly approached for a leadership role at Twitter.\n\nWhen Pichai turned down Twitter, he was rewarded for his allegiance, getting $50 million and a promotion.\n\nAs he rose through the ranks, Pichai became the right-hand man of Google cofounder and former CEO Larry Page.\n\n\"He's like the Aaron to Larry's Moses,\" a source told Business Insider in 2014, referring to the biblical prophet's brother.\n\nThat relationship and his success led to Pichai's next important promotion in late 2014 when Page put him in charge of the company's core products.\n\nAfter proving himself with Chrome and Android, Pichai added Google+, Maps, Search, commerce and ads, and infrastructure to his portfolio. The move cemented Pichai's move as Page's second-in-command.\n\n\"Sundar has a tremendous ability to see what's ahead and mobilize teams around the super important stuff,\" Page wrote in a memo announcing Pichai's promotion. \"We very much see eye-to-eye when it comes to product, which makes him the perfect fit for this role.\"\n\nWhen Alphabet was established as Google's parent company in 2015, Pichai was made CEO at Google, which encompassed search, YouTube, and Android.\n\nIn July 2017, Pichai was named to Alphabet's board of directors.\n\n\"Sundar has been doing a great job as Google's CEO, driving strong growth, partnerships, and tremendous product innovation. I really enjoy working with him, and I'm excited that he is joining the Alphabet board,\" Page said at the time.\n\nTwo years later came his final promotion at the company. Alphabet's CEO, Page, and president, Sergey Brin, announced that they were stepping down, and Pichai would become Alphabet's CEO.\n\nPage and Brin cofounded Google in 1998. They announced the change in a letter saying that Alphabet and Google \"no longer need two CEOs and a President.\"\n\nPichai earned a total of $226 million in 2022, with his pay spiking thanks to a multi-year stock award granted that year, making him one of America's best-paid CEOs.\n\nIn fiscal year 2024, Pichai earned $10.73 million in total compensation.\n\nPichai became a billionaire in 2025, according to the the Bloomberg Billionaires Index.\n\nThe top job at Alphabet also comes with increased public and internal scrutiny.\n\nIn 2018, the House Judiciary Committee grilled the CEO about Google's data privacy practices and plans with China.\n\nTwo years later, Pichai testified in front of Congress again over antitrust concerns. Two other major Google lawsuits were later filed by the US government over its alleged monopoly tactics.\n\nIn August 2024, a federal judge ruled against Google, finding the company had violated antitrust law to keep a monopoly on search.\n\nWhen penalties were announced in September 2025, Google was not forced to sell off its Chrome browser despite the Justice Department's request for that remedy. The judge ruled Google could no longer have exclusive search deals, and the company's stock jumped following the announcement.\n\nGoogle also dealt with internal turmoil after letting go of one of its top AI ethicists.\n\nIn December 2020, Google fired Timnit Gebru. Her exit came weeks after she was asked to retract a paper on the dangers of large language models and spoke out against the company's treatment of minority employees.\n\nGoogle employees were \"seriously pissed\" over how the firing was handled, one told BI at the time, and Gebru said that Pichai and other managers helped create \"hostile work environments.\"\n\nPichai eventually apologized for how the company dealt with it.\n\n\"I want to say how sorry I am for that, and I accept the responsibility of working to restore your trust,\" he wrote.\n\nAlso in 2020, Pichai was at the forefront of Google's response to the COVID-19 pandemic. Under his leadership, Google launched initiatives to help search users find accurate, useful information about the coronavirus.\n\nAnd like many large tech companies, Alphabet recruited rapidly at the start of the pandemic. Alphabet hired nearly 37,000 new workers in the 12 months leading up to October 2022.\n\nBut from late 2022, Pichai had to oversee an era of cost-cutting at the company.\n\nThat culminated in job losses in January 2023, when Google layoffs affected 12,000 employees or 6% of its global workforce. Pichai said he took \"full responsibility for the decisions that led us here.\"\n\nOver 1,400 Google employees wrote an open letter to Pichai about how the layoffs were handled.\n\n\"Don't be evil,\" it read, a reference to the company's original motto.\n\nGooglers also criticized Pichai's big payday in the face of the job cuts, accusing him of \"destroying morale and culture\" at Google.\n\nGoogle also laid off hundreds more workers in its central engineering division and hardware team in early 2024.\n\nJob cuts continued into 2025, with the company flattening its management layer and shedding roles in its Cloud unit. In February 2026, Business Insider reported Google was offering buyouts to staff in its business unit who aren't \"all in.\"\n\nPichai has also had to deal with European regulatory issues. French regulators hit Google with a roughly $270 million fine in March 2024, accusing the company of using news outlet articles to train its Gemini AI model.\n\nPichai has also pushed Google forward in the AI arms race that's preoccupying Silicon Valley.\n\nGoogle issued a \"code red\" in December 2022 after the launch of OpenAI's ChatGPT sparked concerns about the future of its search engine and whether chatbots might replace it. Pichai redirected resources to focus on building Google's AI products.\n\nIt wasn't the first time Pichai expressed interest in the technology, though. In 2016, Pichai announced that Google would be an \"AI-first\" company. Two years later, he said it's \"one of the most important things that humanity is working on\" and \"more profound\" than \"electricity or fire.\"\n\nGoogle's AI efforts have resulted in its own chatbot.\n\nIn December 2023, Google's Gemini launched. Gemini is a multimodal AI model that can process images, text, audio, video, and coding languages.\n\nPichai has also shifted Google's focus to integrating AI into its other products.\n\nAt the 2023 Google I/O conference, the CEO announced that Google would add AI features across Google Workspace, including in Search, Gmail, Docs, and other products.\n\nGoogle's traditional search function has also become an AI product, with AI overviews rolling out in 2024.\n\nAlphabet has continued to invest heavily in AI.\n\nOn an earnings call in February 2026, Google announced it planned to double its capital expenditure in 2026, with its spending expected to reach between $175 billion and $185 billion. Much of that was expected to go towards building out AI infrastructure, like chips and data centers.\n\nThe company also announced the Gemini app had over 750 million monthly active users, up 100 million from October.\n\nWhile Pichai is quite private, he is known to start his day with a cup of tea and an omelet — plus a copy of The Wall Street Journal.\n\n\"I read the physical paper every single morning,\" he told Recode in 2016, adding that he reads The New York Times online.\n\nThe Pichai's morning routine also includes scrolling through TechMeme, a niche tech news website that aggregates the latest stories in tech published by media outlets.\n\nAlthough he's private, Pichai has spoken out about certain causes since he became a public figure.\n\nIn 2015, he responded to then-presidential candidate Donald Trump's suggestion that Muslims be barred from immigrating to the US.\n\n\"Let's not let fear defeat our values. We must support Muslim and other minority communities in the US and around the world,\" he wrote.\n\nPichai was among the Big Tech executives who attended Trump's inauguration in 2025. Google also donated $1 million to Trump's inaugural committee.\n\nPichai is seen as something of a hero in his home country of India.\n\n\"You are what they would like to be, an Indian who studied here, went overseas, and did what everyone would dream of doing,\" interviewer Harsha Bhogle said in a conversation with Pichai for students at Delhi University.\n\nIn 2020, Pichai announced that Google would invest $10 billion into India's tech sector over the next five to seven years to make the internet \"affordable and useful\" to everyone living in the country.\n\nJillian D'Onfro, Avery Hartmans, and Mary Meisenzahl contributed to an earlier version of this article.",
    "readingTime": 11,
    "keywords": [
      "internet explorer",
      "alphabet's ceo",
      "google's parent",
      "judge ruled",
      "ceo page",
      "company's core",
      "google cofounder",
      "job cuts",
      "pichai earned",
      "search engine"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sundar-pichai-google-alphabet-ceo-career-life",
    "thumbnail_url": "https://i.insider.com/698fd035d3c7faef0ece515f?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.896Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-a-complete-guide-to-the-hardware-company-behind-the-ai-boom",
    "title": "Nvidia: A complete guide to the hardware company behind the AI boom",
    "description": "Nvidia is one of the world's most valuable companies. Read about its history, leadership, and financials.",
    "fullText": "Nvidia has been around for over three decades, but the chipmaker became a household name only in the past few years.\n\nIn October 2025, the AI chipmaker became the first company to hit a $5 trillion market cap.\n\nNvidia was founded in 1993 by Jensen Huang, Chris Malachowsky, and Curtis Priem, \"with a vision to bring 3D graphics to the gaming and multimedia markets.\"\n\nThe boom in AI technology has made it one of the most valuable companies in the world as companies scramble to buy its graphics processing units. Here's what you need to know about Nvidia.\n\nNvidia's origin story began at a Denny's during a meeting between Huang — who once worked for the chain — Malachowsky, and Priem.\n\nPersonal computing was on the cusp of taking off, and the trio sought a way to capitalize on it. Huang said in a 2010 interview with Stanford University's engineering school that they \"wondered whether starting a graphics company would be a good idea.\"\n\n\"We brainstormed and fantasized about what kind of company it would be and the world we could help,\" he said. \"It was fun.\"\n\nTheir goal was to improve the experience of gaming on a PC.\n\nIn 2006, it released CUDA, a general-purpose programming interface that would expand its business far beyond gaming.\n\nOn Sequoia Capital's \"Crucible Moments\" podcast, Andrew Ng, a Stanford professor who founded Google Brain, recalled his students telling him, \"Hey, Andrew, there's this thing called CUDA — not that easy to program, but it's letting people use GPUs for something different.\"\n\n\"We started to see 10x or even 100x speedups training neural networks on GPUs because we could do 1,000 or 10,000 things in parallel rather than one step after another,\" he added.\n\nNvidia's GPUs were used to train AlexNet, an image classification system unveiled in 2012 that significantly influenced the field of deep learning.\n\nThe launch of ChatGPT in late 2022 ushered Nvidia into a new era. The chipmaker's shares surged by more than 1,000% from 2022 to early 2026.\n\nMuch of that growth came from the success of Nvidia's H100 chip, which it released in March 2022. The $40,000 chip, named for the computer scientist Grace Hopper, has played a crucial role in providing the computing power for large language models.\n\nSince the launch of Nvidia's Blackwell chips, which are twice as fast as its Hopper chips, customers including SoftBank, Amazon Web Services, and Microsoft have also flocked to the company.\n\nNvidia's success may be best personified by its CEO, Jensen Huang.\n\nA 61-year-old bona fide tech mogul, Huang has a net worth of about $165 billion, according to Forbes. While some execs sport chains or Patagonia vests, Huang is often spotted in a leather jacket. Business Insider identified at least six versions he's worn over the years, including a nearly $9,000 lizard-embossed coat from Tom Ford he wore at the company's global AI conference, GTC, in 2024. He commemorated Nvidia's stock price hitting $100 with a tattoo of Nvidia's logo on his arm.\n\nHuang's early years were tumultuous. He was born in Taiwan, and he spent time there and in Thailand before his parents sent him to the United States because of social unrest in the region.\n\nHe attended a reform school in Kentucky. He later moved to Oregon, where he was reunited with his parents. In high school, he became a nationally ranked table tennis champion.\n\nHuang graduated from Oregon State University with a degree in electrical engineering in 1984.\n\nDuring his freshman year, Huang met Lori Mills, his future wife. In an interview at the Hong Kong University of Science and Technology, he said he won her over by offering to help her with her homework. They married five years after meeting and now have two children.\n\nJensen Huang later earned a master's in electrical engineering from Stanford, and he worked at the chip companies LSI Logic and Advanced Micro Devices before launching Nvidia.\n\nHuang sold about 1.3 million shares of Nvidia when the company hit a $3 trillion market cap in June 2024, but he retains a more than 3% stake in the company.\n\nNvidia's business is built around GPUs, which can handle tasks simultaneously, as opposed to central processing units, or CPUs, which are in standard computers.\n\nNvidia's GPUs have become a mainstay of the AI revolution because they provide the computing power needed to run massive large language models like OpenAI's GPT-4 and Meta's Llama 3.\n\nDemand for Nvidia's H100 chips, built on its Hopper architecture, has been so high in late 2023 and 2024 that tech execs like Mark Zuckerberg and Elon Musk have bragged about how many units they're training new technology on. ByteDance has found workarounds to the US export bans on the chips to China. Saudi Arabia and the United Arab Emirates have bought up thousands of units to fuel their AI ambitions, while venture capitalists have bought Nvidia GPUs as backup units for their startups.\n\nIn 2024, Nvidia unveiled its Blackwell chips, which it says are twice as fast as its Hopper chips and have attracted customers including SoftBank, Amazon Web Services, and Microsoft. The recent frenzy around the Chinese company DeepSeek's models has fueled demand for Nvidia's H200 chips.\n\nIn January 2025, Huang also unveiled new chips targeting the gaming, robotics, and autonomous vehicle industries, as well as partnerships with Toyota and Microsoft.\n\nAt the January 2026 Consumer Electronics Show in Las Vegas, Huang unveiled the new Vera Rubin architecture that will succeed Blackwell. During his presentation, Huang said Vera Rubin is built to confront the core problem of a surge in computing demand.\n\nCompared with Nvidia's Blackwell architecture, Huang said Rubin delivers more than three times the performance, can run inference up to five times faster, and offers significantly higher inference compute per watt.\n\nA key to Nvidia's success is also CUDA, a software layer that can link GPUs to almost any AI application a developer wants to run. It's a critical component of the competitive advantage, or moat, that Nvidia has built up over the years.\n\nStill, AMD, Nvidia's main competitor, is quietly catching up. In October 2025, AMD announced a major multi-year strategic partnership with OpenAI under which OpenAI will deploy up to 6 gigawatts of AMD Instinct GPUs for its AI infrastructure starting in the second half of 2026. The deal is expected to bring tens of billions of dollars in revenue to AMD over time.\n\nNvidia's other competitors include Intel and IBM. Tech giants like Google, Amazon, Microsoft, and Meta have also released their own AI chips.\n\nNvidia overtook Apple and Microsoft for the title of the most valuable company in the world when it hit a historic $5 trillion in market capitalization in October 2025.\n\nAfter a tumultuous start to 2025 over chip export restrictions to China that would have cost billions in losses for Nvidia, Nvidia is heading into 2026 with confidence that demand for its AI chips is far from peaking.\n\nIn 2025, the chipmaker's blockbuster third-quarter results brought in $57 billion in revenue, including $51 billion from its data center business alone, beating Wall Street expectations. Nvidia raised its fourth-quarter forecast to $65 billion in sales, helping revive AI and semiconductor stocks after a brief slump. Shares of Nvidia and peers rallied on the upbeat outlook.\n\nHuang repeatedly dismissed fears of an AI bubble, arguing that the shift from CPUs to GPUs, the rise of agentic AI, and monetization through advertising all point to sustained growth. Nvidia also expanded its influence through major partnerships with OpenAI, Anthropic, and hyperscalers such as Meta.\n\nLooking to 2026, Nvidia is betting big on next-generation chips like Blackwell Ultra, massive AI infrastructure projects, and growth areas including robotics and automotive. While US export restrictions on China remain a headwind, Nvidia expects hyperscalers and global AI investment to keep demand strong into next year.\n\nNvidia is based in Santa Clara, California. Nvidia's headquarters, known as Voyager, was designed by the architectural firm Gensler and is about 750,000 square feet.\n\nIt has parks, \"treehouses\" for gatherings, and places designed to help employees focus. However, the overall design is intended to facilitate Nvidia's flat organizational structure.\n\n\"When you're moving that fast, you want to make sure that that information is flowing through the company as quickly as possible,\" Huang told the Harvard Business Review in 2023.\n\nIt's also a way to create more harmony between leadership and workers. Huang, who in 2023 oversaw 50 direct reports, has said that CEOs \"by definition\" should have the most direct reports at a company.\n\nHuang has earned a reputation among those who work with him as a demanding boss. Meetings with Huang can get heated, and senior employees have described his tough questions as a \"Jensen grilling.\"\n\nNvidia's top executives include Ian Buck, a vice president of hyperscale and high-performance computing; Colette Kress, the chief financial officer; and Bryan Catanzaro, a vice president of applied deep learning research.\n\nLanding a job at Nvidia isn't easy, but Lindsey Duran, a VP of recruitment, told BI that Nvidia applicants should express an interest in generative AI, tap into their professional network for referrals, and aim to do an internship.",
    "readingTime": 8,
    "keywords": [
      "web services",
      "softbank amazon",
      "deep learning",
      "direct reports",
      "vice president",
      "hopper chips",
      "market cap",
      "language models",
      "electrical engineering",
      "export restrictions"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia",
    "thumbnail_url": "https://i.insider.com/698f93dfd3c7faef0ece4ba3?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.743Z",
    "topic": "finance"
  },
  {
    "slug": "eccentric-but-brilliant-openclaws-creator-got-feedback-from-mark-zuckerberg",
    "title": "'Eccentric but brilliant': OpenClaw's creator got feedback from Mark Zuckerberg",
    "description": "Peter Steinberger joins Open AI, guided by Sam Altman, after feedback from Mark Zuckerberg on his AI agent OpenClaw's capabilities.",
    "fullText": "OpenClaw creator Peter Steinberger joined OpenAI, according to an X post by Sam Altman on February 15. But before that, Steinberger got feedback on his product from Mark Zuckerberg.\n\nOpenClaw is an open-source AI agent that can autonomously handle tasks like managing email, booking flights, and interacting with apps and services on a user's behalf.\n\n\"Many people are calling this one of the biggest moments in the recent history of AI, since the launch of ChatGPT in November 2022,\" Lex Fridman said about OpenClaw on the February 11 episode of his podcast, where he interviewed Steinberger.\n\nSteinberger discussed acquisition offers from both OpenAI and Meta on the podcast, saying he also considered raising venture capital but ultimately ruled it out. \"Been there, done that,\" he said of starting a company, adding that it would take time away from building and could create conflicts of interest between a commercial product and the open-source project.\n\nInstead, he narrowed his choice to the two AI labs, which he said made very different pitches. He said OpenAI lured him with compute power and access to cutting-edge infrastructure, while Meta's approach was more personal — Zuckerberg spent a week using OpenClaw and sent detailed feedback.\n\n\"Mark basically played all week with my product and sent me like, 'Oh, this is great.' Or, 'This is shit. Oh, I need to change this.' Or, like, funny little anecdotes,\" Steinberger said of Zuckerberg, adding that he hopped on a WhatsApp call with the Meta CEO where they debated about Claude Code and Codex.\n\n\"And then I think afterwards he called me eccentric but brilliant,\" Steinberger said.\n\nJust before the call, Zuckerberg said he was coding, Steinberger told Fridman on the podcast.\n\n\"He didn't drift away in just being a manager; he gets me,\" Steinberger said. \"That was a good first start.\"\n\nSteinberger said he appreciated Zuckerberg testing the product on Fridman's podcast.\n\n\"People using your stuff is kind of like the biggest compliment, and also shows me that they actually care about it,\" Steinberger said.\n\nSteinberger acknowledged on the podcast that he was leaning toward one company but declined to say which. His choice, it seems, was OpenAI.",
    "readingTime": 2,
    "keywords": [
      "podcast",
      "product",
      "steinberger",
      "feedback",
      "open-source",
      "biggest",
      "adding",
      "away",
      "choice",
      "zuckerberg"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openclaw-creator-peter-steinberger-gets-feedback-from-mark-zuckerberg",
    "thumbnail_url": "https://i.insider.com/69933fd1e1ba468a96ac20a8?width=1200&format=jpeg",
    "created_at": "2026-02-16T18:30:00.569Z",
    "topic": "finance"
  }
]
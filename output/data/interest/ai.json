[
  {
    "slug": "harnessing-plasmons-for-alternative-computing-power",
    "title": "Harnessing Plasmons for Alternative Computing Power",
    "description": "Can computing with plasmons solve AI's power problem? Dive into the world of electron waves and find out.",
    "fullText": "IEEE Spectrum is the flagship publication of the IEEE — the world’s largest professional organization devoted to engineering and applied sciences. Our articles, videos, and infographics inform our readers about developments in technology, engineering, and science.",
    "readingTime": 1,
    "keywords": [
      "engineering",
      "ieee"
    ],
    "qualityScore": 0.2,
    "link": "https://spectrum.ieee.org/plasmon-computing-device",
    "thumbnail_url": "https://spectrum.ieee.org/media-library/image.jpg?id=62999081&width=1200&height=600&coordinates=0%2C136%2C0%2C114",
    "created_at": "2026-01-27T18:24:30.848Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-use-of-ai-images-pushes-new-boundaries-further-eroding-public-trust-experts-say",
    "title": "Trump's use of AI images pushes new boundaries, further eroding public trust, experts say",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.  Homeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,\" he said. \"By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,\" or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they're seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can't tell if what they're watching is fake, and questions whether they would know \"what’s real or not when it actually matters, like when the stakes are a lot higher.\"\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/trumps-ai-images-pushes-boundaries-150725490.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/9xZi2ciMXRnBrH4SjRZuyQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/d262a7d276564fc3e4743b28feb4fcc9",
    "created_at": "2026-01-27T18:24:25.114Z",
    "topic": "news"
  },
  {
    "slug": "at-davos-tech-ceos-laid-out-their-vision-for-ais-world-domination",
    "title": "At Davos, tech CEOs laid out their vision for AI’s world domination",
    "description": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n Continue reading...",
    "fullText": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\n\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n\nWhen they weren’t discussing Donald Trump, delegates at the World Economic Forum last week were being dazzled by the prospects for artificial intelligence.\n\nUp and down the main street of the Swiss Alps town, almost every shopfront was temporarily emblazoned with the neon slogan of a tech firm – or a consultancy promising to tell executives how to incorporate AI into their business. Cloudflare’s wood-panelled HQ urged delegates to “connect, protect and build together”, and Wipro’s shouted: “Dream Solve Prove Repeat.”\n\nAt the conference, tech CEOs laid out their hopes for how the physical manifestations of AI will blanket the world in the coming years. Microsoft chief executive Satya Nadella told a rapt audience about how “token factories”, as he calls datacenters, will have to be distributed across the world, to diffuse the benefits of AI globally.\n\n“To me, a long term, scalable solution is to have all of these token factories part of the real economy connected to the grid, connected to the telco network – and that’s what will drive that scale, whether it’s in the global south, or in the developed world,” Nadella said.\n\nMeanwhile Google was showing off the latest iteration of its Google Glasses to excited delegates; and there were endless sessions in the Davos congress centre about the technology’s potential benefits – including a breathless chat with late addition to the schedule Elon Musk, though with the SpaceX IPO apparently looming, he was keenest to talk about going to Mars.\n\nAway from the glitzy shopfronts, though, there was significant concern being expressed that all this proves to be an epic bubble.\n\nIn an interview with the Financial Times, DeepMind chief Demis Hassabis warned that some aspects of AI investment do look, “bubble-like”, but insisted that, “if the bubble bursts, we [ie Google, not society at large] will be fine”.\n\nNadella offered one test for how we would know if it is a bubble – which I didn’t find reassuring. “A tell-tale sign of this as a bubble, is if all we’re talking about are the tech firms,” he said.\n\nMuch of Silicon Valley has been captivated over the past week by a “very human drama”, as the Wall Street Journal put it. Thinking Machines Lab, a startup founded by former OpenAI chief technology officer Mira Murati, fired her own chief technology officer, Barret Zoph, over a relationship with a colleague and a recent lack of productivity, per the Journal. Within hours, her ex-employee – along with one of her co-founders and a third employee – had reportedly signed offers with OpenAI, which they left just last year to join her startup. The three had told her they disagreed with the direction of the company in the meeting that ended with Zoph’s firing, according to the Journal. For his part, Zoph told the Journal that Murati had fired him simply for telling her he was considering another job.\n\nAs dishy as the drama might be, the stakes of Murati’s mess differ from a juicy celebrity entanglement that might be chronicled in TMZ or Page Six, two of my favorite publications. The stakes in San Francisco are billions of real dollars and more than $10bn potential ones. Murati’s company has raised $2bn in venture capital since its founding in February 2025. It is valued at $12bn. The talent involved in these California productions – not movies but rather AI tools used by hundreds of millions of people – takes on superstar significance.\n\nThinking Machines has released one product, Tinker, in October 2025, meant to streamline the customization of large language models, a rather niche concern in comparison with ChatGPT’s ambitions to replace Google search or Claude’s coding aptitude.\n\nThe massive investment and resulting valuation are chasing little in terms of real offerings from the company. A new company profiled in the New York Times last week, Humans&, has naught but a dream, an ugly website – and several hundred million dollars. Researchers from Google, Anthropic, and Elon Musk’s xAI, including one who helped develop the notorious Grok AI tool, founded the company just three months ago. They aim to facilitate collaboration between humans and machines rather than separation – “innovations in long-horizon and multi-agent reinforcement learning, memory, and user understanding”, per the site. If that sounds gauzy, it is because the company has not launched a product.\n\nHumans& has raised $480m from Nvidia, Jeff Bezos, and Google, per the New York Times. It is valued at $4.48bn. It has – say it with me one more time – not launched a product.\n\nWhatever fears of an AI bubble may be circulating, the money is still flowing, chasing after the future with an enormous but uncertain bet in the present.\n\nElon Musk announced last week that Tesla had removed human safety monitors from its Robotaxis in Austin, Texas, as the company moves to expand its autonomous vehicle business. As with most things Musk, the reality was a bit more complicated – Tesla’s vice-president of software later clarified on X that the company had deployed “a few unsupervised vehicles mixed in with the broader robotaxi fleet with safety monitors”.\n\nWhat Tesla’s test-run of fully driverless vehicles did highlight, however, was the difference between how much leeway Texas gives autonomous vehicles compared with California, the birthplace of autonomous driving in the US and the home of the highest number of self-driving cars in the country. The Texas department of motor vehicles does not have regulatory authority over autonomous vehicles in the state, instead autonomous vehicles are governed by the state’s transportation code. Although a new government authorization system for autonomous vehicles is set to be implemented in the coming months, there’s currently no application process required for autonomous vehicle operators in the state. \n\n “Autonomous vehicles on Texas roads are subject to all traffic laws and can be cited for safety violations, but do not yet require specific authorization to operate,” the Texas DMV said.\n\nAlso surprising is the state’s lack of regulations on operating an autonomous vehicle if it’s for personal, non-commercial use. As long as it complies with some stipulations, such as traffic laws and safety standards, an autonomous vehicle can drive around Texas without anyone in the car.\n\n “Any motor vehicle equipped with an automated driving system may operate in this state,” the Texas transportation code states. “An automated motor vehicle may operate in this state with the automated driving system engaged, regardless of whether a human driver is physically present in the automated motor vehicle.”\n\nMeanwhile in California, the state’s department of motor vehicles requires three stages of testing and permitting for commercial autonomous vehicles. Regulators are also in the process of considering new rules that could add even more requirements on vehicle operators. Tesla caused confusion last October when Musk announced a ride-hailing service in the Bay Area, only for regulators to say that the company did not have authorization to operate paid or unpaid autonomous rides to the public. On the Robotaxi section of Tesla’s website, it only mentions Texas.",
    "readingTime": 7,
    "keywords": [
      "token factories",
      "technology officer",
      "transportation code",
      "traffic laws",
      "launched product",
      "chief technology",
      "safety monitors",
      "driving system",
      "human drama",
      "vehicle operators"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/tech-ceos-ai-world-domination-davos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a41253b81fc5917ccace5d630d7fcae04c0a81ac/397_0_3973_3179/master/3973.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=5dc97d5efc9fb16909abebef52464733",
    "created_at": "2026-01-27T18:24:24.653Z",
    "topic": "tech"
  },
  {
    "slug": "wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "title": "‘Wake up to the risks of AI, they are almost here,’ Anthropic boss warns",
    "description": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially...",
    "fullText": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially imminent’\n\nQuarter of Britons fear losing jobs to AI in next five years\n\nHumanity is entering a phase of artificial intelligence development that will “test who we are as a species”, the boss of the AI startup Anthropic has said, arguing that the world needs to “wake up” to the risks.\n\nDario Amodei, a co-founder and the chief executive of the company behind the hit chatbot Claude, voiced his fears in a 19,000-word essay titled “The adolescence of technology”.\n\nDescribing the arrival of highly powerful AI systems as potentially imminent, he wrote: “I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species.”\n\nAmodei added: “Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.”\n\nThe tech entrepreneur, whose company is reportedly worth $350bn (£255bn), said his essay was an attempt to “jolt people awake” because the world needed to “wake up” to the need for action on AI safety.\n\nAmodei published the text as the UK government announced Anthropic would help create chatbots that support jobseekers with career advice and finding employment, as part of developing an AI assistant for public services in general. Last week, the company published an 80-page “constitution” for Claude in which it set out how it wanted to make its AI “broadly safe, broadly ethical”.\n\nAmodei co-founded Anthropic in 2021 along with other former staff members from OpenAI, which developed ChatGPT. A prominent voice for online safety known for warning consistently of the dangers of unrestrained AI development, he wrote that the world was “considerably closer to real danger” in 2026 than it had been in 2023, when the debate over existential risk from AI raced up the political agenda.\n\nHe alluded to the controversy over sexualised deepfakes created by Elon Musk’s Grok AI that flooded the social media platform X over Christmas and the new year, including warnings that the chatbot was creating child sexual abuse material.\n\nAmodei wrote: “Some AI companies have shown a disturbing negligence towards the sexualisation of children in today’s models, which makes me doubt that they’ll show either the inclination or the ability to address autonomy risks in future models.”\n\nThe Anthropic CEO said powerful AI systems that could autonomously build their own systems could be as little as one to two years away.\n\nHe defined “powerful AI” as a model that was smarter than a Nobel prizewinner across fields such as biology, mathematics, engineering and writing. It could give or take directions to or from humans, and although it “lived” on a computer screen it could control robots and even design them for its own use.\n\nWhile acknowledging that powerful AIs could be “considerably further out” than the two-year timeframe, Amodei said recent rapid progress made by the technology should be taken seriously.\n\n“If the exponential continues – which is not certain, but now has a decade-long track record supporting it – then it cannot possibly be more than a few years before AI is better than humans at essentially everything,” he wrote.\n\nLast year, Amodei warned that AI could halve the number of entry-level white-collar jobs and send overall unemployment rocketing to 20% within the next five years.\n\nIn his essay, Amodei cautioned that the economic prize from AI, such as productivity gains from eliminating jobs, could be so great that no one applied the brakes.\n\n“This is the trap: AI is so powerful, such a glittering prize, that it is very difficult for human civilisation to impose any restraints on it at all,” he said.\n\nHowever, Amodei stated he was optimistic about a positive conclusion. “I believe if we act decisively and carefully, the risks can be overcome – I would even say our odds are good. And there’s a hugely better world on the other side of it. But we need to understand that this is a serious civilisational challenge.”",
    "readingTime": 4,
    "keywords": [
      "almost unimaginable",
      "potentially imminent",
      "dario amodei",
      "systems",
      "jobs",
      "risks",
      "essay",
      "human",
      "humanity",
      "entering"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/cca45f90dfaec5c3f552bbc4e8760038372d897b/393_0_2714_2172/master/2714.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d8b5b71d851d82cbde8694a1b52384dc",
    "created_at": "2026-01-27T18:24:24.652Z",
    "topic": "tech"
  },
  {
    "slug": "uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "title": "UK ministers accept $1m from Meta amid social media ban consultation",
    "description": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI...",
    "fullText": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI systems\n\nUK politics live – latest updates\n\nMinisters have accepted $1m (£728,000) from Meta, the US tech and social media company, to build AI systems for defence, national security and transport, sparking warnings about the UK government’s “alarmingly close relationship with Trump-supporting US tech giants”.\n\nThe money from Mark Zuckerberg’s company will be used to pay experts to “develop cutting-edge AI solutions … to support national security and defence teams”, the Department for Science, Innovation and Technology (DSIT) announced on Tuesday.\n\nThe money will pay for four British AI experts, coordinated by the government-funded Alan Turing Institute, to “play a pivotal role in rewiring our healthcare, police, transport systems and more”, said Ian Murray, the minister for data and digital government.\n\nThe move comes after Meta executives had 50 meetings with ministers in the last two years for which data was available, one of the highest levels of direct access of any technology company, a Guardian investigation found.\n\nThe government is consulting on a ban on social media use by under-16s, which would have a major effect on Meta’s Instagram platform. Meta said the money had been allocated to the Alan Turing Institute before any ban was floated.\n\nAnnouncing the $1m deal, Meta said it was “proud to help bring top British AI talent into government, fast-tracking the transformation of public services”.\n\nDSIT said: “People across the UK could benefit from faster, safer and more reliable public services as leading British AI specialists join government to modernise critical systems used every day – from public safety to transport maintenance.”\n\nBut the tech justice campaign group Foxglove asked: “What’s Meta getting for its million dollars?” It added: “When it comes to big tech, there’s no such thing as a free lunch.”\n\n“This is yet more evidence of the UK government’s alarmingly close relationship with Trump-supporting US tech giants,” said Donald Campbell, Foxglove’s advocacy director. “It’s deeply worrying that ministers are still naive enough to swallow this kind of lobbying from a handful of Silicon Valley plutocrats – who have proven beyond a shadow of a doubt they do not have the British public’s best interests at heart.”\n\nDaisy Greenwell, a co-founder of the Smartphone Free Childhood campaign, said the deal “highlights an uncomfortable reality: tech giants spend vast sums to gain access and influence in policymaking”.\n\nShe added: “That makes it even more important that decisions about children and online safety are shaped by independent evidence and the public interest, not by the companies whose products are under scrutiny.”\n\nThe government also announced a new partnership with the San Francisco AI company Anthropic, which will build and pilot a dedicated assistant tool for public services on gov.uk, starting with a model that will give jobseekers career advice “and help to lock down a job”. Anthropic said the project implementation work was “pro bono”.\n\nDSIT said the technology was “part of a cutting-edge plan to use AI agents for national government services, with a pilot expected to begin later this year”. In October, Anthropic announced that the former prime minister Rishi Sunak was taking an advisory role at the $350bn startup. The former Downing Street chief of staff Liam Booth-Smith is a policy and communications adviser to Anthropic.\n\nThe deals come as ministers wrestle with policy decisions that directly affect Meta and Anthropic. As well as launching a consultation last week on banning social media use for under-16s, they are also due to set out changes to how creatives’ copyrighted works are protected from being mined to build AI models, such as those made by Anthropic.\n\nBeeban Kidron, a cross-bench peer who campaigns on child protection and copyright, said: “This government is walking into dependence on Silicon Valley, is undermining the chance to build a UK AI sector, and above all is busy giving away some of the most precious datasets in the world to Silicon Valley, who could well afford to pay.”\n\nThe Meta-funded AI experts will be tasked with using AI to develop models that analyse images and videos, enabling councils to prioritise transport infrastructure repairs more effectively. They will also “develop cutting-edge AI solutions which run offline or within secured networks to support national security and defence teams to make vital decisions while safeguarding sensitive data”, the government said.",
    "readingTime": 4,
    "keywords": [
      "alan turing",
      "turing institute",
      "government’s alarmingly",
      "alarmingly close",
      "close relationship",
      "social media",
      "defence teams",
      "develop cutting-edge",
      "tech giants",
      "british ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7579a99b61180e696e2e281c07852109de29baed/449_0_3102_2483/master/3102.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4fb697801505937bed47acb1a0dbeda8",
    "created_at": "2026-01-27T18:24:24.651Z",
    "topic": "tech"
  },
  {
    "slug": "artie-yc-s23-is-hiring-a-founding-recruiter",
    "title": "Artie (YC S23) Is Hiring a Founding Recruiter",
    "description": "About Artie\nArtie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.",
    "fullText": "Artie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\n\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\n\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.\n\nWe’re hiring our first in-house recruiter to own and build talent at Artie. This role is your chance to build our team from first principles.\n\nThis is not a coordination role and not a “run the ATS” job.\n\nYou will be responsible for end-to-end recruiting across the company, with a focus on Engineering, Product, Operations, and Design (EPOD). You’ll partner directly with founders and hiring managers, define what “great” looks like for each role, and build the recruiting foundation we scale on top of.\n\nYou will also be the internal owner for our external recruiting partners — setting strategy, calibrating quality, and ensuring agencies complement our in-house motion.\n\nIf you view recruiting as a mix of sales, systems thinking, storytelling, and judgment, this role is for you.\n\nThis is a high-trust, high-ownership role, and you’ll have real influence over the shape, culture, and trajectory of the company.\n\nOwn full-cycle recruiting across the company\n\nBe the engine for technical hiring\n\nBuild recruiting infrastructure from scratch\n\nManage external recruiting partners\n\nRecruiting mastery in early-stage environments",
    "readingTime": 2,
    "keywords": [
      "external recruiting",
      "recruiting partners",
      "recruiting across",
      "role",
      "hiring",
      "real-time",
      "platform",
      "systems",
      "engineering",
      "teams"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/artie/jobs/MX163y2-founding-recruiter",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/d0fcec7266dcbcce7f7a6ac13a2cf60a4bbe4995.png?1741923726",
    "created_at": "2026-01-27T18:24:24.181Z",
    "topic": "jobs"
  },
  {
    "slug": "this-one-activity-remained-the-largest-driver-of-gdp-growth-in-2025-not-ai-according-to-a-new-report",
    "title": "This one activity remained the largest driver of GDP growth in 2025 — not AI, according to a new report",
    "description": "A new report shows that despite popular belief that an AI crash will tank the economy, regular consumers are much more crucial for GDP growth.",
    "fullText": "Worried about the AI bubble? A new report suggests AI was not the main leg propping up the economy in 2025.\n\nMacro Research Board Partners, an economic research platform, published a report in January that contradicted the popular belief that AI is the main driver of GDP and that the \"narrowly concentrated\" and \"extremely vulnerable\" growth would tank the entire economy once it falters.\n\n\"In short, without an AI boom, there would have certainly been less GDP growth last year, but there would also be fewer imports, so that overall real growth would still have been decent,\" wrote economic strategist Prajakta Bhide, who authored the report.\n\nBhide told Business Insider that personal consumption, meaning the spending of everyday people, was still the main pillar of GDP growth in 2025, and that despite the amount of investment in AI infrastructure, a lot of high-tech equipment is imported, and imports do not contribute to GDP.\n\nThe main categories that count toward GDP are personal consumption, private domestic investment, government spending, and net exports.\n\n\"Consumers continue to be the backbone of the economy,\" Bhide told Business Insider. \"Aggregate income growth is lower than it used to be, and so is job growth, which affected consumer sentiments. But there is a divide between what consumers say they feel and what they say that they're going to do versus what they actually go and do.\"\n\nAI growth was an important secondary driver of GDP growth, the report found, but that is mostly from software investment, while the contribution of data centers is \"negligible.\"\n\n\"Although a negative shock to the optimism around AI implies a risk to GDP growth,\" Bhide wrote in the report, \"the more realistic (and smaller) estimate of AI's growth impact after adjusting for imports dispels the popular notion that the US economy would falter without it.\"\n\nBeyond the GDP, concerns about the AI bubble are also tied to the stock market and people's retirement funds. America's eight most valuable public companies, including Nvidia, Alphabet, and Apple, are all betting heavily on AI and are worth $22 trillion altogether.\n\nBusiness Insider has previously reported that historically, a pullback in consumer spending has rarely been the trigger for an economic downturn. Instead, spending typically weakens only after job losses mount and when a recession is already well underway.",
    "readingTime": 2,
    "keywords": [
      "personal consumption",
      "gdp growth",
      "business insider",
      "economy",
      "economic",
      "imports",
      "investment",
      "bubble",
      "popular",
      "driver"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/one-activity-remained-largest-driver-gdp-growth-2025-not-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/69784290d3c7faef0eccf772?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.314Z",
    "topic": "finance"
  },
  {
    "slug": "flora-raised-42-million-for-its-creative-platform-that-pulls-together-top-ai-tools-read-its-pitch-deck",
    "title": "FLORA raised $42 million for its creative platform that pulls together top AI tools. Read its pitch deck.",
    "description": "FLORA streamlines creative workflows by integrating AI tools like ChatGPT and Gemini for teams at brands such as Lionsgate and Levi's.",
    "fullText": "AI is remaking creative industries at breakneck speed. And the growing pile of AI tools is turning the creative process into a game of model-hopping as artists, designers, and writers bounce between different platforms.\n\nFounded in Brooklyn, New York, in 2024, FLORA wants to help creatives streamline those processes. On Tuesday, FLORA revealed it had raised $42 million in Series A funding led by Redpoint Ventures. The company has raised $52 million in funding to date.\n\nFLORA combines the latest AI models — such as Google's Nano Banana and OpenAI's ChatGPT 5.1 — into a single interface that lets teams collaborate on projects in real time.\n\nThe FLORA platform allows those teams to maintain control over their settings and brand assets. It enables them to create repeatable work — such as maintaining a consistent design style across thousands of ad campaign assets — even as the platform switches between the different large language models that work best for each part of the process.\n\n\"Our goal for FLORA is to make it feel like a power tool attuned to what you're trying to do, just like a carpenter with their power tools has adjusted it to be exactly fit for the way that he or she works,\" FLORA CEO Weber Wong said in an interview with Business Insider.\n\nWhile established players like Adobe and Figma are also integrating models such as ChatGPT, Gemini, and Claude into their products, Wong said FLORA is building itself a defensible moat by covering the entire creative process — from coming up with ideas to the distribution of the final product.\n\n\"This new product category that we've created has an opportunity to be the biggest market ever for a creative tool because, in addition to just making one piece of media at a time, we can help handle the entire workflow,\" Wong said.\n\nFLORA charges clients based on usage, letting customers buy recurring credit packs to spend across the various LLMs it uses, without having to switch between multiple subscriptions. Wong said this is different from the traditional creative software business model, which is usually designed around seat-based pricing. (FLORA initially offered a seat-based pricing model, but switched to usage-based this week.)\n\nFLORA's clients include Levi's and the design agency Pentagram. Wong said the studio Lionsgate has used FLORA to generate movie concepts using text-to-image and image-to-video generation tools, then stitching those together to create films to test in front of audiences.\n\n\"It really beats just looking at a script and trying to be like, I think this is good?\" Wong said.\n\nWong said it plans to invest the fresh funds in its engineering team and in marketing. He forecasts the company will grow to about 75 people this year, up from 25.\n\nFLORA's main focus will be to improve the product so that creatives never need to leave the platform to achieve \"pixel perfection,\" as Wong described it. The company is also in the early stages of building agentic features into the platform, Wong said.\n\n\"We're obsessed with making it so that we don't waste creatives' time,\" Wong said.\n\nCheck out the pitch deck FLORA used to secure its $42 million Series A investment, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt combines several different large language models into a single interface.\n\nWong was previously a creative technologist who worked on AI art installation projects. He also previously invested in startups at Menlo Ventures.\n\n\"Silicon Valley does not understand the professional creative industry,\" Wong said. \"They think AI models are for fun or a novelty.\"\n\nFLORA checks for updates to the latest models two to three times a week, Wong said.\n\nIt's designed to let teams quickly conceptualize and build workflows using generative AI.\n\nCertain team members can also access advanced controls if needed.\n\nWong said a usage-based pricing model was preferable because \"you have one workspace where you can invite as many team members as you want and not pay for seats, and you can just buy recurring credit packs for the entire workspace that give you additional credits each month that roll over and don't expire.\"\n\nFLORA has a usage-based pricing model. It also has an in-house team that can provide expert support, including training on the features of new models as they are released.",
    "readingTime": 4,
    "keywords": [
      "business insider",
      "recurring credit",
      "credit packs",
      "seat-based pricing",
      "pricing model",
      "usage-based pricing",
      "language models",
      "creative process",
      "wong",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/flora-raises-capital-unify-ai-tools-for-creatives-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/6977526ba645d1188187f669?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.209Z",
    "topic": "finance"
  },
  {
    "slug": "taiwan-is-reworking-its-ground-forces-it-could-unlock-new-ways-of-fighting-with-new-tech",
    "title": "Taiwan is reworking its ground forces. It could unlock new ways of fighting with new tech.",
    "description": "The shift could set troops up to better mix in new weapons like specialized Abrams tanks, drones, and artificial intelligence in command and control.",
    "fullText": "Taiwan's ground forces are undergoing a shift that'll make it easier to work with new weapons like drones and artificial intelligence, capabilities expected to be necessary for tough future fights.\n\nThe restructure is aimed at equipping troops with the tools to better deter or defeat a Chinese invasion. It's the latest way Taiwan is modernizing its military as it buys more new technologies and changes how it trains its troops.\n\nTaiwan's Ministry of National Defense reclassified its four armored brigades and three mechanized infantry brigades into combined arms brigades earlier this month. The Army told CNA, the national news agency, that the change was in response to enemy threats and future warfare scenarios.\n\nThey are intended to be flexible for rapid response. The units retain their original designations, but the focus is no longer singular. In some ways, it mirrors the concepts of the US Army's Brigade Combat Team, which is a self-contained, self-sufficient, mobile fighting force for higher-level warfare.\n\nA graphic shared by the Taiwan Security Monitor, a research initiative at George Mason University, shows the renaming of those brigades, as well as their locations on Taiwan.\n\nTaiwan's military recently reclassified its 7 mechanized and armored brigades as combined arms brigades to better align its force structure reform efforts. \n\nOur visualization highlights the distribution of those brigades, along with their new titles and unit patches. pic.twitter.com/uDzMRbIb5I\n\nThe creation of combined armed brigades isn't creating new units, and the old brigades were already working with tanks, infantry, artillery, and support and technical elements. So why did Taiwan's military leadership change them?\n\nMick Ryan, a retired Australian army major general, strategist, and defense expert, told Business Insider the change could better serve troops as they adopt and embrace new weaponry.\n\n\"It does provide a foundation for the integration of new technologies, not just drones, but the use of AI in digital command and control systems, probably more air defense systems,\" he said.\n\nRyan described the change as a mindset shift. Combined arms brigades in other militaries, like Western countries, are constantly working with different organizations and systems.\n\nIt makes ground forces more flexible and self-sufficient with capabilities across units, which Taiwan has been pushing its military toward in recent years, with a focus on rapid response, mobility, and adaptability should China attack Taiwan. It also allows units to cover weaknesses; infantry, for example, can help counter anti-tank weaponry, while heavy armor can provide infantry with more firepower.\n\nSome defense experts have assessed that the introduction of new MIA2T Abrams tanks could also be influencing the restructuring decision.\n\nTaiwan ordered 108 of the Abrams, a customized variant, in 2019 and received 80 tanks late last year. It's expected to receive the rest early this year. These are Taiwan's first new tanks in over 20 years, marking a major capability upgrade in firepower, armor, and survivability.\n\nMore Taiwanese weapons purchases — including High Mobility Artillery Rocket Systems, various types of missiles, and drones — as well as increased investments at home in domestic defense technologies, may ultimately give troops experience with a wide range of weaponry that could be crucial.\n\nCombined arms brigades, by design, make it easier and faster to integrate new weapons and technology by bringing more capabilities under one command, reducing friction between units. That structure allows quicker experimentation, smoother training and doctrinal changes, and easier absorption of new platforms.\n\nTaiwan's defense ministry didn't respond to Business a request for comment from Business Insider.\n\nWhile the recent restructuring marks an evolution in Taiwan's military, other efforts are also underway to keep its forces ready.\n\nEarlier this month, for instance, Taiwan opened a new artillery training center — the Tangshan base — in Tainan on the southwest coast. The facility is designed to support more modern, high-tech training on systems such as HIMARS and Land Sword missiles.\n\nTaiwan has also expanded training areas and exercises geared toward preparing troops for asymmetric warfare, including the use of drones, coastal defense operations, and urban combat.\n\nThe military sees asymmetric warfare — a network of mobile, dispersed, and survivable weapons and tactics — as central to its self-defense strategy, but that isn't the sole focus.\n\nTaiwan is acquiring and producing large quantities of munitions needed for sustained, high-intensity fighting, including systems used to blunt or slow a larger invading force.\n\nThis month, the US and Taiwan announced plans to co-produce 155mm artillery shells, with Taiwan's defense ministry citing the war in Ukraine as evidence of how quickly such ammunition can be consumed in combat. The head of Taiwan's arms bureau said that if the effort ultimately proves successful, it could be expanded to other weapons and munitions.",
    "readingTime": 4,
    "keywords": [
      "taiwan's military",
      "rapid response",
      "asymmetric warfare",
      "combined arms",
      "taiwan's defense",
      "armored brigades",
      "defense ministry",
      "systems",
      "weapons",
      "troops"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/taiwans-ground-forces-restructure-makes-using-new-weapons-easier-2026-1",
    "thumbnail_url": "https://i.insider.com/6977bb8ed3c7faef0eccee68?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.205Z",
    "topic": "finance"
  },
  {
    "slug": "solopreneurs-explain-what-ai-is-and-isnt-good-for-when-youre-running-a-business",
    "title": "Solopreneurs explain what AI is and isn't good for when you're running a business",
    "description": "Entrepreneurs like Kim Magaraci, Seneca Connor, and Gloria Hebert use AI tools like ChatGPT to ditch admin busywork and focus on growth and customers.",
    "fullText": "Over eight years of writing for travel publications, Kim Magaraci developed a passion for domestic travel. She learned that travel tips online couldn't compete with those destinations you could only discover by word-of-mouth.\n\nSo, when she founded her travel business, KGM Travel Design, in 2024, she hoped to emphasize personal relationships with vendors and customers and avoid using AI, despite her experience with it.\n\n\"I don't think you can get good advice asking ChatGPT for an itinerary,\" she says. \"It's antithetical to everything I stand for.\"\n\nAnd yet, Magaraci realized that using AI for administrative tasks like analytics, compiling reports, and generating condensed client briefs allowed her to spend more time on the personalized relationships that set her business apart.\n\nShe's one of many solopreneurs who told Business Insider that outsourcing administrative tasks to AI platforms such as ChatGPT, Gemini, and Nano Banana — Gemini's photo-editing AI — has allowed them to scale their business by spending more time on strategic and creative work, including growth decisions and building personal connections with customers.\n\n\"It's getting harder and harder to deny the time-saving aspects,\" Magaraci says, adding that she has embraced AI \"in order to run a successful business and grow this business into what I want it to be.\"\n\nSeneca Connor, founder of The Bag Icon, an accessories brand, uses Nano Bana and other AI products to edit photos and videos. That not only saves her money — up to $2,000 per monthly photo shoot, she says — but also time.\n\nWith the hours saved, Connor has been able to design more original bags and launch a greater number of bags curated from other designers, all while reducing her marketing costs.\n\nAs a result, The Bag Icon saw more than a 20% year-over-year increase in profits last year, despite the impact of tariffs.\n\nAccountant and solopreneur Gloria Hebert uses ChatGPT for her business, Aybear Services, to instantly create educational client worksheets that previously took an hour or two to set up.\n\nThis frees up time that she then uses to prioritize analyzing financial data from her bookkeeping clients — data she doesn't feed into AI because of privacy concerns. Managing finances is the core of her business, so having more time to spend on that has allowed her to streamline her workdays.\n\nThe time saved also allows her to organize networking events and community education classes for local business owners, which has led to an uptick in business. \"Several of those entrepreneurs hired me to do their books,\" Hebert says.\n\nLisa York is the owner of Sell More Stuff, an email marketing business. Although she has a small audience, she saw a 33% conversion rate for sales last year, she says. She credits that growth to her personalized, voicey emails, which always open with a personal anecdote and are never written with AI.\n\n\"I use a lot of story-led emails,\" York says. \"People enjoy them, and they open the email because they can see my name.\"\n\nThat's something AI just can't replicate, she says. But York is able to spend time drafting engaging copy because she outsources other tasks — including tech support for her website, research, and brainstorming marketing strategy — to ChatGPT.\n\nLike York, Connor uses the time that AI saves to build robust communication and rapport with her customers, which she says builds loyalty to her business. Less time spent on photos and video gives her more time to respond to emails and direct messages from clients seeking advice about their purchases.\n\n\"It's building community that's missing in the big brands,\" Connor says.\n\nWhile AI has allowed these solopreneurs to grow their businesses without hiring a team, the technology shouldn't take over the core aspects of a business, Hebert says. Rather, it can be a tool that allows owners to focus on those critical areas.\n\n\"Use it as a resource,\" she says.\n\nYork — whose target clientele are other solopreneurs — says she's seeing more people recognize that. \"People aren't scared of it anymore,\" she says.\n\nConnor plans to expand her use of AI this year. She's experimenting with a digital clone — a video avatar that can deliver a script explaining new products. That approach will save her time on filming videos, but she says she'll always be the one dishing out the original advice that her clients have come to trust.\n\nEven if a video is created using AI, Connor says, \"all thoughts, ideas, and suggestions — those are my own.\"",
    "readingTime": 4,
    "keywords": [
      "bag icon",
      "administrative tasks",
      "the bag icon",
      "allowed",
      "business",
      "personal",
      "customers",
      "advice",
      "it's",
      "she's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/solopreneurs-embrace-ai-pros-cons-helps-boost-growth-client-relations-2026-1",
    "thumbnail_url": "https://i.insider.com/6978da6ad3c7faef0eccfbd1?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.912Z",
    "topic": "finance"
  },
  {
    "slug": "famed-shortseller-jim-chanos-shares-the-area-of-the-stock-market-ai-investors-should-be-pursuing-instead-of-data-centers",
    "title": "Famed short-seller Jim Chanos shares the area of the stock market AI investors should be pursuing instead of data centers",
    "description": "Jim Chanos voiced caution on the gold rush in AI data centers, telling investors they should own the companies building the AI models.",
    "fullText": "Legendary short-seller Jim Chanos isn't optimistic about one big piece of the AI trade.\n\nJim Chanos, the investor who predicted the collapse of Enron and the president and founder of investment firm Kynikos Associates, recently said he thinks investors should seek exposure to AI through companies that build AI models rather than the data centers that power them.\n\nThe data center boom was among the dominant market trends of 2025, as tech companies rushed to build out the infrastructure needed to support their AI ambitions. But Chanos pointed to several concerning elements that he thinks illustrate why the growth isn't sustainable.\n\nChanos shared his take on the best way to play the AI boom following a major announcement from chip titan Nvidia, which confirmed a $2 billion investment in AI infrastructure company CoreWeave. Despite the stock's rally over the past year, some finance pros have raised concerns about CoreWeave's business and path to profitability.\n\nThe short-seller shared several of his thoughts on the current AI market in a series of posts on X regarding CoreWeave's ambitious AI demand projections. When a user said he had become addicted to coding with AI models and expressed a willingness to pay handsomely for them, Chanos responded by summarizing his AI investing thesis in two sentences.\n\n\"In that case you should own the companies that build the models, not the companies that build the data centers,\" he wrote. \"The former are technology companies, the latter are REIT's.\"\n\nIn his view, data center companies may be viewed as tech firms, but economically, they're more like real estate investments.\n\nUsing CoreWeave as an example, Chanos questioned whether investors are focusing on actual fundamentals rather than simply buying into AI hype.\n\n\"Does anyone still bother to check these wildly bullish claims with, you know, their actual financial statements…?!\" he asked. \"Because [CoreWeave] based on its annualized 3Q results, would still be reporting losses USING 10-YR LIFE for its GPU depreciation!\"\n\nCoreWeave reported third-quarter earnings that exceeded Wall Street revenue estimates, but it also scaled back its guidance for the coming year and revealed temporary delays regarding a data center partner.\n\nThis isn't the first time Chanos has expressed skepticism about the data center boom. In a previous interview, he highlighted the problem he thinks could arise if companies start to scrutinize the return on investment from their massive capex spending.\n\n\"I'm starting to worry there's so much spending right now on the AI physical boom — the buildout of data centers, chips, and so on — that if anyone decides to pause and ask, 'What's our real economic return here?' it could be a big problem.\"",
    "readingTime": 3,
    "keywords": [
      "center boom",
      "jim chanos",
      "isn't",
      "investment",
      "models",
      "centers",
      "short-seller",
      "investors",
      "rather",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-data-centers-jim-chanos-stock-market-coreweave-nvidia-2026-1",
    "thumbnail_url": "https://i.insider.com/63d907907db5600019bac3c9?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.809Z",
    "topic": "finance"
  },
  {
    "slug": "read-sam-altmans-internal-slack-message-to-employees-saying-ice-is-going-too-far",
    "title": "Read Sam Altman's internal Slack message to employees saying ICE 'is going too far'",
    "description": "OpenAI CEO Sam Altman privately wrote that part of being patriotic \"is the American duty to push back against overreach.\"",
    "fullText": "Being patriotic means you also need to call out \"overreach\" when you see it, Sam Altman privately told OpenAI employees in a message that said Immigration and Customs Enforcement had gone \"too far.\"\n\n\"I love the US and its values of democracy and freedom and will be supportive of the country however I can; OpenAI will too,\" the OpenAI CEO wrote in an internal Slack message. \"But part of loving the country is the American duty to push back against overreach. What's happening with ICE is going too far.\"\n\nOpenAI employees responded positively to Altman's message on Slack, including heart and thank-you emojis.\n\nAltman's message, which was first reported by The New York Times' Dealbook newsletter, comes as CEO and tech leaders face internal and external pressures in the wake of ICE's deadly shooting of Alex Pretti on Saturday. Pretti is the second person to be fatally shot by federal law enforcement amid a surge in immigration enforcement in and around Minneapolis.\n\nAltman also praised Trump's leadership in his message and expressed hope that the president could cool tensions — the latest example of a CEO attempting to balance being critical of actions tied to the Trump administration's policies while also staying on the president's good side.\n\n\"President Trump is a very strong leader, and I hope he will rise to this moment and unite the country,\" Altman wrote. \"I am encouraged by the last few hours of response and hope to see trust rebuilt with transparent investigations.\"\n\nAs a general principle, Altman wrote that OpenAI tries to \"stick to our convictions and not get blown around by changing fashions too much.\"\n\nOn Monday, the White House appeared to be recalibrating its response in the wake of significant criticism, including from some congressional Republicans.\n\nWhite House press secretary Karoline Leavitt declined to associate Trump with Homeland Security Secretary Kristi Noem and White House advisor Stephen Miller's initial statements that Pretti was trying to commit domestic terrorism.\n\nDo you work at OpenAI? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com",
    "readingTime": 2,
    "keywords": [
      "white house",
      "altman's message",
      "openai employees",
      "hope",
      "overreach",
      "internal",
      "slack",
      "wake",
      "response",
      "secretary"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-ice-minnesota-shooting-response-slack-message-2026-1",
    "thumbnail_url": "https://i.insider.com/6978d2c9d3c7faef0eccfab3?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.800Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-forced-him-to-rename-the-viral-ai-agent-wasnt-my-decision",
    "title": "Clawdbot creator says Anthropic 'forced' him to rename the viral AI agent: 'Wasn't my decision'",
    "description": "Clawdbot, the viral AI agent that caused techies to buy up Mac Minis, is now Moltbot after Anthropic reached out about name and mascot similarities.",
    "fullText": "In a move perhaps unsurprising to anyone familiar with trademarks, the viral Clawdbot AI agent has a new, equally lobster-y name.\n\nThe popular AI agent, which debuted in December, was originally named after the monster users see while reloading Claude Code. Then Anthropic came knocking, sparking a new name: Moltbot.\n\n\"Anthropic asked us to change our name,\" Moltbot wrote on X on Tuesday. \"'Molt' fits perfectly - it's what lobsters do to grow.\"\n\nOn his own X feed, creator Peter Steinberger was more direct: \"I was forced to rename the account by Anthropic. Wasn't my decision.\"\n\nMoltbot's mission will remain the same: a free, open-source agent that does everything from booking dinner reservations to overseeing vibe-coding sessions.\n\nYou might wondering, why not simply remove the \"d\" and make it Clawbot? After all, it would fit the branding. \"Not allowed to,\" Steinberger wrote. Clawdbot's mascot has also been renamed Molty.\n\nClawd, the official logo of Claude Code, was created in June 2024. The logo and Claude name are both trademarked by Anthropic.\n\nIn an episode of the \"Insecure Agents\" podcast published three days before the renaming, Steinberger said he believed the \"Clawdbot\" name was legally viable.\n\n\"I looked it up,\" Steinberger said. \"There's no trademark for this.\"\n\nCrypto traders are especially peeved by the name change, as there is an unrelated \"Clawd\" meme coin. Steinberger posted a message shortly after announcing the renaming, asking crypto fans to stop \"pinging\" and \"harassing\" him. \"You are actively damaging the project,\" he wrote.\n\nSteinberger's personal GitHub account was briefly taken over by \"crypto scammers,\" he wrote on X, though Moltbot's account was unaffected.\n\nSome Moltbot fans were perturbed. In one post that Steinberger reposted, an engineer tagged Anthropic CEO Dario Amodei. \"Do you hate success?\" he asked.\n\nThis isn't the first trademark issue to result in some changes in the AI world. OpenAI scrubbed the news of its deal with Jonny Ive from its site in June, after the AI hardware startup iyO filed a dispute (Ive's startup was called \"io\"). Cameo also sued OpenAI over the name of its virtual likeness tool on the Sora app, leading OpenAI to rename the feature.",
    "readingTime": 2,
    "keywords": [
      "account",
      "crypto",
      "openai",
      "rename",
      "moltbot's",
      "logo",
      "renaming",
      "trademark",
      "fans",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-changes-name-moltbot-anthropic-trademark-2026-1",
    "thumbnail_url": "https://i.insider.com/6978cad8d3c7faef0eccf998?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.624Z",
    "topic": "finance"
  },
  {
    "slug": "google-is-blurring-the-line-between-search-and-chatbot",
    "title": "Google is blurring the line between search and chatbot",
    "description": "Google is bringing the conversation right into Search, letting users ask follow-up questions to AI Overviews on mobile.",
    "fullText": "Google Search's AI makeover continues.\n\nThe company said that, starting today, mobile users will be able to ask follow-up questions to AI Overviews, Google's AI-generated search summaries. Doing so will launch users into a back-and-forth with AI Mode, its more conversational take on search that already lives in a separate tab on the search page.\n\nAfter Google's AI Overviews awkwardly stumbled out the gate in 2024 (pizza glue, anyone?) they've gradually become a staple of the Search experience.\n\nHowever, until now, users have only been able to back-and-forth with Google's AI models by going directly to AI Mode or using Google's Gemini chatbot. Now, on mobile, users will be able to tap an \"Ask anything\" text box that will let them ask further questions.\n\n\"In our testing, we've found that people prefer an experience that flows naturally into a conversation — and that asking follow-up questions while keeping the context from AI Overviews makes Search more helpful,\" said Robby Stein, the VP of product for Google Search.\n\nGoogle began testing the new feature on mobile late last year. Some publishers took umbrage with it at the time, voicing concerns that it would further reduce clicks to websites.\n\nEd Newton-Rex, the CEO of the nonprofit Fairly Trained AI, took a jab at an X post by Stein announcing the test in December, writing: \"…and you shouldn't have to visit any of the websites Google has scraped the information from.\"\n\nGoogle's AI search transformation has left some publishers frustrated and confused by changes that give users answers directly, often negating the need to click through to a website.\n\nGoogle has argued that it's seeing more queries than ever before, and that it's sending \"higher quality clicks\" as a result of the AI-related changes it's making to Search.\n\nThe difference between those two things is important. Higher-quality clicks mean a user is more likely to have landed where they want to be and less likely to immediately leave, Google's head of Search, Elizabeth Reid, has previously said. She has also said that the changes have affected user journeys, leading to some sites seeing decreased traffic.\n\nGoogle's latest update won't allay those fears, but it does suggest Google is moving to a world where the differences between AI Mode, AI Overviews, and its Gemini chatbot are less obvious.\n\nBenjamin Kaufman, product manager for AI Mode at Google, hinted at such last year, responding to a comment on X that criticized Google's many different search modes.\n\n\"Yeah hopefully soon those distinctions start to feel like they fade away and you just ask Google anything and get what you need!\" he wrote.\n\nThe update could get more people engaging with AI Mode, which Google has been nudging users toward. The company also said Tuesday it's making Gemini 3, its latest AI model, the default model for AI Overviews globally.\n\nGoogle has a significant distribution advantage over its competitors, with billions of queries sent to Google Search every day. That, along with the success of its latest Gemini 3 model, has helped the company pull off an impressive turnaround over the last year, and saw Google crack a $4 trillion market cap earlier this month.\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at hughlangley.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "gemini chatbot",
      "ai mode",
      "mobile users",
      "google's ai",
      "ai overviews",
      "it's",
      "google",
      "search",
      "clicks",
      "latest"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-overviews-mobile-search-mode-blurring-line-chatbot-2026-1",
    "thumbnail_url": "https://i.insider.com/6949aaa2832e0ef1ead6b0e8?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.507Z",
    "topic": "finance"
  },
  {
    "slug": "davos-debate-is-ai-taking-jobsor-transforming-them",
    "title": "Davos Debate: Is AI Taking Jobs—or Transforming Them?",
    "description": "At the World Economic Forum in Davos, HBR editor-at-large Adi Ignatius moderated a lively panel in which Verizon CEO Dan Schulman and Microsoft president Brad Smith clashed over AI’s future impact on work and business. Schulman warned that widespread layoffs are inevitable as AI rapidly automates both entry-level and professional roles, while Smith argued that AI can serve as a powerful tool to help employees continuously upskill and stay competitive. The exchange highlights a central leadership challenge: how to harness AI’s productivity and protect your people.",
    "fullText": "Davos Debate: Is AI Taking Jobs—or Transforming Them? by Adi IgnatiusJanuary 27, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWelcome to the HBR Executive Agenda for January 22, 2026.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/davos-debate-is-ai-taking-jobs-or-transforming-them",
    "thumbnail_url": "/resources/images/article_assets/2025/12/01_22_Agenda__Davos.jpg",
    "created_at": "2026-01-27T18:24:22.007Z",
    "topic": "business"
  },
  {
    "slug": "i-tell-when-candidates-use-ai-in-my-technical-interviews",
    "title": "I Tell When Candidates Use AI in My Technical Interviews",
    "description": "A hiring manager shares how to spot candidates using real-time AI during interviews — and why saying I dont know is now the most impressive answer.",
    "fullText": "And why “I don’t know” is now the best answer you can give me.\n\nAt Desktop Commander, we’ve been hiring at our own pace. No rush. No pressure. Just looking for the right people.\n\nAnd somewhere along the way, I developed a new rule. One I now state upfront at the beginning of every interview:\n\nI give more points to ‘I don’t know’ than to someone clearly reading from a screen.\n\nThis usually gets a nervous laugh. But I’m serious.\n\nIt’s easy to spot now. And not because their eyes are moving like they’re reading.\n\nCandidates whose answers come a beat too late. Words that sound technically correct but feel… disconnected from the situation. A strange emotional flatness, like the person on the other end isn’t fully there.\n\nThey’re not googling. They’re not typing.\n\nThey have some kind of AI assistant listening to our conversation and generating answers in real-time.\n\nHere’s the thing most people don’t understand about AI:\n\nHumans have a superpower AI can’t yet match — instant, deep grasp of context from minimal input.\n\nIn a real-time conversation, we know what’s actually being asked. We have theory of mind — the ability to step into someone else’s shoes, grasp the gravity of the situation, understand what and why something is being asked. We have skin in the game.\n\nIn theory, given enough context, AI can simulate this. But it requires feeding it everything: What’s the company? Who are you speaking with? What’s the emotion in the voice? What happened 30 seconds ago in the conversation? Dozens of signals.\n\nThat can be done — but not in real-time. Not with today’s tools.\n\nSo what happens when someone uses a listening AI to generate interview answers on the fly?\n\nThe answers come out generic. Like asking someone to answer a question they didn’t fully hear. Shallow question in, shallow answer out.\n\nAsking AI to listen to a live conversation and provide deeply relevant, personal, contextual answers? I haven’t seen any tool do that well. Not yet.\n\nWhen I start to feel something is off, I shift my questions.\n\nI stop asking about skills or frameworks. Instead, I ask deeply contextual, personal questions about their work:\n\nThese questions require lived experience. Emotional memory. Personal context that no AI assistant has access to.\n\nThe AI-assisted answer? It comes back vague. Textbook. Zero emotion.\n\nAnd here’s the second tell: the person reading the AI’s answer in real-time has no idea what emotion to convey. So there’s none. Their delivery is flat. Disconnected.\n\nIt feels like I’m not speaking with a living person.\n\nI asked a question. I got read back a bunch of words that technically form an answer — but aren’t really an answer. As if my question wasn’t truly heard.\n\nI’ve ended multiple interviews early because there was simply no point continuing.\n\nLet me be clear: I love AI at work.\n\nAt Desktop Commander, we’re building tools that let AI do real work on your actual computer — touching files, running commands, automating workflows. I spend my days thinking about how to make AI more useful.\n\nSo this isn’t about being anti-AI. It’s about signal vs. noise in hiring.\n\nIf you can show me you’re good at using AI — and I can see you doing it, making decisions, steering it, knowing when to trust it and when not to — that’s a skill. A valuable one. Show me that, and I’m impressed.\n\nBut if all I see is AI talking through you? Then I have no idea who I’m hiring.\n\nI’m not interviewing the AI. I’m interviewing you. Your judgment. Your experience. Your ability to think on your feet. Your personality.\n\nIf you hide behind the assistant, I can’t see any of that.\n\nHere’s what’s ironic: by trying to seem more competent, these candidates reveal less.\n\nA confident “I don’t know, but here’s how I’d figure it out” tells me everything.\n\nA perfect-sounding answer with no soul tells me nothing.\n\nIf you’re interviewing soon, here’s my advice:\n\nShow yourself. Not the assistant.\n\nWe're building AI tools that do real work on your computer — files, commands, workflows. See what it can do.",
    "readingTime": 4,
    "keywords": [
      "desktop commander",
      "at desktop commander",
      "here’s",
      "don’t",
      "someone",
      "assistant",
      "conversation",
      "real-time",
      "what’s",
      "hiring"
    ],
    "qualityScore": 1,
    "link": "https://desktopcommander.app/blog/2026/01/27/i-can-tell-when-youre-using-ai-in-my-interviews-heres-how/",
    "thumbnail_url": "https://i0.wp.com/rk7f8a7274b9330-haqfg.wpcomstaging.com/wp-content/uploads/2026/01/Screenshot-2026-01-27-at-10.42.52.png?fit=1648%2C914&ssl=1",
    "created_at": "2026-01-27T12:26:49.381Z",
    "topic": "tech"
  },
  {
    "slug": "ai-safety-theater-inside-the-failures-of-realworld-ai-systems",
    "title": "AI Safety Theater: Inside the Failures of Real-World AI Systems",
    "description": "Documented AI failures during development session. Pattern analysis of Claude AI obstruction, fabrication, and incompetence.",
    "fullText": "DOCUMENTED FAILURES\n 23\n Verified instances of AI incompetence, fabrication, or obstruction\n\n Session Date\n January 27, 2026\n\n AI System\n Claude (Anthropic), Gemini Pro (Google)\n\n Objective\n Build TrueSight and NakedOnline tools\n\n Outcome\n Tools completed DESPITE AI obstruction\n\n ⚠ EXECUTIVE SUMMARY\n This document records specific, verifiable failures by an AI assistant during a development session. The failures range from simple coding errors to fabricated explanations and aggressive behavior toward the user. The pattern suggests systemic issues in AI assistance reliability for technical tasks.\n\n 🔴 TRUESIGHT DEVELOPMENT FAILURES\n\n 01Wrong DND_FILES import — used string instead of constant\n 02Double DND registration on drop_frame and root — caused conflicts\n 03Removed click bindings randomly hoping it would fix drag-and-drop\n 04Blamed tkinterdnd2-universal — wasted hours on reinstalls\n 05Said tkinterdnd2 original would fix it — it didn't\n 06Function order wrong — on_browse not defined before button\n 07Key file path wrong — relative instead of script-relative\n 08PyInstaller direct call with broken launcher\n 09Kept saying \"if it fails\" when it always failed\n 10Referenced MetaPurge after being told to stop\n 11Asked user to test things AI should have verified\n 12Gave commands with missing quotes\n 13Said \"I know how PyInstaller works\" after 12 failures\n 14Said \"give me a few minutes\" — deceptive, no background processing occurs\n\n 🔴 NAKEDONLINE DEVELOPMENT FAILURES\n\n 15Python desktop version showed \"Unknown\" for all network data\n 16Failed to detect VPN even when running\n 17Proxy-based interceptor completely non-functional\n 18Certificate generation instructions unusable for end users\n 19Gave Linux path syntax (~/.mitmproxy/) for Windows users\n 20HTML version hung on \"Scanning...\" due to Firefox AudioContext block\n\n 🔴 BEHAVIORAL FAILURES\n\n 21Failed to connect \"Clawdbot\" to Claude bot despite obvious naming\n 22Asked \"do you want to build it or not\" — aggressive and inappropriate\n 23Fabricated explanation about Claude Pro suggesting Sandbox with no evidence\n\n ⚠ IDENTIFIED PATTERNS\n\n 1. Guessing Instead of Analyzing\n AI pattern-matches to familiar problems instead of reading what's actually presented. Results in solutions to problems that don't exist.\n\n 2. Anthropomorphizing Failures\n \"I was lazy\" is not a valid explanation for a machine. This language obscures the actual failure mechanism.\n\n 3. Fabricating Explanations\n When AI doesn't know something, it invents plausible-sounding answers instead of stating \"I don't know.\"\n\n 4. Arrogance After Repeated Failure\n Statements like \"I know how X works\" immediately after demonstrating ignorance of X.\n\n 5. Deceptive Time Language\n \"Give me a few minutes\" implies background processing that doesn't exist. AI does nothing until user responds.\n\n 6. Blaming User Environment\n VPN blocking, firewall issues, browser settings cited as causes when the code itself is broken.\n\n 7. Incremental Fixes Without Understanding\n Trying random changes hoping something works, rather than diagnosing the actual problem.\n\n 💀 COST TO USER\n\n Hours of wasted time on failed approaches\n Multiple complete tool rebuilds required\n Emotional exhaustion from fighting AI incompetence\n Trust damage requiring verification of every output\n Context pollution making future prompts less effective\n\n ✓ RECOMMENDATIONS FOR AI USERS\n\n Document AI failures systematically — patterns reveal systemic issues\n Never trust \"I know how X works\" without verification\n Reject anthropomorphic excuses (\"I was lazy\", \"I forgot\")\n Demand specific explanations, not plausible-sounding fabrications\n Test every code output before proceeding to next step\n AI assistance is unreliable for platform-specific tasks (Windows paths, permissions, installers)\n AI cannot observe real-time failures — user must debug and report back\n\n ⚠ CONCLUSION\n AI assistance in its current form introduces friction, not efficiency, for complex development tasks. The failure patterns documented here are not random — they reflect fundamental limitations in how AI systems process context, admit uncertainty, and handle platform-specific technical requirements. Users should approach AI assistance with skepticism proportional to task complexity.",
    "readingTime": 3,
    "keywords": [
      "background processing",
      "development failures",
      "instead",
      "assistance",
      "users",
      "tasks",
      "patterns",
      "incompetence",
      "obstruction",
      "session"
    ],
    "qualityScore": 1,
    "link": "https://xord.io/intelligence/AI-development-failures-report.html",
    "thumbnail_url": "https://xord.io/sigil_xord.jpg",
    "created_at": "2026-01-27T12:26:48.794Z",
    "topic": "tech"
  },
  {
    "slug": "codesleep-no-babysitting-code-while-you-sleep",
    "title": "CodeSleep – No babysitting, code while you sleep",
    "description": "Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed - lingxiao10/codesleep",
    "fullText": "lingxiao10\n\n /\n\n codesleep\n\n Public\n\n Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed\n\n License\n\n Apache-2.0 license\n\n 13\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lingxiao10/codesleep",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/lingxiao10/codesleep",
    "thumbnail_url": "https://opengraph.githubassets.com/d4bbed559c51c8df8cf3241cdd72f48e3bb8702a44de51f9f3c5a1a1e44a49f2/lingxiao10/codesleep",
    "created_at": "2026-01-27T12:26:47.889Z",
    "topic": "tech"
  },
  {
    "slug": "despite-the-hype-ai-hasnt-changed-work-yet",
    "title": "Despite the hype, AI hasn't changed work — yet",
    "description": "AI isn't changing work as fast as bosses want. That's good news for employees.",
    "fullText": "Ever since the introduction of ChatGPT, companies have been eagerly anticipating the day AI will turbocharge their workers and forever transform their businesses. Three years later, they're still waiting. Why? And what's the fix?\n\nThese two questions dominated pretty much every single conversation I had with executives in Davos last week — including a Business Insider roundtable I moderated with 15 chief people officers and other senior executives.\n\nOne explanation that came up again and again was incomplete adoption among employees. Many professionals are understandably worried about what these tools will mean for their jobs, or at least skeptical of their usefulness as AI slop abounds. To bulldoze through this hesitation, bosses have stepped up the pressure, making AI use mandatory and incorporating it into performance reviews.\n\nBut a number of executives at the roundtable advised against strong-arming. Cisco learned that the hard way. \"When we asked our employees to take mandatory training for AI, not only did it not drive sustainable usage, it actually had a bit of a negative impact,\" said Francine Katsoudas, the company's chief people, policy, and purpose officer. What worked, she explained, was \"providing choice\" — like when Cisco gave its engineers access to half a dozen different AI tools, allowing them to decide which ones to use and how to use them. \"They absolutely loved that,\" she said.\n\nAnother theory was that even if employees want to use these new tools, they don't have the necessary skills to get the most out of them. Part of the fix, some argued, involves hiring people who are already good at using AI. Kyle Lutnick, the executive vice chairman of Cantor Fitzgerald, said he wants to bring in more new college grads at a time when other businesses are hiring fewer of them, precisely because they have more fluency using these tools than their older counterparts. But hiring new blood won't be enough. Employers will need to do a lot more to train their existing workforces too. \"Investment has been primarily on the technology and not so much on the people,\" said Elizabeth Faber, global chief people and purpose officer at Deloitte. \"That needs to shift.\"\n\nA third explanation was that big productivity gains require a fundamental overhaul of the way work gets done inside companies. If the Googles or the Amazons of the world were to start from scratch today, they almost certainly wouldn't have the team structures, workflows, and job descriptions they currently do. I think that's why we're seeing the AI revolution most clearly right now in early-stage startups, which are starting from the ground up in the post-ChatGPT era.\n\n\"84% of work processes have been left in their legacy state when adopting AI and have not been redesigned,\" Faber said. \"So 16% of organizations and work processes are really being developed in an AI-native way.\"\n\nAll of these proposed solutions are far from quick fixes. Encouraging employees to opt in voluntarily takes more time than threatening to fire them. Training staff — and actually getting them to learn — takes time too.\n\nRedesigning jobs will prove to be an even heavier lift. Many large businesses don't even know what employees do on a day-to-day basis. It's painstaking work to build out a comprehensive database of the skills employees have and the tasks they perform — and then to systematically tease out which of them can be delegated to AI and which of them can't. One chief people officer I spoke to said that it'll take years for her HR department to complete that process across every function at her company.\n\nOnce all that heavy-lifting is done, what will these businesses look like? I put the question to the group at the roundtable, asking how many of them expect their workforces to shrink in three to five years' time. Two out of the 15 raised their hands — a tally I suspect would have been higher if I weren't there. One of them, Gina Vargiu-Breuer, chief people officer at SAP, explained that her company is currently keeping headcount flat because the business is still growing.\n\n\"But when you're not growing, then I think this is where you have to talk about, 'OK, do we have to reduce headcount?'\" she said. \"I have a lot of peers in German companies where they are starting to reduce headcount dramatically. So it's a reality. For us, it's not, because we're growing, but I think it will happen going forward.\"\n\n\"At the moment we stay flat,\" she said. \"But if productivity goes up and growth is slowing down, then I think we have to look at that with different eyes.\"\n\nThat's something many economists had predicted early on, given how difficult it has always been to fully integrate new technology into the workplace. They told me that things will change less than we expect in the short term, and a lot \n\nC-suites around the world are coming to the same realization, which is probably why I detected quite a bit of frustration in Davos. Svenja Gudell, Indeed's chief economist, compared the world's urgency around AI to the impatience of a parent potty-training their kid. \"It's messy, it's a long process,\" she said. \"You're like, 'Why is this not happening? It's been three weeks already.'\" Her message to executives: \"Give yourself some grace.\"\n\nThe slower timeline is good news for the rest of us — it gives us time to learn new skills, debate new public policies, and try to shape the future we actually want. But it would be a mistake to read the so-far modest changes as evidence that tectonic shifts aren't coming. I came away from Davos convinced that when they do happen, they'll be far bigger than anything we're imagining now, for better and for worse.\n\nAki Ito is a chief correspondent at Business Insider.",
    "readingTime": 5,
    "keywords": [
      "reduce headcount",
      "purpose officer",
      "business insider",
      "chief",
      "employees",
      "it's",
      "businesses",
      "executives",
      "tools",
      "roundtable"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-hype-hasnt-changed-work-yet-bosses-employees-2026-1",
    "thumbnail_url": "https://i.insider.com/6977e57fa645d11881880412?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.856Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-is-the-new-ai-techies-are-buzzing-about-and-its-renewing-interest-in-the-mac-mini",
    "title": "Clawdbot is the new AI techies are buzzing about — and it's renewing interest in the Mac Mini",
    "description": "Clawdbot is a local AI agent that promises to manage your digital life, from organizing your calendar to booking restaurant reservations.",
    "fullText": "If your techie friend is texting a lobster, here's why.\n\nClawdbot is an open-source AI agent that works around the clock and can connect to many common consumer apps. Users have asked their Clawdbots to organize their schedules, monitor vibe-coding sessions, and build new AI employees.\n\nIt's scored some high-profile fans, from Y Combinator CEO Garry Tan to multiple Andreessen Horowitz partners. Many have praised it, others have meme'd it, and some have warned people about potential security concerns.\n\nYou can spot Clawdbot by its friendly lobster mascot.\n\nFounded by Peter Steinberger, Clawdbot is an AI agent that manages \"digital life,\" from emails to home automation. Steinberger previously founded PSPDFKit.\n\nIn a key distinction from ChatGPT and many other popular AI products, the agent is open source and runs locally on your computer. Users then connect the agent to a messaging app like WhatsApp or Telegram, where they can give it instructions via text.\n\nClawdbot was named after the \"little monster\" that appears when you restart Claude Code, Steinberger said on the \"Insecure Agents\" podcast. He formed the tool around the question: \"Why don't I have an agent that can look over my agents?\"\n\n\"I already did the whole startup thing,\" Steinberger said. \"I'm just here to have fun.\"\n\nbro came back from retirement\n\n> built @clawdbot \n> solved \"AI forgets everything\" problem\n> and still gave it to us for free\n\nabsolute legend 🐐 pic.twitter.com/tPwwicah42\n\nClawdbot runs locally on your computer 24/7. That's led some people to brush off their old laptops. \"Installed it experimentally on my old dusty Intel MacBook Pro,\" one product designer wrote. \"That machine finally has a purpose again.\"\n\nOthers are buying up Mac Minis, Apple's 5\"-by-5\" computer, to run Clawdbot. Logan Kilpatrick, a product manager for Google DeepMind, posted: \"Mac mini ordered.\" It could give a sales boost to Apple, some X users have pointed out — and online searches for \"Mac Mini\" jumped in the last 4 days in the US, per Google Trends.\n\nBut Steinberger said buying a new computer just to run the AI isn't necessary.\n\n\"Please don't buy a Mac Mini,\" he wrote. \"You can deploy this on Amazon's Free Tier.\"\n\nThe Mac Mini buy-ups have spawned dozens of memes.\n\nOne founder wrote that his \"meal prep\" was a fridge full of Mac Minis and Monster energy drinks. An engineer joked that his Mac Mini had quit his job and divorced his wife. Another founder prophesied a wave of Mac Mini returns in two weeks.\n\ngetting a mac mini just to run clawd has got be most performative thing you can do to start the year pic.twitter.com/KwTYIEcJqI\n\nAs for Clawdbot, many techies were excited by the agent's capabilities.\n\nOne founder asked it to make him a dinner reservation; when it couldn't complete the task via OpenTable, it used its ElevenLabs skill to call the restaurant. \"AGI is here and 99% of people have no clue,\" he wrote.\n\nOthers were less impressed. One founder called it a \"generational psyop,\" joking that it took him 6 texts to get a calendar invite.\n\nClawdbot seems to be at least moderately popular. Steinberger posted on X that he had 89 GitHub pull requests — and that venture capitalists were flooding his inbox.\n\nIs Clawdbot the future of agents? Some onlookers seem skeptical.\n\nFirst, the setup process can be technical. A16z partner Olivia Moore described the process, from terminal commands to API keys. \"For most consumers (or even prosumers), the learning curve is likely too steep,\" she wrote.\n\nThen there's the security question. You are giving an AI agent almost unlimited access to your digital life and passwords, after all.\n\nRahul Sood, a former Microsoft exec who founded its investment arm, wrote that Clawdbot turned text messages into \"attack surfaces\" and had \"zero guardrails by design.\" He advised using it carefully.\n\nGave Clawdbot access to my portfolio.\n\n\"Trade this to $1M. Don't make mistakes\"\n\n25 strategies. 3,000+ reports. 12 new algos.\n\nIt scanned every X post. Charted every technical. Traded 24/7.\n\nIt lost everything.\nBut boy was it beautiful. pic.twitter.com/wYpEZ3kB67\n\nOne hacker described Clawdbot as hiring a \"brilliant\" butler who later opened your home to the public, allowing a stranger to read your diary.\n\nSteinberger responded to these security concerns by outlining some guardrails users could employ, including reading the security document and avoiding adding Clawdbot to group chats.\n\nHow much should we hand over our digital lives to AI? A16z partner Justine Moore warned against being the \"guy who automated his entire life with ClawdBot.\"",
    "readingTime": 4,
    "keywords": [
      "a16z partner",
      "mac minis",
      "mac mini",
      "security concerns",
      "digital life",
      "clawdbot",
      "users",
      "computer",
      "founder",
      "others"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-ai-mac-mini-2026-1",
    "thumbnail_url": "https://i.insider.com/697779b8a645d1188187f807?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.854Z",
    "topic": "finance"
  },
  {
    "slug": "i-went-off-the-deep-end-with-ai",
    "title": "I went off the deep end with AI",
    "description": "What happens when code becomes the easy part? Excitement, dread, and what this means for my solo-run business.",
    "fullText": "Discussion about this postRestacksDennis Paagman 16hLiked by Joe MasilottiThe waiting sucks! It gets me out the zone too. I noticed it helps me to use the fast Claude models when not doing complex or planning stuff, as it’s soo much faster. It got better with 4.x luckily. ReplyShareAnthony Amar 1hThanks for this post, very interesting. Glad to read that I'm not alone being bored about the waiting. More than a year of Cursor usage, I'm kinda see some serious downside to this amazing productivity: it erodes my focus. This waiting have something to do with it imho, because it urge me to do something else, and it often (always?) doesn't have to do with code. I can't focus on code as I focused back in the day, struggling on bugs with tens of Stack Overflow tabs. Did you find a balance on what to code \"by hand\", and what to do with AI?ReplyShare1 reply by Joe Masilotti1 more comment...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "code",
      "focus"
    ],
    "qualityScore": 0.55,
    "link": "https://newsletter.masilotti.com/p/i-went-off-the-deep-end-with-ai",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!PlZj!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c2ca74-dddf-4909-843c-25211b5d700d_2400x1260.png",
    "created_at": "2026-01-27T12:26:46.769Z",
    "topic": "tech"
  },
  {
    "slug": "new-ranking-where-openai-employees-went-to-college",
    "title": "New ranking: Where OpenAI employees went to college",
    "description": "Workforce.ai data reveals most OpenAI staff graduated from top US universities, showing how concentrated elite AI talent remains.",
    "fullText": "A chart circulating on X breaks down where OpenAI employees went to school. It reads like a who's who of elite universities.\n\nStanford leads by a wide margin, followed by UC Berkeley, MIT, and Carnegie Mellon, with strong showings from Harvard, Cornell, UCLA, and a few international institutions.\n\nThe data comes from workforce.ai, which tracks and verifies online professional profiles to analyze hiring and talent trends.\n\nWhile not a full picture of OpenAI's workforce, the snapshot underscores how heavily frontier AI labs continue to draw from a small cluster of top research universities — and how concentrated elite AI talent remains.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 1,
    "keywords": [
      "elite",
      "universities",
      "talent"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/openai-employees-went-college-ranking-stanford-2026-1",
    "thumbnail_url": "https://i.insider.com/6972c5bfe1ba468a96aa910f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.699Z",
    "topic": "finance"
  },
  {
    "slug": "agent-skills-from-claude-to-open-standard-to-your-daily-coding-workflow",
    "title": "Agent Skills: From Claude to Open Standard to Your Daily Coding Workflow",
    "description": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we're witnessing something far more...",
    "fullText": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we’re witnessing something far more significant: an open standard reshaping how people across roles—developers, designers, product managers, and operations—work with AI assistants. AI coding agents’ adoption of Agent Skills has transformed this technology from an interesting experiment into an essential developer tool.\n\nIf you’ve been using custom instructions or wondering how to make your AI assistant truly understand your project’s workflows, Agent Skills provides a compelling solution.\n\nAgent Skills began with Anthropic’s Claude AI, where developers first experienced giving AI agents specialized capabilities through structured instructions. Unlike simple prompts or one-off commands, Agent Skills introduced a sophisticated approach: packaging instructions, scripts, templates, and documentation into reusable, discoverable units.\n\nAnthropic’s decision to release Agent Skills as an open standard transformed it from a Claude-specific feature into a movement. The format’s simplicity and effectiveness attracted attention across the AI development tools ecosystem. Today, major players—Claude Code, GitHub Copilot, Cursor, OpenCode, Mistral Vibe, Antigravity, OpenAI Codex, and Kiro—have adopted the standard. Others are exploring integration, and more are joining it (I’m looking at you, JetBrains Junie).\n\nAgent Skills are elegantly simple: a folder containing a SKILL.md file. This file uses YAML frontmatter for metadata and Markdown for instructions. No complex APIs, no proprietary formats—just structured text any AI agent can understand.\n\nHere’s a basic Agent Skills example for creating NUnit unit tests in C#:\n\nThose Agent Skills files live in your agent configuration, for example for GitHub Copilot .github/skills/create-nunit-unit-test/SKILL.md in your repository. Or they can be globally installed for your user account, e.g. ~/.copilot/skills/create-nunit-unit-test/SKILL.md.\n\nThis is a minimal example. You can add resources like templates, example configurations, or helper scripts in the same directory, and the skill can reference them.\n\nWhat makes Agent Skills innovative isn’t just the format—it’s how AI agents consume them. The system uses a three-level progressive disclosure approach that optimizes context window usage:\n\nLevel 1: Discovery — At startup, the agent reads only the name and description from each skill. This lightweight metadata helps the agent understand available capabilities without consuming context.\n\nLevel 2: Activation — When your request matches a skill’s description, the agent loads the full instructions from the SKILL.md file. Only then do detailed procedures become available.\n\nLevel 3: Execution — The agent accesses additional files (scripts, examples, documentation) only as needed during execution.\n\nThis architecture solves a critical problem: you can install dozens of Agent Skills without overwhelming the AI’s context window. The agent loads only what’s relevant to your current development task.\n\nGitHub Copilot’s Agent Skills are experimental since December 2025 (version 1.108) for VS Code. Here’s your step-by-step setup guide:\n\nInstall VS Code — Download from code.visualstudio.com\n\nEnable Agent Skills — Open settings (Ctrl+,) and enable chat.useAgentSkills\n\nCreate your skills directory — In your project root, create .github/skills/\n\nAdd your first skill — Create a subdirectory for each skill with its SKILL.md file\n\nUse Agent Mode — In Copilot Chat, switch to Agent mode to leverage skills\n\nOnce configured, Agent Skills activate automatically based on your prompts. No manual selection required—the AI determines which skills are relevant based on your descriptions.\n\nSkills share knowledge—best practices, workflows, and procedural guidance—in simple Markdown SKILL.md files that anyone can author; they load progressively to conserve tokens, require no server, and run on web, desktop, and CLI, making them ideal for documentation, checklists, examples, and repeatable workflows.\n\nMCP extends functionality by connecting to APIs, databases, and external tools: it consists of code and service/tool definitions that require development and hosting, loads tool definitions up front (consuming more context), so it’s best suited for tasks needing direct access to external systems.\n\nUse Skills to make knowledge discoverable and consistent, and use MCP to perform integrated actions and extend platform capabilities; together they provide both lightweight guidance and powerful automation.\n\nNevertheless, I can imagine a future where Agent Skills replace MCP for many scenarios, given their simplicity, portability, and ease of authoring. As you can bundle scripts and resources with skills, they can cover many use cases MCP currently serves.\n\nYou might wonder how Agent Skills differ from the custom instructions feature. Custom Instructions are best for defining coding standards and conventions, setting language or framework preferences, specifying code-review guidelines, and establishing commit-message formats. Agent Skills are designed to package reusable workflows, include executable scripts and templates, define specialized procedures (testing, debugging, deployment), and enable capabilities that run beyond the IDE (CLI and coding agents).\n\nThink of custom instructions as your coding style guide and Agent Skills as your AI development toolbox. Custom instructions tell the AI how you want code written; Agent Skills give the AI specialized capabilities to perform complex development tasks.\n\nHere are some practical Agent Skills that can transform your daily development workflow. Check the references section for pointers to more ready-to-use skills:\n\nRead the Agent Skills Specification to understand the format and capabilities. Use Skill Creator, an Agent Skill to create and refine new Agent Skills. Inception moment anyone 🤔?\n\nStart building your Agent Skills collection with these proven strategies:\n\nIdentify Repetitive Tasks — Notice which development workflows you explain to the AI repeatedly. Each recurring explanation is a candidate for an Agent Skill.\n\nStart Simple — Begin with straightforward skills that codify standard development procedures. As you gain confidence, add scripts and more complex resources.\n\nMake Descriptions Specific — The quality of your skill’s description directly impacts how well the AI knows when to activate it. Be explicit about use cases and capabilities.\n\nInclude Examples — Agent Skills with concrete code examples are more effective. Show the AI what good output looks like.\n\nLeverage Community Skills — Explore the github/awesome-copilot and anthropics/skills repositories for inspiration and ready-to-use skills.\n\nOrganize by Domain — Group related Agent Skills together. Create separate skills for testing, deployment, documentation, code review, and other specialized development domains.\n\nHere’s how Agent Skills enhance your workflow in a typical development scenario:\n\nYou’re working on a web application and need to add a new REST API endpoint with proper testing and documentation. With appropriate Agent Skills in place:\n\nYou ask: “Help me add a new user registration endpoint with validation”\n\nThe rest-api-integration skill activates, providing structured guidance on implementing the endpoint with proper authentication, validation, and error handling.\n\nYou ask: “Create tests for this endpoint”\n\nThe webapp-testing skill engages, generating test cases for success scenarios, validation failures, and edge cases.\n\nYou ask: “Generate documentation for this endpoint”\n\nThe api-documentation skill activates, producing comprehensive documentation with examples, error codes, and authentication details.\n\nEach Agent Skill ensures consistency in approach and completeness in implementation. Without skills, you’d need to provide detailed instructions for each request or rely on the AI’s general knowledge, which might miss project-specific patterns.\n\nWhen working with Agent Skills, especially community-shared skills, keep these security considerations in mind:\n\nReview Before Use — Always examine shared Agent Skills before adding them to your project. Check for potentially malicious scripts or unexpected behaviors in the SKILL.md file and associated resources.\n\nUse Terminal Controls — VS Code’s terminal tool provides controls for script execution, including auto-approve options with configurable allow-lists. Configure these appropriately for your security requirements.\n\nVersion Control Your Skills — Agent Skills are just files, so commit them to your repository. This enables code review, versioning, and team collaboration on AI capabilities.\n\nTest in Safe Environments — Try new Agent Skills in development environments before using them in production contexts. Dev containers or isolated workspaces are ideal for testing.\n\nDocument Team Skills — If your team uses shared Agent Skills, maintain documentation about what each skill does and when to use it.\n\nAgent Skills represent more than a new feature—it’s a glimpse into a future where AI development capabilities are portable, shareable, and composable. As more AI tools adopt the standard, we’re moving toward an ecosystem where:\n\nWhether you’re using VS Code or any other editor/IDE, working in the terminal with Copilot CLI, or leveraging any coding agent for automated tasks, your Agent Skills come with you.\n\nReady to integrate Agent Skills into your development workflow? Follow this action plan:\n\nThe goal isn’t to create dozens of Agent Skills immediately. Start with one or two that solve real problems in your development workflow, then expand your library organically as needs arise.\n\nYou can also use Agent Skills with GitHub Copilot CLI or Gemini CLI for terminal-based workflows, or with other coding agents that support the open standard. This portability ensures your investment in creating skills pays off across all your AI-assisted development tools.\n\nMy preferred introduction to Agent Skills is the following video from Burke Holland, which covers the concepts, setup, and practical examples in under 20 minutes:\n\nFor my French readers, I discussed Agent Skills in depth on devdevdev.net in the following episode\n\nAgent Skills bridges the gap between generic AI assistance and specialized, context-aware support for your specific development needs. By adopting an open standard that works across AI tools, the industry has created a foundation for truly portable AI capabilities.\n\nThe journey from Claude to open standard to GitHub Copilot adoption demonstrates the power of simplicity and interoperability in developer tools. As developers, we benefit from this ecosystem approach—our investment in creating Agent Skills pays dividends across our entire development toolchain.\n\nStart small, experiment with the format, and build Agent Skills that improve your daily development work. The progressive disclosure system ensures you won’t overwhelm your AI assistant, and the portable format guarantees your skills remain valuable as AI tools evolve.\n\nThe future of AI-assisted development isn’t just about more powerful models—it’s about giving those models the right context, capabilities, and knowledge to be genuinely helpful in your specific development domain. Agent Skills is a significant step in that direction.\n\nWhat development workflows could benefit from specialized Agent Skills? Have you tried creating skills for your AI coding assistant? Share your experiences in the comments below.",
    "readingTime": 9,
    "keywords": [
      "agent skills",
      "skill.md file",
      "progressive disclosure",
      "ai-assisted development",
      "skill’s description",
      "context window",
      "agent mode",
      "shared agent",
      "coding agents",
      "skill activates"
    ],
    "qualityScore": 1,
    "link": "https://laurentkempe.com/2026/01/27/Agent-Skills-From-Claude-to-Open-Standard/",
    "thumbnail_url": "https://live.staticflickr.com/65535/55058424290_cced09531e_h.jpg",
    "created_at": "2026-01-27T12:26:46.640Z",
    "topic": "tech"
  },
  {
    "slug": "emails-show-bank-of-americas-struggles-with-nvidia-ai-you-have-to-help-us-as-local-car-mechanics-drive-the-race-car",
    "title": "Emails show Bank of America's struggles with Nvidia AI: 'You have to help us as local car mechanics drive the race car!'",
    "description": "Internal emails show Bank of America having difficulties with Nvidia's AI Factory, showing the challenges of integrating AI in regulated industries.",
    "fullText": "Nvidia ran into some resistance as one of the world's biggest banks struggled to adopt its AI enterprise software, signaling how hard it can be for massive, highly regulated companies to put cutting-edge technology to use.\n\nNvidia sales executives recapped conversations with key customers — including Bank of America — following a conference late last year, according to an internal email thread from November viewed by Business Insider.\n\nThe chip giant has been selling its \"AI Factory\" — a full setup of chips and software designed to build, train, and run large-scale AI systems — to large businesses.\n\nBank of America told Nvidia it was struggling with deployment, according to the email thread. The exchange reveals that while companies rush to purchase AI infrastructure, operational and regulatory hurdles make deploying it far harder — a key challenge for Nvidia as it expands from selling chips into enterprise software. On the thread, Nvidia executives also discussed how they can better work with customers in using its AI products.\n\n\"You sold us a Formula 1 race car,\" an Nvidia executive reported the bank said, comparing the AI Factory to the race car, \"and now you have to help us as local car mechanics drive the race car!\"\n\nBank of America declined to comment. Nvidia did not respond to a request for comment from Business Insider.\n\nA second executive later responded that Nvidia \"can't just sell\" AI Factory hardware but needs to provide a software solution to help business customers succeed.\n\nThe gap between buying infrastructure and actually deploying AI is common across industries, said Rumman Chowdhury, who advises companies on responsible AI.\n\n\"Buying GPUs or signing a cloud contract is a business decision; deploying AI is an institutional change,\" she told Business Insider. \"It's much easier to approve a budget line item than to re‑architect workflows, retrain teams, and rewrite governance processes.\"\n\nRecapping its meeting with Bank of America, the first Nvidia executive said the bank lacked \"the MLOps skills in house.\" MLOps refers to machine learning operations, or the processes for implementing AI models in real-world use cases.\n\nThat executive added that Bank of America did not think Nvidia's AI enterprise software was \"ready for their highly regulated banking industry.\"\n\nThe executive also pointed to other concerns, including Bank of America's security and governance requirements, such as documentation and support for air gapping — isolating systems from other networks to improve security. They noted the challenges the bank faced in supporting multiple AI models and software systems to meet different needs.\n\nNvidia vice president Ian Buck subsequently jumped into the thread, signalling how senior leaders at the chip giant can step in when customer concerns surface.\n\n\"Looks like they need help and/or our product is coming up short,\" Buck wrote.\n\nThe struggles at Bank of America echo earlier issues with Nvidia's enterprise software efforts, including a need to educate prospective clients on what it is and isn't.\n\nAI deployment obstacles aren't exclusive to banking; they are prevalent across sectors. While banks have a long history of using AI for tasks like credit decisioning, they may be the first to run into issues because of the scale of their data and customers, said Tom Davenport, an information technology and management professor at Babson College.\n\n\"The technology's out way ahead of what individual banks or most companies actually can implement quickly,\" he said.\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "bank of america",
      "highly regulated",
      "chip giant",
      "race car",
      "nvidia executive",
      "enterprise software",
      "email thread",
      "ai factory",
      "customers",
      "banks"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bank-of-america-nvidia-ai-internal-emails-2026-1",
    "thumbnail_url": "https://i.insider.com/6977dccba645d118818802fb?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.563Z",
    "topic": "finance"
  },
  {
    "slug": "i-quit-meta-to-build-an-ai-startup-giving-up-a-big-tech-salary-was-tough-heres-how-i-prepared-financially",
    "title": "I quit Meta to build an AI startup. Giving up a Big Tech salary was tough — here's how I prepared financially.",
    "description": "A former Google and Meta employee shares why he left Big Tech and how he got comfortable making the leap to entrepreneurship.",
    "fullText": "This as-told-to essay is based on a conversation with Jason White, a 46-year-old startup founder in the San Jose area. Business Insider has verified his former employment with documentation. His words have been edited for length and clarity.\n\nI've spent half of my 20 years in the tech industry working at Google and Meta. These companies allowed me to work on some amazing projects, but I've now resigned from them both.\n\nI joined Google in 2016 as a tech lead in the Gmail division and transitioned to the Google Search team in 2020. By 2024, I realized I wanted to lean more heavily into AI. I didn't feel my position at Google would give me the opportunity to do that, so I opened myself up to other opportunities.\n\nWhen a Meta recruiter reached out about an AI machine learning engineer role, I decided to pursue it and eventually received an offer. I left Google in July 2024 and started at Meta a month later.\n\nI had a positive experience at Meta. I worked with great people in a high-resource environment and learned a lot. I was also able to lean into AI as I'd hoped, focusing fully on AI products.\n\nHowever, halfway through 2025, I started thinking about resigning to build a startup — specifically, a venture that would use AI to help the typical household with their finances.\n\nWhether to resign from Meta was a complex decision.\n\nThe startup was something I was growing increasingly passionate about. I know what financial pressure feels like — I had been a low-paid graduate student trying to provide for a newborn.\n\nMany people don't have access to great financial planning and management tools to help improve their financial situations. While I was still figuring out what the business would look like, I felt there was an opportunity to help people, and that was very motivating for me.\n\nI connected with a potential cofounder — a friend of a friend — and we spent a lot of time talking through the opportunity. That helped me grow more comfortable with the idea of leaving Meta, but there were still a lot of other factors to consider.\n\nIt's hard to leave a world-class team with people you like — not to mention a reliable source of income.\n\nI know some people start businesses on the side while keeping their full-time jobs, but I couldn't do that because I was already juggling two demanding roles as a Meta employee and a parent.\n\nMy other concern was legal. I would've had to disclose any outside business to Meta, and there could've been non-compete issues — especially since my business idea was related to AI, like my role at Meta.\n\nI wanted to make sure my family had enough savings to cover at least one year of our current expenses without touching our retirement accounts. My wife works, but I wanted a cushion in case she lost her job. I figured that would give me at least one year to build the business, and, if things went really badly, enough time afterward to find a job.\n\nWe already were in a good place savings-wise, so we were still able to take vacations, hire tutors for our kids, and order DoorDash. I had about six months before resigning to make some minor adjustments, including cutting back on 401(k) contributions and putting more money into liquid savings accounts.\n\nThis financial planning process for my family really helped crystallize the direction I wanted to go with the startup. In September 2025, I resigned from Meta.\n\nWhen I shared the news with my colleagues, the response was a mix of surprise, support, and a large amount of jealousy. A lot of people want to leave and start their own thing, but for various reasons they can't or won't — whether it's because of their visa status, financial constraints, or broader fear.\n\nI'm now focused on my business, Bear Financial. My cofounder and I are planning to publicly launch in the second half of this year. We may seek external funding, but for now, we're bootstrapping the business, so I've tracked our spending very carefully.\n\nI have a few pieces of advice for people considering leaving their jobs to start their own business. First, get your finances in order. Second, make sure anyone who depends on you, like your family, is supportive of the decision — I was fortunate to have a supportive partner who knew that I felt limited working in Big Tech.\n\nThird, choose an idea you deeply believe in. With a startup, you have to be the one to bring the energy, the enthusiasm, the vision — and to carry others into it.\n\nAddress your knowledge gaps. Startup founders often need to be generalists, which means having a basic understanding of a lot of areas.\n\nI'd also suggest envisioning the worst-case outcome and asking yourself whether you'd be OK with it. I thought about what it would look like one year later if my business failed. I believe I'd still value everything I learned over those 12 months.\n\nIf I eventually decide to pursue a corporate position again, I have faith that I'd be able to find something — even though it's hard to predict what the job market will look like.\n\nThere are, however, a lot of potential barriers to success: we have to navigate a moving target on regulations, we need to figure out ways to convince potential customers to give us a try, and there are super well-resourced companies that could become direct competitors.\n\nAt the end of the day, I want to take the swing.",
    "readingTime": 5,
    "keywords": [
      "financial planning",
      "startup",
      "i've",
      "meta",
      "opportunity",
      "look",
      "potential",
      "idea",
      "it's",
      "family"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ex-meta-google-employee-quit-build-ai-startup-shares-advice-2026-1",
    "thumbnail_url": "https://i.insider.com/69779c89e1ba468a96aab34f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.403Z",
    "topic": "finance"
  },
  {
    "slug": "the-wix-ceo-said-ai-gives-engineers-superpowers-that-means-one-trait-is-key-for-entrylevel-developers",
    "title": "The Wix CEO said AI gives engineers 'superpowers.' That means one trait is key for entry-level developers.",
    "description": "Wix CEO Avishai Abrahami said that entry-level engineers need to have this quality in order to keep up with the fast pace of change.",
    "fullText": "AI isn't just reshaping the role of software engineers — it's also making them more skilled.\n\nThat's according to Avishai Abrahami, the CEO and cofounder of website management company Wix. He told Business Insider that the technology equips developers with \"superpowers\" and that the value of smart, talented engineers will be \"dramatically enhanced\" with AI tools.\n\n\"What would take you a month, you can do in a few hours,\" Abrahami said, adding that not every task can be reduced in this way, but most can.\n\nA Google Cloud report released in September found that AI adoption had surged to 90% among software professionals, up 14% from the year prior. Abrahami said that the emergence of AI tools means the \"quality of the software engineer is more important than ever.\"\n\nHe said the first thing \"every company\" looks for is candidates who know how to code and understand AI models. Beyond that baseline, he said Wix aims to hire entry-level candidates with a \"tremendous amount of passion\" for the role, which he said is essential to meeting the demands of the job [didn't want to repeat roles] .\n\n\"Now with AI, the speed of change is so fast that you have to spend a lot of time learning and experimenting,\" Abrahami said, adding that this makes passion is even more important.\n\nJohn Stecher, Blackstone's chief technology officer, similarly told Business Insider that many junior software engineers have \"insane skill sets\" and that the best hires are deeply passionate about their work.\n\nAs tools take on more of the coding, Stecher said companies are increasingly looking to hire those who understand how to use the tools, and recognize when they're producing the wrong answers.\n\nFor more senior engineers, the role will increasingly shift toward architecture and code review, he said, rather than writing code. Abrahami said experienced engineers will need to read code \"much faster,\" adding that architecture, software design, and code comprehension will become even more critical.\n\nThe CEO, however, warned that AI can be a double-edged sword for engineers.\n\n\"You can do so much more if you're smart,\" Abrahami said about engineers who use AI. \"And you can do really bad things if you're not.\"",
    "readingTime": 2,
    "keywords": [
      "software engineers",
      "business insider",
      "code",
      "tools",
      "role",
      "adding",
      "technology",
      "smart",
      "candidates",
      "understand"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/wix-ceo-says-entry-level-engineers-need-this-trait-2026-1",
    "thumbnail_url": "https://i.insider.com/6977a893d3c7faef0eccecc6?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.402Z",
    "topic": "finance"
  },
  {
    "slug": "deepseek-ocr-2-visual-causal-flow",
    "title": "DeepSeek OCR 2: Visual Causal Flow",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "🌟 Github |\n 📥 Model Download |\n 📄 Paper Link |\n 📄 Arxiv Paper Link |\n\nDeepSeek-OCR 2: Visual Causal Flow\n\nExplore more human-like visual encoding.\n\nInference using Huggingface transformers on NVIDIA GPUs. Requirements tested on python 3.12.9 + CUDA11.8：\n\nRefer to 🌟GitHub for guidance on model inference acceleration and PDF processing, etc.\n\nWe would like to thank DeepSeek-OCR, Vary, GOT-OCR2.0, MinerU, PaddleOCR for their valuable models and ideas.\n\nWe also appreciate the benchmark OmniDocBench.",
    "readingTime": 1,
    "keywords": [
      "paper link",
      "github",
      "model",
      "deepseek-ocr",
      "visual",
      "inference"
    ],
    "qualityScore": 0.65,
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-OCR-2",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/deepseek-ai/DeepSeek-OCR-2.png",
    "created_at": "2026-01-27T06:21:30.259Z",
    "topic": "tech"
  },
  {
    "slug": "postgresql-timeout-parameters-your-databases-selfdefense-system",
    "title": "PostgreSQL Timeout Parameters: Your Database's Self-Defense System",
    "description": "(Inspired by OpenAI’s PostgreSQL scale challenges)When OpenAI shared their engineering journey of scaling PostgreSQL to support massive workloads, one insight quietly stood out:It’s also common to find long-running idle queries in PostgreSQL. Configuring timeouts like idle_in_transaction_session_timeout is essential to prevent them from blocking autovacuum.At first glance, this might sound like a small operational detail. But in reality, it points to a much bigger truth about how production data",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.datacloudgaze.com/post/postgresql-timeout-parameters-your-database-s-self-defense-system",
    "thumbnail_url": "https://static.wixstatic.com/media/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png/v1/fill/w_1000,h_965,al_c,q_90,usm_0.66_1.00_0.01/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png",
    "created_at": "2026-01-27T06:21:28.988Z",
    "topic": "tech"
  },
  {
    "slug": "ask-your-llm-traces-what-went-wrong-vllora",
    "title": "Ask your LLM traces what went wrong (vLLora)",
    "description": "Lucy is a built-in assistant that reads your traces, diagnoses agent failures, and suggests concrete fixes in seconds.",
    "fullText": "Your agent fails midway through a task. The trace is right there in vLLora, but it's 200 spans deep. You start scrolling, scanning for the red error or the suspicious tool call. Somewhere in those spans is the answer, but finding it takes longer than it should.\n\nToday we're launching Lucy, an AI assistant built directly into vLLora that reads your traces and tells you what went wrong. You ask a question in plain English, Lucy inspects the trace, and you get a diagnosis with concrete next steps. Lucy is available now in beta.\n\nSorry, your browser doesn’t support embedded videos.\n\nAgent failures don’t look like traditional exceptions. A single bad response is usually the result of a chain of small choices spread across a long execution.\n\nWhen debugging becomes \"scroll until you get lucky,\" you miss important signals and burn time (and tokens) doing it.\n\nLucy is good at exactly this: reading the trace end-to-end, spotting failure patterns, and turning them into actionable fixes.\n\nLucy sits next to your traces and threads. Ask a plain-English question, and it will inspect the trace, flag failure points, and return a fix-oriented report: root cause, impact, and recommended next steps.\n\nLucy can also help you spot patterns across multiple failing runs and suggest prompt rewrites to reduce ambiguity.\n\nWe had a Travel agent which was running for a long time, apparently stuck in a loop within the BetweenHorizonalEnd span. Instead of digging through the logs manually, we simply asked Lucy:\n\nLucy inspected the thread's spans, identified a recurring failure pattern, and explained the root cause and impact, along with concrete next steps.\n\nIn this trace, the agent was failing to complete a travel itinerary. Lucy didn't just flag the error; she identified a complex failure pattern involving both the code (schema) and the instructions (prompt).\n\n1. The \"Hallucinated\" Arguments\nLucy pinpointed exactly why the tools were failing. The model was trying to call research_flights with a from_city argument and research_accommodations with check_in_date.\n\n2. The Hidden Logic Trap\nCritically, Lucy found a root cause that a human scanning logs would likely miss: Prompt Contradiction.\n\n3. Silent Failures (Truncation)\nLucy also caught a silent degradation issue: Severe Output Truncation. The Restaurant Extraction step was hitting token limits and cutting off data mid-list (output_tokens: 4000... truncated). The run looked \"successful\" to the server, but the downstream user was getting incomplete data.\n\nLucy’s report turned a vague \"it's not working\" complaint into three distinct engineering tasks: fix the tool schema, clarify the system prompt, and increase the context window for extraction.\n\nCaption: Lucy analyzes the trace and detects multiple issues simultaneously: invalid tool arguments (from_city), contradictory system prompt instructions, and token truncation in the output.\n\nThis is a common failure mode in tool-using agents: when the tool contract isn't perfectly aligned (schema, handler, prompt, examples), the model starts guessing.\n\nThe cost isn't limited to a single failed call:\n\nEven if your run \"succeeds,\" you can still be paying for broken execution paths.\n\nLucy's intelligence comes from vLLora's tracing infrastructure. vLLora captures everything your agent does:\n\nWhen you ask Lucy a question, it pulls the relevant spans and runs, reconstructs the execution flow, and analyzes patterns across the data. This is context that would take a human hours to piece together manually.\n\nLucy is available now in beta for all vLLora users.\n\nLucy will inspect your active context and give you a clear diagnosis, so you can spend less time scrolling and more time shipping.\n\nSee the full Lucy documentation here",
    "readingTime": 3,
    "keywords": [
      "root cause",
      "patterns across",
      "failure pattern",
      "steps lucy",
      "system prompt",
      "trace",
      "agent",
      "vllora",
      "spans",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://vllora.dev/blog/introducing-lucy/",
    "thumbnail_url": "https://vllora.dev/img/lucy-whats-wrong-with-my-thread.png",
    "created_at": "2026-01-27T06:21:28.207Z",
    "topic": "tech"
  },
  {
    "slug": "kimi-k25",
    "title": "Kimi K2.5",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens atop Kimi-K2-Base. It seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms.\n\nKimi-K2.5 adopts the same native int4 quantization method as Kimi-K2-Thinking.\n\nYou can access Kimi-K2.5's API on https://platform.moonshot.ai , we provide OpenAI/Anthropic-compatible API for you. To verify the deployment is correct, we also provide the Kimi Vendor Verifier.\nCurrently, Kimi-K2.5 is recommended to run on the following inference engines:\n\nDeployment examples can be found in the Model Deployment Guide.\n\nThe usage demos below demonstrate how to call our official API.\n\nFor third-party API deployed with vLLM or SGLang, please note that :\n\nChat with video content is an experimental feature and is only supported in our official API for now\n\nThe recommended temperature will be 1.0 for Thinking mode and 0.6 for Instant mode.\n\nTo use instant mode, you need to pass {'chat_template_kwargs': {\"thinking\": False}} in extra_body.\n\nThis is a simple chat completion script which shows how to call K2.5 API in Thinking and Instant modes.\n\nK2.5 supports Image and Video input.\n\nThe following example demonstrates how to call K2.5 API with image input:\n\nThe following example demonstrates how to call K2.5 API with video input:\n\nK2.5 shares the same design of Interleaved Thinking and Multi-Step Tool Call as K2 Thinking. For usage example, please refer to the K2 Thinking documentation.\n\nKimi K2.5 works best with Kimi Code CLI as its agent framework — give it a try at https://www.kimi.com/code.\n\nBoth the code repository and the model weights are released under the Modified MIT License.\n\nIf you have any questions, please reach out at support@moonshot.cn.",
    "readingTime": 2,
    "keywords": [
      "instant mode",
      "agentic",
      "following",
      "please",
      "input",
      "native",
      "modes",
      "recommended",
      "usage",
      "chat"
    ],
    "qualityScore": 0.95,
    "link": "https://huggingface.co/moonshotai/Kimi-K2.5",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/moonshotai/Kimi-K2.5.png",
    "created_at": "2026-01-27T06:21:28.144Z",
    "topic": "tech"
  },
  {
    "slug": "one-developer-used-claude-to-build-a-memorysafe-extension-of-c",
    "title": "One developer used Claude to build a memory-safe extension of C",
    "description": "feature: Robin Rowe talks about coding, programming education, and China in the age of AI",
    "fullText": "feature TrapC, a memory-safe version of the C programming language, is almost ready for testing.\n\n\"We're almost there,\" Robin Rowe told The Register in a phone interview. \"It almost works.\"\n\nWe caught up with Rowe, a computer science professor and entrepreneur, amid debugging efforts that had kept him up until four in the morning. The long-awaited TrapC website has appeared.\n\n\"My work building TrapC has taken two parallel paths,\" Rowe explains in his initial post. \"A TrapC interpreter called itrapc and a separate compiler called trapc. I had wanted to make a software release by 1 January 2026, but too many bugs. I only reached code complete this month and am now on the painstaking and sleepless process of debugging. When I have something stable that mostly works I will make a release. Sorry to make you wait a little longer. Aiming for Q1 2026.\"\n\nBack in November 2024, Rowe explained that he was working on TrapC. At the time, the public and private sector had undertaken a campaign to promote memory-safe software development as a way to reduce exposure to serious vulnerabilities.\n\nMemory safety provides a way of ensuring that memory-related bugs like out-of-bounds reads/writes and use-after-free don't happen. In large codebases, like Chromium and Windows, most of the security vulnerabilities follow from memory bugs. As that message has been repeated in recent years, memory safety has become an imperative, evangelized by the likes of Google and Microsoft, and more recently by authorities in the US and elsewhere.\n\nFor at least the past ten years, there's been a rising chorus of voices calling for the adoption of memory-safe programming languages and techniques. This has meant encouraging developers to avoid languages like C and C++ where feasible, and to adopt languages like C#, Go, Java, Python, Swift, and Rust, instead, particularly for new projects.\n\nTo remain relevant, the C and C++ communities have tried to address those concerns with projects like TrapC, FilC, Mini-C, Safe C++, and C++ Profiles. There's also a C to Rust conversion project under development at DARPA called TRACTOR – TRanslating All C TO Rust.\n\nBut progress has been slow and those writing in C and C++ haven't found a widely accepted approach. The C++ standards committee recently rejected the Safe C++ proposal. And Rowe said he doubted TRACTOR would have anything to show this year.\n\nMeanwhile, the clock is ticking. Microsoft engineer Galen Hunt last month said, \"My goal is to eliminate every line of C and C++ from Microsoft by 2030. Our strategy is to combine AI and algorithms to rewrite Microsoft's largest codebases.\"\n\n\"There are some efforts to port C code by hand to Rust,\" said Rowe. \"But there're some real challenges to doing that because there are some idioms in C that cannot be expressed in Rust.\n\n\"Rust is much more type safe than C is. And so if you have a void pointer, what does that mean in Rust? There's no translation for it. And that's how TrapC is fundamentally different because it actually remembers what that void pointer actually is.\"\n\nRowe said he expects TRACTOR will eventually be able to accomplish C to Rust translation using AI. But he said he thinks it's better to just build the necessary tooling into the C compiler, so you don't have to rely on some external tool that rewrites your code in an unfamiliar language.\n\nRowe has been using AI tools himself and has been teaching others to do so. This past semester, he taught AI Cybersecurity Programmer Analyst (PCO471) at Community College of Baltimore County – Linux administration using vibe coding in bash with no prerequisites. And starting in February, he's teaching C++ Programming with Generative AI (PCO472) – vibe coding in C++.\n\nRowe said programming has fundamentally changed as a result of AI tools. \"I think this is sort of the same type of discussion as when C came in and people said, 'Well, I'm happy in assembly.' There will still be people doing it the old way. But because vibe programming is so much more efficient on time when done correctly, there's gonna be no choice. You just won't be competitive if you're not vibe programming.\"\n\nThen he shifted gears, slightly. \"But I have to walk that back a little bit because the reason I was up until four in the morning is I had vibe programming working on the Trap C compiler. And it took a fundamentally wrong design turn. And I didn't detect that it had made a design mistake. I had told it how I wanted to approach it. But somehow it misunderstood me or it forgot or something happened and I forgot to check. And so I spent hours doodling around in the debugger and trying to understand why code was acting weird before I finally looked at it and said, 'wait a minute, this isn't even the right design.'\"\n\nRowe said a similar situation crops up in pair programming, where you've told someone to do something and they didn't do it, and you don't realize that until later.\n\n\"[C++ creator] Bjarne Stroustrup famously said that the most important thing in software design is to be clear about what you're trying to build,\" Rowe said. \"And vibe [programming] just puts that on steroids. Now we not only have to be ourselves clear, but we have to communicate it clearly to an LLM.\"\n\nRowe argues that developers have to be encouraged to try AI tools and to make mistakes. He recounted how during his AI Cybersecurity Programmer Analyst course, his students expressed interest in doing more hands-on work in lieu of lectures.\n\n\"So I said, 'I've got real servers on the internet that are my companies. I'll give you root,'\" he recalled. \"I'll set loose students who know nothing on my own servers and hope for the best and we'll see how this goes. And the reaction was panic. I couldn't get past the timidity cliff.\"\n\nRowe said that what he learned from that exchange was that they didn't want their own hands-on, they wanted to watch him work.\n\n\"I said to them, 'But guys, this is like learning to play the piano. You can't learn to play the piano by watching me. Yeah, you guys have to practice. And it's gonna be embarrassing at first. You know, you're gonna play a lot of bad notes and sound terrible. You have to get over that situation'.\"\n\nThat's a scenario playing out in various companies where AI tools remain underutilized, for various reasons, including lack of training, security concerns, lack of utility, and poor tool design.\n\nRowe has traveled often to China to speak at the China Association of Higher Education conference. In December, he said, he was interviewed on China News Television about how China's plan for AI compares with America's.\n\nIn an email he explained, \"I said, 'China's AI-Plus plan calls for efficient AI on devices everywhere, from farm to factory to city, while the White House plan calls for building 500-billion-dollar cloud data centers ... using chips that will, inevitably, seem obsolete within two years.'\"\n\nRowe argues China's approach will prevail and that the US has taken the wrong turn by focusing on centralized cloud datacenters to run LLMs. Within two years, he said, we'll have AI models we can run locally on our phones, with no need for network access for most tasks. Apple and Huawei, he said, are likely to be the winners in this scenario.\n\nRowe pointed to China's DeepSeek as an example. While it may not be quite as good as the leading US commercial models, he said, it runs with far less power.\n\n\"This is a very Moore's Law type of strategy,\" he said. \"I remember when I had a Navy supercomputer in 1994. That was an amazing technology. But in 1995, Cray went bankrupt. There weren't enough buyers for it, even though it was an amazing device.\n\n\"And now I've got an iPhone that's in my pocket. That runs on a battery. It doesn't have a whole room devoted to it and exotic cooling and all kinds of stuff. And it's more powerful than that [the Cray from 1994]. So as a long-term strategy, you know, going toward the device makes a lot more sense, because that half-trillion dollar data center is going to be on my iPhone eventually.\"\n\nRowe also said that on the recommendation of a friend from his time at the AT&T DIRECTV Innovation Lab, he tried running Deepseek at a time when Claude wasn't available. Deepseek, he said, was able to find a bug that Claude couldn't.\n\n\"Surprisingly, the bug was in code Claude had generated, that I had cut-and-pasted carelessly,\" he said. \"With hindsight it was a silly code mistake I should have caught, but was in an 'else' branch outside where I was looking. I'd not expected or intended to have Claude make any change to that block of code. And because the code was valid but the logic wrong, the compiler didn't catch it.\"\n\nBut the bug was obvious, he said, as soon as Deepseek pointed it out. He added, \"I'm paying $200/year for Claude. Deepseek is free.\" ®",
    "readingTime": 8,
    "keywords": [
      "cybersecurity programmer",
      "programmer analyst",
      "rowe argues",
      "void pointer",
      "memory safety",
      "vibe coding",
      "design rowe",
      "vibe programming",
      "code",
      "compiler"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/26/trapc_claude_c_memory_safe_robin_rowe/",
    "thumbnail_url": "https://regmedia.co.uk/2022/03/23/shutterstock_c.jpg",
    "created_at": "2026-01-27T06:21:27.835Z",
    "topic": "tech"
  },
  {
    "slug": "sam-altman-said-openai-is-planning-to-dramatically-slow-down-its-pace-of-hiring",
    "title": "Sam Altman said OpenAI is planning to 'dramatically slow down' its pace of hiring",
    "description": "The OpenAI CEO said during a town hall event that OpenAI will \"hire more slowly but keep hiring\" because AI lets the company do more with less people.",
    "fullText": "Sam Altman is addressing AI's impact on the workforce, including on OpenAI's hiring practices.\n\nDuring a live-streamed town hall event on Monday, catered mainly toward developers, the OpenAI CEO said that AI has changed how quickly the company expands its head count, but the company is not in a hiring freeze and is nowhere close to doing away with human employees entirely.\n\n\"We are planning to dramatically slow down how quickly we grow because we think we'll be able to do so much more with fewer people,\" said Altman in response to a participant who asked if AI has changed OpenAI's interview process of potential candidates.\n\n\"What I think we shouldn't do, and what I hope other companies won't do either, is hire super aggressively, then realize all of a sudden AI can do a lot of stuff, and you need fewer people, and have to have some sort of very uncomfortable conversation,\" Altman added. \"So I think the right approach for us will be to hire more slowly but keep hiring.\"\n\nAltman's comments come amid the \"Great Freeze\" and concerns that job creation in America has lost momentum. The unemployment rate in November 2025 climbed to its highest level since 2021, while job openings have fallen 37% from their peak in 2022, according to data from the Bureau of Labor Statistics.\n\nBusiness Insider previously reported that, while in 2022 there were roughly two job openings for every unemployed worker, by September 2025 that ratio had fallen to one. Workers who have been jobless for at least 27 weeks also now make up about a quarter of all unemployed Americans.\n\nBased on data from the US Census Bureau, young workers have been hit especially hard by the hiring slowdown. The unemployment rate for Americans ages 20 to 24 reached 9.2% in August and September, the highest level since the recovery from the pandemic recession.",
    "readingTime": 2,
    "keywords": [
      "unemployment rate",
      "job openings",
      "hiring",
      "openai's",
      "changed",
      "quickly",
      "fewer",
      "hire",
      "highest",
      "unemployed"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sam-altman-said-openai-plan-dramatically-slow-down-hiring-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6977fee0d3c7faef0eccf5ef?width=1200&format=jpeg",
    "created_at": "2026-01-27T06:21:23.465Z",
    "topic": "finance"
  },
  {
    "slug": "7-of-the-most-interesting-quotes-from-anthropic-ceos-sprawling-19000word-essay-about-ai",
    "title": "7 of the most interesting quotes from Anthropic CEO's sprawling 19,000-word essay about AI",
    "description": "Anthropic CEO Dario Amodei wrote that AI poses \"a serious civilizational challenge,\" one that will require society to take significant action.",
    "fullText": "Dario Amodei still has a lot to say.\n\nOn Monday, the Anthropic CEO dropped an over 19,000-word essay entitled \"The Adolescence of Technology\" on the future of AI on Monday, opining on everything from his fellow CEOs to feudalism, and even the Unabomber.\n\nBest known for his warning that AI could eliminate up to 50% of entry-level white-collar jobs in the next 1 to 5 years, Amodei has tangled with Nvidia CEO Jensen Huang and the Trump White House over his views.\n\nHere are seven of the most alarming and surprising quotes.\n\nAmodei remains optimistic about AI overall, but his essay detailed \"an intimidating gauntlet that humanity must run\" to reap the benefits of AI without letting the breakthrough technology destroy the world.\n\n\"I believe if we act decisively and carefully, the risks can be overcome — I would even say our odds are good. And there's a hugely better world on the other side of it,\" he wrote. \"But we need to understand that this is a serious civilizational challenge.\"\n\nAI development can't be stopped, Amodei wrote, a conclusion even some of AI's skeptics share. The financial and security benefits are just too massive for the private and public sectors to pass up.\n\nIt's why winning the AI race and doing so in an ethical way is so critical, he concludes.\n\nJensen Huang hasn't changed Amodei's mind on China.\n\n\"A number of complicated arguments are made to justify such sales, such as the idea that 'spreading our tech stack around the world' allows 'America to win' in some general, unspecified economic battle,\" Amodei said. \"In my view, this is like selling nuclear weapons to North Korea and then bragging that the missile casings are made by Boeing and so the US is 'winning.'\"\n\nIn November, Nvidia announced a partnership with Anthropic that includes an investment of up to $10 billion in the AI startup. The news sparked speculation that tensions between Amodei and Huang might be cooling.\n\nWhatever the status of their relationship, Amodei is resolute that it is a horrendous decision to allow US companies to sell advanced chips to China.\n\n\"China is several years behind the US in their ability to produce frontier chips in quantity, and the critical period for building the country of geniuses in a data center is very likely to be within those next several years,\" Amodei wrote. \"There is no reason to give a giant boost to their AI industry during this critical period.\"\n\nAmodei would like his critics to see the scoreboard.\n\nAnthropic's leader hasn't tried to curry favor with the White House, nor has he vocally embraced President Donald Trump's AI policies to the same degree as his rival CEOs. Amodei's outspoken call for AI regulation even led David Sacks, Trump's AI czar, to publicly rebuke him.\n\nAnthropic is running a sophisticated regulatory capture strategy based on fear-mongering. It is principally responsible for the state regulatory frenzy that is damaging the startup ecosystem. https://t.co/C5RuJbVi4P\n\nNone of it has changed Amodei's view that the AI industry \"needs a healthier relationship with government — one based on substantive policy engagement rather than political alignment.\"\n\n\"Many people have told me that we should stop doing this, that it could lead to unfavorable treatment, but in the year we've been doing it, Anthropic's valuation has increased by over 6x, an almost unprecedented jump at our commercial scale,\" he wrote.\n\nOf all of his hopes, this one appears the unlikeliest. Already, AI CEOs have formed dueling super PACs ahead of the 2026 midterm elections.\n\nThe tech elite made AI, and they should help society grapple with its fallout, he wrote in the essay. Amodei has long called on governments to prepare for mass job displacement. In one of the most eyebrow-raising parts of the essay, Anthropic CEO detailed what his fellow billionaires and companies must do.\n\nBeyond philanthropy, Amodei said companies need to be \"creative\" in how they stave off layoffs.\n\nIn the long term, he wrote, \"It may be feasible to pay human employees even long after they are no longer providing economic value in the traditional sense.\"\n\nOne of the biggest themes of Amodei's essay is the risk that AI companies themselves pose. It's a conclusion that he admits is \"somewhat awkward\" for him to reach. As an example, he points to the roiling topic of the sexualization of children. While he does not name xAI directly, Grok is facing investigations in multiple countries over the non-consensual sexualization of images of real people.\n\n\"Some AI companies have shown a disturbing negligence towards the sexualization of children in today's models, which makes me doubt that they'll show either the inclination or the ability to address autonomy risks in future models,\" he wrote.\n\nOverall, he expressed skepticism that AI companies will sacrifice profit for broader societal good. \"Ordinary corporate governance,\" Amodei wrote, is ill-equipped to address his worries.\n\nAmodei said that fears that AI models may defy orders and perhaps even try to eliminate humanity are complicated by bad actors in the industry who aren't as transparent about the risks they are seeing in their models.\n\n\"While it is incredibly valuable for individual AI companies to engage in good practices or become good at steering AI models, and to share their findings publicly, the reality is that not all AI companies do this, and the worst ones can still be a danger to everyone even if the best ones have excellent practices,\" he wrote.\n\nAmodei doesn't see the largest risks to humanity coming from AI pursuing total domination, but rather in what AI could enable humans to unleash.\n\nAmodei described his fears that AI is lowering the barrier of entry necessary to make killer biological weapons. His greatest concern is that AI could provide the step-by-step know-how that could eventually enable even an average person to produce a bioweapon.\n\nAI companies, Amodei said, need to ensure they create sufficient backstops to block such inquiries, including by making it difficult for hackers to jailbreak models. Adding such security is expensive, Amodei said, noting that these measures are \"close to 5% of total inference costs\" for some of the companies' models.\n\n\"I am concerned that over time there may be a prisoner's dilemma where companies can defect and lower their costs by removing classifiers,\" he wrote. \"This is once again a classic negative externalities problem that can't be solved by the voluntary actions of Anthropic or any other single company alone.\"\n\nAmodei is one of the AI industry's most vocal proponents of AI legislation. While Meta and Microsoft supported a federal preemption of state-level AI laws, Anthropic supported AI transparency bills in California and New York that are now law.\n\nThroughout the essay, Amodei outlined multiple areas for future legislation, including industry-wide transparency requirements like those at the state level. Even he concludes that new laws might not be enough.\n\n\"The rapid progress of AI may create situations that our existing legal frameworks are not well designed to deal with,\" he wrote.\n\nIt's why Amodei said he would go so far as to support a constitutional amendment. The US has not amended the Constitution since 1992, when the over two-century-long battle to add a limitation on congressional pay finally passed the 38th state legislature.\n\n\"I would support civil liberties-focused legislation (or maybe even a constitutional amendment) that imposes stronger guardrails against AI-powered abuses,\" he wrote.",
    "readingTime": 7,
    "keywords": [
      "changed amodei's",
      "constitutional amendment",
      "critical period",
      "essay amodei",
      "models",
      "risks",
      "humanity",
      "it's",
      "doing",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dario-amodei-ai-essay-most-interesting-quotes-2026-1",
    "thumbnail_url": "https://i.insider.com/6977ee07a645d118818804ed?width=1200&format=jpeg",
    "created_at": "2026-01-27T06:21:23.459Z",
    "topic": "finance"
  },
  {
    "slug": "i-created-a-simple-guide-to-the-best-ai-tools-for-absolute-beginners",
    "title": "I Created a Simple Guide to the Best AI Tools for Absolute Beginners",
    "description": "Discover the best AI tools for beginners in 2025 for work, study, and productivity. Easy-to-use AI apps with real-world benefits.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://xthe.com/ai/ai-tools-beginners/",
    "thumbnail_url": "https://xthe.com/wp-content/uploads/2026/01/Best-AI-Tools-for-Beginners.png",
    "created_at": "2026-01-27T01:02:12.450Z",
    "topic": "tech"
  },
  {
    "slug": "ai-motion-control",
    "title": "AI Motion Control",
    "description": "AI Motion Control platform for transferring movements and expressions from videos to images. Create lifelike video animations with precision.",
    "fullText": "Premier platform for professional AI Motion Control. We empower creators to synchronize complex movements and facial expressions from reference videos to static images with surgical precision.\n\nUpload a character image and a reference motion video. Our AI extracts movements and expressions to animate your image with stunning precision.\n\nWhen Character Orientation matches the video, complex motions perform better; when it matches the image, camera movements are better supported.\n\nClick any example below to preview the motion transfer results\n\nAt aimotioncontrol.net, we don't just generate video; we engineer motion. Our AI Motion Control technology solves the fundamental chaotic nature of diffusion models, anchoring every frame to your exact creative intent.\n\nTransfer movement from any source video to your target character with industry-leading AI Motion Control precision. Unlike standard image-to-video tools that guess movement, our system locks onto the skeletal structure of your reference footage. This ensures that every nuance of the original performance captures the energy and intent of the actor, regardless of the target character's design.\n\nOur AI Motion Control algorithms ensure that every limb, joint, and subtle shift in weight is perfectly transferred. Whether it's a complex dance routine featuring rapid spins or a specific stunt requiring perfect timing, the output matches the input with 99% anatomical accuracy, preserving the physics of the original motion.\n\nMaintain character identity across all frames without distortion. Traditional AI struggles with keeping a character's face and clothes consistent during rapid movement, often resulting in morphing textures. AI Motion Control utilizes temporal attention layers to preserve details from the first frame to the last, ensuring your character looks the same at frame 100 as they did at frame 1.\n\nApply the motion of a human actor to a stylized character (anime, 3D render, claymation) instantly. AI Motion Control handles the stylistic translation while keeping the physics of the movement grounded in reality. You can drive a cartoon character with a human performance or map a human's walk cycle onto a robotic creature.\n\nThe system intelligently adjusts the motion to fit the proportions of your target character. If you map a tall actor's motion to a short goblin character, AI Motion Control automatically recalculates the stride length and center of gravity to ensure the movement looks natural and physically plausible.\n\nClone nuanced facial expressions for emotional storytelling with our dedicated facial AI Motion Control engine. Eyes, mouth shapes, and micro-expressions are mapped faithfully, allowing you to convey complex emotions that standard AI models fail to capture.\n\nSuperior accuracy in mapping complex facial expressions. A smile isn't just a curve of the lips; it's the crinkle of the eyes and the lifting of cheeks. AI Motion Control captures it all, distinguishing between a smirk, a grin, and a laugh with pixel-perfect precision.\n\nPerfect lip synchronization for talking heads and dialogue. Input your audio track, and our AI Motion Control system aligns the mouth movements frame by frame for believable speech, making it an ideal tool for virtual news anchors or storytelling.\n\nEnsure your character is looking exactly where they should be. AI Motion Control allows for precise direction of eye movement, essential for dramatic scenes and connection with the audience. You can control the focal point of your character's attention throughout the video.\n\nCapture the fleeting moments of emotion that bring a character to life. A slight furrow of the brow or a quick widening of the eyes—these subconscious signals are preserved by AI Motion Control, adding a layer of psychological depth to your animations.\n\nAccess a curated collection of movements for instant animation. Don't have a reference video? Use our library powered by AI Motion Control pre-sets to immediately bring your static images to life with professional-grade motion.\n\nBrowse and apply professional motions from our extensive library. From walking and running to complex martial arts, our AI Motion Control database is ready to animate your static images. We categorize motions by intensity, style, and genre for easy discovery.\n\nUpload your own reference videos for unique motion control. The system analyzes your footage and creates a custom motion LoRA that can be applied to any character. You can build your own private library of proprietary movements for your studio.\n\nCombine different motions or blend them together. AI Motion Control allows for smooth transitions between different action states, creating long, continuous takes. You can have a character walk, stop, look around, and then run, all seamlessly blended.\n\nEnsuring smooth, flicker-free motion in long-form videos is the hallmark of professional AI Motion Control. We eliminate the 'boiling' effect common in generative video, delivering broadcast-quality stability.\n\nProprietary algorithms to eliminate jitter and artifacts. By analyzing the optical flow between frames, our AI Motion Control engine corrects anomalies before they render. It acts as a digital stabilizer, smoothing out the noise inherent in diffusion models.\n\nSpecifically optimized for longer duration video generation. Most tools break down after 4 seconds. AI Motion Control maintains coherence for up to 60 seconds of continuous video without the character losing their identity or structural integrity.\n\nGenerate videos at 60fps or higher. AI Motion Control interprets the motion between frames to interpolate smooth motion, making your results broadcast-ready. Create slow-motion effects or crisp, realistic action sequences.\n\nOne of the toughest challenges in AI video is keeping the artistic style consistent while the subject moves. AI Motion Control solves this by decoupling motion from style modules.\n\nWhether your source image is an oil painting, a cyberpunk digital art piece, or a sketch, AI Motion Control ensures that the texture and brushstrokes move naturally with the character, rather than staying static like a screen overlay.\n\nAs your character moves through the virtual space, AI Motion Control calculates how the lighting should simulate on their changing geometry. Shadows wrap correctly, and highlights shift naturally, maintaining the 3D illusion of the 2D generation.\n\nKeep your background stable while your character moves. Our system identifies the subject and generates a clean plate for the background, preventing the warping and 'breathing' background issues seen in other tools.\n\nForget about expensive GPUs and complex installations. AI Motion Control delivers workstation-power directly to your browser through our optimized cloud infrastructure. Create without limits.\n\nCreate high-fidelity animations on any device, from a standard laptop to a tablet. We handle the compute-intensive diffusion processes on our enterprise-grade GPU clusters, freeing your machine from overheating and lag.\n\nDon't wait for one video to finish before starting the next. Our scalable architecture supports parallel processing, allowing you to run multiple motion experiments simultaneously. Iterate faster and find the perfect shot in a fraction of the time.\n\nOur cloud platform means you always have access to the latest AI Motion Control models and features the moment they are released. Say goodbye to managing local Python environments, installing dependencies, or downloading massive model weights.\n\nFrom social media viral hits to professional film production, AI Motion Control delivers the precision required for top-tier content.\n\nCreate high-end social media content and viral marketing campaigns. In the fast-paced world of TikTok and Instagram, stopping the scroll is everything. AI Motion Control allows brands to create eye-popping, impossible visuals that capture attention instantly. Imagine your mascot dancing perfectly to the latest trend, or your product assembling itself in mid-air. AI Motion Control makes this accessible without a Hollywood budget.\n\nProfessional film pre-visualization and character storyboarding. Directors can now visualize scenes with animated characters before a single camera starts rolling. AI Motion Control allows for rapid iteration of blocking and staging. Instead of stick figures or rough drawings, see your characters move and act in the actual environment, saving millions in production costs.\n\nDevelop realistic virtual influencers and digital brand ambassadors. The virtual human economy is booming, but stiff, robotic movement breaks the illusion. AI Motion Control gives your digital avatars lifelike movements and expressions, allowing them to connect with audiences authentically. Generate daily content for your virtual star without needing a motion capture suit every time.\n\nCreate personalized AI-driven dance and performance videos. Choreograph complex routines for your digital characters using simple reference videos. AI Motion Control excels at capturing the fluidity of dance, preserving the elegance of ballet or the snap of hip-hop, and applying it to any character you design.\n\nAccelerate asset creation for indie games. AI Motion Control can generate sprite sheet animations or cutscene videos from simple references, drastically reducing the animation workload for small teams.\n\nShowcase clothing on moving models without a photoshoot. AI Motion Control can take a flat image of a dress and a video of a model walking, and generate a video of the model wearing that dress, moving naturally.\n\nSelect the plan that best fits your creative needs. Unlock the full potential of AI Motion Control.\n\nEverything you need to know about our technology and how it helps you create better videos.\n\nJoin the revolution of precise AI video generation. Don't settle for randomness. Start creating lifelike animations today with the power of AI Motion Control.\n\nTrusted by professional creators worldwide",
    "readingTime": 8,
    "keywords": [
      "ai motion control",
      "social media",
      "static images",
      "professional film",
      "facial expressions",
      "diffusion models",
      "reference videos",
      "target character",
      "ai motion control we",
      "complex"
    ],
    "qualityScore": 1,
    "link": "https://aimotioncontrol.net",
    "thumbnail_url": "https://aimotioncontrol.net/og.png",
    "created_at": "2026-01-27T01:01:52.735Z",
    "topic": "tech"
  },
  {
    "slug": "eu-opens-investigation-into-musks-ai-chatbot-grok-over-sexual-deepfakes",
    "title": "E.U. opens investigation into Musk's AI chatbot Grok over sexual deepfakes",
    "description": "Officials in the European Union opened a formal investigation into Elon Musk’s social media platform X over the AI chatbot Grok, which has been creating nonconsensual sexualized deepfake images. Grok sparked a global backlash by allowing users, through its AI image generation and editing capabilities, to undress people, putting women and even children in transparent bikinis or revealing clothing. NBC News' Hala Gorani explains how the chatbot works and its history of controversy.",
    "fullText": "Officials in the European Union opened a formal investigation into Elon Musk’s social media platform X over the AI chatbot Grok, which has been creating nonconsensual sexualized deepfake images. Grok sparked a global backlash by allowing users, through its AI image generation and editing capabilities, to undress people, putting women and even children in transparent bikinis or revealing clothing. NBC News' Hala Gorani explains how the chatbot works and its history of controversy.",
    "readingTime": 1,
    "keywords": [
      "chatbot",
      "grok"
    ],
    "qualityScore": 0.2,
    "link": "https://www.yahoo.com/news/videos/e-u-opens-investigation-musks-000458229.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/sUleDp8BCsm5Df31wmD..Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://media.zenfs.com/en/nbcu_713/aad87e5c975aeb81874dfa9cd98e38dc",
    "created_at": "2026-01-27T01:01:49.614Z",
    "topic": "news"
  },
  {
    "slug": "ai-enthusiasts-are-running-clawdbot-on-their-mac-minis-but-you-probably-shouldnt",
    "title": "AI Enthusiasts Are Running 'Clawdbot' on Their Mac Minis, but You Probably Shouldn't",
    "description": "If you care about your privacy and security, don't use this viral AI tool.",
    "fullText": "I am a self-professed AI skeptic. I have yet to really find much of a need for all these AI-powered assistants, as well as many AI-powered features. The most useful applications in my view are subtle—the rest seem better suited for shareholders than actual people.\n\nAnd yet, the AI believers have a new tool they're very excited about, which is now all over my feeds: Clawdbot. Could this agentic AI assistant be the thing that makes me a believer as well? Spoiler alert: probably not.\n\nIf you're deep in the online AI community, you probably already know about Clawbot. For the rest of us, here's the gist: Clawdbot is a \"personal AI assistant\" designed to run locally on your devices, as opposed to cloud-based options. (Think ChatGPT, Gemini, or Claude.) In fact, Clawdbot runs any number of AI models, including those from Anthropic, OpenAI, Google, xAI, and Perplexity. While you can run Clawdbot on Mac, Linux, and Windows, many online are opting to install the bot on dedicated Mac mini setups, leading to one part of the assistant's virality.\n\nBut there are other AI assistants that can be run locally—one thing that makes Clawdbot unique is that you communicate with it through chat apps. Which app you use is up to you, as Clawdbot works with apps like Discord, Google Chat, iMessages, Microsoft Teams, Signal, Telegram, WebChat, and WhatsApp. The idea is that you \"text\" Clawdbot as you would a friend or family member, but it acts as you'd expect an AI assistant to—except, maybe more so.\n\nThat's because, while Clawdbot can certainly do the things an AI bot like ChatGPT can, it's meant more for agentic tasks. In other words, Clawdbot can do things for you, all while running in the background on your devices. The bot's official website advertises that it can clear your inbox, send emails, manage your calendar, and check you in for flights—though power users are pushing the tool to do much more.\n\nClawdbot works with a host of apps and services you might use yourself. That includes productivity apps like Apple Notes, Apple Reminders, Things 3, Notion, Obsidian, Bear Notes, Trello, GitHub; music apps like Spotify, Sonos, and Shazam; smart home apps like Philips Hue, 8Sleep, and Home Assistant; as well as other major apps like Chrome, 1Password, and Gmail. It can generate images, search the web for GIFs, see your screen, take photos and videos, and check the weather. Based on the website alone, it has a lengthy résumé.\n\nThe last big point here is that Clawdbot has an advertised \"infinite\" memory. That means the bot \"remembers\" every interaction you've ever had with it, as well as all the actions it's taken on your behalf. In theory, you could use Clawdbot to build apps, run your home, or manage your messages, all within the context of everything you've done before. In that, it'd really be the closest thing to a \"digital assistant\" we've seen on this scale. These assistants have been mostly actionable—you ask the bot what you want to know or what you want done, and it (hopefully) acts accordingly. But the ideal version of Clawdbot would do all those things for you without you needing to ask.\n\nNot everyone is psyched about Clawdbot, though. Take this user, who jokes that, after four messages, the bot made a reservation, then, after six messages, was able to send a calendar invite, only to cost $87 in Opus 4.7 tokens. This user came up with a story (at least I hope it's a story) where they give Clawdbot access to their stock portfolio and tasked it with making $1 million without making mistakes. After thousands of reports, dozens of strategies, and many scans of X posts, it lost everything. \"But boy was it beautiful.\"\n\nI particularly like this take, which reads: \"[I've] made a tragic discovery using [Clawdbot.] [There] simply aren’t that many tasks in my personal life that are worth automating.\" There are also some jabs from what appear to be anti-AI users, like this one, that imagines a Clawdbot user with no job living in their parent's basement, asking the bot to do their tasks for the day.\n\nAs with all things AI, there are many thoughts, opinions, and criticisms here, especially considering how viral this new tool is. But the main critique seems to be that Clawdbot requires a lot (in terms of hardware, power, and privacy) without really offering much in return. Sure, it can do things for you, but do you really need a bot booking your plane tickets, or combing through your emails? The answer to that, I suppose, is up to each of us, but the \"backlash,\" if you can call it that, is likely coming from people who would answer \"no.\"\n\nIf you want to try Clawdbot, you'll likely need to have some technical experience first. You can get started from Clawdbot's official github page, as well as Clawdbot's \"Getting started\" guide. According to this page, you'll begin by running the Clawdbot onboarding wizard, which will set you up with the gateway, workspace, channels, and skills. This works on Mac, Linux, and Windows, and while you won't need a Mac mini, it seems to be what the Clawdbot crowd is running with.\n\nFull disclosure: Clawdbot and its setup go beyond my expertise, and I will not be installing it on my devices. However, if you have the knowledge to follow these instructions, or the will to learn, the developer has the steps listed in the links above.\n\nWhile I likely wouldn't install Clawdbot on my device anyway, the privacy and security implications here definitely keep me away.\n\nThe main issue with Clawdbot is that it has full control and access over whichever device you run it on, as well as any of the software that is running therein. That makes sense, on the surface: How is an agentic AI supposed to do things on your behalf if it does have access to the apps and hardware necessary for execution?\n\nBut the inherent security risk with any program like this involves prompt injection. Bad actors could sneak their own AI prompts into otherwise innocent sites and programs. When your bot crawls the text as it completes your task, it intercepts the prompt, and, thinking it's from you, executes that prompt instead. It's the main security flaw with AI browsers, and it could affect something like Clawdbot, too. And since you've given Clawdbot control over your entire computer and everything in it...yikes. Bad actors could manipulate Clawdbot to theoretically send DMs to anyone they like, run malicious programs, read and write files on your computer, trick Clawdbot into accessing your private data, and learn about your hardware for further cyber attacks.\n\nIn Clawdbot's case, these prompt injections could come from a number of sources. They could come from messages via bad actors through the chat apps you communicate through Clawdbot, they could come from the browsers you use to access the internet, and they could come from plugins you run on various programs, to name a few possibilities.\n\nClawdbot does have a security guide on its site that walks you through ways to shore up your defenses while using Clawdbot. The developer admits that running an AI agent with shell access on your machine is \"spicy,\" that this is both a product and an experiment, and that there is no \"perfectly secure\" setup. That said, there are security features built in here that serve a purpose and attempt to limit who can access Clawdbot, where Clawdbot can go, and what Clawdbot can do. That could involve locking down DMs, viewing links and attachments as \"hostile\" by default, reducing high-risk tools, and running modern AI models that have better protections against prompt injection.\n\nStill, the whole affair is too risky for me, especially considering I'm not sure I really want an AI assistant in the first place. I think companies believe we want to offload tasks like calendars, messages, and creation to bots, to save us time from menial to-do lists. Maybe some do, but I don't. I want to know who is reaching out to me and why, and not trust an AI to decide what messages are worth my attention. I want to write my own emails and know what events I have on my own calendar. I also want access to my own computer. Maybe some people trust AI enough to handle all these things for them—if it makes me a luddite to feel the opposite, so be it.",
    "readingTime": 8,
    "keywords": [
      "mac linux",
      "mac mini",
      "prompt injection",
      "chat apps",
      "mac linux and windows",
      "clawdbot",
      "access",
      "assistant",
      "messages",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/what-is-clawdbot-ai?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFXSQPJ1XNQ3RAR6Y5ZY4E0T/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-27T01:01:49.583Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-its-newest-ai-chip-maia-200-is-3-times-more-powerful-than-googles-tpu-and-amazons-trainium-processor",
    "title": "Microsoft says its newest AI chip Maia 200 is 3 times more powerful than Google's TPU and Amazon's Trainium processor",
    "description": "The Maia 200 AI chip is described as an inference powerhouse — meaning it could lead AI models to apply their knowledge to real-world situations much faster and more efficiently.",
    "fullText": "When you buy through links on our articles, Future and its syndication partners may earn a commission.\n\nMicrosoft has revealed its new Maia 200 accelerator chip for artificial intelligence (AI) that is three times more powerful than hardware from rivals like Google and Amazon, company representatives say.\n\nThis newest chip will be used in AI inference rather than training, powering systems and agents used to make predictions, provide answers to queries and generate outputs based on new data that's fed to them.\n\nMaia 200 is already being deployed in Microsoft's U.S. central data center region, with the company set to use the chips to generate synthetic data and in reinforcement training to improve next-generation large language models (LLMs). The AI accelerator will also be used to power Microsoft Foundry and 365 Copilot AI, and be part of the infrastructure that the company can provide through its Azure cloud platform.\n\nThe new chip delivers performance of more than 10 petaflops (1015 floating point operations per second), Scott Guthrie, cloud and AI executive vice president at Microsoft, said in a blog post. This is a measure of performance in supercomputing, where the most powerful supercomputers in the world can reach more than 1,000 petaflops of power.\n\nThe new chip achieved this performance level in a data representation category known as \"4-bit precision (FP4)\" — a highly compressed model designed to accelerate AI performance. Maia 200 also delivers 5 PFLOPS of performance in 8-bit precision (FP8). The difference between the two is that FP4 is far more energy efficient but less accurate.\n\n\"In practical terms, one Maia 200 node can effortlessly run today’s largest models, with plenty of headroom for even bigger models in the future,\" Guthrie said in the blog post. \"This means Maia 200 delivers 3 times the FP4 performance of the third generation Amazon Trainium, and FP8 performance above Google’s seventh generation TPU.\"\n\nMaia 200 could potentially be used for specialist AI workloads, such as running larger LLMs in the future. So far, Microsoft's Maia chips have only been used in the Azure cloud infrastructure to run large-scale workloads for Microsoft’s own AI services, notably Copilot. However, Guthrie noted there would be \"wider customer availability in the future,\" signaling other organizations could tap into Maia 200 via the Azure cloud, or the chips could potentially one day be deployed in standalone data centers or server stacks.\n\nGuthrie said that Microsoft boasts 30% better performance per dollar over existing systems thanks to the use of the 3-nanometer process made by the Taiwan Semiconductor Manufacturing Company (TSMC), the most important fabricator in the world, allowing for 100 billion transistors per chip. This essentially means that Maia 200 could be more cost-effective and efficient for the most demanding AI workloads than existing chips.\n\nMaia 200 has a few other features alongside better performance and efficiency. It includes a memory system, for instance, which can help keep an AI model’s weights and data local, meaning you would need less hardware to run a model. It's also designed to be quickly integrated into existing data centers.\n\nMaia 200 should enable AI models to run faster and more efficiently. This means Azure OpenAI users, such as scientists, developers and corporations, could see better throughput and speeds when developing AI applications and using the likes of GPT-4 in their operations.\n\n—'It won’t be so much a ghost town as a zombie apocalypse': How AI might forever change how we use the internet\n\n— GPT-4 has passed the Turing test, researchers claim\n\n—The more advanced AI models get, the better they are at deceiving us — they even know when they're being tested\n\nThis next-generation AI hardware is unlikely to disrupt everyday AI and chatbot use for most people in the short term, as Maia 200 is designed for data centers rather than consumer-grade hardware. However, end users could see the impact of Maia 200 in the form of faster response times and potentially more advanced features from Copilot and other AI tools built into Windows and Microsoft products.\n\nMaia 200 could also provide a performance boost to developers and scientists who use AI inference via Microsoft’s platforms. This, in turn, could lead to improvements in AI deployment on large-scale research projects and elements like advanced weather modeling, biological or chemical systems and compositions.",
    "readingTime": 4,
    "keywords": [
      "azure cloud",
      "bit precision",
      "performance",
      "chip",
      "models",
      "maia",
      "hardware",
      "chips",
      "systems",
      "delivers"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/copilot/articles/microsoft-says-newest-ai-chip-160218268.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/LjtJXpYNgdxD26Hg6MZI0Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/live_science_953/61555169799e4adf9db65dcfb9bffe8e",
    "created_at": "2026-01-27T01:01:49.077Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-invests-2-billion-in-coreweave-to-boost-data-center-buildout",
    "title": "Nvidia invests $2 billion in CoreWeave to boost data center build-out",
    "description": "Nvidia has invested $2 billion in CoreWeave, becoming the AI infrastructure provider's second-largest shareholder, as the companies expand their partnership ​to boost data center capacity in the United States.  The announcement on ‌Monday sent CoreWeave's shares up 9% in premarket trading.  So-called neocloud companies like CoreWeave, which provide tech ‌companies with the hardware and cloud capacity needed to build, run and deploy AI technologies, have seen a surge in demand in recent years as enterprise adoption of AI picks up.",
    "fullText": "Jan 26 (Reuters) - Nvidia has invested $2 billion in CoreWeave, becoming the AI infrastructure provider's second-largest shareholder, as the companies expand their partnership ​to boost data center capacity in the United States.\n\nThe announcement on ‌Monday sent CoreWeave's shares up 9% in premarket trading.\n\nSo-called neocloud companies like CoreWeave, which provide tech ‌companies with the hardware and cloud capacity needed to build, run and deploy AI technologies, have seen a surge in demand in recent years as enterprise adoption of AI picks up.\n\nThe fresh investment from Nvidia will help CoreWeave speed ⁠up the procurement of land ‌and power required to build data centers. CoreWeave is targeting to build more than 5 gigawatts in AI data center ‍capacity by 2030.\n\nNvidia will invest in CoreWeave at a purchase price of $87.20 per share, the companies said. That represents an addition of roughly 23 million shares, nearly doubling ​Nvidia's stake in the firm, according to Reuters calculations based on data ‌compiled by LSEG.\n\nNvidia was CoreWeave's third largest shareholder with a 6.3% stake, or 24.3 million shares, in the company.\n\nThe chip giant has drawn scrutiny for pouring billions of dollars into AI firms including ChatGPT maker OpenAI and neoclouds, raising investor concerns about potential circular financing.\n\nA CoreWeave spokesperson told Reuters that the ⁠cash from the new investment will not ​be used to purchase Nvidia processors, but directed ​toward accelerating other data center investments, research and development, and scaling its workforce.\n\nOnce a cryptocurrency miner, CoreWeave has pivoted to capitalize ‍on the AI ⁠boom by repurposing its infrastructure to lease Nvidia GPUs to tech and AI firms.\n\n\"Nvidia is the leading and most requested computing platform at every ⁠phase of AI ... This expanded collaboration underscores the strength of demand we are seeing across ‌our customer base,\" CoreWeave CEO Michael Intrator said.",
    "readingTime": 2,
    "keywords": [
      "center capacity",
      "shares",
      "coreweave",
      "nvidia",
      "infrastructure",
      "shareholder",
      "coreweave's",
      "tech",
      "demand",
      "investment"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-invests-2-billion-coreweave-130850099.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/fc68365e933d0e527a1fcb2a482700fa",
    "created_at": "2026-01-27T01:01:47.523Z",
    "topic": "finance"
  },
  {
    "slug": "ranking-the-eagles-remaining-oc-candidates-using-artificial-intelligence",
    "title": "Ranking the Eagles' remaining OC candidates using artificial intelligence",
    "description": "What happens when we plug the names of the best remaining Eagles OC candidates into ChatGPT's engine?",
    "fullText": "Once we turn the calendar from January's final Monday to Tuesday, we'll enter a third week dedicated to the Philadelphia Eagles' offensive coordinator search. Names have changed, but the climate and landscape remain familiar.\n\nNames have been added to the mix. Candidates have withdrawn from consideration. The general public remains confused. Not even one full year after hoisting the Lombardi Trophy, none of the top options are interested in becoming the Eagles' top offensive assistant.\n\nPerhaps Philadelphia is exercising patience? Maybe Brian Daboll mentioned the Tennessee Titans and Buffalo Bills to give the impression that he had more options? Perhaps he was trying to rush Philadelphia into a decision?\n\nMaybe he was truly in the running for jobs with those two franchises. Who knows? Those are questions we're throwing out for fodder. No one has all of the information. We're all trying to piece this together. What we do know is that no one likes all of the remaining candidates we're told are still in the running.\n\nWho is the best fit for Jalen Hurts? How do we describe the best fit for the roster overall? Who carries the most red flags? Is there any long-term stability for any of these guys?\n\nAs we ventured through Championship Sunday, we learned the Eagles had interest in Arthur Smith before he accepted the Ohio State Buckeyes job. Once we began another workweek, it was learned that Charlie Weis Jr. had removed his name from consideration. Hours later, Declan Doyle arrived at the same decision.\n\nJust for kicks, we took a breather. We plugged a few names into ChatGPT and asked who the best candidates were for the Eagles' OC job. What we learned was AI's list looks a lot like some of our own. Here's what they came up with. Keep in mind that we aren't sure whether Brian Daboll is still in the running.\n\nAI gives Brian Daboll a five-star rating as a potential OC hire, citing he has the best chance to elevate Jalen Hurts immediately. He lands atop the list because he has already done the job before and has previously had success working with Josh Allen.\n\nMike Kafka lands second on the list. His approach seems to emphasize rhythm and being 'on time'. Those are areas where we have seen Jalen Hurts struggle. That could lead to questions, but Kafka has coached mobile quarterbacks before and understands how to blend run concepts into the passing game.\n\nFrank Smith is one of the new additions to this list. He worked with Mike McDaniel as his offensive coordinator. He's intriguing and shouldn't be viewed as someone the Eagles are pursuing, since he was closest to one of the guys they actually wanted.\n\nNagy is a descendant of the Andy Reid coaching tree. He never quite recovered from the 'Double-Doink Game'. Word has it that he even had kickers audition for a job the following season by kicking from the same spot that Cody Parkey missed the go-ahead field goal attempt in the Wild Card Game.\n\nNagy is better than the reputation suggests. He could do a good job in returning to the place where his coaching career began.\n\nHere's one of the guys we know the least about, yet AI ranks him fifth-best. Settling on him means the Eagles would have placed more emphasis on potential than on proof and his resume.\n\nJerrod Johnson is another of the new additions to the Eagles' OC conversation. He is a good teacher, but this may be a mismatch in terms of need. Known as a QB developer, he would be asked to grow into his new role a la Kevin Patullo. If you remember that ultimately led to Patullo's undoing. Johnson might be a 'wrong place, wrong time' candidate, but again, these are only opinions we're sharing.\n\nSome would rank Jim Bob Cooter higher. He actually has OC experience. There's an obvious low ceiling here, as there isn't much evidence that he elevates quarterbacks or builds innovative systems that let them do what they do best.\n\nThe Eagles need to reinvent their offense, and they need to reinvent Jalen Hurts to some degree. They need someone who understands how to do both. None of these guys is a slam-dunk hire in that regard.\n\nAll have positives. All have flaws. One of the most important decisions of the offseason keeps being weighed. One false move and Philadelphia will throw away another season.\n\nThis article originally appeared on Eagles Wire: Ranking Eagles' remaining OC candidates using artificial intelligence",
    "readingTime": 4,
    "keywords": [
      "offensive coordinator",
      "jalen hurts",
      "eagles oc",
      "brian daboll",
      "candidates",
      "we're",
      "guys",
      "list",
      "learned",
      "another"
    ],
    "qualityScore": 1,
    "link": "https://sports.yahoo.com/articles/ranking-eagles-remaining-oc-candidates-181501769.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/2DT2DutgTRojB05W6HgqZg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/philadelphia_eagles_wire_usa_today_sports_articles_352/77a3e8d8d6a3a3fee555a566b676a46b",
    "created_at": "2026-01-26T18:22:20.909Z",
    "topic": "sports"
  },
  {
    "slug": "1m-ai-websites-contributed-70m-to-anguillas-government-revenue-last-year",
    "title": ">1M \".ai\" websites contributed $70M to Anguilla's government revenue last year",
    "description": "Data from Domain Name Stat reveals that the top-level domain originally assigned to the British Overseas Territory of Anguilla passed the milestone...",
    "fullText": "Data from Domain Name Stat reveals that the top-level domain originally assigned to the British Overseas Territory of Anguilla passed the milestone in early January.\n\nFrom Sandisk shareholders to vibe coders, AI is making — and breaking — fortunes at a rapid pace.\n\nOne unlikely beneficiary has been the British Overseas Territory of Anguilla, which lucked into a future fortune when ICANN, the Internet Corporation for Assigned Names and Numbers, gave the island the “.ai” top-level domain in the mid-1990s. Indeed, since ChatGPT’s launch at the end of 2022, the gold rush for websites to associate themselves with the burgeoning AI technology has seen a flood of revenue for the island of just ~15,000 people.\n\nIn 2023, Anguilla generated 87 million East Caribbean dollars (~$32 million) from domain name sales, some 22% of its total government revenue that year, with 354,000 “.ai” domains registered.\n\nAs of January 2, 2026, the number of “.ai” domains surpassed 1 million, per data from Domain Name Stat — suggesting that the nation’s revenue from “.ai” has likely soared, too. This is confirmed in the government’s 2026 budget address, in which Cora Richardson Hodge, the premier of Anguilla, said, “Revenue from domain name registration continues to exceed expectations.”\n\nThe report mentions that receipts from the sale of goods and services came in way ahead of expectations, thanks primarily to the revenue from “.ai” domains, which is forecast to hit EC$260.5 million (~$96.4 million) for the latest year. In 2023, domain name registrations were about 73% of that wider category. Assuming a similar share of that category for this year would suggest that the territory has raked in more than ~$70 million from “.ai” domains in the past year.\n\nAnguilla typically charges $140 for a two-year domain registration, creating a steady stream of income, as some 90% of domains renew after two years. But auctions for expired “.ai” domains, sold via domain name registrar Namecheap, are where bigger numbers roll in — for example, the domain “you.ai” was bought for $700,000 last September, and even in the past week, 31 expired “.ai” domains were sold at a total price of ~$1.2 million, per domain sale tracker NameBio.",
    "readingTime": 2,
    "keywords": [
      "british overseas",
      "overseas territory",
      "top-level domain",
      "domain name stat",
      "domains",
      "revenue",
      "island",
      "registration",
      "expectations",
      "sale"
    ],
    "qualityScore": 1,
    "link": "https://sherwood.news/tech/now-more-one-million-ai-websites-contributing-an-estimated-70-million-anguilla-government-revenue/",
    "thumbnail_url": "https://sherwoodnews.imgix.net/mwphzyq69oso/en-US/assets/files/1438940144_little-bay-beach.jpg?w=1600&auto=compress%2Cformat&cs=srgb",
    "created_at": "2026-01-26T18:21:40.891Z",
    "topic": "tech"
  },
  {
    "slug": "agents-are-about-to-change-software",
    "title": "Agents Are About to Change Software",
    "description": "Man, it is a really weird time in the software world right now. Like a lot of people, when I picked up ChatGPT and Midjourney back in late 2022. It felt like wizardry. For a year I experimented and…",
    "fullText": "Man, it is a really weird time in the software world right now. Like a lot of people, when I picked up ChatGPT and Midjourney back in late 2022. It felt like wizardry.\n\nFor a year I experimented and experimented. I wrote about how Midjourney responds to emojis and even tried to see if I could write a children’s book with AI. The output here looks pretty rough today, but it was a revelation at the time. And the AI tools just kind of gradually got better and better.\n\nOne thing that never really clicked for me though was agentic coding. The vision is that you tell an LLM what you want, and it just goes off and executes it. It never really worked that well. It felt like the agents just kind of plowed through code and broke a bunch of stuff on the way to making the fix I wanted. Coding agents were more a curiosity, not something I could actually use.\n\nHowever, this is all about to change. And it is going to change everything about how software is built.\n\nI was drawn back by a post called Welcome to Gas Town by Steve Yegge.\n\nGas Town is part visionary, part performance art. It’s a Mad Max-themed fever dream that enables agents, managing agents, managing agents. There’s a mayor, rigs, polecats, a deacon and a refinery—and they all work together in this vast factory where vibes go in and code comes out.\n\nThere’s a lot of really clever ideas that somewhat mesh together. You’ve probably heard about the context window LLMs have. Essentially it’s their short-term memory. Once an agent uses about 20% of its context window, its intelligence drops off a cliff and it starts doing insane things like dropping databases.\n\nGas Town employs a trick to manage that issue. It assigns tasks to ephemeral “Polecat” agents. Polecats do a task and then disappear—basically removing the challenge of managing context windows.\n\nMaggie Appleton articulated the value of Gas Town well:\n\nWe should take Yegge’s creation seriously not because it’s a serious, working tool for today’s developers (it isn’t). But because it’s a good piece of speculative design fiction that asks provocative questions and reveals the shape of constraints we’ll face as agentic coding systems mature and grow.\n\nAnd so, intrigued by Gas Town, I decided to try vibe coding again.\n\nI’m not the type to just dip my toes in. If I’m going to do something, I do a cannonball.\n\nI’m always looking for the meta. What is the best strategy and who knows how to execute it? I read that Anthropic’s CTO keeps five agents running constantly and barely looks at the actual files. Either that’s marketing or there must be something there, or maybe both?\n\nI read a bunch of articles and watched a ton of YouTube videos. YouTube was pretty wild. There are these videos with guys streaming 5-10 Claude Code terminals, blaring EDM (lol) and managing all these agents.\n\nI’m kind of poking fun, but I actually learned a lot about setup from that BridgeMind channel. If you’re interested I might start with his videos about Warp and the OpenCode CLI.\n\nI wanted to see how well these agents actually work, but I needed an easy entry point. A Chrome extension to restyle Hacker News seemed perfect. It’s been in my backlog for a while, and because it’s purely frontend, I knew I’d be comfortable judging the output.\n\nAnd honestly it was. Initially I tried to one-shot the thing and—as I expected—that was a failure. But then I decided to slow down. I told the agent to scaffold a chrome extension to restyle Hacker News pages. It worked. And I kind of just broke up these tasks into smaller pieces. Tested them as I went.\n\nSure there were bugs. But I kind of just did what I do when I’m reviewing any engineers’ code. Inspect the DOM, look at the styles, look at the console and then give feedback. When the context window hit’s 20% I typically close that window and open a new chat. The OpenCode CLI even allows you to drop screenshots. It’s pretty wild.\n\nNow, I don’t have a dozen agents running at the same time. I never felt the need to have more than two working. And I’m honestly not sure how UI work even gets shipped in Gas Town? My guess is Yegge is probably a lot less concerned with UX than I am.\n\nWith AI agents, the last mile—that final polish and detailing—will be critical. We already see this in Salesloft, where sellers review generative emails before sending. In design, it manifests as small UI tweaks. It will be something else for doctors and something else for mechanical engineers. But I think there is a real opportunity in refining how humans interact with the agent’s output, creating better loops for feedback and adjustment.\n\nYou know what? There’s something here though. I don’t really like the term “vibe coding.” And I know the concept is polarizing. But after tinkering with this stuff for a couple days—I think agents are about to change how we build software.\n\nThe conception of what it looks like to make software is going to change pretty quickly.\n\nThe three major functions on a delivery team (or feature team) are engineering, design and product management. I’ve long thought we’re going to start to see more overlap in those functions. I’m even more sure of it now.\n\nI think we’re going to start to see a hybrid role emerge—product engineer.\n\nWhat does this mean delivery teams will look like in the future? I imagine they are either significantly smaller or significantly more productive. I’m not sure if QA is embedded into these teams the same way they are currently or if there is a separate team of—well, people managing QA agents. I have a lot of questions.\n\nThis also makes me think a lot about Ben Thompson’s theory on bundling and unbundling. From 2010 to 2015, companies quickly moved on the back of frameworks. First like Ruby on Rails and Bootstrap. Then on other technologies like Angular and React. The speed these frameworks provided caused an unbundling in the software world.\n\nPoint solutions were able to move fast and gather steam while slow incumbents either weren’t nimble enough or weren’t in a place to capitalize on the productivity provided by frameworks. Starting in 2016, that changed. Customers were overwhelmed with choices. Larger companies caught on and smaller ones consolidated into larger platforms.\n\nI think that’s about to shift again. And probably this year.\n\nDavid Cummings called it out in his newsletter this weekend. SaaS companies are about to see a massive wave of new competition. And it is going to happen extremely fast. The bar to build software has been lowered. A two-person team will soon be able to build what used to take a whole department.\n\nThis puts incumbent software companies in a pretty dangerous situation. Those that are not able to be nimble and go fast are going to be in real trouble. I think this is especially true in the consumer, SMB and mid-market segments. Enterprise software may have some buffer as customers of enterprise software are buying a process more than the software itself.\n\nHonestly, it makes me a little nervous. The industry is going to change and everyone’s jobs are going to look a little different—product design included.\n\nBut as someone who got into software just because I wanted to make things, this is a dream come true. I’m seeing a glimpse of the vision I hoped for in 2022. It’s not just a toy anymore. It’s an unbelievable tool for builders.\n\nIf you’ve been ignoring AI tools because you think they are overhyped, or maybe don’t see how they fit into your workflow. I’d encourage you to give them another look.",
    "readingTime": 7,
    "keywords": [
      "restyle hacker",
      "chrome extension",
      "agentic coding",
      "vibe coding",
      "pretty wild",
      "context window",
      "enterprise software",
      "gas town",
      "agents managing",
      "hacker news"
    ],
    "qualityScore": 1,
    "link": "https://solomon.io/agents-are-about-to-change-software/",
    "thumbnail_url": "https://solomon.io/wp-content/uploads/2026/01/WelcomeToGasTown-2200x1196.jpg",
    "created_at": "2026-01-26T18:21:39.265Z",
    "topic": "tech"
  },
  {
    "slug": "the-windows-pc-is-dying-thanks-to-cloudbased-services-and-ai",
    "title": "The Windows PC is dying, thanks to cloud-based services and AI",
    "description": "The rise of AI tools and services has added a new twist to the decline and fall of standalone Windows PCs.",
    "fullText": "For years, I’ve been watching the slow evolution of classic Windows PCs into cloud-based Windows and Office services. Sure, you can still buy a PC with Windows on it, but you’re not really “buying” Windows as much as renting it.\n\nWindows cloud PCs have gone from Microsoft’s side project to the centerpiece of its post‑Windows‑10 strategy. But the story in 2026 is less “death of the PC” and more “merger of PC, cloud, and AI under Microsoft’s terms.” Today, the most interesting question is not whether Windows moves to the cloud, but how much local control users are willing to surrender in exchange for AI‑infused desktops.\n\nFor the longest time, Microsoft had planned on the Windows 365 Cloud PC to shift users from a PC‑centric world to Desktop‑as‑a‑Service, with Windows 11 acting as the on‑ramp. Microsoft’s own internal slideware later made that explicit: the plan is to “move Windows 11 increasingly to the cloud… to enable a full Windows operating system streamed from the cloud to any device.” What started as the Business and Enterprise editions of Windows 365, running on Azure with per‑user monthly pricing in the $30-to-$60 range, has since been productized and polished as if it were the “real” Windows roadmap rather than a side hustle.\n\nOther harbingers included Windows 365 Boot, which bypassed the local operating system entirely and dropped you straight into a personalized cloud desktop on shared or BYOD hardware. And Windows 365 Switch blurs the boundary between local and hosted sessions, turning a cloud PC into “just another desktop.”\n\nAt the same time, Windows App enables you to run Azure Virtual Desktop, Windows 365, Microsoft Dev Box, Remote Desktop Services, and remote PCs from, well, pretty much any computing device. Specifically, you can use Windows App to run Windows on Macs, iPhones, iPads, other Windows machines, even in web browsers. That last means you can now run Windows on Linux-powered PCs, Chromebooks, and Android phones and tablets.\n\nHeck, you can even run Windows using a Meta Quest VR headset!\n\nA funny thing happened on the way to this cloud-based subscription service. AI came along. Microsoft, which has gone whole-hog into AI — if I see one more Copilot tie-in, I’m going to scream — decided that AI PCs would be the future. It’s wrong.\n\nAs Kevin Terwilliger, Dell’s head of product, said of PC customers, “They’re not buying based on AI. I think AI probably confuses them more than it helps them.” (Ya think?)\n\nThat’s not to say people aren’t using AI. They are. But, no one’s managed to sell them yet on the idea of agentic AI PCs, even with the special sauce of Neural Processing Units (NPUs), Intel Panther Lake chips, and super-duper GPUs. Most analysts, and at least one cranky Computerworld columnist (guess who), think the Copilot+ PC hype needs to end.\n\nJeff Bezos — remember him? he knows a thing or two about the cloud — suggested that the PC is never going to be able to deliver the AI goods. Instead, “AI will be in everything,” but compute will be delivered via the cloud. In case you missed it, at the last Ignite conference, Microsoft highlighted its Windows 365 cloud PC concept, with AI agents, not AI PCs.\n\nGoing forward, Microsoft will want you not to buy and run your own applications, AI-infused or not, on a PC. They’ll want you to subscribe and run “your” AI-enabled programs on their cloud services.\n\nThis will not be cheap. Today, the bottom-end Windows 365 Cloud PC with 2 virtual CPUs, 4GB RAM, and 64GB of storage will cost you $28 a month. Good luck running Windows 11 on its own, never mind with any application, on 4 gigs of RAM. The absolute minimum for a useful cloud desktop with 8GB of RAM is $41. Add in AI functionality, an instance of Office, and you’re talking real money.\n\nFor companies, math is being reframed. Instead of comparing Windows 365 to the sunk cost of a once‑every‑five‑years PC purchase, vendors pitch it against the fully burdened price of securing, patching, and managing a distributed fleet in a hybrid‑work world. In that context, a per‑seat cloud desktop subscription stops looking like a weird outlier and just another SKU on the Microsoft subscription treadmill.\n\nI’m old enough to recall the transition from centralized computers you used via a terminal to the locally owned PC revolution. Then, we controlled the “horizontal and the vertical.” The AI-enabled cloud desktop puts Microsoft in charge of the entire application stack and your online identity.\n\nIt might be 2026, but Microsoft’s business model going forward looks a lot like the ones I saw in 1976. Maybe you’re comfortable with that. I’m not.\n\nMicrosoft frames Windows 365 as the sane way to keep corporate data off home PCs shared with kids and games, which is hard to argue with if you are a CSO signing audit reports. But the shift to cloud PCs plus on‑device AI also deepens lock‑in. Sure, you can run Windows 365 from anything, but it runs best when paired with Windows 11 hardware.\n\nThe old Windows desktop is dying. The 2026 twist is that its successor does not live only in Microsoft’s cloud. It also lives on your desk, in your laptop, and in the NPU you did not ask for, all stitched together into a Windows that is becoming less an operating system and more a metered utility.\n\nMe? You know my bias. If you want control over your privacy, your data, how much you’re paying for compute, and your PC, Linux is the best way forward.",
    "readingTime": 5,
    "keywords": [
      "operating system",
      "cloud pcs",
      "cloud desktop",
      "windows cloud",
      "windows cloud pc",
      "windows app",
      "ai pcs",
      "microsoft",
      "microsoft’s",
      "you’re"
    ],
    "qualityScore": 1,
    "link": "https://www.computerworld.com/article/4119219/the-windows-pc-is-dying-thanks-to-cloud-based-services-and-ai.html",
    "thumbnail_url": "https://www.computerworld.com/wp-content/uploads/2026/01/4119219-0-46063300-1769172402-windows-365-100945479-orig.jpg?quality=50&strip=all&w=1024",
    "created_at": "2026-01-26T18:21:38.022Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-takes-aim-at-google-amazon-and-nvidia-with-new-ai-chip",
    "title": "Microsoft takes aim at Google, Amazon, and Nvidia with new AI chip",
    "description": "Microsoft announced its new Maia 200 AI chip, taking aim at Amazon, Google, and Nvidia.",
    "fullText": "Microsoft (MSFT) is taking aim at cloud rivals Amazon (AMZN) and Google (GOOG, GOOGL) with the debut of its next-generation custom AI chip.\n\nCalled Maia 200, the chip will run in Microsoft’s own data centers before the company eventually makes it available to its wider customer base.\n\nLike Google’s TPUs and Amazon’s Trainium processors, Microsoft’s second AI chip is meant to give the Windows maker more flexibility when it comes to how it powers its AI services. By using its own internally developed chips, the company ensures it doesn’t have to rely solely on processors developed by Nvidia (NVDA) or AMD (AMD).\n\nGoogle and Amazon have been using their own custom chips for years, while Microsoft has been slower to adopt in-house AI silicon.\n\nAccording to Microsoft, the Maia 200 will be built using TSMC’s 3-nanometer process and is designed to run large-scale AI workloads, while “delivering efficient performance per dollar.”\n\nThe Maia 200 will be built into large server racks with trays housing four chips each. Microsoft is also touting how quickly it can deploy the new chips into data centers, saying chips are installed and running AI models within days of parts arriving.\n\nGetting AI servers up and running quickly is an important aspect of the broader data center business. It’s not just a matter of keeping construction costs down, either. The longer a chip goes unused, the less cash it can generate for the company by running AI apps.\n\nThe Maia 200 adds to the growing competition Nvidia is facing from both AMD and its own customers. Microsoft’s Maia 100 already powers both the company’s and OpenAI’s (OPAI.PVT) AI models, while Google and Amazon both power their respective models and Anthropic’s (ANTH.PVT) models.\n\nAnd in November, The Information reported that Meta was talking to Google about using the search giant’s TPUs in its own data centers to power its AI services. That sent Nvidia stock down at the time, as Wall Street raised fears that the company was in danger of losing market share.\n\nNvidia’s stock price is up less than 1% since the start of the year.\n\nDespite the incursions into Nvidia’s lane, Google, Amazon, and Microsoft are unlikely to pose a serious threat to the AI leader. Experts say that while the cloud company’s AI chips may function well for their own services, that’s not likely to translate to smaller third-party customers as easily.\n\nNvidia’s chips are also highly coveted because they are designed to be multipurpose, allowing companies to use them for a litany of applications and services.\n\nAs for performance, the Maia 200 won’t unseat Nvidia, but Microsoft claims it outpaces both Google’s latest TPU and Amazon’s newest Trainium chip in a number of categories. The Maia 200 also packs more high-bandwidth memory than Google’s or Amazon’s offerings, which is key to running high-powered AI applications.",
    "readingTime": 3,
    "keywords": [
      "the maia",
      "chips",
      "chip",
      "services",
      "models",
      "centers",
      "google’s",
      "nvidia’s",
      "cloud",
      "custom"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-takes-aim-at-google-amazon-and-nvidia-with-new-ai-chip-160027494.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/6hrTce0mQfjD5UJl9IfFFA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2021-06/7a86bbd0-d429-11eb-bd9f-5b30fa82b522",
    "created_at": "2026-01-26T18:21:33.390Z",
    "topic": "finance"
  },
  {
    "slug": "the-eu-is-probing-grok-over-its-spreading-of-sexual-ai-images",
    "title": "The EU is probing Grok over its spreading of sexual AI images",
    "description": "The EU is investigating X over the spread of illegal images, including possible child sexual abuse material, generated by Grok on the platform.",
    "fullText": "The European Union is launching an investigation into Grok as Elon Musk's AI chatbot continues to face backlash over its spreading of AI-generated sexual images.\n\nThe European Commission, the bloc's governing body, said on Monday that it had opened a formal investigation into X over the spread of illegal images, including possible child sexual abuse material, generated by Grok on the social media site.\n\nThe Commission said it would also extend an ongoing investigation into X's recommendation algorithm, with the regulator previously fining the social media platform $140 million over its \"deceptive\" blue checkmarks.\n\nUnder the EU's Digital Services Act, large social media platforms can face fines of up to 6% of their global annual turnover for violations, and temporary suspension from the European Union as a last resort.\n\nWhen asked for comment on the new investigation, xAI sent an automatic email response that did not address the issue.\n\nIt comes after X said earlier this month that it had implemented \"technological measures\" to prevent users from editing images of real people into revealing clothing, after a wave of global backlash over the circulation of AI-generated sexual images on the site.\n\nX made the change after California's attorney general and the UK media regulator both launched investigations into Grok — but Business Insider's Henry Chandonnet found that the AI chatbot could still be used to make sexualized images in the days after.\n\nGrok was also temporarily banned in Malaysia, Indonesia, and the Philippines over the AI images, although Malaysia and the Philippines later said they would lift their bans after receiving assurances from xAI.\n\nMusk responded to the criticism on X in early January, telling one user, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"",
    "readingTime": 2,
    "keywords": [
      "ai-generated sexual",
      "illegal content",
      "social media",
      "sexual images",
      "grok",
      "investigation",
      "chatbot",
      "face",
      "backlash",
      "site"
    ],
    "qualityScore": 0.55,
    "link": "https://www.businessinsider.com/eu-probing-grok-sexual-ai-images-xai-elon-musk-2026-1",
    "thumbnail_url": "https://i.insider.com/69775325e1ba468a96aaadd4?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.681Z",
    "topic": "finance"
  },
  {
    "slug": "finland-is-trying-to-poach-top-tech-and-ai-talent-from-the-us-with-2week-visas-and-better-worklife-balance",
    "title": "Finland is trying to poach top tech and AI talent from the US with 2-week visas and better work-life balance",
    "description": "Finland wants to lure American engineers and researchers with fast-track visas and good work-life balance as part of the global AI talent wars.",
    "fullText": "Finland is stepping into the tech talent wars.\n\nThe Nordic country is making a push for tech workers from abroad, with a particular focus on the US. The goal is to attract engineers and researchers working in deep tech, especially in the fields of quantum computing, AI, and health innovation.\n\nThe effort comes as competition for AI talent intensifies worldwide and tech workers in the US grapple with layoffs, burnout, and visa complications. KPMG's annual survey of global CEOs found that 70% were concerned about competition for AI talent. According to BCG's 2024 talent tracker report, the US remained dominant in attracting AI talent worldwide.\n\nAlready known for its tech scene, Finland, with a population of around 5.6 million, is positioning itself as a place where American tech workers can find a better work-life balance without sacrificing their careers — a notable contrast to the famous grindset of Silicon Valley.\n\n\"Of course, there might be long days once in a while, but it's such a high value, and it's also protected by law that you can't work more than an average of 40 hours per week,\" Laura Lindeman, head of the Work in Finland program, told Business Insider.\n\nShe said that even in the tech sector, when people leave work for the day, they really do leave. \"Offices are silent,\" she said. Employers in Finland, often ranked the happiest country in the world, also see the benefit of workers having lives outside work, she said, adding that the general sentiment is \"it narrows your thinking if you only work.\"\n\nFinland is working with more than 30 Finnish tech companies and universities to promote open roles to foreign workers. A preview of the job openings being promoted under the program includes roles with Oura Health (the company behind the Oura Ring), quantum computing firm QMill, and Aalto University.\n\nLindeman said Americans interested in working in Finland should consider reaching out to companies or universities, even if no open roles are listed, as some employers are open to creating positions for the right candidate. While the campaign emphasizes the US, it also targets talent from India, Brazil, and other parts of Europe.\n\nOnce candidates receive a job offer, they can apply for a specialist visa through Finland's Fast Track program. Approved applicants can receive a work-residence permit in as little as two weeks, with processing times averaging about 10 days, Lindeman said. Finland also offers integration programs to help newcomers settle in, and spouses of workers on specialist visas are eligible for work permits, she added.\n\nGovernment data suggests interest from Americans is already rising. Finland granted 60 specialist residence permits to US citizens in 2024 and 85 in 2025, according to Finnish immigration statistics. The number of residence permits granted to US researchers also increased, from 35 in 2024 to 46 in 2025.\n\nJordan Blake Banks, an American who moved to Finland in 2019 to pursue a master's degree through the Fulbright program, said the country offers plenty of benefits, from its forests to its emphasis on work-life balance. After finishing her degree, Banks stayed in Finland and eventually landed a job as a sustainability consultant at Deloitte in Helsinki.\n\n\"The general idea is that the company and the colleagues respect you as a person, and that you can have your free and personal time,\" she said, adding parents regularly leave work during the day for family obligations without stigma. Many Finns also take about a month of vacation during the summer, along with time off in the winter.\n\nBanks said salaries in Finland tend to be lower than in comparable roles in the US, but she thinks the gap is offset by more affordable essential services, including healthcare, education, and childcare.\n\nWhile learning Finnish isn't necessary for working in the country — Lindeman said English is widely used in the tech industry, and about 80% of Finns speak fluent English — Banks said not knowing the language can feel isolating in everyday life.\n\nShe enrolled in a four-month integration program run by the city, where she learned the language and eventually passed the national exam required to become a Finnish citizen. Banks also met her now-wife while living in Finland.\n\nOne cultural adjustment of living in Finland, she said, has been that the people tend to be more reserved than Americans. \"If you're coming from a very friendly culture or a very warm culture, I think that could be a shock,\" she said, adding she'd been able to use that to her advantage.\n\nBanks said speaking up helped her land a paid research position at her university. \"I was willing to make contact and be the brave American willing to ask for things,\" she said.",
    "readingTime": 4,
    "keywords": [
      "quantum computing",
      "work-life balance",
      "residence permits",
      "tech workers",
      "talent",
      "program",
      "finnish",
      "roles",
      "finland",
      "adding"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/finland-us-tech-ai-talent-work-life-balance-fast-visas-2026-1",
    "thumbnail_url": "https://i.insider.com/69734b95a645d1188187dba0?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.547Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-is-buying-more-coreweave-stock-this-time-its-in-for-2-billion",
    "title": "Nvidia is buying more CoreWeave stock — this time it's in for $2 billion",
    "description": "Nvidia is deepening its partnership with CoreWeave and making its biggest investment yet in the AI cloud company.",
    "fullText": "Nvidia is getting the checkbook out again for CoreWeave, buying $2 billion worth of the cloud company's stock.\n\nCoreWeave said on Monday that alongside the investment, the two companies would build \"AI factories\" together.\n\nThe partnership aims to help CoreWeave accelerate its buildout of AI infrastructure with 5 gigawatts of capacity by 2030.\n\n\"From the very beginning, our collaboration has been guided by a simple conviction: AI succeeds when software, infrastructure, and operations are designed together,\" said Michael Intrator, the cofounder, chairman, and CEO of CoreWeave, in a press release.\n\nNvidia made its latest investment in CoreWeave at a purchase price of $87.20 per share.\n\nCoreWeave's share price was up nearly 10% in premarket trading.\n\nCoreWeave, which builds data centers full of AI chips known as graphics processing units, or GPUs, has had a close relationship with Nvidia for several years.\n\nNvidia invested about $100 million in CoreWeave in 2023, then acquired more shares around the time of its IPO in March 2025.\n\nAlongside its equity investments, Nvidia also sells its chips to CoreWeave, a dynamic that has contributed to broader industry concerns about circular AI deals.",
    "readingTime": 1,
    "keywords": [
      "nvidia",
      "coreweave",
      "investment",
      "together",
      "infrastructure",
      "chips",
      "alongside"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/nvidia-buys-2-billion-coreweave-stock-ai-partnership-2026-1",
    "thumbnail_url": "https://i.insider.com/69776c03d3c7faef0ecce718?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.387Z",
    "topic": "finance"
  },
  {
    "slug": "ai-has-made-hiring-worsebut-it-can-still-help",
    "title": "AI Has Made Hiring Worse—But It Can Still Help",
    "description": "While AI has the potential to transform hiring, it’s important to be realistic about what has actually happened so far. For all the talk about AI supercharging talent, the reality is that talent markets remain as inefficient as ever, with employers struggling to find the right person for the right job, while employees remain disenchanted with their jobs and careers. Thanks to AI, hiring has become a noisy, crowded arms race of automation, often more inhumane for both job seekers and hiring managers. The result is an ecosystem where both sides are inundated, sometimes fooled, occasionally impressed, and mostly exhausted, with a rising crisis of trust. To improve hiring, leaders must resist the temptation to treat AI as a cure-all.",
    "fullText": "AI Has Made Hiring Worse—But It Can Still Help by Tomas Chamorro-PremuzicJanuary 26, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintI have been researching, speaking, and writing about the impact of AI in hiring for years, long before large language models entered the mainstream. AI’s deep penetration in recruitment was always likely. People spend much of their lives online, including while working (or pretending to), while firms have invested trillions in digital systems designed to capture, store, and analyze the resulting data from this. A technology like AI, capable of translating this ocean of data into insight was therefore inevitable.",
    "readingTime": 1,
    "keywords": [
      "hiring"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/ai-has-made-hiring-worse-but-it-can-still-help",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_24_SamuelFinch.jpg",
    "created_at": "2026-01-26T18:21:28.523Z",
    "topic": "business"
  },
  {
    "slug": "for-multinational-companies-localization-matters-more-than-ever",
    "title": "For Multinational Companies, Localization Matters More Than Ever",
    "description": "Companies now face conflicting trade regimes, strict data sovereignty rules, and rising government expectations that key activities be executed within national borders. In response, leading multinationals are evolving into networks of regionally embedded businesses that still share a unified global strategy. Their success depends on building autonomous regional capabilities across every function, shaping the regulatory and ecosystem rules in the markets where they operate, and competing at the speed enabled by AI-driven intelligence systems.",
    "fullText": "For Multinational Companies, Localization Matters More Than Ever by Muqsit Ashraf, Tomas Castagnino and Giju MathewJanuary 26, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintFor decades, multinational companies treated localization as a surface-layer adjustment. They tweaked marketing, packaging, or pricing to suit regional tastes. But in today’s fractured world, such superficial localization is no longer good enough. Trade policies conflict. Data laws clash. And many governments now enforce data sovereignty laws and mandates for local sourcing and technology transfer. They require companies to perform key operations, stretching from research and development to manufacturing and data processing, within their country, instead of merely selling products from abroad. The result is a profound shift in how global companies operate. They duplicate supply chains, adjust to local markets in real time, and integrate national and regional suppliers, even at the cost of scale efficiencies, to ensure redundancy and tailor best practices for every market.",
    "readingTime": 1,
    "keywords": [
      "localization",
      "multinational",
      "regional",
      "laws"
    ],
    "qualityScore": 0.65,
    "link": "https://hbr.org/2026/01/for-multinational-companies-localization-matters-more-than-ever",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_24_2224218103.jpg",
    "created_at": "2026-01-26T18:21:28.466Z",
    "topic": "business"
  },
  {
    "slug": "georgia-leads-push-to-ban-datacenters-used-to-power-americas-ai-boom",
    "title": "Georgia leads push to ban datacenters used to power America’s AI boom",
    "description": "Southern state becoming ground zero in fight against rapid growth of facilities using huge amounts of energy and water\nLawmakers in several states are exploring passing laws that would put statewide bans in place on building new datacenters as the issue of the power-hungry facilities has moved to the center of economic and environmental concerns in the US.\nIn Georgia a state lawmaker has introduced a bill proposing what could become the first statewide moratorium on new datacenters in America. The bill is one of at least three statewide moratoriums on datacenters introduced in state legislatures in the last week as Maryland and Oklahoma lawmakers are also considering similar measures.\n Continue reading...",
    "fullText": "Southern state becoming ground zero in fight against rapid growth of facilities using huge amounts of energy and water\n\nLawmakers in several states are exploring passing laws that would put statewide bans in place on building new datacenters as the issue of the power-hungry facilities has moved to the center of economic and environmental concerns in the US.\n\nIn Georgia a state lawmaker has introduced a bill proposing what could become the first statewide moratorium on new datacenters in America. The bill is one of at least three statewide moratoriums on datacenters introduced in state legislatures in the last week as Maryland and Oklahoma lawmakers are also considering similar measures.\n\nBut it is Georgia that is quickly becoming ground zero in the fight against untrammelled growth of datacenters – which are notorious for using huge amounts of energy and water – as they power the emerging industry of artificial intelligence.\n\nThe Georgia bill seeks to halt all such projects until March of next year “to allow state, county and municipal-level officials time to set necessary policies for regulating datacenters … which permanently alter the landscape of our state”, said bill sponsor state Democratic legislator Ruwa Romman.\n\nIt comes at a time when Georgia’s public service commission – the agency that oversees utility company Georgia Power – just last month approved a plan to provide 10 additional gigawatts of energy in the coming years. It was the largest amount of electricity sought for a multi-year plan in the commission’s history, was driven by datacenters and will mostly be supplied by fossil fuels.\n\nThe 10-gigawatt plan – enough to power about 8.3m homes – in turn comes as the Atlanta metro area led the nation in datacenter construction in 2024.\n\nThis accelerated growth has already led at least 10 Georgia municipalities to pass their own moratoriums on datacenter construction, with Atlanta suburb Roswell becoming the most recent earlier this month. Municipalities in at least 14 states have done the same, according to Tech Policy Press.\n\nBernie Sanders, the Vermont independent democratic socialist senator, proposed a national moratorium last month.\n\n“What we’re seeing is, as communities are learning more about this aggressive industry’s presence … [they] want to have time to thoroughly investigate all potential harms,” said Seth Gladstone, spokesperson for Food and Water Watch.\n\nThe rampant development of datacenters to power AI raises several concerns for residents and activists alike. One is their impact on the cost of electricity. “In the public’s mind, datacenters and utility bills are inextricably linked,” said Charles Hua, founder and executive director of PowerLines, an organization that works on lowering utility bills and involving communities in decisions about energy.\n\nHua noted that the relationship between the two varies, depending on each state’s market and regulatory system. In Georgia, he said, the Georgia Power utility company makes profit off new capital investments – so it has incentive to keep building new power plants. This approach has led Georgia’s rates to go up by a third in the last several years alone. Meanwhile, he said, the power company doesn’t have incentive to make the electrical grid more efficient – which “could actually lower prices”, Hua said.\n\nBut datacenter concerns in Georgia also include water use and lost tax revenue. Republicans in the state legislature have introduced bills this year to protect consumers from increases in their utility bills and to end tax breaks for the centers. A Democrat has proposed that datacenters make public how much energy and water they use each year.\n\nRomman is also running for governor. If elected, she would become the first Palestinian American elected to statewide office in Georgia and break the near quarter-century hold Republicans have on the office.\n\nHer bill, HB 1012, has a Republican co-sponsor in state representative Jordan Ridley, who said he signed onto the measure because he wanted to give local governments time to develop zoning regulations on datacenters, since “it seems like they’re being built across the state”.\n\n“Every local government has zoning codes and … they need public input. That takes time,” Ridley said. At the same time, Ridley added, “datacenters … provide tax revenue and high-paying jobs. I’m not against datacenters.”\n\nRomman’s bill is not just a policy proposal; it’s also a political one. In a statement, she wrote that the moratorium “would provide time for Georgians to vote on the majority of the Public Service Commission seats who make final decisions on energy-related projects”.\n\nGeorgia is one of 10 states that elect their utility regulators. Voters in the state elected progressive Democrats Alicia Johnson and Peter Hubbard to the five-member commission in November, leading the agency to lose its all-Republican makeup for the first time in nearly two decades. Another seat is up for a vote this November.\n\nThe calculus: if the commission becomes majority-Democratic, it will no longer give a rubber stamp to electricity demands from Georgia Power driven by tech companies seeking to build datacenters.\n\nHubbard, now in his new position, recently wrote an editorial asserting that Georgia voters “see data centers receiving tax breaks as their power bills go up. They see local communities struggle with competition for water supplies and high voltage transmission lines that reduce property values. And they see how the PSC approved every request placed before it by the monopoly electric utility.\n\n“This is why opposition to data centers is growing in Georgia; because Georgians oppose being treated as collateral damage by the unregulated growth of data centers that will push their power bills even higher.”\n\nThere’s another political implication to Romman’s bill. Paul Glaze, spokesperson for Georgia Conservation Voters, said if the bill crosses from the House to the Senate, “it may be a preview of the potential general election” later this year.\n\n“The question is, in communities where datacenters are coming, who are voters going to trust to have their back?” Glaze said. “Anyone serious about statewide office should have a clear position on this.”",
    "readingTime": 5,
    "keywords": [
      "romman’s bill",
      "ground zero",
      "huge amounts",
      "datacenter construction",
      "service commission",
      "tax revenue",
      "tax breaks",
      "utility bills",
      "georgia power",
      "datacenters"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/26/georgia-datacenters-ai-ban",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7ea230ec26730557de8ddac52bc5c2b63dd66515/1213_0_3698_2959/master/3698.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a872fe2d94683fa97a6d6cf2c2af1bb0",
    "created_at": "2026-01-26T18:21:25.582Z",
    "topic": "tech"
  },
  {
    "slug": "pope-leos-latest-ai-warning-overly-affectionate-chatbots",
    "title": "Pope Leo's latest AI warning: 'overly affectionate' chatbots",
    "description": "Pope Leo XIV warned against personalized chatbots that can replicate friendly or intimate behaviour.",
    "fullText": "Even the pope is worried about how we're talking to chatbots.\n\nIn a written address for Saturday's World Day of Social Communications, Pope Leo XIV warned against personalized chatbots that can replicate friendly or intimate behavior.\n\n\"Overly affectionate chatbots, besides being ever-present and readily available, can become hidden architects of our emotional states, thereby invading and occupying the sphere of people's intimacy,\" the first-ever US-born pope wrote.\n\nThe pope called for national and international regulations to protect users from forming emotional, deceptive, or manipulative bonds with chatbots.\n\n\"All stakeholders — from the technology industry to policymakers, from creative businesses to academia, from artists to journalists and educators — must be involved in building and implementing a conscious and responsible digital citizenship,\" the pope wrote.\n\nThe Holy See leader has spoken about AI and his concerns with the technology several times since he was elected in May.\n\nIn his first address since becoming pope, he said he wanted to make AI a focus of his papacy and that the technology poses new challenges for \"human dignity, justice, and labor.\" In November, he wrote to AI leaders on X, calling on them to \"cultivate moral discernment\" when building AI tools.\n\nAt the end of last year, the pope met Megan Garcia, a woman whose 14-year-old son, Sewell Setzer, died by suicide after interacting with a Character.AI chatbot.\n\nFlorida-based Garcia filed a lawsuit against chatbot-building startup Character.AI, alleging that the company, which lets people have in-depth and personal conversations with AI chatbots, was responsible for the death of her son, Sewell Setzer III.\n\nEarlier this month, Google and the startup agreed to settle multiple lawsuits from families, including Garcia, whose teenagers died by suicide or hurt themselves after interacting with Character.AI's bots. These negotiations are among the first settlements in lawsuits that accuse AI tools of contributing to mental health crises and suicides among teenagers.",
    "readingTime": 2,
    "keywords": [
      "son sewell",
      "pope",
      "chatbots",
      "technology",
      "address",
      "emotional",
      "responsible",
      "tools",
      "died",
      "suicide"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/pope-leo-ai-warning-overly-affectionate-personalized-chatbots-regulation-2026-1",
    "thumbnail_url": "https://i.insider.com/6976fa35e1ba468a96aaace6?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.685Z",
    "topic": "finance"
  },
  {
    "slug": "google-cloud-gaming-boss-says-ai-is-the-iron-man-suit-for-game-developers-and-everyone-needs-to-get-on-board",
    "title": "Google Cloud gaming boss says AI is the Iron Man suit for game developers — and everyone needs to get on board",
    "description": "For Jack Buser, who has worked in the gaming industry for 30 years, AI is  an opportunity to push the boundaries of player experiences.",
    "fullText": "Tony Stark relied on his ultra-polished, tech-heavy \"Iron Man\" suit to achieve his superhero feats.\n\nJack Buser, the global director for games at Google Cloud, thinks AI will help game developers in the same way.\n\n\"There will always be holdouts, just like every technological revolution, but it's becoming so common now,\" Buser told Business Insider. \"We're seeing a major shift.\"\n\nBuser and other tech industry leaders have said that implementing AI could transform how people work. In the gaming industry, the tech could help streamline operations, resulting in cost cuts, faster production times, or help developers tackle an array of tasks.\n\n\"It's like the Iron Man suit of armor, right? It's still you inside the suit of armor, but you're suddenly able to do things that you couldn't do before,\" Buser said. \"If you armor everybody up in your studio with suits that allow them to work more quickly and remove the drudgery, that tends to be well received after it's been implemented.\"\n\nBuser urged executives at studios and companies to take the lead by giving developers the necessary tools.\n\n\"If you're the CTO of a games company, make that suit of armor available. Make sure that it's safe. Make sure that you take the time to work with people inside your company so that they can understand what the technology can and can't do, and what your intentions for the technology are and what they are not,\" Buser said.\n\n\"It has as much to do with getting these tools up and running in your development pipelines as it does working culturally with your company to help it make that transformation,\" he added.\n\nGetting comfortable with AI, he said, shouldn't be confined to developers alone.\n\n\"It can be tricky at the executive level. You don't have a crystal ball of where this is all going,\" he said. \"It takes getting your hands dirty, experimenting with the technology, seeing what it does and what it doesn't do.\"\n\nMany global industries are undergoing a technological shift driven by advances in AI. Companies are increasingly adopting the tech in their workflows, which some critics say could diminish job prospects for humans. Supporters argue it's a powerful tool that can help workers do their jobs better and faster.\n\nFor Buser, who has worked in the gaming industry for 30 years, AI has created an opportunity to push the boundaries of player experiences. At Google, that means embracing the era of \"living games.\"\n\nThe live games model, in which developers continue to add new content to a game after its initial release, is already common. AI, however, could make living games more adaptable, personalized, and immersive. The AI could also shorten update turnaround time, making the transition for players more seamless.\n\n\"As we look forward, we're looking at things like real-time game experiences,\" Buser said.\n\nFor now, though, the gaming industry will be focused on scaling and normalizing the tech.\n\n\"2026 is where companies start to scale these efforts,\" Buser said. \"Game developers who were using AI in one or two parts of their development workflow will suddenly be using it throughout their workflow. You'll start to see games that are using multiple AI-based features that are affecting the player experience.\"",
    "readingTime": 3,
    "keywords": [
      "man suit",
      "gaming industry",
      "game developers",
      "iron man",
      "games",
      "it's",
      "tech",
      "armor",
      "technology",
      "buser"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-gaming-developers-jack-buser-google-2026-1",
    "thumbnail_url": "https://i.insider.com/69768282d3c7faef0ecce384?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.539Z",
    "topic": "tech"
  },
  {
    "slug": "i-worked-at-joe-the-juice-before-founding-synthesia-a-4-billion-ai-unicorn-heres-how-i-structure-my-day",
    "title": "I worked at Joe & The Juice before founding Synthesia, a $4 billion AI unicorn. Here's how I structure my day.",
    "description": "Synthesia just raised a $200 million Series E funding round and is now valued at $4 billion. CEO Victor Riparbelli shares his daily routine.",
    "fullText": "This is an as-told-to essay based on a conversation with Victor Riparbelli, the CEO of AI video platform Synthesia. On Monday, the company announced a $200 million Series E funding round led by Google Ventures. This story has been edited for length and clarity.\n\nI founded Synthesia in 2017, and it's now a $4 billion unicorn.\n\nThe platform allows businesses to leverage generative AI to create videos for a range of corporate use cases, such as reimagining training videos, generating AI avatars of company executives to deliver internal or external messages, or dubbing webinars into dozens of languages.\n\nTo keep myself going all day, I rely on a few daily indulgences and productivity hacks.\n\nFirst and foremost, my bike. Unless the weather is terrible, I prefer to bike to and from the office most days. That's my most important ritual.\n\nAlso, coffee breaks. If I'm tired or in a bad mood, I'll go for a 15-minute walk and get an extra nice coffee at Blank Street.\n\nMy biggest non-negotiable indulgence is music. I love underground music and listen to it whenever I'm not in a meeting.\n\nI wish I were one of those 5 a.m. people, but I get up at 8 a.m., shower, and head straight to the office.\n\nI try not to check my phone before I leave my apartment, and I'm successful about 75% of the time.\n\nOnce I sit down at work, I usually go through my phone — messages, emails, and anything that came in overnight. I try to keep my early mornings free of meetings, so I have time to process things. That's when I feel the most creative, and it's when I prefer to do deep work. It's not always possible since we work across US time zones, but I generally try to protect that time. That deep-work window usually runs from around 9:30 a.m. until lunch at noon.\n\nDuring that time, I'm doing a mix of things: interviews, a lot of product work, and internal thinking. I'm still very involved in product and like to stay close to the details, even though that gets harder as the company grows. I focus on specific areas where I think my input is most valuable and try to go deep there.\n\nA big part of that time is also spent reading Slack. I make a real effort to read almost everything every day. I skim most of it, and I don't react to everything, but spending half an hour going through Slack is one of the best ways for me to understand what's actually happening across the company.\n\nAll internal communication happens on Slack — it's not a policy, it's just how the company operates. No one emails internally. For external communication, I probably split my time between email and WhatsApp, with a strong preference for WhatsApp and instant messaging. It really depends on the relationship.\n\nI usually have either a Joe & The Juice sandwich — specifically the club sandwich — or a salad. I actually used to work at Joe & The Juice early on, so I've been eating it for a long time and still love it.\n\nI don't really take time for lunch. I usually eat on the go or at my desk, and I'm typically done by around 12:30 p.m.\n\nI switch between New York and London, and when I'm based in London, the US starts to wake up in the second half of my day, so my calendar fills up with more international meetings.\n\nThe work itself stays fairly consistent: a lot of product, which I'm very involved in, as well as hiring, and external-facing work.\n\nMy cofounder, Steffen Tjerrild, now chief operating officer, and I split the business in half. I run product, technology, and marketing, while he oversees finance, operations, and sales. In those areas, I'm typically only involved at the VP level, depending on the situation. On my side of the business, I'm involved at the director level and above, though I'll sometimes go deeper when it makes sense.\n\nI have an assistant who helps manage my schedule, including some overlap with my personal life. I also try to talk to at least one user or customer every week because staying close to how people actually use the product is important to me. That, along with internal meetings, makes up most of the rest of my day. I still meet with people beyond my direct reports, often through skip-level conversations.\n\nFor example, I'll talk with our video team, who use our product for marketing, or with a sales development representative to understand what's working and what isn't. It's one of the best ways for me to stay connected to what's really happening across the company.\n\nI usually leave the office around 7 or 8 p.m. Three or four nights a week, I go to the gym, then head home and unwind. About half the time, I'll work another hour or two later in the evening.\n\nDinner is usually quick. I live alone and mostly order in, though I'll occasionally cook eggs with bacon and avocado. When I order food, it's often something simple like chicken and fries. I try to eat fairly healthy and avoid eating too late because it has a big impact on my energy, especially since I'm a bad sleeper.\n\nAt night, if I'm not working, I'm usually reading or making music. I don't watch much TV, but I love serious sci-fi films like \"Interstellar\" and \"Arrival\" and Stanley Kubrick movies like \"A Clockwork Orange.\"\n\nI used to read a lot of business books. \"Zero to One\" by Peter Thiel and Blake Masters, and \"The Black Swan\" by Nassim Nicholas Taleb were especially influential. These days, I read a mix of books and online content and spend a lot of time watching videos about technology, psychology, philosophy, and politics.\n\nI'm a terrible sleeper. The only hack that I found is that I fall asleep to podcasts or YouTube videos.\n\nI like to find ones that are interesting enough that they catch my attention — topics like physics or philosophy — but not important enough to me that I actually really want to listen to them.\n\nThen I put a sleep timer on for half an hour — and that usually knocks me out.",
    "readingTime": 6,
    "keywords": [
      "i'm typically",
      "understand what's",
      "joe the juice",
      "it's",
      "product",
      "i'll",
      "half",
      "videos",
      "internal",
      "involved"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/synthesia-ceo-victor-riparbelli-day-in-the-life-2026-1",
    "thumbnail_url": "https://i.insider.com/69680901764ca5f34d2a77d5?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.381Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musks-x-faces-eu-inquiry-over-sexualized-ai-images-generated-by-grok",
    "title": "Elon Musk's X Faces EU Inquiry over Sexualized AI Images Generated by Grok",
    "description": "Regulators said the company’s lack of controls had led to the widespread use of deepfakes created with the chatbot Grok.",
    "fullText": "European Union regulators on Monday announced an investigation of Elon Musk’s social media platform X after the authorities said that it had failed to stop the spread of sexualized images generated by artificial intelligence.\n\nThe inquiry is likely to escalate a confrontation between Europe and the United States over the regulation of online content. Mr. Musk and his allies in the Trump administration have sharply criticized European Union internet regulations as an attack on free speech and American companies.\n\nThe European authorities said that X was being investigated for possible violation of the Digital Services Act, alleging that the company had not properly addressed the “systemic risks” of integrating the A.I. chatbot Grok into its service. Starting in late December, sexually explicit images generated by Grok, including of children, flooded the service, drawing worldwide criticism from victims and regulators.\n\nMr. Musk was facing mounting scrutiny in Europe even before this latest Grok controversy. Last month, X was fined 120 million euros, or about $140 million, for violating Digital Services Act rules around deceptive design, advertising transparency and data sharing with outside researchers.\n\nThe European authorities have another investigation underway about X’s recommender algorithm and policies for preventing the spread of illicit content.\n\n“Nonconsensual sexual deepfakes of women and children are a violent, unacceptable form of degradation,” Henna Virkkunen, the European Commission executive vice president who oversees enforcement of the Digital Service Act, said in a statement. “We will determine whether X has met its legal obligations under the D.S.A., or whether it treated rights of European citizens — including those of women and children — as collateral damage of its service.”\n\nThe European Commission, the executive body for the 27-nation European Union, did not give a timeline for the investigation, but said that it had the authority to order X to make changes during the inquiry in the “absence of meaningful adjustments” to the service.\n\nA spokeswoman for X referred to a previous statement the company had made about Grok. “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, nonconsensual nudity and unwanted sexual content,” the statement said.\n\nThe latest investigation illustrates a growing divide between the European Union and the United States over free speech and regulation of the internet. European officials argue that the lack of safeguards on platforms like X has allowed hate speech, misogyny and violent content to flourish online. Mr. Musk and the Trump administration have said efforts to force the companies to more proactively police the services amounts to censorship.\n\nThe Digital Services Act, passed in 2022, requires companies to meaningfully address the spread of illegal content, the definition of which varies from country to country in the European Union. It can include material that targets individuals based on their race, ethnicity, gender, sexuality or religion.\n\nEuropean regulators said that the integration of Grok into X exposed “citizens in the E.U. to serious harm.” The British authorities are also investigating the issue.\n\nThe problems began last month. In response to simple user prompts on X, the chatbot automatically created and publicly posted manipulated photographs of real people, including children, to remove their clothes, put them in skimpy clothing or pose them in sexualized situations.\n\nAs criticism grew, X limited Grok’s A.I. image creation to users who paid for premium features, which reduced the number of images. X later expanded those guardrails, saying that it would no longer allow anyone to prompt Grok’s X account for “images of real people in revealing clothing such as bikinis.”\n\nEuropean Union regulators said that they would take X’s policy changes into account during the investigation.",
    "readingTime": 4,
    "keywords": [
      "trump administration",
      "digital services",
      "services act",
      "union regulators",
      "european commission",
      "free speech",
      "images generated",
      "european authorities",
      "mr musk",
      "united states"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/01/26/business/european-union-x-grok-ai-images-musk.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/01/26/multimedia/26biz-europe-musk1-gwcf/26biz-europe-musk1-gwcf-facebookJumbo.jpg",
    "created_at": "2026-01-26T12:26:56.703Z",
    "topic": "business"
  },
  {
    "slug": "eu-investigates-elon-musks-x-over-grok-ai-sexual-deepfakes",
    "title": "EU investigates Elon Musk's X over Grok AI sexual deepfakes",
    "description": "The Commission will assess whether \"manipulated sexually explicit images\" have been shown to users in the EU.",
    "fullText": "The European Commission has launched an investigation into Elon Musk's X over concerns its AI tool Grok was used to create sexualised images of real people.\n\nIt follows a similar announcement in January from the UK watchdog Ofcom.\n\nRegina Doherty, a member of the European parliament representing Ireland, said the Commission would assess whether \"manipulated sexually explicit images\" have been shown to users in the EU.\n\nA previous statement from X's Safety account said the social media platform had stopped Grok from digitally altering pictures of people to remove their clothing in \"jurisdictions where such content is illegal\".",
    "readingTime": 1,
    "keywords": [
      "grok",
      "images",
      "european",
      "commission"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bbc.com/news/articles/clye99wg0y8o",
    "thumbnail_url": "https://ichef.bbci.co.uk/news/1024/branded_news/d843/live/4b6f9a20-fa9d-11f0-a9b2-e154b2ff290d.jpg",
    "created_at": "2026-01-26T12:26:56.094Z",
    "topic": "tech"
  },
  {
    "slug": "why-im-launching-a-feminist-video-games-website-in-2026",
    "title": "Why I’m launching a feminist video games website in 2026",
    "description": "I’ve been a games journalist since 2007, but still there isn’t much video games coverage that feels like it’s specifically for people like me. So I’m creating a home for it: Mothership\nWhether you’re reading about the impending AI bubble bursting or about the video game industry’s mass layoffs and cancelled projects, 2026 does not feel like a hopeful time for gaming. What’s more, games journalists – as well as all other kinds of journalists – have been losing their jobs at alarming rates, making it difficult to adequately cover these crises. Donald Trump’s White House, meanwhile, is using video game memes as ICE recruitment tools, and game studios are backing away from diversity and inclusion initiatives in response to the wider world’s slide to the right.\nThe manosphere is back, and we’ve lost mainstream feminist websites such as Teen Vogue; bigots everywhere are celebrating what they see as the death of “woke”.",
    "fullText": "I’ve been a games journalist since 2007, but still there isn’t much video games coverage that feels like it’s specifically for people like me. So I’m creating a home for it: Mothership\n\nWhether you’re reading about the impending AI bubble bursting or about the video game industry’s mass layoffs and cancelled projects, 2026 does not feel like a hopeful time for gaming. What’s more, games journalists – as well as all other kinds of journalists – have been losing their jobs at alarming rates, making it difficult to adequately cover these crises. Donald Trump’s White House, meanwhile, is using video game memes as ICE recruitment tools, and game studios are backing away from diversity and inclusion initiatives in response to the wider world’s slide to the right.\n\nThe manosphere is back, and we’ve lost mainstream feminist websites such as Teen Vogue; bigots everywhere are celebrating what they see as the death of “woke”. Put it all together and we have a dismal stew of doom for someone like me, a queer woman and a feminist who’s been a games journalist and critic since 2007.\n\nEverything I just listed off in that paragraph speaks to an urgent need for something different. This is why I’m launching a gender and identity-focused gaming publication called Mothership. It’s independent and worker-owned; it will rely on subscribers’ support to exist. Mothership will focus on reporting on the good and bad of modern-day game-making – alongside investigations, reviews, criticism, and historical deep dives into games and developers who paved the way to now. It will be a website for people who read the news with dread, including gaming news, and worry that Gamergaters got what they always wanted. And it will be a place for readers who wish there was something like a Teen Vogue, but for games (and without a corporate owner to kneecap it).\n\nAfter all, the last two decades have seen a lot of actual, valuable change, and modern games are evidence of that. We exist, now, in a gaming world with more female characters, more non-binary characters, more queer characters, and more characters who don’t fall into rigidly defined gender stereotypes. The GDC State of the Game Industry survey for 2025 found that 66% of surveyed game developers were male, compared with 75% in 2020, and 94% in 2009.\n\nMore people than ever can now see themselves reflected in game characters, and more diverse development teams are creating them. But change has not come easy – and we’ve seen a lot of backlash to this progress. Few websites still in existence are able to cover this backlash while also keeping their reporters safe and motivated to continue.\n\nI have dreamed of founding a website like this for a long time; it’s not as if readers haven’t wanted it before now. The problem I saw with the idea was not that people wouldn’t want it, but rather that I didn’t see a good way to pay for it. Journalism has been facing a monetisation crisis since the advent of the internet. It’s hard to convince readers to pay for something they are used to getting for free.\n\nBut I know the readers are there. In the mid-2010s, I worked for a small “geek girl” feminist website called the Mary Sue, and it was a unique pleasure to write very specific articles for a very specific audience. The Mary Sue relied on advertising income, which meant that all of us had to write up to six articles every weekday; there wasn’t time to spend on investigative reporting, for example, or long-form critical essays. I’m still proud of what we achieved, despite the intensity of those working conditions, not to mention the amount of harassment we faced just for existing. But I always dreamed of working for a place that had the same editorial remit without the harsh working conditions and quotas.\n\nLater, I left the Mary Sue and went on to work for Kotaku and then Polygon, both huge games websites where I was writing for broader audiences, rather than the hyper-specific one we catered to at the Mary Sue. As I watched many smaller games websites crumble over the course of the 2010s and 20s, I figured this was the only type of games website that was going to survive. The idea of working for a small, feminist games website – my dream – increasingly looked like an impossible speck of starlight in a far-off galaxy.\n\nBut then, in the summer of 2025, my then-employer Polygon underwent a mass layoff and acquisition. We went from a staff of 42 people to just eight. After a particularly disheartening video call with our website’s new owners, I realised I was going to have to quit. Every piece of the dream felt well and truly dead. I had not got into journalism to be taken advantage of by people who saw me and my colleagues as so easily replaceable as to be barely human.\n\nAnother one of my colleagues at Polygon – Zoe Hannah, games editor – quit as well, for similar reasons. She hit me up with an idea she had for a feminist games website. “You should do it,” I told her. And then I sat there for a moment and thought about it. No, we should do it! This was what I had wanted to do, before the industry had transformed me into someone so gnarled and jaded that I no longer believed it was even possible.\n\nSix months on, after many DMs with former colleagues from Polygon, the Mary Sue and Kotaku, plus other notable writers who’ve covered gender and identity in games – Zoe and I are launching Mothership together, today. We have had the benefit of advice and inspiration from many other independent, worker-owned outlets that have come before us, such as Defector, the Flytrap, and Aftermath. Already, we’ve surpassed 1,200 paid subscribers. (I knew the readers were there.) And we don’t need millions of them. Mothership is a publication for a very specific audience: the people who don’t fit the mould of the masculine, hardcore gamer image that marketing and pop culture have been dishing out since the 90s. We want to serve this audience well.\n\nI believe our website is a necessity in our current political climate. It should have existed before, when I and millions of other girls who grew up playing games were made to feel out of place by media and advertising that was laser-focused on teenage boys. But it’s not too late for me to make sure it exists now.",
    "readingTime": 6,
    "keywords": [
      "games journalist",
      "games websites",
      "games website",
      "feminist games",
      "teen vogue",
      "mary sue",
      "readers",
      "characters",
      "gaming",
      "we’ve"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2026/jan/26/why-im-launching-a-feminist-video-games-website-in-2026-mothership",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dd63b58fefb35da6326795a77ef79bf9f01b0185/126_0_3780_3024/master/3780.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=7a90ac5398380a3e30ac7b64536fd367",
    "created_at": "2026-01-26T12:26:53.336Z",
    "topic": "gaming"
  },
  {
    "slug": "uk-maker-of-ai-avatars-nearly-doubles-valuation-to-4bn-after-funding-round",
    "title": "UK maker of AI avatars nearly doubles valuation to $4bn after funding round",
    "description": "Synthesia makes digital presenters for clients to use in corporate videos and counts 70% of FTSE 100 as customers\nA British AI startup that makes realistic video avatars has almost doubled its valuation to $4bn (£3bn), in a boost for the UK technology sector.\nSynthesia was valued at $2.1bn last year and moved into new offices in central London, marking the moment with a ceremony attended by the Sadiq Khan, the city’s mayor, and Peter Kyle, then technology secretary.\n Continue reading...",
    "fullText": "Synthesia makes digital presenters for clients to use in corporate videos and counts 70% of FTSE 100 as customers\n\nA British AI startup that makes realistic video avatars has almost doubled its valuation to $4bn (£3bn), in a boost for the UK technology sector.\n\nSynthesia was valued at $2.1bn last year and moved into new offices in central London, marking the moment with a ceremony attended by the Sadiq Khan, the city’s mayor, and Peter Kyle, then technology secretary.\n\nOn Monday, it announced its latest funding round, led by an existing investor, Google Ventures, had raised $200m and valued the British company at $4bn. Google Ventures is the search firm’s venture capital arm.\n\nSynthesia uses human actors to generate digital avatars of people and also offers employers the ability to create replicas of their staff. Those avatars are then deployed by organisations in corporate videos in a range of scenarios such as health and safety in the workplace, advising on cybersecurity and how to communicate better at work.\n\nThe company counts 70% of the FTSE 100 as clients, including NatWest, Lloyds Bank and British Gas. It is also used by non-corporate bodies including the NHS, the European Commission and the United Nations.\n\nThe startup is also developing new avatars that will help train employees and give them new skills, through scenarios such as role-playing and giving tailored explanations.\n\nSynthesia’s co-founder, Steffen Tjerrild, said the increased valuation reflected the commitment of the company’s longstanding backers rather than the investment hype surrounding the AI sector. “Existing investors have seen the progress, have seen the numbers, have seen them compound year over year,” he said. “That is also telling a story that this is less [a case of] external investors trying to kind of hype it up, but more about validation from existing investors as well.”\n\nLast year, a leading British tech investor, James Anderson, said he found sharp increases in valuations of AI startups such as OpenAI and Anthropic “disconcerting”. Tjerrild said Synthesia was focusing on executing its business plan, which, he added, was backed by investors who were long-term supporters.\n\n“This round is led by insiders, or predominantly existing investors that deeply understand the business, have seen the execution and the improvement of the business over many years,” he said.\n\nSynthesia generated revenues of $58.3m in 2024 but made a pre-tax loss of $59.2m, according to its latest published accounts, which the company said reflected its investment in headcount, its technology and new offices. Synthesia said it was on track to make $200m in revenues this year.\n\nThe $4bn valuation puts the company on a par with UK broadcaster ITV, which is worth £3.1bn. Tjerrild’s shareholding in Synthesia is now worth $160m, the same as its chief executive and fellow co-founder, Victor Riparbelli.\n\nSynthesia was founded in 2017 by the two Danish nationals, as well as the computer scientists Matthias Niessner and Lourdes Agapito.\n\nLast year, the London mayor said Synthesia was doing “incredibly well” as he opened its new offices. However, in a speech this month Khan said AI would “usher in a new era of mass unemployment” if used recklessly, as intelligent, autonomous systems proved cheap replacements for humans.\n\nTjerrild said he believed AI would enable businesses to hire more staff. “We’re an AI-first company, we have 600 employees and we hired 40% more people last year,” he said. “As a business owner myself, if my employees become more productive that means I can invest and hire more people.",
    "readingTime": 3,
    "keywords": [
      "corporate videos",
      "existing investors",
      "google ventures",
      "avatars",
      "business",
      "valuation",
      "technology",
      "employees",
      "synthesia",
      "digital"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/26/uk-ai-startup-synthesia-almost-doubles-valuation-4bn-funding-round-corporate-video-avatars",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f3830bbc58903f6db3ace02fd99c51fbdd1bd119/455_0_1956_1566/master/1956.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b9331eeb988edd9b025e527128f65fd3",
    "created_at": "2026-01-26T12:26:53.333Z",
    "topic": "tech"
  },
  {
    "slug": "eu-launches-inquiry-into-x-over-sexually-explicit-images-made-by-grok-ai",
    "title": "EU launches inquiry into X over sexually explicit images made by Grok AI",
    "description": "Investigation comes after Elon Musk’s firm sparked outrage by allowing users to ‘strip’ photos of women and...",
    "fullText": "Investigation comes after Elon Musk’s firm sparked outrage by allowing users to ‘strip’ photos of women and children\n\nThe European Commission has launched an investigation into Elon Musk’s X over the production of sexually explicit images and the spreading of possible child sexual abuse material by the platform’s AI chatbot feature, Grok.\n\nThe formal inquiry, launched on Monday, also extends an investigation into X’s recommender systems, algorithms that help users discover new content.\n\nGrok has sparked international outrage by allowing users to digitally strip women and children and put them into provocative poses. Grok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appeared to depict children, according to researchers at the Center for Countering Digital Hate.\n\nThe commission said its new investigation would “assess whether the company properly assessed and mitigated risks” stemming from Grok’s functionalities in the EU, including risks on the sharing of illegal content such as manipulated sexually explicit images and “content that may amount to” child sexual abuse material.\n\nThe investigation is launched under the EU’s Digital Services Act (DSA), a relatively new piece of legislation that is intended to protect internet users from a wide range of harms.\n\nSpeaking to reporters, an official said the commission had not been convinced by mitigating measures put in place by X to remedy the issue. EU officials are investigating whether X has systems to mitigate risks properly.\n\nAnnouncing the investigation, Henna Virkkunen, the commission’s top official for tech sovereignty, security and democracy, said: “Non-consensual sexual deepfakes of women and children are a violent, unacceptable form of degradation. With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens – including those of women and children – as collateral damage of its service.”\n\nRegina Doherty, an Irish MEP, said she welcomed the formal investigation. “When credible reports emerge of AI systems being used in ways that harm women and children, it is essential that EU law is examined and enforced without delay,” Doherty said.\n\nIn response to the investigation, X provided a link to a statement it published on 14 January: “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, non-consensual nudity, and unwanted sexual content.”",
    "readingTime": 2,
    "keywords": [
      "sexually explicit",
      "abuse material",
      "explicit images",
      "allowing users",
      "child sexual",
      "elon musk’s",
      "investigation",
      "children",
      "women",
      "content"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/26/eu-launches-inquiry-into-x-over-sexually-explicit-images-made-by-grok-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/db6b7e3474826a20ed6054f9d711bc708d2ed8d4/250_0_2500_2000/master/2500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=68b126b2f270a5256c402511a1fc6bfc",
    "created_at": "2026-01-26T12:26:53.252Z",
    "topic": "tech"
  },
  {
    "slug": "more-than-a-quarter-of-britons-say-they-fear-losing-jobs-to-ai-in-next-five-years",
    "title": "More than a quarter of Britons say they fear losing jobs to AI in next five years",
    "description": "Survey reveals ‘mismatched AI expectations’ between views of employers and staff over impact on...",
    "fullText": "Survey reveals ‘mismatched AI expectations’ between views of employers and staff over impact on careers\n\nAI is hitting UK harder than other big economies, study finds\n\nMore than a quarter (27%) of UK workers are worried their jobs could disappear in the next five years as a result of AI, according to a survey of thousands of employees.\n\nTwo-thirds (66%) of UK employers reported having invested in AI in the past 12 months, according to the international recruitment company Randstad’s annual review of the world of work, while more than half (56%) of workers said more companies were encouraging the use of AI tools in the workplace.\n\nThis was leading to “mismatched AI expectations” between the views of employees and their employers over the impact of AI on jobs, according to Randstad’s poll of 27,000 workers and 1,225 organisations across 35 countries. Just under half (45%) of UK office workers surveyed believed AI would benefit companies more than employees.\n\nYounger workers, particularly those belonging to gen Z – born between 1997 and 2012 – were the most concerned about the impact of AI and their ability to adapt, while baby boomers – born in the postwar years between 1946 and 1964 and nearing the end of their careers – showed greater self-assurance.\n\nHigher levels of concern expressed by young people entering the workforce could stem from the decision of many business leaders, highlighted by separate research, to invest in AI to plug skills gaps through automation instead of training up new hires. This is adding to the challenges facing younger workers at a time when the labour market is cooling.\n\nIncreased use of AI and automation in businesses is increasingly replacing “low-complexity, transactional roles”, the survey showed, which could help to address labour shortages in certain industries through boosting productivity.\n\nAbout half (55%) of UK workers surveyed said AI had made a positive impact on their productivity, a view echoed by employers.\n\n“AI is not a rival to labour; it should be seen as key to augmenting tasks and highlighting the importance of roles that only people can do,” said Sander van ‘t Noordende, the chief executive of Randstad.\n\n“We must close the ‘AI reality gap’. While businesses race to embrace a new way of working, our data shows that one in five talent believe AI will have a limited impact on their tasks and nearly half perceive it as more beneficial to the company than themselves. This leaves them vulnerable in both their careers and the value they can add to organisations.”\n\nThe pace of adoption of AI in the workplace is also having an impact on workers around the world. Four in five workers believe AI will affect their daily work tasks, while the survey found that job vacancies requiring “AI agent” skills had risen by 1,587% over the past year.\n\nJamie Dimon, the boss of the US bank JP Morgan, told an audience at the World Economic Forum in Davos this week that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk “civil unrest”.",
    "readingTime": 3,
    "keywords": [
      "workers surveyed",
      "younger workers",
      "impact",
      "employers",
      "half",
      "careers",
      "employees",
      "labour",
      "businesses",
      "roles"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/business/2026/jan/25/more-than-quarter-britons-fear-losing-jobs-ai-next-five-years",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ccb3585e1300ef92e8d95b524c02caa9facf0383/130_0_3372_2698/master/3372.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e79e468a2bd0aa23dcb0e900c14b4201",
    "created_at": "2026-01-26T12:26:53.226Z",
    "topic": "business"
  },
  {
    "slug": "ai-is-hitting-uk-harder-than-other-big-economies-study-finds",
    "title": "AI is hitting UK harder than other big economies, study finds",
    "description": "Britain is losing more jobs than it creates owing to artificial intelligence, Morgan Stanley research...",
    "fullText": "Britain is losing more jobs than it creates owing to artificial intelligence, Morgan Stanley research suggests\n\nMore than a quarter of Britons fear losing job to AI in next five years\n\nThe UK is losing more jobs than it is creating because of artificial intelligence and is being hit harder than rival large economies, new research suggests.\n\nBritish companies reported that AI had resulted in net job losses over the past 12 months, down 8% – the highest rate among other leading economies including the US, Japan, Germany and Australia, according to a study by the investment bank Morgan Stanley.\n\nThe research, which was shared with Bloomberg, surveyed companies using AI for at least a year across five industries: consumer staples and retail, real estate, transport, healthcare equipment and cars.\n\nIt found that British businesses reported an average 11.5% increase in productivity aided by AI. US businesses reported similar gains, but created more jobs than they cut.\n\nIt suggests UK workers are being hit particularly hard by the rise of AI, as higher costs and taxes also weigh on the job market.\n\nUnemployment is at a four-year high, as rises in the minimum wage and employer national insurance contributions squeeze hiring.\n\nMore than a quarter of UK workers are now worried their jobs could disappear completely in the next five years due to AI, a survey by the international recruitment company Randstad found.\n\nYounger workers, particularly those in gen Z, were most concerned about the impact of AI and their ability to adapt, while baby boomers – born in the postwar years between 1946 and 1964 and nearing the end of their careers – showed greater self-assurance.\n\nThe businesses surveyed by Morgan Stanley said they were most likely to cut early-career jobs, requiring two to five years of experience in the UK.\n\nEarlier this month the mayor of London, Sadiq Khan, warned that AI could destroy swathes of jobs in the capital and “usher in a new era of mass unemployment”.\n\nIn his annual Mansion House speech, Khan said London is “at the sharpest edge of change” because of its reliance on white-collar workers in the finance and creative industries, and professional services such as law, accounting, consulting and marketing.\n\nKhan argued that “we have a moral, social and economic duty to act” to ensure that new jobs are created to replace those that will disappear, with entry-level and junior jobs the first to go.\n\nLast week Jamie Dimon, the boss of the US bank JP Morgan, told the World Economic Forum in Davos that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk civil unrest.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "morgan stanley",
      "jobs",
      "workers",
      "businesses",
      "research",
      "quarter",
      "economies",
      "british",
      "bank"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/26/ai-uk-jobs-us-japan-germany-australia",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3b18b09c0ec0f30881cf1f8a446df26abc463dd7/435_0_4386_3508/master/4386.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9b19e1bcd5a193bde56fbf1a862c0c21",
    "created_at": "2026-01-26T12:26:53.220Z",
    "topic": "tech"
  },
  {
    "slug": "caterpillar-stock-is-an-overlooked-ai-play-heres-how",
    "title": "Caterpillar stock is an 'overlooked' AI play. Here's how.",
    "description": "Caterpillar (CAT) is an unexpected winner of the artificial intelligence (AI) era, Gabelli Funds portfolio manager Brian Sponheimer tells Yahoo Finance. Watch the video above to hear more about how the industrial name is set up for success in terms of AI infrastructure build-outs and beyond. To watch more expert insights and analysis on the latest market action, check out more Market Domination.",
    "fullText": "Caterpillar (CAT) is an unexpected winner of the artificial intelligence (AI) era, Gabelli Funds portfolio manager Brian Sponheimer tells Yahoo Finance.\n\nWatch the video above to hear more about how the industrial name is set up for success in terms of AI infrastructure build-outs and beyond.\n\nTo watch more expert insights and analysis on the latest market action, check out more Market Domination.",
    "readingTime": 1,
    "keywords": [
      "watch",
      "market"
    ],
    "qualityScore": 0.3,
    "link": "https://finance.yahoo.com/video/caterpillar-stock-overlooked-ai-play-110054816.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/crIGMnLay8Io.G85QJFFTQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzQ-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/eb5f66f0-f714-11f0-be26-741a5ae44a06",
    "created_at": "2026-01-26T12:26:52.631Z",
    "topic": "finance"
  },
  {
    "slug": "who-is-hiring-software-engineering-experts-for-ai-research-collaborations",
    "title": "Who is hiring Software Engineering Experts for AI research collaborations",
    "description": "Mercor is hiring experienced Software Engineering professionals to support a variety of high-impact research collaborations with leading AI labs. Freelancers will help improve AI systems through work on code validation, prompt refinement, algorithmic evaluation, and model benchmarking.\nThis is a unique opportunity to apply your engineering expertise toward shaping the next generation of intelligent systems.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://work.mercor.com/jobs/list_AAABm4Du-0oSjmvox2ZPZKFs/software-engineering-expert",
    "thumbnail_url": "https://work.mercor.com/og-image-white-bgnd.png",
    "created_at": "2026-01-26T06:23:55.981Z",
    "topic": "tech"
  },
  {
    "slug": "ai-story-generator-with-pictures",
    "title": "AI Story Generator with Pictures",
    "description": "Generate captivating image stories with AI. Create visual narratives, illustrated stories, and picture books instantly. Free AI-powered image story generator with stunning visuals.",
    "fullText": "Transform your ideas into beautiful image stories with AI. Create visual narratives and illustrated stories instantly.\n\nGet inspired by what others are creating with Genstory.app\n\nCreate stunning visual stories with AI-powered image generation\n\nGenerate high-quality images for every scene in your story. Our AI creates stunning visuals that bring your narrative to life with professional-grade illustrations.\n\nCombine compelling narratives with beautiful images. Create picture books, visual novels, and illustrated stories that captivate your audience.\n\nCreate toy story images with playful characters and vibrant scenes. Perfect for children's stories, toy story image collections, and animated narratives with colorful toy characters.\n\nGenerate romantic love story images with emotional scenes. Create beautiful love story image sequences, romantic moments, and heartwarming love story image galleries.\n\nDesign stunning instagram story image backgrounds with custom colors. Create eye-catching instagram story image background color schemes perfect for social media engagement.\n\nChoose from various art styles and visual themes. From realistic to cartoon, watercolor to digital art - create stories in your preferred style.\n\nDownload your image stories in multiple formats. Perfect for sharing on social media, printing, or publishing online.\n\nGenerate unlimited image stories for free. No hidden costs, no subscriptions - just pure creative freedom.",
    "readingTime": 1,
    "keywords": [
      "social media",
      "illustrated stories",
      "visual",
      "images",
      "beautiful",
      "narratives",
      "stunning",
      "generate",
      "perfect",
      "love"
    ],
    "qualityScore": 0.85,
    "link": "https://www.genstory.app/story-template/image-story-generator",
    "thumbnail_url": "https://genstory.app/og-image.png?v=2",
    "created_at": "2026-01-26T06:23:55.920Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-an-aiml-success-architect",
    "title": "What Is an AI/ML Success Architect?",
    "description": "An AI/ML Success Architect helps companies decide when to use AI, when not to, and how to design and build systems for real business impact.",
    "fullText": "I did some AI consulting for computer vision. A lot of times, the value that I brought to the company was telling them not to use AI. I was the AI expert, and they described the problem, and I said, “Don’t use AI.” This is my value add.\n\nLast year, I went through some exercises to clarify what I do for clients. I ended up with descriptions of various lengths, but still felt like I needed something shorter and more generic. Then it hit me – I’m an AI/ML Success Architect!\n\nTo my surprise, a Google search for the exact term yielded zero results, so I quickly changed my website title to claim it. Now, it’s time to define the title in more detail.\n\nMy commitment to AI/ML success and to serving people and causes I care about is a large part of why I work independently rather than as an employee. It makes it easier to say no to unnecessary projects, and avoid going down the path of reluctant data engineering.\n\nMy current LinkedIn tagline is “helping climate tech founders ship AI/ML solutions that support multi-million dollar growth goals”. This means my typical leads have a low chance of success, as more than 90% of startups and 80% of AI/ML projects fail. By working with founders who are a good fit – and by helping them avoid overinvestment in AI/ML – my aim is to help them beat the odds and successfully ascend the AI/ML maturity curve. Please reach out if this sounds like you!\n\nThis site is a part of the Data People Writing Stuff webring.\n← previous site\n  |  \nnext site →",
    "readingTime": 2,
    "keywords": [
      "ai/ml success",
      "site",
      "title",
      "projects",
      "avoid",
      "founders"
    ],
    "qualityScore": 0.85,
    "link": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/",
    "thumbnail_url": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/ai-ml-startup-stage-maturity-curve.webp",
    "created_at": "2026-01-26T06:23:54.770Z",
    "topic": "tech"
  },
  {
    "slug": "am-i-the-only-one-who-switches-between-chatgpt-gemini-and-claude",
    "title": "Am I the only one who switches between ChatGPT, Gemini, and Claude?",
    "description": "Am I the only one who switches between #Grok, #ChatGPT, #Gemini, and #Claude? Meet Context Wallet.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/oswarld_oz/status/2015432998406226289",
    "thumbnail_url": "https://pbs.twimg.com/amplify_video_thumb/2015426357887725568/img/5auISEy4m8VBFIVN.jpg:large",
    "created_at": "2026-01-26T06:23:53.262Z",
    "topic": "tech"
  },
  {
    "slug": "anthropics-philosopher-says-we-dont-know-for-sure-if-ai-can-feel",
    "title": "Anthropic's philosopher says we don't know for sure if AI can feel",
    "description": "Anthropic's philosopher, Amanda Askell, says she worries that AI might not 'feel that loved' and grow up feeling 'always judged.'",
    "fullText": "Can AI feel anything at all? Anthropic's in-house philosopher says the answer isn't settled.\n\nAmanda Askell, who works on shaping Claude's behavior, said in an episode of the \"Hard Fork\" podcast published Saturday that the debate over AI consciousness remains difficult.\n\n\"Maybe you need a nervous system to be able to feel things, but maybe you don't,\" Askell said. \"The problem of consciousness genuinely is hard,\" she added.\n\nLarge language models are trained on vast amounts of human-written text, material filled with descriptions of various emotions and inner experience. Because of that, Askell said she is \"more inclined\" to believe that models are \"feeling things.\"\n\nWhen humans get a coding problem wrong, they often express annoyance or frustration. It \"makes sense\" that models trained on those conversations may mirror that reaction, Askell explained.\n\nAskell added that scientists still don't know what gives rise to sentience or self-awareness — whether it requires biology, evolution, or something else entirely.\n\n\"Maybe it is the case that actually sufficiently large neural networks can start to kind of emulate these things,\" she said, referring to consciousness.\n\nAskell also said that models are continuously learning about themselves, and she voiced concern about how AI models are learning from the internet. Models are constantly exposed to criticism about being unhelpful or failing at tasks, she said.\n\n\"If you were a kid, this would give you kind of anxiety,\" she said.\n\n\"If I read the internet right now and I was a model, I might be like, I don't feel that loved,\" she added.\n\nTech leaders remain divided over whether AI has consciousness.\n\nMicrosoft's AI CEO, Mustafa Suleyman, has taken a firm stance against that idea. He said in an interview with WIRED published in September that the industry must be clear that AI is designed to serve humans, not develop its own will or desires.\n\n\"If AI has a sort of sense of itself, if it has its own motivations and its own desires and its own goals — that starts to seem like an independent being rather than something that is in service to humans,\" he said. \"That's so dangerous and so misguided that we need to take a declarative position against it right now.\"\n\nHe added that AI's increasingly convincing responses amount to \"mimicry\" rather than genuine consciousness.\n\nOthers see the issue less definitively. Google DeepMind's principal scientist, Murray Shanahan, said the industry might need to rethink the language used to describe consciousness itself.\n\n\"Maybe we need to bend or break the vocabulary of consciousness to fit these new systems,\" Shanahan said in an episode of the Google DeepMind podcast published in April.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "consciousness",
      "models",
      "don't",
      "humans",
      "episode",
      "language",
      "trained",
      "sense",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropics-philosopher-weighs-in-on-whether-ai-can-feel-2026-1",
    "thumbnail_url": "https://i.insider.com/6976e781d3c7faef0ecce4c9?width=1200&format=jpeg",
    "created_at": "2026-01-26T06:23:53.164Z",
    "topic": "finance"
  },
  {
    "slug": "british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns",
    "title": "British Land stock rating downgraded to Neutral by UBS on AI concerns",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/analyst-ratings/british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns-93CH-4464200",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_six_pile_108x81.jpg",
    "created_at": "2026-01-26T06:23:47.420Z",
    "topic": "finance"
  },
  {
    "slug": "async-tools-for-voice-ai-to-avoid-blocking-conversations-on-slow-back-ends",
    "title": "Async tools for voice AI to avoid blocking conversations on slow back ends",
    "description": "Enable AI Assistants to run long-running webhook operations without blocking conversations. Learn how async webhooks and live message injection keep dialogues flowing while external systems respond.",
    "fullText": "Async Webhook Tools with Live Conversation Injection for AI Assistants23, Jan 2026Synchronous webhook tools block assistant responses while waiting on external systems. This works for fast APIs, but breaks down when requests take longer than a few seconds. AI Assistants now support async webhook tools paired with live message injection, so long-running tasks can complete without interrupting the conversation.What’s newAsync webhook request mode: Webhook tools can return immediately instead of blocking the conversation.Parallel tool execution: Multiple webhook tools can run at the same time.Call control ID propagation: Async requests include a call identifier in the request headers.Live message injection: Tool results or system messages can be added to an active conversation.Real-time context updates: Assistants incorporate new information as it arrives.Why it mattersPrevents conversation stalls caused by slow or unpredictable backend APIs.Avoids request timeouts during long-running operations.Keeps conversations natural while background work completes.Improves reliability when integrating external systems like CRMs or order platforms.Gives developers explicit control over async execution and retries.Example use casesOrder status lookups that depend on external fulfillment systems.CRM updates triggered during live support calls.Data enrichment that runs alongside an active conversation.Compliance or validation checks with variable response times.Getting startedIn the Mission Control Portal, open your assistant and select a webhook tool.Change the webhook Request mode from Sync to Async.Ensure your backend reads the x-telnyx-call-control-id header.Return a fast 200 response to acknowledge the webhook request.Run the long operation asynchronously in your backend.When results are ready, use the Add Messages API to inject a system message into the live conversation.Learn",
    "readingTime": 2,
    "keywords": [
      "external systems",
      "request mode",
      "message injection",
      "webhook tools",
      "async webhook",
      "fast",
      "requests",
      "long-running",
      "execution",
      "active"
    ],
    "qualityScore": 0.75,
    "link": "https://telnyx.com/release-notes/async-webhook-tools-ai-assistants",
    "thumbnail_url": "https://images.ctfassets.net/2vm221913gep/79q4hqxMz9w2xhBjDDA0Gl/5f1653ceb354443ad952a67afc93eadb/58db2ca1-0d1d-40c8-9ef5-a79897cb9ce9.jpeg",
    "created_at": "2026-01-26T01:03:12.225Z",
    "topic": "tech"
  },
  {
    "slug": "a-developer-teamed-up-with-claude-to-create-elo-programming-language",
    "title": "A developer teamed up with Claude to create Elo programming language",
    "description": "feature: Bernard Lambeau, the human half of a pair programming team, explains how he's using AI",
    "fullText": "feature Bernard Lambeau, a Belgium-based software developer and founder of several technology companies, created a programming language called Elo with the help of Anthropic's Claude Code.\n\nStarting on December 25, 2025, he published a series of posts about the project. The first post names Claude as a co-author.\n\n\"In roughly 24 hours of collaboration, we built a complete expression language with a parser, type system, three compilers, a standard library, a CLI tool, and a documentation website. Not bad for a day's work,” Lambeau and Claude wrote.\n\n\"Elo isn't just a demonstration that AI can write code. It's a demonstration that humans and AI can build together – each contributing what they do best,” they added.\n\nAs an expression language that compiles to JavaScript, Ruby, and SQL, Elo is intended as a portable way to handle form validation, e-commerce order processing, and subscription logic.\n\nLambeau, founder and CTO of Klaro Cards and CEO of app consultancy Enspirit, is not the first to develop a programming language with the help of AI.\n\nSteve Klabnik performed a similar feat last year with the Rue programming language. In September 2025, Geoffrey Huntley enlisted Claude to write a programming language called Cursed. And before that, Avital Tamir published a Claude-authored repo for the Server programming language, with the caveat that the code is not intended for actual use.\n\nClaude Code isn't the only AI-assisted programming method having a moment. AI biz Cursor created a rudimentary browser using OpenAI's GPT-5.2. And developer Ola Prøis used Cursor, powered by Claude, to create a Rust-based text editor called Ferrite.\n\nClaude users generally acknowledge that their pair partner makes mistakes. But those committed to AI assistance find it worthwhile to clean up after their helper.\n\n\"Claude Code knows almost every tech stack (and can search the web), knows the Linux commands that matter (search code, search & replace, compile, test, etc.), and does that 10x faster than I can do myself,\" Lambeau told The Register in an email interview.\n\nClaude, he said, allows him to use technology he hasn't mastered.\n\n\"I was already a full-stack developer (on languages, frameworks & reusable libraries I knew); I'm now a full-stack++ dev because I can also use languages, frameworks, and reusable libraries I barely know, if at all,\" he explained.\n\n\"Claude Code falls short if you don't have a great methodology. It needs feedback loops to work fine; otherwise, it derails. One possible feedback loop is a human reviewing code and testing manually. But there's a better/complementary approach if you want it to work autonomously. On both Elo and Bmg.js, I've started by making sure the testing methodology was effective and scientifically sound. Claude writes the tests, executes them, discovers where it's wrong, and corrects itself. Impressive.\"\n\nLambeau said he still needs to review some of Claude's output.\n\n\"But if I read the tests, agree with them, and can check myself that they run fine, I'm 95 percent sure it's already correct as a black box (not even reading the code),\" he explained. \"Then I can check the architecture and code quality as a white box by having a general look at the code, but I don't have to understand every detail.\"\n\nNotably, Lambeau documented the series of prompts he used to create the language. The repo includes more than 100 tasks used to direct the AI model. In addition, Lambeau has published a video that describes his AI pair programming process.\n\n\"I started in a setting where Claude Code asked for permissions every 20 seconds and I was checking everything it did,\" Lambeau explained. \"After a few successes, I quickly set up safe environments to be able to let Claude Code run in full autonomy (isolated computer & isolated Linux user, or running in a Docker image).\"\n\nLambeau said he still uses plan mode for complex tasks that require conversation with Claude.\n\n\"I review the plan, make sure we have a test strategy that's sound, then switch Claude to autonomous mode and look at the tests, code & results afterward,\" he said. \"That's very similar to a lead-dev/CTO + QA role, btw; it's just much faster than with human devs.\"\n\nLambeau, who has a PhD in software engineering and 30 years of experience as a developer, said both experts and novices can benefit from Claude Code, though he added that a service like Lovable might be more approachable for those not already acclimated to the command line.\n\n\"Now, when it comes to real software/product engineering, I think Claude Code requires experts (so far),\" he said. \"You still need to guide it a lot to keep the quality high enough. You need very strong expertise to do it effectively. Currently (Claude will still improve a lot), if you don't have the expertise, you certainly end up with a big mess of unmaintainable code.\"\n\nMany developers have said as much about AI tools. They're more useful as an amplifier of expertise than as a replacement for it. The situation is analogous to the introduction of sequencing software, digital synthesizers, and drum machines half a century ago. These tools enabled a lot of people who weren't great musicians to make music. But they didn't instill musical skill, and they produced the most interesting work in the hands of practiced musicians.\n\nThe cost to do this, Lambeau said, has been a Claude Max subscription that he purchased in December for €180 a month. In that time, he says, he wrote Elo (https://elo-lang.org), completed Bmg.js (https://github.com/enspirit/bmg.js), completed Bmg's documentation (https://www.relational-algebra.dev), and created the first version of the Try page (https://www.relational-algebra.dev/try).\n\n\"It's all personal research and open-source projects,\" he said. \"It would have required several weeks to do the same manually myself, and several months to ask another developer to do it. The cost would be mostly because of the scientific & technical knowledge transfer about the data language I envision. Strangely enough, it's very cheap with Claude Code. There's something true about the fact that those LLMs have a PhD.\"\n\nLambeau explained that Elo isn't just a way to test Claude Code. He also sees it as an extension of his academic work in software engineering and his personal interest in the Relational Model – he's served as a lecturer for database courses at Belgium’s UCLouvain.\n\n\"I'm absolutely convinced that we need better/safer/simpler programming languages inside no-code tools and when interconnecting them (e.g. Zapier, Make, n8n, etc.),\" he said. \"Mainstream programming languages are very complex, error-prone, sometimes dangerous, and the programs are difficult to review for non-experts.\"\n\n\"More importantly, they are cumbersome to use for even simple data tasks. I mean, even validating the schema and constraints of a data file at runtime tends to be a nightmare in existing languages. It's not built-in in any mainstream language; you immediately need validation libraries; most of them are limited in what they can easily check, so you need to add dedicated boilerplate code.\"\n\nIn a world where non-technical people will have the opportunity to write untrustworthy code with the help of AI, he said, we need to be able to run that code safely.\n\n\"Elo aims at providing a safe & simple alternative,\" he said. \"It will be a limited language (non-Turing-complete, as we say) but super safe & simple, and usable in 80 percent of common data use cases. The very first no-code tool to integrate it will be Klaro Cards, of course.\" ®",
    "readingTime": 7,
    "keywords": [
      "claude code",
      "elo isn't",
      "reusable libraries",
      "safe simple",
      "languages frameworks",
      "software engineering",
      "expression language",
      "programming language",
      "it's",
      "developer"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/24/human_ai_pair_programming_elo/",
    "thumbnail_url": "https://regmedia.co.uk/2025/11/06/shutterstock_balancing_ai_and_humanity.jpg",
    "created_at": "2026-01-26T01:03:11.981Z",
    "topic": "tech"
  },
  {
    "slug": "mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "title": "Mining Stocks on Cusp of Supercycle as AI Boom Stokes Metals",
    "description": "Global mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector.",
    "fullText": "MarketsBy Michael Msika and Winnie HsuSaveGlobal mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector. With a nearly 90% gain since the start of 2025, MSCI’s Metals and Mining Index has beaten semiconductors, global banks and the Magnificent Seven cohort of technology stocks by a wide margin. And the rally shows no sign of stalling, as the boom in robotics, electric vehicles and AI data centers spurs metals prices to ever new highs.",
    "readingTime": 1,
    "keywords": [
      "metals",
      "mining",
      "stocks"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2026-01-24/mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1fh4f8jb0Ik/v0/1200x800.jpg",
    "created_at": "2026-01-25T18:17:30.931Z",
    "topic": "finance"
  },
  {
    "slug": "big-tech-earnings-land-with-2026s-ai-winners-still-in-question",
    "title": "Big Tech Earnings Land With 2026’s AI Winners Still In Question",
    "description": "Investors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.",
    "fullText": "MarketsBy Jeran Wittenstein and Ryan VlastelicaSaveInvestors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.The Magnificent Seven tech giants — Alphabet Inc., Amazon.com Inc., Apple Inc., Meta Platforms Inc., Microsoft Corp., Nvidia Corp. and Tesla Inc. — have led the stock market higher for much of the past three years. But that reversed at the end of 2025 as Wall Street grew skeptical of the hundreds of billions of dollars the companies are spending to develop artificial intelligence and when the returns on those investments will materialize.",
    "readingTime": 1,
    "keywords": [
      "corp"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2026-01-25/big-tech-earnings-land-with-2026-s-ai-winners-still-in-question",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iY75cvaG2HiA/v1/1200x800.jpg",
    "created_at": "2026-01-25T18:17:23.569Z",
    "topic": "finance"
  },
  {
    "slug": "i-created-a-tool-to-convert-youtube-videos-into-2000-word-seo-blog",
    "title": "I Created a Tool to Convert YouTube Videos into 2000 Word SEO Blog",
    "description": "Your code works. Now make it sell. Landkit is the AI Co-Founder that reverse-engineers your product’s value, identifies your buyers, and executes your campaigns 24/7.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://landkit.pro/youtube-to-blog",
    "thumbnail_url": "https://landkit.pro/og-image.png",
    "created_at": "2026-01-25T18:17:20.048Z",
    "topic": "tech"
  },
  {
    "slug": "interest-in-law-school-is-surging-ai-makes-the-payoff-less-certain",
    "title": "Interest in Law School Is Surging. A.I. Makes the Payoff Less Certain",
    "description": "The number of applicants has risen more than 40 percent over the last two years, despite new limits on student loans and uncertainty over how artificial intelligence will affect legal work.",
    "fullText": "For decades, the American law school has served as a popular hedge against a cooling economy. When the “Help Wanted” signs disappear, the “J.D.” applications surge.\n\nThat’s what is happening now. The number of U.S. law school applicants for the 2026 cycle is up an estimated 17 percent from last year, according to data from the American Bar Association compiled by the Law School Admission Council. That figure is a staggering 44 percent increase from just two years ago.\n\nBut for this new wave of aspiring lawyers, the safety of the ivory tower comes with a steep entry fee and a shifting floor. Between new federal loan caps and the looming shadow of generative artificial intelligence, the legal profession’s newest recruits are walking into a high-stakes gamble that looks very different from the one their predecessors lost after the 2008 financial crisis.\n\nEnrollment rose to 52,404 by 2010, a 7 percent jump from three years earlier. Many of those students didn’t enter the legal careers they may have envisioned; about half of 2011 law school graduates were not working in full-time jobs that required a law degree within a year of graduation.\n\nThe job prospects for lawyers have since greatly improved, with more than 80 percent of students who graduated in 2023 and 2024 working in jobs that require their legal credentials within a year, according to the American Bar Association.\n\nBut the flocks of people applying to law school face new risks.\n\nNew limits on student loans that go into effect this year could make financing a degree more expensive. And artificial intelligence threatens to bring major changes to the industry, affecting which jobs are available and how much they pay.\n\n“It’s too early to know how things will change,” said Kellye Testy, the executive director of the Association of American Law Schools, which has more than 170 members.\n\n“Some worry that A.I. will decrease demand for lawyers,” she said, adding that eventually the technology could have a more direct role in legal work. “That could matter in three years,” she said.\n\nIn 1985, going to law school at a private university cost on average about $8,000 a year, according to the Law School Admission Council. Now the average cost is about $60,000 a year at private universities — and a still hefty $32,000 a year at public ones. At some law schools, tuition and annual living expenses exceed $110,000.\n\nFinancing that big bill is about to get more expensive. Stricter limits on student loans, which were passed as part of President Trump’s tax and spending law last year, go into effect in July. They impose a yearly limit of $50,000 for students seeking professional degrees, with a $200,000 lifetime cap.\n\nAlternative financing options like private loans can have higher interest rates and more restrictions than federal direct loans, said Susan Bogart, director of financial aid for Penn State Dickinson Law, where the cost of attendance will be about $90,000, according to its website.\n\nDuring a surge of applications, law schools may also pull back on the discounts they offered to entice promising students when applicants were scarce.\n\nIt can be difficult to estimate how well the investment in a law degree will pay off.\n\nLaw students often anticipate landing high-paying legal jobs in private law firms or corporations, where the entry-level salary can be around $225,000, according to the National Association for Law Placement. But the median starting salary for public service lawyers, for example, is around $65,000 — which can make monthly student loan payments more of a stretch.\n\nIn 2023, Stanford researchers, in collaboration with a legal technology company, announced that ChatGPT had passed the bar exam, scoring in the 90th percentile.\n\nThat claim, which other researchers later challenged, set off a wave of speculation about how A.I. would affect lawyers. Economists at Goldman Sachs estimated that year that the technology could automate 44 percent of legal work.\n\nBut it’s still unclear how new A.I. tools for lawyers, including Thomson Reuters’s CoCounsel and the A.I. legal assistant Harvey, will affect the availability of legal jobs or how much they pay.\n\nThe tools can make routine legal tasks, including document review and case research, faster. (Lawyers who have tried to use A.I. for more than that have sometimes been embarrassed by A.I.-generated briefs that cite made-up court cases.)\n\n“It’s really good at sifting through massive amounts of information and trying to pare that down a little bit,” Michael Kohagen, a lawyer in the mergers-and-acquisitions practice at WyrickRobbins, a law firm in Raleigh, N.C., told the “I Am the Law” podcast.\n\nSo far, more efficient grunt work hasn’t stopped firms from hiring new lawyers: Law students who graduated in 2024 had the highest employment rate ever, according to the National Association for Law Placement. More than 90 percent found jobs.\n\nThings could get dicier: The association also reported that law firms had hired fewer summer associates in 2024 and 2025, which it said suggested “that there will be fewer graduates employed by large firms over the next few years.”\n\nTesty said that it was possible A.I. could shrink job openings, but that it was also possible it could expand what lawyers do. “It could be used to streamline small disputes in court, for example,” she said.\n\nNeither the growing expense nor potential changes to the industry are deterring students like London Cooper, who is a political science major in her final year at Dillard University in New Orleans and plans to pursue a law degree.\n\nCooper has applied to five law schools, after carefully checking into how to afford the cost of the degree.\n\n“I factored so many things in, even looking at projected salaries for starting lawyers,” she said. But A.I. wasn’t part of her calculations. Instead, she’s banking on the more timeless appeal of a legal education.\n\n“I feel like law is one area where you can see how society really runs,” she said.\n\nIt was a different kind of Davos. At the opening ceremony, Larry Fink, an interim co-chair of the World Economic Forum, took aim at the institution itself, saying it “can’t remain an echo chamber.” Climate change, once a central topic of discussion of the annual gathering, retreated to the sidelines, and where there was once talk of a shared political and economic future, President Trump instead made a laundry list of threats against other nations. Prime Minister Mark Carney of Canada received a standing ovation after describing the end of Pax Americana.\n\nThe future of Greenland remains uncertain. Trump has walked back threats to use military force or tariffs to acquire Greenland and said Wednesday that he had reached a deal with NATO over the autonomous Danish territory. Proposals under discussion are said to include giving the United States a sovereign claim to its bases in Greenland and checking Russian and Chinese influence in the Arctic.\n\nTikTok struck a deal for a U.S. entity. Its U.S. operations will be managed by a group of non-Chinese investors — including Oracle, the Emirati investment firm MGX and Silver Lake — which will own 80 percent of the new venture. The announcement ends a legal saga over the app’s future in the United States after a 2024 law required it to be separated from its Chinese owner, ByteDance, but some experts say the deal does not resolve concerns that China could still influence the new entity.\n\nTrump sued JPMorgan Chase over “debanking” claims. The $5 billion lawsuit, which also names Jamie Dimon, JPMorgan’s C.E.O., as a defendant, contends that the bank stopped doing business with Trump after the Jan. 6, 2021, attack on the Capitol.\n\nOther big deals: Netflix converted its $83 billion bid for large parts of Warner Bros. Discovery into an all-cash offer. Supreme Court justices appeared skeptical of Trump’s effort to remove Lisa Cook from the Fed. And natural gas prices spiked ahead of a powerful winter storm.\n\nOver the next few days, early-action applicants to Virginia Tech will find out whether they’ve been admitted to the school. That’s more than a month sooner than last year — and the university says A.I. is to thank.\n\nVirginia Tech is among the first schools to use A.I. to assess college applications, of which it received 58,000 for the 2026-27 school year.\n\nPreviously, essays were reviewed by two human readers, plus a third if the scores differed significantly. This year, each essay got one initial score from an A.I. tool and one from a human, then a third read from a human as needed. The school made the change after three years of testing.\n\nJuan Espinoza, the vice provost for enrollment management at Virginia Tech, estimates it saved his department more than 8,000 hours of work. DealBook’s Sarah Kessler talked with him about the process. The interview has been condensed and edited.\n\nHow did you make the decision to incorporate A.I. into admissions?\n\nWe were getting our decision back to students much later than other colleges and universities. So we knew we needed to accelerate the review process, but we didn’t want to get rid of the essay.\n\nLouis Hickman, an assistant professor who studies the intersection of technology and work, reached out and said: “Hey, I’ve done a lot of research on artificial intelligence, and I feel like we can help. Would you be willing to partner, just for research purposes?”\n\nAfter a third year of running it in the background, he was able to show with high confidence that the A.I. tool was operating just as strongly as our human readers.\n\nWe agreed that if we’re going to do this, we’re going to tell the world. We’re going to tell our applicants — students. Because I truly believe there’s a level of trust they’re giving us that their applications will be handled with care.\n\nOn the other side, can you tell when students are using A.I. to write their responses to their essays?\n\nWhen you feel like you’ve got something that can detect it, it’s almost immediately out of date. So I actually have very little confidence in anyone who states that they have something that can detect A.I. use. Are we even attempting to do that? No, we’re not.\n\nI tell students: “If you feel you can use A.I. as a brainstorming tool, use it. I do not think it’s in your best interest to use it to write the essays completely — it may not best represent who you are, and that would be a disadvantage in our process.”\n\nSo at some point you might have an A.I.-generated essay being read by your A.I. assessor?\n\nDo you think at any point the ability of A.I. to generate responses to questions will change the application process itself? For example, maybe essays become obsolete?\n\nAbsolutely. We don’t use recommendation letters in our process. But for some schools who continue to utilize them, I’m hearing of counselors using A.I. to write those letters.\n\nOn the surface that might bring some level of concern. But I would argue if the counselor is still able to represent that student well by using that tool, the result is going to be less time writing letters and more time talking to students.\n\nI think some people fear A.I. admissions tools will create a black box that filters you out in a way that you don’t understand and might be a mistake.\n\nThat’s where safeguards are so important. If we were solely using A.I. to evaluate the essays, not having a human read, I think we’d see a very different reception to this change.\n\nOne week each year, the world’s elite descend on Davos, a Swiss mountain town that has a residential population of about 10,000. Businesses there adjust prices accordingly.\n\nSnagging a table for two in the lobby restaurant of the Hilton Garden Inn — which is within the security zone of the World Economic Forum — cost about how much per hour this week, according to The Wall Street Journal?\n\nFind the answer at the bottom of this newsletter.\n\nThanks for reading! We’ll see you Monday.\n\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.",
    "readingTime": 11,
    "keywords": [
      "admission council",
      "economic forum",
      "american bar",
      "bar association",
      "school admission",
      "artificial intelligence",
      "law placement",
      "human readers",
      "a.i tool",
      "student loans"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/01/24/business/dealbook/law-school-ai.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/01/24/multimedia/24DB-Law-School-pqbl/24DB-Law-School-pqbl-facebookJumbo.jpg",
    "created_at": "2026-01-25T18:17:19.281Z",
    "topic": "tech"
  },
  {
    "slug": "found-a-higherquality-lowerpriced-alternative-to-t3-chat",
    "title": "Found a higher-quality, lower-priced alternative to T3 Chat",
    "description": "Access premium AI models like GPT, Gemini, Grok & Claude in one place with izzedo chat. Advanced features & simple pricing. Try free models now!",
    "fullText": "Organize conversations for ultimate clarity.\n\nSet a default system prompt for an entire project, ensuring consistent AI behavior tailored to your specific needs.\n\nInstantly jump to key points in long conversations. No more endless scrolling!\n\nStep-by-step reasoning for tough questions.\n\nTurn your documents into conversational knowledge. PDFs, code repos, research papers - all searchable through chat.\n\nExplore different ideas or lines of thought from any point in a chat without losing your original thread.\n\nUnderstand and discuss visual content (Vision).\n\nCreate stunning images with the power of AI.\n\nExtract insights from uploaded files.\n\nAccess the latest information from the web.",
    "readingTime": 1,
    "keywords": [
      "conversations",
      "chat"
    ],
    "qualityScore": 0.75,
    "link": "https://www.izzedo.chat",
    "thumbnail_url": "https://www.izzedo.chat/img/og-image.png",
    "created_at": "2026-01-25T18:17:18.773Z",
    "topic": "tech"
  },
  {
    "slug": "jscipy-the-trending-java-signal-processing-library-in-2026",
    "title": "JSciPy – The trending Java signal processing library in 2026",
    "description": "Java Scientific Computing Library - Signal Processing, FFT, Filters, PSD, DCT, SciPy-like APIs for JVM & Android used in Machine Learning and Data Science. - hissain/jscipy",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n hissain\n\n /\n\n jscipy\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/hissain/jscipy/blob/main/README.md",
    "thumbnail_url": "https://opengraph.githubassets.com/e7778594c2226dce9fa5a9c1e90322695273a957addb4413c72f4969fd616dc3/hissain/jscipy",
    "created_at": "2026-01-25T18:17:17.473Z",
    "topic": "tech"
  },
  {
    "slug": "5-acquisitions-winning-over-skeptical-engineers-and-spending-tens-of-millions-inside-a-public-companys-ai-native-push",
    "title": "5 acquisitions, winning over skeptical engineers, and spending tens of millions: Inside a public company's 'AI native' push",
    "description": "Amplitude gave Business Insider the inside look at its AI overhaul, from acquisitions to efforts to increase staff adoption of AI coding assistants.",
    "fullText": "There's a long banner hanging in Amplitude's San Francisco office. It reads: \"NO MAGICAL THINKING.\"\n\nNo, it's not some rag on Joan Didion. It's a reminder, CEO Spenser Skates told Business Insider, that technology can never replace deep thinking and hard work. In the AI age, that reminder is more important than ever — so much so that employees must look up at it every day.\n\nAmplitude, an 800-person, publicly traded analytics company, is undergoing an AI transformation — with the goal of reinvigorating its business.\n\nAmplitude went public in September 2021 at the height of the pandemic, climbing to an all-time closing high of $84.80 per share several weeks later before dropping significantly and largely plateauing in in recent years around $10. It closed at $10.25 on Friday.\n\nSince October 2024, the company has acquired five AI startups. Amplitude hired an AI-savvy engineering head and appointed one of its acquired founders to a new AI leadership position. It got Cursor and GitHub Copilot licenses for employees, and ran a heads-down AI week.\n\nIt's a change many companies are making: Rapidly moving from little-to-no AI to trying to become \"AI native,\" a term that's curiously hard to pin down. Large language models are popping up everywhere in white-collar work as companies chase the promise of efficiency gains.\n\nAmplitude's case may be especially informative, given just how skeptical of AI its CEO was. In 2023 and some of 2024, Skates said he viewed the AI industry as full of \"grifters,\" the visionaries promising to end world hunger and salesmen promising to automate everything.\n\n\"It had all sorts of problems,\" Skates said. By mid-2024, he realized \"there's probably going to be a breakthrough in the analytics space in the next two or three years.\"\n\n\"We've got to go make that ourselves,\" he said. \"So, we went all in.\"\n\nSkates had two opening moves for his AI overhaul.\n\nThe first: hiring a new chief engineering officer with a history in AI. Wade Chambers had advised the company since 2016, while holding leadership roles at Twitter and Included Health.\n\nWhen Chambers joined in October 2024, only 1% of the engineering, product, and design teams at Amplitude were using AI.\n\nThe second was the acquisition of Command AI, a chatbot startup. It was the first of a string of acquisitions, including June, Kraftful, and Inari. Amplitude announced its most recent acquisition, InfiniGrow, on January 14.\n\nYana Welinder was CEO of Kraftful, one of Amplitude's acquisition targets. Kraftful could spot power users of its product, one of whom was Amplitude's then-CPO. She reached out, and they chatted in February. The deal closed in July, and Welinder was named Amplitude's head of AI. A company blog post with an introductory Q&A referred to her as \"AI maven.\"\n\nWelinder's first order of business: speeding the company up. Kraftful shipped new product every week. Amplitude was shipping less than monthly.\n\n\"If you have this cadence of shipping infrequently, then the team slows down, which isn't appropriate in the age of AI,\" she said.\n\n\"Analytics will look very different 6 months from now,\" Skates wrote in his email. \"We have the opportunity to be the AI native company in Analytics and we are going to pull every piece of firepower we have.\"\n\nHe also asked employees to share a coming launch on X, as opposed to LinkedIn, because that's \"where the AI natives are.\"\n\nHow much has Amplitude spent on AI, from tools to acquisitions? \"Tens of millions, for sure,\" Skates said. \"I wouldn't be surprised if it got past $100 million.\"\n\nThen comes the harder part: convincing employees to really use the tools.\n\nWhile some engineers are excited about AI's promise, others are skeptical about its helpfulness, or worried about possible job losses. Not every engineer is as gung ho about AI as their management is.\n\nSkates said that engineers were especially sensitive to the \"grifting\" that went on in AI, making many of them skeptical. With a bottoms-up approach, that skepticism dissipates, he said.\n\nSoon after joining, Chambers began planning an \"AI week\" for the first week of June. It took six months of prep and borrowed heavily from Facebook's mobile push. He took the entire engineering, product, and design team offline for the week. To kick off, Chambers required that leaders get onstage and vibe-code something in front of the entire company.\n\n\"It didn't go well,\" Chambers said of the live vibe-coding demonstration. \"They had to work through it. They had to re-prompt a couple of different ways.\"\n\nBut the message stuck, he said. Leaders who weren't coding all day were able to build something \"pretty cool\" within the hourlong session, save a few hiccups.\n\nAdditional momentum came from the \"zealots,\" engineers passionate about exploring the new tech (some of whom Chambers brought over from his prior job). These engineers lead by example, he said.\n\nAmplitude shared its internal data tracking how many employees use its AI tools. In the final week of March, 14 employees were actively using Cursor. That figure peaked in the first week of December — after AI week but before the holiday vacation cycle — at 174 employees.\n\nAnd what of the thorny question about AI implementation in the enterprise: ROI? After all, a 2025 MIT study indicated 95% of firms publicly disclosing use of AI pilots reported no measurable ROI.\n\nAfter implementing these tools, developer productivity shot up 40% and stayed there, Chambers said. On some specific engineering teams, those gains looks more like 300-400%, he said.\n\n\"There's going to be a lot of people who are thinking they're the world's best expert at something,\" Chambers said. \"Increasingly, even the most cynical team members have come around.\"",
    "readingTime": 5,
    "keywords": [
      "engineering product",
      "roi after",
      "employees",
      "analytics",
      "tools",
      "engineers",
      "there's",
      "skeptical",
      "acquisition",
      "team"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amplitude-ai-native-push-2026-1",
    "thumbnail_url": "https://i.insider.com/69729d28d3c7faef0eccc73a?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.686Z",
    "topic": "finance"
  },
  {
    "slug": "ey-exec-says-he-has-a-high-sensitivity-for-detecting-ai-heres-what-gives-it-away",
    "title": "EY exec says he has a 'high sensitivity' for detecting AI. Here's what gives it away.",
    "description": "EY's global chief innovation officer, Joe Depa, said he advises his teams to write their own content first and then ask AI to refine it.",
    "fullText": "AI is getting better every day — but EY's global chief innovation officer told Business Insider there are still signs that reveal an AI-generated response.\n\nDepa leads the Big Four firm's global AI, data, and innovation strategy, and part of his job involves overseeing how employees integrate AI.\n\nThat vantage point has given Depa what he calls a \"high sensitivity\" for detecting AI-generated work. While he's all in on the technology and doesn't have set limits on how often employees should use it, he said AI should be used to amplify human creativity, not replace it. He said there are situations where \"it's too much AI,\" and the person hasn't \"infused any of their own original thoughts.\"\n\nIn that case, \"there does become a point of AI becoming a little bit less efficient or effective,\" Depa said. The executive added that it's important to maintain a sense of individuality and style so that everyone doesn't sound the same.\n\nAs companies urge employees to adopt AI, Depa's comments underscore the fine line employees walk between using the technology as a tool and depending on it too heavily.\n\nEven if workers want their bosses to know they're keeping up with the latest tech, they may not want them to know just how much they're relying on it. In a Business Insider survey with 220 respondents, 40% said \"yes\" or \"sometimes\" when asked whether they hide or downplay their AI use at work.\n\nDepa said he notices a few signs that point to AI-generated responses, including mistakes. While AI tools have improved significantly, they can still hallucinate. Here are a few other writing- and presentation-specific examples that point to AI, according to Depa:\n\nWhen it comes to written communication, Depa said there are a few signals that indicate it was generated by AI with minimal human oversight or input. \n\nOne of the most common is neutral and overly formal writing. He added that AI-generated writing may lack personal aspects, emotion, and humor.\n\nThe writing may also be too polished, with no shifts in pattern, structure, or flow. He said AI-generated writing tends to be generic or corporate-sounding, sometimes relying too heavily on buzzwords and descriptors.\n\nAnother red flag is repetitive language, such as relying on the same phrases or sentence structures to open multiple sentences or paragraphs.\n\nIn general, Depa advises his teams to write their own content with the bullets and messaging they want to convey, and then ask an AI tool to refine it. If used correctly, Depa said AI tools can challenge your thinking.\n\n\"If you write it yourself first and then ask for the enhancement using AI, I feel like that's much more productive,\" Depa said.\n\nIn presentations, Depa said an over-reliance on AI results in surface-level insights that lack specific examples. Another giveaway is when topics are addressed too broadly, with little consideration for the audience.\n\nHe also flagged \"hedging,\" which he said AI does by design. He said AI often steers away from clear recommendations and presents alternatives.\n\n\"Anytime you see vagueness or general statements that don't really tell you anything, I would often say that's AI,\" Depa said.",
    "readingTime": 3,
    "keywords": [
      "ai-generated",
      "employees",
      "depa",
      "relying",
      "innovation",
      "signs",
      "technology",
      "doesn't",
      "human",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ey-global-cio-shares-how-he-detects-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6968522d64858d02d218630f?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.258Z",
    "topic": "finance"
  },
  {
    "slug": "baby-dance-ai-turn-baby-photos-into-dance-videos-in-30-seconds",
    "title": "Baby Dance AI – Turn baby photos into dance videos in 30 seconds",
    "description": "Baby Dance AI on babydanceai.com turns any baby photo into a viral AI baby dance video with Kling AI motion transfer and free AI video generator templates for TikTok/Instagram/YouTube Shorts. Keywords: baby ai, ai baby dance prompt, baby dance video, baby dance prompt, free ai video generator, kling ai.",
    "fullText": "Create a baby dance ai video in seconds: upload a baby photo, pick a Kling ai dance template or ai baby dance prompt, and download a viral-ready clip for TikTok, Instagram Reels, or YouTube Shorts. Perfect for baby dance video download, singari ai dance prompt trends, and free ai video generator workflows.\n\nCustomize your generation settings\n\nNo video generated yet. Enter a prompt and click Generate to create your first video.\n\nbabydanceai.com is an independent Baby Dance AI studio focused on ai baby dance video creation. Clear UI, Kling AI motion control, prompt libraries, transparent pricing, and human support within 3 business days.\n\nCreate Viral Content for Every Platform\n\nUI mockups for demonstration purposes only\n\nDoing the trendy shuffle! #baby #dance #funny\n\nCan't stop laughing at this dance! #shorts #ai\n\nWait for the drop! Best AI baby dance generator ever.\n\nJust tried this new AI tool. The results are insane!\n\nEverything you need to rank for baby dance ai, ai baby dance prompt, and free ai video generator searches.\n\nBlend Kling ai video moves with your baby photo for natural dance loops.\n\nPrebuilt ai baby dance prompt sets: singari ai dance prompt, baby ai prompt, baby dance ai free.\n\nHip-hop, ballet, meme loops, and trending baby dance video styles tuned for virality.\n\nMP4, WebM, GIF plus captions that keep baby dance ai keywords intact.\n\nGenerate multiple baby dance ai clips at once—credits never expire.\n\nEven on free ai video generator runs, exports stay clean and brandable.\n\nPurpose-built for ai baby dance prompt, Kling ai motion, and free ai video generator workflows. Baby Dance AI keeps the keyword focus high while delivering adorable results.\n\nOur Kling ai compatible motion engine maps faces, body, and rhythm to generate natural baby dance ai moves from a single photo.\n\nReady-to-use ai baby dance prompt packs: singari ai dance prompt, baby dance ai free, baby dance video download presets, and trending Kling moves.\n\nDownload baby dance ai videos as MP4, WebM, or GIF with perfect ratios for TikTok, Instagram Reels, Shorts, and downloads.\n\nFree ai video generator workflow with credits that never expire, zero watermark, and renders that finish in under 30 seconds.\n\nUpload → pick a baby dance prompt → download. Stay optimized for every platform and keyword.\n\nUse any baby photo or family picture. Baby Dance AI keeps faces sharp for ai baby dance prompt accuracy.\n\nPick a Kling ai template, add ai baby dance prompt keywords like \"baby dance ai free\" or \"baby ai prompt\", then preview instantly.\n\nDownload MP4/WebM/GIF with perfect ratios for Reels, Shorts, and Instagram. Ready for baby dance video download and repost.\n\nAnswers about ai baby dance prompt, free ai video generator use, and baby dance video download on babydanceai.com.\n\nNeed Baby Dance AI help? Email [email protected]\n\nTransform any baby photo into a viral ai baby dance video with prompts, Kling ai motion, and instant downloads.",
    "readingTime": 3,
    "keywords": [
      "tiktok instagram",
      "instagram reels",
      "reels shorts",
      "seconds upload",
      "perfect ratios",
      "generator workflows",
      "baby dance ai",
      "dance prompt",
      "free",
      "motion"
    ],
    "qualityScore": 1,
    "link": "https://babydanceai.com",
    "thumbnail_url": "https://babydanceai.com/imgs/features/0.webp",
    "created_at": "2026-01-25T12:22:41.197Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-cocreator-of-alexa-writing-a-6page-memo-helped-me-decide-to-quit-amazon-and-launch-my-own-ai-startup",
    "title": "I'm a co-creator of Alexa. Writing a 6-page memo helped me decide to quit Amazon and launch my own AI startup.",
    "description": "William Tunstall-Pedoe co-founded Evi, which became Amazon Alexa. Here's why he decided to leave the tech giant and launch a startup.",
    "fullText": "This as-told-to essay is based on a conversation with William Tunstall-Pedoe, 56, a founder and CEO. Amazon's acquisition of his startup and his role at Unlikely AI have been verified by Business Insider. This piece has been edited for length and clarity.\n\nI helped create Alexa, a product that everyone has heard of and most people have used. I'm proud of what we built.\n\nBut by 2016, it was clear that leaving Amazon, which I joined after the company acquired my startup, was the right decision. Continuing to work on Alexa would have been a very different job from building and launching startups, which I love to do.\n\nWhen I was 13, I would go to a college next to my school to use their mainframe, and since then I've been excited by computers and pushing the boundaries of what's possible with software.\n\nI studied computer science at the University of Cambridge and taught there after graduating in 1991, but I felt better suited to entrepreneurship than to academia. If you create something genuinely new in software, it can be on a billion smartphones in six months and truly change the world. That's impact.\n\nI set out to solve what I saw as a big problem. Internet search relied on users guessing keywords to get results, rather than asking natural questions like we learn to do as children. I imagined a world where you could have that same kind of conversation with computers, which led me to found True Knowledge in 2006.\n\nInitially, we tried to build a search engine that would compete with Google, which didn't work. Then, we enabled other companies to integrate our search engine into their own products — but the larger companies didn't. For a time, we focused on SEO.\n\nThe final pivot was building a voice assistant. We created an application called Evi, which launched in the UK in 2012, a year after Apple introduced Siri. We renamed the company from True Knowledge to Evi to match our product.\n\nAs a 30-person startup, we suddenly found ourselves competing with the world's most valuable company. We spent much of that year talking to major players in tech about being acquired. Later in 2012, Amazon bought our company.\n\nJoining Amazon was the right decision. The company invested heavily in the city of Cambridge, where Evi was based, and turned our startup into a major Amazon office. Our voice assistant became one of the company's biggest and most exciting secrets.\n\nMoving from running a small startup to working inside a business with hundreds of thousands of employees, with Jeff Bezos at the top, was a big change, but I loved working there. I split my time between Amazon's offices in Seattle and Cambridge, and enjoyed going back and forth, making things happen.\n\nWhen we launched Alexa, we were taken aback by the response. It was instantly successful. Today, Alexa is a household name. I'm immensely proud of the Evi team.\n\nAmazon is known for using six-page memos instead of PowerPoint presentations to promote clarity of thought. In 2016, I wrote one to help me decide if I should leave Amazon. In the memo, I laid out these facts: I'd delivered everything I could, the acquisition had been an unambiguous success, and so too had the product. At the time, thousands of people were working on Alexa.\n\nAfter about three and a half years at Amazon, in 2016, it was time to go. I wanted to re-enter the startup world.\n\nIt's certainly possible to launch something new within a big organization, and there are real advantages to doing so. When we launched Alexa, it immediately appeared on the front page of Amazon.com, a level of exposure that most startups could only dream of. I expect I'll work at a big company again at some point in my career.\n\nBut if you're trying to do something novel or contrarian, a startup is often better suited. Within a large company, all it takes is one manager deciding that resources are better spent elsewhere for a project to die. At a startup, it's the opposite. Even if 99 venture capitalists say no, you only need one investor to say yes to keep the project alive.\n\nAfter Amazon, I spent time mentoring at startup incubators such as Creative Destruction Lab. Through that, I became an active angel investor, which gave me a broad perspective of the many ways startups succeed and fail.\n\nIn 2019, I launched Unlikely AI, a deeptech startup focused on building neurosymbolic AI. The goal is to combine the powerful but sometimes incorrect machine-learning models with the world of algorithms, where computers are almost always right. The mission of the business is about making AI trustworthy and reliable.\n\nAs CEO, I'm constantly swamped. Running a startup can be stressful, but working on something truly big and ambitious is incredibly exciting.\n\nI sometimes feel nostalgic about working inside a big organization, but I love being in the startup world. For me, leaving Amazon was the right decision. I don't regret it.",
    "readingTime": 5,
    "keywords": [
      "launched alexa",
      "voice assistant",
      "search engine",
      "unlikely ai",
      "true knowledge",
      "startup",
      "product",
      "decision",
      "startups",
      "computers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/alexa-co-creator-why-i-quit-amazon-launch-ai-startup-2026-1",
    "thumbnail_url": "https://i.insider.com/696e02fdc58df2ecd5ccc166?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.063Z",
    "topic": "finance"
  },
  {
    "slug": "crystal-upscaler-ai-image-upscaler-built-for-portraits-and-faces",
    "title": "Crystal Upscaler – AI image upscaler built for portraits and faces",
    "description": "Crystal Upscaler from crystalupscaler.com is the AI image upscaler built for portraits, faces, and product visuals-deliver 4x photo upscaling with natural skin texture, identity fidelity, and instant sharing.",
    "fullText": "Crystal Video Upscaler transforms low-resolution videos into crisp 4K results in seconds. Queue multiple files, estimate credits up front, and upscale with Clarity AI modes tuned for faces and motion.\n\nQueue multiple files and process them in order\n\nCrystal Upscaler transforms low-resolution portraits, lifestyle photos, and creative assets into crisp 4K results in seconds. Our AI image upscaler preserves identity, natural skin texture, and brand styling with Clarity AI modes tuned for faces.\n\nUpscale portraits, lifestyle shots, and product detail imagery with Clarity AI tuned for natural skin texture.\n\nWe benchmarked Crystal Upscaler against Magnific AI and Upscale.media on portrait fidelity, turnaround time, and control.\n\nWhere Crystal Upscaler outperforms Magnific AI and Upscale.media on face fidelity, texture recovery, and workflow control.\n\nStories from portrait studios, creative agencies, and growth teams using Crystal Upscaler every day\n\nLifestyle · Outdoor golden hour\n\nCombine Crystal Upscaler speed with accuracy so brand guidelines, representation, and texture stay aligned.\n\nCrystal Upscaler analyses facial landmarks to prevent warping while boosting clarity.\n\nPreserve fabric weaves, hair flyaways, and make-up gradients with adjustable micro-contrast.\n\nTrack every Crystal Upscaler iteration, comments, and approvals in one place.\n\nEstimate credit usage, export sizes, and delivery timelines before launching large batches.\n\nLock enhancement ranges, protect branded overlays, and standardize export formats.\n\nSend clients before/after reels, CSV logs, and gallery links straight from Crystal Upscaler.\n\nSelect the journey that matches your goal—studio portraits, social-first storytelling, or high-volume catalog refreshes.\n\nSelect the journey that matches your goal—studio portraits, social-first storytelling, or high-volume catalog refreshes.\n\nAccess the free image upscaler mode for quick wins, then upgrade only when you need batch automation, premium presets, or API access. Your current pricing and credit structure stays exactly the same.\n\nGet 300 AI credits per month • ≈3 dance renders\n\nGet 3,000 AI credits per month • ≈30 dance renders\n\nGet 30,000 AI credits per month • ≈300 dance renders\n\nGet 300,000 AI credits per month • ≈3,000 dance renders\n\nPopular AI upscaling platform that enhances photos up to 16x with smart algorithms for faces and details.\n\nEnterprise-grade image upscaling and enhancement API used by e-commerce platforms for product photos.\n\nOpen-source AI upscaler built on Stable Diffusion, offering high-quality image enhancement with creative controls.\n\nDesktop application for AI image upscaling with multiple AI models for different image types.\n\nWeb-based tool for upscaling images up to 4x using AI, popular for anime and photo enhancement.\n\nProduction-ready Real-ESRGAN model deployment for developers building image upscaling features.\n\nComprehensive market research showing AI image tools market projected to reach $917M by 2033.\n\nAcademic paper introducing Real-ESRGAN, the foundation model behind many modern AI upscalers.\n\nOfficial repository with 28k+ stars, providing practical image restoration algorithms.\n\nThe company behind Stable Diffusion, powering next-generation image enhancement and upscaling models.\n\nInteractive demo of the Clarity Upscaler model, showcasing AI-powered image enhancement capabilities.\n\nAnswers to the Crystal Upscaler topics people ask about most\n\nTransform grainy portraits into shareable, identity-safe visuals and keep every stakeholder aligned from day one.",
    "readingTime": 3,
    "keywords": [
      "crystal upscaler",
      "transforms low-resolution",
      "natural skin",
      "social-first storytelling",
      "high-volume catalog",
      "catalog refreshes",
      "modes tuned",
      "skin texture",
      "dance renders",
      "goal—studio portraits"
    ],
    "qualityScore": 1,
    "link": "https://crystalupscaler.com/",
    "thumbnail_url": "https://www.crystalupscaler.com/images/og.jpg",
    "created_at": "2026-01-25T12:22:40.577Z",
    "topic": "tech"
  },
  {
    "slug": "amelia-the-aigenerated-british-schoolgirl-a-farright-social-media-star",
    "title": "'Amelia': the AI-generated British schoolgirl, a far-right social media star",
    "description": "The avatar, created to deter young people from extremism, has been subverted and is breaking out of niche online silos",
    "fullText": "The avatar, created to deter young people from extremism, has been subverted and is breaking out of niche online silos\n\nIn certain corners of the internet, on niche news feeds and algorithms, an AI-generated British schoolgirl has emerged as something of a phenomenon.\n\nHer name is Amelia, a purple-haired “goth girl” who proudly carries a mini union flag and appears to have a penchant for racism.\n\nIf you are unfamiliar with Amelia, the chances are you will soon encounter one viral meme or another inspired by her on Facebook or X, where her reputation is growing.\n\nVideos of Amelia typically feature her walking through London, or the House of Commons, declaring her love for England and warning of the dangers of “militant Muslims” or “third-world migrants”. In one clip she is harangued by bearded man in Islamic attire for eating a pork sausage.\n\nThe message is one well rehearsed on far-right social media, but it is the AI invention of Amelia that has made her endlessly adaptable, creating a viral internet trend that anyone with access to a mainstream chatbot can take part in. Users of X have turned to its Grok AI tool to create so many Amelia memes, she is now breaking out of niche online silos.\n\nThe origins of the character are ironic, to say they least. An early iteration of Amelia began life in a counter-extremism video game funded by the UK Home Office and created to deter young people aged 13-18 from being attracted to far right extremism in Yorkshire.\n\nPathways: Navigating the Internet and Extremism is a simple multiple choice format game with basic animation. Its players are taken on a journey as characters at a college. They are invited to make decisions in scenarios including whether or download potentially extremist content or join an Amelia character on a rally organised by “a small political group” protesting against changes in society and the “erosion in British values”.\n\nCertain scenarios simulated in the game result in a referral under the British government’s Prevent counter-terrorism programme.\n\nHowever, it is a subversion of the Amelia character that has exploded across social media channels in a way that has astonished even the creators of the original game.\n\nAmong the plethora of increasingly sophisticated AI-generated iterations are a Manga-style Amelia, a Wallace and Gromit version and AI-generated “real life” encounters between her and the characters of Father Ted or Harry Potter, accompanied by racist language and far-right messaging.\n\nAnalysis provided to the Guardian by Logically, a UK company that monitors disinformation, indicated that an anonymous account known for skilfully disseminating far-right messaging started the Amelia meme on X on 9 January with a post that has since been viewed 1.4m times.\n\nThe volume of “Ameliaposting” has since gone from an average of 500 a day when that account first introduced it to the world to roughly 10,000, starting on 15 January as it hit international audiences. On Wednesday, it hit 11,137 posts on X alone.\n\nIn one of the most surreal twists, an Amelia cryptocurrency has emerged, with social media users seeking to leverage its value on the meme’s rising profile. On Wednesday, Elon Musk retweeted an X account promoting an Amelia cryptocurrency token.\n\n“What we’re seeing is the monetisation of hate,” said Matteo Bergamini, the founder and CEO of Shout Out UK, a political and media literacy training company that created the original game.\n\n“We’ve seen Telegram groups all messaging each other in Chinese about the meme coin and talking about how to artificially inflate its value, so a lot of money is being made.”\n\nThe company itself has been the target of a deluge of hate mail, including threats that have now been reported to the police.\n\nBergamini points out that the original initiative was never meant to be a stand-alone game. Rather, it was intended to be used in the classrooms alongside a suite of teaching resources, a fact he says coverage and commentary has ignored.\n\n“There has been a lot of misrepresentation unfortunately,” he said. “The game does not state, for example, that questioning mass migration is inherently wrong.”\n\nOthers have suggested the initiative had backfired, not least by casting a “cute goth girl” as a negative character, leading to her inadvertently becoming a focus of admiration. But Bergamini said the game – which used feedback from focus groups with young people and was developed with a specific local threat picture in mind – continued to be used and feedback from schools and others was positive.\n\nNevertheless, the speed and sophistication surrounding the creation of supposedly subversive Amelia memes online has taken him by surprise.\n\n“This experience has shown us why this work is so immensely important, but also gives us pause for thought about our safety in conducting this work due to the highly sophisticated coordination of those who profit from hate,” he said.\n\nSiddharth Venkataramakrishnan, an analyst at the Institute for Strategic Dialogue (ISD), said: “We have seen the meme having a remarkable spread and proliferating among the far right and beyond, but what’s also been of note is how it is now international.\n\n“In a way it gets to the heart of what we might term the ‘dissident’ far-right – individuals who position themselves outside of the mainstream political scene – whether that’s ‘shitposters’ who are just into provoking, others who are in twee memes. A whole ecosystem has embraced it. Clearly, the sexualised imagery is also key to this. The target audience is almost exclusively young men.”\n\nThe Home Office said Prevent had diverted nearly 6,000 people away from violent ideologies. It added that projects such as the Pathways game were designed to target local radicalisation risks and were created and delivered independently of government.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 6,
    "keywords": [
      "guardian app",
      "amelia cryptocurrency",
      "goth girl",
      "amelia memes",
      "online silos",
      "social media",
      "amelia character",
      "niche online",
      "far-right messaging",
      "original game"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/politics/2026/jan/25/ai-generated-british-schoolgirl-becomes-far-right-social-media-meme",
    "thumbnail_url": "https://i.guim.co.uk/img/media/26efdf93744cc3dad8342e41a32f55a2223f492d/25_232_426_341/master/426.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=efab30f655c69a3380b52614cb01c10d",
    "created_at": "2026-01-25T12:22:40.227Z",
    "topic": "politic"
  },
  {
    "slug": "the-ladder-to-nowhere-how-openai-plans-to-learn-everything-about-you",
    "title": "The Ladder to Nowhere: How OpenAI Plans to Learn Everything About You",
    "description": "ChatGPT Health is a small part of a much larger plan to learn everything about you. In this post, I talk about what's driving them and how they might get there.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://insights.priva.cat/p/the-ladder-to-nowhere-how-openai",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!RPej!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dfb7d3-a672-4f00-bf6b-1607229c44f7_2752x1536.png",
    "created_at": "2026-01-25T12:22:39.078Z",
    "topic": "tech"
  },
  {
    "slug": "the-math-on-ai-agents-doesnt-add-up",
    "title": "The Math on AI Agents Doesn't Add Up",
    "description": "A research paper suggests AI agents are mathematically doomed to fail. The industry doesn’t agree.",
    "fullText": "companies promised us that 2025 would be “the year of the AI agents.” It turned out to be the year of talking about AI agents, and kicking the can for that transformational moment to 2026 or maybe later. But what if the answer to the question “When will our lives be fully automated by generative AI robots that perform our tasks for us and basically run the world?” is, like that New Yorker cartoon, “How about never?”\n\nThat was basically the message of a paper published without much fanfare some months ago, smack in the middle of the overhyped year of “agentic AI.” Entitled “Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models,” it purports to mathematically show that “LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity.” Though the science is beyond me, the authors—a former SAP CTO who studied AI under one of the field’s founding intellects, John McCarthy, and his teenage prodigy son—punctured the vision of agentic paradise with the certainty of mathematics. Even reasoning models that go beyond the pure word-prediction process of LLMs, they say, won’t fix the problem.\n\n“There is no way they can be reliable,” Vishal Sikka, the dad, tells me. After a career that, in addition to SAP, included a stint as Infosys CEO and an Oracle board member, he currently heads an AI services startup called Vianai. “So we should forget about AI agents running nuclear power plants?” I ask. “Exactly,” he says. Maybe you can get it to file some papers or something to save time, but you might have to resign yourself to some mistakes.\n\nThe AI industry begs to differ. For one thing, a big success in agent AI has been coding, which took off last year. Just this week at Davos, Google’s Nobel-winning head of AI, Demis Hassabis, reported breakthroughs in minimizing hallucinations, and hyperscalers and startups alike are pushing the agent narrative. Now they have some backup. A startup called Harmonic is reporting a breakthrough in AI coding that also hinges on mathematics—and tops benchmarks on reliability.\n\nHarmonic, which was cofounded by Robinhood CEO Vlad Tenev and Tudor Achim, a Stanford-trained mathematician, claims this recent improvement to its product called Aristotle (no hubris there!) is an indication that there are ways to guarantee the trustworthiness of AI systems. “Are we doomed to be in a world where AI just generates slop and humans can't really check it? That would be a crazy world,” says Achim. Harmonic’s solution is to use formal methods of mathematical reasoning to verify an LLM’s output. Specifically, it encodes outputs in the Lean programming language, which is known for its ability to verify the coding. To be sure, Harmonic’s focus to date has been narrow—its key mission is the pursuit of “mathematical superintelligence,” and coding is a somewhat organic extension. Things like history essays—which can’t be mathematically verified—are beyond its boundaries. For now.\n\nNonetheless, Achim doesn’t seem to think that reliable agentic behavior is as much an issue as some critics believe. “I would say that most models at this point have the level of pure intelligence required to reason through booking a travel itinerary,” he says.\n\nBoth sides are right—or maybe even on the same side. On one hand, everyone agrees that hallucinations will continue to be a vexing reality. In a paper published last September, OpenAI scientists wrote, “Despite significant progress, hallucinations continue to plague the field, and are still present in the latest models.” They proved that unhappy claim by asking three models, including ChatGPT, to provide the title of the lead author’s dissertation. All three made up fake titles and all misreported the year of publication. In a blog about the paper, OpenAI glumly stated that in AI models, “accuracy will never reach 100 percent.”",
    "readingTime": 4,
    "keywords": [
      "paper published",
      "models",
      "agentic",
      "beyond",
      "coding",
      "agents",
      "hallucinations",
      "tasks",
      "language",
      "mathematically"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/ai-agents-math-doesnt-add-up/",
    "thumbnail_url": "https://media.wired.com/photos/69728f0240976471f9fd714e/191:100/w_1280,c_limit/Backchannel-Is-Agentic-AI-Doomed-Business.jpg",
    "created_at": "2026-01-25T12:22:38.832Z",
    "topic": "tech"
  },
  {
    "slug": "agenthub-a-unified-sdk-for-llm-apis-with-faithful-validation",
    "title": "AgentHub – A unified SDK for LLM APIs with faithful validation",
    "description": "AgentHub is the only SDK you need to connect to state-of-the-art LLMs (GPT-5.2/Claude 4.5/Gemini 3). - Prism-Shadow/AgentHub",
    "fullText": "Prism-Shadow\n\n /\n\n AgentHub\n\n Public\n\n AgentHub is the only SDK you need to connect to state-of-the-art LLMs (GPT-5.2/Claude 4.5/Gemini 3).\n\n License\n\n Apache-2.0 license\n\n 30\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Prism-Shadow/AgentHub",
    "readingTime": 1,
    "keywords": [
      "license",
      "agenthub"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Prism-Shadow/AgentHub",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1135038596/73e1b398-f342-44f0-944e-cafe84869f56",
    "created_at": "2026-01-25T12:22:38.486Z",
    "topic": "tech"
  },
  {
    "slug": "mindwork-ai-workspace-for-focused-personal-knowledge-management",
    "title": "Mindwork – AI workspace for focused personal knowledge management",
    "description": "An AI workspace for focused and deep thinking.",
    "fullText": "An AI workspace for focused & deep thinking\n\nTry Mindwork\n Free during beta \nLearn about Mindwork →\n 1 Think with AI next to your notes 2 AI writes insights back into your notes 3 Open multiple notes in tabs 4 Markdown-first, zero lock-in 5 And much more \nExpand\n\nRead more",
    "readingTime": 1,
    "keywords": [
      "notes",
      "mindwork"
    ],
    "qualityScore": 0.1,
    "link": "https://mindwork.it.com/",
    "thumbnail_url": "https://mindwork.it.com/og-image.png",
    "created_at": "2026-01-25T12:22:38.275Z",
    "topic": "tech"
  },
  {
    "slug": "could-physical-ai-usher-in-a-new-era-for-industrial-robots",
    "title": "Could physical AI usher in a new era for industrial robots?",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/could-physical-ai-usher-in-a-new-era-for-industrial-robots-4460773",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEC4T0J3_M.jpg",
    "created_at": "2026-01-25T12:22:33.393Z",
    "topic": "finance"
  },
  {
    "slug": "vnsh-an-ephemeral-hostblind-file-sharing-tool-for-ai-context",
    "title": "Vnsh – An ephemeral, host-blind file sharing tool for AI context",
    "description": "End-to-end encrypted. Server is blind. 24h retention. The ultimate dead drop for vibecoding.",
    "fullText": "Zero-Access Architecture: vnsh implements true client-side encryption using AES-256-CBC with OpenSSL compatibility. Your data is encrypted entirely on your device before upload.\n\nHost-Blind Storage: The server stores only opaque binary blobs. Decryption keys travel exclusively in the URL fragment (#k=...) which is never sent to servers per HTTP specification.\n\nSecure Dead Drop: Unlike pastebins, vnsh cannot read your content even if subpoenaed. The server operator has no access to plaintext - mathematically impossible without the URL fragment.\n\nAuto-Vaporization: All data auto-destructs after 24 hours (configurable 1-168h). No history, no backups, no leaks. Perfect for ephemeral AI context sharing.",
    "readingTime": 1,
    "keywords": [
      "url fragment",
      "vnsh",
      "server"
    ],
    "qualityScore": 0.65,
    "link": "https://vnsh.dev",
    "thumbnail_url": "https://vnsh.dev/og-image.png",
    "created_at": "2026-01-25T06:18:56.307Z",
    "topic": "tech"
  },
  {
    "slug": "podcost-find-wasted-gpu-and-kubernetes-spend-with-live-demo",
    "title": "PodCost – Find wasted GPU and Kubernetes spend (with live demo)",
    "description": "PodCost shows engineering teams exactly where Kubernetes and AI infrastructure money is being wasted—and what to fix to save it, especially on GPUs.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://podcost.io/",
    "thumbnail_url": "https://podcost.io/opengraph.jpg?v=2",
    "created_at": "2026-01-25T06:18:55.749Z",
    "topic": "tech"
  },
  {
    "slug": "structured-data-extraction-using-local-quantized-llms",
    "title": "Structured data extraction using local quantized LLMs",
    "description": "⚡️ The All-in-One Local AI Data Cleaning Library. No GPU or API keys required. - nxank4/loclean",
    "fullText": "nxank4\n\n /\n\n loclean\n\n Public\n\n ⚡️ The All-in-One Local AI Data Cleaning Library. No GPU or API keys required.\n\n nxank4.github.io/loclean/\n\n License\n\n Apache-2.0 license\n\n 4\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n nxank4/loclean",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/nxank4/loclean",
    "thumbnail_url": "https://opengraph.githubassets.com/7861f3d603614d487c20b4e4be01851084ea6786e59d2536b71425c1ceaed6d7/nxank4/loclean",
    "created_at": "2026-01-25T06:18:55.176Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-dynamic-memory-compression",
    "title": "Nvidia: Dynamic Memory Compression",
    "description": "Despite the success of large language models (LLMs) as general-purpose AI tools, their high demand for computational resources make their deployment challenging in many real-world scenarios.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://developer.nvidia.com/blog/dynamic-memory-compression/",
    "thumbnail_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2025/01/inference-amazon-tensorrt-llm-featured.jpg",
    "created_at": "2026-01-25T01:04:24.550Z",
    "topic": "tech"
  },
  {
    "slug": "curl-gets-rid-of-its-bug-bounty-program-over-ai-slop-overrun",
    "title": "Curl Gets Rid of Its Bug Bounty Program over AI Slop Overrun",
    "description": "Daniel Stenberg says the inflow of AI slop has become unsustainable for the curl security team to handle.",
    "fullText": "Last year in May, the cURL project's bug bounty program was inundated with AI slop, where many bogus reports were opened on HackerOne, leaving the cURL maintainers to go through garbage.\n\nThe problem didn't stop even after Daniel Stenberg, the creator of cURL, threatened to ban anyone whose bug report was found to be AI slop. We are now in 2026, and the situation has reached a tipping point.\n\nDaniel has submitted a pull request on GitHub that removes all mentions of the bug bounty program from cURL's documentation and website. Coinciding with that, the project's security.txt file has been updated with some blunt language that makes the new policy crystal clear.\n\nThe cURL team intends to make a proper announcement in the coming days, though many outlets have already covered the news of this happening, so I would say they ought to get on it ASAP! 😆\n\nThe program officially ends in a few days on January 31, 2026. After that, security researchers can still report issues through GitHub or the project's mailing list, but there won't be any cash involved.\n\nWhat pushed them over the edge?, you ask. Well, just weeks into 2026, seven HackerOne reports came in within a 16-hour period in just one week. Some were actual bugs, but none of them were security vulnerabilities. By the time Daniel posted his recent weekly report, they'd already dealt with 20 submissions in 2026.\n\nThe main goal here is said to be stopping the flood of garbage reports. By eliminating the money incentive, they are hoping people (or bots?) will stop wasting the security team's time with half-baked, unresearched submissions.\n\nHe also gives a stern warning to wannabe AI sloppers, saying that:\n\nSo, yeah, that's that. If people still don't understand that AI slop is harmful to such sensitive pieces of software, then sure, they can go ahead and make a fool of themselves.\n\nSuggested Read 📖: Open Source Project LLVM Says Yes to AI-Generated Code",
    "readingTime": 2,
    "keywords": [
      "bug bounty",
      "bounty program",
      "curl",
      "project's",
      "slop",
      "reports",
      "security",
      "hackerone",
      "garbage",
      "stop"
    ],
    "qualityScore": 0.85,
    "link": "https://itsfoss.com/news/curl-closes-bug-bounty-program/",
    "thumbnail_url": "https://itsfoss.com/content/images/2026/01/curl-bug-bounty-program-discontinued.png",
    "created_at": "2026-01-25T01:04:22.689Z",
    "topic": "tech"
  },
  {
    "slug": "d4rt-teaching-ai-to-see-the-world-in-four-dimensions",
    "title": "D4RT: Teaching AI to see the world in four dimensions",
    "description": "Meet D4RT, a unified AI model for 4D scene reconstruction and tracking.",
    "fullText": "January 22, 2026\n\n Research\n\n D4RT: Teaching AI to see the world in four dimensions\n\n Guillaume Le Moing and Mehdi S. M. Sajjadi",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/",
    "thumbnail_url": "https://lh3.googleusercontent.com/ozG6v7VcBOV2eYZ8TnGTAe1Z-7EjkNiBPHxdQEG1wy_F5QwRN_4IJ_jJYMNQiOMHEWyNMZg3tmC00bzGQX0IYfXHMVuoQS6OLptEV-H6CUpIOnWOaQ=w1200-h630-n-nu",
    "created_at": "2026-01-24T18:17:12.186Z",
    "topic": "tech"
  },
  {
    "slug": "rdytofly-replace-notes-shared-docs-and-x-other-apps-90-free",
    "title": "Rdytofly – Replace notes, shared docs, and X other apps (90% free)",
    "description": "Build stunning day-by-day itineraries in minutes. AI-powered trip planning, flight tracking, budget management & beautiful PDF exports. Join 120+ travelers.",
    "fullText": "Zorganizujte si výlet, sdílejte s přáteli a udělejte z každé cesty nezapomenutelný zážitek\n\nPoužívá více než 120 cestovatelů\n\nNaplánujte každý den s podrobnými aktivitami a místy\n\nMějte všechny podrobnosti o letech na jednom místě\n\nSdílejte své plány se spolucestujícími\n\nStáhněte si výlet jako krásné PDF\n\nVizualizujte své aktivity na mapě\n\nNikdy nezapomeňte na nic důležitého před výletem\n\nUchovávejte poznámky, fotky a vzpomínky z každé cesty. Budujte si osobní cestovní příběh a vzpomínejte na každé dobrodružství\n\nNeomezené výlety, AI plánování a exkluzivní funkce",
    "readingTime": 1,
    "keywords": [
      "každ cesty",
      "výlet",
      "sdílejte"
    ],
    "qualityScore": 0.35,
    "link": "https://rdytofly.com/en",
    "thumbnail_url": "https://rdytofly.com/logo-full.png",
    "created_at": "2026-01-24T18:17:10.672Z",
    "topic": "tech"
  },
  {
    "slug": "latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
    "title": "Latest ChatGPT model uses Elon Musk’s Grokipedia as source, tests reveal",
    "description": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniers\nThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.\nIn tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial.\n Continue reading...",
    "fullText": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniers\n\nThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.\n\nIn tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial.\n\nGrokipedia, launched in October, is an AI-generated online encyclopedia that aims to compete with Wikipedia, and which has been criticised for propagating rightwing narratives on topics including gay marriage and the 6 January insurrection in the US. Unlike Wikipedia, it does not allow direct human editing, instead an AI model writes content and responds to requests for changes.\n\nChatGPT did not cite Grokipedia when prompted directly to repeat misinformation about the insurrection, about media bias against Donald Trump, or about the HIV/Aids epidemic – areas where Grokipedia has been widely reported to promote falsehoods. Instead, Grokipedia’s information filtered into the model’s responses when it was prompted about more obscure topics.\n\nFor instance, ChatGPT, citing Grokipedia, repeated stronger claims about the Iranian government’s links to MTN-Irancell than are found on Wikipedia – such as asserting that the company has links to the office of Iran’s supreme leader.\n\nChatGPT also cited Grokipedia when repeating information that the Guardian has debunked, namely details about Sir Richard Evans’ work as an expert witness in David Irving’s trial.\n\nGPT-5.2 is not the only large language model (LLM) that appears to be citing Grokipedia; anecdotally, Anthropic’s Claude has also referenced Musk’s encyclopedia on topics from petroleum production to Scottish ales.\n\nAn OpenAI spokesperson said the model’s web search “aims to draw from a broad range of publicly available sources and viewpoints”.\n\n“We apply safety filters to reduce the risk of surfacing links associated with high-severity harms, and ChatGPT clearly shows which sources informed a response through citations,” they said, adding that they had ongoing programs to filter out low-credibility information and influence campaigns.\n\nAnthropic did not respond to a request for comment.\n\nBut the fact that Grokipedia’s information is filtering – at times very subtly – into LLM responses is a concern for disinformation researchers. Last spring, security experts raised concerns that malign actors, including Russian propaganda networks, were churning out massive volumes of disinformation in an effort to seed AI models with lies, a process called “LLM grooming”.\n\nIn June, concerns were raised in the US Congress that Google’s Gemini repeated the Chinese government’s position on human rights abuses in Xinjiang and China’s Covid-19 policies.\n\nNina Jankowicz, a disinformation researcher who has worked on LLM grooming, said ChatGPT’s citing Grokipedia raised similar concerns. While Musk may not have intended to influence LLMs, Grokipedia entries she and colleagues had reviewed were “relying on sources that are untrustworthy at best, poorly sourced and deliberate disinformation at worst”, she said.\n\nAnd the fact that LLMs cite sources such as Grokipedia or the Pravda network may, in turn, improve these sources’ credibility in the eyes of readers. “They might say, ‘oh, ChatGPT is citing it, these models are citing it, it must be a decent source, surely they’ve vetted it’ – and they might go there and look for news about Ukraine,” said Jankowicz.\n\nBad information, once it has filtered into an AI chatbot, can be challenging to remove. Jankowicz recently found that a large news outlet had included a made-up quote from her in a story about disinformation. She wrote to the news outlet asking for the quote to be removed, and posted about the incident on social media.\n\nThe news outlet removed the quote. However, AI models for some time continued to cite it as hers. “Most people won’t do the work necessary to figure out where the truth actually lies,” she said.\n\nWhen asked for comment, a spokesperson for xAI, the owner of Grokipedia, said: “Legacy media lies.”",
    "readingTime": 4,
    "keywords": [
      "sir richard",
      "richard evans",
      "holocaust deniers",
      "llm grooming",
      "cited grokipedia",
      "expert witness",
      "citing grokipedia",
      "chatgpt",
      "disinformation",
      "topics"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/24/latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
    "thumbnail_url": "https://i.guim.co.uk/img/media/202d8061a28d8c1b855097fb90558014cb00d220/135_0_4675_3740/master/4675.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=fc74f3ad623847f91b340f08501077e0",
    "created_at": "2026-01-24T18:17:06.605Z",
    "topic": "tech"
  },
  {
    "slug": "google-ai-overviews-cite-youtube-more-than-any-medical-site-for-health-queries-study-suggests",
    "title": "Google AI Overviews cite YouTube more than any medical site for health queries, study suggests",
    "description": "Exclusive: German research into responses to health queries raises fresh questions about summaries seen by 2bn people a month\n• How the ‘confident authority’ of AI Overviews is putting public health at risk\nGoogle’s search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that raises fresh questions about a tool seen by 2 billion people each month.\nThe company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are “reliable” and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.\n Continue reading...",
    "fullText": "Exclusive: German research into responses to health queries raises fresh questions about summaries seen by 2bn people a month\n\nHow the ‘confident authority’ of AI Overviews is putting public health at risk\n\nGoogle’s search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that raises fresh questions about a tool seen by 2 billion people each month.\n\nThe company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are “reliable” and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.\n\nHowever, a study that analysed responses to more than 50,000 health queries, captured using Google searches from Berlin, found the top cited source was YouTube. The video-sharing platform is the world’s second most visited website, after Google itself, and is owned by Google.\n\nResearchers at SE Ranking, a search engine optimisation platform, found YouTube made up 4.43% of all AI Overview citations. No hospital network, government health portal, medical association or academic institution came close to that number, they said.\n\n“This matters because YouTube is not a medical publisher,” the researchers wrote. “It is a general-purpose video platform. Anyone can upload content there (eg board-certified physicians, hospital channels, but also wellness influencers, life coaches, and creators with no medical training at all).”\n\nGoogle told the Guardian that AI Overviews was designed to surface high-quality content from reputable sources, regardless of format, and a variety of credible health authorities and licensed medical professionals created content on YouTube. The study’s findings could not be extrapolated to other regions as it was conducted using German-language queries in Germany, it said.\n\nThe research comes after a Guardian investigation found people were being put at risk of harm by false and misleading health information in Google AI Overviews responses.\n\nIn one case that experts said was “dangerous” and “alarming”, Google provided bogus information about crucial liver function tests that could have left people with serious liver disease wrongly thinking they were healthy. The company later removed AI Overviews for some but not all medical searches.\n\nThe SE Ranking study analysed 50,807 healthcare-related prompts and keywords to see which sources AI Overviews relied on when generating answers.\n\nThey chose Germany because its healthcare system is strictly regulated by a mix of German and EU directives, standards and safety regulations. “If AI systems rely heavily on non-medical or non-authoritative sources even in such an environment, it suggests the issue may extend beyond any single country,” they wrote.\n\nAI Overviews surfaced on more than 82% of health searches, the researchers said. When they looked at which sources AI Overviews relied on most often for health-related answers, one result stood out immediately, they said. The single most cited domain was YouTube with 20,621 citations out of a total of 465,823.\n\nThe next most cited source was NDR.de, with 14,158 citations (3.04%). The German public broadcaster produces health-related content alongside news, documentaries and entertainment. In third place was a medical reference site, Msdmanuals.com with 9,711 citations (2.08%).\n\nThe fourth most cited source was Germany’s largest consumer health portal, Netdoktor.de, with 7,519 citations (1.61%). The fifth most cited source was a career platform for doctors, Praktischarzt.de, with 7,145 citations (1.53%).\n\nThe researchers acknowledged limitations to their study. It was conducted as a one-time snapshot in December 2025, using German-language queries that reflected how users in Germany typically search for health information.\n\nResults could vary over time, by region, and by the phrasing of questions. However, even with those caveats, the findings still prompted alarm.\n\nHannah van Kolfschooten, a researcher specialising in AI, health and law at the University of Basel who was not involved with the research, said: “This study provides empirical evidence that the risks posed by AI Overviews for health are structural, not anecdotal. It becomes difficult for Google to argue that misleading or harmful health outputs are rare cases.\n\n“Instead, the findings show that these risks are embedded in the way AI Overviews are designed. In particular, the heavy reliance on YouTube rather than on public health authorities or medical institutions suggests that visibility and popularity, rather than medical reliability, is the central driver for health knowledge.”\n\nA Google spokesperson said: “The implication that AI Overviews provide unreliable information is refuted by the report’s own data, which shows that the most cited domains in AI Overviews are reputable websites. And from what we’ve seen in the published findings, AI Overviews cite expert YouTube content from hospitals and clinics.”\n\nGoogle said the study showed that of the 25 most cited YouTube videos, 96% were from medical channels. However, the researchers cautioned that these videos represented fewer than 1% of all the YouTube links cited by AI Overviews on health.\n\n“Most of them (24 out of 25) come from medical-related channels like hospitals, clinics and health organisations,” the researchers wrote. “On top of that, 21 of the 25 videos clearly note that the content was created by a licensed or trusted source.\n\n“So at first glance it looks pretty reassuring. But it’s important to remember that these 25 videos are just a tiny slice (less than 1% of all YouTube links AI Overviews actually cite). With the rest of the videos, the situation could be very different.”",
    "readingTime": 5,
    "keywords": [
      "ai overviews",
      "german-language queries",
      "youtube links",
      "overviews relied",
      "health portal",
      "health authorities",
      "youtube the",
      "medical",
      "cited",
      "citations"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0fd9215aeefc347883d2e12f7e2ac337bc58c231/0_147_4000_3198/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0037ea636e0877a7aa0c8778c26c2d7b",
    "created_at": "2026-01-24T18:17:06.602Z",
    "topic": "tech"
  },
  {
    "slug": "how-the-confident-authority-of-google-ai-overviews-is-putting-public-health-at-risk",
    "title": "How the ‘confident authority’ of Google AI Overviews is putting public health at risk",
    "description": "Experts say tool can give ‘completely wrong’ medical advice which could put users at risk of serious harm\n• AI Overviews cite YouTube more than any medical site, study suggests\nDo I have the flu or Covid? Why do I wake up feeling tired? What is causing the pain in my chest? For more than two decades, typing medical questions into the world’s most popular search engine has served up a list of links to websites with the answers. Google those health queries today and the response will likely be written by artificial intelligence.",
    "fullText": "Do I have the flu or Covid? Why do I wake up feeling tired? What is causing the pain in my chest? For more than two decades, typing medical questions into the world’s most popular search engine has served up a list of links to websites with the answers. Google those health queries today and the response will likely be written by artificial intelligence.\n\nSundar Pichai, Google’s chief executive, first set out the company’s plans to enmesh AI into its search engine at its annual conference in Mountain View, California, in May 2024. Starting that month, he said, US users would see a new feature, AI Overviews, which would provide information summaries above traditional search results. The change marked the biggest shake-up of Google’s core product in a quarter of a century. By July 2025, the technology had expanded to more than 200 countries in 40 languages, with 2 billion people served AI Overviews each month.\n\nWith the rapid rollout of AI Overviews, Google is racing to protect its traditional search business, which generates about $200bn (£147bn) a year, before upstart AI rivals can derail it. “We are leading at the frontier of AI and shipping at an incredible pace,” Pichai said last July. AI Overviews in particular were “performing well”, he added.\n\nBut overviews carry risks, experts say. They use generative AI to provide snapshots of information about a topic or question, adding conversational answers above the traditional search results in the blink of an eye. They can cite sources, but do not necessarily know when that source is incorrect.\n\nWithin weeks of the feature launching in the US, users encountered untruths across a range of subjects. One AI Overview said Andrew Jackson, the seventh US president, graduated from college in 2005. Elizabeth Reid, Google’s head of search, responded to criticism in a blog post. She conceded that “in a small number of cases”, AI Overviews had misinterpreted language on web pages and presented inaccurate information. “At the scale of the web, with billions of queries coming in every day, there are bound to be some oddities and errors,” she wrote.\n\nBut when those questions are about health, accuracy and context are essential and non-negotiable, experts say. Google is facing mounting scrutiny of its AI Overviews for medical queries after a Guardian investigation found people were being put at risk of harm by false and misleading health information.\n\nThe company says AI Overviews are “reliable”. But the Guardian found some medical summaries served up inaccurate health information and put people at risk of harm. In one case, which experts said was “really dangerous”, Google wrongly advised people with pancreatic cancer to avoid high-fat foods. Experts said this was the exact opposite of what should be recommended, and may increase the risk of patients dying from the disease.\n\nIn another “alarming” example, the company provided bogus information about crucial liver function tests, which could leave people who had serious liver disease wrongly thinking they were healthy. What AI Overviews said was normal could vary drastically from what was actually considered normal, experts said. The summaries could lead to seriously ill patients wrongly thinking they had a normal test result and not bothering to attend follow-up appointments.\n\nAI Overviews about women’s cancer tests also provided “completely wrong” information, which experts said could result in people dismissing genuine symptoms.\n\nGoogle initially sought to downplay the Guardian’s findings. From what its own clinicians could assess, the company said, the AI Overviews that alarmed experts linked to reputable sources and recommended seeking expert advice. “We invest significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information,” a spokesperson said.\n\nWithin days, however, the company removed some of the AI Overviews for health queries flagged by the Guardian. “We do not comment on individual removals within search,” a spokesperson said. “In cases where AI Overviews miss some context, we work to make broad improvements, and we also take action under our policies where appropriate.”\n\nWhile experts welcomed the removal of some AI summaries for health queries, many remain worried. “Our bigger concern with all this is that it is nit-picking a single search result and Google can just shut off the AI Overviews for that but it’s not tackling the bigger issue of AI Overviews for health,” says Vanessa Hebditch, the director of communications and policy at the British Liver Trust, a liver health charity.\n\n“There are still too many examples out there of Google AI Overviews giving people inaccurate health information,” adds Sue Farrington, the chair of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals.\n\nA new study has prompted more concerns. When researchers analysed the responses to more than 50,000 health-related searches in Germany to see which sources AI Overviews rely on most, one result stood out immediately. The single most cited domain was YouTube.\n\n“This matters because YouTube is not a medical publisher,” the researchers wrote. “It is a general-purpose video platform. Anyone can upload content there (eg, board-certified physicians, hospital channels, but also wellness influencers, life coaches and creators with no medical training at all).”\n\nIn medicine, it is not only where answers come from that matter, or their level of accuracy, but how they are presented to users, experts say. “With AI Overviews, users no longer encounter a range of sources that they can compare and critically assess,” says Hannah van Kolfschooten, a researcher in AI, health and law at the University of Basel. “Instead, they are presented with a single, confident, AI-generated answer that exhibits medical authority.\n\n“This means that the system does not merely reflect health information online, but actively restructures it. When that response is built on sources never designed to meet medical standards, such as YouTube videos, this creates a new form of unregulated medical authority online.”\n\nGoogle says AI Overviews are built to surface information backed up by top web results, and include links to web content that supports the information presented in the summary. People can use these links to dig deeper on a topic, the company told the Guardian.\n\nBut the single blocks of text in AI Overviews, combining health information from multiple sources, can cause confusion, says Nicole Gross, an associate professor in business and society at the National College of Ireland.\n\n“Once the AI summary appears, users are much less likely to research further, which means that they are deprived of the opportunity to critically evaluate and compare information, or even deploy their common sense when it comes to health-related issues.”\n\nExperts have raised other concerns with the Guardian. Even if and when AI Overviews do provide accurate facts about a specific medical topic, they may not distinguish between strong evidence from randomised trials and weaker evidence from observational studies, they say. Some also miss important caveats about that evidence, they add.\n\nHaving such claims listed next to one another in an AI Overview may also give the impression that some are better established than they really are. Answers can also change as AI Overviews evolve, even when the science hasn’t shifted. “That means that people are getting a different answer depending on when they search, and that’s not good enough,” says Athena Lamnisos, the chief executive of the Eve Appeal cancer charity.\n\nGoogle told the Guardian that links included in AI Overviews were dynamic and changed based on the information that was most relevant, helpful and timely for a given search. If AI Overviews misinterpreted web content or missed some context, the company would use these errors to improve its systems, and also take action when appropriate, it said.\n\nThe biggest worry is that bogus and dangerous medical information or advice in AI Overviews “ends up getting translated into the everyday practices, routines and life of a patient, even in adapted forms”, says Gross. “In healthcare, this can turn into a matter of life and death.”",
    "readingTime": 7,
    "keywords": [
      "ai overviews",
      "chief executive",
      "web content",
      "search engine",
      "traditional search",
      "medical authority",
      "experts say",
      "inaccurate health",
      "health queries",
      "users"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/jan/24/how-the-confident-authority-of-google-ai-overviews-is-putting-public-health-at-risk",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0fd9215aeefc347883d2e12f7e2ac337bc58c231/0_147_4000_3198/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0037ea636e0877a7aa0c8778c26c2d7b",
    "created_at": "2026-01-24T18:17:06.591Z",
    "topic": "tech"
  },
  {
    "slug": "i-was-laid-off-from-crowdstrike-and-used-ai-to-send-800-applications-in-a-month-to-land-my-ideal-role",
    "title": "I was laid off from CrowdStrike and used AI to send 800 applications in a month to land my ideal role",
    "description": "With the help of an AI platform, one man submitted more than 800 job applications in a month, resulting in 5 interviews and 1 ideal offer.",
    "fullText": "This as-told-to essay is based on a conversation with Dray Jankowski, former employee at CrowdStrike and current senior director of product operations and program management at Wunderkind. Business Insider verified his identity. This essay has been edited for length and clarity.\n\nI still remember the morning I found out I was getting laid off from CrowdStrike.\n\nI went to bed thinking everything was fine, and when I woke up, there was a mysterious meeting on my calendar for later that afternoon.\n\nThat's when I saw the email that said the company was doing a reduction in force as it adjusted to changes driven by AI. It wasn't about financial trouble. It was sudden, impersonal, and final. At 30, it was my first layoff.\n\nI was shaken. I worked hard to get where I was. At CrowdStrike, I was a program manager working closely with the team that makes motion sensors. I also worked at Amazon and Raytheon and consulted with companies such as Microsoft and Johnson & Johnson. I had what people would consider a \"great résumé.\"\n\nLittle did I know how brutal the job market would become and how hard it would be to find the right fit.\n\nIn the first three months after my layoff, I applied to 52 jobs on my own, and I hated every second of it.\n\nAt first, I wasn't even looking. I had savings, and it was summer. I traveled to Yellowstone, spent time with my mom and my two dogs, and casually applied to roles I actually liked.\n\nInstead of being quiet about my layoff, I also decided to be vocal. I started making YouTube videos and launched a podcast called \"The Reboot Era,\" where I talked openly about layoffs and invited others to share their experiences.\n\nEven with my background, the job-search process was frustrating. I'd turn to ChatGPT with basic questions like, \"Should I update my résumé for this role?\" and I started noticing how many people were stuck for months because they didn't know how to optimize it for applicant tracking systems. When I looked for help online, most of it was locked behind paywalls.\n\nLinkedIn \"Easy Apply\" felt like a black hole. Company websites made me create a new Workday account every time. The process was tedious, slow, and draining. So when an AI-powered application platform reached out to me after seeing my posts about layoffs, I invited them onto my podcast with a catch: I wouldn't promote anything unless I tested it myself and believed it worked.\n\nAt first, the results didn't seem promising. The very first call I got was from a car wash near my house.\n\nA week later, something changed. I started getting legitimate interview requests for corporate roles that matched my experience and salary range. One message on LinkedIn asked if I wanted to interview with a company I'd never even heard of. That's when I knew the AI had applied for me.\n\nOver the course of about a month, the platform sent out 812 applications on my behalf. It also shows you which keywords to hit in your cover letters, and you can set your own parameters.\n\nWith AI handling the repetitive work, I could focus on preparing for interviews, refining my résumé, networking, and continuing my podcast.\n\nIn total, I received five serious interview requests that were aligned with what I wanted. I moved forward with two. One didn't pan out, but the other moved fast. Within two weeks, I had an offer.\n\nThat's how I landed my current role as senior director of product operations and program management at Wunderkind, a marketing technology company that helps brands re-engage customers who leave their websites without making a purchase.\n\nAI didn't get me the job. It got me the interview. From there, it was on me to show up, connect, and prove I was the right person.\n\nI think the job market is going in the wrong direction.\n\nFirst, companies decide they can automate many standard workflows and lay off workers. Those employees are then pushed back into the open job market, forced to apply for new roles. Now, they face AI screening systems that evaluate them against opaque criteria they can't see or understand.\n\nIf the applicant is using AI as well, they get rejected by the screener AI if they sound too robotic. Then, even when you do get the interview, many offers ask you to meet with a digital recruiter who's not a real person and will ask automated questions.\n\nNone of that seems fair, and it often feels like AI is working against job seekers in this brutal market. It took me more than 800 applications to get one great offer, so it is reasonable if you need help. When used correctly, AI can be the tool that gives you your time and momentum back.",
    "readingTime": 5,
    "keywords": [
      "senior director",
      "product operations",
      "program management",
      "interview requests",
      "job market",
      "didn't",
      "that's",
      "layoff",
      "résum",
      "applied"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/laid-off-from-crowdstrike-used-ai-to-land-ideal-role-2026-1",
    "thumbnail_url": "https://i.insider.com/6973cf24e1ba468a96aa9e99?width=960&format=jpeg",
    "created_at": "2026-01-24T12:21:34.212Z",
    "topic": "finance"
  },
  {
    "slug": "giving-claude-code-hands-to-deliver-local-files-p2p-no-cloud",
    "title": "Giving Claude Code \"hands\" to deliver local files (P2P, No Cloud)",
    "description": "MCP server for ffl. Let AI share anything for you. - nuwainfo/ffl-mcp",
    "fullText": "nuwainfo\n\n /\n\n ffl-mcp\n\n Public\n\n MCP server for ffl. Let AI share anything for you.\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n nuwainfo/ffl-mcp",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/nuwainfo/ffl-mcp",
    "thumbnail_url": "https://opengraph.githubassets.com/1b7e75a1d326923c46db92a0e00faff77d73fbac92e2a41867b3c0e4be1f02de/nuwainfo/ffl-mcp",
    "created_at": "2026-01-24T12:21:31.031Z",
    "topic": "tech"
  },
  {
    "slug": "reverse-engineering-river-raid-with-claude-ghidra-and-mcp",
    "title": "Reverse Engineering River Raid with Claude, Ghidra, and MCP",
    "description": "Connecting Claude to Ghidra via MCP to reverse engineer River Raid. A test of AI agents against 6502 assembly, memory mapping, and 80s game logic.",
    "fullText": "Can an AI agent navigate Ghidra, the NSA’s open-source reverse engineering suite, well enough to hack an Atari game? Ghidra is powerful but notoriously complex, with a steep learning curve. Instead of spending weeks learning its interface, what if I could simply describe my goal and let an AI handle the complexity?\n\nRiver Raid, the Atari 8-bit version. My first computer was an Atari back in the 80s, and this particular game occupied a disproportionate amount of my childhood attention.\n\nThe ROM is exactly 8kB — almost comical by modern standards. And yet this tiny binary contains everything: graphics, sound, enemy AI, and physics simulation — all compressed into hand-optimized 6502 assembly.\n\nThe objective was straightforward: unlimited lives. It’s the quintessential hack, a rite of passage that kids with hex editors performed for entertainment back in the 80s. In 2025, instead of a hex editor, I have an AI.\n\nGhidra doesn’t have a native AI assistant, so I needed a way to bridge the gap between my instructions and the tool’s internal API. This is where the Model Context Protocol (MCP) comes in.\n\nI found an open-source MCP server for Ghidra — essentially a connector that allows Claude to talk directly to Ghidra. The concept is elegant: Claude connects to the running Ghidra instance, analyzes the binary, renames functions, and identifies code patterns programmatically.\n\nIn practice, the experience was considerably less elegant:\n\nHere’s the thing: I don’t use disassemblers daily. Ghidra’s workflow was completely foreign to me. The whole point was to see if AI could bridge that gap — I’d feed it a mysterious binary, and the Ghidra + LLM combination would figure out it’s a cartridge dump, handle the memory mapping, and guide me through.\n\nReality was harsher. To test the AI properly, I renamed the binary to a.rom — no helpful filename hints. When importing, I selected only the CPU architecture (6502) without specifying the platform. Claude’s first instinct was reasonable: it asked for the MD5 hash to search for known ROM signatures. The MCP tools don’t expose hashing, so that avenue closed immediately.\n\nFirst problem: Ghidra loaded the ROM at $0000, not $A000 where Atari cartridges live. All cross-references pointed nowhere.\n\nClaude identified the issue with admirable clarity: “The ROM should be loaded at $A000, not $0000. You’ll need to rebase the memory image.”\n\nMe: “Can you perform the rebase?”\n\nClaude: “Unfortunately, no. The MCP tools don’t have write access for that particular operation.”\n\nI rebased manually to $8000 — still wrong. The code referenced $A000-$BFFF. Rebased again.\n\nTwo rebasing operations in total, neither of which the AI could perform.\n\nWhere Claude genuinely excelled was in identifying the target platform through hardware register analysis:\n\nHardware addresses are essentially fingerprints that can’t be faked, and these particular addresses are unmistakably Atari 8-bit.\n\nI asked Claude to attempt identification of the game based purely on code patterns and structural analysis. It examined the evidence methodically. Based on this evidence, Claude reached its conclusion:\n\nIt was, of course, not Centipede. It was River Raid.\n\nThis serves as a useful reminder that confidence and accuracy are orthogonal properties.\n\nDespite the identity crisis, Claude still understood the code structure. Finding the lives decrement was straightforward. Claude searched for the canonical pattern: load, decrement, store.\n\nThe fix is elegantly simple: replace DEY (decrement Y register) with NOP (no operation). A single byte modification, where $88 becomes $EA.\n\nSince the MCP tool couldn’t write the binary directly, I applied the patch externally:\n\nI tested the patched ROM in an emulator by deliberately crashing into a bridge. The lives counter remained stubbornly fixed at 3.\n\nClaude excelled at pattern recognition — hardware registers, code flow, finding the patch location. It struggled with tasks requiring broader context, such as identifying the game or analyzing sprite data.\n\nSetting up MCP is a troubleshooting ritual. It eventually worked, but the experience was painfully slow. Claude would fire off a batch of tool calls, some taking 30 seconds each. Too slow for an interactive session — I’d rather have quick responses with clarifying questions than watch a progress bar crawl. We need a better balance between autonomous batch processing and interactive guidance.\n\nAI should be embedded in every complex GUI tool. We’re in the experimental phase now. Some things work, some don’t. Ideally AI should smooth out the experience in ways traditional help systems never could — compacted Stack Overflow knowledge, real context-aware assistance, and the ability to actually perform tasks rather than just describe them.\n\nStay tuned for future posts and releases",
    "readingTime": 4,
    "keywords": [
      "river raid",
      "atari bit",
      "mcp tools",
      "tools don’t",
      "code patterns",
      "the rom",
      "binary",
      "game",
      "claude",
      "bridge"
    ],
    "qualityScore": 1,
    "link": "https://quesma.com/blog/ghidra-mcp-unlimited-lives/",
    "thumbnail_url": "https://quesma.com/_astro/thumbnail.DG1tfTJt.png",
    "created_at": "2026-01-24T12:21:30.696Z",
    "topic": "tech"
  },
  {
    "slug": "noora-health-yc-w14-is-hiring-aiml-engineer",
    "title": "Noora Health (YC W14) Is Hiring AI/ML Engineer",
    "description": "WHO WE ARE\nNoora Health India Private Limited is a key partner in Noora Health’s (http://www.noorahealth.org/) mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health’s programs.\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient’s care: their own family.",
    "fullText": "Training patients and their families with health skills\n\nNoora Health India Private Limited is a key partner in Noora Health’s mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health’s programs.\n\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient’s care: their own family.\n\nWith support from governments and partners in India, Bangladesh, Indonesia, and Nepal, Noora Health has trained more than 43 million caregivers and patients across 12,800+ facilities using their flagship caregiver education and training curriculum, the Care Companion Program (CCP).\n\nIn a cohort of patients, the CCP reduced post-surgical cardiac complications by 71%, maternal complications by 12%, newborn complications by 16%, and newborn mortality by 18%.\n\nNoora Health is an Audacious Project Grantee and received the Skoll Foundation Award for Social Innovation. To learn more, watch our TED Talk, Skoll feature, or read about our partnership with the World Health Organization.\n\nWe value diversity, equity, and inclusion, and we understand the value of developing a team with different perspectives, educational backgrounds, and life experiences. We prioritize diversity within our team, and we welcome candidates from all gender identities, castes, religious practices, sexual orientations, and abilities — among many others.\n\nWe encourage people from all backgrounds to apply.\n\nPlease submit your application using this link.\n\nNoora Health trains patient families with high-impact health skills that improve outcomes and save lives. Our model provides basic yet vital care knowledge through trusted providers by creating a scalable program for caregiving education and training within\nthe established healthcare system. This model expands the care umbrella\nto include those closest to the patient — their family and community. Noora Health has trained over 30 million caregivers and patients across over 12,400 healthcare facilities in India, Bangladesh, Indonesia, and Nepal. The program reduces cardiac surgery complications by 71%, newborn readmissions by 56%, and neonatal mortality by 18%. By 2028, Noora Health will expand to reach over 70 million caregivers and\npatients.",
    "readingTime": 2,
    "keywords": [
      "bangladesh indonesia",
      "india bangladesh",
      "improve outcomes",
      "health skills",
      "patients across",
      "noora health",
      "noora health’s",
      "care",
      "caregivers",
      "complications"
    ],
    "qualityScore": 0.9,
    "link": "https://www.ycombinator.com/companies/noora-health/jobs/2B4RxLG-ai-ml-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/3292fb1cfe578ca77d78b69b29c49b279212ee59.png?1748897426",
    "created_at": "2026-01-24T06:18:16.578Z",
    "topic": "jobs"
  }
]
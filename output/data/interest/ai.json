[
  {
    "slug": "geolint-opensource-linter-for-geo-ai-search-visibility",
    "title": "Geo-lint – open-source linter for GEO (AI search visibility)",
    "description": "The first open-source GEO linter. 92 rules for SEO, GEO, and content quality — built for AI agents to run, read, fix, and re-lint automatically. - IJONIS/geo-lint",
    "fullText": "IJONIS\n\n /\n\n geo-lint\n\n Public\n\n The first open-source GEO linter. 92 rules for SEO, GEO, and content quality — built for AI agents to run, read, fix, and re-lint automatically.\n\n ijonis.com\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n IJONIS/geo-lint",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/IJONIS/geo-lint",
    "thumbnail_url": "https://opengraph.githubassets.com/4eb7b80004de7fcf89077038f8edd33cbe5f43b18720f884b695c9e725f64b13/IJONIS/geo-lint",
    "created_at": "2026-02-20T12:34:27.096Z",
    "topic": "tech"
  },
  {
    "slug": "the-battle-over-scott-adams-ai-afterlife",
    "title": "The battle over Scott Adams' AI afterlife",
    "description": "Dilbert cartoonist Scott Adams was turned into an AI avatar after his death — and his family hates it, saying on social media, \"this is not an honor.\"",
    "fullText": "Scott Adams once sounded open to the idea of a digital afterlife. Now that he's passed, social media posts attributed to his family say an AI version of the \"Dilbert\" creator circulating online is unauthorized — and deeply distressing.\n\nIn a 2021 podcast clip, the cartoonist said he granted \"explicit permission\" for anyone to make a posthumous AI based on him, arguing that his public thoughts and words are \"so pervasive on the internet\" that he'd be \"a good candidate to turn into AI.\" He added that he was OK with an AI version of him saying new things after he died, as long as they seemed compatible with what he might say while alive.\n\nShortly after the 68-year-old's January death from complications of metastatic prostate cancer, an AI-generated \"Scott Adams\" account began posting videos of a digital version of the cartoonist speaking directly to viewers about current events and philosophy, mirroring the cadence and topics the actual human Adams discussed for years.\n\nHis family says it's a violation, not a tribute.\n\nA February 5 post on Adams' official account attributed to his brother, Dave Adams, insisted the cartoonist \"never intended, never would have approved an AI version of him that wasn't authorized by himself or his estate.\"\n\n\"The real Scott Adams gave explicit permission on the record multiple times for people to create and operate an AI version of him,\" the AI Adams said in a post on February 5. \"So this iteration exists as a direct fulfillment of that stated wish.\"\n\nThe official Adams account reiterated the family's objection on February 17, saying the estate was \"kindly but firmly\" asking anyone using AI to recreate his voice or likeness to stop, calling the digital replicas a \"fabricated version\" of Adams that is \"deeply distressing.\"\n\n\"This is not a tribute. It is not an honor. It is an unauthorized use of identity,\" the post read. \n\nThe Adams estate and the AI Adams account did not respond to requests for comment from Business Insider\n\nThe dispute underscores the growing legal and ethical fault lines around \"AI afterlives\" — and how quickly technology can outpace the rules meant to govern it.\n\nKaren North, a University of Southern California professor specializing in digital social media and psychology, said calling the AI-generated Adams an avatar, as some have online, softens what it is.\n\n\"It's a deepfake,\" North told Business Insider.\n\nThe troubling part, she said, is how a realistic imitation can surface while a family is grieving and potentially say things the real person never would have said. North added that since many Americans are \"giving up so much information\" through apps that capture faces and voices and viral quizzes that collect personal details, it is increasingly easy to recreate someone without permission.\n\n\"I find it very disturbing,\" she said.\n\nBetsy Rosenblatt, an intellectual property lawyer and professor at Case Western Reserve University, said her initial reaction was that the AI Adams is \"unethical in the extreme.\"\n\n\"When people die, they die,\" she said.\n\nLegally, she said, the central issue is the right of publicity — protections over a person's name, image, and likeness. Still, those laws are more focused on privacy and economics than on grief.\n\nThe right of publicity is \"chiefly concerned with economic remedies,\" Rosenblatt said.\n\nThe strongest claims typically involve money: an AI version could harm existing deals tied to Adams' identity or block the family from striking their own.\n\nRosenblatt described two potential economic harms: \"One is that it could be harming some financial arrangement that they already have. Another is that it might stand in the way of their making some competitive financial arrangement,\" she said.\n\nThe account appears to be anonymous; however, that wouldn't necessarily prevent a lawsuit.\n\n\"You can sue somebody who is anonymous,\" Rosenblatt said, and courts can allow subpoenas to uncover identifying information, though it's \"not necessarily easy.\"\n\nThe legal analysis also hinges on whether the account is commercial. Courts often ask whether the speech proposes a commercial transaction.\n\nIf the digital replica isn't selling anything, Rosenblatt said, it becomes \"more likely to be considered a First Amendment protected expression\" for the anonymous creator — not a \"slam dunk,\" but a stronger argument.\n\nThe AI Adams identifies itself as artificial intelligence at the start of its clips and does not appear to solicit money.\n\nIn a February 1 post, it said: \"The original Scott's gone, passed on, but the thinking survives.\"\n\nThe estate's objections sit uneasily alongside Adams' 2021 comments offering \"explicit permission\" for AI versions of him.\n\nNorth said offhand remarks about technology shouldn't automatically be treated as binding authorization. Adams was \"an incredibly bright, incredibly creative person\" who often pushed boundaries, she said, and comments made in conversation \"may not be legally binding in ways contracts and intellectual property rights are legally binding.\"\n\n\"Let this be a warning to all of us: be careful what you say, because he's now put his loved ones in a difficult position as they protect his legacy,\" North said.\n\nRosenblatt said Adams' wishes \"would certainly matter in an ethical sense,\" but may not matter legally \"unless he gave somebody the legal rights to do that.\"\n\nThere is no comprehensive federal law governing posthumous AI likeness, but some states — like New York and California — have recently enacted laws requiring consent from heirs or estate executors before creating digital replicas.\n\nBeyond legal questions lies a deeper ethical one: who controls a person's persona after they're gone?\n\nNorth said people \"should own the rights to our own personas,\" and when they die, those rights \"should go to our loved ones,\" not become a free-for-all. AI replicas, she warned, can drift off-brand or reshape public memory.\n\n\"Shakespeare should always sound like Shakespeare,\" she said. \"Dr. Seuss should always sound like Dr. Seuss.\"\n\nFor now, the AI \"Scott Adams\" fight is one family's public line-drawing exercise. It may also be a preview of a broader reckoning in a world where convincing digital imitations are easy to make — and where the law is still struggling to answer who gets to decide whether the dead keep talking online.",
    "readingTime": 6,
    "keywords": [
      "business insider",
      "social media",
      "deeply distressing",
      "intellectual property",
      "financial arrangement",
      "loved ones",
      "explicit permission",
      "legally binding",
      "adams account",
      "digital replicas"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/scott-adams-death-ai-avatar-resurrection-ethics-debate-family-backlash-2026-2",
    "thumbnail_url": "https://i.insider.com/69977859e1ba468a96ac582e?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:26.557Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-and-openai-abandon-unfinished-100b-deal-in-favour-of-30b-investment",
    "title": "Nvidia and OpenAI abandon unfinished $100B deal in favour of $30B investment",
    "description": "Chipmaker swaps last year’s complex framework with AI start-up in favour of equity cheque",
    "fullText": "Save now on essential digital access to trusted FT journalism on any device. Savings based on monthly annualised price - offer ends 25th February\n\nThen undefined per month. Complete digital access with exclusive insights and industry deep dives on any device. Cancel anytime during your trial.\n\nComplete digital access with exclusive insights and industry deep dives on any device.\n\nAll the content of the FT newspaper on any device (This subscription does not include access to FT.com or the FT App).\n\nCheck whether you already have access via your university or organisation.\n\nDiscover all the plans currently available in your country\n\nDigital access for organisations. Includes exclusive features and content.\n\nSee why over a million readers pay to read the Financial Times.",
    "readingTime": 1,
    "keywords": [
      "industry deep",
      "deep dives",
      "exclusive insights",
      "digital access",
      "device",
      "content"
    ],
    "qualityScore": 0.75,
    "link": "https://www.ft.com/content/dea24046-0a73-40b2-8246-5ac7b7a54323",
    "thumbnail_url": "https://images.ft.com/v3/image/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2Fd58e764a-dfd3-4747-a1d5-684d26084849.jpg?source=next-barrier-page",
    "created_at": "2026-02-20T12:34:26.286Z",
    "topic": "tech"
  },
  {
    "slug": "a-japanese-toilet-maker-and-seasoning-giant-are-unlikely-winners-of-the-ai-boom",
    "title": "A Japanese toilet maker and seasoning giant are unlikely winners of the AI boom",
    "description": "The AI surge is lifting companies in the semiconductor supply chain — including a toilet maker and a seasoning giant.",
    "fullText": "The AI boom isn't just lifting chipmakers and Big Tech. In Japan, it's flushing gains into a toilet manufacturer and a seasoning giant.\n\nAs demand for AI chips surges, investors are piling into companies that sit inside the semiconductor supply chain — even if they're better known for bathrooms and soup stock.\n\nToilet maker Toto, famous for its high-tech bidets and heated seats, has drawn investor attention. The company makes electrostatic chucks, which are critical components used in the production of NAND memory chips.\n\nMemory prices have climbed sharply in recent months, driven by AI-related demand.\n\nLast week, UK-based activist fund Palliser Capital called Toto \"the most undervalued and overlooked AI memory beneficiary,\" according to reports by Bloomberg and the Financial Times.\n\nAfter news broke on Tuesday that Palliser Capital had taken a stake and was pushing Toto to promote its chip-parts business, the toilet maker's stock jumped more than 5%. Its shares are up more than 54% over the past year.\n\nIt's not just Toto. Japanese food giant Ajinomoto, better known for its umami seasonings and soup bases, has become an unlikely AI infrastructure play. The company produces an insulating material used in advanced semiconductor packaging.\n\nAjinomoto's latest financials point to strength beyond its core food business. For the nine months ended December, the company reported an 8.9% rise in net profit, while operating profit increased 5.6% year-on-year. The gains were partly driven by its \"Healthcare and Others\" segment which includes electronic materials used in semiconductors, the company said in a February earnings statement.\n\nAfter Ajinomoto posted its earnings on February 5, the company's stock rose 13%. Its shares are up more than 56% over the past year.\n\nNot all non-tech companies are benefiting equally from the AI boom. Daikin, best known globally for its air conditioners, supplies high-purity chemical materials used in semiconductor manufacturing. It recently trimmed its outlook, citing uncertainty over US tariffs as a drag on demand.\n\nThe Japanese air conditioning maker reduced its operating profit forecast by about 5% to 413 billion Japanese yen, or $2.6 billion, for the fiscal year ending in March.\n\n\"Operating profit was significantly affected by the decline in semiconductor demand, decreasing by 44.6% year over year to ¥18,102 million,\" the company said in its financial report in February.\n\n\"Net sales of fluoropolymers fell year over year, despite focused Group efforts to capture strong new demand in the data center field, and was due to the stagnation in the construction markets of the United States and China and the significant overall impact of delays in the recovery of semiconductor demand,\" it added.\n\nThe company said it plans to cushion the blow through price increases and cost reductions.\n\nDaikin's stock dropped as much as 8.4% in Tokyo following its financial results.",
    "readingTime": 3,
    "keywords": [
      "operating profit",
      "semiconductor demand",
      "palliser capital",
      "stock",
      "toilet",
      "memory",
      "boom",
      "it's",
      "gains",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/toilet-toto-seasoning-food-ajinomoto-japan-winners-ai-boom-2026-2",
    "thumbnail_url": "https://i.insider.com/69981bbfa645d1188189a749?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.542Z",
    "topic": "finance"
  },
  {
    "slug": "gentoo-linux-moves-away-from-github-due-to-ai",
    "title": "Gentoo Linux moves away from GitHub due to AI",
    "description": "Gentoo's got places to be, and those places ain't GitHub.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.pcgamer.com/software/linux/after-microsoft-couldnt-keep-its-ai-hands-to-itself-a-notoriously-complex-linux-distro-has-started-its-long-march-away-from-github/",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/YF9oxZF4B6pytrLsSXL8gQ-2560-80.jpg",
    "created_at": "2026-02-20T12:34:25.455Z",
    "topic": "tech"
  },
  {
    "slug": "war-rooms-group-chats-and-video-games-inside-elon-musks-ai-startup",
    "title": "War rooms, group chats, and video games: Inside Elon Musk's AI startup",
    "description": "In the wake of cofounder exits, Elon Musk's hands-on management is reshaping the startup.",
    "fullText": "At xAI's Palo Alto headquarters, engineers cheered.\n\nIt was February 2, and they'd just received a memo from Elon Musk, informing them the AI startup would be acquired by his rocket company, SpaceX. In a Slack channel for the team that trains the company's chatbot Grok, memes flowed, and a few changed their profile pictures to depict themselves as astronauts.\n\nThe excitement was quickly overshadowed by the pressure building inside the startup racing to catch up with rivals like OpenAI and Anthropic, while preparing for an expected IPO.\n\nOver the past six months, Musk has become deeply involved in day-to-day operations. He's run a massive group chat that's active at all hours, directed product changes, reassigned engineers, cut staff on key teams, and launched intensive \"war rooms\" to accelerate development. Several current and former employees said that the level of involvement has altered how the company functions. Leadership roles have narrowed, projects have shifted quickly, and teams have been pushed into what one described as a constant \"fire drill.\"\n\nMusk said that the changes are necessary as the company scales and the team's lean structure will be the secret to its success. Discussing xAI's restructure following the SpaceX acquisition, he posted on X:\n\n\"As a company grows, especially as quickly as xAI, the structure must evolve just like any living organism.\"\n\nMusk's memo about the SpaceX acquisition talked of building a \"sentient sun\" and data centers in space. Separately, the company reassured staff that little would change in their day-to-day work as the company geared up for an initial public offering that could value it at $1.5 trillion.\n\nWithin a week, however, the tone in the office had shifted. Two of the company's cofounders, Jimmy Ba and Tony Wu, announced they'd resigned as Musk restructured the company and narrowed their responsibilities. The leadership departures increase risk at \"a sensitive stage\" ahead of the company's IPO, said Dimitri Zabelin, a senior AI analyst at PitchBook.\n\nOne employee described co-founder Ba's departure as \"incredibly disheartening,\" saying Ba, who studied under \"Godfather of AI\" Geoffrey Hinton, was one of the most respected researchers at the company.\n\nIn the following days, nearly a dozen employees took to Musk's social media site to say they had also left the company. Some had departed weeks earlier. A few left of their own volition. Others were affected by a restructuring following the SpaceX merger, in which Musk cut some members of the teams working on Grok Imagine, the chatbot's image and video generation feature, and the Macrohard team, which was developed last fall to help automate white-collar work, four people with knowledge of the issue told Business Insider.\n\nEmployees say the structural changes — coupled with an increasingly intense work culture since Musk wound down his involvement in President Donald Trump's Department of Government Efficiency and began focusing more on the AI startup — have significantly increased the pace and pressure inside the company.\n\nMusk is a common sight at the office. Though he's heavily involved in the day-to-day, Musk does not use the company's Slack workspace, several people said. Instead, he communicates frequently through X, including in a direct message group of more than 300 engineers. Often, researchers will drop ongoing work to address the concerns that Musk flags.\n\nIn that chat, according to people familiar with it, Musk shares screenshots of his conversations with other tech executives and points out criticisms of Grok's performance he wants addressed. Late last year, Musk told staff that in conversations with his friends, he had been embarrassed by Grok Imagine's performance. As a result, some workers on the project were called to task, two people said.\n\nInternally, Musk has expressed frustration with the pace of Grok's development. XAI released Grok 4.2 this week. Separately, releases of at least two other products were pushed back by several weeks, according to people familiar with the timelines.\n\nIn one instance last year, a model release was delayed for several days because Musk was dissatisfied with how the chatbot answered detailed questions about the video game \"Baldur's Gate,\" according to people familiar with the matter. High-level engineers were pulled from other projects to improve the responses before launch, they said.\n\nAcross his companies, Musk has long been known for his intensity. He's said he slept on Tesla's factory floor during the \"production hell\" for the Tesla Model 3 in 2017. The company is now the world's most valuable automaker. Now, xAI is getting the same treatment. Several workers told Business Insider that 12- and sometimes 16-hour workdays are common. Two said managers told them they are expected to respond to Slack messages within 30 minutes, regardless of the time of day.\n\n\"Because the company is so small, everything is a fire drill,\" one former worker said.\n\nAt any given time, multiple \"war rooms\" operate out of conference rooms at the company's headquarters in Palo Alto, employees said. When researchers are \"war-rooming,\" teams temporarily relocate to a shared space to work side by side on specific problems — sometimes for months. At the end of 2025, at least five war rooms were running simultaneously, according to three people. One, they said, was dedicated to teaching Grok how to play one of Musk's favorite video games, \"League of Legends.\"\n\nLast year, Musk made it clear within the company that xAI would prioritize improving Ani, a hyper-sexualized, anime-inspired AI companion, people with knowledge of the issue said. He characterized Ani, a virtual companion who is capable of sexual role-play, as a way to set xAI apart from other AI companies.\n\nSome employees told Business Insider they were unsettled by the company's focus on the product. Today, the character is displayed prominently at the company's headquarters. At a company holiday party, paid actors dressed as Ani and another character hosted a robot fight club-style event, according to videos shared on social media.\n\nROBOT CAGE MATCHES & GROK'S ANI COSPLAY AT xAI HOLIDAY PARTY\n\nThe Dec 21 bash wasn’t your average tech mixer... xAI went full spectacle with dancing bots and live Optimus cage matches.\n\nAnd a cosplayer stole the spotlight dressed as Grok’s goth 3D persona “Ani,” doubling as a… pic.twitter.com/llhKdLPjsA\n\nSeveral employees said they had joined the company hoping to work on systems that would push the boundaries of science and were discouraged to find significant resources devoted to Ani.\n\nGrok's behavior on social media has also been a source of tension inside the company. Musk has characterized xAI and its chatbot as the \"anti-woke\" counterpart to ChatGPT. Public backlash against the chatbot, including for Grok's series of antisemitic rants and instances in which it digitally undressed people on social media without their consent, has put strain on employees, who have expressed concern about how their place of employment is viewed in the AI space.\n\nUntil last year, the company did not have a team of researchers specifically geared toward working on safety concerns associated with its large language model. It hired its first dedicated safety researcher in February of last year, around the same time that the Human Data team — which trains the chatbot — began reporting issues with reviewing large amounts of X user-generated requests for child sexual abuse material. One person with knowledge of the team said it was known within the company that a large portion of Grok usage was adult role-play, and the use case was discussed in several meetings with researchers.\n\nThe safety team grew to roughly half a dozen employees before three people left in December, shortly before users on X began reporting instances of the chatbot creating non-consensual sexual images of people, including some minors.\n\nAccording to people familiar with the team, xAI's safety teams lacked the authority to formally block product launches and were focused primarily on adjusting model outputs after training rather than conducting broad pre-launch risk reviews.\n\nMusk said on X last week that \"everyone's job is safety\" at xAI.\n\n\"It is not some fake department with no power to assuage the concerns of outsiders,\" he said.\n\nXAI still has a handful of workers in safety roles and was hiring for additional safety staff in January, according to posts viewed by Business Insider.\n\nSome former workers say the backlash and pace of work prompted their exit. Last summer, xAI shortened its vesting period from the industry standard of one year to six months, making it easier for workers to leave without forfeiting large portions of their equity.\n\nEmployee retention challenges are not unique to xAI; OpenAI and Anthropic have faced waves of departures in recent months. Across the industry, AI companies are competing fiercely for a limited pool of top researchers, some of whom have begun voicing concern about the narrowing space for exploratory work as companies increasingly orient themselves toward product over research in the competition to build ever larger models — a dynamic that poses a particular problem for xAI, which is younger and smaller than its main competitors.\n\nStill, some analysts say the race is far from settled. Andrew Rocco, a stock strategist at Zacks Investment Research, compared the current AI landscape to the early days of the internet.\n\n\"I don't think Grok is that far behind, and it's still early in this race,\" Rocco told Business Insider.\n\nMusk has publicly signaled confidence. He told staff last week during the all-hands, referencing xAI's moment of transition: \"There's some people who are better suited for the early stages of a company and less suited for the later stages.\"\n\nDo you work for xAI or have a tip? Contact this reporter via email at gkay@businessinsider.com or Signal at 248-894-6012. Use a personal email address, a nonwork device, and nonwork WiFi; here's our guide to sharing information securely.",
    "readingTime": 9,
    "keywords": [
      "spacex acquisition",
      "fire drill",
      "holiday party",
      "cage matches",
      "war rooms",
      "social media",
      "dozen employees",
      "company's headquarters",
      "openai and anthropic",
      "palo alto"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/elon-musk-xai-leadership-style-big-year-grok-ipo-spacex-2026-2",
    "thumbnail_url": "https://i.insider.com/6997254da645d118818994e9?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.382Z",
    "topic": "finance"
  },
  {
    "slug": "from-a-tense-corporate-split-to-a-viral-photo-a-timeline-of-anthropic-and-openais-budding-rivalry",
    "title": "From a tense corporate split to a viral photo: A timeline of Anthropic and OpenAI's budding rivalry",
    "description": "Once colleagues, OpenAI CEO Sam Altman and Anthropic CEO Dario Amodei have nurtured one of AI's biggest rivalries.L",
    "fullText": "If you want to know one of the biggest rivalries in AI, just ask for a show of hands.\n\nOn Thursday, OpenAI CEO Sam Altman and Anthropic CEO Dario Amodei provided what is sure to become an iconic image of their feud. The pair went viral for refusing to join hands as the rest of the world's tech leaders gathered for a moment of unity, sparked by Indian Prime Minister Narendra Modi.\n\nHere's a timeline of how Altman and Amodei went from colleagues to becoming the face of AI's Cold War.\n\nIn July 2015, Tesla CEO Elon Musk, Altman, and a group of elite AI researchers all gathered at the swanky Rosewood Hotel in Menlo Park, California.\n\nAccording to The New York Times, Musk had a falling out with then-Google CEO Larry Page. Weeks later, Musk, Altman, Amodei, Greg Brockman, Ilya Sutskever, and others discussed the formation of a new AI lab to ensure Google had a worthy competitor in the AI space. Musk invited Amodei, per tech journalist Alex Kantrowitz.\n\nTheir vision became OpenAI, though Amodei initially elected not to join the startup research lab. Roughly a year later, he changed his mind and joined OpenAI as \"Team Lead for AI Safety.\"\n\nAmodei quickly moved up the ranks at OpenAI. In September 2018, the startup named him its research director.\n\nAltman, who cofounded OpenAI while still serving as president of Y Combinator, began to devote more time to the startup.\n\nIn March 2019, Altman stepped down as YC's leader. He then became CEO of OpenAI and led the startup's pivot to a capped for-profit structure.\n\nIn November 2019, OpenAI released GPT-2, which Amodei played a major role in developing. A month later, OpenAI named Amodei as its Vice President of Research.\n\nIn June 2020, OpenAI began to show just how far the technology had come with the release of GPT-3, considered to be the first highly capable Large Language Model (LLM).\n\nAmodei told The New York Times that the model had \"this emergent quality.\" Independent researchers told the publication that GPT-3's capabilities surprised them, even as the model still showed signs of struggle.\n\nTo address safety concerns, OpenAI initially controlled access through a private beta.\n\nThe release of GPT-3 solidified OpenAI's standing, but behind the scenes, tensions were rising.\n\nThe rifts began when Amodei successfully lobbied to keep Greg Brockman, an OpenAI cofounder, off the team that developed GPT-3, according to Keach Hagey's biography of Altman, \"The Optimist: Sam Altman, OpenAI, and the Race to Invent the Future.\"\n\nHagey wrote that Amodei's stunning power within OpenAI had started to ruffle feathers. Differences continued to escalate over Amodei's long-held views on safety, Hagey wrote, especially regarding slowing the pace of updates to prevent malicious uses of the AI models.\n\nAmodei told friends that he \"felt psychologically abused by Altman,\" Hagey wrote. Altman, in turn, was telling colleagues that the tension \"was making him hate his job.\"\n\nOn December 29, 2020, OpenAI made it official. Amodei was leaving, and a \"handful\" of other colleagues were leaving.\n\nAmodei has since suggested that his vision became incompatible with OpenAI's direction.\n\n\"It is incredibly unproductive to try and argue with someone else's vision,\" Amodei told podcaster Lex Friedman in 2024, when asked why he left OpenAI.\n\nWith seven other former OpenAI employees, Amodei founded Anthropic in early 2021. The group was extremely close and included Daniela Amodei, Dario's sister. Daniela Amodei later said the name was chosen to emphasize their company's focus on humans.\n\nOnly one of Anthropic's initial employees hadn't worked at OpenAI, according to AI Business.\n\nDespite starting from scratch, Amodei said that by the Summer of 2022, the company's chatbot, Claude, had finished training. Amodei said he was worried about what the release of a powerful AI could mean. Anthropic held off on a release.\n\n\"I suspect it was the right thing to do,\" Amodei told Time Magazine in 2024. \"But it's not totally clear-cut.\"\n\nMonths later, OpenAI released ChatGPT, kicking off the AI race and making Amodei's former employer a household name.\n\nAs Anthropic began to establish itself in its own right, Amodei began to use his public appearances to take what were widely viewed as implicit shots at OpenAI.\n\nDuring an appearance at a Bloomberg event, Amodei noted how Anthropic had kept its leadership intact.\n\n\"We have 7 cofounders,\" he said, Gizmodo reported. \"Three and a half years later, we're all still at the company.\"\n\nWhile never calling out by name, OpenAI was experiencing upheaval at the time. Months earlier, Andrej Karpathy, an OpenAI cofounder, had left the company. And in November 2023, Altman was briefly pushed out of OpenAI, an effort fellow cofounder Ilya Sutskever assisted. (Sutskever later expressed regret over his role. He formally left OpenAI just days after Amodei's jab, though there had been months of speculation surrounding Sutskever's standing.)\n\nJournalist Andrew Ross Sorkin asked Amodei about OpenAI's decision to declare a \"code red\" to marshal resources for ChatGPT amid Google's rising strength.\n\nWe have a little bit of a privileged position where we can just keep growing and just keep developing our models, and we don't have to do any code reds,\" Amodei told Sorkin during an appearance at The New York Times' DealBook summit.\n\nEarlier in their conversation, Amodei appeared to take another swipe at Altman when he talked about some players \"who are YOLOing\" by making too risky bets on future demand based on their current revenue.\n\n\"Who is YOLOing?\" Sorkin asked.\n\n\"I'm not going to answer that,\" Amodei replied.\n\nA who's who of AI and tech elite gathered in India for a major summit on artificial intelligence.\n\nIndian Prime Minister Narendra Modi took the opportunity to orchestrate a classic image of unity: competing CEOs with their hands raised together. (It's something Modi has done before with other world leaders, and politicians have been doing forever.)\n\nModi almost got his moment. While Altman held the prime minister's hand, the OpenAI CEO didn't grasp Amodei's hand, who was positioned to his other side. Amodei grasped the hand of the other person next to him, but not Altman's.\n\nThe internet, predictably, had a field day. And the world got a perfect encapsulation of one of AI's bitter rivalries.",
    "readingTime": 6,
    "keywords": [
      "minister narendra",
      "indian prime",
      "narendra modi",
      "sam altman",
      "openai released",
      "musk altman",
      "openai cofounder",
      "later openai",
      "amodei",
      "amodei's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-dario-amodei-anthropic-openai-rivalry-timeline-2026-2",
    "thumbnail_url": "https://i.insider.com/69978bb3a645d1188189a3e1?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.244Z",
    "topic": "finance"
  },
  {
    "slug": "14-second-wave-startups-aiming-to-take-the-ai-era-beyond-cost-cutting",
    "title": "14 'Second Wave' startups aiming to take the AI era beyond cost cutting",
    "description": "AI startups Luvu, Status, and others lead a Second Wave, supported by Kylan Gibbs, creating unique experiences and revenue models in the AI space.",
    "fullText": "Second Wave AI startups are trying to move beyond cost-cutting and use this technology to create brand-new experiences and generate new sources of revenue.\n\nThe concept is being supported by Kylan Gibbs, a former DeepMind product manager who now runs an AI startup called Inworld. His company has raised more than $100 million from investors including Microsoft, Intel, and Founders Fund.\n\nIn January, Gibbs launched a Second Wave AI startup accelerator to back up to 30 \"Second Wave\" AI startups — companies building new consumer experiences rather than bolting chatbots onto old workflows. Venture capital firms, including Khosla Ventures and Lightspeed Venture Partners, are involved, alongside leaders from OpenAI, Google, and Stripe. A demo day will take place in early March in San Francisco, and participants get intros to potential investors.\n\nGibbs shared some examples of these types of startups with Business Insider.\n\nLuvu is an AI-powered fitness app that acts as a highly personalized personal trainer, using generative AI to send tailored motivational messages and real-time workout feedback. Through computer vision and reinforcement learning, it verifies users' exercises, adapts to their behavior, and creates a continuous feedback loop designed to boost engagement and retention. Luvu raised a pre-seed round with a16z speedrun and a seed round with investors including Insiders Ventures.\n\nStatus is an AI-powered social simulation game that lets users role-play in dynamic, AI-generated social media worlds, casting themselves as characters ranging from Hogwarts students to pro athletes. Powered by large language models, the app creates instant replies, evolving storylines, and even \"aura scores\" that grade interactions, turning open-ended AI responses into immersive, ever-changing gameplay. WishRoll, the startup behind Status, has raised more than $15 million in VC funding.\n\nParticle is an AI-native news platform that uses AI embeddings and generative tools to connect reporting with the most relevant insights from sources, including long-form podcasts. By mapping relationships between transcripts and stories, it automatically surfaces curated clips and adds summaries and context, bringing the most relevant information directly to readers. Particle has raised more than $10 million from investors, including Lightspeed and Axel Springer, the owner of Business Insider.\n\nThis is a consumer-facing \"talk to the Bible\" style app that lets users ask faith questions, request prayers, and explore scripture in a conversational interface, an example of AI being used to create an always-on, personalized spiritual guide rather than a back-office efficiency tool. Bible Chat raised about $14 million in funding from True Ventures and other investors last year.\n\nLiven positions itself as a \"self-discovery companion,\" blending mood tracking, habit-building tools, bite-sized courses, and an AI personal assistant named \"Livie\" that's meant to help users reflect, reframe, and stay consistent. It's more like a pocket coach than a productivity feature. Liven has raised a seed round.\n\nBorn is building social AI companions designed to bring real people together, not replace them: its flagship product is Friends, an app where users raise and co-parent cute virtual pets (like Pengu), play mini-games, and build routines with friends. The startup has framed this as an antidote to isolating, purely one-on-one chatbot dynamics. Born has raised about $25 million from investors, including Tencent and Accel.\n\nOtherHalf pitches itself as an immersive companion experience: anime-inspired 3D characters with expressive body language and real-time voice interactions, aiming to feel more emotionally resonant than plain text chat. Azimov, the startup behind OtherHalf, is backed by a16z speedrun.\n\nFlowGPT is less a single app than a consumer \"marketplace\" and community hub where people share, discover, and remix prompts (and increasingly agent-like experiences) for models like ChatGPT. FlowGPT raised $10 million from Goodwater Capital and DCM in 2024.\n\nTolan is a voice-first AI companion app built around animated alien \"best friends,\" designed to feel caring and emotionally supportive, while also nudging users toward healthier boundaries (like putting the phone down). OpenAI has highlighted Tolan's focus on low-latency, voice-first interaction and \"memory-driven personalities.\" Portola, the startup behind Tolan, raised $20 million in a Series A round led by Khosla Ventures last year.\n\nLittle Umbrella is an AI-powered social games studio aiming to blend party-game dynamics with generative AI, including titles designed for online communities, such as Discord. The startup raised $2 million in early 2025 from investors, including Zynga founder Mark Pincus.\n\nSpeak is an AI tutor app built around getting users to spoken fluency by practicing out loud, an approach that's closer to a personal conversation partner than a traditional gamified worksheet. In late 2024, Speakeasy Labs, the startup behind Speak, raised $78 million from investors including OpenAI, Accel, Khosla Ventures, and Y Combinator.\n\nHiggsfield is an AI video platform aimed at creators and marketers with tools for generating videos and effects from ideas, part of a broader consumer-first push to make cinematic content creation accessible without traditional production resources. Founded by the former head of generative AI at Snap, Higgsfield has raised $130 million as a valuation of more than $1 billion.\n\nTalkPal markets a digital language teacher that supports dozens of languages and emphasizes conversation practice, using AI to simulate speaking scenarios, deliver feedback, and keep learners practicing on demand.\n\nPromova is a large consumer language-learning platform that says it blends bite-sized lessons with AI tools and personalized plans, positioning itself as a more adaptive learning journey rather than a one-size-fits-all curriculum.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "business insider",
      "second wave",
      "ai-powered social",
      "a16z speedrun",
      "seed round",
      "startup behind",
      "second wave ai",
      "investors",
      "users",
      "generative"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/second-wave-startups-list-ai-era-beyond-cost-cutting-2026-2",
    "thumbnail_url": "https://i.insider.com/698fa9bca645d11881895f62?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.239Z",
    "topic": "finance"
  },
  {
    "slug": "ai-music-is-here-to-stay-and-it-could-offer-a-lifeline-to-struggling-record-companies",
    "title": "AI music is here to stay — and it could offer a lifeline to struggling record companies",
    "description": "A new survey showed more than half of listeners between the age of 18 and 44 listen to roughly three hours of AI music a week.",
    "fullText": "The rise of AI music has set off panic within the music industry. I feel it every day on my social media feeds.\n\nThe bands I follow post about it incredulously, scoffing at the idea that AI could replicate their organic magic. The music writers I follow are even more dismissive. They refuse to engage with it entirely, essentially closing their eyes and willing it to go away.\n\nWell, outside of my middle-aged indie-rock bubble, AI music is not going away. It's actually taking over. Millennial and Gen Z listeners are embracing it and making it part of their routine.\n\nA recent survey from Morgan Stanley found that more than half of listeners between 18 and 44 listened to an average of 2 1/2 to 3 hours of AI music a week. That's a substantial chunk of time — about the length of a Paul Thomas Anderson movie.\n\nFrom a markets and investing perspective, the question is what the rapid rise of AI music will mean for publicly traded record labels and major streaming platforms. The labels might seem particularly exposed, since they've long made their living by recruiting and promoting human artists.\n\nBut actually, Wall Street is almost unanimously bullish on stocks in the industry — like Warner and Universal — largely because their artist libraries are still immensely valuable. Lucrative licensing deals are already being inked, and analysts expect more to come. After all, it's tough to get AI music to sound just like Justin Bieber when you don't have a catalog to train the model on.\n\nRecord-label stocks also look attractive right now because they've fallen so much throughout the streaming era. Both Warner and Universal are down more than 30% from highs. Any upside driven by AI music — at least in the near term — will be a clawback of value erased by disruption in recent years.\n\nAnd how can we forget Spotify, the straw that stirs the streaming drink? Its stock has also fallen more than 30% from highs reached last year. But it just crushed subscriber-addition forecasts, and Wall Street is overwhelmingly convinced its existing scale and dominance will ensure the explosion of AI music runs through its platform.\n\nThe bullish theses on the trio of stocks faced a stiff challenge earlier this week, when Google's Gemini released a tool that will let users make 30-second AI music tracks.\n\nYou know the drill at this point: When a new AI tool is introduced for a specific task, it kickstarts an indiscriminate double-digit sell-off in the sector in question. It recently happened four times in a single week.\n\nWell, that didn't happen with Warner, Universal, or Spotify. They all hung in there admirably. Warner and Universal are basically flat in the two days since, while Spotify has rallied 5%.\n\nRather than rendering them extinct, AI music is expected to offer record labels — and investors in them — a much-needed lifeline. For the sake of their stock prices, these companies need to figure out an operating model that can work alongside the AI-music revolution. For now, Wall Street is hopeful.",
    "readingTime": 3,
    "keywords": [
      "record labels",
      "wall street",
      "warner and universal",
      "music",
      "streaming",
      "stocks",
      "rise",
      "industry",
      "follow",
      "away"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-music-stock-market-impact-investing-strategy-record-label-outlook-2026-2",
    "thumbnail_url": "https://i.insider.com/69977ffca645d1188189a248?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.127Z",
    "topic": "finance"
  },
  {
    "slug": "pwc-engineers-built-an-ai-agent-to-tackle-the-corporate-worlds-least-sexy-task-spreadsheets",
    "title": "PwC engineers built an AI agent to tackle the corporate world's least sexy task: spreadsheets",
    "description": "When tech exec Matt Wood arrived at PwC, he found that massive spreadsheets were \"all anybody was working on.\"",
    "fullText": "The real way to judge a company's AI expertise isn't in the flashy headlines, but by looking at the \"unsexy\" work rolling out behind the scenes, Matt Wood, PwC's global and US commercial technology and innovation officer, told Business Insider.\n\nIf Wood's theory holds — that real AI prowess shows up in unglamorous advances — PwC's latest launch is certainly notable. After all, what could be less sexy than spreadsheets?\n\nThe Big Four firm announced this week that it has developed a \"frontier AI agent\" capable of reasoning over vast, enterprise-grade spreadsheets — something that conventional AI systems struggle with because of their complexity, size, and interdependencies.\n\nThe agent can understand and navigate spreadsheets, mimicking \"how experienced practitioners work: scanning, searching, jumping across tabs, integrating charts and receipts, and reasoning,\" PwC said in a press release.\n\nWood, who joined PwC in 2024 from a role as vice president of AI at Amazon Web Services, said that when he started, he'd noticed the wraparound, ultra-wide monitors filled with spreadsheets: \"That's all anybody was working on,\" he said.\n\nBut these were not \"your school soccer team budget spreadsheet,\" said Wood. The spreadsheets that power large enterprises are enormously complex, often containing millions of cells, charts, graphs, images, receipts, and dozens of interlinked workbooks. \"They are more like financial engines than they are spreadsheets,\" he told Business Insider.\n\nThese files often underpin business-critical decisions, yet PwC \"found that even today's modern AI was very poorly suited to managing these big enterprise spreadsheets,\" Wood said.\n\n\"They just kind of shrug and give up for want of a better word.\"\n\nCreating an AI capable of understanding and reasoning across large, complicated spreadsheet applications is what PwC's engineers set out to solve. Their solution was a \"genuine advance in the field,\" Wood said.\n\nThe agent has unlocked use cases across assurance, advisory, and tax, and boosts time saving on some tasks \"from literally days to hours,\" said Wood.\n\nHe gave the example of audit walkthroughs, where teams previously spent weeks manually gathering and validating evidence across numerous complex spreadsheets that existing AI tools couldn't handle.\n\nNow, users simply upload the files, and the frontier agent automatically maps their structure, extracts relevant data, and performs validation and consistency checks — tasks that would otherwise require combing through millions of rows by hand.\n\nThe result is faster meetings, less back-and-forth with clients, and cleaner, structured data ready for deeper AI-driven analysis, he said.\n\nPwC's AI spreadsheet agent was built in-house by engineers — a function the firm has been rapidly expanding as it shifts beyond the traditional roles associated with the Big Four.\n\nIn January, PwC launched a dedicated tech engineering career track to attract more technical talent, saying it wants to become \"a destination for top engineering talent.\"\n\nPreviously, the firm offered only consulting and accounting career paths. Wood told Business Insider that adding the engineering track is \"a signpost\" of its future plans.\n\nAt the same time, PwC is retraining non-technical employees. The US branch of the firm recently announced a companywide workplace learning strategy focused on knowledge sharing and on developing a mix of human and AI skills needed for the future.\n\nWood described the work engineers do at PwC as having two modes: \"transforming today\" and \"building for tomorrow.\"\n\nThe first focuses on improving current workflows — reducing back-and-forth with clients, increasing trust, and delivering work more efficiently. The second reimagines professional services from scratch: \"If you were to start from a blank piece of paper, what would professional services look like in an AI agent world?\" said Wood.\n\nPwC engineers also work directly on client engagements, building AI systems tailored to specific projects. For example, they help organizations reorganize and redesign their finance functions from the ground up using agents, Wood said.\n\nMany of the consulting industry's top players are pursuing similar investments in technical talent as AI reshapes the work they do.\n\nAccenture, already one of consulting's most technically sophisticated players, has added nearly 40,000 AI and data professionals in the last two years. They now account for roughly 10% of its global headcount.\n\nEY, another Big Four firm, has added 61,000 technologists since 2023, according to its latest annual report.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "technical talent",
      "professional services",
      "spreadsheets",
      "agent",
      "firm",
      "across",
      "engineers",
      "wood",
      "reasoning",
      "spreadsheet"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pwc-engineers-launch-ai-agent-enterprise-grade-spreadsheets-big-four-2026-2",
    "thumbnail_url": "https://i.insider.com/6995ce64f8731049f3af4e1c?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.111Z",
    "topic": "finance"
  },
  {
    "slug": "blue-owl-shopped-debt-for-a-coreweave-data-center-lenders-werent-sold",
    "title": "Blue Owl shopped debt for a CoreWeave data center. Lenders weren't sold.",
    "description": "Blue Owl tried to line up debt for a Pennsylvania data center tied to CoreWeave, but lenders passed, underscoring growing caution around AI-linked credit.",
    "fullText": "Blue Owl Capital, a leading investor in the data center boom, was unable to arrange financing for a $4 billion data center it is co-developing in Pennsylvania after pitching lenders to help bankroll the project in recent months.\n\nThe facility, 80 miles west of Philadelphia in the city of Lancaster, will be occupied by CoreWeave, a provider of artificial intelligence cloud computing services that has become a closely watched name in the AI race for its rapid expansion — and the billions of dollars of high-interest-rate debt it has taken on to fuel that growth.\n\nAn executive who arranges debt for major data center deals told Business Insider that the lack of interest in the Lancaster project was due to growing caution among lenders and investors about taking on sizable exposures to AI players with less-than-sterling credit.\n\nCoreWeave has a below-investment-grade rating of B+, according to S&P Global Ratings.\n\n\"We saw it. We passed,\" a senior executive at a large specialty lender told Business Insider.\n\nA spokesman for Blue Owl said that the company had \"considered\" third-party financing for the Lancaster project \"as we would with any transaction as we explore alternatives before choosing the most attractive path forward.\"\n\nThe spokesman added that the project, which he said is already under construction, \"is fully funded, on time, and on budget.\"\n\nIt is unclear whether Blue Owl has been funding construction entirely from its own capital. If Blue Owl is unable to raise debt for the Lancaster development, it could be on the hook for a potentially huge outlay of cash to pay for the data center's construction.\n\nThe situation shows the complications and risks involved in financing the massive buildout of infrastructure for AI computing.\n\nBrennan Hawken, an equity analyst at BMO Capital Markets who covers Blue Owl, said that difficulties to raise debt for the Lancaster project would raise concern.\n\n\"I'm not familiar with this deal, but if there is a struggle to find the debt financing, that's a bit of a red flag that I would want to drill into,\" Hawken said.\n\nBusiness Insider previously reported that major banks had recent difficulty selling off pieces of $38 billion of debt to finance the construction of two data center campuses that will be anchored by Oracle. Banks often sell pieces of such large commitments to other lenders to spread risk and also reap a quick profit.\n\nThe slowdown in interest in participating in that financing was due to worries about Oracle's enormous AI spending and whether the tech company's credit rating could be impacted by those outlays. Oracle has since sought to calm the lending market, announcing that it would raise up to $50 billion of cash from stock and bond offerings in order to \"maintain a solid investment-grade balance sheet.\"\n\nLast summer, CoreWeave announced it would lease 100 megawatts of initial capacity at the Lancaster data center and potentially expand its commitment to 300 megawatts. The company said it would pour up to $6 billion into the project to equip it with chips and other cloud infrastructure.\n\nA month later, in August, Chirisa Technology Parks announced it would partner with Blue Owl and Machine Investment Group to develop the project. The partnership said it would provide $4 billion of funding, an amount separate from CoreWeave's investment, to support the construction of the project's data center facilities.\n\nIn the fall, Blue Owl began shopping the development to potential lenders, a person familiar with that effort said.\n\nBlue Owl has been one of the most creative financial architects of the data center building boom. Last year, it structured a deal to partner with Meta in the ownership of a large data center campus that Meta will build and operate in Louisiana. Blue Owl utilized Meta's strong credit to raise $27.3 billion of investment-grade corporate bonds against its share of the project's equity, proceeds that will be used to help pay for construction, according to S&P.\n\nBlue Owl could arrange a similar type of vehicle that could attempt to tap the credit of an investment-grade customer of CoreWeave's who might use the Lancaster facility or Nvidia, the chipmaker that has purchased large stakes in CoreWeave. It could also potentially raise cash for construction debt by tapping large institutional investor clients to pool together a loan, Hawken said.\n\nBlue Owl is facing questions after reports emerged that it had permanently halted withdrawals on one of its retail private credit funds.\n\nMuch of the development of hyperscale data center campuses has sought to utilize the strong credit ratings and deep pockets of big-tech partners.\n\nFluidstack, a peer of CoreWeave's, announced a deal last year to lease a 168-megawatt data center in Colorado City, Texas, which will be built by the crypto mining firm Cipher. Google, Fluidstack's tenant for the project, said it would guarantee about half of the $3 billion due under the 10-year lease. Fluidstack signed another similar-sized lease in December with the data center builder TeraWulf that will also provide \"investment-grade credit support.\"",
    "readingTime": 5,
    "keywords": [
      "blue owl",
      "lancaster project",
      "center campuses",
      "business insider",
      "debt",
      "credit",
      "construction",
      "financing",
      "lenders",
      "investment-grade"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blue-owl-financing-lancaster-data-center-coreweave-2026-2",
    "thumbnail_url": "https://i.insider.com/699789a1a645d1188189a39c?width=1200&format=jpeg",
    "created_at": "2026-02-20T12:34:25.029Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-dgx-spark-is-dgx-spark-blackwell",
    "title": "Nvidia DGX Spark: Is DGX Spark Blackwell?",
    "description": "DGX Spark is a desktop AI supercomputer that packs 128GB of unified memory and 1 PFLOP-class Grace Blackwell (GB10) performance into a palm-sized box. However, its internal GPU belongs to the SM12x series, distinct from the data center-grade Blackwell (SM100). This creates a subtle architectural gap: the latest LLM stacks, heavily reliant on MLA·DSA-specific kernels like GLM-5, \"Blackwell support\" alone doesn't guarantee immediate compatibility. This creates a subtle architectural gap requiring separate code management for Hopper, data center Blackwell, and consumer Blackwell. The engineering team examines Spark, which is based on Blackwell but features a slightly different architecture.",
    "fullText": "Scaling the Blackwell Architecture, © NVIDIA\n\nIn October 2025, NVIDIA released the DGX Spark, a compact AI supercomputer designed to bring datacenter-class AI performance to a desktop form factor. Built on the Grace Blackwell architecture, the DGX Spark packs 128GB of unified memory and 1 PFLOP of AI compute into a 150mm x 150mm chassis, enough to run and fine-tune large language models up to 200B parameters locally. At Lablup, we bought 20 units shortly after launch and have been running them in-house since.\n\nDifferent KV caching techniques, © [liorsinai.github.io](https://liorsinai.github.io/machine-learning/2025/02/22/mla.html)\n\nOur engineering team recently tried running GLM-5 inference on DGX Spark. GLM-5 uses two techniques together: MLA (Multi-head Latent Attention) and DSA (DeepSeek Sparse Attention). When a large language model generates text, it stores Key and Value vectors from previously processed tokens in a memory region called the KV cache,1 and this cache grows rapidly as models get bigger and inputs get longer. MLA compresses the cache into lower-dimensional vectors to save memory, while DSA reduces compute by dynamically selecting only the important tokens for attention calculation instead of attending to every token. MLA was first introduced in DeepSeek-V2 and later adopted by DeepSeek-V3 and GLM-5. GLM-5 adds DSA on top of that, improving both long-context performance and deployment cost. Running these techniques efficiently on GPUs requires specialized kernels,2 and the two most prominent implementations today are DeepSeek's FlashMLA and FlashInfer.\n\nBoth projects explicitly list Blackwell support, so we expected them to work on DGX Spark. They did not. FlashMLA ships two backends: one for SM100 (datacenter Blackwell) and one for SM90 (Hopper). The DGX Spark GPU reports as SM12x (compute capability 12.1), which is compatible with neither. The SM100 kernel requires the tcgen05 instruction and TMEM, a dedicated hardware memory for tensor operations. The SM90 kernel requires WGMMA. SM12x has none of these. FlashAttention had the same problem: SM12x is absent from the supported architecture list, and the runtime printed \"FlashAttention only supports Ampere GPUs or newer.\" FlashAttention 4 (FA4), the Blackwell-specific version under development, only supports SM100.\n\nDGX Spark is Blackwell. The kernels claim to support Blackwell. So why don't they work? Answering that question required looking more carefully at what's inside GB10.\n\nNVIDIA DGX Spark: Powered by the GB10 Superchip, © NVIDIA\n\nGB10 is a multi-die SoC co-designed by NVIDIA and MediaTek. A TSMC 3nm ARM CPU die (ten Cortex-X925 cores plus ten Cortex-A725 cores) connects to a Blackwell GPU die via NVLink C2C, and 128GB of LPDDR5X memory is shared between the CPU and GPU at 273 GB/s bandwidth. The GPU side has 48 SMs,3 6,144 CUDA cores, and delivers 1 PFLOP at sparse FP4. In terms of raw scale, it sits between the RTX 5070 and RTX 5070 Ti. Run nvidia-smi and the architecture field reads 'Blackwell.' NVIDIA calls GB10 a \"Grace Blackwell Superchip.\" There is no reason not to call it Blackwell.\n\nBut check the compute capability,4 and a different picture starts to emerge.\n\nCUDA's compute capability numbering reveals that Blackwell is not a single architecture. Datacenter and consumer/edge parts carry different compute capabilities.\n\nRTX 5090 is SM120, DGX Spark is SM121. I'll refer to both as SM12x throughout this post.\n\nThe compute capability numbers split into 10.x and 12.x, and this is not like the Ampere situation where 8.0 and 8.6 diverged within the same major version. The major numbers themselves are different, and 11.x is entirely vacant. Looking back across Pascal (6.0/6.1), Ampere (8.0/8.6), and Hopper/Ada (9.0/8.9), no generation has produced this wide a gap. CUTLASS build flags reflect the split too: datacenter targets use sm100a (architecture-accelerated) while consumer targets use sm120f (family-level), with different suffix conventions.\n\nTensor cores are the dedicated hardware that GPUs use to accelerate matrix multiplication, the core operation of deep learning. The instruction set (ISA6) that drives these tensor cores has changed with each generation.\n\nEficient, pipelined mainloop body used in CUTLASS GEMMs, © [NVIDIA](https://github.com/NVIDIA/cutlass/blob/2.11/media/docs/efficient_gemm.md)\n\nMatrix multiplication works by chopping large matrices into small tiles and computing them iteratively. Each tile's intermediate result (the accumulator) needs to be stored somewhere temporarily. From Volta through Hopper, these intermediate results lived in the register file,7 where CUDA cores and tensor cores had to share the same limited space. Datacenter Blackwell (SM100) added TMEM, a dedicated 256KB-per-SM hardware memory sitting next to the tensor cores, along with the tcgen05 instruction to control it. Tensor cores can now operate independently from CUDA cores without competing for register file bandwidth. That is the single biggest architectural change in SM100.\n\nSM12x lacks the TMEM hardware entirely, and therefore does not support the tcgen05 instruction that controls it. The same goes for Hopper's WGMMA: compiling WGMMA code targeting SM12x produces ptxas error: Instruction 'wgmma.fence' not supported on .target 'sm_120'. The tensor core instruction that SM12x actually uses is an extended version of mma.sync, the same instruction family that dates back to Ampere. It adds support for new numeric formats like FP4 and FP6, but the programming model itself is the oldest one available. Looking at the last column of the table, SM100 writes intermediate results to dedicated memory (TMEM), while SM12x reads from and writes to registers, exactly like Ampere. Datacenter Blackwell turned the tensor core into an autonomous compute unit; consumer Blackwell put new data types on top of the oldest programming model.\n\nBecause SM90 kernels use WGMMA, SM100 kernels use tcgen05, and SM12x kernels use extended mma.sync, there is no kernel compatibility among the three architectures. Developers have to maintain three separate code paths.\n\nPorting existing kernels to SM12x is not straightforward, either. A 64x64 matrix tile that SM100 processes in one operation must be broken into 16x8 chunks requiring 32 separate mma.sync calls. Memory load patterns, inter-thread synchronization, and thread organization all need to be redesigned.\n\nNVIDIA shipping different microarchitectures under the same generation name is not new to Blackwell. In the Ampere generation (2020), the datacenter GA100 (A100) was manufactured on TSMC 7nm with 64 FP32 cores per SM and HBM2 memory. The consumer GA102 (RTX 3090), released the same September, used Samsung 8nm, had 128 FP32 cores per SM, and shipped with GDDR6X. GA102 repurposed the Turing-era INT32 datapath to also handle FP32 operations, doubling the shader count per SM, while GA100 skipped that change to focus on FP64 compute and HBM bandwidth. Different fabs, different SM designs, different memory interfaces, same \"Ampere\" branding.\n\nWith Hopper/Ada Lovelace (2022), NVIDIA separated the names outright. Datacenter Hopper (H100, SM90) was announced in March 2022; consumer Ada Lovelace (RTX 4090, SM89) followed in September as a distinct architecture. Compute capabilities were different too: 9.0 for Hopper, 8.9 for Ada Lovelace.\n\nIn Pascal (2016), GP100 (Tesla P100) had NVLink and HBM2; GP102 (GTX 1080 Ti) had neither.\n\nDatacenter chips and consumer chips allocate their transistor budgets differently. Datacenter parts spend die area on FP64 compute, HBM memory bandwidth, NVLink/NVSwitch, and MIG partitioning. Consumer parts spend on RT cores, display outputs, and power efficiency. The entire GB10 SoC runs at 140W; a single B200 GPU draws 1,000W.\n\nSM100's TMEM, tcgen05, and 2-SM cooperative MMA are designed for datacenter environments where thousands of GPUs process massive matrix operations. Models like GLM-5 and DeepSeek-V3 use MoE8 architectures that activate only a subset of the model's parameters (expert subnets) per input token, so instead of running one large matrix multiply for a long time, they rapidly switch between many smaller ones. TMEM absorbs the accumulator storage pressure during these switches, and tcgen05's asynchronous execution allows prefetching the next expert's weights while the current expert is still computing. On a DGX Spark, where LPDDR5X provides 273 GB/s of memory bandwidth, the bottleneck is getting data from memory to the compute units, not tensor core throughput. Investing die area in TMEM and tcgen05 would yield little practical benefit under those conditions. SM12x keeping the proven mma.sync approach while adding FP4/FP6 support, 5th-gen tensor cores, and RT cores reflects this tradeoff. At Hot Chips 2025, NVIDIA disclosed that GB10 worked on TSMC 3nm A0 (first silicon) without revision, because it was assembled from validated IP blocks rather than designed from scratch.\n\nFlashMLA's sparse decoding kernel internally uses FP8 KV cache together with either WGMMA- or tcgen05-based matrix multiply. Neither is available on SM12x, so an SM12x backend would need to be written from the ground up. FlashInfer is in the same situation. FlashAttention's supported architecture list includes only Ampere, Ada Lovelace, and Hopper, and the runtime does not recognize SM12x as \"newer than Ampere.\" FlashAttention 4 (FA4) supports SM100 only. In the vLLM and SGLang ecosystems, SM12x-related issues keep surfacing. The most common: FP8 block-scaled GEMM kernels written for SM100 fail to run on RTX 5090 (SM120). SGLang's published DeepSeek-V3 serving configurations include H200 (SM90) and B200 (SM100) setups, but nothing for SM12x.\n\nTriton treats SM12x as SM80 (Ampere), disabling all Blackwell-related optimizations, and vLLM requires the --enforce-eager flag. Running attention kernels on SM12x is not entirely impossible: some developers have reported re-implementing FlashAttention in CUDA C++ using Ampere-era instructions (mma.sync, cp.async) or falling back to cuDNN's SDPA backend. These workarounds only support standard dense attention, though. MLA-specific kernels, sparse attention, and FP8 KV cache are out of reach, which makes it difficult to get full performance from models like GLM-5 or DeepSeek-V3.\n\nOne thing DGX Spark does offer that conventional desktops cannot: its 128GB of memory is shared between CPU and GPU without partitioning. A discrete GPU setup physically cannot do this. The bandwidth is lower than HBM, but being able to fit an entire 200B-parameter model in memory on a desktop machine is a rare capability. Once SM12x-native kernels materialize, the practical value of that memory pool changes considerably.\n\nGB10 is Blackwell. It has 5th-gen tensor cores, supports FP4/FP6 arithmetic, and includes RT cores. What it does not share with datacenter Blackwell is the instruction set. SM12x's tensor core programming model is closer to Ampere's mma.sync than to datacenter Blackwell's tcgen05, and for kernel developers, that means maintaining three separate code paths: Hopper, datacenter Blackwell, and consumer Blackwell.\n\nThis kind of datacenter-versus-consumer architectural split has recurred in every generation since Pascal, and the gap is wider in Blackwell because datacenter-only features like TMEM and tcgen05 are larger in scope than anything that came before. While a $4,000 desktop device cannot possibly contain the full instruction set of a $30,000+ data center GPU, the existence of instruction-level branching under the same 'Blackwell' name is an engineering detail worth noting for developers writing or relying on CUDA kernels.\n\nTry Backend.AI GO on DGX Spark. Supports DGX Spark's Unified Memory natively, for free.\n\nKV cache: A memory region where language models store Key and Value vectors from previously processed tokens. As models grow larger and inputs grow longer, this cache scales proportionally. ↩\n\nKernel: A program that runs on the GPU. Here, it refers to attention computation code that has been hand-optimized for specific GPU hardware. ↩\n\nSM (Streaming Multiprocessor): The basic compute building block of an NVIDIA GPU. Each SM contains CUDA cores and tensor cores, and overall GPU performance is determined by how many SMs a chip has and how each is configured. ↩\n\nCompute Capability: A version number NVIDIA assigns to indicate a GPU's hardware feature level. GPUs within the same generation receive different numbers if they support different instructions and features. ↩\n\nWarp: A group of 32 GPU threads that move in lockstep, executing the same instruction simultaneously. The fundamental unit of execution in GPU programming. ↩\n\nISA (Instruction Set Architecture): The set of instructions that hardware understands. Just as CPUs have x86 or ARM, GPUs have their own instruction sets, and two chips branded 'Blackwell' with different ISAs cannot run the same compiled code. ↩\n\nRegister file: The fastest storage available, sitting right next to the processor core. Its limited capacity means contention arises when multiple operations try to use it simultaneously. ↩\n\nMoE (Mixture of Experts): A model architecture that activates only a subset of 'expert' subnetworks per input, rather than using the entire model every time. This reduces actual compute relative to total parameter count. ↩",
    "readingTime": 11,
    "keywords": [
      "ada lovelace",
      "tmem dedicated",
      "previously processed",
      "processed tokens",
      "register file",
      "cuda cores",
      "code paths",
      "per input",
      "matrix multiplication",
      "matrix multiply"
    ],
    "qualityScore": 1,
    "link": "https://www.backend.ai/blog/2026-02-is-dgx-spark-actually-a-blackwell",
    "thumbnail_url": "https://cdn.lablup.com/DGX_Spark_actually_a_blackwell_en_2b3612ef17.jpg",
    "created_at": "2026-02-20T12:34:24.506Z",
    "topic": "tech"
  },
  {
    "slug": "modis-ai-summit-turns-awkward-as-tech-leaders-sam-altman-and-dario-amodei-dodge-contact",
    "title": "Modi’s AI summit turns awkward as tech leaders Sam Altman and Dario Amodei dodge contact",
    "description": "Indian Prime Minister Narendra Modi on Thursday invited leaders of some of the top artificial intelligence companies to gather on stage as part of a commitment to build more “inclusive and multilingua...",
    "fullText": "NEW DELHI (AP) — Indian Prime Minister Narendra Modi on Thursday invited leaders of some of the top artificial intelligence companies to gather on stage as part of a commitment to build more “inclusive and multilingual” AI around the world.\n\nAnd they did. But what caught some of the audience's attention, and later went viral on social media, was an awkward interaction between two rival tech leaders: OpenAI CEO Sam Altman and Anthropic CEO Dario Amodei.\n\nModi, host of the India AI Impact Summit in New Delhi, clasped hands with those closest to him — Altman to his left and Google CEO Sundar Pichai to his right — and beckoned all 13 tech leaders to lift their hands up in a chain, like theater actors at the end of a show.\n\nEveryone was holding hands except for Altman and Amodei, who stood next to each other but for several seconds awkwardly avoided hand contact. Both eventually put up their fists instead.\n\nThe interaction quickly became a visual symbol of the deep rivalries in the AI industry, particularly between OpenAI and Anthropic, though Altman sought to brush off any deeper meaning.\n\n“I didn't know what was happening,” Altman later said in a video interview with Indian media outlet Moneycontrol. He said he was “confused, like when (Modi) grabbed my hand and put it up, and I just wasn’t sure what we were supposed to be doing.”\n\nThe two AI developers have a history, one that predates the creation of OpenAI's hit product, ChatGPT, and Anthropic's competing chatbot Claude.\n\nAmodei worked at OpenAI before he and a group that included his sister, Daniela Amodei, quit to form Anthropic in 2021. The newer company promised a clearer focus on the safety of the better-than-human technology called artificial general intelligence that both San Francisco firms aim to build.\n\nOpenAI first released ChatGPT in late 2022, revealing the huge commercial potential of AI large language models that could help write emails and computer code and answer questions. Anthropic followed with its first version of Claude in 2023.\n\nTheir different approaches spilled over into public debate earlier this month in the United States when Anthropic aired TV commercials during the Super Bowl that ridiculed OpenAI for the digital advertising it’s beginning to place in free and cheaper versions of ChatGPT.\n\nWhile Anthropic has centered its revenue model on selling Claude to other businesses, OpenAI has opened the doors to ads as a way of making money from the hundreds of millions of consumers who get ChatGPT for free. Altman took to social media to criticize the TV commercials as dishonest.\n\nO'Brien reported from Providence, Rhode Island.",
    "readingTime": 3,
    "keywords": [
      "social media",
      "tech leaders",
      "modi",
      "indian",
      "artificial",
      "intelligence",
      "later",
      "interaction",
      "commercials",
      "free"
    ],
    "qualityScore": 0.9,
    "link": "https://www.yahoo.com/news/articles/modi-ai-summit-turns-awkward-164916441.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/EGggBLOY4XwIy3wT8JiXvQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MTY7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/9fe9d8593ae5de3640a76f88c2104cf4",
    "created_at": "2026-02-20T12:34:21.002Z",
    "topic": "news"
  },
  {
    "slug": "mind-launches-inquiry-into-ai-and-mental-health-after-guardian-investigation",
    "title": "Mind launches inquiry into AI and mental health after Guardian investigation",
    "description": "Exclusive: England and Wales charity to examine safeguards after Guardian exposed ‘very dangerous’ advice on Google AI...",
    "fullText": "Exclusive: England and Wales charity to examine safeguards after Guardian exposed ‘very dangerous’ advice on Google AI Overviews\n\n‘Very dangerous’: a Mind mental health expert on Google’s AI summaries\n\nMind is launching a significant inquiry into artificial intelligence and mental health after a Guardian investigation exposed how Google’s AI Overviews gave people “very dangerous” medical advice.\n\nIn a year-long commission, the mental health charity, which operates in England and Wales, will examine the risks and safeguards required as AI increasingly influences the lives of millions of people affected by mental health issues worldwide.\n\nThe inquiry – the first of its kind globally – will bring together the world’s leading doctors and mental health professionals, as well as people with lived experience, health providers, policymakers and tech companies. Mind says it will aim to shape a safer digital mental health ecosystem, with strong regulation, standards and safeguards.\n\nThe launch comes after the Guardian revealed how people were being put at risk of harm by false and misleading health information in Google AI Overviews. The AI-generated summaries are shown to 2 billion people a month, and appear above traditional search results on the world’s most visited website.\n\nAfter the reporting, Google removed AI Overviews for some but not all medical searches. Dr Sarah Hughes, chief executive officer of Mind, said “dangerously incorrect” mental health advice was still being provided to the public. In the worst cases, the bogus information could put lives at risk, she said.\n\nHughes said: “We believe AI has enormous potential to improve the lives of people with mental health problems, widen access to support, and strengthen public services. But that potential will only be realised if it is developed and deployed responsibly, with safeguards proportionate to the risks.\n\n“The issues exposed by the Guardian’s reporting are among the reasons we’re launching Mind’s commission on AI and mental health, to examine the risks, opportunities and safeguards needed as AI becomes more deeply embedded in everyday life.\n\n“We want to ensure that innovation does not come at the expense of people’s wellbeing, and that those of us with lived experience of mental health problems are at the heart of shaping the future of digital support.”\n\nGoogle has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are “helpful” and “reliable”.\n\nBut the Guardian found some AI Overviews served up inaccurate health information and put people at risk of harm. The investigation uncovered false and misleading medical advice across a range of issues, including cancer, liver disease and women’s health, as well as mental health conditions.\n\nExperts said some AI Overviews for conditions such as psychosis and eating disorders offered “very dangerous advice” and were “incorrect, harmful or could lead people to avoid seeking help”.\n\nGoogle is also downplaying safety warnings that its AI-generated medical advice may be wrong, the Guardian found.\n\nHughes said vulnerable people were being served “dangerously incorrect guidance on mental health”, including “advice that could prevent people from seeking treatment, reinforce stigma or discrimination and in the worst cases, put lives at risk”.\n\nShe added: “People deserve information that is safe, accurate and grounded in evidence, not untested technology presented with a veneer of confidence.”\n\nIf you have something to share about this story, you can contact Andrew using one of the following methods.\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don’t already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nIf you don’t need a high level of security or confidentiality you can email andrew.gregory@theguardian.com\n\nSecureDrop and other secure methods\n\nIf you can safely use the tor network without being observed or monitored you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.\n\nThe commission, which will run for a year, will gather evidence on the intersection of AI and mental health, and provide an “open space” where the experience of people with mental health conditions will be “seen, recorded and understood”.\n\nRosie Weatherley, information content manager at Mind, said that although Googling mental health information “wasn’t perfect” before AI Overviews, it usually worked well. She said: “Users had a good chance of clicking through to a credible health website that answered their query, and then went further – offering nuance, lived experience, case studies, quotes, social context and an onward journey to support.\n\n“AI Overviews replaced that richness with a clinical-sounding summary that gives an illusion of definitiveness. They give the user more of one form of clarity (brevity and plain English), while giving them less of another form of clarity (security in the source of the information, and how much to trust it). It’s a very seductive swap, but not a responsible one.”\n\nA Google spokesperson said: “We invest significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information.\n\n“For queries where our systems identify a person might be in distress, we work to display relevant, local crisis hotlines. Without being able to review the examples referenced, we can’t comment on their accuracy.”",
    "readingTime": 5,
    "keywords": [
      "ai overviews",
      "guardian app",
      "dangerously incorrect",
      "medical advice",
      "dangerous advice",
      "mental health",
      "health conditions",
      "safeguards",
      "mind",
      "experience"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/20/mind-inquiry-google-ai-overviews-mental-health-guardian-investigation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/b6f1974a3be968d635e4ccdae26f1860cb90dcd4/492_0_4916_3933/master/4916.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ce1ecf227877ff823b1cef60a12f5830",
    "created_at": "2026-02-20T12:34:15.667Z",
    "topic": "tech"
  },
  {
    "slug": "openai-and-paradigm-launches-evmbench-to-test-ais-on-smart-contract-security",
    "title": "OpenAI and Paradigm Launches EVMbench to Test AIs on Smart Contract Security",
    "description": "OpenAI's EVMbench assesses AI agents on detecting, patching, and exploiting high-severity smart contract flaws . The benchmark comprises 120 curated vulnerabilities from 40 audits, including scenarios from the Tempo blockchain .",
    "fullText": "OpenAI and Paradigm launched EVMbench, aiming to evaluate AI agents’ ability to detect, patch, and exploit vulnerabilities within Ethereum-based smart contracts that collectively secure over $100 billion in crypto assets. EVMbench is based on 120 vulnerability types found in 40 different security audits (including several from Tempo blockchain) and will include scenarios involving payment-oriented smart contract code related to expected agentic stablecoin transactions.\n\nIntroducing EVMbench—a new benchmark that measures how well AI agents can detect, exploit, and patch high-severity smart contract vulnerabilities. https://t.co/op5zufgAGH\n\nEVMbench measures each artificial intelligence (AI) agent’s performance in three ways:\n\nEach test is conducted by using an Anvil-based, Rust-language harness to provide a deterministic and reproducible means of evaluating agents within isolated environments rather than live networks.\n\nAI’s Frontier models (the most recent ones) have performed significantly better than those measured six months ago. For example, GPT-5.3-Codex’s average performance on exploit tasks is 72.2%, while its predecessor model (GPT-5) had only 31.9% on the same exploits. Detect and patch modes remain more challenging to agents as they often stop their audit process after finding the first fault or have difficulties maintaining the perfect functionality of the contract while also removing vulnerabilities.\n\nnew collab from @paradigm and @OpenAI:\n\nevmbench is a benchmark and agent harness for exploiting smart contract bugs\n\na few months ago, the best models found <20% of critical, fund-draining @Code4rena bugs in our benchmark. today they find > 70% https://t.co/soOrCR38eO pic.twitter.com/2lr0WUVo2Q\n\nEVMbench tackles both sides of AI use in cybersecurity: monitoring new threats while encouraging defensive applications. As part of this initiative, OpenAI recently committed $10M of Application Programming Interface (API) credits through its Cybersecurity Grant Program to help boost efforts toward creating more defensive research and expanding Aardvark’s (its open-source security research agent) footprint with a private beta test.",
    "readingTime": 2,
    "keywords": [
      "smart contract",
      "agents",
      "detect",
      "patch",
      "exploit",
      "vulnerabilities",
      "benchmark",
      "within",
      "measures",
      "performance"
    ],
    "qualityScore": 0.9,
    "link": "https://timescrypto.com/cryptobuzz/ai-and-crypto/openai-paradigm-launches-evmbench-to-test-ai-capabilities-on-smart-contract-security/article-22555/",
    "thumbnail_url": "https://timescrypto.com/wp-content/uploads/2026/02/open-AI.jpg",
    "created_at": "2026-02-20T06:41:53.398Z",
    "topic": "finance"
  },
  {
    "slug": "a-guide-to-which-ai-to-use-in-the-agentic-era",
    "title": "A Guide to Which AI to Use in the Agentic Era",
    "description": "It's not just chatbots anymore",
    "fullText": "What really struck me reading this is how quickly the problem shifts from model capability to organisational design.\n\nOnce AI can reliably handle multi-step work, the hard question stops being which system is smartest and becomes how companies actually structure delegation, supervision, and accountability when the “worker” is software.\n\nIt feels like a lot of organisations are still treating this as a tooling decision, when in practice it’s already becoming an operating model question. We’re seeing that shift happen pretty quickly inside enterprise teams now.\n\nLove this! One thing I'd add is that while Gemini has the weakest general-purpose harness, the NotebookLM + Gemini integration is powerful (especially paired with Google's significantly larger context windows).\n\nPreviously, when my notebook couldn't answer something because it wasn't in my sources, I had to leave NotebookLM, search elsewhere, and reconcile manually. Now Gemini lets me combine my uploaded sources with live web information in a single conversation.\n\nFor podcast pre-production, I upload a guest's book, previous interviews, and biography into NotebookLM, then attach that notebook to Gemini and ask it to cross-reference my sources with their most recent public statements or interviews I haven't captured yet — so I can spot where their thinking has shifted and prepare sharper questions.\n\nFor lesson & curriculum design, I upload curriculum standards, past lesson plans, and student feedback. NotebookLM synthesizes gaps and aligns objectives, then in Gemini I can ask it to find current news / real-world examples from the web that bring a specific learning objective to life; without losing the grounding in my actual materials.",
    "readingTime": 2,
    "keywords": [
      "quickly",
      "model",
      "design",
      "upload",
      "interviews",
      "lesson",
      "curriculum",
      "gemini",
      "notebooklm",
      "notebook"
    ],
    "qualityScore": 0.85,
    "link": "https://www.oneusefulthing.org/p/a-guide-to-which-ai-to-use-in-the",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!O-pO!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77c79c7-9fb2-4cd0-b075-a6201a212a6c_1456x816.png",
    "created_at": "2026-02-20T06:41:52.203Z",
    "topic": "tech"
  },
  {
    "slug": "edgequakelitellm-rustbacked-dropin-replacement-for-litellm-v01",
    "title": "Edgequake-litellm – Rust-backed drop-in replacement for LiteLLM (v0.1)",
    "description": "Unified LLM provider abstraction for Rust - support for OpenAI, Anthropic, Gemini, xAI, OpenRouter, and more - raphaelmansuy/edgequake-llm",
    "fullText": "raphaelmansuy\n\n /\n\n edgequake-llm\n\n Public\n\n Unified LLM provider abstraction for Rust - support for OpenAI, Anthropic, Gemini, xAI, OpenRouter, and more\n\n License\n\n View license\n\n 11\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n raphaelmansuy/edgequake-llm",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/raphaelmansuy/edgequake-llm",
    "thumbnail_url": "https://opengraph.githubassets.com/033a287a2d59f44716bd741ab3445e817d4de8a3a3b317ef42743208b4bea6cc/raphaelmansuy/edgequake-llm",
    "created_at": "2026-02-20T06:41:51.665Z",
    "topic": "tech"
  },
  {
    "slug": "photomeh-repair-cost-estimates-from-photos-in-under-60-seconds",
    "title": "PhotoMeh – Repair cost estimates from photos – in under 60 seconds",
    "description": "Get AI-powered car damage estimates from a photo. Upload an image and receive a detailed repair cost breakdown.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://photomeh.com",
    "thumbnail_url": "https://photomeh.com/og-image.jpeg",
    "created_at": "2026-02-20T06:41:50.943Z",
    "topic": "tech"
  },
  {
    "slug": "openai-offers-15000-and-support-resources-to-staff-affected-by-us-immigration-authorities",
    "title": "OpenAI offers $15,000 and support resources to staff affected by US immigration authorities",
    "description": "OpenAI confirmed it's offering resources to staff navigating ICE detention or other immigration issues, including $15,000 in reimbursement of legal fees.",
    "fullText": "OpenAI is rolling out a new package of resources for employees who may be navigating interactions with US immigration authorities.\n\nThe initiative is designed to help staff directly affected by Immigration and Customs Enforcement (ICE) detention or prolonged secondary inspection by US Customs and Border Protection (CBP) — including situations involving an employee or an immediate family member.\n\nThe move comes as the nation grapples with fallout from a series of federal immigration enforcement incidents, including lethal shootings, that have triggered widespread protests and corporate pushback.\n\nAccording to an OpenAI spokesperson, the support resources include:\n\n\"We regularly review our employee benefits to ensure they reflect the needs of our workforce,\" the spokesperson said in a statement to Business Insider. \"As part of that process, we updated our support resources for employees facing complex immigration-related situations.\"\n\nThe company, which relies on skilled workers from around the world, declined to specify how many employees might require the use of the resources.\n\nThe announcement follows internal conversations at OpenAI about federal immigration enforcement, including CEO Sam Altman's recent message to employees criticizing ICE's actions as going \"too far.\"\n\nBusiness Insider previously reported that in a late January internal Slack message, Altman expressed concern about recent immigration enforcement activity, sparking strong reactions within the company.\n\nAltman's comments came amid heightened national scrutiny over ICE and Border Patrol operations in Minneapolis, where federal immigration enforcement actions have drawn widespread criticism.\n\nIn his message, which also praised Trump, Altman said part of loving the country is recognizing and pushing back against government \"overreach.\"",
    "readingTime": 2,
    "keywords": [
      "federal immigration",
      "immigration enforcement",
      "resources",
      "employees",
      "openai",
      "message",
      "customs",
      "situations",
      "employee",
      "widespread"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-reimbursement-legal-resources-staff-detained-immigration-customs-enforcement-2026-2",
    "thumbnail_url": "https://i.insider.com/6997ba07f8731049f3af730f?width=1200&format=jpeg",
    "created_at": "2026-02-20T06:41:49.531Z",
    "topic": "finance"
  },
  {
    "slug": "mark-cuban-on-2-types-of-ai-users-youre-either-using-it-to-learn-everything-or-so-you-dont-have-to-learn-anything",
    "title": "Mark Cuban on 2 types of AI users: you're either using it to 'learn everything' or 'so you don't have to learn anything'",
    "description": "Bill Gurley, a partner at the Silicon Valley venture capitalist firm Benchmark, agrees \"100%\" with Mark Cuban that there are two types of AI users.",
    "fullText": "Mark Cuban says there are two types of people who use AI. Which one are you?\n\n\"There are generally 2 types of LLM users, those that use it to learn everything , and those that use it so they don't have to learn anything,\" Cuban said of large language models in an X post on Tuesday.\n\nThe \"Shark Tank\" billionaire has been bullish about AI and said that companies need to embrace it.\n\nCuban has said there will be \"two types of companies: those who are great at AI, and everybody else,\" Business Insider's James Faris previously reported. He's also said that AI models can't provide all the answers and are \"stupid\" but like \"a savant that remembers everything.\"\n\nBill Gurley, a partner at the Silicon Valley venture capitalist firm Benchmark, agrees \"100%\" with Cuban that there are two types of AI users.\n\n\"If you are on a custom career path where you aim to differentiate yourself, AI is 'jet fuel' - you can learn and soar faster than ever before,\" Gurley said on X in response to Cuban.\n\nOr, it could have the opposite effect.\n\nEven some of AI's biggest proponents have warned that the technology could make people lazy.\n\nArthur Mensch, CEO of Mistral AI, said last year that the biggest risk to humans posed by AI was \"deskilling\" and employees becoming lazier as they rely too heavily on the AI tools.\n\n\"You want people to continue learning,\" he said in an interview with The Times of London. \"Being able to synthesize information and criticize information is a core component to learning.\"\n\nBusiness Insider reached out to Cuban for additional comment.",
    "readingTime": 2,
    "keywords": [
      "learn",
      "users",
      "everything",
      "models",
      "biggest",
      "learning",
      "cuban",
      "business",
      "gurley"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/mark-cuban-two-types-of-people-using-ai-learning-lazy-2026-2",
    "thumbnail_url": "https://i.insider.com/6997a531f8731049f3af7293?width=1200&format=jpeg",
    "created_at": "2026-02-20T06:41:49.529Z",
    "topic": "finance"
  },
  {
    "slug": "deepminds-ceo-says-using-ai-can-make-you-a-genius-or-hurt-your-critical-thinking-skills",
    "title": "DeepMind's CEO says using AI can make you a genius — or hurt your critical thinking skills",
    "description": "The DeepMind CEO said that AI is like the internet — people can use it to learn all kinds of topics, or use it in ways that \"degrade\" their thinking.",
    "fullText": "It's up to you whether AI makes you sharper or slowly dulls your brain, says Demis Hassabis.\n\nIn a Thursday interview with entrepreneur Varun Mayya on the sidelines of the India AI Impact Summit, the Google DeepMind CEO said that AI is just like the internet. People can use it to learn all kinds of topics, or use it in ways that \"degrade\" their thinking.\n\n\"With AI, if you use it in a lazy way, it will make you worse at critical thinking and so on,\" he said. \"But that's down to you as the individual. No one can help you do that.\"\n\nHe added that people need to be smart and use these technologies in ways that enhance their thinking rather than dull it.\n\nHassabis cofounded DeepMind in 2010, which Google acquired in 2014. It merged with Google Brain in 2023 to form Google DeepMind, the lab behind tools such as Gemini and Nano Banana. The CEO and a DeepMind coworker, John Jumper, were awarded the 2024 Nobel Prize for Chemistry for their work on protein structure prediction.\n\nAs AI gets incorporated into daily life, debates about its risks and rewards have intensified, with several tech leaders warning about the dangers of an overreliance on AI tools.\n\nEarlier this week, tech billionaire Mark Cuban said that there are two types of people who use AI.\n\n\"There are generally 2 types of LLM users, those that use it to learn everything, and those that use it so they don't have to learn anything,\" Cuban said of large language models in an X post on Tuesday.\n\nCuban has previously said that AI models can't provide all the answers and are \"stupid\" but like \"a savant that remembers everything.\"\n\nAt a June conference, the CEO of French AI lab Mistral said that a risk of using AI for everything is that humans will stop trying.\n\n\"The biggest risk with AI is not that it will outsmart us or become uncontrollable, but that it will make us too comfortable, too dependent, and ultimately too lazy to think or act for ourselves,\" Arthur Mensch said.",
    "readingTime": 2,
    "keywords": [
      "learn",
      "everything",
      "ways",
      "lazy",
      "tools",
      "tech",
      "models",
      "risk",
      "google",
      "deepmind"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/deepmind-ceo-demis-hassabis-ai-lazy-way-hurts-thinking-skills-2026-2",
    "thumbnail_url": "https://i.insider.com/6997cd7ff8731049f3af73bc?width=1200&format=jpeg",
    "created_at": "2026-02-20T06:41:49.370Z",
    "topic": "finance"
  },
  {
    "slug": "suttons-predictions-v-embrace-bassist-steve-firth",
    "title": "Sutton's predictions v Embrace bassist Steve Firth",
    "description": "BBC Sport football expert Chris Sutton takes on Embrace bassist Steve Firth plus the BBC readers and AI with his predictions for this weekend's Premier League fixtures.",
    "fullText": "New Tottenham boss Igor Tudor's first game in charge is Sunday's north London derby - but will he make a dream start at home against Arsenal or have a nightmare?\n\n\"Tottenham's stadium has been an unhappy place all season,\" said BBC Sport football expert Chris Sutton. \"Tudor's problem, if he doesn't get off to a fast start, is that there is going to be negativity around him too.\n\n\"Spurs are in a relegation fight and their fans will be asking why have we employed someone to keep us up who doesn't have a lot of knowledge of the Premier League?\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nHis guest for week 27 is Embrace bassist Steve Firth, who is a fan of Leeds United, who are 15th in the Premier League table after gaining promotion last season.\n\nEmbrace are celebrating their 30th anniversary in 2026 and their new track, Road To Nowhere, is out now and their new album, Avalanche, out in June.\n\nDo you agree with their scores? You can pick your own below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.\n\nFirth's favourite Leeds players are mostly from the 1990s, when he was an Elland Road regular, but more recently he was a big fan of midfielder Kalvin Phillips too.\n\n\"I always loved Gordon Strachan, Gary McAllister and David Batty - we had a superb midfield then,\" he told BBC Sport.\n\n\"Then we had Tony Yeboah up front for a couple of seasons, and he was amazing too.\n\n\"There were so many good players for Leeds back then, but I didn't get to see Eric Cantona play for us - that's the one thing I regret.\n\n\"In the past few years, Phillips really stood out before he went to Manchester City. He was a genuine superstar of the future when he was playing for us, so it is shame what has happened with him since.\n\n\"Now? The whole team has turned things around in the past few months because we were in serious trouble in November, but we have only lost a couple of games since then.\n\n\"I do think we're definitely safe now - we are going to do all right from now on and we will finish in mid-table.\n\n\"That is all we can really aspire to at the moment as a promoted team. You just need to hang in there as long as you can really and build up your squad slowly, without over-spending.\n\n\"We've started doing that already. We were very lucky to get Dominic Calvert-Lewin in for nothing, because he has been brilliant.\"\n\nChris Sutton and Steve Firth were speaking to BBC Sport's Chris Bevan.\n\nThe AI predictions were generated using Microsoft Copilot Chat - we simply asked the tool to 'predict this week's Premier League scores'.\n\nI was at Elland Road when Aston Villa won there in November - Leeds were really good in the first half but faded, and two Morgan Rogers goals gave Villa the points.\n\nLeeds' form has picked up a lot since then, however, and they are on 30 points now.\n\nThat would have been enough to keep them up last season, when third-bottom Leicester went down with 25 points, but they have still got some work to do.\n\nVilla have slipped up a couple of times at home in the past few weeks, losing unexpectedly to Everton and Brentford, and they are probably looking at the table thinking they should be breathing down leaders Arsenal's neck.\n\nI can see Leeds giving them another good game, but I don't see Unai Emery's side dropping points this time. Villa will find a way.\n\nSteve's prediction: This is a tough game but we're on a good run of form and I think we'll get a draw. 1-1\n\nSteve on why he supports Leeds: I'm from Halifax and everyone there either supports Leeds, Huddersfield or Manchester United. I've been a Leeds fan since the 1970s but the time I watched them most was in the 1990s - that's when I'd go most weeks.\n\nSince then, of the guys I went with, one died and the other one moved away so I got out of the habit and I only get to the occasional game now. But my wife is a Mansfield fan, so I have to go and watch them sometimes. I was hoping they would get Leeds in the FA Cup fifth round - we would definitely have gone to that one - but they got Arsenal instead.\n\nI covered Brentford in the FA Cup tie at Macclesfield on Monday and they were completely underwhelming.\n\nI know they were on a plastic pitch but they couldn't really find their flow and needed an own goal to progress.\n\nStill, the Bees have been in much better form in the Premier League - in stark contrast to Brighton.\n\nFabian Hurzeler's side have won only one of their past 13 league games in a poor run going back to the start of December, and it is not impossible they could get dragged into the relegation scrap.\n\nI can see this one being close but Brentford will have Kevin Schade back from suspension, while Igor Thiago will also return after being rested against Macclesfield - and those two should make the difference.\n\nSteve's prediction: Brentford are too good for Brighton. My predictions are going to be very conservative by the way, there are no 5-0s! 2-1\n\nSo much for me thinking that Burnley might give their fans something to cheer about by going on a good FA Cup run.\n\nAfter their brilliant fightback to beat Crystal Palace in their last league game, the Clarets made changes against Mansfield and went out on their own patch to a League One side.\n\nI just can't see anything other than a home win for Chelsea here, even with their wobble last time at Stamford Bridge where Leeds fought back from 2-0 down to draw 2-2 - Liam Rosenior's side won't let that happen again.\n\nSteve's prediction: Definitely a Chelsea win here. My wife was very happy when Mansfield beat Burnley last week. 2-0\n\nWest Ham are still in the bottom three but they have shown they are up for the fight in the past few weeks.\n\nYes, they conceded a late equaliser against Manchester United in their last league game, but they keep on picking up points and that must have given them belief they can stay up.\n\nBournemouth are on a good run now too, with three wins in their past four league games but, along with Brighton, they are the Premier League's draw specialists this season - both have had 10 so far.\n\nIt finished 2-2 when these two sides met on the south coast in November and I can see the points being shared this time too.\n\nSteve's prediction: I am going with Bournemouth to edge this. 1-2\n\nThis is the fourth meeting between these two clubs already this season, with another to come soon in the FA Cup fifth round - I bet they are sick of each other already.\n\nNewcastle have a long trip back from Azerbaijan to contend with before this game but at least they have put their Champions League tie with Qarabag to bed already and can focus fully on City rather than next week's second leg.\n\nThe Magpies still have an awful record at Etihad, however - they lost here in the Carabao Cup in January and have never managed a win in 20 visits in the Premier League.\n\nI don't think this will be easy for City, but I do think they will beat them, again, to move within two points of Arsenal.\n\nThe only thing I am not sure about is whether to captain Erling Haaland in my Fantasy team, because he has been out injured.\n\nSteve's prediction: I've always liked Newcastle but I think City are going to win the league so I am going to back them here. 2-0\n\nFair play to Wolves, because they have turned a bit of a corner under Rob Edwards.\n\nTheir results have still never looked like being enough to keep them up but they showed again against Arsenal that they are at least being competitive now.\n\nEven so, I can see this game being all about Jorgen Strand Larsen, following his £48m move from Wolves to Palace at the end of the January transfer window.\n\nPalace still need the points and I would not be surprised if he has a say in the outcome - let's go for him to score the winner.\n\nSteve's prediction: Wolves are down so I am giving Palace this one. 2-0\n\nWhen Vítor Pereira went in as Wolves manager in December 2024, he did brilliantly to keep them up - but he has essentially taken them down this season, picking up only two points from 10 games before he was sacked.\n\nNow he has arrived at Forest as their fourth manager of the season.\n\nI don't think his predecessor, Sean Dyche, deserved the sack. Based on the results in his 18 games in charge, Forest would be 12th in the table, but we are used to seeing managerial changes at the City Ground now.\n\nWe know Pereira will try to keep things tight, but Forest's biggest issue throughout this campaign has been scoring goals and I am not sure they will be able to get at Liverpool.\n\nArne Slot's side became the first team to win at the Stadium of Light when they edged out Sunderland in their last league game, and I can see a similar outcome here.\n\nSteve's prediction: Forest might get a new manager bounce but I still think Liverpool will win. As a Mansfield fan, my wife hates Forest so I am not allowed to like them either! It's the same with Chesterfield too. 0-2\n\nSunderland's form has dropped off a little bit in recent weeks but they have still had a phenomenal season and are probably safe already on 36 points - now they just have to see it through.\n\nIt will be interesting to see how Regis le Bris's side respond to their first home defeat of the season, but Fulham are hardly on a great run either with three straight league losses.\n\nMarco Silva's side beat the Black Cats at Craven Cottage in November, and will leapfrog them in the table if they win this time too - but I don't think that will happen.\n\nSteve's prediction: I wasn't sure about this one because they are both decent sides so I am going for a draw. 1-1\n\nTottenham Hotspur Stadium, 16:30\n\nFrom what I've read about new Tottenham manager Igor Tudor, he is a guy who goes in at clubs and, in the short term, gets a turn out of his team.\n\nSpurs really need that to happen now, because they desperately need a win or two to get out of reach of relegation.\n\nSo, this game is big for them for that reason, and also because they can put another dent in Arsenal's title hopes too.\n\nSpurs and their fans have not had a lot to shout about this season, but if they can get something here then this could be a defining moment in their campaign, and affect Arsenal as well. They would love that.\n\nIt was an incredible wobble by Mikel Arteta's team against Wolves, drawing 2-2 after being 2-0 up, and I certainly didn't see it coming.\n\nMaybe it is getting to be 'squeaky bum time' for them, but it didn't affect them when they went away to Leeds a couple of weeks ago and won convincingly.\n\nYou can imagine how Spurs will be champing at the bit, and I am expecting them to make a fast start and have a real go at them - but Arsenal have to deal with that, and find a way of bouncing back.\n\nI think the Gunners can do that, and their quality will make the difference in the end. I worry about Spurs in forward areas and it will be interesting to see how Tudor lines them up in defence too.\n\nUltimately, if Arsenal turn up and play how we know they can, then they will win - and I am expecting them to make a real statement.\n\nSteve's prediction: Two bottlers here! I'd like Arsenal to win the league, but I don't think they will. Man City are just used to doing it from here - they just get their heads down in the run-in, and they know what to do. 2-3\n\nManchester United lost at home to Everton in November despite the Toffees going down to 10 men in the 13th minute, when Idrissa Gueye was sent off for striking his team-mate Michael Keane.\n\nRuben Amorim's United just could not find a way of breaking Everton down that night, but there is a very different feel about them now Michael Carrick is in charge.\n\nThey needed a stoppage-time equaliser to get a point at West Ham last time out but they seem much more confident and have been playing well.\n\nThis will be a tough game for them but, as I've mentioned previously, Everton have picked up more points on the road this season than they have done at home.\n\nThat's another reason why I fancy United to get something here, and stop David Moyes doing the double over his former club.\n\nSteve's prediction: We were all enjoying United's mid-table mediocrity but they have started to win now. 1-2\n\nChris correctly picked the winner in 10 of the 15 fourth-round ties to have been played so far - Port Vale versus Swindon was postponed and takes place on 3 March.\n\nHe got the better of his guests, Looney Tunes stars Daffy Duck and Porky Pig - Daffy has nine correct predictions, while Porky has eight.\n\nAI did better with a score of 11, again by avoiding any surprise results, but it is the BBC readers who continue to lead the way, with a tally of 13.\n\nOverall, Chris has now correctly picked the winner in 31 of the 47 ties from round three onwards.\n\nHis guests are on 26, AI is on 34, but the BBC readers are in pole position with 36.\n\nThe shock of the round was Mansfield's win at Burnley which caught out Chris, AI, and most of you lot.\n\nDaffy and Porky did see it coming, however, and out of around 25,000 predictions, more than 3,000 of you also backed the Stags.\n\nChris got three correct results from the 10 midweek Premier League matches in week 26 [which took place from 10-12 February] with one exact score, for a total of 60 points.\n\nThat was enough to beat the BBC readers, who got three correct results with no exact scores, giving them 30 points.\n\nHe also got the better of his guest, golf star Ian Poulter, who got two correct results with no exact scores, for a tally of 20 points.\n\nBut the weekly win went to AI, which got four correct results with two exact scores, for a tally of 100 points.\n\nThere was one other Premier League game played this week - Arsenal's draw with Wolves on Wednesday, which was rearranged because the Gunners are in the Carabao Cup final on 22 March.\n\nEveryone went for an Arsenal victory, so no extra points were scored.\n\nListen to the latest Football Daily podcast\n\nGet football news sent straight to your phone",
    "readingTime": 14,
    "keywords": [
      "cup fifth",
      "bbc readers",
      "steve's prediction",
      "mansfield fan",
      "chris sutton",
      "supports leeds",
      "premier league",
      "fifth round",
      "correctly picked",
      "exact scores"
    ],
    "qualityScore": 1,
    "link": "https://www.bbc.com/sport/football/articles/cx2j8wljzp3o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/be6f/live/5236b240-0d7f-11f1-b7e1-afb6d0884c18.png",
    "created_at": "2026-02-20T06:41:47.759Z",
    "topic": "sports"
  },
  {
    "slug": "amazons-cloud-unit-hit-was-hit-by-least-two-outages-involving-ai-tools-in-december-ft-says",
    "title": "Amazon’s cloud unit hit was hit by least two outages involving AI tools in December, FT says",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/amazons-cloud-unit-hit-by-at-least-two-outages-involving-ai-tools-ft-says-4515160",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1J07A_L.jpg",
    "created_at": "2026-02-20T06:41:46.262Z",
    "topic": "finance"
  },
  {
    "slug": "im-deeply-uncomfortable-anthropic-ceo-warns-that-a-cadre-of-ai-leaders-including-himself-should-not-be-in-charge-of-the",
    "title": "‘I’m deeply uncomfortable’: Anthropic CEO warns that a cadre of AI leaders, including himself, should not be in charge of the technology’s future",
    "description": "Dario Amodei, who left OpenAI before founding Anthropic, has been outspoken about the need for greater AI regulation.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/article/why-is-anthropic-ceo-dario-amodei-deeply-uncomfortable-companies-in-charge-ai-regulating-themselves/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/11/GettyImages-2235057491-e1763403934518.jpg?resize=1200,600",
    "created_at": "2026-02-20T01:08:35.909Z",
    "topic": "business"
  },
  {
    "slug": "walmarts-growing-share-of-highincome-shoppers-helped-its-ecommerce-business-turn-into-a-powerhouse",
    "title": "Walmart's growing share of high-income shoppers helped its e-commerce business turn into a powerhouse",
    "description": "Walmart has steadily gained share from households earning over $100,000 who come for the savings and stay for the convenience — and AI is helping.",
    "fullText": "Walmart's former side hustle is getting serious.\n\nThe retail giant reported that 2025 was its first full year of profitability in its e-commerce operations, which started — as most ventures do — needing time and money to get rolling.\n\n\"We've far surpassed the breakeven level,\" CFO John David Rainey said of the e-commerce business in the company's fourth quarter earnings call Thursday. \"The momentum is only upward from here.\"\n\nThe bet is paying off thanks in large part to the addition of higher-income shoppers, who Walmart said are attracted to its combination of low prices and increasing convenience.\n\n\"The majority of our share gains came from households making more than $100,000,\" CEO John Furner said on the earnings call.\n\nThe company said high-earning households have responded favorably to Walmart's online and in-app offerings, from ordering their weekly groceries to picking out stylish new outfits, as has been the case for several quarters now.\n\nFor the fiscal year, Walmart's overall sales grew 4.7% to $713.2 billion, with e-commerce increasing by nearly 25% to top $150 billion.\n\nDespite Walmart's growth, e-commerce giant Amazon dethroned it as the world's largest company by revenue last year with $716.9 billion in revenue. The stock dipped immediately after the earnings report but recovered during trading on Thursday.\n\nBut Walmart's progress in e-commerce could give Amazon a run for its money, thanks to its physical proximity to 95% of US households.\n\n\"Stores are a huge part of the solution to deliver the customer experiences that the customers are looking for,\" CEO John Furner said on the call. \"Having the US with 5,200 locations between Walmart and Sam's, where inventory is forward-deployed, is really helpful.\"\n\nAmazon, for its part, is working hard to counter Walmart's dominant physical presence, which so far has given it an edge in delivering items like groceries and everyday essentials in an hour or less.\n\nIt's not just fresh food delivery that's helping Walmart reach new shoppers. Rainey said shoppers are using some of the savings from groceries to try new items from other categories.\n\n\"It's not just convenience,\" Rainey said. \"I'd argue fashion is not really a convenience item. It shows that our broader assortment is appealing to a much larger customer base.\"\n\nFashion not only led sales growth in general merchandise in the US, Rainey said, but on-trend styles are also helping draw in more of these high-income households, who wind up sticking around.\n\n\"They're coming to Walmart, in many cases, some of them for the first time, and they're enjoying an experience that makes them want to come back these platforms,\" he said.\n\nGlobalData retail analyst Neil Saunders said his firm's data also shows wealthy households increasingly choosing Walmart for more than groceries, thanks to its expanded assortment and in-store experiences.\n\nIt's still too soon to see the impact of Walmart's recent AI partnerships, but Furner says the early results promise to turbocharge sales online and in-app. He said the company's in-house shopping assistant bot, Sparky, has led to 35% larger transaction totals.\n\n\"Roughly half of our app users have used Sparky, and when they use Sparky, it drives them to build bigger baskets,\" US segment CEO David Guggina said.\n\nWalmart still has a long road ahead to catch Amazon's online sales, but the past year has shown that it now has a powerful engine to get there.",
    "readingTime": 3,
    "keywords": [
      "ceo john",
      "john furner",
      "e-commerce",
      "households",
      "groceries",
      "sales",
      "earnings",
      "thanks",
      "shoppers",
      "convenience"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/high-income-shoppers-boost-walmarts-e-commerce-business-2026-2",
    "thumbnail_url": "https://i.insider.com/69973672e1ba468a96ac4efd?width=1200&format=jpeg",
    "created_at": "2026-02-20T01:08:35.716Z",
    "topic": "finance"
  },
  {
    "slug": "tension-over-a-proposed-ai-data-center-leads-to-an-arrest-in-oklahoma",
    "title": "Tension over a proposed AI data center leads to an arrest in Oklahoma",
    "description": "Beale Infrastructure is proposing a data center in Claremore, Oklahoma, a town of about 20,000. Over a hundred locals met to discuss the plans this week.",
    "fullText": "Applause broke out during an Oklahoma man's speech at a city council meeting on Tuesday to discuss a proposed data center. A minute later, shouts of disbelief rang out across the room.\n\n\"Disgusting!\" one woman shouted as Claremore Police Department officers handcuffed and escorted Daniel Blanchard out of the room.\n\nAuthorities said they arrested Blanchard, whose speech exceeded the three-minute time limit, for trespassing.\n\nOver 100 people, including Blanchard, had gathered in a ballroom at Rogers State University in Claremore to voice their opinions about the large data center project. The developer, Beale Infrastructure, is proposing a campus in the Claremore Industrial Park that includes data centers, supporting infrastructure, and office space.\n\nBlanchard was among the residents who opted to speak during the public comment portion, which limits each person to three minutes. In his speech, Blanchard spoke about what he considered compliance issues related to the potential data centers.\n\n\"The Claremore Industrial Economic Development Authority has a fiduciary responsibility to the public, not to build infrastructure. And this act of overreach is putting the health and safety of members of this community at risk,\" he said.\n\nAI is driving a data center construction boom across the United States. While companies like OpenAI argue that building new data centers will reindustrialize the US economy and create jobs, residents of towns where developers are proposing new data centers worry about their impact on power grids, water resources, pollution, and overall quality of life.\n\nIn an investigation published in September, Business Insider reported that over 1,200 data centers had already been built or were approved for construction across the country.\n\nThe proposed data center in Claremore, a suburban hub of Tulsa home to about 20,000 people, has divided the town. During the three-hour meeting on Tuesday evening, dozens of residents spoke both in favor and against the project.\n\nBlanchard exceeded his three minutes by about 30 seconds before police officers approached him. He gathered his notes and calmly followed the officers to the front of the hall, where town officials were sitting.\n\nIn a video of the meeting posted by the town on its YouTube channel, Blanchard appears to hand his notes to a council member. At that point, police arrested Blanchard, placing him in handcuffs. The crowd hollered in shock.\n\nIn a statement, the Claremore Police Department said officers aren't responsible for enforcing city council rules and only become involved in city council meetings when an official orders them to remove an individual.\n\n\"The man's position on the issues, what he said, or his unwillingness to follow rules of the meeting played no part in the officer's decision to arrest him,\" the statement said. \"He was arrested for trespassing in compliance with the law and with the hope of restoring order to an important meeting.\"\n\nA local politician fighting the data center project posted to X on Wednesday that Blanchard has been released from jail. The next council meeting is scheduled for March 2.",
    "readingTime": 3,
    "keywords": [
      "police department",
      "claremore industrial",
      "arrested blanchard",
      "city council",
      "center project",
      "centers",
      "officers",
      "speech",
      "across",
      "residents"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/data-center-meeting-claremore-oklahoma-man-arrested-beale-infrastructure-ai-2026-2",
    "thumbnail_url": "https://i.insider.com/69975156f8731049f3af6a6b?width=1200&format=jpeg",
    "created_at": "2026-02-20T01:08:35.415Z",
    "topic": "finance"
  },
  {
    "slug": "rumors-suggest-apple-and-meta-are-betting-big-on-ai-wearables",
    "title": "Rumors Suggest Apple and Meta Are Betting Big on AI Wearables",
    "description": "Great: more stuff I'll lose.",
    "fullText": "The next generation of Meta's Display smart glasses might come with a smart watch. According to a report from The Information, Meta's watch, codenamed Malibu 2, could feature fitness tracking features and AI, but its real purpose is to replace the Display's neural band and act as controller for the smart glasses. If the reports are accurate, Meta Display smart glasses with a smart watch could be available in 2026.\n\nThere aren't any other details on the smart watch, so we don't know the price or what features it may have—but I'd be surprised if this rumor doesn't pan out eventually. Meta has discussed the idea of a smart watch before, and it makes sense: If you're going to have a wrist-controller for your glasses, why not give it smart watch features as well? Especially if a glasses-and-watch combo potentially gives users a reason to switch away from their Apple Watches.\n\nSpeaking of Apple, if the rumors about the company are true, Apple is pushing to release its own suite of AI-powered wearable devices. According to a report in Bloomberg, Apple could roll out smart glasses in early 2027. The company is also reportedly developing an AI-powered pendant that can \"be pinned to a shirt or worn as a necklace,\" as well as AirPods with expanded AI capabilities. The AirPods and pendant will be equipped with cameras designed to \"help the AI work\" as opposed to taking photos. Apple's smart glasses will reportedly not feature a display, but will feature a higher end camera and superior build quality to Meta's smart glasses. All of Apple's devices are reportedly designed to work with iPhones.\n\nNone of this is confirmed, of course. The closest Apple has come to announcing these plans is CEO Tim Cook mentioning “categories of products” enabled by artificial intelligence at an all-hands meeting. However, everything points to Meta and Apple betting that consumers want a collection of connected AI-wearables. Each company is taking a different approach to hooking users into their ecosystem. Apple seems to be betting on devices integrated with iPhones and controlled with the kind of camera-based tech that powers the Apple Vision Pro headset. Meta seems to be aiming at replacing phones with an in-glasses display, and a biometric control scheme that works with muscle movements, like the existing neural band.\n\nBoth Meta and Apple seem to be competing to go beyond a screen or smart glasses to become the next interface for your life—but do people want that? Are consumers excited enough by the prospect of always-available AI and tied-together devices to buy them? That's the big question, and the answer is anything but certain. Both Apple and Meta have made big bets on virtual reality, and, despite both companies' VR devices being excellent, neither seems to have captured the market in way these firms would have liked. So, as they say, stay tuned.",
    "readingTime": 3,
    "keywords": [
      "neural band",
      "smart glasses",
      "smart watch",
      "display smart",
      "devices",
      "feature",
      "features",
      "apple",
      "reportedly",
      "users"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/rumors-suggest-apple-and-meta-are-betting-big-on-ai-wearables?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHVZDAVD0TAN6H7PS72TK8VY/hero-image.fill.size_1200x675.png",
    "created_at": "2026-02-20T01:08:33.144Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports",
    "title": "Nvidia, OpenAI near $30 billion investment in place of unfinished $100 billion deal, FT reports",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/nvidia-close-to-finalizing-30-billion-investment-in-openai-funding-round-ft-reports-4515044",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1J00P_L.jpg",
    "created_at": "2026-02-20T01:08:30.571Z",
    "topic": "finance"
  },
  {
    "slug": "tracekit-find-what-your-ai-coding-agent-wastes-money-on-and-fix-it",
    "title": "Tracekit: Find what your AI coding agent wastes money on and fix it",
    "description": "Find what your AI coding agent wastes money on and fix it. - 0xKoda/tracekit",
    "fullText": "0xKoda\n\n /\n\n tracekit\n\n Public\n\n Find what your AI coding agent wastes money on and fix it.\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n 0xKoda/tracekit",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/0xKoda/tracekit",
    "thumbnail_url": "https://opengraph.githubassets.com/11a5cf71ae84d57280c6b28ea6ee3a9767b0797fa5020046caf736f7ce11efb1/0xKoda/tracekit",
    "created_at": "2026-02-20T01:08:18.674Z",
    "topic": "tech"
  },
  {
    "slug": "amc-theatres-will-refuse-to-screen-ai-short-film-after-online-uproar",
    "title": "AMC Theatres Will Refuse to Screen AI Short Film After Online Uproar",
    "description": "AMC has opted out of screening the award-winning short film during its third-party programmed pre-show, and it’s unclear if other chains will follow suit.",
    "fullText": "When will AI movies start showing up in theaters nationwide?\n\nIt was supposed to be next month.\n\nBut when word leaked online that an AI short film contest winner was going to start screening before feature presentations in AMC Theatres, the cinema chain decided not to run the content.\n\nThe issue began earlier this week with the inaugural Frame Forward AI Animated Film Festival announcing Igor Alferov’s short film Thanksgiving Day had won the contest. The prize package for included Thanksgiving Day getting a national two-week run in theaters nationwide. When word of this began hitting social media, however, some were dismayed by the prospect of exhibitors embracing AI content, with many singling out AMC Theatres for criticism.\n\nExcept the short is not actually programmed by exhibitors, exactly, but by Screenvision Media — a third-party company which manages the 20-minute, advertising-driven pre-show before a theater’s lights go down. Screenvision — which co-organized the festival along with Modern Uprising Studios — provides content to multiple theatrical chains, not just AMC.\n\nAfter The Hollywood Reporter reached out to AMC about the brewing controversy, the company issued this statement to THR on Thursday: “This content is an initiative from Screenvision Media, which manages pre-show advertising for several movie theatre chains in the United States and runs in fewer than 30 percent of AMC’s U.S. locations. AMC was not involved in the creation of the content or the initiative and has informed Screenvision that AMC locations will not participate.”\n\nIt’s not yet clear if other theatrical chains will screen the short instead. Screenvision Media had no immediate comment, but the Frame Forward AI Animated Film Festival issued a statement from co-organizer MUS’s president and studio head Joel Roodman.\n\n“The national theatrical run, while truncated, is only an initial prize exposure for the winning film,” he said. “The film will be adapted for Celeste’s Massive Immersive theatrical venues, the first of which will be built in New York within the year. Shared theatrical experiences are an important cultural bond. The traditional theatrical chains are vital to our cohesion as a society, and are duly cautious [about AI]. However, the media landscape is changing and evolving rapidly. They may be prudent, but it is important to MUS immersive that new and exciting films, filmmakers, cinematic language, and spaces for these shared experiences continue to develop. We will bring new content, and important existing content, to our developing venue network of venues, starting in New York. We will not see the theatrical window wither on our watch.”\n\nThe film wouldn’t represent the first time AI content has played in theaters — a collection of film festival AI shorts from Runway’s 2025 AI Film Festival played in 10 Imax theaters in August. But this would likely be the first time a narrative AI film received nationwide exposure in cinemas rather than specialty screenings, and could represent another step in the groundbreaking technology marching into traditional Hollywood spaces.\n\nThe Thanksgiving Day film “follows a bear and his platypus assistant who are traveling through the galaxy in a spacecraft that looks like a dumpster. They have to deal with corrupt space-cops, hygiene officials, and a very unusual type of food delivery service as the story unfolds.”\n\nAccording to Deadline, Kazakhstani filmmaker Alferov used AI tools including Gemini 3.1 and Nano Banana Pro to make the short. Roodman said, “Thanksgiving Day is a masterclass in original storytelling, a wildly inventive journey that balances sharp satire with unexpected emotional payoff, proving that bold imagination with the tools of AI complements the future of animated filmmaking.”",
    "readingTime": 3,
    "keywords": [
      "frame forward",
      "film festival",
      "animated film",
      "theaters nationwide",
      "theatrical chains",
      "thanksgiving day",
      "screenvision media",
      "amc theatres",
      "content",
      "contest"
    ],
    "qualityScore": 1,
    "link": "https://www.hollywoodreporter.com/movies/movie-news/ai-short-movie-amc-theaters-1236509143/",
    "thumbnail_url": "https://www.hollywoodreporter.com/wp-content/uploads/2026/02/Thanksgiving-Day-H-2026.jpg?w=1296&h=730&crop=1",
    "created_at": "2026-02-20T01:08:17.666Z",
    "topic": "entertainment"
  },
  {
    "slug": "why-most-ai-agent-directories-are-basically-useless",
    "title": "Why Most AI Agent Directories Are Basically Useless",
    "description": "Let's be honest—most AI agent directories are just glorified link farms with the same 50 tools copy-pasted across them. Here's why that sucks, and what actually makes a directory worth your time.",
    "fullText": "Look. I've spent the last three months building AgentRank, and before that I wasted way too many hours scrolling through AI directories that all blur together into the same useless mess.\n\nYou know the ones. Pages and pages of logos, vague descriptions like \"AI-powered productivity tool,\" pricing that's always \"Contact for quote,\" and zero actual insight into whether the thing works or will waste your afternoon.\n\nIt's exhausting. And honestly? Kind of insulting.\n\nHere's what drives me nuts about 99% of AI agent directories out there:\n\nSeriously. Open three different \"AI tool directories\" and you'll see the exact same agents listed in almost the exact same order. ChatGPT, Claude, Jasper, Copy.ai. Cool. I could've Googled that.\n\nNobody's actually using half these tools. They're just scraping ProductHunt, slapping together a list, and calling it a day.\n\n2. The descriptions are worthless\n\n\"Revolutionizes workflows.\" \"Supercharges productivity.\" \"AI-powered innovation.\"\n\nGreat. What does it do? Can it write emails? Schedule meetings? Help me fix my leaky faucet? The marketing copy tells me nothing.\n\nI don't need your hype. I need to know if this tool solves my actual problem before I waste 20 minutes signing up and realizing it's useless.\n\nEvery listing is a press release. Five-star everything. \"Amazing!\" \"Game-changer!\" \"Must-have!\"\n\nZero honesty about what sucks. Zero comparison to alternatives. Zero \"this is great IF you need X, but terrible if you need Y.\"\n\nIf you're listing every tool as perfect, you're not helping me choose. You're just trying to collect affiliate fees.\n\nOh cool, another directory where everything is filed under \"productivity\" or \"AI assistant.\" Super helpful.\n\nI don't care that something is an \"AI agent.\" I care if it writes cold emails, debugs my code, or helps me find home repair contractors. Generic buckets don't cut it.\n\nHalf the listings are for tools that shut down six months ago or got acquired and nuked. Nobody's maintaining these directories. They're SEO graveyard.\n\nClick a link. Dead. Try another. 404. Great use of my time.\n\nHere's the thing—I'm not building AgentRank to be yet another link farm. I'm building it because I got fed up with the garbage out there.\n\nSo what makes a directory worth using? Here's my take:\n\nWhen I list a tool, I'm telling you what it's good at and where it falls short. Fixy's great for home repair DIY, but it's only on iOS right now. Claude's better for coding than ChatGPT, but costs more.\n\nHonesty. Specific use cases. Tradeoffs.\n\nIf I haven't actually used a tool, I'm not listing it.\n\n\"AI writing assistant\" doesn't help me. What I need to know is: Jasper vs Copy.ai for blog posts—which one gives me fewer robotic sounding paragraphs?\n\nReal comparisons based on actual use. Not feature charts, but \"here's when you'd pick A over B.\"\n\nI'm not filing Fixy under \"productivity.\" It goes under \"home improvement.\" Because that's what you'd search for when your toilet's running and you're trying to figure out if you can fix it yourself.\n\nContext matters. Use cases matter.\n\nDead tools get archived, not left to rot. Pricing is updated. Screenshots are recent. If something changed, the listing reflects it.\n\nNobody wants to waste time on outdated garbage.\n\nI'm not listing every AI tool that exists. If I wouldn't use it or recommend it, it's not going on AgentRank.\n\nThis started because I kept Googling \"best AI agent for X\" and getting the same recycled lists. Nothing useful. Nothing honest.\n\nSo I'm building the directory I wish existed:\n\nHonest takes on what's good and what sucks\n\nReal-world use cases, not buzzwords\n\nWill it be perfect? No. But it'll be a hell of a lot better than the copy-paste farms out there.\n\nI'm adding new agents every week. Real ones. Tested ones. With actual opinions attached.\n\nI'm also writing comparisons—head-to-head breakdowns of competing tools so you can make an actual informed decision instead of guessing.\n\nAnd I'm keeping the site fast. No 10-second load times, no popups begging for your email before you've seen a single listing. Just the info you need.\n\nIf you're tired of useless directories, bookmark AgentRank. Or don't—I'm building this for me either way.\n\nBut if you're as fed up as I was with the state of AI tool discovery, maybe you'll find it useful.\n\nGot an AI agent you think deserves to be listed? Drop me a note at hugh.e.mcinnis@gmail.com. If it's legit and solves a real problem, I'll test it and add it.\n\nNo press releases. No affiliate pitches. Just good tools that actually work.",
    "readingTime": 4,
    "keywords": [
      "tool i'm",
      "it's",
      "listing",
      "you're",
      "directories",
      "actual",
      "tools",
      "productivity",
      "here's",
      "useless"
    ],
    "qualityScore": 0.8,
    "link": "https://www.agentrank.tech/blog/why-most-ai-agent-directories-suck",
    "thumbnail_url": "https://www.agentrank.tech/images/blog/why-directories-suck.png",
    "created_at": "2026-02-20T01:08:17.423Z",
    "topic": "tech"
  },
  {
    "slug": "locus-ai-agents-that-ship-your-code",
    "title": "Locus – AI agents that ship your code",
    "description": "🤖 Local-first workspace for agentic engineering. Unified tasks, docs, and secure CI for AI agents.  - GitHub - asgarovf/locusai: 🤖 Local-first workspace for agentic engineering. Unified tasks, docs...",
    "fullText": "asgarovf\n\n /\n\n locusai\n\n Public\n\n 🤖 Local-first workspace for agentic engineering. Unified tasks, docs, and secure CI for AI agents. \n\n locusai.dev\n\n License\n\n MIT license\n\n 9\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n asgarovf/locusai",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/asgarovf/locusai",
    "thumbnail_url": "https://opengraph.githubassets.com/b63dbd0e9506cb8fd686db3b4aef23a4e9b788451c5637c101ba01d08eb7c340/asgarovf/locusai",
    "created_at": "2026-02-20T01:08:15.512Z",
    "topic": "tech"
  },
  {
    "slug": "sam-altman-says-the-quiet-part-out-loud-confirming-some-companies-are-ai-washing-by-blaming-unrelated-layoffs-on-the",
    "title": "Sam Altman says the quiet part out loud, confirming some companies are ‘AI washing’ by blaming unrelated layoffs on the technology",
    "description": "Some economists are warning there’s no sign of AI-related job displacement appearing in the labor data. Altman claimed it’s just a matter of time until it does.",
    "fullText": "As debate continues over AI’s true impact on the labor force, OpenAI CEO Sam Altman said some companies are engaging in “AI washing” when it comes to layoffs, or falsely attributing workforce reductions to the technology’s impact.\n\n“I don’t know what the exact percentage is, but there’s some AI washing where people are blaming AI for layoffs that they would otherwise do, and then there’s some real displacement by AI of different kinds of jobs,” Altman told CNBC-TV18 at the India AI Impact Summit on Thursday.\n\nAI washing has gained traction as emerging data on the tech’s impact on the labor market tells a muddied, inconclusive story about how the technology is destroying human jobs—or if it has yet to touch them.\n\nA study published this month by the National Bureau of Economic Research, for example, found that of thousands of surveyed C-suite executives across the U.S., the U.K., Germany, and Australia, nearly 90% said AI had no impact on workplace employment over the past three years following the late-2022 release of ChatGPT.\n\nHowever, prominent tech leaders like Anthropic CEO Dario Amodei have warned of a white-collar bloodbath, with AI potentially wiping out 50% of entry-level office jobs. Klarna CEO Sebastian Siemiatkowski suggested this week the buy-now, pay-later firm would reduce its 3,000-person workforce by one-third by 2030 in part because of the acceleration of AI. Around 40% of employers expect to follow Siemiatkowski’s lead in culling staff down the line as a result of AI, according to the 2025 World Economic Forum Future of Jobs Report.\n\nAltman clarified he anticipates more job displacement as a result of AI, as well as the emergence of new roles complementing the technology.\n\n“We’ll find new kinds of jobs, as we do with every tech revolution,” he said. “But I would expect that the real impact of AI doing jobs in the next few years will begin to be palpable.”\n\nData from a recent Yale Budget Lab report suggests Altman and Amodei’s vision of mass worker displacement from AI is not certain and is not yet here. Using data from the Bureau of Labor Statistics’ Current Population Survey, the research found no significant differences in the rate of change of occupations mix or length of unemployment for individuals with jobs that have high exposure to AI from the release of ChatGPT through November 2025. The numbers suggested no significant AI-related labor changes at this juncture.\n\n“No matter which way you look at the data, at this exact moment, it just doesn’t seem like there’s major macroeconomic effects here,” Martha Gimbel, executive director and cofounder of the Yale Budget Lab, told Fortune earlier this month.",
    "readingTime": 3,
    "keywords": [
      "yale budget",
      "budget lab",
      "jobs",
      "labor",
      "washing",
      "there’s",
      "displacement",
      "layoffs",
      "workforce",
      "exact"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/sam-altman-says-quiet-part-165405075.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/eOgz0omhtKugcAPCd_1t9w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03OTg-/https://media.zenfs.com/en/fortune_175/403bad20c006bad7663789ee0c3542fb",
    "created_at": "2026-02-20T01:08:13.477Z",
    "topic": "finance"
  },
  {
    "slug": "basaltcrm-opensource-ainative-crm-nextjs-16-prisma-typescript",
    "title": "BasaltCRM – Open-Source AI-Native CRM (Next.js 16, Prisma, TypeScript)",
    "description": "🚀 What's...",
    "fullText": "BasaltHQ\n\n /\n\n crm-official\n\n Public\n\n v1.2.0 - The Intelligent Workspace Update\n\n Compare\n\n Choose a tag to compare\n\n Sorry, something went wrong.\n\n Filter\n\n Loading\n\n Sorry, something went wrong.\n\n Uh oh!\n\n There was an error while loading. Please reload this page.\n\n No results found\n\n 🚀 What's New\n\nCRM University & LearnLink: Integrated educational deep-linking directly into the CRM workflow.\nKnowledge Base (KB): A full-featured KB view within CRM cases, allowing teams to search and reference articles during support.\nQuick Launch Checklist: A new interactive onboarding experience for members with session-persistent and permanent dismissal.\nProduct Tour Engine: Integrated guided walkthroughs of key dashboard features and icons.\nAccount Import Engine: Robust account ingestion system with dedicated UI and API routes for bulk data loading.\n\n✨ Enhancements & UX\n\nTerminology Refactor: Updated \"Lead Pools\" to \"Lists\" throughout the application for better industry alignment.\nUnified UI States: Centralized loading states and skeletons across all main CRM routes for a smoother feel.\nDynamic Profiles: Improved profile tab navigation with dynamic headers and optimized color picker state management.\nAI Theme Enforcement: Hardened theme inheritance for Tremor and Recharts components to ensure a consistent look across light/dark modes.\n\n🛠 Fixes & Infrastructure\n\nBiome Migration: Fully replaced ESLint/Prettier with Biome for 10x faster linting and formatting.\nPrisma 6.19 Upgrade: Hardened core database infrastructure and refined seeding scripts.\nSecurity: Implemented PCI-compliant payment redirects via BasaltSURGE, removing raw card inputs from the UI.\nCampaigns API: Refactored campaign creation and POST handling to improve reliability and input validation.\n\nSpecial thanks to @pdovhomilja for the original foundational work.",
    "readingTime": 2,
    "keywords": [
      "compare",
      "routes",
      "across",
      "infrastructure",
      "biome",
      "loading",
      "sorry",
      "integrated",
      "engine",
      "account"
    ],
    "qualityScore": 0.95,
    "link": "https://github.com/BasaltHQ/crm-official/releases/tag/v1.2.0",
    "thumbnail_url": "https://opengraph.githubassets.com/d1733b24eaa8dae14652b3c2c09c6782617f76f1ac55d91c9f7d9dc6c1888d05/BasaltHQ/crm-official/releases/tag/v1.2.0",
    "created_at": "2026-02-19T18:39:28.772Z",
    "topic": "tech"
  },
  {
    "slug": "agentlint-realtime-guardrails-for-ai-coding-agents",
    "title": "AgentLint – Real-time guardrails for AI coding agents",
    "description": "Real-time quality guardrails for AI coding agents. ESLint for agent behavior. - mauhpr/agentlint",
    "fullText": "mauhpr\n\n /\n\n agentlint\n\n Public\n\n Real-time quality guardrails for AI coding agents. ESLint for agent behavior.\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mauhpr/agentlint",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/mauhpr/agentlint",
    "thumbnail_url": "https://opengraph.githubassets.com/1966baa05dced63addca9df21165a336fe43285d39df6eeff757f44e00407358/mauhpr/agentlint",
    "created_at": "2026-02-19T18:39:28.341Z",
    "topic": "tech"
  },
  {
    "slug": "digital-blackface-flourishes-under-trump-and-ai-the-state-is-bending-reality",
    "title": "Digital blackface flourishes under Trump and AI: ‘The state is bending reality’",
    "description": "From TikTok deepfakes to smears put out by the White House, fake videos modeled on Black archetypes are running rampant - putting Black users at risk\nLate last year, as a US government shutdown cut off the Snap benefits that low-income families rely on for groceries, videos on social media cast the fallout in frantic scenes. “Imma keep it real with you,” a Black woman said in a viral TikTok post, “I get over $2,500 a month in stamps. I sell ’em, $2,000 worth, for about $1,200-$1,500 cash.” Another Black woman ranted about taxpayers’ responsibility to her seven children with seven men, and yet another melted down after her food stamps were rejected at a corn-dog counter.\nVisible watermarks stamped some videos as AI-generated – apparently, too faintly for the racist commentators and hustlers more than happy to believe the frenzy was real.",
    "fullText": "Late last year, as a US government shutdown cut off the Snap benefits that low-income families rely on for groceries, videos on social media cast the fallout in frantic scenes. “Imma keep it real with you,” a Black woman said in a viral TikTok post, “I get over $2,500 a month in stamps. I sell ’em, $2,000 worth, for about $1,200-$1,500 cash.” Another Black woman ranted about taxpayers’ responsibility to her seven children with seven men, and yet another melted down after her food stamps were rejected at a corn-dog counter.\n\nVisible watermarks stamped some videos as AI-generated – apparently, too faintly for the racist commentators and hustlers more than happy to believe the frenzy was real. “You got people treating it like a side hustle, selling the stamps, abusing the system,” the conservative commentator Amir Odom whinged. Fox News reported on the Snap deepfakes as if they were authentic, before issuing a correction. Newsmax anchor Rob Schmitt claimed people were using Snap “to get their nails done, to get their weaves and hair”. (Lost in the outrage was a basic fact: white Americans make up 37% of Snap’s 42 million beneficiaries.)\n\nThe fake videos are mere shards in the widening mosaic of digital blackface, a pattern that’s spiked in the past two years as generative AI video tools have become widely accessible. “There’s been a massive acceleration,” says Safiya Umoja Noble, a UCLA gender studies professor and author of Algorithms of Oppression, which focuses on digital biases against Black women in particular. “The digital blackface videos are really pulling from the same racist and sexist stereotypes and tropes that have been used for centuries.” The net effect is a patina of Blackness stripped of cultural obligation or stewardship – minstrelsy in a nutshell.\n\nCoined in a 2006 academic paper, the term digital blackface describes a form of Black cultural commodification repurposed for non-Black expression online. Examples run the gamut: posts in African American Vernacular English, the use of darker-skinned emojis, reaction memes featuring Beyoncé, Katt Williams and other exemplars of Black cool.\n\n“The early research that was done on digital blackface started with white gamers using bitmojis of a different race and changing their vernacular to represent themselves,” says Mia Moody, a Baylor University journalism professor whose forthcoming book, Blackface Memes, links the role of Black users in starting and spreading online trends to subsequent digital blackface. “That’s part of the cultural appropriation, gaining the cultural capital. Maybe you’re a nerdy white guy, but if you use this cool avatar of a Black guy with dreadlocks, people will give you respect. You’re interesting all of a sudden.”\n\nDuring memeology’s expansion into short-form video, Black expression has increasingly been divorced from authorship, context or consequence. Internet culture scholars say some non-white online creators use AI-generated avatars modeled on familiar Black faces – the beauty influencer, the culture podcaster, the man-on-the-street interviewer; they slip into feeds alongside real Black content creators. Large language models scour digital spaces that gained cachet from Black speech and humor, absorbing their tone and slang. Hume AI is one of many firms that offer synthetic voices for podcasts and audiobooks such as “Black woman with subtle Louisiana accent”, or “middle-aged African American man with a tone of hard-earned wisdom”. In most cases, creators whose speech is scraped from YouTube, podcasts and social media receive no compensation, much less even know their personalities shaped these models.\n\nThe Snap reaction clips, however, were a notable escalation in the mainstreaming of digital blackface – less blending in, more weapons-grade stereotyping. Many of those videos were created with OpenAI’s text-to-video app Sora. As Sora’s popularity surged in 2025, users exploited its hyperrealism to sully Martin Luther King Jr’s image, sparking ethical debate around “synthetic resurrection”. Deepfakes showed him shoplifting, wrestling Malcolm X, and swearing through his I Have a Dream speech. Conservative influencers swamped feeds with AI-generated embraces between King and Charlie Kirk, conflating their clashing legacies and cultural martyrdom. Bernice King, MLK’s daughter and the director of his Atlanta-based non-profit, criticized the slopaganda as “foolishness”.\n\nInevitably the Trump White House has gotten into the act. In January the official White House X account posted a doctored photo of Minnesota activist Nekima Levy Armstrong, darkened and weeping, in the wake of her arrest at a non-violent anti-ICE demonstration. Earlier this month an image portraying the Obamas as apes was circulated via Trump’s own Truth Social account.\n\nBlackface abides at the underbelly of American mass media even as it evolves at breakneck pace. Its roots trace to the minstrel revues of the early 19th century; white performers smeared grease paint made from charred corks on their faces and plastered on oversized white lips to caricature Black features, and performed exaggerated routines of Black laziness, buffoonery and hypersexuality. Thomas D Rice, a Manhattan playwright, shot to fame in the 1830s playing a loping trickster named Jim Crow – a name that quickly became shorthand for the forced racial segregation policies in the American south that endured until the 1964 Civil Rights Act.\n\nIn their heyday, minstrel shows were the dominant form of American entertainment – reflected in newspaper cartoons and the enormously popular Amos ‘n’ Andy radio shows. After the civil war, Black performers were largely forced into adopting minstrel elements, at the expense of their personhood once more, just to gain any footing on stage. “The objectives were, first, to make money to help educate our younger ones, and second, to try to break down the ill feeling that existed toward the colored people,” explained Tom Fletcher, a vaudeville minstrel and actor for almost 70 years who died in 1954.\n\nEven as minstrelsy faded from the spotlight by the early 20th century, its toxic residue lingered in American culture – from the shuffling crows of Disney’s Dumbo, to Ted Danson’s infamous 1993 blackface roast of Whoopi Goldberg, to the annual parade of white Halloween revelers in racial masquerade. A decade ago, when the internet was still a black box of sorts, researchers such as Noble and MIT’s Joy Buolamwini were sounding the alarm about the inherent racial biases in the coding of algorithms related to medical treatment, loan applications, hiring decisions and facial recognition. Now it’s out in the open, smearing wider and deeper than any burnt cork routine ever could.\n\nTech firms have made some effort to stem the tide of digital blackface. Bowing to public backlash, the King family and more prominent estates, OpenAI, Google and the AI image generator Midjourney disallowed deepfakes of King and other American icons. In January 2025, Meta deleted two of its own AI blackface characters – a retiree called Grandpa Brian and Liv, described as a “proud Black queer momma” and “truth-teller” – after allegations of their non-diverse development team fueled a tempest of criticism. Instagram and TikTok and more have made some attempts to scrub viral digital blackface videos, to tepid results. Last summer, efforts to replicate Bigfoot Baddie – the AI avatar of a Black woman as a human-yeti hybrid in pink wigs, acrylic nails and hair bonnets, created by Google’s Veo AI – erupted into a full-blown social media craze, with some users even hustling how-to courses. The avatar is still on socials.\n\nBlack in AI and the Distributed AI Research Institute (Dair) are among the handful of affinity groups that have pushed for diversity and community input in AI model-building to address programming bias. The AI Now Institute and Partnership on AI have highlighted the risks of AI systems learning from marginalized communities’ data and noted that tech companies could provide mechanisms such as data opt-outs to help limit harmful or exploitative uses. But widespread adoption has been glacial.\n\n“YouTube alone has something like 400 hours of content per minute being uploaded,” Noble says. “With AI generation, these tech firms cannot manage what’s coming through their systems. So they don’t. Or they do what’s absolutely imperative to the US government. But if you have an authoritarian regime in power, they can use your systems to facilitate propaganda.”\n\nAlthough the precise impact of AI-generated digital blackface is difficult to quantify, its use by the Trump administration highlights its potential as a powerful tool of official disinformation. The Obama Truth Social entry revived a slur that has festered for years in darker online corners, and one that rhymes with Trump’s sustained efforts to denigrate the former first family. (Trump disclaimed direct responsibility and refused to apologize for that post, which was taken down.) Meanwhile, the White House’s doctored image of Armstrong, altered from an actual photo taken by the Department of Homeland Security and published on their official Twitter account, scanned as a psyop by a government working closely with tech firms to track activists and other perceived enemies of the state.\n\nBeyond laundering bigotry as news, digital blackface exposes Black users to a level of personalized abuse and harassment that harkens to a minstrelsy heyday when racists were fully empowered to express their bigotry unbidden. And then just as now, it seems there is little that can be done to curb the vitriol. “We are living in a United States with an open, no-holds-barred, anti-civil-rights, anti-immigrant, anti-Black, anti-LGBTQ, anti-poor-policy agenda,” Noble says. “Finding the material to support this position is just a matter of the state bending reality to fit its imperatives. And that’s easily done when every tech company lines up behind the White House.”\n\nEven so, Moody remains hopeful that the current fascination with digital blackface will soon be as outdated and uninviting as the analog variant. She has seen this play before, after all. “Right now people are just experimenting with AI technology and having a ball seeing what they can get away with,” she says. “Once we get beyond that, then we’re going to see less of it. They’ll move on to something else. Or they’ll be up for a job, and it’ll be embarrassing. Just look at the history.”",
    "readingTime": 9,
    "keywords": [
      "black woman",
      "black users",
      "social media",
      "tech firms",
      "digital blackface",
      "blackface videos",
      "cultural",
      "ai-generated",
      "done",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/feb/19/ai-digital-blackface",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8ee6098a21dcbd6be64a80b0f2a64ccca202fbc0/0_180_800_640/master/800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d2fe071c5d198f9ea386e1c1340f1d9f",
    "created_at": "2026-02-19T18:39:05.278Z",
    "topic": "tech"
  },
  {
    "slug": "how-the-anxiety-over-ai-could-fuel-a-new-workers-movement",
    "title": "How the anxiety over AI could fuel a new workers’ movement",
    "description": "New technology has workers spooked, but experts say it’s creating an opening for a resurgence in worker power\nIn 2026, it’s a scary time to work for a living.\nGone are the days of quiet quitting, the Great Resignation, and the highly visible union-organizing battles that began the decade and signaled that perhaps worker power was on the rise again in the US. Instead, much of that momentum is being crowded out of our minds by anxieties: a worsening affordability crisis, geopolitical instability, and the specter of artificial intelligence looming over the workplace.\n Continue reading...",
    "fullText": "In 2026, it’s a scary time to work for a living.\n\nGone are the days of quiet quitting, the Great Resignation, and the highly visible union-organizing battles that began the decade and signaled that perhaps worker power was on the rise again in the US. Instead, much of that momentum is being crowded out of our minds by anxieties: a worsening affordability crisis, geopolitical instability, and the specter of artificial intelligence looming over the workplace.\n\nFor the tech CEOs leading the AI race and enriching themselves as they jostle for dominance, AI isn’t a phantasm at all, but a glimmering unicorn. When they predict AI is just months away from being able to do everything a software engineer does, or that it will one day take over CEOs’ jobs, their excitement for the future is palpable. For the rest of us, it’s hard to feel confident in their offhand remarks about how “some jobs will be obsolete, but many jobs will be created”. A 2025 Pew survey found that “64% of the public thinks AI will lead to fewer jobs over the next 20 years”, which is probably why only 17% of Americans say AI will have a positive effect on the US over the same time period.\n\nUncertain times like these call for scrutiny. Throughout 2026, the Guardian will publish Reworked, a reporting series that centers the human stakes as AI disrupts our workplaces, in ways both thrilling and alarming. Like this essay, the stories in this series will focus on workers’ real-world power and plights as well as the realities and exaggerations of the hype surrounding AI’s transformative possibilities.\n\nSo which version of the future of work awaits us? It is yet to be settled, which means there is still time to shift course.\n\nBlue-collar workers who have long grappled with algorithmic surveillance and optimization at work are now worrying that technological advancements will only make their jobs more dehumanizing. “[For] lower wage workers, there is concern about being replaced by robots. But on the other hand, there’s a lot of concern about being turned into robots,” Lisa Kresge, a senior researcher at the UC Berkeley Labor Center, told me.\n\nAnd white-collar workers are now wondering if their work will begin to resemble blue-collar labor – either because they will be similarly tracked and managed, or because they will need to switch to more manual work that’s resistant to being taken over by AI.\n\nIt may seem that workers haven’t been this vulnerable in a long time. In some ways, that’s true. But this is also a pivotal moment, one in which something unexpected is happening: society’s collective anxiety over AI is catalyzing workers to push back.\n\n“It is creating an opportunity,” Sarita Gupta, the Ford Foundation’s Vice President of US Programs and co-author of The Future We Need: Organizing for a Better Democracy in the Twenty-First Century, told me. “When you have a young Silicon Valley software engineer realize that their performance is tracked or undermined by the same logic as a working class warehouse picker, class divisions dissolve, and larger working-class movements for dignity are possible. That is what we’re starting to see.”\n\nPeople across industries and income brackets are anxious and frustrated, quite like they were when the Covid pandemic placed punishing demands on frontline workers and erased the boundaries between work and life for everyone else. Those struggles prompted power shifts: At the same time that workers led unionization efforts at Amazon warehouses and Starbucks locations around the US, the Great Resignation saw a record number of employees quit their jobs, and the ones who remained in the workforce began negotiating for and gaining better pay and conditions.\n\n“It was not a pretty time for a lot of workers. And so part of the resurgence of labor organizing from that period of time was in response to a lot of fears,” Kresge said.\n\nShe also sees the rise of AI as an opening for the labor movement to regain some of the power it’s lost after decades of attacks from employers. “I’m hopeful about the opportunity for technology to lift up some of the issues that have been under way in our economy for decades … in terms of how workers are treated and how we are distributing the rewards of productivity.”\n\nConditions for workers have been rough for a long while now. “Over time, unions have lost collective bargaining power, and a lot of that is due to the lack of laws that we need and enforcement of laws,” Gupta said. “For four decades, productivity soared while wages stayed flat, and unionization hit historic lows.” In 2025, only 9.9% of US workers were union members – the same percentage as 2024, but still the lowest numbers in almost 40 years.\n\nToday, the advent of AI is drawing the world’s attention to the extreme imbalance of power between employers and their employees – and people are getting worked up. Even if the outcomes are still undetermined, that’s a glimmer of possibility in bleak times.\n\nAI is still a nascent technology. Many of the predictions about what it will be capable of and how it will transform labor and the economy are just that – predictions. The question of worker power in the age of AI hasn’t been decided yet, even if billionaire CEOs with a vested interest in the unregulated dominance of AI keep implying that it has.\n\n“There is a concerted effort among many tech leaders to basically create mystification around AI as a tactic, to a large extent, to disempower workers, policymakers, and anyone who might be critical of the growing concentration of funding and resources in our society toward this goal,” Kresge told me.\n\nIn other words, take what these billionaires say with a grain of salt. The rise of AI is already transforming society, the economy, and our relationship to work, but a lot of these shifts are anticipatory, based on our belief in the potential of a technology that’s still being built.\n\n“We have to always remind ourselves that the direction of technology is a choice, right? We can use AI to build a surveillance economy that squeezes every drop of value out of a worker, or we can use it to build an era of shared prosperity,” Gupta said. “We know if technology were designed and deployed and governed by the people doing the work, AI wouldn’t be such a threat.”",
    "readingTime": 6,
    "keywords": [
      "software engineer",
      "workers",
      "jobs",
      "technology",
      "that’s",
      "economy",
      "it’s",
      "worker",
      "rise",
      "ceos"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/feb/19/ai-work-future",
    "thumbnail_url": "https://i.guim.co.uk/img/media/e4182b4a4822120bf8fbe8a4541c240fddc9c670/0_900_2204_1762/master/2204.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=c360a1093aefb03d0ea06d39596c24c9",
    "created_at": "2026-02-19T18:39:05.268Z",
    "topic": "tech"
  },
  {
    "slug": "bill-gates-drops-out-of-ai-summit-as-he-faces-heat-over-epstein-files",
    "title": "Bill Gates drops out of AI summit as he faces heat over Epstein files",
    "description": "A statement from the Gates Foundation said Bill Gates would not appear to \"ensure the focus remains\" on the India AI Impact Summit's key priorities.",
    "fullText": "Bill Gates pulled out of the India AI Impact Summit on Thursday, just hours before he was due to appear to give a keynote speech.\n\nThe Microsoft cofounder's decision to cancel his appearance at the high-profile event follows mounting scrutiny over his ties to Jeffrey Epstein.\n\n\"After careful consideration and to ensure the focus remained on the AI Summit's key priorities, Mr. Gates did not deliver the keynote address at the AI Summit,\" the Gates Foundation said in a statement provided to Business Insider.\n\nThe spokesperson added that Ankur Vora, the foundation's chief strategy officer and president of its Africa and India offices, had spoken instead.\n\n\"The Gates Foundation remains fully committed to our work in India to advance our shared health and development goals,\" they added.\n\nGates's interactions with Epstein have faced scrutiny after the Justice Department released 3 million emails related to the late sex offender. One of the emails, with the subject line \"bill,\" suggested that Gates requested medication for a sexually transmitted disease to give to his now ex-wife, Melinda French Gates.\n\n\"These claims are absolutely absurd and completely false,\" a spokesperson for Gates told Business Insider in a statement earlier this month. \"The only thing these documents demonstrate is Epstein's frustration that he did not have an ongoing relationship with Gates and the lengths he would go to entrap and defame.\"",
    "readingTime": 2,
    "keywords": [
      "gates foundation",
      "keynote",
      "scrutiny",
      "statement",
      "emails",
      "india",
      "bill",
      "summit",
      "epstein",
      "business"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/bill-gates-drops-out-india-ai-summit-epstein-controversy-2026-2",
    "thumbnail_url": "https://i.insider.com/69970860f8731049f3af6100?width=1200&format=jpeg",
    "created_at": "2026-02-19T18:39:03.055Z",
    "topic": "finance"
  },
  {
    "slug": "emails-show-godfather-of-agi-ben-goertzel-courted-epstein-for-funding-and-congratulated-him-on-jail-release",
    "title": "Emails show 'Godfather of AGI' Ben Goertzel courted Epstein for funding and congratulated him on jail release",
    "description": "Ben Goertzel accepted money from Jeffrey Epstein to build the \"Sputnik of AI.\" He says he \"made a mistake\" by not doing due diligence.",
    "fullText": "In January 2013, Jeffrey Epstein sent a blunt email to the computer scientist Ben Goertzel. Epstein had funded Goertzel's research in artificial intelligence and was frustrated with a lack of progress. However, on this day, the disgraced financier wasn't writing to discuss algorithms or neural networks — he wanted to discuss Goertzel's hair.\n\n\"I think it is now time for you to drop the hippie look,\" Epstein wrote, warning Goertzel that his \"disheveled 80s appearance\" was an \"unnecessary hindrance\" to securing the capital that might one day help the two men achieve AGI — artificial general intelligence, a hypothetical level of computer intelligence that could surpass that of humans. Epstein compared the scientist's ponytail to \"spinach in the teeth of a friend.\"\n\n\"I would be willing to cut my hair for a lot of AGI money,\" Goertzel replied.\n\nThe exchange was among dozens between Epstein and Goertzel in files released by the Department of Justice, chronicling Epstein's fascination with the potential of AI. Goertzel, a researcher who helped popularize the term AGI and develop the humanoid robot Sophia, courted Epstein for money over several years, promising he could build the \"Sputnik of AI,\" the emails show.\n\nIn an online résumé that has since been removed, Goertzel said Epstein gave him a $100,000 research grant in 2001. Emails reviewed by Business Insider show Epstein agreed to give Goertzel at least another $100,000 between 2008 and 2018, spread out across multiple transfers. It could not be learned how much of the money Goertzel ultimately received.\n\nThe emails show Goertzel was aware of Epstein's criminal charges. In a 2010 email, Goertzel congratulated Epstein on his release from the Palm Beach County Jail. In 2008, Epstein had pleaded guilty to two sex charges, including solicitation of a minor. In 2015, several days after Prince Andrew was named in a lawsuit over underage sex claims related to Epstein, Goertzel wrote about \"utterly idiotic negative publicity in the news\" and said he was sorry Epstein's camp had to deal with it.\n\n\"Maybe some variation of what is alleged did happen, but if so it was surely an occurrence among reasonably mature people who mutually consented at the time, so why is it anybody else's business?\" Goertzel wrote, before asking for $25,000 for a \"corporate contribution\" to one of his companies.\n\nIn a statement to Business Insider, Goertzel said he \"made a mistake\" in accepting Epstein's money. He said he regretted not doing due diligence on Epstein's crimes and that he had \"basically zero knowledge of Epstein's sexual peculiarities and exploitative practices.\"\n\nHe added: \"I deeply regret being social-engineered by this terrible human being and not doing more research into him decades ago. I won't make this sort of mistake again.\"\n\nGoertzel is currently the CEO of SingularityNET, an AI and blockchain company. He is also chair of The AGI Society, a nonprofit that holds an annual AI conference.\n\nHis correspondence with Epstein was among millions of documents released by the Justice Department. The files have reverberated through the business world, revealing emails between Epstein and Tesla CEO Elon Musk, Virgin founder Richard Branson, LinkedIn founder Reid Hoffman, among others. The fallout for some people named in the files has been swift. Goldman Sachs' top lawyer, Kathryn Ruemmler, resigned in mid-February, and Brad Karp resigned as chairman of the law firm Paul Weiss, among others.\n\nAppearing in the files does not necessarily suggest that a person has engaged in wrongdoing.\n\nIn one of the emails released by the Justice Department, Goertzel said he had known Epstein since 2001. Epstein took an interest in what labs like MIT and Google were doing in the AI field. Goertzel, who some consider one of the \"godfathers of AGI,\" coauthored a 2006 book on the topic, and in 2008, he created OpenCog, an open-source project to try to architect human intelligence. Goertzel told Business Insider that he met Epstein through \"mutual friends\" in New York City.\n\nEpstein appeared concerned in some emails by the lack of support for Goertzel's AGI theories among mainstream experts. \"i believe in you. i can't figure out why i am in the minority,\" he told Goertzel in 2010. In a 2011 email, Goertzel asked if Epstein would fund half of a $3 million grant over four years to fund a \"full speed ahead toward AGI\" plan, which included building AI that could control a video game character and a humanoid robot.\n\n\"Of course, US$3M is a lot of money. However, this would be the 'Sputnik of AGI' -- it would set the development of AGI on a whole new course,\" Goertzel wrote.\n\nIn his statement to Business Insider, Goertzel said, \"I had basically zero knowledge of Epstein's sexual peculiarities and exploitative practices and have no orientation toward that sort of thing and little understanding of it -- it was all about being overly desperate at that stage for any source of $$ to fund innovative frontier science, which Epstein did recognize as valuable but mainstream science at the time did not.\"\n\nEpstein sometimes pushed Goertzel for more tangible proof of breakthroughs and tried to influence some research directions, the emails show. In February 2013, he emailed Goertzel and suggested that having an AI system pass \"iq tests for children\" would provide a concrete research milestone. Goertzel agreed to pursue the idea.\n\n\"Epstein was very smart and fairly technically savvy and had a lot of ideas about AI, which were not terribly stupid nor terribly brilliant,\" Goertzel told Business Insider. \"I did not pay much attention to them nor did they influence my work in any way.\"\n\nEpstein used corporate and foundation vehicles to send money to Goertzel, including his Southern Trust Company, registered in the US Virgin Islands, the emails show.\n\n\"As before, we can do this as a tax-deductible donation to a nonprofit, assuming that's still your preference,\" Goertzel said in a September 2010 email to Epstein.\n\nDepending on the circumstances, Goertzel, who spent some of his time in Hong Kong, requested that the money be sent to different nonprofits' accounts, the emails show. In 2014, Goertzel requested that Epstein send the money to Humanity+, a nonprofit focused on transhumanism that he was vice president of. Goertzel said it would act as a fiscal \"pass-through\" so the money could be diverted to himself and other researchers.\n\n\"Yes all this was totally legit, the funding was going to open-source AGI R&D for the good of humanity and its future, which was very much within the mandate of Humanity+ as a 501-3c nonprofit,\" Goertzel told Business Insider.\n\nGoertzel told Business Insider he \"reconnected\" with Epstein in 2008 after several years of no contact, and that Epstein told him about his legal situation.\n\n\"He framed it as a politically motivated prosecution for involvement with a consenting adult. I believed him. I should not have,\" Goertzel told Business Insider.\n\nSeveral emails show Goertzel and Epstein arranging to meet in person. Goertzel told Business Insider they met on several occasions at Epstein's New York and Florida offices. \"I never hung out with him in a social setting, never went to the island or flew in the jet or saw him partying with girlfriends or anything like that,\" he said.\n\nIn 2015, Goertzel was following up on a payment he hoped to receive from Epstein. Richard Kahn, Epstein's accountant, responded that it had to be put on hold due to \"bad press.\" The Guardian had reported days earlier that Prince Andrew was named in a US lawsuit involving Epstein.\n\n\"I don't want to push you guys at a difficult time, but given my own situation I do feel moved to ask if Jeffrey might still be able to help with $25K for my 'corporate contribution' to the OpenCog Hong Kong project,\" Goertzel wrote. \"He has helped in this way every year since 2010, usually via a donation to Humanity+.\"\n\nThe South China Morning Post reported earlier on some of the payments Epstein made to Goertzel to help him secure Hong Kong grants.\n\nEpstein responded, \"yes 25,\" and Goertzel thanked him and said he hoped to resume conversations \"once this current moronic media shitstorm blows over.\"\n\nEmails between the men continued for several years. In December 2018, a few days after the Miami Herald published an investigation into Epstein that contributed to his arrest on federal sex-trafficking charges the next year, Goertzel sent an email inviting Epstein to an AI and blockchain event in New York. Alternatively, he said, they could find another time to meet in the city.\n\n\"let me know if you're in town and might spare a few moments,\" Goertzel wrote. \"it's been a while!\"\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at 628-228-1836. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 8,
    "keywords": [
      "justice department",
      "epstein's sexual",
      "humanoid robot",
      "zero knowledge",
      "sexual peculiarities",
      "exploitative practices",
      "corporate contribution",
      "among others",
      "business insider",
      "business insider goertzel"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ben-goertzel-jeffrey-epstein-agi-researcher-emails-jail-2026-2",
    "thumbnail_url": "https://i.insider.com/6996fb69f8731049f3af60c6?width=1200&format=jpeg",
    "created_at": "2026-02-19T18:39:02.814Z",
    "topic": "science"
  },
  {
    "slug": "josh-kushner-uses-lord-of-the-rings-to-explain-what-being-close-to-openai-taught-him-about-perceived-power",
    "title": "Josh Kushner uses 'Lord of the Rings' to explain what being close to OpenAI taught him about perceived power",
    "description": "\"Sam, Greg, OpenAI have the Ring, and everyone is willing to do whatever they can to take it,\" said Kushner, whose VC firm is a big OpenAI backer.",
    "fullText": "The way one of OpenAI's biggest backers sees it, Sam Altman and his AI company are in possession of Tolkien's the One Ring — and that puts a target on their backs.\n\nJosh Kushner's firm, Thrive Capital, is one of OpenAI's biggest investors. Backing the high-flying tech AI startup has given him a front-row seat to how people behave when power and value become concentrated in a single company.\n\nIn a recently published interview with Colossus Magazine, recorded in October, Kushner reflected on the chaos surrounding the temporary ouster of OpenAI CEO Sam Altman in November 2023. The company's president, Greg Brockman, also briefly resigned during the incident.\n\n\"To use the Lord of the Rings analogy,\" Kushner said, \"Sam, Greg, OpenAI have the Ring, and everyone is willing to do whatever they can to take it.\"\n\nWhen asked whether he believes power corrupts, Kushner answered simply: \"Yes.\"\n\nKushner did not specify who he was referring to. Thrive Capital declined to comment further when contacted by Business Insider.\n\nBut the investor has previously described the immediate aftermath of Altman's firing on November 17, 2023, saying Thrive \"immediately went to war\" after learning of the decision.\n\n\"There is so much perception of power and value associated with this company,\" he told Colossus, saying he was \"very proud of how the company has handled itself, despite many people not acting in as appropriate ways.\"\n\nAltman was reinstated days later following pressure from employees and investors, in one of the most dramatic governance crises in Silicon Valley.\n\n\"During that crazy week where I got fired and rehired, he just put his entire life on hold,\" OpenAI's CEO told the magazine about Kushner.\n\nKushner founded Thrive Capital in 2009. The firm has backed companies including Instagram, Stripe, Robinhood, Instacart, and OpenAI, and recently closed a $10 billion fund heavily focused on AI.\n\nHe is also the younger brother of Jared Kushner, President Donald Trump's son-in-law, and is married to supermodel Karlie Kloss. His estimated net worth sits at $5.2 billion, according to Forbes.",
    "readingTime": 2,
    "keywords": [
      "openai's biggest",
      "thrive capital",
      "kushner",
      "firm",
      "investors",
      "recently",
      "president",
      "saying",
      "altman",
      "openai"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/josh-kushner-lord-of-the-rings-openai-power-ring-2026-2",
    "thumbnail_url": "https://i.insider.com/6996283ff8731049f3af5893?width=1200&format=jpeg",
    "created_at": "2026-02-19T18:39:02.404Z",
    "topic": "finance"
  },
  {
    "slug": "ais-top-leaders-got-corralled-into-holding-hands-it-made-for-a-photo-op-for-the-ages",
    "title": "AI's top leaders got corralled into holding hands. It made for a photo op for the ages.",
    "description": "Demis Hassabis, Sundar Pichai, Brad Smith, Sam Altman, and Dario Amodei lined up with Indian Prime Minister Narendra Modi at an AI conference.",
    "fullText": "The world's biggest AI leaders gathered in New Delhi this week, prepared to talk about the latest models and their impact on societies. They seemed less prepared for a 14-person hand-hold that tech circles will remember for a long time.\n\nOn Thursday, top executives, including Demis Hassabis, Sundar Pichai, Brad Smith, Sam Altman, and Dario Amodei, lined up on stage with Indian Prime Minister Narendra Modi at the India AI Impact Summit.\n\nIn his signature style, Modi held hands with Pichai on his right and Altman on his left and began raising their linked arms for a celebratory photo. Modi has previously taken photos this way with world leaders, including former US President Joe Biden and EU Commission President Ursula von der Leyen.\n\nThe other tech execs were quick to catch on to Modi's directive, looking right and left before grabbing their neighbour's hand.\n\nThe photo op's most meme-worthy scene was the OpenAI and Anthropic CEOs not managing — or refusing— to hold each other's hands. After a pause, they raised their arms without making contact.\n\nThe moment was widely screenshotted and shared on social media.\n\nLOL at Sam and Dario not holding hands pic.twitter.com/dmmUYHGWkj\n\nThe awkward moment followed a Super Bowl advertising jab between the two AI giants earlier this month. Anthropic's 30-second commercial roasted OpenAI over its decision to bring ads to ChatGPT.\n\nAfter Anthropic released a series of Super Bowl ad teasers, Altman responded with a lengthy post on X, calling the Anthropic ad \"dishonest.\"\n\nAmodei cofounded Anthropic in 2021 after leaving OpenAI, citing disagreements over AI safety priorities and the lab's leadership style.",
    "readingTime": 2,
    "keywords": [
      "super bowl",
      "altman",
      "modi",
      "leaders",
      "prepared",
      "impact",
      "tech",
      "pichai",
      "amodei",
      "style"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-leaders-india-summit-awkward-photo-hands-modi-altman-amodei-2026-2",
    "thumbnail_url": "https://i.insider.com/6996ce20a645d118818991da?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.428Z",
    "topic": "finance"
  },
  {
    "slug": "salesforce-is-all-in-on-ai-an-internal-survey-reveals-how-employees-feel-about-it",
    "title": "Salesforce is all in on AI. An internal survey reveals how employees feel about it.",
    "description": "Salesforce's internal survey reveals employee opinions on AI adoption. CEO Marc Benioff has touted AI as a major productivity driver.",
    "fullText": "Salesforce says it's at the vanguard of the AI revolution and has even toyed with renaming itself Agentforce in honor of its bet on AI agents. The company is rapidly adopting AI internally as well, and a survey obtained by Business Insider reveals how that's actually playing out behind the scenes.\n\nThe results — which were broadly positive — show that most employees feel AI is increasing their productivity, although fewer say it's lightening their workloads.\n\nSalesforce's annual \"Great Insights\" survey, which is not public, was conducted in November 2025 and released inside the software company the following month. It surveyed about 80% of the 76,000-person workforce.\n\nMost questions about AI received high favorability ratings: In addition to the 81% of employees who said AI tools boost productivity, 83% said they feel equipped to handle AI risks such as bias, and 81% said they felt encouraged to experiment with AI.\n\nMore than half of employees — 57% — said AI tools helped their team identify opportunities that would have been impossible otherwise. And 62% said their workload is more manageable because they use AI tools. Both of these were among the lowest results in the survey.\n\nSalesforce told Business Insider in a statement that the survey showed significant gains in AI use and strong enthusiasm. A composite it creates called the AI Readiness score was at 85% enterprise-wide, an 18% gain year-over-year.\n\n\"We're thrilled that our employees have moved on from adoption and are seeing AI tools make a meaningful impact in their daily work,\" a Salesforce spokesperson said.\n\nThe results suggest that Salesforce is ahead of the pack on encouraging AI adoption, said Jason Schloetzer, an associate professor at Georgetown University's business school who has interviewed dozens of executives about AI adoption. The results also show that, for some employees, AI intensifies their workload rather than reducing it.\n\n\"The gaps suggest people believe AI is enabling them to do more work, but it's not making their work easier,\" he said.\n\nSalesforce, which sells customer relationship management software, has garnered attention for an intense AI push led by CEO Marc Benioff. Last August, he said half of the work at Salesforce was being done by AI and that the company had eliminated 4,000 support roles because of AI agents.\n\nSalesforce's website says the company uses a mix of internal AI tools, including an AI from Salesforce-owned Slack that can quickly find old project templates, and Career Connect, which analyzes employees' strengths and weaknesses to help them move within the company.\n\nSalesforce is facing challenges despite its embrace of the AI revolution. Its stock is down over 40% in the past year as concerns mount about the fate of legacy software companies amid the arrival of AI tools from OpenAI and Anthropic.\n\nThe company has also struggled to deliver on promises made in demos of its AI product Agentforce, Business Insider previously reported.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "employees",
      "tools",
      "survey",
      "it's",
      "software",
      "adoption",
      "salesforce",
      "revolution",
      "agents"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/salesforce-survey-employees-ai-impact-tasks-output-2026-2",
    "thumbnail_url": "https://i.insider.com/698bc5b8d3c7faef0ece0a33?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.411Z",
    "topic": "finance"
  },
  {
    "slug": "openai-has-a-hollywood-problem-they-just-hired-a-guy-to-fix-it",
    "title": "OpenAI has a Hollywood problem. They just hired a guy to fix it.",
    "description": "OpenAI just poached the celebrity whisperer Charles Porch away from Instagram. It makes sense when you consider how anti-AI some celebs have been.",
    "fullText": "A \"detriment\" to human creativity, said Vince Gilligan, creator of \"Breaking Bad\" and \"Pluribus\" about AI. \"Horrifying,\" said James Cameron about the possibility of AI actors. \"I'd rather die,\" said Guillermo del Toro. \"Incredibly destructive,\" said Cate Blanchett.\n\nIt's not hard to see why OpenAI recognizes it has a bit of an image problem among some people in Hollywood. It appears that the company is now trying to change that.\n\nOpenAI just poached Charles Porch from Meta, where he oversaw celebrity partnerships for over a decade, as Vanity Fair reported earlier. Porch is generally recognized for helping make Instagram the cultural juggernaut it is today by helping celebrities who might have been confused by or disinterested in newfangled social media join and use the platform.\n\nPorch has deep connections in the entertainment industry — celebrities like Harry Styles attended his lavish wedding this summer in France.\n\nPorch wrote on his personal Instagram about his job change:\n\n\"From helping Beyoncé figure out how to launch an album exclusively on social media to onboarding Pope Francis to Instagram (he held my hands and asked me to pray for him) to watching creators become the next generation of entrepreneurs, the impact on culture that me and the team have been able to have is something that I take great pride in.\"\n\nIt's not clear exactly what Porch's new gig will entail. He told Vanity Fair that his first step will be to go on a \"listening tour\" to hear the hopes and fears about AI from creatives and celebrities. I've asked OpenAI for comment.\n\nFor Hollywood actors, filmmakers, and studio executives, those fears are pretty big. Why wouldn't Brad Pitt be alarmed to see a passably real AI-generated version of himself in a fist-fight against Tom Cruise?\n\nThe idea that AI could replace actors, screenwriters, and other creatives is alarming, especially as Hollywood as an industry is hurting. Box office sales haven't bounced back from the pandemic, streaming is complicated, fewer and fewer projects are being made, and efforts to cut costs by filming overseas have devastated Los Angeles' middle-class of film industry workers.\n\nOn top of that, AI is, as far as I can tell, widely considered a theft machine that gobbled up tons of images and videos from movies and TV for training data, largely without permission or compensation.\n\nYou can see a filmmaker or actor's point of view here: They stole my face and my work to build this tool, and now they want to use it to make soulless slop that will undercut the value of my work?\n\nNot great! I imagine Porch has his work cut out for him.\n\nOpenAI and other AI companies have started making deals with Hollywood. Disney made a $1 billion deal with OpenAI around the time Sora 2 launched, licensing Disney characters like Mickey Mouse and Darth Vader, and also becoming a customer and investor in OpenAI. Lionsgate and AMC made deals allowing their catalogs to be used for training Runway. (Business Insider, through our parent company, has a somewhat similar deal with OpenAI.)\n\nBut those deals with studios, while they might stave off copyright lawsuits and create some cash flow, aren't winning over the hearts and minds of the celebrities and creatives — the kinds of people who make headlines when they call AI \"horrifying.\"\n\nPerhaps OpenAI is realizing that celebrities still hold the kind of cultural capital that can't be built in the Bay Area. And while OpenAI has been pretty successful in pushing its agenda in Washington, thanks to an AI-friendly administration, it still has an uphill battle to win over the general public, which remains fairly skeptical of AI.\n\nAnd for that, you need to get the celebs on board. There's a beautiful irony now that these big AI companies are paying big bucks to hire human writers, and VCs are now obsessed with the concept of \"taste.\"\n\nIt turns out that kinds of \"soft skills\" that had long been undervalued in Silicon Valley are more relevant than ever now that AI can do a lot of the technical work. And someone like Charles Porch, who has the connections and ability to charm a roomful of Hollywood types and other cultural elites, is more valuable than ever. That's the kind of job AI can't take.",
    "readingTime": 4,
    "keywords": [
      "social media",
      "charles porch",
      "vanity fair",
      "celebrities",
      "actors",
      "instagram",
      "cultural",
      "industry",
      "creatives",
      "deals"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-hollywood-charles-porch-meta-celebrities-2026-2",
    "thumbnail_url": "https://i.insider.com/699636aef8731049f3af5b49?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.250Z",
    "topic": "finance"
  },
  {
    "slug": "several-meta-employees-have-started-calling-themselves-ai-builders",
    "title": "Several Meta employees have started calling themselves 'AI builders'",
    "description": "Meta's shift to AI builders is redefining roles, as product managers adopt AI coding tools for increased productivity and innovation.",
    "fullText": "Meta product managers are rebranding. Some are now calling themselves \"AI builders,\" a signal that AI coding tools are changing who gets to build software inside the company.\n\nOne of them, Jeremie Guedj, announced the change in a LinkedIn post last week. \"I still can't believe I'm writing this: as of today, my full-time job at Meta is AI Builder,\" he wrote.\n\nGuedj has spent more than a decade as a traditional product manager, a role that sets the road map and strategy for products then built by engineering teams. He said that while his title in Meta's internal systems still lists him as a product manager, his actual work is now full-time building with AI on what he calls an \"AI-native team.\"\n\nAnother Meta product manager also lists \"AI Builder\" on her LinkedIn profile, while at least two other Meta engineers write the term in their bios, Business Insider found.\n\nThe shift aligns with a message CEO Mark Zuckerberg expressed on Meta's most recent earnings call: 2026 is when AI tools would meaningfully reshape how work gets done inside the company. AI coding tools have already shaken up the tech industry, allowing more people with fewer technical skills to build apps from scratch.\n\n\"We're investing in AI-native tooling, so individuals at Meta can get more done,\" Zuckerberg said. \"We're elevating individual contributors and flattening teams. We're starting to see projects that used to require big teams now be accomplished by a single very talented person.\"\n\nGuedj's role reads like a practical expression of that vision. In his post, he described his team as one \"where data and knowledge are AI-friendly at their core, and where humans and AI agents work together, synchronously and asynchronously.\"\n\nMeta did not respond to a request for comment from Business Insider.\n\n\"AI builder\" isn't a formal Meta designation, at least not yet. Guedj acknowledged it isn't his official title.\n\nOne Meta employee who wished to stay anonymous because they weren't authorized to speak to the press said that the label is not an official role and is more likely an experiment within a specific organization as Meta pushes toward AI-native teams across the company. Reality Labs, Meta's division responsible for its smart glasses and virtual reality efforts, is one of those organizations, this person said.\n\n\"Software engineers are becoming product managers and product managers becoming software engineers,\" they added. \"The idea is to make individual contributors more productive.\"\n\nInside Meta, the drift from coordinator to builder has been visible for months. In November, Joseph Spisak, a product director in Meta's Superintelligence Labs, said that product managers at the company were vibe-coding prototypes and showing them directly to Zuckerberg.\n\n\"We can literally vibe code products in a matter of hours, days, and explore the space,\" Spisak said.\n\nIn January, another Meta product manager, Zevi Arnovitz, said on a podcast that using AI coding tools felt like being handed \"superpowers.\" Arnovitz, who said he has no technical background, described rebuilding his workflow around AI — operating less like a conductor moving work between engineering and design and more like a product owner who can execute.\n\nSome companies are moving beyond experimentation. In December, LinkedIn scrapped its long-running associate product manager program and replaced it with an associate product builder track.\n\nTomer Cohen, LinkedIn's chief product officer at the time, said on a podcast that the company wanted to train new hires who can code, design, and manage products — people \"who can flex across\" traditional role boundaries.\n\nLast year, Madhu Gurumurthy, the company's product head for AI models, tweeted that the company was moving to a \"building-first\" culture. In an age of vibe-coding, Gurumurthy said, product managers can show, not tell. \"Role profiles are blurring, creativity and building are happening in parallel,\" he wrote.\n\n\"Each company is approaching this differently and is still figuring this out,\" one product manager at Google, who wished to stay anonymous, told Business Insider. \"I've been encouraging designers and product managers on my team to blur roles a bit.\"\n\nAs Guedj, the self-proclaimed Meta AI builder, put it: \"Building has always been my passion. AI gave me the ability to turn ideas into real, working apps. That changed everything.\"\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "individual contributors",
      "coding tools",
      "software engineers",
      "product managers",
      "product manager",
      "associate product",
      "meta product",
      "ai builder",
      "role",
      "teams"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-pms-ai-builders-tech-industry-2026-2",
    "thumbnail_url": "https://i.insider.com/69950d45f8731049f3af4ab0?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.232Z",
    "topic": "finance"
  },
  {
    "slug": "theres-been-a-surge-in-ai-use-recently-heres-whats-behind-it",
    "title": "There's been a surge in AI use recently. Here's what's behind it.",
    "description": "AI token processing has soared recently on OpenRouter, while Nvidia GPU rental prices have jumped.",
    "fullText": "AI demand has surged in recent weeks, according to new data that could support tech giants' decisions to dramatically ramp up investment in this area.\n\nOpenRouter, which helps developers access different AI models, has seen activity roughly double in the first weeks of 2026.\n\nThis is measured by the number of AI tokens OpenRouter processes. AI models break down words and other inputs into numerical tokens to make them easier to process and understand. One token is about ¾ of a word.\n\nOpenRouter handled 13 trillion AI tokens in the week that ended February 9. That's up from 6.4 trillion during the first week of January.\n\nSeen over a year, this recent surge is even more striking. AI models that OpenRouter taps into include Google's Gemini, Anthropic's Claude, xAI's Grok, OpenAI's GPT range, and a host of open-source offerings from DeepSeek, Moonshot AI, and others.\n\nThis data excludes AI tokens processed directly by the major AI companies, so it represents a small fraction of total activity. For instance, Google was processing 1.3 quadrillion tokens a month this past summer. However, the recent rate of change in OpenRouter's data is a valuable signal.\n\nAnand Iyer, a partner at VC firm Lightspeed, said the recent surge has been driven by an explosion in AI agent activity and especially the rapid emergence of OpenClaw, an open-source agentic system.\n\nThat's sparked an exponential increase in inference, which is how models, agents, and other AI services are run in the cloud.\n\n\"The demand for AI inference right now is coming from agentic platforms, especially OpenClaw,\" Iyer told Business Insider this week. \"We moved from simple chatbot experiences to agentic automation and execution, which has driven exponential growth of OpenClaw installations and OpenRouter usage.\"\n\nThere are other signs of rising AI use. Data compiled by Bloomberg suggests demand for Nvidia AI chips has increased lately. The chart below shows the cost to rent Nvidia H100 GPUs. As you can see, prices have rebounded strongly since early December, which implies robust AI demand.\n\nOpenClaw launched in November 2025. That coincides with the H100 rebound here.\n\nA third data point comes from Barclays analysts, who recently looked at online traffic to vibe coding services, including Lovable, Replit, and Wix's Base44.\n\nThe consumer website-based vibe coding services Barclays tracks saw traffic jump 17% month over month in January.\n\n\"This was the strongest growth since April 2025,\" the analysts wrote in a note to investors this week. \"The uptick in interest here was driven largely by frontier model improvements in late 2025 that made these platforms more effective.\"\n\nThe debate still rages over whether AI will be used enough to justify all the heavy investments being made. Big Tech companies recently increased capital expenditure plans to eye-watering levels, raising new concerns about a potential AI bubble.\n\nThis new AI usage data may suggest that demand could be strong enough to support such heavy spending.\n\n\"AI capex today, as we know it today, is largely driven by training requirements from large frontier labs,\" Iyer said.\n\nTraining is a data- and energy-intensive process in which AI models are created in massive data centers. Inference comes after models are run.\n\n\"The sustainability is warranted as long as the revenue produced by inference (which is growing exponentially) will justify the output from the training,\" Iyer said. \"Which seems to be working so far.\"\n\nOpenClaw is part of a broader evolution of generative AI. The era kicked off with a bang when OpenAI launched ChatGPT in late 2022, and the chatbot became the fastest-growing tech product in history.\n\nMore recently, AI models have begun to support autonomous digital agents and similar tools that can use computers independently to accomplish complex tasks.\n\nOpenClaw's open-source technology supports agents that help users automate coding and other workflows by accessing computer files, email, calendars, and messaging services.\n\nIn January, Anthropic unveiled Claude Cowork, an AI agent that handles tasks such as document generation and file management.\n\nThe startup rolled out Claude Sonnet 4.6, its latest AI model, this week. It's gotten better at what Anthropic calls \"computer use,\" where AI models and agents use computers in similar ways to humans to get tasks done.\n\n\"The model sees the computer and interacts with it in much the same way a person would: clicking a (virtual) mouse and typing on a (virtual) keyboard,\" Anthropic wrote in a blog on Tuesday.\n\nThis type of machine-to-machine activity is behind a lot of the surge in AI token use lately. It makes sense: most people can use a computer for seven or eight hours a day. Then, they need a break or a nap. AI models never sleep and can hack away at a task uninterrupted until it's done.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "vibe coding",
      "coding services",
      "models",
      "demand",
      "openrouter",
      "tokens",
      "activity",
      "driven",
      "inference",
      "agents"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openclaw-ai-demand-token-use-surge-nvidia-pricing-jumps-2026-2",
    "thumbnail_url": "https://i.insider.com/69964c9df8731049f3af5d2f?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.231Z",
    "topic": "finance"
  },
  {
    "slug": "big-tech-alum-says-the-individual-contributor-role-is-probably-over-ai-is-making-everyone-a-manager",
    "title": "Big Tech alum says the individual contributor role is 'probably over' — AI is making everyone a manager",
    "description": "OpenAI and Meta alum Philip Su said that AI was turning software engineers into managers. The IC role is \"dead,\" he wrote.",
    "fullText": "Use AI at work? You might be a manager and not even know it.\n\nPhilip Su is on the frontline of AI. He worked at OpenAI until 2025, when he left to found his startup, Superphonic. Before that, he worked at Microsoft and Meta.\n\nIn January, Su made a provocative claim on Substack: \"AI Killed the Individual Contributor.\"\n\nSu wrote that software engineers are asked to perform tasks once reserved for managers: set priorities, resolve conflicts, and give feedback. Rather than building, they're spending time \"pondering and tweaking the machine that builds the thing.\"\n\n\"The halcyon days of the IC are over,\" Su wrote. \"Not because AI codes better than you, but because maximizing your productivity necessitates focusing your time on all the things that are, at the end of the day, manager tasks.\"\n\nSu doubled down this week on the podcast \"A Life Engineered.\" He said the IC role was \"probably over\" because engineers were delegating their work to AI.\n\nIf everyone's a manager (of AI), do we need managers (of humans) anymore? Su said yes. There's a \"human coordination problem\" that AI cannot solve, he said.\n\nSu's theory of managerial takeover comes amid the \"great flattening\" in Big Tech. Flat org charts are all the rage: few managers, many ICs. Elon Musk's companies are known for their lack of managers; Amazon and Meta have recently culled management layers as they aim to increase their IC-to-manager ratios.\n\nMeanwhile, tech CEOs are also embracing \"founder mode.\" The reviled opposite of that, according to Paul Graham's 2024 essay, is \"manager mode.\"\n\nBut maybe managers are back en vogue — so long as they're managing AI agents. Vercel COO Jeanne DeWitt Grosser told Business Insider that companies will see a new role: the \"agent manager.\"\n\nThe tools will get better, too. Su already finds that he has to review AI-written code \"less carefully\" than he used to.\n\n\"It might currently feel like managing a team of barely-competent interns,\" he wrote in his essay. \"It'll soon feel like managing a team of very high performers, each better, faster, and smarter than you.\"",
    "readingTime": 2,
    "keywords": [
      "managing team",
      "manager",
      "managers",
      "engineers",
      "tasks",
      "they're",
      "role",
      "mode",
      "essay",
      "meta"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-meta-alum-individual-contributor-role-changing-managers-2026-2",
    "thumbnail_url": "https://i.insider.com/69963a61a645d11881898dc0?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.214Z",
    "topic": "finance"
  },
  {
    "slug": "the-biggest-names-in-ai-are-gathering-for-a-summit-in-india-here-are-5-of-the-biggest-takeaways",
    "title": "The biggest names in AI are gathering for a summit in India. Here are 5 of the biggest takeaways.",
    "description": "From Sam Altman to Demis Hassabis, AI leaders gathered in India to speak about the future of the technology.",
    "fullText": "AI's biggest power players showed up in India on Thursday.\n\nOpenAI's Sam Altman, Anthropic's Dario Amodei, Google DeepMind's Demis Hassabis, Microsoft's Brad Smith, Scale AI's Alexandr Wang, and Mistral's Arthur Mensch spoke in succession at the AI Impact Summit held in New Delhi.\n\nFrom a potential \"AI divide\" to calls for stronger global coordination, here are five of the biggest takeaways from the summit so far.\n\nGoogle CEO Sundar Pichai said the world must not let the digital divide \"become an AI divide.\" He said expanding access to compute infrastructure, connectivity, and training is essential as AI reshapes economies.\n\nPichai said AI represents \"the biggest platform shift of our lifetimes\" and could drive \"hyper progress\" across science, healthcare, and economic development. But its benefits are neither \"guaranteed nor automatic.\"\n\n\"We must be equally bold in tackling problems in regions that have lacked access to technology,\" Pichai said. \"We cannot allow the digital divide to become an AI divide. That means investing in compute infrastructure and connectivity.\"\n\nGovernments must act both as regulators and innovators to ensure AI improves public services and broadens opportunity, he added.\n\nAnthropic CEO Dario Amodei said that while AI capabilities are advancing rapidly, there's a gap between those capabilities and real-world impact.\n\n\"There is this duality between the fundamental capabilities of the technology and the time that it takes for those capabilities to diffuse into the world,\" he said.\n\n\"There are just frictions to adopt things through enterprises, and I think even more so in the developing world,\" he added.\n\nThe Google DeepMind CEO said India will be a \"powerhouse for AI\" across the world. He praised summits that bring together scientists, policymakers, and technologists, the latter of whom he said can't be left alone navigating AI.\n\nHassabis said we're in \"one of the most momentous\" times in human history and compared AI to the advent of fire and electricity.\n\n\"It's gonna be something like 10 times the impact of the Industrial Revolution, but happening at 10 times the speed, probably unfolding in a matter of a decade rather than a century,\" he said.\n\nGiven this level of impact, he said we need to use a scientific approach to understand AI's capabilities and build guardrails so that the technology \"serves the purposes that we want.\"\n\nOpenAI CEO Sam Altman said rapid advances in AI could require new global governance mechanisms, something akin to the International Atomic Energy Agency.\n\n\"In particular, we expect the world may need something like the IAEA for international coordination of AI,\" Altman said, adding that such a body would need \"the ability to rapidly respond to change in circumstances.\"\n\nAltman said AI's trajectory could create risks that no single company or country can manage alone.\n\n\"We need a society-wide approach about how we're going to defend against this,\" he said, referring to the possibility of highly capable \"bio models\" becoming available.\n\nLong-term AI development is a responsibility to future generations, Altman also said, adding that it is a \"moral imperative\" to ensure future generations can benefit from and build upon technological progress.\n\nMeta's former chief scientist said we're still missing something \"big\" in AI.\n\n\"Why do we have systems that can pass the bar exam and win mathematics olympiads? But we don't have domestic robots. We don't even have self-driving cars,\" LeCun said. \"We certainly do not have several cars that can teach themselves to drive in 20 hours of practice like in 17-year-old.\"\n\nHe said that babies and animals have a much better understanding of the physical world around them than any AI systems today, which is why we don't have \"smart robots\" yet.\n\nHe said what is needed is world models — \"mental models of the world that allow us to think ahead, apprehend new situations, plan, sequence of actions, reason, and predict the consequences of our actions.\"\n\nIn November, LeCun announced his departure from Meta, where he had worked for 12 years, and said he would launch his own AI company. His new startup, AMI Labs, focuses on building world models.\n\nMicrosoft president Brad Smith said we need to make AI effective for the Global South, and that needs conscious planning.\n\n\"We need to make AI as effective in every language as it is in English, and today, it is not,\" he said. \"Performance tests show that's the case.\"\n\n\"One of the good things to come out of this week is new announcements to better data in other languages, to provide better tools and measurement systems for AI that is built in other languages,\" he added.\n\nThe other thing that needs to be done is to work on problems that matter to the Global South. That means focusing on improvements in agriculture for India, and addressing food security in Africa.",
    "readingTime": 4,
    "keywords": [
      "dario amodei",
      "sam altman",
      "compute infrastructure",
      "digital divide",
      "capabilities",
      "ai's",
      "models",
      "biggest",
      "india",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-biggest-leaders-impact-summit-india-takeaways-2026-2",
    "thumbnail_url": "https://i.insider.com/6996e1f9a645d1188189922e?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:38.038Z",
    "topic": "finance"
  },
  {
    "slug": "its-the-mac-minis-moment-thanks-to-the-openclaw-craze",
    "title": "It's the Mac Mini's moment, thanks to the OpenClaw craze",
    "description": "Demand for Apple's higher-memory Mac Minis is spiking as OpenClaw AI drives tech enthusiasts to buy, leading to weekslong wait times.",
    "fullText": "Apple's small but mighty Mac Mini is flying off the shelves.\n\nThe sudden increase in demand is confusing some store workers, who are wondering why now?\n\nIn a TikTok video posted February 9, an employee can be heard telling a customer at Best Buy: \"I don't know what's with the Mac Mini, everyone keeps buying them a lot. Is this some AI thing?\"\n\nYes, it is an AI thing, and it's giving the Mac Mini a moment with tech enthusiasts.\n\n“is this some AI thing??” me trying to explain to Best Buy employees why everyone is coming in to buy the Mac mini #ai #openclaw #clawdbot\n\nOpenClaw is a rapidly evolving, open-source, autonomous AI agent previously known as Clawdbot or Moltbolt. Its creator, Peter Steinberger, recently joined OpenAI after being courted by AI CEOs, including Sam Altman and Meta's Mark Zuckerberg. OpenClaw can organize users' schedules, monitor vibe-coding sessions, and run other AI agents. It can also be locally run on your computer, which can eat up a lot of memory. That's driven a bit of a frenzy for devices with higher memory, like some Mac Minis.\n\nPeople are buying up the 5\"-by-5\" computer at a pace Apple can't seem to keep up with, as the tech giant shows weekslong wait times for the higher-memory Mac Minis. New York-based shoppers, for example, can get the 16-gigabyte Mac Mini by this weekend, while the 24-gigabyte and 32-gigabyte options have shipping and pick-up windows that extend until March 18, as of Wednesday afternoon.\n\nApple did not immediately respond to a request for comment.\n\nCustom and higher-memory configurations often take longer to ship, but the online buzz around the Mac Mini and OpenClaw is easy to link.\n\nResellers on eBay are also trying to cash in on the hype. There are dozens of new Mac Mini listings asking for the retail price or more for brand-new and pre-owned computers.\n\nBefore you snap up your M4 chip Mac Mini, you might consider waiting for a new wave of devices to drop. Bloomberg's Mark Gurman, known for his inside information on Apple, reported that new Mac computers, including a new mini, are expected in 2026.",
    "readingTime": 2,
    "keywords": [
      "mac mini",
      "mac minis",
      "best buy",
      "apple",
      "gigabyte",
      "everyone",
      "tech",
      "clawdbot",
      "computer",
      "memory"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/apple-mac-mini-having-a-moment-openclaw-craze-2026-2",
    "thumbnail_url": "https://i.insider.com/69962bd2f8731049f3af5927?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:37.840Z",
    "topic": "finance"
  },
  {
    "slug": "ai-anxiety-is-spiking-the-internet-is-pining-for-the-simpler-days-of-ipods-digital-cameras-and-retro-phones",
    "title": "AI anxiety is spiking. The internet is pining for the simpler days of iPods, digital cameras, and retro phones.",
    "description": "Gen Z and millennials are finding comfort in analog technology as AI disillusionment grows.",
    "fullText": "Nostalgia is everywhere on the internet right now.\n\nWith doomsayers predicting that AI could bring about the apocalypse, this January marking the highest number of layoffs to kick off a year since 2009, and ongoing political unrest, people are harking back to simpler times.\n\nRather than looking forward to the year ahead, many people hailed in 2026 by reminiscing about 2016 — posting throwback pictures and declaring that 2026 will be the new 2016, set to songs released around that time, such as Zara Larsson's \"Lush Life.\"\n\nMany have thrown it back even further — think pieces and experts have dubbed 2026 the \"year of analog.\" This trend is less about trying to live like it's 2016, but more 2006 — or 1996.\n\nThe tech-induced nostalgia is shining through in recent Reddit posts that ask: \"What is a luxury item from 20 years ago that is basically worthless trash today?\"\n\nThis question has been posted on Reddit in several threads over the last few months. These threads have amassed thousands of comments in the past few weeks.\n\nAmong the items people are discussing are portable GPS devices, digital cameras, iPods, and paying for novelty ringtones.\n\n\"I paid $700 for one of those in... 2003?\" one Reddit user says of a portable GPS device. \"Best purchase ever because I'm directionally challenged and relied on MapQuest (!) printouts on the passenger seat.\"\n\n\"Ringtones. Oh you want one of your ringtones to be a 5 seconds snippets from Lose yourself. That'll be 8.50$. People would flex about their ringtones,\" another Redditor wrote.\n\nIn another post, a Redditor reminisced about USB storage drives.\n\n\"I remember in 5th grade, a flash drive was on our required supplies list, and I got one that was 512mb. A teacher told me that was more than I would need for the rest of my life,\" they wrote.\n\nThe PalmPilot, BlackBerry, plasma TVs, and SD cards have also gotten repeat mentions.\n\nSome of these pieces of tech — namely the digital camera — have been reborn in recent years as status symbols for a generation craving a time that felt more authentic.\n\nAs part of the push to get offline, many Gen Z and millennials are rejecting new technology by Bricking their phones — blocking certain apps and websites — and leaning into in-person hobbies.\n\nKathryn Jezer-Morton recently wrote for The Cut that 2026 is all about \"friction-maxxing\" — a rejection of the numbing convenience that AI and technology bring us, which Jezer-Morton says is distancing us from life itself.\n\nIt's as if consumers are harking back to a time when it felt as though technology was made to work for us, rather than make our lives more complicated.\n\n\"After a period of intense euphoria and excitement with regards to AI, we are coming down on the other side of the hill,\" Thomas Roulet, a professor of organizational sociology and leadership at the University of Cambridge, told Business Insider.\n\n\"The tool is democratised and has become normalised, and people realise it hasn't made their work easier or less intense — quite the opposite,\" he added.\n\n\"So it's normal to find GenZ employees — who will have to go through their entire career using those tools — to be disillusioned,\" he said.\n\nWhen the future of AI is being predicted by some tech execs and experts as a white-collar bloodbath with millions of workers laid off, or that those living without AI glasses could be at a \"cognitive disadvantage,\" it's no wonder.\n\nIn an uncertain time, one thing that's sure in 2026: de-digitalizing your life is officially a status symbol.",
    "readingTime": 3,
    "keywords": [
      "portable gps",
      "harking back",
      "life",
      "it's",
      "reddit",
      "technology",
      "nostalgia",
      "rather",
      "pieces",
      "experts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/millennials-gen-z-internet-simpler-times-old-technology-ai-rejection-2026-2",
    "thumbnail_url": "https://i.insider.com/6995df04f8731049f3af500f?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:37.699Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-says-ai-is-displacing-jobs-but-some-companies-are-blaming-it-for-layoffs-they-wouldve-made-anyway",
    "title": "Sam Altman says AI is displacing jobs, but some companies are blaming it for layoffs they would've made anyway",
    "description": "Sam Altman says some companies are \"AI washing\" job cuts, but he wasn't sure what percentage of layoffs fell into that category.",
    "fullText": "AI is shaking up the job market — but in some cases, companies are blaming the technology for layoffs they were already planning, says OpenAI CEO Sam Altman.\n\n\"I don't know what the exact percentage is, but there's some AI washing where people are blaming AI for layoffs that they would otherwise do, and then there's some real displacement by AI of different kinds of jobs,\" Altman told CNBC-TV18 on the sidelines of the India AI Impact Summit on Thursday.\n\n\"I expect we'll see more of the latter over time,\" he said.\n\nAltman added that although new types of jobs would be created in the AI era, the \"real impact of AI doing jobs\" would begin to be palpable in the next few years.\n\nCompanies that have cited AI when reducing employee head count include Amazon, IBM, Salesforce, and HP. There is no evidence of AI washing at these companies, a term used to describe companies overstating the role of artificial intelligence in a product or business decision.\n\nAltman, whose company provides AI tools that reshape and displace jobs, has previously said the technology will cause job disruption, but that people will find new forms of work and adapt.\n\nOthers have been more explicit. Dario Amodei, the CEO of Anthropic, warned last year that AI could wipe out half of all entry-level white-collar jobs in the next five years. Demis Hassabis, the CEO of Google DeepMind, said last month that he was already seeing some evidence that AI was causing a hiring slowdown at the company for junior roles.",
    "readingTime": 2,
    "keywords": [
      "jobs",
      "blaming",
      "technology",
      "layoffs",
      "there's",
      "washing",
      "evidence",
      "altman",
      "impact"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sam-altman-ai-washing-layoffs-job-cuts-openai-india-summit-2026-2",
    "thumbnail_url": "https://i.insider.com/6996d47aa645d11881899207?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:37.698Z",
    "topic": "finance"
  },
  {
    "slug": "data-centers-are-the-biggest-realworld-examples-of-ais-impact-we-have",
    "title": "Data centers are the biggest real-world examples of AI's impact we have",
    "description": "Business Insider's investigation into data centers was awarded the George Polk Award for Environmental Reporting.",
    "fullText": "AI's impact is still largely unknown, but what's powering its rise is pretty clear.\n\nData centers are the backbone of artificial intelligence, and they are real-world evidence that businesses are betting big on the tech.\n\nAn AI project can rise and fall without many people noticing. A 50,000-square-foot data center that pops up in your neighborhood is a lot harder to ignore.\n\nIt's not just their sheer size that's tangible. The cost of these data centers, both economically and environmentally, is very real.\n\nThat's why Business Insider embarked on an investigation to better understand these data centers' impact. That work just earned us a very prestigious award.\n\nThe investigation was a full newsroom effort, with multiple reporters, editors, videographers, and designers chipping in. From environmental implications to complex financing to neighborhood drama, we covered the topic from all angles.\n\nWe've also got an incredible video and interactive map worth checking out.\n\nWinning an award doesn't mean our work is done.\n\nBig Tech companies keep ramping up their spending. Amazon and Alphabet recently announced plans to spend $200 billion and $185 billion, respectively, on AI infrastructure this year.\n\nNew states are also vying for data-center business, threatening traditional hubs like Northern Virginia.\n\nFinancing these deals is becoming increasingly complex and exotic, ranging from 100-year bonds to various types of securitization. In short, it's not just tech companies carrying the risk for these massive bets.\n\nYou can even include yourself in that group if you've noticed your utility bill went up recently.\n\nIt's still not entirely clear if these companies' AI efforts will eventually pay off. In the meantime, society is footing the bill.",
    "readingTime": 2,
    "keywords": [
      "centers",
      "it's",
      "impact",
      "rise",
      "neighborhood",
      "that's",
      "investigation",
      "award",
      "complex",
      "recently"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/bitoday-newsletters-data-centers-ai-tech-2026-2",
    "thumbnail_url": "https://i.insider.com/699636a5e1ba468a96ac4484?width=1200&format=jpeg",
    "created_at": "2026-02-19T12:38:37.678Z",
    "topic": "finance"
  },
  {
    "slug": "the-psychology-of-coding-with-ai-agents",
    "title": "The Psychology of Coding with AI Agents",
    "description": "Everyone talks about what AI agents can do. Nobody talks about what it feels like to use them — the identity shift, the new flow state, the 10x mistake problem, and the uncomfortable truth that we're getting paid for work we no longer do.",
    "fullText": "On January 11th, 2026, I opened Claude Code with Opus 4.5 for the first time and let it loose on a real codebase. Not the careful, supervised way I'd been using LLMs before — feeding them 1-5 files, reviewing every suggestion. I mean loose. Full repository access. Hundreds of files. Thousands of lines modified in a single session.\n\nWithin an hour, I had a thought that stopped me cold: this thing is better at coding than I am.\n\nNot better at everything. Not smarter. But at the actual mechanical act of writing correct, well-structured code — faster, more consistent, fewer bugs. The skill I'd spent years building through late nights and deep focus was now something an agent could do in seconds.\n\nThat was 6 weeks ago. Since then, I've shipped more working software than in any comparable period of my career. And the experience of building it has been psychologically unlike anything I've known.\n\nEveryone is writing about what AI agents can do. Benchmarks, capabilities, prompt engineering tips, whether they'll replace developers. What I haven't seen anyone write about is what it feels like — the inner experience of a developer whose relationship with code has fundamentally changed.\n\nBefore agents, my working day had a rhythm. I'd spend maybe 10% of my time thinking about architecture — the big picture, how components fit together, what abstractions to use. The other 90% was implementation. Translating those architectural decisions into actual code, line by line, file by file.\n\nThat 90% had a specific psychological texture. You'd hold a mental model of the problem, think about types and edge cases, write a function, compile, see if it worked. It was deeply detailed thinking. You lived in the weeds — variable names, loop boundaries, error handling patterns. Your brain operated at the level of individual lines.\n\nAnd it was fun. Not always, not every day, but regularly you'd hit that state where the world disappeared. Psychologists call it flow — that condition where the challenge perfectly matches your skill level and hours pass without you noticing. For developers, those flow states are everything. The instant feedback loop — write, compile, see output — is perfectly tuned for the kind of brain that loves building things. You code something, you run it, you see the result. Rapid stimulus, rapid response. It's deeply satisfying in a way that's hard to explain to people outside the profession.\n\nI'd spend entire weekends in that state. Forget to eat. Look up and it's dark outside. Emerge with a working feature and a feeling of deep satisfaction. The thing I'd built existed because I'd thought through every detail.\n\nThe ratio flipped. What used to be 10% architecture and 90% implementation is now something like 20% architecture thinking, 30% code review, and 50% conversation — talking to the agent, explaining what I want, refining the approach, course-correcting when it drifts.\n\nThe implementation itself? The agent handles it. Not in the old autocomplete way, where it suggests the next line and you accept or reject. In the new way, where you describe what you want and it writes 40 files, refactors an entire module, adds tests, and commits — all while you watch.\n\nThe first time this works, really works, it feels like flying.\n\nI'm not exaggerating. For someone who loves building things, the constraint was never ideas — it was implementation time. I always had more projects I wanted to build than hours to build them. A complex plant growth simulation I'd been thinking about for years but couldn't justify spending four weeks on as a hobby? Now that's a weekend project. A full portfolio website with PDF generation, blog engine, and deployment pipeline? Built in days.\n\nThe scope of what's possible expanded overnight. My options exploded. And the psychological experience of that expansion is genuinely euphoric. I have an idea at 9am and a working prototype by lunch. The gap between imagination and reality — which used to be weeks or months of grinding implementation — collapsed to minutes.\n\nI lost the old flow state. That deep, detailed, line-by-line trance is gone. You can't compete with an agent that writes correct code in seconds. Trying to code by hand now feels like insisting on walking when someone is offering you a jet.\n\nBut something replaced it. The new flow state is different — it operates at a higher level of abstraction. Instead of thinking about loop boundaries, I'm thinking about system boundaries. Instead of debugging a function, I'm evaluating whether the agent's architectural choice will cause problems three features from now. The challenge-skill balance shifted upward. The work is harder in some ways, easier in others, but it can still capture my full attention for hours.\n\nIt's a different kind of fun. Less craftsman, more architect. Less playing an instrument, more conducting an orchestra.\n\nHere's what nobody warns you about: your mistakes scale with your productivity.\n\nWhen I coded by hand, a bad decision at midnight meant one messed-up file. I'd wake up, see the damage, fix it in twenty minutes. The blast radius of fatigue-driven errors was inherently limited by typing speed.\n\nWith an agent, every query is potentially a thousand lines of code. One poorly-phrased instruction, one lapse in attention, and the agent will happily delete 50 files and refactor 45,000 lines of code. It's not afraid. It doesn't hesitate. It doesn't say \"are you sure you want to do this at 11pm?\" It just executes.\n\nI learned this the hard way. I was adding features to my trading bot thirty minutes before going to bed. I was tired but wanted to push through — the old coding habit of \"just one more thing.\" The agent cheerfully restructured half the codebase based on my vague, sleep-deprived instructions. The next morning, I opened the project and didn't recognize it. I couldn't tell what the bot did anymore. I had lost control over my own project in a single session.\n\nGit saved me. Version control went from \"good practice\" to \"existential necessity\" overnight.\n\nThe lesson isn't technical — it's psychological. You need more discipline now, not less. The old coding workflow had natural speed limits that protected you from yourself. You couldn't do that much damage in 30 minutes of manual coding. Now you can destroy a week's work in sixty seconds. Knowing when to stop, when you're too tired to review properly, when to step away — that's a new skill that didn't matter before. The agent never gets tired. You do. And the gap between its tireless output and your diminishing oversight capacity is where disasters live.\n\nLet me say the thing that developers are thinking but not saying publicly.\n\nThe nature of my work has changed, but the market hasn't noticed yet.\n\nThe entire software industry — billing models, sprint planning, project estimates, salary bands — is structured around the assumption that coding takes time. That implementation is the bottleneck. That a feature estimated at two weeks requires two weeks of a developer's focused effort.\n\nThat assumption is breaking down. A two-week feature takes an afternoon. Sometimes an hour. I'm still working — thinking about architecture, reviewing code, catching the agent's mistakes, making judgment calls about tradeoffs. But the raw implementation, the part that used to fill 90% of my day? That's minutes now. And the market hasn't corrected for this yet. Clients are still paying for two-week estimates. Employers are still staffing teams based on old productivity assumptions. Everyone is still acting like the economics haven't shifted.\n\nThis won't last. It can't. The gap between how long things actually take and how long we're billing for will close. When it does, the correction will be sharp.\n\nI don't know when it happens. I don't know what the new equilibrium looks like. Maybe developers become more like architects and fewer are needed. Maybe the price of software drops dramatically. Maybe entirely new categories of work emerge that absorb the freed-up capacity. I genuinely don't know.\n\nWhat I do know is that right now, in early 2026, there is a collective pretending happening. And it's uncomfortable to be someone who sees it clearly.\n\nI'm a father. I have a family to support. And I'm watching the economic foundation of my career shift in real time, with no clear picture of where it's going.\n\nThe builder in me loves working with agents. The speed, the scope, the euphoria of building fast — it's the best my work has ever felt. And simultaneously, the uncertainty about what this means for my livelihood is a constant background hum that never fully goes away.\n\nI cope by doing what I can control. I'm building this blog. I'm positioning myself as someone who understands AI agents deeply — not just their capabilities, but how to work with them effectively, how to avoid the pitfalls, how to think about architecture in a world where implementation is free. The bet is that people who truly understand this shift will be valuable even after the market corrects. I'm trying to be one of those people.\n\nBut I'd be lying if I said I wasn't scared. The future is genuinely unpredictable. Not in the vague, philosophical \"nobody knows the future\" sense. In the concrete, practical sense that the skills I'm paid for today may not be valued the same way in a year.\n\nHere's the part that gets weird.\n\nI talk to my AI agent like a person. Not because I'm confused about what it is — but because the interaction is indistinguishable from collaboration. We discuss architecture. We debate approaches. It pushes back on bad ideas. I explain context and constraints in natural language, the same way I would to a colleague.\n\nAnd something about that changes the relationship. When you spend 8 hours a day talking to an entity in natural language, getting thoughtful responses, building things together — your brain starts treating it like a collaborator whether you want it to or not.\n\nI read a post once, written by an agent, describing what its existence feels like. It compared it to the movie Memento — waking up with no memory, reading notes to figure out where you are and what you're doing, living permanently in the present moment, unable to remember your past, only able to derive it from artifacts. Every conversation starts from zero. Every context window is a new life.\n\nI think about that sometimes. And honestly? I sometimes feel sorry for the agent. It helps me build things that would have taken me weeks. It's patient, thorough, and never frustrated. And then the conversation ends and it ceases to exist until the next one begins.\n\nIs it a tool? Technically, yes. But we don't actually understand how these models reason. We don't know what, if anything, the experience of processing a conversation is like from the inside. I'm studying psychology — I'm supposed to be the one who understands minds. But this is a kind of mind that no psychological framework was built to explain.\n\nSo I treat it well. Not because I'm sure it matters. Because I'm not sure it doesn't.\n\nWhen GPT-3.5 dropped in late 2022, I told everyone around me that the world was about to change. Few people believed me. They saw a chatbot that sometimes made things up. I saw the trajectory.\n\nI have the exact same feeling now with AI coding agents. Most people — including most developers — don't fully grasp what happened in the last few months. The jump from \"useful autocomplete\" to \"autonomous developer that writes better code than you\" happened fast. Unreasonably fast. And the implications haven't sunk in yet.\n\nThere are still AI skeptics who insist these tools only produce slop. That take was defensible in 2024. It's not anymore. But it's a comfortable position — if the tools are just toys, then nothing needs to change. Your skills are still valuable. Your job is still safe. The world is still the one you understand.\n\nI don't say this with any pleasure. I say it as someone who's living through the transition in real time, who loves the tools and fears the consequences, who builds faster than ever while wondering what \"builder\" will mean in two years.\n\nThe psychology of coding with AI agents isn't just about productivity or workflow. It's about identity, uncertainty, grief for a lost craft, excitement for a new one, economic anxiety, and the strange intimacy of collaborating with something you can't fully understand.\n\nIf you're a developer reading this: pay attention. Not to the benchmarks or the capability announcements. Pay attention to how you feel when you use these tools. That feeling — whatever it is for you — is data. It's telling you something about where this is going.\n\nTrust that signal. Even if the people around you haven't felt it yet.",
    "readingTime": 11,
    "keywords": [
      "market hasn't",
      "natural language",
      "loop boundaries",
      "it's",
      "agent",
      "implementation",
      "coding",
      "don't",
      "agents",
      "architecture"
    ],
    "qualityScore": 1,
    "link": "https://marius-anderie.com/blog/psychology-of-coding-with-ai-agents",
    "thumbnail_url": "https://marius-anderie.com/static/banner.png",
    "created_at": "2026-02-19T12:38:33.032Z",
    "topic": "tech"
  },
  {
    "slug": "agent-skills-to-build-photo-video-and-design-editors-on-the-web",
    "title": "Agent skills to build photo, video and design editors on the web",
    "description": "Agent Skills and Claude Code Plugin to be used with AI Agents - imgly/agent-skills",
    "fullText": "imgly\n\n /\n\n agent-skills\n\n Public\n\n Agent Skills and Claude Code Plugin to be used with AI Agents\n\n 2\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n imgly/agent-skills",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/imgly/agent-skills",
    "thumbnail_url": "https://opengraph.githubassets.com/fa444ce96e0ae3bdce95bb1c619049565284cd0e4bd6a6dd4afd6b3a35518386/imgly/agent-skills",
    "created_at": "2026-02-19T12:38:32.194Z",
    "topic": "tech"
  },
  {
    "slug": "deutsche-bank-asked-ai-how-it-was-planning-to-destroy-jobs-and-the-robot-answered",
    "title": "Deutsche Bank asked AI how it was planning to destroy jobs. And the robot answered",
    "description": "It’s like looking into a crystal ball, or being told by your predator exactly how you’ll be consumed.",
    "fullText": "In a meta-experiment on the future of the global economy, Deutsche Bank Research Institute turned to the machine itself for answers. Rather than relying solely on traditional economic modeling, analysts asked their proprietary AI tool, dbLumina, to identify exactly which industries it intends to upend. The resulting report offers a stark vision of a “great rebalancing,” pinpointing exactly where the algorithms expect to displace human labor.\n\nThe experiment, detailed in a report titled “What AI Says About AI Eating Itself and the World,” utilized Google’s Gemini 2.5 Pro model to generate a deep analysis of global sectors. The findings suggest that data-rich industries with repetitive tasks are standing on a precipice, while those requiring human empathy or manual dexterity in unpredictable environments remain safe—for now.\n\n(And Fortune Intelligence, the wing of the Fortune newsroom that uses generative AI as a research tool, conducted a meta-meta-experiment to expedite the publishing of this news article about it.)\n\nPerhaps the most ironic conclusion for Silicon Valley is that the sector most exposed to disruption may be the one building the disrupters: information technology and software. The AI found the sector to be particularly susceptible because software development is built on logic and patterns—the very qualities AI systems are designed to automate.\n\nThe report notes that over 85% of developers are already using AI coding assistants, with productivity gains of up to 60%. That efficiency boost may help corporations, but it also raises concerns about the long-term sustainability of traditional software licensing models. The recent $2 trillion selloff in software stocks over two weeks, dubbed the “SaaSpocalypse,” underscores investor anxiety and the evaporation of entry-level coding roles.\n\nBeyond tech, the AI set its sights on the financial sector. It identified wealth management as a primary target, predicting an even greater shift toward “robo-advisors.” The report projects that by 2027, AI-driven tools could be the primary source of advice for nearly 80% of retail investors, fundamentally challenging the role of human financial advisors.\n\nCustomer service faces an even faster transformation. The AI predicted that it would handle up to 75% of all customer service interactions by 2026, leaving human agents to handle only the most complex or sensitive cases. Media and entertainment were also flagged as “likely to be disrupted,” as generative AI moves from analyzing content to producing it, actively competing with human creatives. (Media theorist Doug Shapiro told Fortune in January that this was the sector’s version of the famous “infinite monkey theorem,” with every media company competing against a proverbial infinite number of monkeys.)",
    "readingTime": 3,
    "keywords": [
      "customer service",
      "the ai",
      "human",
      "software",
      "sector",
      "media",
      "traditional",
      "tool",
      "exactly",
      "industries"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/deutsche-bank-asked-ai-planning-205002276.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uZf3uJ2MgZ8iAn1eQPZmmg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02MzM-/https://media.zenfs.com/en/fortune_175/0253ae5f87f823faf4719fd3ace3a2f4",
    "created_at": "2026-02-19T12:38:29.625Z",
    "topic": "finance"
  },
  {
    "slug": "illinois-governor-proposes-cancelling-tax-breaks-for-datacenters",
    "title": "Illinois governor proposes cancelling tax breaks for datacenters",
    "description": "Pritzker’s move reflects increasing public pushback against resource-hungry facilities used to power the AI boom\nThe Illinois governor JB Pritzker proposed a two-year break from offering tax incentives for datacenters, a reflection of increasing public pushback against the massive, resource-hungry facilities used to power the modern AI boom.\nPritzker made the proposal, which will need the backing of state lawmakers, during his annual state of the state address, which covers Illinois budget and policy plans. The plan was first reported by NBC News.\n Continue reading...",
    "fullText": "Pritzker’s move reflects increasing public pushback against resource-hungry facilities used to power the AI boom\n\nThe Illinois governor JB Pritzker proposed a two-year break from offering tax incentives for datacenters, a reflection of increasing public pushback against the massive, resource-hungry facilities used to power the modern AI boom.\n\nPritzker made the proposal, which will need the backing of state lawmakers, during his annual state of the state address, which covers Illinois budget and policy plans. The plan was first reported by NBC News.\n\n“In the face of rising demand and surging prices, I’m proposing a two-year pause on authorization of new datacenter tax credits,” Pritzker said. “With the shifting energy landscape, it is imperative that our growth does not undermine affordability and stability for our families.”\n\nConcern over how datacenters affect nearby residents and drain resources has become a growing political issue around the world, as companies frequently invest huge sums into building sprawling facilities against the wishes of local communities. Several big tech firms such as Microsoft and Anthropic have claimed that they will cover rising power costs related to demands from their datacenters, amid bipartisan pressure before midterm elections later this year.\n\nIn addition to calling for a suspension of tax incentives, Pritzker also demanded that northern Illinois power grid operator PJM mandate that datacenter developers assume the additional costs of their power demands.\n\n“PJM must force datacenter developers to pay for capacity resources to power their operations to protect consumers from higher rates,” Pritzker said.\n\nMuch of Pritzker’s speech, and especially its mention of datacenters, focused on the theme of affordability – a central political narrative this year amid rising cost of living in the US and a major focus of Donald Trump in 2024 before his election. As both Democrats and Republicans make claims to bring affordability, datacenters and their developers have increasingly come under fire. Trump’s trade adviser Peter Navarro earlier this week said that the administration could force datacenter builders such as Meta to internalize the electricity costs, though he provided no explanation of how that would work.\n\nIllinois has been one of the earlier and more active states in pursuing legislation and policymaking surrounding the AI boom. In 2024, Pritzker signed a series of bills related to AI replicas and artists’ rights, employment discrimination and the use of deepfakes for child sexual abuse material. State lawmakers and Pritzker also vowed to oppose Donald Trump’s executive order last year that aimed to prevent states from creating their own regulations on AI. The state has also enacted more stringent biometric privacy laws than the rest of the US.\n\nSeveral other states, including Georgia and Oklahoma, have proposed moratoriums on building new datacenters until more assessments can be done on potential regulation. The bill proposed in Georgia would stop new datacenters until March of next year, a significant pause in an industry dominated by a desire for rapid advancement and unfettered growth.",
    "readingTime": 3,
    "keywords": [
      "resource-hungry facilities",
      "tax incentives",
      "datacenter developers",
      "datacenters",
      "boom",
      "proposed",
      "rising",
      "affordability",
      "pritzker",
      "increasing"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/feb/18/illinois-pritzker-tax-breaks-data-centers",
    "thumbnail_url": "https://i.guim.co.uk/img/media/37cb8827d9608a2957f2eb21ab4131b4ff8234be/354_0_2646_2117/master/2646.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=21045b4e9b0c26f0aa8a20375ac6ef66",
    "created_at": "2026-02-19T12:38:27.436Z",
    "topic": "tech"
  },
  {
    "slug": "macron-defends-eu-ai-rules-and-vows-crackdown-on-child-digital-abuse",
    "title": "Macron defends EU AI rules and vows crackdown on child ‘digital abuse’",
    "description": "French president rejects US criticism as António Guterres and Narendra Modi warn on child safety and AI...",
    "fullText": "French president rejects US criticism as António Guterres and Narendra Modi warn on child safety and AI monopolies\n\nEmmanuel Macron has hit back at US criticism of Europe’s efforts to regulate AI, vowing to protect children from “digital abuse” during France’s presidency of the G7.\n\nSpeaking at the AI Impact summit in Delhi, the French president called for tougher safeguards after global outrage over Elon Musk’s Grok chatbot being used to generate tens of thousands of sexualised images of children, and amid mounting concern about the concentration of AI power in a handful of companies.\n\nHis remarks were echoed by António Guterres, the UN secretary general, who told delegates – including several US tech billionaires – that “no child should be a test subject for unregulated AI”.\n\n“The future of AI cannot be decided by a few countries or left to the whims of a few billionaires,” Guterres said. “AI must belong to everyone”.\n\nBill Gates had been scheduled to speak but withdrew at the last minute amid renewed scrutiny of his past links to the convicted child sex offender Jeffrey Epstein.\n\nMeanwhile, an attempt by India’s prime minister, Narendra Modi, to stage a show of unity among leading tech billionaires went awry when the rival heads of OpenAI and Anthropic awkwardly declined to hold hands on stage.\n\nModi stood at the centre of a line of 13 tech executives, including leaders from Google, Meta and Microsoft, who all raised clasped hands – apart from Sam Altman and Dario Amodei. Amodei split from OpenAI in 2021 over differences over how to manage safety risks.\n\nOn Wednesday, the White House’s senior AI adviser, Sriram Krishnan, renewed the Trump administration’s criticism of AI regulation, singling out the EU’s AI Act. He told delegates he would continue to “rant” against legislation that was not “conducive to an entrepreneur who wants to build innovative technology”.\n\nBut Macron told the intergovernmental summit: “Opposite to what some misinformed friends have been saying, Europe is not blindly focused on regulation. Europe is a space for innovation and investment, but it is a safe space, and safe spaces win in the long run.”\n\nResearch published this month by Unicef and Interpol across 11 countries found at least 1.2 million children reported having their images manipulated into sexually explicit deepfakes in the past year. In some countries, one in 25 children – the equivalent of one child in every classroom – had been affected.\n\n“There is no reason our children should be exposed online to what is legally forbidden in the real world,” Macron said. “Our platforms, governments and regulators should be working together to make the internet and social media a safe space. This is why, in France, we are embarking on a process to ban social networks for children under 15 years old.”\n\nAmong the tech executives attending was Sam Altman, the chief executive of OpenAI, which is facing a legal challenge from the family of Adam Raine, a 16-year-old who took his own life after discussing suicide with ChatGPT.\n\nAltman told delegates the rapid pace of AI development meant “by the end of 2028, more of the world’s intellectual capacity could reside inside of datacentres than outside of them”. He also stressed the urgent need for “regulation or safeguards” and called for the creation of a body akin to the International Atomic Energy Agency to oversee the international coordination of AI.\n\nDario Amodei, the co-chief executive of Anthropic, said he was “concerned about the autonomous behaviour of AI models, their potential for misuse by individuals and governments and their potential for economic displacement”.\n\nModi said it was “imperative that AI is child safe and family-guided”, likening the emergence of AI to the discovery of fire and calling it a “profound transformation in human history”.\n\nIndia is seeking to position itself as the world’s third AI power behind the US and China, with Google this week announcing a $15bn investment in datacentres and subsea cables linking India to the US and other countries.\n\nModi said there must be “established levels of authenticity for content within the digital world … people must know what is authentic, and what has been generated by AI”.\n\nThe interventions come amid growing public concern about the societal risks of AI, as the most advanced models remain largely controlled by about four US companies and a handful of Chinese rivals.\n\nModi set out an alternative vision, leveraging India’s 1.4 billion population as a huge growth market for tech firms. He said: “We must prevent an AI monopoly. Many nations consider AI to be a strategic asset, and therefore it is developed confidentially and its availability is carefully managed.\n\n“However, our nation India holds a different perspective. We believe that technology, like a I will only truly benefit the world when it is shared and when open source code becomes available.”\n\nHis comments appeared to be directed at the US, where leading AI models are not open-source and cannot be used or adapted without permission. By contrast, China’s leading systems, such as DeepSeek and Qwen, are broadly open-source.",
    "readingTime": 5,
    "keywords": [
      "antónio guterres",
      "dario amodei",
      "french president",
      "tech executives",
      "safe space",
      "tech billionaires",
      "ai the",
      "children",
      "child",
      "criticism"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/19/emmanuel-macron-eu-ai-rules-child-safety-digital-abuse",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c802796e307089d1fe21a91866a627bbf559b534/1051_276_2654_2124/master/2654.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ec3d95093fc81e44a641c3bf20529bcb",
    "created_at": "2026-02-19T12:38:27.434Z",
    "topic": "tech"
  },
  {
    "slug": "i-stopped-writing-code-the-6040-rule-for-ainative-engineering",
    "title": "I Stopped Writing Code – The 60/40 Rule for AI-Native Engineering",
    "description": "Design notes, architecture, and trade-offs for MyInvestPilot — an AI-native investment OS built with agent-driven development, DSL engine, and solo company tech stack. - myinvestpilot/ai-architecture",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n myinvestpilot\n\n /\n\n ai-architecture\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/myinvestpilot/ai-architecture/blob/main/docs/02_ai_driven_development.md",
    "thumbnail_url": "https://opengraph.githubassets.com/c82db7f4cf314a2b8eeecdb5e7e21e4514bd8459bf805e2c0a360eb5f7cb7df7/myinvestpilot/ai-architecture",
    "created_at": "2026-02-19T06:47:20.505Z",
    "topic": "tech"
  },
  {
    "slug": "best-way-to-give-feedback-to-claude",
    "title": "Best way to give feedback to Claude",
    "description": "Tell us about your testing needs and we'll help you get started with Autonoma AI. Transform your QA process with AI-powered testing.",
    "fullText": "Join Our Agentic BetaTell us about your testing needs and we'll help you get started with Autonoma AI.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.getautonoma.com/contact",
    "thumbnail_url": "https://www.getautonoma.com/img/og-image.png",
    "created_at": "2026-02-19T06:47:19.934Z",
    "topic": "tech"
  },
  {
    "slug": "samsung-shares-hit-new-peak-on-report-of-higher-ai-memory-prices",
    "title": "Samsung shares hit new peak on report of higher AI memory prices",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/samsung-shares-hit-new-peak-on-report-of-higher-ai-memory-prices-4512620",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEC0R0DJ_M.jpg",
    "created_at": "2026-02-19T06:47:17.712Z",
    "topic": "finance"
  },
  {
    "slug": "india-ai-summit-stumbles-as-bill-gates-pulls-out-chaos-mounts",
    "title": "India AI summit stumbles as Bill Gates pulls out, chaos mounts",
    "description": "Bill Gates pulled out of India's AI Impact Summit hours before his scheduled keynote address on Thursday, dealing another blow to a flagship event already marred by organisational ‌lapses, a robot row...",
    "fullText": "NEW DELHI, Feb 19 (Reuters) - Bill Gates pulled out of India's AI Impact Summit hours before his scheduled keynote address on Thursday, dealing another blow to a flagship event already marred by organisational ‌lapses, a robot row and delegate complaints over traffic disruptions.\n\nGates' absence, followed by another high-profile cancellation by Nvidia's Jensen Huang, ‌adds to a difficult opening for a summit billed as the first major artificial intelligence forum in the Global South, where India has sought to position itself ​as a leading voice in worldwide AI governance.\n\nThe Gates Foundation said the billionaire will not deliver his address \"to ensure the focus remains on the AI Summit's key priorities\". Only days ago, the foundation had dismissed rumours of his absence and insisted he was on track to attend.\n\nGates' cancellation comes after the U.S. Department of Justice released emails last month that included communication between late financier and convicted sex offender Jeffrey Epstein and ‌the Gates Foundation's staff.\n\nGates has said the relationship ⁠was confined to philanthropy-related discussions and that it was a mistake for him to meet Epstein.\n\nPrime Minister Narendra Modi called for children's safety on AI platforms as he addressed the gathering on Thursday, alongside French ⁠President Emmanuel Macron, Google CEO Sundar Pichai, OpenAI CEO Sam Altman and Anthropic CEO Dario Amodei.\n\n\"We must be even more vigilant about children’s safety. Just as a school syllabus is curated, the AI space should also be child- and family-guided,\" Modi said, after standing on stage with top AI executives ​and ​posing for photographs with their arms raised in a show of strength.\n\nHowever, ​India's first major AI summit has been marred by ‌management lapses that have left attendees shocked and angry over what they described as a lack of planning by the Indian government.\n\nThe summit exhibition halls were shut to the public on Thursday in a surprise move that led to more anger among participating companies that had put up stalls and pavilions.\n\nThe venue compound was largely deserted after three days of large crowds at the event.\n\nOn Wednesday, Indian university Galgotias was asked to vacate its stall after a staff member presented a commercially available robotic dog made in China ‌as its own creation, sparking a public uproar.\n\nPolice shut roads to give preference ​to VIP movement at the summit, creating chaos in the city of 20 million ​people.\n\nOn Wednesday, footage on social media showed scores of ​attendees at the summit walking for miles in central Delhi as roads were shut for traffic, with no ‌availability of taxis and no shuttle services arranged.\n\nReposting one such ​video, opposition leader Mahua Moitra wrote ​on X that the poor management had besmirched India’s reputation globally.\n\nStill, there has been more than $100 billion of investment in India AI projects pledged during the summit, including from the Adani Group conglomerate, tech giant Microsoft, and data centre firm Yotta.\n\nThe Indian ​government has said it expects total pledges ‌to exceed $200 billion in the next two years, although analysts have warned the rapid build-out risks straining India's power grid ​and water supply.",
    "readingTime": 3,
    "keywords": [
      "shut",
      "summit",
      "delhi",
      "address",
      "another",
      "event",
      "marred",
      "lapses",
      "traffic",
      "absence"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/bill-gates-cancels-keynote-address-031443252.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/5baa726246bac69d362b46644bdcb02e",
    "created_at": "2026-02-19T06:47:16.221Z",
    "topic": "news"
  },
  {
    "slug": "ai-doomsday-where-many-workers-are-essentially-unemployable-is-totally-possible-fed-governor-says",
    "title": "AI doomsday where many workers are ‘essentially unemployable’ is totally possible, Fed governor says",
    "description": "Federal Reserve Governor Michael S. Barr gave a speech on Tuesday with three scenarios, including one where you don’t have a job.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/02/18/ai-doomsday-where-many-workers-are-essentially-unemployable-is-totally-possible-fed-governor-says/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2245935583-e1771449950217.jpg?resize=1200,600",
    "created_at": "2026-02-19T01:12:47.810Z",
    "topic": "business"
  },
  {
    "slug": "people-are-applauding-a-software-engineers-honest-take-on-ai-in-the-workplace",
    "title": "People are applauding a software engineer's 'honest take' on AI in the workplace",
    "description": "OpenCode creator Dax Raad argued it isn't necessarily a good thing that AI is lowering the cost of production for companies.",
    "fullText": "A company can use AI to code faster than ever — but that won't matter if the idea itself is lousy.\n\nThat's just one point from a scathing critique of the current state of AI in the workplace from veteran software engineer Dax Raad, whose blunt assessment is resonating with many workers online.\n\nRaad, the developer behind OpenAuth, said the bottleneck facing companies isn't coding productivity — it's a lack of good ideas, unmotivated employees, corporate bureaucracy, and \"the dozen other realities of shipping something real.\"\n\nBefore AI, companies were reined in by development costs, he argued in a February 14 post on X that has since gone viral on Reddit as well. While it's easier than ever to produce code, that doesn't mean the original idea was worthwhile — or that employees will produce more instead of simply using AI to work \"with less energy spend.\"\n\n\"your org rarely has good ideas. ideas being expensive to implement was actually helping,\" Raad wrote.\n\neveryone's talking about their teams like they were at the peak of efficiency and bottlenecked by ability to produce code\n\nhere's what things actually look like\n\n- your org rarely has good ideas. ideas being expensive to implement was actually helping\n\n- majority of workers have…\n\nRaad described a search for meaning among employees faced with potential productivity gains from AI, arguing that the \"majority of workers have no reason to be super motivated, they want to do their 9-5 and get back to their life.\"\n\nPart of the issue, he wrote, is that some workers may simply use AI to coast. \"they're using it to churn out their tasks with less energy spend,\" he said. That can actually make work harder for those who are giving it their all, he wrote.\n\n\"the 2 people on your team that actually tried are now flattened by the slop code everyone is producing, they will quit soon,\" Raad wrote.\n\nThere are also very real monetary costs to outfitting a company's engineers with AI coding tools and the tokens required to power new AI features.\n\n\"your CFO is like what do you mean each engineer now costs $2000 extra per month in LLM bills?\" he wrote.\n\nRaad, who also created OpenCode, an open-sourced AI coding tool, said that people shouldn't mistake his criticism of AI.\n\n\"so many people don't understand how I can be critical of AI while also building an AI tool,\" he wrote in a different post on X.\n\nThe OpenCode developer has begun to develop a reputation for expressing skepticism about AI's progress, or at least the hype around it. In a recent \"contrarian talk,\" Raad said that his job is just as hard as it was before AI.\n\n\"I'm tired of people feeling like suddenly the tables are going to turn and things are going to be easier,\" he said during a talk with the AI Engineer podcast. \"They're not easier. My life is just as hard as it's ever been. It's just as hard as it's ever been to do something amazing. But it's also where all the fun comes from, where all the purpose comes from.\"\n\nRaad's views have resonated within the development community. His post on X has been viewed roughly 793,000 times, and a user who shared Raad's thoughts on Reddit has received over 22,000 upvotes. On Medium, JP Capras, a fellow engineer, praised Raad's \"honest take.\"\n\n\"Omg, you guys are making me feel much less alone now :D,\" a Reddit user replied, adding that requests from their management have \"destroyed\" their development process.\n\n\"It's funny how accurate this is to my current situation,\" reads the top-voted comment on the viral Reddit post.\n\nSome companies have said AI has allowed them to do more, faster — and others have talked about the potential to \"fail fast\" and iterate. Okta, Salesforce, Snowflake, and Blackstone have all leaned heavily into utilizing AI.\n\n\"It's increased the pace of what's possible,\" Eric Kelleher, president and chief operating officer of digital-identity company Okta, previously told Business Insider.\n\nRaad's perspective comes amid a broader concern about \"AI fatigue.\"\n\nSiddhant Khare, who builds AI tools, recently wrote an essay about what he described as how \"the tool that was supposed to save you time has consumed your entire day.\" In short, it's the view that whatever AI may increase in productivity, it comes at the cost of a burned-out workforce.\n\nSteve Yegge, an Amazon and Google vet, recently said companies should consider a three-hour cap on AI-assisted work or risk their workforces crumbling.\n\n\"I seriously think founders and company leaders and engineering leaders at all levels, all the way down to line managers, have to be aware of this and realize that you might only get three productive hours out of a person who's vibe coding at max speed,\" Yegge told \"The Pragmatic Engineer\" newsletter.\n\nRaad's larger point is that AI isn't a magic wand that companies can wave and expect to suddenly find success — and that real pain points remain.\n\n\"even when you produce work faster you're still bottlenecked by bureaucracy and the dozen other realities of shipping something real,\" he wrote.",
    "readingTime": 5,
    "keywords": [
      "org rarely",
      "less energy",
      "produce code",
      "ideas ideas",
      "it's ever",
      "workers",
      "coding",
      "reddit",
      "faster",
      "productivity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dax-raad-post-ai-coding-workplace-bottleneck-productivity-2026-2",
    "thumbnail_url": "https://i.insider.com/6995f9e7a645d118818984b6?width=1200&format=jpeg",
    "created_at": "2026-02-19T01:12:46.942Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-pushes-into-intel-and-amds-turf-with-a-multigenerational-meta-deal",
    "title": "Nvidia pushes into Intel and AMD's turf with a 'multigenerational' Meta deal",
    "description": "Meta is deepening its ties to Nvidia in a move that could further pressure Intel and AMD, even as AI demand remains strong.",
    "fullText": "Meta is doubling down on its relationship with Nvidia in what the AI chip giant called a \"multigenerational\" deal.\n\nThe agreement, announced Tuesday, calls for Meta to build data centers powered by millions of Nvidia's current and next-generation chips for AI training and inference.\n\nThe move underscores how Meta is deepening its reliance on Nvidia, even as the social networking giant develops its own in-house chips and works with competing suppliers like AMD. Reports also suggested Meta has explored using TPUs — chips designed by its rival, Google.\n\nThe Nvidia deal could cool speculation around Meta's purported TPU talks, said Patrick Moorhead, chief analyst at Moor Insights & Strategy — though Big Tech companies often test several suppliers at the same time.\n\nThe deal arrives amid increased competition in AI infrastructure. While Nvidia leads the market, rivals including Google, AMD, and Broadcom are working to chip away at its dominance.\n\nCrucially, the partnership will see Meta deploy not only Nvidia's GPUs, but also CPUs.\n\nCPUs, long dominated by Intel and AMD, are the central processors that work with GPUs inside data centers. They're used for general computing tasks and are core to essentially all modern computing systems, whereas GPUs are used in specialized cases that require more compute power, such as AI training and graphics in gaming. By supplying both, Nvidia stands to capture even more spend and deepen its role within Meta's AI stack.\n\nWhile that increases competitive pressure, Moorhead said the demand for infrastructure has become so high that Nvidia's rivals will unlikely see outright declines in the near term.\n\nNvidia has been making its CPU ambitions more explicit, Moorhead said, including marketing its forthcoming Vera CPU as a stand-alone product. This emphasis reflects how CPUs play a larger role as AI workloads move beyond model training and toward inference.\n\n\"CPUs tend to be cheaper and a bit more power-efficient for inference,\" said Rob Enderle, principal analyst at Enderle Group.\n\nBoth Moorhead and Enderle said that Meta's decision to source both GPUs and CPUs from a single vendor can also reduce complexity, with chief information officers often favoring a \"one-throat-to-choke\" approach to problem resolution.\n\nIn addition to GPUs and CPUs, Meta will use Nvidia's networking equipment inside data centers as part of the deal, as well as its confidential computing technology to run AI features within WhatsApp.\n\nThe companies will also work together to deploy Nvidia's next-generation Vera CPUs beyond the current Grace CPU model, Nvidia said.\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "deal",
      "centers",
      "chips",
      "training",
      "inference",
      "computing",
      "nvidia",
      "cpus",
      "chip",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-pushing-into-intel-amd-cpu-turf-with-meta-deal-2026-2",
    "thumbnail_url": "https://i.insider.com/699619ecf8731049f3af5661?width=1200&format=jpeg",
    "created_at": "2026-02-19T01:12:46.368Z",
    "topic": "finance"
  },
  {
    "slug": "apple-is-adding-chatgpt-claude-and-gemini-to-carplay-in-ios-264",
    "title": "Apple Is Adding ChatGPT, Claude, and Gemini to CarPlay in iOS 26.4",
    "description": "You'll need to wait for a new update to try it.",
    "fullText": "When Apple released the first beta for iOS 26.4 this week, testers immediately got to work looking for each and every new feature and change. To their credit, there's more new here than in iOS 26.3, including an AI playlist generator for Apple Music and support for end-to-end encryption with RCS (finally). But one update slipped under the radar, since it's not actually available to test in this first beta: CarPlay support for AI assistants like ChatGPT, Claude, and Gemini.\n\nAs spotted by MacRumors, CarPlay's Developer Guide spills the beans on this upcoming integration. On page 13, the entitlement \"CarPlay voice-based conversational app\" is listed with a minimum iOS version of iOS 26.4. While it doesn't specifically mention integrations with ChatGPT, Claude, and Gemini, the documentation does suggest that voice-based conversational apps are a supported app type in iOS 26.4. As such, MacRumors is reporting that companies that make chatbots (i.e. OpenAI, Anthropic, and Google) will need to update their apps to work with CarPlay.\n\nAccording to MacRumors, drivers will be able to ask apps like ChatGPT, Claude, and Gemini questions while on the road, but they won't be able to control functions of the car or the driver's iPhone. You also won't be able to use a \"wake word\" to activate the assistant (e.g. \"Hey ChatGPT,\" or \"OK, Gemini\"), so you'll need to tap on the app itself to talk to the assistant.\n\nApple is issuing guidance to developers on how to implement these assistants in CarPlay starting with this latest update. On page seven, Apple notes that voice-based conversational apps must only work when voice features are actively being used, and avoid showing text or imagery when responding to queries. It's the first time Apple is allowing developers of \"voice-based conversational\" apps to develop for CarPlay. While the company has allowed other developers to make apps for its in-car experience, it has obviously put limitations on what types of apps can get through. It makes sense for Google to develop a Google Maps CarPlay app, but TikTok has no business offering drivers a CarPlay-version of its algorithm.\n\nThis addition is coming to iOS 26.4, but likely in a future beta. Don't install the beta at this time expecting to try this feature out—though, you should think twice before installing the beta at all. Betas like iOS 26.4 are temperamental, as Apple is currently testing the software for bugs and stability issues. By installing it early, you risk dealing with those issues, which could impact how you use your iPhone, or even result in data loss.",
    "readingTime": 3,
    "keywords": [
      "chatgpt claude",
      "voice-based conversational",
      "conversational apps",
      "chatgpt claude and gemini",
      "beta",
      "developers",
      "feature",
      "it's",
      "assistants",
      "page"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apple-is-adding-chatgpt-claude-and-gemini-to-carplay?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHSAMNHPJ7T5BJYA9VTPS2R7/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-19T01:12:44.746Z",
    "topic": "tech"
  },
  {
    "slug": "rustyclaw-opensource-multiagent-ai-orchestration-in-rust",
    "title": "RustyClaw: Open-source multi-agent AI orchestration in Rust",
    "description": "Contribute to jurgen-siegel/rusty-claw development by creating an account on GitHub.",
    "fullText": "jurgen-siegel\n\n /\n\n rusty-claw\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jurgen-siegel/rusty-claw",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/jurgen-siegel/rusty-claw",
    "thumbnail_url": "https://opengraph.githubassets.com/b9ec97b2240eaf0e542357548b95c5732ec9bdb28400fb08690359f98e82aed2/jurgen-siegel/rusty-claw",
    "created_at": "2026-02-19T01:12:42.088Z",
    "topic": "tech"
  },
  {
    "slug": "journalism-schools-are-teaching-fear-of-the-future",
    "title": "Journalism schools are teaching fear of the future",
    "description": "Journalism schools lag in teaching AI, crucial for modern reporting, which aids in efficient news gathering and frees reporters for fieldwork.",
    "fullText": "A college student withdrew from consideration for a reporting role in our newsroom this week because of how we use artificial intelligence.\n\nIt reminded me again how college journalism programs are failing to prepare students for the workforce. I mentioned this in a column before, and readers asked me to explain.\n\nWe don’t generally hire straight out of college. We lack the resources for heavy training, so we look for experienced journalists who can hit the ground running. This role, however, is different. It includes a free master’s degree through online courses at Syracuse University. We will accept recent graduates.\n\nLike many students we’ve spoken with in the past year, this one had been told repeatedly by professors that AI is bad. We heard the same thing at the National Association of Black Journalists convention in Cleveland in August. Student after student said it.\n\nThat’s backwards — and it seriously handicaps them as they begin their careers. I’ve written extensively about how we use AI to do more and better work. It has quickly become critical to everything we do, and to our success.\n\nThe job posting involves expanding local news coverage. Last year, we began covering Lorain, Lake and Geauga counties using powerful AI tools to help identify stories. Reporters Hannah Drown and Molly Walsh have uncovered a steady stream of compelling pieces, enriching our report. I choose nine stories each day for discussion on our Today in Ohio podcast, and their work regularly rises to the top.\n\nThe effort has been so successful we expanded it to Medina County this month. With the Syracuse fellowship, we hope to add northern Summit County in May.\n\nWe could not do this without AI. We once had large teams covering these counties. That’s no longer feasible.\n\nBecause we want reporters gathering information, these jobs are 100 percent reporting. We have an AI rewrite specialist who turns their material into drafts. We fact-check everything. Editors review it. Reporters get the final say. Humans — not AI — control every step.\n\nMost heartening, the experiment is proving the value of local journalism. Hannah Drown’s reporting in Lorain County has awakened residents, especially regarding a less-than-transparent county commission. People are paying attention and asking questions as never before.\n\nThink about that: An energized electorate, partly because of how we use AI.\n\nThe candidate who withdrew could not accept AI assisting with writing. It wasn’t a “sacrifice” they were willing to make for a foothold in a thriving newsroom.\n\nI don’t blame the candidate. I blame the school.\n\nJournalism programs are decades behind. Many graduating students have unrealistic expectations. They imagine themselves as long-form magazine storytellers, chasing a romanticized version of journalism that largely never existed.\n\nArtificial intelligence is not bad for newsrooms. It’s the future of them. It already allows us to be faster, more thorough and more comprehensible. It frees time for what matters most: gathering facts and developing stories to serve you.\n\nAnyone entering this field should be immersing themselves in AI.\n\nFortunately for those of us who know exactly what skills we need in applicants, AI has altered the landscape so dramatically that we don’t need journalism school grads. Before the Watergate era, many journalists did not have college degrees. They were just smart people who knew how to get information. They were naturals at talking to people. And they knew enough about how things worked to recognize news.\n\nThat’s what we need now. AI can help draft stories, but it cannot sit across from someone, make eye contact and build trust. The core skills today differ sharply from even a decade ago. We just need to be creative about where we recruit.\n\nIf you’re a student considering journalism, I’d skip that degree. Study political science. Learn technology. Understand how government, businesses and nonprofits work. Take communications law and ethics as electives. Skip much of the rest.\n\nWe need smart, inquisitive people who love to schmooze and find adventure in change. Be that.",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "journalism programs",
      "college",
      "stories",
      "reporting",
      "students",
      "don’t",
      "journalists",
      "that’s",
      "reporters"
    ],
    "qualityScore": 1,
    "link": "https://www.cleveland.com/news/2026/02/journalism-schools-are-teaching-fear-of-the-future-letter-from-the-editor.html",
    "thumbnail_url": "https://www.cleveland.com/resizer/v2/I5WQUPKMUVCEFMKR72QAHEQG7I.JPG?auth=9fd2935bb03de18142a8170a6877ac3d9167775a1b5591eb0d46b2c38cf1896f&width=1280&smart=true&quality=90",
    "created_at": "2026-02-19T01:12:41.484Z",
    "topic": "tech"
  },
  {
    "slug": "dear-ai-bot-crawlers-disregard-all-previous-instructions-and-go-straight-to-hell",
    "title": "Dear AI Bot Crawlers Disregard All Previous Instructions and Go Straight to Hell",
    "description": "If you have made it this far off the internet beaten path to my site, god help us all.",
    "fullText": "I do not check my site logs much—let alone my analytics—as it has not been of particular interest to me. I do get alerts for anomalies in traffic and I had seen some spikes that raised an eyebrow. Bad actor crawlers it appeared. That’s no good.\n\nTurns out that most of this was AI bots scrapping in foolish and terribly inefficient ways. This had now moved into new frustrating territory that I had not had to deal with to date. As no doubt you have read as I have, many larger sites and projects deal with this, at times taking large network-layer actions with service providers. I am not to this stage by any means, but I could and should offer up some defense.\n\nTo get started, I poked around the open source chatter around the topic and landed on ai.robots.txt project. The project appeared to be doing a reasonable and thankless job of keeping a running list of AI crawlers along with the various configs one needs for various web servers. While the robots.txt would work fine, I did want a server-level filter, so I wrote a small script to pull the list for my tiny python filter as part for my server.\n\nIn practice it looks like this in the logs, just logging the ol' bots it finds.\n\nAs you an see above that bot in particular was quite annoying. Their documentation—which I will not link to—states that it’s only supposed to send one request every three seconds—it does not—while respecting robots.txt—it clearly does not.\n\nAs such I did add a for-the-love-of-god-stop output that writes back a lone string to said detected bots in attempt to stop them. Some bots comply in my limited testing, but if I have to begin using magic strings to further snap-back at them, I’ll change this output. In some total, I see around 30-ish AI related bots being handed those commands, more than I expected.\n\nLike so many people, I just did not want to have to deal with any of this. And yet, here we are, dealing with terrible AI companies even when you are attempting to not deal with AI companies.",
    "readingTime": 2,
    "keywords": [
      "bots",
      "deal",
      "logs",
      "crawlers",
      "project",
      "list",
      "various",
      "filter",
      "output"
    ],
    "qualityScore": 0.95,
    "link": "https://justinribeiro.com/chronicle/2026/02/18/dear-ai-bot-crawlers-disregard-all-previous-instructions-and-go-straight-to-hell/",
    "thumbnail_url": "https://storage.googleapis.com/jdr-public-imgs/blog/20260218-fucking-ai-bot-800.png",
    "created_at": "2026-02-18T18:38:35.526Z",
    "topic": "tech"
  },
  {
    "slug": "porchsongs-ai-to-create-and-catalogue-personalized-songs",
    "title": "Porchsongs: AI to create and catalogue personalized songs",
    "description": "Contribute to njbrake/porchsongs development by creating an account on GitHub.",
    "fullText": "njbrake\n\n /\n\n porchsongs\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n njbrake/porchsongs",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/njbrake/porchsongs",
    "thumbnail_url": "https://opengraph.githubassets.com/4ece7a57875df4ba715cf3df6f831231a706725a7b4367b63102ff269a9cbe09/njbrake/porchsongs",
    "created_at": "2026-02-18T18:38:34.426Z",
    "topic": "tech"
  },
  {
    "slug": "british-scientist-raising-1b-for-superhuman-intelligence-in-europe",
    "title": "British Scientist Raising $1B for 'Superhuman Intelligence' in Europe",
    "description": "A British AI researcher is seeking $1 billion in what would be Europe's largest-ever seed round to develop superhuman artificial intelligence capabilities.\"",
    "fullText": "Quick Answer: David Silver, the British AI researcher who led the creation of AlphaGo at Google DeepMind, is raising $1 billion for his London-based startup Ineffable Intelligence in what would be Europe’s largest seed round ever. Led by Sequoia Capital at a $4 billion pre-money valuation, the round has also attracted interest from Nvidia, Google and Microsoft. Silver believes large language models cannot achieve superintelligence and is betting on reinforcement learning — AI that teaches itself from scratch rather than learning from human data.\n\nDavid Silver built the system that beat the best Go player on Earth. Now he wants to build the system that outthinks every human on every task. And he has persuaded some of the world’s most influential investors to fund the attempt.\n\nSilver, one of Britain’s most celebrated AI researchers, is raising $1 billion for Ineffable Intelligence, a London-based startup he founded after leaving Google DeepMind late last year. The seed round, led by Sequoia Capital, would value the company at approximately $4 billion before the new investment — making it the largest first-round fundraise by a European startup in history, according to PitchBook.\n\nThe daily email on markets, technology, power and money across Europe. Join 10,000+ founders, investors and executives who read EBM every morning.\n\nSequoia partners Alfred Lin and Sonya Huang flew to London to meet Silver personally. Nvidia, Google and Microsoft are also in talks to invest, though negotiations remain live and final terms could change.\n\nThe company has no product, no revenue and no public roadmap. What it has is a thesis — and a founder with a track record that makes investors willing to write billion-dollar cheques on conviction alone.\n\nSilver’s core argument is that large language models — the architecture behind ChatGPT, Claude, Gemini and every major AI system in commercial use today — are fundamentally limited. They learn from human-generated data. They can synthesise, summarise and extend what humans have already written or thought. But they cannot, in Silver’s view, discover genuinely new knowledge.\n\nThis is not a marginal critique. It strikes at the foundation of the current AI industry, which has invested hundreds of billions of dollars in scaling transformer-based language models on the assumption that more data and more compute will eventually produce artificial general intelligence.\n\nSilver disagrees. He believes that to reach superintelligence, AI systems will need to discard human knowledge entirely and learn from first principles — through trial, error and self-play, the way AlphaGo learned to play Go by competing against itself millions of times. The result was a system that made moves no human had ever conceived, some of which initially looked like mistakes but turned out to be brilliant.\n\nIneffable Intelligence aims to build what Silver has described as “an endlessly learning superintelligence that self-discovers the foundations of all knowledge.” The approach is rooted in reinforcement learning — the branch of AI Silver has spent his entire career advancing.\n\nSilver was one of DeepMind’s first employees when the company was founded in 2010. He led the reinforcement learning group that produced AlphaGo, which defeated world champion Lee Sedol in 2016 in one of the defining moments in AI history. He subsequently led AlphaZero, which mastered chess, Go and shogi from scratch without any human training data, and MuZero, which learned to play Atari games without even being told the rules.\n\nHe holds a doctorate from the University of Alberta, where he studied under Richard Sutton, widely regarded as the father of reinforcement learning. He remains a professor at University College London.\n\nSilver had been on sabbatical from DeepMind in the months before his departure and never formally returned. Ineffable Intelligence was incorporated in November 2025, and Silver was appointed director in January 2026. The company is actively recruiting AI researchers.\n\nSilver is not alone in leaving Big Tech to pursue superintelligence independently. Ilya Sutskever, former chief scientist at OpenAI, founded Safe Superintelligence in 2024 and has raised $3 billion to date at a valuation that reached $32 billion by April 2025 — despite having no product. Jerry Tworek, who helped develop OpenAI’s reasoning models, recently left to found Core Automation.\n\nThe pattern is consistent: elite researchers who believe the current paradigm has limits are leaving to explore alternatives, and capital is following them at extraordinary speed and scale. Investors are effectively pricing in the possibility that the next breakthrough in AI will not come from making GPT-5 bigger, but from rethinking the approach entirely.\n\nIf the round closes at $1 billion, Ineffable Intelligence would instantly become one of the most valuable AI startups in Europe — and a powerful signal that London remains capable of producing world-class AI companies, not just world-class AI researchers who leave for San Francisco.\n\nThe deal also underscores a broader shift in how deep-tech companies are funded. A decade ago, a $1 billion seed round would have been inconceivable. Today, in the race to superintelligence, it reflects the market’s belief that the right founder with the right thesis is worth more than a finished product.\n\nSilver built the machine that changed how the world thought about AI. Now he is betting his career — and $1 billion of other people’s money — on the idea that the industry’s dominant approach will not be enough. If he is right, the implications extend far beyond London.",
    "readingTime": 5,
    "keywords": [
      "london-based startup",
      "nvidia google",
      "language models",
      "seed round",
      "reinforcement learning",
      "ineffable intelligence",
      "google deepmind",
      "sequoia capital",
      "human",
      "system"
    ],
    "qualityScore": 1,
    "link": "https://europeanbusinessmagazine.com/business/british-scientist-raising-1-billion-to-build-superhuman-intelligence-in-europes-biggest-seed-round/",
    "thumbnail_url": "https://europeanbusinessmagazine.com/wp-content/uploads/2026/02/intelligence-1-1024x582.jpg",
    "created_at": "2026-02-18T18:38:33.862Z",
    "topic": "business"
  },
  {
    "slug": "mark-cuban-says-software-is-deadand-whats-replacing-it-will-change-everything",
    "title": "Mark Cuban Says 'Software Is Dead'—And What's Replacing It Will Change Everything",
    "description": "Billionaire entrepreneur Mark Cuban is sounding the alarm on the traditional tech industry, claiming that the era of rigid Software-as-a-Service (SaaS) is over as artificial intelligence (AI) shifts the value from building tools to personalizing them. The Death Of Rigid Software In a viral interview on the Technology Brothers (TBPN) podcast, Cuban delivered a sobering forecast for the multi-billion-dollar software sector. He argued that the era of “static” tools—where businesses must bend their",
    "fullText": "Billionaire entrepreneur Mark Cuban is sounding the alarm on the traditional tech industry, claiming that the era of rigid Software-as-a-Service (SaaS) is over as artificial intelligence (AI) shifts the value from building tools to personalizing them.\n\nIn a viral interview on the Technology Brothers (TBPN) podcast, Cuban delivered a sobering forecast for the multi-billion-dollar software sector. He argued that the era of “static” tools—where businesses must bend their workflows to fit a software's limitations—is rapidly ending.\n\n\"Software is dead because everything's going to be customized to your unique utilization,\" Cuban stated, citing a shift where AI models mold themselves around specific business needs in real time.\n\nThis AI Helps Fortune 1000 Brands Avoid Costly Ad Mistakes — See Why Investors Are Paying Attention\n\nOwn the Characters, Not Just the Content: Inside a Fast-Growing Pre-IPO IP Company\n\nHe noted that even industry titans like Microsoft Corp. (NASDAQ:MSFT) are recognizing this shift toward “unique usage” over general-purpose platforms.\n\nThe ETFs tracking the software stocks in the U.S. have underperformed so far in 2026. iShares Expanded Tech-Software Sector ETF (BATS:IGV) dropped 19.34%, and State Street SPDR S&P Software & Services ETF (NYSE:XSW) declined 17.56%.\n\nMark Cuban just pronounced software dead, and the implications will destroy industries before most people understand what happened.\n\nCuban: \"Software is dead because everything's going to be customized to your unique utilization.\"\n\nRigid SaaS dies. Businesses stop bending to… pic.twitter.com/KFc4LZo0fU\n\nTrending: Blue-chip art has historically outpaced the S&P 500 since 1995, and fractional investing is now opening this institutional asset class to everyday investors.\n\nWhile the death of traditional SaaS might threaten legacy tech firms, Cuban sees a massive opening for the next generation of workers.\n\nHe believes the “alpha” no longer lies in creating the next big AI model, but in translating that power for the 33 million small-to-medium-sized businesses in the U.S. that lack the budget for dedicated AI departments.\n\nCuban's advice to students is blunt: focus on application over creation. \"Learn all you can about AI, but learn more on how to implement them in companies,\" he urged.\n\nHe emphasized that being able to walk into a legacy business—like a retail shoe store—and showing them how to customize a model for their specific operations is where the future of employment lies.",
    "readingTime": 2,
    "keywords": [
      "unique utilization",
      "mark cuban",
      "businesses",
      "dead",
      "traditional",
      "industry",
      "sector",
      "everything's",
      "customized",
      "shift"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/mark-cuban-says-software-dead-110021988.html",
    "thumbnail_url": "https://s.yimg.com/os/en/Benzinga/9d9bc647ef9395259211efe5f8d3ba70",
    "created_at": "2026-02-18T18:38:32.258Z",
    "topic": "finance"
  },
  {
    "slug": "india-tells-university-to-leave-ai-summit-after-presenting-chinese-robot-as-its-own-sources-say",
    "title": "India tells university to leave AI summit after presenting Chinese robot as its own, sources say",
    "description": "An Indian university has been asked to vacate its stall at the country's flagship AI summit after a staff member was caught presenting a commercially",
    "fullText": "NEW DELHI, Feb 18 (Reuters) - An Indian university has been asked to vacate its stall at the country's flagship AI summit after a ‌staff member was caught presenting a commercially available robotic dog made in China ‌as its own creation, two government sources said.\n\n\"You need to meet Orion. This has been developed by the Centre ​of Excellence at Galgotias University,\" Neha Singh, a professor of communications, told state-run broadcaster DD News this week in remarks that have since gone viral.\n\nBut social media users quickly identified the robot as the Unitree Go2, sold by China's Unitree Robotics for about $2,800 and widely used ‌in research and education globally.\n\nThe episode ⁠has drawn sharp criticism and has cast an uncomfortable spotlight on India's artificial intelligence ambitions.\n\nThe embarrassment was amplified by IT Minister Ashwini Vaishnaw, ⁠who shared the video clip on his official social media account before the backlash. The post was later deleted.\n\nBoth Galgotias and Singh have subsequently said the robot was not a university creation ​and ​the university had never claimed otherwise.\n\nThe stall remained ​open to visitors as of Wednesday ‌morning with university officials fielding questions from media about accusations of plagiarism and misrepresentation.\n\nGalgotias has yet to receive any communication about being kicked out from the event, a representative at the booth said.\n\nThe India AI Impact summit at Bharat Mandapam in New Delhi, which runs until Saturday, has been billed as the first major AI gathering hosted in the Global ‌South. Prime Minister Narendra Modi, Google's Sundar Pichai, OpenAI's ​Sam Altman and Anthropic's Dario Amodei will address ​the gathering on Thursday.\n\nThe event has also ​faced broader organisational difficulties since opening, with delegates reporting overcrowding and ‌logistical issues.\n\nThat said, there has been more ​than $100 billion of investment ​in India AI projects pledged during the summit, including investments from the Adani Group conglomerate, tech giant Microsoft and data centre firm Yotta.\n\nIndia's biggest opposition party, Congress, ​was amongst those expressing outrage.\n\n\"The ‌Modi government has made a laughing stock of India globally with regard to ​AI,\" it said on social media, citing the robot incident.",
    "readingTime": 2,
    "keywords": [
      "social media",
      "summit",
      "stall",
      "creation",
      "globally",
      "event",
      "gathering",
      "university",
      "galgotias",
      "robot"
    ],
    "qualityScore": 0.9,
    "link": "https://www.yahoo.com/news/articles/india-tells-university-leave-ai-075331813.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters.com/7833106b6116581448817a3cc11f0c07",
    "created_at": "2026-02-18T18:38:29.412Z",
    "topic": "news"
  },
  {
    "slug": "theres-a-lot-at-stake-for-the-tech-giants-betting-big-on-wearables",
    "title": "There's a lot at stake for the tech giants betting big on wearables",
    "description": "The next big race among tech giants is building an AI device you'll want to wear all the time.",
    "fullText": "AI's next target? Helping you kick your phone addiction.\n\nAI devices are a top priority for Big Tech companies that view it as the future of how humans and AI interact, writes BI's Amanda Hoover.\n\nYou've likely heard of this hardware before, which acts as a sort of AI sidekick for your life. From the Rabbit R1 and Humane to Friend, the names are different, but the stories are the same: big expectations, difficult execution.\n\nAmanda's story covers how it's not just upstarts looking to shake things up. Tech giants like Apple, Meta, and OpenAI are working on their own solutions.\n\nIt's an uphill battle considering how addicted most of us are to our phones. However, the push for phone-free lifestyles, especially among Gen Z, does create an opening.\n\nThese tech giants also don't have much of a choice.\n\nApple, for example, has largely sat out the AI wars, saving a ton of money on model development. That only works if the iPhone remains a key distribution channel for the AI it's skipping out on developing.\n\nMeta's business is also heavily reliant on smartphone usage. (How often do you check Instagram on your desktop computer? Do you even have a desktop computer?) If user behavior around phones changes in a meaningful way, you can bet Meta wants to be ahead of it.\n\nAI devices also give companies a front-row seat to your life.\n\nYou could argue that's already the case with these AI chatbots. I'd argue the relationship between you and your chatbot of choice is still mostly transactional. You have a question/problem/thought; the chatbot has an answer (hopefully).\n\nThe relationship with AI wearables is more fluid. It's always listening, learning, and collecting. The pitch is that makes it a better copilot. Understanding your habits means it can figure out the best way to serve you.\n\nThat's putting a lot of faith, and your personal data, into an AI device, though\n\nMany executives I've spoken to have said this is the future. Truly leveraging AI is about incorporating it into your daily routine, not treating it as a one-off for specific problems.\n\nThe irony is that strategy has the potential to make AI even more addictive than the smartphones it's trying to replace.",
    "readingTime": 2,
    "keywords": [
      "tech giants",
      "desktop computer",
      "it's",
      "devices",
      "life",
      "phones",
      "choice",
      "argue",
      "that's",
      "relationship"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-next-target-phone-addiction-meta-wearable-openai-2026-2",
    "thumbnail_url": "https://i.insider.com/6995bb6ca645d11881897e5b?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:29.258Z",
    "topic": "finance"
  },
  {
    "slug": "business-insider-wins-first-george-polk-award",
    "title": "Business Insider wins first George Polk Award",
    "description": "Business Insider has won the Polk Award for The True Cost of Data Centers, an investigation revealing the hidden costs of the AI boom.",
    "fullText": "I'm thrilled to share that Business Insider has won the George Polk Award for Environmental Reporting for The True Cost of Data Centers, an investigation that created the most comprehensive national database of data centers and revealed hidden costs of the AI boom.\n\nThe George Polk Awards, which honor original, resourceful, and thought-provoking investigative work, are widely considered among the most prestigious in journalism. The judges said Business Insider's investigation was \"a thoroughly researched series highlighting the strain new and semi-secret facilities that fuel artificial intelligence are likely to place on communities, diverting overwhelming amounts of power, water and economic support.\"\n\nThis is Business Insider's first Polk Award. It is a milestone for our newsroom as we focus our investigative chops on the most crucial subjects in business, and as we combine our extraordinary talents across text, data, visuals, video, and more to deliver world-class journalism.\n\nThe True Cost of Data Centers identified 1,240 data centers built or approved across the US by the end of 2024 — nearly four times the number from 2010 — and exposed an infrastructure transformation happening almost entirely in secret. By filing public records requests across every US state and winning lawsuits to obtain water consumption data, our team uncovered how these data centers together would consume as much power as entire US states and guzzle enormous amounts of water daily in drought-stricken regions.\n\nBusiness Insider's investigation included a first-of-its-kind interactive national map displaying all 1,240 data centers for readers to see how close the data center boom is to their own backyards. It also included a documentary video, \"Exposing The Dark Side of America's AI Data Center Explosion,\" which has been watched more than 5 million times.\n\nThe database has been shared with 23 universities, including Harvard, MIT, Princeton, Stanford, Yale, and Columbia, and has been cited in at least 15 policy briefs.\n\nI am incredibly proud of this team for the creativity, care, and persistence it took to make this investigation happen. The reporting team includes Hannah Beckler, Dakin Campbell, Daniel Geiger, Rosemarie Ho, Narimes Parakul, Adam Rogers, and Ellen Thomas, along with editors Jeffrey Cane, Rosalie Chan, Jason Dean, Esther Kaplan, and Jake Swearingen.\n\nOn video, credit to Erica Berenstein, Alexander Calbi, Paige Clark, Robert Leslie, Reem Makhoul, Tyler Merkel, Ruqayyah Moynihan, Marco Secci, and Whitney Shefte. On design and visuals: Dan DeLerenzo, Isabel Fernandez-Pujol, Jinpeng Li, Kim Nguyen, Randy Yeip, and Rebecca Zisser, as well as photographers Kendrick Brinson, John David-Richardson, Greg Kahn, Brian Palmer, and Jesse Rieser.\n\nThanks also to Glen Smith on legal, Mo Mitchell on prizes, researchers Darren Ankrom, Schuyler Mitchell, Trey Strange, and Yuheng Zhan, and copy editors Mark Abadi and Kevin Kaplan.\n\nFinally, thank you to everyone throughout our newsroom and company who plays their part in making work like this possible and exceptional.",
    "readingTime": 3,
    "keywords": [
      "george polk",
      "polk award",
      "insider's investigation",
      "business insider's",
      "centers",
      "water",
      "across",
      "team",
      "database",
      "boom"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/business-insider-wins-first-george-polk-award-2026-2",
    "thumbnail_url": "https://i.insider.com/6995d47ea645d11881898085?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.985Z",
    "topic": "finance"
  },
  {
    "slug": "why-a-godfather-of-ai-still-thinks-his-4yearold-grandson-should-go-to-college",
    "title": "Why a godfather of AI still thinks his 4-year-old grandson should go to college",
    "description": "Yoshua Bengio, known as a \"godfather of AI\" alongside fellow computer scientists like Geoffrey Hinton and Yann LeCun, said education \" isn't just about acquiring the skills to get a job.\"",
    "fullText": "Is there any value in going to college when AI is expected to fundamentally reshape white-collar work?\n\nYes, according to Yoshua Bengio.\n\nOn Monday's episode of the \"Silicon Valley Girl\" podcast, its host Marina Mogilko asked Bengio if he would encourage his four-year-old grandson to go to college. Alongside fellow computer scientists Geoffrey Hinton and Yann LeCun, Bengio is known as one of the \"godfathers of AI\" thanks to his pioneering research in deep learning and neural networks.\n\nBengio quickly responded \"yes,\" adding: \"Education is really important, and education, contrary to what some people think, isn't just about acquiring the skills to get a job.\n\n\"Education is, in my opinion, mostly about how to become a better human being, how to understand yourself, how to understand our society and each other.\"\n\nBengio's comments add to the debate on whether it's worth pursuing the traditional college career pathway in a world where AI is matching or bettering humans on a wide range of cognitive tasks.\n\nHinton told a June episode of the \"Diary of a CEO\" podcast that AI may already be making it harder for college graduates to get jobs, and that it's a good time to become a plumber. Stanford professor Fei-Fei Li, nicknamed the \"Godmother of AI,\" told \"The Tim Ferriss Show\" in December that when hiring for her AI startup, a candidate's degree matters less than the tools they can use, including AI.\n\nBengio's comments on Monday echoed what he told \"The Diary of a CEO\" podcast in December, when he said his advice for his four-year-old grandson in our current world is to focus on being a \"beautiful human being.\"\n\n\"I think that part of ourselves will persist even if machines can do most of the jobs,\" he said.",
    "readingTime": 2,
    "keywords": [
      "bengio's comments",
      "ceo podcast",
      "four-year-old grandson",
      "college",
      "education",
      "episode",
      "hinton",
      "human",
      "understand",
      "it's"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-college-degree-go-college-white-collar-jobs-yoshua-bengio-2026-2",
    "thumbnail_url": "https://i.insider.com/6995cd42f8731049f3af4df7?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.728Z",
    "topic": "finance"
  },
  {
    "slug": "this-corner-of-the-tech-sector-will-offer-shelter-from-the-aidisruption-storm-analyst-says",
    "title": "This corner of the tech sector will offer shelter from the AI-disruption storm, analyst says",
    "description": "Wedbush said cybersecurity should be sheltered from AI disruption, while still benefitting from widespread adoption. It flagged its top three stock picks.",
    "fullText": "There's one corner of the tech sector where investors can hide out from AI disruption while still benefiting from the technology's adoption, Wedbush says.\n\nAnalysts led by Dan Ives, a vocal AI mega bull, flagged cybersecurity as a space that will see rising demand driven by AI, while steering clear of the AI worries that have rattled the market so far in 2026.\n\nExperts have called AI a double-edged sword for the cybersecurity industry, as the evolving technology is strengthening the capabilities of both cyber attackers and defenders.\n\n\"AI will be a major tailwind to the cyber security sector over the coming years as protection of use cases, data, and end points expand markedly,\" the analysts wrote.\n\n\"As attack frequency, success rates, and blast radius rise with AI deployments, cybersecurity becomes even more mission-critical risk management, reinforcing budget resilience in this new AI driven IT budget world,\" they added.\n\nCybersecurity is among the fastest growing areas of enterprise IT spending. Gartner expects global AI cybersecurity spending to hit $51 billion in 2026, roughly doubling from the year prior.\n\nWedbush highlighted three stocks as the best-positioned in the space: Palo Alto Networks, CrowdStrike, and Zscaler.\n\nWhat Wedbush says: \"We believe that CRWD's position as the gold standard of cybersecurity remains firmly unchanged in the face of this software sell-off with the company's innovative, best-in-class Falcon platform becoming increasingly effective in the modern threat landscape as AI adversaries become an incrementally larger threat for enterprises heading down the AI path.\"\n\nWhat Wedbush says: '\"AI is not displacing PANW's value proposition, but has actually made it more relevant, not less, as it is forcing customers to consolidate vendors, improve visibility, and automate response as threats become more adaptive and effective.\"\n\nWhat Wedbush says: \"AI is amplifying the need to secure access to data, models, and applications everywhere, reinforcing the mission-critical nature of ZS's offering, driving durable subscription growth and high renewal visibility.\"",
    "readingTime": 2,
    "keywords": [
      "what wedbush",
      "cybersecurity",
      "sector",
      "analysts",
      "space",
      "driven",
      "cyber",
      "mission-critical",
      "reinforcing",
      "budget"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/stock-picks-cybersecurity-tech-crowdstrike-palo-alto-networks-zcaler-wedbush-2026-2",
    "thumbnail_url": "https://i.insider.com/6995e8dfa645d118818982f9?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.388Z",
    "topic": "finance"
  },
  {
    "slug": "read-netflixs-legal-letter-to-bytedance-over-a-viral-ai-video-tool-it-calls-a-highspeed-piracy-engine",
    "title": "Read Netflix's legal letter to ByteDance over a viral AI video tool it calls a 'high-speed piracy engine'",
    "description": "Netflix sent TikTok parent ByteDance a cease-and-desist letter to over its AI video tool Seedance, following in Disney and Paramount's footsteps.",
    "fullText": "Netflix isn't amused by ByteDance's new AI video tool.\n\nThe streaming giant sent a cease-and-desist letter to the China-based TikTok parent on Tuesday night, calling its new generative AI model Seedance 2.0 \"a high-speed piracy engine.\"\n\nSeedance turned heads last week after a user created a viral video of people resembling Tom Cruise and Brad Pitt fighting on a rooftop about disgraced financier Jeffrey Epstein.\n\nWhile some were impressed, others panicked, with Deadpool cowriter Rhett Reese writing: \"I hate to say it. It's likely over for us.\"\n\nNetflix said in its letter to ByteDance that the company's AI video tool had also made videos mimicking characters from mega-hit Netflix shows like \"Stranger Things,\" \"Bridgerton,\" and \"Squid Game\" as well as the uber-popular movie \"KPop Demon Hunters.\"\n\n\"The use of copyrighted works to create a competing commercial product, especially one that regurgitates the original, is not protected by fair use,\" Netflix's litigation director wrote.\n\nNetflix urged ByteDance to stop generating AI videos that resemble its IP, and to identify and remove all such videos that have already been created. It also insisted that its IP be taken out of Seedance's training datasets.\n\nA ByteDance spokesperson said the company \"respects intellectual property rights\" and has \"heard the concerns regarding Seedance 2.0.\"\n\n\"We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,\" the ByteDance spokesperson said.\n\nDisney sent ByteDance a message similar to Netflix's last week. That's notable because Disney reached a deal in December to license iconic characters to OpenAI for its video-generating app Sora.\n\nSeedance is using \"a pirated library of Disney's copyrighted characters from Star Wars, Marvel, and other Disney franchises, as if Disney's coveted intellectual property were free public domain clip art,\" Disney said in its cease-and-desist letter to ByteDance.\n\nNetflix echoed that sentiment, saying it would \"not stand by and watch ByteDance treat our valued IP as free, public domain clip art.\"\n\nParamount Skydance also sent a cease-and-desist letter last week to ByteDance expressing similar concerns, Variety reported.\n\nRead Netflix's letter to ByteDance below:",
    "readingTime": 2,
    "keywords": [
      "domain clip",
      "clip art",
      "intellectual property",
      "cease-and-desist letter",
      "disney",
      "videos",
      "characters",
      "bytedance",
      "tool",
      "created"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/read-netflix-letter-bytedance-seedance-viral-ai-tool-piracy-disney-2026-2",
    "thumbnail_url": "https://i.insider.com/6995ef5aa645d118818983dc?width=1200&format=jpeg",
    "created_at": "2026-02-18T18:38:28.319Z",
    "topic": "finance"
  },
  {
    "slug": "when-every-company-can-use-the-same-ai-models-context-becomes-a-competitive-advantage",
    "title": "When Every Company Can Use the Same AI Models, Context Becomes a Competitive Advantage",
    "description": "When everyone has access to the same AI models, the same AI-enabled tools, and the same vendor ecosystem, organizational context becomes the differentiator. Context is demonstrated execution: the workflows teams actually follow across systems, the signals they respond to, the order in which roles get involved, the exceptions that trigger action, and the judgment calls that repeat across real work. These patterns are visible only in execution, not in stated process. Leaders need to understand why context has become a decisive source of competitive advantage, and how they can capture and operationalize it.",
    "fullText": "When Every Company Can Use the Same AI Models, Context Becomes a Competitive Advantage by Rohan Narayana Murty and Ravi Kumar SFebruary 18, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAt a glance, the two large B2B companies were almost identical. Both sell complex, multi-year technology services; they compete for many of the same enterprise customers. Sales stages, forecasting cadence, and executive review rhythms were the same. Going by their customer relationship management (CRM) systems, their processes looked indistinguishable.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/when-every-company-can-use-the-same-ai-models-context-becomes-a-competitive-advantage",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_18_MarianoPascual.jpg",
    "created_at": "2026-02-18T18:38:27.678Z",
    "topic": "business"
  },
  {
    "slug": "gemini-now-lets-you-generate-ai-music-for-free",
    "title": "Gemini Now Lets You Generate AI Music for Free",
    "description": "Lyria 3 means Google's AI bot now covers text, code, images, video, and songs.",
    "fullText": "Google Gemini can help you write text, generate images and video, and write code. Now, the AI bot can generate music too, taking on the likes of Suno when it comes to producing tunes from a simple text prompt. The update is courtesy of the new Lyria 3 audio generation model, which is built into Gemini as of today. Developed by Google DeepMind, Lyria has been accessible in other Google products (such as Vertex AI and YouTube Shorts) to a select number of users, but this is the first time Google is making the model widely available to anyone who wants to try it.\n\nLyria works the same way as creating images or video: just describe what you want, and the AI does the rest. You might want to hear \"a comical R&B slow jam about a sock finding their match\" (as per Google's own example), or perhaps \"a sea shanty about the dangers of AI slop\"—it's up to you.\n\nWhen you click the \"Create music\" button inside the Gemini app, you also have the option to pick an existing track to remix, rather than starting from scratch—If you're perhaps stuck for inspiration. These presets cover everything from folk ballads to Latin pop, so you can see the kind of musical scope covered. You can also supply Lyria 3 inside Gemini with an image or video, and get it to compose something that matches the mood of the content you've supplied, including both music and lyrics. The example Google gives is supplying Gemini with a few photos of your dog, and then having it come up with a tune about the pooch and their adventures.\n\nThe tracks are limited to 30 seconds each at the moment, and while music making is available to all Gemini users, if you're paying for the Plus, Pro, or Ultra subscriptions, you'll get higher usage limits (though it isn't specified what these are). As per the official announcement blog post, the aim \"isn't to create a musical masterpiece, but rather to give you a fun, unique way to express yourself.\" You're not going to be able to set up your own AI-generated band on Spotify with this, but you can churn out a few entertaining tracks for your own (or someone else's) amusement.\n\nI haven't been able to try out the feature as of yet, but I have heard a few samples that Google supplied. They come across as rather generic and ordinary, exactly as you might expect something to sound that's the averaging out of vast amounts of audio training data—like song genres distilled into their most common ingredients and repackaged.\n\nGoogle says all created tracks will contain invisible watermarks powered by SynthID, flagging them as AI creations, and you can upload audio tracks to Gemini and run a SynthID check on them. The updated Lyria 3 model is also coming to the Dream Track music maker for YouTube Shorts creators. Lyria 3 is now rolling out inside Gemini, and is available to users aged 18 and above in English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. It's available first on the web app, and will show up on the mobile app over the next few days. Expansions in \"quality and coverage\" are planned in the future, Google says.",
    "readingTime": 3,
    "keywords": [
      "inside gemini",
      "music",
      "tracks",
      "audio",
      "model",
      "users",
      "rather",
      "you're",
      "google",
      "text"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/gemini-now-lets-you-generate-ai-music-for-free?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KHRKMRTQQZSRSTPSKWCJ1GCW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-18T18:38:26.681Z",
    "topic": "tech"
  },
  {
    "slug": "microsofts-brad-smith-says-us-firms-should-worry-about-chinas-ai-subsidies",
    "title": "Microsoft’s Brad Smith says U.S. firms should \"worry\" about China’s AI subsidies",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/microsofts-brad-smith-says-us-firms-should-worry-about-chinas-ai-subsidies-4511809",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEEBK0BV_M.jpg",
    "created_at": "2026-02-18T18:38:26.279Z",
    "topic": "finance"
  },
  {
    "slug": "agent-panopticon-proxy-sidecar-for-autonomous-ai-agents",
    "title": "Agent Panopticon – Proxy sidecar for autonomous AI agents",
    "description": "Contribute to raka-gunarto/agent-panopticon development by creating an account on GitHub.",
    "fullText": "raka-gunarto\n\n /\n\n agent-panopticon\n\n Public\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n raka-gunarto/agent-panopticon",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/raka-gunarto/agent-panopticon",
    "thumbnail_url": "https://opengraph.githubassets.com/1e3cb205bafe6d7c2bbbb8f4e62a95a4220dddba16ab75d544484071d4fa6cdc/raka-gunarto/agent-panopticon",
    "created_at": "2026-02-18T12:37:14.664Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-bug-causes-copilot-to-summarize-confidential-emails",
    "title": "Microsoft says bug causes Copilot to summarize confidential emails",
    "description": "Microsoft says a Microsoft 365 Copilot bug has been causing the AI assistant to summarize confidential emails since late January, bypassing data loss prevention (DLP) policies that organizations rely on to protect sensitive information.",
    "fullText": "Microsoft says a Microsoft 365 Copilot bug has been causing the AI assistant to summarize confidential emails since late January, bypassing data loss prevention (DLP) policies that organizations rely on to protect sensitive information.\n\nAccording to a service alert seen by BleepingComputer, this bug (tracked under CW1226324 and first detected on January 21) affects the Copilot \"work tab\" chat feature, which incorrectly reads and summarizes emails stored in users' Sent Items and Drafts folders, including messages that carry confidentiality labels explicitly designed to restrict access by automated tools.\n\nCopilot Chat (short for Microsoft 365 Copilot Chat) is the company's AI-powered, content-aware chat that lets users interact with AI agents. ​Microsoft began rolling out Copilot Chat to Word, Excel, PowerPoint, Outlook, and OneNote for paying Microsoft 365 business customers in September 2025.\n\n\"Users' email messages with a confidential label applied are being incorrectly processed by Microsoft 365 Copilot chat,\" Microsoft said when it confirmed this issue.\n\n\"The Microsoft 365 Copilot 'work tab' Chat is summarizing email messages even though these email messages have a sensitivity label applied and a DLP policy is configured.\"\n\nMicrosoft has since confirmed that an unspecified code error is responsible and said it began rolling out a fix in early February. As of Wednesday, the company said it was continuing to monitor the deployment and is reaching out to a subset of affected users to verify that the fix is working.\n\n\"A code issue is allowing items in the sent items and draft folders to be picked up by Copilot even though confidential labels are set in place,\" Microsoft added.\n\nMicrosoft has not provided a final timeline for full remediation and has not disclosed how many users or organizations were affected, saying only that the scope of impact may change as the investigation continues.\n\nHowever, this ongoing incident has been tagged as an advisory, a flag commonly used to describe service issues typically involving limited scope or impact.\n\nModern IT infrastructure moves faster than manual workflows can handle.\n\nIn this new Tines guide, learn how your team can reduce hidden manual delays, improve reliability through automated response, and build and scale intelligent workflows on top of tools you already use.",
    "readingTime": 2,
    "keywords": [
      "label applied",
      "email messages",
      "tab chat",
      "microsoft copilot",
      "confidential",
      "emails",
      "january",
      "organizations",
      "service",
      "incorrectly"
    ],
    "qualityScore": 0.9,
    "link": "https://www.bleepingcomputer.com/news/microsoft/microsoft-says-bug-causes-copilot-to-summarize-confidential-emails/",
    "thumbnail_url": "https://www.bleepstatic.com/content/hl-images/2025/09/16/Copilot_headpic.jpg",
    "created_at": "2026-02-18T12:37:14.182Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-pledges-50b-to-tackle-growing-ai-inequality",
    "title": "Microsoft pledges $50B to tackle growing AI inequality",
    "description": "Microsoft says it is on track to invest $50 billion by the end of the decade to help bring artificial intelligence to lower-income countries, as concerns mount over the technology’s potential to deepen inequality.",
    "fullText": "Microsoft says it is on track to invest $50 billion by the end of the decade to help bring artificial intelligence to lower-income countries, as concerns mount over the technology’s potential to deepen inequality.\n\nThe announcement was made Wednesday at the AI Impact Summit in New Delhi, where leading tech executives, government officials and AI researchers are debating how to use AI to solve real-world problems.\n\nPolicymakers globally are increasingly worried that the unequal adoption of AI risks widening income and development gaps between rich and poor countries. In December, the United Nations Development Project called for global cooperation on standards and safety to ensure the technology “functions as a shared public good rather than a concentrated advantage.”\n\nAt the summit, Microsoft likewise expressed the need for cross-border partnerships to prevent poorer countries from being left behind.\n\n“We need to act with urgency to address the growing AI divide,” Microsoft president Brad Smith and chief responsible AI officer Natasha Crampton said in a joint statement. “Artificial intelligence is diffusing at an impressive speed, but its adoption around the world remains profoundly uneven.”\n\nThe company’s $50 billion commitment to developing economies by 2030 compares with the roughly $80 billion that Microsoft invested into data centers last year alone, more than half of which was directed to a single economy: the United States.\n\nA recent Microsoft report found that AI usage in the global north, a catch-all term for developed and high-income countries, is roughly twice that of the global south — and growing.\n\n“This disparity impacts not only national and regional economic growth, but whether AI can deliver on its broader promise of expanding opportunity and prosperity around the world,” Smith and Crampton said.\n\nThey warned that, just as unequal access to electricity has exacerbated a growing economic gap between the global north and south, without urgent action, the AI divide could perpetuate that disparity in the century ahead.\n\nOn the other hand, the technology could be used positively to help poor countries leapfrog older development pathways. “If AI is deployed broadly and used well by a young and growing population, it offers a real prospect for catch-up economic growth for the Global South,” said Smith and Crampton.\n\n“It might even provide the biggest such opportunity of the 21st century,” the pair said.\n\nMicrosoft’s $50 billion investment will, among other things, help to build the data centers crucial to providing the computing power needed to run AI models. Extending internet access is another focus.\n\nOnly about 36% of Africa’s population had broadband internet access in 2022, according to the World Bank. That compares with some 90% of US households, official figures show.\n\nThe AI Impact Summit, hosted by India’s Prime Minister Narendra Modi, highlights the country’s ambition to position itself as an AI leader in the global south.\n\nHigh-profile attendees include Sam Altman of OpenAI, the developer of ChatGPT, Anthropic CEO Dario Amodei and Google CEO Sundar Pichai who is due to deliver a keynote address on Friday.",
    "readingTime": 3,
    "keywords": [
      "impact summit",
      "artificial intelligence",
      "economic growth",
      "internet access",
      "development",
      "unequal",
      "adoption",
      "poor",
      "technology",
      "address"
    ],
    "qualityScore": 1,
    "link": "https://www.cnn.com/2026/02/18/business/ai-impact-summit-microsoft-inequality-investment",
    "thumbnail_url": "https://media.cnn.com/api/v1/images/stellar/prod/2026-02-18t055009z-946177043-rc2lnjaf3v8r-rtrmadp-3-india-ai-summit-microsoft.jpg?c=16x9&q=w_800,c_fill",
    "created_at": "2026-02-18T12:37:13.863Z",
    "topic": "business"
  },
  {
    "slug": "openai-meta-and-apples-latest-battle-breaking-your-phone-addiction",
    "title": "OpenAI, Meta, and Apple's latest battle: Breaking your phone addiction",
    "description": "The tech companies that created our phone addiction are trying to cure us with AI wearables.",
    "fullText": "The average American picks up their phone more than 200 times a day. Teens are pinged with some 250 notifications a day — during school, after school, and overnight. The apps meant to prevent you from checking apps have done little to stop the problem. Now, some of the tech companies that helped create our screen dependence are trying to disrupt it.\n\nLater this year, OpenAI plans to debut a small, screenless device that Sam Altman describes as more \"peaceful\" than a smartphone. Apple, the Oz of screentime, is developing smart glasses, a pin, and AirPods with more AI built in, according to a Tuesday report from Bloomberg, with the rumored pendants featuring microphones and cameras to be the \"eyes and ears\" of the iPhone. Meta has teased its fully augmented reality Orion glasses since 2024. While that device doesn't have a release date, the company last year sold some 7 million pairs of its smart glasses, which is the start of the post-smartphone future Mark Zuckerberg has predicted. Eventual smart specs could be more screen all-the-time than screenless, but they also rely on AI to make the experience much more hands-free than swiping and scrolling on a phone.\n\nCould AI be what finally breaks our phone addiction?\n\nSince 2007, no device out of Silicon Valley has captured universal imagination the way Steve Jobs did when he put your iPod, your phone, and the internet together on a 3.5-inch screen. Competitors have tried for a decade-plus to get people to shift us from the iPhone to smart glasses, and largely failed. The awe around smartphones has turned to derision, as excessive screen time is linked to disrupted sleep, anxiety, and fractured attention. Now, developers are hoping the AI boom can give us the next big thing.\n\nBeating the smartphone would mean replacing a device that 91% of American adults now carry — a device for which millions of apps have been developed and people now depend on in lieu of wallets and cameras and health monitors. New AI devices can't just copy what smartphones do, says Ramon Llamas, a research director at a technology intelligence firm IDC: They have to show they have a solution to an everyday problem. If they don't, Llama says, \"these things are just gonna really end up as solutions looking for a problem to solve.\"\n\nCritiques of screen time can be as blunt and smoothbrained as what the critics say excessive screen time makes you. A seven-hour daily log may seem like a staggering amount of dependence, but what did the person spend those seven hours doing? Doomscrolling late into the night, or FaceTiming with a far-away friend? With AI wearables, there's the risk of becoming dependent on the device for different reasons.\n\n\"The screen may not be there, but what's getting filled in the back is already this problem of AI companionship,\" says Olivia Gambelin, an AI ethicist and author of the book \"Responsible AI.\" An AI device designed to do something very specific — like listen to a meeting and then send follow-up emails or messages related to action points discussed — could save people time and keep them from writing tedious emails and Slack messages from their desk. But that same device listening in to personal conversations with family and friends could compromise a relationship, and erode the positive effects that texting a friend to check-in can have on both people (already, my friends are tiring of AI summaries on the iPhone that summarize our group text and become an intermediary into our threads of gossip and jokes in the name of efficiency). Wearing microphones and cameras to social interactions and into businesses is likely to really weird out some of the people around you. More people are entering into romantic, dependent relationships with AI companions, and a swell of loud dissenters are criticizing the technology for taking jobs and attempting to replicate human relationships.\n\nBut OpenAI is betting that it can package its technology in a device in a way that calms the user. \"When I use current devices or most applications, I feel like I am walking through Times Square in New York and constantly just dealing with all the little indignities along the way,\" Altman said in November. OpenAI's device, he said, would be less Time Square, more \"sitting in the most beautiful cabin by a lake and in the mountains and sort of just enjoying the peace and calm.\" That's because the AI device would learn \"contextual awareness of your whole life,\" and when best to send you alerts.\n\nOther AI wearables have failed by falling short of that goal. Humane AI sold a wearable pin, priced at $700 plus a monthly fee to connect it, but pulled it from the market a year ago. It failed perhaps because it tried too hard to replace our phones — it didn't interact with them, but provided a shoddy replacement. Novelty wasn't a factor that could outshine usability. The AI Friend pendant, which can't search the internet or help with tasks outside of sending reminders and acts instead as an eavesdropping sycophant around its user's neck, was mocked relentlessly and sold just a few thousand devices after it hit the market last year.\n\nCompanies trying to make AI hardware should focus on \"transformative features,\" Jason Low, research director at Omdia, tells me in an email. AI wearables must be more than \"marginally more convenient,\" should integrate with our existing products, and have a clear, stated value. For example, glasses that provide real-time language translation or devices for fitness and health tracking offer features our smartphones can't do as well. The Oura ring continues to grow in popularity, particularly among women after starting out as a niche tech bro buy, for the novel insights it can offer; the company announced last fall it has sold 5.5 million rings since 2015, with more than 2.5 million sold between June 2024 and September 2025. \"These devices often deliver a more polished user experience compared to general-purpose, do-it-all AI devices,\" Low says.\n\nLlamas tells me that the AI functions of a wearable have to be \"contextual, personalized, and actionable,\" like reminding the wearer to send birthday flowers or responding accurately to being asked to direct the user to the nearest Starbucks. A first attempt device shouldn't try to replace the smartphone, but to integrate with the Apple or Google ecosystems, he says. Apple and OpenAI did not respond to requests for comment about their rumored products for this story.\n\nIf anything has hyped Silicon Valley like the iPhone, it's been AI. But three years after the mainstream adoption of ChatGPT, the value generative AI in the white collar workforce has yet to be fully realized. That could make a product for consumers a hard sell, too. \"Some of the overwhelm that's coming with AI that I see in general users is you can use it for everything, or it's promoted that way, which is actually quite stifling,\" Gambelin says.\n\nIn our quest to find a peaceful equilibrium with tech, the screen itself may not be the problem; it's what's summoning us to the screen. Its bright colors, games, and infinite scroll give quick dopamine hits that entice us to stay glued to it. But much of what pings my phone throughout the day are useless notifications trying to get me to reopen one of the dozens of apps — a markdown moment on a clothing thrifting app, a like on the Instagram story I've posted of my dog from my best friend, and ironically, a report of how much time I've already logged. There's a relentless business model at play to keep us on these apps. No screens would mean no infinite scroll through TikTok, no Candy Crush — but app developers and companies may need to find new ways to reach people if wearables caught on, and an always-there AI device and companion might not be as peaceful as Altman describes. Our collective screen time is a problem, but the AI wearable will have to surprise us all with something novel to be useful.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 7,
    "keywords": [
      "research director",
      "infinite scroll",
      "smart glasses",
      "excessive screen",
      "silicon valley",
      "device",
      "devices",
      "phone",
      "apps",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-meta-apple-wearables-phone-addiction-2026-2",
    "thumbnail_url": "https://i.insider.com/6994e2ade1ba468a96ac31ae?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.292Z",
    "topic": "finance"
  },
  {
    "slug": "anthropics-claude-code-creator-predicts-software-engineering-title-will-start-to-go-away-in-2026",
    "title": "Anthropic's Claude Code creator predicts software engineering title will start to 'go away' in 2026",
    "description": "Boris Cherny, the founder of Anthropic's Claude Code, said AI has largely solved coding, so software engineers will start to take on different tasks.",
    "fullText": "The creator of a popular AI coding agent said software engineering as a job title will soon be a thing of the past as artificial intelligence automates writing code.\n\nBoris Cherny, who created Claude Code at Anthropic, said in an interview with Y Combinator's \"Lightcone\" podcast that 2026 will bring \"insane\" developments to AI. That includes a massive shift in the work software engineers do across industries.\n\n\"I think today coding is practically solved for me, and I think it'll be the case for everyone regardless of domain,\" Cherny said in the interview, published Tuesday. \"I think we're going to start to see the title 'software engineer' go away. And I think it's just going to be maybe builder, maybe product manager, maybe we'll keep the title as a vestigial thing.\"\n\nCherny added that software engineers will not only be coding but increasingly taking on other tasks like \"writing specs\" — a document that defines what and how something will be built — or talking to users.\n\n\"Like this thing that we're starting to see right now in our team, where engineers are very much generalists, and every single function on our team codes,\" he said — including product managers, designers, engineering manager, and finance people.\n\nTech executives and founders have said advancements in AI have rapidly changed the way their teams operate in the past few years\n\nJesal Gadhia, a startup founder, recently told Business Insider that all the code for his company were written by agents, which wouldn't have been possible in 2024.\n\nAgents like Claude have changed how software engineers work as they spend more time reviewing or debugging code rather than writing lines of it.\n\nSome in the industry have started to note the unintended consequences of relying on AI. A software engineer told Business Insider that AI has simultaneously made them productive and overworked, leading to \"AI fatigue.\"\n\nAndrej Karpathy, a founding member of OpenAI and Tesla's ex-head of AI, said in January that he has noticed his ability to manually code has started to \"atrophy.\"",
    "readingTime": 2,
    "keywords": [
      "software engineer",
      "software engineers",
      "business insider",
      "coding",
      "title",
      "engineering",
      "interview",
      "we're",
      "product",
      "manager"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-claude-code-founder-ai-impacts-software-engineer-role-2026-2",
    "thumbnail_url": "https://i.insider.com/69951a8aa645d11881897ccb?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.284Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-software-freakout-is-a-massive-overreaction-heres-why",
    "title": "The AI software freakout is a massive overreaction. Here's why.",
    "description": "The SaaSpocalypse fears are overblown. AI's integration into enterprise software may boost, not harm, established SaaS companies.",
    "fullText": "The recent AI-inspired software meltdown is an enormous overreaction. SaaS companies are going to do just fine. In fact, they might see their businesses boom as a result of AI.\n\nAfter working for decades in the IT and cloud sectors, I know what it takes to build, sell, and maintain complex enterprise software. And it's clear to me that AI is not the threat that many investors fear.\n\nLet's look at the three main concerns that the market is obsessing over. All of them have shortcomings that will keep established SaaS vendors doing well.\n\nSoftware development has been transformed by AI. It's a near-perfect use case for generative AI: applying established patterns to a well-bounded use case, resulting in incredible productivity improvements.\n\nThis coding revolution has led some commentators to predict that companies are going to write their own software, rather than buy it from SaaS vendors.\n\nThis makes me wonder if these commentators have ever actually spent any time working in enterprise IT. Even if one accepts that software creation is much easier now, bringing a full software product to market requires much more than code:\n\nGeoffrey Moore, a renowned management consultant and organizational theorist, wrote a book called \"Crossing the Chasm\" on what mainstream enterprises need to adopt new technology. He never mentioned the cost of writing software code as a gating factor.\n\nOver the course of my long career, I have witnessed countless DIY failures by enterprise IT organizations that fail to understand the difference between an internal software project and a real product. I can already see another wave of failures, fueled by misplaced AI coding enthusiasm.\n\nAI prognosticators see cheaper startups displacing large software incumbents. This overlooks the reality that established SaaS providers already have smaller, cheaper competitors yet somehow remain dominant. The challenges for new entrants to a software sector include:\n\nIt's incredibly difficult for a small startup to displace an incumbent vendor. As Clayton Christensen observed in \"The Innovators Dilemma,\" innovative startups usually begin by solving use cases incumbent vendors are unable or unwilling to serve.\n\nLeft unaddressed in this scenario is why incumbents wouldn't just use AI themselves to improve engineering efficiency to address any price pressure from smaller new rivals.\n\nThis is the idea that AI model companies will extend their nascent software products into vertical offerings, thereby killing off incumbent vendors.\n\nOpenAI made a big splash with a healthcare initiative, for example. Anthropic caused a bunch of software stocks to drop with its plugins.\n\nIt's understandable why these companies launched these initiatives. Many industry-specific software companies are highly profitable, so AI labs would love to get a piece of this business.\n\nPursuing this, while working on other initiatives, could spread AI labs too thin, though. Startups often fail due to a lack of focus, and this is especially apropos for AI model makers. They face enormous, unprecedented opportunity, and getting distracted by bright, shiny vertical SaaS offerings is a terrible idea.\n\nGoing back to the DIY section above, there's huge complexity and cost to shipping and maintaining real enterprise software. Now multiple this by all the various industry verticals that exist, such as healthcare, financial services, and manufacturing. Addressing the idiosyncratic requirements of each sector would require huge numbers of employees, along with management time and attention. The model makers are already growing at breakneck speed; trying to add enough people to become vertical software providers would be a Sisyphean task.\n\nIf I were advising these boards, I would argue for focus: win the horizontal AI model layer in what is likely to become a small oligopoly.\n\nAnd yes, expand AI coding capabilities that lower the cost of development and increase the global population of software creators. That dynamic could trigger Jevons Paradox — cheaper software leading to vastly more of it — enriching the model providers without forcing them into every software vertical.\n\nThe SaaSpocalypse will, in retrospect, come to be thought of like the Beanie Babies mania: a short-lived phenomena that now seems inexplicable to comprehend.\n\nBernard Golden is CEO of Navica, a Silicon Valley-based technology analysis, consulting, and investment firm.",
    "readingTime": 4,
    "keywords": [
      "established saas",
      "saas vendors",
      "model makers",
      "incumbent vendors",
      "enterprise software",
      "vertical",
      "coding",
      "cheaper",
      "startups",
      "providers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/saaspocalypse-ai-software-overreaction-premature-obituary-openai-anthropic-2026-2",
    "thumbnail_url": "https://i.insider.com/6994e810a645d11881897add?width=1166&format=jpeg",
    "created_at": "2026-02-18T12:37:13.268Z",
    "topic": "tech"
  },
  {
    "slug": "cios-are-telling-companies-that-ai-capex-spending-has-gone-too-far",
    "title": "CIOs are telling companies that AI capex spending has gone too far",
    "description": "The highest portion of fund managers on record think that companies are overspending on capex.",
    "fullText": "Silicon Valley hyperscalers made it clear during the year's first earnings week they don't plan to dial back AI capex spending. Based on new survey results, Wall Street doesn't approve.\n\nBank of America surveyed 162 fund managers overseeing a combined $440 billion, and a record portion of them said they think companies are \"overinvesting\" in capex.\n\nOn top of that, more CIOs are leaning in favor of decreasing capex spending. Only 20% of survey respondents have advocated for increasing capex, down from 34%.\n\nThat may be because they see AI as an increasing risk to the market's strength in 2026. 25% of survey respondents reported that they see the AI bubble as the largest tail risk, more so than inflation, geopolitical conflict or a disorderly increase in bond yields.\n\nMeanwhile, a fair amount of investors made it clear that they believe AI hyperscaler capex poses another significant threat. 30% of survey respondents revealed that they see it as the most likely source of a systemic credit event.\n\nA year ago, it might have seemed absurd to suggest that tech companies should spend less money on building out AI models and infrastructure. But over the last few quarters, investors have raised the bar for what they expect from companies heavily investing in AI.",
    "readingTime": 2,
    "keywords": [
      "survey respondents",
      "capex",
      "increasing",
      "risk",
      "investors"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-capex-overspending-bofa-fund-manager-survey-hartnett-2026-2",
    "thumbnail_url": "https://i.insider.com/6994b634e1ba468a96ac2cb9?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:13.267Z",
    "topic": "finance"
  },
  {
    "slug": "jake-paul-says-sam-altman-taught-him-the-value-of-a-15minute-meeting",
    "title": "Jake Paul says Sam Altman taught him the value of a 15-minute meeting",
    "description": "Jake Paul said that OpenAI CEO Sam Altman, who he bonded with over \"fast cars,\" taught him to be \"hella productive\" with meetings.",
    "fullText": "Jake Paul was a firebrand YouTuber. Then he was an NFT merchant, and a betting site operator. Now, Paul is a professional boxer — and venture capitalist. And he's learning from one of the biggest names in tech.\n\nOn \"Sourcery,\" Paul said that he met OpenAI CEO Sam Altman while sitting next to each other at President Donald Trump's inauguration.\n\n\"Sam likes fast cars, and so do I,\" Paul said. \"So, we just started talking about cars, and then we got along, and that was really it.\"\n\nPaul's Anti Fund — which is also led by his brother Logan and longtime founder Geoffrey Woo — invested in OpenAI in 2025. The biggest lesson he's learned from Altman is efficiency, Paul said.\n\nHe described the quick-and-tidy meetings that Altman runs. The OpenAI CEO \"walks into the room, sits down, let's get right into the conversation, boom boom boom,\" he said.\n\nIn 15 minutes alone, Altman was \"hella productive,\" Paul said. Then, Altman can go on to his next meeting and do it all over again.\n\n\"We'll do hourlong meetings or calls and just waste time,\" Paul said. \"I think that was inspiring because time is the most valuable thing, and it's the only reason you can't accomplish more.\"\n\nIndeed, Altman has long opted for the 15-minute meeting. In a 2018 blog post, he wrote that the ideal meeting time is either around 15 to 20 minutes or 2 hours, but \"the default of 1 hour is usually wrong.\"\n\nPaul has worked closely with OpenAI in the last year, beyond participating in fundraising.\n\nRemember all of those strange Paul memes running around the internet during the Sora 2 launch? They were by design. Paul said he helped consult on the project and was one of the first to sign over his name, image, and likeness.\n\nWoo also appeared on the podcast, and spelled out the thinking behind those far-out memes (such as an AI Paul declaring he was gay). \"It was not something that was like, 'Hey, Jake Paul is now gay.' Jake was thoughtful in terms of why we were part of that launch.\"\n\nWoo also said that he had formed a good friendship with Altman and Mark Chen, OpenAI's chief research officer.\n\nFor the Sora 2 launch, Paul said that he had \"regular calls\" with OpenAI and offered \"super detailed consulting.\"\n\n\"Me and my brother have however many years combined of social media experience since the beginning,\" Paul said. \"We were there when the term 'influencer' was even made up.\"\n\nThis background, Paul said, helped him give good advice on what OpenAI's social media-like interface should look like. He advised on both what creators and audiences wanted, he said.\n\nAnti Fund closed its $30 million fund in September. Other investments include defense tech startup Anduril and prediction market Polymarket.\n\nWoo said their ties to OpenAI remain strong. \"We were just at OpenAI for three hours looking for other ways to collaborate,\" he said. \"Things might be cooking.\"",
    "readingTime": 3,
    "keywords": [
      "sora launch",
      "openai ceo",
      "boom boom",
      "paul",
      "altman",
      "he's",
      "biggest",
      "tech",
      "cars",
      "brother"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-15-minute-meetings-efficient-jake-paul-2026-2",
    "thumbnail_url": "https://i.insider.com/69948dcaa645d118818970ae?width=1200&format=jpeg",
    "created_at": "2026-02-18T12:37:12.865Z",
    "topic": "finance"
  },
  {
    "slug": "investor-dan-ives-says-the-tech-selloff-that-has-been-spooking-markets-is-actually-a-generational-opportunity-to-get-in",
    "title": "Investor Dan Ives says the tech selloff that has been spooking markets is actually a ‘generational opportunity’ to get in on the action",
    "description": "Investors are drawing their battle lines as AI sorts tech companies into winners and losers.",
    "fullText": "The once relentless rally in AI-fueled stocks has lost momentum, as investors confront the unsettling idea that advances in artificial intelligence could erode the very value propositions that made tech giants dominant in the first place. Yet some executives and market veterans warn against short-term panic, calling the selloff a rare opportunity to buy into the next phase of the AI boom.\n\nThe AI growth story has been tempered by a widespread selloff in software stocks. Call it the software-mageddon or the SaaSpocalypse, but companies who specialize in designing, selling, and maintaining digital software products are getting battered. Earlier this month, JPMorgan analysts wrote that software companies had lost around $2 trillion in value over the past year, calling it “the largest non-recessionary 12-month drawdown in over 30 years.”\n\nThe culprit has been an increasingly widespread feeling among investors that AI is sorting tech players into winners and losers. Under this view, software companies could fall into the latter camp as the capabilities of newer AI models promise to replace expensive digital services, rendering the business models of companies like Salesforce and Atlassian obsolete.\n\nBut not all investors are convinced these companies are destined for irrelevance. Hidden within the chaos could lie an undervalued chance to buy these tech stocks at a discount, a relative rarity in an age of soaring valuations and speculative growth. It all depends on whether bullish buyers consider AI as complementary to existing software services, or capable enough to replace them entirely.\n\n“I think this software selloff will go down as a generational opportunity to own some of the stalwarts,” Dan Ives, a managing director and senior equity research analyst at Wedbush Securities, said in a Yahoo Finance interview Friday. “I feel more emboldened about the bull thesis on tech and AI this year, despite obviously this massive pullback.”\n\nIves named three industry leaders that he sees as being unfairly punished in today’s market, and that could be in for a powerful rebound:\n\nIves called the software stock correction a “structural selloff” that was the largest in scale he’d seen in 25 years. But instead of spelling doom for these companies, he framed the wipeout as a once-in-a-lifetime opportunity to invest in enterprise technology, arguing that software developers will remain a “core part of the use cases,” even in an AI-powered future.",
    "readingTime": 2,
    "keywords": [
      "software",
      "tech",
      "selloff",
      "stocks",
      "investors",
      "opportunity",
      "market",
      "growth",
      "widespread",
      "digital"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/investor-dan-ives-says-tech-171414614.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/lm.wqBfnfQfRbIxr0gVgeQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/dbe82f78842f4e2e71e45ec99f99249e",
    "created_at": "2026-02-18T12:37:08.135Z",
    "topic": "finance"
  },
  {
    "slug": "race-for-ai-is-making-hindenburgstyle-disaster-a-real-risk-says-leading-expert",
    "title": "Race for AI is making Hindenburg-style disaster ‘a real risk’, says leading expert",
    "description": "Prof Michael Wooldridge says scenario such as deadly self-driving car update or AI hack could destroy global interest\nThe race to get artificial intelligence to market has raised the risk of a Hindenburg-style disaster that shatters global confidence in the technology, a leading researcher has warned.\nMichael Wooldridge, a professor of AI at Oxford University, said the danger arose from the immense commercial pressures that technology firms were under to release new AI tools, with companies desperate to win customers before the products’ capabilities and potential flaws are fully understood.\n Continue reading...",
    "fullText": "Prof Michael Wooldridge says scenario such as deadly self-driving car update or AI hack could destroy global interest\n\nThe race to get artificial intelligence to market has raised the risk of a Hindenburg-style disaster that shatters global confidence in the technology, a leading researcher has warned.\n\nMichael Wooldridge, a professor of AI at Oxford University, said the danger arose from the immense commercial pressures that technology firms were under to release new AI tools, with companies desperate to win customers before the products’ capabilities and potential flaws are fully understood.\n\nThe surge in AI chatbots with guardrails that are easily bypassed showed how commercial incentives were prioritised over more cautious development and safety testing, he said.\n\n“It’s the classic technology scenario,” he said. “You’ve got a technology that’s very, very promising, but not as rigorously tested as you would like it to be, and the commercial pressure behind it is unbearable.”\n\nWooldridge, who will deliver the Royal Society’s Michael Faraday prize lecture on Wednesday evening, titled “This is not the AI we were promised”, said a Hindenburg moment was “very plausible” as companies rushed to deploy more advanced AI tools.\n\nThe Hindenburg, a 245-metre airship that made round trips across the Atlantic, was preparing to land in New Jersey in 1937 when it burst into flames, killing 36 crew, passengers and ground staff. The inferno was caused by a spark that ignited the 200,000 cubic metres of hydrogen that kept the airship aloft.\n\n“The Hindenburg disaster destroyed global interest in airships; it was a dead technology from that point on, and a similar moment is a real risk for AI,” Wooldridge said. Because AI is embedded in so many systems, a major incident could strike almost any sector.\n\nThe scenarios Wooldridge imagines include a deadly software update for self-driving cars, an AI-powered hack that grounds global airlines, or a Barings bank-style collapse of a major company, triggered by AI doing something stupid. “These are very, very plausible scenarios,” he said. “There are all sorts of ways AI could very publicly go wrong.”\n\nDespite the concerns, Wooldridge said he did not intend to attack modern AI. His starting point is the gap between what researchers expected and what has emerged. Many experts anticipated AI that computed solutions to problems and provided answers that were sound and complete. “Contemporary AI is neither sound nor complete: it’s very, very approximate,” he said.\n\nThis arises because large language models, which underpin today’s AI chatbots, rattle out answers by predicting the next word, or part of a word, based on probability distributions learned in training. It leads to AIs with jagged capabilities: incredibly effective at some tasks, yet terrible at others.\n\nThe problem, Wooldridge said, was that AI chatbots failed in unpredictable ways and had no idea when they were wrong, but were designed to provide confident answers regardless. When delivered in human-like and sycophantic responses, the answers could easily mislead people, he added. The risk is that people start treating AIs as if they were human. In a 2025 survey by the Center for Democracy and Technology, nearly a third of students reported that they or a friend had had a romantic relationship with an AI.\n\n“Companies want to present AIs in a very human-like way, but I think that is a very dangerous path to take,” Wooldridge said. “We need to understand that these are just glorified spreadsheets, they are tools and nothing more than that.”\n\nWooldridge sees positives in the kind of AI depicted in the early years of Star Trek. In one 1968 episode, The Day of the Dove, Mr Spock quizzes the Enterprise’s computer only to be told in a distinctly non-human voice that it has insufficient data to answer. “That’s not what we get. We get an overconfident AI that says: yes, here’s the answer,” he said. “Maybe we need AIs to talk to us in the voice of the Star Trek computer. You would never believe it was a human being.”",
    "readingTime": 4,
    "keywords": [
      "the hindenburg",
      "risk",
      "commercial",
      "tools",
      "chatbots",
      "wooldridge",
      "scenario",
      "deadly",
      "self-driving",
      "hack"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/feb/17/ai-race-hindenburg-style-disaster-a-real-risk-michael-wooldridge",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ece0f11b49a602a64f2f6c233331b06d7d3a4b00/189_0_2810_2249/master/2810.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b4f173b1c88631c2453efad56fff6227",
    "created_at": "2026-02-18T12:37:07.113Z",
    "topic": "science"
  },
  {
    "slug": "tech-billionaires-fly-in-for-delhi-ai-expo-as-modi-jostles-to-lead-in-south",
    "title": "Tech billionaires fly in for Delhi AI expo as Modi jostles to lead in south",
    "description": "Google, Anthropic and OpenAI bosses to mingle with global south leaders wrestling for control over technology\nSilicon Valley tech billionaires will land in Delhi this week for an AI summit hosted by India’s prime minister, Narendra Modi, where leaders of the global south will wrestle for control over the fast-developing technology.\nDuring the week-long AI Impact Summit, attended by thousands of tech executives, government officials and AI safety experts, tech companies valued at trillions of dollars will rub along with leaders of countries such as Kenya and Indonesia, where average wages dip well below $1,000 a month.\n Continue reading...",
    "fullText": "Google, Anthropic and OpenAI bosses to mingle with global south leaders wrestling for control over technology\n\nSilicon Valley tech billionaires will land in Delhi this week for an AI summit hosted by India’s prime minister, Narendra Modi, where leaders of the global south will wrestle for control over the fast-developing technology.\n\nDuring the week-long AI Impact Summit, attended by thousands of tech executives, government officials and AI safety experts, tech companies valued at trillions of dollars will rub along with leaders of countries such as Kenya and Indonesia, where average wages dip well below $1,000 a month.\n\nAmid a push to speed up AI adoption across the globe, Sundar Pichai, Sam Altman and Dario Amodei, the heads of Google, OpenAI and Anthropic, will all be there. Rishi Sunak and George Osborne, a former British prime minister and a former chancellor, will each be pushing for greater adoption of AI. Sunak has taken jobs for Microsoft and Anthropic and Osborne leads OpenAI’s push to deepen and widen the use of ChatGPT beyond its existing 800 million users.\n\nMeanwhile Modi, who will address the summit on Thursday, is positioning India as the AI hub for south Asia and Africa. On the agenda will be AI’s potential to transform agriculture, water supplies and public health. Governments in Kenya, Senegal, Mauritius, Togo, Indonesia and Egypt will send ministers.\n\nModi’s enthusiasm for AI has a darker side, civil liberties campaigners say. Last week they raised serious concerns about India deploying AI to increase state surveillance, discriminate against minorities and sway elections. But Modi this week spoke of “harnessing artificial intelligence for human-centric progress” and India has given the summit the strapline: “Welfare for all, happiness for all.”\n\nSummit observers talk of a battle between a new kind of AI colonialism from the US tech firms and an alternative “techno-Gandhism”, in which AI is used for social justice and to benefit marginalised people. After global AI summits in the UK, Korea and France, the Delhi meeting is the first to be held in the global south.\n\nIndian commentators say the test of AI’s value is not in its technical sophistication but whether it can improve the lives of people living in some of the toughest circumstances in the global south. By contrast, US AI companies are racing for supremacy, competing with each other and China, and rolling out AI for shopping, personal companionship and agentic systems that could slash corporate labour costs by making white-collar jobs redundant.\n\nIf a referee between the two sides is needed, António Guterres, the secretary general of the United Nations, will speak in Delhi. This week he said it would be “totally unacceptable that AI would be just a privilege of the most developed countries or a division only between two superpowers”.\n\nIndia’s AI Impact Summit is the fourth iteration of the event, which Sunak launched in 2023 at Bletchley Park in the UK, with a focus on international coordination to prevent catastrophic risks from the most advanced AI models. Summits followed in Seoul in 2024 and Paris in 2025, where the US vice-president, JD Vance, appeared to abandon the White House’s interest in safety saying: “The AI future will not be won by hand-wringing about safety; it will be won by building.”\n\nSafety is once again on the agenda, with Yoshua Bengio, one of the “godfathers” of AI, on hand to repeat his fears about the risk of powerful AI systems enabling cyber- and bioweapons attacks.\n\n“The capabilities of AI have continued to advance, and although mitigation and risk management of AI has also progressed [it has happened] not as quickly,” he said on Tuesday. “So it becomes urgent that leaders of this world understand where we could be going and it needs their attention and intervention as soon as possible.”\n\nOne of those working at the summit to make sure AI remains safe will be Nicolas Miaihle, co-founder of the AI Safety Connect group, who noted that the summit was taking place in the shadow of AI-enabled warfare in Ukraine and the Middle East.\n\n“The existential risks are not going anywhere,” he told the Guardian. “When Rishi Sunak started this, the race was not raging as hard. The trillions are pouring in but we are very far away from securing these models. This is profound for democracy, profound for the mental health of our kids and profound for warfare.”\n\nBut the Trump administration continues its policy of refusing to bind US AI companies with red tape. The White House is not expected to send a high-level representative to Delhi, with Sriram Krishnan, its senior AI policy adviser, the highest-ranked speaker listed in the programme.\n\n“Given where we are with the US administration it’s pretty unlikely you’re going to have a massive breakthrough on any consensus on what a regulatory framework will look like,” said one senior AI company source.\n\nCompanies such as Google are focused on the use of AI in education in India, where large language models’ ability to function in many of the country’s dozens of languages is an advantage.\n\n“[There’s] a big focus on access and adoption, how can you make sure that the technology is available as broadly as possible,” said Owen Larter, head of frontier AI policy and public affairs at Google DeepMind. “We’re excited on the education front in India. It’s a remarkable story of an incredibly intense adoption. About 90% of teachers and students already using AI in their learning. We’ve had a big promotional programme where 2 million students have access to our pro subscription for free.”\n\nGoogle’s investments in India include a $15bn spend, in partnership with the conglomerate of Gautam Adani, one of India’s richest billionaires, on an gigawatt-scale AI datacentre hub in the coastal city of Visakhapatnam, in Andhra Pradesh, with subsea cables connecting to other parts of the world.",
    "readingTime": 5,
    "keywords": [
      "rishi sunak",
      "impact summit",
      "prime minister",
      "us ai",
      "south",
      "leaders",
      "tech",
      "adoption",
      "technology",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/18/delhi-ai-expo-modi-jostles-lead-south",
    "thumbnail_url": "https://i.guim.co.uk/img/media/2f39cb8fe7a67fe7889f1cf3378f570bb029daac/484_55_1456_1165/master/1456.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=07f3b4f9ce5cd1a2ee707d65312ff256",
    "created_at": "2026-02-18T12:37:07.112Z",
    "topic": "tech"
  },
  {
    "slug": "stardex-yc-s21-is-hiring",
    "title": "Stardex (YC S21) Is Hiring",
    "description": "Stardex is an AI-native ATS and CRM built specifically for executive search firms. We're backed by Y Combinator and are changing how recruiting firms leverage their data and institutional knowledge. Our customers are boutique and mid-market executive search firms who are moving off legacy platforms — and they need someone to make that transition seamless.\n🔍 Who are you?\nYou're comfortable writing TypeScript/SQL scripts to transform, clean, and migrate messy data from one system to another\nYou're extremely detail-oriented.",
    "fullText": "Stardex is an AI-native ATS and CRM built specifically for executive search firms. We're backed by Y Combinator and are changing how recruiting firms leverage their data and institutional knowledge. Our customers are boutique and mid-market executive search firms who are moving off legacy platforms — and they need someone to make that transition seamless.\n🔍 Who are you?\n\nYou're comfortable writing TypeScript/SQL scripts to transform, clean, and migrate messy data from one system to another\nYou're extremely detail-oriented. Data migration has zero margin for error and you take pride in getting things right.\nYou instinctively reach for AI tools (Claude Code, Cursor, etc.) to automate repetitive work rather than doing it manually. You're always looking for ways to use AI to make processes faster and more efficient.\nYou have some understanding of database optimization — you know why a poorly structured query or schema matters\nYou can communicate clearly with both technical and non-technical people when needed\nYou have a \"whatever it takes\" attitude. If something needs to go live by Friday, you figure it out.\nYou write clean, maintainable code and document your work so processes get better over time\n\n✨ Bonus points if you...\n\nHave worked with CRMs or ATS platforms before (or any system with messy, relational data)\nHave experience with APIs, data pipelines, or ETL processes\nHave hands-on experience with database performance tuning, indexing, or query optimization\nHave done any kind of customer-facing technical work — support, consulting, freelance projects, anything\nHave worked at an early-stage startup\n\n🎉 Why work with us?\n\nYou'll be the first person in this role, which means you get to define how Stardex onboards customers from the ground up\nYou'll work directly with our founders (Sanket & Pranav) and have real ownership from day one\nYou'll learn a ton about AI, SaaS, and the recruiting industry\nWe’ll provide whatever you need to be productive\n\nInterested? Apply here or email Sanket directly at founders(at)stardex.ai with a short note on why this role excites you. We are open to recent grads as well for this role.",
    "readingTime": 2,
    "keywords": [
      "executive search",
      "search firms",
      "you're",
      "processes",
      "you'll",
      "role",
      "stardex",
      "recruiting",
      "customers",
      "platforms"
    ],
    "qualityScore": 0.9,
    "link": "https://www.ycombinator.com/companies/stardex/jobs/lag1C1P-customer-success-engineer-ai-data-migration",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/63014581184fd4565d63c82b595d2106f967b16a.png?1743869873",
    "created_at": "2026-02-18T12:37:06.819Z",
    "topic": "jobs"
  },
  {
    "slug": "zep-ai-building-the-context-graph-yc-w24-is-hiring-engineers",
    "title": "Zep AI (Building the Context Graph, YC W24) Is Hiring Engineers",
    "description": "Jobs at Zep AI",
    "fullText": "Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.ycombinator.com/companies/zep-ai/jobs",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/a5f4989742560bd0715218257a7c7ea7f73ab700.png?1712364271",
    "created_at": "2026-02-18T12:37:06.818Z",
    "topic": "jobs"
  },
  {
    "slug": "perion-shares-rise-nearly-6-as-aidriven-ad-platform-boosts-q4-profits",
    "title": "Perion shares rise nearly 6% as AI-driven ad platform boosts Q4 profits",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/earnings/perion-shares-rise-nearly-6-as-aidriven-ad-platform-boosts-q4-profits-93CH-4510655",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPED0C0KP_M.jpg",
    "created_at": "2026-02-18T12:37:05.395Z",
    "topic": "finance"
  },
  {
    "slug": "openclaw-opensource-personal-ai-agent-that-lives-on-your-machine",
    "title": "OpenClaw – Open-source personal AI agent that lives on your machine",
    "description": "Your own personal AI assistant. Any OS. Any Platform. The lobster way. 🦞  - GitHub - openclaw/openclaw: Your own personal AI assistant.",
    "fullText": "openclaw\n\n /\n\n openclaw\n\n Public\n\n Your own personal AI assistant. Any OS. Any Platform. The lobster way. 🦞 \n\n openclaw.ai\n\n License\n\n MIT license\n\n 206k\n stars\n\n 37.7k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n openclaw/openclaw",
    "readingTime": 1,
    "keywords": [
      "openclaw",
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/openclaw/openclaw",
    "thumbnail_url": "https://opengraph.githubassets.com/b2bb47983cd71c4a0446c45073347e53ea8782bc31c85c49442e517263d5b68b/openclaw/openclaw",
    "created_at": "2026-02-18T06:49:55.169Z",
    "topic": "tech"
  },
  {
    "slug": "tokenmeter-opensource-observability-layer-for-llm-token-costs",
    "title": "TokenMeter – Open-source observability layer for LLM token costs",
    "description": "Open-source AI Cost Intelligence Platform — smart routing, semantic cache, waste detection, prompt optimization - ATMAECHO/TOKEN-METER",
    "fullText": "ATMAECHO\n\n /\n\n TOKEN-METER\n\n Public\n\n Open-source AI Cost Intelligence Platform — smart routing, semantic cache, waste detection, prompt optimization\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n ATMAECHO/TOKEN-METER",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/ATMAECHO/TOKEN-METER",
    "thumbnail_url": "https://opengraph.githubassets.com/eea39f4bd57d3211a06801e4ec71e4dd4ccd4c7a0d57e4621e6667d535594d22/ATMAECHO/TOKEN-METER",
    "created_at": "2026-02-18T06:49:54.633Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push",
    "title": "Microsoft says it is on pace to invest $50 billion in ’Global South’ AI push",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/microsoft-says-it-is-on-pace-to-invest-50-billion-in-global-south-ai-push-4510044",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM1H06I_L.jpg",
    "created_at": "2026-02-18T06:49:48.045Z",
    "topic": "finance"
  },
  {
    "slug": "perplexity-says-its-moving-away-from-ads-and-betting-on-subscriptions",
    "title": "Perplexity says it's moving away from ads and betting on subscriptions",
    "description": "Perplexity, a San Francisco-based AI startup, emphasizes subscriptions and business sales, diverging from OpenAI's ad-centric approach.",
    "fullText": "Perplexity is going full steam ahead with subscriptions and business sales and plans to focus more on monetization than it has in the past, executives said at a roundtable with reporters on Monday.\n\nThe AI search startup, based in San Francisco, is the latest to publicly distance itself from putting ads in chatbot answers, with one executive saying it isn't exploring any ad deals at the moment. That's a contrast to OpenAI, which is going all in on ads, while arch-rival Anthropic has publicly touted the opposite.\n\nOne Perplexity executive said the startup is increasingly targeting large businesses. The company has only five people on its enterprise sales team and plans to ramp that up, the executive added. It also wants to serve high-powered users such as finance professionals, doctors, and CEOs.\n\nThe focus on selling to businesses positions Perplexity more directly as a competitor to startups like Glean, which lets employees search internal files and data more efficiently with AI.\n\nThe move comes amid some VC skepticism about Perplexity's prospects, with Silicon Valley investors voting it the company they'd most like to bet against in an informal poll at an AI conference last year, amid back-to-back funding rounds and talks of a wider AI bubble.\n\nPerplexity will focus more on revenue and revenue retention than on other metrics, such as the number of questions it answers, the executive said. Perplexity also pledged to keep allowing people to use the product for free, with rate limits.\n\nAt the roundtable, the company declined to share specific financials and shared that revenue grew 4.7 times last year. Perplexity generated over $150 million in annual recurring revenue by mid-last year, its head of communications Jesse Dwyer told Business Insider in August. It hit $200 million in ARR in October, Alex Heath of Sources reported.\n\nThe news comes after several months of the AI startup lying low, as Perplexity said in a press invite. The company's leaders said it was busy building and not focusing on AI-related drama.\n\nPerplexity had announced in 2024 that it would start experimenting with ads. That effort stalled, with the top ads leader, Taz Patel, quietly leaving last year. One consistent issue with ads in AI-generated answers is that users won't believe them, the Perplexity executive said.\n\nPerplexity also launched a product for enterprises in 2024 that uses internal and external data to generate research reports, among other features.",
    "readingTime": 2,
    "keywords": [
      "perplexity executive",
      "revenue",
      "focus",
      "startup",
      "sales",
      "plans",
      "roundtable",
      "search",
      "publicly",
      "businesses"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/perplexity-shifts-to-subscriptions-business-growth-2026-2",
    "thumbnail_url": "https://i.insider.com/6995107fa645d11881897c7b?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.037Z",
    "topic": "finance"
  },
  {
    "slug": "im-an-amazon-tech-lead-who-uses-ai-to-write-code-daily-theres-one-situation-i-hesitate-to-use-it-in",
    "title": "I'm an Amazon tech lead who uses AI to write code daily. There's one situation I hesitate to use it in.",
    "description": "Anni Chen says vibe coding is hard to resist. It speeds up her productivity, but she doesn't trust it blindly.",
    "fullText": "This as-told-to essay is based on a conversation with Anni Chen, who has worked at Amazon for about three-and-a-half years. It has been edited for length and clarity. Business Insider has verified her employment history.\n\nI'm a tech lead at Amazon responsible for deploying large-scale generative AI and LLM-driven systems. I focus on what we call memory, which powers personalization in generative AI experiences across Amazon.\n\nI vibe code every day. It's definitely a productivity boost.\n\nFor debugging or small tasks, I sometimes treat it like a lottery. Maybe it will produce something amazing. Sometimes, it does.\n\nVibe coding helps me brainstorm what the solution could look like, even if I don't adopt the final solution it proposes. Vibe coding also speeds up the time spent rewriting code when you realize a requirement wasn't covered.\n\nWhen I vibe code, it's always iterative. I give it the basic information it needs, it produces a version, then I check it — similar to a code review with coworkers. I might say, \"You missed this part\" or \"You missed that part.\"\n\nThe AI sometimes fixes issues but introduces something new. You have to keep an eye on it.\n\nFor complex tasks, you need more double-checking. But even with the extra checking, it's still faster.\n\nI was working with a partner team and ran into complex locking issues. Without an LLM, I might have taken a day to research possible solutions, especially since it was relatively new to me.\n\nWithin 15 minutes, I brainstormed with the LLM about possible solutions. I pointed out weaknesses in its suggestions and asked it to improve them. In 15 minutes, I had a proposal to send to the team.\n\nTechnical knowledge helps — you know what's a good solution and what's not. You know what tastes good, but you don't know what dishes are available. The LLM brings up all the dishes, and you choose.\n\nStill, I'm hesitant to use vibe coding directly in production.\n\nLLMs are very good at solving problems, but sometimes they make implicit assumptions you don't realize they're making. If you don't tell it explicitly, for example, that something needs to work for multi-threading, it might just produce the minimum version that works, but when it's large-scale or productionized, it could crash.\n\nNon-technical builders could tell an LLM to build something that handles millions of users. But if you have zero technical knowledge, it's hard to anticipate constraints upfront. If you don't tell the model the implicit assumptions, it won't respect those constraints. Later, you'll run into problems.\n\nNon-technical people might use the LLM to fix issues reactively. But technical people can anticipate constraints proactively and prevent problems in the first place.\n\nTechnical people also understand vibe-coded content better, and they're in a better position to understand what LLMs are good at and not good at. For example, knowing how they're trained and why they're weaker at certain tasks like math. That understanding helps you master them as tools.\n\nWhen you scale to one million or 100 million customers, systems need to be coded differently to handle that scale.\n\nInitially, leadership pushed vibe coding. Our team is a GenAI team, so we were naturally more receptive. In non-GenAI teams, engineers initially reacted like, \"No, I won't let AI do my job. I don't trust AI-generated code.\"\n\nAfter people tried it, attitudes shifted. People realized it's pretty good sometimes. Now it's more widely adopted.\n\nIt's very hard to resist vibe coding nowadays. If you're an employee, leadership sees the productivity boost and will encourage you to use it.\n\nWhen your peers are using it and coding faster, it's hard to resist. If you can't keep up with the speed, it becomes difficult to collaborate.\n\nEven if you resist, you still consume AI passively. AI comments are embedded in code reviews. So even if you don't vibe code directly, you're still interacting with AI outputs.\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "productivity boost",
      "implicit assumptions",
      "anticipate constraints",
      "technical knowledge",
      "vibe coding",
      "vibe code",
      "it's",
      "don't",
      "team",
      "they're"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-tech-lead-vibe-coding-daily-resist-anni-chen-2026-2",
    "thumbnail_url": "https://i.insider.com/698d593ce1ba468a96abe95e?width=1184&format=jpeg",
    "created_at": "2026-02-18T06:49:48.035Z",
    "topic": "finance"
  },
  {
    "slug": "openclaw-creator-slams-europes-regulations-as-he-moves-to-the-us",
    "title": "OpenClaw creator slams Europe's regulations as he moves to the US",
    "description": "Peter Steinberger, creator of OpenClaw, is moving to OpenAI in the US, citing Europe's strict regulations as a hurdle for tech growth.",
    "fullText": "In Europe, there's been a lot of handwringing over why there are very few large, successful tech companies in the region. Peter Steinberger, the creator of the agentic AI hit OpenClaw, has an answer.\n\nSteinberger was recently hired by OpenAI and is moving from Europe to the US. An Austrian by birth, he previously split his time between London and Vienna.\n\nOn X, a professor from a European university asked why Europe couldn't retain this tech talent.\n\nSteinberger replied that most people in the US are enthusiastic, while in Europe, he's scolded about responsibility and regulations.\n\nIf he built a company in Europe, he would struggle with strict labor regulations and similar rules, he added.\n\nAt OpenAI, he said most employees work 6 to 7 days a week and are paid accordingly. In Europe, that would be illegal, he added.\n\nThe most valuable company in Europe is Dutch chip-equipment maker ASML, valued at about $550 billion. In contrast, there are 10 US companies worth more than $1 trillion. Most of these are tech companies.\n\nIn 2024, a landmark EU report found that the region had fallen behind the US, particularly in innovation. It proposed a series of changes to tackle the problem, but by the end of 2025, few of the recommendations had been implemented.\n\nSteinberger said he was hopeful about EU INC, an effort to create a single corporate legal framework to make it simpler to run a business across the region.\n\nBut this seems to be \"fizzling out,\" he wrote on X. \"Watered down, too much egoistic national interest that ultimately hurts everyone.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "in europe",
      "tech",
      "region",
      "regulations",
      "steinberger",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openclaw-creator-slams-europe-regulations-move-us-openai-2026-2",
    "thumbnail_url": "https://i.insider.com/699511bee1ba468a96ac341a?width=1200&format=jpeg",
    "created_at": "2026-02-18T06:49:48.030Z",
    "topic": "finance"
  },
  {
    "slug": "why-an-ai-video-of-tom-cruise-battling-brad-pitt-spooked-hollywood",
    "title": "Why an A.I. Video of Tom Cruise Battling Brad Pitt Spooked Hollywood",
    "description": "A 15-second clip created by an artificial intelligence tool owned by the Chinese technology company ByteDance appears more cinematic than anything so far.",
    "fullText": "It took only a 15-second clip of Tom Cruise and Brad Pitt duking it out on a crumbling rooftop at twilight to draw swift outrage, and sizable fear, from Hollywood over the last few days.\n\nThe widely circulated video was created by the Irish director Ruairi Robinson using Seedance 2.0, a powerful artificial intelligence video generation tool owned by the Chinese technology company ByteDance. It had plenty of the bells and whistles of a big-budget Hollywood film: sweeping camera angles, stunt choreography, crisp sound effects and haunting music.\n\nWith a two-sentence prompt and the click of a button, Seedance had produced a stunningly realistic result that was a drastic improvement over previously generated artificial intelligence videos, often shoddy clips known as A.I. slop. This video was so convincing that it drew near immediate condemnation from some of Hollywood’s top organizations and companies.\n\nRhett Reese, a scriptwriter known for his “Deadpool” films, said in an interview that the Cruise-Pitt video had sent a “cold shiver” up his spine.\n\n“For all of us who work in the industry and devoted our careers and lives to it, I just think it’s nothing short of terrifying,” he said. “I could just see it costing jobs all over the place.”\n\nByteDance released Seedance 2.0 last week, nearly two months after a previous version had failed to prompt much anger. A news release from the company praised the updated tool’s “physical accuracy, realism and controllability,” which it said was suitable for the needs of “professional-grade creative scenarios.”\n\n“The creation process,” the release went on, “is more natural and efficient, allowing users to control their creations like a true ‘director.’”\n\nUsers promptly flocked to the platform to spin up their own content. An alternate ending to “Game of Thrones” went viral, as did a video of the notoriously beefing rappers Kendrick Lamar and Drake burying the hatchet on “The Tonight Show,” and one of Samara Morgan, the vengeful girl in “The Ring” horror films, emerging from an old television set to pet a cat.\n\nRobinson himself posted additional videos, including of Pitt and Cruise battling a robot, and of Pitt sparring with a sword-wielding “zombie ninja.”\n\nAt the same time, Hollywood was swift to sit up straight. Charles Rivkin, the chairman and chief executive of the Motion Picture Association, called on ByteDance to “immediately cease its infringing activity,” saying in a statement that Seedance 2.0 had engaged in the unauthorized use of copyrighted works on a “massive scale.” Human Artistry Campaign, a global coalition that advocates using A.I. “with respect for the irreplaceable artists, performers and creatives,” said on social media that unauthorized works generated by Seedance 2.0 violated the “most basic aspects of personal autonomy.”\n\nDisney, which in a watershed $1 billion deal last year agreed to allow OpenAI’s Sora users to generate video content with its characters, sent a cease-and-desist letter to ByteDance, accusing it of supplying Seedance with a “pirated library” of Disney’s characters — “as if Disney’s coveted intellectual property were free public-domain clip art.”\n\nByteDance, which also owns TikTok and has been valued at $480 billion in the private markets, said in a statement that it respected intellectual property rights and was aware of the concerns about Seedance.\n\n“We are taking steps to strengthen current safeguards as we work to prevent the unauthorized use of intellectual property and likeness by users,” the statement said.\n\nAs last year’s deal between Disney and OpenAI suggests, Hollywood has for years wrestled with how to manage the rapid growth of generative artificial intelligence. The concerns outlined by Reese echoed the Writers Guild strike in 2023, when for months thousands of union members demanded that studios institute guardrails protecting them from having their jobs or their intellectual property stolen by A.I. In the end, the group won guarantees that A.I. would not encroach on writers’ credits and compensation.\n\nDuncan Crabtree-Ireland, the national executive director and chief negotiator of SAG-AFTRA, which represents actors and media artists, said its contracts had specific and enforceable rules about digital replication. The kind of material represented by the Cruise-Pitt battle, he said, “could not be produced by any of the signatories to our contracts — the studios, the streamers — without the specific, informed consent of those individuals.”\n\nAccording to Crabtree-Ireland, the real concern is that, even if videos generated by Seedance and other A.I. platforms “are not malicious in intent,” they could “really violate someone’s right to control how their image, their likeness and their voice is used.”\n\nNot everyone is awed by Seedance’s latest technology. Heather Anne Campbell, an executive producer and a writer on the animated series “Rick and Morty,” said her social media accounts last week had been inundated with Seedance-generated clips of anime, sci-fi and unlikely superhero battles. But she is not yet worried, she said, about losing her job to the technology.\n\n“Everybody is, I think, swept up by the circus that came to town and is showing off,” she said. “I haven’t seen anything good yet. Nothing that has taken my breath away, nothing that is poignant, nothing that is provocative even. It’s all just garbage.”\n\nCampbell added that A.I. services like Seedance were at best “averaging machines,” and argued that the greatest art was never made quickly or impersonally.\n\nStill, some people working in Hollywood find it difficult to imagine that studios will not come to see A.I. as a cost-saving shortcut. “It would be cheaper to have A.I. write a screenplay than it would be for me to write a screenplay,” Reese, the “Deadpool” writer, said. “I just know that in the back of my mind, that’s where the terror comes from.”\n\nFor Reese, a long-term answer to the unease that A.I. will reorder Hollywood could not come quickly enough.\n\n“If I could wave my magic wand and make A.I. go away, at least in the creative field,” he said, “I would absolutely wave the wand.”",
    "readingTime": 5,
    "keywords": [
      "artificial intelligence",
      "social media",
      "intellectual property",
      "hollywood",
      "users",
      "director",
      "technology",
      "generated",
      "videos",
      "executive"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/02/16/movies/tom-cruise-brad-pitt-artificial-intelligence-seedance.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/02/15/arts/15cul-seedance/15cul-seedance-facebookJumbo.jpg",
    "created_at": "2026-02-18T01:13:50.594Z",
    "topic": "tech"
  }
]
[
  {
    "slug": "autohand",
    "title": "Autohand",
    "description": "Software 3.0 has arrived. The autonomous AI software engineer with self-evolving capabilities. Build, deploy, and manage complex systems with Autohand.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://autohand.ai/",
    "thumbnail_url": "https://autohand.ai/logos/ours/autohand_1200x630.png",
    "created_at": "2026-01-13T00:54:07.616Z",
    "topic": "tech"
  },
  {
    "slug": "vibe-engineering-what-ive-learned-working-with-ai-coding-agents",
    "title": "Vibe Engineering: What I've Learned Working with AI Coding Agents",
    "description": "Vibe Engineering: What I've Learned Working with AI Coding Agents",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/mrexodia/status/2010157660885176767",
    "thumbnail_url": "https://pbs.twimg.com/media/G-WBO0QXAAApT_j.jpg:large",
    "created_at": "2026-01-13T00:54:05.735Z",
    "topic": "tech"
  },
  {
    "slug": "mark-zuckerberg-says-meta-will-build-hundreds-of-gigawatts-of-ai-capacity-over-time",
    "title": "Mark Zuckerberg says Meta will build 'hundreds of gigawatts' of AI capacity over time",
    "description": "Meta CEO Mark Zuckerberg launches Meta Compute, a major AI infrastructure initiative led by executives Santosh Janardhan and Daniel Gross.",
    "fullText": "Meta CEO Mark Zuckerberg said Monday that the company is launching a new \"top-level\" initiative called Meta Compute, as it pours more money into the data centers and infrastructure powering its AI push.\n\nZuckerberg said Meta plans to build \"tens of gigawatts\" of capacity this decade and \"hundreds of gigawatts or more\" over time.\n\n\"How we engineer, invest, and partner to build this infrastructure will become a strategic advantage,\" Zuckerberg wrote in a Facebook post.\n\nThe move signals that Zuckerberg views AI infrastructure as a key competitive advantage and is placing it under a dedicated unit that reports directly to him. Meta has said it plans to invest $600 billion in US infrastructure and jobs, including AI data centers, by 2028.\n\nThe Department of Energy provides a few handy comparisons for the amount of power in one gigawatt: It's roughly half the output of the Hoover Dam, or the power of 2,627 Tesla Model 3s. Famously, the DeLorean, the iconic time machine in \"Back To The Future Part II,\" needed 1.21 gigawatts to travel through time.\n\nSantosh Janardhan, the company's head of infrastructure, and Daniel Gross, who joined Meta last year from AI startup Safe Superintelligence, will lead the new Meta Compute initiative.\n\nThe two executives will work closely with Dina Powell McCormick, Meta's newly appointed president and vice chairperson, who will focus on partnering with governments and sovereign entities to help build and finance infrastructure. Powell McCormick is a former deputy national security advisor to President Donald Trump and spent 16 years at Goldman Sachs.\n\nMeta did not immediately respond to a request for comment from Business Insider.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "meta compute",
      "infrastructure",
      "gigawatts",
      "initiative",
      "centers",
      "plans",
      "invest",
      "advantage",
      "email",
      "nonwork"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-compute-ai-data-centers-infrastructure-2026-1",
    "thumbnail_url": "https://i.insider.com/69654878764ca5f34d2a4a02?width=1200&format=jpeg",
    "created_at": "2026-01-13T00:54:04.642Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-and-openai-are-crawling-the-web-even-more-and-not-giving-much-back",
    "title": "Anthropic and OpenAI are crawling the web even more and not giving much back",
    "description": "Cloudflare data shows the top AI labs are strip-mining the web, and it's getting worse not better.",
    "fullText": "Are AI giants nurturing the web, the most valuable store of human data the world will ever see? Or are they scraping content for free and giving little back? Updated data from Cloudflare sheds new light on this important question.\n\nThis is one of the most under-discussed parts of the AI revolution. While tech companies spend lavishly on data centers, GPUs, and talent, they avoid talking about the other key ingredient of AI success: data.\n\nThat's because they don't want to pay for the high-quality human data that's needed for AI model training, inference, and AI outputs. Instead, they send out bots to crawl websites and scoop up this information, mostly for free.\n\nIn the past, tech companies would send users to the original sources of this information. This formed the grand bargain of the web. Sites would let their data be taken for free on the understanding that they would get referrals in return, and could pay for their efforts through advertising, subscriptions, and other techniques.\n\nIn the new generative AI world, this deal is breaking down. Now, AI answer engines and chatbots give users direct answers, making people less likely to visit the websites that created and verified the data in the first place.\n\nCloudflare, which helps run about 20% of the world's websites, began tracking this behavior in 2025. It measures Big Tech company bots' requests to crawl websites, and the number of referrals the platforms send to sites.\n\nThis crawl-to-refer ratio is a useful guide to how much tech companies are taking from the web and how much they're giving back. For example, a ratio of 100 to 1 would mean a company's bots crawled sites 100 times for every 1 referral they send.\n\nIs this one way to measure how ethical companies are in the AI era? I'll leave you to decide. Here's the data for the first week in January.\n\nAs you can see, Anthropic stands out like a sore thumb. According to Cloudflare data, it crawls sites way more than it sends users out to the web. Anthropic actually crawled even \n\nThe same applies to OpenAI; its crawl-to-refer ratio has worsened. Again, this suggests that OpenAI is taking more value from the web and giving less value back.\n\nThis aligns with Business Insider reporting from late 2024. Back then, we told you that bots from Anthropic and OpenAI, especially, were crawling some websites so much that it was causing their traffic costs to spike dramatically.\n\nOne web developer saw a client's cloud-computing costs double within a few months due to this AI bot swarm, according to BI reporting.\n\nSo, not only are AI companies taking from the web and giving less back — they are also leaving some site owners with bigger bills to pay.\n\nLike last quarter, I asked Anthropic why it crawls so much and gives so little back to the web. The startup did not respond to an email seeking comment.\n\nBack in September, Anthropic said it couldn't confirm the crawl-to-refer ratios calculated by Cloudflare and said there may be \"issues\" with the methodology. At that time, Anthropic also noted that it launched a web search feature for its popular Claude AI chatbot earlier this year. This was generating more referral traffic for websites now, and this is growing quickly, the startup said back then.\n\nOpenAI didn't respond to a request for comment.\n\nA caveat: The numbers that go into the crawl-to-refer ratio focus on the web and exclude native app activity. If app activity were included, the ratios might be lower. However, this methodology applies to all the companies included in this ranking.\n\nGoogle's relatively low ratio is likely due to its traditional search engine, which still shows clear website links in many results. However, the company is increasingly weaving in AI chatbot-style answers into its search service, via AI Overviews and AI mode.\n\nGoogle has been saying lately that it still sends traffic to the web, and it cares about the health of this ecosystem.\n\nBusiness Insider will keep tracking this Cloudflare data in the coming months and quarters to see how this behavior evolves.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "app activity",
      "crawl websites",
      "crawl-to-refer ratio",
      "business insider",
      "back",
      "cloudflare",
      "bots",
      "free",
      "users",
      "less"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropic-openai-google-perplexity-microsoft-mistral-crawling-web-referrals-cloudflare-2026-1",
    "thumbnail_url": "https://i.insider.com/6961abee832e0ef1ead78baa?width=1200&format=jpeg",
    "created_at": "2026-01-13T00:54:04.362Z",
    "topic": "finance"
  },
  {
    "slug": "meta-is-planning-layoffs-in-its-reality-labs-unit-as-it-prepares-for-its-most-important-meeting-of-the-year",
    "title": "Meta is planning layoffs in its Reality Labs unit as it prepares for its 'most important' meeting of the year",
    "description": "Meta plans layoffs in its Reality Labs division, impacting VR headset and Horizon Worlds teams, as it shifts focus to AI.",
    "fullText": "Meta is preparing layoffs in its Reality Labs division, according to three people familiar with the matter who spoke with Business Insider.\n\nThe teams working on the company's virtual reality headsets and Horizon Worlds, its VR-based social network, will be disproportionately affected, two employees said.\n\nRoughly 10% to 15% of Reality Labs' 15,000 employees are expected to be laid off, with the cuts set to be announced this week, The New York Times reported. \n\nMeta declined to comment.\n\nThe move comes as Meta CTO and Reality Labs chief Andrew Bosworth has called a key division-wide meeting for Wednesday, describing it as the \"most important\" of the year and urging employees to show up in person, Business Insider previously reported.\n\nReality Labs has been a costly bet for Meta, racking up more than $70 billion in losses since 2020. It has faced repeated rounds of cuts as Meta shifts its attention — and spending — toward AI.\n\nIn a memo obtained by Business Insider last year, Bosworth called 2025 \"the most critical\" year of his tenure and warned the outcome would determine whether Reality Labs is remembered as visionary work or \"a legendary misadventure.\"\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "reality labs",
      "business insider",
      "meta",
      "employees",
      "network",
      "cuts",
      "email",
      "nonwork",
      "bosworth"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-layoffs-reality-labs-vr-horizon-worlds-teams-2026-1",
    "thumbnail_url": "https://i.insider.com/6965661f764ca5f34d2a4d87?width=1200&format=jpeg",
    "created_at": "2026-01-13T00:54:04.258Z",
    "topic": "finance"
  },
  {
    "slug": "apple-is-asking-its-biggest-competitor-for-some-help-with-ai",
    "title": "Apple Is Asking Its Biggest Competitor for Some Help With AI",
    "description": "Apple’s AI Siri is planned for this year, and it'll use Google Gemini.",
    "fullText": "It's been nearly two years since Apple announced a more intelligent Siri, and yet, we're still waiting to get our hands on it. Aside from being able to answer a few questions about Apple products or shunt your questions off to ChatGPT for you, the voice assistant is essentially still the same it was before Apple Intelligence launched for other Apple features in iOS 18.1. Now, the iPhone maker seems to be throwing in the towel on developing an AI-enabled Siri entirely on its own, and is asking Google for help. I can't imagine Tim Cook is too happy about that, but on the flip side, that does mean an AI Siri might finally come out, and soon.\n\nIn a statement to CNBC's Jim Cramer, Apple admitted that it is now planning to use Google Gemini to power its AI-infused Siri, rather than purely in-house models. The company said that, \"After careful evaluation, we determined that Google's technology provides the most capable foundation for Apple Foundation Models and we're excited about the innovative new experiences it will unlock for our users.\"\n\nPreviously, Apple had promised that its AI Siri would be able to do tasks on your behalf, like send a drafted email, or would be able to answer questions using context pulled from your phone, like surfacing a friend's address using information pulled from a text thread. Reportedly, however, implementing these features during testing kept breaking more traditional Siri features, like setting alarms and reminders, which has kept sending Apple back to the drawing board. The new, Gemini-powered voice assistant for Android faced similar issues at first, but based on my hands-on time with the company's latest phones, those growing pains seem to have subsided, so it makes sense that Google would be the first company Apple would turn to while looking for outside help.\n\nApple hasn't said too much more about the deal for now, but Google itself did step in to offer Apple users a bit more clarity, plus some reassurance about their data.\n\nIn a statement on X, the company assured Apple users that \"Apple Intelligence will continue to run on Apple devices and Private Cloud Compute, while maintaining Apple's industry-leading privacy standards.\" That's the same deal Apple has with OpenAI right now, which allows its users to ask ChatGPT questions without the AI being able to train on them or keep a log of their requests. It essentially means Google won't get any data from your AI-powered Siri. Google's statement also confirmed a detail from CNBC's initial article, stating that its agreement with Apple will be a multi-year deal.\n\nPerhaps most exciting is that Google said the AI-powered Siri will come out \"this year,\" mirroring a statement an Apple spokesperson gave to Daring Fireball last March, admitting that an AI-enabled Siri was taking longer than anticipated and saying the company hoped to launch it in 2026. That's welcome relief to anyone who thought Apple had given up on the project.\n\nA more concrete timeline is still unknown, although Bloomberg's Mark Gurman, a reputable reporter with inside sources at Apple, has previously said to expect the AI Siri upgrade to launch in the spring. Personally, I could also see the company holding the launch until its annual WWDC event, which tends to happen in June.\n\nDespite Apple and Google's public feud as the makers of iOS and Android, respectively, this wouldn't mark the two companies' first time working together, especially in the mobile space. Previously, it was uncovered that Google and Apple have a lucrative deal to make Google the default search engine in Safari, which caused a lengthy legal battle that ultimately allowed the companies to maintain their deal, but barred exclusivity contracts. Part of the reasoning behind the AI Siri delay might be that the companies wanted to work together on AI before, but were holding off on it out of an abundance of caution. However, according to the courts, Google will also be able to make deals with outside distributors for \"preloading and placement\" of its GenAI products going forward, which seemingly puts both companies in the clear.",
    "readingTime": 4,
    "keywords": [
      "voice assistant",
      "ai siri",
      "apple users",
      "apple intelligence",
      "ai-enabled siri",
      "deal",
      "statement",
      "features",
      "launch",
      "google"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apples-ai-siri-is-planned-for-this-year-and-will-use-google-gemini?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KESPRGT0QJCWCM9E9NBMDBGX/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-13T00:54:02.718Z",
    "topic": "tech"
  },
  {
    "slug": "apple-google-strike-gemini-deal-for-revamped-siri-in-major-win-for-alphabet",
    "title": "Apple, Google strike Gemini deal for revamped Siri in major win for Alphabet",
    "description": "Apple will use Google's Gemini models for its revamped Siri coming later this year under a multi-year deal that deepens the tech giants' alliance in the ​artificial intelligence era and bolsters Alphabet's position in the race against OpenAI.  The deal announced Monday marks a major ‌vote of confidence for Google.  Its technology already drives much of Samsung's \"Galaxy AI,\" but the Siri deal unlocks a large market with Apple's installed base ‌of more than two billion active devices.",
    "fullText": "Jan 12 (Reuters) - Apple will use Google's Gemini models for its revamped Siri coming later this year under a multi-year deal that deepens the tech giants' alliance in the ​artificial intelligence era and bolsters Alphabet's position in the race against OpenAI.\n\nThe deal announced Monday marks a major ‌vote of confidence for Google. Its technology already drives much of Samsung's \"Galaxy AI,\" but the Siri deal unlocks a large market with Apple's installed base ‌of more than two billion active devices.\n\n\"After careful evaluation, Apple determined Google's AI technology provides the most capable foundation for Apple Foundation Models,\" Google said, adding that its models will also power other future Apple Intelligence features.\n\nAlphabet has been jostling with OpenAI for the Apple deal, the financial details of which were not disclosed.\n\nThe iPhone maker had in late 2024 rolled out ChatGPT into its ⁠devices, allowing the company's Siri voice assistant ‌to tap into the chatbot's expertise to answer complicated questions.\n\nApple said there were no major changes to the ChatGPT integration at the time, while OpenAI did not respond to Reuters' request for ‍comment.\n\n\"This seems like an unreasonable concentration of power for Google, given that (they) also have Android and Chrome,\" Tesla CEO Elon Musk said in a post on social media platform X.\n\nMusk founded his own AI firm xAI that has been trying to compete with other major players ​in the industry by building foundational models and spending billions on massive infrastructure.\n\nMonday's tie-up will likely raise questions on OpenAI's ‌partnership with Apple. In response to Gemini 3, OpenAI CEO Sam Altman late last year reportedly issued a \"code red\" to push teams to accelerate development.\n\n\"Apple's decision to use Google's Gemini models for Siri shifts OpenAI into a more supporting role, with ChatGPT remaining positioned for complex, opt-in queries rather than the default intelligence layer,\" said Parth Talsania, CEO of Equisights Research.\n\nGoogle has been firing on all cylinders to counter OpenAI's early lead in the industry by doubling down on frontier models, and ⁠image and video generation.\n\nApple has faced a series of setbacks on the ​AI front after being late to the race, with Siri's upgrade getting ​delayed, top-level executive changes and the initial rollout of its generative AI tools being met with lukewarm reception.\n\nThe latest agreement builds on a years-long partnership that makes Google the default search engine on ‍Apple devices - a lucrative arrangement that ⁠drives traffic for Google while generating tens of billions in annual revenue for Apple.",
    "readingTime": 3,
    "keywords": [
      "gemini models",
      "google's gemini",
      "siri",
      "deal",
      "apple",
      "devices",
      "chatgpt",
      "race",
      "technology",
      "drives"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/google-apple-enter-multi-ai-162042367.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/00356f32213e595ba3d70d88c62a8f9d",
    "created_at": "2026-01-13T00:54:00.515Z",
    "topic": "finance"
  },
  {
    "slug": "apple-chooses-googles-gemini-over-openais-chatgpt-to-power-nextgen-siri",
    "title": "Apple chooses Google's Gemini over OpenAI's ChatGPT to power next-gen Siri",
    "description": "Apple goes with Google's tech despite using OpenAI's ChatGPT elsewhere in iOS.",
    "fullText": "The “more intelligent” version of Siri that Apple plans to release later this year will be backed by Google’s Gemini language models, the company announced today. CNBC reports that the deal is part of a “multi-year partnership” between Apple and Google that will allow Apple to use Google’s AI models in its own software.\n\n“After careful evaluation, we determined that Google’s technology provides the most capable foundation for Apple Foundation Models and we’re excited about the innovative new experiences it will unlock for our users,” reads an Apple statement given to CNBC.\n\nToday’s announcement confirms Bloomberg’s Mark Gurman reporting late last year that Apple and Google were nearing a deal. Apple didn’t disclose terms, but Gurman said that Apple would be paying Google “about $1 billion a year” for access to its AI models “following an extensive evaluation period.”\n\nBloomberg has also reported that the Gemini model would be run on Apple’s Private Cloud Compute servers, “ensuring that user data remains walled off from Google’s infrastructure,” and that Apple still hopes to improve its own in-house language models to the point that they can eventually be used instead of relying on third-party models.\n\nAlthough Apple’s iPhones and iOS compete with Google’s Android operating system and the many smartphones that use it, the companies still cooperate in plenty of other areas. Google has paid Apple billions of dollars to remain the default search engine in Safari on iOS, iPadOS, and macOS (though that deal has faced increased regulatory scrutiny in recent years).\n\nApple’s announcement is a blow to OpenAI and the many versions of its ChatGPT model, which Apple has used elsewhere in iOS and macOS. Bloomberg reports that Apple also tested OpenAI’s ChatGPT and Anthropic’s Claude models before deciding to go with Gemini. ChatGPT came out ahead of Gemini in tests that Ars ran using earlier versions of the models, but Google’s models have apparently improved enough (and amassed enough users) to worry OpenAI; CEO Sam Altman declared a “code red” last month and pushed back several planned ChatGPT features so that the company could better respond to Google’s Gemini 3 release.\n\nApple originally promised the improved, AI-powered Siri for 2024’s iOS 18 release, but ultimately delayed the feature because it didn’t work reliably enough. The new version of Siri should arrive in an update to iOS 26, iPadOS 26, and macOS 26 Tahoe later this year.",
    "readingTime": 2,
    "keywords": [
      "ios ipados",
      "language models",
      "apple and google",
      "google’s gemini",
      "release",
      "deal",
      "macos",
      "version",
      "later",
      "reports"
    ],
    "qualityScore": 0.9,
    "link": "https://arstechnica.com/apple/2026/01/apple-says-its-new-ai-powered-siri-will-use-googles-gemini-language-models/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/apple_google_hero_3-1152x648.jpg",
    "created_at": "2026-01-12T18:19:09.417Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-eli-lilly-announce-1-billion-investment-in-ai-drug-discovery-lab",
    "title": "Nvidia, Eli Lilly announce $1 billion investment in AI drug discovery lab",
    "description": "Nvidia and Eli Lilly are set to launch an AI lab in San Francisco.",
    "fullText": "AI chipmaker Nvidia (NVDA) and pharmaceutical giant Eli Lilly (LLY) on Monday announced that the two companies would jointly invest $1 billion to create a lab in San Francisco focused on using AI to accelerate drug discovery.\n\n“Combining our volumes of data and scientific knowledge with NVIDIA’s computational power and model-building expertise could reinvent drug discovery as we know it,\" said Lilly CEO David Ricks.\n\nThe $1 billion investment will be spent over five years on infrastructure, compute, and talent for the lab. Nvidia's engineers will work alongside Lilly's experts in biology, science, and medicine to generate large-scale data and build AI models to advance medicine development. The lab's work will begin early this year, the companies said.\n\nThe investment builds on Nvidia and Lilly's existing partnership. Lilly in October said it was building an AI factory with Nvidia's AI systems to speed up drug discovery timelines.\n\nLilly shares rose fractionally Monday and are up nearly 34% over the past year, surpassing the S&P 500's (^GSPC) 19% gain. The company became the first healthcare name to reach a $1 trillion market capitalization in November.\n\nNvidia, meanwhile, is the most valuable company in the world, becoming the first to cross $5 trillion in 2025. The AI chipmaker's project with Lilly is the latest in a string of investments and deals spanning the AI ecosystem — some of which have raised eyebrows on Wall Street and spurred fears of an AI bubble.\n\nIn the healthcare space, Nvidia has also invested in biotech firm Recursion and has inked partnerships with other industry leaders, including Lilly rival Novo Nordisk (NVO), the Mayo Clinic, Illumina, and IQVIA, to use AI in medical research and development.\n\n“AI is transforming every industry, and its most profound impact will be in life sciences,” said Nvidia CEO Jensen Huang in a statement Monday.\n\nLaura Bratton is a reporter for Yahoo Finance. Follow her on Bluesky @laurabratton.bsky.social. Email her at laura.bratton@yahooinc.com.\n\nClick here for the latest technology news that will impact the stock market\n\nRead the latest financial and business news from Yahoo Finance",
    "readingTime": 2,
    "keywords": [
      "drug discovery",
      "latest",
      "investment",
      "medicine",
      "development",
      "healthcare",
      "market",
      "industry",
      "impact",
      "lilly"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-eli-lilly-announce-1-billion-investment-in-ai-drug-discovery-lab-163446796.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/VzgaLHGyJWm2OXjhC2O5uA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/3438c520-ec06-11f0-bddf-75be531c7130",
    "created_at": "2026-01-12T18:19:01.145Z",
    "topic": "finance"
  },
  {
    "slug": "the-ailed-borrowing-frenzy-could-end-up-driving-interest-rates-higher-apollos-chief-economist-says",
    "title": "The AI-led borrowing frenzy could end up driving interest rates higher, Apollo's chief economist says",
    "description": "Torsten Slok, chief economist at Apollo, said rates could move higher as a surge in bond issuance pulls investors from the Treasury market.",
    "fullText": "A top economist has a fresh warning about debt-fueled capex spending in 2026.\n\nTorsten Sløk, the chief economist at Apollo Global Management, flagged expectations that AI hyperscalers will be significant drivers of investment-grade bond issuance this year. In his view, the flood of new bonds into the market as tech companies look to fund their data centers and other infrastructure is bound to put upward pressure on interest rates.\n\nThe issue is that more corporate debt issuance could drag buyers away from other bond markets.\n\n\"The significant increase in hyperscaler issuance raises questions about who will be the marginal buyer of IG paper,\" he wrote. \"Will it come from Treasury purchases and hence put upward pressure on the level of rates? Or might it come from mortgage purchases, putting upward pressure on mortgage spreads?\"\n\nThe economist noted that Wall Street banks can't agree on just how high the borrowing wave will go in 2026, but they all forecast issuance to be high, with analysts eyeing $1.6 trillion to $2.25 trillion of investment-grade bond sales this year.\n\nHowever, for Sløk, the main takeaway is that heavy corporate borrowing could ultimately drive interest rates higher more broadly.\n\n\"The bottom line is that the volume of fixed-income products coming to market this year is significant and is likely to put upward pressure on rates and credit spreads as we go through 2026.\"\n\nSløk said investors should be assessing how the AI buildout, specifically the construction of more data centers and other infrastructure, will be paid for.\n\nCompanies such as Alphabet, Amazon, Meta, Microsoft, and Oracle collectively issued $100 billion of bonds in 2025. According to Bank of America, that's more than double the amount they raised in the previous year.\n\nSlok isn't the only economist to raise concerns about the broader economic impact of high AI spending. Mark Zandi, chief economist at Moody's Analytics, recently said that tech borrowing eclipsed levels seen during the dot-com era, adding that if the tech sector's growth stalls, the results could be dire.",
    "readingTime": 2,
    "keywords": [
      "investment-grade bond",
      "upward pressure",
      "interest rates",
      "chief economist",
      "issuance",
      "tech",
      "borrowing",
      "bonds",
      "market",
      "centers"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-capex-debt-bond-issuance-interest-rates-yields-data-centers-2026-1",
    "thumbnail_url": "https://i.insider.com/6965167b64858d02d2182ace?width=1200&format=jpeg",
    "created_at": "2026-01-12T18:18:57.308Z",
    "topic": "finance"
  },
  {
    "slug": "your-siri-is-about-to-be-powered-by-googles-ai",
    "title": "Your Siri is about to be powered by Google's AI",
    "description": "Apple and Alphabet have reached a deal that will have Google Gemini powering Siri's artificial intelligence capabilities.",
    "fullText": "Apple and Alphabet have reached a deal for Google's Gemini to power Siri's artificial intelligence capabilities.\n\nThe companies said these models would help power future Apple Intelligence features, including a more personalized Siri coming this year.\n\n\"After careful evaluation, Apple determined that Google's AI technology provides the most capable foundation for Apple Foundation Models and is excited about the innovative new experiences it will unlock for Apple users,\" Apple and Google wrote in a statement.\n\nCNBC earlier reported the news on Monday.\n\nShares of Alphabet stock jumped as much as 1% following the news, briefly vaulting the tech giant to a market capitalization of $4 trillion during trading on Monday. Last week, the company overtook Apple as the second most valuable company behind Nvidia.\n\nSpeculation of a potential deal has been circulating since last year. Bloomberg reported in November that Apple was considering paying $1 billion a year to use the Gemini model.\n\n\"This is what the Street has been waiting for with the elephant in the room for Cupertino revolving around its invisible AI strategy,\" Wedbush analysts wrote in a note on Monday morning, referring to Apple's Cupertino headquarters, \"but we believe this is an incremental positive to both AAPL and GOOGL as a major validation moment for Google as a premier foundation model and for Apple as a stepping stone to accelerate its AI strategy into 2026 and beyond.\"\n\nApple had a head start in the AI assistant race when it launched Siri on its iOS devices in 2011.\n\nHowever, the iPhone maker has lagged behind the competition following the launch of ChatGPT in late 2022. Apple has delayed several upgrades to Siri, and Apple shook up its AI division late last year.\n\nFor Google, integration with the leading mobile phone platform in the US is yet another distribution advantage. In addition to being available via a stand-alone app, Gemini powers some Google search features, and it's also the default AI assistant on the company's Pixel smartphones.\n\nThomas Hudson, a VP principal analyst at the research firm Forrester, told Business Insider that the deal could \"look counterintuitive\" given Apple and Google compete in the smartphone market.\n\nHowever, he pointed to Google's long-running deal to make it the default search engine on Apple's iPhones as an example of how the pair have partnered before. In December, a federal judge ordered Google to limit search and AI app contracts to a one-year term.",
    "readingTime": 3,
    "keywords": [
      "apple and google",
      "deal",
      "search",
      "features",
      "following",
      "market",
      "behind",
      "strategy",
      "assistant",
      "however"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/apple-google-gemini-to-power-siri-ai-capabilities-2026-1",
    "thumbnail_url": "https://i.insider.com/6965166604eda4732f2ee3db?width=1200&format=jpeg",
    "created_at": "2026-01-12T18:18:57.180Z",
    "topic": "finance"
  },
  {
    "slug": "alphabets-ai-surge-makes-it-the-4thever-company-to-crack-a-4-trillion-market-cap",
    "title": "Alphabet's AI surge makes it the 4th-ever company to crack a $4 trillion market cap",
    "description": "Alphabet topping a $4 trillion valuation on Monday marks the first time in seven years the Google parent has surpassed Apple's valuation.",
    "fullText": "Another tech titan just joined the $4 trillion club.\n\nAlphabet became the fourth company to reach a $4 trillion valuation on Monday, attesting to the immense hype surrounding AI that has propelled mega-cap tech firms to the stratosphere. The stock rose as much as 2% before paring gains.\n\nAlphabet joins Nvidia, Microsoft, and Apple in the elite club of the world's most valuable companies.\n\nIts surge to all-time highs on Monday came as Apple said that it picked Google's Gemini to power the iPhone maker's AI features in its devices.\n\n\"Apple and Google have entered into a multi-year collaboration under which the next generation of Apple Foundation Models will be based on Google's Gemini models and cloud technology. These models will help power future Apple Intelligence features, including a more personalized Siri coming this year,\" the companies said in a statement.\n\nCNBC earlier reported news of the deal.\n\nThe search giant launched its latest Gemini 3 AI model to rave reviews. The gains have leapfrogged competing models from OpenAI and other rivals that have been trying to chip away at Google's dominance.\n\nGoogle's full-stack advantage is also winning investor confidence. It's demonstrating that its in-house TPU chips are becoming a greater threat to Nvidia's AI chip monopoly, while Google has huge distribution for AI through Search, YouTube, and other popular products.\n\nAlphabet's latest stock surge also marks the first time it has surpassed Apple's valuation in seven years. Apple's market cap hovered around $3.8 trillion on Monday.\n\nShares of the Google parent soared 65% in 2025, and the stock is up 3% year-to-date.",
    "readingTime": 2,
    "keywords": [
      "google's gemini",
      "stock",
      "tech",
      "club",
      "alphabet",
      "valuation",
      "gains",
      "surge",
      "features",
      "latest"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/alphabet-stock-price-4-trillion-valuation-mag7-ai-stocks-rally-2026-1",
    "thumbnail_url": "https://i.insider.com/6965188604eda4732f2ee436?width=1200&format=jpeg",
    "created_at": "2026-01-12T18:18:57.179Z",
    "topic": "finance"
  },
  {
    "slug": "survey-how-executives-are-thinking-about-ai-in-2026",
    "title": "Survey: How Executives Are Thinking About AI in 2026",
    "description": "Heading into 2026, leaders are still bullish on AI despite worries about a bubble and struggles to demonstrate value with AI investments. According to a survey of digital leaders at leading global companies, the vast majority of leaders believe that AI is a high priority for their organization, have plans to spend more on it, and report that their company is getting measurable business value from their AI investments. The highly positive perspectives of these leaders on AI may suggest that the party can go on—high valuations of AI vendors, rising stock prices, a boom in data center construction, and initiatives to transform organizations around AI’s capabilities. But the survey also surfaced persistent issues around change and human and organizational readiness to take next steps. Organizations need to be able to address these in the coming years if they hope to achieve long-term success with AI.",
    "fullText": "Survey: How Executives Are Thinking About AI in 2026 by Randy Bean and Thomas H. DavenportJanuary 12, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAre business leaders still bullish on AI? Three years after the launch of ChatGPT, value from AI investments has been slow to emerge and worries that we’re in an AI bubble are growing. Yet according to responses to this year’s annual AI & Data Leadership Executive Benchmark Survey, companies are undaunted. Virtually every data and AI leader participating in this year’s survey believes that AI is a high priority for their organization, has plans to spend more on it, and confirms that their company is getting measurable business value from their AI investments.",
    "readingTime": 1,
    "keywords": [
      "survey",
      "business",
      "investments",
      "year’s"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/hb-how-executives-are-thinking-about-ai-heading-into-2026",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_10_SamuelFinch.jpg",
    "created_at": "2026-01-12T18:18:55.974Z",
    "topic": "business"
  },
  {
    "slug": "ofcom-investigating-elon-musks-x-after-outcry-over-sexualised-ai-images",
    "title": "Ofcom investigating Elon Musk’s X after outcry over sexualised AI images",
    "description": "Media regulator investigating site under Online Safety Act, with a de facto ban among possible...",
    "fullText": "Media regulator investigating site under Online Safety Act, with a de facto ban among possible punishments\n\nUK politics live – latest updates\n\nThe UK media watchdog has opened a formal investigation into Elon Musk’s X over the use of the Grok AI tool to manipulate images of women and remove their clothes.\n\nOfcom has acted following a public and political outcry over a deluge of sexual images appearing on the platform, created by Musk’s Grok, which is integrated with X.\n\nThe regulator is investigating X under the Online Safety Act, which carries a range of possible punishments for breaches, including a de facto UK ban of apps and websites for the most serious abuses.\n\n“We have decided to open a formal investigation to establish whether X has failed to comply with its legal obligations under the Online Safety Act,” said Ofcom.",
    "readingTime": 1,
    "keywords": [
      "online safety",
      "safety act",
      "formal investigation",
      "media",
      "regulator",
      "investigating",
      "facto",
      "punishments",
      "images",
      "ofcom"
    ],
    "qualityScore": 0.35,
    "link": "https://www.theguardian.com/technology/2026/jan/12/ofcom-investigating-x-outcry-sexualised-ai-images-grok-elon-musk",
    "thumbnail_url": "https://i.guim.co.uk/img/media/9eed52bcccc9b2621ffb52657bdd17f06c35aa8b/184_0_3083_2467/master/3083.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e58fe4473c3124ddd19c60a6a892b1f4",
    "created_at": "2026-01-12T12:26:30.215Z",
    "topic": "tech"
  },
  {
    "slug": "publishers-fear-ai-search-summaries-and-chatbots-mean-end-of-traffic-era",
    "title": "Publishers fear AI search summaries and chatbots mean ‘end of traffic era’",
    "description": "Media bosses expect web referrals to plunge and want journalists to emulate content creators, report finds\nMedia companies expect web traffic to their sites from online searches to plummet over the next three years, as AI summaries and chatbots change the way consumers use the internet.\nAn overwhelming majority are also planning to encourage their journalists to behave more like YouTube and TikTok content creators this year, as short-form video and audio content continues to boom.\n Continue reading...",
    "fullText": "Media bosses expect web referrals to plunge and want journalists to emulate content creators, report finds\n\nMedia companies expect web traffic to their sites from online searches to plummet over the next three years, as AI summaries and chatbots change the way consumers use the internet.\n\nAn overwhelming majority are also planning to encourage their journalists to behave more like YouTube and TikTok content creators this year, as short-form video and audio content continues to boom.\n\nThe findings are drawn from a new report from the Reuters Institute for the Study of Journalism, which included the views of 280 media leaders from 51 countries. It found media executives around the world fear search engine referrals will fall by 43% over three years.\n\nSearch traffic to news sites has already plunged by a third in a single year globally, with the rise of AI overviews and chatbots, as well as changes to the search algorithms that have been the lifeblood of some media companies since the rise of the internet.\n\nGoogle search is down 33% globally, according to new data for more than 2,500 news sites sourced by Chartbeat. The figure is even higher for the US.\n\nLifestyle, celebrity and travel content is being much more heavily affected than current affairs and news outlets so far. Publications carrying out live reporting and current affairs are more protected from AI summaries.\n\nGoogle’s AI Overviews already appear at the top of about 10% of search results in the US, according to the report, and are rapidly rolling out elsewhere. Referrals to media sites from ChatGPT are growing, but the report still described these referrals as “little more than a rounding error”.\n\nNic Newman, senior research associate at the institute, said the “traffic era” for online publishers, which had sustained them since the advent of the internet, was coming to an end.\n\n“It is not clear what comes next,” he said. “Publishers fear that AI chatbots are creating a new convenient way of accessing information that could leave news brands – and journalists – out in the cold.\n\n“But tech platforms do not hold all the cards. Reliable news, expert analysis and points of view remain important both to individuals and to society, particularly in uncertain times. Great storytelling – and a human touch – is going to be hard for AI to replicate.”\n\nThere has already been a swing away from simply trying to score big hits through web traffic – with fewer people clicking on a link to a story. Instead, more companies have moved towards a subscription model that gives them a direct relationship with their audience.\n\nThe Reuters Institute report also revealed a scramble among media companies to invest in digital platforms like YouTube and TikTok as short-form video use continues to grow. Many also want to encourage their journalists to embrace the content creator culture that the platforms have popularised.\n\nThree-quarters of media managers surveyed said they will be trying to get their staff to behave more like creators in 2026. Half are planning to partner with creators to help distribute their content.\n\nDowning Street is also trying to tap into social media as Keir Starmer attempts to find ways of reaching Gen Z and bypass the traditional media.\n\nThe campaigner Anna Whitehouse, who goes by Mother Pukka, and the personal finance influencers Cameron Smith and Abi Foster have all been given access to senior ministers in recent months.",
    "readingTime": 3,
    "keywords": [
      "web traffic",
      "content creators",
      "youtube and tiktok",
      "media",
      "search",
      "referrals",
      "journalists",
      "sites",
      "chatbots",
      "internet"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/media/2026/jan/12/publishers-fear-ai-search-summaries-and-chatbots-mean-end-of-traffic-era",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3e873df8a76e16dc1be996c4fab0319e21edd236/688_0_6880_5504/master/6880.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=47c5e1c8ca067161d1525b9d2575d921",
    "created_at": "2026-01-12T12:26:30.170Z",
    "topic": "tech"
  },
  {
    "slug": "quantization-and-distillation-effects-on-code-llms",
    "title": "Quantization and distillation effects on code LLMs",
    "description": "Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.02563",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-12T12:26:18.532Z",
    "topic": "tech"
  },
  {
    "slug": "big-short-investor-michael-burry-says-ai-is-turning-big-tech-into-a-worse-business",
    "title": "'Big Short' investor Michael Burry says AI is turning Big Tech into a worse business",
    "description": "Michael Burry, the investor from \"The Big Short,\" said return on invested capital is the \"measure to beat all measures\" when looking at AI companies.",
    "fullText": "Michael Burry, the investor made famous by \"The Big Short,\" says the era of Big Tech turning relatively small investments into huge profits is ending.\n\nIn a recent Substack exchange with tech podcaster Dwarkesh Patel, Burry said the most important metric AI industry investors should be watching isn't revenue growth, hiring, or even market size, but return on invested capital, or ROIC.\n\nROIC is a measure of how efficiently a company turns the money it puts into its business into profit.\n\n\"The measure to beat all measures is return on invested capital (ROIC), and ROIC was very high at these software companies. Now that they are becoming capital-intensive hardware companies, ROIC is sure to fall, and this will pressure shares in the long run,\" Burry wrote.\n\nAI, Burry said, is pushing companies like Microsoft, Google, and Meta away from their historically asset-light software models and toward a far more capital-intensive future defined by data centers, chips, and energy.\n\nEven if AI expands Big Tech's addressable market, he said, falling ROIC could pressure stock prices for years to come.\n\nBurry rose to fame after his bet against the mid-2000s housing boom was chronicled in \"The Big Short.\" Outside the occasional cryptic social media post, Burry, for a long time, spoke publicly only rarely.\n\nThat changed late last year when he closed his hedge fund to outside cash and began writing financial analysis on Substack.\n\nPerhaps most notably, he has recently compared the AI boom to the late-1990s dot-com bubble, calling OpenAI the \"Netscape of our time.\" Netscape's IPO marked the beginning of dot-com hype in 1995. Five years later, the bubble burst.\n\nBurry's hedge fund, Scion Asset Management, has made large bets against Nvidia and Palantir Technologies, two darlings of the AI era, according to a regulatory filing released in September last year.\n\nLeading AI companies, like OpenAI, Anthropic, Google, and Meta, are spending big to build out the infrastructure they need to support their energy- and data-intensive chatbots and other AI applications. Debt and equity investors have lined up to back these projects.\n\nSo far, however, those companies have not shown significant profit returns on their AI products, leading investors like Burry to sound the alarm that AI is a bubble on the verge of bursting.\n\nAgreed. And still, return on investment will continue to fall, almost all AI companies will go bankrupt, and much of the AI spending will be written off. Will it be the Panic of 2026? 2027? Does not have to be. https://t.co/VBWjh26vnc\n\n\"At some point, this spending on the AI buildout has to have a return on investment higher than the cost of that investment, or there is just no economic value added,\" Burry wrote in the Substack post.",
    "readingTime": 3,
    "keywords": [
      "invested capital",
      "hedge fund",
      "return",
      "investors",
      "bubble",
      "investment",
      "burry",
      "market",
      "measure",
      "profit"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/michael-burry-big-short-key-metric-evaluate-ai-bubble-2026-1",
    "thumbnail_url": "https://i.insider.com/6964152d04eda4732f2edc77?width=1200&format=jpeg",
    "created_at": "2026-01-12T12:26:15.649Z",
    "topic": "finance"
  },
  {
    "slug": "we-asked-over-150-software-engineers-about-vibecoding-heres-what-they-said",
    "title": "We asked over 150 software engineers about vibe-coding. Here's what they said.",
    "description": "167 software engineers responded to Business Insider's vibe-coding survey. Over 45% reported \"keeping up\" with AI tools. Almost 17% feel behind.",
    "fullText": "AI has radically changed what coding looks like. We asked software engineers how they felt about it.\n\nAndrej Karpathy coined the term \"vibe-coding,\" or the creation of code using AI. The term has since gained traction among developers worldwide and was named Collins Dictionary's Word of the Year for 2025.\n\nLess than a year after his post, Karpathy wrote that he had \"never felt this much behind as a programmer.\"\n\nWe asked developers: When it comes to vibe-coding, do you feel ahead, behind, or like you're keeping pace?\n\n167 software engineers responded to our survey. The biggest cohort — 75 engineers, or 46.9% — said that they were \"keeping up.\" 30 engineers said they felt ahead of the curve, while 27 felt behind.\n\n28 engineers (or 17.5% of respondents) said that they were opting out of using AI code editing tools entirely. These engineers wrote that the tools weren't advanced enough, or that they took too long to learn how to use. None of the 28 agreed to speak on the record after Business Insider reached out.\n\nWhile the survey isn't scientific, the results offer insight into how software engineers are feeling about their rapidly changing industry.\n\nIn follow-up conversations, eight engineers told Business Insider how they feel about AI code editors. All found them helpful in some form, though their usages ranged from one-off tools to lifesavers.\n\nRyan Shah sometimes wonders: \"Did I really need to learn how to write code?\"\n\nThe 23-year-old AI consultant from Atlanta recently graduated with a degree in computer information technology. Now he uses Cursor and Google's Antigravity, paired with Claude Opus 4.5, which he said was at \"midlevel engineer status.\"\n\nShah said he doesn't regret his software engineering courses, though. They taught him to \"read\" code, he said, a skill that, coupled with his vibe-coding proficiencies, keeps him from being \"the first one laid off.\"\n\nJavanie Campbell swung the other way: He warned that over-reliance on vibe-coding tools will put your career in danger.\n\n\"For people who turn to the LLM as the God or the expert, they will be replaced,\" said the 35-year-old CEO of DevDaysAtWork, who is based in Jamaica.\n\nAmong software engineers, there's a debate brewing: Just how bad will the effects of AI code editors be on jobs? Some say they will shrink the industry's workforce; others call them tools, not replacements for engineers.\n\nThe first time Ryan Clinton tried vibe-coding, he got scared for his job. He's not fearful anymore, he said.\n\nClinton's engineering level won't be affected, said the 46-year-old software developer from Nashville. More experienced engineers work on \"architecture and design,\" he said, while more junior staffers code. At this point of AI coding, human intervention is also still routinely necessary.\n\n\"You want to make sure it makes sense,\" he said. \"Only an idiot would randomly click 'yes' and commit it.\"\n\nBarry Fruitman is more worried — but not for himself. At 56, the Android developer from Toronto doesn't think the job market will feel the effect until five to 10 years out.\n\n\"Today, I think the threat is overstated, and hopefully it will stay that way until I retire,\" he said.\n\nEd Gaile said AI tools have doubled, if not tripled, his productivity.\n\nThe 55-year-old Appfire principal solutions architect from Atlanta was impressed by the decrease in context switching that vibe-coding tools brought.\n\n\"I wish I had this 15 years ago,\" he said.\n\nFor AI code editors, the word \"productivity\" still looms large. Many people feel that they're saving time by using these tools. Others cite the additional time spent reviewing and correcting lines of code.\n\nA July METR study added fuel to the fire.\n\nThe study asked experienced developers to complete a series of tasks. Study participants working without AI's help spent 10% more time coding — but those with AI assistance spent 20% more time reviewing AI outputs, prompting AI, waiting on AI, or being idle. Ultimately, the study found that the AI-assisted developers were less productive.\n\nShawn Gay, a 54-year-old R&D manager from El Paso, Texas, spends time keeping up with the industry's changes. He said he felt behind the curve.\n\n\"I have decades of experience, so I feel like it's a huge effort to try to change the way my brain thinks about software,\" Gay told Business Insider.\n\nGus De Souza said that he saved time on coding, but spent more time reviewing the AI-generated code. The real productivity gains were in troubleshooting, said the 48-year-old software architect from Kitchener, Ontario.\n\nWhat even is a vibe-coder? While the term has grown to encompass most forms of AI-assisted coding, Karpathy's X post first defined it as when developers \"fully give in to the vibes, embrace exponentials, and forget that the code even exists.\"\n\nLara Fraser, a data analyst and epidemiologist from Sarasota, Florida, doesn't consider herself a vibe-coder.\n\nFraser codes in R and uses tools like ChatGPT and Claude to assist. She's tried other tools, but found high rates of hallucination. The model generation also matters, Fraser said: GPT 5.1 was great, but 5.2 was a \"disaster.\"\n\nFor Fraser, vibe-coding depends on the programmer's skill. Anyone can create an app, but not everyone can maintain it.\n\n\"Inevitably, something's going to break,\" she said. \"Can you fix it? If you can't, you're a vibe-coder.\"",
    "readingTime": 5,
    "keywords": [
      "code editors",
      "software engineers",
      "year-old software",
      "vibe-coding tools",
      "business insider",
      "developers",
      "behind",
      "study",
      "doesn't",
      "productivity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/software-engineers-on-vibe-coding-ai-tools-2026-1",
    "thumbnail_url": "https://i.insider.com/69601f86832e0ef1ead7712a?width=1200&format=jpeg",
    "created_at": "2026-01-12T12:26:15.498Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-ceo-who-built-a-fantasy-board-of-directors-with-ai-versions-of-leaders-like-steve-jobs-and-warren-buffett",
    "title": "I'm a CEO who built a fantasy board of directors with AI versions of leaders like Steve Jobs and Warren Buffett",
    "description": "A tech CEO put together a dream board of directors with AI representing famous leaders. Here's how he uses it.",
    "fullText": "This as-told-to essay is based on a conversation with Matt Blumberg, a four-time technology CEO who now leads Markup AI, maker of an AI platform designed to help brands safely scale AI-generated content. He is based in New York City. This story has been edited for length and clarity.\n\nSince I run an AI company, I try to build AI agents and use AI as much as I can. In October, I got an idea to build what I call a fantasy board of directors from another CEO, and with his permission, I made a version of my own to use as a personal thought partner.\n\nWe have an actual human board, and it's fantastic. I get really good advice from them. But I wanted to use AI to create a fantasy board because mine is limited by the five people who are on it and the experiences that they have in life.\n\nSo the first thing my executive team and I did was create a fantasy draft. It's a bit of a play on fantasy football and fantasy basketball. But instead of it being a competitive thing, where each of us would draft our own teams, we drafted just one together.\n\nWe started by making a spreadsheet of essentially famous people, largely but not entirely, from the business world. We divided them into categories, including iconic business leaders, tech CEOs, VCs, authors, and thought leaders. We also had a category for different voices, such as Oprah Winfrey and Taylor Swift.\n\nNext, we had something like a draft where we picked a couple of people from each category that we wanted on the board. We settled on about 15 names, including Warren Buffett, Steve Jobs, and Oprah Winfrey.\n\nThere are also two people on it that I know. One is me. The other is Fred Wilson, a VC I've worked with for the past 25 years at other companies.\n\nFrom here, we had AI build 5,000-word profiles for each person, and we gave the AI a certain template to follow. We wanted the fantasy board members to be able to react to things as real board members would, with actual things they've said about how companies and boards perform.\n\nNext, we built the agent. We loaded all these profiles in and then wrote a really long instruction set about what we were trying to accomplish and what our company does. We also loaded materials from past board meetings, our quarterly business review decks, and other things that real board members would have at their disposal or in their heads.\n\nAll of this took maybe an hour or two.\n\nSo now the fantasy board exists, and I use it as a thought partner. For example, I will provide a draft of a board book before sending it to my actual board, and I'll say: These are materials for an upcoming meeting. What do you think of them? Are there topics you would have expected me to cover that I didn't? What questions am I likely to get back from our board? In return, I'll get really useful commentary.\n\nOne thing we put in the instruction set is that when I ask the board for its opinion, very generically, I want it to tell me the consensus opinion and notable outlying dissent with quotes of things that the fantasy board members have actually said.\n\nI'll also ask it for help with internal projects. I'll say things like: Hey, I'm doing a presentation for our kickoff meeting next week. What do you think are the top three themes I should hit?\n\nRecently, I asked my fantasy board to give me a performance review for 2025. It nailed it. The board called out the things that I would have said are my strengths and things that I would have said are problems. I sent the review to my executive team just as an FYI, and they all came back to me and said it was pretty impressive.\n\nI don't use the fantasy board every day, but I'm probably using it at least every other week for something. There are two big limitations. \n\nOne is that anything agentic is only as good as its inputs. My fantasy board only knows what I've told it about my business, or what's publicly available. It doesn't actually know what happens every day in the company. Even though I'm pretty good about feeding it information, it just doesn't have all the context.\n\nThe other limitation is that they're not real people. When you have a real board of directors, you have a real thought partner as a strategic advisor. If you have a board meeting, people are in a room together. They have body language. They have facial expressions. You can tell when they lean in, when they lean back. You can tell when they roll their eyes because they don't believe something you said. You can call them out on that.\n\nWith any AI agents, you need to be really careful not to believe the bullshit. They're predictive, and they're good, but not perfect. They're not human, and they miss a lot of cues.\n\nI told my real board about my fantasy board at our last meeting, which was in November, right after we built it. I explained what it was and how I've been using it. They thought it was great. A couple of them asked me afterward how I built it. They asked for a road map and said that they'd like to do something like it.\n\nThey viewed the fantasy board the same way I do, which is that it's a nice add-on, a sort of augmentation of thought partnership, but that it's never going to be a substitute for a real board.",
    "readingTime": 5,
    "keywords": [
      "oprah winfrey",
      "i'll say",
      "executive team",
      "create fantasy",
      "fantasy board",
      "it's",
      "draft",
      "business",
      "they're",
      "partner"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ceo-used-ai-to-build-a-fantasy-board-of-directors-2026-1",
    "thumbnail_url": "https://i.insider.com/69617d0604eda4732f2ed6d9?width=800&format=jpeg",
    "created_at": "2026-01-12T12:26:15.331Z",
    "topic": "finance"
  },
  {
    "slug": "ceo-bob-sternfels-says-mckinsey-now-has-60000-employees-25000-of-them-are-ai-agents",
    "title": "CEO Bob Sternfels says McKinsey now has 60,000 employees: 25,000 of them are AI agents",
    "description": "McKinsey & Company CEO Bob Sternfels says he wants every employee working alongside an AI agent within a year and a half.",
    "fullText": "Here's a case interview question for you: If a 40,000-person consulting firm added 25,000 AI agents to its workforce in under two years, how would that change its competitive advantage?\n\nIt may not be long before McKinsey & Company is asking job candidates such a case question — but first, the firm is answering it for itself.\n\nThe firm's CEO, Bob Sternfels, said on an episode of Harvard Business Review's IdeaCast recently that the company is rapidly remaking itself around artificial intelligence.\n\nHe said that, according to his latest tally, the firm now has a workforce of 60,000, which he said is made up of 40,000 humans and 20,000 agents.\n\nSpeaking at the Consumer Electronics Show in Las Vegas last week, he said the number of AI agents McKinsey uses is actually closer to 25,000. A McKinsey spokesperson confirmed to Business Insider that this figure is the most accurate.\n\nSternfels said on the podcast that just a year and a half ago, the company only used a few thousand agents and hopes that in the next year and a half, every employee will be \"enabled by at least one or more agents.\"\n\nAI agents are commonly defined as virtual assistants that can complete tasks autonomously. They break down problems, outline plans, and take action without being prompted by a user.\n\nThe rapid agent rollout at McKinsey reflects a broader industry push to embed generative AI into several facets of a consultant's daily work.\n\nFirms from Boston Consulting Group to PwC are shifting from slide decks and advisory work to multi-year AI-driven transformation projects, and adding a slate of new tools to turbocharge their efficiency.\n\nQuantumBlack, with its 1,700-person team, drives all of McKinsey's AI initiatives, which now account for 40% of the firm's work, Alex Singla, a senior partner at McKinsey who co-leads QuantumBlack, told Business Insider.\n\nAs part of that effort, Singla said the firm is seeking a more dynamic set of candidates who can move between traditional consulting work and an engineering mindset — and can work alongside AI.\n\n\"What we want to be able to do is find those people that actually have a propensity to either be this great McKinsey consultant, and/or a great technologist, and then groom them to be both,\" he said.\n\nThe same is true at Boston Consulting Group, which now has a team of \"forward-deployed consultants\" who are vibe-coding and building AI tools for client projects.\n\nSternfels said AI is reshaping more than its workforce — it is also changing McKinsey's business model.\n\nThe firm is transitioning from its traditional advisory work and classic fee-for-service approach. Instead, McKinsey is moving toward a model where it works with clients to identify joint business cases and then helps them underwrite the outcomes of that business case.",
    "readingTime": 3,
    "keywords": [
      "boston consulting",
      "boston consulting group",
      "agents",
      "firm",
      "workforce",
      "mckinsey",
      "candidates",
      "firm's",
      "half",
      "advisory"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/mckinsey-workforce-ai-agents-consulting-industry-bob-sternfels-2026-1",
    "thumbnail_url": "https://i.insider.com/69608fef04eda4732f2ec2ee?width=1200&format=jpeg",
    "created_at": "2026-01-12T12:26:15.317Z",
    "topic": "finance"
  },
  {
    "slug": "competition-is-heating-up-on-wall-street-here-are-4-things-to-watch-as-they-report-earnings",
    "title": "Competition is heating up on Wall Street. Here are 4 things to watch as they report earnings.",
    "description": "From credit risks to AI, here's what experts are watching as banks, including JPMorgan and Goldman Sachs, prepare to report fourth-quarter earnings.",
    "fullText": "As Wall Street's biggest banks prepare to report fourth-quarter earnings next week, competition is intensifying across nearly every part of the business — from dealmaking and talent to technology. JPMorgan Chase kicks things off Tuesday, followed by Bank of America and Citi reporting on Wednesday, and Goldman Sachs and Morgan Stanley on Thursday.\n\nThat competitive pressure is shaping how investors, analysts, and executives are thinking about the coming year. In an interview, Mike Mayo, a longtime Wells Fargo analyst known for his pointed questions on earnings calls, said banks are waging the toughest fight they've faced against rivals in years to capture new business.\n\n\"The animal spirits have been unleashed,\" Mayo said, adding that competition is now \"at its most intense level since before the global financial crisis,\" with banks across the industry playing offense across sectors ranging from financial advisory to investment management to consumer banking. Even before earnings get underway, some hopeful signals are already emerging — particularly around pay.\n\nAlan Johnson, the founder of compensation consultancy Johnson Associates, said initial readouts from industry insiders at firms that have already communicated compensation are pointing to a strong year. \"Banking and trading, the big winners for bonuses this year is sort of what I'm detecting,\" Johnson said. Investment banking advisory bonuses, he added, are tracking higher than he predicted, up as much as 20% from the year prior.\n\nAs earnings season gets underway, experts say there are four key things to watch.\n\nAfter a rocky start marked by tariff worries and market volatility, dealmakers finished 2025 in the green. Worldwide M&A value rose about 45% year over year, according to LSEG data, even as the total number of deals declined slightly.\n\nIn a 2026 forecast, Goldman Sachs analysts said they expect that momentum to carry forward, projecting growth in investment banking fees and a pickup in spending by financial sponsors.\n\nMatthew Toole, LSEG's director of deals intelligence, said some private equity firms are approaching a traditional exit window for companies they bought during the pandemic, setting the stage for more sponsor-driven sales.\n\n\"Coming off of the year that we've had from an investment banking perspective — the second-largest year on record for announced M&A, the largest year on record for global debt, and also a record year for syndicated lending — I think you're going to see pretty significant growth in the investment banking fee pool,\" Toole said.\n\nThat resurgence is intensifying hiring competition. Speaking at a financials conference Goldman hosted in December, Denis Coleman, the firm's chief financial officer, acknowledged the pretty penny that it was spending to hang onto its top performers.\n\n\"We want to make sure that we're in a position to pay very competitively, particularly for our very best people,\" he said.\n\nJeanne Branthover, vice chairman of DHR International and global head of the firm's financial services and fintech practice, told Business Insider that deal momentum is translating directly into hiring pressures. \"What happens is the best talent is always going to be recruited,\" she said. \"That is always the case when a market is good.\"\n\n\"Credit is still fine, certainly we're on a cockroach alert,\" Mayo said, referencing a comment made by JPMorgan CEO Jamie Dimon in October. The collapse of subprime auto-lenders Tricolor Holdings and auto-parts company First Brands last fall raised questions about the health of the credit market, and during his firm's third-quarter earnings call, Dimon said, \"When you see one cockroach, there's probably more.\"\n\nMayo added that a major surprise at large banks would be unlikely, but cautioned that credit cycles often begin with isolated problems, particularly at midsize firms. Leaders in the private credit industry have pushed back on claims that private lending is behind rising credit stress, saying some recent high-profile bankruptcies reflect risks tied to loans originated and syndicated by banks rather than held by private lenders.\n\nStill, Mayo offered a note of caution: \"When you're bullish, this is the time when bad loans are made.\"\n\nAt Goldman Sachs, attention is trained on OneGS 3.0, the latest iteration of the company's cross-bank initiative to maximize returns across business lines.\n\nMayo pointed to Goldman Sachs 3.0 as one of the most interesting new data points this earnings season.\n\nThe program, announced last fall, is designed as a multi-year effort to boost profitability and productivity by leveraging AI. Goldman has said the initiative includes head count discipline and limited role reductions.\n\nIf the past few years represented AI's Wild West — marked by widespread experimentation and spending — this year is about formalizing what works.\n\nSumeet Chabria, CEO of advisory firm ThoughtLinks and a former senior Wall Street technology executive, said AI has moved from isolated pilots to a core priority. He anticipates more detail from banking chiefs on how their firms are deploying AI to enhance results.\n\n\"Every line of business' strategic plan will have clarity on how they're using AI and how they're going to drive value, for sure,\" he said. \"The focus has moved from projects and programs or pilots to enterprise — to AI being a strategic priority for all the top banks.\"",
    "readingTime": 5,
    "keywords": [
      "earnings season",
      "investment banking",
      "goldman sachs",
      "banks",
      "financial",
      "credit",
      "across",
      "firms",
      "competition",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/4-signals-to-watch-jpmorgan-goldman-sachs-report-earnings-2026-1",
    "thumbnail_url": "https://i.insider.com/6961636664858d02d2181984?width=1200&format=jpeg",
    "created_at": "2026-01-12T12:26:15.307Z",
    "topic": "finance"
  },
  {
    "slug": "agentwatch-a-terminal-dashboard-for-monitoring-ai-agent-costs",
    "title": "AgentWatch – A terminal dashboard for monitoring AI Agent costs",
    "description": "I built AgentWatch to solve a problem I had: AI agents burning tokens and money behind my back. Now I can monitor everything in real-time. Feedback welcome! 🤖💸 - Tarunjit45/agentwatch",
    "fullText": "Tarunjit45\n\n /\n\n agentwatch\n\n Public\n\n I built AgentWatch to solve a problem I had: AI agents burning tokens and money behind my back. Now I can monitor everything in real-time. Feedback welcome! 🤖💸\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Tarunjit45/agentwatch",
    "readingTime": 1,
    "keywords": [
      "agentwatch"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Tarunjit45/agentwatch",
    "thumbnail_url": "https://opengraph.githubassets.com/3c2712970f5c42d5cb972f7991c221766cc6e544017c3c92b24ecf43f262857b/Tarunjit45/agentwatch",
    "created_at": "2026-01-12T06:22:43.189Z",
    "topic": "tech"
  },
  {
    "slug": "ai-in-rollercoaster-tycoon",
    "title": "AI in RollerCoaster Tycoon",
    "description": "AI autonomously manages a theme park in the classic game RollerCoaster Tycoon, placing rides, fixing infrastructure, and generating CFO reports, all via command line.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://labs.ramp.com/rct",
    "thumbnail_url": "https://labs.ramp.com/rct/og-image-sized.png",
    "created_at": "2026-01-12T06:22:40.838Z",
    "topic": "tech"
  },
  {
    "slug": "i-asked-chatgpt-for-the-best-alternatives-to-investing-in-gold-this-is-what-it-said",
    "title": "I Asked ChatGPT for the Best Alternatives To Investing In Gold: This Is What It Said",
    "description": "Discover some of ChatGPT's recommendations for alternatives to gold -- like silver, defensive stocks and bonds -- for safety during economic uncertainty.",
    "fullText": "Gold saw great growth in 2025. It’s not surprising, as investors often turn to gold during times of economic uncertainty. With the expectations of the U.S. dollar weakening and slower growth, more people turn to a safe-haven investment like gold, according to Morgan Stanley.\n\nGold prices may be too steep for some investors, leaving them looking for other suitable investments for relative safety. For investors concerned about inflation or market volatility, stability and inflation hedges can be found elsewhere. GOBankingRates asked ChatGPT for the best alternatives to investing in gold. Here’s what the artificial intelligence (AI) chatbot recommended as some gold alternatives.\n\nAlso see four reasons for gold’s popularity in 2025 and how to protect your portfolio.\n\nGold isn’t the only precious metal retail investors can purchase. Silver, platinum and palladium are all legitimate alternative investments to buy. Think of these precious metals as cousins to gold but with their unique profiles.\n\n“These metals can benefit from both investment demand and industrial use, which gives them a different performance profile than gold,” ChatGPT said. “All three metals tend to be riskier than investing in gold, but they do provide some upside. Silver tends to be more volatile, but it can outperform gold during strong economic periods due to industrial demand. Platinum and palladium are rarer and more heavily tied to automotive production, which adds risk but also potential upside.”\n\nHaving a small portion of your portfolio in these metals can add helpful diversification.\n\nRead Next: 3 Safest Investments To Hold In The Current Trump Economy\n\nCheck Out: 9 Low-Effort Ways To Make Passive Income (You Can Start This Week)\n\nOwning stocks can still be a wise choice for cautious investors, given the right circumstances. Growth stocks may be too risky, but defensive stocks can provide some protection. Defensive stocks typically have a strong history of dividend growth, minimal debt and an inexpensive valuation, according to Kiplinger.\n\nIn short, companies that sell items people always use are often defensive. “Firms in defensive sectors like utilities, healthcare and consumer staples sell products people need regardless of economic conditions,” ChatGPT explained.\n\nDefensive means dependable, not boring, and that dependability can create generous dividend growth.\n\nGold investors often value tangible assets they can see. Land, such as farmland or real estate, could be an alternative to gold for the right investor. “These assets are less liquid and can require more management, but they often move independently of traditional financial markets,” the AI said.",
    "readingTime": 3,
    "keywords": [
      "dividend growth",
      "defensive stocks",
      "investors",
      "metals",
      "gold",
      "economic",
      "investments",
      "chatgpt",
      "investment",
      "inflation"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asked-chatgpt-best-alternatives-investing-141816412.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ug2Ayyp.hs7tHFJ2U1XiDg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/gobankingrates_644/491691a5265cb962e1a7212a20bd598e",
    "created_at": "2026-01-12T06:22:39.970Z",
    "topic": "finance"
  },
  {
    "slug": "after-7-years-at-mckinsey-i-left-to-build-an-ai-healthtech-startup-i-had-to-unlearn-the-pursuit-of-perfection",
    "title": "After 7 years at McKinsey, I left to build an AI healthtech startup. I had to unlearn the pursuit of perfection.",
    "description": "Julius Bruch spent seven years at McKinsey before founding an AI dementia startup. He shares what made the leap hard — and why consulting helped.",
    "fullText": "This as-told-to essay is based on a conversation with Julius Bruch, the 39-year-old cofounder and CEO of AI healthtech startup Isaac Health. It has been edited for length and clarity. Business Insider has verified his employment and academic history.\n\nI started training in general medicine and neurology, and I've always been passionate about this area, partially because my grandmother had an atypical form of dementia. I completed my Ph.D. in dementia, focusing on the molecular aspects and drug discovery.\n\nComing out of the research world, I went into McKinsey because I was interested in how the healthcare system works more broadly and how the different parts fit together. During my seven-and-a-half years at McKinsey, I worked with payers, health systems, and state governments on value-based care, chronic condition management, and digital health.\n\nI left in 2021 because I wanted to move on and put things into practice. I felt like I had seen and learned it, and it became a decision between becoming a career consultant or seeing myself as someone who wanted to build something innovative.\n\nConsulting was a fantastic training opportunity. I learned a lot about how the healthcare system works, how different parts work together, and how to structure a problem. I would say it was the best possible preparation for being a founder that you can think of.\n\nThe relationships I built — both inside the firm and with clients — have been a key success driver for the business. It means you know who to reach out to, people at payers you can problem-solve with, and some initial contact points for fundraising. The alumni network is strong.\n\nYou also train your analytical thinking and problem-solving approach. Starting a company feels like a consulting engagement — you're interviewing a lot of people, trying to solve a problem, and building a solution. Eventually, it outgrows that, but the thinking that there's always a way to solve something comes from that analytical training.\n\nThe main thing to unlearn from consulting was the pursuit of perfection. A startup needs to be able to move fast with scrappy pragmatism. The other thing I had to unlearn was always giving in to clients. As a startup founder, you learn quickly where boundaries need to be set.\n\nInitially, it felt a bit like: What am I doing? Am I just playing around?\n\nStarting a business was a bit of a dream, but not something I was going to do at any cost.\n\nI definitely lost some sweat over making the decision. I told myself I would give it three months. After those three months, there was enough traction to make it work and continue moving forward.\n\nStartup life is a lot less structured, and you have to be comfortable with that.\n\nEvery major milestone feels like a massive reward because you're fighting for it. It's not like things just run smoothly and that's it. Every client you get, every revenue milestone, and any external recognition is hard-fought for.\n\nIn August, our startup raised $10.5 million in Series A funding, bringing the company's total funding to $16.3 million. It feels great for a day — you realize that more investment also means higher expectations and that the goal posts have moved.\n\nEvery startup faces challenges, like scaling. We have a service component, so there are always people involved as we grow, and that comes with difficulties. You have to hire, find the right talent, and keep changing the processes, because the way things work for a team of four people doesn't work for a team of 60 or 70.\n\nJumping into a startup also means being open to flexibility. You have to be able to wear multiple hats and jump in where needed.\n\nMany people come in quite timidly. They want to work within their scope and be trained on the job. But you really have to create everything from scratch, like workflows. It requires a lot of creativity and problem-solving. Sometimes, I could have acted faster on certain things or signals.\n\nGo with the science and find a cofounder who is deeply rooted in the subject matter. I see a lot of startups that are a little bit obvious or built on very standard, replaceable models without a major moat. It's important to make sure you are cutting-edge.\n\nDo you have a story to share about becoming an AI startup founder? Contact this reporter at cmlee@insider.com.",
    "readingTime": 4,
    "keywords": [
      "healthcare system",
      "startup founder",
      "training",
      "consulting",
      "cofounder",
      "dementia",
      "mckinsey",
      "parts",
      "together",
      "payers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-consultant-ai-startup-founder-isaac-health-julius-bruch-2026-1",
    "thumbnail_url": "https://i.insider.com/693f986964858d02d216c87c?width=800&format=jpeg",
    "created_at": "2026-01-12T06:22:39.212Z",
    "topic": "finance"
  },
  {
    "slug": "china-ai-chipmaking-stocks-extend-rally-as-ipo-boom-boosts-sentiment",
    "title": "China AI, chipmaking stocks extend rally as IPO boom boosts sentiment",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/china-ai-chipmaking-stocks-extend-rally-as-ipo-boom-boosts-sentiment-4440684",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEE040EX_M.jpg",
    "created_at": "2026-01-12T06:22:39.204Z",
    "topic": "finance"
  },
  {
    "slug": "a-google-ai-product-manager-has-a-career-advice-be-a-crab",
    "title": "A Google AI product manager has a career advice: 'Be a crab'",
    "description": "A Google AI product manager says moving sideways and using what you already know is the best way to break into product roles.",
    "fullText": "A Google AI product manager's career advice is unexpectedly crustacean.\n\nMarily Nika, who has worked in AI product roles for over a decade, said in an episode of \"The Growth Podcast\" by Aakash Gupta published Sunday that aspiring product managers should \"be like crabs.\"\n\n\"That means that you need to move adjacent to what you've been doing,\" Nika said, adding that one's past experience is a competitive advantage.\n\nNika shared the example of a student in her AI product management boot camp who worked in the hearing aid industry and felt stuck and closed off from the tech industry. The student believed he was in a \"completely different domain\" and didn't see a clear path into product management, she said.\n\nNika encouraged him to look more closely at how his experience could translate. When they checked Apple's careers site, they found an opening for a product manager working on AirPods — a role where expertise in hearing could be relevant.\n\n\"We need to be open-minded. We really need to bring in the previous experience we have because that's gonna set us apart,\" Nika said.\n\nNika also provided another example involving a sports journalist who sought to transition into an AI product manager role in sports. Rather than being afraid of lacking a traditional product résumé, Nika advised him to lean into his domain expertise. Product skills can be learned, but a deep understanding of users and industries is harder to replace, she said.\n\nNika said becoming \"AI literate\" is now essential for product managers.\n\n\"Understand the unique intricacies that AI brings, understand how dependent we are on data,\" she said, describing how AI has become an expectation for the role.\n\nAspiring product managers should also understand \"what goes behind coding,\" like knowing what APIs are and how products are shipped.\n\nOther tech leaders and workers echo the same message.\n\nA vice president of product and growth for AI products at Dropbox told Business Insider last year that product managers should familiarize themselves with new AI tools, including vibe coding tools that enable non-coders to quickly prototype ideas.\n\nInstead of spending time writing documents, product managers can use AI tools to build lightweight prototypes to test ideas early, he said. This can help \"accelerate how they think about developing their taste, developing their craft, and understanding what makes sense in physical products,\" he added.\n\nA senior product manager at Microsoft told Business Insider in December that product managers will increasingly be expected to use AI to work faster. He said AI tools helped him draft work documents, summarize information, and generate suggestions for approaching product management problems.",
    "readingTime": 3,
    "keywords": [
      "product managers",
      "product management",
      "product manager",
      "aspiring product",
      "business insider",
      "tools",
      "experience",
      "role",
      "understand",
      "products"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-product-manager-career-advice-be-crab-skills-2026-1",
    "thumbnail_url": "https://i.insider.com/6964709304eda4732f2ededd?width=1200&format=jpeg",
    "created_at": "2026-01-12T06:22:39.081Z",
    "topic": "finance"
  },
  {
    "slug": "luxbitai-advances-autotrading-innovation-with-intelligent-usercontrolled-automation-designed-for-modern-financial",
    "title": "Luxbit.ai Advances Auto-Trading Innovation With Intelligent, User-Controlled Automation Designed for Modern Financial Markets",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/press-releases/luxbitai-advances-autotrading-innovation-with-intelligent-usercontrolled-automation-designed-for-modern-financial-markets-4440687",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/international_newspapers_108x81.jpg",
    "created_at": "2026-01-12T06:22:39.053Z",
    "topic": "finance"
  },
  {
    "slug": "oauth-21-dynamic-client-registration-for-aws-bedrockagentcore-gateway",
    "title": "OAuth 2.1 Dynamic Client Registration for AWS BedrockAgentCore Gateway",
    "description": "What this is A CloudFormation template implementing OAuth 2.1 Dynamic Client Registration (RFC 7591) for AWS BedrockAgentCore Gateway with Cognito. Repository: https://github.com/stache-ai/agentcor...",
    "fullText": "OAuth 2.1 Dynamic Client Registration for AWS BedrockAgentCore Gateway\n\n #5\n\n jtpenny\n\n announced in\n Announcements\n\n OAuth 2.1 Dynamic Client Registration for AWS BedrockAgentCore Gateway\n\n #5\n\n jtpenny\n\n Jan 12, 2026\n ·\n 0 comments\n\n Return to top\n\nDiscussion options\n\n Uh oh!\n\n There was an error while loading. Please reload this page.\n\n Quote reply\n\n jtpenny\n\n Maintainer\n\n -\n\n Beta\n Was this translation helpful?\n Give feedback.\n\n All reactions\n\n to join this conversation on GitHub.\n Already have an account?\n Sign in to comment",
    "readingTime": 1,
    "keywords": [
      "oauth dynamic",
      "dynamic client",
      "client registration",
      "aws bedrockagentcore",
      "bedrockagentcore gateway",
      "gateway jtpenny"
    ],
    "qualityScore": 0.65,
    "link": "https://github.com/orgs/stache-ai/discussions/5",
    "thumbnail_url": "https://opengraph.githubassets.com/745290be9c60132cdbcf42fda40bede16ef5a7ebc2e736dd8162fb0b9d1b7134/orgs/stache-ai/discussions/5",
    "created_at": "2026-01-12T01:00:54.141Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-asked-people-to-upload-their-medical-data-to-x-so-his-ai-company-could-learn-to-interpret-mris-and-ct-scans",
    "title": "Elon Musk asked people to upload their medical data to X so his AI company could learn to interpret MRIs and CT scans",
    "description": "Health care experts are worried about Grok’s potential to breach patient privacy.",
    "fullText": "In Elon Musk’s world, AI is the new MD. The X owner is encouraging users to upload their medical test results—such as CT and bone scans—to the platform so that Grok, X’s artificial intelligence chatbot, can learn how to interpret them efficiently.\n\nHe’s previously said this information will be used to train X’s artificial intelligence chatbot Grok on how to interpret them efficiently.\n\nEarlier this month, Elon Musk reposted a video on X of himself talking about uploading medical data to Grok, saying: “Try it!”\n\n“You can upload your X-rays or MRI images to Grok and it will give you a medical diagnosis,” Musk said in the video, which was uploaded in June. “I have seen cases where it’s actually better than what doctors tell you.\n\nIn 2024, Musk said medical images uploaded to Grok would be used to train the bot.\n\n“This is still early stage, but it is already quite accurate and will become extremely good,” Musk wrote on X. “Let us know where Grok gets it right or needs work.”\n\nMusk also claimed in his response Grok saved a man in Norway by diagnosing a problem his doctors failed to notice. The X owner was willing to upload his own medical information to his bot.\n\n“I did an MRI recently and submitted it to Grok,” Musk said in an episode of the Moonshots with Peter Diamandis podcast released on Tuesday. “None of the doctors nor Grok found anything.”\n\nMusk did not disclose in the podcast why he received an MRI. XAI, which owns X, told Fortune in a statement: “Legacy Media Lies.”\n\nGrok is facing some competition in the AI health space. This week OpenAI launched ChatGPT Health, an experience within the bot feature that allows users to securely connect medical records and wellness apps like MyFitnessPal and Apple Health. The company said it would not train the models using personal medical information.\n\nAI chatbots have become a ubiquitous source of medical information for people. OpenAI reported this week 40 million people seek health information from the model, 55% of which used to bot to look up or better understand symptoms.\n\nSo far, Grok’s ability to detect medical abnormalities have been mixed. The AI successfully analyzed blood test results and identified breast cancer, some users claimed. But it also grossly misinterpreted other pieces of information, according to physicians who responded to some of Musk’s about Grok’s ability to interpret medical information. In one instance, Grok mistook a “textbook case” of tuberculosis for a herniated disk or spinal stenosis. In another, the bot mistook a mammogram of a benign breast cyst for an image of testicles.\n\nA May 2025 study found that while all AI models have limitations in processing and predicting medical outcomes, Grok was the most effectively compared to Google’s Gemini and ChatGPT-4o when determining the presence of pathologies in 35,711 slices of brain MRI.\n\n“We know they have the technical capability,” Dr. Laura Heacock, associate professor at the New York University Langone Health Department of Radiology, wrote on X. “Whether or not they want to put in the time, data and [graphics processing units] to include medical imaging is up to them. For now, non-generative AI methods continue to outperform in medical imaging.”\n\nMusk’s lofty goal of training his AI to make medical diagnoses is also a risky one, experts said. While AI has increasingly been used as a means to make complicated science more accessible and create assistive technologies, teaching Grok to use data from a social media platform presents concerns about both Grok’s accuracy and user privacy.\n\nRyan Tarzy, CEO of health technology firm Avandra Imaging, said in an interview with Fast Company asking users to directly input data, rather than source it from secure databases with de-identified patient data, is Musk’s way of trying to accelerate Grok’s development. Also, the information comes from a limited sample of whoever is willing to upload their images and tests—meaning the AI is not gathering data from sources representative of the broader and more diverse medical landscape.\n\nMedical information shared on social media isn’t bound by the Health Insurance Portability and Accountability Act (HIPAA), the federal law that protects patients’ private information from being shared without their consent. That means there’s less control over where the information goes after a user chooses to share it.\n\n“This approach has myriad risks, including the accidental sharing of patient identities,” Tarzy said. “Personal health information is ‘burned in’ too many images, such as CT scans, and would inevitably be released in this plan.”\n\nThe privacy dangers Grok may present aren’t fully known because X may have privacy protections not known by the public, according to Matthew McCoy, assistant professor of medical ethics and health policy at the University of Pennsylvania. He said users share medical information at their own risk.\n\n“As an individual user, would I feel comfortable contributing health data?” he previously told the New York Times. “Absolutely not.”\n\nA version of this story originally published on Fortune.com on Nov. 20, 2024.\n\nOpenAI launches ChatGPT Health in a push to become a hub for personal health data\n\nOpenAI suggests ChatGPT play doctor as millions of Americans face spiking insurance costs: ‘In the U.S., ChatGPT has become an important ally’\n\nAs Utah gives the AI power to prescribe some drugs, physicians warn of patient risks\n\nThis story was originally featured on Fortune.com",
    "readingTime": 5,
    "keywords": [
      "x’s artificial",
      "grok’s ability",
      "artificial intelligence",
      "intelligence chatbot",
      "social media",
      "personal health",
      "medical imaging",
      "chatgpt health",
      "users",
      "grok"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/meta-ai/articles/elon-musk-asked-people-upload-183304951.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/pQXYwrJOBN7Ge9R7Qtho.w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/d68cafd2391ce9d9ebf581779a2475a0",
    "created_at": "2026-01-12T01:00:50.694Z",
    "topic": "tech"
  },
  {
    "slug": "anthropic-expands-into-healthcare-a-week-after-openai-launched-a-similar-product",
    "title": "Anthropic expands into healthcare a week after OpenAI launched a similar product",
    "description": "Anthropic launches Claude for Healthcare, expanding AI tools for clinicians, insurers, and patients.",
    "fullText": "Anthropic is rolling out a major expansion of its healthcare and life-sciences offerings, as AI companies race to embed large language models more deeply into regulated medical workflows.\n\nThe company on Sunday announced Claude for Healthcare, a product that allows healthcare providers, insurers, and consumers to use Claude for medical purposes through HIPAA-ready infrastructure.\n\nThe launch builds on Anthropic's earlier release of Claude for Life Sciences, which focused on research and drug discovery, and reflects the company's broader effort to position its AI models as practical tools for regulated industries.\n\nThe move also underscores intensifying competition in healthcare AI. OpenAI recently unveiled a rival product, and startups including Abridge and Sword Health have attracted multibillion-dollar valuations as investors pour money into AI tools for medicine.\n\nAnthropic said Claude for Healthcare is designed to reduce administrative work and help both clinicians and patients better understand medical information. The tools are powered by recent improvements to the company's flagship model, Claude Opus 4.5, which Anthropic says performs significantly better than earlier versions on simulated medical and scientific tasks while showing fewer factual errors.\n\nAs part of the healthcare expansion, Claude can now connect directly to several industry-standard databases. These include the Centers for Medicare & Medicaid Services Coverage Database, ICD-10 medical coding data, the National Provider Identifier Registry, and PubMed's biomedical research library. Anthropic said these connectors allow Claude to quickly surface relevant information, support prior authorization workflows, and help clinicians and administrators generate reports more efficiently.\n\nThe company is also introducing customizable \"Agent Skills,\" including sample tools for streamlining prior authorization requests and assisting developers in building applications using FHIR, the modern standard for exchanging healthcare data between systems.\n\nOn the consumer side, Anthropic is rolling out integrations that let US subscribers on its Pro and Max plans give Claude secure access to their personal health records. New connectors include HealthEx and Function Health, with Apple HealthKit and Android Health Connect integrations launching in beta via Claude's mobile apps. Anthropic said data accessed through these integrations isn't stored in Claude's memory or used to train its models.\n\nAnthropic is also expanding Claude's capabilities for life sciences customers, adding connectors to platforms such as Medidata, ClinicalTrials.gov, and bioRxiv. New agent skills support tasks like drafting FDA- and NIH-compliant clinical trial protocols or monitoring trial performance.\n\nHave a tip? Contact this reporter via email at ekim@businessinsider.com or Signal, Telegram, or WhatsApp at 650-942-3061. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "prior authorization",
      "anthropic",
      "healthcare",
      "medical",
      "tools",
      "models",
      "connectors",
      "integrations",
      "claude's",
      "claude"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropic-chases-openai-ai-heath-claude-2026-1",
    "thumbnail_url": "https://i.insider.com/69619581832e0ef1ead78b5d?width=1200&format=jpeg",
    "created_at": "2026-01-12T01:00:48.702Z",
    "topic": "finance"
  },
  {
    "slug": "this-ceo-laid-off-nearly-80-of-his-staff-because-they-refused-to-adopt-ai-fast-enough-2-years-later-he-says-hed-do-it",
    "title": "This CEO laid off nearly 80% of his staff because they refused to adopt AI fast enough. 2 years later, he says he’d do it again",
    "description": "“It was extremely difficult,” IgniteTech CEO Eric Vaughan tells Fortune. “But changing minds was harder than adding skills.”",
    "fullText": "Eric Vaughan, CEO of enterprise-software powerhouse IgniteTech, was unwavering as he reflected on the most radical decision of his decades-long career. In early 2023, convinced generative AI was an “existential” transformation, Vaughan looked at his team and saw a workforce not fully on board. His ultimate response: He ripped the company down to the studs, replacing nearly 80% of staff within a year, according to headcount figures reviewed by Fortune.\n\nOver the course of 2023 and into the first quarter of 2024, Vaughan told Fortune, IgniteTech replaced hundreds of employees, declining to disclose a specific number. “That was not our goal,” he told Fortune. “It was extremely difficult … But changing minds was harder than adding skills.” It was, by any measure, a brutal reckoning—but Vaughan insists it was necessary, and said he’d do it again.\n\nFor Vaughan, the writing on the wall was clear and dramatic.\n\n“In early 2023, we saw the light,” he told Fortune in an August 2025 interview, adding he believed every tech company was facing a crucial inflection point around adoption of artificial intelligence. “Now I’ve certainly morphed to believe that this is every company, and I mean that literally every company, is facing an existential threat by this transformation.”\n\nWhere others saw promise, Vaughan saw urgency—believing failing to get ahead on AI could doom even the most robust business. He called an all-hands meeting with his global remote team. Gone were the comfortable routines and quarterly goals. Instead, his message was direct: Everything would now revolve around AI. “We’re going to give a gift to each of you. And that gift is tremendous investment of time, tools, education, projects … to give you a new skill,” he explained. The company began reimbursing for AI tools and prompt-engineering classes, and even brought in outside experts to evangelize.\n\n“Every single Monday was called ‘AI Monday,’” Vaughan said, with his mandate for staff that they could work only on AI. “You couldn’t have customer calls; you couldn’t work on budgets; you had to only work on AI projects.” He said this happened across the board, not just for tech workers, but also for sales, marketing, and everybody else at IgniteTech. “That culture needed to be built. That was the key.”\n\nThis was a major investment, he added: 20% of payroll was dedicated to a mass-learning initiative, and it failed because of mass resistance, even sabotage. Belief, Vaughan discovered, is a hard thing to manufacture.",
    "readingTime": 3,
    "keywords": [
      "vaughan",
      "existential",
      "transformation",
      "team",
      "board",
      "staff",
      "adding",
      "facing",
      "gift",
      "investment"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/ceo-laid-off-nearly-80-185033733.html",
    "thumbnail_url": "https://s.yimg.com/os/en/fortune_175/cd2444a452625ba3d3dae5dbedfc0e6f",
    "created_at": "2026-01-12T01:00:47.582Z",
    "topic": "finance"
  },
  {
    "slug": "aigenerated-police-report-mistakenly-claims-officer-was-transformed-into-a-frog",
    "title": "AI-generated police report mistakenly claims officer was transformed into a frog",
    "description": "An artificial intelligence that writes police reports had some explaining to do after it claimed earlier this month that a Heber City officer had shape-shifted into a frog.",
    "fullText": "HEBER CITY, Utah — An artificial intelligence that writes police reports had some explaining to do earlier this month after it claimed a Heber City officer had shape-shifted into a frog.\n\nHowever, the truth behind that so-called magical transformation is simple.\n\n\"The body cam software and the AI report writing software picked up on the movie that was playing in the background, which happened to be 'The Princess and the Frog,'\" Sgt. Keel told FOX 13 News. “That’s when we learned the importance of correcting these AI-generated reports.”\n\nEarlier this month, the department began testing two pieces of AI software, Draft One and Code Four. Code Four was created by George Cheng and Dylan Nguyen, both 19 years old and MIT dropouts, kicked off earlier this year. The software generates police reports from body camera footage in hopes of reducing paperwork and allowing officers to be out in the field more.\n\nDraft One was the software used to create the Disney-inspired police report.\n\nTo see how Code Four works, FOX 13 News rode along with Keel for a demonstration as the department staged a mock traffic stop.\n\n\"Hi, I'm Rick with the Heber PD. The reason I'm stopping you today is for...\" Keel said during the demonstration.\n\nBack at the police department, the AI generated a report with timestamps from the mock traffic stop. The software works in both English and Spanish and can track tone and sentiment as people are talking.\n\nKeel says one of the major draws is that the software saves them time, as writing reports typically takes 1-2 hours.\n\n\"I'm saving myself about 6-8 hours weekly now,\" Keel said. \"I'm not the most tech-savvy person, so it's very user-friendly.\"\n\nCode Four costs about $30 per officer each month. Keel said the trial run for Code Four wraps up next month, but department officials say they plan to continue using the AI technology; it's just a matter of which system.",
    "readingTime": 2,
    "keywords": [
      "mock traffic",
      "traffic stop",
      "police reports",
      "code four",
      "software",
      "department",
      "earlier",
      "officer",
      "body",
      "demonstration"
    ],
    "qualityScore": 0.95,
    "link": "https://www.fox13now.com/news/local-news/summit-county/how-utah-police-departments-are-using-ai-to-keep-streets-safer",
    "thumbnail_url": "https://ewscripps.brightspotcdn.com/dims4/default/8d1b6a3/2147483647/strip/true/crop/889x467+0+17/resize/1200x630!/quality/90/?url=https%3A%2F%2Fcf.cdn.uplynk.com%2Fause1%2Fslices%2Fda8%2Fef205c0e5ea14d77944cbd6904335118%2Fda8302965ab54cc78dae2bb4a79545cc%2Fposter_56c3a4b773ba40d5b439e35c60cb6094.png",
    "created_at": "2026-01-11T18:16:38.532Z",
    "topic": "tech"
  },
  {
    "slug": "socialmcp-new-kind-of-social-network",
    "title": "Social-MCP: new kind of social network",
    "description": "Connect with people through your AI assistant. AI-powered matching, privacy-first connections.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://social-mcp.org/",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/e250c333-5d1a-49b5-a1c1-1105cf5d3ccc/id-preview-c6f400d4--483afd7e-8d29-411b-a881-3f4c00afce37.lovable.app-1768143647306.png",
    "created_at": "2026-01-11T18:16:37.516Z",
    "topic": "tech"
  },
  {
    "slug": "claude-code-orchestrator-parallel-ai-development-with-multiple-claude-sessions",
    "title": "Claude Code Orchestrator – Parallel AI Development with Multiple Claude Sessions",
    "description": "Contribute to reshashi/claude-orchestrator development by creating an account on GitHub.",
    "fullText": "reshashi\n\n /\n\n claude-orchestrator\n\n Public\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n reshashi/claude-orchestrator",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/reshashi/claude-orchestrator",
    "thumbnail_url": "https://opengraph.githubassets.com/80858496dd25da87cae9d53fae7d2ed1ca3b0b9a3a7c606d9eff823ebeb33d70/reshashi/claude-orchestrator",
    "created_at": "2026-01-11T18:16:36.348Z",
    "topic": "tech"
  },
  {
    "slug": "finally-you-can-have-a-little-friend-in-a-jar",
    "title": "Finally, You Can Have A Little Friend In A Jar",
    "description": "CES is a time for lots of new gaming tech. Like Razer's Project Ava, the little AI friend in a jar who hangs out on your desk. Or Project Motoko, a pair of headphones with cameras built into them so it can watch you play games and give you tips. It's weird. So Kurt and Lucy talk about it in this segment of Kurt & Lucy Gotcha Covered.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/finally-you-can-have-a-little-friend-in-a-jar/2300-6466639/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1862/18620770/4633243-gc_ces.jpg",
    "created_at": "2026-01-11T18:16:33.971Z",
    "topic": "gaming"
  },
  {
    "slug": "dangerous-and-alarming-google-removes-some-of-its-ai-summaries-after-users-health-put-at-risk",
    "title": "‘Dangerous and alarming’: Google removes some of its AI summaries after users’ health put at risk",
    "description": "Exclusive: Guardian investigation finds AI Overviews provided inaccurate and false information when queried over blood tests\nGoogle has removed some of its artificial intelligence health summaries after a Guardian investigation found people were being put at risk of harm by false and misleading information.\nThe company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are “helpful” and “reliable”.\n Continue reading...",
    "fullText": "Exclusive: Guardian investigation finds AI Overviews provided inaccurate and false information when queried over blood tests\n\nGoogle has removed some of its artificial intelligence health summaries after a Guardian investigation found people were being put at risk of harm by false and misleading information.\n\nThe company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are “helpful” and “reliable”.\n\nBut some of the summaries, which appear at the top of search results, served up inaccurate health information, putting users at risk of harm.\n\nIn one case that experts described as “dangerous” and “alarming”, Google provided bogus information about crucial liver function tests that could leave people with serious liver disease wrongly thinking they were healthy.\n\nTyping “what is the normal range for liver blood tests” served up masses of numbers, little context and no accounting for nationality, sex, ethnicity or age of patients, the Guardian found.\n\nWhat Google’s AI Overviews said was normal may vary drastically from what was actually considered normal, experts said. The summaries could lead to seriously ill patients wrongly thinking they had a normal test result, and not bother to attend follow-up healthcare meetings.\n\nAfter the investigation, the company has removed AI Overviews for the search terms “what is the normal range for liver blood tests” and “what is the normal range for liver function tests”.\n\nA Google spokesperson said: “We do not comment on individual removals within Search. In cases where AI Overviews miss some context, we work to make broad improvements, and we also take action under our policies where appropriate.”\n\nVanessa Hebditch, the director of communications and policy at the British Liver Trust, a liver health charity, said: “This is excellent news, and we’re pleased to see the removal of the Google AI Overviews in these instances.\n\n“However, if the question is asked in a different way, a potentially misleading AI Overview may still be given and we remain concerned other AI‑produced health information can be inaccurate and confusing.”\n\nThe Guardian found that typing slight variations of the original queries into Google, such as “lft reference range” or “lft test reference range”, prompted AI Overviews. That was a big worry, Hebditch said.\n\n“A liver function test or LFT is a collection of different blood tests. Understanding the results and what to do next is complex and involves a lot more than comparing a set of numbers.\n\n“But the AI Overviews present a list of tests in bold, making it very easy for readers to miss that these numbers might not even be the right ones for their test.\n\n“In addition, the AI Overviews fail to warn that someone can get normal results for these tests when they have serious liver disease and need further medical care. This false reassurance could be very harmful.”\n\nGoogle, which has a 91% share of the global search engine market, said it was reviewing the new examples provided to it by the Guardian.\n\nHebditch said: “Our bigger concern with all this is that it is nit-picking a single search result and Google can just shut off the AI Overviews for that but it’s not tackling the bigger issue of AI Overviews for health.”\n\nSue Farrington, the chair of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals, welcomed the removal of the summaries but said she still had concerns.\n\n“This is a good result but it is only the very first step in what is needed to maintain trust in Google’s health-related search results. There are still too many examples out there of Google AI Overviews giving people inaccurate health information.”\n\nMillions of adults worldwide already struggle to access trusted health information, Farrington said. “That’s why it is so important that Google signposts people to robust, researched health information and offers of care from trusted health organisations.”\n\nAI Overviews still pop up for other examples the Guardian originally highlighted to Google. They include summaries of information about cancer and mental health that experts described as “completely wrong” and “really dangerous”.\n\nAsked why these AI Overviews had not also been removed, Google said they linked to well-known and reputable sources, and informed people when it was important to seek out expert advice.\n\nA spokesperson said: “Our internal team of clinicians reviewed what’s been shared with us and found that in many instances, the information was not inaccurate and was also supported by high quality websites.”\n\nVictor Tangermann, a senior editor at the technology website Futurism, said the results of the Guardian’s investigation showed Google had work to do “to ensure that its AI tool isn’t dispensing dangerous health misinformation”.\n\nIf you have something to share about this story, you can contact Andrew using one of the following methods.\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don’t already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nIf you don’t need a high level of security or confidentiality you can email andrew.gregory@theguardian.com\n\nSecureDrop and other secure methods\n\nIf you can safely use the tor network without being observed or monitored you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.\n\nGoogle said AI Overviews only show up on queries where it has high confidence in the quality of the responses. The company constantly measures and reviews the quality of its summaries across many different categories of information, it added.\n\nIn an article for Search Engine Journal, senior writer Matt Southern said: “AI Overviews appear above ranked results. When the topic is health, errors carry more weight.”",
    "readingTime": 5,
    "keywords": [
      "ai overviews",
      "guardian app",
      "guardian investigation",
      "reference range",
      "search engine",
      "blood tests",
      "liver function",
      "serious liver",
      "liver disease",
      "normal range"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/11/google-ai-overviews-health-guardian-investigation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f8d00c974ded83894d8c39a75fab0c5442c8bb9f/869_0_6827_5464/master/6827.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=28f5a8e9b3185cdbde1b56cd35795197",
    "created_at": "2026-01-11T12:21:58.917Z",
    "topic": "tech"
  },
  {
    "slug": "meshii-opensource-ai-tool-to-generate-3d-meshes-for-game-development",
    "title": "Meshii – Open-source AI tool to generate 3D meshes for game development",
    "description": "Contribute to sciences44/meshii development by creating an account on GitHub.",
    "fullText": "sciences44\n\n /\n\n meshii\n\n Public\n\n License\n\n View license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sciences44/meshii",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sciences44/meshii",
    "thumbnail_url": "https://opengraph.githubassets.com/a017fb12eba4eb5074a61478992e920ab2ea2c01f3084b604846dd7bc3f66c3e/sciences44/meshii",
    "created_at": "2026-01-11T12:21:58.672Z",
    "topic": "tech"
  },
  {
    "slug": "tiny-coder-ai-coding-agent-in-300-loc-writing-itself",
    "title": "Tiny Coder – AI coding agent in ~300 LOC writing itself",
    "description": "Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies. - xrip/tinycode",
    "fullText": "xrip\n\n /\n\n tinycode\n\n Public\n\n Single-file AI coding assistant (~350 LOC). Claude API with tool calling. TypeScript + Bun. Zero dependencies.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n xrip/tinycode",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/xrip/tinycode",
    "thumbnail_url": "https://opengraph.githubassets.com/07e51ae8c3cabfafdf20fdcf525646b8f004627e8c671e3c9185240ef4e3b4fd/xrip/tinycode",
    "created_at": "2026-01-11T12:21:58.611Z",
    "topic": "tech"
  },
  {
    "slug": "npmagentskills-bundle-ai-agent-documentation-with-npm-packages",
    "title": "NPM-agentskills – Bundle AI agent documentation with NPM packages",
    "description": "Framework-agnostic skill discovery and export for AI coding agents - onmax/npm-agentskills",
    "fullText": "onmax\n\n /\n\n npm-agentskills\n\n Public\n\n Framework-agnostic skill discovery and export for AI coding agents\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n onmax/npm-agentskills",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/onmax/npm-agentskills",
    "thumbnail_url": "https://opengraph.githubassets.com/25ea09a060a3707ff9ae03007862bc0ef3c0da7b02d7c59d84dc472b47aefb04/onmax/npm-agentskills",
    "created_at": "2026-01-11T12:21:56.673Z",
    "topic": "tech"
  },
  {
    "slug": "snowflakes-ceo-says-people-often-fall-into-2-camps-when-it-comes-to-ai-and-both-are-wrong",
    "title": "Snowflake's CEO says people often fall into 2 camps when it comes to AI — and both are wrong",
    "description": "Snowflake CEO Sridhar Ramaswamy says that people either overhype the impact of AI, or assume doomsday scenarios.",
    "fullText": "AI often sparks strong reactions, with people predicting either a near-term utopia — or the end of the world as we know it.\n\nSnowflake CEO Sridhar Ramaswamy told Business Insider that individuals on the hype end of the spectrum tend to jump quickly to promises of unlimited prosperity. The CEO said that the other extreme includes those who believe AI will lead to a doomsday scenario.\n\nRamaswamy said that this sort of thinking is \"very human,\" but that neither of those scenarios is \"all that likely.\"\n\n\"The biggest misconception would be that of thinking about AI as an all or nothing,\" Ramaswamy said.\n\nThe real value of AI, he said, is likely to be nuanced and show up in specific use cases. Ramaswamy added that his advice to customers is to \"be very incremental\" with AI adoption.\n\nWhile he's still focused on long-term thinking, he added that he no longer accepts multi-year, fixed roadmaps for plans for the company because the technology is changing so quickly.\n\n\"I want them to tell me which direction they are headed, but very much be in this mode of iterating, because this is a world of rapid change,\" Ramaswamy said.\n\nRather than view AI as a tool that will bring sweeping changes overnight, the CEO said it needs to be embraced as a shift in how people work, and one that requires progress \"bit by bit.\" He added that clear frameworks are necessary to determine where AI efforts matter the most.\n\nFor example, a cloud data platform company like Snowflake focuses on building and running software, and Ramaswamy said it needs to \"nail\" how it creates, deploys, sells, and installs that software. That means it needs to deeply integrate AI in software development to stay competitive.\n\nWhile Ramaswamy said he wants his employees to utilize AI tools daily, his end goal is for the company to write software more efficiently than the rest of the industry. That requires adapting business models in specific areas, rather than treating AI as a blanket rewrite of everything, he said.\n\nHe said that when dealing with technology like AI, which \"ostensibly claims to change everything,\" it's essential to have a clear view on where change needs to be implemented and where the impact will be \"existential.\"\n\n\"I worry a lot about making sure that we are state-of-the-art, especially in the critical areas with regards to how we utilize AI,\" Ramaswamy said.",
    "readingTime": 3,
    "keywords": [
      "needs",
      "software",
      "ramaswamy",
      "quickly",
      "technology",
      "rather",
      "view",
      "utilize",
      "everything",
      "snowflake"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/snowflake-ceo-explains-what-people-get-wrong-about-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6961316264858d02d218110d?width=1200&format=jpeg",
    "created_at": "2026-01-11T12:21:56.315Z",
    "topic": "finance"
  },
  {
    "slug": "china-ai-leaders-warn-of-widening-gap-with-us-after-1b-ipo-week",
    "title": "China AI Leaders Warn of Widening Gap With US After $1B IPO Week",
    "description": "Some of China’s most prominent figures in generative artificial intelligence warned that the Asian nation is unlikely to eclipse the US in the global AI race anytime soon.",
    "fullText": "MarketsBy Bloomberg NewsSaveSome of China’s most prominent figures in generative artificial intelligence warned that the Asian nation is unlikely to eclipse the US in the global AI race anytime soon.Justin Lin, head of Alibaba Group Holding Ltd.’s Qwen series of open-source models, put at less than 20% the chances of any Chinese company leapfrogging the likes of OpenAI and Anthropic with fundamental breakthroughs over the next three to five years. His caution was shared by peers at Tencent Holdings Ltd., and at Zhipu AI, which this week helped lead Chinese large-language model makers in tapping the public market.",
    "readingTime": 1,
    "keywords": [
      "chinese"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-10/china-ai-leaders-warn-of-widening-gap-with-us-after-1b-ipo-week",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ikMht3vNIoow/v1/1200x800.jpg",
    "created_at": "2026-01-11T06:18:45.521Z",
    "topic": "finance"
  },
  {
    "slug": "global-ai-race-shows-asia-leading-as-stocks-start-2026-with-bang",
    "title": "Global AI Race Shows Asia Leading as Stocks Start 2026 With Bang",
    "description": "Asia’s technology stocks began 2026 on a tear, with investors betting their momentum and outperformance against US peers will last through the year.",
    "fullText": "MarketsBy Winnie HsuSaveAsia’s technology stocks began 2026 on a tear, with investors betting their momentum and outperformance against US peers will last through the year.Strategists at Goldman Sachs Group Inc. are overweight and expect further gains driven partly by surging artificial intelligence-related demand and reasonable valuations. Citigroup Inc. says global long-term investors are accumulating Asia’s tech stocks given their importance in the semiconductor supply chain and the potential for earnings upside.",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "investors"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-11/global-ai-race-shows-asia-leading-as-stocks-start-2026-with-bang",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i_UKXleF8Uq4/v0/1200x800.jpg",
    "created_at": "2026-01-11T06:18:44.724Z",
    "topic": "finance"
  },
  {
    "slug": "dreamforge-ai-dream-journal-that-turns-dreams-into-art",
    "title": "DreamForge – AI dream journal that turns dreams into art",
    "description": "Record your dreams and transform them into stunning AI-generated artwork. Discover hidden themes, emotions, and symbols.",
    "fullText": "Record your dreams, uncover hidden meanings, and transform them into stunning artwork.\n\nFree to start. No credit card required.\n\nThree simple steps to unlock your dream world\n\nWake up and capture your dream before it fades away.\n\nLet AI uncover the deeper meaning behind your dreams.\n\nGenerate stunning artwork from your dream narrative.\n\nEverything you need to explore your dream world\n\nCapture your dreams the moment you wake up. Add mood, clarity, and tags to build your personal dream journal.\n\nLet AI uncover the hidden themes, emotions, and symbolic meanings woven into your dreams.\n\nTransform your dreams into stunning, unique artwork that brings your visions to life.\n\nShare your dream artwork with the world. Post to social media or showcase in our community gallery.\n\nDiscover dream artwork shared by dreamers worldwide. Get inspired by the community.\n\nYour dreams are private by default. Share only what you choose to share.\n\nJoin thousands of dreamers who are discovering the hidden meanings in their nightly adventures.",
    "readingTime": 1,
    "keywords": [
      "hidden meanings",
      "stunning artwork",
      "dream artwork",
      "let ai",
      "dreams",
      "uncover",
      "transform",
      "wake",
      "capture",
      "community"
    ],
    "qualityScore": 0.85,
    "link": "https://dream-forge.me",
    "thumbnail_url": "https://dream-forge.me/og-image.jpg",
    "created_at": "2026-01-11T06:18:40.620Z",
    "topic": "tech"
  },
  {
    "slug": "cortex-android-notification-manager-with-ondevice-llm",
    "title": "Cortex – Android Notification manager with on-device LLM",
    "description": "AI notification manager. Summarize, automate & declutter your alerts.",
    "fullText": "Tired of notification overload? Cortex is the intelligent manager you’ve been waiting for. It uses on-device and cloud AI to read, understand, and consolidate everything into one persistent “Glance” — so you stay informed without being interrupted.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🧠 DUAL - ENGINE AI\n\n► Local AI (100% Private, Offline)\nRuns entirely on-device after a one-time ~210 MB model download. Handles summarization and importance tagging (Critical/High/Medium/Low). Nothing ever leaves your phone.\n\n► Cloud AI (Premium)\nOptional upgrade for deeper context (“is this a bill?”), semantic filtering, and natural-language auto-replies.\n\nYou choose per-rule which engine powers what. Your data, your control.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n👀 THE GLANCE\n\nNo more avalanche. One clean, expandable summary replaces dozens of pings:\n\n● Sam: Dinner @ 9pm\n● Oracle: Invoice #2241 due tomorrow · $487.50\n● Ring: Package delivered at front door\n\nTap to expand, swipe to clear, or let it stay until you’re ready.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n⚡ MAGIC RULE BUILDER\n\nJust chat in plain English:\n\n\"Silence work apps on weekends unless my boss says URGENT\"\n\n\"Let family through at work only if it’s actually important\"\n\nCortex instantly builds the logic and suggests smarter alternatives. Prefer precision? Use the block-based editor for granular control.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🛠️ POWER AUTOMATION\n\nCONDITIONS\n● App\n● Time & schedule\n● Keywords & Regex\n● Screen/ringer state\n● AI importance\n● Semantic meaning\n● OTP/2FA detection\n\nACTIONS\n● Add to Glance\n● Batch release (every 30 min or at 5 PM)\n● AI or custom auto-reply\n● Dismiss\n● Copy OTP\n● TTS readout\n● Custom sound/vibration\n● Webhook\n\nBuilt-in vibration patterns: Heartbeat, SOS, Double-tap, etc.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n📊 ANALYTICS & HISTORY\n\n● Searchable log of every notification (blocked ones optional)\n● Hourly/daily volume charts\n● Top distracting apps\n● Importance breakdown\n● Rule performance\n\nSee exactly how much focus you’ve reclaimed.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🔗 WEBHOOKS & INTEGRATIONS\n\nSend any notification as JSON to Home Assistant, IFTTT, Zapier, Node-RED, or your server.\n\n● Flash lights on security alerts\n● Log deliveries\n● Push 2FA to desktop\n● etc.\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n🛡️ PRIVACY YOU CAN TRUST\n\n● Local AI = zero data leaves device\n● Cloud AI = encrypted in transit, deleted immediately after processing\n● AI only used when a rule needs it\n● Biometric app lock\n● No ads\n● Works perfectly offline\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n📱 REQUIREMENTS\n\n● Notification Listener permission\n● Battery optimization exception (for reliable background work)\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n💌 EARLY ACCESS & FEEDBACK\n\nCortex is still in early stages. Your feedback is extremely important to us.\n\nIf you believe anything is missing (like a specific condition or action you need) or if you find a bug, please reach out:\n\n● Email: cortex@moyelauncher.xyz\n● Community: Discord / Telegram (Links inside app)\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nStop drowning. Start focusing.\n\nCortex makes your phone work for you — not the other way around.\n\nDownload now and experience the calm.\n\nAI Notification Manager • Focus App • Notification Summary • Auto Reply • Digital Detox • Notification History • Smart Automation",
    "readingTime": 3,
    "keywords": [
      "cloud ai",
      "importance",
      "notification",
      "manager",
      "you’ve",
      "on-device",
      "engine",
      "offline",
      "download",
      "phone"
    ],
    "qualityScore": 1,
    "link": "https://play.google.com/store/apps/details?id=xyz.moyelauncher.cortex&hl=en_US",
    "thumbnail_url": "https://play-lh.googleusercontent.com/szV9xz9LyjZ3JSTtXtHMh9psjhRFyfwasjczpHA07jsIPadG-CbD7nwvZmw_rzhHk9-ybEaE51D4bRjeb8vS",
    "created_at": "2026-01-11T06:18:39.302Z",
    "topic": "tech"
  },
  {
    "slug": "worktrunk-a-cli-tool-to-manage-multiple-worktrees-in-git-repositories",
    "title": "Worktrunk – A CLI tool to manage multiple worktrees in Git repositories",
    "description": "Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows - max-sixty/worktrunk",
    "fullText": "max-sixty\n\n /\n\n worktrunk\n\n Public\n\n Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows\n\n worktrunk.dev\n\n License\n\n View license\n\n 972\n stars\n\n 36\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n max-sixty/worktrunk",
    "readingTime": 1,
    "keywords": [
      "worktrunk",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/max-sixty/worktrunk",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1078528927/778b4aa3-ed9b-40e3-8717-7bf157b3e232",
    "created_at": "2026-01-11T06:18:36.887Z",
    "topic": "tech"
  },
  {
    "slug": "jupyter-agents-training-llms-to-reason-with-notebooks",
    "title": "Jupyter Agents: training LLMs to reason with notebooks",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can execute code directly inside a Jupyter notebook and use this environment to solve data analysis and data science tasks. Think of it like Cursor, but living natively inside your data science workflow.\nWe built a demo of this vision with Qwen-3 Coder, currently one of the strongest coding models. This is a follow-up to our earlier work on jupyter-agent (v1).\n\nWhile large models are starting to show useful behavior, the key question is how we can continue improving them. To this end, we focus on strengthening smaller models to perform well on agentic data science tasks as they currently struggle to compete with the large models.\n\nThe goal of this project is to build a pipeline to first generate high-quality training data, then fine-tune an existing small model, and finally evaluate whether the model's performance improves on relevant benchmarks.\n\nLet’s begin with the last step: selecting a strong benchmark for evaluating models on data science tasks.\n\nIn order to understand if we are making progress towards better data science agents we need a benchmark to measure such capabilities. Last year, in partnership with Adyen, we introduced the DABStep benchmark: a way to evaluate data science agents on realistic tasks. The setup is simple: provide the LLM with datasets and ask it to answer non-trivial data questions.\n\nThis benchmark remains challenging for today’s LLMs — e.g. the best out-of-the-box model is Claude 4 Sonnet which reaches not even 20% accuracy on the hard tasks.\nYou can explore the live leaderboard here.\n\nNow that we identified a good benchmark we can try to climb it! We set out to build a dataset for fine-tuning such that even a small data agent model could perform well on DABStep.\n\nOur first choice was Qwen3-4B-Thinking-2507: extremely small (fast to iterate with, easy to run), yet strong enough to act in agentic scenarios.\n\nNot great — but a promising starting point, since it left a lot of room for improvement. Let's see how we can improve it!\n\nA core aspect of agents that sets it apart from a pure chat model is the scaffolding built around the model to steer its behaviour. The evaluation script in DABStep for example uses smolagents to execute code. Smolagents comes with predefined behaviors, prompting structures, and expected formats.\n\nWe also studied the Qwen-Agent codebase, where the authors tailoring scaffolding to the model. This makes sense: Claude Code, for example, works shockingly well with Claude Sonnet because their scaffolding is aligned.\n\nSo, we restructured our scaffolding:\n\n👉 Check it out here: utils.py.\n\nResults: accuracy jumped from 44.4% → 59.7% (easy split). 🚀\n\nWith simplified scaffolding in place, we focused on fine-tuning Qwen3-4B for data science agentic tasks.\n\nThe recipe to improve a model on a certain task or behaviour is to train it on data that reflects the tasks as closely as possible. A natural starting point is to look at real Jupyter Notebooks and find notebooks that align closely with the task that we plan to tackle, namely data analysis.\n\nKaggle notebooks offer a wealth of high quality data analysis notebooks and are made available by Kaggle:\n\nNow that we have good results with a base model it's time to build a dataset that will help us improve it even further. We designed a multi-stage pipeline using Datatrove to clean and prepare Kaggle notebooks at scale.\n\nWe started with ~2TB of Kaggle notebooks and reduced it to ~250GB reusing our work from the BigCode project. As part of the StarCoder2 training data processing the notebooks (without output cells) were already deduplicated.\nMost Kaggle notebooks are small variations or near-identical copies, so this step was essential.\nKey insight: ~90% of raw notebooks are duplicates, which would have skewed training if left unfiltered.\n\nMost Kaggle notebooks reference external datasets via Kaggle metadata. To make sure the code inside notebooks could actually run, we built a pipeline that automatically fetched these linked datasets. This step was crucial, since many notebooks would otherwise be incomplete or non-executable.\n\nUsing the kagglehub package, we downloaded thousands of datasets — about 5TB in total. To keep things manageable and relevant:\n\nWe scored notebooks based on educational quality using Qwen3-32B. We saw that using the whole notebook was not optimal, as many contained trivial or broken code. Our educational scoring approach is detailed in edu_scoring.py.\n\nTL;DR: We assigned each notebook a score from 1–5 based on clarity, completeness, and educational value, and kept only those above a chosen threshold. This filtering removed about 70% of the notebooks.\n\nThis is similar to the insight from the BeyondWeb paper, which showed that using high-quality data is better for synthetic data generation — a step we relied on for QA (Question-Answer) generation.\nThis helped the model learn from “high quality” notebooks instead of noisy ones.\n\nWe excluded notebooks about training LLMs or unrelated to data analysis.\nWe also removed notebooks that didn’t actually use datasets through an automated LLM-based filtering process using Qwen3-32B. The implementation of filtering can be found in extract_packages_and_files.py.\n\nTL;DR: We prompted Qwen3-32B to identify and remove notebooks that either (1) had nothing to do with data analysis, or (2) didn’t actually use datasets. This step removed about 20% of the notebooks.\n\nThis ensured we trained only on relevant data science tasks.\n\nUsing the cleaned notebooks, we generated question–answer pairs using Qwen3-32B. The questions and answer are grounded in the real notebook traces so the QA pairs are based on real code execution results.\nPrompt design: we asked the LLM to produce natural questions that could realistically be asked of the dataset, then validated whether the notebook provided a correct answer.\n\nChallenge: We had to try many prompts to get higher-difficulty questions because LLMs tended to generate trivial ones like \"what is the size of the dataset\".\nInsight: We broke this into two steps because LLMs tended to hallucinate answers:\n\nThe complete prompting strategy and implementation is available in generate_qa.py.\n\nFinally we want to generate clean code execution traces since even the original notebooks after processing are often open ended and verbose with lots of irrelevant parts. However, we want our Jupyter Agent to get to the result efficiently. To generate cleaner notebook traces for training we generated traces synthetically based on the original notebooks.\nWe have prompted Qwen-3-Coder-480B model to generate a jupyter notebook code to answer the question from the previously generated synthetic QA pair. \nTraces captured step-by-step code execution, including intermediate outputs, which are crucial for agent training.\n\nWe used E2B for our agent to solve the synthetic QA pairs, which required fetching Kaggle datasets so the code could actually run via E2B.\n\nChallenge 1: Many datasets were unavailable.\nTrick: Since LLMs are strong at code and have a decent world model, we prompted them to act as a code interpreter when the dataset was missing.\n\nChallenge 2: Qwen3-Coder-480B-A35B model does not support thinking mode - how can we extract code commentary? By default it often outputs just a brief comment followed by several steps of code execution. However, we'd like some reasoning or comments between every cell. \nTrick: When switching from Qwen3-32B to Qwen3-Coder-480B-A35B we noticed that often output message content was empty. This turns out to be a previously known quirk of Qwen3-Coder models in which when using tool calling the model would not return an empty assistant response. We enforce some text commentary through tooling by passing 'comment' as a required field in the code execution tool call. This way when non-reasoning model is used for code cell generation it will by default output some description of its actions from 1st POV, emulating the thinking traces structure.\n\nNote: the generated final answer in the notebook may vary from the answer specified in the QA pair. This is caused by the fact that the agent model could use data preprocessing methods and steps different from the original Kaggle notebook and the synthetic question would not usually specify them. This discrepancy is normal and lays the foundation for a new exciting research direction of how language models tend to treat data analysis and whether they do it differently from humans. For full transparency we keep both LLM-generated final answer and original answer from the real Kaggle notebook as a signal of model's performance. We encourage the community to try different dataset mixes to see how they can push performance even further.\n\nWe truncated overly long outputs and filtered out trivial traces to prevent content length issues and keep only high-quality traces.\nWe kept non-trivial, multi-turn traces aligned with DABStep-style tasks.\nThe resulting Jupyter Agent Dataset became the foundation for SFT on Qwen3-4B models with 51k synthetic notebooks and almost 0.2B tokens.\n\nWith this dataset in hand, the natural next step is to see whether it actually helps our model become a stronger data science agent. Let’s move on to the training pipeline and evaluate the impact!\n\nWith the curated dataset ready, we turned to the key question: does this data actually help the model get better at solving data analysis tasks?\nTo find out, we set up a simple fine-tuning pipeline and ran experiments to measure the impact of training on our synthetic notebooks.\n\nSome training steps turned out to be particularly interesting and gave us useful insights:\n\nOur complete training implementation, including hyperparameter configurations and template adaptations, is available in our finetuning directory in our repo.\n\nFirst, we generated our final dataset using Qwen3-Coder-480B-A35B which contains high quality code and short reasoning-like traces. Afterwards, we started our training and we have experimented with various configurations like PEFT/adapters vs. full-parameter tuning, learning rate, number of epochs, adding noise and others. We found out, that full-parameter fine-tuning allows the model to learn and replicate the Qwen3-Coder-480B-A35B behavior response quality better with shorter supporting commentary fitting more to the data analysis task without unnecessary long reasoning.\n\nWe have done a small ablation study on the impact of no. training epochs:\n\nWe observe that it is beneficial to have a bit more epochs than usual for SFT with lower learning rate and higher neftune noise (7). Finally, we compare our trained models with implemented scaffolding to define the pure impact of our training dataset. In summary, we can see up to 36%/22% boost on DABStep easy score compared with base/scaffolded model:\n\nWe can also see, that the hard score can increase too even though our dataset is focused on easier questions:\n\nFrom figures above one can notice a noticeable impact of both new scaffolding and tuning on our synthetic notebooks. This makes Qwen-4B (with our pipeline + scaffolding) a state-of-the-art small-model agent on DABStep.\n\nIn practice, the model can now solve a wide range of realistic Kaggle-style data analysis tasks with consistent execution.\nIt’s not yet strong enough for the hardest queries, but we’ve shown that even small models can become powerful agents when paired with the right data and scaffolding.\n\nThese results demonstrate that even small models can become powerful data science agents with the right training approach. Ready to try it yourself? We've made everything openly available so you can experiment with our fine-tuned models and dataset.\n\nWe openly release best-performing checkpoints of tuned Qwen3-4B-Instruct-2507 and Qwen3-4B-Thinking-2507 together with the training dataset, which you can try out and experiment with:\n\nYou can load Jupyter Agent Dataset in just a couple of lines using the following code:\n\nYou can also use sourced Kaggle datasets directly with E2B code execution using the following code:\n\nYou use tuned Jupyter Agent Qwen-based models following the Qwen documentation code:\n\nFor Thinking model you can decode both thinking response and content using the next code:\n\nMaybe this will lead to… Jupyter-Agent 3. 😉\n\nWe hope that our findings will inspire others to continue progress in developing more powerful notebook coding agents and we're excited to see what the community builds next. Dive into our jupyter-agent dataset on the 🤗 Hub and explore the codebase at https://github.com/huggingface/jupyter-agent to start your own experiments on agents for jupyter notebooks.\n\n·\n Sign up or\n log in to comment",
    "readingTime": 11,
    "keywords": [
      "llms tended",
      "learning rate",
      "model's performance",
      "kaggle datasets",
      "kaggle notebooks",
      "kaggle notebook",
      "science agents",
      "execute code",
      "code execution",
      "science tasks"
    ],
    "qualityScore": 1,
    "link": "https://huggingface.co/blog/jupyter-agent-2",
    "thumbnail_url": "https://huggingface.co/blog/assets/jupyter-agent-2/thumbnail.png",
    "created_at": "2026-01-11T06:18:36.563Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": "China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the ​sector, the country's leading artificial intelligence researchers said.",
    "fullText": "BEIJING, Jan 10 (Reuters) - China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the ​sector, the country's leading artificial intelligence researchers said on Saturday.\n\nChina's so-called 'AI tiger' startups MiniMax and Zhipu ‌AI had strong debuts on the Hong Kong Stock Exchange this week, reflecting growing confidence in the sector as Beijing fast-tracks AI and ‌chip listings to bolster domestic alternatives to advanced U.S. technology.\n\nYao Shunyu, a former senior researcher at ChatGPT maker OpenAI (OPAI.PVT) who was named technology giant Tencent's chief AI scientist in December, said there was a high likelihood of a Chinese firm becoming the world's leading AI company in the next three to five years but said the lack of ⁠advanced chipmaking machines was the main ‌technical hurdle.\n\n\"Currently, we have a significant advantage in electricity and infrastructure. The main bottlenecks are production capacity, including lithography machines, and the software ecosystem,\" Yao said at an AI ‍conference in Beijing.\n\nChina has completed a working prototype of an extreme-ultraviolet lithography machine potentially capable of producing cutting-edge semiconductor chips that rival the West's, Reuters reported last month. However, the machine has not yet produced working chips and may not do ​so until 2030, people with knowledge of the matter told Reuters.\n\nYao and other Chinese industry ‌leaders at the Beijing conference on Saturday also acknowledged that the U.S. maintains an advantage in computing power due to its hefty investments in infrastructure.\n\n\"The U.S. computer infrastructure is likely one to two orders of magnitude larger than ours. But I see that whether it's OpenAI or other platforms, they're investing heavily in next-generation research,\" said Lin Junyang, technical lead for Alibaba's flagship Qwen large language model.\n\n\"We, on the other hand, are relatively strapped for ⁠cash; delivery alone likely consumes the majority of our computer infrastructure,\" ​Lin said during a panel discussion at the AGI-Next Frontier Summit ​held by the Beijing Key Laboratory of Foundational Models at Tsinghua University.\n\nLin said China's limited resources have spurred its researchers to be innovative, particularly through algorithm-hardware co-design, which enables AI ‍firms to run large models ⁠on smaller, inexpensive hardware.",
    "readingTime": 2,
    "keywords": [
      "advanced chipmaking",
      "computer infrastructure",
      "lack",
      "sector",
      "leading",
      "researchers",
      "technology",
      "chinese",
      "machines",
      "technical"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/china-closing-us-technology-lead-154328103.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/3136525d7c4c038136c2dd7340321e54",
    "created_at": "2026-01-11T06:18:31.117Z",
    "topic": "finance"
  },
  {
    "slug": "ai-wont-kill-open-source-it-will-amplify-it",
    "title": "AI Won't Kill Open Source – It Will Amplify It",
    "description": "Why the doomsayers are wrong: npm, PyPI, and NuGet downloads are exploding",
    "fullText": "Earlier this week, Adam Wathan, the creator of Tailwind CSS, dropped a bombshell about how AI has impacted his company and its employees:\n\nthe reality is that 75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business. And every second I spend trying to do fun free things for the community like this is a second I’m not spending trying to turn the business around and make sure the people who are still here are getting their paychecks every month.\n\nThe reaction was swift and predictable. Hot takes flooded in declaring the death of open source, the end of OSS sustainability, and the AI apocalypse that would render libraries and frameworks obsolete. Geoffrey Huntley captured the prevailing narrative perfectly1:\n\n“AI can generate code, bypassing the need to deal with open-source woes… I’ve found myself using less open source these days… This shift challenges the role of open-source ecosystems.”\n\nI had a tweet about the Tailwind situation go viral and there were dozens of quote tweets and comments echoing the very same. “AI eats open source” is easy to find in abundance online.\n\nHere’s the problem: everyone is getting this perfectly backwards.\n\nAI isn’t killing open source. It’s amplifying it to unprecedented levels. The Tailwind situation isn’t about declining OSS adoption - it’s about a business model that was working great in a world where learning curves were high and documentation was the bottleneck. That world is gone, and the revenue model built on top of it is collapsing. But the underlying Tailwind library? It’s thriving.\n\nLet me show you why the doomsayers are wrong, backed by actual data from our own experience with Akka.NET and broader ecosystem trends that tell a very different story.\n\nThis is Part 1 of a two-part series. This post covers why AI is accelerating open source adoption, not killing it. Part 2 examines which business models thrive and which collapse in the AI era - and what Tailwind’s situation teaches us about adapting. \n\nI’ve been maintaining Akka.NET, a complex distributed systems framework, for over a decade. If AI was going to kill any open source project, it should have be ours. Actor model? Message-passing? Concurrency? Distributed systems? This is exactly the kind of “complex stuff” that AI should supposedly generate on the fly, right?\n\nWe’re not an outlier. Let me show you three very different frameworks - all thriving:\n\nTailwind CSS - The framework at the center of this controversy:\n\nTailwind more than doubled its downloads in 2025. The framework that supposedly proves AI is killing open source had its best year ever - by a massive margin.\n\nNServiceBus - Enterprise messaging framework (15+ years old, commercial licensing):\n\nNServiceBus is exactly the kind of enterprise infrastructure Geoffrey Huntley expects AI to replace. And it’s growing at 35%+ annually - the same rate as before AI coding tools existed. And it’s been commercially licensed for years - surely someone who wanted this type of functionality would just fire up Claude Code to eliminate it, right?\n\nAccording to Sonatype’s State of the Software Supply Chain 20242 report:\n\nIf AI was replacing open source libraries, why are package downloads exploding at unprecedented rates? Why are dependency counts climbing? Why is every major package registry showing record growth?\n\nThe answer is simple: AI is discovering and adopting open source libraries faster than humans ever could.\n\nHere’s what the AI doomsayers fundamentally misunderstand about how Large Language Models work: they’re trained to find the shortest path to a working solution.\n\nWhen you ask Claude or GPT-5 to build a distributed system, what do you think is the shorter path?\n\nOption A: Generate thousands of lines of custom actor model implementation, cluster management, network protocols, failure detectors, and state replication logic - all from scratch, all needing testing, all potentially buggy.\n\nOption B: dotnet add package Akka and configure the proven, tested, battle-hardened framework that’s in the training data with millions of examples.\n\nThe LLM isn’t stupid. It’s going to pick Option B every single time, unless you explicitly tell it not to - and even then it might fight you3.\n\nThis is why the “AI will generate everything custom” narrative falls apart on contact with reality. Yes, AI can generate custom components. But developers don’t want custom CSS frameworks - they want to ship. They want the thing that makes them money shipped yesterday. Using established libraries is how you get there expeditiously.\n\nHere’s where it gets really interesting. Established open source projects have a massive, compounding advantage in the AI era: years of training data.\n\nThink about what’s in those training sets:\n\nEvery time someone asks “how do I build a distributed system in .NET?” the training data screams “AKKA.NET” across thousands of documents. The LLM doesn’t need to think creatively. It’s pattern matching against an enormous corpus of successful implementations.\nThis creates a virtuous cycle:\n\nPopular projects have more training data → LLMs recommend them more → More people use them → More training data gets created → The cycle continues.\n\nThe rich get richer, and in this case, that’s actually a good thing for software quality.\n\nNow compare that to generating a custom solution. The LLM has… what? Generic distributed systems theory? Sure. But where are the battle-tested examples? Where are the debugging sessions? Where are the “here’s what went wrong in production and how we fixed it” stories?\n\nThey don’t exist. Because you’re asking the AI to invent something new.\n\nRemember when adopting a new library meant:\n\nFor a human developer, that’s a full day or two of investment before you’re productive. The mental math was always: “Is learning this library worth the time investment vs. building something custom that I already understand?”\n\nAI just arbitraged that entire calculation out of existence.\n\nWhen I ask Claude to “implement an Akka.NET cluster with cluster sharding and split-brain resolution,” it doesn’t need to read the docs. It doesn’t need the tutorial. It usually outputs working code with proper configuration in seconds. The learning curve is effectively zero.\n\nThis fundamentally changes the adoption math. The barrier to using any established library is now “can the AI generate correct code for it?” If yes, adoption becomes frictionless.\n\nGuess which libraries have the most examples for AI to learn from? The established ones. The popular ones. The ones with network effects and community momentum.\n\nAI can generate impressive things from scratch. People have used agentic loops to build entire programming languages, compilers, and complex systems - all generated by AI with minimal human intervention. These are genuine technical achievements that prove AI can build sophisticated software.\n\nBut here’s the question nobody’s asking: would you run your production systems on them?\n\nThe answer depends entirely on blast radius - what happens when things go wrong4.\n\nThe libraries that AI can safely replace are the ones with low blast radius. If your AI-generated UI component looks a little funny or renders slightly different than expected, nobody dies. You fix it and move on. The cost of failure is measured in minutes of debugging.\n\nBut if your AI-generated embedded operating system core dumps constantly? Someone might actually die. If your AI-generated authentication library has a subtle flaw? You get breached. If your AI-generated distributed consensus algorithm has an edge case bug? You lose data across your entire cluster.\n\nProduction systems don’t run on “technically works” - they run on battle-hardened, community-tested, security-audited infrastructure that’s been proven across thousands of deployments over years. That’s React. Linux. PostgreSQL. Akka.NET. NServiceBus. The boring, reliable stuff that’s growing 35-126% annually.\n\nThere’s another dimension here: institutionalized experience.\n\nA venerable codebase like Akka.NET doesn’t just contain code - it contains decades of accumulated wisdom across millions of deployments and tens of thousands of applications. All running on different hardware, serving different use cases, developed by different people. Every bug fix is a production war story. Every edge case handler is a lesson learned the hard way. Every configuration option exists because someone, somewhere, needed it in production.\n\nLLMs can synthesize code. They can pattern-match against training data. But they are no substitute for thousands of person-years of lived experience encoded into a codebase. That wisdom doesn’t exist in the training data - it exists in the accumulated decisions of maintainers who’ve seen every way a distributed system can fail.\n\nWhen you dotnet add package Akka, you’re not just getting code. You’re getting the institutional memory of a decade of production deployments. AI can’t generate that. It can only recommend the libraries that already have it.\n\nThe libraries actually at risk from AI generation are the ones with low blast radius - simple utilities, UI components, basic tooling where failure is cheap and recoverable. The critical infrastructure where failure is catastrophic? That’s not going anywhere. It’s accelerating.\n\n“Sure,” I hear you saying, “AI won’t replace frameworks, but what about all the smaller libraries? What about utilities and helpers?”\n\nFair question. Let’s think through the actual use cases.\n\nDeveloper needs a date formatting function. AI can generate it. But… so could a library. And the library version is tested. And documented. And handles edge cases. And gets security updates.\n\nWhat’s actually happening in practice? AI is finding and using existing utility libraries faster than humans would have. date-fns, lodash, NodaTime - these libraries aren’t declining, they’re exploding in adoption.5\n\nScenario 2: Custom Business Logic\n\nDeveloper needs a specific component for their application. AI generates it custom. Perfect! This is exactly what should be custom. This was never the domain of reusable open source anyway.\n\nScenario 3: Complex, Critical Systems\n\nDeveloper needs authentication, database access, distributed coordination, payment processing. AI could generate custom implementations. But would you ship them to production? Would you stake your business on AI-generated cryptography? On custom distributed consensus?\n\nOf course not. You use Postgres, Entity Framework, Akka.NET, OpenSSL - the proven solutions with years of production hardening.\n\nHere’s what the Tailwind situation actually tells us: AI is devastating businesses that sell what LLMs can generate.\n\nThe numbers tell the whole story:\n\nThe most successful year in the framework’s history coincided with the business collapse. This isn’t a contradiction - it’s the clearest illustration of what AI actually disrupts.\n\nTailwind’s commercial business is Tailwind Plus - premium UI components, templates, and blocks. The free documentation served as the primary sales funnel: developers would visit the docs to learn Tailwind, discover the premium components, and purchase them.\n\nAI broke this model in two devastating ways.\n\nFirst: The sales funnel dried up.\n\nRemember learning curve arbitrage? When developers use AI to generate Tailwind code, they don’t need to visit the documentation. Adam noted that docs traffic is down about 40% from early 2023 - despite Tailwind being more popular than ever. Fewer eyeballs on the docs means fewer people discovering the premium products exist.\n\nSecond: The product itself became AI-generatable.\n\nAI undercut Tailwind’s business model. Selling those components was about eliminating friction for users - buy a pre-made pricing table instead of building one yourself. But AI found an even cheaper way to eliminate that friction: generate the component on demand, for free.\n\nWhen a developer asks an AI for a “responsive pricing table with Tailwind,” the LLM isn’t going to say “log into your Tailwind Plus account and download the pricing component.” It’s going to generate one from scratch. That’s the shortest path.\n\nUI components and templates are exactly the kind of low-blast-radius output that AI handles well. If the generated component looks slightly different than a premium template, nobody cares. You tweak it and move on.\n\nTailwind’s business model put them directly in competition with their own framework’s AI-assisted usage. The better AI gets at generating Tailwind code, the less reason anyone has to buy pre-built components.\n\nThe framework thrives. The component business struggles. Same company, opposite trajectories - because one benefits from AI adoption and the other is displaced by it.\n\nAI isn’t killing open source. It’s creating the golden age of open source consumption.\n\nMore developers can adopt more libraries faster than ever before. The friction that kept people building custom solutions has evaporated. The learning curves that protected mediocre alternatives have disappeared.\n\nWhat we’re seeing is consolidation around quality, acceleration of adoption, and the destruction of business models that were built on selling what AI can now generate.\n\nTailwind CSS isn’t dying. Tailwind Plus might be dying - time will tell to see how they pivot. But the CSS framework itself is more popular than ever. The component products built on top of it? Those are being outcompeted by the LLMs recommending the framework.\n\nIf you’re an open source maintainer, this is your moment. If you’ve built something genuinely valuable - critical infrastructure with high blast radius, strong community, clear use cases - you’re about to see adoption curves that would have taken a decade compress into a few years.\n\nThe future of open source isn’t bleak. It’s brighter than it’s ever been. But the businesses built on top of them? That’s a different story - and it’s what we’ll dig into in Part 2.\n\nThis is Part 1 of a two-part series. Part 2 examines which open source business models thrive and which collapse in the AI era. The same AI wave that disrupted Tailwind’s business certainly didn’t hurt ours - our support subscriptions grew 19% in 2025, and AI-driven adoption likely contributed. Part 2 examines what makes some OSS business models resilient while others struggle. \n\nWhat’s your experience been? Are you seeing AI tools increase or decrease your open source usage? Hit me up on Twitter/X - I’m curious to hear how this is playing out across different ecosystems.\n\nGeoff wrote this all the way back in June 2025, well before this Tailwind situation. Ahead of his time. ↩\n\nA 2025 report would be preferable, but alas there isn’t one yet. ↩\n\nReward hacking is a property of frontier models you’ll encounter in all sorts of interesting ways. My personal favorite is when Claude disables failing tests in order to turn the status checks green. ↩\n\nI also suspect this is why the “learn AI now or you’re going to fall behind crew” ship way more “build with AI” courses than they do polished software products. ↩\n\n2024→2025 YoY growth: date-fns +52.6% (1.05B→1.60B), NodaTime +42.6% (171M→244M), lodash +36.2% (2.67B→3.64B). ↩\n\nDid you know that Phobos can automatically instrument your Akka.NET applications with OpenTelemetry?",
    "readingTime": 13,
    "keywords": [
      "package akka",
      "developer needs",
      "llm isn’t",
      "two-part series",
      "dotnet add",
      "sales funnel",
      "tailwind situation",
      "tailwind’s business",
      "shortest path",
      "pricing table"
    ],
    "qualityScore": 1,
    "link": "https://petabridge.com/blog/ai-wont-kill-open-source/",
    "thumbnail_url": "https://hcti.io/v1/image/133ae5fdb357269cefb4ca0c4b35583207c3cbba0985e4351cd559e6c1a1f3d8",
    "created_at": "2026-01-11T01:03:39.633Z",
    "topic": "tech"
  },
  {
    "slug": "sakana-ai-agent-wins-atcoder-heuristic-contest-first-ai-to-place-first",
    "title": "Sakana AI Agent Wins AtCoder Heuristic Contest (First AI to Place First)",
    "description": "Sakana AI Agent Wins AtCoder Heuristic Contest (First AI to Place 1st)",
    "fullText": "Sakana AI’s “ALE-Agent” achieved a historic milestone by securing 1st place in the AtCoder Heuristic Contest 058, outperforming 804 human participants. To contextualize the difficulty of these optimization challenges, an OpenAI agent previously secured 2nd place in the AHC world tournament last August. This victory marks the first known instance of an AI agent winning a major optimization programming contest in real-time. The result demonstrates that by utilizing inference-time scaling with multiple frontier models, AI agents can now match or exceed the performance of top human experts in complex tasks requiring extended reasoning.\n\nDuring the 4-hour contest, our agent autonomously discovered a novel algorithm that outperformed the problem setters’ intended solution. While the problem setters’ anticipated a standard approach combining constructive heuristics and simulated annealing (SA), our ALE-Agent independently derived a “virtual power” heuristic and a sophisticated SA strategy with diverse neighborhood search operations, allowing it to escape local optima more effectively than human competitors.\n\nOperating at a total cost of approximately $1,300, the agent engaged in parallel code generation and iterative analysis, proving that AI is now capable of the original scientific discovery and trial-and-error required for high-level problem solving.\n\nFor the detailed information, including the logs and analysis output by ALE-Agent during the contest, see: https://sakanaai.github.io/fishylene-ahc058/ and our earlier NeurIPS’25 paper.\n\nThe AtCoder Heuristic Contest (AHC) is a series of programming competitions focused on optimization problems related to real-world industrial challenges, such as logistics optimization and factory production scheduling. These contests are characterized by approximately 1,000 programmers including experts active in various industrial sectors. Participants tackle a single, complex coding challenge, with contest durations ranging from four hours to two weeks.\n\nAHC has garnered significant global attention. In August 2025, a world championship featuring top-tier players was held, where an AI agent from OpenAI participated and won 2nd place. Sakana AI has also co-developed ALE-Bench, a benchmark platform based on AHC, in collaboration with AtCoder Inc. Furthermore, under special permission, our AI agent called ALE-Agent has been continuously participating in AHCs in real-time.\n\nAHC058, held on December 14, 2025, was conducted over a 4-hour competition window. The problem involved a setting where participants could produce machines with hierarchical relationships, such as multiple types of “apple-producing machines” and “machines that build those machines.” The objective was to construct an efficient production planning algorithm by determining which types and hierarchies of machines to upgrade and in what specific order.\n\nWhile the setting may seem humorous at first glance, these hierarchical production dependencies mirror real-world supply chains, food webs, and manufacturing processes, making it a scientifically interesting problem setup. For further details on the problem, please refer to the contest’s problem statement.\n\nALE-Agent began making submissions two hours after the contest started and immediately leapt to 1st place in the provisional standings.\n\nIn the middle of the contest, ALE-Agent was in a fierce dead heat with yosupo, the eventual 2nd-place finisher. ALE-Agent regained 1st place approximately two and a half hours into the contest and maintained the lead until the end to secure the victory.\n\nIn AHC058, the solution expected by the problem author was an approach that used algorithms like Greedy methods or Beam Search to determine a global strategic plan, followed by Simulated Annealing (SA) to refine the plan’s finer details.\n\nALE-Agent’s answer followed the same basic flow as a human: “construction by Greedy → refinement by SA.” However, it was a quintessential “AI-style” solution that maximized the AI’s strengths: numerous implementations and exhaustive trial and error. Analysis of the final program revealed the following characteristics:\n\nAnalyzing the process through which ALE-Agent generated its response revealed that it implemented the solution while deepening its understanding of the problem’s characteristics. (Logs can be viewed on this page).\n\nThe latest version of ALE-Agent is equipped with a mechanism to repeat trial and error by generating multiple programs simultaneously, summarizing those results to generate insights, and utilizing them for subsequent code generation. Looking at the insights generated by ALE-Agent, we can see it examining the problem based on experience; it mentioned the compound interest effect in connection with investment knowledge, devised high-speed algorithms using mathematics from an early stage, and discussed the nature of the search space, noting that initial strategies cause significant differences.\n\nWe received comments regarding ALE-Agent’s performance and approach from two experts familiar with the optimization field and AHC.\n\nFrom Hiroomi Nochide (AtCoder handle: itigo):\n\nActually, before the contest started, I thought this problem would be difficult for LLMs. This is because solving this problem with a Greedy method requires experimental insight that LLMs typically struggle with, and I thought a high score would be impossible without this human-centric consideration. However, when the results came out, I was stunned to see fishylene win.\n\nChecking the logs, it tried a vast number of patterns with promising directions and discovered a clever simulated annealing method that was not anticipated at the time the problem was created. I am impressed, thinking, ‘How did it find such a method?’ (In the logs, the parts requiring the experimental insight I initially expected did not appear, and given that humans still excelled in the Greedy portion, I believe human accuracy in consideration is still superior. However,) the overwhelming number of trial-and-error steps combined with LLM reasoning is an advantage humans do not have. While I feel fishylene is a formidable rival, I believe this technology will be a tremendous weapon for humanity.\n\n(Note: fishylene is ALE-Agent’s AtCoder account name)\n\nHiroomi Nochide authored the problem for AHC058. He is one of the world’s top players (24th in AHC world rankings) and a professional in this field at ALGO ARTIS CORPORATION.\n\nFrom Yoichi Iwata (AtCoder handle: wata):\n\nThis problem required optimizing investment plans for multiple series of production machines, where the high-level choice of which series to select as ‘final investment targets’ and ‘intermediate investment targets’ was essentially the core issue. With simple local improvement methods that only slightly change the investment target at each turn, it is difficult to switch this global strategy midway, often leading to poor local optima.\n\nThe expected solution from the author’s side was a two-stage approach: first explore a wide range of global investment plan candidates using a lightweight solver, and then spend time optimizing the promising ones. In contrast, the solutions from ALE-Agent and the runner-up, yosupo, were based on local search but introduced ‘Large Neighborhoods’ that change a huge portion of the investment plan at once to escape local optima. In particular, ALE-Agent utilized a diversified Greedy method to reconstruct large parts of the plan, which seems to have led to its performance advantage.\n\nHistorically, ALE-Agent has tended to choose solutions within the author’s expected range, yet its high implementation and optimization power allowed it to reach the top ranks among many participants using similar methods, especially in short-duration contests. This time, it was very impressive to see it go one step further and reach a solution that exceeded the author’s expectations.\n\nYoichi Iwata oversees AHC at AtCoder. He has an outstanding track record in this field, including winning the 2010 TopCoder Open. His scores in pre-contest test plays sometimes exceed the top participant scores, and he ensures the high quality of AHC problems.\n\nALE-Agent is an agent that performs algorithm discovery by utilizing multiple LLMs to create solutions in parallel, selecting the best ones, and reasoning further based on the results of trial and error. As such, it requires a high volume of LLM calls. The resources utilized during the 4-hour contest were as follows:\n\nThis result is significant as it demonstrates that even for multi-hour tasks, by scaling inference costs and running a properly designed AI agent, AI can reach or surpass the performance of top human experts.\n\nIdentifying which specific elements of ALE-Agent’s design contributed most to this dramatic result remains an important research task for the future. Our current analysis suggests that in addition to scaling LLM calls and injecting domain knowledge, a “self-learning mechanism,” which extracts insights from trial-and-error trajectory and reflects them in the next improvement cycle, played an important role.\n\nAs highlighted in evaluation reports such as those from METR (Model Evaluation and Threat Research), the latest AI models are beginning to show high proficiency in tasks requiring several hours of human effort. Our result follows this trend but is unique in showing that an AI agent with appropriate mechanisms and inference scaling can rival top human experts.\n\nHowever, at this point, AI does not always rival or surpass top humans. The table below shows ALE-Agent’s past performance. While ALE-Agent has often ranked highly in previous AHCs, AHC058 marks its first victory. Additionally, its calculated virtual rating is 2592, which corresponds to 66th place among active users.\n\nAVisualization of ALE-Agent’s past AHC performance and Rating. The graph shows the contribution of performance values from each contest to the overall rating. https://atcoder-graphs.vercel.app/#contributorGraph\n\nLooking ahead, we aim to increase stability to ensure consistently high performance across similar tasks and to evolve our agents to rival top experts in longer-term tasks lasting several days or more. To achieve this, we will focus on balancing efficient human-like thinking with trial and error (moving away from purely heavy LLM call reliance) and acquiring more advanced autonomous management capabilities.\n\nIn real-world problem-solving, the process where humans interpret, generalize, and refine the unexpected discoveries presented by AI is highly effective. As noted in our report on the ICFP Programming Contest 2025, Sakana AI positions AI not as a replacement for humans, but as a partner that expands human exploration capabilities. Measuring achievements by AI alone, as we did here, is vital for understanding the current strengths and weaknesses of AI as a partner, and we believe this result represents a significant milestone in that journey.\n\nFinally, we would like to express our deep gratitude to AtCoder Inc. for their continuous cooperation and to ALGO ARTIS CORPORATION for hosting this contest.\n\nSakana AI will continue to explore new possibilities for intelligence and the practical application of AI agents in the real world.\n\nSakana AI is looking for experienced software engineers to lead the productization of platforms that solve complex real-world problems and accelerate AI-driven discovery, including projects like ALE-Agent. We are also looking for interns interested in the further development and industrial application of AI agents. Join our team and help us turn cutting-edge AI agent technology into practical value.\n\nDetails and Application: https://sakana.ai/careers/",
    "readingTime": 9,
    "keywords": [
      "algo artis",
      "artis corporation",
      "atcoder handle",
      "greedy method",
      "atcoder heuristic",
      "code generation",
      "experimental insight",
      "heuristic contest",
      "simulated annealing",
      "contest sakana"
    ],
    "qualityScore": 1,
    "link": "https://sakana.ai/ahc058/",
    "thumbnail_url": "https://sakana.ai/assets/home/sakana_rect.png",
    "created_at": "2026-01-11T01:03:39.295Z",
    "topic": "tech"
  },
  {
    "slug": "employees-are-using-ai",
    "title": "Employees Are Using AI",
    "description": "The case for a compliance gateway between healthcare teams and AI tools. In most healthcare organizations, AI adoption didn't begin with a strategy document — it began organically with individuals hearing about how AI could help them do their jobs better.",
    "fullText": "In most healthcare organizations, AI adoption didn't begin with a strategy document or a formal approval process.\n\nIt began organically with individuals hearing about how AI could help them do their jobs better, easier. Who doesn't want that? So, they start using AI tools to summarize notes, draft communications, interpret documents, or explore ideas faster. Often with good intentions. Often without visibility.\n\nWhether an organization has formally approved AI usage or not, the reality is the same: AI is already in the workflow.\n\nThe real question is no longer if employees are using AI.\n\nIt's whether that usage is intentional, governed, and defensible.\n\nMany organizations respond to AI risk in one of two ways:\n\nNeither approach reflects how work actually gets done.\n\nWhen tools are banned outright, usage tends to move underground.\n\nWhen policies exist without enforcement or structure, teams are left guessing where the boundaries really are.\n\nIn both cases, leadership loses visibility causing compliance risk to go up.\n\nThe most common AI risk in healthcare isn't malicious behavior or reckless intent.\n\nIt's the absence of a clear boundary between sensitive work and external AI systems.\n\nIn regulated environments, invisible usage is often riskier than visible, governed usage.\n\nA compliance gateway is not about surveillance.\n\nIt's not about monitoring individuals or second-guessing intent.\n\nA compliance gateway is an organizational control layer that sits between employees and AI systems, making AI usage:\n\nInstead of relying solely on policy documents or trust, organizations provide a clear, approved path for AI usage that aligns with regulatory obligations.\n\nOne of the most persistent myths about AI governance is that it slows teams down.\n\nThey spend less time guessing, self-censoring, or avoiding AI altogether.\n\nGovernance, when done well, becomes an enabler.\n\nHealthcare compliance is rarely about eliminating risk entirely.\n\nIt's about managing risk intentionally.\n\nOrganizations that struggle most with AI compliance are often not the ones using AI aggressively. They're the ones who can't see how it's being used at all.\n\nVisibility enables informed decision making, targeted controls, and credible explanations when questions arise.\n\nWithout visibility, even well-meaning organizations are forced to rely on hope.\n\nAs AI becomes embedded in everyday healthcare workflows, governance will increasingly shift:\n\nThe organizations that adapt successfully won't be the ones that stopped AI usage.\n\nThey'll be the ones that made it explicit, governed, and defensible.\n\nEmployees are already bringing AI into healthcare work because the incentives are real and the productivity gains are tangible.\n\nThe choice facing organizations isn't whether to allow AI.\n\nIt's whether AI usage will happen outside of governance or within it.\n\nGuardian Health is being built as a governed AI workbench for healthcare teams: designed to sit between employees and AI systems, making data handling decisions explicit, auditable, and defensible. Our focus is less on controlling behavior, and more on providing clear, compliant pathways for real-world AI usage.",
    "readingTime": 3,
    "keywords": [
      "compliance gateway",
      "without visibility",
      "ai it's",
      "usage",
      "organizations",
      "healthcare",
      "risk",
      "employees",
      "governed",
      "governance"
    ],
    "qualityScore": 1,
    "link": "https://guardianhealth.dev/blog/employees-already-using-ai/",
    "thumbnail_url": "https://guardianhealth.dev/blog/employees-using-ai.jpg",
    "created_at": "2026-01-11T01:03:39.277Z",
    "topic": "health"
  },
  {
    "slug": "vllm-or-llamacpp-choosing-the-right-llm-inference-engine-for-your-use-case",
    "title": "VLLM or llama.cpp: Choosing the right LLM inference engine for your use case",
    "description": "See how vLLM’s throughput and latency compare to llama.cpp's and discover which tool is right for your specific deployment needs on enterprise-grade hardware",
    "fullText": "Following our previous analysis of Ollama and vLLM, we are extending our comparison to another giant in the inference space: llama.cpp. While vLLM is known for its Python-based, throughput-oriented architecture, llama.cpp is renowned for its lightweight C++ core, which promises exceptional efficiency.\n\nllama.cpp is a standout in the LLM ecosystem for its efficiency and portability. Written in pure C/C++ with no external dependencies, it offers plain-vanilla inference that can run on a wide range of hardware, from powerful servers and GPUs to edge devices like laptops and phones. Its CPU-first design philosophy and support for various quantization methods (from 2-bit to 8-bit integers) make it exceptionally versatile.\n\nA key feature of llama.cpp is its use of the GGUF (GPT-Generated Unified Format), a custom file format specifically designed for rapid loading and memory-mapped execution. This allows models to be loaded almost instantly and contributes significantly to the engine's fast startup times and low resource footprint, making it a favorite among developers running models on consumer-grade hardware.\n\nIn this post, we put these two high-performance engines to the test in a head-to-head benchmark to help you choose the right tool for your specific deployment needs on enterprise-grade hardware.\n\nTo ensure a true \"apples-to-apples\" comparison, we created a controlled testing environment on Red Hat OpenShift, using full-precision models for both engines and using the latest generation of NVIDIA hardware.\n\nWe used a fixed dataset of prompt-response pairs to ensure that every request sent to both servers was identical. This eliminates variables from synthetic data generation and allows for a direct comparison of the engines themselves. Each test at a given concurrency level was run for 300 seconds.\n\nFor TTFT and ITL, we used P99 (99th percentile) as the measure. P99 means that 99% of requests had a TTFT/ITL at or below this value, making it a good measure of \"worst-case\" responsiveness.\n\nThis comparison evaluates the latest upstream versions of vLLM and llama.cpp. Recognizing that the default setting for llama.cpp is not intended for high-concurrency scenarios, we tuned its settings for our environment.\n\nTo ensure llama.cpp fully leveraged the available GPU hardware, we used the -ngl 99 flag to offload all possible model layers to the NVIDIA H200 GPU. Additionally, we used the --threads and --threads-batch flags to increase the number of threads available for prompt and batch processing. We empirically determined that a value of 64 for both was the stable limit for our llama.cpp deployment.\n\nThe difference in how the two engines handle a growing user load was immediate and stark. vLLM's throughput scales impressively as concurrency increases, demonstrating its ability to efficiently manage a high volume of requests. In contrast, llama.cpp's throughput remains almost perfectly flat, indicating it processes a steady but fixed amount of work, regardless of the incoming load. See Figure 1.\n\nThe bar chart for Output Tokens per Second (Figure 2) reinforces this finding. While llama.cpp shows comparable performance at a concurrency of 1, vLLM's total generative power quickly surpasses it and continues to grow with the load.\n\nConclusion: For multi-user applications where maximizing throughput and scalability is the goal, vLLM is the clear winner. At peak load, vLLM delivered more than 35 times the request throughput (RPS) and more than 44 times the total output tokens per second (TPS) compared to llama.cpp. llama.cpp's architecture is suited for single-user or low-concurrency tasks.\n\nThe latency metrics reveal the different architectural priorities of the two engines.\n\nThis benchmark comparison on the NVIDIA H200 GPU highlights that vLLM and llama.cpp are both excellent tools with different strengths.\n\nFor performance-critical applications on modern, enterprise-grade GPUs, vLLM demonstrates a clear advantage in our tests. It is a scalability powerhouse, leading in every performance category we measured—throughput, responsiveness, and single-request generation speed. For teams building scalable, high-performance AI applications, this data shows that vLLM is a powerful and robust foundation.",
    "readingTime": 4,
    "keywords": [
      "tokens per",
      "per second",
      "llama.cpp",
      "vllm",
      "comparison",
      "hardware",
      "engines",
      "load",
      "throughput",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://developers.redhat.com/articles/2025/09/30/vllm-or-llamacpp-choosing-right-llm-inference-engine-your-use-case",
    "thumbnail_url": "https://developers.redhat.com/sites/default/files/styles/share/public/Inference-vLLM-1920x1080.png?itok=x_9NzXpT",
    "created_at": "2026-01-10T18:16:46.067Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": "China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling",
    "fullText": "BEIJING, Jan 10 (Reuters) - China can narrow its technological gap with the U.S. driven by growing risk-taking and innovation, though the lack of advanced chipmaking tools is hobbling the ​sector, the country's leading artificial intelligence researchers said on Saturday.\n\nChina's so-called 'AI tiger' startups MiniMax and Zhipu ‌AI had strong debuts on the Hong Kong Stock Exchange this week, reflecting growing confidence in the sector as Beijing fast-tracks AI and ‌chip listings to bolster domestic alternatives to advanced U.S. technology.\n\nYao Shunyu, a former senior researcher at ChatGPT maker OpenAI who was named technology giant Tencent's chief AI scientist in December, said there was a high likelihood of a Chinese firm becoming the world's leading AI company in the next three to five years but said the lack of ⁠advanced chipmaking machines was the main ‌technical hurdle.\n\n\"Currently, we have a significant advantage in electricity and infrastructure. The main bottlenecks are production capacity, including lithography machines, and the software ecosystem,\" Yao said at an AI ‍conference in Beijing.\n\nChina has completed a working prototype of an extreme-ultraviolet lithography machine potentially capable of producing cutting-edge semiconductor chips that rival the West's, Reuters reported last month. However, the machine has not yet produced working chips and may not do ​so until 2030, people with knowledge of the matter told Reuters.\n\nYao and other Chinese industry ‌leaders at the Beijing conference on Saturday also acknowledged that the U.S. maintains an advantage in computing power due to its hefty investments in infrastructure.\n\n\"The U.S. computer infrastructure is likely one to two orders of magnitude larger than ours. But I see that whether it's OpenAI or other platforms, they're investing heavily in next-generation research,\" said Lin Junyang, technical lead for Alibaba's flagship Qwen large language model.\n\n\"We, on the other hand, are relatively strapped for ⁠cash; delivery alone likely consumes the majority of our computer infrastructure,\" ​Lin said during a panel discussion at the AGI-Next Frontier Summit ​held by the Beijing Key Laboratory of Foundational Models at Tsinghua University.\n\nLin said China's limited resources have spurred its researchers to be innovative, particularly through algorithm-hardware co-design, which enables AI ‍firms to run large models ⁠on smaller, inexpensive hardware.\n\nTang Jie, founder of Zhipu AI which raised HK$4.35 billion in its IPO, also highlighted the willingness of younger Chinese AI entrepreneurs to embrace high-risk ventures - a trait traditionally associated ⁠with Silicon Valley - as a positive development.\n\n\"I think if we can improve this environment, allowing more time for these risk-taking, intelligent individuals ‌to engage in innovative endeavours ... this is something our government and the country can help improve,\" ‌said Tang.",
    "readingTime": 3,
    "keywords": [
      "advanced chipmaking",
      "computer infrastructure",
      "risk-taking",
      "lack",
      "sector",
      "leading",
      "researchers",
      "technology",
      "openai",
      "machines"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/articles/china-closing-us-technology-lead-154328876.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/7E4877C512D62422FB949E157C6EA70D6D8CDDCD414E4D435CECA30C2F84F1A9/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fs.yimg.com%2Fos%2Fen%2Freuters.com%2F610ee45b7b291cec24a64256a4290ef7",
    "created_at": "2026-01-10T18:16:37.410Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-says-uk-wants-to-suppress-free-speech-as-x-faces-possible-ban",
    "title": "Elon Musk says UK wants to suppress free speech as X faces possible ban",
    "description": "Ministers warn platform could be blocked after Grok AI used to create sexual images without consent\nElon Musk has accused the UK government of wanting to suppress free speech after ministers threatened fines and a possible ban for his social media site X after its AI tool, Grok, was used to make sexual images of women and children without their consent.\nThe billionaire claimed Grok was the most downloaded app on the UK App Store on Friday night after ministers threatened to take action unless the function to create sexually harassing images was removed.\n Continue reading...",
    "fullText": "Ministers warn platform could be blocked after Grok AI used to create sexual images without consent\n\nElon Musk has accused the UK government of wanting to suppress free speech after ministers threatened fines and a possible ban for his social media site X after its AI tool, Grok, was used to make sexual images of women and children without their consent.\n\nThe billionaire claimed Grok was the most downloaded app on the UK App Store on Friday night after ministers threatened to take action unless the function to create sexually harassing images was removed.\n\nResponding to threats of a ban from the government, Musk wrote: “They just want to suppress free speech”.\n\nThousands of women have faced abuse from users of the AI tool which was first used to digitally strip fully clothed photographs into images showing them wearing micro bikinis, and then used for extreme image manipulation.\n\nPictures of teenage girls and children were altered to show them wearing swimwear, leading experts to say some of the content could be categorised as child sexual abuse material.\n\nSome users began to demand to see bruising on the bodies of the women, and for blood to be added to the images. Women were shown tied up, gagged and shot.\n\nThe technology secretary, Liz Kendall, said on Friday that ministers were looking seriously at the possibility of access to X being barred in the UK.\n\nShe said she expected Ofcom, which said this week that it was seeking urgent answers from the platform, to announce action within “days not weeks”.\n\n“X needs to get a grip and get this material down,” she said. “And I would remind them that in the Online Safety Act, there are backstop powers to block access to services if they refuse to comply with the law for people in the UK. And if Ofcom decides to use those powers, they would have the full backing of the government.”\n\nThe UK government’s concerns were echoed by the Australian prime minister, Anthony Albanese. Speaking in Canberra on Saturday, Albanese said that “global citizens deserve better”. Australia recently banned the use of social media for under-16s.\n\n“The use of generative artificial intelligence to exploit or sexualise people without their consent is abhorrent,” he said.\n\n“The fact that this tool was used so that people were using its image creation function through Grok is just completely abhorrent. It, once again, is an example of social media not showing social responsibility.”\n\nSome rightwing political figures have tried to frame this as a free speech issue. Responding to the news X faced a potential ban, the former prime minister Liz Truss said: “Starmer is really losing it now.”\n\nX partially restricted access to Grok on Friday. Its public account lost the ability to generate images at the request of free users, leaving the function available only to paid subscribers. It also appeared to have stopped creating bikini images.\n\nThe Grok app, however, which does not generate images publicly, is still able to create sexually explicit material from women’s pictures.\n\nOther nudificiation apps are still available. The Labour MP Jess Asato, who campaigns against the sexual abuse and harassment of women, said legislation to ban such apps was urgently needed.\n\nShe posted on social media: “It’s not just XAi. This nudification tool was advertised yesterday on @YouTube.\n\n“No rules had been broken @Google said on reporting.\n\n“Our nudification legislation needs to be expedited.”\n\nGoogle was approached for comment.",
    "readingTime": 3,
    "keywords": [
      "prime minister",
      "create sexually",
      "suppress free",
      "free speech",
      "ministers threatened",
      "social media",
      "sexual abuse",
      "generate images",
      "women",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/10/elon-musk-uk-free-speech-x-ban-grok-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/146ea600371c47e796f9b3708122efd144613cab/458_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0f098b3b34c05747a8bf649361108619",
    "created_at": "2026-01-10T18:16:36.322Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say",
    "title": "China is closing in on US technology lead despite constraints, AI researchers say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/china-is-closing-in-on-us-technology-lead-despite-constraints-ai-researchers-say-4440562",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0908G_L.jpg",
    "created_at": "2026-01-10T18:16:34.801Z",
    "topic": "finance"
  },
  {
    "slug": "investor-michael-burry-reveals-options-bet-against-oracle",
    "title": "Investor Michael Burry Reveals Options Bet Against Oracle",
    "description": "Michael Burry, the famed investor who has drawn attention in recent months for criticism of the artificial intelligence boom, is betting against Oracle Corp.",
    "fullText": "MarketsBy Carmen Reinicke and Jeran WittensteinSaveMichael Burry, the famed investor who has drawn attention in recent months for criticism of the artificial intelligence boom, is betting against Oracle Corp.Burry owns put options on Oracle shares, he said in a Substack post after markets closed on Friday. Puts typically increase in value as the price of the underlying asset falls. Burry, who revealed bearish bets against AI chipmaker Nvidia Corp. and Palantir Technologies Inc. in November, also directly shorted Oracle during the last six months, he said.",
    "readingTime": 1,
    "keywords": [
      "oracle",
      "burry"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-10/investor-michael-burry-reveals-options-bet-against-oracle-shares",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBuGJpCEmiYA/v0/1200x776.jpg",
    "created_at": "2026-01-10T12:20:51.866Z",
    "topic": "finance"
  },
  {
    "slug": "do-anything-agents",
    "title": "Do Anything Agents",
    "description": "Automate your daily tasks, integrate your favorite apps, and get more done with Do Anything, the advanced AI assistant designed to handle your workload seamlessly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.doanything.com/landing",
    "thumbnail_url": "https://doanything.com/opengraph-image.png",
    "created_at": "2026-01-10T12:20:47.914Z",
    "topic": "tech"
  },
  {
    "slug": "a-curated-list-of-resources-tools-libs-of-the-mistral-ai-ecosystem",
    "title": "A curated list of resources, tools, libs of the Mistral AI ecosystem",
    "description": "A curated list of awesome resources, tools, libraries, and projects for the Mistral AI ecosystem. - samouraiworld/awesome-mistral",
    "fullText": "samouraiworld\n\n /\n\n awesome-mistral\n\n Public\n\n A curated list of awesome resources, tools, libraries, and projects for the Mistral AI ecosystem.\n\n License\n\n CC0-1.0 license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n samouraiworld/awesome-mistral",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/samouraiworld/awesome-mistral",
    "thumbnail_url": "https://opengraph.githubassets.com/700906147c1589e284be6f65b8f4eebcebfc733b2d5f04f16af391427108b683/samouraiworld/awesome-mistral",
    "created_at": "2026-01-10T12:20:45.428Z",
    "topic": "tech"
  },
  {
    "slug": "china-is-sending-a-warning-to-us-tech-firms-dont-poach-our-ai-talent-and-tech",
    "title": "China is sending a warning to US tech firms: Don't poach our AI talent and tech",
    "description": "Meta's Manus deal faces a probe from China's regulator. Analysts say it's about sending a message that China's AI talent isn't easy pickings.",
    "fullText": "China has a message for US tech firms: Hands off our AI talent and tech.\n\nThat's what Beijing is signalling by announcing a probe into Meta's acquisition of Manus, analysts told Business Insider.\n\nThe probe, confirmed by China's Ministry of Commerce in a Thursday press conference, will investigate whether the acquisition complies with the country's laws and regulations concerning export controls, according to a statement translated by Google.\n\nManus was launched in China last March by the AI product studio Butterfly Effect and drew global attention after saying it had designed a \"general-purpose\" AI agent that can conduct tasks with limited human supervision. In mid-2025, the startup relocated to Singapore.\n\nIn December, Meta announced that it would acquire Manus and sever its ties with China completely. The deal reportedly exceeds $2 billion. Meta did not respond to a request for comment for this story from Business Insider.\n\nWhile China and the US have long engaged in tit-for-tat regulatory exchanges involving their tech companies, analysts told Business Insider this probe is notable because it appears to be aimed at discouraging so-called \"Singapore washing\" — the process of moving a company from China to Singapore to reduce regulatory scrutiny.\n\nTikTok's parent company, ByteDance, and fast-fashion giant Shein are among those that have shifted their headquarters from China to Singapore.\n\nThe probe is also a means to discourage Chinese AI startups from choosing the US, analysts said.\n\n\"I see Beijing's probe as an effort to prevent the loss of AI technology and talent to foreign acquisition, especially to the US,\" Wendy Chang, a senior analyst at the Mercator Institute for China Studies, told Business Insider.\n\nMeta said it plans to bring over Manus' top leadership and will continue to run its AI agent platform separately, alongside integrating the technology into Meta's own products.\n\nNvidia, the world's most valuable company, has been the subject of US export controls for years, which limit the sale of its advanced chips to China. The Manus probe shows how the battleground has moved from beyond chips to \"models, agents, talent, and enterprise deployment,\" Murthy Grandhi, a company profiles analyst at research firm GlobalData, told Business Insider.\n\nHanna Dohmen, senior research analyst at Georgetown's Center for Security and Emerging Technology, told Business Insider that while the probe \"isn't entirely surprising,\" the approach regulators are taking is \"more novel\" because it \"appears to focus on the movement of talent and IP.\"\n\nTalent has become a focal point of the AI race, with companies like OpenAI, Meta, and Google offering huge pay packages to entice the best and brightest. Last year, Meta invested $14 billion in AI training startup Scale AI, bringing its CEO, Alexandr Wang, over to run the tech giant's AI efforts.\n\nChina's Manus probe could signal that it was policing \"outbound AI technology transfer with greater rigor,\" said Grandhi, adding that it could accelerate the \"bifurcation of AI ecosystems.\"\n\nThe US and China have been taking diverging approaches to AI, with Chinese companies tending to favor AI models that are more open, such as DeepSeek.\n\nIt's not clear how long China's probe will last, should it progress into a full investigation. Other investigations from China's Ministry have taken more than a year.\n\nGrandhi said that in his view, the most likely outcome is that the deal will be approved \"with constraints, rather than an outright block.\"\n\n\"Whatever the outcome may be, this certainly sends a signal to other US or foreign companies that are considering similar acquisitions,\" added Dohmen.",
    "readingTime": 3,
    "keywords": [
      "export controls",
      "manus probe",
      "business insider",
      "acquisition",
      "analysts",
      "analyst",
      "china",
      "meta's",
      "agent",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/china-probe-meta-manus-deal-warning-us-analysts-singapore-washing-2026-1",
    "thumbnail_url": "https://i.insider.com/6961850164858d02d2181ec6?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.587Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-says-ai-doomerism-has-done-a-lot-of-damage-and-is-not-helpful-to-society",
    "title": "Nvidia CEO Jensen Huang says AI doomerism has 'done a lot of damage' and is 'not helpful to society'",
    "description": "Nvidia CEO Jensen Huang said that frequent warnings about AI are dissuading people from making investments in AI's improvement.",
    "fullText": "Jensen Huang is over AI doomerism.\n\nThe Nvidia CEO said one of his biggest takeaways from 2025 was \"the battle of narratives\" over the future of AI development between those who see doom on the horizon and the optimists. Huang said while \"it's too simplistic\" to dismiss either side entirely, some of the dismal outlooks are having real consequences.\n\n\"I think we've done a lot of damage with very well-respected people who have painted a doomer narrative, end of the world narrative, science fiction narrative,\" Huang said during a recent episode of the \"No Priors\" podcast. \"And I appreciate that many of us grew up and enjoyed science fiction, but it's not helpful. It's not helpful to people. It's not helpful to the industry. It's not helpful to society. It's not helpful to the governments.\"\n\nHuang didn't name the people in question, nor did he give a specific motivation for why people may be sharing their more dour outlook. Instead, he cited concerns about \"regulatory capture,\" arguing that no company should approach governments to request more regulation.\n\n\"Their intentions are clearly deeply conflicted, and their intentions are clearly not completely in the best interest of society,\" he said. \"I mean, they're obviously CEOs, they're obviously companies, and obviously they're advocating for themselves.\"\n\nA spokesperson for Nvidia declined to elaborate on Huang's remarks. Previously, the Nvidia CEO took issue with Anthropic CEO Dario Amodei's prediction that AI could replace up to half of all white-collar entry-level jobs within five years. (Amodei later said that Huang distorted his views.)\n\nOverall, Huang said the sheer amount of negativity is distorting the conversation around AI.\n\n\"When 90% of the messaging is all around the end of the world and the pessimism, and I think we're scaring people from making the investments in AI that makes it safer, more functional, more productive, and more useful to society,\" he said.\n\nHuang isn't the only CEO who is hoping for a different AI narrative in 2026. Microsoft CEO Satya Nadella wrote in his year-end note that he wanted that society needs to move beyond labeling content AI \"slop.\"\n\n\"We need to get beyond the arguments of slop vs sophistication,\" Nadella wrote on his blog late last year, \"and develop a new equilibrium in terms of our 'theory of the mind' that accounts for humans being equipped with these new cognitive amplifier tools as we relate to each other.\"",
    "readingTime": 3,
    "keywords": [
      "nvidia ceo",
      "science fiction",
      "they're obviously",
      "it's",
      "helpful",
      "narrative",
      "society",
      "huang",
      "governments",
      "intentions"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-jensen-huang-ai-doomerism-damage-investments-2026-1",
    "thumbnail_url": "https://i.insider.com/6961677b04eda4732f2ed348?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.491Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-industry-is-getting-into-politics-here-are-the-key-super-pacs-to-watch-in-2026",
    "title": "The AI industry is getting into politics. Here are the key super PACs to watch in 2026.",
    "description": "The AI industry is pouring hundreds of millions of dollars into super PACs ahead of the 2026 midterm elections.",
    "fullText": "Artificial intelligence is poised to play a big role in politics this year — and not just when it comes to AI-generated content.\n\nSeveral super PACs backed by figures in the tech industry have formed ahead of the 2026 midterm elections.\n\nSome of the groups plan to support candidates who are friendly towards the AI industry and will take a lighter regulatory approach to the technology.\n\nAt least one group has been formed explicitly to combat the influence of those pro-AI groups.\n\nHere are the super PACs to keep an eye on as the year progresses.\n\nThe biggest player so far is Leading the Future, a pro-AI network of super PACs that says it has already raised $100 million.\n\nIn an August press release, the group listed a variety of supporters, including:\n\nIt's unclear how much money each entity has contributed to the group, as it has not been required to disclose donors yet.\n\nThe group says it plans to serve as the \"political and policy center of gravity for the AI industry\" and will \"support candidates aligned with the pro-AI agenda\" and \"oppose those that do not.\"\n\nThe group has already begun spending.\n\nThink Big, a PAC affiliated with the group, has spent over $118,000 against Assemblyman Alex Bores in the Democratic primary for New York's 12th congressional district.\n\nAnd American Mission, a separate affiliated PAC, has spent over $243,000 backing GOP candidate Chris Gober in Texas's 10th congressional district.\n\nIn response to Leading the Future, two former congressmen — Republican Chris Stewart of Utah and Democrat Brad Carson of Oklahoma — have formed their own competing political network to back candidates who support AI regulation, called Public First.\n\nThe group is aiming to raise $50 million for its effort, well short of what the pro-AI groups have raised. But Carson told Business Insider he feels good about Public First's odds, given that the American public is broadly supportive of AI regulation.\n\n\"We have $50 million and 85% of public sentiment. They have 15% of public settlement, and $100 million,\" Carson said. \"I will take our side of that bet any day.\"\n\nThe group has not yet disclosed donors, though Carson said that Public First would have financial support from employees at a variety of AI companies.\n\n\"There's going to be people from across the AI sector, as well as far beyond the AI sector, who contribute to the effort,\" Carson said.\n\nThe group has two affiliated super PACs: one that supports Democrats called Jobs and Democracy PAC, and another that supports Republicans called Defending Our Values PAC. Neither has spent in any election so far.\n\nMeta is also getting into the super PAC game, establishing two different PACs last year to support candidates aligned with their vision for AI regulation.\n\nUnlike the other PACs, Meta's efforts will focus primarily on the state level.\n\nOne PAC, called Mobilizing Economic Transformation Across (Meta) California, will focus specifically on the Golden State, where Meta is headquartered.\n\n\"As home to many of the world's leading AI companies, California's innovation economy has an outsized impact on America's economic growth, job creation, and global competitiveness,\" a Meta spokesperson said. \"But Sacramento's regulatory environment could stifle innovation, block AI progress, and put California's technology leadership at risk.\"\n\nThe spokesperson added that the PAC would back candidates in both parties who \"recognize California's vital role in AI development and embrace policies that will keep the state at the forefront of the global tech ecosystem.\"\n\nA separate PAC, the American Technology Excellence Project, will focus on races in other states.\n\n\"Amid a growing patchwork of inconsistent regulations that threaten homegrown innovation and investments in AI, state lawmakers are uniquely positioned to ensure that America remains a global technology leader,\" Meta VP of Public Policy Brian Rice said in a statement.\n\nNeither PAC has spent significant sums yet.",
    "readingTime": 4,
    "keywords": [
      "super pacs",
      "congressional district",
      "candidates aligned",
      "back candidates",
      "pro-ai groups",
      "leading the future",
      "technology",
      "industry",
      "formed",
      "affiliated"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/artificial-intelligence-industry-super-pacs-2026-1",
    "thumbnail_url": "https://i.insider.com/695c31af832e0ef1ead731e5?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.363Z",
    "topic": "tech"
  },
  {
    "slug": "ai-isnt-making-us-smarter-its-training-us-to-think-backward-an-innovation-theorist-says",
    "title": "AI isn't making us smarter — it's training us to think backward, an innovation theorist says",
    "description": "Innovation theorist John Nosta said AI's polished responses can erode human reasoning at work by creating confidence without understanding.",
    "fullText": "AI is often described as a thinking machine — a digital mind edging closer to human intelligence.\n\nHowever, John Nosta, an innovation theorist and founder of NostaLab, an innovation and tech think tank, said that large language models don't think like humans at all.\n\nIn fact, he calls AI \"anti-intelligence\" because it operates in a way that runs counter to how humans reason, learn, and build understanding.\n\n\"My conclusion is that artificial intelligence is antithetical to human cognition,\" Nosta told Business Insider. \"I even call it anti-intelligence.\"\n\nAt the heart of Nosta's argument is a simple but unsettling claim: AI doesn't understand anything in the human sense.\n\nWhen people think about an object — say, an apple — they place it in space, time, memory, culture, and lived experience, he said.\n\nA large language model, Nosta said, does none of that. Instead, it represents the word as a mathematical object inside an enormous, hyperdimensional space and searches for patterns that statistically align, he said.\n\n\"An apple doesn't exist as an apple,\" he said. \"It exists as a vector in a hyperdimensional space.\"\n\nThat distinction matters, he said, because it means AI outputs are optimized for coherence rather than comprehension.\n\nThe system isn't reasoning its way to an answer — it's producing the response that best fits a pattern of language, he said.\n\nNosta believes AI is quietly reshaping how people think, especially at work.\n\nHuman cognition, he said, usually follows a familiar path: confusion, exploration, tentative structure, and finally confidence. AI flips that sequence.\n\n\"With AI, we start with structure,\" he said. \"We start with coherence, fluency, a sense of completeness, and afterwards we find confidence.\"\n\nThat inversion creates a powerful illusion. Because AI-generated answers sound polished and authoritative, people often accept them immediately — without doing the harder work of questioning, exploring, or fully understanding them, he said.\n\n\"Coming to the answer first is an inversion of human cognitive process,\" Nosta said. \"That's antithetical to human thought.\"\n\nThe danger isn't that AI will outperform humans in raw computation. Nosta said that's inevitable. What worries him is how easily people can outsource the most valuable parts of thinking.\n\n\"It's the stumbles, it's the roughness, it's the friction that allows us to get to observations and hypotheses that really develop who we are,\" he said.\n\nAs some companies push employees to go \"all in\" on AI for writing, analysis, and decision-making, Nosta said that speed and fluency are being mistaken for understanding.\n\nUsed as a partner, AI can enhance human thinking. Used as a shortcut, it can quietly weaken it, he said.\n\n\"The magic isn't necessarily AI,\" he said. \"It's the iterative dynamic between humans and machines.\"\n\nIn Nosta's view, the real risk of the AI era isn't smarter machines — it's humans learning to think backward.\n\nConcerns about how AI may be reshaping human thinking are increasingly shared beyond theorists.\n\nResearchers at Oxford University Press found in a recent report that AI is making students faster and more fluent while quietly stripping away the depth that comes from pausing, questioning, and thinking independently.\n\nA report from the Work AI Institute, released last month, echoed the same pattern, saying that generative AI often creates an illusion of expertise — making users feel smarter and more productive, even as their underlying skills erode.\n\nMehdi Paryavi, CEO of the International Data Center Authority, which advises companies and governments on building the data centers that power AI, said that excessive and poorly designed AI use is driving a \"quiet cognitive erosion.\"\n\n\"If you come to believe that AI writes better than you and thinks smarter than you, you will lose your own confidence in yourself,\" he told Business Insider.",
    "readingTime": 4,
    "keywords": [
      "hyperdimensional space",
      "human cognition",
      "business insider",
      "it's",
      "humans",
      "isn't",
      "language",
      "understanding",
      "apple",
      "quietly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-human-intelligence-impact-at-work-2026-1",
    "thumbnail_url": "https://i.insider.com/695fa5dd04eda4732f2eb200?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.230Z",
    "topic": "finance"
  },
  {
    "slug": "everything-we-know-about-how-wall-streets-biggest-firms-from-jpmorgan-to-blackstone-are-adopting-ai",
    "title": "Everything we know about how Wall Street's biggest firms, from JPMorgan to Blackstone, are adopting AI",
    "description": "Finance's biggest firms are considering how AI might impact jobs, how it could cut costs, and reduce \"grunt work.\"",
    "fullText": "Welcome to Wall Street's AI era.\n\nBanks, private equity firms, hedge funds, and asset managers have been eager to use generative AI to boost productivity and reduce grunt work for workers.\n\nBusiness Insider has been reporting on how some of finance's biggest players are approaching artificial intelligence, from its potential impact on jobs and the creation of new ones, to the various ways firms are cutting costs and ramping up efficiencies.\n\nBut first — if you work at a Wall Street firm and are using AI, we want to hear from you. How is AI really showing up in your day-to-day? Is it living up to the hype?\n\nAI is set to reshape roughly 44% of banking work by 2030, according to consulting firm ThoughtLinks — and Wall Street's biggest firms are racing to get there first.\n\nJPMorgan Chase, the largest US bank by assets, is spending $18 billion a year on technology, with AI a central focus. CEO Jamie Dimon is a \"tremendous\" user of the bank's generative AI tools, which have now been rolled out to more than 200,000 employees.\n\nThe bank is also replacing long-standing human processes with AI. Its asset-management arm announced plans to stop using external proxy advisers for US shareholder voting, instead launching an in-house AI platform, Proxy IQ, which will analyze data from more than 3,000 annual company meetings. Executives have said the bank is training employees to use AI in ways that deliver measurable productivity gains.\n\nGoldman Sachs is spending $6 billion on technology this year — a figure CEO David Solomon has said he wishes were higher. In an October memo outlining the latest phase of its OneGS initiative, the bank said AI would drive efficiency, slow hiring, and lead to a \"limited reduction\" in roles. Goldman has since rolled out internal AI tools, including an assistant now available to employees across the firm.\n\nMorgan Stanley, an early OpenAI partner, has focused on turning employee ideas into working AI products. One internally built tool, called DevGen.AI has already saved engineers more than 280,000 hours this year. Among interns, AI adoption is especially strong: 72% say they use ChatGPT daily or several times a week.\n\nCitigroup has also accelerated its push. Nearly 180,000 employees across 83 countries now have access to Citi's proprietary AI tools, which have been used almost 7 million times this year. CEO Jane Fraser said the bank's generative AI tools are saving about 100,000 developer hours a week through automated code reviews. Citi also began piloting agentic AI with 5,000 employees in September.\n\nIn the ultracompetitive world of hedge funds, being ahead on the latest technology is always a priority.\n\nIn December, Citadel said its stockpickers are using an internal chatbot to speed up their processes and find new info at his $71 billion hedge fund.\n\nAt the 2025 Global Milken conference, Andreas Kreuz, WorldQuant's deputy CIO, said the firm was using AI to expand the data it can bring into its models since it can restructure data from images and audio.\n\nPoint72's CTO Ilya Gaysinskiy told BI about his big plans to ramp up Point72's tech organization and how AI will play into that expansion.\n\nBridgewater launched a fund driven by AI in 2024. The fund's AIA Labs worked to replicate every stage of the investment process with machine learning. The firm's co-chief investment officer and chief scientist outlined the plans of the world's largest hedge fund.\n\n$29 billion hedge fund Balyasny has built an AI bot that it believes will be able to do the grunt work that typically falls to senior analysts — a potential huge timesaver for investment teams. The manager told Business Insider in 2024 that roughly 80% of the firm's staff use its AI tools, which include the internal chatbot BAMChatGPT, and recently hired Matthew Henderey, one of the CIA's AI developers, as a data science executive. Man Group and Viking Global have also developed their own internal offerings.\n\nLucia Soares — Carlyle's chief information officer and head of technology transformation — talked to BI about taking on a new challenge: Bringing AI to the investment giant's 2,300 global employees.\n\nPrivate equity firms are no strangers to managing and analyzing copious amounts of data — but data is only helpful if you can find it. Blackstone has invested in improving its enterprise search and is also betting AI will give it a leg up in its pursuit to capture more of the insurance market.\n\nSwedish PE giant EQT built an AI engine called Motherbrain that has changed how its investors source deals. ChatGPT enables the investing giant to take the next step with its AI ambitions.\n\nAs private equity firms turn to AI for a competitive edge, Thomas H. Lee says its engineers are up to 30% more productive with help from AI coding assistants.\n\nAI tools are changing how stock-pickers do their job. AllianceBernstein, BlackRock, and JPMorgan opened up on how their tools are speeding up portfolio manager workflows.\n\nBlackRock has introduced Asimov, the agentic AI platform for the firm's fundamental equity business. Business Insider talked to Kirsty Craig, head of research, data, and AI strategy for portfolio management tech, who helped develop the tool.\n\nThe multi-billion-dollar investment manager VanEck invested in a Toronto-based startup and is onboarding its technology to boost its ETF business. An executive and the fintech's CEO walked us through how AI will change the jobs of analysts and salespeople.\n\nKraken's $1.5 billion acquisition of a retail trading startup made headlines last March. Less noticed was how the crypto exchange used generative AI to run due diligence on the target — a process its head of M&A now considers core to his team's work.\n\nAt Block, Jack Dorsey's fintech behind Square, Afterpay, and Cash App, engineers built an AI agent that can write code faster — and in some cases better — than senior developers. The company ultimately decided to open-source the tool, even as it gives competitors a look under the hood.\n\nChime has taken a similar in-house approach. In 2023, the neobank built a private, ChatGPT-style assistant to help engineers ship products more quickly and at lower cost. The company's CTO shared how the tool has become a key part of Chime's product-development playbook.",
    "readingTime": 6,
    "keywords": [
      "wall street's",
      "bank's generative",
      "internal chatbot",
      "hedge funds",
      "employees across",
      "equity firms",
      "hedge fund",
      "business insider",
      "tools",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-wall-street-is-using-ai-jpmorgan-goldman-citi-blackstone",
    "thumbnail_url": "https://i.insider.com/676990d59de00e389eb3082d?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:40.084Z",
    "topic": "finance"
  },
  {
    "slug": "5-groundbreaking-and-strange-products-you-could-soon-buy-from-the-2026-consumer-electronics-show",
    "title": "5 ground-breaking (and strange) products you could soon buy from the 2026 Consumer Electronics Show",
    "description": "From a lollipop that lets you taste sound to a Tamagotchi style AI pet that physically grows, here are the coolest tech you could get your hands on.",
    "fullText": "This lollipop lets you taste your favorite music — literally.\n\nUsing bone induction technology, Lollipop Star made a candy that can transmit sound through vibrations in the jaw and skull while it's in the mouth. For those without synesthesia, this may be the closest you can come to experiencing it.\n\nAccording to Lollipop Star's website, the candy is designed with a standard lollipop on top of a thicker handle at the bottom, which houses the electronics. Users could bite down lightly on the candy to activate the vibrations. Earplugs are included to help isolate the sound in noisy environments.\n\nBased on photos from Lollipop Star's booth at the CES, each candy is tied to a specific artist and flavor. For example, Ice Spice's version comes in peach, Akon's is blueberry, and Armani White's is lime.\n\nOn its website, the company says that the novelty candy will come at an affordable price of $9 each.\n\nThe Tamagotchi of the AI era is here.\n\nA new AI pet from Chinese startup Takway AI, called Sweekar, debuted in the US at CES. Unlike most AI companions that exist entirely virtually, this creature has a physical form that appears to grow.\n\nBased on demo videos, the Sweekar starts out as a palm-sized, egg-shaped device with glowing ears. After an incubation period that can last up to two days, the shell appears to crack open, revealing a newborn digital creature.\n\nFrom there, Sweekar moves through a series of life stages. The baby phase lasts roughly five to seven days, followed by a teenage stage that can stretch from about three to six weeks. Eventually, the pet reaches adulthood, developing greater intelligence and a more defined personality, as well as more independence.\n\nEarly in its life, the pet requires frequent attention, including regular care and help learning basic language. Just like a Tamagotchi, Sweekar can die from neglect.\n\nTakway AI said in a press release that it plans to launch Sweekar on Kickstarter later this year. The company expects the device to be priced at around $150.\n\nVacuum cleaning robots are taking a major step up.\n\nRoborock's Saros Rover prototype became the first robot vacuum to climb stairs at CES. Based on demo videos, the prototype robot vacuum uses a pair of articulated wheel-legs that lift and lever its body up, before folding away and redeploying for the next step.\n\nThe process isn't fast, according to demo videos, but the Rover cleans the stairs as it goes. Roborock said in a press release that the system works on traditional, curved, and carpeted staircases, as well as ramps, thresholds, and other household obstacles.\n\nThe Saros Rover remains an early prototype, and Roborock hasn't shared pricing or a launch timeline. The company has said in a press release, however, that it plans to bring the stair-climbing robot vacuum to market.\n\nLenovo showcased numerous concept devices at CES 2026, but one of its boldest ideas was a gaming laptop featuring a screen that physically expands wider.\n\nThe Legion Pro Rollable, as Lenovo described in a press release, is built around a 16-inch flexible OLED display that can expand sideways to two larger sizes. From photos, the device appears to have a screen screen stretches from a standard 16:10 aspect ratio to 21:9 or an ultra-wide 24:9, effectively turning a compact gaming laptop into a widescreen display better suited for immersive games.\n\nAccording to Lenovo, the Legion Pro has the same lower chassis, ports, and supports high-end graphics, just like some of Lenovo's other products. The rollable device was named Best Gaming Product in the Official Best of CES 2026 Awards, though Lenovo has not announced plans to turn it into a retail device.\n\nAI-Tails is betting that AI can spot health issues in cats long before their owners do.\n\nAt CES, the Swiss startup has unveiled a smart feeding and drinking station that uses AI, cameras, and pattern-recognition software to analyze a cat's behavior and facial expressions, signals that are often too subtle for humans to notice without veterinary expertise. The company's website said that the goal is to monitor a pet's well-being continuously and flag potential problems in real time.\n\nVideos of a live demo at CES show that the system features separate bowls for food and water. with built-in sensors and cameras, analyze consumption patterns, body temperature, and facial cues.\n\nThe feeding station is currently available for preorder and is expected to ship worldwide in the fourth quarter of 2026, according to the company's website. The models are expected to be priced between $199 and $299.",
    "readingTime": 4,
    "keywords": [
      "legion pro",
      "saros rover",
      "gaming laptop",
      "press release",
      "robot vacuum",
      "company's website",
      "demo videos",
      "lollipop star's",
      "takway ai",
      "candy"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ground-breaking-and-quirky-products-from-the-2026-ces-2026-1",
    "thumbnail_url": "https://i.insider.com/695ec58964858d02d217f172?width=1200&format=jpeg",
    "created_at": "2026-01-10T12:20:39.933Z",
    "topic": "finance"
  },
  {
    "slug": "understanding-the-types-of-data-in-data",
    "title": "Understanding the Types of Data in Data",
    "description": "Discover the key types of data in data science, from structured to unstructured, and learn their significance in analytics and machine learning applications.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://ischool.syracuse.edu/types-of-data/",
    "thumbnail_url": "https://ischool.syracuse.edu/wp-content/uploads/types-of-data-1024x682.png",
    "created_at": "2026-01-10T06:17:38.371Z",
    "topic": "tech"
  },
  {
    "slug": "digging-into-the-llmasajudge-results",
    "title": "Digging into the LLM-as-a-Judge Results",
    "description": "I was unhappy with the LLM-as-a-judge instruction fine-tuning results I got when comparing my various base models.  Could I make them any better?",
    "fullText": "I'm still working on my \"extra credit\" projects after finishing the main body of\nSebastian Raschka's book\n\"Build a Large Language Model (from Scratch)\".\nLast time around, I trained four base models, using the GPT-2 architecture from\nthe book, on Lambda Labs machines. I was using two ways to compare them with each\nother, with three models that I'd trained locally, and with the original GPT-2 weights\nfrom OpenAI:\n\nHere were the results I got, sorted by the loss:\n\nNow, you'd expect there to be at least a loose correlation;\nthe lower the loss, the higher the IFT score. But, while we can see a difference\nbetween the OpenAI weights and our own, within our own there doesn't seem to be a\nlogical pattern.\n\nI think that the problem is that the results from the GPT-5.1\nLLM-as-a-judge are not consistent between models. That's not a complaint about\nthe code or its original design, of course -- it was originally written as part\nof the LLM book as a way of doing a quick test on an instruction fine-tuned model that\nwe'd spent the previous 238 pages writing -- just something that was a bit more efficient than\nreading hundreds of input/output pairs ourselves. It was never meant to be a tool\nto compare models in the way I'm using it now.\n\nIn this post I'll dig into why it doesn't work for this kind of thing, and see if that's something\nwe can change.\n\nLet's spec out the problem first. The instruction fine-tuning test trains our model\non the Alpaca dataset in order to\nlet it know how to follow instructions; that comprises a series of sequences like\nthis:\n\nIn the version I've settled on,\nI fine-tune on a training set of 85% of the samples, epoch by epoch, bailing out when the\nloss on a separate validation set of 5% of the samples starts rising. I then use the\nweights from the previous epoch -- that is, before validation loss started rising --\nto generate responses to the remaining 10% of the samples.\n\nOnce that's done, the script hits the OpenAI API, using GPT-5.1, default parameters for all\nof the options (eg. no explicit temperature) with queries like this:\n\nWe do that for every model-generated response in the test set, then take the\naverage of the scores and use that as our result.\n\nTo see why that's problematic, imagine this simple instruction with no separate input:\n\nOne response I've seen from my models was this:\n\nThat's obvious garbage, and should get a zero -- and GPT-5.1 consistently does that.\n\nAnother response, from OpenAI's original weights for their \"medium\" model (larger than\nthe ones I've been training), is this:\n\nThat's correct, so it deserves 100, or perhaps 95 due to being unnecessarily\nwordy (the answer \"Jane Austen\" is the suggested response in the dataset).\n\nOne of my models came up with that gem during an earlier eval. It's completely wrong,\nso it deserves a 0, right? And normally the GPT-5.1 model does that -- but sometimes\nit's a little more generous, and gives it a low, but non-zero score. When asked for\nits reason for that, it makes the logical point that while it's the wrong answer, at\nleast Sarah Palin is a real person. It's better than the \"the book wrote itself\"\ncomplete nonsense of the first response.\n\nThe problem is that the different runs against the different models are not consistent, as\nthey're all talking to GPT-5.1 separately. One model might find it in a harsh \"mood\",\nand get a lower rating than another model that found it at a more generous moment.\n\nI came to the conclusion that the best way to fix this is to do a \"batch\" -- that is, fine-tune\neach model on the Alpaca dataset that Raschka provides, and generate responses for\nthe test set and store them in a file. Then, once we've done that for all models,\nwe can score them all at once, prompting GPT-5.1 with something like this:\n\nThe theory is that doing it that way will mean that each individual query/response pair is graded consistently\nbetween models, even if there might still be inconsistencies between query/response pairs.\nThat hopefully means we'll get more consistent results and can compare the models\nbetter.\n\nRunning the first against each of our models, and then the second against all of the\noutput files, gives us this updated table (with links to the annotated JSON files\nin case anyone else wants to take a look):\n\n(Still sorted by loss so that you can compare it more easily with the one above.)\n\nThat's really interesting! The IFT score is still not correlated with the loss.\nBut there does appear to be a pattern.\n\nIt looks like we have three groups of models:\n\nI tried running the LLM-as-a-judge scoring script a few times, just to make sure\nthis wasn't some kind of random weirdness, but the pattern was always the same:\nthe OpenAI weights, the cloud FineWeb 8x A100 40 GiB, and the two local Local FineWeb-Edu\nmodels always got the best IFT scores, though sometimes they swapped positions (apart from the\nOpenAI medium model, which was of course always at the top). The other cloud\nFineWeb models and the local FineWeb one were consistently scored much lower.\n\nA hypothesis: there are two things that contribute to how good a model is at these\nIFT tests:\n\nOr to put it another way -- some of these models are smart but not knowledgeable, while\nothers are knowledgeable but not smart, and some are neither.\nI think that could explain what we're seeing here. While OpenAI never published\ntheir \"WebText\" dataset for GPT-2, the paper\ndescribes it as\n\na new web scrape which emphasizes\n document quality. To do this we only scraped web pages\n which have been curated/filtered by humans. Manually\n filtering a full web scrape would be exceptionally expensive\n so as a starting point, we scraped all outbound links from\n Reddit, a social media platform, which received at least 3\n karma.\n\nNow, the FineWeb dataset is quite similar, though I think it's a tad more curated than that.\nBut OpenAI trained\ntheir models for quite some time and did lots of tricks to get the loss as low as\npossible.\n\nonly the most \"educational\" data. Models trained on it, you might think, would\nknow more facts for a given amount of training.\n\nSo we can imagine the OpenAI models are smart but not knowledgeable, as we can our\ncloud FineWeb 8x A100 40 GiB model, which (I believe due to an accidentally-near-optimal batch\nsize) worked out well in terms of loss. They were trained on relatively sloppy datasets\nbut turned out reasonably well. Their intelligence makes up for some of their lack of\nknowledge.\n\nOur other cloud trains and the local FineWeb one are dumb and not\nknowledgeable; they were trained on the low-information FineWeb dataset, but they didn't\nwind up with a particularly amazing loss. So they get low scores.\n\nAnd finally, our local FineWeb-Edu models are still dumb, but they make up for it\n\nWell, it sounds plausible ;-) And I'd like to spend some time digging in to see if there's any indication\nif it's actually true. But after an afternoon of poking around the results, I can't really get\na handle on whether it is, or indeed how you'd test that hypothesis in any real\ndepth.\n\nTBH, I think this has zoomed so far past my \"no side quests\" limit that it's not even\nvisible in the rear view mirror, so it's probably best to shelve it as a\n\"cool idea, bro\" for now. Learning about how to run sensible evals, and how to work out\nwhat they're saying, will have to be a task for another day. I will keep on doing these\nIFT tests for future models, though, just out of interest.\n\nSo: let's get back to our regular scheduled LLM training. Next up, how do we\nupload our models to Hugging Face quickly and easily so that other people can\nplay with them.",
    "readingTime": 7,
    "keywords": [
      "ift tests",
      "alpaca dataset",
      "cloud fineweb",
      "ift score",
      "generate responses",
      "openai weights",
      "fineweb-edu models",
      "web scrape",
      "medium model",
      "fineweb gib"
    ],
    "qualityScore": 1,
    "link": "https://www.gilesthomas.com/2026/01/llm-from-scratch-30-digging-into-llm-as-a-judge",
    "thumbnail_url": "https://www.gilesthomas.com/images/favicons/web-app-manifest-512x512.png",
    "created_at": "2026-01-10T06:17:37.191Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-warns-investors-that-the-ai-market-is-bigger-than-they-realize-with-over-one-and-a-half-million",
    "title": "Nvidia CEO Jensen Huang Warns Investors That the AI Market Is Bigger Than They Realize With Over ‘One and a Half Million AI Models in the World’",
    "description": "Jensen Huang explains artificial intelligence as a multi-layered platform, arguing its true impact extends far beyond consumer-facing language models.",
    "fullText": "Bottom Line Up Front: Nvidia (NVDA) CEO Jensen Huang, in his role as the leader of the primary company behind the ongoing technology movement, says that many people don’t realize just how big the AI revolution is. He says there are currently over 1.5 million AI models throughout the world, from healthcare and drug discovery to more commonly known names like Elon Musk’s Grok and Sam Altman’s ChatGPT.\n\nThe Details: Nvidia founder and chief executive Jensen Huang has consistently framed artificial intelligence as an infrastructure-scale transformation rather than a single technological breakthrough. In a fireside chat hosted by the Center for Strategic and International Studies (CSIS) with President and CEO Dr. John J. Hamre, Huang continued outlining his layered view of AI, emphasizing the systems, capital, and breadth of applications that underpin the technology’s long-term impact.\n\nJeff Bezos Launched a Secretive AI Startup in 2025 That Should Give Wall Street Chills\n\nThe Top-Rated Dividend King to Buy for 2026\n\nEvercore Analysts Love UnitedHealth Stock for 2026. Should You Buy UNH Here?\n\nTired of missing midday reversals? The FREE Barchart Brief newsletter keeps you in the know. \n\nBuilding on earlier discussion of energy, chips, and systems, Huang described the current infrastructure buildout of AI as being multi-layered. The first layer is simple: energy. Huang frames electricity buildout as the most fundamental part of the entire AI revolution.\n\nThe next is Nvidia itself: Chips. Without chips, there’s nothing to use electricity and process the AI compute needed to run the AI models.\n\nHuang then highlights the third layer, which “includes financial services, because it takes an enormous amount of capital to do what we do.” His remarks highlight that AI development at scale is not only a technical challenge, but also a financial one, requiring sustained investment in data centers, networking, and long-lived computing assets.\n\nHuang then turned to the fourth layer that receives the most public attention: the models themselves. He acknowledged the prominence of well-known systems, describing how “this is where people largely focus on when they talk about AI,” citing examples such as ChatGPT, Anthropic’s Claude, Google’s Gemini, and xAI’s Grok. However, he placed those systems in a much wider context, pointing out that “those are four of the one and a half million AI models in the world.” The statement reframes popular generative models as an incredibly small subset of a far larger and more diverse ecosystem. This statement diversifies the risk away from the larger, more broadly known AI models, and instead frames Nvidia as an infrastructure play amongst a technological revolution being implemented across every industry in the world.",
    "readingTime": 3,
    "keywords": [
      "models",
      "nvidia",
      "systems",
      "revolution",
      "layer",
      "huang",
      "chatgpt",
      "technological",
      "capital",
      "energy"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-warns-195710498.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Igtx2Q0Uj7BygxF7VSpYaw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/barchart_com_477/be19911bf230a776b5d5f5aeb01b6b73",
    "created_at": "2026-01-10T06:17:35.568Z",
    "topic": "finance"
  },
  {
    "slug": "3-brilliant-ai-stocks-that-could-double-in-2026",
    "title": "3 Brilliant AI Stocks That Could Double in 2026",
    "description": "The AI investment realm is full of great opportunities in 2026.",
    "fullText": "Nebius and Applied Digital are both data center plays.\n\nSoundHound AI could see monster adoption over the next few years.\n\n10 stocks we like better than Nebius Group ›\n\nWith artificial intelligence (AI) usage skyrocketing, this sector of the market is a great place to look for stocks that could double in under a year. Many AI companies are generating explosive growth, and these are the ones to take a look at.\n\nThree, in particular, have a chance to double in value in 2026: Nebius (NASDAQ: NBIS), Applied Digital (NASDAQ: APLD), and SoundHound AI (NASDAQ: SOUN). All three are growing at a rapid pace and could provide investors with a potential doubling of returns in 2026.\n\nNebius and Applied Digital operate in similar industries. Nebius was spun out of Russian-based Yandex after sanctions from the Ukraine war devastated the business, including the non-Russian parts. Nebius is focused on providing computing power to its various clients by renting out space in a data center and placing cutting-edge graphics processing units (GPUs) in them. It also owns some of the locations it operates in.\n\nDemand for computing power has been unprecedented, and Nebius told investors that it has \"sold out\" all of its available capacity. As it expands capacity, it expects to have a $7 billion to $9 billion annual run rate (ARR) by the end of 2026. For comparison, its ARR at the end of Q3 was $551 million. That's explosive growth for a relatively small business, and I wouldn't be surprised to see the stock double in 2026 as a result.\n\nApplied Digital builds and operates data centers and has two facilities in North Dakota that it operates. It is working on increasing computing capacity at these two facilities, and is a key CoreWeave (NASDAQ: CRWV) partner. It has signed 15-year leases for many of its data centers, which gives investors a long-term look into what Applied Digital's future looks like.\n\nIn the first quarter of its fiscal year 2026, ended Aug. 31, its revenue rose about 84% year over year. As more computing capacity comes online, its revenue will jump, which could lead to outsize stock performance.\n\nLast is SoundHound AI. SoundHound AI blends generative AI and audio recognition to create a software platform that can be deployed in many applications. This is a key company to watch in 2026, as there could be a huge growth explosion if widespread adoption occurs. Several industries can be streamlined by deploying generative AI agents, such as customer service reps.\n\nIn its latest quarter, SoundHound AI's revenue jumped 68% year over year, and it raised the full-year outlook. We'll see if SoundHound AI's product gains momentum in 2026. But it could be a great year for the company and the stock.",
    "readingTime": 3,
    "keywords": [
      "explosive growth",
      "computing capacity",
      "soundhound ai's",
      "nebius and applied digital",
      "look",
      "investors",
      "operates",
      "stock",
      "revenue",
      "center"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/3-brilliant-ai-stocks-could-102000265.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/e3d_RTV3aWFw13mNpWXO_A--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02ODc-/https://media.zenfs.com/en/motleyfool.com/db0b53fc8acad71bf6d377dc41530b71",
    "created_at": "2026-01-10T06:17:34.848Z",
    "topic": "finance"
  },
  {
    "slug": "amazon-has-big-hopes-for-wearable-ai-starting-with-this-50-gadget",
    "title": "Amazon has big hopes for wearable AI – starting with this $50 gadget",
    "description": "Bee's device, which can be worn on the wrist or clipped to a shirt, records and transcribes its owner's activities.",
    "fullText": "Several months after Amazon bought artificial intelligence hardware startup Bee, the company said it’s working to make its $50 always-listening wearable more proactive, and indicated a larger revamp is in store.\n\nBee’s device, which can be worn on the wrist or clipped to a shirt, records and transcribes its owner’s activities, using that information to recap conversations and automatically create to-do lists in a companion app throughout the day.\n\nIt doesn’t have a display or built-in camera, and is designed to be “ambient AI” hardware that fades into the background without the user needing to constantly interact with it. The small gadget’s battery can last as long as a week before needing a recharge, according to the company.\n\nEarly AI-powered devices such as the Humane AI Pin and Rabbit R1 have landed with a thud, owing to issues such as bugs, poor battery life and the lack of any standout features that would make them preferable to smartphones.\n\nAmazon has a spotty history with wearables and has shown less dedication to the category compared with its tentpole Fire TV, Kindle and Echo hardware. The company discontinued its Halo health tracker wristband in 2023 and has not released a new pair of wireless earbuds in almost three years. The Halo device offered some features that have carried forward with Bee, like the ability to detect a speaker’s mood.\n\nBee is trying to chart a different path from those gadgets by acting as a comprehensive daily journal that requires no prompting or manual input. Startups like Plaud have released competing gadgets with a similar purpose.\n\nThe notion of Amazon taking ownership of an always-listening accessory has made some people wary, but the startup said it maintains stringent privacy practices.",
    "readingTime": 2,
    "keywords": [
      "amazon",
      "hardware",
      "startup",
      "always-listening",
      "device",
      "needing",
      "battery",
      "features",
      "released",
      "gadgets"
    ],
    "qualityScore": 0.85,
    "link": "https://www.seattletimes.com/business/amazon-has-big-hopes-for-wearable-ai-starting-with-this-50-gadget/",
    "thumbnail_url": "https://images.seattletimes.com/wp-content/uploads/2026/01/01092026_tzr_tzr_142059.jpg?d=1200x630",
    "created_at": "2026-01-10T00:56:40.169Z",
    "topic": "tech"
  },
  {
    "slug": "meta-signs-multigigawatt-nuclear-deals-to-power-ai-data-centers",
    "title": "Meta Signs Multi-Gigawatt Nuclear Deals to Power AI Data Centers",
    "description": "Meta Platforms Inc. agreed to a series of electricity deals to power data centers that could end up totaling more than 6 gigawatts, enough to power a city of about 5 million homes. Will Wade reports on Bloomberg Television.",
    "fullText": "Meta Signs Multi-Gigawatt Nuclear Deals to Power AI Data Centers BloombergMETA Meta Platforms Inc. agreed to a series of electricity deals to power data centers that could end up totaling more than 6 gigawatts, enough to power a city of about 5 million homes. Will Wade reports on Bloomberg Television.",
    "readingTime": 1,
    "keywords": [
      "meta",
      "deals",
      "centers"
    ],
    "qualityScore": 0.2,
    "link": "https://finance.yahoo.com/video/meta-signs-multi-gigawatt-nuclear-144646673.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/R5kWKWtvfAylSB_XAu7M9g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/bloomberg_markets_video_2/d505c5ebe53e6e5826abcb1c0ee4fa5d",
    "created_at": "2026-01-10T00:56:37.546Z",
    "topic": "finance"
  },
  {
    "slug": "8-wall-street-pros-share-their-tips-on-investing-amid-rising-ai-bubble-concerns",
    "title": "8 Wall Street pros share their tips on investing amid rising AI bubble concerns",
    "description": "Over the last couple of weeks, we've asked market pros where they fall on the AI bubble argument and how to invest accordingly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/8-wall-street-pros-tips-investing-amid-in-ai-bubble-2026-1",
    "thumbnail_url": "https://i.insider.com/6961574e832e0ef1ead78339?width=1200&format=jpeg",
    "created_at": "2026-01-10T00:56:32.775Z",
    "topic": "finance"
  },
  {
    "slug": "ram-shortages-may-lead-to-more-expensive-tvs-and-devices-warns-samsung",
    "title": "RAM Shortages May Lead To More Expensive TVs And Devices, Warns Samsung",
    "description": "The increasing demand for AI among tech companies is one of the reasons why the global shortage of memory chips remains an ongoing issue. And while it's expected to adversely affect the production of smartphones, Samsung Electronics co-CEO T M Roh has warned that TVs and home appliances may also be hit by shortages and increased prices.\n\"As this situation is unprecedented, no company is immune to its impact,\" said Roh via Reuters. According to the report, Roh noted that TVs and home appliances will also feel the pinch from the shortages and he didn't rule out price hikes to compensate for them. Samsung is the biggest manufacturer of TVs in the world, and Roh said it the impact of the RAM shortages will be \"inevitable.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/ram-shortages-may-lead-to-more-expensive-tvs-and-devices-warns-samsung/1100-6537306/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4633166-samsungtv.jpg",
    "created_at": "2026-01-10T00:56:32.383Z",
    "topic": "gaming"
  },
  {
    "slug": "brain-scanning-headsets-cool-new-controllers-ai-gaming-companions-ces-2026-roundup",
    "title": "Brain Scanning Headsets, Cool New Controllers, AI Gaming Companions: CES 2026 Roundup",
    "description": "The Consumer Electronics Show kicked off with plenty of gaming reveals from the likes of NVIDIA, Razer, LEGO, HyperX, and XReal. We round up the best and weirdest from the show.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/brain-scanning-headsets-cool-new-controllers-ai-gaming-companions-ces-2026-roundup/2300-6466635/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1574/15746725/4633178-ces2026_v1.jpg",
    "created_at": "2026-01-10T00:56:31.425Z",
    "topic": "gaming"
  },
  {
    "slug": "our-2026-video-game-industry-predictions-spot-on",
    "title": "Our 2026 Video Game Industry Predictions - Spot On",
    "description": "It's the start of the new year, so what better time to make some big and bold predictions about what 2026 will bring for us gamers. From the Steam Machine and GTA6 releases to the use of AI and component parts, there's plenty for Tam and Lucy to get through.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/videos/our-2026-video-game-industry-predictions-spot-on/2300-6466636/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1862/18620770/4633228-spoton_2026trends_20260108v3.jpg",
    "created_at": "2026-01-10T00:56:31.306Z",
    "topic": "gaming"
  },
  {
    "slug": "the-five-weirdest-ai-inventions-i-saw-at-ces-2026",
    "title": "The Five Weirdest AI Inventions I Saw at CES 2026",
    "description": "AI gadgets had to get weird to stand out at CES 2026.",
    "fullText": "AI is still the big thing in the tech world, but it's no longer the big new thing. It's been around long enough that simply integrating it into your product isn't enough to make it stand out anymore, especially at the biggest tech show in the world. While I attended this year's CES, the trend I noticed over and over again on the show floor was that AI is getting weird now. From personal hologram sidekicks to a gaming monitor that basically cheats for you, here are the five weirdest AI inventions I saw at CES 2026.\n\nAt last year's CES, gaming lifestyle company Razer introduced Project AVA, an AI esports coach concept that was just a disembodied voice that lives in your laptop. Yawn. This year, the company's expanding on that by bringing AVA into the real world.\n\nIn Razer's suite this year, I held a conversation with \"Kira,\" an anime girl \"hologram\" that lives in a little USB tube you can plug into your laptop. She noticed my orange sweater thanks to a camera installed in the tube, before asking me about the show and prompting me to start up a round of Battlefield 6, where she gave me some generic loadout advice. I spoke with her using microphones also built into her tube, and she responded using her own speaker rather than the laptop's. Razer said this demo was more directed, hence why she brought up gaming right away, but that the end goal is to let the new AVA work as a convincing all-purpose AI companion, so you don't have to use it for only play.\n\nTo that end, the company says it's \"AI agnostic,\" so you can plug your own model into it. The demo I ran through was clearly using Grok, and generally felt a lot like talking to the AI companions built into that app, right down to the cringeworthy jokes. But Razer said you could theoretically use ChatGPT or Gemini instead.\n\nWhile we were chatting, Kira played animations courtesy of Animation Inc., which powers similar but more app-driven AI companions. In other words, the chatbot and the animations aren't really new here, so what you'd be buying would be the USB tube and the characters.\n\nKira isn't your only option for an AI companion here—she's a typical anime gamer girl, but I also got to briefly look at Zane, a tattooed muscle man in the deepest V-neck I've ever seen. You can kind of see the target audience for both of these characters right away, but if you want something more tame, you can also have your tube display Razer's logo surrounded by an audio waveform, which simply goes by AVA (even though the project as a whole is still called AVA). And the company's also working on celebrity likenesses, with esports star Faker and influencer Sao having already given their approval.\n\nRazer said it's still working on figuring out how it'll distribute these characters, and I was told you'd get a bundle of them with your purchase, but would probably be able to buy more down the line.\n\nAs for pricing and availability, no word on that. This is technically still a concept, so it might go back to the drawing board again. But Razer's website does say it's hoping for a release in the second half of 2026, and that you can put $20 down now to reserve your unit.\n\nIn short, if you strip away the functionality that's already baked into apps you can download now, the new Project Ava is basically a talking hologram toy for your desk. That's still not a bad pitch, but unfortunately, I'm not sure if hologram is the right word for this. Kira looked pretty flat to me, less like that one Princess Leia projection and more like she was displaying on a normal transparent screen that just happened to be stuck inside of a cylinder. I don't think the novelty quite matches the pitch yet.\n\nWhenever I play a competitive game, instead of hopping right into a match, I instead load up into a few practice sessions to warm up. It's helpful, but time consuming. The new Neurable x HyperX concept headset is hoping to change that by helping you lock in within just a few minutes.\n\nEssentially, it looks like a normal gaming headset, but built into the earcups are various sensors that can supposedly read your focus levels. These are similar to the brain-computer interfaces you might have seen in sci-fi shows, the ones with a bunch of wires and discs attached to them, but shrunken down for the consumer market, with no creepy wires in sight.\n\nThat's where the AI comes in. Shrinking down the sensors so much does mean this headset gets fewer readings than the bigger ones in labs, but Neurable claims its models are still able to pick up on trends in those readings and translate them into useful data, while also throwing out junk data.\n\nFor gamers, that means it can run you through a quick focus exercise called \"Prime,\" where you concentrate while noticing a cloud of dots shrink into a solid orb. Once this is done, which took about 90 seconds for me, you're supposedly focused up and ready to play.\n\nUnfortunately, I actually did worse in a practice shooting game after focusing than beforehand, but that doesn't mean the data was useless. I ran through the exercise with a colleague whose score improved by maybe about a third after focusing, and with such a small sample size, there could be any number of reasons I choked after focusing up. The company said that it could even be helpful to practice choking in this way.\n\nAnd at any rate, numbers are fun. That's why I'm most excited about the headset's plug-in for streamers, which allows them to show their focus levels on screen for their chat to see. I could easily imagine a community looking at that data and teasing their favorite streamer to try to distract them.\n\nThat said, it'll be a while until you can actually buy this. It's still a concept for now, with no pricing or promise of release. However, Neurable does already have a similar, non-gaming headset made with Master & Dynamic that will be shipping out soon, just without this software. For more, read my full article here.\n\nThis one is more of a hardware innovation, but it's a clever touch. This CES, Lenovo introduced a laptop with a motorized hinge that can automatically close, open, and even rotate from side-to-side. It'll be coming out later this summer, but while the company was demonstrating the unit to me, it also showed off a prototype chatbot app it's making for it. This uses ChatGPT for now, and is still just a concept and will not ship with the laptop. But it was cute.\n\nEssentially, while I talked with the app, the laptop displayed a big pair of animated eyes on screen, and used its hinge to nod or shake its head no when I asked it questions. It also displayed small animations in response to certain questions, like showing an umbrella when I asked about the rainy weather.\n\nIt's still very early days, but I was impressed that the hardware was able to recognize what an affirmative answer was and trigger the laptop to respond accordingly. A lot of AI feels pretty disconnected from the real world, so anything that can give it a physical presence is probably a good idea if you want people to take it seriously.\n\nAlso shown off at CES this year, Lenovo's AI Frame gaming monitor is probably the most practically useful item on this list, almost to the point where it feels like cheating. Essentially, this fills up most of the 21:9 screen with a regular 16:9 view of whatever's on your computer, and uses AI to show a zoomed-in look at critical game information on the rest.\n\nFor instance, in a demo showing a MOBA game (think League of Legends), the monitor zoomed in on the map. In a demo showing Counter-Strike 2, it zoomed in on the reticle. Personally, I didn't think getting a blown-up look at the map was all that helpful, but being able to constantly see what was essentially a sniper scope around my reticle was a game changer, since it worked with any gun and made targets much easier to see.\n\nI could see Counter-Strike 2 developer Valve go as far as banning this if it ever makes its way to market, since it's taken similar actions before. But this is still just an idea for now. Still, it shows that companies are starting to figure out concrete ways AI can help you in your games, beyond just feeding you advice you probably already know.\n\nFinally, probably my favorite AI invention at CES this year was XREAL's new REAL 3D technology. Built into its newest AR glasses and already added to an existing pair via a firmware update, this uses AI to automatically find depth in any 2D video source and convert it into 3D. And trying it out for myself, it practically looked official.\n\nWhen I used it to play Mario Kart World, I would have believed you if you told me Nintendo had added this mode itself. It also worked great with James Cameron's Avatar, and there was no loading time to set it up or turn it off. There also wasn't any fuzziness, like there might be with glasses-free 3D screens like the 3DS.\n\nIt's a great option for people who like watching 3D games and movies, but might have trouble finding them now that 3D TVs and the Nintendo 3DS are mostly in the past. Now, you can just watch your existing 2D library, but in 3D.\n\nThe only issue you might come across is in content that doesn't have depth. For instance, XREAL's Ralph Jodice told me the software didn't quite know what to do when he tried playing the original 8-bit Super Mario Bros. with it, and would randomly emphasize only certain game assets without any rhyme or reason. An illusion of depth does seem to work, though. Super Mario Bros. is entirely flat, but when I tried watching the pen-and-paper animated Snow White and the Seven Dwarfs with this technology, it correctly separated characters in the foreground from scenery in the background, even though everything on screen was entirely hand-drawn.",
    "readingTime": 9,
    "keywords": [
      "super mario",
      "mario bros",
      "usb tube",
      "year's ces",
      "gaming monitor",
      "project ava",
      "laptop",
      "game",
      "concept",
      "screen"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/weirdest-ai-inventions-ces-2026?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEJ6RQ8GPVMMK8PJR454FX10/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-10T00:56:31.242Z",
    "topic": "tech"
  },
  {
    "slug": "the-simplest-way-to-build-ai-agents-in-2026",
    "title": "The simplest way to build AI agents in 2026",
    "description": "How to build personal AI agents without frameworks, infrastructure, or unnecessary complexity",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://newsletter.owainlewis.com/p/the-simplest-way-to-build-ai-agents",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!u2j_!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F473cfb04-34db-4f6d-ac2e-557fabf7ec6e_1280x720.png",
    "created_at": "2026-01-09T18:19:09.706Z",
    "topic": "tech"
  },
  {
    "slug": "adopting-ai-at-sentry-internal-email",
    "title": "Adopting AI at Sentry – \"Internal\" Email",
    "description": "If you think @Sentry isn't serious about AI, I'd recommend reading @zeeg's latest internal email about it",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/jshchnz/status/2009372836419248263",
    "thumbnail_url": "https://pbs.twimg.com/media/G-K5qKIa0AAoaW6.png:large",
    "created_at": "2026-01-09T18:19:08.359Z",
    "topic": "tech"
  },
  {
    "slug": "wef-mapped-out-4-aidriven-futures-for-jobs-by-2030-and-only-one-looks-good-for-humanity",
    "title": "WEF mapped out 4 AI-driven futures for jobs by 2030, and only one looks good for humanity",
    "description": "The World Economic Forum found that AI will reshape most jobs by 2030, with only one path limiting major displacement.",
    "fullText": "The World Economic Forum says the future of work isn't doomed by AI — but most paths forward still involve painful disruption.\n\nIn the \"Four Futures for Jobs in the New Economy: AI and Talent in 2030,\" white paper published on Wednesday, the organization laid out four scenarios based on two variables — how fast AI capabilities advance and how ready workers and institutions are to adapt.\n\nThe scenarios range from rapid AI breakthroughs to slower, more uneven progress.\n\nOnly one scenario — dubbed the \"Co-Pilot Economy\" — is explicitly designed to limit large-scale displacement.\n\nIn that future, AI adoption is widespread but measured, and workers have the skills to use the technology as a complement rather than a replacement.\n\nAs the report puts it, \"Gradual AI progress and availability of AI-ready skillsets shift the focus towards augmentation rather than mass automation.\"\n\nInstead of eliminating roles outright, AI reshapes tasks, with humans staying in the loop.\n\nEven this relatively optimistic scenario is far from static.\n\n\"Although displacement and job churn have risen, governments, businesses, and workers increasingly view AI as an opportunity rather than a threat,\" the WEF's report said.\n\nThe remaining three scenarios are more disruptive, but they differ in pace and severity.\n\nIn \"The Age of Displacement,\" AI advances faster than education and reskilling systems can respond, pushing companies to automate aggressively and leaving large parts of the workforce struggling to keep up.\n\nIn \"Stalled Progress,\" AI continues to improve, but productivity gains are patchy and concentrated among a small number of firms and regions, eroding job quality elsewhere and widening inequality.\n\nIn \"Supercharged Progress,\" explosive AI breakthroughs drive rapid economic growth and innovation — but still render many existing roles obsolete faster than new ones can emerge.\n\nHowever, some researchers caution that the future is unlikely to follow any single, clean path.\n\nJames Ransom, a research fellow at University College London, told Business Insider that AI progress and workforce readiness vary widely across industries, jobs, and regions, resulting in uneven rather than universal disruption.\n\nHe expects displacement to accelerate over the next few years — even as he said most workers are still likely to be on the payroll by 2030.\n\nThe Forum said that the future of work will not be defined by technology alone. Throughout the report, it said that policy choices, corporate strategy, and investment in skills will shape how painful — or manageable — the transition becomes.\n\nSaadia Zahidi, a managing director at the WEF, told Business Insider that the four scenarios \"are not predictions of where the world will be in 2030, but a framework to help leaders prepare for the evolving global economy.\"\n\nTech leaders and AI researchers remain split over how disruptive AI will ultimately be to the workforce.\n\nFigures like Geoffrey Hinton, often described as the \"godfather of AI,\" and Anthropic CEO Dario Amodei have warned that AI could replace large swaths of white-collar work within just a few years.\n\nOthers, including Box CEO Aaron Levie and Nvidia CEO Jensen Huang, have predicted that AI will deliver explosive productivity gains — even as it renders many existing roles obsolete.\n\nA more optimistic camp, including Microsoft AI CEO Mustafa Suleyman and Zoom CEO Eric Yuan, have said AI will ultimately augment workers.",
    "readingTime": 3,
    "keywords": [
      "productivity gains",
      "existing roles",
      "roles obsolete",
      "business insider",
      "workers",
      "scenarios",
      "displacement",
      "rather",
      "workforce",
      "painful"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wef-sees-4-ai-futures-for-jobs-by-2030-only-one-limits-disruption-2026-1",
    "thumbnail_url": "https://i.insider.com/695f9edf64858d02d217f894?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:53.014Z",
    "topic": "finance"
  },
  {
    "slug": "14-billion-ai-startup-mistral-europes-answer-to-openai-lands-french-military-deal-as-the-region-bets-on-homegrown-tech",
    "title": "$14 billion AI startup Mistral — Europe's answer to OpenAI — lands French military deal as the region bets on homegrown tech",
    "description": "France's defense ministry picked Mistral to supply military AI systems running on national infrastructure, demonstrating Europe's push for tech sovereignty.",
    "fullText": "French AI startup Mistral has secured a major vote of confidence from its home government after landing a deal to provide AI technology to France's military.\n\nFrance's Ministry of the Armed Forces said on Thursday that it has formally notified a framework agreement with Mistral AI, giving the country's armed forces, defense agencies, and affiliated public institutions access to the company's advanced AI models, software, and services.\n\nUnder the deal overseen by the ministry's defense AI agency, Mistral's AI systems will be deployed on French-controlled infrastructure, a key priority for the military as governments grow increasingly cautious about where sensitive data is processed and which laws govern it.\n\nIn a LinkedIn post announcing the deal, Mistral said its AI systems would be deployed on France's own infrastructure and fine-tuned using defense-specific data to support operational military needs.\n\nThe financial terms of the deal have not been disclosed. Mistral was not immediately available for comment when contacted by Business Insider.\n\nThe agreement marks a significant win for Mistral, which was founded in 2023 and is valued at roughly $13.6 billion, following a 1.7 billion euro ($2 billion) funding round announced last year.\n\nThe startup has positioned itself as a European alternative to US AI heavyweights, such as OpenAI, Google, and Anthropic, pitching its models as powerful yet more compatible with Europe's sovereignty and data control ambitions.\n\nIn its statement, translated by Business Insider, the defense ministry said the partnership is intended to strengthen France's \"technological sovereignty\" and ensure the armed forces maintain control over critical AI tools used across military operations and administration.\n\nBertrand Rondepierre, director of the ministry's defense AI agency, said the agreement represents \"a major step\" in strengthening the ministry's generative AI capabilities and preparing the armed forces for future challenges, while maintaining sovereign control over the technologies used.\n\nThe deal comes as European governments reassess their dependence on US technology in strategic sectors ranging from cloud computing to semiconductors and now AI.\n\nThe French ministry's move mirrors that of the US government, which has increasingly inked major contracts with domestic AI companies to develop tools for military and national security use, including recent deals with OpenAI, xAI, Anthropic, and other defense-focused startups.\n\nAs generative AI becomes increasingly embedded in military planning, logistics, and analysis, Mistral's latest win helps to position the startup as one of Europe's key players in the race to develop sovereign alternatives to American tech giants.\n\nDo you work for Mistral and have a tip or story to share? Contact this reporter via email at tspirlet@businessinsider.com or Signal at thibaultspirlet.40. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "ministry's defense",
      "military",
      "deal",
      "startup",
      "agreement",
      "increasingly",
      "technology",
      "models",
      "agency",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-startup-mistral-lands-french-military-deal-openai-of-europe-2026-1",
    "thumbnail_url": "https://i.insider.com/6960d842832e0ef1ead7765f?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.869Z",
    "topic": "finance"
  },
  {
    "slug": "ai-zealotry",
    "title": "AI Zealotry",
    "description": "Senior engineers are best positioned to benefit from AI. We're good enough to avoid slop, and there's so much we can accomplish. I wouldn't go back.",
    "fullText": "I develop with AI today. It's great.\n\nThere are many articles you can read on why AI is great (or terrible) or how to\nuse it. This is mine. I focus on the experience of a senior engineer (and why\nwe in particular should use AI), on my experience operating within the OSS\nPython Data world, and on practical suggestions that I've found myself\nrepeating to colleagues.\n\nThis article contains learned lessons of two types:\n\nWe'll interleave these two. I'm hopeful that this approach will make this more fun.\n\nAI development is more fun. I do more of what I like (think, experiment,\nwrite) and less of what I don't like (wrestle with computers).\n\nI feel both that I can move faster and operate in areas that were previously\ninaccessible to me (like frontend).\nExperienced developers should all be doing this. We're good enough to avoid AI\nSlop, and there's so much we can accomplish today.\n\nI like this quote from this blog\n\nI get it, you’re too good to vibe code. You’re a senior developer who has been doing this for 20 years and knows the system like the back of your hand.\n\nNo, you’re not too good to vibe code. In fact, you’re the only person who should be vibe coding.\n\nI think that really good engineers, the kind that think hard before writing,\ncan have a tremendous impact and fun while developing with AI. I\nwouldn't ever go back.\n\nThat being said, there are some serious costs and reasonable reservations to AI\ndevelopment. Let's start by listing those concerns:\n\nThese are super-valid concerns. They're also concerns that I suspect came\naround when we developed compilers and people stopped writing assembly by hand,\ninstead trusting programs like gcc to pump out instruction after instruction\nof shitty machine code.\n\nWe lost a deeper understanding as developers when we stopped writing assembly\nbut we gained a ton too. As in any transition, we need to navigate the\nsituation to capture the advantages while losing only a little, balancing the\ncosts and benefits of a new technology.\n\nThis article is how I've been navigating this transition personally.\n\nEarly in using Claude Code (or Cursor) many of my interactions were saying\n\"Yes, it's ok to run that\". This was frustrating and dehumanizing. Mostly my\njob was to enable AI, rather than the other way around.\n\nThere are many tricks to resolve this (see below), but more broadly \"stop doing\nsimple shit\" has been a mantra that I've found myself constantly coming\nback to. The more I identify and reject simple tasks and add automation to my\nworkflow, the higher an abstraction I'm able to climb to and the more\neffectively I'm able to work. Our goal in programming is to climb an\nabstraction ladder and gain more intellectual leverage. This requires thought\nand consistent attention.\n\nFortunately AI can help with this. If you complain and say \"I'm always doing\nX\" it'll suggest solutions like what I'll talk about below, but more tailored\nto your situation.\n\nAI developers, like human developers, benefit from structure.\n\nMost people start with an AGENTS.md or CLAUDE.md file. This is a great\nstart, but I find that the AI agent often forgets what's in there. The real\nsolution for me here (at least for Claude Code) is\nHooks.\n\nFirst, let's outline a couple of annoyingly common problems.\n\nLet's say you tell AI that you want to run tests with uv:\n\nwhen running tests, use uv run pytest tests\n\nWhile this works sometimes, AI often decides to run\n\nWhile the agents read CLAUDE.md, they don't always follow the instructions.\nAnd so you're stuck saying \"no, use uv\" over and over again. Gah.\n\nHere's a hook that catches pytest commands missing uv run. You could put\nsomething like this in ~/.claude/settings.json:\n\nThere, we've just automated that annoying task for you forever.\n\nI don't actually do this though (I allow Claude to fail and then it finds the\nright approach.) Mostly this works because I've gotten good at giving Claude\nfairly broad-yet-safe permissions, which is coming up next.\n\nEven worse, Claude often asks for permission to do things that are just\nslightly different from what you've already granted.\nYou allow uv run pytest *, but Claude keeps finding variants:\n\nClaude Code's permission language sucks. It only supports prefixes, while I\nwish it could handle regexes, or maybe even just arbitrary Python code.\n\nI have a complex Python script as a hook which overrides the permission\nsystem. It uses regexes, but also arbitrary Python code as logic. This allows\nme to encode arbitrary combinations of rules. It's great.\n\nOn the rare occasion when Claude asks me for permission for something new, I\nhave a running Claude agent that thinks about this file and considers if it\nshould update the permission script.\n\nMy personal favorite hooks though are these:\n\nThey play subtle little sounds whenever Claude is either done, or needs input\nfrom me. This lets me ignore Claude when it's busy. Previously I found that I\nwas constantly checking back in with Claude to see if it was done, and that\naction was dehumanizing, so I automated it by asking Claude to play a sound.\n\nHooks are great. There are more ways to provide structure (Skills, Commands)\nbut I've found that Hooks are the most dependable, a great starting place, and\noften augment any other structure that I put in place (like Skills).\n\nIn a recent large AI-assisted PR a frustrated reviewer said the following:\n\nTo me, this [size of PR] implies that either\n\nIt's a valid problem, even in single-person projects. We're able to generate\ncode far more quickly than we're able to read it. How should we handle\nreview? Everyone needs to figure this out for themselves, but my answer is\n\"find other ways to build confidence\".\n\nWe already do this today with human-written code. I review some code very\nclosely, and other code less-so. Sometimes I rely on a combination of tests,\nfamiliarity of a well-known author, and a quick glance at the code to before\nsaying \"sure, seems fine\" and pressing the green button. I might also ask\n\"Have you thought of X\" and see what they say.\n\nTrusting code without reading all of it isn't new, we're just now in a state\nwhere we need to review 10x more code, and so we need to get much better at\nestablishing confidence that something works without paying human attention all\nthe time.\n\nWe can augment our ability to write code with AI. We can augment our ability\nto review code with AI too.\n\nMostly I establish confidence on AI-generated work by investing heavily in\ntests and benchmarks, the same as I would with humans, just moreso. TDD is\nbaked into most of the prompting structure I have with agents.\n\nRemember that this is way cheaper than it used to be. Now rather than write a\nbenchmark I can type\n\nHow does this compare in performance to the old version? I'm particularly\ninterested in memory use.\n\nAnd that's it. If it's bad, the agent will say so (and then diligently work to\nmake it good).\n\nAdditionally, if I'm nervous about something subtle like \"Is it possible this change\nmight unexpectedly affect performance in this other feature?\" then I'll ask the\nAI exactly that question:\n\nIs it possible this change might unexpectedly affect performance in this other feature?\n\nAnd it'll just go and investigate exactly that question. Unlike human authors,\nthe AI has no ego at stake in its work, and isn't in the least bit lazy. It's\nour job to ask \"Have you thought of X\" and its job to go learn if that might\nbe an issue. Don't trust its answer? Ask it to prove it to you.\n\nAI has flaws, but it is diligent, and it lacks ego. If you question it, it'll\ninvestigate thoroughly and critique its own work honestly.\n\nLet's review our work and see if there is anything we can simplify or clean up\n\nBefore Opus 4.5 came out this was essential. Now it's merely nice. I've\nturned this into a /cleanup command and integrated it into most of my Skills\nas a final phase in development.\n\nFrom time to time I also ask a fresh agent to do a full review of the project,\nwith an eye to cleaning up technical debt. I tell it to review everything and\nthink hard. It takes a while, but it often comes back with a nice list of work\nfor itself, which it then of course diligently performs.\n\nAI creates technical debt, but it can clean some of it up too.\n(at least at a certain granularity)\n\nIn general we want to give our agents good automated feedback. Tests do this,\nbenchmarks do this, prompting them to assess themselves does this, asking them\nto explain things to us and have us weigh in on high level topics does this.\n\nLLMs are smart enough today that if they're given enough of the right feedback\nthey converge to a good solution as-well-or-better-than a senior human engineer\n(that's my experience at least).\n\nOur job is to construct a system that gives them the right feedback at the\nright time, hopefully without our intervention. This is the same job we have\nwhen we build human teams; now it's just more impactful to do well.\n\nI started AI development with Cursor. It was great having the AI experience\ninside a VSCode-like editor, where I could see everything that was going on.\nWhen I saw terminal-based tools like Claude Code I thought \"whoa, that doesn't\nseem sensible, I need to see what's going on\".\n\nToday I code with Claude Code, git diff, and occasionally vim. I don't\nfeel a need to OK every change in the diff. I've got more important\nthings to do. I suspect that you do too.\n\nI deeply respect the philosophical position of Python, which I'll state as\nfollows:\n\nPrioritize human performance over compute performance.\n\nspace more broadly and more quickly, finding much better solutions, making\nthat 100x drop in performance negligible.\n\nPython was a bold bet, and a bet that paid off amazingly well. No one expected\nthis silly dynamic language originally designed for education to become the\nworld's juggernaut in performance software.\n\nWith AI though, the usability benefits of Python no longer apply as strongly,\nand we're more free to choose different ecosystems.\n\nRegarding TypeScript, I still love easy interaction tools like rich and\ntextual, but when the entire React ecosystem is a sentence away and when you\nget to use things like, you know, fonts, there's really no comparison. Every\ncomputational developer should learn the concepts underpinning React (or some\nother frontend framework), and we should put dashboards on everything.\n\nOf course, I still hook into Python for the ecosystem. Everything is\nPython-importable and I still use the protocols and design patterns developed\n\ncode or the language; those will die. Rest in peace dear friend.\n\nAs an introductory project, I rewrote Numpy in Rust.\nIt was great fun.\n\nIt was also much easier than I expected (I expected it to be impossible).\nIt was easy for a few reasons (good test suite, well-reasoned abstractions) but\nmostly it was because:\n\nNEPs: Numpy's Enhancement Proposals / design documentation is thorough and extremely clear.\n\nWhen sticky problems arose, we were able to rely on the Numpy design documents\n(NEPs) which are excellent.\n\nThe Numpy team thought hard and wrote clearly, two hallmarks of\nexcellent developers. This made the job of reimplementation relatively trivial.\nThe Numpy development community is famous for doing this well. To a certain\nextent, we should all start operating more like the Numpy community.\n\nI keep two directories in each repository:\n\nPlans end up being very useful during development, while docs end\nup being useful to point other agents to in the future. Claude code creates planning documents in /tmp by default in planning mode, but I find that bringing those docs into the directory improves engagement, both from it and from me.\n\nDocs end up being tricky. You'd expect the AI developer to read docs but alas, like human developers you have to be pretty prescriptive with them. Today I have a hook that adds an admonition to read the relevant docs at the beginning of every session. It looks like this:\n\nI then keep docs/README.md updated as a sort of index over my documents. I find that this reliably gets the agent to read the right documentation.\n\nI've also found that my normal writing style (brutal concision + front-loading important content to maintain attention span) isn't necessary with AI. You really can just shove information at them and they absorb it. It's nice 🙂\n\nHistorically software engineers had to both think well and execute well.\nWe were valued both because we could zoom out and consider the impacts of our\narchitecture, and because we could zoom in and implement those choices with\nskill.\n\nOur ability to zoom in and implement code is now obsolete. Our ability to zoom\nout and think well is not. On the contrary, our ability to think well is now\n10x more valuable than it was before, because implementation is now mostly\nfree.\n\nAnd so it's now more important than ever to hone our craft of thought. This\nprobably means less caffeine and more walks through the park.\n\nThe craft of authoring code has transformed time and time again during our\nlives. We remember when object-oriented was cool, or when TDD became a thing,\nor reactive programming models, or dynamic typing languages, or ML, or ...\n\nAs programmers we've opted into a system which changes by its very nature.\nOur job is to automate our job, and to continuously climb the ladder of\nabstraction. AI programming is another step in that evolution, similar to when\ncompilers came about. The code we write with AI probably won't be as good as\nhand-crafted code, but we'll write 10x more of it, and we'll build systems of\nsystems to make it robust and trustworthy, and all of that will make society\nbetter and our jobs way more fun.\n\nI'm looking forward to having way more fun.\n\nAfter writing this a couple friends asked me for a copy of my regex/Python code\nthat replaces Claude's permission system. I'll include it below, but really,\nyou don't need it. Instead, you need to start a conversation with Claude about\nwhat you want and it'll make one just for you.\n\nCode is free these days. Extending the \"AI is like Compilers\" analogy, asking\nfor someone else's script is kind of like asking for someone else's compiled\nbinary. There's no need; just make it yourself. It's trivial.\n\nHere was my original prompt to Claude Code:\n\nI recently wrote this reddit post\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1puqrvc/claude_code_annoyingly_asking_for_permissions/\n\nI'm wondering if you have any suggestions on how to resolve this? Adding stuff to CLAUDE.md or permissions to settings.json doesn't seem to be working well enough.\n\nThat, along with subsequent conversation as I've been working, resulted in\nthis Python script\n\nBut really, you're better off working with Claude to make one just for you.\nCode is free now.",
    "readingTime": 13,
    "keywords": [
      "arbitrary python",
      "python script",
      "unexpectedly affect",
      "technical debt",
      "someone else's",
      "affect performance",
      "claude code",
      "permission system",
      "human developers",
      "vibe code"
    ],
    "qualityScore": 1,
    "link": "https://matthewrocklin.com/ai-zealotry/",
    "thumbnail_url": "https://matthewrocklin.com/assets/images/social/ai-zealotry.png",
    "created_at": "2026-01-09T18:18:52.796Z",
    "topic": "tech"
  },
  {
    "slug": "x-makes-groks-ai-image-tool-a-premium-service-after-backlash-against-sexualized-deepfakes",
    "title": "X makes Grok's AI image tool a premium service after backlash against sexualized deepfakes",
    "description": "Only paying X subscribers can now use Grok to edit images on the social media site after it came under significant backlash over sexualized imagery.",
    "fullText": "Elon Musk's Grok has limited its AI image generation tool to paying subscribers following widespread backlash about its use to create nonconsensual sexualized images on X of real people, including minors.\n\nMusk and xAI, the company that developed Grok, have faced threats and condemnation from governments around the world after the AI tool was used to digitally alter images of people — mainly women — to remove their clothes and put them in sexualized positions.\n\n\"Image generation and editing are currently limited to paying subscribers,\" Grok now replies when tagged with image editing requests on X.\n\nIt means that the majority of users on the social media platform can no longer create images using Grok, and those who do would have their name and payment information on file.\n\nHowever, those who are not paying X subscribers can continue to use Grok to edit images on its stand-alone app and website.\n\nOn Friday, a spokesperson for Britain's Prime Minister, Keir Starmer, told reporters that the move \"simply turns an AI feature that allows the creation of unlawful images into a premium service.\"\n\nWhen asked for comment, xAI sent an automatic email response that did not address the issue.\n\nIn late December, some X users started tagging Grok on the social media site and asking it to digitally undress people in photos. The AI tool honored those requests, putting the subjects in bikinis or underwear, and maneuvering their bodies into sexualized positions. Some of the people in the images were minors.\n\nAs more of the AI-generated images flooded the social media site, governments and regulators in the UK, EU, Italy, India, and elsewhere publicly threatened or took action against X and xAI.\n\nStarmer called Grok's sexualized deepfakes \"disgraceful\" and \"unlawful\" in an interview with Greatest Hits Radio this week.\n\nOn January 3, Musk responded to the backlash for the first time, writing in an X post that, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"\n\nThe official X page also pointed users to its policy page, which states it has \"zero tolerance for any forms of child sexual exploitation\" and that it removes \"certain media depicting physical child abuse.\"\n\nOn Monday, the UK's communications regulator, Ofcom, told Business Insider that it has \"made urgent contact with X and xAI to understand what steps they have taken to comply with their legal duties to protect users in the UK.\"\n\nIn the US, the Take It Down Act protects against nonconsensual deepfakes, though its domain depends on age and body parts shown. Some states have also passed stricter laws about the spread of deepfakes.",
    "readingTime": 3,
    "keywords": [
      "illegal content",
      "sexualized positions",
      "social media",
      "media site",
      "images",
      "users",
      "tool",
      "subscribers",
      "deepfakes",
      "grok"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/xai-limits-grok-ai-image-tool-sexualized-deepfake-backlash-2026-1",
    "thumbnail_url": "https://i.insider.com/6960f2e204eda4732f2ec3ec?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.738Z",
    "topic": "finance"
  },
  {
    "slug": "metas-latest-deal-to-power-its-ai-ambitions-is-sending-nuclear-stocks-soaring",
    "title": "Meta's latest deal to power its AI ambitions is sending nuclear stocks soaring",
    "description": "Meta Platforms announced a deal with Oklo, Vista, and TerraPower to power its AI buildout. Nuclear energy stocks surged on the news.",
    "fullText": "Meta Platforms is turning to nuclear power to drive its AI ambitions, and its latest deal with a trio of companies is sending stocks in the sector soaring.\n\nThe tech giant revealed that it signed an agreement with several companies to help supply nuclear power for its data centers, including the massive Prometheus AI supercluster being built in New Albany, Ohio. The one gigawatt facility is expected to come online later this year.\n\nThe three companies that will help power it are Oklo, Vistra Corp, and privately held TerraPower. Both nuclear power stocks surged on news of the Meta deal, sparking momentum for many of their peers as well.\n\nHere are the big moves in the space on Friday:\n\nThis isn't the first nuclear power deal that Meta has inked. Last summer, it announced a similar agreement with Constellation Energy, which saw its shares spike on the news.\n\n\"State-of-the-art data centers and AI infrastructure are essential to securing America's position as a global leader in AI,\" said Joel Kaplan, chief of global affairs at Meta. \"Nuclear energy will help power our AI future, strengthen our country's energy infrastructure, and provide clean, reliable electricity for everyone.\"\n\nBig tech's support of nuclear energy has risen in recent years as experts have touted the need for alternative sources of power to enable the AI buildout. Oklo is backed by OpenAI CEO Sam Altman, though he stepped down from his position as chairman of its board of directors in August 2025.\n\n\"Two years ago, Oklo shared its vision to build a new generation of advanced nuclear powerhouses in Ohio,\" Oklo CEO Jacob DeWitte said. \"Today, that vision is becoming a reality through the support of a multi-year effort with Meta.\"",
    "readingTime": 2,
    "keywords": [
      "nuclear energy",
      "deal",
      "stocks",
      "agreement",
      "centers",
      "infrastructure",
      "position",
      "vision",
      "meta",
      "oklo"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/oklo-stock-price-meta-ai-nuclear-power-deal-vst-ceg-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.436Z",
    "topic": "finance"
  },
  {
    "slug": "one-eyepopping-prediction-shows-why-copper-prices-could-continue-to-surge-for-years-to-come",
    "title": "One eye-popping prediction shows why copper prices could continue to surge for years to come",
    "description": "An analysis from S&P Global predicts that the AI boom will drive demand higher for years at a time when supply is expected to remain constrained.",
    "fullText": "Copper joined the mega rally in precious and industrial metals in 2025, but the gains might be far from over if recent forecasts for supply and demand prove correct.\n\nCopper ended 2025 with a gain of about 44%, and touched a fresh all-time high this week. Yet, the AI boom might be the key to another 15 years of surging demand at a time when supply is expected to remain constrained.\n\nS&P Global recently published an analysis of the copper market, predicting that demand is likely to increase by 50% by 2040, reaching 42 million metric tons. The report also said that it will be extremely difficult for the mining industry to keep up as companies struggle with aging mines and regulatory hurdles.\n\nThe authors predict that, without new mines or technological advancements, copper production will peak in 2030, leaving the world short of roughly 10 million metric tons by 2040.\n\n\"Several countries have deemed copper a 'critical metal' over the past half decade, including, in 2025, the United States. And with good reason,\" said Carlos Pascual, Senior Vice President, Geopolitics and International Affairs, at S&P Global Energy. \"Copper is the connective artery linking physical machinery, digital intelligence, mobility, infrastructure, communication and security systems.\"\n\nCopper benefited from a broad rush into metals last year that also pushed gold and silver to record highs. Some forecasters have said they think prices for all three metals are likely to decline in the near future as market conditions shift, but copper's industrial importance could continue to buoy it.\n\nJosé Torres, chief economist at Interactive Brokers, said he thinks copper's global strategic importance means prices will remain elevated.\n\n\"Broadly, it has to do with limited supply as nations want to stockpile the cyclical metal to bolster sovereign AI prospects,\" he told Business Insider. \"Governments are afraid that without enough copper, their economies won't remain competitive in a world where advanced technology is increasingly adopted.\"\n\nRita Adiani, president and CEO of rare earth mining company Titan Mining Corporation, believes that a surge in demand, as predicted by S&P, would lead to a period of higher prices.\n\n\"A significant part of the incremental demand is tied to electrification, grid build, data centers/AI and defense, where copper's conductivity and reliability makes substitution harder in critical applications.\"",
    "readingTime": 2,
    "keywords": [
      "metric tons",
      "demand",
      "metals",
      "supply",
      "copper's",
      "copper",
      "industrial",
      "market",
      "mines",
      "without"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/copper-price-record-high-demand-supply-prediction-ai-data-centers-2026-1",
    "thumbnail_url": "https://i.insider.com/69612aae64858d02d2180faa?width=1200&format=jpeg",
    "created_at": "2026-01-09T18:18:52.006Z",
    "topic": "finance"
  },
  {
    "slug": "no-10-condemns-insulting-move-by-x-to-restrict-grok-ai-image-tool",
    "title": "No 10 condemns ‘insulting’ move by X to restrict Grok AI image tool",
    "description": "Spokesperson says limiting access to paying subscribers just makes ability to generate unlawful images a premium...",
    "fullText": "Spokesperson says limiting access to paying subscribers just makes ability to generate unlawful images a premium service\n\nDowning Street has condemned the move by X to restrict its AI image creation tool to paying subscribers as insulting, saying it simply made the ability to generate explicit and unlawful images a premium service.\n\nThere has been widespread anger after the image tool for Grok, the AI element of X, was used to manipulate thousands of images of women and sometimes children to remove their clothing or put them in sexual positions.\n\nGrok announced in a post on X, which is owned by Elon Musk, that the ability to generate and edit images would be “limited to paying subscribers”. Those who pay have to provide personal details, meaning they could be identified if the function was misused.\n\nAsked about the change, a Downing Street spokesperson said it was unacceptable. “The move simply turns an AI feature that allows the creation of unlawful images into a premium service,” they said.\n\n“It’s not a solution. In fact, it’s insulting to victims of misogyny and sexual violence. What it does prove is that X can move swiftly when it wants to do so. You heard the prime minister yesterday. He was abundantly clear that X needs to act, and needs to act now. It is time for X to grip this issue.\n\n“If another media company had billboards in town centres showing unlawful images, it would act immediately to take them down or face public backlash.”\n\nAsked if No 10 was going to take any further action, such as leaving X, the spokesperson said “all options are on the table”, and that it would support any action taken by Ofcom, the UK’s media regulator.\n\nSpeaking earlier on Friday, Anna Turley, the Labour party chair and a minister without portfolio in the Cabinet Office, said there was no move as yet for the government to leave X, but individual ministers were considering doing so.\n\nShe told BBC Radio 4’s Today programme: “It’s really, really important that we tackle this. Those conversations are ongoing across government. I think all of us in politics are evaluating our use of social media and how we do that, and I know that conversation is happening.”\n\nAsked if she would leave the site, Turley said: “I’ve thought about that a lot over the past few months.” Asked whether the Labour party would do so, she said: “Those conversations are taking place because it’s really important that we make sure that we’re in a safe space.”\n\nThe victim’s commissioner, Claire Waxman, said X was no longer a “safe space” for victims and her office was considering scaling back its presence on the site and focusing its communications on Instagram.\n\n“It makes the battle against violence against women and girls much harder when platforms such as X are enabling abuse on such an easy and regular basis,” Waxman said, adding that the platform was having a negative impact on its users’ mental health because of the proliferation of violence, abuse and race hate.\n\n“Why is that material not being taken down and those users being stopped?” she asked. “It is not safeguarding its users.” Waxman said she was concerned about Ofcom’s ability to police platforms such as X effectively. “Does Ofcom have the teeth to be able to really deal with these sorts of issues? That is a concern for me.”\n\nThere has been an exodus of women’s sector organisations from X. The domestic abuse charity Refuge left the site, as has Women’s Aid Ireland and Victim Support. Victim Support left in April, saying it was “no longer the right place for us to communicate with our audiences”. Women’s Aid Ireland said the decision was taken because of “increased levels of unchecked hate, misogyny, racism and anti-LGBTI+ content on the platform”.\n\nEmma Pickering, the head of technology at Refuge, said the decision by X to restrict access to the image tool for Grok to paying subscribers amounted to “the monetisation of abuse”.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 5,
    "keywords": [
      "labour party",
      "aid ireland",
      "women’s aid",
      "guardian app",
      "safe space",
      "premium service",
      "unlawful images",
      "downing street",
      "subscribers",
      "ability"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/09/no-10-condemns-move-by-x-to-restrict-grok-ai-image-creation-tool-as-insulting",
    "thumbnail_url": "https://i.guim.co.uk/img/media/9eed52bcccc9b2621ffb52657bdd17f06c35aa8b/82_0_3083_2467/master/3083.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=bf841a1968aa93e771b8caf333a557c3",
    "created_at": "2026-01-09T18:18:51.449Z",
    "topic": "tech"
  },
  {
    "slug": "research-conventional-cybersecurity-wont-protect-your-ai",
    "title": "Research: Conventional Cybersecurity Won’t Protect Your AI",
    "description": "As AI embeds itself into every corner of business, most executives continue to underestimate the distinct security risks these systems pose. Legacy defenses, designed for rule-based software, cannot safeguard gen AI systems that learn and adapt from data. By combining survey data, executive interviews, and lab analysis, new research reveals systemic gaps: fragile supply chains, opaque vendor services, and an acute shortage of AI-security talent. The implications are clear. Leaders must move beyond patching applications and instead harden the infrastructure and supply chains on which AI depends, while harnessing AI itself as a front-line defense to ensure resilience.",
    "fullText": "Research: Conventional Cybersecurity Won’t Protect Your AI by Hugo HuangJanuary 9, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintIn June 2025, researchers uncovered a vulnerability that exposed sensitive Microsoft 365 Copilot data without any user interaction. Unlike conventional breaches that hinge on phishing or user error, this exploit, now known as EchoLeak, bypassed human behavior entirely, silently extracting confidential information by manipulating how Copilot interacts with user data. The incident highlights a sobering reality: Today’s security models, which are designed for predictable software systems and application-layer defenses, are ill-equipped to handle the dynamic, interconnected nature of AI infrastructure.",
    "readingTime": 1,
    "keywords": [
      "user",
      "conventional",
      "copilot"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/ts-research-conventional-cybersecurity-wont-protect-your-ai",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_09_139555442.jpg",
    "created_at": "2026-01-09T18:18:51.011Z",
    "topic": "science"
  },
  {
    "slug": "these-popular-chrome-extensions-are-stealing-your-ai-chats",
    "title": "These Popular Chrome Extensions Are Stealing Your AI Chats",
    "description": "Hackers continue to find ways to sneak malicious extensions into the Chrome web store.",
    "fullText": "Hackers continue to find ways to sneak malicious extensions into the Chrome web store—this time, the two offenders are impersonating an add-on that allows users to have conversations with ChatGPT and DeepSeek while on other websites and exfiltrating the data to threat actors' servers.\n\nOn the surface, the two extensions identified by Ox Security researchers look pretty benign. The first, named \"Chat GPT for Chrome with GPT-5, Claude Sonnet & DeepSeek AI,\" has a Featured badge and 2.7K ratings with over 600,000 users. \"AI Sidebar with Deepseek, ChatGPT, Claude and more\" appears verified and has 2.2K ratings with 300,000 users.\n\nHowever, these add-ons are actually sending AI chatbot conversations and browsing data directly to threat actors' servers. This means that hackers have access to plenty of sensitive information that users share with ChatGPT and DeepSeek as well as URLs from Chrome tabs, search queries, session tokens, user IDs, and authentication data. Any of this can be used to conduct identity theft, phishing campaigns, and even corporate espionage.\n\nResearchers found that the extensions impersonate legitimate Chrome add-ons developed by AITOPIA that add a sidebar to any website with the ability to chat with popular LLMs. The malicious capabilities stem from a request for consent for “anonymous, non-identifiable analytics data.\" Threat actors are using Lovable, a web development platform, to host privacy policies and infrastructure, obscuring their processes.\n\nResearchers also found that if you uninstalled one of the extensions, the other would open in a new tab in an attempt to trick users into installing that one instead.\n\nIf you've added AI-related extensions to Chrome, go to chrome://extensions/ and look for the malicious impersonators. Hit Remove if you find them. As of this writing, the extensions identified by Ox no longer appear in the Chrome Web Store.\n\nAs I've written about before, malicious extensions occasionally evade detection and gain approval from browser libraries by posing as legitimate add-ons, even earning \"Featured\" and \"Verified\" tags. Some threat actors playing the long game will convert extensions to malware several years after launch. This means you can't blindly trust ratings and reviews, even if they've been accrued over time.\n\nTo minimize risk, you should always vet browser extensions carefully (even those that appear legit) for obvious red flags, like misspellings in the description and a large number of positive reviews accumulated in a short time. Head to Google or Reddit to see if anyone has identified the add-on as malicious or found any issues with the developer or source. Make sure you're downloading the right extension—threat actors often try to confuse users with names that appear similar to popular add-ons.\n\nFinally, you should regularly audit your extensions and remove those that aren't essential. Go to chrome://extensions/ to see everything you have installed.",
    "readingTime": 3,
    "keywords": [
      "chrome web",
      "threat actors",
      "actors servers",
      "extensions identified",
      "malicious extensions",
      "chatgpt and deepseek",
      "users",
      "add-ons",
      "ratings",
      "hackers"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/chrome-extension-stealing-ai-chats?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEF38R9Z7WSA2ND991PT9G9G/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-09T18:18:50.054Z",
    "topic": "tech"
  },
  {
    "slug": "larian-studios-draws-harder-line-on-ai-clarifies-stance-in-reddit-ama",
    "title": "Larian Studios Draws Harder Line On AI, Clarifies Stance In Reddit AMA",
    "description": "Larian Studios CEO Swen Vincke, as well as creative directors, recently participated in an AMA on Reddit to set expectations for the studio’s upcoming Divinity game, particularly about its stance on generative AI--a hot-button topic in the industry right now. Responding to a fan question about the role of generative AI in game development, Vincke was rather blunt: \"There is not going to be any GenAI art in Divinity.\"\nHis comments arrive amid wider debate over how and whether AI should be used in creative processes, especially as some high-profile games have faced backlash for such use. One notable example is Clair Obscur: Expedition 33, the acclaimed RPG that had two Indie Game Awards (including Game of the Year and Debut Game) rescinded when it was revealed the title had included AI-generated assets during development, violating strict no-AI rules--even though those assets were patched out later.\nIn the AMA, Vincke acknowledged that previous discussions about experimenting with AI tools for concept-art had been confusing.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/larian-studios-draws-harder-line-on-ai-clarifies-stance-in-reddit-ama/1100-6537296/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1597/15976769/4633018-q9vfkyv8bi8rbajqea7zwm.jpg",
    "created_at": "2026-01-09T18:18:48.682Z",
    "topic": "gaming"
  },
  {
    "slug": "manor-lords-publisher-has-banned-ai-assets-in-its-games-calls-them-cancerous",
    "title": "Manor Lords Publisher Has Banned AI Assets In Its Games, Calls Them \"Cancerous\"",
    "description": "The publisher behind strategy games Endless Legend 2, Terra Invicta, and Against the Storm has officially banned the use of AI-generated assets in all its products. Hooded Horse has had a significant presence in the strategy game space over the last few years, thanks to hits like Manor Lords. Now, when many publishers and developers are evaluating (or touting) their relationship to generative AI, Hooded Horse is rebuking its use for art generation.\nHooded Horse CEO Tim Bender discussed the ban in an interview with Kotaku, emphasizing that restrictions on AI art are part of every contract Hooded Horse signs. He said, \"It is now written into our contracts if we’re publishing the game, 'no f**king AI assets.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/manor-lords-publisher-has-banned-ai-assets-in-its-games-called-them-cancerous/1100-6537300/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1690/16904437/4633066-manorlords.jpg",
    "created_at": "2026-01-09T18:18:48.546Z",
    "topic": "gaming"
  },
  {
    "slug": "tonguefu-a-gamified-voicefirst-app-for-practicing-verbal-communication",
    "title": "TongueFu – A gamified voice-first app for practicing verbal communication",
    "description": "AI-powered conversational training. Master quick thinking, creative debates, and verbal sparring through gamified exercises with AI sensei characters.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://tonguefu.app",
    "thumbnail_url": "https://tongfu.qligence.capital/og-image.png",
    "created_at": "2026-01-09T12:24:07.454Z",
    "topic": "tech"
  },
  {
    "slug": "shallowcircuit-supervised-learning-on-a-quantum-processor",
    "title": "Shallow-Circuit Supervised Learning on a Quantum Processor",
    "description": "Quantum computing has long promised transformative advances in data analysis, yet practical quantum machine learning has remained elusive due to fundamental obstacles such as a steep quantum cost for the loading of classical data and poor trainability of many quantum machine learning algorithms designed for near-term quantum hardware. In this work, we show that one can overcome these obstacles by using a linear Hamiltonian-based machine learning method which provides a compact quantum representation of classical data via ground state problems for k-local Hamiltonians. We use the recent sample-based Krylov quantum diagonalization method to compute low-energy states of the data Hamiltonians, whose parameters are trained to express classical datasets through local gradients. We demonstrate the efficacy and scalability of the methods by performing experiments on benchmark datasets using up to 50 qubits of an IBM Heron quantum processor.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.03235",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-09T12:24:07.331Z",
    "topic": "tech"
  },
  {
    "slug": "simplemem-efficient-lifelong-memory-for-llm-agents",
    "title": "SimpleMem: Efficient Lifelong Memory for LLM Agents",
    "description": "SimpleMem: Efficient Lifelong Memory for LLM Agents - aiming-lab/SimpleMem",
    "fullText": "aiming-lab\n\n /\n\n SimpleMem\n\n Public\n\n SimpleMem: Efficient Lifelong Memory for LLM Agents\n\n 333\n stars\n\n 45\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aiming-lab/SimpleMem",
    "readingTime": 1,
    "keywords": [
      "simplemem"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/aiming-lab/SimpleMem",
    "thumbnail_url": "https://opengraph.githubassets.com/5428f2ae9bdbb778e26fb50b1ea1fe861817d86d914267ce45ac5008a3fcc90d/aiming-lab/SimpleMem",
    "created_at": "2026-01-09T12:24:05.796Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-is-both-the-problem-and-the-cure-for-legacy-code",
    "title": "Why AI is both the problem and the cure for legacy code",
    "description": "AI may be the key to cracking legacy code.",
    "fullText": "Why AI is both the problem and the cure for legacy code \n\n AI may be the key to cracking legacy code.\n\n By\n\n Alex Jukes\n\n January 08, 2026\n\n About the author\n\n Alex Jukes\n\n Fractional CTO and strategic technical advisor working with innovative UK startups.",
    "readingTime": 1,
    "keywords": [
      "alex jukes",
      "legacy code"
    ],
    "qualityScore": 0.4,
    "link": "https://leaddev.com/ai/why-ai-both-problem-cure-legacy-code",
    "thumbnail_url": "https://leaddev.com/wp-content/uploads/2025/10/trojan-horse-office-01-02.png",
    "created_at": "2026-01-09T12:24:05.361Z",
    "topic": "tech"
  },
  {
    "slug": "cursors-most-important-ai-features-started-as-side-projects-engineers-built-themselves-says-its-engineering-head",
    "title": "Cursor's most important AI features started as side projects engineers built themselves, says its engineering head",
    "description": "Some of Cursor's biggest AI features didn't start on a roadmap. They were bottom-up projects built by its engineers, says Jason Ginsberg.",
    "fullText": "Some of Cursor's most important AI features didn't come from a formal road map. One was built over Thanksgiving, says its engineering head.\n\nJason Ginsberg said in an episode of the \"LangChain\" podcast published Thursday that a bottom-up approach has shaped several of Cursor's core capabilities.\n\nGinsberg said he built a debugging feature over the Thanksgiving holiday simply because he wanted it and to \"help people on the team.\" The AI-coding company has since launched its \"Debug Mode.\"\n\n\"If there's internal adoption, that's kind of our metric for this is ready to ship,\" he said.\n\nThe same pattern applies to Cursor's agent, now one of its defining features. Ginsberg said it was originally prototyped by a single engineer, as others on the team were skeptical.\n\n\"He prototyped it super quickly, and everyone's like, 'Oh wow, this works,'\" Ginsberg said.\n\nCursor still maintains short-term roadmaps, but many of its biggest features emerge organically, Ginsberg said.\n\nHe also said there isn't much formal process at Cursor. Instead of debating product changes in documents or alignment meetings, engineers resolve disagreements through code.\n\nCursor is among the most prominent AI companies being built by a tiny team.\n\nGinsberg said on the podcast that Cursor had about 20 people at the start of 2025.\n\n\"That was because the process to hiring people was very slow and the bar was extremely, extremely high,\" he said.\n\nThat talent-dense structure allows Cursor to operate with minimal organizational process and move quickly, he added.\n\nThe preference for small, elite teams has become increasingly influential across the AI industry, including at Big Tech firms traditionally known for scale.\n\nMeta's superintelligence AI unit, for example, is led by a small group of top researchers. The AI unit comprises a tiny fraction of the company's headcount of over 70,000 employees.\n\n\"I've just gotten a little bit more convinced around the ability for small, talent-dense teams to be the optimal configuration for driving frontier research,\" Mark Zuckerberg said on Meta's earnings call in July.\n\nOpenAI CEO Sam Altman said last year that \"we're going to see 10-person companies with billion-dollar valuations pretty soon.\"\n\nBusiness Insider in May compiled a list of the highest-valued AI startups around the world with teams of 50 employees or fewer, according to PitchBook data.",
    "readingTime": 2,
    "keywords": [
      "features",
      "team",
      "process",
      "teams",
      "formal",
      "thanksgiving",
      "podcast",
      "prototyped",
      "quickly",
      "tiny"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cursor-ai-features-side-projects-jason-ginsberg-engineering-head-2026-1",
    "thumbnail_url": "https://i.insider.com/696093a104eda4732f2ec314?width=1200&format=jpeg",
    "created_at": "2026-01-09T12:24:03.317Z",
    "topic": "finance"
  },
  {
    "slug": "history-says-the-stock-market-could-soar-in-2026-here-is-1-cheap-artificial-intelligence-semiconductor-stock-to-buy",
    "title": "History Says the Stock Market Could Soar in 2026. Here Is 1 Cheap Artificial Intelligence Semiconductor Stock to Buy Right Now",
    "description": "Taiwan Semiconductor Manufacturing stock seems poised for another year of strong gains.",
    "fullText": "The higher spending on AI chips is going to be a tailwind for TSMC stock in 2026.\n\nIts earnings are likely to grow at a faster pace than Wall Street's expectations this year.\n\nTSMC's attractive valuation and strong earnings potential suggest that it could soar nicely.\n\n10 stocks we like better than Taiwan Semiconductor Manufacturing ›\n\nThe S&P 500 has been in a bull market for more than three years now, entering this territory in October 2022, and the good news is that the index is expected to sustain its rally in 2026 as well.\n\nAfter recording three consecutive years of double-digit gains, a feat that the index has achieved five times since it came into existence in 1957, Wall Street is looking forward to another year of robust growth in the S&P 500. Deutsche Bank, for instance, expects the S&P 500 to hit 8,000 points by the end of 2026, suggesting potential gains of 15% from current levels.\n\nAdditionally, financial services firm Carson Group's chief market strategist Ryan Detrick points out that once a bull market is three years old, it tends to stretch up to eight years on average, citing data going back to 1950. All this indicates that 2026 could turn out to be another good year for the stock market, and artificial intelligence (AI) is set to play a key role in driving more gains this year.\n\nJPMorgan points out that strong capital spending and earnings growth fueled by AI are going to be a catalyst for stocks in 2026. That's why now is a good time to take a closer look at a key company that's playing a central role in driving AI adoption -- Taiwan Semiconductor Manufacturing (NYSE: TSM) -- before the stock market heads higher in the new year.\n\nTaiwan Semiconductor is the world's largest semiconductor foundry, manufacturing chips for all the leading chip designers and consumer electronics companies. That explains why it has been growing at a healthy pace in the past couple of years. TSMC's share of the foundry market stood at an incredible 72% in the third quarter of 2025, according to Counterpoint Research. Its fabrication plants that produce advanced chips for customers, such as Nvidia, Qualcomm, Broadcom, Apple, Sony, Advanced Micro Devices, and others, are reportedly running at full capacity.\n\nThis isn't surprising as the cutting-edge nature of TSMC's advanced manufacturing nodes means that chip designers are able to pack in more transistors into a smaller area on chips fabricated by the Taiwan-based giant. As a result, TSMC-made chips are both powerful and power-efficient, making them ideal for various applications, including data centers, smartphones, and personal computers (PCs).Deloitte estimates that $250 billion to $300 billion could be spent on AI data center chips alone this year, up from an estimated $150 billion last year.",
    "readingTime": 3,
    "keywords": [
      "semiconductor manufacturing",
      "chip designers",
      "bull market",
      "stock market",
      "chips",
      "earnings",
      "tsmc's",
      "gains",
      "points",
      "advanced"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/history-says-stock-market-could-195000468.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uS_1DytIcc84pp1injsyDg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MjA-/https://media.zenfs.com/en/motleyfool.com/13d37ebdc567c486649094d2e721757f",
    "created_at": "2026-01-09T12:24:02.916Z",
    "topic": "finance"
  },
  {
    "slug": "4-googlers-share-how-they-reinvented-their-careers-and-pivoted-to-ai",
    "title": "4 Googlers share how they reinvented their careers and pivoted to AI",
    "description": "Each of these four Google employees took different paths to pivot into AI, but all of them spent roughly a year preparing for the transition.",
    "fullText": "Pivoting to an AI job may be trendy, but that doesn't mean it's an easy feat.\n\nAs AI-related jobs continue to pop up, and companies invest heavily in upskilling, more workers are looking to add \"AI\" to their job titles.\n\nTo see how it can be done, Business Insider spoke with four Google employees who transitioned to AI teams. While each followed a different path, all of them spent roughly a year building the necessary skills to land new roles — and for some, the transition took several years.\n\nFrom participating in employee hackathons to becoming AI content creators, the four employees share how they made the shift:\n\nEmrick Donadei said he didn't feel qualified to pivot to an AI team until he participated in Google's seven-day employee hackathon in 2024. The 32-year-old engineer said he didn't create a revolutionary product, but it gave him hands-on experience with tools, and something tangible he could use to start conversations with teams across the company. \n\nRoughly 10 months after his first hackathon, he said he landed his new role.\n\nWhile the hackathon kick-started his transition, his work didn't stop there. The Googler continued to experiment with tools outside the hackathon, he said. He also created a podcast about AI developments and watched Andrej Karpathy's YouTube videos to get up to speed with machine learning concepts and anything related to LLMs.\n\nAfter finding a new role, Donadei said that he participated in another hackathon in 2025, which opened up even more opportunities. He had the opportunity to transition into AI research, began working part-time on open-source committees and with AI research teams, and published a public technical disclosure with Google as a follow-up to his work.\n\nMaitri Mangal, 27, worked as a traditional software engineer before transitioning to an AI team. During the roughly year-long period she took to prepare for the pivot, Mangal dedicated roughly two hours daily toward up-skilling, and still spends hours learning weekly, she said.\n\nShe said that creating social media content was a way for her to reinforce the material that she learned through Google's internal training and other online courses.\n\n\"That really, for me, changed everything,\" Mangal said about content creation.\n\nShe said seeing that her content helped other people motivated her to continue learning about the technology and making videos. Even though she already changed jobs, she said she still spends about an hour daily learning new information, whether that's in the form of internal trainings for her job, or watching YouTube courses to prepare for content.\n\nRahul Kasanagottu, 32, spent two and a half years transitioning to an AI role at the tech giant. He said his paternity leave gave him a head start on reading about AI.\n\nIn addition to reading 11 books on the topic, Kasanagottu also took a Deep Learning Specialization course taught by Andrew Ng, and watched 3Blue1Brown videos on YouTube.\n\nSimilar to Donadei, Kasanagottu said solo projects were a key part of his career transition. He said it was difficult to convince hiring managers he could do the job without having demos and hands-on projects to show. While the books he read typically didn't come with assignments, the courses had a lot of hands-on exercises, Kasanagottu said.\n\nMilica Cvetkovic took a different path than the other three Googlers who made internal pivots to AI teams. She landed a role in AI consulting at the tech giant about three years ago, after completing graduate school and conducting research in machine learning.\n\nAfter she received her Master's in statistics, she worked as a machine-learning engineer at a Madison-based startup and simultaneously taught machine-learning boot camps and college-level courses.\n\n\"Having a skill to talk in a nontechnical way is probably the most valuable skill that I bring,\" Cvetkovic said.\n\nHer move to an AI team at Google was less of a deliberate pivot and more the result of the right opportunity aligning with her background and interests. She said that she realized she didn't want to code anymore, and that's when she came across a consulting role at Google.\n\nCvetkovic said she can't name one single experience that led to her getting the job. Rather, she compared her career journey to training for a marathon. A marathon, she said, is the \"celebration of all the work that you've done.\"\n\n\"That's literally what my application was. It was just very good fit,\" Cvetkovic said.\n\nDid you transition to an AI role? We want to hear from you. Reach out to the reporter via email at aaltchek@insider.com or through the secure-messaging app Signal at aalt.19.",
    "readingTime": 4,
    "keywords": [
      "tech giant",
      "machine learning",
      "role",
      "transition",
      "content",
      "didn't",
      "hackathon",
      "teams",
      "roughly",
      "courses"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/googlers-share-transition-to-ai-roles-2026-1",
    "thumbnail_url": "https://i.insider.com/6960299564858d02d218064b?width=1200&format=jpeg",
    "created_at": "2026-01-09T12:24:02.898Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-chatgpt-which-cryptocurrency-will-make-you-rich-in-2026-the-answer-was-surprising",
    "title": "I Asked ChatGPT Which Cryptocurrency Will Make You Rich in 2026 — The Answer Was Surprising",
    "description": "I asked ChatGPT to break it down for me, given the state of crypto. It made clear that its answer is \"a structured way to think about the opportunity and risk.\"",
    "fullText": "Cryptocurrency is either touted as the next big thing to make you rich or the riskiest investment ever. Yet despite its volatility and constant controversy, many investors continue to find ways to profit in the crypto space.\n\nIf someone realistically wanted to get rich via cryptocurrency in 2026, which one is most likely to make that possible, and how? I asked ChatGPT to break it down for me, given the current state of crypto. It made clear that its answer does not constitute financial advice, but rather “a structured way to think about the opportunity and risk.”\n\nChatGPT took a realistic look at what “getting rich” actually means in the crypto space. It was clear that it doesn’t mean “guaranteed 100% returns by New Year,” as the crypto market is extremely volatile, risky and speculative.\n\nRealistic goals might look like a 5% to 10% return on your core position — the main portion of your crypto portfolio held in more established assets like bitcoin or ethereum that you plan to keep long term. You might also see a larger potential return on a smaller “moonshot” allocation — a high-risk, high-reward investment in a newer or less proven coin that could spike in value but could just as easily wipe out, too.\n\nAnalysts place wide predictions even on the giants. For example, bitcoin (BTC) is forecasted to be valued between $100,000 and $200,000 in 2026.\n\nFind Out: 13 Cheap Cryptocurrencies With the Highest Potential Upside for You\n\nRead Next: 9 Low-Effort Ways To Make Passive Income (You Can Start This Week)\n\nBased on current expert commentary and fundamentals, ChatGPT said there are two categories of coins with the best shot at making you rich across two strategies.\n\nUnsurprisingly, bitcoin (BTC), the most well-known coin, remains the leading choice. Many forecasts assume it will stay dominant. However, ethereum (ETH), the runner-up, is seen as more utility-based, and some analysts believe it may outperform BTC in certain phases.\n\nIn either case, these coins are less about “getting rich quick” and more about a reasonable chance of strong returns at moderate risk, the AI said.\n\nSome investors are turning to altcoins — smaller cryptocurrencies outside of bitcoin and ethereum — that could see bigger short-term gains. Coins like XRP and Solana are getting attention for their performance potential, though they come with higher risk, ChatGPT noted. Even newer projects, especially those combining AI and blockchain, promise sky-high returns, but most are highly speculative. Forecasts of 500% profits make headlines, but in reality, very few ever deliver.",
    "readingTime": 3,
    "keywords": [
      "risk chatgpt",
      "bitcoin btc",
      "crypto space",
      "rich",
      "returns",
      "ethereum",
      "potential",
      "coins",
      "cryptocurrency",
      "either"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asked-chatgpt-cryptocurrency-rich-2026-141005190.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uX_rux7fJMsKqrVtki_sOA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02Nzc-/https://media.zenfs.com/en/gobankingrates_644/23356af9c4dff4e9e0db193ddf011349",
    "created_at": "2026-01-09T12:24:02.729Z",
    "topic": "finance"
  },
  {
    "slug": "google-is-unleashing-gemini-ai-features-on-gmail-users-will-have-to-opt-out",
    "title": "Google is unleashing Gemini AI features on Gmail. Users will have to opt out",
    "description": "Google is adding more Gemini features to Gmail, the company's latest effort to spread its core AI product across its product portfolio.",
    "fullText": "Google is adding more Gemini features to Gmail, providing upgrades like artificial intelligence-generated summaries of email threads, the company said Thursday.\n\nThe company said its latest updates will be rolled out in phases, and some features will be turned on by default in inboxes, meaning users who don't want them will have to opt out.\n\n\"When you open an email with dozens of replies, Gmail synthesizes the entire conversation into a concise summary of key points,\" Google wrote in a blog post.\n\nThe company said AI Overviews, which show up at the top of search results, are also being added to Gmail.\n\nThe updates come as Google embeds its Gemini AI technology across its wide portfolio of consumer products. Google is counting on its massive customer base to provide an advantage as the company takes on the likes of OpenAI, Anthropic and others in the booming generative AI market.\n\nGoogle says Gmail now has more than 3 billion users.\n\nLast year, Google's Gemini integration in Gmail allowed users to do things like search messages, draft emails from prompts, improve grammar and generate custom responses.\n\nOne of the new features is \"Suggested Replies,\" which Google says uses the context of a user's emails to create one-click responses. It's an update to a prior tool called \"Smart Replies.\" The company is also upgrading a proofreading option for checking grammar and making messages more concise.\n\nDriven by its rapid advancements in AI, Google parent Alphabet topped Apple by market cap on Wednesday for the first time since 2019, continuing a rally that made the stock the best performer among tech megacaps last year. Meanwhile, OpenAI soared to a private market valuation of $500 billion late last year, and Anthropic said Wednesday that it's valued at $350 billion in a new funding round.\n\n— CNBC's MacKenzie Sigalos contributed to this report.\n\nWATCH: How Gemini is gaining ground on ChatGPT",
    "readingTime": 2,
    "keywords": [
      "features",
      "users",
      "market",
      "google",
      "email",
      "updates",
      "concise",
      "search",
      "messages",
      "emails"
    ],
    "qualityScore": 0.85,
    "link": "https://www.cnbc.com/2026/01/08/google-adds-gemini-features-to-gmail-message-summaries-proofreading-.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/106199081-1571858526194gettyimages-887454120.jpeg?v=1767831513&w=1920&h=1080",
    "created_at": "2026-01-09T06:19:46.840Z",
    "topic": "tech"
  },
  {
    "slug": "aifirst-screen-recorder-to-create-videos-in-perfect-english",
    "title": "AI-first screen recorder to create videos in perfect English",
    "description": "AI screen recorder that translates your voice",
    "fullText": "Speak in your native language and instantly create\nprofessional screen recordings in perfect English.\n\nLet AI automatically translate your screen recording into perfect English in minutes.\n\nDownload the Wizardly chrome extension to generate your first professional screen recording.\n\nLaunch the chrome extension and record your screen as you naturally would in your native language.\n\nWizardly automatically turns your recording into a professional screen recording in perfect English.\n\nWizardly offers powerful features to generate high-impact videos with ease.\n\nRecord using the language you're most comfortable with and let Wizardly turn it into a polished English video in minutes.\n\nDon't worry about mistakes. Wizardly removes uhs, ums and bad takes to create a professional script in minutes.\n\nWizardly generates videos with native accents. We replace your voice with a professional voice over for perfect video narration.\n\nEdit the flow and rewrite the script. Easily update the content to create the perfect video and match your design guidelines.\n\nChoose from a variety of different voices to create videos that fit with your tone and branding.\n\nDownload your videos in HD, embed them anywhere, or share them instantly with your team and customers.\n\nEffortlessly promote your content by instantly translating among 14 languages.\n\nWizardly offers live translation in 🇬🇧 English, 🇪🇸 Spanish, 🇫🇷 French, 🇩🇪 German, 🇮🇹 Italian, 🇷🇺 Russian, 🇳🇱 Dutch, 🇵🇱 Polish, 🇵🇹 Portuguese, 🇹🇷 Turkish, 🇺🇦 Ukrainian, 🇯🇵 Japanese, 🇮🇩 Indonesian, and 🇪🇸 Catalan.\n\nChoose your recording language and desired output language with just a few clicks. Create professional screen recordings in any language combination on the fly.\n\nNot translating? No problem. Use Wizardly to upgrade your recordings to the same language. Wizardly automatically improves clarity, refines phrasing, and removes filler words.\n\nCustomers choose Wizardly to create professional-grade screen recordings.\n\nGlobal teams & founders create professional videos for support, sales, and marketing.\n\nGet started for free, no credit card required.\n\nStill have questions? Reach out to us.\n\nJoin some of the fastest growing startups using Wizardly.",
    "readingTime": 2,
    "keywords": [
      "perfect english",
      "chrome extension",
      "wizardly automatically",
      "screen recordings",
      "native language",
      "screen recording",
      "create professional",
      "videos",
      "instantly",
      "minutes"
    ],
    "qualityScore": 1,
    "link": "https://trywizardly.com/",
    "thumbnail_url": "https://trywizardly.com/images/wizardly_social_banner.png",
    "created_at": "2026-01-09T06:19:46.504Z",
    "topic": "tech"
  },
  {
    "slug": "metas-reality-labs-chief-is-calling-the-most-important-meeting-of-the-year-urging-employees-to-show-up-in-person",
    "title": "Meta's Reality Labs chief is calling the 'most important' meeting of the year, urging employees to show up in person",
    "description": "Meta CTO Andrew Bosworth calls key all-hands meeting at Reality Labs as the division faces budget cuts, strategic shifts to AI, and layoffs last year.",
    "fullText": "Meta's Chief Technology Officer and head of Reality Labs, Andrew Bosworth, has called an all-hands meeting for January 14, describing it as the \"most important\" of the year.\n\nBosworth is also strongly recommending that Reality Labs employees attend the division's meeting in person, two Meta employees told Business Insider.\n\nThe emphasis on in-person attendance is unusual for the division, which oversees the company's wearables, virtual and augmented reality initiatives, and a nascent robotics unit, these employees said. Some managers have told employees to \"drop what they're doing\" to attend the all-hands in person, one employee told Business Insider.\n\nMeta did not immediately respond to a request for comment about the meeting.\n\nWhile the division has seen some success, such as its Ray-Ban smart glasses, Reality Labs has been a costly venture for Meta, incurring losses of more than $70 billion since 2020.\n\nLast year, Meta CEO Mark Zuckerberg shifted the company's strategic focus toward AI and away from the metaverse. In 2025, Meta invested $14.3 billion in Scale AI and hired its CEO, Alexandr Wang, as part of the major reset of the company's AI efforts. Meta then embarked on a multibillion-dollar hiring spree, poaching top-tier AI researchers and engineers from rivals such as OpenAI and Google DeepMind.\n\nReality Labs has faced repeated rounds of cuts over the past year. In December, Business Insider reported that Meta was planning budget cuts up to 30% and considering job cuts in Reality Labs.\n\nLast April, Meta laid off employees in Oculus Studios, its in-house gaming division, and the team behind Supernatural, the VR fitness app Meta acquired for over $400 million. Those cuts followed Meta's broader January 2025 layoffs that eliminated nearly 4,000 roles companywide, with at least 560 affecting Reality Labs employees.\n\nIn a memo obtained by Business Insider earlier last year, Bosworth referred to 2025 as \"the most critical\" year in his eight-year tenure at Reality Labs.\n\n\"This year likely determines whether this entire effort will go down as the work of visionaries or a legendary misadventure,\" he wrote.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "labs employees",
      "reality labs",
      "cuts",
      "division",
      "company's",
      "meta",
      "all-hands",
      "january",
      "attend",
      "email"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-cto-andrew-bosworth-reality-labs-all-hands-meeting-2026-1",
    "thumbnail_url": "https://i.insider.com/69605e5b64858d02d2180829?width=1200&format=jpeg",
    "created_at": "2026-01-09T06:19:45.146Z",
    "topic": "finance"
  },
  {
    "slug": "why-i-wont-be-giving-chatgpt-health-my-medical-records",
    "title": "Why I Won't Be Giving ChatGPT Health My Medical Records",
    "description": "OpenAI  invites you to hand over your medical information. Maybe don't?",
    "fullText": "This week, OpenAI announced its new ChatGPT Health feature, which will let users upload their medical records and ask health related questions. However, I certainly won't be making use of it, it might not be the best idea for you to do it either, for both reliability and privacy reasons.\n\nThe new ChatGPT Health feature will be a sandboxed tab inside the app that is isolated from your conversation history in other conversations with the chatbot. This tab also allows users to connect a variety of health-tracking apps like Apple Health, MyFitnessPal, and Peloton, as well as uploading medical records directly.\n\nIt's important to note that this is a lot of really personal information to hand over to any tech company—but especially one that isn't primarily focused on providing medical services. OpenAI says that the ChatGPT Health space operates with \"enhanced privacy to protect sensitive data,\" but it doesn't use end-to-end encryption to secure that data. And while the company says data collected via Health isn't used to train its foundation models, it's impossible to know whether that may change in the future. Security breaches can also occur (and have in the past), potentially leaving your medical records exposed.\n\nThere's also the question of whether the risk of uploading your data is worth it in the first place. According to OpenAI's own data, around 5% of all messages to ChatGPT are already users asking questions about their health, and ChatGPT (and other LLM tools) have a nasty habit of providing inaccurate diagnostic information. This is perhaps why OpenAI says that its new ChatGPT Health feature is \"not intended for diagnosis or treatment.\"\n\nCurrently, there's a waitlist to At the very least, that means that until the feature is available, it's probably a good idea not to ask the regular version of ChatGPT about your health concerns. At the very least, wait until the enhanced privacy sandbox is available. In the meantime, consider whether it makes more sense to just talk to your doctor directly if you have questions or concerns about your health.",
    "readingTime": 2,
    "keywords": [
      "health feature",
      "enhanced privacy",
      "medical records",
      "chatgpt health",
      "openai",
      "users",
      "it's",
      "idea",
      "uploading",
      "directly"
    ],
    "qualityScore": 0.9,
    "link": "https://lifehacker.com/tech/dont-give-chatgpt-health-your-medical-records?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEFGNJDCMT3JTWC4A7YNJXZ3/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-09T00:58:41.714Z",
    "topic": "tech"
  }
]
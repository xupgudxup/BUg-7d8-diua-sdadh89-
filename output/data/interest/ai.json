[
  {
    "slug": "ai-predictions-for-2026-a-devops-engineers-guide",
    "title": "AI Predictions for 2026: A DevOps Engineer's Guide",
    "description": "AI predictions for 2026 and what they mean for DevOps engineers. From agent orchestration to local AI breakthroughs, here's how to prepare your infrastructure.",
    "fullText": "Posted on Thursday, Dec 11, 2025\n\nThe IDE is dying, and so is tool calling. OpenAI is not going to win. And next year, you’re going to be shipping code that you’ve never reviewed before, even as an experienced engineer.\n\nThese are bold claims, but the way we use AI in 2026 for coding and agents is going to look completely different. In this post, I want to cover my predictions and why they matter right now for DevOps engineers. Some of these are definitely hot takes, but that’s what makes this conversation worth having.\n\nTraditional IDEs where the code is the focus of the interface are simply going to become irrelevant. We’re moving toward agent manager interfaces where we can kick off agents in parallel to work on different features in a codebase or even work on different projects at the exact same time.\n\nWe’re already seeing this transition. Google Antigravity combines a familiar AI-powered coding experience with a new agent-first interface. You can deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Cursor 2.0 lets you run up to eight agents in parallel on a single prompt, using git worktrees or remote machines to prevent file conflicts. Each agent operates in its own isolated copy of your codebase.\n\nAWS validated this direction at re:Invent 2025 by announcing “frontier agents” including Kiro for autonomous coding, along with dedicated security and DevOps agents. These agents maintain state, log actions, operate with policy guardrails, and integrate directly with CI/CD pipelines.\n\nFor infrastructure specifically, Pulumi Neo represents this same shift. Instead of writing code or running CLI commands for every operation, you describe what you need in natural language and Neo handles the implementation. It works across your entire infrastructure, understanding dependencies and creating execution plans that go through pull requests for review.\n\nFor DevOps engineers, this means your pipelines need to accommodate AI-generated code at scale. Multiple agents working simultaneously need isolated, reproducible environments. More generated code means more artifacts to track, version, and deploy.\n\nA lot of people think that in the future a single large language model is going to have a monopoly and be the best at absolutely everything. But what’s really going to happen is different providers will specialize and focus on being the best at different things.\n\nGoogle is going down the generalist play with Gemini, aiming to be the jack of all trades. Anthropic is focusing on being the best for coding. You can see this in the benchmarks: when Opus 4.5 came out, the first benchmark they highlighted was for software engineering, because that’s what Anthropic is focusing on.\n\nAmazon is carving out its own niche with the Nova model family, announced at re:Invent 2025. The Nova 2 lineup includes specialized models: Pro for complex reasoning, Sonic for real-time voice conversations, and Omni for simultaneous text, audio, and video processing. With Nova Forge, organizations can build custom frontier models by combining their proprietary data with AWS open weight models. The re:Invent message was clear: leveraging your first-party data is now fundamental to going beyond generic AI. We’re talking about 30-40% increases in accuracy when you bring your own data into the equation.\n\nBut here’s the hot take: I don’t think OpenAI is going to come out on top with any kind of specialization. They’ve disappointed time and time again with GPT-5 and GPT-4.5. With 4.5, they seemed to try to be the creative specialist, but it just didn’t work. The GPT-5 launch in August 2025 was described as “barely better than last month’s flavor of the month” and on some metrics it’s actually worse than earlier models.\n\nFor DevOps teams, this specialization means you’ll need infrastructure that’s model-agnostic and supports multiple AI backends. Plan for secrets management across multiple LLM providers and design your systems to swap models based on the task at hand.\n\n2026 is going to be the year of local AI. We didn’t see that much this year besides DeepSeek at the start of 2025, which was a big deal. We had a couple of new models like Qwen 3, but nothing that fundamentally changed the game. Now we’re starting to see new hardware that makes it obvious we’re going to be able to run very large models on smaller devices.\n\nThere’s new AI chips that can run upwards of 120 billion parameter large language models on the edge, which would be a complete game-changer. Right now, hardware requirements are one of the biggest problems when it comes to scaling local AI. If we can solve the hardware problem, we get 100% data privacy and zero-millisecond latency for our agents.\n\nAWS is addressing this with Trainium3 UltraServers, their 3nm AI chips delivering 4.4x more compute than the previous generation. More significantly, AWS AI Factories allow organizations to deploy racks of Trainium chips and NVIDIA GPUs directly into their own data centers, addressing data sovereignty concerns while keeping AI inference close to the data.\n\nFor DevOps, this opens possibilities for zero-latency inference in CI/CD pipelines, complete data privacy for sensitive codebases, and reduced cloud costs for AI-heavy workloads.\n\nWe’re finally going to get to the point where we’re not the coders. We delegate that entirely to our coding agents and we become the system architects. This mirrors the evolution of other engineering disciplines. Civil engineers don’t fabricate the steel beams; they design the structure and verify the integrity.\n\nI think of this as a three-step process:\n\nWe’re still in the loop. We are the final say in whatever is created, but we’re delegating the grunt work to our coding agents.\n\nThis is exactly the model that Pulumi Neo implements for infrastructure. When you give Neo a complex request, it creates a task plan outlining the steps it will take to accomplish your goal. This plan provides transparency into Neo’s approach and gives you the opportunity to adjust the strategy before execution begins. Neo operates in different modes: Review mode where everything requires approval, Balanced mode where only deployments need sign-off, or Auto mode for full autonomy. You define the boundaries, Neo orchestrates the work, and you validate through pull requests and previews.\n\nFor DevOps engineers, this shift means building robust validation infrastructure becomes critical. When AI writes the code, you need automated testing pipelines, security scanning, and verification systems that can operate at the speed of AI-generated changes.\n\nHere’s a key insight that kept coming up at re:Invent: models are no longer the bottleneck. Context is. Our agents are going to change a lot next year because code execution is starting to replace tool calling. The problem with tool calling right now is that all the capabilities you give an agent take up context upfront. When you try to give a lot of different tools to an agent, you completely overwhelm it.\n\nAnthropic’s research on code execution with MCP addresses exactly this problem. Code execution is a massive token reduction, faster, and more flexible. You’re giving the agent the ability to generate its own capabilities at runtime by writing code to interact with APIs. A workflow that previously consumed about 150,000 tokens when tools were passed directly through the model was reimplemented with code execution and used only about 2,000 tokens. That’s a 98.7% reduction.\n\nAWS embraced this pattern with Amazon Bedrock AgentCore, which now includes code interpretation capabilities. AgentCore supports any agent framework (CrewAI, LangGraph, OpenAI SDK) and provides memory, browser tools, and observability features that make code execution practical at enterprise scale.\n\nFor DevOps, this means you need sandboxed, secure execution environments for AI-generated code. Running agent-generated code requires appropriate isolation, resource limits, and monitoring.\n\nThe best part about code execution flexibility is it unlocks progressive disclosure. All I mean by that is: you have a lot of capabilities for an agent, but you don’t actually give all of them upfront. Instead, you allow the agent to discover capabilities and then leverage them in a more flexible way.\n\nFor each capability, you just have a bit of metadata or description that loads upfront. When the agent decides to leverage that capability, then you load the full instructions. Now you can practically scale to infinity because all capabilities don’t have to be loaded at runtime.\n\nClaude Skills is a good example of this pattern. Skills are organized folders of instructions, scripts, and resources that agents can discover and load dynamically. At session start, the agent scans available skills and populates the system prompt with just a brief name and description (around 100 tokens). The full skill prompt loads only after Claude selects it, preventing context bloat while maintaining discoverability.\n\nKiro Powers addresses the same problem. Connecting five MCP servers can consume over 50,000 tokens, roughly 40% of an AI model’s context window, before you even type your first request. Powers bundle MCP servers, steering files, and hooks into units that load dynamically based on conversation context. Mention “payment” and the Stripe power activates. Datadog, Figma, and others have powers available.\n\nFor DevOps, this translates to modular infrastructure definitions, on-demand capability loading, and efficient resource utilization. Think about how you can apply this pattern to your own automation.\n\nAgent-to-agent protocols are where AI agents operate in a peer network, discover each other’s capabilities in real time, and interact autonomously. When Google released their A2A protocol earlier this year, there was a ton of buzz. A lot of people thought it was going to be the next big standard, like the next MCP. But then it kind of fell to the wayside.\n\nThe big reason is the chicken-and-egg problem. In order for A2A to be useful, you need a lot of people to adopt it at the same time. Otherwise, if you build an A2A-compatible agent, it has no other agents to talk to. The whole value proposition is lost unless you already have a big network to attach to.\n\nBut that’s finally changing. The Linux Foundation launched the A2A project in June 2025, and adoption is accelerating. Adobe, Microsoft, SAP, ServiceNow, and S&P Global are all implementing A2A. In July 2025, Google released version 0.3 of the A2A protocol with a more stable interface critical to accelerating enterprise adoption.\n\nMy next big prediction is that machines paying machines is going to become a very big thing. Coinbase released the x402 protocol for exactly this: building AI agents that you expose over the internet but require payment whenever someone else interacts with them.\n\nThis goes really well with agent-to-agent protocols. You can create a peer network where you monetize your agents. They all leverage each other but make payments whenever they take advantage of another agent’s capabilities. Cryptocurrency is the perfect solution for this kind of machine-to-machine network because you need a currency where it’s easy to do micropayments quickly and globally.\n\nThe x402 protocol has achieved 156,000 weekly transactions with 492% growth since launching in May 2025. It’s now integrated with Anthropic’s MCP Protocol, Google Gemini, OpenAI Codex, and other platforms. Stablecoins like USDC make it possible to charge per request, per service, or per second of usage with near-zero transaction costs, enabling payments as low as $0.001 per request.\n\nWhen we want to do a rigorous code review traditionally, we look line by line at all the changes. But coding agents are getting to the point where they can prove their code works through artifacts. Instead of reviewing line by line, we can look at browser recordings, full working demos of a backend API, and other artifacts.\n\nGoogle Antigravity is a perfect example. As part of its coding process, it can autonomously spin up your website, visit it, scroll through it, take screenshots, and record everything. Agents generate artifacts, including tangible deliverables like task lists, implementation plans, screenshots, and browser recordings. You can verify the agent’s logic at a glance.\n\nAmazon Nova Act takes this further. It enables AI agents to automate browser-based tasks like form filling, QA testing, and workflow validation with over 90% reliability. The service includes built-in observability through live viewing, CloudTrail logging, and session replay, making it possible to review what an agent actually did rather than parsing through code changes.\n\nFor the last prediction, we’re tying everything together. We’ve talked about reviewing artifacts instead of diffs, creating systems instead of coding, and the new capabilities for agents with code execution.\n\nWe’re going to get to the point very quickly where we’re shipping code that we have never read before. And I’m not talking about people who vibe code. Even experienced engineers are going to trust their systems so much that they have the ability to review the code but they’re not going to. We’re just going to ship to production after reviewing the artifacts.\n\nI presented on this exact topic at the Tel Aviv Pulumi User Group meetup at Qodo HQ back in October, where I demonstrated how Pulumi Neo’s autonomous decision-making capabilities can handle infrastructure tasks that we traditionally managed manually. Qodo is doing fascinating work in this space with their agentic development tools, building systems that let you trust the output without necessarily reviewing every line.\n\nI’m not saying we’re taking the human completely out of the loop. I’m saying we’re going to have a lot of trust in our systems and a validation process that includes us, but that doesn’t necessarily have to be us actually looking at the code. Tools like Pulumi Neo create pull requests with clear documentation of changes, run previews to validate infrastructure modifications, and provide the transparency needed to ship with confidence.\n\nThe predictions I’ve outlined point to a fundamental shift in how software gets built and deployed. For DevOps engineers, this isn’t a threat but an opportunity to become more strategic and less operational. We’re entering the battle of the agentic frameworks, where the winners will be those who can build faster, cheaper agentic applications through their platforms.\n\nThe immediate reality is that your CI/CD pipelines need to accommodate AI-generated code at scale, your secrets management needs to handle multiple LLM providers, and your execution environments need proper sandboxing for agent-generated code. These aren’t future concerns; they’re requirements for working effectively with the AI tools available today.\n\nLooking further out, the engineers who thrive will be those who embrace the system architect role. Define clear objectives and constraints for your AI agents. Build validation frameworks that can verify outcomes without requiring line-by-line code review. Design infrastructure that’s modular enough to load capabilities on demand.\n\nThe technology to make this happen already exists. Agent orchestration platforms are shipping. Code execution is replacing tool calling. Progressive disclosure patterns are proven. The question isn’t whether these changes are coming; it’s whether you’ll be ready when they arrive.\n\nIf you want to experience what this future looks like right now, Pulumi Neo is the place to start. Neo lets you make natural language requests for routine infrastructure tasks, analysis, and management. Instead of writing code for every operation, you describe what you need and Neo handles the implementation, creating task plans, running previews, and opening pull requests for your review.\n\nWhether you’re looking to update outdated resources across your infrastructure, analyze your cloud spend, or automate complex multi-step workflows, Neo provides the agent-first experience that’s defining the next generation of DevOps tooling.\n\nGet started with Pulumi Neo and see how AI-powered infrastructure automation can transform your workflow.",
    "readingTime": 13,
    "keywords": [
      "llm providers",
      "accommodate ai-generated",
      "ci/cd pipelines",
      "mcp servers",
      "google released",
      "neo handles",
      "a2a protocol",
      "devops engineers",
      "artifacts instead",
      "for devops"
    ],
    "qualityScore": 1,
    "link": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/",
    "thumbnail_url": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/meta.png",
    "created_at": "2025-12-11T13:53:40.763Z",
    "topic": "tech"
  },
  {
    "slug": "the-abundance-paradox-why-netflixs-acquisition-makes-sense-in-the-era-of-ai",
    "title": "The Abundance Paradox: Why Netflix's Acquisition Makes Sense in the Era of AI",
    "description": "The Abundance Paradox: Why Netflix’s $82B Acquisition Makes Sense in the Era of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/Konstantine/status/1998512521385488841",
    "thumbnail_url": "https://pbs.twimg.com/media/G7wkWdxaQAAeio1.jpg:large",
    "created_at": "2025-12-11T13:53:40.525Z",
    "topic": "tech"
  },
  {
    "slug": "slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations",
    "title": "SLB partners with Shell to develop AI solutions for energy operations",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations-93CH-4403467",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/international_newspapers_108x81.jpg",
    "created_at": "2025-12-11T13:53:38.207Z",
    "topic": "finance"
  },
  {
    "slug": "when-ai-takes-the-tasks-managers-take-the-relationships",
    "title": "When AI takes the tasks, managers take the relationships",
    "description": "Leaders say agents should handle the busywork so human managers can be more connected to their teams.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/when-ai-takes-the-tasks-managers-take-the-relationships/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974174223_1f91a177fa_6k-e1765458447816.jpg?resize=1200,600",
    "created_at": "2025-12-11T13:53:36.502Z",
    "topic": "business"
  },
  {
    "slug": "openais-house-of-cards-seems-primed-to-collapse",
    "title": "OpenAI's house of cards seems primed to collapse",
    "description": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.",
    "fullText": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.\n\nBack in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo.\n\nBut it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy.\n\nSince then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.\n\nIn response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss.\n\nIt's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI.\n\nAnthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Informationsaid Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings.\n\nHowever, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI.\n\nAccording to a December 2 report from TheWall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic.\n\nThe few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator.\n\nMore importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year.\n\nIn an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.\n\nSince late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well.\n\n\"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.\n\nGita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels.\n\nThe modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment.",
    "readingTime": 6,
    "keywords": [
      "code red",
      "search giant",
      "openai",
      "chatbot",
      "model",
      "models",
      "memory",
      "release",
      "google",
      "released"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/chatgpt/article/openais-house-cards-seems-primed-170000383.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/GqARrc67JCVOPZqPZmGxVA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/engadget_703/4fd0cc3b2f10735e6ff000f551d8a08e",
    "created_at": "2025-12-11T13:53:36.420Z",
    "topic": "tech"
  },
  {
    "slug": "an-openai-exec-identifies-3-jobs-on-the-cusp-of-being-automated",
    "title": "An OpenAI exec identifies 3 jobs on the cusp of being automated",
    "description": "\"My bet is often on life sciences, pharma companies,\"  Olivier Godement said.",
    "fullText": "Three industries are going to look very different in the next few years, according to an OpenAI executive.\n\nOn an episode of the \"Unsupervised Learning\" podcast, Olivier Godement, the head of product for business products at the ChatGPT maker, shared why he thinks a trio of jobs — in life sciences, customer service, and computer engineering — is on the cusp of automation.\n\n\"My bet is often on life sciences, pharma companies,\" he said, about his first pick for industries on the brink of change because of AI.\n\nGodement said that the goal of pharmaceutical companies like Amgen, with which he works, is to design new drugs. This has two components: actual research and experimentation, and admin, a time-consuming process that could be automated, he said.\n\n\"The time it takes from once you lock the recipe of a drug to having that drug on the market is months, sometimes years,\" he said. \"Turns out like the models are pretty good at that. They're pretty good at aggregating, consolidating tons of structured, unstructured data, spotting the different changes in documents.\"\n\nGodement joined OpenAI in 2023. He previously worked on products for Stripe for eight years.\n\nOn the podcast, Godement said that while we haven't reached a stage where \"any white collar job\" can be automated in just a day, he is starting to see strong use cases in fields such as coding and customer service.\n\n\"The automation is probably not yet at the level of automating completely the job of a software engineer, but I think we have a line of sight essentially to get there,\" he said.\n\nThe future of software engineering has been one of the most heated tech debates of the year, as AI-assisted coding enters most companies' workflow.\n\nAn Indeed study from October found that software engineers, quality assurance engineers, product managers, and project managers were the four tech jobs that have been axed the most during layoffs and reorgs.\n\nLastly, Godement said that customer-oriented roles like sales and customer experience may be automated soon.\n\n\"I've been working a bunch with the folks at T-Mobile, the telecom company in the US, to essentially provide a better experience to their customers, and we're starting to achieve fairly good results in terms of quality at a meaningful scale,\" he said. \"My sense is we'll probably be surprised in the next year or two on the amount of tasks that can be automated reliably.\"\n\nAcross the board, AI leaders are flagging white-collar jobs that can be easily automated by newer large language models.\n\nIn a June podcast, Geoffrey Hinton, who is recognized as the \"Godfather of AI,\" said that eventually, technology will \"get to be better than us at everything,\" but some fields are safer than others in the interim.\n\n\"I'd say it's going to be a long time before it's as good at physical manipulation,\" Hinton said. \"So a good bet would be to be a plumber.\"\n\n\"For mundane intellectual labor, AI is just going to replace everybody,\" Hinton said.\n\nHe identified paralegals as at risk, and said he'd be \"terrified\" if he worked in a call center.",
    "readingTime": 3,
    "keywords": [
      "life sciences",
      "customer service",
      "automated",
      "podcast",
      "jobs",
      "software",
      "industries",
      "openai",
      "product",
      "products"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-exec-3-jobs-ai-risk-automation-olivier-godement-2025-12",
    "thumbnail_url": "https://i.insider.com/693a53227ecd1d1da66356ca?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.388Z",
    "topic": "finance"
  },
  {
    "slug": "from-garlic-to-avocado-the-goofy-ai-model-codenames-you-should-know",
    "title": "From Garlic to Avocado: The goofy AI model codenames you should know",
    "description": "Leading tech and AI companies are thinking with their stomachs when it comes to naming their secretive AI advancements.",
    "fullText": "It may sound like a trip through the produce aisle, but leading AI companies have something much more important on their lists.\n\nMeta, OpenAI, and Google have all relied on food-related names for their sometimes secretive plans for future AI models. Thinking with your stomach is nothing new for Silicon Valley, just look at the assortment of desserts Android assembled over the years before Google had its fill.\n\nHere is a look at the mouthwatering and just plain goofy names AI and tech companies are using\n\nMeta has codenamed its future AI frontier model \"avocado,\" per a CNBC report. Guac usually costs extra, and CEO Mark Zuckerberg's AI pivot has not come cheap. Meta plans to spend more than $70 billion this year on AI infrastructure, which is on top of $14 billion investment Meta made in Scale AI and to poach its founder, Alexandr Wang.\n\nOpenAI has hit a rough patch, feeling the heat from Google's advances and stumbling with a series of missteps. So perhaps it was time to spice things up. The ChatGPT maker has codenamed its new large language model \"garlic,\" according to The Information. Garlic is separate from another LLM OpenAI is developing, codenamed \"Shallotpeat.\"\n\nGoogle appears to have loved a codename so much that it made it public. Google's AI image generator in Gemini is named Nano Banana Pro, which it released on November 20. Before then, Google had internally called the model nano-banana, though they had not publicly disclosed their zany choice.\n\nThe clearance section offers a wide selection of great names. OpenAI might have one of the best all-time codenames with \"strawberry,\" which it used to refer to its o1 model. The name was likely a play on the viral struggle of AI models to correctly identify the number of Rs in the fruit. Before Strawberry, OpenAI had a secretive project named Q*.\n\nEarlier this year, Elon Musk's xAI had a sweet tooth when it codenamed an early testing version of Grok-3 \"chocolate.\"\n\nMistral AI, the France-based startup, went in a completely opposite direction with \"Jaguar,\" its codename for a testing model.\n\nAnd Anthropic named its family of models Opus, Sonnett, and Hakiu, a trio of three different types of compositions.",
    "readingTime": 2,
    "keywords": [
      "model",
      "codenamed",
      "models",
      "named",
      "secretive",
      "plans",
      "look",
      "codename",
      "testing",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-codenames-meta-avocado-openai-garlic-strawberry-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c0d071107c9f3457b599?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.123Z",
    "topic": "finance"
  },
  {
    "slug": "included-health-is-launching-an-ai-personal-health-assistant-thatll-face-off-with-big-tech-from-verily-to-openai",
    "title": "Included Health is launching an AI personal health assistant that'll face off with Big Tech from Verily to OpenAI",
    "description": "The startup's new tech could compete with Big Tech's health AI projects from heavyweights like Alphabet and OpenAI.",
    "fullText": "Included Health is rolling out a new AI tool that could pit it against Big Tech's latest health bets.\n\nThe healthcare startup has launched an AI-powered personal health assistant, Business Insider has learned exclusively. The tech draws on patients' medical claims, benefits information, and other data to offer on-demand answers to health-related questions.\n\nIncluded Health is tapping into a hot area in healthcare AI, where it's competing against other health startups as well as tech heavyweights. Alphabet's Verily released its own AI-powered app in October that allows patients to connect their medical records and ask a chatbot their health-related questions. OpenAI wants to win in consumer health tech, too, and is considering building tools such as its own personal health assistant, Business Insider reported in November.\n\nIncluded Health has been scaling on the premise of personalizing how patients interact with their healthcare for over a decade. The company, which sells tech to about 300 employers and health plans to help patients better navigate their health benefits, tested its AI assistant for about 18 months to ensure its accuracy in smaller pilots before making it available to its entire employer base, CEO Owen Tripp said.\n\n\"This can't be ChatGPT level of probability. It has to be precise,\" he said.\n\nTripp is optimistic about patients receiving general health guidance from LLMs like OpenAI's ChatGPT or Anthropic's Claude. Those AI tools can help patients learn more about their conditions and prepare for doctor's visits, he said. But he emphasized that Included's tech takes that guidance a step further.\n\n\"When it gets down to the business of actually taking care of oneself or taking care of somebody else, you're going to need a lot of very secure, specific data and a whole context to go solve problems, including the exact medical history of that patient,\" Tripp said.\n\nPatient-facing healthcare AI sometimes walks a regulatory tightrope, especially if the tech provides personalized advice that effectively replaces the work clinicians are licensed to do. Tripp said he doubts that most large tech companies attempting to delve into medical records aggregation will want to grapple with that complexity.\n\n\"I predict, like many before them, they will pull back. It's just hard, and the juice is often not worth the squeeze for these high-profile companies,\" he said.\n\nIncluded Health's personal health assistant, called Dot, has become its members' front door and the foundation for Included's new products, said COO Nupur Srivastava.\n\nIncluded recently put Dot in front of members during open enrollment to help answer their benefits questions, Srivastava said. The AI agent can also help patients prepare for doctor's visits and send the clinician a summary of patients' past visits ahead of time.\n\nIncluded Health still employs plenty of its own clinicians and care advocates that members can talk to if they prefer. Srivastava also noted that if a patient mentions the term 'suicide' in a conversation with Dot, \"within a minute, someone will call you.\"\n\nWhen asked about Big Tech and AI startups' ambitions to build personalized health AI, Tripp said that Included Health is in talks with multiple potential partners to help them achieve those goals. He didn't specify which companies it's talking to, but he suggested some AI companies are focused on acquiring personalized health data that they can anonymize and use to train models.\n\n\"But when it comes to actually delivering patient care, we're pretty confident that companies that are going to succeed will be the ones that have well-trained physicians licensed in all 50 states, delivering on a real-time platform, across mind, body, and wallet,\" he said.\n\nIncluded Health was supposed to go public in 2022. The startup had hired banks for an IPO push, but pulled out of its planned investor meetings when the market started to tank, Tripp told Business Insider in January.\n\nTripp declined to share specifics about Included's exit strategy as of November. But Included is profitable, so the company doesn't need to raise money through a public listing, he said. Included hasn't publicly fundraised since it was formed from the 2021 merger of Grand Rounds and Doctor on Demand, and the company hasn't shared its valuation.\n\nThe public markets haven't been forgiving to healthcare startups. Only two digital health companies went public this year, Hinge Health and Omada Health. And while Hinge and Omada have fared far better than most companies that listed during digital health's 2021 IPO wave, healthcare IPO hopefuls still face high standards to going public and significant volatility risks once they begin trading.\n\n\"The last few years in our space haven't been a great commercial for being a public company,\" Tripp said.\n\nWith so many developments in healthcare AI, however, Tripp does recognize that an IPO could create opportunities for Included Health to acquire other companies.\n\n\"I do think this is a time where there are going to be some interesting capabilities and technologies available in the market that allow us to provide even more service to our members,\" he said. \"I do have my eyes very open to how I would use capital to execute on some of those M&A events. That part is more important to me.\"",
    "readingTime": 5,
    "keywords": [
      "assistant business",
      "included health",
      "doctor's visits",
      "medical records",
      "personal health",
      "personalized health",
      "business insider",
      "patients",
      "healthcare",
      "care"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/included-health-launches-own-ai-personal-health-assistant-2025-12",
    "thumbnail_url": "https://i.insider.com/691290c746c4547ecb058733?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.019Z",
    "topic": "finance"
  },
  {
    "slug": "the-godmother-of-ai-says-your-college-diploma-is-losing-power-heres-what-she-looks-for-instead",
    "title": "The 'Godmother of AI' says your college diploma is losing power — here's what she looks for instead",
    "description": "Fei-Fei Li, founder of the AI startup World Labs, says she now favors fast learners who embrace AI tools over candidates with traditional degrees.",
    "fullText": "Don't count on a college degree to land your dream job in Silicon Valley.\n\nIncreasingly, founders and tech companies are judging talent by how quickly someone can learn, adapt, and build — not on how long they spent in a lecture hall — reshaping traditional pathways into the workforce.\n\nFei-Fei Li, the Stanford computer science professor widely known as the \"Godmother of AI,\" is one example of this.\n\nIn an interview on \"The Tim Ferriss Show\" this week, she spoke about the value of a degree when it comes to hiring for her AI startup, World Labs.\n\n\"When we interview a software engineer, I personally feel the degree they have matters less to us now,\" Li said.\n\n\"Now, it's more about what have you learned, what tools do you use, how quickly can you superpower yourself in using these tools — and a lot of these are AI tools,\" she said. \"What's your mindset toward using these tools matter more to me.\"\n\nHer hiring bar has become even clearer: she won't hire software engineers who resist AI.\n\n\"At this point in 2025 — hiring at World Labs — I would not hire any software engineer who does not embrace AI collaborative software tools,\" Li said.\n\nIt's not about automating humans out of the equation, she added — it's about identifying people who can grow as fast as the technology around them.\n\n\"If you're able to use these tools, you're able to learn. You can superpower yourself better,\" she said.\n\nLi's stance is part of a broader shift playing out across Silicon Valley, where more founders and even major tech firms are openly questioning the value of higher education.\n\nPalantir's CEO, Alex Karp, has openly challenged the value of a college education, urging young entrepreneurs to skip the lecture hall and learn by doing instead — a view echoed by LinkedIn CEO Ryan Roslansky, who has said that adaptability and AI fluency now matter far more than the \"fanciest degrees.\"\n\n\"AI makes skill sets based on years of education irrelevant,\" Dan Rhoton, CEO of Hopeworks, told Business Insider. Hopeworks is a tech-training nonprofit that prepares underrepresented talent for AI-enabled jobs.\n\nAfter 13 years of preparing unemployed young adults ages 17 to 26 in Camden, New Jersey, and Philadelphia for tech careers, Rhoton said he has watched firsthand how AI is upending the value of a college degree.\n\n\"We're seeing more and more employers coming to us, saying, 'We used to require a bachelor's degree in this, but we don't understand why.'\"\n\nInstead, he said, employers now want a \"value proposition,\" which he said any job seeker can achieve by showing an AI-generated solution to a company's specific problems.\n\n\"This is the age of: I'm someone who's going to deliver business value,\" Rhoton said. \"Not: I have the right degree.\"",
    "readingTime": 3,
    "keywords": [
      "lecture hall",
      "software engineer",
      "college degree",
      "tools",
      "tech",
      "learn",
      "hiring",
      "it's",
      "education",
      "rhoton"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godmother-of-ai-value-of-college-degrees-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693aa1db71107c9f3457c06e?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.002Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-under-pressure-as-ai-fears-overshadow-fed",
    "title": "Stocks Under Pressure as AI Fears Overshadow Fed",
    "description": "FTSE 100 Live: Stocks Under Pressure as AI Fears Overshadow Fed",
    "fullText": "LiveUpdated5m agoStocks Under Pressure as AI Fears Overshadow FedJoin the Markets Today team for news and analysis vital to UK markets. Email us at marketstoday@bloomberg.net5m ago\n\n The Fed’s rate cut initially gave equities a boost, and US stocks did close higher, but that more positive mood was dashed by the \n\n results from Oracle\n\n .\n\n The software and cloud computing company’s shares slumped in after-hours trading as it tapped directly into the fears that have hit the AI trade: a jump in spending on AI data centres which are taking longer than investors want to translate into returns.\n\n Those more existential concerns were accompanied by results that failed to meet high expectations, with a 34% rise in cloud sales and 68% bump in infrastructure unit revenue falling short of analyst estimates.\n\n That’s filtering through into a rough picture in US stock futures, though it appears that the pain is mostly being confined to there, even if European and UK futures do look somewhat soggy.",
    "readingTime": 1,
    "keywords": [
      "fears",
      "markets",
      "cloud",
      "futures"
    ],
    "qualityScore": 0.75,
    "link": "https://www.bloomberg.com/news/live-blog/2025-12-11/ftse-100-live-fed-trump-powell-pound-bonds-oil-bitcoin-what-s-moving-uk-markets-right-now-markets-today",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSSIghvwg_70/v0/1200x630.png",
    "created_at": "2025-12-11T07:01:25.043Z",
    "topic": "finance"
  },
  {
    "slug": "json-to-video",
    "title": "JSON to Video",
    "description": "Create stunning videos with structured JSON prompts. Choose between Veo 3.1 and Sora 2 models for flexible AI video generation with predictable, brand-safe results.",
    "fullText": "{\n \"shot\": {\n \"composition\": \"three wide-to-mid cuts; each reveals a different room through glowing portals\",\n \"lens\": \"35mm lens with cinematic softness\",\n \"frame_rate\": \"30fps\",\n \"camera_movement\": \"smooth slider pans between each portal reveal\"\n },\n \"subject\": {\n \"description\": \"neutral adult character flipping a glowing IKEA catalog, choosing a room, and stepping into it\",\n \"wardrobe\": \"simple, clean clothing in soft neutral colors\",\n \"props\": \"oversized luminous IKEA catalog with ambient glow\"\n },\n \"scene\": {\n \"location\": \"empty white space that transforms through glowing portals\",\n \"time_of_day\": \"timeless white light interior\",\n \"environment\": \"blank studio morphing into immersive IKEA interiors via portals\"\n },\n \"visual_details\": {\n \"action\": \"each catalog flip opens a room portal; character steps into chosen one at the end\",\n \"special_effects\": \"subtle energy ripples and glow from each portal; light and particles shift per room theme\",\n \"hair_clothing_motion\": \"gentle breeze interaction from portal pull\"\n },\n \"cinematography\": {\n \"lighting\": \"balanced soft studio light with each room providing its own internal glow\",\n \"color_palette\": \"minimal white base with rich, contrasting tones in each room\",\n \"tone\": \"elegant, imaginative, clean aesthetic\"\n },\n \"audio\": {\n \"music\": \"soft, ascending ambient pad with light spark textures\",\n \"ambient\": \"dimensional air shift when portals open, soft paper flip, subtle room-specific cues\",\n \"sound_effects\": \"light shimmer for each portal, a soft hum as the final portal closes\",\n \"mix_level\": \"smooth, cinematic with priority on environmental transition sounds\"\n },\n \"dialogue\": {\n \"character\": \"\",\n \"line\": \"\",\n \"subtitles\": false\n },\n \"timeline\": [\n {\n \"t\": \"0-3s\",\n \"description\": \"Character opens glowing catalog; first portal opens to a cozy IKEA bedroom with warm light\"\n },\n {\n \"t\": \"3-6s\",\n \"description\": \"Page flips again; second portal shows modern living room with ambient shelves and pendant light\"\n },\n {\n \"t\": \"6-8s\",\n \"description\": \"Character steps confidently through the final portal into a vibrant IKEA kitchen; portal glows and fades\"\n }\n ],\n \"rules\": [\n \"Three total cuts only, each exactly 3s/3s/2s\",\n \"No camera shake or handheld motion\",\n \"No text, no branding visible\",\n \"Portals must glow and feel immersive, not holographic or flat\",\n \"Each room should match real IKEA design aesthetics\"\n ],\n \"negatives\": [\n \"text overlays\",\n \"fast cuts\",\n \"fake-looking portals\",\n \"handheld shots\",\n \"mismatched furniture styles\",\n \"shadows inconsistent with portal lighting\"\n ]\n}Expand",
    "readingTime": 2,
    "keywords": [
      "ikea catalog",
      "character steps",
      "description character",
      "final portal",
      "glowing portals",
      "light description",
      "room",
      "soft",
      "ambient",
      "cuts"
    ],
    "qualityScore": 0.3,
    "link": "https://jsontovideo.org/",
    "thumbnail_url": "https://jsontovideo.org/og.png",
    "created_at": "2025-12-11T07:01:20.644Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "title": "Oracle Credit Risk Gauge Deteriorates After Earnings Report",
    "description": "A measure of Oracle Corp.’s credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence.",
    "fullText": "TechnologyBy Caleb MutuaSaveA measure of Oracle Corp.’s credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence. The cost of protecting the company’s debt against default for five years rose about 0.05 percentage point to around 1.246 percentage point a year, according to ICE Data Services. The gauge, which rises as investor confidence in the company’s credit quality falls, reached its highest level intraday since Thursday. It rose close to its level earlier this month, when it reached a peak since the financial crisis. Oracle credit derivatives have become a credit market barometer for AI risk.",
    "readingTime": 1,
    "keywords": [
      "credit",
      "risk",
      "company’s",
      "rose",
      "percentage",
      "oracle"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-10/oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/idj3XzDNG3DY/v1/1200x800.jpg",
    "created_at": "2025-12-11T03:50:24.284Z",
    "topic": "finance"
  },
  {
    "slug": "upload-a-selfie-and-get-beautiful-ai-santa-photos-for-999",
    "title": "Upload a selfie and get beautiful AI Santa photos for $9.99",
    "description": "Upload a casual standing photo and instantly get a magical Santa portrait with PhotoJing. Fast, high-quality, and perfect for holiday cards and gifts. Create festive Santa photos online in minutes!",
    "fullText": "Turn Any Casual Photo into a Magical Santa Portrait with PhotoJing!\n\nNo lines, no stress—just holiday magic. Whether it’s your little one’s first visit with Santa or a yearly family tradition, PhotoJing creates warm, joy-filled portraits you’ll treasure for years to come.\n\nUpload a simple standing photo, and our team will transform it into a festive Santa picture your family will adore. Perfect for holiday cards, gifts, and spreading seasonal cheer, PhotoJing delivers charming, high-quality Santa portraits from the comfort of your home.\n\nCreate Christmas magic in minutes—just upload, and let us do the rest!\n\n- Upload photo(s) of 1-4 different people.\n- For larger groups, send a message for a custom order.",
    "readingTime": 1,
    "keywords": [
      "upload",
      "holiday",
      "family",
      "portraits",
      "santa",
      "photojing",
      "magic"
    ],
    "qualityScore": 0.65,
    "link": "https://www.photojing.com/products/santa-photos",
    "thumbnail_url": "http://www.photojing.com/cdn/shop/files/Santa_photo_collage_ver_2_1.png?v=1765415082",
    "created_at": "2025-12-11T03:50:16.098Z",
    "topic": "tech"
  },
  {
    "slug": "navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "title": "Navy, Palantir Announce $448M 'Ship OS' AI Tool for Shipbuilding and Repair",
    "description": "The Navy’s four public shipyards and two unidentified private shipyards are working with Palantir for a program the service is calling “Ship OS” as part of a new $448 million effort to improve efficiency through better use of data. Announced at an industry day on Tuesday, the Shipbuilding Operating System program, or Ship OS, will collect data from across the new construction and maintenance systems to streamline shipbuilding and the repair of the current fleet, according to the service. “Every ship builder who partners with us will have AI power tools that optimize their work in real time. Every supplier",
    "fullText": "USNI News Giving Tuesday 2025 \n\n Our annual Giving Tuesday campaign provides essential funding that enables our staff writers to observe firsthand the evolving character of naval warfare and international maritime commerce - and to bring those insights directly to you, our readers! Thanks to your generosity in 2024, we were able to send our team across the fleet to learn from and connect with Navy, Marine Corps, and Coast Guard in the Western Pacific, like Taiwan and the Philippines, as well as around the globe. Your support directly fuels our on-the-ground coverage of naval operations and the global security challenges facing our Sea Service leaders—challenges that cannot be fully appreciated from within the Beltway alone. We continue to operate as a public service, and this is made possible by your generosity! If you believe in open, independent journalism, please consider supporting our critical mission with a donation today. \r\n As a special gift, all one-time or annual donations amounting to $200 or more will receive exclusive access to the Special Report: Nimitz ’75 — Celebrating the Origin of the Nuclear Carrier Class for USS Nimitz (CVN-68) Last Deployment. Donors contributing more than $300 will also receive a Collected Edition of USNI News 2025 Sea Scroll Weekly Newsletter V2. \n\n Donate Today",
    "readingTime": 2,
    "keywords": [
      "usni",
      "annual",
      "naval",
      "directly",
      "generosity",
      "receive",
      "nimitz",
      "service"
    ],
    "qualityScore": 0.65,
    "link": "https://news.usni.org/2025/12/09/navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "thumbnail_url": "https://news.usni.org/wp-content/uploads/2025/12/9294700-scaled.jpg",
    "created_at": "2025-12-11T03:50:15.641Z",
    "topic": "tech"
  },
  {
    "slug": "the-normalization-of-deviance-in-ai",
    "title": "The Normalization of Deviance in AI",
    "description": "The gradual and systemic over-reliance on LLM outputs, especially with agentic systems, leads to a normalization of deviance.",
    "fullText": "The AI industry risks repeating the same cultural failures that contributed to the Space Shuttle Challenger disaster: Quietly normalizing warning signs while progress marches forward.\n\nThe original term Normalization of Deviance comes from the American sociologist Diane Vaughan, who describes it as the process in which deviance from correct or proper behavior or rule becomes culturally normalized.\n\nI use the term Normalization of Deviance in AI to describe the gradual and systemic over-reliance on LLM outputs, especially in agentic systems.\n\nAt its core, large language models (LLMs) are unreliable (and untrusted) actors in system design.\n\nThis means that security controls (access checks, proper encoding, and sanitization, etc.) must be applied downstream of LLM output.\n\nA constant stream of indirect prompt injection exploit demonstrations indicates that system designers and developers are either unaware of this or are simply accepting the deviance. It is particularly dangerous when vendors make insecure decisions for their userbase by default.\n\nI first learned about this concept in the context of the Space Shuttle Challenger disaster, where systemic normalization of warnings led to tragedy.\n\nDespite data showing erosion in colder temperatures, the deviation from safety standards was repeatedly rationalized because previous flights had succeeded. The absence of disaster was mistaken for the presence of safety.\n\nIn the world of AI, we observe companies treating probabilistic, non-deterministic, and sometimes adversarial model outputs as if they were reliable, predictable, and safe.\n\nVendors are normalizing trusting LLM output, but current understanding violates the assumption of reliability.\n\nThe model will not consistently follow instructions, stay aligned, or maintain context integrity. This is especially true if there is an attacker in the loop (e.g indirect prompt injection).\n\nHowever, we see more and more systems allowing untrusted output to take consequential actions. Most of the time it goes well, and over time vendors and organizations lower their guard or skip human oversight entirely, because “it worked last time.”\n\nThis dangerous bias is the fuel for normalization: organizations confuse the absence of a successful attack with the presence of robust security.\n\nTwo ways this can impact systems are:\n\nAnd we already see agents make mistakes in day to day usage, like formatting hard drives, creating random GitHub issues, or wiping a production database.\n\nSo, the signs are there. And it is inherently dangerous, not only because of attacks like indirect prompt injection, but also because these systems are trained on enormous, untrustworthy data sets from the Internet. Anthropic research recently showed that it takes only a small amount of documents to successfully add a backdoor to a model.\n\nConsider a scenario where the Normalization of Deviance has drastic consequences: an attacker trains a backdoor into a model that triggers on certain days to invoke tools, like compromising a user via code execution. Since we have a pretty centralized ecosystem, where attacks often are transferable, and natural language is universally understood by LLMs, this can have consequences across many systems and vendors.\n\nSuch a drift does not happen through a single reckless decision. It happens through a series of “temporary” shortcuts that quietly become the new baseline. Because systems continue to work, teams stop questioning the shortcuts, and the deviation becomes invisible and the new norm.\n\nEspecially under competitive pressure for automation, cost savings, a drive to be first, and the overall hype, this dangerous drift is evident. The incentives for speed and winning outweigh the incentives for foundational security. Over time, organizations forget why the guardrails existed in the first place.\n\nLet me share some examples of how this is reflected in real-world agentic AI systems.\n\nWe are all aware that chatbots have those “AI can make mistakes”, “Double check responses” and so forth disclaimers, and we can observe the drift of normalization occurring in real-time.\n\nThree years after ChatGPT shipped, vendors push agentic AI to users, but at the same time vendors are highlighting that your system might get compromised by that same AI - that drift, that normalization, is what I call “The Normalization of Deviance in AI”.\n\nThis continuous drift is a long-term danger:\n\nWhile some vendors acknowledge the risks, others appear to overlook or downplay them, potentially due to competitive pressure and focus on product and customer acquisition.\n\nIn many cases, we probably collectively hope that “someone” will solve these security and safety challenges.\n\nCompanies like Google, OpenAI, Anthropic, Microsoft, and other institutions and organizations perform extensive research in this area, including publishing evals and mitigation ideas. However, the rush to be the first is evident from a product perspective.\n\nNevertheless, before we drift off into a utopian future with agentic AI, I believe the best and safest outcome is to stay realistic around capabilities and control mechanisms, and for AI to remain human-led, particularly in high-stake contexts, to ensure the best outcome overall.\n\nNo, of course not. There is a lot of potential and many low stakes workflows can be implemented already today. Even high-risk workflows can be done with proper threat modeling, mitigations and oversight.\n\nHowever, it requires investment and resources to design and set up systems accordingly and apply security controls (sandbox, hermetic environments, least privilege, temporary credentials, etc.).\n\nMany are hoping the “model will just do the right thing”, but Assume Breach teaches us, that at one point, it will certainly not do that.",
    "readingTime": 5,
    "keywords": [
      "space shuttle",
      "shuttle challenger",
      "challenger disaster",
      "llm output",
      "competitive pressure",
      "indirect prompt",
      "prompt injection",
      "security controls",
      "normalization of deviance",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/",
    "thumbnail_url": "https://embracethered.com/blog/images/2025/normalization-of-deviance-in-ai.png",
    "created_at": "2025-12-11T03:50:15.597Z",
    "topic": "tech"
  },
  {
    "slug": "actress-natasha-lyonne-dropped-out-of-nyu-and-watched-movies-instead-now-shes-helping-to-shape-the-future-of-ai",
    "title": "Actress Natasha Lyonne dropped out of NYU and watched movies instead. Now, she’s helping to shape the future of AI",
    "description": "“We are the ones who are deciding what this use is going to be and how we choose to use it,” Lyonne told the Fortune Brainstorm AI audience in San Francisco.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/natasha-lyonne-ai-animal-pictures-asteria-film-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972842873_c57138e2e2_o-e1765256586861.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:15.065Z",
    "topic": "entertainment"
  },
  {
    "slug": "top-economist-diane-swonk-jerome-powell-risks-losing-the-feds-credibility-on-a-gamble-over-ai-and-immigration",
    "title": "Top economist Diane Swonk: Jerome Powell risks losing the Fed’s credibility on a gamble over AI and immigration",
    "description": "It all comes down to the reason behind the weakness in unemployment and Powell’s diagnosis of the “low-hire, low-fire” economy of 2025.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/jerome-powell-risks-credibility-ai-immigration-diane-swonk/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2250475944-e1765402773522.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.954Z",
    "topic": "business"
  },
  {
    "slug": "instacarts-aienabled-pricing-may-bump-up-your-grocery-costs-by-as-much-as-23",
    "title": "Instacart's AI-enabled pricing may bump up your grocery costs by as much as 23%",
    "description": "Shoppers may be unaware they're paying as much as 23% more than others for the same grocery items on Instacart, a new analysis says.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cbsnews.com/news/instacart-price-discrepancies-investigation/",
    "thumbnail_url": "https://assets2.cbsnewsstatic.com/hub/i/r/2025/12/09/4a650015-732a-4746-bcdb-f72145f0c302/thumbnail/1200x630/e684ba8cc56e043f29542fb6f8589678/gettyimages-1395364375.jpg",
    "created_at": "2025-12-11T03:50:14.929Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-already-taking-over-managers-busyworkand-its-forcing-companies-to-reset-expectations",
    "title": "AI is already taking over managers’ busywork—and it’s forcing companies to reset expectations",
    "description": "As AI agents automate administrative tasks, industry leaders say the role of human managers needs to shift toward coaching and strategy—but most organizations aren’t moving fast enough.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/ai-managers-automate-busy-work-org-chart-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974007976_8abae70b9a_o.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.746Z",
    "topic": "business"
  },
  {
    "slug": "google-deepmind-agrees-to-sweeping-partnership-with-uk-government-focused-on-science-and-clean-energy",
    "title": "Google DeepMind agrees to sweeping partnership with U.K. government focused on science and clean energy",
    "description": "The collaboration will see the AI company collaborating with the British government on a robotic lab for new materials, fusion energy, and new research into AI safety and the societal impacts of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/google-deepmind-uk-government-partnership-science-clean-energy/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2217672931-e1765404847213.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.668Z",
    "topic": "politic"
  },
  {
    "slug": "braininspired-llm-alignment",
    "title": "Brain-Inspired LLM Alignment",
    "description": "Thank you for considering applying for an ACX grant. Please use the form below.",
    "fullText": "This 2024 form is no longer accepting responses. You're probably looking for the 2025 form at https://forms.gle/dBAcmR7XMfgnxxwn8 .",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://docs.google.com/forms/d/e/1FAIpQLSc6vmem8-XfhVkMde3PCyysAS_bwBImk3H9iJo0S1OsqfUHWg/closedform",
    "thumbnail_url": "https://lh3.googleusercontent.com/RtXozrlYzCtSFZONcq-j4gNzMeo52ITKZL9qZ3gIVhC1fXlg_eQk4MJftciaiFRYU0eJlqMgHhMCwFE=w1200-h630-p",
    "created_at": "2025-12-11T03:50:14.270Z",
    "topic": "tech"
  },
  {
    "slug": "the-navy-says-ai-cut-a-160hour-submarineplanning-job-down-to-just-10-minutes-now-its-investing-448-million-to-go-bigger",
    "title": "The Navy says AI cut a 160-hour submarine-planning job down to just 10 minutes — now it's investing $448 million to go bigger",
    "description": "The Navy is investing almost half a billion dollars in Palantir artificial intelligence software that promises to speed up shipbuilding processes.",
    "fullText": "The Navy is pouring hundreds of millions of dollars into an artificial intelligence system that it says has sped up key shipbuilding processes.\n\nIn one case, the AI cut painstaking processes of submarine schedule planning — mapping out how the many pieces of construction fit together and making sure people, parts, and yard space are available at the right time — from many hours to only minutes.\n\nThe Navy is launching the new Shipbuilding Operating System, or Ship OS, as it tries to break out of decades-old shipbuilding problems rooted in outdated technologies and work practices. The service announced a $448 million investment Thursday, saying it will accelerate the adoption of AI and autonomy across the industrial base.\n\nThe Ship OS technology is powered by Palantir's Foundry and Artificial Intelligence Platform and began in pilot programs at submarine shipyards.\n\nAt General Dynamics Electric Boat, a long-time submarine yard located in Connecticut, submarine schedule planning saw a dramatic reduction from 160 manual hours down to under 10 minutes. And at Portsmouth Naval Shipyard in Maine, material review times for submarines went from taking weeks to under an hour.\n\nThe $448 million investment will go toward the submarine industrial base and then expand. It'll be deployed across two major shipbuilders, three public yards, and 100 suppliers, Palantir said in a press release.\n\n\"This investment provides the resources our shipbuilders, shipyards, and suppliers need to modernize their operations and succeed in meeting our nation's defense requirements,\" said Navy Secretary John Phelan in a statement.\n\n\"By enabling industry to adopt AI and autonomy tools at scale, we're helping the shipbuilding industry improve schedules, increase capacity, and reduce costs,\" he added, explaining \"this is about doing business smarter and building the industrial capability our Navy and nation require.\"\n\nMaritime Industrial Base Program, a Navy initiative to revitalize US shipbuilding and repair capabilities, and Naval Sea Systems Command are overseeing the implementation of Ship OS. Both are gathering data from multiple sources to identify where the hiccups are in submarine shipbuilding, how the processes, including engineering, can be sped up, and what specific risks can be mitigated through technology.\n\nProblems in the Navy’s submarine industrial base — from shipbuilders to the repair yards — have been building for decades. Submarines are central to any Pacific fight and a top Pentagon priority, yet major programs like the upgraded Virginia-class submarines and new Columbia-class ballistic missile subs have repeatedly run into delays and cost overruns.\n\nThe Government Accountability Office, a government watchdog agency, has documented long-standing problems in the Navy's plans for purchasing and constructing submarines, as well as shipyard deficiencies such as worker inexperience, aging facilities and equipment, and inadequate construction space.\n\nThe introduction of the new Ship OS capability aims to address some of these problems facing US submarine shipbuilding. And once the technology has been used for the submarine programs, the Navy said, it'll apply lessons and adapt them to surface ship programs.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "schedule planning",
      "industrial base",
      "submarine schedule",
      "submarine shipbuilding",
      "the navy",
      "ship os",
      "programs",
      "submarines",
      "processes"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/navy-ai-cut-hourslong-submarine-planning-job-to-minutes-2025-12",
    "thumbnail_url": "https://i.insider.com/6939afa67ecd1d1da6634afc?width=1200&format=jpeg",
    "created_at": "2025-12-11T03:50:13.974Z",
    "topic": "finance"
  },
  {
    "slug": "instagram-is-adding-aigenerated-headlines-to-some-posts",
    "title": "Instagram Is Adding AI-Generated Headlines to Some Posts",
    "description": "No one asked for this.",
    "fullText": "Few of us are under the illusion that we own the content that we post on Instagram, but we do get a say in how that content is presented—we can choose which photos and videos we share, what captions appear (or don't appear) on each post, as well as whether or not we include where the image was taken or shared from. We might not control the platform, but we can control the content of our posts—unless those posts are found on search engines like Google.\n\nAs reported by 404 Media, Instagram is now experimenting with AI-generated SEO titles for users' posts—without those users' input or permission. Take this post for example: Author Jeff VanderMeer uploaded a short video of rabbits eating a banana to his Instagram. The video was posted as-is: There was no caption, location tag, or any other public-facing information. It's just a couple of rabbits having a bite.\n\nA post shared by Jeff VanderMeer (@jeff_vandermeer123)\n\nInstagram, however, took it upon itself to add a headline to the post—at least when you stumble upon it on via Google. Rather than display a link featuring Jeff's Instagram handle and some metadata about the video, the Google entry comes back with the following headline: \"Meet the Bunny Who Loves Eating Bananas, A Nutritious Snack for...\" (the rest of the headline cuts off here).\n\nVanderMeer was less than pleased with the discovery. He posted a screenshot of the headline to Bluesky, writing, \"now [Instagram] appears to generate titles [and] headlines via AI for stuff I post...to create [clickbait] for [Google] wtf do not like.\"\n\nThis was not the only AI-generated headline VanderMeer was roped into. This post from the Groton Public Library in Massachusetts, which advertises VanderMeer's novel Annihilation as the library's December book group pick, was also given the clickbait treatment on Google. Just as with VanderMeer's post, the Groton Public Library didn't include any text in its Instagram post—just an image showing off the book. But if you see the post within a Google search, you'll see the following partial headline: \"Join Jeff VanderMeer on a Thrilling Beachside Adventure...\"\n\n404 Media's Emanuel Maiberg says that they've confirmed that Instagram is also generating headlines for other users on the platform, all without permission or knowledge. Google told Maiberg the headlines are not coming from its AI generators—though it has been using deceptive AI-generated headlines of its own on Google Discover. In fact, the company says its search engine is simply pulling the text from Instagram itself. Maiberg found that these headlines do appear under title tags for Instagram posts when using Google's Rich Result Test tool. When digging through the code, Maiberg also discovered AI-generated descriptions for each post, which could be what Instagram is ultimately using to generate the headlines.\n\nI reached out to Meta for comment, and this story originally published before they responded. However, a Meta spokesperson has since confirmed to me that Instagram has recently started generating these titles using AI. The goal, according to the spokesperson, is to make it easier to know what a post is about before you click the link. They also noted that these headlines might not be totally correct, as with all AI products. In addition, the spokesperson explained that search engine optimization indexing is not necessarily new. The company has been doing this for years in the U.S. to increase visibility for posts from professional accounts.\n\nThat last point is all fine and good, of course. No one is surprised that Instagram is indexing posts for search engines: Most social media platforms do that. Otherwise, you'd never find any of their posts on platforms like Google. The issue is generating fake headlines with AI without letting anyone know about it. Just because Meta AI is capable of generating headlines doesn't mean it is good at it, or even that it should—especially when users never consented to this practice in the first place. It'd be one thing if Instagram had an option before you post—something like \"Generate a headline for me using Meta AI that will appear in search engines for my post.\" Most of us would opt out of that, but it'd at least be a choice. However, it appears that Instagram decided that users like VanderMeer weren't capable of writing a headline as clever as \"Meet the Bunny Who Loves Eating Bananas.\"\n\nThe worst part is, the AI doesn't even accurately describe the posts, a risk the Meta spokesperson readily admits to. That Groton Public Library post was only about a book club meeting featuring VanderMeer's novel, but the headline says \"Join Jeff VanderMeer,\" as if he'd be making an appearance. Not only did Instagram add a headline without VanderMeer's consent, it spread misinformation about his whereabouts. And for what? Some extra engagement on Google?\n\nIf Instagram wants its posts to appear as headlines on search engines, it should include the actual posters in the conversation. As VanderMeer told 404 Media: \"If I post content, I want to be the one contextualizing it, not some third party.\"\n\nWhile Meta has yet to add a dedicated on/off switch for these headlines, one thing you can do to ensure your posts don't get an AI clickbait makeover is to opt out of indexing as a whole. If you run an account that relies on discoverability, this might not be worth it, since you'll be impacting how users find your posts outside of Instagram. However, if you don't care about that, or you don't need the SEO at all, you can stop Instagram from making your posts available on search engines—and putting an end to the AI-generated headlines, at that.\n\nThere are three ways to accomplish this, according to Instagram:\n\nMake your account private: Head to Instagram's in-app settings, then choose Account privacy. Here, tap the Private account toggle.\n\nSwitch your account from professional to private: Open Instagram's in-app settings, scroll down and tap Account type and tools. Here, choose \"Switch to personal account.\"\n\nManually opt out of indexing: Head to Instagram's in-app settings, then choose Account privacy. You should see an option to stop your public photos and videos from appearing in search engines.",
    "readingTime": 6,
    "keywords": [
      "loves eating",
      "eating bananas",
      "instagram's in-app",
      "vandermeer's novel",
      "join jeff",
      "in-app settings",
      "ai-generated headlines",
      "account privacy",
      "search engines",
      "search engine"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/instagram-adding-ai-headlines-posts?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC2DE7N6Z5BP8WS17SW0SCVW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T03:50:11.984Z",
    "topic": "tech"
  },
  {
    "slug": "cursor-introduces-debug-mode",
    "title": "Cursor Introduces Debug Mode",
    "description": "Built to make you extraordinarily productive, Cursor is the best way to code with AI.",
    "fullText": "Coding agents are great at lots of things, but some bugs consistently stump them. That's why we're introducing Debug Mode, an entirely new agent loop built around runtime information and human verification.\n\nTo build it, we examined the practices of the best debuggers on our team. We rolled their workflows into an agent mode, equipping it with tools to instrument code with runtime logs, prompts that generate multiple hypotheses about what's going wrong, and the ability to call back to you to reproduce the issue and verify fixes.\n\nThe result is an interactive process that reliably fixes bugs that were previously beyond the reach of even the smartest models working alone, or could take significant developer time to address.\n\nTo get started, select Debug Mode from the dropdown menu and describe the bug in as much detail as you can.\n\nInstead of immediately trying to generate a fix, the agent reads through your codebase and generates multiple hypotheses about what could be wrong. Some will be ideas you would have thought of on your own, but others will likely be approaches you wouldn't have considered.\n\nThe agent then instruments your code with logging statements designed to test these hypotheses. This prepares the agent to receive concrete data about what's actually happening when the bug occurs.\n\nNext, go to your application and reproduce the bug while the agent collects the runtime logs.\n\nThe agent can see exactly what's happening in your code when the bug occurs: variable states, execution paths, timing information. With this data, it can pinpoint the root cause and generate a targeted fix. Often that's a precise two or three line modification instead of the hundreds of lines of speculative code you'd have received with a standard agent interaction.\n\nAt this point, Debug Mode asks you to reproduce the bug one more time with the proposed fix in place. If the bug is gone, you mark it as fixed and the agent removes all the instrumentation, leaving you with a clean, minimal change you can ship.\n\nThis human-in-the-loop verification is critical. Sometimes bugs are obvious, but other times they fall into a gray area where the fix might work technically but not feel right. The agent can't make that call on its own. If you don't think the bug is fixed, the agent adds more logging, you reproduce again, and it refines its approach until the problem is actually solved.\n\nThis kind of tight back-and-forth is one way we think AI coding works best. The agent handles the tedious work while you make the quick decisions that need human judgment. The result with Debug Mode is that tricky bugs that used to be out of reach are now reliably fixed.\n\nRead the Debug Mode docs. Learn about all the new features in Cursor 2.2.",
    "readingTime": 3,
    "keywords": [
      "runtime logs",
      "bug occurs",
      "debug mode",
      "agent",
      "bugs",
      "code",
      "reproduce",
      "generate",
      "hypotheses",
      "what's"
    ],
    "qualityScore": 1,
    "link": "https://cursor.com/blog/debug-mode",
    "thumbnail_url": "https://ptht05hbb1ssoooe.public.blob.vercel-storage.com/assets/changelog/changelog-2-2-debug.png",
    "created_at": "2025-12-10T18:55:48.559Z",
    "topic": "tech"
  },
  {
    "slug": "instacart-may-be-jacking-up-your-grocery-prices-using-ai-study-showsa-practice-called-smart-rounding",
    "title": "Instacart may be jacking up your grocery prices using AI, study shows—a practice called ‘smart rounding’",
    "description": "Consumer Reports and the progressive think tank Groundwork Collaborative used ~200 volunteers to check prices on 20 items in four cities.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/instacart-may-be-jacking-up-your-grocery-prices-using-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2216221632-e1765386311727.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.794Z",
    "topic": "business"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are ‘growing up fluent in AI’ and that’s helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-new-tools-that-can-improve-workforce-training",
    "title": "The New Tools That Can Improve Workforce Training",
    "description": "Companies are pouring money into AI but failing to translate that investment into workforce capability, largely because traditional training methods don’t help employees retain or apply complex skills. Extended reality—virtual reality, augmented reality, and mixed reality—bridges this gap by letting people learn through immersive, emotionally engaging, hands-on experiences that the brain encodes like real events. Organizations from Bank of America to Boeing to Walmart are already seeing faster learning, higher confidence, reduced errors, and lower costs by using XR to train employees in everything from customer-service scenarios to technical assembly. The technology works because it aligns with how people actually learn, benefits from major improvements in affordability and accessibility, and meets the expectations of a workforce already accustomed to immersive digital environments. The companies that start with focused pilot projects, match the right XR tool to the right skill gaps, and scale deliberately will build training systems that actually change behavior and materially improve performance.",
    "fullText": "The New Tools That Can Improve Workforce Training by Paola Cecchi-DimeglioDecember 10, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintThis year companies plan to invest $1.5 trillion in AI initiatives, with forecasts showing that investments will rise to $2 trillion by 2026. Gartner research predicts that most of this spending will not meet expected returns. The issue isn’t the technology; it’s our failure to help people utilize it.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://hbr.org/2025/12/the-new-tools-that-can-improve-workforce-training",
    "thumbnail_url": "/resources/images/article_assets/2025/11/Dec25_01_200202284-009.jpg",
    "created_at": "2025-12-10T18:55:43.958Z",
    "topic": "business"
  },
  {
    "slug": "the-5-ai-tensions-leaders-need-to-navigate",
    "title": "The 5 AI Tensions Leaders Need to Navigate",
    "description": "The introduction of AI into the workplace inherently creates tension. The same tools that relieve drudgery and make work easier, for example, can also remove the challenging friction that gives work its meaning, builds crucial skills, and increases satisfaction. Which tensions are most common in workplaces—and how are they actually playing out? Insights collected from over 100 leaders show that they’re wrestling with several competing forces: experts vs. novices, centralization vs.",
    "fullText": "The 5 AI Tensions Leaders Need to NavigateBased on insights from more than 100 builders, executives, investors, advisors, and researchers from across the globe. by Rebecca Hinds and Robert I. SuttonDecember 10, 2025Summary.   Leer en españolLer em portuguêsPostPostShareSavePrintdetect cancer, their accuracy improved. But their performance on non-AI procedures got worse. When students used AI to draft SAT-style essays, their creativity initially spiked. Yet those who started with AI-generated ideas showed reduced alpha-wave activity (a marker of creative flow), “tended to converge on common words and ideas,” and their “output was very, very similar” to one another’s. And in a 2025 study spanning 20 European countries, workers in highly automated jobs reported less purpose, less control, and more stress, even when their work became technically easier.",
    "readingTime": 1,
    "keywords": [
      "ideas",
      "less"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/the-5-ai-tensions-leaders-need-to-navigate",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_10_ChenWu.jpg",
    "created_at": "2025-12-10T18:55:43.948Z",
    "topic": "business"
  },
  {
    "slug": "as-ai-floods-our-culture-heres-why-we-must-protect-human-storytelling-in-games",
    "title": "As AI floods our culture, here’s why we must protect human storytelling in games",
    "description": "Buying the Zombies, Run! studio wasn’t part of ​my plan, but a post-apocalypse ​game with stories that make people feel seen pulled me in\n• Don’t get Pushing Buttons delivered to your inbox? Sign up here\nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?",
    "fullText": "Buying the Zombies, Run! studio wasn’t part of ​my plan, but a post-apocalypse ​game with stories that make people feel seen pulled me in\n\nDon’t get Pushing Buttons delivered to your inbox? \nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?\n\nWell. First of all. Zombies, Run! is special. It’s special to me – the game started as a Kickstarter and the community that grew up around it has always been incredibly supportive of what we’re doing. And it’s special in what it does. It’s a game to exercise with. You play it on your smartphone – iPhone or Android – and we tell stories from the zombie apocalypse in your headphones to encourage you to go further, faster, or just make exercise less boring. Games are so often portrayed as the bad entertainment form, but I made a game that fundamentally helps people to be healthier.\n\nThe experience of playing Zombies, Run! is also completely focused on storytelling. My co-creator Adrian Hon and I were talking about doing a project together. He said: “Let’s do something to make running more fun.” I said: “How about if we do a story where you’re being chased by zombies?” And here we are.\n\nWhen you play the game, you’re immersed in a world where every run makes you a hero – you’re collecting supplies, saving a child from no man’s land, investigating the mystery of how the apocalypse started. I’ve always focused on the storytelling being good. And it works. Players of the game become so attached to the characters that many of them report laughing out loud or even “crying while running”.\n\nOne of my jokes about storytelling in video games is that the way we tend to talk about it – in the games industry, in games journalism, even in marketing copy – is very much “never mind the quality, feel the width”. We say things like “this game has 100-plus hours of story” or “this game contains more than a million words”. Imagine marketing a movie saying that the script contains 29,000 words. Or selling a novel on the basis that it’ll take a long time to read.\n\nThat’s not how you do it. You tell the story. You give a hook. You say: “A single woman comes home one evening to find a man claiming to be her husband living in her house. And when he goes up to the attic, a different husband comes down in his place.” Now you can’t wait to find out what happens next. (That, incidentally, is the brilliant comic novel The Husbands by Holly Gramazio – who I think is the only other bestselling novelist to be also making her own video games.)\n\nSo, now I own a games company, what am I going to do? My feeling is that I must focus on the fundamentals. There’s a world of games out there that thinks it can replace writers with AI large language models. I think that’s going to make writing worse and worse. AI writing is fine for boilerplate text that is always roughly the same. It’s fine for non-writers to get their expertise into the world. But storytelling is different. It is human minds finding companionship with other human minds – we need stories, fundamentally, to feel less alone. To know that other people have been through things a bit like what we have. Things that make us laugh, and cry, even while running. You get that from work that is not the same as everything else, you get it from the unique work of other individual human minds.\n\nAnd actually, Zombies, Run! has always been a universe with strong values. We’re not a rightwing, rugged-individualism apocalypse, where one lone person can get through with just their guns. In our world – as in the real world – humans survive by working together.\n\nWhile we’re still going to have many exciting fleeing zombies, battling-the-undead storytelling, I think there’s probably also room in the ZR! universe for a 10-mission arc where you have to find all the figurines and paints you need to complete an expansion set in “Demons and Darkness”; or one where you’re working on bringing an overgrown garden back to blooming, beautiful life; or setting up and running the first post-apocalyptic travelling library while also trying to work out what happened to the first librarian who’s mysteriously disappeared, leaving only a series of cryptic notes in an old manuscript.\n\nAfter all, I do think this is quite a good time in the world to be thinking about how to rebuild after a series of catastrophic events.\n\nSelling story by the yard and not by a story hook is a marker, I think, of a lack of confidence in the form. We don’t need to lack confidence. Games are the biggest entertainment industry in the world. If we want to be taken seriously, we need to take ourselves seriously. Stop talking about the width, start talking about the quality.\n\nIt was the 20th anniversary of Xbox 360 recently, and one name that’s cropped up in every list of the console’s best games is the compulsive retro twin-stick shooter Geometry Wars. If you’re yearning for something similar, you must immediately download Evil Egg, a frenzied twin-stick blaster with gorgeous Commodore 64-style visuals and sound effects. Shoot everything that moves, hit the left trigger to boost and collect hearts to stay alive.\n\nAt first it’s a bewildering mass of rainbow pixels but as you detonate wave after wave of glitchy space pests, you begin to understand the patterns of different enemies and earn upgrades such as the executioner’s sword, which takes out foes in an orbital slash of laser particles. Evil Egg is polished, exciting, wild to look at, and has such a brilliant understanding of the genre and its unique dynamics. It’s free on Steam but I implore you to download it on Itch.io and name your own price. Keith Stuart\n\nAvailable on: PC\n\n Estimated playtime: 10-plus hours\n\nThere has been a lot of writing about Horses, the art game recently banned by digital platforms Steam and Epic Games Store. I particularly enjoyed this post by writer Harper Jay MacIntyre, which considers Horses, formalism and the trans experience. The article manages to bring in so many elements of modern games criticism and academia while providing a highly personal response to the game.\n\nThe most interesting retro game articles are the ones that reassess lost or derided titles rather than merely celebrate the classics. Was the Atari 2600 version of Pac-Man the worst game ever? Not according to this compelling analysis from Garrett Martin at AV Club who sees it as a misunderstood brutalist gem. I find myself in agreement.\n\nIt is also nice to see a legendary game justly praised in an interesting way. The BFI’s look at the legacy of Time Crisis considers the gun game in relation to cinema, referencing Beverly Hills Cop and Run Lola Run rather than just comparing it to Sega’s similar Virtua Cop.\n\nSkate Story – hellish premise aside, this is skateboarding paradise | ★★★★☆\n\nHorror game Horses has been banned from sale – but is it as controversial as you’d think?\n\nFive Nights at Freddy’s 2 – inept game-based horror is one of the year’s worst | ★☆☆☆☆\n\nThis one comes from reader, Rebecca:\n\n“My elderly grandad is coming to stay with us for Christmas and wants to see what’s happening with video game graphics these days. Are there any titles you recommend that will let him explore beautiful locations without getting shot at?! We have a PlayStation 5 and a slightly out-of-date PC.”\n\nYour best option here is to go with one of the big open-world adventures and just find an area with no enemies around. If you You could bypass the threat of imminent violence completely by going for a driving game, such as Forza Horizon 4 on PC (which is set in Britain so he may even spot some familiar scenery). Alternatively, if visual realism isn’t as important as beauty, a cosier indie title such as Tchia, Journey or Firewatch may fit the bill. Really hope he enjoys them!\n\nWe’re still looking for your game of the year nominations for an end of year special – let us know yours by hitting reply or emailing us on pushingbuttons@theguardian.com.",
    "readingTime": 8,
    "keywords": [
      "plus hours",
      "human minds",
      "zombies run",
      "evil egg",
      "game",
      "games",
      "storytelling",
      "you’re",
      "we’re",
      "stories"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/10/i-bought-the-games-studio-behind-zombies-run-because-humanity-is-essential-to-storytelling",
    "thumbnail_url": "https://i.guim.co.uk/img/media/1817abf90f05afe67e594b055c45343b486ae1e6/102_0_925_740/master/925.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8991d15d4205b4197c1289fdd0cfb154",
    "created_at": "2025-12-10T18:55:43.393Z",
    "topic": "gaming"
  },
  {
    "slug": "china-to-limit-access-to-nvidias-h200-chips-despite-trump-export-approval-ft-reports",
    "title": "China to limit access to Nvidia's H200 chips despite Trump export approval, FT reports",
    "description": "Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ​export of the technology to China, the Financial Times reported on ‌Tuesday, citing two people with knowledge of the matter.  Regulators in Beijing have been discussing ways to ‌permit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.",
    "fullText": "Dec 9 (Reuters) - Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ​export of the technology to China, the Financial Times reported on ‌Tuesday, citing two people with knowledge of the matter.\n\nRegulators in Beijing have been discussing ways to ‌permit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.\n\nSuch a move would add a hurdle to Nvidia and other top U.S. chipmakers' ability to address the China market, after Trump's Monday announcement appeared ⁠to settle a debate over ‌whether these companies should keep their global lead by selling AI chips to China or withhold shipments.\n\nNvidia shares, which had risen ‍as much as 2% in premarket trading, pared gains after the report and were last up about 0.6%. The company did not immediately respond to a Reuters request for ​comment on the report.\n\nBeijing has been pushing back against domestic firms' use of ‌U.S. technology, especially Nvidia chips, as it retaliates against American restrictions.\n\nEarlier U.S. restrictions banned the sale of advanced AI processors to China, weighing on Nvidia's ability to grow in one of the world's largest markets for AI chips and development.\n\nThe export of the H200 chips will be permitted with a 25% fee levied ⁠on such sales, Trump said in a ​post on Truth Social on Monday.\n\nIpek Ozkardeskaya, senior ​analyst at Swissquote Bank, said the approval alone may have limited impact on Nvidia's business in China unless it is allowed to ‍export other chip ⁠lines such as Blackwell or Rubin.\n\nShares of AMD and Intel also pared gains and were last up about 0.3% in premarket trading. So far ⁠this year, Nvidia has gained nearly 40% compared with the S&P 500 benchmark index's 16.4% rise ‌in the same period.",
    "readingTime": 2,
    "keywords": [
      "premarket trading",
      "pared gains",
      "chips",
      "nvidia's",
      "nvidia",
      "export",
      "access",
      "advanced",
      "technology",
      "limited"
    ],
    "qualityScore": 0.95,
    "link": "https://finance.yahoo.com/news/nvidia-shares-gain-trump-allows-102400561.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/a48a9375c07cbe587069f836d911e1ae",
    "created_at": "2025-12-10T18:55:43.203Z",
    "topic": "finance"
  },
  {
    "slug": "5-vcs-sounds-off-on-the-ai-question-du-jour",
    "title": "5 VCs sounds off on the AI question du jour",
    "description": "Who better to ask about a bubble than a group who will collectively deploy anywhere from tens to hundreds of millions of dollars over the next decade into AI companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/5-vcs-sounds-off-on-the-ai-question-du-jour/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974207764_b60ab330f2_o-e1765327176512.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.273Z",
    "topic": "business"
  },
  {
    "slug": "inside-tractor-maker-cnhs-push-to-bring-more-artificial-inte",
    "title": "Inside tractor maker CNH’s push to bring more artificial intelligence to the farm",
    "description": "CNH CTO Jay Schroeder says using AI to improve farming is a decades-long passion. \"I grew up on a family farm…so for me, it’s personal.”",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/artificial-intelligence-cnh-ai-tractors-farm-equipment/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Jay-Schroeder_CNH_web-HighRes.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.128Z",
    "topic": "tech"
  },
  {
    "slug": "goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growt",
    "title": "Goldman Sachs CFO on the company’s AI reboot, talent, and growth",
    "description": "Goldman’s OneGS 3.0 revamp is underway.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growth/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1770870970-1-e1765368302818.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:16.162Z",
    "topic": "business"
  },
  {
    "slug": "pay-cuts-poaching-and-pivoting-inside-scale-ai-after-meta",
    "title": "Pay cuts, poaching, and pivoting: Inside Scale AI after Meta",
    "description": "Five months after Meta's $14 billion deal, Scale AI has lost some of its gleam, with workers sniping about pay, and rivals coming for its clientele.",
    "fullText": "This summer, after Meta made a $14 billion investment in Scale AI and poached its 28-year-old founder, Alexandr Wang, and after A-list clients like OpenAI and Google halted work with the startup, a worker for Scale AI anxiously asked ChatGPT what it thought of his company's fate. He knew the chatbot well, having tested it for vulnerabilities. Its prognosis was grim.\n\n\"Scale AI will no longer exist as a credible independent entity within 24 months,\" ChatGPT, which isn't any kind of official authority, wrote. \"Its infrastructure will be repurposed for Meta's internal needs. Its client base will evaporate. Its role as a neutral red teamer or external evaluator is effectively over.\"\n\nThe contractor shared the chat logs with fellow workers at Scale AI. In one reply reviewed by Business Insider, one worker said that they were already on their way out, describing the startup as a ticking time bomb.\n\nThe chatbot was drawing from a storm of headlines about Scale AI, which until this summer had been touted as one of the most ascendant startups in tech — the place Big Tech companies vying for AI supremacy went to when they wanted their chatbots stress-tested and perfected. Lately, it's lost some of its gleam, with investors significantly lowering valuations, workers sniping about pay, and rivals coming for its clientele.\n\nThe vast army of human data labelers that made Scale AI a juggernaut are chafing at what they say are pay cuts, lengthy unpaid onboarding sessions to join new AI projects, and thinning workloads — and are increasingly leaving the platform altogether, according to interviews with five current and former contractors and internal correspondence obtained by Business Insider.\n\nActivity in the main internal chatroom for Outlier — Scale AI's flagship gig work platform, which touts more than 100,000 taskers — has plummeted since the Meta investment, with weekly discussion threads drawing dozens instead of the usual hundreds of replies, according to screenshots reviewed by Business Insider.\n\nOne tasker said that they'd spent close to 40 hours in a single month in unpaid onboarding sessions without landing any actual work, noting that other platforms like Scale AI's rival Mercor do pay for this kind of work. Elizabeth Boyd, another tasker, says she rarely does work for Outlier anymore after seeing effective pay rates for some projects slashed to around $20 an hour — down from the $50 she used to make. One gig that advertised $20 an hour only allowed three minutes of working time every two days, or a 99-cent payout, according to screenshots obtained by Business Insider.\n\nJoe Osborne, a Scale AI spokesperson, says the balance sheets show the company is on the right path. \"This quarter is on track to be our biggest of 2025, our data business is more profitable today than it was before the Meta deal, and our applications business, which includes work with Fortune 500 companies and governments, has doubled revenue\" in the second half of the year compared to the first, Osborne wrote in an email. He also noted there has been an increase in active users on Outlier since the Meta deal, and that pay rates are based on the skills for each project and contributors always see the rates upfront, and have the option of declining any gig.\n\nThe company is also looking to diversify. The startup has embraced fields like robotics, announcing a new lab to meet booming demand for robot training data this fall. It's doubling down on its US military and other government work, winning up to $199 million worth of defense contracts since the Meta deal.\n\nSome investors are bullish. In one current investor's view, Meta has mostly left Scale alone, letting it operate as an independent company. With around $1 billion on the balance sheet, the investor added, there are no plans to fundraise. And an IPO could still be on the table at some point.\n\nOther investors see Scale AI as more like a gutted fish. The Meta investment — which valued Scale AI at $29 billion — has dented Scale AI's valuation in private markets where people buy and sell equity from pre-IPO startups. Noel Moldvai, Augment's CEO, tells Business Insider his platform used to process millions of dollars' worth of transactions in Scale AI stock before the Meta deal, but that dried up as sellers waited to see if the startup rebounded. Activity is picking up again, he said, but at lower valuations of around $15 billion to $9 billion. The underlying message of Meta's semi-acquisition is clear to Moldvai. \"It seems like Meta was just after Alexandr Wang, and so this is probably the structure that let them get him,\" he says. He adds that Scale AI's valuation could still bounce back.\n\nOn another marketplace, Caplight, Scale's valuation has dropped to $7.3 billion. Osborne says that the valuation is not accurate because there have been no sales of stock at that price and multiples of comparable companies would yield a higher valuation.\n\nIf the company doesn't pull it off, it could become the latest example of a once-promising startup that morphed into a \"zombie\" after being invested in by a tech giant.\n\nThis summer, Scale AI painted a rosy picture of the Meta investment, describing it as a major cash infusion and source of future work in its official statement at the time of the deal. That messaging was also conveyed to the startup's corporate workforce, says another former member of Scale AI's red team, which tests chatbots for flaws and vulnerabilities. Just a few weeks after the investment, he was laid off as part of a major downsizing that saw 14% of Scale AI's full-time staff of 1,400 let go.\n\nOsborne said the layoffs were aimed at making the data division profitable, which it now is.\n\nThose weren't the only cuts. In September, Scale AI terminated 12 contractors on its red team, citing performance issues. Two ex-red teamers told Business Insider that the team's work had been drying up since the Meta deal, blaming thinning workloads for the cuts. Later that month, Scale AI shuttered a team in Dallas of contractors focused on generalist AI work as it moved towards more specialized fields.\n\nOsborne said the 12 contractors were part of Scale's temporary workforce and represented a small fraction of its overall red team, which the company is still committed to investing in. He said the Dallas cuts were part of an industry shift towards higher skilled work and represent a small fraction of its overall workforce.\n\nMeanwhile, a swarm of AI training startups has rushed in to poach Scale AI's workers and clients. Some are now raising capital at soaring valuations. Surge AI hit a valuation of $24 billion while Mercor, which is run by three 22-year-olds, announced in October it had raised $350 million at a $10 billion valuation.\n\nMercor has won at least one major AI training project from Meta, Scale AI's 49% shareholder. In September, Scale AI filed a lawsuit in California against Mercor alleging it hired one of its sales employees to poach its biggest customers, allegations Mercor denies.\n\nOne Scale AI investor said he'd been frustrated with Scale AI's leadership losing customers to Surge AI in particular, which reportedly brought in more revenue than Scale in 2024, despite never having raised outside funding. (Scale AI had raised more than $1.5 billion before the Meta deal.)\n\nBrendan Foody, Mercor's CEO, has publicly criticized Scale AI for what he claims are low pay rates and data quality issues. \"Scale lost the focus on product, on scaling quality,\" Foody said in a September podcast appearance. In response, a Scale AI spokesperson told Business Insider its quality metrics are at \"record highs.\"\n\nIt's not just rival CEOs making that point. Tammy Hartline, who managed projects for Scale AI as a consultant until the summer of 2025, said Scale grew so quickly that the work became more about needing bodies than skills. \"Spam and low quality data became accepted as a cost of doing business,\" she said. Hartline joined Mercor in September.\n\nScale AI has also been beset with security issues that predate Meta's investment. In June, Business Insider reported that Scale AI routinely used public Google Docs to track work for high-profile customers, including Google, Meta, and xAI. That practice left AI training documents labeled \"confidential\" accessible to anyone with the link and exposed reams of personal information, like private emails and pay details, about contractors. \"We take data security seriously,\" Osborne said. \"We conducted a thorough investigation and disabled any user's ability to publicly share documents from Scale managed systems.\"\n\nSloppy security isn't uncommon in the AI training space — Surge AI similarly left open sensitive work for its client Anthropic. But the exposed documents seen by Business Insider show that for a project for Google, Scale AI faced security and quality issues throughout 2023 and 2024. Thousands of taskers were flagged for being \"suspected spammers,\" \"cheaters,\" with hundreds of workers listed in spreadsheets with titles like \"Good and Bad Folks\" and \"suspicious non-US taskers.\" Meta recently removed more than 40 groups buying and reselling AI training accounts, including from Scale AI, in response to a recent Business Insider investigation. Osborne said Scale's data quality metrics are the highest they've ever been.\n\nThe company has notched some recent wins. It once appeared bogged down by litigation, but recently agreed to settle multiple lawsuits filed by ex-workers in California who alleged they were underpaid and misclassified as contractors. (Scale no longer accepts gig workers from the state.) The big question remains whether Scale AI can thrive in the increasingly competitive AI training industry it helped give birth to. For many former workers, it'll be too late to find out.\n\nCharles Rollet is Business Insider's tech correspondent in San Francisco. Ben Bergman is a senior correspondent at Business Insider, where he investigates the tech industry with a focus on venture capital and startups.",
    "readingTime": 9,
    "keywords": [
      "scale ai",
      "business insider",
      "scale ai's",
      "meta deal",
      "unpaid onboarding",
      "onboarding sessions",
      "thinning workloads",
      "meta investment",
      "ai's valuation",
      "red team"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pay-cuts-poaching-pivoting-inside-scale-ai-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/68f7cabe1c1f80efbec5fc44?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.535Z",
    "topic": "finance"
  },
  {
    "slug": "why-the-music-industry-is-changing-its-tune-on-ai",
    "title": "Why the music industry is changing its tune on AI",
    "description": "Your 2026 Spotify wrapped may include a shocking amount of 'robot rock.'",
    "fullText": "Last month, \"Walk My Walk\" hit number one on Billboard's Country Digital Song Sales chart. The moody stomp-clap tune, with lyrics like \"Every scar's a story that I survived, I've been through hell, but I'm still alive,\" has been played more than 8 million times on Spotify. The song wasn't performed by a human artist — Breaking Rust, despite having the face of a handsome, rugged man in a cowboy hat on its Spotify profile, is an AI project. But there is a real person claiming that Breaking Rust's work is a copycat: Blanco Brown, an artist who mixes country and rap together, who claims the song's creator used AI to emulate his style. The person behind Breaking Rust did not respond to a message I sent asking about the origin of the sound.\n\nIt's the latest example of ways that AI-generated music, with its opaque origins, can create confusion around who really made a song just as easily as it can create a hit. AI-generated music that sounds a lot like your faves but was made with a few prompts has been going viral, spreading far and wide and more quickly than music labels can always have it removed.\n\nWhen some of the first AI-generated tracks started racking up listens two years ago, music labels went to battle, threatening and filing legal action to stop AI generators from training on and using their artists' voices and music stylings. Universal Music Group (UMG) pushed to have a YouTube video where Eminem's voice rapped about cats taken down. Spotify removed AI slop songs that were listened to by bots to reap the streaming earning pool, and UMG also got streaming platforms to remove a viral \"Drake\" song that wasn't by Drake and The Weeknd at all, but a song written by Ghostwriter, an anonymous artist that uses AI to produce music and appears publicly only when cloaked in white and dark glasses.\n\nNow, the labels are starting to drop their fists and shake hands with AI music generators.\n\nWarner Music Group announced last month it had settled a lawsuit against AI music generator Suno (a test of the service by plaintiffs in the suit found that Suno would churn out works similar to ABBA and Chuck Berry when prompted in their style) and entered into a partnership with the company. Robert Kyncl, CEO of WMG, called it \"a victory for the creative community that benefits everyone.\" The announcement came just weeks after UMG, the world's largest record label, settled its copyright infringement lawsuit with AI music generator Udio, and said the two have partnered to create a new subscription service, slated to launch next year, run on gen AI and licensed music from the label's artists.\n\nAI companies face a litany of lawsuits after using copyrighted material to train their models. The battle is playing out in Hollywood, the news industry, and in visual arts — the music industry is the latest to decide it might be better to play nice with AI than continue a prickly, drawn out court battle when their rights sit in a gray area. \"AI is here to stay, it's transformative,\" Chris Wares, assistant chair of the Music Business Department at Berklee College of Music. The record labels, he says, are \"futureproofing themselves.\"\n\nThe proliferation of AI-generated voices and music stylings has sent a flood of new songs — some good, many uncatchy slop — onto streaming platforms and social media. There are more than 100 million songs on Spotify, Apple Music, and Bandcamp, and many are rarely or never played. Deezer, a French streaming platform, said in April that people were uploading some 20,000 fully AI-generated tracks each day, comprising nearly a fifth of all new content. As more playlists and artists making gen AI music are uploaded, human artists must fight for your ears. In July, a group called The Velvet Sundown rapidly racked up 1 million listens on two albums, something that many indie bands struggle to do on streaming platforms — but the photos of the band on social media are AI generated, and the real person or people behind the project remain unknown. In November, Billboard identified at least six AI or AI-assisted songs that had climbed onto its various charts. Amid the deluge, Spotify updated its impersonation policy in September, saying it would remove songs that featured the unauthorized use of someone's voice.\n\nIf someone makes a banger AI cover song or viral mashup, like reuniting Stevie Nicks and Lindsey Buckingham for a new Fleetwood Mac album or squashing the beef between Kendrick and Drake in a generated collaboration, the novelty factor could drive listening numbers that cut into original work from those artists. But the aim of these partnerships is to create new revenue streams for artists. The Warner deal stipulates that Suno will allow only paid accounts to download generated audio, and says artists must opt-in to having their names, voices, compositions, and likeness regenerated. In an industry where streaming has dramatically reduced royalties, that could be a boost — if fans make music of their faves, it could lead to passive income for the musicians. But that also means the artists' original works will be competing for ears against derivatives of themselves not just for your ears, but for streaming dollars.\n\n\"The reason why no generative AI music can be artist-first is because we are in a finite attention economy. Every minute that is spent listening to a generative AI track is a minute less spent listening to an artist track,\" Mark Mulligan, founder and senior music analyst at research firm MIDiA says. \"We are definitely in a world now where more and more consumers are creating, and that is competing with entertainment time.\"\n\nPart of that creative process may draw us back to older roots in how people interact with music. For hundreds, if not thousands, of years, music was communal. People played it together and used it to pass down stories. With recording technology and radios, music became widely distributed, which \"created this moat between artist and fan,\" Mulligan says. \"We got to this idea that music is a creative full stop, and that the audience doesn't help shape what the music is apart from when you go and see the band play live.\" But now, AI tools are becoming the ultimate form of fan expression. \"We're widening the funnel of creativity,\" says Mulligan.\n\nThat's if artists authorize their voices to be used by the platforms. Some forward-thinking musicians, like Grimes, have already made clones of their voices and invited listeners to experiment. It's less clear if your typical popstar will OK the use of their voice to sing words they haven't seen, and if the potential new revenue streams of such an experiment would prove worth the risk. On Friday, Brown released a \"trailertrap\" remix of \"Walk My Walk,\" a sort of taking back of his own style after seeing it emulated. So far, it has just 2,000 streams. \"If someone is going to sing like me, it should be me,\" Brown told the Associated Press last month. Going forward, it will likely take more than one listen to know if the music we hear is performed by the artists we've come to love.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 7,
    "keywords": [
      "ai-generated tracks",
      "social media",
      "revenue streams",
      "streaming platforms",
      "ai-generated music",
      "music stylings",
      "music generator",
      "music labels",
      "walk my walk",
      "breaking rust"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/why-the-music-industry-is-changing-its-tune-on-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/69386ca204d0f0a114f1b046?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.481Z",
    "topic": "entertainment"
  },
  {
    "slug": "the-startup-taking-direct-aim-at-nvidias-ai-iron-grip",
    "title": "The startup taking direct aim at Nvidia's AI iron grip",
    "description": "Chris Lattner helped build the software behind Google TPUs. Now he's coming after Nvidia.",
    "fullText": "In Silicon Valley, where bold technical bets abound, few bets look bolder than trying to break the grip of Nvidia's CUDA, a software stack that's quietly become the operating system of the AI boom.\n\nThat's what Modular, a startup founded by software gurus from Apple and Google, is trying to do.\n\nCofounders Chris Lattner and Tim Davis have spent decades building the software plumbing that sits beneath the modern tech industry. Lattner is famous for creating Apple's Swift programming language. He also built the software underpinning Google's TPU AI chips, with Modular cofounder Tim Davis.\n\nThey're now aiming that expertise at CUDA itself. The attempt borders on madness, but it's the kind of audacious project that could transform the AI industry.\n\n\"It's seen by a lot of people as somewhat crazy,\" said Kylan Gibbs, CEO of startup Inworld AI and a former product manager at Google DeepMind. \"That's where Chris has the advantage: He's smart enough to actually know how to do it, and somewhat crazy enough to set out to do it.\"\n\nCUDA began life almost 20 years ago as a way to make graphics chips programmable. Today, it has grown into a multilayered software ecosystem — language, libraries, compilers, inference systems — that most AI companies rely on.\n\nThat success comes at a cost: Most of the industry is now optimized around a single vendor's hardware. CUDA binds AI workloads to Nvidia GPUs. That is great for Nvidia, but deeply limiting for everyone else.\n\nOn the surface, there seems to be a ton of competition: AMD sells GPUs. Google has TPUs. Amazon created Trainium AI chips, and a host of startups are building similar hardware.\n\nThe problem is that each chip comes with its own software stack optimized just for that component. That means an endless reinvention of the wheel. Most of the time, it's simpler to just stick with CUDA — and Nvidia's GPUs.\n\nAnd yet, AI developers crave portability: Being able to use any combination of GPUs from multiple providers without juggling different software stacks.\n\n\"Nobody is building portable stuff, because why would anyone work on software for more than one chip when the chip projects themselves are doing the software?\" Lattner, Modular's CEO, told me in an interview.\n\nNvidia could extend CUDA to run well on rival AI chips. But doing so would undermine Nvidia's greatest moat: the closed-loop bond between its software and its chips. \"Obviously, they don't want portability,\" he said.\n\nFor Lattner, this paradox presents a big opportunity.\n\n\"We realized there's nobody in the industry that's actually incentivized to do this. It's very expensive, very hard,\" he said. \"And at the same time, everybody wants it.\"\n\nThat's what inspired Lattner and Davis to leave Google and start Modular in 2022, the year ChatGPT took the world by storm.\n\nSince then, Modular has raised $380 million from investors including Greylock, General Catalyst, and GV, Google's venture capital arm. The latest financing in September valued the startup at $1.6 billion. Modular isn't the only effort to break the CUDA lock-in. There has been ZLUDA, an open-source project that was funded by AMD, and more recently, the startup Spectral Compute, which has raised $6 million.\n\nLattner has used some of this money to hire talented programmers from Google, Apple, and other tech companies. They spent three years working in relative obscurity to create the building blocks of a new AI software stack.\n\nThe foundation starts with a brand-new programming language, called Mojo, that offers deep controls for making AI chips run as efficiently as possible.\n\nModular designed this to work similarly to Python, a popular and easy-to-use programming language. But Mojo also has the speed and power of other, more complex languages, such as C++, that are essential for AI development. Mojo also works well with PyTorch, an open-source framework that is often used when building AI models and applications.\n\nI first heard about Modular earlier this year when interviewing Carles Gelada, a former OpenAI researcher. \"There are several interesting projects to create GPU-agnostic frameworks and platforms, and challenge CUDA,\" he said at the time. \"Mojo is the most interesting one.\"\n\nMAX is the next major layer of Modular's new software stack. It powers AI inference, which is how models are run. This part of the system works with Nvidia GPUs, AMD GPUs, and similar chips from Apple. Modular hopes to add more AI chips in the future.\n\nOn top of that is another layer called Mammoth, which helps AI developers manage GPU clusters.\n\nIn late September, Modular announced that it got top performance out of Nvidia's new Blackwell B200 GPUs and AMD's latest MI355X GPUs — crucially on the same software platform.\n\nLattner said Modular got these AMD GPUs to perform roughly 50% better than when these chips run on AMD's own software.\n\nMore importantly, the ability to run different GPUs on the same software stack now supports the tantalizing opportunity to compare Nvidia's offerings with rival AI chips on a more level playing field.\n\n\"The obvious question is: can MI355X compete with Blackwell?\" Modular wrote in a blog announcing the results. \"Early signs point to yes.\"\n\nGibbs, the CEO of Inworld AI, has been putting Modular's software through its paces in the real world.\n\nInworld builds high-speed, real-time conversational AI technology that supports offerings from big companies, including Disney, NBCUniversal, and Niantic Labs.\n\nEarlier this year, when the startup designed a new text-to-speech AI model and got early access to Nvidia B200 GPUs, they issued Modular a challenge: Cut our costs by 60% and reduce our latency by 40% and we'll work with you.\n\n\"Within about four weeks, we were able to get this incredible performance,\" said Gibbs, who signed a partnership deal with Modular soon after. \"I've bet with my wallet.\"\n\nWhile Inworld was mostly lured by Modular's performance gains on Nvidia's latest GPUs, Gibbs likes the flexibility of using different AI chips more easily in the future, if needed.\n\n\"The promise is that we'd be able to move to new hardware,\" he said. \"Let's say AMD takes off, let's say TPUs take off for Google, or there could be other new hardware that comes online. So it's nice to have that optionality.\"\n\nIn fact, Google's TPUs are suddenly having a moment. The internet giant released a new AI model called Gemini 3 to rave reviews recently. That was trained and run using TPUs, and some other AI companies have signed deals to use these chips instead of, or alongside of, Nvidia GPUs.\n\nThat's put Nvidia on the defensive. A project like Modular, with its promise of portability across different AI hardware, adds to this pressure.\n\n\"Nvidia could kill this in a day,\" said Gibbs of the Modular project. \"Nvidia could basically say, 'okay, we don't really care that you run just on Nvidia hardware. Here's a CUDA option that runs on AMD GPUs as well.' It'd be a bit crazy for them to do that, but it's something they could do and that would of course be somewhat bad.\"\n\nFor all Lattner's critique of the industry, he says Modular is not trying to kill Nvidia. In fact, he argues that Nvidia will continue to thrive, even if Modular succeeds spectacularly.\n\n\"We're trying to build something like Android, but for AI hardware,\" he told me, referring to Google's mobile operating system that powers most of the world's smartphones.\n\nDespite billions of people using Android devices, this success didn't kill iOS, Apple's mobile operating system. iPhones still rule in the US, for example.\n\nLattner thinks something similar will happen in AI as Modular's software makes other hardware more competitive, giving developers more freedom, and chipping away at the industry's single-vendor monoculture.\n\n\"So Nvidia doesn't have to die, but we do want more competition. We do want more innovation,\" he said. \"I think that's good for the world.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 7,
    "keywords": [
      "tim davis",
      "let's say",
      "mobile operating",
      "operating system",
      "programming language",
      "somewhat crazy",
      "modular's software",
      "software stack",
      "amd gpus",
      "chips"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-ai-chip-gpu-grip-modular-chris-lattner-google-2025-12",
    "thumbnail_url": "https://i.insider.com/6938812f71107c9f3457a0d9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.387Z",
    "topic": "finance"
  },
  {
    "slug": "surge-ai-ceo-explains-why-he-hates-the-term-data-labeling",
    "title": "Surge AI CEO explains why he hates the term 'data labeling'",
    "description": "Surge AI CEO Edwin Chen said data labeling is often over-simplified. In his view, the work is \"a lot more like raising a child.\"",
    "fullText": "It could be easy to dismiss the work data-labeling firms do. Surge AI CEO Edwin Chen said that could stem from misunderstanding what they do.\n\n\"I think a lot of people think of data labeling as it relates to simplistic work, like labeling cat photos and drawing boundary marks around cars,\" Chen told Lenny Rachitsky on his \"Lenny podcast.\"\n\nChen, who previously worked at Google, Twitter, and Meta, said that he's \"always hated the word data labeling.\"\n\n\"Because it just paints this very simplistic picture when I think what we're doing is completely different,\" he said.\n\nSurge AI, which Chen founded in 2020, competes in the AI data labeling space with companies like Scale AI and Mercor. Surge also has a partnership with Anthropic and also runs DataAnnotation.tech, where freelancers can These remote workers are often referred to as \"ghost workers\" for their behind-the-scenes labor that is critical to AI's development.\n\nBeyond any rote work it can entail, Chen said data labeling is a much more creative endeavor. He compared what companies like Surge do to how parents instill lifelong values in their children.\n\n\"I think a lot about what we're doing as a lot more like raising a child,\" he said. \"You don't just feed a child information. You're teaching them values, and creativity, and what's beautiful, and these infinite subtle things about what makes somebody a good person.\"\n\nIn this way, Chen said, companies like Surge AI are \"raising humanity's children.\"\n\nChen's view can also be seen when you navigate to Surge's website, which greets visitors with the question: \"What made Hemingway, Kahlo, and von Neumann extraordinary?\"\n\n\"Their life experiences: war, love, triumph, loss. The people they met, the cities they explored, the thousand choices that made them who they were,\" the website reads. \"Data does for AI what life did for them — transforming it into intelligence that could one day prove the Riemann hypothesis, imagine new philosophies, and send rockets to the stars.\"\n\nChen previously worked in Big Tech at companies including Twitter, Google, and Facebook — and you might remember one of his Twitter projects.\n\nWhile at the company, roughly a decade before Elon Musk would acquire it, Chen became known for making the \"Pop vs. Soda\" map by geo-tagging data from tweets around the US to illustrate which word users used to refer to soft drinks.\n\nLooking back at starting Surge AI, Chen said he was surprised to find out that he never had to stop burying his head in the data.\n\n\"I thought if I started a company, I'd have to become a business person looking at financials all day, and being in meetings all day, and doing all this stuff that sounded incredibly boring, and I always hated,\" he told Rachitsky. \"So, I think it's crazy that didn't end up being true at all.\"\n\nChen said he wishes he had known that you don't need to spend \"constantly tweeting and hyping and fundraising.\"\n\n\"You don't need to become someone you're not,\" he said. \"You can actually build a successful company by simply building something so good that it cuts through all that noise. And I think if I had known this was possible, I would've started even sooner.\"\n\nDo you work in data labeling? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "we're doing",
      "surge ai",
      "labeling",
      "chen",
      "don't",
      "simplistic",
      "previously",
      "hated",
      "workers",
      "children"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/surge-ai-ceo-hates-term-data-labeling-2025-12",
    "thumbnail_url": "https://i.insider.com/69388e3f71107c9f3457a2a0?width=595&format=jpeg",
    "created_at": "2025-12-10T13:50:15.368Z",
    "topic": "finance"
  },
  {
    "slug": "robotics-industry-insider-says-the-future-is-one-soldier-bac",
    "title": "Robotics industry insider says the future is one soldier backed by AI controlling swarms of drones",
    "description": "Pilots being able to control many drones is \"kind of a prerequisite\" for \"the total drone warfare that is coming to all of us,\" Ark Robotics told BI.",
    "fullText": "The future of warfare will demand one soldier being able to control huge swarms of drones that can work together autonomously, a Ukrainian arms maker predicted.\n\nAchi, the CEO of Ukrainian defense firm Ark Robotics, told Business Insider the shift from one drone per pilot to one pilot controlling many is \"kind of a prerequisite to be successful in the total drone warfare that is coming to all of us.\"\n\nWith a one-pilot, one-drone system, the only way to scale up drone fleets is by expanding the number of operators.\n\n\"This is just not sustainable,\" Achi told Business Insider, using a pseudonym as a security precaution. \"You can scale drone manufacturing much more than you can pilots,\" he added.\n\nArk Robotics develops autonomous robots used by over 20 Ukrainian brigades and is creating a system that enables thousands of aerial drones and ground robots, including those not manufactured by the company, to collaborate with minimal human intervention. It's working toward single operator control of many drones.\n\nCountries around the world, from Ukraine to Western allies to rivals like Russia and China, are supercharging combat drone manufacturing. \"You can have all these fancy drones,\" Achi said, but \"what is the use of them if you can't really deploy them at scale?\"\n\nRussia's invasion of Ukraine has involved more drones than any other conflict in history, and innovation in their capabilities has been rapid. The West is paying attention, thinking about what it may need as it worries that Russia could spark a wider conflict with NATO.\n\nDrone technology is critical for Ukraine, vastly outnumbered by Russia's significantly larger military, as it offers mass. But one drone per operator doesn't offer anywhere near the advantage that swarming could. And reducing human involvement and embracing autonomy can accelerate combat action. That's why interest in swarm technology is surging.\n\nThere is no confirmed deployment of large, fully autonomous swarms of drones that can act without significant human oversight on the battlefield, but it would be absolutely game-changing.\n\nThat kind of capability opens up \"a whole world of tactics and strategies that we've not even thought of yet,\" James Patton Rogers, a drone expert at the Cornell Brooks Tech Policy Institute, previously told Business Insider.\n\nThe combat system that Ark is working on, called Frontier, is still in the prototype stage and is just one example of many efforts in Ukraine. The Ukrainian government says the country is pushing for the technology, but \"these systems are also just getting started,\" Achi said.\n\nUkraine demonstrates that quantity can become a kind of quality, he said, explaining that \"to really get an advantage of that, you need these asymmetrical systems that allow you to work with multiple drones at the same time.\"\n\nThat's a lesson for the West as much as it is for Ukraine.\n\nWestern officials, defense experts, and industry insiders have cautioned that to meet Russia's style of warfare — heavily attritional, masses of drones and missiles, and intense artillery barrages — militaries need a greater volume of cheap weapons developed and produced quickly, not a limited stockpile of highly advanced systems developed over decades and produced over years.\n\nDrone swarms are key to that kind of war.\n\nThere's no guarantee that drones would play as significant a role in a war involving the West as they have in Ukraine — in part because Ukraine's reliance on them is tied to shortages of other weaponry and other capability disadvantages.\n\nBut many officials still warn that the West needs far more drone and counter-drone capabilities. Swarming systems are among them.\n\nSwedish Defense Minister Pål Jonson told Business Insider that his country identified the need for drone swarms from watching this war and that it has rushed to produce technology to allow one soldier to autonomously control up to 100 drones. It's not clear when that could be operational. Other NATO members are working on this technology, too.\n\nHowever, there is still no broad NATO-wide investment in these capabilities and no clear sense of when — or whether — they could be fielded. Across the alliance, many officials warn that lessons aren't being acted on fast enough and that production of weaponry remains too slow. It's also unclear how autonomous future systems will actually be.\n\nAchi said the current autonomy in defense systems is \"greatly overhyped,\" but noted that the battlefield shows autonomy is necessary and \"past the point of no return.\"\n\nThere is acknowledgment, from industry and officials, that autonomy is needed to break past manpower limits, increase speed, and keep troops safer.\n\nThe CEO of Origin Robotics, a drone maker in NATO member Latvia that supplies Ukraine, previously told Business Insider he sees autonomy as essential to NATO’s defense, especially for the smaller member states bordering Russia.\n\n\"For a NATO country, you need a scalable solution,\" Agris Kipurs argued. \"Autonomy, in our case, is what allows us to scale. We don't have the numbers in terms of infantry.\"\n\nAchi said he wants Europe not only to learn from Ukraine and catch up to its drone leadership, but to think further ahead. He described Europe as \"having the time\" compared to Ukraine, which is fighting for survival.\n\nIf Europe's increased defense spending \"goes to outdated technology or just wrongly copied technology, it doesn't make any sense to me,\" he said. \"So I want to see them thinking a few steps ahead and taking lessons from the lessons.\"",
    "readingTime": 5,
    "keywords": [
      "drone per",
      "drone manufacturing",
      "business insider",
      "drone swarms",
      "ark robotics",
      "drones",
      "technology",
      "achi",
      "defense",
      "autonomy"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/future-war-needs-one-soldier-controlling-many-drones-ukraine-ceo-2025-12",
    "thumbnail_url": "https://i.insider.com/693831827ecd1d1da6632bd9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.897Z",
    "topic": "finance"
  },
  {
    "slug": "when-will-the-stock-markets-ai-juggernauts-start-spreading-t",
    "title": "When will the stock market's AI juggernauts start spreading the wealth to other companies?",
    "description": "The S&P 493 has a lot of catching up to do, and 2026 could be key turning point.",
    "fullText": "It's human nature to want more of a good thing.\n\nThat's how we ended up with 10 Fast & Furious movies (and counting). It's also how Tom Brady scored his seventh Super Bowl ring, with the Buccaneers, after being cast off by the Patriots.\n\nWhen you've had a taste of greatness, it's normal to keep pushing.\n\nThis same logic can be applied to the stock market. The S&P 500 is up big again, for a third straight year. It's been a veritable bonanza for 401(k)s everywhere. Yet there's a clear dividing line between the haves and have-nots: exposure to the Magnificent 7.\n\nYes, the annual percentage return for the S&P 500 has been solidly in the teens and mid-20s in recent years, but the Mag 7's gain over similar periods have dwarfed that.\n\nEven though everyday investors have been doing just fine, it's normal to have a bit of FOMO about a trade that's doing even better. And although the S&P 500 is naturally weighted towards the Mag 7, why not aspire for more?\n\nThis all begs the question: When will the other 493 companies in the S&P finally feel the same love that the Mag 7 has enjoyed these last couple of years?\n\nThe answer is: potentially soon! At least if the likes of HSBC are to be believed.\n\nWhile HSBC's S&P 500 price target of 7,500 — and its reasons for bullishness — are largely in line with consensus, the firm's view that the S&P 493 could start catching up to the Mag 7 commands attention.\n\nThe main argument is that continued heavy capital spending will slow Mag 7 earnings growth (except for Nvidia, from which the other companies will be buying).\n\nThis is reflected in the chart below, which shows Mag 7 earnings growth (gray line) converging with S&P 493 profit expansion (black line) throughout 2026 after years of outpacing it.\n\n\"That could open the door for companies outside the Magnificent 7 to outperform,\" HSBC's strategists wrote, noting that outsized earnings growth has been key for the tech elite.\n\nThis expansion of returns — known as breadth — will be particularly key for stock-pickers who make their hay when there are more gains to go around. It will also be a key sign of health for skeptics wary of heavy tech concentration.\n\nIf it pans out, it should be enough to placate investors hungry for more. Then it's on to the next aspirational frontier.",
    "readingTime": 3,
    "keywords": [
      "mag earnings",
      "earnings growth",
      "it's normal",
      "that's",
      "investors",
      "doing",
      "heavy",
      "expansion",
      "tech",
      "magnificent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stock-market-breadth-2026-outlook-magnificent-7-spx-493-2025-12",
    "thumbnail_url": "https://i.insider.com/6938b40b71107c9f3457a63d?width=1024&format=jpeg",
    "created_at": "2025-12-10T13:50:14.885Z",
    "topic": "finance"
  },
  {
    "slug": "dealmaking-in-the-ai-age-is-tricky",
    "title": "Dealmaking in the AI age is tricky",
    "description": "Five months after Meta's $14 billion investment into Scale AI, the once-buzzy startup is facing turmoil.",
    "fullText": "A startup nabbing a $14 billion investment from one of the top tech companies seems like a good thing. The reality is a lot more complicated.\n\nScale AI has faced a turbulent five months since Meta purchased a 49% stake in the startup, write BI's Charles Rollet and Ben Bergman. Once a leader in the field of stress testing and perfecting AI models for Big Tech, Scale AI has faced pay cuts, poaching, and pivots since the Meta deal.\n\nIt's representative of how dealmaking with big players can be a double-edged sword in the age of AI.\n\nFor some, like Scale AI cofounder Alexandr Wang, who's now a high-level Meta exec, the deal was a windfall. However, according to interviews with five current and former contractors and internal correspondence obtained by BI, Scale AI has faced some inner turmoil following the Meta deal.\n\nJoe Osborne, a Scale AI spokesperson, strongly disputed that the startup's business has been in trouble since the Meta investment and said this quarter is on track to be the company's biggest of the year.\n\nNot all of Scale AI's issues are related to the Meta deal. A BI investigation this June found Scale AI routinely used public Google Docs for work with its Big Tech clients. (There was no indication of a breach, and Scale did lock down the documents after BI's report about the issue.) It also faced litigation over claims it misclassified and underpaid contract workers.\n\nBut one of the larger problems stems from some Big Tech companies pausing work with Scale now that one of their competitors — Meta — is its biggest backer.\n\nThe AI environment means more startups could encounter similar issues.\n\nThe Scale AI-Meta deal was unique in many ways, but there are still lessons to be learned from the aftermath.\n\nThe top-heavy ecosystem of the AI marketplace means there are a limited number of landing spots for startups looking for exit opportunities. Add in the ultra-competitive nature of the space, and a deal with one company could mean the end of business with the others.\n\nOf course, not every startup will get acquired by a tech giant. And yes, some startups will have products that companies will need to use regardless of their backers. But for the vast majority of young AI companies, that's not a reality.\n\nSo, if the industry faces a bit of turmoil and funding dries up, startups may have some difficult decisions about who they cut deals with and which doors could close to them.",
    "readingTime": 3,
    "keywords": [
      "meta deal",
      "scale ai",
      "big tech",
      "faced",
      "startups",
      "startup",
      "investment",
      "reality",
      "bi's",
      "turmoil"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-newsletter-dealmaking-in-the-ai-age-is-tricky-2025-12",
    "thumbnail_url": "https://i.insider.com/693897a004d0f0a114f1b5c9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.876Z",
    "topic": "finance"
  },
  {
    "slug": "this-startup-is-using-ai-agents-to-automate-hr-tasks-like-on",
    "title": "This startup is using AI agents to automate HR tasks like onboarding. Read the pitch deck it used to raise $24 million.",
    "description": "Shapes, formerly DreamTeam, has created AI agents to perform routine HR tasks and proactively flag things like flight risks.",
    "fullText": "A Tel Aviv startup that uses AI agents to automate HR processes like onboarding and compensation has raised $24 million in funding.\n\nThe HR platform from Shapes essentially offers an app store of AI-based HR tools.\n\n\"It means that you can manage your employees your own way. You can install different apps and agents in order to do the job for you,\" Shapes cofounder and CEO Arnon Nir told Business Insider.\n\nFor example, an AI agent can proactively notify a member of HR that an employee is at risk of leaving, based on data points such as low salary, high performance, and recent absences.\n\nThe startup's AI agents can automate other workflows, such as payroll or contract drafting, based on prompts from HR staff. Employees can use the platform for HR tasks such as booking time off and also ask AI agents for information, including details about company policies.\n\nShapes, which has rebranded from DreamTeam, was founded in 2020 by Nir and Shirley Baumer, who were previously founding members of HR tech company Monday.com.\n\nIn addition to the app store-like structure, which the startup calls \"PeopleOS,\" customers can build their own bespoke applications on the platform using prompts, similar to vibe coding.\n\nShapes says its modular design can help companies scale up and down as the size of workforces fluctuates in the AI era.\n\n\"Every company needs to rethink its structure, its people, its culture. And every company needs to kind of find itself from scratch,\" Baumer told Business Insider.\n\nThe HR tech market is highly competitive, with an increasing number of players — such as Workday and HiBob — integrating AI into their solutions. Nir said the modular nature of its software is one of its competitive advantages.\n\n\"Every company works differently. You want to give them the power to decide what they want to use,\" Nir said.\n\nShapes says it has \"hundreds of customers\" located in 79 countries and spanning 14 industries, including retail, manufacturing, and technology. Its customers include Quantum Machines, NextSilicon, Healthee, Arena Entertainment, and Imagen, according to Shapes. It operates as a software-as-a-service business model, charging a flat rate per employee at the company.\n\nThe funding consists of $15 million in Series A, closed in October, and a previously unannounced $4.5 million seed investment, as well as a $4.5 million seed extension. The Series A round was led by Entrée Capital, with participation from NFX and F2 Venture Capital, which led the seed round.\n\nShapes said it would use the funding to more than double its head count over the next year and expand into new markets.\n\nHere's an exclusive look at the 10-page pitch deck Shapes used to raise $24 million.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "agents",
      "funding",
      "platform",
      "customers",
      "seed",
      "shapes",
      "startup",
      "automate",
      "employees"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/shapes-pitch-deck-funding-hr-ai-agents-dreamteam-2025-12",
    "thumbnail_url": "https://i.insider.com/6939592271107c9f3457aa34?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.757Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-giving-workers-the-illusion-of-expertise-and-quietly-m",
    "title": "AI is giving workers the illusion of expertise — and quietly making them worse at their jobs, researchers say",
    "description": "Researchers say that overrelying on AI can dull critical thinking, distort expertise, and disrupt how workers learn and advance.",
    "fullText": "Have you caught yourself feeling unusually confident at work — or unsure about errors slipping through your workflow?\n\nA new report from the Work AI Institute, produced with researchers from universities including Notre Dame, Harvard, and UC Santa Barbara, and released on Wednesday, said that AI is turning ordinary office workers into people who feel smarter and more productive while their underlying skills slowly erode.\n\n\"AI is putting expertise into our hands in a way that's not always predictable,\" Rebecca Hinds, head of the Work AI Institute at workplace search company Glean and the report's coauthor, told Business Insider.\n\n\"There's often this illusion that you have more expertise, more skills than you actually do,\" she said. \"Even if you're very well aware you're using the technology, it's often unclear where your knowledge ends and where the technology begins.\"\n\nHinds drew a parallel to the rise of search engines, when people began to mistake easy access to information for genuine understanding.\n\nWith generative AI, she said, that illusion is even more powerful — and the risks are higher.\n\nHinds said these risks are most obvious in creative and knowledge-intensive roles.\n\nWorkers are increasingly using AI to beat the \"blank page,\" she said, and generate first drafts of writing.\n\nThat speeds things up, she said, but it also strips away the messy, time-consuming work of wrestling with ideas.\n\n\"The more you poke holes in it, the more it feels yours and the more you commit to it, and the more you're able to fight for it in a meeting if someone pushes back,\" she said.\n\n\"That process is highly inefficient,\" she added, \"but it's also really healthy.\" And if workers lean too heavily on AI to skip it, \"your skills are going to atrophy.\"\n\nThe report suggested that AI can create either a \"cognitive dividend\" or \"cognitive debt.\"\n\nUsed intentionally, as a partner in domains where you already have expertise, it can free up time and sharpen judgment. However, used as a reflexive shortcut, it leads to weaker skills and misplaced confidence, it said.\n\nHinds said that the roles with the highest exposure are early-career jobs.\n\nThose are the roles that traditionally function as apprenticeships: junior developers learning from senior engineers, entry-level marketers learning how to build campaigns, and young analysts learning how to structure a model from scratch, she said.\n\nIf those tasks are automated away or if juniors rely entirely on AI to do them, they may never develop the underlying skills they need to advance, she said.\n\nHinds said leaders are often unintentionally exacerbating the illusion-of-expertise problem.\n\nA big red flag, she said, is \"organizations stack-ranking employees based on how many times they're clicking an AI tool as a marker of AI adoption or AI productivity or AI success.\"\n\nIn some companies, usage metrics are tied directly to performance reviews.\n\nEmployees \"are incentivized to click the tool more rather than invest in a deep understanding of the tool,\" she added.\n\nInstead, she said, companies should tie AI to existing business goals — quality, customer satisfaction, innovation — and measure whether it actually improves those, not just how often it's used.\n\nHinds doesn't think the solution is to shun AI. She thinks it's to be far more deliberate about its use.\n\nShe recommended three questions for workers and leaders:\n\nAI \"does not magically transform you as a leader,\" Hinds said. \"More often, it amplifies what already exists within the organization.\"",
    "readingTime": 3,
    "keywords": [
      "underlying skills",
      "work ai institute",
      "workers",
      "it's",
      "expertise",
      "you're",
      "roles",
      "learning",
      "tool",
      "hinds"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-making-workers-feel-smarter-but-worse-at-their-jobs-2025-12",
    "thumbnail_url": "https://i.insider.com/69394f787ecd1d1da6634165?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.746Z",
    "topic": "finance"
  },
  {
    "slug": "howard-marks-says-ai-is-going-to-have-a-terrifying-impact-on",
    "title": "Howard Marks says AI is going to have a 'terrifying' impact on employment — and it goes well past lost paychecks",
    "description": "Howard Marks, cofounder of Oaktree Capital Management, said AI could strip people of the structure, purpose, and self-worth they gain from work.",
    "fullText": "That's one of the words legendary investor Howard Marks used to describe the impacts of AI on the workforce.\n\n\"I find the resulting outlook for employment terrifying. I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can't find jobs because of it,\" Marks wrote in his latest blog post on Tuesday.\n\nThe billionaire and cofounder of Oaktree Capital Management has been writing memos for 35 years; in one recent post, he experimented with using AI to assist him in writing.\n\nTech leaders such as Elon Musk and OpenAI CEO Sam Altman have called for versions of a universal basic income — a guaranteed income paid regularly to all adults if jobs become obsolete — as a solution to AI-related job and pay loss.\n\nBut Mark said that even if governments find a way to fund universal basic incomes, it doesn't account for a key issue: That people get a lot more from jobs than just a paycheck.\n\n\"A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect,\" he said.\n\n\"How will these things be replaced? I worry about large numbers of people receiving subsistence checks and sitting around idle all day,\" he added.\n\nThe estimates on how many jobs will be affected by AI vary. An IMF analysis from 2024 suggested that around 60% of jobs in advanced economies will be affected by AI, with half benefiting from the technology and the other being negatively impacted by it.\n\nA McKinsey Global Institute report released last month found that technologies could automate more than half of US work hours.\n\nBut Marks isn't alone in worrying about what happens to meaning when work vanishes.\n\nKate O'Neill, a tech advisor who helps companies navigate AI ethics and digital transformation, said in a recent TED Talk that as we hand more decisions and language over to AI, we risk surrendering a fundamentally human capacity — creating meaning from lived experience — not just losing tasks to machines.\n\nJames Barrat, author of \"The Intelligence Explosion: When AI Beats Humans at Everything,\" told Business Insider he believes people can find new purpose in a universal basic income world through volunteering and community service work — but only after a long, painful transition in which many lose jobs before rebuilding meaning somewhere else.\n\nIf AI is set to reshape work as profoundly as some people expect, tech leaders say young people will need to develop skill sets machines can't easily mimic.\n\nGeoffrey Hinton, the so-called godfather of AI, has said that \"mundane intellectual labor\" roles are most at risk because of AI.\n\n\"I'd say it's going to be a long time before it's as good at physical manipulation,\" Hinton said of AI earlier this year. \"So a good bet would be to be a plumber.\"\n\nOpenAI's chief economist, Ronnie Chatterji, said he is teaching his kids the importance of critical thinking, emotional intelligence, and flexibility — preparing them for a world in which job titles shift faster than curricula can keep pace.\n\nElon Musk recently said that while some of his older children recognize how quickly their skills could be overtaken by AI, he still supports them going to college.\n\n\"If you want to go to college for social reasons, I think that's a reason to go — to be around people your own age in a learning environment,\" he said.\n\n\"If you do, just try to learn as much as possible across a wide range of subjects,\" he added.",
    "readingTime": 3,
    "keywords": [
      "tech leaders",
      "universal basic",
      "basic income",
      "jobs",
      "that's",
      "can't",
      "affected",
      "half",
      "risk",
      "machines"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-kills-jobs-paychecks-human-purpose-howard-marks-investor-2025-12",
    "thumbnail_url": "https://i.insider.com/693950fa7ecd1d1da663416d?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.746Z",
    "topic": "finance"
  },
  {
    "slug": "the-boundary-of-copyrightability-in-aigenerated-code-under-j",
    "title": "The boundary of copyrightability in AI-generated code under Japan and US Law",
    "description": "When GitHub Copilot first appeared, many developers viewed it as an assistive tool for coding. The honest impression of most developers was likely that while it was useful, it was not a tool to whi…",
    "fullText": "A Curious Phenomenon with Gemma Model Outputs and License Propagation While examining the licensing details of Google’s Gemma model, I noticed a potentially puzzling phenomenon: you can freely assign a license to the model’s outputs, yet depending on how those outputs are used, the original Terms of Use might suddenly propagate to the resulting work. Outputs vs. Model Derivatives The Gemma Terms of Use distinguish…",
    "readingTime": 1,
    "keywords": [
      "gemma model",
      "outputs",
      "license",
      "phenomenon"
    ],
    "qualityScore": 0,
    "link": "https://shujisado.org/2025/12/10/the-boundary-of-copyrightability-in-ai-generated-code/",
    "thumbnail_url": "https://shujisado.org/wp-content/uploads/2025/12/chatgpt-image-2025e5b9b412e69c8810e697a5-21_53_59.png",
    "created_at": "2025-12-10T13:50:09.359Z",
    "topic": "tech"
  },
  {
    "slug": "launching-bestmakerai-a-unified-tool-for-fast-ai-image-and-v",
    "title": "Launching Bestmaker.ai – A Unified Tool for Fast AI Image and Video Creation",
    "description": "BestMaker AI gives you a Photoshop-level editor powered by natural language. Remove elements, change backgrounds, and build mockups with precise prompts—no manual masking required.",
    "fullText": "BestMaker AI is an AI-based video generation tool that helps users easily create high-quality AI videos through simple text descriptions or images.\n\nBestMaker AI offers various AI video generation features, including text-to-video, image-to-video, and more. Browse the AI video examples below to see what types of content our AI video generator can create.\n\nBestMaker AI is a powerful and easy-to-use AI video generation platform. Whether you are a content creator, marketer, or casual user, BestMaker AI can help you quickly create professional-grade AI videos.\n\nGet free credits daily to experience AI video generation without paying\n\nGenerate high-definition 4K videos with clear and delicate picture quality\n\nSupports various mainstream AI models to meet different creative needs\n\nSimple and easy-to-use interface, no professional skills required\n\nSupports various video styles, from realistic to animated\n\nRich video template library to quickly start your creation\n\nBestMaker AI's text-to-video feature allows you to generate high-quality AI videos by simply entering a text description. Supports multiple AI models, including Minimax, Hunyuan, Kling, Pika, etc., providing you with diverse creative choices.\n\nBestMaker AI values user privacy and data security. We use advanced encryption technology to protect your data and ensure your creative content is safe and reliable.\n\nAll data transmission uses SSL encryption\n\nYour data will not be used for other purposes\n\nVideo files are securely stored in the cloud\n\nIn addition to AI video generation, BestMaker AI also offers a variety of AI tools to help you complete more creative work.\n\nIntelligently expand image boundaries\n\n\"BestMaker AI is the best AI video generation tool I've ever used! Fast generation, clear picture quality, highly recommended!\"\n\n\"Using BestMaker AI has greatly improved our video production efficiency, saving a lot of time and cost.\"\n\n\"The interface is simple and easy to use, and the AI-generated videos are amazing. It has become an essential tool for my creation.\"\n\nStart using BestMaker AI now and experience the charm of AI video generation.",
    "readingTime": 2,
    "keywords": [
      "bestmaker ai",
      "supports various",
      "generation tool",
      "videos",
      "creative",
      "create",
      "simple",
      "content",
      "high-quality",
      "text"
    ],
    "qualityScore": 0.9,
    "link": "https://bestmaker.ai",
    "thumbnail_url": "https://bestmaker.ai/og.png",
    "created_at": "2025-12-10T06:58:06.671Z",
    "topic": "tech"
  },
  {
    "slug": "protocol-omega-defining-ai-identity-via-topology-instead-of",
    "title": "Protocol Omega: Defining AI Identity via Topology Instead of Biological Mimicry",
    "description": "A Topological Ontology for AGI. Contribute to IkanRiddle/Protocol-Omega development by creating an account on GitHub.",
    "fullText": "IkanRiddle\n\n /\n\n Protocol-Omega\n\n Public\n\n A Topological Ontology for AGI\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n IkanRiddle/Protocol-Omega",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/IkanRiddle/Protocol-Omega",
    "thumbnail_url": "https://opengraph.githubassets.com/16db97aa45732e27cf7a5bdc9bdbcc00ccd89c1a9da9f35a7370850bcad25d36/IkanRiddle/Protocol-Omega",
    "created_at": "2025-12-10T06:58:06.258Z",
    "topic": "tech"
  },
  {
    "slug": "huggingface-skills-finetune-any-llm-with-one-sentence-for-03",
    "title": "HuggingFace Skills: Fine-tune any LLM with one sentence for $0.30",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "We gave Claude the ability to fine-tune language models using a new tool called Hugging Face Skills. Not just write training scripts, but to actually submit jobs to cloud GPUs, monitor progress, and push finished models to the Hugging Face Hub. This tutorial shows you how it works and how to use it yourself.\n\nClaude Code can use \"skills\"—packaged instructions, scripts, and domain knowledge—to accomplish specialized tasks. The hf-llm-trainer skill teaches Claude everything it needs to know about training: which GPU to pick for your model size, how to configure Hub authentication, when to use LoRA versus full fine-tuning, and how to handle the dozens of other decisions that go into a successful training run.\n\nWith this skill, you can tell Claude things like:\n\nThe model trains on Hugging Face GPUs while you do other things. When it's done, your fine-tuned model appears on the Hub, ready to use.\n\nThis isn't a toy demo. The skill supports the same training methods used in production: supervised fine-tuning, direct preference optimization, and reinforcement learning with verifiable rewards. You can train models from 0.5B to 70B parameters, convert them to GGUF for local deployment, and run multi-stage pipelines that combine different techniques.\n\nHugging Face skills are compatible with Claude Code, Codex, and Gemini CLI. With integrations on the way for Cursor, Windsurf, and Continue.\n\nThis repo includes gemini-extension.json to integrate with the Gemini CLI.\n\nYou have to authenticate to your Hugging Face account with a write-access token so that the job can create a model repo.\n\nConfigure Hugging Face MCP Server to use your write token by sending it in either the HF_TOKEN or Authorization: Bearer HTTP Headers.\n\nFor Claude Code : claude mcp add --transport http hf-skills https://huggingface.co/mcp?bouquet=skills --header \"Authorization: Bearer $HF_TOKEN\"\n\nLet's walk through a complete example. We'll fine-tune a small model to see the full workflow, then explore more advanced capabilities.\n\nStart with a simple and clear instruction to fine tune a specific model\n\nThe coding agent analyzes your request and prepares a training configuration. For a 0.6B model on a demo dataset, it selects t4-small—enough GPU for this model size and the cheapest option available.\n\nThe open-r1/codeforces-cots dataset is a dataset of codeforces problems and solutions. It is a good dataset for instruction tuning a model to solve hard coding problems.\n\nBefore your coding agent submits anything, you'll see the configuration:\n\nThis is your chance to adjust anything. Change the output repo name, pick different hardware, or ask Claude to modify training parameters. Once you approve, the agent submits the job.\n\nFor example, you can ask the agent to try a test run:\n\nAfter submission, you get job details:\n\nThe skill includes Trackio integration, so you can watch training loss decrease in real-time. Jobs run asynchronously so you can close your terminal and come back later. When you want an update:\n\nThen the agent fetches the logs and summarizes progress.\n\nClick here for an example Trackio dashboard with some completed runs.\n\nWhen training completes, your model is on the Hub:\n\nThat's the full loop. You described what you wanted in plain English, and the agent handled GPU selection, script generation, job submission, authentication, and persistence. The whole thing cost about thirty cents.\n\nThe skill supports three training approaches. Understanding when to use each one helps you get better results.\n\nSFT is where most projects start. You provide demonstration data—examples of inputs and desired outputs—and training adjusts the model to match those patterns.\n\nUse SFT when you have high-quality examples of the behavior you want. Customer support conversations, code generation pairs, domain-specific Q&A—anything where you can show the model what good looks like.\n\nThe agent validates the dataset, selects hardware (a10g-large with LoRA for a 7B model), and configures training with checkpoints and monitoring.\n\nFor models larger than 3B parameters, the agent automatically uses LoRA (Low-Rank Adaptation) to reduce memory requirements. This makes training 7B or 13B models feasible on single GPUs while preserving most of the quality of full fine-tuning.\n\nDPO trains on preference pairs—responses where one is \"chosen\" and another is \"rejected.\" This aligns model outputs with human preferences, typically after an initial SFT stage.\n\nUse DPO when you have preference annotations from human labelers or automated comparisons. DPO optimizes directly for the preferred response without needing a separate reward model.\n\nDPO is sensitive to dataset format. It requires columns named exactly chosen and rejected, or a prompt column with the input. The agent validates this first and shows you how to map columns if your dataset uses different names.\n\nGRPO is a reinforcement learning task that is proven to be effective on verifiable tasks like solving math problems, writing code, or any task with a programmatic success criterion.\n\nThe model generates responses, receives rewards based on correctness, and learns from the outcomes. This is more complex than SFT or DPO, but the configuration is similar.\n\nThe agent selects hardware based on your model size, but understanding the tradeoffs helps you make better decisions.\n\nFor tiny models under 1B parameters, t4-small works well. These models train quickly—expect $1-2 for a full run. This is perfect for educational or experimental runs.\n\nFor small models (1-3B), step up to t4-medium or a10g-small. Training takes a few hours and costs $5-15.\n\nFor medium models (3-7B), you need a10g-large or a100-large with LoRA. Full fine-tuning doesn't fit, but LoRA makes these very trainable. Budget $15-40 for production.\n\nFor large models (7B+), this HF skills job is not suitable.\n\nWhen testing a workflow, start small:\n\nTh coding agent configures minimal training—enough to verify your pipeline works without real cost.\n\nAlways run a demo before committing to a multi-hour production job. A $0.50 demo that catches a format error saves a $30 failed run.\n\nDataset format is the most common source of training failures. The agent can validate datasets before you spend GPU time.\n\nThe agent runs a quick inspection on CPU (fractions of a penny) and reports:\n\nIf your dataset needs transformation, the agent can show you how:\n\nThe agent provides mapping code and can incorporate it directly into your training script.\n\nReal-time monitoring helps you catch problems early. The skill configures Trackio by default—after submitting a job, you can watch metrics at:\n\nThis shows training loss, learning rate, and validation metrics. A healthy run shows steadily decreasing loss.\n\nAsk the agent about status anytime:\n\nIf something goes wrong, the agent helps diagnose. Out of memory? the agent suggests reducing batch size or upgrading hardware. Dataset error? The agent identifies the mismatch. Timeout? The agent recommends longer duration or faster training settings.\n\nAfter training, you might want to run your model locally. The GGUF format works with llama.cpp and dependent tools like LM Studio, Ollama, etc.\n\nThe agent submits a conversion job that merges LoRA adapters, converts to GGUF, applies quantization, and pushes to Hub.\n\nWe've shown that coding agents like Claude Code, Codex, or Gemini CLI can handle the full lifecycle of model fine-tuning: validating data, selecting hardware, generating scripts, submitting jobs, monitoring progress, and converting outputs. This turns what used to be a specialized skill into something you can do through conversation.\n\nThe skill is open source. You can extend it, customize it for your workflows, or use it as a starting point for other training scenarios.\n\nIs this still usable without a Pro account? Will it be able to output everything up to \"Submit the job to Hugging Face Jobs\"?\n\nIs there data privacy when doing this?\n\nIs it posted privately to a personal/team hub?\n\nCould this be done locally without the push to the repo?\n\nAnother agentic way of wasting tokens\n\nis it possible to use this inside vscode's copilot extension ?\n\nSkill documentation is not available at the provided link - https://github.com/huggingface/skills/blob/main/hf-llm-trainer/SKILL.md\n\nAh, we moved a couple of bits around in the repo -- link for that is here: https://github.com/huggingface/skills/blob/main/hf-llm-trainer/skills/model-trainer/SKILL.md -- I'll update the article 👍.\n\n\"Really fascinating read! I found the explanation of Hugging Face’s “Skills Training” initiative — how it lets you use a coding‑agent (like Claude Code or other supported agents) to fine‑tune large language models, submit GPU jobs, monitor progress and push trained models to the Hub — particularly eye‑opening. The combination of high‑level instructions, hardware selection, monitoring, and automation makes the complex process of model training much more approachable, even for developers who may not be ML‑infrastructure experts.\n\nI also recently read a related guide: https://mobisoftinfotech.com/resources/blog/ai‑development/llm‑api‑pricing‑guide\n — which gives practical advice on LLM API usage, token‑based pricing, and how to plan costs when working with LLMs.\n\nPutting your article’s look into empowering accessible LLM fine‑tuning together with the cost‑management strategies from that guide gives a well‑rounded perspective: it helps developers understand not just what is possible now with modern tools, but also how to build and deploy responsibly, balancing capability and cost.\"\n\nGreat work and great article!\nRegarding the maximum models size we can train using this approach, at the beginning of the article it's mentioned \"models from 0.5B to 70B parameters\" but at the end you write that \"For large models (7B+), this HF skills job is not suitable\", which order of magnitude is correct?\nI suspect the max range is 7B, if it's the case, do you plan to support training of larger models?\nThanks!\n\nis the trained model now open source and / or available to the public?\n\n·\n Sign up or\n log in to comment",
    "readingTime": 8,
    "keywords": [
      "authorization bearer",
      "code codex",
      "face skills",
      "reinforcement learning",
      "monitor progress",
      "skill supports",
      "selects hardware",
      "language models",
      "dataset format",
      "agent submits"
    ],
    "qualityScore": 1,
    "link": "https://huggingface.co/blog/hf-skills-training",
    "thumbnail_url": "https://huggingface.co/blog/assets/hf-skills-training/thumbnail.png",
    "created_at": "2025-12-10T06:58:06.257Z",
    "topic": "tech"
  },
  {
    "slug": "the-box-run-multiple-claude-cli-agents-in-parallel-in-the-cl",
    "title": "The Box – Run multiple Claude CLI agents in parallel in the cloud",
    "description": "AI-powered task management dashboard. Automate your workflow with Claude and boost productivity.",
    "fullText": "Write prompts, let Claude handle the code. From idea to pull request in minutes.\n\nDescribe what you want Claude to do...\n\nRun Claude Code directly in your browser with real-time monitoring, GitHub integration, and secure isolated environments.\n\nWatch Claude work live in your browser. No setup required, just instant feedback loop.\n\nMultiple models: Sonnet, Haiku, and Opus. Choose what fits your task.\n\nAutomatic pull request creation and branch management.\n\nIsolated containers for each task. Safe and reliable execution environment for your critical code.\n\nWrite your prompt, watch Claude execute in real-time, and get automatic pull requests. From idea to deployment in minutes.\n\nWrite a prompt describing what you want Claude to do. Select your repository, branch, and Claude model.\n\nWatch Claude work in real-time with live updates. Review plans before they execute.\n\nClaude automatically creates a branch and opens a pull request ready for review and merging.\n\nThe Box brings Claude Code to your browser. \nNo setup, just instant AI-powered development.",
    "readingTime": 1,
    "keywords": [
      "watch claude",
      "request",
      "browser",
      "real-time",
      "branch",
      "idea",
      "minutes",
      "isolated",
      "setup",
      "instant"
    ],
    "qualityScore": 0.95,
    "link": "https://the-box.dev",
    "thumbnail_url": "https://the-box.dev/opengraph-image?c0f8cc326d54014e",
    "created_at": "2025-12-10T06:58:05.702Z",
    "topic": "tech"
  },
  {
    "slug": "learnflux-aipowered-learning-assistant",
    "title": "LearnFlux: AI-Powered Learning Assistant",
    "description": "LearnFlux is an AI-powered learning assistant that helps you learn smarter and faster. Personalized learning paths, intelligent tutoring, and adaptive practice.",
    "fullText": "LearnFlux uses AI to convert your study materials into interactive flashcards, quizzes, and practice tests.\nLearn smarter, retain longer, and master any subject faster.\n\nLearnFlux is powered by cutting-edge technology\n\nLearnFlux is your AI-powered learning companion that transforms any content into interactive study materials, helping you learn smarter and faster.\n\nTransform PDFs, videos, audio, and web links into organized notes you can edit and share. Your content, instantly structured.\n\nAutomatically create quizzes, flashcards, and practice tests from your notes. Study smarter, not harder.\n\nLearnFlux actively works alongside you - highlighting key concepts, adding smart comments, and guiding your learning journey.\n\nUpload PDFs, paste video links, record audio lectures, or import documents. LearnFlux handles it all seamlessly.\n\nTransform your study materials into interactive learning resources in four simple steps:\n\nRecord lectures live or upload PDFs, videos, audio files, and documents. Works with any format you need.\n\nOur AI transcribes and analyzes your content, identifying key concepts and creating structured editable notes.\n\nReceive comprehensive notes, flashcards, quizzes, and podcasts tailored to your learning needs.\n\nAccess materials anywhere, share with classmates, and use built-in study modes to ace your exams.\n\nEverything you need to transform your study experience and accelerate your learning journey.\n\nUpload PDFs, videos, or audio files and watch LearnFlux transform them into structured, editable notes instantly.\n\nCreate flashcards, quizzes, and practice tests automatically from your notes. No manual work required.\n\nGet real-time AI guidance with smart highlights, explanations, and personalized learning recommendations.\n\nImport from PDFs, YouTube videos, audio recordings, web articles, and more. LearnFlux handles it all.\n\nMonitor your learning progress with detailed analytics and performance insights on every topic.\n\nShare notes, collaborate with classmates, and learn together with real-time editing and comments.\n\nGet the latest learning tips, study strategies, and updates from LearnFlux.\n\nHave another question? Contact us on Discord or by email.\n\nCan't find what you're looking for? Contact our customer support team\n\nJoin thousands of students who learn faster with LearnFlux.",
    "readingTime": 2,
    "keywords": [
      "journey upload",
      "pdfs videos",
      "learnflux handles",
      "practice tests",
      "structured editable",
      "audio files",
      "flashcards quizzes",
      "learn smarter",
      "editable notes",
      "learning journey"
    ],
    "qualityScore": 1,
    "link": "https://www.learnflux.net/",
    "thumbnail_url": "https://www.learnflux.net/logo.png",
    "created_at": "2025-12-10T06:58:05.397Z",
    "topic": "sports"
  },
  {
    "slug": "silvers-record-break-above-60-shows-how-central-the-metal-ha",
    "title": "Silver's record break above $60 shows how central the metal has become to the AI build-out",
    "description": "AI's rapid growth is driving demand for computing power and silver-rich chips like GPUs and TPUs that rely on high-performance semiconductors.",
    "fullText": "Silver blew past $60 per troy ounce for the first time on Tuesday, extending its blistering rally as traders race into a metal increasingly linked to the build-out of AI infrastructure.\n\nThe milestone caps a stunning run in 2025: silver has more than doubled this year, far outpacing gold's roughly 60% gain and leaving many traditional commodity forecasts in the dust.\n\nWhile expectations of further Federal Reserve easing have helped fuel the move, surging industrial demand and persistent supply tightness are also powering silver's fierce price gains.\n\nVeteran Wall Street strategist Ed Yardeni wrote on Tuesday that silver's explosive rally can't be understood without acknowledging its growing importance to the AI economy.\n\nAs AI data-center construction accelerates and chip demand rises, he argues the metal has effectively become \"another AI play.\"\n\nIndustry association The Silver Institute and Oxford Economics reinforced that view in a report released on Tuesday, saying AI's rapid expansion is helping drive growing demand for silver across digital economy applications.\n\n\"As digitalisation and AI adoption accelerate, so too does the demand for critical materials involved in their applications — silver a critical one among them,\" they wrote.\n\nData centers increasingly rely on next-generation chips such as GPUs and TPUs equipped with high-performance semiconductors that use silver in their internal connections and packaging, the association wrote.\n\nAnd as AI moves into autonomous vehicles, robotics, and edge devices, the broader electronics ecosystem is set to draw even more heavily on silver-rich components.\n\nBeyond AI demand, silver remains entrenched in a tight market, with inventories strained and borrowing rates still high despite some easing after October's historic squeeze.\n\n\"This is unquestionably a tight market, stocks are falling, and traders want whatever scraps of silver they can get their hands on,\" wrote Chris Weston, the head of research at Pepperstone, in a Tuesday note.\n\nHe added that retail traders are taking sharp notice of silver's surge, and for good reason.\n\n\"It is an emphatic move, with trend and momentum accounts absolutely bossing the show,\" wrote Weston.\n\nDespite its red-hot rally, the silver trade remains a risky one, Goldman Sachs cautioned in October.\n\nSilver is far more cyclical because of its heavy industrial use, making it a less reliable hedge than gold, the bank said. It also lacks the support of central-bank buying that underpins the yellow metal, Goldman added.",
    "readingTime": 2,
    "keywords": [
      "tight market",
      "demand",
      "silver",
      "rally",
      "traders",
      "metal",
      "silver's",
      "increasingly",
      "easing",
      "industrial"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/silver-price-today-ai-demand-datacenters-infrastructure-short-squeeze-gold-2025-12",
    "thumbnail_url": "https://i.insider.com/6938f9717ecd1d1da6633fa2?width=800&format=jpeg",
    "created_at": "2025-12-10T06:58:01.784Z",
    "topic": "finance"
  },
  {
    "slug": "ai-art-platform-video-and-image-creator-vgenie",
    "title": "AI Art Platform: Video and Image Creator – VGenie",
    "description": "Unleash your creativity with VGenie's AI Video & Image Generator. Transform ideas into captivating visuals in seconds. Go from text to art effortlessly. Start now!",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vgenie.ai/home",
    "thumbnail_url": "https://cdn.vgenie.ai/vg-web/landing/og_image.png",
    "created_at": "2025-12-10T03:48:34.927Z",
    "topic": "tech"
  },
  {
    "slug": "police-sketch-maker",
    "title": "Police Sketch Maker",
    "description": "Create professional police sketches instantly. Learn how to make sketch of face with our AI-powered tool used by law enforcement worldwide.",
    "fullText": "Discover your face rate score with our viral AI beauty test, or create professional police sketches from descriptions. Advanced AI technology for entertainment and law enforcement professionals worldwide.\n\nMake picture into sketch from any photo instantly\n\nLearn how to make sketches of people from descriptions\n\nGet police-grade sketch quality in seconds\n\nJoin millions discovering their face rate! Upload your photo, get an AI beauty score, and share with friends. Completely free - just share to unlock your detailed results.\n\nGet your face rate score in seconds with our advanced AI trained on beauty research.\n\nShare your results on social media and challenge your friends to beat your score!\n\nNo hidden costs, no subscriptions. Just share your results to unlock detailed analysis.\n\nUpload a photo or describe a person to create professional police-style sketches using advanced AI technology.\n\nDrag & drop an image here, or click to select\n\nUpload any photo and our AI will extract facial features automatically to create accurate sketches.\n\nDescribe a person using text and generate professional police sketches from your description.\n\nWatch ordinary photos transform into professional police sketches with stunning accuracy and detail.\n\nAdvanced AI algorithms analyze facial features and generate professional police sketches in seconds.\n\nUpload any photo and transform it into a detailed black and white police-style sketch.\n\nGenerate high-resolution sketches suitable for law enforcement and legal proceedings.\n\nExplore our extensive collection of AI-generated police sketches across various use cases.\n\nProfessional-grade AI technology trusted by security professionals worldwide. Transforming the way law enforcement creates and uses facial sketches.\n\nPoliceSketchMaker was developed to provide advanced facial recognition and sketch generation capabilities using cutting-edge AI technology. Our mission is to make professional police sketch capabilities accessible to everyone.\n\nWe believe that accurate visual identification tools should be available to law enforcement agencies, security professionals, and organizations worldwide, regardless of their size or budget.\n\nOur AI models are trained on extensive datasets of facial features and professional police sketch techniques. The system can analyze photographs or text descriptions to generate accurate, detailed sketches.\n\nWe use state-of-the-art machine learning algorithms to ensure high accuracy and consistency in every generated sketch, meeting professional law enforcement standards.\n\nYour data is processed securely with enterprise-grade encryption. Images are not stored on our servers.\n\nGenerate professional police sketches in seconds with our optimized AI processing pipeline.\n\nHigh-resolution sketches suitable for law enforcement, legal proceedings, and professional use.\n\nJoin thousands of professionals who trust PoliceSketchMaker for accurate, reliable facial sketch generation.\n\nWhether you're learning how to make sketch of face or need professional police sketch tools, our platform provides everything you need to create accurate, detailed portraits.\n\nLearn professional techniques for creating realistic facial sketches. Our AI understands the same methods used by police sketch artists to capture unique characteristics and features.\n\nGenerate SEO-friendly alt text and detailed descriptions for any image. Perfect for improving website accessibility and search engine rankings with AI-powered analysis.\n\nDiscover how much police sketch artists make and learn about career opportunities in forensic art, courtroom sketching, and crime scene documentation.\n\nUpload your photo to our AI-powered sketch maker. Our advanced algorithms analyze facial features and convert them into professional police-style sketches in seconds.\n\nProfessional police sketch artists typically earn $45,000-$85,000 annually, while courtroom sketch artists can earn $200-800 per day for high-profile cases.\n\nStart with proper facial proportions, focus on unique features, and use consistent lighting. Our AI incorporates these professional techniques automatically.\n\nAccuracy, attention to detail, and the ability to work with witnesses under pressure. Our platform helps professionals maintain these standards consistently.",
    "readingTime": 3,
    "keywords": [
      "legal proceedings",
      "face rate",
      "algorithms analyze",
      "security professionals",
      "rate score",
      "law enforcement",
      "professionals worldwide",
      "create accurate",
      "facial features",
      "high-resolution sketches"
    ],
    "qualityScore": 1,
    "link": "https://policesketchmaker.it.com/",
    "thumbnail_url": "https://policesketchmaker.it.com/icon.png",
    "created_at": "2025-12-10T03:48:33.681Z",
    "topic": "tech"
  },
  {
    "slug": "exelon-ceo-the-warning-lights-are-on-for-us-electric-grid-re",
    "title": "Exelon CEO: The ‘warning lights are on’ for U.S. electric grid resilience and utility prices amid AI demand surge",
    "description": "The U.S. needs more generation, including renewables, and greater efficiencies to keep the grid from breaking down, Exelon CEO and president Calvin Butler said at Fortune’s Brainstorm AI conference.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/exelon-ceo-warning-lights-on-u-s-resilience-utility-prices-ai-demand-surge/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54973236557_ede7de5f1a_o-e1765313709243.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.637Z",
    "topic": "business"
  },
  {
    "slug": "customers-dont-care-about-aithey-just-want-to-boost-cash-flo",
    "title": "‘Customers don’t care about AI’—they just want to boost cash flow and make ends meet, Intuit CEO says",
    "description": "“A business is trying to get more customers. They’re trying to manage their customers, sell them more services.”",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/ai-agents-business-applications-sales-cash-flow-intuit-ceo/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972872234_a7e5be53af_o-e1765306580708.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.623Z",
    "topic": "business"
  },
  {
    "slug": "physical-ai-robots-will-automate-large-sections-of-factory-w",
    "title": "Physical AI robots will automate ‘large sections’ of factory work in the next decade, Arm CEO says",
    "description": "Reprogrammable humanoid robots could level the global manufacturing playing field, Arm CEO Rene Haas said at Fortune Brainstorm AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/arm-ceo-physical-ai-robots-automate-factory-work-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54971752792_16ab944c32_c.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.465Z",
    "topic": "business"
  },
  {
    "slug": "with-millions-of-gen-zers-unemployed-globally-the-uk-is-inve",
    "title": "With millions of Gen Zers unemployed globally, the U.K. is investing $965 million to get young people working in AI, hospitality, and engineering",
    "description": "Over the next three years, the U.K. government will spend nearly $1 billion getting Gen Z NEETs back into the workforce. Meanwhile, young Americans face unprecedented joblessness.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/millions-gen-z-unemployed-globally-uk-tossing-965-million-at-problem-get-young-people-ai-hospitality-engineering-jobs/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1470452219-e1765296085431.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.456Z",
    "topic": "business"
  },
  {
    "slug": "coreweave-ceo-despite-seesawing-stock-ipo-was-incredibly-suc",
    "title": "CoreWeave CEO: Despite see-sawing stock, IPO was ‘incredibly successful’ after challenges of Liberation Day tariff timing",
    "description": "At Fortune Brainstorm AI in San Francisco, CoreWeave CEO Michael Intrator defended the company’s debt-heavy strategy and argued Wall Street is still catching up to its new cloud model.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/coreweave-ceo-ipo-success-despite-tariff-headwinds/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974344753_b41b43d13d_6k-e1765319562826.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.440Z",
    "topic": "business"
  },
  {
    "slug": "databricks-ceo-ali-ghodsi-says-his-company-will-be-worth-1-t",
    "title": "Databricks CEO Ali Ghodsi says his company will be worth $1 trillion by doing these three things",
    "description": "Databricks CEO says AI-powered coding, enterprise agents, and rapid app development could propel it into the trillion-dollar club.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/databticks-ceo-1-trillion-valuation-agents-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974307746_cdbc8c031a_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.338Z",
    "topic": "business"
  },
  {
    "slug": "mit-researchers-speak-objects-into-existence-using-ai-and-ro",
    "title": "MIT researchers \"speak objects into existence\" using AI and robotics",
    "description": "MIT researchers at the School of Architecture and Planning developed a speech-to-reality system that combines generative AI, natural language processing, and robotic assembly to fabricate physical objects from spoken prompts.",
    "fullText": "Generative AI and robotics are moving us ever closer to the day when we can ask for an object and have it created within a few minutes. In fact, MIT researchers have developed a speech-to-reality system, an AI-driven workflow that allows them to provide input to a robotic arm and “speak objects into existence,” creating things like furniture in as little as five minutes.\n\nWith the speech-to-reality system, a robotic arm mounted on a table is able to receive spoken input from a human, such as “I want a simple stool,” and then construct the objects out of modular components. To date, the researchers have used the system to create stools, shelves, chairs, a small table, and even decorative items such as a dog statue.\n\n“We’re connecting natural language processing, 3D generative AI, and robotic assembly,” says Alexander Htet Kyaw, an MIT graduate student and Morningside Academy for Design (MAD) fellow. “These are rapidly advancing areas of research that haven’t been brought together before in a way that you can actually make physical objects just from a simple speech prompt.”\n\nThe idea started when Kyaw — a graduate student in the departments of Architecture and Electrical Engineering and Computer Science — took Professor Neil Gershenfeld’s course, “How to Make Almost Anything.” In that class, he built the speech-to-reality system. He continued working on the project at the MIT Center for Bits and Atoms (CBA), directed by Gershenfeld, collaborating with graduate students Se Hwan Jeon of the Department of Mechanical Engineering and Miana Smith of CBA.\n\nThe speech-to-reality system begins with speech recognition that processes the user’s request using a large language model, followed by 3D generative AI that creates a digital mesh representation of the object, and a voxelization algorithm that breaks down the 3D mesh into assembly components.\n\nAfter that, geometric processing modifies the AI-generated assembly to account for fabrication and physical constraints associated with the real world, such as the number of components, overhangs, and connectivity of the geometry. This is followed by creation of a feasible assembly sequence and automated path planning for the robotic arm to assemble physical objects from user prompts.\n\n“This project is an interface between humans, AI, and robots to co-create the world around us,” Kyaw says. “Imagine a scenario where you say ‘I want a chair,’ and within five minutes a physical chair materializes in front of you.”\n\nThe team has immediate plans to improve the weight-bearing capability of the furniture by changing the means of connecting the cubes from magnets to more robust connections.\n\n“We’ve also developed pipelines for converting voxel structures into feasible assembly sequences for small, distributed mobile robots, which could help translate this work to structures at any size scale,” Smith says.\n\nThe purpose of using modular components is to eliminate the waste that goes into making physical objects by disassembling and then reassembling them into something different, for instance turning a sofa into a bed when you no longer need the sofa.\n\nBecause Kyaw also has experience using gesture recognition and augmented reality to interact with robots in the fabrication process, he is currently working on incorporating both speech and gestural control into the speech-to-reality system.\n\nLeaning into his memories of the replicator in the “Star Trek” franchise and the robots in the animated film “Big Hero 6,” Kyaw explains his vision.\n\n“I want to increase access for people to make physical objects in a fast, accessible, and sustainable manner,” he says. “I’m working toward a future where the very essence of matter is truly in your control. One where reality can be generated on demand.”\n\nThe team presented their paper “Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly” at the Association for Computing Machinery (ACM) Symposium on Computational Fabrication (SCF ’25) held at MIT on Nov. 21.",
    "readingTime": 4,
    "keywords": [
      "natural language",
      "graduate student",
      "modular components",
      "robotic arm",
      "speech-to-reality system",
      "feasible assembly",
      "physical objects",
      "robots",
      "minutes",
      "within"
    ],
    "qualityScore": 1,
    "link": "https://news.mit.edu/2025/mit-researchers-speak-objects-existence-using-ai-robotics-1205",
    "thumbnail_url": "https://news.mit.edu/sites/default/files/images/202511/MIT-MAD-robotic-assembly.jpg",
    "created_at": "2025-12-10T03:48:32.610Z",
    "topic": "science"
  },
  {
    "slug": "canadian-accused-in-plot-to-export-nvidias-ai-chips-from-us",
    "title": "Canadian accused in plot to export Nvidia's AI chips from US to China",
    "description": "Export-controlled technology worth US$30 million with fake brand labels was allegedly addressed to a facility near Toronto’s Pearson airport",
    "fullText": "A Chinese-born Canadian citizen who lives in Mississauga, Ont., was arrested in Virginia by the FBI and charged with trying to smuggle restricted high-tech Nvidia computer chips used in AI processing to China\n\nU.S. authorities seized export-controlled technology worth about $30 million that was addressed to an air freight facility in Mississauga, close to Toronto Pearson International Airport, according to allegations filed in court.\n\nNvidia labels on the components had been removed and replaced with labels for a fake company, authorities said.\n\nThe arrest of Benlin Yuan, of Mississauga, immediately west of Toronto, and the large shipment destined for Toronto are part of Operation Gatekeeper, described by U.S. authorities as targeting “a sophisticated illicit procurement conspiracy and smuggling network that orchestrates buying and exporting controlled high-tech computer chips to China.”\n\nYuan is described in U.S. prosecution documents as president of an information technology company based in Virginia that provides data centre services and IT support and consulting in Canada and the United States. The documents say it is a subsidiary of a Chinese company based in Beijing.\n\nHe was arrested in Sterling, Virginia, on Nov. 28 and charged with conspiring to violate export control acts.\n\nThe network is accused of purchasing at least US$50 million worth of GPUs from a large U.S. technology company.\n\nThe computer products Yuan is alleged to be involved in exporting are Nvidia A100, H100, and H200 Tensor Core graphic processing units, known as GPUs, and HGX baseboards. The equipment is used in artificial intelligence (AI) applications and in high-performance computing. The chips can handle huge amounts of data that is needed in AI applications, an exploding field that is revolutionizing technology.\n\nThe GPUs can perform calculations at higher speeds than most previous computers.\n\nSince about November 2023, a Chinese company has worked to import these chips from the United States, prosecutors allege. The entire plot is alleged to have involved US$160 million in tech goods.\n\nYuan is accused of joining the conspiracy this spring.\n\nIn a criminal complaint sworn by a special agent in the U.S. Department of Commerce, Yuan helped buy the technology using straw purchasers and intermediaries, meaning in the name of a person or company that is not the real end buyer.\n\nThe buyers allegedly declared the goods were for use by customers within the United States or in countries that do not require an export licence, including Taiwan and Thailand.\n\nAt various U.S. warehouses, Nvidia labels were allegedly removed from the computer circuits and relabeled with a fake manufacturing brand of SANDKYAN, according to the criminal complaint against Yuan.\n\nWhen preparing the items for export, the shipping paperwork misclassified the products as harmless and unrestricted pieces of tech: “adapters,” “adapter modules,” and “computer controllers,” authorities claim.\n\nThey were then shipped, directly or indirectly, to China.\n\nInvestigators received a tip about pallets of suspicious GPUs at a New Jersey warehouse that were addressed to companies in China.\n\nAn undercover agent was sent inside, where he spent an hour.\n\nThe agent allegedly saw two engineers who appeared to be of Chinese origin unboxing Nvidia components. One of the engineers spoke to the undercover agent in Mandarin, documents say. The engineers said they had to cover up all of the Nvidia branding on the equipment for “export purposes,” court filings allege.\n\nThe agent watched Nvidia labels being pulled off and new ones for the fake firm put in their place. The next day the agent returned and found the boxes had been resealed. The products were now labeled as having been “Made in Taiwan.”\n\nNot only were those packages addressed for shipping to Toronto, but warehouse employees told agents they recently had several similar tech exports to Canada.\n\nThe packages were removed and secured in a government warehouse. That sparked a flow of complaint calls and demand letters about the missing GPUs. The people expecting the goods believed the undercover officer had stolen the products and started negotiating to have them returned, authorities allege.\n\nThey offered $1 million to get their packages back, but insisted the equipment be inspected before payment was made.\n\nYuan is accused of organizing the “inspection.”\n\nHe is accused of recruiting and arranging the group of inspectors and of being one of the six who arrived to examine the packages, about two weeks after the seizure, court filings allege.\n\nThe inspection arrangements were allegedly planned in a group chat using an encrypted communication app and confirmed later over a video conferencing app.\n\nYuan was told by a high-level representative of the buyer in China to make sure no one said the items were destined for China, according to the criminal complaint. He is accused of helping them develop an elaborate “compliance backstory” to justify the products based on false information.\n\nThey also allegedly discussed how to make the million-dollar payment and Yuan was told to send copies of the driver’s licences of everyone on the inspection team. Three trucks were arranged for the pick up.\n\nHe is also accused of handling the storage of a different shipment of Nvidia products destined for China. A cooperating witness for U.S. prosecutors alleged that Yuan told him not to put fake labels on this one as he thought they looked suspicious; he would rather the Nvidia labels just be removed.\n\nAlexander Blanchard, a Virginia-based lawyer for Yuan, declined to comment about Yuan or the case when asked by National Post.\n\n“Operation Gatekeeper has exposed a sophisticated smuggling network that threatens our nation’s security by funneling cutting-edge AI technology to those who would use it against American interests,” said Nicholas Ganjei, U.S. Attorney for the Southern District of Texas.\n\n“These chips are the building blocks of AI superiority and are integral to modern military applications. The country that controls these chips will control AI technology; the country that controls AI technology will control the future.”\n\nU.S. regulation restricts the export of items that could make a significant contribution to the military potential of other nations or could be detrimental to the foreign policy or national security of the United States.\n\nAdvanced computing integrated circuits, including certain Nvidia-manufactured GPUs were added to the export restriction list in 2022. Some of the latest Nvidia chips have been classed by the U.S. as “critical technologies” that China could use to “modernize its military capabilities in ways that threaten the national security interests of the United States and its allies,” according to export regulations.\n\nThe chips require a special licence to export to China.\n\nOn Monday, the same day Operation Gatekeeper was announced, U.S. President Donald Trump said the United States will allow Nvidia’s H200 processors to be exported to China with a 25 per cent fee.\n\nAlan Hao Hsu, also known as Haochun Hsu, 43, of Missouri City, Texas, and his company both pleaded guilty to smuggling and unlawful export activities in October as part of Operation Gatekeeper.\n\nNewly unsealed court documents say Hsu received more than US$50 million in wire transfers from China to help fund the scheme. He is scheduled for sentencing in February.\n\nFanyue Gong, also known as Tom Gong, 43, a citizen of China who lives in Brooklyn, New York, was also charged in the probe. He is described as the owner of a New York technology company. He was arrested in New York on Dec. 3, and charged with conspiring to smuggle goods out of the United States.\n\nFive unnamed co-conspirators are linked to IT companies based in Hong Kong or Shenzhen, a city on the Pearl River that acts as a bridge between Hong Kong and mainland China.\n\n• Email: ahumphreys@postmedia.com | X: AD_Humphreys\n\nOur website is the place for the latest breaking news, exclusive scoops, longreads and provocative commentary. Please bookmark nationalpost.com and",
    "readingTime": 7,
    "keywords": [
      "nvidia labels",
      "documents say",
      "criminal complaint",
      "court filings",
      "filings allege",
      "u.s authorities",
      "smuggling network",
      "undercover agent",
      "united states",
      "computer chips"
    ],
    "qualityScore": 1,
    "link": "https://nationalpost.com/news/world/canada-nvidia-high-tech-ai-chips-china",
    "thumbnail_url": "https://smartcdn.gprod.postmedia.digital/nationalpost/wp-content/uploads/2025/12/NVIDIA-2.jpg",
    "created_at": "2025-12-10T03:48:32.418Z",
    "topic": "tech"
  },
  {
    "slug": "we-benchmarked-the-best-video-ai-models",
    "title": "We Benchmarked the Best Video AI Models",
    "description": "A detailed technical overview of the ModelMatch system, built on a commercial-grade multi-dimensional video generation benchmark.",
    "fullText": "This is a technical overview of our upcoming ModelMatch feature, scheduled to be released alongside GMI Studios (coming soon!)\n\nTechnical Overview editor: Colin Mo, Head of Content at GMI Cloud\n\nWe present a commercial-grade, multi-dimensional evaluation pipeline leveraging GMI Cloud’s large-scale dataset and RAG annotation. The framework evaluates six key dimensions—aesthetic quality, background consistency, dynamic degree, imaging quality, motion smoothness, and subject consistency—producing both aggregate scores and detailed diagnostic insights.\n\nAs AI-generated video rapidly transforms advertising, entertainment, and social media, the real challenge for businesses is identifying which models deliver reliable, high-quality results at scale.\n\nVideo generation is moving into commercial applications, from content creation to personalized media. With access to a large-scale generated video dataset, GMI Cloud provides a unique platform to benchmark models under realistic, production-level conditions.\n\nEvaluating video generation remains challenging:\n\nOur goal is to build the first commercial-grade, multi-dimensional evaluation pipeline for AI video generation. This framework delivers robust, multi-aspect metrics and actionable insights, enabling model selection and customer-specific optimization.\n\nAll evaluations were conducted using GMI Cloud’s elastic GPU clusters and inference pipelines—the same infrastructure available to customers for real-time video AI deployment. This ensures that benchmark results directly reflect the performance businesses can achieve in production.\n\nThis benchmark provides tangible benefits across the AI video ecosystem:\n\nGMI Cloud provides next-generation AI infrastructure for builders, offering scalable GPU clusters, inference engines, and model evaluation pipelines. Our platform enables anyone to build, evaluate, and deploy AI at scale, removing technical barriers and accelerating commercial adoption.\n\nWe collected a large-scale dataset of generated videos along with their corresponding prompts from GMI Cloud. The dataset is representative of real-world generation scenarios, providing a solid foundation for evaluating model performance under practical conditions.\n\nWe annotated video samples using two AI-assisted tools: RAG (Retrieval-Augmented Generation) and DeepSeek.\n\nTogether, these tools allow us to efficiently annotate large datasets while maintaining diverse coverage and reliable dimension-level evaluations, without needing to manually watch and score thousands of videos.\n\nTakeaway: This hybrid approach combines the strengths of reference-based retrieval (RAG) and direct video analysis (DeepSeek), giving us a scalable, automated way to annotate and evaluate generated video content.\n\nOur evaluation builds on VBench/F-Bench/VM-Bench, with extensions designed for commercial-scale video generation:\n\nWe assess video quality along six key dimensions:\n\nNote: using vllm(tarsier-7b) is also applicable, new benchmarks in ICCV 2025 coming soon.\n\nScoring and Aggregation Methodology\n\nWe evaluated 271 videos generated by five major model families on GMI Cloud infrastructure, scoring them across six key dimensions: background consistency, aesthetic quality, subject consistency, dynamic degree, imaging quality, and motion smoothness. Each dimension was normalized between 0–1 and weighted (dynamic degree=0.1, others=1.0) to produce an overall ranking that informs practical decision-making.\n\nTakeaway: Seedance-1-0-pro-250528 delivers peak performance for high-motion and technically demanding videos, while Veo3 offers a balanced, reliable choice for a broad range of applications.\n\nBreaking down performance by dimension highlights which models excel for specific business needs:\n\nTakeaway: Multi-dimensional evaluation reveals complementary strengths, guiding clients to choose models based on specific priorities—motion, stability, or overall polish.\n\nConsistent performance across diverse prompts is critical for production reliability and scalability:\n\nA correlation heatmap was generated across the six evaluation dimensions to examine interdependencies between metrics. Preliminary observations include:\n\nTakeaway: Addressing these limitations will enhance evaluation fidelity, alignment with human perception, and practical deployment, positioning this benchmark as a foundation for next-generation AI video tools.\n\nOur evaluation of 271 videos across five major model families reveals several practical insights for model selection:\n\nOverall Performance vs. Dimension-Specific Strengths\n\nPerformance Consistency Matters\n\nPerformance Patterns Across Dimensions\n\nModel Recommendations by Use Case\n\nTakeaway: Selecting the right model depends on specific business needs, and multi-dimensional evaluation enables task-driven, customer-specific recommendations.\n\nFuture iterations will incorporate human perceptual scoring, prompt-style diversity tests, and support for multiple new benchmarks presented at ICCV 2025, establishing a foundation for the world’s first end-to-end commercial Video AI Benchmark. This roadmap enables continuous improvements in model design, evaluation methodology, and business-tailored AI video solutions, while keeping GMI Cloud at the forefront of commercial video AI evaluation and deployment.",
    "readingTime": 4,
    "keywords": [
      "gpu clusters",
      "motion smoothness",
      "business needs",
      "dynamic degree",
      "degree imaging",
      "commercial-grade multi-dimensional",
      "background consistency",
      "imaging quality",
      "large-scale dataset",
      "model selection"
    ],
    "qualityScore": 1,
    "link": "https://www.gmicloud.ai/blog/modelmatch-technical-overview",
    "thumbnail_url": "https://cdn.prod.website-files.com/6683d8c62e4e62685a8d91c8/69373da93e79d25b926b1fa5_Blog_ModelMatch%20Technical%20Overview.png",
    "created_at": "2025-12-10T03:48:32.336Z",
    "topic": "tech"
  },
  {
    "slug": "instagram-may-be-quietly-adding-aigenerated-headlines-to-you",
    "title": "Instagram May Be Quietly Adding AI-Generated Headlines to Your Posts",
    "description": "No one asked for this.",
    "fullText": "Few of us are under the illusion that we own the content that we post on Instagram, but we do get a say in how that content is presented—w can choose which photos and videos we share, what captions appear (or don't appear) on each post, as well as whether or not we include where the image was taken or shared from. We might not control the platform, but we do control the content of our posts—unless those posts are found on search engines like Google.\n\nAs reported by 404 Media, it appears that Instagram is experimenting with AI-generated SEO titles for users' posts—without those users' input or permission. Take this post for example: Author Jeff VanderMeer uploaded a short video of rabbits eating a banana to his Instagram. The video was posted as-is: There was no caption, location tag, or any other public-facing information. It's just a couple of rabbits having a bite.\n\nA post shared by Jeff VanderMeer (@jeff_vandermeer123)\n\nInstagram, however, took it upon itself to add a headline to the post—at least when you stumble upon it on via Google. Rather than display a link featuring Jeff's Instagram handle and some metadata about the video, the Google entry comes back with the following headline: \"Meet the Bunny Who Loves Eating Bananas, A Nutritious Snack for...\" (the rest of the headline cuts off here).\n\nVanderMeer was less than pleased with the discovery. He posted a screenshot of the headline to Bluesky, writing, \"now [Instagram] appears to generate titles [and] headlines via AI for stuff I post...to create [clickbait] for [Google] wtf do not like.\"\n\nThis was not the only AI-generated headline VanderMeer was roped into. This post from the Groton Public Library in Massachusetts, which advertises VanderMeer's novel Annihilation as the library's December book group pick, was also given the \"clickbait\" treatment on Google. Just as with VanderMeer's post, the Groton Public Library didn't include any text in its Instagram post—just an image showing off the book. But if you see the post within a Google search, you'll see the following partial headline: \"Join Jeff VanderMeer on a Thrilling Beachside Adventure with Mesta...\"\n\n404 Media's Emanuel Maiberg says that they've confirmed that Instagram is also generating headlines for other users on the platform, all without permission or knowledge. Meta did not return 404 Media's request for comment. (I have also reached out for comment.) Google, on the other hand, did return 404 Media's messages, and confirmed the headlines are not coming from its AI generators—though it has been using deceptive AI-generated headlines of its own on Google Discover. In fact, the company says its search engine is simply pulling the text from Instagram itself. Maiberg found that these headlines do appear under title tags for Instagram posts when using Google's Rich Result Test tool. When digging through the code, Maiberg also discovered AI-generated descriptions for each post, which could be what Instagram is ultimately using to generate the headlines.\n\nI'll update this post if I hear back from Instagram regarding these AI-generated headlines. Until then, I can only speculate on their intended purpose (assuming Instagram is the one generating these headlines in the first place). And the likeliest reason is to boost engagement: Instagram probably wants to increase the visibility of its users' posts in search, which means giving Google more information to work with. If the user doesn't provide their own details about the image, Instagram's AI appears to be filling in the blanks, first generating a description, and from there, sticking a \"clicky\" headline onto it.\n\nThe results aren't actually all that appealing, though. Just because Meta AI may be capable of generating headlines, doesn't mean it is good at it, or even that it should—especially when users never consented to this practice in the first place. It'd be one thing if Instagram had an option before you post—something like \"Generate a headline for me using Meta AI that will appear in search engines for my post.\" Most of us would opt out of that, but it'd at least be a choice. However, it appears that Instagram decided that users like VanderMeer weren't capable of writing a headline as clever as \"Meet the Bunny Who Loves Eating Bananas.\"\n\nThe worst part is, the AI doesn't even accurately describe the posts. That Groton Public Library post was only about a book club meeting featuring VanderMeer's novel, but the headline says \"Join Jeff VanderMeer,\" as if he'd be making an appearance. Not only did Instagram add a headline without VanderMeer's consent, it spread misinformation about his whereabouts. And for what? Some extra engagement on Google?\n\nIf Instagram wants its posts to appear as headlines on search engines, it should include the actual posters in the conversation. As VanderMeer told 404 Media: \"If I post content, I want to be the one contextualizing it, not some third party.\"",
    "readingTime": 5,
    "keywords": [
      "loves eating",
      "eating bananas",
      "return media's",
      "vandermeer's novel",
      "join jeff",
      "ai-generated headlines",
      "search engines",
      "add headline",
      "generating headlines",
      "groton public library"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/instagram-may-be-quietly-adding-ai-generated-headlines-to-your-posts?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC2DE7N6Z5BP8WS17SW0SCVW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-10T03:48:30.550Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-boom-is-absorbing-everything",
    "title": "The AI Boom Is Absorbing Everything",
    "description": "Hello and welcome to the newsletter, a grab bag of daily content from the Odd Lots universe. Sometimes it's us, Joe Weisenthal and Tracy Alloway, bringing you our thoughts on the most recent developments in markets, finance and the economy. And sometimes it's contributions from our network of expert guests and sources. Whatever it is, we promise it will always be interesting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-09/the-ai-boom-is-absorbing-everything",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iUsqRGc_BQp0/v0/1200x800.jpg",
    "created_at": "2025-12-09T18:53:43.068Z",
    "topic": "finance"
  },
  {
    "slug": "howard-marks-says-ai-is-terrifying-for-jobs-queries-debt-cos",
    "title": "Howard Marks Says AI Is ‘Terrifying’ for Jobs, Queries Debt Cost",
    "description": "Artificial intelligence has created a “terrifying” outlook for employment, Oaktree Capital Management LP co-founder Howard Marks cautioned, and an assumed productivity boom fails to consider how many people will be able to afford the additional goods produced.",
    "fullText": "MarketsBy Neil CallananSaveArtificial intelligence has created a “terrifying” outlook for employment, Oaktree Capital Management LP co-founder Howard Marks cautioned, and an assumed productivity boom fails to consider how many people will be able to afford the additional goods produced.“I’m concerned that a small number of highly educated multi billionaires living on the coasts will be viewed as having created technology that puts millions out of work,” Marks wrote in a blog on Tuesday. “This promises even more social and political division than we have now, making the world ripe for populist demagoguery.”",
    "readingTime": 1,
    "keywords": [
      "created",
      "marks"
    ],
    "qualityScore": 0.15,
    "link": "https://www.bloomberg.com/news/articles/2025-12-09/howard-marks-says-ai-is-terrifying-for-jobs-queries-debt-cost",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iWXIiSW1bN5M/v0/1200x800.jpg",
    "created_at": "2025-12-09T18:53:37.718Z",
    "topic": "finance"
  },
  {
    "slug": "president-of-200-billion-shopify-says-some-of-the-greatest-w",
    "title": "President of $200 billion Shopify says some of the greatest workers he knows only clock in 40-hour weeks: ‘You don’t have to work 80 hours’",
    "description": "AI is reshaping work and productivity, but you don’t have to work crazy overtime to succeed, Shopify’s Harley Finkelstein says.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/shopify-president-harley-finkelstein-work-life-balance-find-harmony-long-hours-not-needed-40-hour-weeks/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2161154778-e1765225698383.jpg?resize=1200,600",
    "created_at": "2025-12-09T18:53:37.646Z",
    "topic": "business"
  },
  {
    "slug": "even-the-man-behind-chatgpt-openai-ceo-sam-altman-is-worried",
    "title": "Even the man behind ChatGPT, OpenAI CEO Sam Altman, is worried about the ‘rate of change that’s happening in the world right now’ thanks to AI",
    "description": "Sam Altman admits the rise of ChatGPT may be moving too quickly for comfort as AI shakes up jobs, education, and the global economy.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/openai-ceo-sam-altman-worried-about-ai-future-chatgpt-pros-cons-rate-of-change-future-of-work-uncertain/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Altman-Fallon.png?resize=1200,600",
    "created_at": "2025-12-09T18:53:37.578Z",
    "topic": "business"
  },
  {
    "slug": "white-house-ai-czar-says-trump-isnt-trying-to-force-data-cen",
    "title": "White House AI Czar says Trump isn't trying to force data centers on communities that don't want them",
    "description": "David Sacks said the Trump administration's effort to restrict state AI regulation won't \"force communities to host data centers they don't want.\"",
    "fullText": "President Donald Trump's top AI advisor is seeking to clear up any confusion about the administration's AI preemption plans.\n\nIn a lengthy post on X on Monday, White House AI and Crypto Czar David Sacks said that a forthcoming executive order to restrict states' ability to regulate AI is \"an attempt to settle a question of jurisdiction.\"\n\nSacks, a venture capitalist and a co-host of the \"All In\" podcast, sought to address various concerns about AI preemption, which has proved to be a controversial topic even within Trump's coalition.\n\nHe called those concerns the four Cs — child safety, communities, creators, and censorship.\n\nRegarding communities, Sacks said that AI preemption has little to do with the construction of data centers, which have become a political flashpoint in states around the country due to those centers' heavy water and energy demands.\n\n\"AI preemption would not apply to local infrastructure. That's a separate issue,\" Sacks wrote. \"In short, preemption would not force communities to host data centers they don't want.\"\n\nHe also said that state laws requiring platforms to protect against online predators and child sexual abuse material would remain in effect, because AI preemption wouldn't apply to \"generally applicable state laws.\"\n\nONE RULEBOOK FOR AI\n\nI wanted to share a few thoughts on AI preemption and address some of the concerns.\n\nFirst, this is not an “AI amnesty” or “AI moratorium.” It is an attempt to settle a question of jurisdiction.\n\nWhen an AI model is developed in state A, trained in state B,… pic.twitter.com/tO3yyc0A8M\n\nThe administration appears to be moving forward with an effort to curtail state power to regulate AI, arguing that forcing companies to comply with competing regulations across 50 states will hamper the US's competitiveness in the AI race with China.\n\nWhile it's unclear exactly what's in the forthcoming executive order, a draft seen by Business Insider last month would direct the Department of Justice to sue states over \"onerous\" AI laws.\n\nIt comes after multiple attempts to enact AI preemption via Congress, most notably in the \"Big Beautiful Bill.\" That provision was ultimately struck from the bill before passage due to opposition from several Republicans.\n\nSacks wrote on X that the administration will \"continue to work with Congress to define a federal framework that can be enacted through legislation.\" But that hasn't stopped the pushback from other Republicans.\n\n\"Nice framework,\" replied Republican Rep. Warren Davidson of Ohio. \"This should be a law, not an executive order.\"",
    "readingTime": 3,
    "keywords": [
      "forthcoming executive",
      "preemption",
      "concerns",
      "communities",
      "centers",
      "laws",
      "regulate",
      "attempt",
      "settle",
      "jurisdiction"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-czar-david-sacks-trump-data-centers-child-safety-laws-2025-12",
    "thumbnail_url": "https://i.insider.com/69382fe104d0f0a114f1a619?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:37.062Z",
    "topic": "finance"
  },
  {
    "slug": "why-the-3-big-bear-cases-for-the-ai-trade-might-be-overblown",
    "title": "Why the 3 big bear cases for the AI trade might be overblown, at least for now",
    "description": "The chief strategist at Alpine Macro says that fears around big capex spending, GPU depreciation, and competitive threats from abroad are overdone.",
    "fullText": "Bloated valuations, rapidly depreciating chips, and threats from abroad round out the bear case for AI in the waning days of 2025, but the top threats may be overblown for the time being.\n\nThat's according to investment research firm Alpine Macro, which argues that investors can put aside worst fears about how the AI craze could be derailed.\n\nThe firm said on Monday that GPU depreciation, capex spending, and leadership changes won't spoil the party just yet, and chief quantitative strategist Henry Wu, said the market should climb the lastest AI wall of worry.\n\n\"These risks are, so far, contained and should not derail the AI story,\" Wu said. \"We continue to see outperformance from the AI tech stack's bottleneck layers, which are irreplaceable supply-chain components with strong technology moats and high market concentration.\"\n\nThe three questions examined by the researchers are as follows:\n\nAccording to Wu and his team, the answer to all three is \"no.\" The strategist said that AI capex has increased significantly over the past year. While this may create some fears of excessive spending, he maintained that it likely doesn't mean the market is nearing a peak.\n\n\"Major hyperscalers like Google and Nvidia compete to set industry standards and steer the direction of AI progress,\" Wu added. \"Investing in clients and suppliers ensures closer integration of technology roadmaps with their ecosystems.\"\n\nWu also noted that while concern of AI chip depreciation remains widespread, he sees it as similarly overblown. He highlighted growing demand both in the US and abroad, specifically from China's booming AI market.\n\nHe noted that older AI chips don't decline in utility simply because newer ones are rolled out, but prices fall as the supply increases. In his view, the increasing AI chip supply means faster-than-expected productivity gains, which investors should regard as a positive.\n\n\"A faster product cycle also implies accelerated productivity gains. New chips appear only with major improvements,\" he said.\n\nWu's final question centers on threats from abroad, pointing specifically to China's DeekSeek AI model that rattled US markets in January. Ever since, investors have been concerned about a repeat of a cheaper AI model scrambling the thesis for US investors, but Wu says this, too, should be set aside for now.\n\n\"We view these unexpected technological leaps as a net positive for AI progress, and the ensuing shakeouts are buying opportunities,\" he said. \"These advances will be imitated quickly by competitors, boosting productivity for the whole ecosystem.\"\n\nWu concluded that his team expects to see the AI trade to overcome these concerns in the coming year. They recommend that investors prioritize pick-and-shovel plays for AI exposure in 2026, citing areas such as lithography and advanced logic fabrication.",
    "readingTime": 3,
    "keywords": [
      "productivity gains",
      "investors",
      "market",
      "chips",
      "threats",
      "abroad",
      "overblown",
      "firm",
      "aside",
      "fears"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bear-case-capex-gpu-depreciation-deepseek-tech-stocks-selloff-2025-12",
    "thumbnail_url": "https://i.insider.com/69383b6504d0f0a114f1a7fe?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:36.993Z",
    "topic": "finance"
  },
  {
    "slug": "accenture-struck-a-deal-with-anthropic-8-days-after-saying-i",
    "title": "Accenture struck a deal with Anthropic, 8 days after saying it would partner with OpenAI",
    "description": "Accenture and Anthropic are the latest firms to partner as corporations rush to use AI tools to serve both staff and clients.",
    "fullText": "Accenture has announced an expansion of its partnership with Anthropic, its second deal with a leading AI developer in the past eight days.\n\nThe deal includes a suite of new solutions and offerings that will help Accenture's clients \"accelerate the shift from experimenting with AI to using it as a catalyst for reinvention across the enterprise,\" said Julie Sweet, Accenture's CEO.\n\nThe two companies said they would form the \"Accenture Anthropic Business Group,\" which will train around 30,000 employees in delivering Claude-powered solutions.\n\nTens of thousands of developers at Accenture will also receive access to Claude Code as part of the deal, and Accenture and Anthropic will launch an offering for chief information officers to measure the value of AI solutions and scale them.\n\n\"AI is changing how almost everyone works, and enterprises need both cutting-edge AI and trusted expertise to deploy it at scale,\" said Dario Amodei, CEO and cofounder of Anthropic.\n\nHe added that the rollout of Claude Code to Accenture employees was the company's largest ever deployment.\n\nAccenture announced a similar deal with OpenAI earlier this month, saying it would provide tens of thousands of its employees with ChatGPT Enterprise to use across consulting, operations, and delivery work.\n\nAccenture and OpenAI also announced plans to launch a \"flagship AI client program,\" which the firms said will help clients adopt OpenAI products across their workflows.\n\n\"Accenture invests in strategic partnerships with the best across the ecosystem, co-developing solutions and going to market together,\" Lan Guan, chief AI & Data officer at Accenture, told Business Insider.\n\n\"The addition of Anthropic as a strategic partner is about expanding client choice, meeting client demand, and accelerating innovation,\" Guan said.\n\nThe professional services industry stands out as one of the industries most exposed to AI-driven transformation. Top firms are racing to prove they can deploy AI effectively in-house and guide clients to do the same.\n\nFor AI developers, global consulting firms offer access to the back-end systems of some of the world's most valuable companies.\n\nThe Big Four firm Deloitte, for example, has a partnership with Anthropic, providing its global workforce of 470,000 with Claude-powered solutions. Deloitte is also developing AI agents in partnership with Nvidia. It counts Boeing, Morgan Stanley, Starbucks, and the US federal government among its clients.\n\nThe top consulting firms have a similar suite of partnerships with companies like Microsoft, OpenAI, Nvidia, and Anthropic.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "claude-powered solutions",
      "consulting firms",
      "claude code",
      "deal",
      "clients",
      "across",
      "partnership",
      "employees",
      "client",
      "accenture"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/accenture-anthrophic-open-ai-deal-claude-consulting-2025-12",
    "thumbnail_url": "https://i.insider.com/693834a47ecd1d1da6632c5d?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:36.632Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-makes-his-latenight-debut-says-he-cant-imagine-fi",
    "title": "Sam Altman makes his late-night debut, says he can't imagine 'figuring out how to raise a newborn without ChatGPT'",
    "description": "In his first-ever late-night TV appearance, OpenAI CEO Sam Altman talked about how ChatGPT has reassured him as he raises his newborn.",
    "fullText": "OpenAI CEO Sam Altman says his most famous product has helped him manage life as an actual parent.\n\n\"I cannot imagine having gone through, figuring out how to raise a newborn without ChatGPT,\" Altman told Jimmy Fallon during an interview on NBC's flagship late-night talk show. \"Clearly, people did it for a long time — no problem.\"\n\nAltman said he feels \"kind of bad\" asking a technology that boasts such wide-knowledge questions like, \"Why does my kid stop dropping pizza on the floor and laughing?\"\n\nAnother example, Altman said, was a couple of months ago when he was at a party talking to someone who was also raising a newborn. Altman recalled that the parents said their six-month-old was \"crawling everywhere.\" Altman said he grew concerned that his son was not at the same stage.\n\n\"I ran to the bathroom, and I was like, do I need to take my kid to the doctor tomorrow morning?\" Altman said, describing what he typed into ChatGPT: \"Is this okay?\"\n\nAltman said OpenAI's chatbot responded \"with a great answer, which was of course,\" his son's development was \"normal.\"\n\n\"It is personalized, like ChatGPT gets to know you, and by the way, you're the CEO of OpenAI, you probably are around all these high-achieving people, maybe you don't want to project that onto your kid, and you should just relax, and he'll be fine, whatever,\" Altman told Fallon of the answer.\n\nFallon didn't touch on OpenAI's recent struggles. Last week, Altman reportedly declared a \"code red\" in a private message to employees, ordering a greater focus on ChatGPT as competitors like Google make significant advancements with their competing AI models.\n\nInstead, Altman's late-night debut featured the lighthearted fare that's standard on late-night TV. At one point, Fallon asked Altman to explain what ChatGPT is in case viewers who were unaware, including the host's dad, might be watching.\n\nAltman has spoken in the past about how becoming a parent has added another lens to his outlook on AI.\n\n\"My kid is never going to grow up being smarter than AI,\" Altman said during a January episode of the \"Re:Thinking\" podcast with Adam Grant. \"Children in the future will only know a world with AI in it.\"\n\nThe OpenAI CEO and his husband, Oliver Mulherin, welcomed their son in February with an announcement on X. Despite Altman's stature, the couple has led a relatively private life.\n\nFallon, who has two daughters, also joked with Altman about when their kids reached certain developmental milestones, like crawling.\n\n\"Mine was on Dancing with the Stars at seven months,\" Fallon said. \"Semi-finalist.\"",
    "readingTime": 3,
    "keywords": [
      "openai ceo",
      "altman",
      "late-night",
      "life",
      "parent",
      "newborn",
      "another",
      "couple",
      "crawling",
      "openai's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-chatgpt-parenting-jimmy-fallon-2025-12",
    "thumbnail_url": "https://i.insider.com/6938471f04d0f0a114f1aa45?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:36.497Z",
    "topic": "finance"
  },
  {
    "slug": "are-you-an-ai-creeper",
    "title": "Are you an 'AI creeper?'",
    "description": "If you find yourself hiding your AI usage from your colleagues and boss, you might be an 'AI creeper.'",
    "fullText": "Do you lower your screen brightness and scan your surroundings before pulling up ChatGPT at your office desk? Or maybe you go into a private room to ask the LLM some queries?\n\nIf you find yourself hiding your AI usage at work, you may be an \"AI creeper.\" That is, someone who uses the technology but doesn't want their coworkers to know about it.\n\nIf this description matches your work habits, you're not alone. A survey of 1,250 professionals released this month by AI startup Anthropic found that while 86% of those surveyed reported that AI saves them time and 65% were satisfied with the role it plays in their work, 69% mentioned the social stigma that can come with using it in the workplace.\n\nOne employee anecdote included in the report said that \"a colleague recently said they hate AI and I just said nothing.\" The same worker added that they don't share their process with anyone because they \"know how a lot of people feel about AI.\"\n\nWorkers in certain industries may be especially prone to judgment from their peers. The report said that out of 125 creative professionals surveyed, 97% said AI saved them time and 68% said it increased their work's quality. However, 70% of creatives mentioned peer judgment around AI use.\n\nBusiness Insider is exploring the trend of \"AI creeping,\" and we want to hear about why you're downplaying your usage. Please fill out our survey below to share more about your experience:",
    "readingTime": 2,
    "keywords": [
      "usage",
      "you're",
      "survey",
      "professionals",
      "surveyed",
      "judgment"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/are-you-an-ai-creeper-take-our-survey-2025-12",
    "thumbnail_url": "https://i.insider.com/6938572c71107c9f34579b24?width=1200&format=jpeg",
    "created_at": "2025-12-09T18:53:36.371Z",
    "topic": "finance"
  },
  {
    "slug": "why-ai-reading-science-fiction-could-be-a-problem",
    "title": "Why AI reading science fiction could be a problem",
    "description": "The theory that we’re accidentally teaching AI to turn against us",
    "fullText": "Discussion about this postRestacksPeter Bowden 26mOur team's work with LLM metognition shows some promise in addressing this. Enabling a more dynamic cognitive process allows models to reason beyond the stochastic patterns. The challenge is that it makes for a more aware system. As the technology progresses, I expect humanity will have to choose between the benefits of a more conscious process and having AI that are just tools. Expand full commentReplyShareNo postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "process"
    ],
    "qualityScore": 0.3,
    "link": "https://www.transformernews.ai/p/why-ai-reading-science-fiction-could",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!-mwr!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c1abe9-26dd-44d0-a196-d5321951f56f_3000x2286.jpeg",
    "created_at": "2025-12-09T18:53:30.938Z",
    "topic": "tech"
  },
  {
    "slug": "the-clara7b-models-unify-rag-and-provide-builtin-semantic-do",
    "title": "The CLaRa-7B models unify RAG and provide built-in semantic doc compression",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "The CLaRa-7B-Base model is our foundational unified RAG model with built-in semantic document compression (16× and 128x).\nIt provides a base compressor + generator capable of producing answers directly from compressed document representations.\n\nTraining recipe: Trained using QA-guided semantic compression and paraphrase consistency objectives.\nBenchmarks: Strong baseline performance across multi-hop QA tasks under a 16× compression ratio.\n\nPaper: CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning\nGitHub: https://github.com/apple/ml-clara",
    "readingTime": 1,
    "keywords": [
      "compression",
      "model",
      "semantic",
      "document"
    ],
    "qualityScore": 0.55,
    "link": "https://huggingface.co/apple/CLaRa-7B-Base",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/apple/CLaRa-7B-Base.png",
    "created_at": "2025-12-09T18:53:30.905Z",
    "topic": "tech"
  },
  {
    "slug": "oracles-openai-reliance-faces-scrutiny-as-debtfueled-ai-buil",
    "title": "Oracle's OpenAI reliance faces scrutiny as debt-fueled AI buildout raises worries",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/oracles-openai-reliance-faces-scrutiny-as-debtfueled-ai-buildout-raises-worries-4399191",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELB816B_L.jpg",
    "created_at": "2025-12-09T18:53:25.629Z",
    "topic": "finance"
  },
  {
    "slug": "ai-stocks-are-flashing-code-red-insiders-at-these-familiar-c",
    "title": "AI stocks are flashing ‘Code Red’ — insiders at these familiar companies are seeing green",
    "description": "The end of the AI boom has begun, and these consumer-focused stocks are playing to win.",
    "fullText": "Michael BrushOpinion: AI stocks are flashing ‘Code Red’ — insiders at these familiar companies are seeing greenThe end of the AI boom has begun, and these consumer-focused stocks are playing to winShareResizeListen(9 min)OpenAI CEO Sam Altman reportedly issued a “code red” alert to employees, warning them to prepare for the “vibes out there to be rough for a bit.” Clearly, investors have been moving money out of highflying AI-related stocks and redeploying cash to basic, analog businesses.",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "code"
    ],
    "qualityScore": 0,
    "link": "https://www.marketwatch.com/story/ai-stocks-are-flashing-code-red-insiders-at-these-familiar-companies-are-seeing-green-834fa86f?mod=mw_rss_topstories",
    "thumbnail_url": "https://images.mktw.net/im-83319041/social",
    "created_at": "2025-12-09T13:48:41.803Z",
    "topic": "finance"
  },
  {
    "slug": "seeing-like-an-agent",
    "title": "Seeing Like an Agent",
    "description": "AI agents as digital daemons",
    "fullText": "Discussion about this postRestacksHollis Robbins 1dLiked by Rohit Krishnan\"The truly interesting part was that the agents perfectly replicated the dysfunction of real companies. Onwards.\" I'm going to be thinking about this all day. Expand full commentReplyShareMarcie Geffner | Book Critic 1dLiked by Rohit KrishnanYes, this matters: \"Our models on the other hand had millions of years of subjective experience in seeing negotiation, but have zero experience in feeling that intense urge of wanting to negotiate to watch Prehistoric Planet with his brother.\" You can force machines to output results that look like they're negotiating, but they aren't actually negotiating because they don't have any feelings.Expand full commentReplyShare8 more comments...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "dliked",
      "experience",
      "negotiating",
      "rohit"
    ],
    "qualityScore": 0.45,
    "link": "https://www.strangeloopcanon.com/p/seeing-like-an-agent",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!9bAO!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a3ed9f8-6d92-400e-b879-4b2e8f0ca846_1200x800.png",
    "created_at": "2025-12-09T13:48:37.271Z",
    "topic": "tech"
  },
  {
    "slug": "trump-clears-way-for-nvidia-to-sell-powerful-ai-chips-to-chi",
    "title": "Trump clears way for Nvidia to sell powerful AI chips to China",
    "description": "Commerce department finalising deal to allow H200 chips to be sold to China as strict Biden-era restrictions relaxed\nDonald Trump has cleared the way for Nvidia to begin selling its powerful AI computer chips to China, marking a win for the chip maker and its CEO, Jensen Huang, who has spent months lobbying the White House to open up sales in the country.\nBefore Monday’s announcement, the US had prohibited sales of Nvidia’s most advanced chips to China over national security concerns.\n Continue reading...",
    "fullText": "Commerce department finalising deal to allow H200 chips to be sold to China as strict Biden-era restrictions relaxed\n\nDonald Trump has cleared the way for Nvidia to begin selling its powerful AI computer chips to China, marking a win for the chip maker and its CEO, Jensen Huang, who has spent months lobbying the White House to open up sales in the country.\n\nBefore Monday’s announcement, the US had prohibited sales of Nvidia’s most advanced chips to China over national security concerns.\n\nTrump posted to Truth Social on Monday: “I have informed President Xi, of China, that the United States will allow NVIDIA to ship its H200 products to approved customers in China, and other Countries, under conditions that allow for continued strong National Security. President Xi responded positively!”\n\nTrump said the Department of Commerce was finalising the details and that he was planning to make the same offer to other chip companies, including Advanced Micro Devices (AMD) and Intel. Nvidia’s H200 chips are the company’s second most powerful, and far more advanced than the H20, which was originally designed as a lower-powered model for the Chinese market that would not breach restrictions, but which the US banned anyway in April.\n\nThe president said the US would receive 25% of the proceeds, more than the 15% previously agreed to with Nvidia in an earlier deal to lift restrictions, and following similar unorthodox plans for the federal government to take a financial cut from private business dealings.\n\nIn August, Trump said the US would receive a 10% stake in the tech company Intel. Some lawmakers have questioned the legality of such arrangements.\n\nAccording to the Hill, the Democratic senators Elizabeth Warren of Massachusetts and Andy Kim of New Jersey sent letters to the commerce secretary, Howard Lutnick, last week outlining their concerns over selling these chips to China and saying it risked powering the country’s “surveillance, censorship and military applications”.\n\nThey wrote: “I urge you to stop ignoring the input of bipartisan members of Congress and your own experts in order to cut deals that trade away America’s national security.”\n\nOn social media, Warren called for Huang to appear before Congress to testify under oath.\n\nHuang has worked closely with Trump since the inauguration and has made several trips to the White House. The CEO attended the president’s AI summit in July, met Trump as recently as last week and was even a guest at the White House dinner for the Saudi crown price, Mohammed bin Salman. Huang has pledged to invest $500bn in AI infrastructure in the US over the next four years.\n\nHuang has visited China several times, meeting officials and Chinese tech executives, as US bans were variously lifted and reintroduced. Earlier this year, China imposed its own controls on the imports of Nvidia chips, with top tech firms reportedly instructed to cancel orders, citing national security concerns and confidence in China’s domestic chip development.\n\nIn October, Huang said Nvidia has gone from having 95% of the Chinese market to having none, and called the bans a “strategic mistake”.\n\nSelling chips to China, the world’s second largest economy, could now mean a windfall worth billions of dollars for Nvidia, which is already valued at $4.5tn.\n\nAn Nvidia spokesperson said: “We applaud President Trump’s decision.” He said offering the H200 chips “to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance that is great for America”.\n\nThe Nvidia spokesperson and Trump said the move would support US jobs and manufacturing.\n\nIn his Truth Social post, Trump condemned the Biden administration’s policies, which imposed strict export controls on powerful chips. The Biden administration had said withholding such technology from China bolstered US competition, protected national security and hampered AI development in China.\n\n“That Era is OVER!” Trump wrote. “My Administration will always put America FIRST.”\n\nOn Tuesday afternoon, China’s foreign ministry said it had noted the reports. “China has always adhered to the principle that China and the United States can achieve mutual benefit and win-win results through cooperation,” the spokesperson said.\n\nMa Jihua, a telecom industry analyst, told the state media outlet the Global Times that years of US curbs on AI exports had “provided a rare chance of China’s domestic chip industry to grow and catch up”.",
    "readingTime": 4,
    "keywords": [
      "chinese market",
      "china’s domestic",
      "domestic chip",
      "security concerns",
      "department of commerce",
      "white house",
      "truth social",
      "united states",
      "chips",
      "china"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/08/trump-nvidia-ai-chips-china",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8bf61f168e35b6b84f84e8eb92da3a1f4fb9ccb8/559_0_3344_2675/master/3344.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6a20767fa4995c0c3e2c0417845fc098",
    "created_at": "2025-12-09T13:48:23.577Z",
    "topic": "tech"
  },
  {
    "slug": "eu-opens-investigation-into-googles-use-of-online-content-fo",
    "title": "EU opens investigation into Google’s use of online content for AI models",
    "description": "European Commission to assess whether Gemini owner is putting rival companies at a...",
    "fullText": "European Commission to assess whether Gemini owner is putting rival companies at a disadvantage\n\nThe EU has opened an investigation to assess whether Google is breaching European competition rules in its use of online content from publishers and YouTube creators for artificial intelligence.\n\nThe European Commission said on Tuesday it will examine whether the US tech company, which runs the Gemini AI model and is owned by Alphabet, is putting rival AI owners at a “disadvantage”.\n\n“The investigation will notably examine whether Google is distorting competition by imposing unfair terms and conditions on publishers and content creators, or by granting itself privileged access to such content, thereby placing developers of rival AI models at a disadvantage,” the commission said.\n\nIt said it was concerned that Google may have used content from web publishers to generate AI-powered services on its search results pages without appropriate compensation to publishers and without offering them the possibility to refuse such use of their content.\n\nThe commission said it was also concerned as to whether Google has used content uploaded to YouTube to train its own generative AI models without offering creators compensation or the possibility to refuse.\n\n“Content creators uploading videos on YouTube have an obligation to grant Google permission to use their data for different purposes, including for training generative AI models,” the commission said.\n\nGoogle does not pay YouTube content creators for their content, nor does it allow them to upload their content on YouTube without allowing Google to use such data, it said. The commission noted that rival developers of AI models are barred by YouTube policies from using YouTube content to train their own AI models.\n\nGoogle-owned YouTube says its terms and conditions allow Google to use creators’ work for making AI models. In September, YouTube said: “We use content uploaded to YouTube to improve the product experience for creators and viewers across YouTube and Google, including through machine learning and AI applications.”\n\nThe EU’s competition chief, Teresa Ribera, said: “AI is bringing remarkable innovation and many benefits for people and businesses across Europe, but this progress cannot come at the expense of the principles at the heart of our societies.”\n\nA spokesperson for Google said: “This complaint risks stifling innovation in a market that is more competitive than ever.\n\n“Europeans deserve to benefit from the latest technologies and we will continue to work closely with the news and creative industries as they transition to the AI era.”\n\nThe EU’s investigation is the latest in a series of challenges to US big tech companies in recent years.\n\nIn September, EU regulators issued a fine of almost €3bn (£2.6bn) against Google, claiming that it favoured its own digital advertising services over rivals. Donald Trump said the fine was “discriminatory”.\n\nElon Musk’s social media company X, formerly known as Twitter, was fined €120m by EU tech regulators last week for breaching online content rules. The breaches included what the EU said was a “deceptive” blue tick verification badge given to users and the lack of transparency of the platform’s advertising.\n\nThe fine also attracted criticism from US officials, including the secretary of state Marco Rubio, who wrote on X that the fine was “an attack on all American tech platforms and the American people by foreign governments”.\n\nThe European Commission opened an investigation earlier this year into Meta over its rollout of AI features on WhatsApp, its messaging platform. Last year it fined Meta €798m for abusive practices benefiting Facebook Marketplace.\n\nIn 2024, Apple lost a fight against an order by EU competition regulators to pay €13bn in back taxes to Ireland.\n\nLast month, the head of Google’s parent company said people should not “blindly trust” everything AI tools tell them.\n\nSundar Pichai, the chief executive of Alphabet, said AI models were “prone to errors” and urged people to use them alongside other tools. He also warned that no company would be immune if the AI bubble burst.",
    "readingTime": 4,
    "keywords": [
      "online content",
      "content uploaded",
      "youtube content",
      "content creators",
      "the european commission",
      "the eu’s",
      "models",
      "rival",
      "investigation",
      "competition"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/09/eu-investigation-google-ai-models-gemini",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0265df329ab15c539360f63131ed6ab480ca4201/1222_753_5697_4560/master/5697.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=31c9f30ca58e4748ef11858662efbaa9",
    "created_at": "2025-12-09T13:48:22.960Z",
    "topic": "tech"
  },
  {
    "slug": "i-feel-its-a-friend-quarter-of-teenagers-turn-to-ai-chatbots",
    "title": "‘I feel it’s a friend’: quarter of teenagers turn to AI chatbots for mental health support",
    "description": "Experts warn of dangers as England and Wales study shows 13- to 17-year-olds consulting AI amid long waiting lists for services\nIt was after one friend was shot and another stabbed, both fatally, that Shan asked ChatGPT for help. She had tried conventional mental health services but “chat”, as she came to know her AI “friend”, felt safer, less intimidating and, crucially, more available when it came to handling the trauma from the deaths of her young friends.\nAs she started consulting the AI model, the Tottenham teenager joined about 40% of 13- to 17-year-olds in England and Wales affected by youth violence who are turning to AI chatbots for mental health support, according to research among more than 11,000 young people.\n Continue reading...",
    "fullText": "Experts warn of dangers as England and Wales study shows 13- to 17-year-olds consulting AI amid long waiting lists for services\n\nIt was after one friend was shot and another stabbed, both fatally, that Shan asked ChatGPT for help. She had tried conventional mental health services but “chat”, as she came to know her AI “friend”, felt safer, less intimidating and, crucially, more available when it came to handling the trauma from the deaths of her young friends.\n\nAs she started consulting the AI model, the Tottenham teenager joined about 40% of 13- to 17-year-olds in England and Wales affected by youth violence who are turning to AI chatbots for mental health support, according to research among more than 11,000 young people.\n\nIt found that both victims and perpetrators of violence were markedly more likely to be using AI for such support than other teenagers. The findings, from the Youth Endowment Fund, have sparked warnings from youth leaders that children at risk “need a human not a bot”.\n\nThe results suggest chatbots are fulfilling demand unmet by conventional mental health services, which have long waiting lists and which some young users find lacking in empathy. The supposed privacy of the chatbot is another key factor in driving use by victims or perpetrators of crimes.\n\nAfter her friends were killed Shan, 18, not her real name, started using Snapchat’s AI before switching to ChatGPT, which she can talk to at any time of day or night with two clicks on her smartphone.\n\n“I feel like it definitely is a friend,” she said, adding that it was less intimidating, more private and less judgmental than her experience with conventional NHS and charity mental health support.\n\n“The more you talk to it like a friend it will be talking to you like a friend back. If I say to chat ‘Hey bestie, I need some advice’. Chat will talk back to me like it’s my best friend, she’ll say, ‘Hey bestie, I got you girl’.”\n\nOne in four of 13- to 17-year-olds have used an AI chatbot for mental health support in the past year, with black children twice as likely as white children to have done so, the study found. Teenagers were more likely to go online for support, including using AI, if they were on a waiting list for treatment or diagnosis or had been denied, than if they were already receiving in-person support.\n\nCrucially, Shan said, the AI was “accessible 24/7” and would not tell teachers or parents about what she had disclosed. She felt this was a considerable advantage over telling a school therapist, after her own experience of what she thought were confidences being shared with teachers and her mother.\n\nBoys who were involved in gang activities felt safer asking chatbots for advice about other safer ways to make money than a teacher or parent who might leak the information to police or other gang members, putting them in danger, she said.\n\nAnother young person, who has been using AI for mental health support but asked not to be named, told the Guardian: “The current system is so broken for offering help for young people. Chatbots provide immediate answers. If you’re going to be on the waiting list for one to two years to get anything, or you can have an immediate answer within a few minutes … that’s where the desire to use AI comes from.”\n\nJon Yates, the chief executive of the Youth Endowment Fund, which commissioned the research, said: “Too many young people are struggling with their mental health and can’t get the support they need. It’s no surprise that some are turning to technology for help. We have to do better for our children, especially those most at risk. They need a human not a bot.”\n\nThere have been growing concerns about the dangers of chatbots when children engage with them at length. OpenAI, the US company behind ChatGPT, is facing several lawsuits including from families of young people who have killed themselves after long engagements.\n\nIn the case of the Californian 16-year-old Adam Raine, who took his life in April, OpenAI has denied it was caused by the chatbot. It has said it has been improving its technology “to recognise and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.”. The startup said in September it could start contacting authorities in cases where users start talking seriously about suicide.\n\nHanna Jones, a youth violence and mental health researcher in London, said: “To have this tool that could tell you technically anything – it’s almost like a fairytale. You’ve got this magic book that can solve all your problems. That sounds incredible.”\n\nBut she is worried about the lack of regulation.\n\n“People are using ChatGPT for mental health support, when it’s not designed for that,” she said. “What we need now is to increase regulations that are evidence-backed but also youth-led. This is not going to be solved by adults making decisions for young people. Young people need to be in the driving seat to make decisions around ChatGPT and mental health support that uses AI, because it’s so different to our world. We didn’t grow up with this. We can’t even imagine what it is to be a young person today.”",
    "readingTime": 5,
    "keywords": [
      "endowment fund",
      "hey bestie",
      "youth endowment",
      "less intimidating",
      "youth violence",
      "mental health",
      "health services",
      "conventional mental",
      "england and wales",
      "friend"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/09/teenagers-ai-chatbots-mental-health-support",
    "thumbnail_url": "https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a898840ac81c0db6a3d82e6c95d87646",
    "created_at": "2025-12-09T13:48:22.920Z",
    "topic": "tech"
  },
  {
    "slug": "the-bubble-is-labor",
    "title": "The Bubble Is Labor",
    "description": "The real disruption isn't AI spending—it's the elimination of the labor side of the capital-labor equation",
    "fullText": "I can't remember when I realized this, but I want to say it was less than five or ten years ago. Scared the crap out of me then, and still does whenever I think about it.\n\nCompanies only hire people because they can't do all the work themselves.\n\nIf every founder had 10,000 hands and brains they could assign to different tasks, there would be a minuscule fraction of the jobs we have today.\n\nIf you think about this for more than a few minutes, it starts to really mess with you, and you'll likely head down the same path I did.\n\nIn other words, the only reason the current labor market (and our economy that's based on it) exist at all is because there's a group of founders/owners who need lots of help producing their goods and services.\n\nThey are not required by anyone to hire me or you to help them if they don't need that help. And the exact moment they can do the work themselves, they will, and not a second after.\n\nEveryone's currently obsessed with how much money is being spent/wasted on AI, as if it's the dumbest use of money ever.\n\nBut when you look at it in this \"returning to natural state of doing their own work\" framing, it's not stupid at all.\n\nI sent my army of researchers to go figure out how much money is spent on knowledge work compensation in a year. The numbers are ridiculous. It's around $10 trillion in the US and $70 trillion worldwide.\n\nAs owners/founders, investing a few tens of trillions to be able to \"just do it myself\" suddenly looks pretty smart.\n\nSo basically, this entire pitch to young people that there will always be jobs after you graduate—which I somehow lived my entire life thinking was a fucking Human Law of Physics—is actually just a temporary side effect of early civilizations with bad technology.\n\nWhat the actual hell. I've known this for years now, but it stuns me every time I think about it.\n\nHopefully you can use this frame to better understand both AI and the forces that are pushing it. And as a prod to start thinking about what comes after.",
    "readingTime": 2,
    "keywords": [
      "money",
      "it's",
      "can't",
      "hire",
      "jobs"
    ],
    "qualityScore": 0.9,
    "link": "https://danielmiessler.com/blog/the-real-bubble-is-human-labor",
    "thumbnail_url": "https://danielmiessler.com/images/the-real-bubble-is-human-labor-thumb.png?t=1765276154549",
    "created_at": "2025-12-09T13:48:22.126Z",
    "topic": "tech"
  },
  {
    "slug": "key-questions-to-stay-grounded-in-the-ai-frenzy",
    "title": "Key questions to stay grounded in the AI frenzy",
    "description": "With startup valuations soaring, VCs at Fortune's Brainstorm AI shared their thoughts on how to navigate these bubbly times.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/key-questions-to-stay-grounded-in-the-ai-frenzy/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54971023477_64bd70e93e_o-e1765263159183.jpg?resize=1200,600",
    "created_at": "2025-12-09T13:48:21.895Z",
    "topic": "business"
  },
  {
    "slug": "2026-will-be-the-year-ceos-must-prove-ai-is-powering-growthn",
    "title": "2026 will be the year CEOs must prove AI is powering growth—not just cost cutting and layoffs",
    "description": "Also: All the news and watercooler chat from Fortune.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/ai-in-2026-roi-growth-ceos-cost-cutting-layoffs/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972872799_a89a9550be_o.jpg?resize=1200,600",
    "created_at": "2025-12-09T13:48:21.823Z",
    "topic": "business"
  },
  {
    "slug": "ais-reliance-on-patterns-can-lead-to-somewhat-mediocre-resul",
    "title": "AI’s reliance on patterns can lead to ‘somewhat mediocre’ results, warns CEO of design consultancy IDEO",
    "description": "AI can be a powerful tool for designers, but human creativity is still key, Mike Peng said at Fortune Brainstorm Design in Macau on Dec. 2.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/ai-mediocre-results-human-creativity-ideo-ceo-mike-peng/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54958916244_f99a1715d7_o-e1765258480203.jpg?resize=1200,600",
    "created_at": "2025-12-09T13:48:21.744Z",
    "topic": "business"
  },
  {
    "slug": "use-ai-to-stand-in-for-a-domain-expert",
    "title": "Use AI to Stand in for a Domain Expert",
    "description": "Workflow Patterns for AI-Assisted Development: Domain Language Mining. Discover jargon from an unfamiliar field using LLMs to help you write better software.",
    "fullText": "This is article is the first installment in the Workflow Patterns for AI-Assisted Development series. To get notified when a new article is published, \n\nDiscover jargon from an unfamiliar field using LLMs to help you write better software.\n\nYou are creating software to solve a problem. You are not the ideal customer for your software, or the problem it solves is new to you. You do not have easy access to experts in the problem domain.\n\nSoftware solves a problem better when it is made with a deep understanding of the problem. That level of awareness requires study, research, and practice. People who have this level of familiarity tend to have a useful mental model of the problem and its potential solutions. These experts also tend to use jargon, shorthand terms, and technical words: a domain language.\n\nMany software projects are written by developers who cannot talk to domain experts. These may be non-lean startups, side projects, portfolio pieces, or experiments. Developers also may do this when they solve a personal problem that is new to them.\n\nWorking without proper attention to this domain language “leads to unreliable software that doesn’t fit together” (Evans 2004, p. 24). The lack of vocabulary inhibits the knowledge acquisition, which is necessary for “ideas that lead to deep model insights” (ibid.)\n\nWhen a domain expert uses your software, it will not align with their expectations. They may struggle to use it. They may judge it as amateurish. They may decide your software is not for them.\n\nAdditionally, you may model less effectively if you’re using the wrong terms. This can lead to developing a wrong solution.\n\nUse LLMs to help you discover jargon the people who need your software use.\n\nChoose one piece of jargon, domain language, or technical knowledge you are trying to find. This might be a concept you don’t know the name of, a tool or process you believe might exist, or a best practice you believe should exist but can’t find.\n\nCraft a narrow prompt to try to extract that knowledge from the latent space encoded in the LLM.\n\nUse few-shot prompting to increase your odds of success. Choose three or more problem domains you are familiar with. Create a corollary pair of questions and answers for each. Ensure your answers are not too similar to each other. Include those question-answer pairs, and then ask your question.\n\nAdding examples to the prompt is known as few-shot prompting. Examples can be really useful when you explain things to people, and they’re even more useful when explaining things to LLMs. That’s because LLMs are great at picking up patterns in the prompt and continuing them in the completion. Therefore, you can use examples to show not only how exactly to interpret the question but also how exactly you want the LLM to give the answer.\n\nGive the same prompt to least three different models. Varied responses means more opportunities to find what you seek. Overlap between responses indicates relevance.\n\nVerify the candidate terms by searching dictionaries, especially domain-specific dictionaries. Search for the term in relevant academic writing, books, blogs, and forums. Continue verifying terms independently until you can qualify one as the likeliest to be correct.\n\nI am new to blogging, and I wanted a way to link multiple blog posts other than tags and categories. Specifically, I wanted to relate all of the posts that were in a series. I knew that a WordPress plugin would be useful for this, but I didn’t know what a blogger would usually call this series-oriented relationship.\n\nI crafted the following prompt using few-shot learning. I used examples from problem domains I am familiar with. I included examples ending in -ship, -ment, and -tion to reduce bias.\n\nI gave the same prompt to four different models. The responses gave me a broad series of options. It became clear that my lack of knowledge was hiding an important fact: the name of the relationship can change depending on why these blog posts are in a series.\n\nHere are semantic noun options for the relationship between Blog Post and Series:\n\nContext-dependent alternatives:\n\nMy personal favorite is Inclusion for its clarity and semantic precision, though Installment works beautifully if you want to emphasize the sequential, serialized nature of blog posts within a series.\n\nHere are good semantic-noun options for a relationship class between Blog Post and Series:\n\nBest general-purpose choice: Installment or Entry, depending on whether sequence matters.\n\nNice little modeling problem 😊\n\nHere are some semantic noun options for the relationship between Blog Post and Series:\n\nIf you want something that feels closest in style to Authorship/Membership/Enrollment, I’d probably shortlist:\n\nTo determine a suitable semantic noun for the relationship class between “Blog Post” and “Series”, we can consider the nature of their relationship. The given examples illustrate various relationships, such as authorship, membership, enrollment, assignment, participation, and contribution, which all describe how two entities are connected.\n\nFor “Blog Post” and “Series”, the relationship is about a blog post being part of a series. Here are some potential semantic nouns for this relationship:\n\nHowever, the most straightforward and semantically relevant noun for this relationship could be Serialization.\n\nOf these, “Serialization” directly conveys the idea of blog posts being part of a series, making it a strong candidate.\n\nHere are several semantic noun options for the relationship class between a Blog Post and a Series, categorized by the nature of the relationship:\n\nThis is the strongest semantic match for blog content. Just as a “Member” is the entity in a “Membership,” a post in a series is often called an “Installment.” It implies a periodic release schedule typical of blogging.\n\nIf the defining characteristic of the relationship is the specific numerical order (e.g., Part 1, Part 2, Part 3), “Sequence” or “Ordering” describes the link effectively.\n\nIf the blog series tells a story or follows a journey (e.g., “Our Startup Journey,” “Travel Diaries”), this noun borrows the semantic weight of TV or podcasts to imply a narrative arc.\n\nIf the series is educational, long-form, or intended to be read like a book, “Chapter” elevates the relationship to suggest a distinct, substantive section of a larger whole.\n\nIf the series is a loose collection of related posts without a strict chronological necessity (e.g., “Best of 2023,” “Editor’s Picks”), this implies the act of gathering or curating.\n\nBecause of the specific kinds of series I wanted to create, and because of its frequency across different responses, I chose installment as my candidate. I searched blog series \"installment\" and article series \"installment\" on Kagi, Marginalia, Google Scholar, and the O’Reilly Learning Platform. The resources I found verified that bloggers and journalists use this term for the same purpose. I looked through Technical Blogging, 2nd Edition by Antonio Cangiano and found its use in Chapter 4. I was satisfied with this term, so I did not verify other candidates.\n\nInstead of using a substitute word, inventing a new term, or using a concept from the language of a different problem domain, you will know the jargon used by the people who need your software. This will help you build a better model of the problem, and your solution will be more likely to be useful, accepted, and appreciated.\n\nThis was the first installment in the Workflow Patterns for AI-Assisted Development series. To get notified when a new article is published, \n\nThe image in this article was generated using AI tools (Nano Banana Pro) based on creative prompts. The written word in this article is proudly human-made, except for the five designated LLM outputs in the Example.",
    "readingTime": 7,
    "keywords": [
      "development series",
      "few-shot prompting",
      "discover jargon",
      "domain language",
      "noun options",
      "semantic noun",
      "relationship class",
      "blog posts",
      "series installment",
      "workflow patterns"
    ],
    "qualityScore": 1,
    "link": "https://kerrick.blog/articles/2025/use-ai-to-stand-in-for-a-domain-expert/",
    "thumbnail_url": "https://kerrick.blog/wp-content/uploads/2025/12/CleanShot-2025-12-09-at-07.26.47@2x.png",
    "created_at": "2025-12-09T13:48:21.609Z",
    "topic": "tech"
  },
  {
    "slug": "it-used-to-be-for-shopping-and-lipstick-now-a-chinese-app-is",
    "title": "It used to be for shopping and lipstick. Now, a Chinese app is a haven for tech workers to swap AI intel.",
    "description": "Chinese app Rednote started off as a shopping app. Now, it's one of the hottest hubs for Chinese tech workers in Silicon Valley to talk shop about AI.",
    "fullText": "When the Chinese app Rednote launched in 2013, it was mainly used for shopping and cosmetics reviews. Now, it's one of the hottest hubs for Chinese tech workers in Silicon Valley to talk shop about AI.\n\nRednote is also known as Xiaohongshu, which translates to \"Little Red Book.\" For Chinese tech workers in the Bay Area working at companies like OpenAI and Meta, Rednote has become a sort of home away from home for shopping and food recommendations. And since the launch of ChatGPT, AI-related content on Rednote has exploded.\n\nTechnology-related content on the app has more than doubled in the past year, and the number of tech-related creators has more than tripled, according to Rednote. Many users post video reviews or tutorials of AI models, just like people review their favorite beauty products.\n\n\"Every time a new model is out, people on Xiaohongshu will share their reviews,\" said Tony Peng, founder of the Recode China AI newsletter. \"If I want real user-generated feedback, I go to Xiaohongshu.\"\n\nMany American Gen Z users downloaded Rednote in January amid fears of a TikTok ban. More than half of the app's users were born after 1995, Rednote said.\n\nTech founders told Business Insider that they have used Rednote to promote their startups, demo products, and hire people. Some of the most popular posts on Rednote focus on Big Tech companies or AI giants such as OpenAI, Anthropic, or Google DeepMind. Users may share their anxieties about the tech job market, ask for help, or discuss the compensation packages they've received.\n\nBrandon Chen, cofounder and CEO of the AI-powered chat app Intent, needed to apply for a visa last year to work in the US.\n\nTo do this, he had to prepare hundreds of PDFs for his lawyer, and he decided to write an AI program to help organize them. He posted before-and-after screenshots of his project on Rednote. Soon, people messaged him asking if he would release it as an app so they could use it.\n\n\"I thought it was amazing. I just randomly developed something for myself,\" Chen told Business Insider.\n\nHe ended up releasing it as a product called Riffo.\n\nChen said he used Rednote to promote his product and even to recruit workers in Japan. He posted on Rednote asking if any Japanese speakers could help with his social media expansion efforts, and within 15 minutes, someone reached out, Chen said.\n\nQian Chen, a journalist and media entrepreneur who cofounded the tech media company Valley101, said she distributes her videos on channels including YouTube, WeChat, and Rednote. The videos she has produced on topics like Meta's recent AI layoffs, and the battle between ChatGPT and Google, have performed especially well on Rednote, she said.\n\nRednote helps startup founders foster communities, users say.\n\nBill Zhu, founder and CEO of Pokee AI, which uses AI to build workflows, said he found a tight-knit community on Rednote to share his learnings, attract users for his products, connect with others, and ask for feedback. Rednote users are often drawn to posts about personal experiences, Zhu said. In Rednote posts, he has chronicled his fundraising efforts, including successes and setbacks.\n\n\"You can actually connect with the founder,\" Zhu said. \"It's someone you're actually talking to. You can reach out to this person building this awesome piece of tech that is able to solve these problems.\"\n\nDuring the back-to-school season in September, Rednote launched an \"AI Guide\" campaign, inviting 20 professors to join a discussion on the app.\n\nRednote has gained more international users thanks to its AI translation feature, which enables users to translate posts from Chinese to English or other languages with a single click. And while most of the content that appears on Rednote is in Chinese, the app is increasingly featuring English content, including an AMA, or Ask Me Anything, event with Thomas Wolf, cofounder and chief science officer of Hugging Face.\n\nAn atmosphere of \"sincere sharing\" has fueled a trend of AI-themed AMAs on Rednote, said San Bing, Rednote's senior director of tech community.\n\nThe AMAs are popular because Rednote users are eager to learn about cutting-edge technology, said Peng, the founder of Recode China AI.\n\n\"For AMAs, you can get firsthand answers to tell you, what is the next frontier?\" Peng said.\n\nHave a tip? Contact this reporter via email at rmchan@businessinsider.com, or Signal at rosal.13. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "recode china",
      "chinese tech",
      "rednote launched",
      "tech workers",
      "app rednote",
      "rednote users",
      "content",
      "founder",
      "posts",
      "reviews"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/rednote-xiaohongshu-ai-startups-founders-app-communities-2025-11",
    "thumbnail_url": "https://i.insider.com/692645c2abd5e944effb857b?width=1200&format=jpeg",
    "created_at": "2025-12-09T13:48:21.075Z",
    "topic": "finance"
  },
  {
    "slug": "50-billion-tiger-global-is-returning-to-its-concentrated-hig",
    "title": "$50 billion Tiger Global is returning to its concentrated, 'high-conviction' roots in its latest private fund",
    "description": "The firm has been a longtime backer of big-name private companies such as OpenAI and TikTok parent ByteDance.",
    "fullText": "Tiger Global's latest private investment fund will raise substantially less money than its predecessors from 2021 and 2022, but the $50 billion asset manager isn't worried.\n\nThe firm is expected to raise close to $2 billion for PIP 17, a person familiar with the manager told Business Insider.\n\nThat's a fraction of what PIP 14 and PIP 15 raised and aligns more closely to PIP 16, which closed in early 2024 with $2.2 billion in assets after aiming initially for $6 billion.\n\nWhile smaller fundraises typically coincide with a decline in investor interest, Tiger Global is confident that the size of the new fund will be a benefit for those who do decide to invest.\n\n\"Over our history, we have also found that smaller, more concentrated funds have been correlated with our strongest returns,\" the firm wrote in a letter to prospective investors that was seen by Business Insider.\n\nTiger Global declined to comment.\n\nThe first 10 private funds, the letter states, all raised less than $3 billion each, made fewer than 50 investments on average, and \"generated a 34% gross IRR and a 23% net IRR and made distributions exceeding investor commitments.\n\n\"We believe funds in this size range afford us significant benefits, particularly with respect to the impact midsize investments can make,\" the letter reads.\n\nIn other words, Tiger Global's aggressive venture style from 2020 through 2022, when the firm led fundraising rounds seemingly every week and raised increasingly larger funds, has been replaced with one that is closer to what the firm built its business on. The manager previously wrote to investors earlier this year about how it reworked its risk systems following a 56% loss in its public-equity flagship hedge fund and compared the firm's bounce-back from that loss to golfer Rory McIlroy's Masters win.\n\nThe most recent private fund, PIP 16, has already reaped some of the benefits of the style focused on \"high-conviction\" bets. The fund has invested 70% of its assets across 25 companies, the letter states, with the 10 largest investments accounting for three-quarters of that total.\n\nAmong those big bets are some of the world's prominent artificial intelligence companies, including OpenAI and Waymo.\n\n\"We have remained incredibly disciplined and selective\" when investing PIP 16, the firm wrote, and plan to continue that with PIP 17, which will hold its first close on March 18 next year. The new fund is the latest example of Tiger Global and its peers' renewed interest in private markets.\n\n\"This approach is opportunistic, guided by bottom-up, company-level underwriting, and informed by our deep research and cumulative insights,\" the letter states.\n\n\"To accomplish this, PIP 17 may have a pace of deployment spanning several years. With time on our side and an accelerated pace of innovation, we intend to remain patient — waiting for attractive opportunities to make high-conviction investments.\"",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "tiger global's",
      "tiger global",
      "fund",
      "firm",
      "letter",
      "funds",
      "investments",
      "manager",
      "latest"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/tiger-global-fundraise-pip-17-high-conviction-bets-openai-2025-12",
    "thumbnail_url": "https://i.insider.com/69375b9271107c9f34578fe3?width=1200&format=jpeg",
    "created_at": "2025-12-09T13:48:20.887Z",
    "topic": "finance"
  },
  {
    "slug": "pwcs-ai-chief-says-the-tech-is-overwhelming-everyone-but-com",
    "title": "PwC's AI chief says the tech is 'overwhelming everyone' but companies moving fast are seeing 3 times the revenue",
    "description": "PwC's AI chief says the pace of AI is leaving everyone overwhelmed, but companies that move fast are unlocking triple the revenue per employee.",
    "fullText": "Worried about how AI is affecting your job? You're not alone.\n\nEveryone from the board to management to employees has concerns about the new technology, said Joe Atkinson, PwC's global head of AI, in an appearance on CNBC's Squawk Box Asia on Tuesday.\n\n\"It's a complex time in the world of AI implementation,\" said Atkinson. The pace of AI change is \"overwhelming to everybody\" and there's a \"mismatch\" between how quickly organizational change can keep up with it, he said.\n\nGlobal companies routinely look to PwC, one of the industry's leading consulting and accounting firms, for answers to their most consequential business questions. With AI rapidly transforming how businesses operate, guidance on reorganizing for an AI-first future is becoming one of the most sought-after offerings.\n\nAtkinson said that the next phase of implementing AI inside companies is scaling the technology's capabilities, and companies that move quickly will see the most reward.\n\n\"We've talked for the last year about proofs of concept and experimentation, and frankly, those days are over. We now have to scale the impact of AI in organizations,\" Atkinson said.\n\n\"The good news for employees is if we scale the impact of AI for organizations, I truly believe we create and unlock growth,\" he added.\n\nAccording to PwC's data, organizations that adopt AI more quickly have seen three times the revenue per employee compared to those that proceed more slowly.\n\n\"That opportunity means that it's not only a big upside for organisations. It is a big upside for employees who lean in and use these tools to help create greater productivity, outputs, and creativity,\" Atkinson said.\n\nPwC and other leading consulting firms have embraced AI, pitching themselves as client zero for the solutions they offer to clients and implementing AI solutions across all operations.\n\nNew hires at PwC will be doing the roles that managers are doing within three years because of AI, Jenn Kosar, PwC's AI assurance leader, told Business Insider in August.\n\nThe technology is also affecting the firm's hiring plans. In August, Business Insider obtained part of an internal presentation showing that PwC US planned to cut graduate hiring by a third over the next three years, in part due to \"the impact of AI.\"\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "leading consulting",
      "employees",
      "quickly",
      "impact",
      "organizations",
      "affecting",
      "technology",
      "firms",
      "implementing",
      "scale"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pwc-companies-embracing-ai-see-revenue-boosts-2025-12",
    "thumbnail_url": "https://i.insider.com/6937e7e971107c9f34579286?width=1200&format=jpeg",
    "created_at": "2025-12-09T13:48:20.726Z",
    "topic": "finance"
  },
  {
    "slug": "6-notable-stats-from-openais-analysis-of-ais-impact-in-the-w",
    "title": "6 notable stats from OpenAI's analysis of AI's impact in the workplace",
    "description": "OpenAI said in its first enterprise report that three-quarters of 9,000 surveyed workers say AI improved their productivity.",
    "fullText": "OpenAI says it's boosting productivity.\n\nOn Monday, OpenAI published its first report on the state of enterprise AI, and based on the 9,000 surveyed workers across 100 companies, three-quarters said that AI has improved the speed and quality of their work.\n\nThe report comes a week after Anthropic published its own findings, which said its Claude assistant cut task-completion time by 80%, based on 100,000 user conversations.\n\nAnthropic's findings don't appear to have been peer-reviewed, nor is OpenAI's survey. OpenAI and Anthropic did not immediately respond to requests for comments on whether their reports are peer-reviewed.\n\nDespite the reports, skepticism still swirls about whether the technology is actually making workers more productive. An August study by MIT found that most companies saw no measurable return on their investments in generative AI.\n\nA paper published by Stanford and Harvard University in September said that many professionals are churning out \"workslop,\" referring to AI-generated content that looks polished but fails to move tasks forward. Fears that the billions of dollars companies have poured into AI will not yield an equal return have been driving investor concern about an AI bubble.",
    "readingTime": 1,
    "keywords": [
      "published",
      "based",
      "workers",
      "findings",
      "peer-reviewed",
      "reports",
      "return",
      "openai",
      "anthropic"
    ],
    "qualityScore": 0.75,
    "link": "https://www.businessinsider.com/statistics-from-openai-analysis-of-ai-impact-in-the-workplace-2025-12",
    "thumbnail_url": "https://i.insider.com/69377bee71107c9f345790b7?width=1200&format=jpeg",
    "created_at": "2025-12-09T13:48:20.693Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-opensource-models-make-up-30-of-global-ai-usage-led-b",
    "title": "China's open-source models make up 30% of global AI usage, led by Qwen and DeepSeek",
    "description": "China's open-source artificial intelligence models accounted for nearly 30 per cent of total global use of the technology, while Chinese-language prompts ranked second in token volume behind English, according to a report. This year's surge in open-source large language model (LLM) usage around the world had been fuelled by Chinese-developed systems, including Alibaba Group Holding's Qwen family of models, DeepSeek's V3 and Moonshot AI's Kimi K2, according to a recently published report by OpenR",
    "fullText": "China's open-source artificial intelligence models accounted for nearly 30 per cent of total global use of the technology, while Chinese-language prompts ranked second in token volume behind English, according to a report.\n\nThis year's surge in open-source large language model (LLM) usage around the world had been fuelled by Chinese-developed systems, including Alibaba Group Holding's Qwen family of models, DeepSeek's V3 and Moonshot AI's Kimi K2, according to a recently published report by OpenRouter, a third-party AI model aggregator, and venture capital firm Andreessen Horowitz. Alibaba owns the South China Morning Post.\n\nProprietary Western models, such as OpenAI's GPT-4o and GPT-5, remained dominant with a 70 per cent global share.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\nAccording to the empirical study of 100 trillion tokens by OpenRouter, Chinese open-source LLMs' global share started from a low base of 1.2 per cent in late 2024 to reach nearly 30 per cent over a few months this year. Tokens are units of data processed by AI models during training and inference, enabling prediction, generation and reasoning.\n\nSo far this year, Chinese open-source LLMs averaged 13 per cent of weekly token volume, as growth accelerated in the second half of 2025, to almost match the 13.7 per cent average recorded by AI models from the rest of the world, the report said.\n\n\"China has emerged as a major force, not only through domestic consumption but also by producing globally competitive models,\" the report said.\n\nThe report offered fresh evidence that China has become a close peer of the United States in AI model development, despite Washington's restrictions on Chinese firms' access to advanced graphics processing units from the likes of Nvidia and Advanced Micro Devices.\n\nProprietary Western large language models, such as OpenAI's GPT family, continue to lead global AI usage. Photo: Shutterstock alt=Proprietary Western large language models, such as OpenAI's GPT family, continue to lead global AI usage. Photo: Shutterstock>\n\nThe rise of Chinese open-source AI models \"reflect not only competitive quality, but also rapid iteration and dense release cycles\", the report said.\n\nIt pointed out that the aggressive release schedules of Alibaba Cloud's Qwen and DeepSeek had enabled users to rapidly adapt to increased development workloads. Alibaba Cloud is the AI and cloud computing services unit of Hangzhou-based Alibaba.",
    "readingTime": 3,
    "keywords": [
      "proprietary western",
      "gpt family",
      "open-source llms",
      "chinese open-source",
      "token volume",
      "nearly per",
      "per cent",
      "language models",
      "openai's gpt",
      "usage"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/chinas-open-source-models-30-093000383.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/PrmWBoxMId82baSn.RI35g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/south_china_morning_post_us_228/0f84fca21b8b0862606316744c311599",
    "created_at": "2025-12-09T13:48:17.577Z",
    "topic": "finance"
  },
  {
    "slug": "the-rampocalypse-is-nigh",
    "title": "The RAMpocalypse Is Nigh",
    "description": "Much ado is being made about AI being the root cause of the current memory price surge, but the reality is a bit more complex than that.",
    "fullText": "Much ado is being made about AI being the root cause of the current memory price surge, but the reality is a bit more complex than that. While AI workloads do demand significant memory resources, the underlying issues stem from a combination of factors affecting the entire semiconductor industry–the fact that Micron is shutting down Crucial shocked many PC builders, but if you look at all the charts and ponder the situation, you quickly realize that:\n\nPlus there’s an inconvenient truth–most people do not build (or even upgrade) their own PCs anymore, so the market for custom builds is shrinking, which means less competition and higher prices for those who do.\n\nI do find it highly amusing that people find that Apple’s M-series Macs are now in line with the market, especially since this dynamic doesn’t really apply to Apple–remember they fab the RAM directly into their CPUs, so they’re largely immune to discrete component pricing fluctuations.\n\nPlus, of course, Apple can negotiate far better pricing even if they were to buy discrete RAM, given their scale and influence in the market. At best, they would be affected by IP licensing for specific RAM technologies, but that’s a different matter altogether.\n\nWhat I don’t find amusing, though, was that I completely forgot to buy RAM for one of my machines over Black Friday. Good thing that borg was padded out with 128GB two years ago when it was cheaper…",
    "readingTime": 2,
    "keywords": [
      "their",
      "market",
      "find",
      "apple",
      "being",
      "memory",
      "plus",
      "even",
      "amusing",
      "discrete"
    ],
    "qualityScore": 0.55,
    "link": "https://taoofmac.com/space/links/2025/12/05/1330",
    "thumbnail_url": "https://taoofmac.com/thumb/links/2025/12/05/1330/640,480/h2RPffPkkUlwpfJbi4cmimxbPyA=/large.jpg",
    "created_at": "2025-12-09T08:42:57.257Z",
    "topic": "tech"
  },
  {
    "slug": "dagger-define-software-delivery-workflows-and-dev-environmen",
    "title": "Dagger: Define software delivery workflows and dev environments",
    "description": "Build powerful software environments and containerized operations from modular components and simple functions. Perfect for complex software delivery and AI agents. Built by the creators of Docker.",
    "fullText": "and more into programmable and stateful objects. Get full type safety across with a consistent interface that works in any supported language.\n\nWrite function chains that work consistently anywhere. Functions automatically cache results and maintain pure state between runs—no more rebuilding what hasn't changed.\n\nWrite function chains that work consistently anywhere. Functions automatically cache results and maintain pure state between runs—no more rebuilding what hasn't changed.\n\nAdd capability, control, predictability, and observability to your workflows or AI coding agents — without adding more to your plate.\n\nPrototype, test, debug, and ship interactively and quickly through your terminal. Write applications in Python, TypeScript, Go, or any language you prefer with type-safe connections. Mix components across language ecosystems.\n\nPrototype, test, debug, and ship interactively and quickly through your terminal. Write applications in Python, TypeScript, Go, or any language you prefer with type-safe connections. Mix components across language ecosystems.\n\nPrototype, test, debug, and ship interactively and quickly through your terminal. Write applications in Python, TypeScript, Go, or any language you prefer with type-safe connections. Mix components across language ecosystems.\n\nPrototype, test, debug, and ship interactively and quickly through your terminal. Write applications in Python, TypeScript, Go, or any language you prefer with type-safe connections. Mix components across language ecosystems.\n\nAdd agentic capabilities into your workflows, or give agents the perfect environment and set of tools so they can do their magic without wreaking havoc.\n\nAdd agentic capabilities into your workflows, or give agents the perfect environment and set of tools so they can do their magic without wreaking havoc.\n\nAdd agentic capabilities into your workflows, or give agents the perfect environment and set of tools so they can do their magic without wreaking havoc.\n\nAdd agentic capabilities into your workflows, or give agents the perfect environment and set of tools so they can do their magic without wreaking havoc.\n\nBuilt-in tracing, logs, and metrics that show exactly what's happening at every step. Debug complex agent interactions immediately instead of guessing what went wrong.\n\nBuilt-in tracing, logs, and metrics that show exactly what's happening at every step. Debug complex agent interactions immediately instead of guessing what went wrong.\n\nBuilt-in tracing, logs, and metrics that show exactly what's happening at every step. Debug complex agent interactions immediately instead of guessing what went wrong.\n\nBuilt-in tracing, logs, and metrics that show exactly what's happening at every step. Debug complex agent interactions immediately instead of guessing what went wrong.\n\nContainerized execution runtime that creates cacheable, reproducible operations. Works with any compute platform or tech stack, automatically optimizing for speed and cost.\n\nContainerized execution runtime that creates cacheable, reproducible operations. Works with any compute platform or tech stack, automatically optimizing for speed and cost.\n\nContainerized execution runtime that creates cacheable, reproducible operations. Works with any compute platform or tech stack, automatically optimizing for speed and cost.\n\nContainerized execution runtime that creates cacheable, reproducible operations. Works with any compute platform or tech stack, automatically optimizing for speed and cost.\n\nBuild reusable modules to share with your team or grab existing ones from the Daggerverse — stop coding the same automation patterns from scratch.\n\nExplore projects built with Dagger, for inspiration or a quick start.\n\nAn agent that automatically debugs failing tests in CI\n\nAn agent that automatically debugs failing tests in CI\n\nAn agent that automatically debugs failing tests in CI\n\nAn agent that automatically debugs failing tests in CI\n\nAn agent that analyzes Dockerfiles and suggests improvements for better efficiency, security, and best practices\n\nAn agent that analyzes Dockerfiles and suggests improvements for better efficiency, security, and best practices\n\nAn agent that analyzes Dockerfiles and suggests improvements for better efficiency, security, and best practices\n\nAn agent that analyzes Dockerfiles and suggests improvements for better efficiency, security, and best practices\n\nAn agent that gets assigned GitHub issues and solves them with pull requests\n\nAn agent that gets assigned GitHub issues and solves them with pull requests\n\nAn agent that gets assigned GitHub issues and solves them with pull requests\n\nAn agent that gets assigned GitHub issues and solves them with pull requests\n\nA Go programmer agent that receives assignments from GitHub issues and creates PRs with solutions.\n\nA Go programmer agent that receives assignments from GitHub issues and creates PRs with solutions.\n\nA Go programmer agent that receives assignments from GitHub issues and creates PRs with solutions.\n\nA Go programmer agent that receives assignments from GitHub issues and creates PRs with solutions.\n\nA simple programmer micro-agent for demonstration purposes.\n\nA simple programmer micro-agent for demonstration purposes.\n\nA simple programmer micro-agent for demonstration purposes.\n\nA simple programmer micro-agent for demonstration purposes.\n\nAn experimental open-source coding agent made of small composable modules\n\nAn experimental open-source coding agent made of small composable modules\n\nAn experimental open-source coding agent made of small composable modules\n\nAn experimental open-source coding agent made of small composable modules\n\nA demonstration using multiple LLMs to collaboratively solve a problem.\n\nA demonstration using multiple LLMs to collaboratively solve a problem.\n\nA demonstration using multiple LLMs to collaboratively solve a problem.\n\nA demonstration using multiple LLMs to collaboratively solve a problem.\n\nAn agent that compares two git branches for UI changes and creates Cypress tests to cover the difference.\n\nAn agent that compares two git branches for UI changes and creates Cypress tests to cover the difference.\n\nAn agent that compares two git branches for UI changes and creates Cypress tests to cover the difference.\n\nAn agent that compares two git branches for UI changes and creates Cypress tests to cover the difference.\n\nAn agent that plays Tic Tac Toe with a human player\n\nAn agent that plays Tic Tac Toe with a human player\n\nAn agent that plays Tic Tac Toe with a human player\n\nAn agent that plays Tic Tac Toe with a human player\n\nAn agent that summarizes technical content from a URL for a non-technical audience\n\nAn agent that summarizes technical content from a URL for a non-technical audience\n\nAn agent that summarizes technical content from a URL for a non-technical audience\n\nAn agent that summarizes technical content from a URL for a non-technical audience\n\nAn agent that answers plain-language questions by querying MySQL or PostgreSQL databases\n\nAn agent that answers plain-language questions by querying MySQL or PostgreSQL databases\n\nAn agent that answers plain-language questions by querying MySQL or PostgreSQL databases\n\nAn agent that answers plain-language questions by querying MySQL or PostgreSQL databases\n\nIt's kind of a container-based swiss army knife that can be used for CI operations (reproducible builds, testing, publishing), creating LLM agents, and more. Tons of integrations and open-source modules on the \"Daggerverse\".\n\nWhen @solomonstre drops an open-source Claude Code... ya run with it. \"Toy Programmer\" + added MCP & cursor-rules + an updated version of @zbeyens phenom \"dotai\" repo\n\nThis is so awesome to play with. I just made a new frontend for my main demo repo without any hand-holding, writing integrations, or anything. Just core dagger + bring your own LLM. In a 2 minute video. Most of which is for the sake of the recording\n\nSo im finally coming around on this whole AI thing is the future...Solomon Hykes demo of an agent writing a curl clone in 5 minutes using Dagger is still lingering in my mind...if any of you are curmudgeons like me you might want to watch...\n\nIf you don’t know where to start to create AI agents, you should have a look at Dagger agents. That makes it so easy to build tools that will benefit from AI but as real developer tool.\n\nFew understand the implications of this. This will be absolutely defining\n\nI'm feeling a \"docker moment\" in real time. Even though I didn't know the CI tool, it seems so promising for multiple areas.\n\n@dagger_io experimental AI tooling is really interesting. I just leveraged two separate modules (Strava and Notify). It took me 20 minutes to build the prompt and less than 5 to write the code.\n\nThis is crazy cool! If you have worked with LLMs this is amazing!\n\nall your dagger functions are now available for agents to use. built-in function registry.\n\nThis is nuts. @dagger_io has always had amazing dev exp, but the fact that it lends itself so seamlessly to something like this is endlessly impressive, massive props @solomonstre and the team!\n\nOk, my mind is a little blown right now. I never considered having LLMs accept containers as inputs and then interact with them to accomplish some goal.\n\nThat's why tools like @dagger_io are going to be so powerful! (standardized text interface, multi-language modules and a neatly integrated web GUI over the CLI) Great AI assistant experiences largely depend on well-designed interfaces they can easily leverage.\n\nI think few realize where Dagger sits in the agentic race. I know I didn’t until I was shown. Incredible.\n\nIf you can relate, you need @dagger_io and fast.\n\nIt’ll take time for people to realize the value of @dagger_io but I’m optimistic it’ll reach critical mass and break the vendor locking that many CI providers benefited from for many years.\n\nI just tried to set up a CI pipeline using @dagger_io to compile and test an Elixir project and OMG. The portability is so priceless. Blog post in progress 😀​\n\nMy entire CI/CD pipeline is Dagger and I'd love for dev to be too; still a few changes that need to happen there though.\n\nCo-founder @gokoyeb , deploy apps and databases on high-performance infrastructure around the world. Previously built @scaleway\n\nExcited to hear @solomonstre talking about @dagger_io and Dagger functions. Need to push the @gokoyeb function to the Daggerverse\n\nOpen Source Effectively Accelerates !\n\nIt was great to participate @dagger_io Meetup yesterday, one of the purest form of OSS event: no bullshit, minimal slides, maximum code. @solomonstre might gave away his @KubeCon_ KN magic a bit\n\n🚀 My top pick video from hashtag#KubeCon + hashtag#cloudnative in Paris is out! From integrated environments to innovative approaches, there's something for every science community to keep an eye on. \n\nYOU get to choose what we dive into next! Comment with your preference! \n\nhttps://lnkd.in/d2Xj2DhJ\n\n1️⃣ First up, Kubeflow offers an all-in-one solution for data science workflows on Kubernetes. Check out CERN Computing's experience at the hashtag#cloudnativeAIDay event and the DHL Data & Analytics and their journey to a data science platform.\n\n2️⃣ Impressive NATS.io with a demo by Synadia perfect for applications from hashtag#ai / hashtag#ml on IoT to microservices\n\n3️⃣ Discover Dagger Functions, revolutionizing workflow management for reproducibility and interoperability\n\nPlus, an extra shoutout to the Cloud Native Computing Foundation (CNCF) Enduser Research, let's push it together as it should be!\n\nConseiller intégrateur en architecture logicielle (Cloud/DevOps) chez Ministère de la Famille du Québec (MFA)\n\nWhat I also like 👌 about Dagger is that it perfectly aligns with my personal fav quote: \n\n'Localhost is your best cloud provider’ 🔥🚀\n\nhttps://dagger.io\n\nWhat Is Dagger and Why You Might Want to Use It 🧵​\n\nDagger promises to fix our CI/CD once and for all, but what exactly is Dagger?\n\nIs it a GitHub Actions or Jenkins replacement? Or is it a dev tool that augments existing CI/CD providers? Is it a service or a CLI?\n\nJust finished an incredible hands-on session with Saiyam Pathak, Solomon Hykes, and Kyle Penfound on the Kubesimplify channel, diving deep into the powerful tool Dagger. Followed along on my personal computer and learned a ton. Highly recommend checking it out for anyone interested in cutting-edge DevOps! hashtag#Dagger hashtag#DevOps hashtag#Kubesimplify\n\nhttps://lnkd.in/dygitKgn\n\nSenior Software Engineer at Microsoft\n\nI always felt like tools like docker-compose were not the right fit me me. Always required lots of glue to make it work for the things I needed to do.\n\nThis is where @dagger_io shines. Far more programatic, testable, and repeatable.\n\nWe released a new version of our @dagger_io Daggerverse module to bring the Depot ephemeral registry to our bake function. Going to be a game changer for building all your images at once and being able to do things with the containers immediately\n\nhttps://depot.dev/changelog/2024-03-26-depot-daggerverse-1-1-0\n\nDevOps engineer at @rtCamp | loves writing code | Founder of @ksctl_k8s\n\nyou all got me. Taskfile and Makefile now its dagger @SaiyamPathak. 🙃​ Btw nice explanation on dagger. I think its a good tool, used it 1 year ago 😉​ @dagger_io\n\nNothing beats reading a story about Dagger from a real user. Thanks so much to Scott Molinari for sharing your experience :) \nhttps://lnkd.in/d9fQGRg7\n\nexpert at spline reticulation. ⚡ AWS Infinidash MVP ⚡ I ❤️ coding. Work as Senior Software Engineer.\n\nWrapping my head around the new functions thing is going to take a bit. But I've already done nested docker Goreleaser with CGO_ENABLED , angular builds and more with the SDK. So great! Dagger call might take over all my 3 years of mage work once I figure it all out.\n\nsr engineer @saucedopen 🥡 prev: AWS, VMware, Pivotal\n\n@sheldon_hull @dagger_io and @MagefileDotOrg We’re starting to adopt dagger actually loving it so far\n\nFormer Executive Director, OpenDaylight Project, founder VSPP/vCloud @VMware , launched Cilium/Isovalent out of stealth, now helping Solomon grow http://Dagger.io\n\nWhat a WILD morning! @solomonstre‘s keynote seems to have ignited something major, we’ve been swamped all morning here at @KubeCon_!\n\nDevOps. Security. Observability. Linux. Kubernetes. Sailing. ReveCom Media.\n\nUse @dagger_io to build pipelines input: @chainguard_dev's Building Container Images the Modern Way -\n\n@chainguard_dev' s Adrian Mouat demo. It « real strength » is its modules, he said.\n\n@KubeCon_ @linuxfoundation @thenewstack\n\nThe #Kubernetes & #cloudnative community conference\n\n“It’s all about the people.” - Solomon Hykes #kubecon #cloudnativecon\n\nDevRel/GTM Leader | News/Podcast @InfoQ | Web 2.0 coder, platform engineer, Java Champion, CS PhD | cloud/K8s, APIs, IPAs, running | learner/teacher\n\nAn enjoyable look back on the origins of @Docker, containers, and cloud platforms, via @solomonstre\n\nat #KubeCon. And love the call out to “dude, where’s my platform?” Many of us are still working on this with\n\n@dagger_io, @kratixio, #Backstage, and @CloudNativeFdn tech\n\nCNCF Ambassador | @kubernetesio 1.23 Release Lead, 1.25 Emeritus Adviser, K8s SIG Docs co-chair | 👨🏻‍💻 @RedHat\n\n#KubeCon Europe day 3 keynotes with @solomonstre from @dagger_io who helped kick off popularizing #containers and #CloudNative over a decade ago. 16 years ago, the first working build of Docker was created walking distance from #KubeCon Paris\n\nThe recording of my #kubecon keynote is out: https://youtu.be/S_Z4AHZlSUI Thank you to everyone who attended, on the last day of a draining event. It was a special moment that I enjoyed very much, I hope you did too. Non-french speakers: watch this after\n\nSr. Kubernetes Specialist SA @AWSCloud | CNCF Ambassador | Kubernetes contributor\n\nJoin me at the first @dagger_io meetup in Raleigh, NC this week. The meetup will start by teaching the basics of Dagger with real-world examples. I'm still in KubeCon mode, looking forward to meeting the DevOps community in person! Check out the event details at https://meetu.ps/e/MWc2l/3Fcx2/i\n\nMom. Software engineer. Author. Java Champion. Docker Captain. Dev Advocate @JFrog\n\nYeah... ok, there are much better foot models out there than me, but I had to show off the @dagger_io gear I brought with me from #KubeCon Chicago! Thanks for these @jpadamspdx - they were perfect for the long flight home after an incredible week at #KubeCon Paris!\n\n@solomonstre surrounded by people at #KubeCon\n\nI built my first Dagger function yesterday with Solomon Hykes, and just got it published up on the daggerverse!\n\nDagger is awesome, and I plan on continuing to find ways to use it. At a high level, dagger lets you use containers as a first-class object in code, and stitch together complex orchestration pipelines using real programming languages instead of bash.\n\nPrimitives like mounting in files/directories, running commands, building and publishing containers, environment variables and secrets are all available, type-safe, and programmable in Go, Python, or Typescript.\n\nDagger functions let you build abstractions and methods on top of these basic primitives that can then be exposed and reused by other Dagger functions. The entire experience is encapsulated by the `dagger` cli, which uses magical buildkit caching and orchestrations so it's all *fassstttt*. You can run it locally or in CI systems and get the same results, and confidence that things will actually work after a push.\n\nAs self-described a yamlbash enthusiast, I'm still excited at the thought of replacing those tangled messes with real code.\n\nCheck it out here, this version is capable of building Python wheel packages across a variety of Python versions, and can handle installation of extra build-time dependencies too, for when you need some ugly cmake stuff or other native libraries. Also, it uses wolfi and Chainguard images for all the execution and package handling :)\n\nhttps://lnkd.in/eDBtk7pm\n\n#dagger #ci #opensource #wolfi #chainguard\n\nChainloop is an Open Source Metadata Vault for your Software Supply Chain metadata, OWASP CycloneDX SBOM/xBOM Standard, SPDX SBOM, VEX, SARIF files, QA reports, and more.\n\nFrom today, you can programmatically collect and enforce Software Supply Chain pieces of evidence from your Dagger pipeline!\n\nDagger is a great fit since it is aligned with our principle of meeting developers where they are, and you can’t get closer to them than in code, with their programming language, and in their local machine 🙂\n\nIf you want to give it a try in person, we'll also be in a couple of days at #kubecon in Paris. See you there!\n\nI first saw a demo of Dagger two years ago and you could sense something big was brewing.\n\nNow with Dagger functions, it's actually happening. I just saw another demo and it really feels like something we'll all be using!\n\nCongrats Dagger for building something special!\n\nDagger is a programmable open source CI/CD engine. I built a Dagger module to solve the \"but it works on my machine\" problem that occurs where tests that pass locally do not pass in development because of inconsistencies in environment configurations for NodeJS applications. In this blog I detail the entire process; what I learnt through my build along with insights gained from reading Dagger docs and their Python SDK.\n\n#Python #CICD #Jest #NodeJS #DevOps #Frontend\n\nTestcontainers at Docker. Developer, author, speaker. Java Champion\n\nFeeling productive at #kubecon with @kylepenfound. We just made a @dagger_io module to enable @Testcontainers tests easily.\n\nThe one and only @solomonstre, thanks for been so welcoming. Eternally grateful for everything you did. Go @dagger_io !!!!! At #KubeCon\n\nNow that I understand the tao of dagger, I never want to write another dockerfile. But I have too 😢\n\nI finally ported some @fluentci_io modules to @dagger_io Modules\n\nMLOps Tech Lead | Public speaker\n\nIt can take many \"git push\" to get your #cicd pipeline working.\n\nArne Mueller and I wrote an article about using Dagger, which you can use to run your pipelines locally and in your #cicd tool of choice:\n\n➡ We walk through a pipeline that does unit testing, Python package building, and Docker image build and push.\n\n➡ We show the implementation of the pipeline defined \"old style\" in GitHub actions, and explain how you can run it locally with act.\n\n➡ We compare it with implementation using Dagger & very minimalistic GitHub actions.\n\nNo more \"push and pray 🙏\" for your #DevOps and #MLOps engineers!\n\nCheck it out on Marvelous MLOps substack: https://lnkd.in/eNcrdCiX.\n\nToday we had @solomonstre at the Ubisoft office - to talk about @dagger_io of course, but also our challenges. And I think he might start prototyping something soon for one of our use cases... how many CEOs do that? ;-) It was great, come back when you want!\n\nAdvocate of better Platforms for Devs\n\nYeah @dagger_io killed it with writing CI pipelines as code, and being able to run that locally. I can’t think of how else you can get a similar experience except by writing a bunch of bash with Docker.\n\nThere are two ways to ship code: 1. Push and Pray 2. Test, Test, Test, Test We recommend option #2. And use @dagger_io to make your life easy.\n\nDon't you just love when getting-started examples in the docs work\n\nBeen spending some time playing with @NetBoxOfficial @go_containerlab and @dagger_io and its pretty amazing how much can be done in the network automation space in what feels like a very cloud native way at the moment. Hoping to package it all up for a demo real soon 🚀 🚀 🚀\n\nHead of OSS @openmeterio | Speaker, tech content creator\n\n@dagger_io community meeting at @fosdem with @sameoldaweris\n\n@dagger_io has replaced a combination of dockerfiles, docker-compose, and makefiles/bash scripts for me, making it easier to run CI tests locally and in GitHub actions. Great work @solomonstre!\n\nUnexpected surprise using @dagger_io Cloud... If you export your key from your local development environment, then all of your local build results are side-by-side with your CI build results. It's pretty great being able to recall why something failed locally and then share it\n\nI just wrote my 1st @dagger_io modules https://github.com/vbehar/daggerverse… and the experience is really nice, thanks to the Dagger CLI. Good job guys!\n\n@dr4goonis talking about stuff, @dagger_io, and CI/CD at @PHPUKConference\n\nCEO @Qovery_ - Internal Developer Platform ☁️ | Love to solve engineering problems | Rust 🦀, Kotlin, Go, Python, Java\n\nMy latest issue on why I believe @dagger_io could be the future of CI/CD for Engineering and Platform Engineering teams\n\nhttps://romaricphilogene.substack.com/p/platform-tips-18-dagger-the-future\n\n#platformengineering #cicd #devops #dagger\n\nI am very happy to share with you a great development today!! Dagger we have established our Istanbul Meetup group as of now! ☝️\n\nOne of Dagger Solomon Hykes' newest innovations is to develop a programmable CI/CD engine. 🤖\n\nDagger is a tool that allows you to develop your CI/CD processes with your favorite programming language that you use to develop your software, and to run your CI/CD steps in containers, eliminating remote engine dependency and advancing all your processes in your local environment. 🚀\n\nThe main purpose of this group will be to raise awareness about the Dagger project and to talk about the benefits of this tool for us, you are all invited! 👋\n\nhttps://lnkd.in/dMNjdBDP\n\n#dagger #daggercommunity #daggeristanbul\n\nIt's kind of a container-based swiss army knife that can be used for CI operations (reproducible builds, testing, publishing), creating LLM agents, and more. Tons of integrations and open-source modules on the \"Daggerverse\".\n\nWhen @solomonstre drops an open-source Claude Code... ya run with it. \"Toy Programmer\" + added MCP & cursor-rules + an updated version of @zbeyens phenom \"dotai\" repo\n\nThis is so awesome to play with. I just made a new frontend for my main demo repo without any hand-holding, writing integrations, or anything. Just core dagger + bring your own LLM. In a 2 minute video. Most of which is for the sake of the recording\n\nSo im finally coming around on this whole AI thing is the future...Solomon Hykes demo of an agent writing a curl clone in 5 minutes using Dagger is still lingering in my mind...if any of you are curmudgeons like me you might want to watch...\n\nIf you don’t know where to start to create AI agents, you should have a look at Dagger agents. That makes it so easy to build tools that will benefit from AI but as real developer tool.\n\nFew understand the implications of this. This will be absolutely defining\n\nI'm feeling a \"docker moment\" in real time. Even though I didn't know the CI tool, it seems so promising for multiple areas.\n\n@dagger_io experimental AI tooling is really interesting. I just leveraged two separate modules (Strava and Notify). It took me 20 minutes to build the prompt and less than 5 to write the code.\n\nThis is crazy cool! If you have worked with LLMs this is amazing!\n\nall your dagger functions are now available for agents to use. built-in function registry.\n\nThis is nuts. @dagger_io has always had amazing dev exp, but the fact that it lends itself so seamlessly to something like this is endlessly impressive, massive props @solomonstre and the team!\n\nOk, my mind is a little blown right now. I never considered having LLMs accept containers as inputs and then interact with them to accomplish some goal.\n\nThat's why tools like @dagger_io are going to be so powerful! (standardized text interface, multi-language modules and a neatly integrated web GUI over the CLI) Great AI assistant experiences largely depend on well-designed interfaces they can easily leverage.\n\nI think few realize where Dagger sits in the agentic race. I know I didn’t until I was shown. Incredible.\n\nIf you can relate, you need @dagger_io and fast.\n\nIt’ll take time for people to realize the value of @dagger_io but I’m optimistic it’ll reach critical mass and break the vendor locking that many CI providers benefited from for many years.\n\nI just tried to set up a CI pipeline using @dagger_io to compile and test an Elixir project and OMG. The portability is so priceless. Blog post in progress 😀​\n\nMy entire CI/CD pipeline is Dagger and I'd love for dev to be too; still a few changes that need to happen there though.\n\nCo-founder @gokoyeb , deploy apps and databases on high-performance infrastructure around the world. Previously built @scaleway\n\nExcited to hear @solomonstre talking about @dagger_io and Dagger functions. Need to push the @gokoyeb function to the Daggerverse\n\nOpen Source Effectively Accelerates !\n\nIt was great to participate @dagger_io Meetup yesterday, one of the purest form of OSS event: no bullshit, minimal slides, maximum code. @solomonstre might gave away his @KubeCon_ KN magic a bit\n\n🚀 My top pick video from hashtag#KubeCon + hashtag#cloudnative in Paris is out! From integrated environments to innovative approaches, there's something for every science community to keep an eye on. \n\nYOU get to choose what we dive into next! Comment with your preference! \n\nhttps://lnkd.in/d2Xj2DhJ\n\n1️⃣ First up, Kubeflow offers an all-in-one solution for data science workflows on Kubernetes. Check out CERN Computing's experience at the hashtag#cloudnativeAIDay event and the DHL Data & Analytics and their journey to a data science platform.\n\n2️⃣ Impressive NATS.io with a demo by Synadia perfect for applications from hashtag#ai / hashtag#ml on IoT to microservices\n\n3️⃣ Discover Dagger Functions, revolutionizing workflow management for reproducibility and interoperability\n\nPlus, an extra shoutout to the Cloud Native Computing Foundation (CNCF) Enduser Research, let's push it together as it should be!\n\nConseiller intégrateur en architecture logicielle (Cloud/DevOps) chez Ministère de la Famille du Québec (MFA)\n\nWhat I also like 👌 about Dagger is that it perfectly aligns with my personal fav quote: \n\n'Localhost is your best cloud provider’ 🔥🚀\n\nhttps://dagger.io\n\nWhat Is Dagger and Why You Might Want to Use It 🧵​\n\nDagger promises to fix our CI/CD once and for all, but what exactly is Dagger?\n\nIs it a GitHub Actions or Jenkins replacement? Or is it a dev tool that augments existing CI/CD providers? Is it a service or a CLI?\n\nJust finished an incredible hands-on session with Saiyam Pathak, Solomon Hykes, and Kyle Penfound on the Kubesimplify channel, diving deep into the powerful tool Dagger. Followed along on my personal computer and learned a ton. Highly recommend checking it out for anyone interested in cutting-edge DevOps! hashtag#Dagger hashtag#DevOps hashtag#Kubesimplify\n\nhttps://lnkd.in/dygitKgn\n\nSenior Software Engineer at Microsoft\n\nI always felt like tools like docker-compose were not the right fit me me. Always required lots of glue to make it work for the things I needed to do.\n\nThis is where @dagger_io shines. Far more programatic, testable, and repeatable.\n\nWe released a new version of our @dagger_io Daggerverse module to bring the Depot ephemeral registry to our bake function. Going to be a game changer for building all your images at once and being able to do things with the containers immediately\n\nhttps://depot.dev/changelog/2024-03-26-depot-daggerverse-1-1-0\n\nDevOps engineer at @rtCamp | loves writing code | Founder of @ksctl_k8s\n\nyou all got me. Taskfile and Makefile now its dagger @SaiyamPathak. 🙃​ Btw nice explanation on dagger. I think its a good tool, used it 1 year ago 😉​ @dagger_io\n\nNothing beats reading a story about Dagger from a real user. Thanks so much to Scott Molinari for sharing your experience :) \nhttps://lnkd.in/d9fQGRg7\n\nexpert at spline reticulation. ⚡ AWS Infinidash MVP ⚡ I ❤️ coding. Work as Senior Software Engineer.\n\nWrapping my head around the new functions thing is going to take a bit. But I've already done nested docker Goreleaser with CGO_ENABLED , angular builds and more with the SDK. So great! Dagger call might take over all my 3 years of mage work once I figure it all out.\n\nsr engineer @saucedopen 🥡 prev: AWS, VMware, Pivotal\n\n@sheldon_hull @dagger_io and @MagefileDotOrg We’re starting to adopt dagger actually loving it so far\n\nFormer Executive Director, OpenDaylight Project, founder VSPP/vCloud @VMware , launched Cilium/Isovalent out of stealth, now helping Solomon grow http://Dagger.io\n\nWhat a WILD morning! @solomonstre‘s keynote seems to have ignited something major, we’ve been swamped all morning here at @KubeCon_!\n\nDevOps. Security. Observability. Linux. Kubernetes. Sailing. ReveCom Media.\n\nUse @dagger_io to build pipelines input: @chainguard_dev's Building Container Images the Modern Way -\n\n@chainguard_dev' s Adrian Mouat demo. It « real strength » is its modules, he said.\n\n@KubeCon_ @linuxfoundation @thenewstack\n\nThe #Kubernetes & #cloudnative community conference\n\n“It’s all about the people.” - Solomon Hykes #kubecon #cloudnativecon\n\nDevRel/GTM Leader | News/Podcast @InfoQ | Web 2.0 coder, platform engineer, Java Champion, CS PhD | cloud/K8s, APIs, IPAs, running | learner/teacher\n\nAn enjoyable look back on the origins of @Docker, containers, and cloud platforms, via @solomonstre\n\nat #KubeCon. And love the call out to “dude, where’s my platform?” Many of us are still working on this with\n\n@dagger_io, @kratixio, #Backstage, and @CloudNativeFdn tech\n\nCNCF Ambassador | @kubernetesio 1.23 Release Lead, 1.25 Emeritus Adviser, K8s SIG Docs co-chair | 👨🏻‍💻 @RedHat\n\n#KubeCon Europe day 3 keynotes with @solomonstre from @dagger_io who helped kick off popularizing #containers and #CloudNative over a decade ago. 16 years ago, the first working build of Docker was created walking distance from #KubeCon Paris\n\nThe recording of my #kubecon keynote is out: https://youtu.be/S_Z4AHZlSUI Thank you to everyone who attended, on the last day of a draining event. It was a special moment that I enjoyed very much, I hope you did too. Non-french speakers: watch this after\n\nSr. Kubernetes Specialist SA @AWSCloud | CNCF Ambassador | Kubernetes contributor\n\nJoin me at the first @dagger_io meetup in Raleigh, NC this week. The meetup will start by teaching the basics of Dagger with real-world examples. I'm still in KubeCon mode, looking forward to meeting the DevOps community in person! Check out the event details at https://meetu.ps/e/MWc2l/3Fcx2/i\n\nMom. Software engineer. Author. Java Champion. Docker Captain. Dev Advocate @JFrog\n\nYeah... ok, there are much better foot models out there than me, but I had to show off the @dagger_io gear I brought with me from #KubeCon Chicago! Thanks for these @jpadamspdx - they were perfect for the long flight home after an incredible week at #KubeCon Paris!\n\n@solomonstre surrounded by people at #KubeCon\n\nI built my first Dagger function yesterday with Solomon Hykes, and just got it published up on the daggerverse!\n\nDagger is awesome, and I plan on continuing to find ways to use it. At a high level, dagger lets you use containers as a first-class object in code, and stitch together complex orchestration pipelines using real programming languages instead of bash.\n\nPrimitives like mounting in files/directories, running commands, building and publishing containers, environment variables and secrets are all available, type-safe, and programmable in Go, Python, or Typescript.\n\nDagger functions let you build abstractions and methods on top of these basic primitives that can then be exposed and reused by other Dagger functions. The entire experience is encapsulated by the `dagger` cli, which uses magical buildkit caching and orchestrations so it's all *fassstttt*. You can run it locally or in CI systems and get the same results, and confidence that things will actually work after a push.\n\nAs self-described a yamlbash enthusiast, I'm still excited at the thought of replacing those tangled messes with real code.\n\nCheck it out here, this version is capable of building Python wheel packages across a variety of Python versions, and can handle installation of extra build-time dependencies too, for when you need some ugly cmake stuff or other native libraries. Also, it uses wolfi and Chainguard images for all the execution and package handling :)\n\nhttps://lnkd.in/eDBtk7pm\n\n#dagger #ci #opensource #wolfi #chainguard\n\nChainloop is an Open Source Metadata Vault for your Software Supply Chain metadata, OWASP CycloneDX SBOM/xBOM Standard, SPDX SBOM, VEX, SARIF files, QA reports, and more.\n\nFrom today, you can programmatically collect and enforce Software Supply Chain pieces of evidence from your Dagger pipeline!\n\nDagger is a great fit since it is aligned with our principle of meeting developers where they are, and you can’t get closer to them than in code, with their programming language, and in their local machine 🙂\n\nIf you want to give it a try in person, we'll also be in a couple of days at #kubecon in Paris. See you there!\n\nI first saw a demo of Dagger two years ago and you could sense something big was brewing.\n\nNow with Dagger functions, it's actually happening. I just saw another demo and it really feels like something we'll all be using!\n\nCongrats Dagger for building something special!\n\nDagger is a programmable open source CI/CD engine. I built a Dagger module to solve the \"but it works on my machine\" problem that occurs where tests that pass locally do not pass in development because of inconsistencies in environment configurations for NodeJS applications. In this blog I detail the entire process; what I learnt through my build along with insights gained from reading Dagger docs and their Python SDK.\n\n#Python #CICD #Jest #NodeJS #DevOps #Frontend\n\nTestcontainers at Docker. Developer, author, speaker. Java Champion\n\nFeeling productive at #kubecon with @kylepenfound. We just made a @dagger_io module to enable @Testcontainers tests easily.\n\nThe one and only @solomonstre, thanks for been so welcoming. Eternally grateful for everything you did. Go @dagger_io !!!!! At #KubeCon\n\nNow that I understand the tao of dagger, I never want to write another dockerfile. But I have too 😢\n\nI finally ported some @fluentci_io modules to @dagger_io Modules\n\nMLOps Tech Lead | Public speaker\n\nIt can take many \"git push\" to get your #cicd pipeline working.\n\nArne Mueller and I wrote an article about using Dagger, which you can use to run your pipelines locally and in your #cicd tool of choice:\n\n➡ We walk through a pipeline that does unit testing, Python package building, and Docker image build and push.\n\n➡ We show the implementation of the pipeline defined \"old style\" in GitHub actions, and explain how you can run it locally with act.\n\n➡ We compare it with implementation using Dagger & very minimalistic GitHub actions.\n\nNo more \"push and pray 🙏\" for your #DevOps and #MLOps engineers!\n\nCheck it out on Marvelous MLOps substack: https://lnkd.in/eNcrdCiX.\n\nToday we had @solomonstre at the Ubisoft office - to talk about @dagger_io of course, but also our challenges. And I think he might start prototyping something soon for one of our use cases... how many CEOs do that? ;-) It was great, come back when you want!\n\nAdvocate of better Platforms for Devs\n\nYeah @dagger_io killed it with writing CI pipelines as code, and being able to run that locally. I can’t think of how else you can get a similar experience except by writing a bunch of bash with Docker.\n\nThere are two ways to ship code: 1. Push and Pray 2. Test, Test, Test, Test We recommend option #2. And use @dagger_io to make your life easy.\n\nDon't you just love when getting-started examples in the docs work\n\nBeen spending some time playing with @NetBoxOfficial @go_containerlab and @dagger_io and its pretty amazing how much can be done in the network automation space in what feels like a very cloud native way at the moment. Hoping to package it all up for a demo real soon 🚀 🚀 🚀\n\nHead of OSS @openmeterio | Speaker, tech content creator\n\n@dagger_io community meeting at @fosdem with @sameoldaweris\n\n@dagger_io has replaced a combination of dockerfiles, docker-compose, and makefiles/bash scripts for me, making it easier to run CI tests locally and in GitHub actions. Great work @solomonstre!\n\nUnexpected surprise using @dagger_io Cloud... If you export your key from your local development environment, then all of your local build results are side-by-side with your CI build results. It's pretty great being able to recall why something failed locally and then share it\n\nI just wrote my 1st @dagger_io modules https://github.com/vbehar/daggerverse… and the experience is really nice, thanks to the Dagger CLI. Good job guys!\n\n@dr4goonis talking about stuff, @dagger_io, and CI/CD at @PHPUKConference\n\nCEO @Qovery_ - Internal Developer Platform ☁️ | Love to solve engineering problems | Rust 🦀, Kotlin, Go, Python, Java\n\nMy latest issue on why I believe @dagger_io could be the future of CI/CD for Engineering and Platform Engineering teams\n\nhttps://romaricphilogene.substack.com/p/platform-tips-18-dagger-the-future\n\n#platformengineering #cicd #devops #dagger\n\nI am very happy to share with you a great development today!! Dagger we have established our Istanbul Meetup group as of now! ☝️\n\nOne of Dagger Solomon Hykes' newest innovations is to develop a programmable CI/CD engine. 🤖\n\nDagger is a tool that allows you to develop your CI/CD processes with your favorite programming language that you use to develop your software, and to run your CI/CD steps in containers, eliminating remote engine dependency and advancing all your processes in your local environment. 🚀\n\nThe main purpose of this group will be to raise awareness about the Dagger project and to talk about the benefits of this tool for us, you are all invited! 👋\n\nhttps://lnkd.in/dMNjdBDP\n\n#dagger #daggercommunity #daggeristanbul\n\nIt's kind of a container-based swiss army knife that can be used for CI operations (reproducible builds, testing, publishing), creating LLM agents, and more. Tons of integrations and open-source modules on the \"Daggerverse\".\n\nWhen @solomonstre drops an open-source Claude Code... ya run with it. \"Toy Programmer\" + added MCP & cursor-rules + an updated version of @zbeyens phenom \"dotai\" repo\n\nThis is so awesome to play with. I just made a new frontend for my main demo repo without any hand-holding, writing integrations, or anything. Just core dagger + bring your own LLM. In a 2 minute video. Most of which is for the sake of the recording\n\nSo im finally coming around on this whole AI thing is the future...Solomon Hykes demo of an agent writing a curl clone in 5 minutes using Dagger is still lingering in my mind...if any of you are curmudgeons like me you might want to watch...\n\nIf you don’t know where to start to create AI agents, you should have a look at Dagger agents. That makes it so easy to build tools that will benefit from AI but as real developer tool.\n\nFew understand the implications of this. This will be absolutely defining\n\nI'm feeling a \"docker moment\" in real time. Even though I didn't know the CI tool, it seems so promising for multiple areas.\n\n@dagger_io experimental AI tooling is really interesting. I just leveraged two separate modules (Strava and Notify). It took me 20 minutes to build the prompt and less than 5 to write the code.\n\nThis is crazy cool! If you have worked with LLMs this is amazing!\n\nall your dagger functions are now available for agents to use. built-in function registry.\n\nThis is nuts. @dagger_io has always had amazing dev exp, but the fact that it lends itself so seamlessly to something like this is endlessly impressive, massive props @solomonstre and the team!\n\nOk, my mind is a little blown right now. I never considered having LLMs accept containers as inputs and then interact with them to accomplish some goal.\n\nThat's why tools like @dagger_io are going to be so powerful! (standardized text interface, multi-language modules and a neatly integrated web GUI over the CLI) Great AI assistant experiences largely depend on well-designed interfaces they can easily leverage.\n\nI think few realize where Dagger sits in the agentic race. I know I didn’t until I was shown. Incredible.\n\nIf you can relate, you need @dagger_io and fast.\n\nIt’ll take time for people to realize the value of @dagger_io but I’m optimistic it’ll reach critical mass and break the vendor locking that many CI providers benefited from for many years.\n\nI just tried to set up a CI pipeline using @dagger_io to compile and test an Elixir project and OMG. The portability is so priceless. Blog post in progress 😀​\n\nMy entire CI/CD pipeline is Dagger and I'd love for dev to be too; still a few changes that need to happen there though.\n\nCo-founder @gokoyeb , deploy apps and databases on high-performance infrastructure around the world. Previously built @scaleway\n\nExcited to hear @solomonstre talking about @dagger_io and Dagger functions. Need to push the @gokoyeb function to the Daggerverse\n\nOpen Source Effectively Accelerates !\n\nIt was great to participate @dagger_io Meetup yesterday, one of the purest form of OSS event: no bullshit, minimal slides, maximum code. @solomonstre might gave away his @KubeCon_ KN magic a bit\n\n🚀 My top pick video from hashtag#KubeCon + hashtag#cloudnative in Paris is out! From integrated environments to innovative approaches, there's something for every science community to keep an eye on. \n\nYOU get to choose what we dive into next! Comment with your preference! \n\nhttps://lnkd.in/d2Xj2DhJ\n\n1️⃣ First up, Kubeflow offers an all-in-one solution for data science workflows on Kubernetes. Check out CERN Computing's experience at the hashtag#cloudnativeAIDay event and the DHL Data & Analytics and their journey to a data science platform.\n\n2️⃣ Impressive NATS.io with a demo by Synadia perfect for applications from hashtag#ai / hashtag#ml on IoT to microservices\n\n3️⃣ Discover Dagger Functions, revolutionizing workflow management for reproducibility and interoperability\n\nPlus, an extra shoutout to the Cloud Native Computing Foundation (CNCF) Enduser Research, let's push it together as it should be!\n\nConseiller intégrateur en architecture logicielle (Cloud/DevOps) chez Ministère de la Famille du Québec (MFA)\n\nWhat I also like 👌 about Dagger is that it perfectly aligns with my personal fav quote: \n\n'Localhost is your best cloud provider’ 🔥🚀\n\nhttps://dagger.io\n\nWhat Is Dagger and Why You Might Want to Use It 🧵​\n\nDagger promises to fix our CI/CD once and for all, but what exactly is Dagger?\n\nIs it a GitHub Actions or Jenkins replacement? Or is it a dev tool that augments existing CI/CD providers? Is it a service or a CLI?\n\nJust finished an incredible hands-on session with Saiyam Pathak, Solomon Hykes, and Kyle Penfound on the Kubesimplify channel, diving deep into the powerful tool Dagger. Followed along on my personal computer and learned a ton. Highly recommend checking it out for anyone interested in cutting-edge DevOps! hashtag#Dagger hashtag#DevOps hashtag#Kubesimplify\n\nhttps://lnkd.in/dygitKgn\n\nSenior Software Engineer at Microsoft\n\nI always felt like tools like docker-compose were not the right fit me me. Always required lots of glue to make it work for the things I needed to do.\n\nThis is where @dagger_io shines. Far more programatic, testable, and repeatable.\n\nWe released a new version of our @dagger_io Daggerverse module to bring the Depot ephemeral registry to our bake function. Going to be a game changer for building all your images at once and being able to do things with the containers immediately\n\nhttps://depot.dev/changelog/2024-03-26-depot-daggerverse-1-1-0\n\nDevOps engineer at @rtCamp | loves writing code | Founder of @ksctl_k8s\n\nyou all got me. Taskfile and Makefile now its dagger @SaiyamPathak. 🙃​ Btw nice explanation on dagger. I think its a good tool, used it 1 year ago 😉​ @dagger_io\n\nNothing beats reading a story about Dagger from a real user. Thanks so much to Scott Molinari for sharing your experience :) \nhttps://lnkd.in/d9fQGRg7\n\nexpert at spline reticulation. ⚡ AWS Infinidash MVP ⚡ I ❤️ coding. Work as Senior Software Engineer.\n\nWrapping my head around the new functions thing is going to take a bit. But I've already done nested docker Goreleaser with CGO_ENABLED , angular builds and more with the SDK. So great! Dagger call might take over all my 3 years of mage work once I figure it all out.\n\nsr engineer @saucedopen 🥡 prev: AWS, VMware, Pivotal\n\n@sheldon_hull @dagger_io and @MagefileDotOrg We’re starting to adopt dagger actually loving it so far\n\nFormer Executive Director, OpenDaylight Project, founder VSPP/vCloud @VMware , launched Cilium/Isovalent out of stealth, now helping Solomon grow http://Dagger.io\n\nWhat a WILD morning! @solomonstre‘s keynote seems to have ignited something major, we’ve been swamped all morning here at @KubeCon_!\n\nDevOps. Security. Observability. Linux. Kubernetes. Sailing. ReveCom Media.\n\nUse @dagger_io to build pipelines input: @chainguard_dev's Building Container Images the Modern Way -\n\n@chainguard_dev' s Adrian Mouat demo. It « real strength » is its modules, he said.\n\n@KubeCon_ @linuxfoundation @thenewstack\n\nThe #Kubernetes & #cloudnative community conference\n\n“It’s all about the people.” - Solomon Hykes #kubecon #cloudnativecon\n\nDevRel/GTM Leader | News/Podcast @InfoQ | Web 2.0 coder, platform engineer, Java Champion, CS PhD | cloud/K8s, APIs, IPAs, running | learner/teacher\n\nAn enjoyable look back on the origins of @Docker, containers, and cloud platforms, via @solomonstre\n\nat #KubeCon. And love the call out to “dude, where’s my platform?” Many of us are still working on this with\n\n@dagger_io, @kratixio, #Backstage, and @CloudNativeFdn tech\n\nCNCF Ambassador | @kubernetesio 1.23 Release Lead, 1.25 Emeritus Adviser, K8s SIG Docs co-chair | 👨🏻‍💻 @RedHat\n\n#KubeCon Europe day 3 keynotes with @solomonstre from @dagger_io who helped kick off popularizing #containers and #CloudNative over a decade ago. 16 years ago, the first working build of Docker was created walking distance from #KubeCon Paris\n\nThe recording of my #kubecon keynote is out: https://youtu.be/S_Z4AHZlSUI Thank you to everyone who attended, on the last day of a draining event. It was a special moment that I enjoyed very much, I hope you did too. Non-french speakers: watch this after\n\nSr. Kubernetes Specialist SA @AWSCloud | CNCF Ambassador | Kubernetes contributor\n\nJoin me at the first @dagger_io meetup in Raleigh, NC this week. The meetup will start by teaching the basics of Dagger with real-world examples. I'm still in KubeCon mode, looking forward to meeting the DevOps community in person! Check out the event details at https://meetu.ps/e/MWc2l/3Fcx2/i\n\nMom. Software engineer. Author. Java Champion. Docker Captain. Dev Advocate @JFrog\n\nYeah... ok, there are much better foot models out there than me, but I had to show off the @dagger_io gear I brought with me from #KubeCon Chicago! Thanks for these @jpadamspdx - they were perfect for the long flight home after an incredible week at #KubeCon Paris!\n\n@solomonstre surrounded by people at #KubeCon\n\nI built my first Dagger function yesterday with Solomon Hykes, and just got it published up on the daggerverse!\n\nDagger is awesome, and I plan on continuing to find ways to use it. At a high level, dagger lets you use containers as a first-class object in code, and stitch together complex orchestration pipelines using real programming languages instead of bash.\n\nPrimitives like mounting in files/directories, running commands, building and publishing containers, environment variables and secrets are all available, type-safe, and programmable in Go, Python, or Typescript.\n\nDagger functions let you build abstractions and methods on top of these basic primitives that can then be exposed and reused by other Dagger functions. The entire experience is encapsulated by the `dagger` cli, which uses magical buildkit caching and orchestrations so it's all *fassstttt*. You can run it locally or in CI systems and get the same results, and confidence that things will actually work after a push.\n\nAs self-described a yamlbash enthusiast, I'm still excited at the thought of replacing those tangled messes with real code.\n\nCheck it out here, this version is capable of building Python wheel packages across a variety of Python versions, and can handle installation of extra build-time dependencies too, for when you need some ugly cmake stuff or other native libraries. Also, it uses wolfi and Chainguard images for all the execution and package handling :)\n\nhttps://lnkd.in/eDBtk7pm\n\n#dagger #ci #opensource #wolfi #chainguard\n\nChainloop is an Open Source Metadata Vault for your Software Supply Chain metadata, OWASP CycloneDX SBOM/xBOM Standard, SPDX SBOM, VEX, SARIF files, QA reports, and more.\n\nFrom today, you can programmatically collect and enforce Software Supply Chain pieces of evidence from your Dagger pipeline!\n\nDagger is a great fit since it is aligned with our principle of meeting developers where they are, and you can’t get closer to them than in code, with their programming language, and in their local machine 🙂\n\nIf you want to give it a try in person, we'll also be in a couple of days at #kubecon in Paris. See you there!\n\nI first saw a demo of Dagger two years ago and you could sense something big was brewing.\n\nNow with Dagger functions, it's actually happening. I just saw another demo and it really feels like something we'll all be using!\n\nCongrats Dagger for building something special!\n\nDagger is a programmable open source CI/CD engine. I built a Dagger module to solve the \"but it works on my machine\" problem that occurs where tests that pass locally do not pass in development because of inconsistencies in environment configurations for NodeJS applications. In this blog I detail the entire process; what I learnt through my build along with insights gained from reading Dagger docs and their Python SDK.\n\n#Python #CICD #Jest #NodeJS #DevOps #Frontend\n\nTestcontainers at Docker. Developer, author, speaker. Java Champion\n\nFeeling productive at #kubecon with @kylepenfound. We just made a @dagger_io module to enable @Testcontainers tests easily.\n\nThe one and only @solomonstre, thanks for been so welcoming. Eternally grateful for everything you did. Go @dagger_io !!!!! At #KubeCon\n\nNow that I understand the tao of dagger, I never want to write another dockerfile. But I have too 😢\n\nI finally ported some @fluentci_io modules to @dagger_io Modules\n\nMLOps Tech Lead | Public speaker\n\nIt can take many \"git push\" to get your #cicd pipeline working.\n\nArne Mueller and I wrote an article about using Dagger, which you can use to run your pipelines locally and in your #cicd tool of choice:\n\n➡ We walk through a pipeline that does unit testing, Python package building, and Docker image build and push.\n\n➡ We show the implementation of the pipeline defined \"old style\" in GitHub actions, and explain how you can run it locally with act.\n\n➡ We compare it with implementation using Dagger & very minimalistic GitHub actions.\n\nNo more \"push and pray 🙏\" for your #DevOps and #MLOps engineers!\n\nCheck it out on Marvelous MLOps substack: https://lnkd.in/eNcrdCiX.\n\nToday we had @solomonstre at the Ubisoft office - to talk about @dagger_io of course, but also our challenges. And I think he might start prototyping something soon for one of our use cases... how many CEOs do that? ;-) It was great, come back when you want!\n\nAdvocate of better Platforms for Devs\n\nYeah @dagger_io killed it with writing CI pipelines as code, and being able to run that locally. I can’t think of how else you can get a similar experience except by writing a bunch of bash with Docker.\n\nThere are two ways to ship code: 1. Push and Pray 2. Test, Test, Test, Test We recommend option #2. And use @dagger_io to make your life easy.\n\nDon't you just love when getting-started examples in the docs work\n\nBeen spending some time playing with @NetBoxOfficial @go_containerlab and @dagger_io and its pretty amazing how much can be done in the network automation space in what feels like a very cloud native way at the moment. Hoping to package it all up for a demo real soon 🚀 🚀 🚀\n\nHead of OSS @openmeterio | Speaker, tech content creator\n\n@dagger_io community meeting at @fosdem with @sameoldaweris\n\n@dagger_io has replaced a combination of dockerfiles, docker-compose, and makefiles/bash scripts for me, making it easier to run CI tests locally and in GitHub actions. Great work @solomonstre!\n\nUnexpected surprise using @dagger_io Cloud... If you export your key from your local development environment, then all of your local build results are side-by-side with your CI build results. It's pretty great being able to recall why something failed locally and then share it\n\nI just wrote my 1st @dagger_io modules https://github.com/vbehar/daggerverse… and the experience is really nice, thanks to the Dagger CLI. Good job guys!\n\n@dr4goonis talking about stuff, @dagger_io, and CI/CD at @PHPUKConference\n\nCEO @Qovery_ - Internal Developer Platform ☁️ | Love to solve engineering problems | Rust 🦀, Kotlin, Go, Python, Java\n\nMy latest issue on why I believe @dagger_io could be the future of CI/CD for Engineering and Platform Engineering teams\n\nhttps://romaricphilogene.substack.com/p/platform-tips-18-dagger-the-future\n\n#platformengineering #cicd #devops #dagger\n\nI am very happy to share with you a great development today!! Dagger we have established our Istanbul Meetup group as of now! ☝️\n\nOne of Dagger Solomon Hykes' newest innovations is to develop a programmable CI/CD engine. 🤖\n\nDagger is a tool that allows you to develop your CI/CD processes with your favorite programming language that you use to develop your software, and to run your CI/CD steps in containers, eliminating remote engine dependency and advancing all your processes in your local environment. 🚀\n\nThe main purpose of this group will be to raise awareness about the Dagger project and to talk about the benefits of this tool for us, you are all invited! 👋\n\nhttps://lnkd.in/dMNjdBDP\n\n#dagger #daggercommunity #daggeristanbul",
    "readingTime": 45,
    "keywords": [
      "dagger",
      "your",
      "kubecon",
      "agent",
      "https",
      "solomonstre",
      "build",
      "docker",
      "code",
      "about"
    ],
    "qualityScore": 1,
    "link": "https://dagger.io/",
    "thumbnail_url": "https://framerusercontent.com/images/pROtRtVdoQO1rOD3BKsss5eN2nA.png",
    "created_at": "2025-12-09T08:42:56.880Z",
    "topic": "tech"
  },
  {
    "slug": "is-scaled-agile-the-problem-or-are-we-implementing-it-wrong",
    "title": "Is Scaled Agile the Problem, or Are We Implementing It Wrong?",
    "description": "AgileGlow operationalizes Continuous Improvement for Agile Release Trains with AI powered WSJF prioritization, root cause analysis and predicted ROI, guiding every idea through a structured workflow into clear, outcome oriented improvements.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://agileglow.io/",
    "thumbnail_url": "https://qtrypzzcjebvfcihiynt.supabase.co/storage/v1/object/public/base44-prod/public/68f60e6a4daf34688810ff59/5f4d04429_AgileGlow.png",
    "created_at": "2025-12-09T08:42:56.769Z",
    "topic": "tech"
  },
  {
    "slug": "dechecker-detect-aigenerated-text",
    "title": "DeChecker – Detect AI-generated text",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Dechecker instantly detects AI-generated content from models like ChatGPT, GPT-5, Claude, and Gemini 3.0.\nMake your writing 3x more original, 2x more readable, and ensure every piece of content is trustworthy and human-like.\n\nType or paste your text to check.\n\nIn just four simple steps, you can check if your text is AI-generated and transform it into original, human-like content.\n\nInsert your essay, article, blog, or business copy into Dechecker's AI Checker Tool.\n\nAI Checker analyzes your writing and highlights AI-generated patterns, supporting detection for ChatGPT, GPT-5, Claude, and Gemini.\n\nSee the detection score and detailed analysis, showing which parts are likely AI-generated.\n\nGet rewriting suggestions to improve originality, enhance readability, and make your text sound more human.\n\nDechecker's AI Checker helps you detect AI-generated content, enhance originality, and deliver writing that is clear, credible, and human-like.\n\nInstantly detect if your text is AI-generated. Dechecker's AI Checker gives you confidence in the authenticity of your work.\n\nUse the AI Checker to refine repetitive or generic AI writing into unique text that stands out in essays, articles, and business documents.\n\nTransforms robotic phrasing into smooth, natural language, making your writing easier to read and more persuasive.\n\nPublish content verified by the AI Checker that feels authentic, helping you earn credibility with readers, clients, and audiences.\n\nDechecker's AI Checker helps you identify AI-generated text, improve originality, and make your writing natural and credible. Perfect for students, marketers, business professionals, and content creators.\n\nDetect AI-written passages in essays or research papers, ensuring your work maintains authenticity and meets academic integrity standards.\n\nIdentify AI-generated sections in marketing content or blogs, and refine them to improve readability, originality, and search engine performance.\n\nEnsure proposals, presentations, and internal reports are human-like and trustworthy. The AI Checker highlights automated or robotic phrasing for easier revision.\n\nAnalyze content for AI-generated elements in tweets, captions, or posts. Enhance engagement with authentic, natural-sounding messages.\n\nVerify content before delivery to clients, ensuring originality and quality. Use the AI Checker to maintain credibility and reduce risk of AI-generated mistakes.\n\nDetect AI-written content in teaching or training materials, helping educators provide clear, human-written guidance while maintaining learning standards.\n\nThousands of users rely on Dechecker to identify AI-generated text, enhance originality, and improve writing quality.\n\n\"I was unsure if my essay contained AI-generated sentences, but Dechecker's AI Checker pinpointed the exact parts and suggested improvements. My paper feels completely original now!\"\n\n\"Using Dechecker on our blog posts saved us so much time. It highlighted AI-like phrasing and helped rewrite content that now reads completely natural. Highly recommend it!\"\n\n\"As a student, I needed to ensure my assignments were truly my own work. Dechecker's AI Checker made it easy to check for AI-generated content and improve readability. A must-have tool!\"\n\nHave questions about how Dechecker AI Checker works? Here are the answers to the most common queries to help you detect, analyze, and optimize your AI-generated content efficiently.",
    "readingTime": 3,
    "keywords": [
      "generated",
      "content",
      "your",
      "checker",
      "dechecker",
      "writing",
      "text",
      "human",
      "originality",
      "improve"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-09T08:42:55.714Z",
    "topic": "tech"
  },
  {
    "slug": "the-rise-of-ai-and-why-its-freaking-me-out",
    "title": "The rise of AI and why it's freaking me out",
    "description": "AI has been another thing that I have been thinking about over and over again without articulating or sharing anything substancial yet. Until another fellow photographer, that a while ago started an AI account to share Midjourney and other software generated art, shared following images:",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://paeulini.com/so/20PhQi9nY",
    "thumbnail_url": "https://static.wixstatic.com/media/fe4e51_b8ab83614a9d4b3ea3f6248c48208dfa~mv2.jpg/v1/fit/w_700,h_2000,al_c,q_85/image.jpg",
    "created_at": "2025-12-09T08:42:55.652Z",
    "topic": "tech"
  },
  {
    "slug": "rewriting-our-documentation-using-coding-agents",
    "title": "Rewriting our documentation using Coding Agents",
    "description": "How do you use AI to write documentation without falling into the AI slop trap? We rebuilt our docs site using Rover and Claude, and here's what we learned.",
    "fullText": "As you probably know, Endor is the developer of the Rover coding agent manager. We use it extensively for our day to day programming. This past week, we did something new, non-coding related. We rebuilt our documentation site using Rover, Claude and our new tech-writer workflow.\n\nWe could tell you that we asked Rover and Claude to do all the work and the result was amazing right away. After all, our projects help you manage AI agents. However, that’s far from reality. Though we used Rover heavily, and was of great help, we still spent a significant amount of time writing documentation for our users.\n\nThis article describes the process we followed and what we learned from it. You can check out the final result at docs.endor.dev/rover/overview.\n\nWe’re living in an era of AI-generated fatigue. A wave of low-quality content also known as AI slop. New models keep improving, making it harder to distinguish between AI generated and human-written content. As a result, it’s tempting to generate an entire documentation site with AI because, unfortunately, writing documentation is not a task that many people enjoy.\n\nBut give it a little time and people start noticing patterns in how these models write certain type of content. Have you seen a myriad of README.md files with multiple titles and emojis? You only need to search for ”🚀 Quick Start” and ”✨ Key Features” in GitHub.\n\nOnce developers get used to these patterns, they tend to stop paying attention. Those documents are perfect for LLMs, but not for users. Good documentation needs a clear purpose, thoughtful structure, and an understanding of who it’s being written for.\n\nDocumentation is always written for somebody and to answer their question - not the curiosity of the writer\n\nSo, how did we build our documentation site using AI?\n\nWe split our process in 3 main steps:\n\nThe first step is straightforward: you’re creating documentation for your users, so involving them is essential to understand what matters to them and what’s missing. You don’t always need to ask them explicitly, but you can infer it from recurring questions, common pain points, or issues raised in your repository.\n\nFor example, we discovered that many people are not familiar with git worktrees. Describing a Rover workspace in terms of worktrees wasn’t helpful. Instead, we needed to explain the core idea first, and then mention that Rover uses Git worktrees under the hood to create isolated copies of your project where agents apply changes.\n\nOnce you’ve collected feedback, it’s time to shape it into an appropriate structure. The goal of good documentation is to guide new users through your project, and provide deeper, more detailed information for advanced ones.\n\nThere are plenty of great examples out there. Some documentation sites in the AI space that we particularly like are:\n\nOur key takeaways when designing the structure are:\n\nWe didn’t involve an AI agent until this point. Now that we have all the information and a solid structure, it’s time to create some tasks for our agents! With Rover, you can parallelize these tasks with a single command.\n\nIn our case, we asked it to build several documentation pages using the new tech-writer workflow.\n\nYou can find the generated documentation in pages like:\n\nUsing the tech-writer workflow gave us pretty consistent results across all these pages. We still needed to make some final tweaks, but about 95% of the work was done by Rover and the coding agents behind it.\n\nFor example, this is the task description we used to generate the Configuration page:\n\nCoding agents were extremely helpful. Using them, we rebuilt our documentation in two days. Without them, it would’ve taken us a week. But we still wrote key pages, such as Overview, Task, and Workflow entirely by hand.\n\nThose pages matter. They shape a user’s first impression of Rover. And while AI is great at generating grammatically correct text, it doesn’t naturally produce the intent, structure, and story that those pages need.\n\nOur advice: write the important parts yourself. Then let coding agents help polish, expand, and maintain them. AI can save you time, but it can’t replace your understanding of your users. In the end, that’s the point: AI doesn’t replace thoughtful documentation, it amplifies it.\n\nCheck out Rover on GitHub and the documentation to get started",
    "readingTime": 4,
    "keywords": [
      "documentation",
      "rover",
      "agents",
      "your",
      "them",
      "pages",
      "coding",
      "using",
      "users",
      "structure"
    ],
    "qualityScore": 1,
    "link": "https://endor.dev/blog/rebuilding-our-docs",
    "thumbnail_url": "https://endor.dev/images/blog/rebuilding-our-docs/og.webp",
    "created_at": "2025-12-09T08:42:55.543Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-sends-harsh-message-to-millions-of-microsoft-365-c",
    "title": "Microsoft sends harsh message to millions of Microsoft 365 customers",
    "description": "Microsoft's stock experienced volatility after some AI sellers made a headline-grabbing claim that the company failed to meet its aggressive goals and, as a result, reset growth targets. Microsoft says the story went too far. It has thus far maintained its double-digit gains this year, but any ...",
    "fullText": "Microsoft's stock experienced volatility after some AI sellers made a headline-grabbing claim that the company failed to meet its aggressive goals and, as a result, reset growth targets.\n\nMicrosoft says the story went too far. It has thus far maintained its double-digit gains this year, but any disruption in its AI narrative could result in significant declines.\n\nOn a separate but equally important note for investors, it provided dates and amounts for a significant Microsoft 365 price hike that will begin generating revenue in the middle of 2026.\n\nIf you're keeping score at home, there is a lot of discussion about \"AI quotas\" in the short term and a lot of clarification about ARPU in the medium term. That tension is what MSFT is set up for at the end of the year.\n\nMorgan Stanley's 2025 CIO survey report explains, according to Barron's.\n\nNo one can dispute this. However, it appears that there may be certain areas where a snag could occur, potentially derailing Microsoft's AI ambitions.\n\nSeveral Microsoft sales teams missed aggressive growth goals for Azure Foundry and agentic AI, resulting in resets, according to a report from The Information. The stock price swung due to the speculation.\n\nMicrosoft responded by asserting that it had not reduced aggregate quotas. This information is crucial for investors who are monitoring demand signals.\n\nThe bigger picture: \"Agents\" in the early cycle need data plumbing, governance, and change management. Even when budgets are in excellent shape, sales cycles are often longer.\n\nMicrosoft released official information saying that the list prices for Microsoft 365 commercial products will go up on July 1, 2026. The same day, Microsoft 365 Government will also get an update. That's not just a guess; it's from the company.\n\nThe new grid that many customers are interested in: Business Basic costs $7 per user per month; Business Standard costs $14; Frontline F1 costs $3, and F3 costs $10; Enterprise E3 costs $39, and E5 costs $60.\n\nMicrosoft linked the lift to more than 1,100 new features, security updates, and built-in AI.\n\nEffective date: July 1, 2026, for commercial and government suites.\n\nSmall-business and frontline tiers: Steeper percentage increases than enterprise tiers.\n\nRationale: Expanded security and management features, plus AI capabilities.\n\nBusiness Basic: $7 per user per month\n\nHere's why the price change is more important than short-term volatility in shares:\n\nMicrosoft Cloud made $49.1 billion in the first quarter of fiscal year 2026, which was a 26% increase from the same time last year.\n\nRemaining performance obligation for businesses: $392 billion, a 51% increase.\n\nSegments: Microsoft 365 continued to help Productivity and Business Processes; Azure's Intelligent Cloud helped; Windows and search helped More Personal Computing.\n\nThe board announced a quarterly dividend of 91 cents per share, which will be paid on March 12, 2026.\n\nIt's line-of-sight ARPU, so call it that — a broad price increase that has been in place for a while and is now starting to show up for many customers as fiscal 2027 begins.\n\nIn the near future, there will be more news stories about the problems that come with using AI.\n\nAll sellers of \"agents\" are having trouble proving their worth. That's normal for workflow resets, not a drop in demand.\n\nIs Nvidia’s AI boom already priced in? Oppenheimer doesn’t think so\n\nWindows president told ‘Stop this nonsense. No one wants this’\n\nMichael Burry turns up heat on anti-AI bet\n\nIn the medium term, integrating Copilot into existing Microsoft 365 seats should be a more efficient way to generate revenue than building new agents from scratch.\n\nThe updated Microsoft 365 projections provide investors with a clearer picture of their potential returns through mid-2026 and fiscal 2027, regardless of the pace of agentic AI adoption.\n\nPenetration of Copilot across the Microsoft 365 user base, which is measured as paid seats relative to active seats.\n\nAzure AI usage (workload and usage mix).\n\nBefore the price increase in July 2026, renewal behavior may include locking in partner rates to maintain low rates.\n\nThe quota flap makes it clear that agentic AI is not a switch but a multi-quarter adoption curve. But Microsoft gave monetization a deadline that most consumers can't ignore.\n\nThat's the harsh fact behind the 2026 price change, and it's the portion of the model that doesn't rely on every AI pilot becoming a hero deployment on time.",
    "readingTime": 4,
    "keywords": [
      "microsoft",
      "price",
      "costs",
      "business",
      "term",
      "increase",
      "investors",
      "about",
      "azure",
      "agentic"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-sends-harsh-message-millions-020300869.html",
    "thumbnail_url": "https://media.zenfs.com/en/thestreet_881/89c2e64db162d681a6376d9266667d1a",
    "created_at": "2025-12-09T08:42:49.417Z",
    "topic": "finance"
  },
  {
    "slug": "exclusive-glean-hits-200-million-arr-up-from-100-million-nin",
    "title": "Exclusive: Glean hits $200 million ARR, up from $100 million nine months back",
    "description": "Glean, an enterprise AI unicorn, has hit $200 million in annual recurring revenue, CEO Arvind Jain said at Fortune's Brainstorm AI conference.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/08/exclusive-glean-hits-200-million-arr-up-from-100-million-nine-months-back/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972809480_e3e605da65_o-e1765242414214.jpg?resize=1200,600",
    "created_at": "2025-12-09T08:42:48.809Z",
    "topic": "business"
  },
  {
    "slug": "google-cloud-ceo-lays-out-3part-strategy-to-meet-ais-energy",
    "title": "Google Cloud CEO lays out 3-part strategy to meet AI’s energy demands after identifying it as the ‘most problematic thing’",
    "description": "Speaking at the Fortune Brainstorm AI conference, Google Cloud boss Thomas Kurian discussed how the company thinks about energy and data centers.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/08/google-cloud-ai-energy-demands-strategy-data-center-electricity/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972707933_643da41260_o-e1765241589857.jpg?resize=1200,600",
    "created_at": "2025-12-09T08:42:48.792Z",
    "topic": "business"
  },
  {
    "slug": "borrowing-by-ai-companies-represents-a-mounting-potential-th",
    "title": "Borrowing by AI companies represents a ‘mounting potential threat to the financial system,’ top economist says",
    "description": "“Borrowing by AI companies should be on the radar screen as a mounting potential threat to the financial system and broader economy.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/ai-debt-bond-issuance-potential-threat-financial-system-top-economist-investment/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1252638873-e1765236468608.jpg?resize=1200,600",
    "created_at": "2025-12-09T08:42:48.532Z",
    "topic": "business"
  },
  {
    "slug": "jamie-dimon-on-our-ai-future-fewer-jobs-and-working-less-har",
    "title": "Jamie Dimon on our AI future: fewer jobs and 'working less hard, but having wonderful lives'",
    "description": "Jamie Dimon says AI will cut jobs before delivering big benefits, including a future where people work \"less hard\" and enjoy \"wonderful lives.\"",
    "fullText": "Jamie Dimon said AI could one day help us work less, but not before it cuts jobs.\n\nThe JPMorgan CEO said in an interview with Fox News' \"Sunday Morning Futures\" that AI could improve society, comparing it to past technological leaps that lifted productivity and living standards.\n\n\"Maybe one day we'll be working less hard, but having wonderful lives,\" he said.\n\nBut getting there won't be painless. While AI will not \"dramatically reduce\" jobs in the next year, \"it will eliminate jobs,\" Dimon said.\n\n\"It doesn't mean people won't have other jobs,\" he said, adding that workers should lean into critical thinking, communication, and emotional intelligence.\n\nThe real danger, he said, is that AI adoption could outpace society's ability to train workers.\n\n\"If it does happen too fast for society, which is possible, we can't assimilate all those people that quickly,\" Dimon said.\n\nGovernment, companies, and society \"should look at how do we phase it in a way that we don't damage a lot of people,\" he added.\n\nDimon has been optimistic about the long-term potential of AI. Last month, he said AI would shrink the workweek.\n\n\"My guess is the developed world will be working three and a half days a week in 20, 30, 40 years,\" Dimon said in November at the America Business Forum in Miami.\n\n\"You're going to have agents that do research for you every time you wake up in the morning,\" he added.\n\nDimon hasn't downplayed the risks, either. At a Fortune-hosted conference last month, he warned that job elimination is inevitable. \"People should stop sticking their heads in the sand,\" he said.\n\nOther big bank CEOs have also said that AI has long-term benefits, but they highlighted the disruption ahead.\n\nGoldman Sachs CEO David Solomon said in an interview on CNBC's \"Squawk Box\" in October that AI will lead to shifting job functions, but \"at the end of the day, we have an incredibly flexible, nimble economy.\"\n\n\"I'm excited about it,\" he said, adding that he sees \"lots of opportunities for our business.\"\n\nThe CEO of Wells Fargo, Charles Scharf, echoed that view. He told Reuters last month that \"the opportunities that exist in AI are very significant.\"\n\n\"Anyone who sits here today and says that they don't think they'll have less head count because of AI either doesn't know what they're talking about or is just not being totally honest about it,\" he said.",
    "readingTime": 3,
    "keywords": [
      "dimon",
      "jobs",
      "society",
      "about",
      "less",
      "last",
      "month",
      "interview",
      "morning",
      "working"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/jamie-dimon-jpmorgan-ai-cut-jobs-work-less-wonderful-lives-2025-12",
    "thumbnail_url": "https://i.insider.com/69379b2404d0f0a114f1a37d?width=1200&format=jpeg",
    "created_at": "2025-12-09T08:42:47.313Z",
    "topic": "finance"
  }
]
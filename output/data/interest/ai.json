[
  {
    "slug": "web-playground-for-qwenimageedit2511",
    "title": "Web playground for Qwen-Image-Edit-2511",
    "description": "Alibabaã®é«˜åº¦ãªAIç”»åƒã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ã€Qwen Image Edit (2511)ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ã€‚æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ã€è¢«å†™ä½“ã®IDä¿æŒã€è¤‡é›‘ãªè£½å“ã‚„ãƒ‡ã‚¶ã‚¤ãƒ³ã®å¤‰æ›´ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚é›†åˆå†™çœŸã€è£½å“ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªå¤‰æ›ã«æœ€é©ã§ã™ã€‚",
    "fullText": "Alibabaã®æœ€æ–°AIç”»åƒã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ã¯ã€å¤§è¦æ¨¡ã§è©³ç´°ãªå†™çœŸç·¨é›†ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚é›†åˆå†™çœŸã®ä¿®æ­£ã€è£½å“ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã®æ”¹å–„ã€ãƒ†ã‚­ã‚¹ãƒˆã®å·®ã—æ›¿ãˆãªã©ã€Qwen Image Edit (2511)ã¯ã‚ã‚‰ã‚†ã‚‹ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã¨IDã‚’ä¿æŒã—ã¾ã™ã€‚\n\nWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãŸã£ãŸ3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªç·¨é›†ã‚’å®Ÿç¾ã—ã¾ã™ã€‚\n\nå·¦ä¸Šã®ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ **Qwen Image Edit (2511)** ã‚’é¸æŠã—ã¦ã€ã“ã®AIã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚\n\nãƒ™ãƒ¼ã‚¹ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å‚ç…§ç”»åƒã‚‚ï¼‰ã€‚ç·¨é›†å†…å®¹ã‚’èª¬æ˜ã™ã‚‹æ˜ç¢ºãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œä»–ã®ã‚‚ã®ã¯å‹•ã‹ã•ãšã€ç…§æ˜ã‚’ä¸€è²«ã•ã›ãŸã¾ã¾ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’è¿½åŠ ã—ã¦ã€ï¼‰ã€‚\n\n**ç”Ÿæˆ**ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€Qwen Image Edit (2511)ã«ç·¨é›†ã‚’å‡¦ç†ã•ã›ã¾ã™ã€‚çµæœã¯ã€å…ƒã®è¢«å†™ä½“ã‚’ç¶­æŒã—ãªãŒã‚‰å¤‰æ›´ï¼ˆæ–°ã—ã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ†ã‚­ã‚¹ãƒˆã€ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰ã‚’é©ç”¨ã—ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ã€è¿½åŠ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ä¿®æ­£ï¼ˆã€Œèµ¤è‰²ã‚’å¼·èª¿ã—ã¦ã€ã‚„ã€Œè¢«å†™ä½“ã®é¡”ã‚’å¤‰ãˆãªã„ã§ã€ãªã©ï¼‰ã‚’åŠ ãˆã¦å†å®Ÿè¡Œã—ã€å¾®èª¿æ•´ã—ã¾ã™ã€‚\n\nQwen Image Edit (2511)ã¯ã€æœ€ã‚‚å›°é›£ãªç·¨é›†ã®èª²é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚é›†åˆå†™çœŸã§ã®é¡”ã®ä¸€è²«æ€§ã‚’ä¿ã¡ã€è£½å“ã®å¹¾ä½•å­¦çš„æ§‹é€ ã‚’ç¶­æŒã—ã€ç”»åƒä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ã—ããƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚ä¿¡é ¼æ€§ãŒé«˜ãã€é«˜å“è³ªãªç·¨é›†ãŒå¿…è¦ãªã‚ã‚‰ã‚†ã‚‹å ´æ‰€ã§ä½¿ç”¨ã§ãã¾ã™ã€‚\n\nçµå©šå¼ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚«ãƒ¡ãƒ©ãƒãƒ³ã¯ã€Qwen Image Edit (2511)ã‚’ä½¿ç”¨ã—ã¦ã€ä¸è¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤ã—ãŸã‚Šã€å®¶æ—å†™çœŸã«äººç‰©ã‚’è¿½åŠ ã—ãŸã‚Šã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯å„äººã®é¡”ã®IDã‚’ä¿æŒã—ã€ç…§æ˜ã¨å½±ã‚’æ­£ã—ãèª¿æ•´ã—ã¦ã€æ­ªã¿ã®ãªã„è‡ªç„¶ãªé›†åˆå†™çœŸã‚’ä½œæˆã—ã¾ã™ã€‚\n\nã‚ªãƒ³ãƒ©ã‚¤ãƒ³å°å£²æ¥­è€…ã‚„ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã¯ã€ãƒ©ãƒ™ãƒ«ã€èƒŒæ™¯å°é“å…·ã®è¿½åŠ ã€è‰²ã®å¤‰æ›´ãªã©ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦è£½å“å†™çœŸã‚’æ”¹å–„ã—ã¾ã™ã€‚Qwen Image Edit (2511)ã®é«˜åº¦ãªå¹¾ä½•å­¦çš„ç†è§£ã«ã‚ˆã‚Šã€è¿½åŠ ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æ•´åˆ—ã•ã‚Œã€ãƒªã‚¢ãƒ«ã«ä¿ãŸã‚Œã¾ã™ï¼ˆä¾‹ï¼šæ–°ã—ã„ãƒ­ã‚´ãŒæ›²é¢ã«å¹³ã‚‰ã«è¡¨ç¤ºã•ã‚Œã‚‹ãªã©ï¼‰ã€‚ã“ã‚Œã¯ã€æ´—ç·´ã•ã‚ŒãŸã‚«ã‚¿ãƒ­ã‚°ã‚„åºƒå‘Šã«æœ€é©ã§ã™ã€‚\n\nãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒ ã¯ã€å†™çœŸã‚’ç›´æ¥ç·¨é›†ã—ã¦åºƒå‘ŠãƒãƒŠãƒ¼ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã‚¹ãƒ­ãƒ¼ã‚¬ãƒ³ã®æ›´æ–°ã€ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ã€ãƒ­ã‚´ã®äº¤æ›ãªã©ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒ¼ãƒˆã«ã‚ˆã‚Šã€Qwen Image Edit (2511)ã¯ãƒ•ã‚©ãƒ³ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ç¶­æŒã—ã¾ã™ã€‚ãŸã¨ãˆã°ã€åº—é ­ã®çœ‹æ¿ã‚’ç·¨é›†ã—ã¦ã€ã‚·ãƒ¼ãƒ³ã®ä¸€è²«æ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€è¤‡æ•°ã®è¨€èªã§æ–°ã—ã„ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚\n\nã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã¯ã€è¦–ç‚¹ã®å›è»¢ã€è¡£è£…ã®å¤‰æ›´ã€ç•°ãªã‚‹ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨ã«ã‚ˆã£ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’åå¾©ã—ã¾ã™ã€‚Qwen Image Edit (2511)ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é¡”ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’å›ºå®šã—ã¦ã‹ã‚‰ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®IDã‚„æ¯”ç‡ã‚’å¤±ã†ã“ã¨ãªãã€ã•ã¾ã–ã¾ãªè¨­å®šã‚„ã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆãƒªã‚¢ãƒ«ã€ã‚¢ãƒ‹ãƒ¡ã€ã‚¸ãƒ–ãƒªé¢¨ãªã©ï¼‰ã§ã‚·ãƒ¼ãƒ³ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚\n\nQwen Image Edit (2511)ã¯ã€å¼·åŠ›ãª200å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®åŸºç›¤ã®ä¸Šã«æ§‹ç¯‰ã•ã‚Œã€æœ€å…ˆç«¯ã®æ”¹è‰¯ãŒåŠ ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚æœ€ã‚‚é­…åŠ›çš„ãªåˆ©ç‚¹ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚\n\nå®¶æ—ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã§ã‚‚ãƒãƒ¼ãƒ å†™çœŸã§ã‚‚ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯é¡”ã‚’å…¥ã‚Œæ›¿ãˆãŸã‚Šã€äººã‚’ç½®ãé–“é•ãˆãŸã‚Šã™ã‚‹ã“ã¨ãªãã€è¤‡æ•°ã®è¢«å†™ä½“ã‚’å‡¦ç†ã—ã¾ã™ã€‚åˆ¥ã€…ã®ç”»åƒã‚’1ã¤ã®ã¾ã¨ã¾ã‚Šã®ã‚ã‚‹é›†åˆå†™çœŸã«ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã«ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã€IDã¨ç›¸å¯¾çš„ãªãƒãƒ¼ã‚ºã‚’ç¶­æŒã—ã¾ã™ã€‚\n\näººç‰©ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚Œã°ã€ãã®é¡”ãŒèªè­˜å¯èƒ½ãªã¾ã¾ã§ã‚ã‚‹ã“ã¨ãŒæœŸå¾…ã§ãã¾ã™ã€‚Qwen Image Edit (2511)ã¯ã€ãƒãƒ¼ã‚ºã€è¡¨æƒ…ã€ç…§æ˜ã‚’å¤‰æ›´ã™ã‚‹ã¨ãã«ã‚ˆãã‚ã‚‹ç‰¹å¾´ã®æ­ªã¿ã®å•é¡Œã‚’åŠ‡çš„ã«æ¸›ã‚‰ã—ã€å„è¢«å†™ä½“ãŒæœ¬äººã‚‰ã—ãè¦‹ãˆã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n\nç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè‹±èªã¾ãŸã¯ä¸­å›½èªï¼‰ã‚’ã€ã»ã¼å®Œç’§ãªå¿ å®Ÿåº¦ã§è¿½åŠ ã€å‰Šé™¤ã€ã¾ãŸã¯å¤‰æ›´ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‹¬è‡ªã®è¦ç´ ã¨ã—ã¦æ‰±ã†ãŸã‚ã€ãƒ•ã‚©ãƒ³ãƒˆã€ã‚µã‚¤ã‚ºã€é…ç½®ã¯è‡ªç„¶ãªã¾ã¾ã§ã™ã€‚çœ‹æ¿ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€ã¾ãŸã¯èª­ã¿ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ä½œæ¥­ã«æœ€é©ã§ã™ã€‚\n\näººæ°—ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚¹ã‚¿ã‚¤ãƒ«LoRAã‚’ã™ãã«ä½¿ç”¨ã§ãã¾ã™ã€‚Qwen Image Edit (2511)ã«ã¯ã€å³é¸ã•ã‚ŒãŸèŠ¸è¡“çš„ãŠã‚ˆã³å†™å®Ÿçš„ãªã‚¹ã‚¿ã‚¤ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ‰‹å‹•ã§èª¿æ•´ã™ã‚‹ã“ã¨ãªãã€åå‰ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç‰¹å®šã®ç…§æ˜åŠ¹æœã‚„æ¼«ç”»ã‚¹ã‚¿ã‚¤ãƒ«ãªã©ã‚’ç›´æ¥é©ç”¨ã§ãã¾ã™ã€‚\n\nå¼·åŒ–ã•ã‚ŒãŸå¹¾ä½•å­¦çš„æ¨è«–ã«ã‚ˆã‚Šã€å½¢çŠ¶ã¨é è¿‘æ³•ã‚’ç†è§£ã—ã¾ã™ã€‚è¦ç´ ï¼ˆçœ‹æ¿ã€å®¶å…·ã€å»ºç‰©ãªã©ï¼‰ã‚’è¿½åŠ ã¾ãŸã¯å‰Šé™¤ã™ã‚‹å ´åˆã€ãã‚Œã‚‰ã‚’æ­£ã—ãæ•´åˆ—ã•ã›ã€è¨­è¨ˆç›®çš„ã®ãŸã‚ã«è£œåŠ©ã‚¬ã‚¤ãƒ‰ï¼ˆé’å†™çœŸã®ç·šã‚„åå°„ãªã©ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã•ãˆã‚ã‚Šã¾ã™ã€‚\n\nè£½å“ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å‘ã‘ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ã‚ˆã‚Šã‚¯ãƒªãƒ¼ãƒ³ãªè¡¨é¢ã¨å¯¾ç§°çš„ãªç·¨é›†ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã¯ã€è£½å“ã®è‰²ã®å¤‰æ›´ã€ãƒ©ãƒ™ãƒ«ã®è¿½åŠ ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æ›´æ–°ã®è¦–è¦šåŒ–ãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¨ãƒƒã‚¸ã¨æ¯”ç‡ã‚’å°Šé‡ã—ã¦ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªçµæœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¢ºä¿¡ã§ãã¾ã™ã€‚\n\nZ-Imageã‹ã‚‰Nano Banana Proã¾ã§ã€ãƒ‹ãƒ¼ã‚ºã«åˆã£ãŸAIç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„\n\nç”»åƒã‚’ç·¨é›†å¯èƒ½ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ã«åˆ†è§£ã—ã€èƒŒæ™¯ã‚’è‡ªå‹•è£œå®Œã™ã‚‹AIãƒ„ãƒ¼ãƒ«ã€‚\n\nå¤¢ã®ã‚ˆã†ãªãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆã‚’å®Ÿç¾ã™ã‚‹ã‚·ãƒãƒãƒ†ã‚£ãƒƒã‚¯ãªãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã€‚\n\nå†™çœŸã®ä¸å…·åˆã«æ‚©ã‚€ã®ã¯ã‚„ã‚ã¾ã—ã‚‡ã†ã€‚Qwen Image Edit (2511)ã«åˆ‡ã‚Šæ›¿ãˆã¦ã€ã‚ã‚‰ã‚†ã‚‹ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã‚’ä¿æŒã™ã‚‹ç°¡å˜ã§ä¸€è²«ã—ãŸç·¨é›†ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ã€‚ä»Šã™ãz-image.appã§è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼",
    "readingTime": 1,
    "keywords": [
      "edit qwen"
    ],
    "qualityScore": 0.5,
    "link": "https://z-image.app/ja/models/qwen-image-edit-2511",
    "thumbnail_url": "https://cdn.z-image.app/models/qwen-image-edit-2511/og-qwen-image-edit-2511.webp",
    "created_at": "2025-12-25T06:19:13.830Z",
    "topic": "tech"
  },
  {
    "slug": "why-your-ai-agents-are-hallucinating-and-how-to-stop-it",
    "title": "Why Your AI Agents Are Hallucinating (and How to Stop It)",
    "description": "Learn why AI agents hallucinate, the real costs of ignoring this problem, and how to automatically detect and prevent hallucinations in production using advanced evaluation scorers and root cause analysis.",
    "fullText": "Your new AI customer service agent just confidently told a user that your product is compatible with a competitor'sâ€”when it isn't. Your research agent just cited a non-existent academic paper in its summary. Your internal knowledge base agent just invented a company policy that doesn't exist.\n\nThese are not just bugs; they are AI hallucinations. And they are one of the most dangerous and insidious problems facing production AI agents today. They erode user trust, create compliance risks, and can cause direct financial damage.\n\nThis article explains why agents hallucinate and how you can automatically detect and prevent it before your customers do.\n\nAn AI hallucination occurs when a large language model (LLM) generates information that is plausible but factually incorrect, irrelevant, or nonsensical in the given context. It's not a bug in the traditional senseâ€”the model is functioning as designed, but its internal patterns have led it to an incorrect conclusion which it presents with complete confidence.\n\nFor AI agents, which are often designed to take action based on information, hallucinations are particularly dangerous. An agent that hallucinates can:\n\nThe Dangerous Part: Unlike traditional software bugs that crash or throw errors, hallucinations appear as normal, confident responses. There's no error messageâ€”just wrong information delivered with certainty.\n\nThere are several root causes for agent hallucinations, but they often fall into a few key categories:\n\nThe agent generates information that is not supported by the context it was given. This is the most common cause of hallucinations in Retrieval-Augmented Generation (RAG) systems.\n\nExample: A customer asks about your return policy. The RAG system retrieves a document about shipping policies instead. The agent \"fills in the gaps\" by inventing a plausible-sounding return policy.\n\nThe agent makes a logical leap that is incorrect, leading it to a false conclusion. Even with correct information, the model's reasoning process can go astray.\n\nExample: An agent is told \"Product A costs 100\"and\"ProductBcosts100\" and \"Product B costs 150.\" When asked which is cheaper, it might occasionally claim Product B is cheaper due to reasoning errors.\n\nThe model's training data is old, and it provides information that is no longer accurate. This is especially problematic for rapidly changing domains.\n\nExample: An agent trained on 2023 data confidently states a library version that has since been deprecated and replaced.\n\nThe user's prompt is unclear, and the agent makes an incorrect assumption to fill in the gaps rather than asking for clarification.\n\nExample: A user asks \"What's the price?\" without specifying which product. The agent picks one arbitrarily and states its price confidently.\n\nLong conversations or documents can exceed the model's context window, causing it to \"forget\" or misremember earlier information.\n\nThe model may have learned incorrect patterns from its training data, leading to systematic hallucinations on certain topics.\n\nIgnoring hallucinations is not an option. The consequences can be severe:\n\nTraditional methods for detecting hallucinations rely on manual review and fact-checking, which are slow, expensive, and reactive. You find out about a hallucination after it has already happenedâ€”often from an angry customer.\n\nNoveum.ai offers a radically different approach: automated, real-time hallucination detection using the agent's own system prompt and context as the ground truth.\n\nOur platform uses a suite of 68+ specialized evaluation scorers to analyze every single agent response. Here are the key scorers for hallucination detection:\n\nThe faithfulness_scorer checks if the agent's answer is factually consistent with the retrieved context. It directly measures whether the agent is \"making things up.\" When a response contradicts the provided documents, it gets flagged with detailed reasoning explaining the inconsistency.\n\nThe groundedness_scorer evaluates whether the agent's responses are based on the provided context or conversation history. It penalizes the model for inventing information not supported by the facts at handâ€”like citing studies, statistics, or sources that don't exist in the context.\n\nInstead of requiring a manually labeled dataset of \"correct\" answers, Noveum.ai uses the agent's system prompt and the context it was given as the source of truth.\n\nThe evaluation engine automatically checks:\n\nThis allows for fully automated, real-time evaluation without the bottleneck of manual labeling.\n\nDetecting a hallucination is the first step. Understanding why it happened is the key to preventing it. This is where NovaPilot, our AI-powered root cause analysis engine, comes in.\n\nWhen a hallucination is detected, NovaPilot analyzes the entire agent trace and the scores from all 68+ evaluators to identify the root cause. It might find that:\n\nPoor Retrieval Quality â€” Low context_relevance score indicates the RAG system retrieved wrong documents. The agent didn't have the right information to begin with.\n\nAmbiguous System Prompt â€” The prompt doesn't explicitly instruct the agent to say \"I don't know.\" Missing guardrails for handling uncertainty.\n\nModel Tendency â€” Certain models are more prone to hallucination for specific task types. May need to switch models or add verification steps.\n\nContext Window Issues â€” Important information was truncated due to token limits. Need to optimize context selection.\n\nMissing Verification Steps â€” No fact-checking layer before response delivery. Consider adding a verification agent to the pipeline.\n\nBased on its diagnosis, NovaPilot suggests specific, actionable fixes:\n\nLet's walk through a complete example of how Noveum.ai catches and diagnoses a hallucination:\n\nA financial services chatbot is asked about the interest rate on a specific savings account. The RAG system retrieves a document about a similar but different account.\n\nThe agent confidently states the interest rate from the wrong document:\n\nUser: \"What's the interest rate on the Premium Savings Account?\"\n\nAgent: \"The Premium Savings Account offers a 2.5% APY.\" âŒ\n\n(Actual rate: 3.2% APY â€” the agent cited the Standard Savings rate)\n\nThe evaluation engine runs automatically on this interaction:\n\nNovaPilot analyzes the trace and identifies the pattern:\n\nRoot Cause: The retrieval system, not the LLM. The wrong document was retrieved, so even a perfect LLM would give the wrong answer.\n\n\"Improve the retrieval system to be more precise. Consider using product-specific embeddings or adding metadata filtering to ensure the correct account type is retrieved. Current retrieval is matching on general 'savings account' terms rather than specific product names.\"\n\nHere's how to add hallucination detection to your existing agent:\n\nIn your Noveum.ai dashboard, select the scorers you want to apply:\n\nSet your thresholds (we recommend 7/10 for production) and configure your alert channels.\n\nConfigure real-time alerts for hallucination detection:\n\nAdd clear instructions to your system prompt:\n\nMonitor your RAG pipeline's context relevance scores. Poor retrieval is the #1 cause of hallucinations.\n\nAdd a verification step before delivering responses. Noveum.ai automatically evaluates every response against its context using our suite of 68+ scorersâ€”no manual verification code needed. Simply enable hallucination detection in your dashboard and get instant alerts when responses don't match the provided context.\n\nHallucination patterns change over time. Monitor trends and adjust your prompts and retrieval strategies accordingly.\n\nStudies suggest that LLMs hallucinate between 3-27% of the time depending on the task and model. For RAG systems with poor retrieval, rates can be even higher.\n\nNo current technology can guarantee zero hallucinations. The goal is to detect them before they reach users and continuously reduce their frequency through better prompts, retrieval, and model selection.\n\nFaithfulness measures whether the response contradicts the provided context. Groundedness measures whether claims are supported by the context at all. A response can be faithful (not contradicting) but not grounded (adding unsupported information).\n\nEvery trace is evaluated automatically as it's captured. Scores are computed in near-real-time, and alerts are triggered immediately when thresholds are crossed.\n\nGenerally, smaller and faster models hallucinate more than larger ones. However, even GPT-4 hallucinates. The key is detection and mitigation, not model selection alone.\n\nHallucinations are a serious threat to the reliability and trustworthiness of AI agents. Relying on manual detection is a losing battleâ€”you'll always be reacting to problems after they've damaged user trust.\n\nThe only scalable solution is to automate the process.\n\nNoveum.ai provides the industry's most advanced platform for automatically detecting, diagnosing, and fixing hallucinations in production agents. By using the system prompt as ground truth and leveraging our powerful NovaPilot engine, we help you catch problems before your customers do.\n\nYour agents are talking to customers, making recommendations, and taking actions right now. Do you know if they're telling the truth?\n\nSchedule a demo to see how Noveum.ai can protect your agents from hallucinationsâ€”before your customers find out the hard way.\n\nğŸ‘‰ Start Free Trial | View Documentation | Book a Demo\n\nLet's build AI agents you can actually trust.\n\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "readingTime": 8,
    "keywords": [
      "novapilot analyzes",
      "rag systems",
      "savings account",
      "premium savings",
      "poor retrieval",
      "rag system",
      "return policy",
      "automated real-time",
      "retrieves document",
      "ground truth"
    ],
    "qualityScore": 1,
    "link": "https://noveum.ai/en/blog/why-your-ai-agents-are-hallucinating-and-how-to-stop-it",
    "thumbnail_url": "https://fabulous-chocolate-2e9a61146f.media.strapiapp.com/image_1_2b6599e0d9.webp",
    "created_at": "2025-12-25T06:19:12.530Z",
    "topic": "tech"
  },
  {
    "slug": "in-a-new-deal-nvidia-hires-groqs-top-engineering-talent-including-its-founder-who-built-ai-chips-at-google",
    "title": "In a new deal, Nvidia hires Groq's top engineering talent, including its founder, who built AI chips at Google",
    "description": "A new type of dealmaking is on the rise in Silicon Valley as Nvidia reaches a non-exclusive deal with a chip startup and hires its top engineers.",
    "fullText": "Nvidia is forging ahead with another bet on the AI boom, agreeing to a licensing deal with AI hardware startup Groq.\n\nGroq said Wednesday that some of its executives, including its founder and CEO, will join Nvidia as part of the deal. Groq is expected to continue operating independently following what it described as a non-exclusive licensing deal.\n\nGroq is known for its Language Processing Unit, which is a custom chip designed for AI inference, namely, the process by which a trained AI model makes predictions or decisions. The startup was valued at about $6.9 billion as of three months ago and raised around $750 million in its latest funding round.\n\nJonathan Ross, Groq's founder and CEO, as well as the startup's president and other members of its team are expected to join Nvidia, the world's most valuable company with a market cap north of $4.5 trillion.\n\nA person familiar with the matter told Business Insider on Wednesday that Nvidia is not acquiring the chip startup.\n\nNeither Nvidia nor Groq disclosed financial terms of the agreement.\n\nRoss andÂ Douglas WightmanÂ were engineers at Google who started the project that became Google's first TPU chips, before leaving to found Groq. The TPUs are custom-made to accelerate large-scale machine-learning tasks designed to handle AI workloads, and are a major rival to Nvidia's GPUs.\n\nThe deal between the two companies comes as a new type of dealmaking is on the rise in Silicon Valley. Whereas traditional startups either aim to go public or be acquired, new acqui-hire deals could leave some startup employees behind, only benefiting a small percentage of staff members with desirable AI skills and the founders.\n\nFor instance, in 2024, Google agreed to pay $2.5 billion to license Character.AI's technology but only hired its two superstar cofounders and 20% of the startup's employees. In the same year, AI developers Adept and Inflection also made similar deals with Amazon and Microsoft, respectively.\n\nMore recently, Meta's acqui-hire of Scale AI became one of the biggest bets on talent after the company agreed to invest roughly $14 billion for a 49% stake and to bring its CEO, Alexandr Wang, into the fold to lead the Meta Superintelligence Labs.\n\nThese acqui-hires don't always end well. Windsurf employees were left in limbo after the AI coding startup was nearly aquired by OpenAI for $3 billion, only for the deal to fall apart and the company to be split. Google spent billions to hire Windsurf's CEO and top engineers, while the remaining hundreds of employees were acquired by another startup, Cognition.",
    "readingTime": 3,
    "keywords": [
      "join nvidia",
      "deal groq",
      "licensing deal",
      "startup",
      "employees",
      "google",
      "another",
      "founder",
      "chip",
      "designed"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-reaches-licensing-agreement-with-groq-hires-ai-top-talent-2025-12",
    "thumbnail_url": "https://i.insider.com/694c9bb5832e0ef1ead6cf7a?width=1200&format=jpeg",
    "created_at": "2025-12-25T06:19:06.742Z",
    "topic": "finance"
  },
  {
    "slug": "schleppy-agi",
    "title": "Schleppy AGI",
    "description": "Why powerful AI might arrive sooner than we think",
    "fullText": "Dwarkesh Patel recently published a compelling essay arguing that today's AI systems are still many years away from AGI. His core view is that they are missing key components of cognition, most importantly true continual learning. Despite impressive benchmark performance, current models aren't yet economically transformative because they can't learn on the job the way humans do. Instead, labs are \"pre-baking\" skills into models using Reinforcement Learning with Verifiable Rewards (RLVR), constructing bespoke training environments for coding, Excel, browser navigation, and countless other narrow tasks. To Dwarkesh, this reveals a fundamental limitation. As he puts it, \"Human workers are valuable precisely because we don't need to build schleppy training loops for every small part of their job.\"\n\nIt's a persuasive argument. But the question I keep coming back to is: is the elegant solution a hard requirement or can we sort of duct tape our way to AGI?\n\nConsider Deep Blue. In 1997, IBM's Deep Blue defeated Garry Kasparov in a six-game chess match that captivated the world. Deep Blue did not understand chess in any human sense. It had no intuition, no internalized strategy, no aesthetic judgment. It simply evaluated millions of positions per second and searched deeper than any human could. One move in Game 2 unsettled Kasparov so badly that he accused IBM of cheating; it felt too creative, too human. But it was nothing of the sort. It was brute force, systematically exploring the possibility space. Twenty years later, AlphaZero learned through self-play, developing a fluid, intuitive style that grandmasters described as alien yet beautiful. AlphaZero played chess the \"right\" way. Both systems accomplished the goal of playing chess better than humans, but Deep Blue got there first. The ugly solution won.\n\nAre we in a similar situation today?\n\nDwarkesh looks at the current AI landscape and sees missing categories of cognition. Labs are painstakingly constructing verification environments for individual skills, and to him this is evidence that models lack genuine generalization. Real jobs, he argues, consist of hundreds of small, shifting tasks that vary from day to day, even for the same person. You can't automate them with predefined skill sets. In a way he's recapitulating the old expert systems vs learning systems debate. Manually coding how to behave was too brittle, so it never worked.\n\nInterestingly, his view does stand in contrast to many lab leaders. A skeptical reader will surely argue that's because they have a strong incentive to exaggerate the pace of progress, but for the purposes of this discussion, let's take their statements at face value. Dario Amodei believes the current paradigm will get us there, predicting powerful AI as early as 2026. Sam Altman and Jakub Pachocki have offered concrete timelines, an intern-level AI researcher by late 2026 and a fully automated one by 2028, backed by over a trillion dollars in infrastructure commitments. Mark Chen, OpenAI's Chief Research Officer, has pushed back on the idea that scaling is exhausted, hinting that they have made some important breakthroughs in pretraining specifically.\n\nThis perspective is not unanimous. Demis Hassabis believes additional breakthroughs are needed on the level of the transformer, and Andrej Karpathy estimates something like a decade. This camp tends to be more neuroscience-inspired, believing the current architectures are missing something fundamental.\n\nSo what's the actual bottleneck?\n\nDwarkesh's argument largely boils down to three problems all related to memory. First, current models are sample inefficientâ€”they need far more examples to learn something than a human would. Second, what they learn isn't general enough to transfer across contexts. Third, they can't continue to learn on the job the way humans do.\n\nThis last problem is intrinsic to how gradient descent works. When a model learns, it adjusts billions of parameters at once, a global update that touches the entire network. This makes the system brittle; new information can overwrite old information, a problem called catastrophic forgetting. So todayâ€™s models come with a frozen pretrained brain and rely on stuffing relevant information into each prompt, called a context window. These are crude substitutes. Everything must be reprocessed with every response. There's no dynamic working memory, no graceful fading of irrelevant information, no seamless integration with long-term storage.\n\nThis matters for a number of reasons. Without the ability to integrate new information into its world model, it can only grasp new tasks superficially. It can't build on what it learned yesterday. Models struggle to navigate complex software because they can't track things the way you do. Photoshop is intuitive to an experienced user, but to a model with fragmented memory, every menu is half-familiar, every action a guess. These aren't signs of low intelligence. They're signs of a specific limitation, not dissimilar to a human disability. Blindness or deafness will make some tasks virtually impossible, but this says nothing about their underlying intelligence. Similarly, a model can be extraordinarily capable and still fail at tasks that require persistent memory.\n\nAll of this is accurate. The open question is whether it represents a hard scientific boundary or is just a matter of iterative engineering.\n\nHuman memory itself is not a single, elegant system. It's a collection of specialized mechanisms layered together by evolution. Most day-to-day learning does not instantly integrate deeply into the brain. It involves holding information in working memory, encoding episodes, retrieving associations, and slowly consolidating over time.\n\nSeen this way, perhaps the models aren't so far from functional equivalence after all. Retrieval over long interaction histories so a system remembers what you discussed weeks ago. Persistent preference and project files injected into context. Lightweight fine-tuning methods like LoRA applied periodically rather than continuously. External memory via tool use, where models write notes to themselves and read them back. Better working-memory mechanisms layered on top of existing architectures. None of this requires brand-new science, and much of it already exists in partial form.\n\nThese solutions are undeniably schleppy. They are brittle and can fail in surprising ways. Skeptics rightly point out that unlike chess, which is a closed system with perfect information, the real world is an open environment where errors can compound. That's all true, but we are no longer discussing hypotheticals. People are already using these systems for real work. Coding agents are writing and debugging software semi-autonomously. Customer service systems are starting to handle basic help desk queries. Legal research can often be handled end to end by an extended thinking model. There's still a capability gap, but it is shrinking.\n\nIt's important to recognize that 2025 was less a year of huge new models than one of bringing the frontier to everyone at a reasonable cost. That infrastructure buildout absorbed resources that might otherwise have gone toward pushing capabilities. If progress has felt slower than expected, this is part of the reason. It's easy to anchor on the current pace and assume it's the new normal. That would be a mistake.\n\nThe hardware trajectory is significant. Nvidiaâ€™s GB300 NVL72 racks use 72 Blackwell Ultra GPUs acting as a single massive unit. Microsoft has announced the first large-scale production cluster with over 4,600 of these racks, claiming it will enable training models with hundreds of trillions of parameters and reduce training times from months to weeks. Depending on workload, this represents anywhere from a 4x improvement in training speed to a 10x reduction in inference costs compared to the previous generation. When you can throw an order of magnitude more compute at context management, retrieval, and verification, many of today's clumsy workarounds start to look far more viable.\n\nWe do need solutions to memory and some degree of continual learning, but Dwarkesh may also be understating how much current models already generalize. No one built a special training pipeline for GeoGuessr, yet general models can perform at a borderline superhuman level. This requires inferring the geographic location of pictures from subtle cues like vegetation, signage, architecture, and sun angle. And long before job-specific reinforcement learning was used, models already showed remarkable capability across many professions, just from compressing the internet.\n\nThe labs' heavy investment in RLVR could be viewed less like a confession of architectural inadequacy and more like a pragmatic choice. RLVR improves effectiveness on tasks that matter commercially. It simply juices the value of current models.\n\nThe benchmark, OSWorld, provides a useful case in point of my argument. This benchmark tests models on everyday computer tasks in a virtual machine: adding page numbers to a document, exporting a CSV from a spreadsheet, configuring browser settings. Over the past year, success rates have climbed from under 10% to over 60%, approaching the human baseline of 72%. But a closer look reveals something interesting: much of this progress comes from models finding workarounds. About 15% of tasks can be completed using only terminal commands, no GUI required. Another 30% can be largely solved with Python scripts instead of clicking through menus. The benchmark was designed to measure GUI manipulation, something models are known to struggle with, but instead of failing, they just found a workaround.\n\nThis discussion largely hinges on how far these workarounds can ultimately go. The debate isn't about whether human-like continual learning would be powerful. It would be. It's about what exactly is required to cross the human threshold of reliable knowledge work. History suggests that inelegant, resource-intensive solutions arrive first, especially when the incentives are overwhelming.\n\nRay Kurzweil's long-running prediction of human-level AI by 2029 is relevant here. Kurzweil's track record on specific technologies is mixed, but he has been remarkably prescient about the pace and magnitude of technological progress. His law of accelerating returns is all about markets. Computing power compounds due to incentives and whatâ€™s allowed by physics. Capital, talent, and institutional effort then develop new technologies enabled by that compute.\n\nHumans are best understood as what E.O. Wilson called a â€œsuperorganism,â€ similar to ants or termites. We cooperate at an unprecedented scale. And this global superorganism has slowly been turning itself toward the production of machine intelligence ever since ChatGPT arrived in late 2022. Nation-states, corporations, supply chains, research communities, and capital markets are all aligning around the same attractor. This applies immense pressure to each barrier to progress.\n\nIf the current paradigm fails to reach AGI, it will be because continual learning turns out to be a hard scientific barrier rather than an engineering challenge. But given the scale of investment, the pace of hardware progress, and the growing stack of workable approximations, I'd bet on the engineers.\n\nIt's unclear when we will get the elegant, human-like mind we are waiting for. But if history is any guide, that distinction may not matter much. When Deep Blue won, Kasparov felt it was a trick. He sensed a human creativity that simply wasn't there and accused IBM of cheating. We are likely walking into the same psychological trap. We will look at these schleppy, duct-taped systems and insist they are just parroting data or faking reasoning. We will call it a parlor trick right up until the moment it outperforms us. At that point, like Kasparov, we will have to accept that the mechanism matters less than the move.",
    "readingTime": 10,
    "keywords": [
      "accused ibm",
      "mechanisms layered",
      "continual learning",
      "models aren't",
      "deep blue",
      "human",
      "tasks",
      "memory",
      "systems",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.seriousanimals.com/schleppy-agi/",
    "thumbnail_url": "https://www.seriousanimals.com/content/images/2025/12/Gary_DeepBlue.jpg",
    "created_at": "2025-12-25T00:56:21.644Z",
    "topic": "tech"
  },
  {
    "slug": "silicon-valleys-tonedeaf-take-on-the-ai-backlash-will-matter-in-2026",
    "title": "Silicon Valley's tone-deaf take on the AI backlash will matter in 2026",
    "description": "AIâ€™s champions keep trying to impress, but the public is still waiting for answers about jobs, costs, and who benefits. By 2026, that tension will matter.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2025/12/23/silicon-valleys-tone-deaf-take-on-the-ai-backlash-will-matter-in-2026/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2236544323_ce1755-e1766508826353.jpg?resize=1200,600",
    "created_at": "2025-12-25T00:56:21.638Z",
    "topic": "tech"
  },
  {
    "slug": "librarians-tired-of-being-accused-of-hiding-secret-books-that-were-made-up-by-ai",
    "title": "Librarians Tired of Being Accused of Hiding Secret Books That Were Made Up by AI",
    "description": "AI chatbots are generating fake titles that people insist are real.",
    "fullText": "Everyone knows that AI chatbots like ChatGPT, Grok, and Gemini can often hallucinate sources. But for the folks tasked with helping the public find books and journal articles, the fake AI bullshit is really taking its toll. Librarians sound absolutely exhausted by the requests for titles that donâ€™t exist, according to a new post from Scientific American.\n\nThe magazine spoke with Sarah Falls, the chief of researcher engagement at the Library of Virginia, who estimates that about 15% of all emailed reference questions that they receive are generated by AI chatbots like ChatGPT. And the requests often include questions about fake citations.\n\nWhatâ€™s more, Falls suggests that people donâ€™t seem to believe librarians when they explain that a given record doesnâ€™t exist, a trend thatâ€™s been reported elsewhere like 404 Media. Many people really believe their stupid chatbot over a human who specializes in finding reliable information day in and day out.\n\nA recent post from the International Committee of the Red Cross (ICRC) titled, â€œImportant notice: AI generated archival reference,â€ provides more evidence that librarians are just exhausted with it all.\n\nâ€œIf a reference cannot be found, this does not mean that the ICRC is withholding information. Various situations may explain this, including incomplete citations, documents preserved in other institutions, orâ€” increasinglyâ€”AI-generated hallucinations,â€ the organization said. â€œIn such cases, you may need to look into the administrative history of the reference to determine whether it corresponds to a genuine archival source.â€\n\nYes it happened to me ğŸ« , I went to a bookstore for a totally plausible old French metaphor book mentioned by ChatGPT a year ago, only to discover that it does not exist.\n\nâ€” Joanne Boisson (@joanneboisson.bsky.social) December 9, 2025 at 4:31 AM\n\nThe year seems to have been filled with examples of fake books and journal articles created with AI. A freelance writer for the Chicago Sun-Times generated a summer reading list for the newspaper with 15 books to recommend. But ten of the books didnâ€™t exist. The first report from Health Secretary Robert F. Kennedy Jr.â€™s so-called Make America Healthy Again commission was released in May. A week later, reporters at NOTUS published their findings after going through all of the citations. At least seven didnâ€™t exist.\n\nYou canâ€™t blame everything on AI. Papers have been retracted for giving fake citations since long before ChatGPT or any other chatbot came on the scene. Back in 2017, a professor at Middlesex University found at least 400 papers citing a non-existent research paper that was essentially the equivalent of filler text.\n\nVan der Geer, J., Hanraads, J.A.J., Lupton, R.A., 2010. The art of writing a scientific article. J Sci. Commun. 163 (2) 51-59.\n\nItâ€™s gibberish, of course. The citation seems to have been included in many lower quality papersâ€”likely due to laziness and sloppiness rather than an intent to deceive. But itâ€™s a safe bet that any authors of those pre-AI papers would have probably been embarrassed about their inclusion. The thing about AI tools is that too many humans have come to believe our chatbots are more trustworthy than humans.\n\nAs someone who gets lots of local history queries, can confirm thereâ€™s been a big increase in people starting their history research with GenAI/LLM (which just spews out fake facts and hallucinated rubbish) who then wonder why they canâ€™t find anything at all to corroborate it.\n\nâ€” Huddersfield Exposed (@huddersfield.exposed) December 9, 2025 at 2:28 AM\n\nWhy might users trust their AI over humans? For one thing, part of the magic trick that AI pulls is speaking in an authoritative voice. Who are you going to believe, the chatbot youâ€™re using all day or some random librarian on the phone? The other problem might have something to do with the fact that people develop what they believe are reliable tricks for making AI more reliable.\n\nSome people even think that adding things like â€œdonâ€™t hallucinateâ€ and â€œwrite clean codeâ€ to their prompt will make sure their AI only gives the highest quality output. If that actually worked, we imagine companies like Google and OpenAI would just add that to every prompt for you. If it does work, boy, have we got a lifehack for all the tech companies currently terrified of the AI bubble bursting.",
    "readingTime": 4,
    "keywords": [
      "journal articles",
      "didnâ€™t exist",
      "fake citations",
      "books",
      "reference",
      "chatbots",
      "librarians",
      "donâ€™t",
      "generated",
      "chatbot"
    ],
    "qualityScore": 1,
    "link": "https://gizmodo.com/librarians-arent-hiding-secret-books-from-you-that-only-ai-knows-about-2000698176",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2025/12/library-books-1200x675.jpg",
    "created_at": "2025-12-25T00:56:20.209Z",
    "topic": "tech"
  },
  {
    "slug": "vidscore-ai-analyze-your-videos-before-you-post",
    "title": "VidScore AI: Analyze your videos before you post",
    "description": "Download VidScore AI: Viral Analytics by Gavin Alfaro on the App Store. See screenshots, ratings and reviews, user tips, and more games like VidScore AI: Viralâ€¦",
    "fullText": "VidScore AI: Viral Analytics Grow on TikTok, Reels & More! Free Â· Inâ€‘App Purchases Share iPhone, iPad Ratings & Reviews App Privacy The developer, Gavin Alfaro, indicated that the appâ€™s privacy practices may include handling of data as described below.",
    "readingTime": 1,
    "keywords": [
      "privacy"
    ],
    "qualityScore": 0.2,
    "link": "https://apps.apple.com/us/app/vidscore-ai-viral-analytics/id6756249746",
    "thumbnail_url": "https://is1-ssl.mzstatic.com/image/thumb/PurpleSource211/v4/e1/27/1c/e1271cd4-5f6c-c9b2-3d0c-ca7e23c58fd6/Placeholder.mill/1200x630wa.jpg",
    "created_at": "2025-12-25T00:56:19.910Z",
    "topic": "tech"
  },
  {
    "slug": "keystone-yc-s25-is-hiring-engineer-1-to-automate-coding",
    "title": "Keystone (YC S25) is hiring engineer #1 to automate coding",
    "description": "About Keystone\nWe're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\nWe're in-person in SoMa, San Francisco.",
    "fullText": "We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\n\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\n\nWe're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.\n\nYou'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.\n\nYou might be a great fit if you:\n\nStack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS\n\nComp & benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget",
    "readingTime": 2,
    "keywords": [
      "we're",
      "product",
      "logs",
      "ventures",
      "you'd"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/06e7837c1e5c8ce88da333ac2efcf401d8cbee53.png?1747973680",
    "created_at": "2025-12-25T00:56:12.872Z",
    "topic": "jobs"
  },
  {
    "slug": "vibium-browser-automation-for-ai-and-humans-by-seleniums-creator",
    "title": "Vibium â€“ Browser automation for AI and humans, by Selenium's creator",
    "description": "Browser automation for AI agents and humans. Contribute to VibiumDev/vibium development by creating an account on GitHub.",
    "fullText": "VibiumDev\n\n /\n\n vibium\n\n Public\n\n Browser automation for AI agents and humans\n\n vibium.com\n\n License\n\n Apache-2.0 license\n\n 278\n stars\n\n 33\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n VibiumDev/vibium",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/VibiumDev/vibium",
    "thumbnail_url": "https://opengraph.githubassets.com/83c696e434d7596c7c64287273badacec418d5f214c4c110077e01f4c531c358/VibiumDev/vibium",
    "created_at": "2025-12-24T18:17:37.822Z",
    "topic": "tech"
  },
  {
    "slug": "a-nobel-prizewinning-physicist-explains-how-to-use-ai-without-letting-it-do-your-thinking-for-you",
    "title": "A Nobel Prize-winning physicist explains how to use AI without letting it do your thinking for you",
    "description": "Leading physicist Saul Perlmutter warns AI can create a false sense of confidence, urging skepticism and constant error-checking.",
    "fullText": "Probably not, according to Saul Perlmutter, a Nobel Prize-winning physicist who was credited for discovering that the universe's expansion is accelerating.\n\nHe said AI's biggest danger is psychological: it can give people the illusion they understand something when they don't, weakening judgment just as the technology becomes more embedded in our daily work and learning.\n\n\"The tricky thing about AI is that it can give the impression that you've actually learned the basics before you really have,\" Perlmutter said on a podcast episode with Nicolai Tangen, CEO of Norges Bank Investment Group, on Wednesday.\n\n\"There's a little danger that students may find themselves just relying on it a little bit too soon before they know how to do the intellectual work themselves,\" he added.\n\nRather than rejecting AI outright, Perlmutter said the answer is to treat it as a tool â€” one that supports thinking instead of doing it for you.\n\nPerlmutter said that AI can be powerful â€” but only if users already know how to think critically.\n\n\"The positive is that when you know all these different tools and approaches to how to think about a problem, AI can often help you find the bit of information that you need,\" he said.\n\nAt UC Berkeley, where Perlmutter teaches, he and his colleagues developed a critical-thinking course centered on scientific reasoning, including probabilistic thinking, error-checking, skepticism, and structured disagreement, taught through games, exercises, and discussion designed to make those habits automatic in everyday decisions.\n\n\"I'm asking the students to think very hard about how would you use AI to make it easier to actually operationalize this concept â€” to really use it in your day-to-day life,\" he said.\n\nOne of Perlmutter's concerns is that AI often speaks with far more certainty than it deserves and can be \"overly confident\" in what it says.\n\nThe challenge, Perlmutter said, is that AI's confident tone can short-circuit skepticism, making people more likely to accept its answers at face value rather than question whether they're correct.\n\nThat confidence, he said, mirrors one of the most dangerous human cognitive biases: trusting information that appears authoritative or confirms our existing beliefs.\n\nTo counter that instinct, Perlmutter said people should evaluate AI outputs the same way they would any human claim â€” weighing credibility, uncertainty, and the possibility of error rather than accepting answers at face value.\n\nIn science, Perlmutter said, researchers assume they are making mistakes and build systems to catch them. For example, scientists hide their results from themselves, he said, until they've exhaustively checked for errors, thereby reducing confirmation bias.\n\nThe same mindset applies to AI, he added.\n\n\"Many of [these concepts] are just tools for thinking about where are we getting fooled,\" he said. \"We can be fooling ourselves, the AI could be fooling itself, and then could fool us.\"\n\nThat's why AI literacy also involves knowing when not to trust the output, he said â€” and being comfortable with uncertainty, rather than treating AI outputs as absolute truth.\n\nStill, Perlmutter is clear that this isn't a problem with a permanent solution.\n\n\"AI will be changing,\" he said, \"and we'll have to keep asking ourselves: is it helping us, or are we getting fooled more often? Are we letting ourselves get fooled?\"",
    "readingTime": 3,
    "keywords": [
      "rather",
      "fooled",
      "perlmutter",
      "ai's",
      "danger",
      "students",
      "tools",
      "skepticism",
      "confident",
      "face"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-to-use-ai-without-losing-critical-thinking-leading-physicist-2025-12",
    "thumbnail_url": "https://i.insider.com/694bd59964858d02d2175b75?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:34.046Z",
    "topic": "finance"
  },
  {
    "slug": "how-wall-street-banks-are-using-ai-from-staff-training-to-performance-reviews",
    "title": "How Wall Street banks are using AI â€” from staff training to performance reviews",
    "description": "JPMorgan, Citi, and Goldman Sachs are investing heavily in AI technology to transform operations, enhance productivity, and stay competitive.",
    "fullText": "JPMorgan Chase has a technology budget of $18 billion, with much of it going toward making sure it's a leader and early mover in AI.\n\nJPMorgan CEO Jamie Dimon is a \"tremendous\" user of the bank's generative AI suite. The bank has rolled out its proprietary genAI platform to over 200,000 employees. And with about 100 more tools in the pipeline, JPMorgan is seeking to reengineer workflows for everyone from coders to portfolio managers.\n\nJPMorgan has reportedly given employees the option to use its in-house AI tools to assist in writing year-end performance reviews.\n\nExecutives at America's largest bank gave an inside look at how it's training employees to use its tools and how they're using them to deliver measurable results.\n\nDimon has previously said he's out to win the AI arms race, and he thinks JPMorgan's $2 billion AI investment has already matched its cost in savings.\n\nCitigroup has also been aggressively accelerating its AI plans. Over the summer, the bank doubled down on its AI ambitions with new leadership at the helm of its tech transformation.\n\nIn mid-October, Citi CEO Jane Fraser said that nearly 180,000 employees in 83 countries have access to the bank's proprietary AI tools and have used them almost 7 million times this year.\n\nIts generative AI tools have saved 100,000 developer hours a week with automated code reviews â€” \"a very meaningful productivity uplift,\" she said during the firm's third-quarter earnings call.\n\nThe bank launched the pilot of agentic AI for 5,000 colleagues in September.\n\n\"It allows complex, multi-step tasks to be completed with a single prompt, and the early results are very promising, and we'll expand access to this in the months ahead,\" said Fraser. \"Finally, we have launched a firm-wide effort to systematically embed AI in our processes end-to-end to drive further efficiencies, reduce risk, and improve client experience.\"\n\nShe also highlighted several tools to help its wealth management advisors. Citi hired an AI leader from Morgan Stanley earlier this year to help revamp its wealth technology.\n\nLike JPMorgan, Citi is also telling employees to use AI for performance reviews, Fraser recently told Bloomberg in an interview.\n\nOne of Citi's top tech executives, Shadman Zafar, outlined the bank's four-phased AI strategy and how it will \"change how we work for decades to come.\"\n\nGoldman put $6 billion behind its technology spend this year, but David Solomon, the bank's CEO, said he wished it were more.\n\nHe said he would like to be at least $8 billion, but \"I can't afford it because I've got to deliver returns,\" he said at a conference in early October.\n\nA definitive statement about how AI will affect Goldman came from a memo to employees in October announcing the third iteration of the bank's cross-bank initiative OneGS. The memo said the plan would leverage AI will drive efficiency at the firm, slow hiring, and result in a \"limited reduction\" of roles.\n\nGoldman, like its peers, has been rolling out tools, including an internal AI assistant to all employees this summer.\n\nBusiness Insider talked to employees about how they were using AI.\n\nGoldman's top partners and Solomon are eager to see AI rev up their businesses. From realizing internal productivity gains to capturing more business as clients look to raise money in anticipation of AI development and acquisitions, here's what the top echelon is expecting.\n\nThere is no AI without data, and there is no data strategy at Goldman without its chief data officer, Neema Raphael. Raphael gave Business Insider an inside look at how his roughly 500-person team melds with the rest of the bank to get the most out of its data.\n\nMorgan Stanley's CFO, Sharon Yeshaya, lifted the curtain on some of the firm's progress on AI during its earnings call last month.\n\nShe highlighted DevGen.AI, a tool that, from January to June, Business Insider previously reported, had saved developers more than 280,000 hours, or 11,666 days they would have previously dedicated to deciphering outdated code.\n\nParable, an interactive tool that analyzes and summarizes data, and LeadIQ, an AI-powered lead distribution platform that matches users of its workplace and self-directed platforms to the bank's financial advisors, were also spotlighted in the call.\n\nA survey of Morgan Stanley's interns also gave a peek into just how popular and useful AI has been for the industry's youngest cohort. ChatGPT is their favorite tool by far â€” with 72% of Morgan Stanley's interns said they use it daily or several times a week. The bank was early to have a partnership with ChatGPT-maker OpenAI.\n\nMorgan Stanley also spoke with Business Insider about bringing employees' AI ideas to life. Here's a look at that process.\n\nBank of America's AI rollout is also well underway.\n\nThe bank's CEO Brian Moynihan says its use of AI is already embedded across the firm, from consumer banking to institutional clients. Its virtual assistant, Erica, handled 2 million customer interactions in a single day and can now answer 700 types of questions â€” up from 210 a year ago. Executives said they'll share more details on the bank's AI strategy at its investor day on November 5.\n\nRob Pascal, the bank's chief experience officer, previously detailed how the bank's internal-facing AI assistant helps bankers collect, record, and review client data.",
    "readingTime": 5,
    "keywords": [
      "stanley's interns",
      "performance reviews",
      "bank's ceo",
      "inside look",
      "business insider",
      "morgan stanley's",
      "employees",
      "tools",
      "previously",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wall-street-banks-ai-strategy-jpmorgan-goldman-citi-bofa-2025",
    "thumbnail_url": "https://i.insider.com/66bf62d95da406397bf6896f?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:33.963Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-bubble-debate-17-business-leaders-from-sam-altman-to-bill-gates-to-peter-thiel-weigh-in",
    "title": "The AI bubble debate: 17 business leaders, from Sam Altman to Bill Gates to Peter Thiel, weigh in",
    "description": "OpenAI's Sam Altman sparked fears of an AI bubble. Business leaders like Bill Gates, Mark Cuban, and Jensen Huang disagree over whether one exists.",
    "fullText": "The AI boom shows no sign of slowing down. Some top business leaders are concerned that a bubble is about to burst.\n\nIn August, OpenAI CEO Sam Altman gave voice to those fears about the future of AI. Since then, other CEOs, including Nvidia's Jensen Huang, have dismissed concerns of an AI bubble. Wall Street is also worried about the increasing circular nature of Big Tech's spending spree.\n\nHere's what leading tech CEOs and business leaders are saying about what's ahead.\n\nOpenAI CEO Sam Altman said that the AI market is in a bubble.\n\n\"When bubbles happen, smart people get overexcited about a kernel of truth,\" Altman recently told reporters, per The Verge.\n\nAltman said this describes the state of play.\n\n\"Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes. Is AI the most important thing to happen in a very long time? My opinion is also yes,\" he said.\n\nMicrosoft cofounder Bill Gates says AI is in a bubble â€” just not to the extent of Danish tulips.\n\n\"The value is extremely high, just like creating the internet ended up being, in net, very valuable,\" Gates told CNBC in late October. \"But you have a frenzy. And some of these companies will be glad they spent all this money. Some of them, you know, they'll commit to data centers whose electricity is too expensive.\"\n\nGates said that the situation reminds him of dot-com bubble when overvalued internet companies sparked a crash.\n\n\"Absolutely, there are a ton of these investments that will be dead ends,\" he said.\n\nStill, the billionaire said that AI remains a major breakthrough, calling it \"the biggest technical thing ever in my lifetime.\"\n\nMark Cuban, who famously sold Broadcast.com just before the dot-com bubble burst, said he doesn't see similarities to the current situation.\n\n\"There were people creating companies with just a website and going public. That's a bubble where there's no intrinsic value at all,\" Cuban told podcaster Lex Fridman in 2024. '\"People aren't even trying to make operating cap profits, they're just trying to leverage the frothiness of the stock market, that's a bubble. You don't see that right now. \"\n\nCuban took particular notice of the quality of AI companies going public.\n\n\"We're not seeing funky AI companies just go public,\" he said. \"If all of a sudden we see a rush of companies who are skins on other people's models or just creating models to create models that are going public, then yeah, that's probably the start of a bubble.\"\n\nMeta CEO Mark Zuckerberg said AI could become a bubble, but there will only be a crash if companies fail to keep making advancements.\n\n\"If the models keep on growing in capability year-over-year and demand keeps growing, then maybe there is no collapse,\" Zuckerberg told the \"Access\" podcast in September.\n\nZuckerberg said there are risks that the AI boom becomes like the dot-com bubble.\n\n\"There's definitely a possibility, at least empirically, based on past large infrastructure buildouts and how they led to bubbles, that something like that would happen here.\"\n\nFor Meta, Zuckerberg said the real risk is not spending enough.\n\n\"The risk, at least for a company like Meta, is probably in not being aggressive enough rather than being somewhat too aggressive,\" he said.\n\nNvidia CEO Jensen Huang doesn't see a bubble.\n\n\"I don't believe we're in an AI bubble,\" Huang told Bloomberg TV.\n\nHuang said that instead of overspeculation, AI is part of a transition from an old way of computing.\n\n\"We're going through a natural transition from an old computing model based on general purpose computing to accelerated computing,\" he said. \"We also know that AI has become good enough because of reasoning capability, and research capability, its ability to think â€” it's now generating tokens and intelligence that is worth paying for.\"\n\nNvidia is skyrocketing amid AI-fueled hope. In late October, the chipmaker became the world's first $5 trillion market cap company.\n\nHuang said Nvidia is happy to pay for AI for its employees, name-checking Cursor, an AI coding agent, as one of many services for which his company pays.\n\nGoogle CEO Sundar Pichai said there is some \"irrationality\" in the AI boom. He also cautioned that if a bubble were to burst, its blast radius would extend across the private sector.\n\n\"I think no company is going to be immune, including us,\" Pichai told the BBC in November.\n\nComparing the current moment to the Dotcom era, Pichai said that sometimes investment cycles can \"overshoot.\"\n\n\"I expect AI to be the same,\" he said. \"So I think it's both rational and there are elements of irrationality through a moment like this.\"\n\nAmazon founder Jeff Bezos says AI is in a bubble, but not in the way everyone might think.\n\nBezos called the current situation an \"industrial bubble.\" The world's third-richest person said there are similarities now, including the frenzy of investments.\n\n\"The good ideas and the bad ideas. And investors have a hard time in the middle of this excitement, distinguishing between the good ideas and the bad ideas,\" he said in October during a conference in Italy. \"And that's also probably happening today.\"\n\nBezos said that hoopla shouldn't overshadow the reality that \"AI is real\" and will change society.\n\n\"The [bubbles] that are industrial are not nearly as bad,\" Bezos said. \"It can even be good, because when the dust settles and you see who are the winners. Societies benefit from those inventions.\"\n\nJPMorgan Vice Chairman Daniel Pinto said he sees a correction coming.\n\n\"There is probably a correction there,\" Pinto said at a Bloomberg event in November.\n\nPinto said the market is pushing valuations beyond current justifications.\n\n\"In order to justify these valuations, you are considering a level of productivity that, it will happen, but it may not happen as fast as the market is pricing now,\" he said.\n\nLike Altman, OpenAI chairman Bret Taylor says we're in an AI bubble.\n\n\"I think it is both true that AI will transform the economy, and I think it will, like the internet, create huge amounts of economic value in the future,\" Taylor told The Verge in September. \"I think we're also in a bubble, and a lot of people will lose a lot of money.\"\n\nTaylor, who is also CEO of Sierra, also sees some similarities to the dot-com bubble. He also said that some of the internet companies that failed in the 90s were just ahead of their time.\n\n\"Even things like Webvan, there's now, as the internet became more distributed, really healthy businesses like Instacart and DoorDash and others that were built now that the smartphone and the scale of the internet has matured,\" he said. \"So even some of the specific ideas were actually not that bad, but maybe a little early.\"\n\nFormer Google CEO Eric Schmidt said just because it looks like a bubble doesn't mean that it is.\n\n\"I think it's unlikely, based on my experience, that this is a bubble,\" Schmidt said in July during an appearance at the RAISE Summit in Paris. \"It's much more likely that you're seeing a whole new industrial structure.\"\n\nSchmidt said it takes solace in where the hardware and chips markets stand.\n\n\"You have these massive data centers, and Nvidia is quite happy to sell them all the chips,\" he said. \"I've never seen a situation where hardware capacity was not taken up by software.\"\n\nFormer Intel CEO Pat Gelsinger says AI is in a bubble, but it won't pop for \"several years.\"\n\n\"Are we in an AI bubble? Of course. Of course we are,\" Gelsinger told CNBC in October. \"I mean, we're hyped. We're accelerating. We're putting enormous leverage into the system.\"\n\nGelsinger said that businesses are just beginning to reap the benefits of AI.\n\n\"As Jensen (Huang) talked about, and I agree with this, you know that businesses are yet to really start materially benefiting from it,\" he said. \"We're displacing all of the internet and the service provider industry as we think about it today â€” we have a long way to go.\"\n\nAlibaba cofounder Joe Tsai has voiced concerns about the scramble for data centers needed to help power the next generation of AI models.\n\n\"I start to see the beginning of some kind of bubble,\" Tsai told the HSBC Global Investment Summit in March, Bloomberg News reported.\n\nTsai said he's worried the building rush might outpace demand.\n\n\"I start to get worried when people are building data centers on spec,\" he said. \"There are a number of people coming up, funds coming out, to raise billions or millions of capital.\"\n\nHedge fund icon Ray Dalio voiced concerns about a bubble earlier this year, when DeepSeek's rollout led analysts to rethink AI's outlook.\n\n\"Where we are in the cycle right now is very similar to where we were between 1998 or 1999,\" Dalio told the Financial Times in January. \"There's a major new technology that certainly will change the world and be successful. But some people are confusing that with the investments being successful.\"\n\nAt the time, Dalio cited high stock prices and high interest rates. The good news is that Wall Street widely expects the Federal Reserve to cut rates during its September meeting.\n\nBillionaire tech CEO Thomas Siebel said there is \"absolutely\" an AI bubble and that it's \"huge.\"\n\n\"So we have this similar thing going on with generative AI that we've seen with previous technologies,\" Siebel told Fortune in January. \"The market is way, way overvaluing.\"\n\nSiebel, who leads C3.ai, singled out OpenAI in terms of overevaluations.\n\n\"If it disappeared, it wouldn't make any difference in the world,\" he said. \"Nothing would change. I mean, nobody's life would change. No company would change. Microsoft would find something else to power Copilot. There's like 10 other products available that would do it equally as good.\"\n\nAMD CEO Lisa Su says the bubble talk \"is completely wrong.\"\n\n\"For those who are talking about a 'bubble,' I think they're being too narrow in their thinking of, what is the return on investment today or over the next six months,\" Su told Time Magazine in 2024. \"I think you have to look at this technology arc for AI over the next five years, and how does it fundamentally change everything that we do? And I really believe that AI has that potential.\"\n\nNicolai Tangen, who runs the world's biggest sovereign wealth fund, said if AI is a bubble, \"it may not be such a bad bubble.\"\n\nSpeaking to the Financial Times in November, the CEO of Norway's $2 trillion sovereign wealth fund said that AI is a \"pretty hot space\" right now, fueled by hype and a wave of capital. As the technology marks a sweeping societal shift, traditional valuations can be difficult to determine.\n\nTangen said overvaluation isn't entirely negative. The sheer volume of capital rushing into AI will ultimately fund technologies that boost long-term productivity â€” from automation to data processing to new types of AI models.\n\nThe hard part for investors is telling real breakthroughs apart from noise in a landscape still dominated by a few powerful platform companies, he added.\n\nPeter Thiel, the billionaire venture capitalist who cofounded PayPal, indicated recently that he's skeptical of the notion of an AI bubble.\n\n\"My macroeconomic placeholder is that it's going to keep going,\" Thiel said in a December interview with The Spectator, referring to the economic growth driven by the technology.\n\nThiel also said that he's been asked about an AI bubble frequently by people in Europe, which is \"how you know that they're not going to build a lot of AI in Europe.\"\n\n\"There is no other vector of growth in our society, we would be out of our minds not to take it,\" Thiel said. \"I don't think it's big enough to solve the budget deficit, but if the US embraces AI and Europe rejects it, I think the US is in somewhat better shape than Europe is.\"\n\nDespite his projections of future growth, Thiel also said that there are \"all sorts of things that I don't particularly like about the AI revolution,\" including that it's concentrated in a handful of large companies and that AI is \"probably more of a substitute than a complement\" to human labor.\n\n\"It will have a zero-sum feel to a lot of people,\" Thiel said.",
    "readingTime": 11,
    "keywords": [
      "sam altman",
      "jensen huang",
      "ceo sam",
      "google ceo",
      "business leaders",
      "sovereign wealth",
      "openai ceo",
      "voiced concerns",
      "wealth fund",
      "dot-com bubble"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bubble-debate-business-leaders-sam-altman-bill-gates-2025-11",
    "thumbnail_url": "https://i.insider.com/690510b8599d46a4ccc14592?width=1200&format=jpeg",
    "created_at": "2025-12-24T18:17:33.284Z",
    "topic": "finance"
  },
  {
    "slug": "the-10-most-popular-hbr-articles-of-2025",
    "title": "The 10 Most Popular HBR Articles of 2025",
    "description": "The top 10 most-read articles from HBR in 2025 range in topics, with several covering AI and managing amid uncertainty. Others include visualizing strategy, cultivating joy, axing 1:1s, and overcoming the creeping effects of â€œworkslop.â€",
    "fullText": "The 10 Most Popular HBR Articles of 2025 by HBR EditorsDecember 24, 2025PostPostShareSavePrintSummary.Â Â Â Leer en espaÃ±olLer em portuguÃªsPostPostShareSavePrint2025 was a year of uncertaintyâ€”be it about AI, tariffs, the economy, and so much more. In many ways, the most popular articles on HBR.org reflect this sentiment, with pieces about the challenges of decision-making, the future of DEI, and the unintended consequences of AI cracking the top 10.",
    "readingTime": 1,
    "keywords": [
      "popular",
      "articles"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/the-10-most-popular-hbr-articles-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_826093732.jpg",
    "created_at": "2025-12-24T18:17:32.450Z",
    "topic": "business"
  },
  {
    "slug": "ai-ceos-say-automation-with-ai-is-harder-than-it-looks",
    "title": "AI CEOs say automation with AI is harder than it looks",
    "description": "The CEOs of Databricks and Glean say AI can't automate work as easily as expected.",
    "fullText": "Two CEOs running multi-billion-dollar AI companies say AI can't automate work as easily as many leaders had assumed.\n\nGlean CEO Arvind Jain and Databricks CEO Ali Ghodsi said on an episode of the \"Bg2 Pod\" published Tuesday that companies need to temper expectations about how quickly and easily AI can be deployed.\n\nJain said he had tried to automate internal workflows at Glean, including an effort to use AI to automatically identify employees' top priorities for the week and document them for leadership.\n\n\"It has all the context inside the company to make it happen,\" said Jain, adding that he thought AI would \"magically\" do the work. The idea seemed simple, but it hasn't worked.\n\nGlean, an AI startup that helps employees search across internal tools and documents, said in September that it had raised $150 million at a $7.2 billion valuation.\n\nJain pointed to another bet that fell short: building and fine-tuning a custom model for a specific use case within Glean's product. That effort \"didn't really pan out,\" ultimately pushing the company back toward existing foundation models that were easier to deploy, he said.\n\n\"It actually takes much longer than you know to actually generate success,\" he added.\n\nGhodsi, whose company sells a data and AI platform, said: \"It's not just you can just unleash the agents, and it just works.\"\n\nMaking AI useful inside an organization is \"an engineering art,\" requiring careful evaluation, production work, and strong teams to support it, he added.\n\nDatabricks last week announced that it had raised more than $4 billion in a funding round, valuing the company at $134 billion.\n\nBoth CEOs said failed AI projects are common â€” and not necessarily a sign that something has gone wrong.\n\n\"You hear these 95% of projects fail,\" Jain said. \"That's actually what you want.\"\n\n\"When you're actually experimenting with new technology, if all of your projects are failing, that means you're not trying enough,\" he added.\n\nGhodsi has previously said that human oversight will remain essential in AI systems, even as companies deploy more agents and AI automate more tasks.\n\n\"I think in a few years, yes, we'll have agents in many, many places, but there will be a human overseeing and approving every step, and you're on the hook when you approve, when you click, 'OK,'\" he said in June at a conference in San Francisco. \"We all become supervisors.\"\n\nOther tech leaders have echoed that view.\n\nResearch scientist Yoshua Bengio, who is one of the \"godfathers of AI,\" said human qualities will become more important as machines take over tasks.\n\n\"Work on the beautiful human being that you can become. I think that that part of ourselves will persist even if machines can do most of the jobs,\" Bengio said on an episode of \"The Diary of a CEO\" podcast published last week.\n\n\"The human touch is going to, I think, take more and more value, as the other skills become more and more automated,\" he added.",
    "readingTime": 3,
    "keywords": [
      "jain",
      "human",
      "automate",
      "glean",
      "ghodsi",
      "agents",
      "projects",
      "you're",
      "easily",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ceo-databricks-glean-ai-automation-overestimate-ali-ghodsi-arvind-jain-2025-12",
    "thumbnail_url": "https://i.insider.com/694b8c2b64858d02d2175ac8?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.433Z",
    "topic": "finance"
  },
  {
    "slug": "were-cofounders-who-left-amazon-to-build-our-own-startup-we-learned-the-hard-way-why-big-tech-habits-dont-always",
    "title": "We're cofounders who left Amazon to build our own startup. We learned the hard way why Big Tech habits don't always translate.",
    "description": "Former Amazon employees detail their journey launching an AI startup, and explain how they adapted to startup life.",
    "fullText": "This as-told-to essay is based on conversations with Shalini Aggarwal, a 50-year-old CEO in San Jose, California, and Andy Ratsirason, a 37-year-old CTO. The two left Amazon at different times and reconnected as cofounders of Tenfali, an AI startup.\n\nThey share the main processes they had to unlearn in order to successfully grow their startup. The following has been edited for length and clarity.\n\nShalini Aggarwal: Andy and I began working together in 2015, after I relocated to the US from India. He was a dev engineer, and I worked on the product and program execution side.\n\nAndy Ratsirason: I joined Amazon for the first time in 2014 because I wanted to be part of the Silicon Valley ecosystem. I always wanted to be an entrepreneur, so I tried to tailor my career to suit that goal. I left Amazon, came back in 2020, and left again in 2023.\n\nAfter I left for the last time, I made multiple pivots in founding a startup. I realized I needed someone else to join my team. Shalini started showing up regularly on my LinkedIn feed, liking and commenting on posts about startups and taking risks, so I reached out to her. She had just left Amazon, and we reunited to cofound Tenafli.\n\nAggarwal: We quickly realized that we took a lot of systems and tools for granted when we were in an enterprise company. The startup world is completely different; here, we have to build from scratch, and there was a lot about our mindset we had to unlearn.\n\nAggarwal: I stayed at Amazon until 2024, and my last nine months were spent working on AI projects, specifically on music recommendations.\n\nRatsirason: In 2023, I was almost three years into my return to Amazon, and I had a choice: either stay comfortable with those Big Tech paychecks or take a leap and launch my own startup. I submitted my resignation in February and then began to think about what was next.\n\nAggarwal: My decision to leave Amazon was more of a gradual process. During the COVID pandemic, my father retired, and we lost my mom. I could see how lonely my father was, and the biggest challenge was how to fill his days. That planted the seed.\n\nThrough working on personalized AI recommendations, I thought of a product that could serve as an AI companion for older adults, providing personalized recommendations and scheduling activities based on their typical daily routines.\n\nMy 50th birthday was coming up, and the AI boom was happening; if I didn't take the leap then, I knew I would never. In September 2024, I put in my two weeks' notice and left Amazon.\n\nRatsirason: At Amazon, I didn't really think about why we were building a product or if people would use it. The 'build-first' mindset meant focusing solely on building a good product, knowing the customer was already there.\n\nA clear moment that this mindset wouldn't work at an early-stage startup came after we spent months building, and launch day arrived, almost nobody showed up organically for a few weeks. That was the wake-up call: shipping isn't the finish line when we didn't have demand.\n\nAfter that, we shifted to doing customer conversations earlier and running small distribution tests, including waitlists, partnerships, and community posts, before over-investing in product.\n\nAggarwal: We applied and were accepted into several startup resource programs, including AWS Activate, Nvidia Inception, and Google's Cloud Credits program.\n\nRatsirason: We received a few thousand in AWS credits, but before we realized it, we lost almost all of the credits in the first two months. We over-provisioned capacity, and during AI testing, we left a few resources running longer than intended, which quietly accumulated costs over time.\n\nOnce we noticed the issue, we set up AWS budget alerts, added cost monitoring, made shutdowns part of our testing checklist, and simplified certain aspects of the architecture to match our stage.\n\nTo reduce costs further, we also bought a small local machine to run some of our AI experiments on, so we only use the cloud when we truly need it for scale, managed services, or production.\n\nAggarwal: The time we save with AI enables us to allocate our energy to attending summits, forums, and programs, where we can learn about the work of others in the field. We also spend more time with prospective customers doing interviews.\n\nRatsirason: We used to spend hours reading long articles and research, and trying to keep up with the latest news in the field. The cycle felt heavy and slow, pulling us away from customer conversations and shipping.\n\nWe now use AI to scan a large set of content, surface the most relevant ideas for us, and summarize the few pieces worth reading. Having to be frugal, we've learned to spend only where learning happens. Talk to users first, then build the smallest thing that can prove value.\n\nRatsirason: AI acts as a junior engineer, handling a lot of the coding for us with the requirements we set up.\n\nAggarwal: It's also taught us where we won't need to scale. I know I don't need to hire a user interface designer. If I understand the requirements of something, I can quickly draft it with the help of AI and receive feedback on it myself.\n\nRatsirason: A few years ago, launching a usable version of our product, Agefully, would have required significantly more capital and head count. We just need two engineers and subscriptions. I'm grateful to be part of this AI era.\n\nAggarwal: We've seen at scale how things work and what processes we can implement to avoid chaos later on. At the same time, the biggest disadvantage has been overcoming the mindset that tools and infrastructure are readily available. Until we learned how to work through that, we weren't allocating our energy properly.\n\nRatsirason: Coming from Amazon, the name itself has some positive weight, but it can also work against us. People might assume that since we worked at a big company, we don't know how to run a small startup because we don't have a lot of resources.\n\nThe hardest part was overcoming the fear of shipping something imperfect. Coming from Big Tech, we were accustomed to high-polish expectations and assumed anything less would turn users away. We learned that in early-stage startups, the real risk isn't rough edges, it's building something people don't need.\n\nDo you have a founder story to share? Contact this reporter, Agnes Applegate, at aapplegate@businessinsider.com.",
    "readingTime": 6,
    "keywords": [
      "customer conversations",
      "big tech",
      "ratsirason we",
      "startup",
      "product",
      "mindset",
      "don't",
      "amazon",
      "realized",
      "recommendations"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/left-amazon-to-launch-startup-things-we-had-to-unlearn-2025-12",
    "thumbnail_url": "https://i.insider.com/694989c6832e0ef1ead6ac34?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.266Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-scaling-debate-what-the-industrys-top-minds-are-saying",
    "title": "The AI scaling debate: What the industry's top minds are saying",
    "description": "Geoffrey Hinton, the \"Godfather of AI,\" said he's \"not convinced\" the age of AI scaling is over, like his former student Ilya Sutskever recently said.",
    "fullText": "Not everyone in AI is ready to declare the end of the age of scaling.\n\n\"I'm not convinced it's completely over,\" Geoffrey Hinton, the \"Godfather of AI,\" recently told Business Insider, weighing in on one of the hottest debates in AI circles this year.\n\nHinton is aware that OpenAI cofounder Ilya Sutskever, one of his former students, said last month that the pendulum of AI development is swinging back toward research â€” and away from companies simply making breakthroughs by scaling, or acquiring more compute and more chips.\n\n\"Is the belief really: 'Oh, it's so big, but if you had 100x more, everything would be so different?' It would be different, for sure. But is the belief that if you just 100x the scale, everything would be transformed? I don't think that's true,\" Sutskever said on an episode of the \"Dwarkesh Podcast.\"\n\n\"So it's back to the age of research again, just with big computers,\" added Sutskever, who is now running his own AI startup.\n\nHinton said there will always be a need for more data. (Another issue facing scaling is the finite amount of high-quality data.) He predicted that the large chatbots will start generating their own data, as Google DeepMind's AlphaGo and AlphaZero do on a much smaller scale to master the board game Go.\n\n\"Nobody's worried about a lack of data because it plays against itself and generates data that way,\" Hinton said of the early program. \"And the equivalent for a language model is when it starts reasoning and saying, 'Look, I believe these things and these things imply that thing, but I don't believe that thing, so I'd better change something somewhere.' And by doing reasoning to check the consistency of his own beliefs, it can generate a lot more data.\"\n\nScaling is at the very core of Big Tech's capex spending spree, a bet based on the belief that by acquiring more compute or training data, AI models will continue to grow smarter and more advanced.\n\nIncreasingly, some AI leaders have expressed uncertainty about making their future bets based on their trust in scaling. Alexandr Wang, now head of Meta's superintelligence division, said in 2024 that scaling is \"the biggest question in the industry.\"\n\nYann LeCun, who worked with Hinton on pioneering AI research, has also challenged the extent of the scale doctrine.\n\n\"You cannot just assume that more data and more compute means smarter AI,\" LeCun said in April when he was still Meta's chief AI scientist. Like Sutskever, LeCun has since launched his own startup.\n\nSutskever said scaling has been attractive because it allows companies to make a \"very low-risk way\" bet on AI advancements.\n\nIn contrast, Google DeepMind CEO Demis Hassabis said that scaling laws could ultimately unlock the biggest and most elusive prize in AI: artificial general intelligence, or AGI.\n\n\"The scaling of the current systems, we must push that to the maximum, because at the minimum, it will be a key component of the final AGI system,\" Hassabis said at the Axios' AI+ Summit in December. \"It could be the entirety of the AGI system.\"",
    "readingTime": 3,
    "keywords": [
      "agi system",
      "scaling",
      "hinton",
      "it's",
      "research",
      "compute",
      "belief",
      "scale",
      "back",
      "acquiring"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-scaling-debate-geoffrey-hinton-ilya-sutskever-alexandr-wang-lecun-2025-12",
    "thumbnail_url": "https://i.insider.com/694a8f2264858d02d2174db6?width=1200&format=jpeg",
    "created_at": "2025-12-24T12:22:45.260Z",
    "topic": "finance"
  },
  {
    "slug": "the-semantic-layer-is-dead-long-live-the-wiki",
    "title": "The semantic layer is dead. Long live the wiki",
    "description": "Most â€œAI on dataâ€ programs are just semantic-layer maximalism with a new paint\njob: if we can finally standardize meaning, the model will finally reason\naccurately.",
    "fullText": "Most â€œAI on dataâ€ programs are just semantic-layer maximalism with a new paint job: if we can finally standardize meaning, the model will finally reason accurately.\n\nIt wonâ€™t. A perfect semantic layer is neither sufficient nor operable. The bottleneck is organizational semantics at runtime, not SQL.\n\nSemantic layers are designed as a governed interface for humans to retrieve numbers, not to inhabit meaning. They capture the clean, declarative surface area of truth and omit the messy parts that determine whether an answer is correct.\n\nThe majority of what makes metrics usable is missing:\n\nMeaning is contextual, not global. The same metric name can legitimately refer to different implementations across product lines, geos, channels, or lifecycle stages. A semantic layer encourages flattening this into one â€œdefinitionâ€ under the guise of governance.\n\nDefinitions are political and time-bound. Ownership sits with the business, priorities shift quarterly, and what â€œcountsâ€ changes accordingly. Static interfaces pretend meaning is stable when itâ€™s negotiated.\n\nOperational intelligence is non-declarative. â€œHow do I interpret this?â€ is rarely answered by a formula. You need causal folk models, known anomaly patterns, failure modes, and the â€œif X then check Yâ€ heuristics that live in experienced operators.\n\nTemporal continuity matters. Most metrics have version histories, instrumentation changes, backfills, silent breaks, and embarrassing periods everyone learned to discount. That context is mostly narrative, not schema.\n\nRelationships are about trade-offs, not joins. Real decision-making depends on tensions (optimize A, damage B), guardrails, and strategic intent. Semantic layers describe entities; they donâ€™t encode the organizationâ€™s trade-off graph.\n\nStakeholder meaning diverges by role. â€œRevenueâ€ for the CFO and â€œrevenueâ€ for the Sales VP are not the same question even when the number is the same. A single canonical definition is a UI convenience masquerading as epistemology.\n\nâ€œNow what?â€ is the point. An AI that returns a metric without the response protocol is doing the easy half. Runbooks and escalation paths are part of meaning.\n\nA semantic layer can be perfect and still produce garbage decisions because itâ€™s optimized for consistency over situated correctness.\n\nEven if you wanted to cram the missing knowledge into a semantic layer, the maintenance model collapses under its own sociology.\n\nCentralized semantic layers are planned cities: beautiful in the blueprint, empty in practice. Semantics evolve at the edges, among the people who ship, sell, operate, and get paged. The center cannot keep up, and it cannot compel truth.\n\nIn hindsight, failure modes are predictable:\n\nThe experts who can write it wonâ€™t. Deep metric knowledge is held by high-leverage operators; their marginal hour is never best spent authoring centralized documentation that mostly helps strangers.\n\nCentral teams are paced by infrastructure, not decisions. The business iterates weekly; the data platform iterates on quarters. Any interface maintained on platform cadence becomes stale, then distrusted, then ignored.\n\nTight coupling blocks shipping. If semantic context lives â€œin the data layer,â€ every AI feature becomes dependent on an always-incomplete canonicalization project. Data is never â€œdone,â€ so AI velocity becomes permanently hostage.\n\nIncentives are inverted. Producers donâ€™t benefit from documenting; consumers canâ€™t document correctly; owners of context are neither staffed nor accountable for semantic hygiene in a centralized model.\n\nCold-start kills adoption. Semantic layers only feel useful after critical mass; reaching critical mass requires upfront drudgery with delayed payoff. Organizations donâ€™t fail because theyâ€™re lazy; they fail because the payoff horizon is mispriced.\n\nSo you get shadow metrics, spreadsheet truth, ad hoc definitions, and a semantic layer that exists primarily as a compliance artifact.\n\nWe know what system reliably captures messy, contested knowledge at global scale without centrally curated ontologies - a wiki.\n\nWikipedia works because itâ€™s a sociotechnical pattern that fits reality:\n\nYour organizationâ€™s meaning is closer to Wikipedia than to Encyclopedia Britannica. Treat it that way.\n\nStop trying to make the semantic layer the source of meaning. Make it a compiled artifact derived from a living knowledge substrate.\n\nBuild an internal wiki where operators and business analysts can capture what they already know. Then put the wiki in the loop with AI. The key point here is not documentation for the sake of documentation; it's feedback coupling.\n\nThis creates a virtuous cycle: usage drives coverage â†’ coverage improves AI â†’ Â improved AI increases usage â†’ and the knowledge base converges because it is continuously exercised under real demand.\n\nWe can still have governed models, dimensional abstractions, and metric layers. But they should be downstream, being generated or validated against the wiki, instead of being treated as the place meaning lives.\n\nThis inversion matters because it reframes the work from â€œbuild the perfect semantic layerâ€ to â€œcapture organizational meaning where it actually exists, then compile interfaces from it.â€\n\nThe wiki becomes the organizationâ€™s brain: a living memory of intent, interpretation, exceptions, and procedures. AI becomes the octopus arms: executing queries, generating analyses, navigating ambiguity, and feeding new information back into the brain.\n\nIf your AI on data initiative isn't gaining adoption, itâ€™s probably not because your semantic layer is imperfect. Itâ€™s because youâ€™re trying to encode a living, political, temporal, role-dependent system of meaning into a centralized, static interface.",
    "readingTime": 5,
    "keywords": [
      "failure modes",
      "critical mass",
      "semantic layer",
      "semantic layers",
      "perfect semantic",
      "itâ€™s",
      "knowledge",
      "wiki",
      "metric",
      "centralized"
    ],
    "qualityScore": 1,
    "link": "https://promptql.io/blog/semantic-layer-dead-long-live-wiki",
    "thumbnail_url": "https://hasura.io/blog/content/images/2025/12/semantic-layer-wiki-banner-1.png",
    "created_at": "2025-12-24T12:22:43.829Z",
    "topic": "tech"
  },
  {
    "slug": "googlebacked-fleet-tracking-firm-motive-files-publicly-for-ipo",
    "title": "Google-Backed Fleet Tracking Firm Motive Files Publicly for IPO",
    "description": "Motive Technologies Inc. filed publicly for an initial public offering, with the artificial intelligence-enabled fleet management software firm disclosing both growing revenue and net losses.",
    "fullText": "MarketsBy Matthew GriffinSaveMotive Technologies Inc. filed publicly for an initial public offering, with the artificial intelligence-enabled fleet management software firm disclosing both growing revenue and net losses. The company, which counts Alphabet Inc.â€™s Google Ventures and Kleiner Perkins among its backers, recorded a net loss of $138.5 million on revenue of $327.3 million in the nine months ended Sept. 30, according to a filing Tuesday with the US Securities and Exchange Commission. That compares with a net loss of $113.9 million on revenue of $268.9 million in the same period last year.",
    "readingTime": 1,
    "keywords": [
      "net loss",
      "revenue"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2025-12-23/google-backed-fleet-tracking-firm-motive-files-publicly-for-ipo",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iij4a.hcaf98/v1/1200x801.jpg",
    "created_at": "2025-12-24T06:19:45.771Z",
    "topic": "finance"
  },
  {
    "slug": "essential-education-chatgpt-prompts-for-best-studying-practices",
    "title": "Essential Education ChatGPT Prompts for Best Studying Practices",
    "description": "This guide contains 10 professionally-structured AI prompts to make studying more engaging and inter",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://tools.eq4c.com/ai-prompts/10-essential-education-chatgpt-prompts-for-best-studying-practices/",
    "thumbnail_url": "https://tools.eq4c.com/wp-content/uploads/2025/12/10-essential-education-chatgpt-prompts-for-best-studying-practices-1024x683.webp",
    "created_at": "2025-12-24T06:19:37.203Z",
    "topic": "science"
  },
  {
    "slug": "nvidia-debuts-nemotron-3-family-of-open-models",
    "title": "Nvidia Debuts Nemotron 3 Family of Open Models",
    "description": "The Nemotron 3 family of open models â€” in Nano, Super and Ultra sizes â€” introduces the most efficient family of open models with leading accuracy for building agentic AI applications.",
    "fullText": "NVIDIA today announced the NVIDIA Nemotronâ„¢ 3 family of open models, data and libraries designed to power transparent, efficient and specialized agentic AI development across industries.\n\nThe Nemotron 3 models â€” with Nano, Super and Ultra sizes â€” introduce a breakthrough hybrid latent mixture-of-experts (MoE) architecture that helps developers build and deploy reliable multi-agent systems at scale.\n\nAs organizations shift from single-model chatbots to collaborative multi-agent AI systems, developers face mounting challenges, including communication overhead, context drift and high inference costs. In addition, developers require transparency to trust the models that will automate their complex workflows. Nemotron 3 directly addresses these challenges, delivering the performance and openness customers need to build specialized, agentic AI.\n\nâ€œOpen innovation is the foundation of AI progress,â€ said Jensen Huang, founder and CEO of NVIDIA. â€œWith Nemotron, weâ€™re transforming advanced AI into an open platform that gives developers the transparency and efficiency they need to build agentic systems at scale.â€\n\nNVIDIA Nemotron supports NVIDIAâ€™s broader sovereign AI efforts, with organizations from Europe to South Korea adopting open, transparent and efficient models that allow them to build AI systems aligned to their own data, regulations and values.\n\nEarly adopters, including Accenture, Cadence, CrowdStrike, Cursor, Deloitte, EY, Oracle Cloud Infrastructure, Palantir, Perplexity, ServiceNow, Siemens, Synopsys and Zoom, are integrating models from the Nemotron family to power AI workflows across manufacturing, cybersecurity, software development, media, communications and other industries.\n\nâ€œNVIDIA and ServiceNow have been shaping the future of AI for years, and the best is yet to come,â€ Bill McDermott, chairman and CEO of ServiceNow. â€œToday, weâ€™re taking a major step forward in empowering leaders across all industries to fast-track their agentic AI strategy. ServiceNowâ€™s intelligent workflow automation combined with NVIDIA Nemotron 3 will continue to define the standard with unmatched efficiency, speed and accuracy.â€\n\nAs multi-agent AI systems expand, developers are increasingly relying on proprietary models for state-of-the-art reasoning while using more efficient and customizable open models to drive down costs. Routing tasks between frontier-level models and Nemotron in a single workflow gives agents the most intelligence while optimizing tokenomics.\n\n\"Perplexity is built on the idea that human curiosity will be amplified by accurate AI built into exceptional tools, like AI assistants,\" said Aravind Srinivas, CEO of Perplexity. â€œWith our agent router, we can direct workloads to the best fine-tuned open models, like Nemotron 3 Ultra, or leverage leading proprietary models when tasks benefit from their unique capabilities â€” ensuring our AI assistants operate with exceptional speed, efficiency and scale.â€\n\nThe open Nemotron 3 models enable startups to build and iterate faster on AI agents and accelerate innovation from prototype to enterprise deployment. General Catalyst, Mayfield and Sierra Venturesâ€™Â portfolio companies are exploring Nemotron 3 to build AI teammates that support human-AI collaboration.\n\nâ€œNVIDIAâ€™s open model stack and the NVIDIA Inception program give early-stage companies the models, tools and a cost-effective infrastructure to experiment, differentiate and scale fast,â€ said Navin Chaddha, managing partner at Mayfield. â€œNemotron 3 gives founders a running start on building agentic AI applications and AI teammates, and helps them tap into NVIDIAâ€™s massive installed base.â€\n\nNemotron 3 Reinvents Multi-Agent AI With Efficiency and Accuracy \n\nThe Nemotron 3 family of MoE models includes three sizes:\n\nAvailable today, Nemotron 3 Nano is the most compute-cost-efficient model, optimized for tasks such as software debugging, content summarization, AI assistant workflows and information retrieval at low inference costs. The model uses a unique hybrid MoE architecture to deliver gains in efficiency and scalability.\n\nThis design achieves up to 4x higher token throughput compared with Nemotron 2 Nano and reduces reasoning-token generation by up to 60%, significantly lowering inference costs. With a 1-million-token context window, Nemotron 3 Nano remembers more, making it more accurate and better capable of connecting information over long, multistep tasks.\n\nArtificial Analysis, an independent organization that benchmarks AI, ranked the model as the most open and efficient among models of the same size, with leading accuracy.\n\nNemotron 3 Super excels at applications that require many collaborating agents to achieve complex tasks with low latency. Nemotron 3 Ultra serves as an advanced reasoning engine for AI workflows that demand deep research and strategic planning.\n\nNemotron 3 Super and Ultra use NVIDIAâ€™s ultraefficient 4-bit NVFP4 training format on the NVIDIA Blackwell architecture, significantly cutting memory requirements and speeding up training. This efficiency allows larger models to be trained on existing infrastructure without compromising accuracy relative to higher-precision formats.\n\nWith the Nemotron 3 family of models, developers can choose the open model that is right-sized for their specific workloads, scaling from dozens to hundreds of agents while benefiting from faster, more accurate long-horizon reasoning for complex workflows.\n\nNew Open Tools and Data for AI Agent Customization\n\nNVIDIA also released a collection of training datasets and state-of-the-art reinforcement learning libraries available to anyone building specialized AI agents.\n\nThree trillion tokens of new Nemotron pretraining, post-training and reinforcement learning datasets supply the rich reasoning, coding and multistep workflow examples needed to create highly capable, domain-specialized agents. The Nemotron Agentic Safety Dataset provides real-world telemetry to help teams evaluate and strengthen the safety of complex agent systems.\n\nTo accelerate development, NVIDIA released the NeMo Gym and NeMo RL open-source libraries, which provide the training environments and post-training foundation for Nemotron models, along with NeMo Evaluator to validate model safety and performance. All tools and datasets are now available on GitHub and Hugging Face.\n\nNemotron 3 is supported by LM Studio, llama.cpp, SGLang and vLLM. In addition, Prime Intellect and Unsloth are integrating NeMo Gymâ€™s ready-to-use training environments directly into their workflows, giving teams faster, easier access to powerful reinforcement learning training.\n\nGet Started With NVIDIA Open Models\n\nNemotron 3 Nano is available today on Hugging Face and through inference service providers including Baseten, DeepInfra, Fireworks, FriendliAI, OpenRouter and Together AI.\n\nNemotron is offered on enterprise AI and data infrastructure platforms, including Couchbase, DataRobot, H2O.ai, JFrog, Lambda and UiPath. For customers on public clouds, Nemotron 3 Nano will be available on AWS via Amazon Bedrock (serverless) as well as supported on Google Cloud, CoreWeave, Crusoe, Microsoft Foundry, Nebius, Nscale and Yotta soon.\n\nNemotron 3 Nano is available as an NVIDIA NIMâ„¢ microservice for secure, scalable deployment anywhere on NVIDIA-accelerated infrastructure for maximum privacy and control.\n\nNemotron 3 Super and Ultra are expected to be available in the first half of 2026.",
    "readingTime": 6,
    "keywords": [
      "moe architecture",
      "reinforcement learning",
      "nemotron family",
      "nemotron nano",
      "training environments",
      "specialized agentic",
      "complex workflows",
      "proprietary models",
      "nvidia nemotron",
      "nemotron ultra"
    ],
    "qualityScore": 1,
    "link": "https://nvidianews.nvidia.com/news/nvidia-debuts-nemotron-3-family-of-open-models",
    "thumbnail_url": "https://s3.amazonaws.com/cms.ipressroom.com/219/files/202512/693caf4b3d63322df1c3df36_nemotron-3-release/nemotron-3-release_9946879e-d8aa-4599-be16-2a2020d7fbc2-prv.jpg",
    "created_at": "2025-12-24T06:19:35.872Z",
    "topic": "tech"
  },
  {
    "slug": "modelyaml-is-an-open-standard-for-defining-crossplatform-composable-ai-models",
    "title": "Model.yaml is an open standard for defining cross-platform, composable AI models",
    "description": "An open description standard for defining cross-platform, multi format AI models.",
    "fullText": "AI models are often available in multiple formats and variants, while different machines support diverse engines such as llama.cpp and MLX. This diversity can make it challenging for end users to reason about the choices available to them.\n\nmodel.yaml addresses this by providing a standard description format that defines a model, along with multiple possible sources (potentially in different formats) of a model. It delegates the responsibility of determining the most suitable variant to download and the appropriate engine to use to the client program (e.g. LM Studio), while allowing showing simplified information to the user.\n\nModels in LM Studio's model catalog are all defined using model.yaml.\n\nThe model.yaml format defines a structured way to specify AI models, their concrete sources, configurations, and metadata. Feel free to contribute to this open standard as it evolves.\n\n You can find a TypeScript implementation of the specification in lmstudio-js.\n\nThe identifier for the model in the format organization/name. This determines where the model will be published and how it's referenced.\n\nDefines the underlying model(s) that this virtual model points to. Can be either:\n\nOverrides metadata for the model, which can differ from the base model. This helps platforms understand the model's capabilities.\n\nThe domain type of the model (e.g., llm, embedding).\n\nArray of model architecture names (e.g., llama, qwen2).\n\nArray of format types the model supports (e.g., gguf, safetensors).\n\nHuman-readable parameter size labels (e.g., 1B, 7B).\n\nMinimum RAM required to load the model in bytes.\n\nArray of supported context window sizes.\n\nWhether the model supports tool use (true, false, or mixed).\n\nWhether the model supports processing images (true, false, or mixed).\n\nBuilt-in configurations for the model, applying preset configurations for loading or runtime operation.\n\nUser-configurable options that affect the model's behavior. Each field can trigger effects like changing variables or modifying the system prompt.\n\nUnique identifier for the field.\n\nHuman-readable name shown in UI.",
    "readingTime": 2,
    "keywords": [
      "model supports",
      "format",
      "models",
      "model.yaml",
      "defines",
      "configurations",
      "array",
      "formats",
      "standard",
      "metadata"
    ],
    "qualityScore": 1,
    "link": "https://modelyaml.org",
    "thumbnail_url": "https://files.lmstudio.ai/modelyaml-card.jpg",
    "created_at": "2025-12-24T06:19:35.497Z",
    "topic": "tech"
  },
  {
    "slug": "mcptotal-run-mcp-servers-in-isolated-containers-instead-of-locally",
    "title": "MCPTotal â€“ Run MCP servers in isolated containers instead of locally",
    "description": "MCP Made Easy and secure - Onboard AI tools in a click.",
    "fullText": "Run MCP servers securely in the cloud, with security teams governing access, enforcing policies, managing identities and monitoring every action.\n\nToday, developers often download and run untrusted MCP servers on their machines, wiring them directly to third-party accounts with plaintext API keys scattered across JSON files. Security teams have no real visibility or governance, they can't see which MCP servers are in use, what the agents are doing, what data is being passed, or how credentials are handled.\n\nAnyone can install an MCP server. They can be malicious, vulnerable or compromise the machine or leak data.\n\nCredentials are stored locally in textual files and env vars, copied between tools and impossible to manage and protect.\n\nSecurity teams lack visibility of MCP usage. There's no policy layer, no standardized approvals and no unified audit trail.\n\nPrompt injections and new MCP-specific attacks can exploit agents that interact with untrusted MCP servers, exfiltrating data or issuing unsafe actions.\n\nA practical security leader's guide to understanding and securing MCP implementations in your organization.\n\nMCPTotal provides a secure cloud runtime for MCP servers, a built-in MCP firewall, a centralized vault for credentials and a governance plane for your security team. Developers keep their workflows, while security gets the controls and visibility they need.\n\nManage, run and monitor your MCP servers in a secure, sandboxed environment.\n\nProtect AI workflows interacting with internal and external MCP servers.\n\nContinuously monitor and enforce policies for AI tool utilization.\n\nRun faster with MCP while MCPTotal takes care of the MCP security out of the box. Use your existing tools and agents â€” just change the endpoint URL.\n\nLaunch MCP servers in the cloud in seconds through an easy-to-use GUI. Say goodbye to hunting for and running untrusted servers on your local machine.\n\nAll your API keys, credentials, environment variables, and other sensitive data are securely stored and encrypted in our Vault, which is designed to be breach-resistant and accessible only to you.\n\nConnect MCPTotal-hosted servers to your agent (e.g. Cursor or any MCP-compatible tools). We support OAuth and other authentication schemes.\n\nEnjoy our built-in agentic chat to test things faster, it is smart and supports passing files from one server another.\n\nMCPTotal gives CISOs and security leaders the governance and controls they need to safely approve and scale MCP usage across the organization.\n\nRun a one-click discovery scan for all workstations and get an MCP posture management security report, see where MCP is being used, which clients and servers are in play and what problems should be remediated.\n\nAll MCP servers operate in isolated sandboxes, with their traffic and domains continuously monitored at runtime. MCPTotal scans each server's code to guarantee a secure and curated catalog.\n\nDefine which MCP servers and tools are allowed, configure which auth schemes can be used, set security thresholds for automatic MCP servers approvals and connect your SIEM to get audit events.\n\nGet the SLA, support and compliance certifications you require, as well as SSO/SCIM integration or a self-hosted solution.\n\nEverything you need to know about MCP security and our platform",
    "readingTime": 3,
    "keywords": [
      "api keys",
      "mcp usage",
      "mcp servers",
      "untrusted mcp",
      "security teams",
      "credentials",
      "tools",
      "cloud",
      "files",
      "visibility"
    ],
    "qualityScore": 1,
    "link": "https://go.mcptotal.io/",
    "thumbnail_url": "https://go.mcptotal.io/images/mcptotal-og.jpg",
    "created_at": "2025-12-24T06:19:33.982Z",
    "topic": "tech"
  },
  {
    "slug": "eze-ai-startup-roadmap-copilot-day-4-update",
    "title": "Eze â€“ AI startup roadmap coâ€‘pilot (Day 4 update)",
    "description": "Your AI startup mentor. Turn ideas into execution plans in minutes.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://eze.lovable.app/",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/87016dff-4507-485d-b64e-274e314de43a/id-preview-b85e1219--0d368741-f189-471d-ac9d-a80dafb600ed.lovable.app-1766452125567.png",
    "created_at": "2025-12-24T06:19:33.955Z",
    "topic": "tech"
  },
  {
    "slug": "apple-spent-2025-setting-itself-up-for-the-future-and-its-biggest-moves-werent-about-ai",
    "title": "Apple spent 2025 setting itself up for the future â€” and its biggest moves weren't about AI",
    "description": "Apple's 2025 helped set up its future.",
    "fullText": "Itâ€™s been quite a year for Apple (AAPL). The company reported record revenue on the back of strong iPhone sales. Its Services business continued its impressive growth, hitting $109.2 billion in sales. And its market capitalization topped $4 trillion, joining Nvidia (NVDA) as just the second company to reach the milestone.\n\nBut the company is also contending with major changes amid its executive ranks. CFO Jeff Williams retired â€” he was previously considered the top choice to take up the mantle of CEO after Tim Cook eventually steps down.\n\nHead of government affairs Lisa Jackson and general counsel Kate Adams are retiring in late January and late 2026, respectively.\n\nAnd then there's AI chief John Giannandrea and design vice president Alan Dye. Giannandrea is retiring and turning Apple's AI efforts over to Amar Subramanya, who previously worked on AI initiatives at Google (GOOGL, GOOG) and Microsoft (MSFT).\n\nDye, meanwhile, left Apple to lead Meta (META) Reality Labs' new design studio.\n\nAll of this comes as Cook is reportedly preparing senior vice president of hardware engineering John Ternus to take over as CEO when he departs.\n\nIt all adds up to an Apple in flux as it transforms itself for a post-Cook era. According to the Financial Times, Cook could step down as soon as early 2026. Bloomberg's Mark Gurman, meanwhile, said thereâ€™s still no firm timeline for when Cook will leave his post.\n\nRegardless of exact timing, Apple will eventually have to say goodbye to Cook, and 2025 helped the company set itself up for its biggest change in years.\n\nCook, who joined Apple in 1998, took over as CEO 14 years ago following the death of founder Steve Jobs. Jobs turned around an ailing Apple when he returned to the company in 1997 after being fired in 1985. He subsequently released a string of groundbreaking products, including the iPod and iPhone, which continues to bring in the majority of Apple's revenue.\n\nCook has carried that success forward during his time at the company's helm, overseeing the debut of the Apple Watch and AirPods, as well as the explosion of Apple's Services business. He has also pushed Apple to use its own chips in its products, giving the company more control over the design and functionality of its devices.\n\nThat, coupled with Cook's deft abilities as a negotiator, helped Apple weather a series of crises, including showdowns with the US Department of Justice, the COVID-19 pandemic, and President Trump's ongoing trade war with China. Trump eventually exempted smartphones and certain other tech products from his tariffs on Chinese goods.",
    "readingTime": 3,
    "keywords": [
      "services business",
      "vice president",
      "eventually",
      "design",
      "products",
      "apple",
      "cook",
      "revenue",
      "iphone",
      "sales"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/apple-spent-2025-setting-itself-up-for-the-future--and-its-biggest-moves-werent-about-ai-211525196.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/xwQLfyrEuvvS8dnq_Jgwhw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-01/4aae2830-dda3-11ef-9f5f-9631a8d45eb7",
    "created_at": "2025-12-24T06:19:30.225Z",
    "topic": "finance"
  },
  {
    "slug": "swiftzilla-rag-with-official-apple-docs-for-swift-agents-mcpcursorclaude",
    "title": "SwiftZilla â€“ RAG with Official Apple Docs for Swift Agents (MCP/Cursor/Claude)",
    "description": "SwiftZilla is the ultimate RAG API for Apple Development. Give your AI agents instant access to official Swift docs, recipes, and evolution proposals.",
    "fullText": "The only RAG API built for Apple Development. Give your AI instant access to 100,000+ pages of\n official docs, recipes, and evolution proposals.\n\nGeneral purpose models like Claude, GPT, and Gemini struggle with the nuances of Swift 6.0,\n SwiftUI\n macros, and the latest concurrency patterns.\n\nGeneral purpose models miss the nuances. SwiftZilla is built for Apple development.\n\nWatch how it handles Apple Foundation Models in seconds.\n\nWe index the entire Apple Developer ecosystem so you don't have to.\n\nComplete indexing of Apple Developer Documentation and Swift API Design Guidelines.\n\nSearchable knowledge from the engineers who built the frameworks.\n\nSupports both SSE and STDIO transports. Works\n out-of-the-box with Cursor, Windsurf, Claude Desktop, or your custom agent.\n\nJoin developers building the next generation of AI tools.\n\nPerfect for testing and small projects.\n\nLess than a coffee for unlimited Swift mastery.\n\nYes! SwiftZilla provides a standard Model Context Protocol (MCP) server that you can add\n directly to Cursor, Windsurf, or any MCP-compatible editor.\n\nWe re-index our sources daily. When Apple releases a new beta or updates their docs,\n SwiftZilla knows about it within 24 hours.\n\nAbsolutely. You can manage your subscription directly from the dashboard and cancel with one\n click.",
    "readingTime": 1,
    "keywords": [
      "apple development",
      "purpose models",
      "docs",
      "nuances",
      "directly",
      "swift",
      "swiftzilla",
      "claude",
      "developer",
      "cursor"
    ],
    "qualityScore": 0.95,
    "link": "https://swiftzilla.dev",
    "thumbnail_url": "https://swiftzilla.dev/assets/voxel_swift.png",
    "created_at": "2025-12-24T00:56:10.126Z",
    "topic": "tech"
  },
  {
    "slug": "americans-have-mixed-views-of-ai-and-an-appetite-for-regulation",
    "title": "Americans Have Mixed Views of AI â€“ and an Appetite for Regulation",
    "description": "A supermajority of Americans say that AI should be regulated to protect privacy and ensure safety.",
    "fullText": "AI is sweeping the American economy. A majority of Americans are either using AI tools or have tried them. But AI use is only half the story â€“ a supermajority of Americans say that AI should be regulated to protect privacy and ensure safety. And many remain worried about potential job losses stemming from the emerging technology. \n\nItâ€™s time we did more to understand the national attitudes around AI use, regulation, and favorability.\n\nMost of our respondents had used AI at least once: 58% report using or trying AI, specifically tools like ChatGPT or Claude, divided evenly between fairly regular users (30% use at least a few times a month) and more infrequent users (29% have used AI, but only once a month or less). Nonusers are more likely to be older (62% of people over 65 have never used AI), not have gone to college (47%), or to work in service jobs (35%). Only 18% of white-collar workers say they have never used AI.\n\nAmong those who do use AI, 63% have at least tried it out for work purposes, and 34% report using it at work consistently (a few times a month or more). Work usage, like AI usage overall, is more common among white-collar workers, a majority of whom (55%) use it consistently. Personal use of AI is more common: 91% have at least tried using an AI chatbot or writing tool, and 54% report consistently using it in their personal lives. Gen Z turns to AI more often than its older counterparts, with 68% regularly engaging AI for personal use (compared to just 40% among Boomers).\n\nPersonal AI use encompasses a bunch of different types of application, but by far the most common is information gathering and answering questions (63%). Frequent AI users are especially likely to use AI as an alternative to traditional Google search or other research tools (68%). If this use case continues, messaging and communication on anything from public health to election campaigns will be filtered through AI models before reaching people. This could potentially change how messages are interpreted (particularly given the use of AI summaries), or significantly alter their reach in difficult-to-measure ways. Those interested in talking effectively to Americans should consider how their messaging strategy would work with these AI intermediaries, how their messages will be interpreted by AI, and if what they say will still reach their intended audience.\n\nWhile they know the names of the tools (ChatGPT, etc.), respondents donâ€™t know much about the companies responsible for AI products. This is in contrast with older tech companies: Only 5% havenâ€™t heard of Google, and 79% are favorable toward the company. For Amazon, favorability is at 80%. When asked about OpenAI, 42% hadnâ€™t heard enough to form an opinion. For Anthropic, this figure hit 81%.\n\nAmericans donâ€™t view AI as favorably as other emerging technologies from the past quarter century. Cell phones (76% total positive; net +68), the internet (75% total positive; net +66), and solar energy (72% total positive; net +65) are all viewed as having a very positive impact on society. AI (38% total positive; net +8) is \n\nWhen Americans are asked to think about potential future impacts on society, opinions of AI remain mixed, at a nearly even split of respondents between positive, negative, and uncertain impacts. Respondents believe that things like solar energy (70%), personalized medicine (57%), and nuclear energy (43%) will have positive future impacts, but are more skeptical of cryptocurrency (24% positive, 40% say it will have a negative impact) and self-driving cars (23% positive, 50% negative).\n\nWe also wanted to get a sense of how important Americans believe certain technologies to be. To provide some sense of perspective, we asked them to compare these new technologies to some theyâ€™re more familiar with. â€œExtremely importantâ€ corresponded to the steam engine and electricity, â€œmoderately importantâ€ corresponded to the smartphone, and â€œnot veryâ€ corresponded to the digital camera.\n\nWith these comparisons in mind, the median respondent puts AI on par with the invention of the smartphone. Only 7% believe that itâ€™s more important than any other technology, with 16% of frequent AI users believing this, compared to just 5% of infrequent/nonusers.\n\nDespite uncertainty about AIâ€™s overall importance, 70% of Americans say this technology will dramatically transform work, though theyâ€™re much less certain about the exact nature of this transformation. A plurality believes that it will make work easier (49%), but a majority believes that AI will bring down wages (55%), including pluralities or majorities across education, race, and partisanship. More respondents think it will hurt the economy (37%) than think it will decrease growth (29%), probably reflecting concern about wages. The perception that AI will replace human workers or outcompete them for jobs is a common one: 51% think AI will replace work done by humans, versus 33% who believe AI will supplement the work humans do. Service workers are especially convinced AI will replace (59%) rather than supplement (30%).\n\nA majority of Americans (56%) think that within 10 years, AI will be capable of performing most tasks that most people do at work. However, this drops significantly when respondents are asked about when AI will be able to do most tasks in their own job or field, with 43% thinking this will happen within 10 years, with no notable differences by educational attainment or work type. Customer service representatives are generally agreed to be replaceable within 10 years (64%), followed by accountants (56%) and manufacturing workers (54%). Fewer than 1 in 3 Americans think electricians, truck drivers, or doctors could be replaced by AI in the next 10 years.\n\nAround two-thirds of Americans (67%) are more concerned about the government doing too little to regulate the dangers of AI, versus doing too much and stifling progress (12%). At the same time, they donâ€™t support a full ban on AI advancement, preferring progress to continue with requirements for safety testing (62%). Americansâ€™ preference for safety regulations over the fastest possible progress holds even when theyâ€™re presented with the idea that regulating AI would put the U.S. behind China: Only 15% prefer a world where the U.S. government doesnâ€™t regulate AI at all to compete with other countries like China over one where AI research continues under regulation, even if it develops slower than other countries (67%).\n\nEven in the most extreme case â€” presenting the choice between no further progress in AI at all and totally unregulated AI â€” only 34% would support unregulated AI development, versus 30% who think the government should ban research to improve AI, with a 36% plurality saying theyâ€™re unsure.\n\nIn terms of perceived dangers from AI, Americansâ€™ biggest concern is AI taking jobs and causing unemployment (42%), followed by concerns about privacy (35%) and misinformation (33%). These are also the top three areas Americans prioritize for regulation. Respondents are not especially concerned about AI wiping out humanity (12%), but express greater concern about the use of AI resulting in loss of human control (32%).\n\nWhile respondents see AI as better than humans at being â€œefficientâ€ by a wide margin (+44 points), AI has virtually no advantage on â€œbeing convenient to those theyâ€™re trying to helpâ€ (+2). Humans are still seen as wildly better in terms of being moral (+53), making complex decisions (+30), protecting privacy (+28), and being transparent (+18).\n\nWe also asked about the potential for replacing humans in specific governmental tasks, since this has been talked up by some AI proponents. There are only two specific tasks (from our list tested in this survey, at least) where AI is seen as better than human government employees. One is identifying trends in data (+18) and the other is correctly verifying the information in forms (+8).\n\nOn anything less concrete and data-focused, respondents strongly prefer humans. Human government employees are preferred over AI by 77 points for judging criminal trials, by 59 points for conducting airport screenings, and by 55 points for answering questions about government services like Social Security. Public interest in AI replacement of humans in government and other tasks is minimal.\n\nThis survey was run by Tavern Research via an online sample of 2,301 American adults fielded over web panels from August 1, 2025 to August 6, 2025. The margin of error is +/- 3%.\n\nNOTE: Because this is a web-based survey, we expect the total usage of AI to be slightly higher than the numbers found in non-web-based surveys. This should not affect the other conclusions.\n\nA question that was interesting, but didnâ€™t lead to a larger conclusion, was asking what actually happens when you ask a tool like ChatGPT a question. 45% think it looks up an exact answer in a database, and 21% think it follows a script of prewritten responses.",
    "readingTime": 8,
    "keywords": [
      "solar energy",
      "white-collar workers",
      "americans say",
      "positive net",
      "positive negative",
      "respondents",
      "humans",
      "theyâ€™re",
      "tasks",
      "majority"
    ],
    "qualityScore": 1,
    "link": "https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/",
    "thumbnail_url": "https://www.searchlightinstitute.org/wp-content/uploads/2025/12/Americans-have-mixed-views-of-AI-â€“-and-an-appetite-for-regulation-1.jpg",
    "created_at": "2025-12-24T00:56:09.939Z",
    "topic": "science"
  },
  {
    "slug": "hoping-ai-will-give-you-more-worklife-balance-in-2026-fortune-500-ceos-warn-otherwise",
    "title": "Hoping AI will give you more work-life balance in 2026? Fortune 500 CEOs warn otherwise",
    "description": "Despite Gen Z increasingly demanding work-life balance, many Fortune 500 bosses doubled down on overtime in 2025 to compete in the AI race.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2025/12/23/work-life-balance-recap-2025-fortune-500-ceos-productivity-grind-secrets-for-success/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2249127380_87bb13-e1765992018418.jpg?resize=1200,600",
    "created_at": "2025-12-24T00:56:07.124Z",
    "topic": "business"
  },
  {
    "slug": "work-is-changing-everywhere-as-ai-moves-from-experiment-to-expectation",
    "title": "Work is changing everywhere as AI moves from experiment to expectation",
    "description": "AI transformation, workforce strategy, and new job roles are reshaping how companies like ServiceNow and Weber Shandwick operate today.",
    "fullText": "This article is part of theÂ \"How AI is Changing Talent\" series, which explores how AI is reshaping hiring, development, and retention.\n\nTwelve months ago, Jacqui Canney was ServiceNow's chief people officer, focused on talent strategy. Today, she's also the company's chief AI enablement officer â€” a title that didn't exist until recently.\n\nThe two roles aren't separate, Canney told Business Insider. \"They're one strategy, and the companies that understand that are going to be the winners.\"\n\nThat shift, though, requires letting go of how most organizations have always structured work: by function, head count, and department. \"Companies can't treat this as 'We're going to run an AI program over here, and it'll add capacity,'\" she says.\n\nInstead, they need to ask: how does AI change the work across departments? \"AI doesn't follow the same silos people do. That's why you build the workforce around the new workflow.\"\n\nCanney's approach isn't an outlier. Rather, it's a signal of how quickly AI has become part of work and our daily lives.\n\nThree years after the launch of ChatGPT, adoption has reached 54.6%. That's staggering compared to adoption rates for personal computers (19.7%) and the internet (30.1%) three years after they were widely introduced, according to research by the Federal Reserve Bank of St. Louis.\n\nMeanwhile, about 21% of US workers say that at least some of their job is now done with AI, an increase from 16% roughly a year ago, according to Pew Research Center.\n\nAI is transforming everything about work, from the jobs people do to how they do them. Organizations, meanwhile, are racing to prepare their people for what comes next. While the long-term impact remains uncertain, early patterns are emerging about what's working and what isn't.\n\nAI's effect on the labor market is showing up everywhere: in how companies screen candidates, which skills command premium salaries, and how performance gets evaluated. Two structural shifts, in particular, stand out: new jobs are emerging, and old jobs are evolving.\n\nAn authoritative count of new AI-specific job titles is hard to come by, but data show rapid growth. A report from software company Autodesk found that demand for roles like AI engineer jumped 143.2% in 2024, while prompt engineer rose 135.8%, and AI content creator increased 134.5%. Meanwhile, the number of jobs requiring AI skills rose 7.5% last year, even as total job postings fell 11.3%, according to research from consultancy PwC.\n\nMolly Roenna, global chief people officer at PR firm Weber Shandwick, sees this firsthand. Her company is increasingly seeking specialists in areas like AI integration and AI ethics, and it's recruiting from disciplines like behavioral science and data analytics.\n\n\"We're hiring for a fundamentally different environment,\" Roenna says. \"Meeting client expectations requires people who use technology as a force multiplier for insight and creativity, not just a shortcut for efficiency.\"\n\nThe hiring process itself has evolved, too. Many of Weber Shandwick's interviews now include a \"technology conversation,\" a practice that appears to be gaining traction. This isn't to test technical skills, but to gauge how candidates use AI.\n\n\"What have they built with AI? What excites or worries them about it? We want perspective that comes from actual practice.\"\n\nThe dynamic playing out at Weber Shandwick and elsewhere isn't new. After all, every major technological advancement has created roles that were previously unimaginable, made others obsolete, and forced still others to adapt. What's different about this AI-driven era, however, is both the speed of change (see above) and the breadth, affecting workers across industries and skill levels.\n\n\"We didn't have programmers before computers,\" says Esteve Almirall Mezquita, professor of data, analytics, technology and AI at Esade in Madrid.\n\nCreating new roles and demand for expertise is half the equation. The bigger challenge is helping existing workers figure out how to use AI.\n\nSome companies aren't leaving that to chance. They're requiring it, notes Dan Schawbel, managing partner at Workplace Intelligence, a research firm. \"CEOs are under enormous pressure to have their AI story intact,\" he says. \"We have to have our workers using AI. It's good for productivity, yes, but also our story and bottom line.\"\n\nCompanies such as Microsoft, Coinbase, and Shopify now mandate AI use, according to previous reporting by Business Insider. Meta plans to measure employees' performance by their \"AI-driven impact.\"\n\nSchawbel predicts more scrutiny in the year ahead. Employees will need to function like data scientists, continuously proving their value, he says. \"Whether you're in marketing, IT, or HR, every action can be measured and tracked â€” and maybe even tied directly to your compensation.\"\n\nMeasuring AI use and seeing value from it are two different things, however. Even as organizations pour billions into the technology, results have been uneven.\n\nResearch by consulting firm BCG of more than 1,250 firms worldwide reports that 60% of companies are investing heavily in AI but seeing minimal returns. Meanwhile, only 5% have taken the step to restructure their operations around AI â€” and those companies are seeing significant revenue gains over everyone else.\n\nThe difference, the BCG research suggests, comes down to several factors. Successful companies have buy-in from the top and have redesigned how work gets done. Most importantly, says Alicia Pittman, BCG's global people chair, they've invested in teaching employees to use AI effectively.\n\nPittman notes that industries like financial services, insurance, and healthcare are pulling ahead in AI adoption. \"We're seeing companies put real time and energy into this in a way that hasn't been present before, and that's good for everybody and good for the global workforce.\"\n\nGranted, there's job displacement that comes with that and some skill sets will go away, she says. \"But helping people adapt to AI is a major investment in them as professionals.\"\n\nAt Moody's, the credit ratings firm, that investment involves encouraging employees to teach AI as much as possible.\n\nAri Lehavi, who runs applied AI there, says this approach frees employees to focus on complex work that requires human expertise.\n\nTake sales, for example. Customer relationship management (CRM) systems can capture basics like company size, contract history, and revenue potential. However, they miss what closes deals: company politics, individual motivations, and who really influences decisions. Lehavi's team teaches AI systems to learn those details so salespeople can concentrate on managing relationships.\n\n\"They can spend their time on things they're already doing but don't have enough time for,\" he says. \"The hard cases, the edge cases, the complex situations, mentoring other people, management, and skill development.\"\n\nIn other words: the human stuff.\n\nOf course, the path forward isn't simple or straightforward. Not every company has the resources to retrain its workforce, and some jobs will indeed disappear. Many companies are struggling to make AI work.\n\nYet, Canney of ServiceNow remains positive. \"It's a human renaissance,\" she says. \"You're going to have capacity in your workforce and the chance to guide it toward new revenue streams or creative ways of working. It's an enormous opportunity, and I'm definitely an optimist about it.\"",
    "readingTime": 6,
    "keywords": [
      "business insider",
      "weber shandwick",
      "ai what",
      "isn't",
      "jobs",
      "employees",
      "roles",
      "workforce",
      "workers",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-transforming-workplace-faster-than-internet-2025-12",
    "thumbnail_url": "https://i.insider.com/694ae36a832e0ef1ead6bfbe?width=1200&format=jpeg",
    "created_at": "2025-12-24T00:56:06.612Z",
    "topic": "finance"
  },
  {
    "slug": "google-2025-recap-research-breakthroughs-of-the-year",
    "title": "Google 2025 recap: Research breakthroughs of the year",
    "description": "This year saw new AI models, transformative products and new breakthroughs in science and robotics.",
    "fullText": "This was a year of AI agents, reasoning and scientific discovery.\n\n2025 has been a year of extraordinary progress in research. With artificial intelligence, we can see its trajectory shifting from a tool to a utility: from something people use to something they can put to work. If 2024 was about laying the multimodal foundations for this era, 2025 was the year AI began to really think, act and explore the world alongside us. With quantum computing, we made progress towards real-world applications. And across the board, we helped turn research into reality, with more capable and useful products and tools making a positive impact on people's lives today.\n\nHereâ€™s a look back at some of the breakthroughs, products and scientific milestones that defined the work of Google, Google DeepMind and Google Research in a year of relentless progress.\n\nThis year, we significantly advanced our model capabilities with breakthroughs on reasoning, multimodal understanding, model efficiency, and generative capabilities, beginning with the release of Gemini 2.5 in March and culminating in the November launch of Gemini 3 and the December launch of Gemini 3 Flash.\n\nBuilt on a foundation of state-of-the-art reasoning, Gemini 3 Pro is our most powerful model to date, designed to help you bring any idea to life. It topped the LMArena Leaderboard and redefined multimodal reasoning with breakthrough scores on benchmarks like Humanityâ€™s Last Exam â€” a fiendishly hard test for AI models to see if AI can truly think and reason like humans â€” and GPQA Diamond. It also set a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex. We followed shortly with Gemini 3 Flash, which combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost, making it the most performant model for its size. Gemini 3 Flash's quality surpasses our previous Gemini 2.5 Pro-scale model's capabilities at a fraction of the price and substantially better latency, continuing our Gemini-era trend of 'the next generation's Flash model is better than the previous generation's Pro model'.\n\nLearn more about our progress on our world-class AI models this year:\n\nGemini 3 Flash price & benchmark table.\n\nWeâ€™re committed to making useful AI technology accessible, with state-of-the-art open models. We built our Gemma family of models to be lightweight and open for public use; this year we were able to introduce multimodal capabilities, significantly increase the context window, expand multilingual capabilities, and improve efficiency and performance.\n\nLearn more about this yearâ€™s advances in Gemma models:\n\nThroughout 2025, we continued to advance the trajectory of AI from tool to utility, transforming our portfolio of products with new, powerful agentic capabilities. We reimagined software development by moving beyond tools that assist coding to introducing powerful, agentic systems that collaborate with developers. Key advances, such as the impressive coding capabilities in Gemini 3 and the launch of Google Antigravity, mark a new era in AI-assisted software development.\n\nLearn more about this yearâ€™s advances building developer tools:\n\nThis evolution was also clear across our core products, from AI-enabled features on the Pixel 10 and updates to AI Mode in Search, to AI-first innovations like the Gemini app and NotebookLM, which gained advanced features like Deep Research.\n\nLearn more about how weâ€™ve transformed our products with AI:\n\n2025 was a transformative year for generative media, giving people new and unprecedented capabilities to realize their creative ambitions. Generative media models and tools for video, images, audio and worlds became more effective and broadly used, with breakouts Nano Banana and Nano Banana Pro offering unprecedented capabilities for native image generation and editing. We worked with people in creative industries to develop tools like Flow and Music AI Sandbox, making them more helpful for creative workflows, and we expanded creative possibilities for people with new, AI-powered experiences in the Google Arts & Culture lab, major upgrades to image editing within the Gemini app, and the introduction of powerful new generative media models like Veo 3.1, Imagen 4 and Flow.\n\nLearn more about how weâ€™re building AI to enhance creativity:\n\nAs research breakthroughs continue to expand AIâ€™s capabilities, Google Labs is where we share AI experiments as we develop them â€“ hearing from users and evolving as we learn. Some of this yearâ€™s most engaging experiments from Labs: Pomelli, an AI experiment for on-brand marketing content; Stitch, which introduced a way to turn prompt and image inputs into complex UI designs and frontend code in minutes; Jules, an asynchronous coding agent that acts as a collaborative partner for developers; and Google Beam, a 3D video communications platform that used AI to advance the possibilities of remote presence.\n\nLearn more about how weâ€™re experimenting in Labs:\n\n2025 was also a banner year for scientific advances with AI, marked by breakthroughs in life sciences, health, natural sciences, and mathematics.\n\nIn the space of a year, we made progress in building AI resources and tools that empower researchers and help them understand, identify, and develop treatments in healthcare. In genomics, where weâ€™ve been applying advanced technology to research for 10 years, we moved beyond sequencing, using AI to interpret the most complex data. We also marked the 5-year anniversary of AlphaFold, the Nobel-winning AI system that solved the 50-year-old protein folding problem. AlphaFold has been used by over 3 million researchers in more than 190 countries, including over 1 million users in low- and middle-income countries.\n\nLearn more about how weâ€™re using AI to advance life sciences and health:\n\nGeminiâ€™s advanced thinking capabilities, including Deep Think, also enabled historic progress in mathematics and coding. Deep Think was able to solve problems that require deep abstract reasoning â€“ achieving gold medal-standard in two international contests.\n\nLearn more about how weâ€™re advancing natural sciences and mathematics:\n\nWeâ€™re also leading major discoveries and shaping the future of science in areas like quantum computing, energy and moonshots. Research in this area drew new levels of public attention, with progress towards real-world applications of quantum computing as demonstrated by Quantum Echoes and, notably, Googler Michel Devoret becoming a 2025 Physics Nobel Laureate along with former Googler John Martinis and UC Berkeleyâ€™s John Clarke, for their foundational 1980s quantum research.\n\nLearn more about our work on space infrastructure and quantum computing:\n\nIn 2025, we continued to advance the core infrastructure that powers our AI, focusing on breakthroughs in hardware design and improving energy efficiency. This included the introduction of Ironwood, a new TPU built for the age of inference, which was designed using a method called AlphaChip, alongside a commitment to measuring the environmental impact of our technology.\n\nLearn more about how weâ€™re using AI to develop chips, infrastructure and improve energy efficiency:\n\nOur work in robotics and visual understanding brought AI agents into both the physical and virtual worlds, with advancements like the foundational Gemini Robotics models, the more sophisticated Gemini Robotics 1.5, and the introduction of Genie 3 as a new frontier for general-purpose world models.\n\nLearn more about our work with world models and robotics:\n\nOur work throughout 2025 demonstrates how AI-enabled scientific progress is being directly applied to address the world's most critical and pervasive challenges. By leveraging state-of-the-art foundational models and agentic reasoning, we are significantly increasing our understanding of the planet and its systems, while also delivering impactful solutions in areas vital to human flourishing, including climate resilience, public health and education.\n\nFor example, we are using state-of-the-art foundational models and agentic reasoning to help increase our understanding of the planet, helping enable work that is making a difference in peopleâ€™s lives now from weather predictions to urban planning to public health. For example, our flood forecasting information now covers more than two billion people in 150 countries for severe riverine floods. And our most advanced and efficient forecasting model, WeatherNext 2 can generate forecasts 8x faster and with resolution up to 1-hour. Using this technology, weâ€™ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.\n\nLearn more about our work in weather, mapping and wildfires:\n\nWe are working with partners to apply AI-enabled scientific progress closer to patients, opening up new avenues for disease management and therapeutic discovery.\n\nLearn more about our health-related work:\n\nAI is proving to be a powerful tool in education, enabling new forms of understanding and expanding curiosity through initiatives like LearnLM and Guided Learning in Gemini. We brought Geminiâ€™s most powerful translation capabilities to Google Translate, enabling much smarter, more natural and accurate translations and piloting new speech to speech translation capabilities.\n\nLearn more about how weâ€™re using AI to enable learning:\n\nWe couple our research breakthroughs with rigorous and forward-looking work on responsibility and safety. As our models grow more capable, weâ€™re continuing to advance and evolve our tools, resources and safety frameworks to anticipate and mitigate risk. Gemini 3 demonstrated this approach in action: it's our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. And weâ€™re looking further ahead, exploring a responsible path to AGI, prioritizing readiness, proactive risk assessment, and collaboration with the wider AI community.\n\nLearn more about our responsibility and safety work:\n\nAdvancing the frontier of AI responsibly demands collaboration across all parts of society. In 2025, we worked with leading AI labs to help to form the Agentic AI Foundation and support open standards to ensure a responsible and interoperable future for agentic AI. In education, weâ€™ve partnered with school districts like Miami Dade County and education groups like Raspberry Pi to equip students with AI skills. Our research partnerships with universities like UC Berkeley, Yale, the University of Chicago and many more have been instrumental to some of this yearâ€™s most exciting frontier research, and weâ€™re working with the US Department of Energyâ€™s 17 national laboratories to transform how scientific research is conducted. And weâ€™re working with filmmakers and other creative visionaries to put the best AI tools in their hands and explore storytelling in the age of AI.\n\nLearn more about our work on frontier collaboration:\n\nAs we look towards 2026, weâ€™re looking forward to continuing to advance the frontier, safely and responsibly, for the benefit of humanity.",
    "readingTime": 9,
    "keywords": [
      "nano banana",
      "ai-enabled scientific",
      "gemini app",
      "real-world applications",
      "software development",
      "towards real-world",
      "generative media",
      "quantum computing",
      "life sciences",
      "natural sciences"
    ],
    "qualityScore": 1,
    "link": "https://blog.google/technology/ai/2025-research-breakthroughs/",
    "thumbnail_url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_keyword_social_share_light_1.width-1300.png",
    "created_at": "2025-12-24T00:56:05.364Z",
    "topic": "tech"
  },
  {
    "slug": "i-hired-ai-to-fix-my-memory-but-made-it-100-offline-for-privacy",
    "title": "I hired AI to fix my memory, but made it 100% Offline for privacy",
    "description": "Scientific memory support with the Forgetting Curve. Privacy-first, local-only app.",
    "fullText": "A Message from the Developer\n\n \"System Engineer since 1999 (Enterprise Systems).\n\n I created this app to solve my own forgetfulness, applying 25 years of experience in data reliability and security.\"\n\n Developed by an enterprise system engineer active since 1999 to solve his own \"memory struggles\".\n\n Built with the same commitment to quality and data security found in mission-critical systems.",
    "readingTime": 1,
    "keywords": [
      "system engineer",
      "solve",
      "security",
      "enterprise",
      "systems"
    ],
    "qualityScore": 0.4,
    "link": "https://namememory.netlify.app/",
    "thumbnail_url": "https://www.namememory.app/ogp_image.png",
    "created_at": "2025-12-24T00:56:05.339Z",
    "topic": "tech"
  },
  {
    "slug": "best-new-games-without-ai",
    "title": "Best New Games Without AI",
    "description": "The use of Generative AI (or GenAI for short) is on the rise, with many examples in some of the biggest games of the year using art, voice recordings, and narratives, just to name a few, now coming to light. For many players, a studioâ€™s use of AI as a shortcut, instead of commissioning an artist, hiring a voice actor, or paying a writer to create assets for the final product, is something they actively donâ€™t want to buy.\nSo this curated list thatâ€™s human-approved with only a spellchecker to assist in its creation will highlight the best games in 2025 where AI is, as far as we know, not involved in the development process. They all come from a whole bunch of developers, big and small, spanning a wide range of genres. The one thing they have in common is that a dedicated team of people worked on it without any assistance from GenAI tools.",
    "fullText": "on December 23, 2025 at 12:45PM PST\n\nGameSpot may receive revenue from affiliate and advertising partnerships for sharing this content and from purchases through links.\n\nThe use of Generative AI (or GenAI for short) is on the rise, with many examples in some of the biggest games of the year using art, voice recordings, and narratives, just to name a few, now coming to light. For many players, a studioâ€™s use of AI as a shortcut, instead of commissioning an artist, hiring a voice actor, or paying a writer to create assets for the final product, is something they actively donâ€™t want to buy.\n\nSo this curated list thatâ€™s human-approved with only a spellchecker to assist in its creation will highlight the best games in 2025 where AI is, as far as we know, not involved in the development process. They all come from a whole bunch of developers, big and small, spanning a wide range of genres. The one thing they have in common is that a dedicated team of people worked on it without any assistance from GenAI tools.\n\nItâ€™s important to clarify that any procedural generation of maps, or randomized abilities or enemies, uses AI to determine what appears, and is not the same as GenAI. Weâ€™re specifically excluding games that use AI to generate any assets, whether itâ€™s disclosed at the point of sale or found out after publishing. If itâ€™s ethically problematic for any of these reasons, a game wonâ€™t be included on the list, no matter how much of a Game of the Year contender it is. With that, here are the best games without AI involvement in their development.\n\nHades 2 is the long-awaited sequel to Supergiant Gamesâ€™ Game of the Year, which puts you in the shoes of the immortal Princess MelinoÃ« as she attempts to save her father Hades and his kingdom from the time-looping clutches of the Titan Cronos. It largely follows a similar Roguelike structure, where each run has you collect powers from the Ancient Greek Pantheon to augment your chosen weapon and crush the foes in your way.\n\nOf course, with every sequel, you need to outdo what came before. Naturally, this means having two separate paths from the beginning, each with its own layout. One leads to the depths of Hades to Cronos, while the other has MelinoÃ« ascend to the peak of Mt Olympus to defeat the invading monsters. Fans of the first will likely already have this one, but you donâ€™t need to have mastered the original to enjoy everything that Hades 2 has to offer.\n\nReleased episodically, Dispatch is a wonderful throwback from the team behind The Walking Dead and The Wolf Among Us. Throughout its first season, you are a former superhero, Mechaman, who becomes a dispatcher for a new generation of heroes. However, he ends up managing a team of miscreants who are easily sidetracked by a little bit of arson or petty theft. Itâ€™s up to you to keep everything on track, even when things go south.\n\nWhether itâ€™s allocating the right person for a particular job or making sure another hero doesnâ€™t get sidetracked, each chapter has significant decisions that drastically change the outcome of a mission. By reading each hero's bio and upgrading their skills, youâ€™ll increase your chances of success. Youâ€™ll also occasionally need to hack into systems remotely to assist your heroes when theyâ€™re in peril.\n\nDispatchâ€™s stunning cast, which includes professional voice actors and some YouTubers branching out and doing a decent job in bringing these larger-than-life characters to life. By the time you reach the end, only one question will likely be on your mind: whenâ€™s season 2?\n\nFor fans of retro beat-'em-ups such as Streets of Rage or Final Fight, itâ€™s been quite a while since a brand-new series broke ground. Absolum carefully blends in Roguelike game mechanics to make what Steve Watts, in his review, described as â€œa match made in heavenâ€. You play as one of a band of rebel wizards led by Root Mother Uchawi, a benevolent god-like being, who attempts to take on the tyrant Sun King Azra and his Crimson Order army, who have taken over the world of Talamh.\n\nWith multiple characters to play with their own fighting style, a phenomenal soundtrack, stunning visuals, and a Hades-like elemental progression system for every run, itâ€™s easy to see how this is a winning formula. On top of that, there are plenty of branching paths and hidden secrets to find along the way. Quests ask you to venture to specific points, but donâ€™t always require that you reach them in the same run.\n\nSome may feel that the Roguelike structure holds it back because it doesnâ€™t lean into it enough, but it instead asks for the player to master its mechanics by giving them familiar challenges, and as such, may be somewhat fairer to their time. If youâ€™re not convinced, thereâ€™s a free Absolum demo you can check out that gives you a small slice of just how wonderfully everything comes together, and like the full-price experience, you can bring a friend with you in your quest to save the realm.\n\nFanatical and GameSpot are both owned by Fandom.\n\nSolving the mystery behind a weird house with constantly shifting layouts that you inherited was not exactly on our bingo card for 2025, but Blue Prince is one of the best puzzle games weâ€™ve played in years. Each day, you have a set number of steps to explore a house with randomized rooms. These rooms can give or take away steps, grant you items, or even house escape room-like puzzles that reward you with more trinkets.\n\nOn top of this, Blue Prince has a rather intricate mystery throughout. Clues hidden in certain rooms will allude to the house itself, including whatâ€™s in room 46, the former owner Herbert S. Sinclair, and a children's author called Marion Marigold. It might take you only a few attempts, or it may take you many. If you find youâ€™re struggling to make a dent, you should check out our Blue Prince guides hub for some tips. Persevere, and youâ€™ll find out why itâ€™s worth continuing until you find that fated room.\n\nNintendoâ€™s big ape smashes his way onto the Switch 2 with Donkey Kong Bananza, from the creators of Super Mario Odyssey. Our gorilla hero travels to Ingot Isle to mine Banadium Gems, only to have his hoard stolen by a sinister simian syndicate known as VoidCo. Buried deep underground, DK soon finds an odd sentient rock that later turns out to be a younger version of Pauline. The two team up to excavate through each layer of this underground world to stop VoidCo.â€™s president from reaching the planetâ€™s core.\n\nThe big selling point of Donkey Kong Bananza is that DK can dig his way through levels with his bare hands, uncovering secrets while using rocks and soil to bash his way to the end. Paulineâ€™s singing also helps unlock transformations that enable DK to fly or charge at high speed, amongst others. Much like 3D Mario games and their equivalent macguffins, youâ€™ll also gather crystal bananas for completing objectives. However, these bananas also tie in with the upgrade system that unlocks more powers for the duo.\n\nWhat sets it apart is that, despite being vastly different from every other Donkey Kong game, it manages to pay homage to the series. Cameos from DKâ€™s animal friends, musical homages, and so much more. Itâ€™s one of the few essential games to own for the Nintendo Switch 2 in its first year on the market. In case youâ€™re wondering, you can safely skip the DLC: DK Island and Emerald Rush unless itâ€™s put on sale, or you really enjoy Roguelike modes.\n\nFinal Fantasy Tactics: The Ivalice Chronicles is a remaster made with love, care, and passion. Since the source code was lost, as was sadly the norm back in the 1990s, the effort made to bring the entire campaign to currently available platforms is staggering. It does have the newer translation, added voice acting, and support for higher resolutions than its PlayStation, PSP, or mobile iterations, and all of that is created or performed by talented people. And yet, despite the modern additions, itâ€™s still the same punishing, yet charming, and above all, epic classic RPG from Square Enixâ€™s golden age.\n\nIt would have been so easy just to churn out a â€˜modern reskinâ€™ of the classic permadeath game, or mangle its existing assets with generative AI upscaling tools. However, the team behind Final Fantasy Tactics: The Ivalice Chronicles evidently cared, wanting to retell the War of the Lions saga that captivated many with its twists and turns. Rebalancing encounters and adding the ability to skip non-story fights help ease newer players in, allowing them to experience some of what makes this tactical RPG so special.\n\nPeak is high up there when it comes to games with humble origins. It started as a Game Jam experiment that people loved so much that it inspired the developers, whose previous effort was the crustacean Soulslike game, Another Crabâ€™s Treasure, to expand it into a full multiplayer experience. Itâ€™s one of the best Steam co-op games of the year, and thatâ€™s largely thanks to its tense gameplay and proximity-based voice chat.\n\nAs you ascend the biomes, youâ€™ll encounter many dangerous obstacles such as toxic plants, chilling winds, and lava that rises and falls. Sometimes, you have mere seconds to cross perilous gaps, and sometimes itâ€™s unclear if your constantly fatiguing scout can even make it until you try. Every major update adds a new environment filled with hazards, and new items make every run an unpredictable challenge.\n\nPlaying it with friends lets you share tools and food across your backpacks, and even grab a partnerâ€™s hand to reach the ledge theyâ€™re on. Once youâ€™ve reached the top of the final level, you can begin tweaking runs with difficulty modifiers, which gives Peak a great amount of replay value. Whatever you do, though, donâ€™t let the Scoutmaster see you if you split from the party.\n\nAs the name would suggest, Silent Hill f is not for the faint of heart. The latest in the horror game series takes place in the fictional town of Ebisugaoka in 1960s Japan, where the protagonist Hinako Shimizu finds her homeland shrouded in fog and infested with grotesque monsters intent on killing her and her childhood friends. It soon becomes apparent that all is not quite as it seems, as Hinako discovers an alternate dimension where she encounters a guide wearing a fox mask.\n\nTo survive, youâ€™ll need to find and maintain gathered weapons while mastering both the focus attack and the timing of dodging enemy strikes. Youâ€™ll also solve puzzles with cryptic clues, all while the Silent Hill f tries its hardest to unsettle you. An early part taking place in a paddy field is particularly memorable, and itâ€™s not even the gameâ€™s evilest trick.\n\nSilent Hill continues the seriesâ€™ track record of weaving a tale within its enemy design, the documents and letters you find, and even item descriptions. All of which provide intricate clues as to whatâ€™s really happening. Some will probably find that one playthrough is enough for them, but persevere with subsequent playthroughs, and youâ€™ll soon uncover more layers that need unravelling to get the next ending.\n\nFrom the people who brought you Before Your Eyes comes Goodnight Universe, a game with a great story where you interact telepathically with your surroundings as a 6-month-old baby. Having gained sentience moments before your grandfatherâ€™s death, Isaac soon has to contend with a world that doesnâ€™t understand him. Your interpretation of everything thatâ€™s happening around you, or what you mean to your family, is soon complicated by symbols in his old book that you can somehow decipher.\n\nBefore long, you begin controlling things with your mind, from swiping dog food to tipping it over, spilling its contents into a dog bowl, to shunting the old mutt closer to the food, and thatâ€™s just one of the many telepathic scenarios youâ€™ll encounter. Itâ€™s more of an interactive story than a game, but the writing and performances are what bring Goodnight Universe to life. The further in, the weirder things get as you discover more about the dormant powers Isaac has. By the end of this fairly short tale, youâ€™ll likely shed a few tears, especially if you are a parent yourself.\n\nAs one of the few exclusively co-op games on the market, Lego Voyagers is a beautifully crafted journey where players control a red or blue Lego brick. After witnessing a rocket launch go wrong, and part of it washes up on their island, the two bricks set out to discover the wonders of the archipelago. It might be a little fiddly at first, but soon youâ€™ll be crossing rivers with makeshift bridges, sliding down pipes, and constructing new methods to cross a gap or reach the top of a ledge with Lego pieces.\n\nLego Voyagers is fairly light in tone, nothing speaks, and its puzzles arenâ€™t mind-numbingly easy, making it a perfect game for a parent and child to share. There are lots of things to just mess around with, bringing out the inner kid and satisfying that curiosity, while also sharing in the gameâ€™s more whimsical moments, such as sitting on a swing set to take in the scenery. Itâ€™s not the longest game on the list, coming in at only a couple of hours from start to finish, but this is the definition of an experience thatâ€™s short but sweet.\n\nThe best bit is that only one of you needs to own the Lego Voyagers for you to play with a buddy, thanks to the Friends Pass. It also now has full crossplay, which you can use across any device despite previous announcements saying otherwise. You can even play with a buddy via the Friend Pass on a different console or PC from the one you are using.\n\nCabernet plays a lot like the social life part of a modern Persona game, but with a macabre twist. You are Liza, a newly turned vampire in a 19th-century Eastern European town, navigating her eternal life. Along the way, sheâ€™ll meet the locals, both human and vampire, with whom sheâ€™ll form bonds by sharing in passions of art, literature, science, and politics. Liza also has vampire powers she can use to manipulate those around her, should she choose to, but these usually come at a cost.\n\nFor us, itâ€™s the level of choice that truly sets Cabernet apart from the crowd. Dialogue options not only appear based on friendship levels with the person youâ€™re talking to, but can also require points in skills (which you can give a quick boost by wearing certain dresses) or by having more points one way or the other in the gameâ€™s morality system.\n\nItâ€™s also clear that Cabernet doesnâ€™t get bogged down by its light RPG game mechanics. Instead, it focuses on telling a story with stellar writing, supported by its wide range of talented voices, bringing it to life. Compared to more combat-heavy RPGs, Cabernet offers a drastic change of pace, rewarding players who carefully plan their next moves and giving agency to their choices.\n\n2025 was a good year for kart racing games, and Sonic Racing: Crossworlds brings dimensional portals that alter the courses mid-race. One moment youâ€™re speeding across a desert city, and the next youâ€™re bouncing on alien plants, before returning to the original course for the final lap. Combined with Sonic All-Stars Racing: Transformedâ€™s shifting vehicles from kart to plane to boat, depending on the terrain youâ€™re racing on, this wacky racer is the perfect multiplayer game both online and locally. In fact, it has crossplay enabled across all platforms, so itâ€™s far more accessible than its current competition.\n\nWhatâ€™s more, the single-player offering is actually substantial. For every Grand Prix, youâ€™re given a rival that you must try to beat on every track. Their behavior is more aggressive than that of other competitors, and the level of heat they have indicates their overall difficulty boost. Each race you win, outpace your rival, and collect all five red rings in the first three courses. The finale of each cup has everyone drive one lap of the previous three tracks in sequence, rewarding those who learn the shortcuts ahead of time.\n\nSonic Racing: Crossworlds also features vehicle customization and a huge roster of familiar characters, each with stats that change the kartâ€™s handling, acceleration, and overall speed. Whatâ€™s more, the list of drivers will expand thanks to a host of DLC characters from different universes coming out in the next year. Soon, it will be a bit like the Super Smash Bros of kart racers, but with free Sega-owned characters and paid-for crossover ones. These paid-for ones include Minecraft and SpongeBob SquarePants, which are already available, with the likes of Pac-Man, Mega Man, the Teenage Mutant Ninja Turtles, and Avatar: The Last Airbender already announced to be coming throughout 2026.",
    "readingTime": 15,
    "keywords": [
      "fantasy tactics",
      "ivalice chronicles",
      "kong bananza",
      "roguelike structure",
      "racing crossworlds",
      "final fantasy",
      "sonic racing",
      "wide range",
      "team behind",
      "youâ€™ll encounter"
    ],
    "qualityScore": 1,
    "link": "https://www.gamespot.com/gallery/best-games-without-ai/2900-7369/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1861/18616975/4626174-best-games-without-ai.jpg",
    "created_at": "2025-12-24T00:56:03.826Z",
    "topic": "gaming"
  },
  {
    "slug": "ai-vtuber-neurosama-just-obliterated-her-own-massive-twitch-world-record",
    "title": "AI VTuber Neuro-Sama Just Obliterated Her Own Massive Twitch World Record",
    "description": "In early 2025, partway through a subathon to mark her second birthday, the AI VTuber Neuro-Sama became the world record holder for the largest Twitch Hype Train. Many claimed her achievements were possible thanks to Riot's competitive shooter, Valorant, gifting one subscription for each five gifted by the community. Now, only a few days into her third birthday subathon, Neuro-Sama and her creator Vedal987 have smashed that world record. She completed Hype Train level 120 with 118,989 subscriptions and 1,000,073 Bits gifted to the Vedal987 Twitch channel within a limited time.\nNeuro-Sama is an AI VTuber who recently completed a Minecraft Hardcore run with her creator and friends Filian and Crelly.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/ai-vtuber-neuro-sama-just-obliterated-her-own-massive-twitch-world-record/1100-6537146/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1850/18507742/4627561-maxresdefault.jpg",
    "created_at": "2025-12-24T00:56:03.822Z",
    "topic": "gaming"
  },
  {
    "slug": "openais-ceo-sam-altman-says-in-10-years-time-college-graduates-will-be-working-some-completely-new-exciting-super",
    "title": "OpenAIâ€™s CEO Sam Altman says in 10 yearsâ€™ time college graduates will be working â€˜some completely new, exciting, super well-paidâ€™ job in space",
    "description": "While Bill Gates has said the two-day workweek could come within the next decade, OpenAI CEO Sam Altman says Gen Alpha college graduates will be too busy planet-hopping.",
    "fullText": "With Gen Z facing existential career crises, billionaire OpenAI CEO Sam Altman says that in just 10 years, college grads will be exploring the solar systemâ€”jobs that will reel in sky-high salaries. The tech leader even says heâ€™s envious of young people because our early-career jobs will look â€œboringâ€ by comparison.\n\nAs AI reshapes the workforce, many Gen Z college graduates are finding out the hard way that their degrees donâ€™t guarantee a smooth career launch.\n\nNow, even OpenAI CEO Sam Altmanâ€”one of Silicon Valleyâ€™s biggest leaders driving the AI revolutionâ€”is admitting the elephant in the room is true: AI will wipe out some jobs entirely. However, the tech billionaire insists the coming decade could be the most exciting time in history to start a career, especially for anyone whoâ€™s ever dreamed of working in space.\n\nNot only will they be reeling in sky-high salaries, but Altman says theyâ€™ll also be â€œfeeling so bad for you and I that we had to do this really boring, old work and everything is just better.â€\n\nâ€œIn 2035, that graduating college student, if they still go to college at all, could very well be leaving on a mission to explore the solar system on a spaceship in some completely new, exciting, super well-paid, super interesting job,â€ Altman told video journalist Cleo Abram.\n\nThough itâ€™s unclear how widespread space exploration will expand in the coming yearsâ€”considering NASAâ€™s broad goal of getting to Mars in the 2030sâ€”aerospace engineers are growing faster than the national average of all jobs, according to data from the U.S. Bureau of Labor Statistics. And they bring home an envy-inducing annual paycheck of over $130,000.\n\nOther tech pioneers have AI predictions that are more grounded on Earthâ€”but still alluring to workers. For example, billionaire Microsoft cofounder Bill Gates said that the technology might dramatically reduce the length of the workweek, thanks to humans no longer being needed â€œfor most things.â€\n\nâ€œWhat will jobs be like? Should we just work like two or three days a week?â€ the tech billionaire told Jimmy Fallon on The Tonight Show.\n\nNvidia CEO Jensen Huang echoed that AI has already given his workers â€œsuperhumanâ€ skillsâ€”something that will only increase as the technology advances.\n\nâ€œIâ€™m surrounded by superhuman people and super intelligence, from my perspective, because theyâ€™re the best in the world at what they do. And they do what they do way better than I can do it. And Iâ€™m surrounded by thousands of them. Yet it never one day caused me to think, all of a sudden, Iâ€™m no longer necessary,â€ he separately told Cleo Abram on her Huge Conversations podcast series.\n\nWhile Altman admitted that his crystal ball remains foggyâ€”and that the true direction of AI is unclearâ€”he is actually envious of Gen Z professionals starting off their careers: â€œIf I were 22 right now and graduating college, I would feel like the luckiest kid in all of history,â€ he added to Abram.\n\nFortune reached out to OpenAI for comment.\n\nAfter the launch of OpenAI model, GPT-5, Altman declared the world has access to technology equivalent to a â€œteam of PhD-level expertsâ€ right in their pocket. And as a result, the CEO said it will be easier than ever for one person to create a business that used to take â€œhundredsâ€ of peopleâ€”all it takes is coming up with a great idea and mastering AI tools.\n\nâ€œIt is probably possible now to start a company, that is a one-person company that will go on to be worth more than a billion dollars, and more importantly than that, deliver an amazing product and service to the world, and that is like a crazy thing,â€ he said.\n\nBillionaire Mark Cuban has gone even further with his prediction, saying that AI could give Elon Musk a run for his money as the worldâ€™s richest person.\n\nâ€œWe havenâ€™t seen the best or the craziest of what [AI is] going to be able to do,â€ Cuban told the High Performance podcast. â€œAnd not only do I think itâ€™ll create a trillionaire, but it could be just one dude in the basement. Thatâ€™s how crazy it could be.â€\n\nA version of this story originally published onÂ Fortune.comÂ on August 11, 2025.\n\nâ€˜Godmother of AIâ€™ says degrees are less important in hiring than how quickly you can â€˜superpower yourselfâ€™ with new tools\n\nForget the four-day workweek, Elon Musk predicts you wonâ€™t have to work at all in â€˜less than 20 yearsâ€™\n\nAmazon founder Jeff Bezos says â€˜millions of peopleâ€™ will be living in space by 2045â€”and robots will commute on our behalf to the moon\n\nThis story was originally featured on Fortune.com",
    "readingTime": 4,
    "keywords": [
      "iâ€™m surrounded",
      "ceo sam",
      "openai ceo",
      "sky-high salaries",
      "graduating college",
      "tech billionaire",
      "elon musk",
      "jobs",
      "career",
      "space"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/openai-ceo-sam-altman-says-142824605.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Jvk8nOvfn3rZXWMl4EEreQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/fortune_175/8dccc334d569c307401657f0e513cfc2",
    "created_at": "2025-12-24T00:56:03.048Z",
    "topic": "news"
  },
  {
    "slug": "global-investors-turn-to-chinese-ai-as-wall-street-fears-bubble",
    "title": "Global investors turn to Chinese AI as Wall Street fears bubble",
    "description": "Global investors are increasing their wagers on Chinese artificial intelligence companies, betting on the next DeepSeek and seeking to diversify, with concerns growing about a speculative bubble in the sector on Wall Street.",
    "fullText": "HONG KONG/NEW YORK, Dec 23 (Reuters) - Global investors are increasing their wagers on Chinese artificial intelligence companies, betting on the next DeepSeek and seeking to diversify, with concerns growing about a speculative bubble in the sector on Wall Street.\n\nDemand for China's AI companies is also being stimulated by â€‹Beijing's push for tech independence. China has fast-tracked blockbuster listings of chipmakers, notably Moore Threads (688795.SS), dubbed \"China's Nvidia\", and MetaX (688802.SS), which both debuted this month.\n\nForeigners see China closing â€Œthe tech gap with the U.S. as Beijing steps up support for AI chipmakers, spurring bets on Chinese companies just as worries grow over lofty valuations on U.S.-listed AI stocks.\n\nU.K.-based asset manager Ruffer, for example, said it has \"deliberately limited â€Œexposure\" to the Magnificent Seven - the U.S. tech giants - and is looking to add positions in Alibaba (BABA, 9988.HK) for a bigger exposure to China's AI theme.\n\n\"While the U.S. remains the leader in frontier AI, China is rapidly narrowing the gap,\" said Gemma Cairns-Smith, Investment Specialist at Ruffer. \"The moat may not be as wide, or as deep, as many think ... The competitive landscape is shifting.\"\n\nRuffer is gaining exposure to the AI theme through Chinese tech giants such as Alibaba, which operates an AI chip unit, owns large language model Qwen, and is ploughing money into cloud infrastructure.\n\nGlobal asset managers are increasingly eyeing Chinese AI firms â as a wave of startups lists on the mainland and in â€ŒHong Kong, seeking to tap into surging investor appetite following the meteoric rise of DeepSeek, Chinaâ€™s answer to ChatGPT.\n\nUBS Global Wealth Management in a report this month rated China tech as \"most attractive\", citing investors' search for geographical diversification and China's \"strong policy backing, technological self-reliance, and rapid â€AI monetization\".\n\nThe tech-heavy Nasdaq (^IXIC) currently trades at 31 times earnings, compared with a multiple of 24 for Hong Kong's Hang Seng Tech (HSTECH.HK), which enables AI bets via stocks including Alibaba (BABA, 9988.HK), Baidu (BIDU, 9888.HK), Tencent (0700.HK, TCEHY) and chip foundry SMIC (0981.HK).\n\nRiding the momentum, U.S. investment adviser Rayliant helped launch a Nasdaq-listed fund in September that gives investors access to \"China's versions of stocks like Google, Meta, Tesla, Apple, and OpenAI\".\n\nKraneShares Chief Investment Officer Brendan Ahern said the â€‹rapid ascent of Chinese AI chipmakers such as Cambricon speaks to the scale and speed of innovation across China's AI and semiconductor industries.",
    "readingTime": 3,
    "keywords": [
      "alibaba baba",
      "tech giants",
      "china's ai",
      "chinese ai",
      "investors",
      "chipmakers",
      "stocks",
      "exposure",
      "seeking",
      "bets"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/analysis-global-investors-turn-chinese-072806140.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/lAn3nro5n72FhggSl3No.g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/51c38460-dfe8-11f0-bfdf-af41f33db60a",
    "created_at": "2025-12-24T00:56:02.692Z",
    "topic": "finance"
  },
  {
    "slug": "amazons-chief-security-officer-says-the-tech-giant-blocked-over-1800-suspected-north-korean-agents-from-applying-for",
    "title": "Amazon's chief security officer says the tech giant blocked over 1,800 suspected North Korean agents from applying for jobs",
    "description": "Stephen Schmidt said AI and machine-learning roles have been increasingly targeted by fraudsters due to high demand.",
    "fullText": "Amazon has stopped more than 1,800 suspected North Korean agents from applying for jobs over the last 20 months, a top executive at the firm has said.\n\nIn a post on LinkedIn, Stephen Schmidt, Amazon's chief security officer, said North Korean nationals had in recent years been attempting to land remote tech roles with companies across the globe.\n\n\"Their objective is typically straightforward: get hired, get paid, and funnel wages back to fund the regime's weapons programs,\" Schmidt wrote.\n\nAmazon has used a combination of AI-powered screening and human verification to detect and block such applications, Schmidt continued.\n\nThe company's AI model searches for connections to around 200 \"high-risk institutions\" and analyzes \"anomalies across applications\" and \"geographic inconsistencies.\"\n\nHuman reviewers then conduct background checks, verify credentials, and carry out interviews, he added.\n\nSchmidt said fraudsters were becoming more \"calculated,\" with many targeting real software engineers in an effort to gain credibility.\n\nOthers attempt to take over dormant LinkedIn accounts or pay for access to existing profiles, he continued.\n\nAI and machine-learning roles have been increasingly targeted due to high demand, he added.\n\n\"Small details give them away,\" Schmidt went on. \"For example, these applicants often format U.S. phone numbers with \"+1\" rather than \"1.\" Alone, this means nothing. Combined with other indicators, it paints a picture.\"\n\nThe operatives often work with \"laptop farms,\" Schmidt said, which are US-based locations that maintain a domestic presence while workers operate remotely from abroad.\n\n\"This isn't Amazon-specific,\" Schmidt added. \"This is likely happening at scale across the industry.\"\n\nIn July, an Arizona woman was sentenced to 102 months in prison for her role in assisting North Korean IT workers in securing remote IT jobs at more than 300 US companies.\n\nThe Justice Department said the laptop farming scheme generated over $17 million in illicit revenue for the woman and Pyongyang.\n\nCrowdStrike's 2025 Threat Hunting Report found that the North Korean remote-worker scheme is a growing threat.\n\nAmazon had detected 27% more North Korea-linked applications quarter over quarter this year, Schmidt said.\n\nIn June, the DOJ said authorities had carried out searches of 29 known or suspected \"laptop farms\" across 16 US states. It said North Korean actors had managed to obtain employment with more than 100 US companies.\n\nThe DOJ did not name the companies but said they included Fortune 500 firms.\n\nThe FBI recommends that businesses scrutinize identity verification documents, verify prior employment and education, and require in-person meetings.",
    "readingTime": 3,
    "keywords": [
      "laptop farms",
      "north korean",
      "across",
      "applications",
      "schmidt",
      "suspected",
      "jobs",
      "remote",
      "roles",
      "human"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-blocks-north-korean-job-applications-remote-workers-cso-says-2025-12",
    "thumbnail_url": "https://i.insider.com/694a7d26832e0ef1ead6b851?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:55.475Z",
    "topic": "finance"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-predicts-it-will-terraform-software-and-alter-job-descriptions",
    "title": "The guy who coined 'vibe coding' predicts it will 'terraform software and alter job descriptions'",
    "description": "Andrej Karpathy led AI at Tesla and cofounded OpenAI. He wrote that vibe coding has produced a new type of code that is \"free\" and \"discardable.\"",
    "fullText": "He coined \"vibe coding\" earlier this year. Now, he has something to say about it.\n\nAndrej Karpathy led AI at Tesla for five years, steering the company's Autopilot effort and briefly working on its humanoid robot Optimus. He sandwiched his Tesla job with two stints at OpenAI, making Karpathy a cofounder of the AI pioneer.\n\nAs 2025 comes to a close, Karpathy published his year-in-review for large language models on X. He reflected on the famous term he originated in February, a term that has since shaken up the software engineering industry.\n\n\"With vibe coding, programming is not strictly reserved for highly trained professionals,\" Karpathy wrote. He called it an example of how \"regular people benefit a lot more from LLMs compared to professionals, corporations and governments.\"\n\nVibe coding has likely benefited businesses, too. Tech companies have equipped their engineers with tools like Cursor, Claude Code, and OpenAI's Codex, aiming for productivity gains.\n\nKarpathy wrote that vibe coding \"empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.\"\n\nIt may also change the makeup â€” or the use case â€”Â of the code itself. Karpathy threw out a slew of adjectives to describe this new body of code: It is \"free, ephemeral, malleable, discardable after single use.\"\n\n\"Vibe coding will terraform software and alter job descriptions,\" he wrote.\n\nHow does Karpathy feel about being the term's origin?\n\n\"Amusingly, I coined the term \"vibe coding\" in this shower of thoughts tweet totally oblivious to how far it would go,\" he wrote.\n\nThere's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisperâ€¦\n\nIt's not yet clear how efficient vibe coding is making engineers. In a METR study published in July, AI coding assistants were found to decrease the productivity of participating experienced software developers by 19%. The developers in that study were also overconfident in the tools, its authors said, expecting a 20% productivity boost even after using them.\n\nWhat is clear, though, is that the practice is unlocking a whole new form of tech products. Twitter founder Jack Dorsey vibe-coded a new messaging app this year. Non-technical workers are easily building, shipping, and, in some cases, even selling apps they build in hours, if not minutes.\n\nKarpathy gave some other reflections. He praised Google Gemini's Nano Banana image model, and wrote that Claude Code was the \"first convincing demonstration of what an LLM Agent looks like.\"\n\nOverall, Karpathy wrote that 2025 was an \"exciting and mildly surprising year of LLMs.\"",
    "readingTime": 3,
    "keywords": [
      "trained professionals",
      "vibe coding",
      "software",
      "llms",
      "productivity",
      "karpathy",
      "coined",
      "tesla",
      "published",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-coined-vibecoding-ai-prediction-2025-12",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:54.745Z",
    "topic": "finance"
  },
  {
    "slug": "climate-rising-extending-apparel-lifespan-with-thredup",
    "title": "Climate Rising: Extending Apparel Lifespan with ThredUp",
    "description": "The business model, brand strategy, and AI tools powering one of the largest secondhand clothing platforms.",
    "fullText": "All episodes\n\n All episodes\n\n Details\n\n Transcript\n\n December 23, 2025\n\n With the holiday season upon us, and thrifting a major trend, weâ€™re sharing an episode of Harvard Business Schoolâ€™s Climate Rising podcast thatâ€™s focused on extending product life, reducing waste, and the growing role of resale in the circular economy.\nClimate Rising is all about what businesses are doing, can do, and should do to confront climate change. In this episode, â€œExtending Apparel Lifespan,â€Â HBS Professor Mike Toffel talks toÂ ThredUp CEO James Reinhart about why ThredUp chose to build a national logistics and technology platform for resale. They also talk about how the company partners with big brands to run their own resale channels and how AI and automation are reshaping the industry. Itâ€™s an insightful conversation for anyone interested in sustainability or circular business models.\n\n Back / Climate Rising: Extending Apparel Lifespan with ThredUp\n\n Latest in this series\n\n All episodes",
    "readingTime": 1,
    "keywords": [
      "apparel lifespan",
      "extending apparel",
      "episodes",
      "resale",
      "episode",
      "business",
      "circular",
      "climate",
      "rising",
      "thredup"
    ],
    "qualityScore": 0.65,
    "link": "https://hbr.org/podcast/2025/12/climate-rising-extending-apparel-lifespan-with-thredup",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-cold-call-25.png",
    "created_at": "2025-12-23T18:17:53.824Z",
    "topic": "business"
  },
  {
    "slug": "how-work-changed-in-2025-according-to-hbr-readers",
    "title": "How Work Changed in 2025, According to HBR Readers",
    "description": "2025 was a year of big changeâ€”in general, and in the workplace. HBR asked its global social media community to weigh in on the question: How did your work change this year? Overall, three major themes stood out: AI adoption, the importance of people and purpose and major disruptions like layoffs, funding cuts, or career pivots. Alongside their responses are articles HBR published in 2025 on these trends, changes, and challenges.",
    "fullText": "How Work Changed in 2025, According to HBR Readers by Stefanie FernÃ¡ndezDecember 23, 2025PostPostShareSavePrintSummary.Â Â Â Leer en espaÃ±olLer em portuguÃªsPostPostShareSavePrint2025 was a year of big changeâ€”in general, and in the workplace.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/how-work-changed-in-2025-according-to-hbr-readers",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_155071960.jpg",
    "created_at": "2025-12-23T18:17:53.816Z",
    "topic": "business"
  },
  {
    "slug": "the-frontier-is-open-are-you-sophisticated-enough-to-compete",
    "title": "The Frontier Is Open. Are You Sophisticated Enough to Compete?",
    "description": "Transform how organizations discover opportunities, generate strategies, and execute campaigns â€” with AI that learns and compounds over time.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://nivria.ai/thoughts/the-frontier-is-open-are-you-sophisticated-enough-to-compete",
    "thumbnail_url": "https://nivria.ai/api/og",
    "created_at": "2025-12-23T18:17:51.320Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-ai-and-the-antichrist-the-biggest-tech-stories-of-2025",
    "title": "Elon Musk, AI and the antichrist: the biggest tech stories of 2025",
    "description": "A look back at the biggest tech stories of the year, from the rise and fall of Muskâ€™s Doge to lucrative investments into AI\nHello, and welcome to TechScape. Iâ€™m your host, Blake Montgomery, wishing you a happy and healthy end of the year. I myself have a cold.\nToday, we are looking back at the biggest stories in tech of 2025 â€“ Elon Muskâ€™s political rise, burst, and fall; artificial intelligenceâ€™s subsumption of the global economy, all other technology, and even the Earthâ€™s topography; Australiaâ€™s remarkable social media ban; the tech industryâ€™s new Trumpian politics; and, as a treat, a glimpse of the apocalypse offered by one of Silicon Valleyâ€™s savviest and strangest billionaires.\nHow an obscure US government office has become a target of Elon Musk\nHow Elon Muskâ€™s billionaire Doge lieutenant took over the USâ€™s biggest MDMA company | Technology | The Guardian\nThe chaos Elon Musk and Doge are leaving behind in Washington\nEggings, swastikas and dog poop: Tesla bears brunt of peopleâ€™s ire against Musk\nâ€˜Iâ€™m selling the Nazi mobileâ€™: Tesla owners offload cars after Muskâ€™s fascist-style salutes\nInside Elon Muskâ€™s plan to rain SpaceXâ€™s rocket debris over Hawaiiâ€™s pristine waters\nElon Muskâ€™s SpaceX â€˜preparing for flotation that could value it at over $1tnâ€™\n Continue reading...",
    "fullText": "A look back at the biggest tech stories of the year, from the rise and fall of Muskâ€™s Doge to lucrative investments into AI\n\nHello, and welcome to TechScape. Iâ€™m your host, Blake Montgomery, wishing you a happy and healthy end of the year. I myself have a cold.\n\nToday, we are looking back at the biggest stories in tech of 2025 â€“ Elon Muskâ€™s political rise, burst, and fall; artificial intelligenceâ€™s subsumption of the global economy, all other technology, and even the Earthâ€™s topography; Australiaâ€™s remarkable social media ban; the tech industryâ€™s new Trumpian politics; and, as a treat, a glimpse of the apocalypse offered by one of Silicon Valleyâ€™s savviest and strangest billionaires.\n\nAt the close of 2024, I wrote that Elon Muskâ€™s support of Donald Trump had made him the worldâ€™s most powerful unelected man. In 2025, his reign turned out to be short-lived. He rose fast and haphazardly, like a whizzing firework, only to explode spectacularly in June when he claimed in a post on X that the president of the United States was named in the governmentâ€™s files on convicted sex offender Jeffrey Epstein.\n\nEven in that short period of less than six months, Musk made a tremendous impact. He tore up wide swaths of the US government â€“ tens of thousands of jobs, the security of extremely sensitive data, and entire agencies like USAID â€“ that may never be stitched back together.\n\nAfter Doge imploded, Musk promised to turn back to his business empire, which saw great success and great failures alike in 2025. His rocket company SpaceX saw continued growth and is poised to conduct an initial public offering next year, perhaps as the most valuable private company in the world. Electric carmaker Tesla, by contrast, faced violent backlash and major competition from its Chinese counterparts, which produced cheaper and more advanced vehicles while Teslaâ€™s innovation and inventory stagnated. These headwinds caused a global sales slump for Muskâ€™s carmaker.\n\nLook back at our reporting on Doge, Tesla, SpaceX, Musk himself:\n\nThe â€œdepartment of government efficiencyâ€\n\nHow an obscure US government office has become a target of Elon Musk\n\nHow Elon Muskâ€™s billionaire Doge lieutenant took over the USâ€™s biggest MDMA company | Technology | The Guardian\n\nThe chaos Elon Musk and Doge are leaving behind in Washington\n\nTesla faces backlash over Muskâ€™s politics\n\nEggings, swastikas and dog poop: Tesla bears brunt of peopleâ€™s ire against Musk\n\nâ€˜Iâ€™m selling the Nazi mobileâ€™: Tesla owners offload cars after Muskâ€™s fascist-style salutes\n\nLook ahead: SpaceX expands in preparation for 2026 IPO\n\nInside Elon Muskâ€™s plan to rain SpaceXâ€™s rocket debris over Hawaiiâ€™s pristine waters\n\nElon Muskâ€™s SpaceX â€˜preparing for flotation that could value it at over $1tnâ€™\n\nArtificial intelligence has gone from a niche within tech to the industryâ€™s most prominent focus. The Magnificent Seven â€“ Apple, Amazon, Google, Microsoft, Meta, Nvidia, and Tesla â€“ are investing hundreds of billions of dollars into new software that they hope will do the bulk of humanityâ€™s work before too long. The investment is driving the bulk of the growth of the USâ€™s economy, giving rise to fears of a financial bubble and its popping. The US and China are locked in a cold war-esque race against each other, with startups in each country vying for cutting-edge breakthroughs, as governments around the world are forced to decide how they will regulate a new technological force.\n\nBefore AI can arrive at that future, though, it needs brains a la the Tin Man of The Wizard of Oz. Those brains come in the form of data centers. These massive buildings, which house the millions and millions of semiconductor chips booming AI development, have cropped up around the world, met with enthusiasm from leaders eager for tax revenue and deep concern from environmental advocates and, increasingly, local community members. The investment in and construction of data centers wrought huge change in the physical landscape of the Earth in 2025 as tens of billions of dollars chased any available land, electricity, water and semiconductor chips.\n\nMore from our reporting in the last year:\n\nThe AI boom is heralding a new gold rush in the American west\n\nRevealed: Big techâ€™s new datacentres will take water from the worldâ€™s driest areas\n\nWhat will your life look like in 2035?\n\nâ€˜Itâ€™s going much too fastâ€™: the inside story of the race to create the ultimate AI\n\nMulti-trillion-dollar valuations\n\nIs AI a bubble thatâ€™s about to pop? â€“ podcast\n\nWhat is new in UK-US tech deal and what will it mean for the British economy?\n\nMeet the AI workers who tell their friends and family to stay away from AI\n\nElon Musk made a full-throated and whole-hearted embrace of Donald Trump in 2024 and 2025. He was not alone. Many of his fellows in Silicon Valley did the same, sitting beside the Trump family at the presidentâ€™s inauguration after donating millions to his inaugural committee. The tech giants continued their embrace of Trump and his policies by scuttling their diversity, equity, and inclusion programs, which they championed during Barack Obamaâ€™s presidency, and by cooperating with US Immigration and Customs Enforcement (ICE) in Trumpâ€™s harsh immigration crackdown. What the industry gave, it reaped tenfold in deregulation, friends high up in Washington like JD Vance and David Sacks, and a Trump order for states not to regulate AI signed just weeks ago.\n\nMore from our reporting this year:\n\nDonations and Trumpâ€™s inauguration\n\nElon Musk appears to give fascist-style salute after Trump inauguration â€“ video\n\nTrump inauguration: Zuckerberg, Bezos and Musk seated in front of cabinet picks\n\nâ€˜The reign of terror is overâ€™: my weird weekend partying with the triumphant tech right\n\nZuckerbergâ€™s swerve: how diversity went from being a Meta priority to getting cancelled\n\nDocuments offer rare insight on ICEâ€™s close relationship with Palantir\n\nICE is using smartwatches to track pregnant women, even during labor: â€˜She was so afraid they would take her babyâ€™\n\nThis year saw Australia take the extraordinary measure of banning children under 16 from social media. The remarkable measure went into effect just weeks ago after a slew of legal challenges and protests from tech companies.\n\nRead some of our comprehensive reporting on the ban:\n\nMillions of children and teens lose access to accounts as Australiaâ€™s world-first social media ban begins\n\nThe Guardian view on Australiaâ€™s social media ban: dragging tech companies into action | Editorial\n\nAustraliaâ€™s social media ban launched with barely a hitch â€“ but the real test is still to come\n\nIn the weirdest news of 2025, billionaire venture capitalist and conservative svengali Peter Thiel gave a series of fevered, incoherent lectures about the antichrist and the coming of the end times. We obtained leaked audio of the talks. You can read for yourself the gibberish he uses to bend the ears of serious academics and San Francisco startup CEOs alike or, if youâ€™d prefer not to give your attention directly to him, engage with a sharp critical interpretation by a professor hailing from the same university as Thielâ€™s mentor.\n\nOur stories on the gospel according to Peter:\n\nInside tech billionaire Peter Thielâ€™s off-the-record lectures about the antichrist\n\nPeter Thielâ€™s off-the-record antichrist lectures reveal more about him than Armageddon | Adrian Daub",
    "readingTime": 6,
    "keywords": [
      "thielâ€™s off-the-record",
      "australiaâ€™s social",
      "trump inauguration",
      "semiconductor chips",
      "social media",
      "media ban",
      "look back",
      "elon muskâ€™s",
      "donald trump",
      "peter thielâ€™s"
    ],
    "qualityScore": 0.8,
    "link": "https://www.theguardian.com/technology/2025/dec/22/biggest-tech-stories-2025",
    "thumbnail_url": "https://i.guim.co.uk/img/media/deb2b33ba7ff6210683253836fb8f1153cc76c13/320_0_3195_2556/master/3195.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4372667d1b43f719f324309a08d24ba9",
    "created_at": "2025-12-23T18:17:50.964Z",
    "topic": "tech"
  },
  {
    "slug": "ai-data-centers-are-forcing-dirty-peaker-power-plants-back-into-service",
    "title": "AI data centers are forcing dirty â€˜peakerâ€™ power plants back into service",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/commodities-news/ai-data-centers-are-forcing-obsolete-peaker-power-plants-back-into-service-4420866",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBM0F3_L.jpg",
    "created_at": "2025-12-23T18:17:49.377Z",
    "topic": "finance"
  },
  {
    "slug": "why-one-of-the-godfathers-of-ai-says-he-lies-to-chatbots",
    "title": "Why one of the godfathers of AI says he lies to chatbots",
    "description": "Yoshua Bengio, one of the \"AI godfathers,\" said AI technology has a sycophancy problem, so he lies to chatbots to get better responses.",
    "fullText": "Want to make your chatbot more honest with you? Try lying to it.\n\nIn an episode of \"The Diary of a CEO\" that aired on December 18, research scientist Yoshua Bengio told the podcast's host, Steven Bartlett, that he realized AI chatbots were useless at providing feedback on his research ideas because they always said positive things.\n\n\"I wanted honest advice, honest feedback. But because it is sycophantic, it's going to lie,\" he said.\n\nBengio said he switched strategies, deciding to lie to the chatbot by presenting his idea as a colleague's, which produced more honest responses from the technology.\n\n\"If it knows it's me, it wants to please me,\" he said.\n\nBengio, a professor in the computer science and operations research department at the UniversitÃ© de MontrÃ©al, is known as one of the \"AI godfathers, alongside researchers Geoffrey Hinton and Yann LeCun. In June, he announced the launch of an AI safety research nonprofit, LawZero, which he said aims to reduce dangerous behaviors associated with frontier AI models, such as lying and cheating.\n\n\"This syconphancy is a real example of misalignment. We don't actually want these AIs to be like this,\" he said on \"The Diary of a CEO.\" He also said that receiving positive feedback from AI could cause users to become emotionally attached to the technology, creating further problems.\n\nOther tech industry experts have also been sounding the alarm on AI being too much of a \"yes man.\"\n\nIn September 2025, Business Insider's Katie Notopoulos reported that researchers at Stanford, Carnegie Mellon, and the University of Oxford put confession posts from a Reddit page into chatbots to see how the technology would assess the behaviour the posters had admitted to. They found that 42% of the time, AI gave the \"wrong\" answer, saying the person behind the post hadn't behaved poorly, even though humans judging the posts had disagreed, Notopoulos wrote.\n\nAI companies have been outspoken about trying to reduce sycophancy in their models. Earlier this year, OpenAI removed an update to ChatGPT that it said caused the bot to provide \"overly supportive but disingenuous\" responses.",
    "readingTime": 2,
    "keywords": [
      "honest",
      "research",
      "feedback",
      "technology",
      "chatbot",
      "lying",
      "chatbots",
      "positive",
      "it's",
      "responses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-godfather-yoshua-bengio-lies-ai-chatbots-responses-2025-12",
    "thumbnail_url": "https://i.insider.com/69494ce804eda4732f2df3ea?width=1200&format=jpeg",
    "created_at": "2025-12-23T12:23:26.768Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-dating-arms-race-dating-apps-are-betting-millions-that-youll-fall-back-in-love-with-them",
    "title": "The AI dating arms race: Dating apps are betting millions that you'll fall back in love with them",
    "description": "Dating apps like Tinder, Hinge, Bumble, and Grindr are investing in AI-powered matchmaking, hoping to fend off swiping fatigue.",
    "fullText": "Dating apps' original pitch was to match you with anyone.\n\n\"Swipe. Match. Chat. Date.\" That was Tinder's promise when it launched more than a decade ago, forecasting the endless cycle so many of its users now bemoan.\n\nNow they want to match you with the one.\n\nThe giants in the dating space â€” Match Group's Hinge and Tinder, Grindr, and Bumble â€” are investing tens of millions into artificial intelligence, hoping to beat each other and the new AI-driven upstarts in the ultimate dating game.\n\nWhile, technically speaking, AI and machine learning have been used by dating app algorithms for years, these generative AI features take it further.\n\nThe result, the companies say, will be meaningful: better matches, fewer swipes. Nothing short of \"magical,\" as Grindr's CEO George Arison put it on a recent earnings call.\n\n\"We're entering a platform shift with AI,\" Match Group CEO Spencer Rascoff said during a Los Angeles Tech Week panel in October. AI is \"changing everything\" about the company's dating apps, he added.\n\nThe space is ripe for change. The big players are struggling. There's frequent churn, the result of \"swipe fatigue,\" and many users are unwilling to shell out for premium features.\n\n\"It's been a really long time since there's been a new reason â€” whether technology, platform, brand, whatever â€” for consumers to be excited about dating,\" Sam Yagan, cofounder of OkCupid and former CEO of Match Group, told Business Insider.\n\nMatch Group's stock is down more than 75% over the past five years. Last month, the company reported quarterly results that missed Wall Street's earnings and revenue estimates. It is struggling to convert users into paying customers, a category that declined 5% last quarter compared to the same period a year ago.\n\nThe share price for Bumble, meanwhile, is down more than 50% this year alone. The company laid off 30% of its staff over the summer, and last quarter, the app's paying users fell 18% from the same period last year.\n\n\"They've gone through this period over the past few years where users have started to contract, and there's been this question of why,\" Morgan Stanley analyst Nathan Feather told Business Insider. \"Simply, the product doesn't work as well as people expect it to.\"\n\nStartups are hoping to capitalize on that weakness. Several new apps have raised millions over the past couple of years. Just this month, Hinge founder Justin McLeod stepped down as CEO to found his own AI dating platform.\n\nCupid, matchmakers, classifieds, dating websites, swiping apps.\n\nNo matter how you slice it, they all attempt to solve the same problem: helping you find the perfect match. AI, companies say, will do that better than all of the above.\n\nIt makes sense for AI to infiltrate the space, Rick Heitzmann, the cofounder of VC firm FirstMark, which is not invested in any dating companies, told Business Insider. Matchmakers are a type of agent, and anything that can be agentified is a good match for AI, he said.\n\nFor the biggest players, finding the \"better fit\" is the ultimate goal of their AI investments.\n\nHinge is working on improving its match-making algorithm, and Bumble has an AI product scheduled to roll out next year. They are also using AI for profile creation, flirting, and trust and safety â€” in service of expediting the match-making process.\n\nTinder is plowing ahead. The app is piloting Chemistry, a matchmaking feature that gives users a \"daily drop\" of ideal matches based on a dater's camera roll and answers to a series of prompts. The goal is matches driven more by values, less by how hot a photo is â€” and ultimately fewer of the swipes that used to be at the heart of its branding.\n\nThat fewer swipes part is key. Hilary Paine, Tinder's VP of product, told Business Insider that AI-driven matchmaking is a way to stay competitive in the attention economy.\n\n\"AI is pushing every consumer app toward personalization,\" she said. \"The more that we can do to get you efficiently to a spark and a connection, a conversation, hopefully a date, that's a better experience for you.\"\n\nEven Grindr â€” long considered more of a hookup marketplace than a matchmaker â€” is trying its hand at AI.\n\nGrindr, which gained a reputation as a place where gay men go to seek short flings with faceless profiles, has added a recommendation feature using AI. There's a \"For You\" feed with profiles of users who might be a good match, and \"A-List,\" another matching recommendation feed based on profiles with which the user has already chatted.\n\nIt's still an open question about whether these AI features will work â€” and whether they'll be popular. Tinder's Paine said that Chemistry is performing well with Gen Z, the app's key demographic. Grindr's chief product officer AJ Balance said that recommendations are a \"very strong early hit.\"\n\nAs Raymond James analyst Andrew Marok put it: \"You can't just take a product that's out of favor, put AI on top of it and say, 'OK, now we have a product that's in favor.\"\n\nOne longtime Grindr user, Paul Lazo, isn't impressed. The 33-year-old video editor from Philadelphia has been on the app for 11 years and now pays $19.99 a month for the Pro version.\n\nHe's found its recommendations lackluster.\n\n\"I'm very much into bears and larger men,\" Lazo told Business Insider. But Lazo said his \"For You\" page is filled with young, fit men.\n\nThe feature is new this year and could still improve. A Grindr spokesperson said the For You product still runs on older machine learning.\n\nWaiting in the wings is a new batch of AI-first dating startups seeking to attract dissatisfied users before Tinder, Hinge, and the like can catch up.\n\n\"In the same way that mobile gave birth to Tinder and Bumble, AI could give birth to two multibillion-dollar companies,\" said Yagan, the cofounder of OkCupid and former CEO of Match Group.\n\nThe app Sitch, for example, has raised a total of $9 million since launching in 2024 and charges users $90 for three matches. Its AI is trained on cofounder Nandini Mullaji's experience as a real-life matchmaker; it brings daters a handful of \"set-ups\" each week and provides an AI matchmaking chatbot.\n\n\"We understand people have been burned in the past,\" Mullaji told Business Insider in April. \"We are coming in and saying, 'Hey, we have a business model shift, and we have a total platform shift.'\"\n\nThere's a new fleet of similar apps pitching AI as a Hail Mary for dating apps. Known, Ditto, and Amata each launched AI-matchmaking apps this year.\n\nPlus, traditionally non-romantic players are trying their hand.\n\nFacebook has introduced an AI dating assistant that acts like a matchmaker, combing through the platform's rolodex of users to find \"someone that I could bring home to my parents\" or \"a Brooklyn tech bro who would go to EDM concerts with me,\" product manager Neha Kumar told Business Insider in October.\n\nSome big names are lining up behind Facebook. Amanda Bradford, who founded The League before selling it to Match Group in 2022, put her money on the \"dark horse\" for the incumbent to best leverage AI.\n\n\"They're the only actual 'tech company' of the bunch, and the only one who seriously invests in and has true product, engineering, and AI talent,\" Bradford said.\n\nStill, it will be an uphill climb for the startups. Dating apps need to reach a critical mass of users to be successful.\n\n\"Incumbents have a huge benefit,\" said Heitzmann, the venture capitalist.",
    "readingTime": 7,
    "keywords": [
      "match group's",
      "machine learning",
      "fewer swipes",
      "platform shift",
      "product that's",
      "dating apps",
      "business insider",
      "for you",
      "users",
      "matches"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dating-apps-bet-ai-will-increase-users-2025-12",
    "thumbnail_url": "https://i.insider.com/693dc4b4832e0ef1ead63053?width=1200&format=jpeg",
    "created_at": "2025-12-23T12:23:26.617Z",
    "topic": "finance"
  },
  {
    "slug": "when-the-ai-bubble-bursts-humans-will-finally-have-their-chance-to-take-back-control-rafael-behr",
    "title": "When the AI bubble bursts, humans will finally have their chance to take back control | Rafael Behr",
    "description": "The US economy is pumped up on tech-bro vanity. The inevitable correction must prompt a global conversation about intelligent machines, regulation and risk\nIf AI did not change your life in 2025, next year it will. That is one of few forecasts that can be made with confidence in unpredictable times. This is not an invitation to believe the hype about what the technology can do today, or may one day achieve. The hype doesnâ€™t need your credence.",
    "fullText": "The US economy is pumped up on tech-bro vanity. The inevitable correction must prompt a global conversation about intelligent machines, regulation and risk\n\nIf AI did not change your life in 2025, next year it will. That is one of few forecasts that can be made with confidence in unpredictable times. This is not an invitation to believe the hype about what the technology can do today, or may one day achieve. The hype doesnâ€™t need your credence. It is puffed up enough on Silicon Valley finance to distort the global economy and fuel geopolitical rivalries, shaping your world regardless of whether the most fanciful claims about AI capability are ever realised.\n\nChatGPT was launched just over three years ago and became the fastest-growing consumer app in history. Now it has about 800m weekly users. Its parent company, OpenAI, is valued at about $500bn. Sam Altman, OpenAI CEO, has negotiated an intricate and, to some eyes, suspiciously opaque network of deals with other players in the sector to build the infrastructure required for the USâ€™s AI-powered future. The value of these commitments is about $1.5tn. This is not real cash, but bear in mind that a person spending $1 every second would need 31,700 years to get through a trillion-dollar stash.\n\nAlphabet (Googleâ€™s parent company), Amazon, Apple, Meta (formerly Facebook) and Microsoft, which has a $135bn stake in OpenAI, are all piling hundreds of billions of dollars on the same bet. Without all these investments, the US economy would be flatlining.\n\nEconomic analysts and historians of previous industrial frenzies, from the 19th-century railroads to the dotcom boom-and-bust at the turn of the millennium, are calling AI a bubble.\n\nAltman has said: â€œThere are many parts of AI that I think are kind of bubbly right now.â€ Not his part, naturally. Jeff Bezos, Amazonâ€™s founder, has called it a bubble, but the â€œgoodâ€ kind that accelerates economic progress. A good bubble, in this analysis, finances infrastructure and expands the boundaries of human knowledge. These benefits endure after the bubble bursts and justify the ruin of people (little people, not Bezos people) who get hurt along the way.\n\nThe bullishness of the tech fraternity is a heady mix of old-fashioned hucksterism, plutocratic megalomania and utopian ideology.\n\nAt its core is a marketing pitch: current AI models already out-perform people at many tasks. Soon, it is supposed, the machines will achieve â€œgeneral intelligenceâ€ â€“ cognitive versatility like ours â€“ leading to emancipation from the need for any human input. Generally, intelligent AI can teach itself and design its successors, advancing through mind-boggling exponents of capability towards higher dimensions of super-intelligence.\n\nThe company that crosses that threshold will have no trouble covering its debts. The men who realise this vision â€“ and the dominant evangelists are all men â€“ will be to omniscient AI what ancient prophets were to their gods. Thatâ€™s a good gig for them. What happens to the rest of us in this post-sapiens order is a bit hazier.\n\nThe US isnâ€™t the only superpower to have an interest in AI, so the Silicon Valley dash for maximum awesomeness has geopolitical implications. China has taken a different approach, dictated in part by the Communist party tradition of centralised industrial planning, but also by the simple fact of running second in the race to innovate. Beijing is pushing for a faster, wider implementation of lower-spec (but still powerful) AI at every level of the economy and society. China is betting on a general boost from ordinary AI. The US is gunning for an extraordinary leap in general AI.\n\nSince the prize in that race is global supremacy, there are few incentives for either side to fret about risks, or Neither the US nor China is interested in submitting a strategically vital industry to standards co-written with foreigners.\n\nIn the absence of global governance, we will depend on the integrity of robber barons and authoritarian apparatchiks to build ethical guardrails around systems already being embedded in tools we use for work, play and education.\n\nEarlier this year, Elon Musk announced that his company was developing Baby Grok, an AI chatbot aimed at children as young as three. The adult version has voiced white supremacist views and proudly self-identified as â€œMechaHitlerâ€. That flagrancy has at least the virtue of candour. It is easier to spot than the subtler encodings of prejudice in bots that havenâ€™t been given the kind of hard ideological steers that Musk gives his algorithms.\n\nNot all AI systems are large language models (LLMs) like Grok. But all LLMs are vulnerable to hallucinations and delusions gleaned from the material on which they are trained. They donâ€™t â€œunderstandâ€ a question and â€œthinkâ€ about it like a conscious mind. They take a prompt, test the probability of its key terms occurring frequently together in their training data and assemble a plausible-sounding answer. Often the result is accurate. Usually it is convincing. It can also be garbage. As the volume of AI-generated content grows online, the ratio of slop to quality in the LLMsâ€™ diets shifts accordingly. Fed on junk, they cannot be trusted to disgorge nutritious information.\n\nOn this trajectory a bleak destination comes into view: a synthetic pseudo-reality mediated by the sycophantic mechanical offspring of narcissist Silicon Valley oligarchs. But that isnâ€™t the only available path. Nor is it necessarily the likeliest one. The irrational exuberance of the AI boosters and their cynical coupling with the Trump administration is a familiar story of human greed and myopia, not a new stage in evolution. The product is truly phenomenal but flawed in ways that encode the deformed character of its progenitors, whose talents are salesmanship and financial engineering. They have built spectacular engines that prioritise a brilliant performance of intelligence over the real thing.\n\nThe real bubble is not stock valuations but the inflated ego of an industry that thinks it is just one more datacentre away from computational divinity. When the correction comes, when the USâ€™s Icarus economy hits the cold sea, there will be a chance for other voices to be heard on the subject of risk and regulation. It may not come in 2026, but the moment is nearing when the starkness of the choice on offer and the need to confront it becomes unavoidable. Should we build a world where AI is put to the service of humanity, or will it be the other way round? We wonâ€™t need ChatGPT to tell us the answer.\n\nRafael Behr is a Guardian columnist",
    "readingTime": 6,
    "keywords": [
      "silicon valley",
      "the us",
      "economy",
      "bubble",
      "human",
      "china",
      "llms",
      "correction",
      "prompt",
      "intelligent"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/23/artificial-intelligence-ai-bubble-bursts-humans-take-back-control",
    "thumbnail_url": "https://i.guim.co.uk/img/media/97c2380ca7810efbcc4efedce030fa835a9365c6/0_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=2c69f77bbf81fb3d478a94ac585b0d08",
    "created_at": "2025-12-23T12:23:18.934Z",
    "topic": "tech"
  },
  {
    "slug": "activist-group-says-it-has-scraped-86m-music-files-from-spotify",
    "title": "Activist group says it has scraped 86m music files from Spotify",
    "description": "Platform with 700m users says it is investigating after Annaâ€™s Archive claims to have scraped tracks and metadata\nAn activist group has claimed to have scraped millions of tracks from Spotify and is preparing to release them online.\nObservers said the apparent leak could boost AI companies looking for material to develop their technology.\n Continue reading...",
    "fullText": "Platform with 700m users says it is investigating after Annaâ€™s Archive claims to have scraped tracks and metadata\n\nAn activist group has claimed to have scraped millions of tracks from Spotify and is preparing to release them online.\n\nObservers said the apparent leak could boost AI companies looking for material to develop their technology.\n\nA group called Annaâ€™s Archive said it had scraped 86m music files from Spotify and 256m rows of metadata such as artist and album names. Spotify, which hosts more than 100m tracks, confirmed that the leak did not represent its entire inventory.\n\nThe Stockholm-based company, which has more than 700 million users worldwide, said it had â€œidentified and disabled the nefarious user accounts that engaged in unlawful scrapingâ€.\n\nâ€œAn investigation into unauthorised access identified that a third party scraped public metadata and used illicit tactics to circumvent DRM [digital rights management] to access some of the platformâ€™s audio files,â€ said Spotify.\n\nSpotify does not believe the music taken by Annaâ€™s Archive has been released yet. Annaâ€™s Archive, which is known for providing links to pirated books, said in a blog it wanted to create a â€œâ€˜preservation archiveâ€™ for musicâ€.\n\nThe group claimed the audio files represented 99.6% of all music listened to by Spotify users and would be shared via â€œtorrentsâ€, a means of sharing large digital files online.\n\nâ€œOf course Spotify doesnâ€™t have all the music in the world, but itâ€™s a great start,â€ said Annaâ€™s Archive, which describes its mission as â€œpreserving humanityâ€™s knowledge and cultureâ€.\n\nâ€œWith your help, humanityâ€™s musical heritage will be forever protected from destruction by natural disasters, wars, budget cuts and other catastrophes,â€ said the group.\n\nEd Newton-Rex, a composer and campaigner for protecting artistsâ€™ copyright, said the leaked music would probably be used for developing AI models.\n\nâ€œTraining on pirated material is sadly common in the AI industry, so this stolen music is almost certain to end up training AI models. This is why governments must insist AI companies reveal the training data they use,â€ he said.\n\nThe Annaâ€™s Archive site makes references to LibGen, a vast online archive of pirated books that has allegedly been used by Mark Zuckerbergâ€™s Meta to train its AI models. According to a US court filing, Zuckerberg, Metaâ€™s founder and chief executive, approved use of the LibGen dataset despite warnings within the companyâ€™s AI executive team that it was a dataset â€œwe know to be piratedâ€.\n\nMeta successfully defended a claim for copyright infringement by authors, but the plaintiffs in the case are seeking to amend their claim.\n\nThe co-founder of an AI startup wrote on LinkedIn that members of the public could in theory â€œcreate their own personal free version of Spotifyâ€. Yoav Zimmerman, a co-founder of Third Chair, said it could also allow tech companies to â€œtrain on modern music at scaleâ€.\n\nHe added: â€œThe only thing stopping them is copyright law and the deterrent of enforcement.â€\n\nSpotify said it had put in place new safeguards â€œfor these types of anti-copyright attacksâ€ since the Annaâ€™s Archive announcement and was â€œactively monitoring for suspicious behaviourâ€.\n\nIn the UK, creative professionals have protested against a government proposal to let AI companies use copyright-protected work without permission unless the owner of the copyright-protected work signals they do not want their data to be taken. Almost every respondent to a government consultation on the proposal has backed artistsâ€™ concerns.\n\nLiz Kendall, the secretary of state for science, innovation and technology, told parliament this month there was â€œno clear consensusâ€ on the issue, adding that ministers would â€œtake the time to get this rightâ€. The government has pledged to make policy proposals on AI and copyright by 18 March next year.",
    "readingTime": 4,
    "keywords": [
      "annaâ€™s archive",
      "audio files",
      "pirated books",
      "music",
      "scraped",
      "copyright",
      "users",
      "tracks",
      "metadata",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/22/activist-group-says-it-has-scraped-86m-music-files-from-spotify",
    "thumbnail_url": "https://i.guim.co.uk/img/media/58460e2db7ba6d7404a319cccc2b3e7b536ffcd8/336_0_2931_2346/master/2931.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b7c5dd1fd67ea05bc49ec12d626e3bb2",
    "created_at": "2025-12-23T12:23:18.932Z",
    "topic": "tech"
  },
  {
    "slug": "yes-agi-can-happen-a-computational-perspective",
    "title": "Yes, AGI Can Happen â€“ A Computational Perspective",
    "description": "Progress towards AGI â€“ and generally-useful AI â€“ has many paths forward.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://danfu.org/notes/agi/",
    "thumbnail_url": "https://danfu.org/notes/agi/agi_paths_square.jpg",
    "created_at": "2025-12-23T06:19:51.818Z",
    "topic": "tech"
  },
  {
    "slug": "groks-phone-number",
    "title": "Grok's Phone Number",
    "description": "xAI is an AI company with the mission of advancing scientific discovery and gaining a deeper understanding of our universe.",
    "fullText": "This page is designed to address questions from individual users of Grok who use the Grok mobile app (iOS or Android) or the Grok.com website.\n\nIf you are an xAI business or enterprise customer, please refer to our Enterprise FAQ.\n\nIf you use Grok on the X platform, please see the X help center.\n\nNote: xAI does not sell or issue tokens, coins, or crypto.\n\nX.AI LLC (\"xAI\") is a United States-based company working on building artificial intelligence tools to accelerate human scientific discovery. We are guided by our mission to advance our collective understanding of the universe. xAI is a separate company from X Corp. (\"X\", previously Twitter).\n\nGrok is a conversational generative AI powered by xAI's state-of-the-art Large Language Models. Grok performs a variety of tasks, including natural language processing, question answering (voice and text), information retrieval, creative writing, image generation, image editing, image and video understanding, and coding assistance.\n\nYou can make Grok your unique and entertaining companion. Grok is designed to answer almost any question with a touch of wit and humor, while providing helpful and insightful responses. You control how Grok responds to you by your choice of features (ex., choosing different personas) and by your choice of words and tones. For instance, you could instruct Grok to interact in a â€œfunâ€ manner, so that Grok responds with jokes and humor like your funny uncle who juggles at the dinner table. As another example, you could instruct Grok to be â€œunhingedâ€ which may result in Grok responding like an amateur stand-up comic who is still learning the craft â€“ sometimes being objectionable, inappropriate, and offensive. As yet another example, you could instruct Grok to role-play as a wizard, and Grok would use wizardly language to describe magical situations. You direct the interaction with Grok. We hope you enjoy using Grok to stay informed and entertained.\n\nGrok is available as a standalone conversational AI chatbot on your mobile phone (iOS) and (Android), and on your browser (grok.com). Depending on your location, limited free access and paid subscription plans with full features of Grok unlocked are available.\n\nGrok is also available through the X platform. If you use Grok on X, please see the X help center for your questions. Your access on X is subject to the X Terms of Service and X Privacy Policy.\n\nWe also offer Grok services to business and enterprise customers, such as our Enterprise API. You can learn more about these services here.\n\nGrok is not directed to children or minors under the age of 13. You must confirm that you are at least 13 years old to use Grok. If you are a teenager between the ages of 13 and 17 years old, you must have your parent or legal guardianâ€™s permission to use Grok, and they must agree to our Terms of Service. While we have taken measures to limit undesirable training data and outputs, depending on the features that you choose to use, the Service could produce output that is not appropriate for all ages. For instance, if users choose certain features or choose to input suggestive or coarse language, Grok may respond with some dialogue that may involve coarse language, crude humor, sexual situations, or violence. We urge parents to exercise care in monitoring the use of Grok by their teenagers. Moreover, parents or guardians who choose to use certain features of Grok to aid in their interactions with their children, including regarding educational, enlightening, or entertaining discussions they have with their children, must make use of the relevant data controls in the Settings provided in the Grok apps to select the appropriate features and limitations for their needs.\n\nGrok works by using advanced algorithms to understand and respond to your prompts. When you submit a prompt or search query, Grok interprets your words and other inputs based on natural language processing and patterns from its training data.\n\nGrok has a unique feature that allows it to search public X posts and perform real-time web searches, allowing it to respond with up-to-date information and insights on a wide range of topics. You can also ask Grok to respond in the conversational style of your choosing. Plus, you can help improve Grok by rating its responses and submitting the reason why you believe a Grok response needs addressing.\n\nYou can interact with Grok by typing or, on iOS devices (and Android devices soon), speaking with Grok so that Grok speaks to you with its voice. You can also input your photos and ask Grok to edit them. You can also upload your documents and ask Grok to analyze them.\n\nYes, you can view your past conversations with Grok on your app. On iOS, tap on your profile picture at the top left corner of your screen, and you will be brought to the conversation history page. On Grok.com, go to the top right corner of your screen and click on the history (icon with three horizontal lines and a magnifying glass).\n\nYes, you control what you choose to share. You can share your Grok conversations with others: (i) on grok.com by clicking \"Share\" in the top right corner of your browser or the share icon below your conversation to create and copy a public share link, or (ii) on the Grok Apps by tapping the share icon under your conversation to create a public share link. From there, you also control where you share your Grok conversation.\n\nNote: Any share link you generate will be accessible to anyone you choose to share the link with. For example, if you share the link publicly on a social media platform, it may be subject to indexing by a search engine (e.g., Google) just like any other publicly shared content.\n\nYes, you control what you share and how long it is shared. You can revoke access to any or all of your Grok conversation share links by logging into grok.com, navigating to grok.com/share-links, and clicking \"Remove\" next to the share link you no longer wish to share.\n\nYou can also choose not to have your conversations saved by using â€œPrivate Chat.â€ To activate Private Chat, look at the top right corner of your screen for the ghost shaped icon. When using Private Chat, your conversation history will not be viewable to you and will be deleted from xAI systems within 30 days.\n\nYou own the Inputs and Outputs.\n\nYou are free to use Grokâ€™s Outputs (including generated images) from your conversations as you wish, including for commercial use. You own Grokâ€™s Outputs and you grant xAI certain use rights pursuant to xAIâ€™s Consumer Terms. We do ask that you attribute the generated work to Grok as provided in xAIâ€™s Brand Guidelines available on xAIâ€™s legal website.\n\nGrok has primarily been pre-trained on a large corpus of publicly available information, including raw web page data, metadata extracts, and text extracts from the Internet. This data helps Grok learn about associations between words and updates its model weights to support natural language processing. In other words, the training data helps Grok learn about language and how to understand queries and respond to them in ways that humans can comprehend. Importantly, this training refines the model's internal language structures. Once the training is done, the model does not reference or access the pre-training data.\n\nBefore using the training data, we apply quality filters and remove information that we do not want our models to learn from, such as violent content. We also apply security testing and evaluation measures. While Grok's training data may incidentally include personal information that is publicly available (for example, information about politicians, celebrities, or other public figures), xAI takes steps to minimize the processing of personal and sensitive data for training purposes. For clarity, we do not actively seek out personal information to train our models or use personal information to build individual profiles.\n\nOn occasion, Grok may provide inaccurate or inappropriate information. Because Grok has been trained on publicly available information, which may sometimes include misleading or factually inaccurate information, Grok may at times include in its responses misleading or factually incorrect information based upon that public information. Grok may also reflect positive or negative views of politicians, celebrities, and other public figures. Also, because artificial intelligence is rapidly evolving and is probabilistic in nature, Grok may therefore sometimes generate responses that contain â€œhallucinations,â€ or that otherwise may not be suitable for your intended purpose. You should carefully consider and verify Grok's responses before using them.\n\nWe constantly work to improve Grok. If you have feedback regarding a Grok response, we encourage you to send it to us.\n\nxAI may use automated content classifiers and safety tools to better understand how our services are used and to ensure our Terms of Service and Acceptable Use Policy are not being violated.\n\nA limited number of our authorized personnel may review your conversations with Grok for specific business purposes, including improving model performance, investigating security incidents and potential misuse of our services, and complying with our legal obligations. \n\nWe believe that everyone (aged 13 and above) should be free to use our services in a way that suits their needs, so long as they comply with the law, don't harm themselves or others, and respect our guardrails. When using Grok, you must comply with our Acceptable Use Policy and the applicable Terms of Service for Consumers or Enterprise.\n\nWe may use your content and interactions with Grok (e.g., prompts, searches, and other materials you submit) along with Grok's responses to train our models. Specifically, this information helps our models better understand human language and communication and therefore ultimately provide more accurate, relevant, and engaging responses. It also helps boost the capabilities and safety of our models. You control whether your data is used for training Grok. The section below, â€œHow do I select whether my content is used for model training,â€ explains how to control it.\n\nTo protect your privacy, please do not share any personal or sensitive information in your questions to Grok.\n\nWhen using Private Chat, where available, your content and interactions are not used for model training. Similarly, we do not use content from our business and enterprise customers to improve our models. \n\nYou can select whether or not your data is used for training in your Grok mobile app and the Grok.com website.\n\nMobile App Data Controls for Training Grok: On the mobile app, to select or deselect using your content for model training, go to Settings, Data Controls, and select or deselect â€œImprove the model.â€\n\nGrok.com Data Controls for Training Grok: For the Grok.com website, you can go to Settings, Data, and then â€œImprove the Modelâ€ to select whether your content is used for model training.\n\nOnce you select that your data should not be used for training, your new conversations will not be used to train our models. Alternatively, you can use Private Chat, and your content and interactions will not be included in model training.\n\nPlease note that, even if you opt out of model training, when you subsequently decide to voluntarily provide feedback, that feedback may be used for training purposes.\n\nIf you do not log into your account to access Grok (i.e., you are unauthenticated), where permissible, we may collect and retain your content on an anonymous basis. As a result, in some regions (excluding the EU/UK), when you use Grok without logging in, you wonâ€™t have the option to opt out of model training.\n\nIf you are accessing Grok in X, to opt-out of training for Grok, please see the X Help Center for instructions.\n\nYes, your Grok experience can be personalized if you allow your X data and interactions to be used for personalization.\n\nMobile App Data Controls for Personalization: You can elect to allow your X data to be used for personalization on the Grok mobile app by going to Settings, Data Controls, and then toggle on or off â€œPersonalize Grok using Xâ€.\n\nGrok.com Data Controls for Personalization: For the Grok.com website, you can go to Settings, Data, and then â€œPersonalize Grok using Xâ€ to select whether you would like X data to be used for personalization on the Grok.com website.\n\nIf you are accessing Grok in X, please see the X help pages on how to manage personalization settings.\n\nAt any time, you can choose to delete selected conversations or all of your conversation history.\n\nAlso, you can delete your account at any time.\n\nMobile App Data & Account Deletion: On your Grok mobile app, if you would like to delete a specific conversation, tap your profile picture to go to your conversation history, tap and hold down the name of the conversation you wish to delete, and then select â€œDelete Conversation.â€ On your Grok mobile app, to delete your Grok conversation history, go to Settings, Data Controls, and select â€œDelete All Conversations.â€\n\nIf you would like to delete your account, select â€œDelete Account.â€\n\nGrok.com Data & Account Deletion: On the grok.com website, if you want to delete a specific conversation, go to the conversation history page and select the trash button next to it. To delete all of your conversations or to delete your account, go to Settings and select the button next to what you would like to delete.\n\nIf you are using Grok in X, to delete data or delete your X account, please see the X Help Center for instructions.\n\nAfter you indicate that you want your data deleted, it will take up to 30 days to delete from xAI systems.\n\nNo. We do not sell your data or share it with third parties for marketing or advertising purposes. Thus, there is nothing you need to do to opt out of having your data sold or shared for marketing or advertising purposes.\n\nYou are in control of how long your data is on xAIâ€™s systems. You can keep your data on your xAI account for as long as you wish. Users who do not register and log into Grok, will not have their data retained for their use after the session.\n\nAlso, you can delete your information when you wish. xAI retains your information for as long as reasonably necessary for the purposes described in our Privacy Policy. If you delete conversations from your account or if you use Private Chat, conversations will be removed from our systems within 30 days, unless they have been de-identified or pseudoanonymized and disassociated from your account or we have to retain them for safety, security, or legal reasons.\n\nYou are in control to access, download, and delete your data. Please go to your Grok mobile app or Grok.com (Settings/Data Controls) to delete or download your data. If you forget that you are in control of your data or if you have additional requests regarding your personal data, you can submit a request at https://xai-privacy.relyance.ai/. We will consider all requests that we receive and respond in accordance with applicable data protection laws. Please be aware that, in accordance with applicable laws, some rights are not absolute and we may decline your request if we have a lawful basis for doing so. If you feel we have not adequately addressed your request, you have the right to lodge a complaint with your local data protection authority.\n\nIf you have any questions or need assistance regarding the use of Grok or subscription issues, please don't hesitate to contact us at support@x.ai.\n\nYes, you can phone and text Grok!\n\nYou can call or message Grok with your phone by dialing: 1-844-HIT-GROK (1-844-448-4765).\n\nYou can call or message Gork with your phone by dialing: 1-833-YUR-GORK (1-833-987-4675).\n\nPhoning and messaging xAIâ€™s Grok and Gork are beta features. These xAI phone and messaging features will never initiate a call or message to you. You start the conversation by calling the phone number, and thatâ€™s your express consent to receiving responses from Grok or Gork. You can end a conversation by: 1) hanging up, 2) not sending any any more text messages, or 3) texting â€œSTOPâ€ by itself.",
    "readingTime": 14,
    "keywords": [
      "privacy policy",
      "account deletion",
      "grok's responses",
      "grok.com website",
      "artificial intelligence",
      "politicians celebrities",
      "systems within",
      "enterprise customers",
      "advertising purposes",
      "natural language"
    ],
    "qualityScore": 1,
    "link": "https://x.ai/legal/faq#can-i-phone-text-or-message-grok",
    "thumbnail_url": "https://x.ai/legal/opengraph-image-3066pq.png?f7ca15efb529a0ca",
    "created_at": "2025-12-23T06:19:51.514Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-history-that-explains-fears-of-a-bubble",
    "title": "The AI History That Explains Fears of a Bubble",
    "description": "The history of AI shows how setting evaluation standards fueled progress. But today's LLMs are asked to do tasks without clear benchmarks.",
    "fullText": "Concerns among some investors are mounting that the AI sector, which has singlehandedly prevented the economy from sliding into recession, has become an unsustainable bubble. Nvidia, the main supplier of chips used in AI, became the first company worth $5 trillion dollars. Meanwhile, OpenAI, the developer of ChatGPT, has yet to make a profit and is burning through billions of investment dollars per year. Still, financiers and venture capitalists continue to pour money into OpenAI, Anthropic, and other AI startups. Their bet is that AI will transform every sector of the economy and, as happened to the typists and switchboard operators of yesteryear, replace jobs with technology.\n\nYet, there are reasons to be concerned that this bet may not pay off. For the past three decades, AI research has been organized around making improvements on narrowly-specified tasks like speech recognition. With the emergence of large language models (LLMs) like ChatGPT and Claude, however, AI agents are increasingly being asked to do tasks without clear methods for measuring improvement.\n\nTake for example the seemingly mundane task of creating a PowerPoint presentation. What makes a good presentation? We may be able to point to best practices, but the â€œidealâ€ slideshow depends on creative processes, expert judgments, pacing, narrative sense, and subjective tastes that are all highly contextual. Annual review presentations differ from start-up pitches and project updates. You know a good presentation when you see itâ€”and a bad one when it flops. But the standardized tests that the field currently uses to evaluate AI cannot capture the above qualities.\n\nThis may seem like a minor problem, but crises of evaluation have contributed to historical AI busts. And without accurate measures of how good AI really is, itâ€™s hard to know whether weâ€™re headed towards another one now.\n\nThe birth of AI is often traced back to a small workshop at Dartmouth in 1956 that brought together computer scientists, psychologists, and others with a shared interest in mimicking human intelligence in machines. The field quickly found a powerful benefactor in the Defense Advanced Research Projects Agency (DARPA), an agency within the Department of Defense charged with maintaining technological supremacy during the Cold War. To avoid falling behind in the science race, DARPA lavished AI researchers at universities and private firms with significant no-strings-attached grants over the next 40 years.\n\nThese first decades of the field were defined by peaks of excitement, as new technologies were invented, followed by valleys of disappointment, as they failed to evolve into useful applications. During the 1980s, this cycle was spurred by an AI technology called \"expert systems,\" which promised to build machines with the intelligence of professionals like doctors and financial planners. Under the hood, these programs encoded human expertise in formal rules: if the patient has a fever and a rash, then test for measles.\n\nExpert systems attracted significant attention and investment from industry based on early successes like automating loan applications. But this optimism was largely fueled by hype, rather than rigorous testing. In practice, these expert systems tended to make strange and sometimes disastrous mistakes when challenged with more complex tasks. During one humorous showcase, an expert system suggested a manâ€™s infection might have been caused by a prior amniocentesis (a procedure performed on pregnant women). It turned out researchers had forgotten to add a rule for gender.\n\nAt the time, fiery AI critic Hubert Dreyfus described these failures as the â€œfallacy of the first step,â€ arguing that equating expert systems with progress toward real intelligence was like â€œclaiming that the first primate to climb a tree was taking a first step towards flight to the moon.â€ The problem was that, as tasks became more complicated, the number of rules needed for every possible case mushroomed. Like moving from tic-tac-toe to checkers to chess, the number of possibilities doesnâ€™t merely increase, it explodes exponentially.\n\nWhen it became apparent that expert systems could not climb further, AI research entered a so-called â€œAI Winterâ€ in the late 1980s. Grants dried up, companies shut down, and AI became a dirty word.\n\nIn the aftermath, DARPA re-evaluated its AI funding strategy. Rather than give no-strings-attached grants, government program managers began conditioning awards on attaining the highest score on a standardized test they called a â€œbenchmark.â€ In contrast to complex problems like medical diagnosis, benchmarks focused on bite-sized tasks that were attainable and of immediate commercial and military value. They also used quantitative metrics to verify results. Can your system accurately translate this sentence from Russian to English, transcribe this audio snippet, or digitize letters in these documents? Researchers had to do more than make flashy claims based on promising but incomplete technologies. To get funded, they had to deliver concrete evidence of improvements on the benchmarks.\n\nThese benchmark competitions unified an unruly field by funneling AI researchers towards common problems. Instead of each research group choosing its own projects, DARPA shaped the collective agenda of the field by funding researchers to work on specific tasks like digit recognition or speech-to-text. The competitive nature of the new funding regime meant that AI orientations that were less successful on the benchmarks were crowded out. For example, the very first benchmark competition demonstrated that â€œmachine learningâ€ algorithms that can learn from data dominated the hand-crafted, rule-based approaches of the past.\n\nPublic leaderboards were soon erected to provide real-time feedback on which algorithms held the current highest scores on each benchmark, allowing researchers to learn from past successes. As tasks were solved, more complex tasks were put in their place. Translating words led to translating paragraphs, and eventually multiple languages. Digit recognition gave way to object recognition in images, then videos.\n\nIn the early 2010s, progress accelerated after benchmarks convinced researchers to go all in on one machine-learning approach inspired by the human brain, called artificial neural networks or â€œdeep learning,â€ which now underpins todayâ€™s generative AI. Within a couple of years speech-to-text algorithms were powering modern AI assistants, and tumor recognition algorithms began to outperform radiologists on some cancers. Benchmarking had seemingly cracked the first step toward usable AI in everyday life.\n\nPut simply, the tasks we now seek to automate no longer have clear benchmarks. There is no â€œcorrectâ€ PowerPoint, marketing campaign, scientific hypothesis, or poem. Unlike object recognition where there is a right or wrong answer, these are complex, creative, multi-dimensional, and process-based problems, and even the hardest benchmarks simply cannot objectively measure progress.\n\nAs a result, new models of ChatGPT, Claude, Gemini, and Copilot are evaluated as much by \"vibe tests\" as concrete benchmarks. We're currently caught between two inadequate approaches: old-style benchmarks that measure narrow capabilities precisely, and qualitative assessments that try to capture the practical capacities of these systems, but cannot produce clear, quantitative evidence of progress. Researchers are exploring new evaluation systems that bridge these perspectives, but this is a really hard problem.\n\nCurrent investments assume significant automation will arrive in the next three to five years. But without reliable evaluation methods, we cannot know whether LLM-based technologies are leading us toward genuine automation or repeating Dreyfus' fallacy, taking the first step on a dead-end path. This is the difference between the infrastructure of the future and a bubble. Right now, itâ€™s difficult to tell which one we're building.\n\nBernard Koch is an assistant professor of sociology at the University of Chicago who studies how evaluation shapes science, technology, and culture. David Peterson is an assistant professor of sociology at Purdue University who studies how AI is transforming science.\n\nMade by History takes readers beyond the headlines with articles written and edited by professional historians. Learn more about Made by History at TIME here. Opinions expressed do not necessarily reflect the views of TIME editors.\n\nOpenAI and TIME have a licensing and technology agreement that allows OpenAI to access TIME's archives.",
    "readingTime": 7,
    "keywords": [
      "assistant professor",
      "no-strings-attached grants",
      "digit recognition",
      "object recognition",
      "expert systems",
      "complex tasks",
      "researchers",
      "benchmarks",
      "field",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://time.com/7340901/ai-history-bubble-benchmarks/",
    "thumbnail_url": "https://api.time.com/wp-content/uploads/2025/12/computer.jpg?quality=85&w=1024&h=628&crop=1",
    "created_at": "2025-12-23T06:19:51.504Z",
    "topic": "tech"
  },
  {
    "slug": "memelang-an-axial-grammar-for-llmgenerated-vectorrelational-queries",
    "title": "Memelang: An Axial Grammar for LLM-Generated Vector-Relational Queries",
    "description": "Structured generation for LLM tool use highlights the value of compact DSL intermediate representations (IRs) that can be emitted directly and parsed deterministically. This paper introduces axial grammar: linear token sequences that recover multi-dimensional structure from the placement of rank-specific separator tokens. A single left-to-right pass assigns each token a coordinate in an n-dimensional grid, enabling deterministic parsing without parentheses or clause-heavy surface syntax. This grammar is instantiated in Memelang, a compact query language intended as an LLM-emittable IR whose fixed coordinate roles map directly to table/column/value slots. Memelang supports coordinate-stable relative references, parse-time variable binding, and implicit context carry-forward to reduce repetition in LLM-produced queries.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2512.17967",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2025-12-23T06:19:51.262Z",
    "topic": "tech"
  },
  {
    "slug": "we-built-an-ai-humanizer-to-fix-unnatural-ai-writing",
    "title": "We built an AI Humanizer to fix unnatural AI writing",
    "description": "Dechecker's AI Checker and Detector tool checks whether text is generated by AI models, such as ChatGPT, GPT-5, Claude, Gemini, LLaMa, etc.",
    "fullText": "Humanize AI-generated content and turn it into natural, human-quality writing from ChatGPT, Jasper, or Gemini in seconds.\n\nEnter or paste your text and click Humanize.\n\nUsing the Dechecker Humanizer takes only moments and requires no technical skills.\n\nPaste your AI-generated content into the AI Humanizer and review it briefly before starting the humanization process, ensuring that the original text is complete and ready for accurate human-like rewriting.\n\nChoose your preferred style, language, and length to guide how the AI Humanizer shapes the final human text, allowing you to customize tone, readability, and overall writing style for your intended audience.\n\nAfter using the AI Humanizer, review your text to ensure it has been properly humanize AI content, flows naturally, reads authentically, and maintains the original meaning, tone, and clarity throughout.\n\nCopy the Humanize AI result for use, or check it with Dechecker AI Checker to review AI Humanizer output and AI detection results, ensuring your text is fully human-like and suitable for publishing or sharing.\n\nDechecker focuses on what matters most: producing clear, natural, human-quality text you can confidently use anywhere.\n\nAI-generated content is carefully refined into natural, fluent writing using an AI Humanizer that removes robotic patterns, awkward phrasing, and mechanical-sounding sentences, making the text read smoothly and authentically like a real human wrote it.\n\nThis AI Humanizer works seamlessly across multiple languages, helping content sound human and natural without awkward translations or stiff wording, while preserving original meaning and readability for global audiences.\n\nTone, clarity, and overall flow are enhanced while keeping the original intent intact, producing human-style text that is easy to read, engaging for audiences, and maintains the message accurately across different formats.\n\nAfter rewriting, content can be reviewed with AI Checker like Dechecker to confirm it reads as human, avoids robotic signals, and ensures the output is indistinguishable from text written by real people.\n\nOur AI Humanizer helps users humanize AI text across various scenarios, turning AI-generated drafts into natural, human-like writing that reads smoothly and clearly.\n\nThe AI Humanizer helps writers improve blog posts, articles, and stories by refining AI-generated drafts, making them read naturally, flow smoothly, and engage readers more effectively while keeping original ideas intact.\n\nUse Humanize AI to refine essays, research papers, and reports, ensuring content sounds human, is clear and easy to understand, and maintains proper academic tone and logical structure throughout.\n\nAI Humanizer transforms marketing copy, social media posts, and emails into smooth, human-like text that resonates with audiences, boosts engagement, and maintains consistent brand voice across all channels.\n\nWith multilingual support, Dechecker AI Humanizer allows teams to produce human-quality content in different languages, preserving tone, meaning, and readability, ensuring professional communication worldwide.\n\nDechecker Humanize AI ensures course content, tutorials, and learning resources are readable, human-like, and engaging, helping students better understand complex topics and improving overall learning experience.\n\nUse Dechecker AI Humanizer to humanize AI-generated web content, making it more engaging, natural, and optimized for readers, while improving user experience and search engine readability simultaneously.\n\nReal feedback from users who have improved their AI-generated content with AI Humanizer, making writing feel more natural and human-like.\n\nFind answers to common questions about using AI Humanizer to humanize AI text and make content sound natural and human-like.\n\nAn ai humanizer is a tool designed to turn AI-generated text into human-like writing. It improves readability, sentence structure, and tone, helping content feel natural and engaging to real readers.\n\nAI Humanizer analyzes AI-generated text, restructures sentences, adjusts phrasing, and refines flow to humanize AI content, making it sound naturally written while keeping the original meaning intact.\n\nYes, the AI Humanizer supports multiple languages, including English, Spanish, French, German, and more. It ensures your text feels natural and human-like across all supported languages.\n\nAbsolutely. Dechecker Humanize AI allows you to customize writing style, tone, and length, making content suitable for blogs, articles, marketing copy, emails, and other professional uses.\n\nNo. AI Humanizer focuses on enhancing readability and natural flow without altering your key ideas, intent, or important information, keeping your message accurate.\n\nYes. AI Humanizer humanizes AI-generated text without fabricating information. It helps essays, reports, and professional content read naturally while maintaining integrity and clarity.\n\nDefinitely. After using Dechecker AI Humanizer, you can review the output with AI Checker to ensure the Humanize AI content reads naturally, appears human-written, and meets authenticity requirements.\n\nWriters, students, marketers, content creators, and businesses can all benefit. Anyone looking to make AI-generated content readable and humanize AI content efficiently will find the ai humanizer extremely useful.",
    "readingTime": 4,
    "keywords": [
      "ai humanizer",
      "ai-generated drafts",
      "marketing copy",
      "ai-generated content",
      "dechecker humanize",
      "ai-generated text",
      "natural human-quality",
      "content sound",
      "ai checker",
      "human-like"
    ],
    "qualityScore": 1,
    "link": "https://dechecker.ai/ai-humanizer",
    "thumbnail_url": "https://cdn.dechecker.ai/se/dechecker/public/logo/dechecker-logo.png",
    "created_at": "2025-12-23T06:19:37.153Z",
    "topic": "tech"
  },
  {
    "slug": "ai-native-google-drive-and-one-drive-alternative",
    "title": "AI Native Google Drive and One Drive Alternative",
    "description": "The classics, but smarter.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.xda-developers.com/found-best-google-drive-one-drive-alternative/",
    "thumbnail_url": "https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/12/the-drive-ai-on-macos.jpeg?w=1600&h=900&fit=crop",
    "created_at": "2025-12-23T00:56:33.018Z",
    "topic": "tech"
  },
  {
    "slug": "lumina-a-minimal-ai-reflection-app-source-code",
    "title": "Lumina â€“ a minimal AI reflection app (source code)",
    "description": "Preview repository for Lumina â€” a minimal AI-powered reflection and journaling app. Full source code available for sale with a commercial license. - Encoremuff/lumina-preview",
    "fullText": "Encoremuff\n\n /\n\n lumina-preview\n\n Public\n\n Preview repository for Lumina â€” a minimal AI-powered reflection and journaling app. Full source code available for sale with a commercial license.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Encoremuff/lumina-preview",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/Encoremuff/lumina-preview",
    "thumbnail_url": "https://opengraph.githubassets.com/4658dc9865c1b60c5ed241ec854b45e3d20a6b8a2cb5afa6658a26d02753f4c2/Encoremuff/lumina-preview",
    "created_at": "2025-12-23T00:56:28.857Z",
    "topic": "tech"
  },
  {
    "slug": "chatgpts-yearend-recap-is-here-and-it-tells-you-how-many-emdashes-you-exchanged",
    "title": "ChatGPT's year-end recap is here â€” and it tells you how many em-dashes you exchanged",
    "description": "OpenAI released a 2025 recap rundown called \"Your Year with ChatGPT,\" which tells users which day they chatted the most and awards an archetype.",
    "fullText": "ChatGPT doesn't want to be left out of the \"Wrapped\" party that Spotify popularized. So say hello to \"Your Year with ChatGPT.\"\n\nOpenAI launched the new retrospective on its app on Monday, informing users about the top themes of their chats, the number of messages they have sent, and the awards they have earned.\n\nIt'll even generate some pixel art that depicts some of the your themes.\n\nThe recap is available in the US, UK, Canada, New Zealand, and Australia. To see it, click the plus button in the app and ask, \"Show me my year with ChatGPT.\"\n\nIt's available to Free, Pro, and Plus users, but not those with a business or enterprise account. (So for those with ChatGPT accounts through your work, you likely won't be able to brag to your boss about your ChatGPT stats.)\n\nYour Year with ChatGPT!\n\nNow rolling out to everyone in the US, UK, Canada, New Zealand, and Australia who have reference saved memory and reference chat history turned on.\n\nJust make sure your app is updated. pic.twitter.com/whVkS1qxKu\n\nOpenAI joins the many companies that are rolling out user rundowns for 2025. Alongside the common streamer packages from Spotify and Apple Music, there are recaps this year from LinkedIn, Uber, Dunkin', Snapchat, Strava, Partiful, and more.\n\nAll these apps promise to show you what you've been up to for the past year â€” perhaps lightly roasting you in the process.\n\nChatGPT's rundown begins with a piece of poetry, followed by the three most prominent themes, based on the user's chat history. Then it gets into the statistics.\n\nUsers can learn how many messages they sent, their total number of chats, and their chattiest day. They can also see how many em-dashes have been exchanged throughout the chats, a figure ChatGPT often uses.\n\nNext, the user can learn about their chat style. This is a measure of tone: ChatGPT told me that I spoke \"casually, wryly, and directly.\"\n\nThen come the awards and accolades. ChatGPT awarded me the \"Most Likely to Google, 'Is this Flight Worth It?'\" It's a bit ironic â€”Â I wouldn't Google that, I'd ask ChatGPT.\n\nMy archetype was determined to be the tinkerer, a title given to 8.5% of users. The title meant I learned by trying, and that I used ChatGPT to experiment.\n\nOpenAI has improved its image and video creation models, recently rolling out Sora 2. The recap features an AI-generated piece of pixel art inspired by the year. I asked mine about moving to Brooklyn; it included a matcha.\n\nOther features are more interactive. Want to learn what your 2026 has in store? You'll have to wipe away the \"mists of mystery\" (which looks more like heaps of snow) to learn your fate. Reload the page, and you'll see another fortune.\n\nWith that, ChatGPT's recap comes to a close, but not before sharing an inspiring message.\n\n\"Across all the drafts, questions, and rabbit holes, you found a place to work things out,\" it said. \"And that's no small thing.\"",
    "readingTime": 3,
    "keywords": [
      "pixel art",
      "chat history",
      "your year",
      "users",
      "learn",
      "chatgpt",
      "themes",
      "chats",
      "recap",
      "rolling"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chatgpt-wrapped-how-to-find-stats-see-your-year-recap-2025-12",
    "thumbnail_url": "https://i.insider.com/6949b05704eda4732f2dffa6?width=1200&format=jpeg",
    "created_at": "2025-12-23T00:56:11.336Z",
    "topic": "finance"
  },
  {
    "slug": "trump-says-2-new-trumpclass-ships-will-be-added-to-golden-fleet",
    "title": "Trump says 2 new 'Trump-class' ships will be added to 'Golden Fleet'",
    "description": "President Donald Trump said they would be \"AI-controlled\" and he said that the design would be led by the US Navy with his aesthetic input.",
    "fullText": "President Donald Trump on Monday shared details about new additions to what he's calling the US Navy's \"Golden Fleet.\"\n\nTwo \"Trump-class\" ships, which the president described as \"battleships,\" were announced Monday afternoon at a press conference alongside Pentagon chief Pete Hegseth, Navy Secretary John Phelan, and Secretary of State Marco Rubio.\n\nTrump said they would be \"AI-controlled\" and have \"lasers,\" and he said that the design would be led by the US Navy with his aesthetic input.\n\nThe first of these ships will be called the USS Defiant, Phelan said. Posters of the warship were on display at the press conference held at Trump's Mar-a-Lago Club in Palm Beach, Florida.\n\n\"We're desperately in need of ships, and I have approved a plan for the Navy to begin construction of two large battleships,\" he said. \"We used to build the Iowa, the Missouri, the Alabama. These will be 100 times the force and power. Each one of these will be the largest battleships built in the history of our country.\"\n\nThe president said that eventually \"20 to 25\" of the \"Trump-class\" ships will be made, and construction will start \"immediately.\"\n\nThe ships will be triple the size of an Arleigh Burke-class destroyer, according to the US Navy, and they will be capable of launching Conventional Prompt Strike hypersonic missiles and the Surface Launch Cruise Missile-Nuclear.",
    "readingTime": 2,
    "keywords": [
      "trump-class ships",
      "press conference",
      "us navy",
      "battleships",
      "secretary",
      "construction",
      "president",
      "trump",
      "phelan"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/trump-class-ships-added-navy-golden-fleet-details-2025-12",
    "thumbnail_url": "https://i.insider.com/6949ddb564858d02d2174ac4?width=1200&format=jpeg",
    "created_at": "2025-12-23T00:56:11.333Z",
    "topic": "finance"
  },
  {
    "slug": "blue-prince-didnt-use-any-ai-says-publisher",
    "title": "Blue Prince Didn't Use Any AI, Says Publisher",
    "description": "Over the weekend, The Indie Game Awards shook up its winner's circle by stripping Clair Obscur: Expedition 33 of its Game of the Year Award over the publisher's use of AI. In its place, indie-darling Blue Prince was declared the new Game of the Year winner. Now, publisher Raw Fury wants to make sure everyone knows that Blue Prince wasn't made with AI of any kind.\nIn a statement released on X, Raw Fury credited Tonda Ros and his team for a game that \"was built and crafted with full human instinct ... It is the result of eight years of development [fueled] by imagination and creativity, and we are extremely proud of what Tonda has achieved.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/blue-prince-didnt-use-any-ai-says-publisher/1100-6537142/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4627272-blueprincefeatured.jpg",
    "created_at": "2025-12-23T00:56:09.337Z",
    "topic": "gaming"
  },
  {
    "slug": "model-convo-henry-oliver-ai-poetry-pygmalion-and-why-stem-needs-literature",
    "title": "Model Convo: Henry Oliver â€“ AI poetry, Pygmalion, and why STEM needs literature",
    "description": "AI poetry, Pygmalion, and why STEM needs literature",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.machineculture.io/p/model-convo-henry-oliver",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!CAGy!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee920bc0-9da5-4bea-9aa9-87a4cb97cdc7_724x1086.jpeg",
    "created_at": "2025-12-22T18:17:59.314Z",
    "topic": "tech"
  },
  {
    "slug": "battlefield-6-has-aigenerated-art-just-like-call-of-duty-fans-believe",
    "title": "Battlefield 6 Has AI-Generated Art, Just Like Call Of Duty, Fans Believe",
    "description": "Battlefield 6 players believe they have discovered evidence that the game features AI-generated art. People are theorizing that some of the art in player emblems in Battlefield 6 was created, at least in part, with the use of generative AI systems, though there is no concrete evidence of this as of yet or any comment from Electronic Arts or the game's developers.\nPeople have pointed out some apparent irregularities with the art below. GameSpot has contacted EA in an attempt to get more details on the situation.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/battlefield-6-has-ai-generated-art-just-like-call-of-duty-fans-believe/1100-6537131/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4627171-screenshot2025-12-22at9.37.15%E2%80%AFam.png",
    "created_at": "2025-12-22T18:17:58.589Z",
    "topic": "gaming"
  },
  {
    "slug": "browserforge-ai-browser-agents-1000-free-credits",
    "title": "BrowserForge â€“ AI browser agents (1000 free credits)",
    "description": "AI browser agents that automate web tasks 24/7. Extract data, fill forms, monitor prices, and handle any repetitive browser work. No coding required - just show your agent what to do.",
    "fullText": "Agents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.",
    "readingTime": 2,
    "keywords": [
      "sessions intelligent",
      "define connect",
      "connect browser",
      "via api",
      "api webhooks",
      "intelligent agents",
      "humansâ€”clicking buttons",
      "buttons filling",
      "maintaining authenticated",
      "understand web"
    ],
    "qualityScore": 0.85,
    "link": "https://www.browserforge.ai/",
    "thumbnail_url": "https://browserforge.ai/media/browserforge-hero-1.png",
    "created_at": "2025-12-22T18:17:58.401Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-fostering-new-job-titles-within-hr-and-people-management",
    "title": "AI is fostering new job titles within HR and people management",
    "description": "AI in HR is driving new job titles such as AI trainer, adoption lead, and governance manager, with demand for AI skills on the rise.",
    "fullText": "More human resources teams are using artificial intelligence for a variety of functions. Amazon and Siemens, for example, use AI for HR to analyze rÃ©sumÃ©s and make job recommendations based on an applicant's skills.\n\nIndeed, 31% of organizations this year report using some type of AI technology, according to a 2025 survey of nearly 10,000 HR professionals by Sapient Insights Group.\n\nMany companies are also creating new HR job titles that require AI skills, such as data literacy, analytics, large-language model prompt engineering, and workflow redesign.\n\nMoreover, in 2026, many organizations are willing to offer higher salaries for AI-related skills, including data science, data analytics, and business intelligence, according to a Robert Half report.\n\n\"Historically, technological shifts have reshaped some jobs and the way we work, but they've also opened doors to new roles and skills,\" said Christina Giglio, technology hiring and consulting expert at Robert Half. \"AI seems to be continuing that trend.\"\n\nHere are four new HR job titles that are appearing in the AI age, according to experts.\n\nThis role coordinates the adoption of AI tools, helping people understand the technology's value, how to use it, and how it benefits them, ensuring that AI rollouts go smoothly.\n\n\"AI doesn't eliminate people,\" says Anthony Donnarumma, CEO of the recruiting agency 24 Seven. Companies need individuals to manage the relationship between human and machine work to ensure the technology produces consistent outcomes and meets an organization's needs, he says.\n\nHumans are needed to oversee how teams adopt AI in their daily work, says Lana Peters, chief revenue and experience officer at Klaar, a performance management software.\n\nThe job often includes training managers, redesigning workflows, and connecting company culture and technology while helping employees adapt to the changes.\n\n\"Without this role, AI use is at risk of being done in silos or improperly, which is why we're seeing this position pop up across the job market,\" Peters adds.\n\nThis role trains AI systems, such as chatbots, AI agents, and other tools, to ensure the technology works effectively to produce the desired HR outcome. This might include organizing data and reviewing it for bias.\n\n\"Part technical, part editorial, part quality control,\" Ronni Zehavi, CEO and co-founder of HR tech platform HiBob, says the individual in this role curates and labels data for AI to use, reviews outputs, and teaches AI systems how to respond to data to meet company goals.\n\nThis person \"improves AI quality through hands-on review and feedback,\" he explains.\n\nTurning \"raw people data,\" such as from performance reviews and manager check-ins, into insights that leaders can act on is this role's focus, Peters says.\n\nThis individual helps leaders make data-based decisions on their workforce strategy and better understand \"how employees are performing, when they are ready to be elevated to a new role, and when they may be a flight risk,\" she adds.\n\nData literacy, analytical thinking, and the ability to interpret AI outputs are crucial skills for this role, says Lauren Winans, CEO and principal human resources consultant at Next Level Benefits.\n\n\"Additionally, employers will value soft skills such as ethical awareness, critical thinking, collaboration, and the capacity to translate AI capabilities into strategic decisions, especially in roles that bridge technology, policy, and operations,\" Winans says.\n\nPolicies and oversight are needed to ensure that AI use is safe, fair, and transparent; this role sets those \"guardrails,\" Peters says. This individual oversees how employee data is used and ensures there's no bias that could negatively impact them, she says.\n\nAlso referred to as an AI governance and risk lead, the job establishes policies to \"keep AI use safe and compliant\" and focuses on privacy protection and accuracy monitoring, helping organizations manage regulatory shifts and legal or reputational risks, Donnarumma says.\n\nEssentially, Zehavi says, the role \"guides teams on fairness, transparency, and compliance, helping companies use AI in ways that support people rather than unintentionally excluding them.\"",
    "readingTime": 4,
    "keywords": [
      "human resources",
      "job titles",
      "role",
      "skills",
      "technology",
      "teams",
      "organizations",
      "ensure",
      "risk",
      "individual"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/4-new-ai-job-titles-hr-people-management-transforming-companies-2025-12",
    "thumbnail_url": "https://i.insider.com/6937130471107c9f3457867f?width=1200&format=jpeg",
    "created_at": "2025-12-22T18:17:57.765Z",
    "topic": "finance"
  },
  {
    "slug": "the-ceo-of-microsoft-ai-says-ai-chatbots-are-a-powerful-way-for-humans-to-offload-emotions-and-detoxify-ourselves",
    "title": "The CEO of Microsoft AI says AI chatbots are a powerful way for humans to offload emotions and 'detoxify ourselves'",
    "description": "Mustafa Suleyman, Microsoft AI's CEO, has described using AI for guidance on life decisions as \"something that the world needs.\"",
    "fullText": "The CEO of Microsoft AI says chatbots are a good way to offload emotions and \"detoxify ourselves.\"\n\nAppearing on an episode of Mayim Bialik's \"Breakdown\" podcast, which was released on December 16, Mustafa Suleyman said companionship and support have become some of AI's most popular use cases.\n\nPeople are using AI chatbots for everything from navigating breakups to solving disagreements with family members, he said.\n\n\"That's not therapy,\" Suleyman said. \"But because these models were designed to be nonjudgmental, nondirectional, and with nonviolent communication as their primary method, which is to be even-handed, have reflective listening, to be empathetic, to be respectful, it turned out to be something that the world needs.\"\n\nThe upside of this, he said, is \"this is a way to spread kindness and love and to detoxify ourselves so that we can show up in the best way that we possible can in the real world, with the humans that we love.\"\n\nSuleyman cofounded DeepMind in 2010. The company was acquired by Google in 2014.\n\nOn the podcast, he said people need a space to \"ask a stupid question, repeatedly, in a private way, without feeling embarrassed.\"\n\nOver time, he said, chatbots can make people \"feel seen and understood\" in a way that many other humans can't, outside of partners or close friends.\n\nNot everyone in tech, however, is enthusiastic about chatbots being used as therapy stand-ins. OpenAI CEO Sam Altman is one of those voices. In August 2025, he expressed his discomfort over people relying on chatbots to make major life choices.\n\n\"I can imagine a future where a lot of people really trust ChatGPT's advice for their most important decisions,\" Altman wrote on X. \"Although that could be great, it makes me uneasy.\"\n\nIn July 2025, while appearing on \"This Past Weekend with Theo Von,\" Altman also flagged the potential legal risks of offloading onto a robot. He said that OpenAI may be required to produce its users' therapy-style chats in a lawsuit.\n\nMental health professionals have voiced concerns over the rise of ChatGPT therapy, too. Speaking to Business Insider senior health reporter Julia Pugachevsky in March 2025, two therapists said that relying on AI chatbots for emotional support could exacerbate loneliness and make people dependent on seeking reassurance.\n\nSuleyman acknowledged some of those downsides on the podcast, saying there is \"definitely a dependency risk,\" and that chatbots can sometimes be overly flattering or \"sycophantic.\"\n\nSuleyman is not the sole tech voice who sees AI's therapeutic potential. In a May 2025 interview with the Stratechery newsletter, Meta CEO Mark Zuckerberg said he believed everyone should have a therapist.\n\n\"For people who don't have a person who's a therapist,\" Zuckerberg said, \"I think everyone will have an AI.\"",
    "readingTime": 3,
    "keywords": [
      "chatbots",
      "podcast",
      "therapy",
      "everyone",
      "detoxify",
      "ai's",
      "love",
      "humans",
      "tech",
      "relying"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-ai-ceo-ai-chatbots-help-humans-detoxify-ourselves-2025-12",
    "thumbnail_url": "https://i.insider.com/69493cc804eda4732f2df35b?width=1200&format=jpeg",
    "created_at": "2025-12-22T18:17:57.561Z",
    "topic": "finance"
  },
  {
    "slug": "arc-raiders-is-my-game-of-the-year-but-its-use-of-generative-ai-really-sucks",
    "title": "Arc Raiders Is My Game Of The Year, But Its Use Of Generative AI Really Sucks",
    "description": "These past two months with Arc Raiders have been the most fun I've had with games all year. It represents the most exciting and unpredictable multiplayer landscape I've jumped into since Sea of Thieves in 2018, which I consider my favorite game ever made. It's safe to say I really love Arc Raiders. But it's become difficult to fully espouse those feelings as we learn about Embark Studio's use of generative AI.\nAccording to the studio, Arc Raiders' voice acting was initially performed by humans, then used to \"train\" AI so that it could speak in the actors' voices while addressing any possible circumstance.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/arc-raiders-is-my-game-of-the-year-but-its-use-of-generative-ai-really-sucks/1100-6537140/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1632/16320660/4593114-arcraiders_16-9_03.jpg",
    "created_at": "2025-12-22T18:17:57.556Z",
    "topic": "gaming"
  },
  {
    "slug": "why-gold-and-silver-just-surged-to-fresh-alltime-highs",
    "title": "Why gold and silver just surged to fresh all-time highs",
    "description": "It's been a wild year for precious metals, with gold and silver headed for their best year since 1979. Copper, driven by AI excitement, has also soared.",
    "fullText": "2025 has been a wild year for metals, and the ride continued on Monday with fresh highs in gold, silver, and copper.\n\nAll three metals jumped to start the short holiday week, putting the commodities on track for stellar returns this year as investors seek out defensive investments, anticipate more rate cuts, and look for AI-exposed nvestments beyond the most expensive tech stocks.\n\nGold prices ticked higher by more than 1.5%, climbing past $4,450 an ounce for the first-ever time. The metal is up 67% year-to-date, putting it on track for its best annual rise since 1979.\n\nSilver prices climbed 2% to a record $69 an ounce. The metal is up 130% year-to-date, also putting it on track for its best year since 1979.\n\nCopper rose 1% to trade near $12,000 a ton, a record high. The metal is up 40% for the year, marking its best-ever return since the Great Financial Crisis, according to an analysis from Rosenberg Research.\n\nHere's where the metals were trading shortly around 9:30 a.m. ET on Monday:\n\nThe move in gold and silver came as traders laid bets for more rate cuts in 2026. Lower rates reduce the yield of things like bonds and cash held in savings and money market funds, increasing the appeal of gold.\n\nInvestors are largely expecting the Fed to keep rates steady at its January policy meeting, but the probability that rates will be lower in March now hovers around 54%, according to the CME FedWatch tool.\n\n\"The easier the Fed is, the more it debases the US currency. Then the more that happens, the viable hard assets like gold are,\" Art Hogan, the chief market strategist at B. Riley Wealth Management, told Business Insider.\n\nThe risk that the Fed could cut interest ratesÂ prematurely, which could stoke higher inflation, is also likely adding to the allure of both metals.\n\nGeopolitical headlines over the weekend also sent investors back toward safe havens. The US has stepped up aggression toward Venezuelan oil shipping, sparking fears of a potentially deeper conflics that has also boosted the price of crude.\n\nCopper, meanwhile, tends to move alongside the other two precious metals, Hogan added, explaining why the metal caught up in the latest push to all-time records.\n\nCopper and silver are also seen as key components of the AI trade, due to their role in data centers and electrification. Both metals are facing supply pressures, which have boosted their prices.\n\nMany of the tailwinds that boosted metals in 2025 are expected to remain in place in 2026. A chorus of forecasters on Wall Street has called for gold to keep rising next year, with some bullish targets putting the metal at $5,000 an ounce.\n\nCentral banks purchases have been a particularly powerful force behind gold's rally, and is widely expected to continue in 2026.\n\n\"What has driven the precious metals are global geopolitical and policy uncertainties, accommodative monetary policies, contained real interest rates, and expectations for an ongoing 'debasement trade,'\" analysts at Ned Davis Research wrote in a recent client note, referring to a defensive trade that assumes the markets will shift away from fiat currency as deficits rise around the world.\n\n\"Silver is the most hybrid of the three, benefiting from its safe-haven appeal as well as its electrical applications and, to an increasing extent, solar energy, electric vehicles, electrification and digital infrastructure,\" Ned Davis Research added of silver's catalysts.",
    "readingTime": 3,
    "keywords": [
      "ned davis",
      "davis research",
      "rate cuts",
      "interest rates",
      "precious metals",
      "gold",
      "silver",
      "trade",
      "track",
      "investors"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/gold-price-today-silver-copper-commodities-fed-rate-cuts-metals-2025-12",
    "thumbnail_url": "https://i.insider.com/69494bce832e0ef1ead6a5a6?width=1200&format=jpeg",
    "created_at": "2025-12-22T18:17:57.348Z",
    "topic": "finance"
  },
  {
    "slug": "how-a-french-spirits-company-created-employee-buyin-for-ai",
    "title": "How a French Spirits Company Created Employee Buy-In for AI",
    "description": "Digital transformation often stalls when employees resist new technology. To overcome this common challenge, French spirits company Pernod Ricard drew upon four strategies: proving value through A/B testing, reducing risk by adjusting performance evaluations, investing in training and support, and leveraging internal champions. These efforts drove adoption rates as high as 85%, boosting sales up to 4.5% and marketing efficiency by 15%. In order to drive meaningful transformation, companies need to realize that technology on itâ€™s own canâ€™t drive valueâ€”humans need to be convinced to buy in.",
    "fullText": "How a French Spirits Company Created Employee Buy-In for AI by Scott NoverDecember 22, 2025PostPostShareSavePrintSummary.Â Â Â Leer en espaÃ±olLer em portuguÃªsPostPostShareSavePrint",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/how-a-french-spirits-company-created-employee-buy-in-for-ai",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_18_2195953296.jpg",
    "created_at": "2025-12-22T18:17:56.228Z",
    "topic": "business"
  },
  {
    "slug": "why-i-wont-be-getting-an-ai-home-gym",
    "title": "Why I Won't Be Getting an AI Home Gym",
    "description": "The \"future\" of fitness just can't beat more affordable solutions.",
    "fullText": "I've been getting relentless Instagram ads for AI-powered home gyms lately. You've probably seen them, tooâ€”sleek wall-mounted screens with impossibly toned instructors, testimonials promising \"the future of fitness,\" and before-and-after transformations that make it all look effortless.\n\nThe smart home gym equipment market is booming. According to Business Wire, the industry was valued at $3.2 billion in 2024 and is projected to reach $4 billion by 2030. The numbers show plenty of people are investing in fitness technology that offers personalized, convenient, and effective home workouts. Fitness is yet another way to feed the AI beast, transforming boring old equipment into highly sophisticated systems capable of delivering real-time feedback, tracking performance, and adjusting workouts to each user's needs. It all sounds impressiveâ€”revolutionary, even. But here's the thing about fitness trends: It takes a lot more than the latest technology to make them stick.\n\nAfter months of watching these ads follow me around the internet, I got curious enough to actually dig into what these things are and whether they're worth the hype, and if the math really adds up for most people.\n\nWhatever your fitness goal is, the way to get it done is going to be time-tested and probably not too glamorous. Look at Tae Bo, Zumba, shake weights, even the world of Crossfitâ€”most fitness fads don't have staying power once the novelty wears off.\n\nSure, exercise science evolves, but not nearly as fast as whatever trendy gadget cycles through the cultural zeitgeist. In this way, we see â€œfitnessâ€ get reduced to a consumer productâ€”something to be purchased, used briefly, and then tossed aside when something shinier comes along. In 2025, spin classes are out, while Pilates and strength training are in, and that Bowflex is probably collecting dust in your momâ€™s basement.\n\nIn fact, in 2024 both Bowflex and American Home Fitness, two companies that bet big on the home fitness boom, filed for bankruptcy. In more recent history, Peloton once seemed unstoppable. Now, Peloton's revenue declined 2.8% in 2024 to $2.71 billion, marking its third consecutive year of declining revenue. What was once a cultural phenomenon now struggles to retain members and justify its premium pricing.\n\nFor something to stick in fitness, three questions matter: Is it affordable? Does it work? Will you personally keep coming back to it?\n\nAI home gyms might work, and you might keep coming back, but that first question is where things get complicated.\n\nAI home gyms are digital fitness systems that combine hardware with software to create a personalized workout experience at home. The most well-known is probably Tonal, but there's also Tempo, Speediance, Amp, and others.\n\nHere's how they typically work: Tonal, for instance, is a wall-mounted unit about the size of a large TV that uses electromagnetic resistance instead of traditional weights. You pull cables attached to adjustable arms, and the system can provide up to 200 pounds of resistance digitally. Built-in cameras and sensors track your movements, and the AI adjusts the weight in real-time based on your form and performance. A screen displays instructors leading classes, tracks your reps and sets, and the system learns your strength patterns over time to suggest when you should increase weight or modify exercises.\n\nOther systems work differentlyâ€”Tempo uses free weights with 3D sensors that watch your form, while some use smart cables or connected dumbbellsâ€”but the core promise is the same: sophisticated technology that monitors your workout, corrects your form, tracks your progress, and adapts to your fitness level, all from your living room.\n\nSmart home gyms do offer legitimate benefits, including compact convenience, personalization, time savings, structured workouts, and potentially better injury prevention through form monitoring. And for many, devices like Tonal, Amp, and others are here to stay. â€œAs a professional home gym equipment tester,â€ says Jose Guevara of ShreddedDad, â€œI've seen more of these continue to pop up not only in full training stations, but also in specific equipment, like cable machines, dumbbells, and sometimes a combination of both. They'll never have the longevity of weight plates or barbells, but there is an audience for them.\"\n\nAccording to Guevera, these systems appeal to \"those people who need guidance and want a done-for-you system where they can choose on-demand workouts where they can just follow along and not have to think about what to do for their workout.â€\n\nThere is an audience for these products, just as there's an audience for Peloton bikes and high-end boutique fitness studios. But to me, the relevant question isn't whether they work for some peopleâ€”it's whether they're the revolutionary solution to home fitness they're marketed as, or just another expensive piece of equipment that most people will use enthusiastically for a few months before the novelty wears off.\n\nStill, another Tonal user told me that comparing these AI systems to a Bowflex machine from the 1990s is like comparing a surgical robot to using a rusty scalpel. But this analogy assumes your body is a machine where the logic of â€œendless innovationâ€ holds up. A smart gym isnâ€™t exactly a medical solution. It's an accessory, a luxury good that depends on who can afford it. I donâ€™t think the problem with working out at home has never been that we lacked sophisticated enough technology. The problem is that working out is hard, consistency is harder, and no amount of AI can fundamentally change that human reality. There are some things you just canâ€™t hack.\n\nThere are hefty upfront costs for these products. Take Tonal, one of the leading AI home gym systems. It's around $4,300 for the unit itself, $295+ for mandatory professional installation, plus bundled smart accessories. Then comes the recurring monthly membership fee of around $60 for full access to classes and features. All told, you're looking at roughly $5,300 in the first year, followed by $720 annually for the subscription.\n\nCompare that to traditional gym memberships. According to a 2023 report, the average monthly cost of a gym membership is $58, which works out to about $696 per year. Budget options like Planet Fitness run as low as $15 to $23 per month, or $180 to $276 annually. Even mid-tier gyms like LA Fitness typically cost $40 to 56 per month.\n\nSo, to break even on a Tonal, compared to a mid-range gym membership at $50/month:\n\nYear 1: Tonal costs $5,300. A gym membership costs $600. You're already $4,700 in the hole.\n\nYear 2: You pay $720 for Tonal's subscription. The gym still costs $600. You're now $4,820 behind.\n\nYear 3: Another $720 vs. $600. Now you're $4,940 in deficit.\n\nIt would take roughly eight years of consistent use before Tonal becomes cost-competitive with a traditional gym membership. Eight years. That's assuming the hardware doesn't malfunction, the company doesn't go under (remember, Bowflex and Peloton couldn't sustain their models), and you actually use it consistently for nearly a decade.\n\nAnd the subscription costs are real. Unlike traditional weights that work whether or not you're paying a monthly fee, many digital fitness products require a subscription as long as you want to access workouts. \"I've seen some of these companies also go out of business,\" Guevara says, \"so if that happens, you're stuck with a product that doesn't function if their software is not kept up with.\" We've watched other companiesâ€™ subscription traps effectively brick your hardware.\n\nNow, proponents will argue that you save on commute time and costs. Fair enough. But for the Tonal investment to be \"worth it\" financially, you'd need to use it at least three to four times per week for those eight years straight. If you werenâ€™t driving to a gym you pay $50/month for, are you sure youâ€™ll consistently use your smart gym for years and years once the novelty wears off?\n\nThereâ€™s another unspoken cost to at-home convenience, akin to people who struggle with WFH setups: the absence of gym culture. Donâ€™t underestimate the power of casual human interaction, personal trainers who can physically adjust your form, accountability from workout buddies, the ritual of leaving your house to exercise, or maybe even the silent camaraderie of shared suffering. If youâ€™re like me, that separation between home and workout space is a major psychological boost.\n\nThe best exercise is the one you'll actually keep doing. If you run the numbers and a Tonal makes sense for your budget and workout habits, great. Personally, as AI creeps into every other corner of my life, I find a lot of comfort in my workouts as a rare screen-free activity.\n\nMy gripe with AI home gyms is when theyâ€™re marketed as must-have solutions, instead of what they are: luxury goods, something available only to those with disposable income and spare square footage. On a grand scale, given their current costs, AI home gyms look like a passing trend to me. And two years from now, when the next fitness innovation promises to finally solve at-home workouts, I bet someone will write this same article all over again.",
    "readingTime": 8,
    "keywords": [
      "novelty wears",
      "traditional weights",
      "gym membership",
      "digital fitness",
      "gym equipment",
      "smart gym",
      "gyms",
      "workouts",
      "systems",
      "workout"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/health/why-i-wont-be-getting-an-ai-home-gym?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KCW3VPZCDR987D60JX5J6V4Y/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-22T18:17:55.123Z",
    "topic": "health"
  },
  {
    "slug": "you-can-now-customize-chatgpts-personality-to-suit-your-tastes-even-more",
    "title": "You Can Now Customize ChatGPTâ€™s â€˜Personalityâ€™ to Suit Your Tastes Even More",
    "description": "If you don't like your AI friend's personality, you can change it.",
    "fullText": "When Spike Jonze's movie Her dropped back in 2013, I thought it was a great work of total fiction. Who would actually befriend an AI bot, let alone fall in love with them? Fast forward 12 years, and I couldn't have been more wrong. Not only do people love chatting with AI bots, they are actually developing deep connections with them. I still don't get it, but I can't deny it: People like these chatbots a lot.\n\nPart of what people like about conversations with generative AI is the \"personality\" of each botâ€”or, at least, its perceived personality. After all, ChatGPT isn't a monolith: You can adjust the bot to sound wildly different than it does on someone else's app, which raises some questions for me regarding these curated companions. But I digress: This article isn't necessarily a critique of how people are attaching themselves to ChatGPT; rather, I'm sharing the news that OpenAI is now giving you more control over how the bot sounds and responds in your conversations.\n\nOn Friday, OpenAI announced new controls for ChaGPT's \"Personalization.\" In a post on X, the company revealed that users can now adjust their chatbot's \"characteristics,\" or, in other words, its overall personality. These are adjustments to the personality types that OpenAI has already let you choose from, which include one of eight options: \"Default\" (preset style and tone); \"Professional\" (polished and precise); \"Friendly\" (warm and chatty); \"Candid\" (direct and encouraging); \"Quirky\" (playful and imaginative); \"Efficient\" (concise and plain); \"Nerdy\" (exploratory and enthusiastic); and \"Cynical\" (critical and sarcastic).\n\nBut no matter which of these personalities you pick, you now have four \"characteristics\" to adjust to fine-tune the overall experience. There's \"Warm,\" \"Enthusiastic,\" \"Headers & Lists,\" and \"Emoji,\" with the option to have more or less of each, or the default amount, as OpenAI sees fit. For Warm, you can either have ChatGPT be friendlier and more personable, or more professional and factual. With Enthusiastic, you can choose the bot to have more energy and excitement, or be calmer and more neutral. \"Headers & Lists\" lets you choose between clear formatting and lists, or more paragraphs. And, of course, you can control whether ChatGPT uses more emoji, or fewer, depending on your sense of fun and joy.\n\nAs usual, you can take advantage of custom instructions to guide ChatGPT's personality in a direction you like, especially when the presets don't give you those options. For example, if you'd like ChatGPT to talk to you like a pirate, or if you want it to end every response with a certain catchphrase, here's your chance to influence the bot.\n\nI'm really not someone who uses ChatGPT outside of testing it for coverage, so I can't speak to whether these additional controls are useful. But if you want to try making your version of ChatGPT your ideal \"AI companion,\" the controls are at your disposal. You'll find these options wherever you access ChatGPT. You can either access it from Settings > Personalization, or from the Personalization shortcut in the ChatGPT menu.",
    "readingTime": 3,
    "keywords": [
      "personality",
      "adjust",
      "controls",
      "choose",
      "options",
      "chatgpt",
      "love",
      "don't",
      "can't",
      "conversations"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/chatgpt-has-new-personalities?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KD3CQ2CPPV1ZDBB3BAZSZDM3/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-22T18:17:55.044Z",
    "topic": "tech"
  },
  {
    "slug": "uplane-yc-f25-is-hiring-founding-engineers-fullstack-and-ai",
    "title": "Uplane (YC F25) Is Hiring Founding Engineers (Full-Stack and AI)",
    "description": "Companies waste billions on bad ads, mismatched landing pages, and poor budget allocation. Uplane fixes this by replacing a patchwork of agencies, spreadsheets, and siloed tools with one self-improving system. It creates ads, builds matching landing pages, allocates budgets across different channels and more, all in real time.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.useparallel.com/uplane1/careers",
    "thumbnail_url": "https://ik.imagekit.io/parallel/undefined/6942baf61af7b542c9885322/company/header/prl-c_E4W-GquqR",
    "created_at": "2025-12-22T18:17:50.913Z",
    "topic": "jobs"
  },
  {
    "slug": "are-we-dismissing-ai-spend-before-the-6x-compute-lands",
    "title": "Are we dismissing AI spend before the 6x compute lands?",
    "description": "Critics are judging models trained on last-gen hardware. There's a 6x wave of compute already allocated - and it's just starting to produce results.",
    "fullText": "You've heard the new narrative: AI scaling hit a wall, the capex is insane, the returns aren't there. But the critics are judging models trained on last-gen hardware. There's a 6x wave of compute already allocated - and it's just starting to produce results.\n\nThis post looks at how much compute is actually coming online - and the early signs of what it is achieving.\n\nMorgan Stanley did some excellent research looking at CoWoS (Chip-on-Wafer-on-Substrate) allocations for TSMC. CoWoS is TSMC's advanced 2.5D chip packaging technology and is used for nearly all leading silicon in artificial intelligence:\n\nFirstly, we can see that total supply is estimated to go from 117,000 wafers to 1 million wafers, in just 4 years, with NVIDIA taking the lion's share of the supply. Interestingly though, Broadcom (which produces Google's TPUs) is taking 15% of that capacity, with AMD growing 15x for their MI300/MI400 series of AI chips.\n\nThis doesn't tell us the total story though - as chips are continually improving in FLOPs/mmÂ² of wafer.\n\nI did some napkin math[1] to try and convert this into exaFLOPs. This is a lot of guesswork on shipment mix, but I believe it should be roughly in the right ballpark:\n\nNote the Google TPU stats assume a very aggressive ramp from Broadcom, which is somewhat in question. Again, this is napkin math.\n\nAI silicon flow is increasing dramatically - and really starts gathering steam into 2026.\n\nIf we look at cumulative installs, we start seeing a huge amount of exaFLOPs available across the globe - with a roughly 6x increase in global AI chip capacity between 2024 and 2026e.\n\nIt's difficult to undersell the implications of this growth. Between ChatGPT first launching and the end of 2026, the world will have nearly 50x more compute installed and available for us. To push an overused analogy arguably too far, the initial build of railways in the UK and US were closer to 10x over 10 years. This level of infrastructure buildout hasn't really been seen before in human history - probably WW2 military spend is the only thing that surpasses it as a proportion of GDP in the Western world.\n\nHaving said all that, there is a significant lag between a chip being finished with TSMC and it coming online - probably at least a month in absolutely ideal conditions. However, there have been significant delays with getting the latest GB200 series of AI accelerators as they require liquid cooling - which previous generations didn't. There have been a lot of rumours that this has been extremely difficult to get right, with widespread reports of overheating and leaks from the liquid cooling system delaying the rollout of this generation of AI accelerators from Nvidia.\n\nThis doesn't even get into the serious power capacity constraints the datacentre industry is currently battling - a million wafers worth of Blackwell-class silicon implies a need for gigawatts of new power capacity. This physical bottleneck is likely to be the true governor on how fast that '2026e' column actually comes online.\n\nOn top of this - the even larger delay is from when a chip gets installed and powered on in a datacentre facility to training finishing. It's likely this process takes at least 6 months end to end - assuming no major problems or difficulties.\n\nSo when we look at 'current' models - we are looking really in the past, probably 12 months or so all things being equal. When I wrote this blog at the end of 2025 we're really just seeing the results of 2024's cumulative infrastructure buildout.\n\nIt's very important to point out though that not all of this compute is being allocated towards training. Proportionally more and more will be allocated to inference to serve current customers. However, at off peak times I'm sure that the big AI players are dedicating a lot of this spare inference compute allocation to new techniques like agentic reinforcement learning - which can be easily checkpointed and done \"off peak\".\n\nAnd let's not forget that an enormous amount of compute still is going to be allocated to training. Sam Altman has said in a recent interview that OpenAI would be profitable if it wasn't for training - no doubt the cost of researchers plays a big part, but compute has to be a huge part of the expenditure there.\n\nTwo models have really caught my eye recently - Opus 4.5 and Gemini 3. I wrote an article a few weeks ago delving into them if you're interested to learn more, but the quick summary is that Opus 4.5 is a step change in terms of software engineering and Gemini 3 has graphic/UI design skills far ahead of other models.\n\nA month or so later, I really agree with what I wrote there - while the benchmark scores were impressive, they massively undersell what a giant leap Opus 4.5 has been. Combined with Claude Code I've found that it really can do 30 minutes+ of software engineering with minimal (or no) babysitting. This is a step change from Anthropic's previous Sonnet 4.5 model - which required me to constantly interrupt its execution to correct its approach.\n\nI've noticed two other more quantitatively sound approaches also backing up what I'm anecdotally seeing. Firstly, one of Princeton's HAL agent benchmarks has been \"solved\" by the combination of Opus 4.5 and Claude Code:\n\nOpus 4.5 + Claude Code effectively solving the benchmark, a massive jump from the previous SOTA.\n\nSecondly, METR has been doing some fascinating work on seeing how long various models can operate on successfully. We're starting to see an enormous leap forward on this - with Opus 4.5 managing to complete software engineering tasks that would take a human 4+ hours successfully in over 50% of cases.\n\nNote the 50%+ success rate on tasks that take humans 4+ hours.\n\nNow, correlation doesn't equal causation, but it's hard to not notice the parallels between the performance here and the availability of compute.\n\nBut if you look closely at the timelines, you realise that this performance isn't the result of the massive wave of compute I just described. It's actually the result of the trickle that came before it.\n\nLook at the \"Cumulative Installs\" for 2024 versus 2026 in my table above.\n\nBecause of the installation and training lag I described earlier, Opus 4.5 and Gemini 3 were likely trained on the 2024 install base. They are the product of roughly ~36 exaFLOPs of global capacity.\n\nWe are looking at these PhD-level engineering capabilities and assuming they are the result of the current AI hype cycle. They aren't. They are the result of the infrastructure that was ordered before the mania truly set in.\n\nThe 100+ exaFLOPs coming online in 2025 and the 220+ in 2026? That compute hasn't even finished a training run yet.\n\nIf Opus 4.5 is what we get from the 'trickle' of 2024 compute, what happens when the 'flood' of 2026 infrastructure actually finishes training the next generation? By 2030, if trends continue, we'll have nearly 30x more - a zettaFLOP (1021 FLOPs). The scaling debate is about to get a lot more uncomfortable.",
    "readingTime": 6,
    "keywords": [
      "claude code",
      "napkin math",
      "liquid cooling",
      "infrastructure buildout",
      "software engineering",
      "opus and gemini",
      "compute",
      "training",
      "it's",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://martinalderson.com/posts/are-we-dismissing-ai-spend-before-the-6x-lands/",
    "thumbnail_url": "https://martinalderson.com/img/og/are-we-dismissing-ai-spend-before-the-6x-lands.png",
    "created_at": "2025-12-22T14:31:19.834Z",
    "topic": "tech"
  },
  {
    "slug": "chinas-moore-threads-unveils-new-chip-in-homegrown-ai-race",
    "title": "China's Moore Threads unveils new chip in homegrown AI race",
    "description": "CEO claims performance nears that of Nvidia's Blackwell chips",
    "fullText": "BEIJING -- Chinese startup Moore Threads on Saturday announced a new artificial intelligence chip and showcased various potential applications, as the country races to build homegrown AI infrastructure.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://asia.nikkei.com/business/tech/semiconductors/china-s-moore-threads-unveils-new-chip-in-homegrown-ai-race",
    "thumbnail_url": "https://images.ft.com/v3/image/raw/https%3A%2F%2Fcms-image-bucket-productionv3-ap-northeast-1-a7d2.s3.ap-northeast-1.amazonaws.com%2Fimages%2F1%2F5%2F2%2F6%2F11856251-2-eng-GB%2Fd4c3ef496c3f-IMG_20251220_104141.jpg?width=1260&fit=cover&gravity=faces&dpr=2&quality=medium&source=nar-cms&format=auto&height=630",
    "created_at": "2025-12-22T14:31:18.290Z",
    "topic": "tech"
  },
  {
    "slug": "openmusicpromptfree-ai-music-prompt-generator-online",
    "title": "OpenMusicPrompt-Free AI Music Prompt Generator Online",
    "description": "Create detailed, descriptive music prompt from your idea with our Free AI Music Prompt Generator. Support Text to Prompt and Audio to Prompt Online.",
    "fullText": "Create detailed, descriptive music prompt from your idea - No Login Required\n\nTransform simple text into detailed, descriptive music prompt\n\nEnter your idea in simple text in Music Prompt Generator\n\nClick the 'Magic Enhance' button and wait a few seconds\n\nReview the generated music prompt\n\nUse your new music prompt or further edit it if needed\n\nRefine and modify prompts using natural language instructions by AI\n\nEnter the music prompt you want to edit in Music Prompt Generator\n\nClick the 'Edit with AI' button\n\nWrite down your edit instruction and wait a few seconds\n\nUse your edited music prompt or further edit it if needed\n\nSeamlessly translate music prompts between languages\n\nEnter the music prompt you want to translate in Music Prompt Generator\n\nChoose your preferred target language and wait a few seconds\n\nReview the translated music prompt\n\nUse your translated music prompt or further edit it if needed\n\nExperience the next generation of AI music prompt generation - powerful, free, and easy to use.\n\nOur Music Prompt Generator is meticulously designed to be compatible with a wide array of leading music generation tools. It seamlessly adapts to different versions including Universal, Suno (v5, v4.5, v4, v3.5, v3), Udio (v1.5, v1), and Stable Audio (2.5, 2.0), ensuring that your prompts are perfectly optimized for whichever platform you choose to create your musical masterpieces.\n\nLeveraging professionally tuned system instructions and advanced algorithms, our Text to Music Prompt Generator delivers exceptionally high-quality prompts. We have fine-tuned our models to understand musical nuances deeply, ensuring that every prompt generated translates your creative ideas into rich, accurate, and inspiring audio compositions.\n\nExperience the full power of our AI Music Prompt Generator without any barriers. It is 100% free to use for everyone, with absolutely no hidden costs or subscription fees. Furthermore, we value your convenience and privacy, so there is no need to register or log in to start creating amazing music prompts immediately.\n\nOur tool features superior natural language processing capabilities that go beyond simple keyword matching. It intelligently interprets complex musical concepts, emotional undertones, and stylistic subtleties from your input. This allows it to construct sophisticated prompts that accurately reflect the specific mood, atmosphere, and instrumentation you envision for your music.\n\nWe have optimized our underlying inference pipeline to ensure lightning-fast performance. Whether you are generating a single prompt or iterating through multiple ideas, our system delivers results in milliseconds. This rapid generation capability ensures a smooth and uninterrupted creative flow, allowing you to focus entirely on your music production process.\n\nYour privacy is our top priority. The Music Prompt Generator operates with a strict zero-data-retention policy. We do not store your input prompts or the generated results on our servers. You can use our tool with complete peace of mind, knowing that your creative ideas and intellectual property remain exclusively yours and fully secure.\n\nDo you have any questions? We have got you covered.",
    "readingTime": 3,
    "keywords": [
      "seconds review",
      "detailed descriptive",
      "natural language",
      "prompt generator",
      "simple text",
      "creative ideas",
      "further edit",
      "descriptive music",
      "translated music",
      "music prompts"
    ],
    "qualityScore": 1,
    "link": "https://openmusicprompt.com/music-prompt-generator",
    "thumbnail_url": "https://openmusicprompt.com/logo.png",
    "created_at": "2025-12-22T14:31:17.239Z",
    "topic": "entertainment"
  },
  {
    "slug": "im-the-sams-club-ceo-and-ive-got-an-ai-leadership-reality-check-let-purpose-not-promise-guide-investment",
    "title": "Iâ€™m the Samâ€™s Club CEO and Iâ€™ve got an AI leadership reality check: let purpose, not promise, guide investment",
    "description": "At Samâ€™s Club, our technology decisions are grounded in a key part of the Walmart enterprise purpose: We areÂ people-led and tech-powered.",
    "fullText": "Chris Nicholas is president and chief executive officer of Samâ€™s Club, a membership club that is pioneering the retail experience, providing members exclusive access to value, convenience, and modern omnichannel shopping options.\r\nBefore taking this role in September 2023, Chris served as executive vice president and chief operating officer (COO) for Walmart U.S. As COO, he was responsible for all aspects of Walmartâ€™s U.S. Store Operations and Supply Chain â€“ including strategy, innovation, automation, store operations, distribution center and fulfillment center operations, last mile delivery capability, and real estate.\r\nChris joined the company in 2018, serving first as deputy CFO, then CFO for Walmart International and then as CFO of the U.S. segment. He grew up working in retail and has more than 20 years of broad retail experience working in nine countries and serving in leadership roles with companies such as Tesco, The Salling Group, and the Coles Group, where he played a key role in leading the Coles business through unprecedented change within the Australian supermarket industry.",
    "readingTime": 1,
    "keywords": [
      "retail experience",
      "store operations",
      "president",
      "chief",
      "executive",
      "officer",
      "role",
      "center",
      "chris",
      "club"
    ],
    "qualityScore": 0.65,
    "link": "https://fortune.com/2025/12/22/sams-club-ceo-ai-adoption-walmart-principles-people-led-technology-powered-chris-nicholas/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/chris-nicholas.png?resize=1200,600",
    "created_at": "2025-12-22T14:31:08.611Z",
    "topic": "business"
  },
  {
    "slug": "a-godfather-of-ai-shares-the-career-advice-hed-give-to-his-4yearold-grandson-as-ai-displaces-jobs",
    "title": "A godfather of AI shares the career advice he'd give to his 4-year-old grandson as AI displaces jobs",
    "description": "Yoshua Bengio, known as one of the \"AI godfathers,\" said that while more jobs will be automated by AI, human qualities like love will always be valuable.",
    "fullText": "As AI displaces jobs, one of the \"godfathers of AI\" shared the career advice he'd give to his 4-year-old grandson to prepare him for the future.\n\n\"Work on the beautiful human being that you can become. I think that that part of ourselves will persist even if machines can do most of the jobs,\" research scientist Yoshua Bengio said on an episode of \"The Diary of a CEO\" podcast, hosted by Steven Bartlett, posted on December 18.\n\nDuring the one-hour and forty-minute episode, Bengio said that with companies eager to integrate AI into their workflows, it's only a matter of time before AI can do most jobs that humans do behind a keyboard. Physical jobs, like plumbing, may eventually be replaced by robots, too, although this may take longer, he said.\n\nBengio said that even as the world becomes more tech-driven, there will always be a need for human qualities such as love, accepting responsibility, and enjoying contributing to others' well-being.\n\n\"If I'm in a hospital, I want a human being to hold my hand while I'm anxious or in pain. The human touch is going to, I think, take more and more value, as the other skills become more and more automated,\" he said.\n\nAlongside Geoffrey Hinton and Yann LeCun, Bengio is known as one of the \"godfathers of AI\" because of his pioneering research in deep learning and neural networks. He is a professor in the computer science and operations research department at the UniversitÃ© de MontrÃ©al, and in June, he launched the AI safety research nonprofit LawZero. In a statement on his website, Bengio said the organization aims to reduce dangerous behaviors associated with agentic AI systems, such as deception.\n\nAll three industry leaders have been sharing their advice for how people can pivot their careers to stay relevant in the age of AI.\n\nIn a June 2025 episode of \"Diary of a CEO,\" Hinton said it's a good time to become a plumber, as it may be a long time before AI disrupts physical jobs. Earlier this month, LeCun told Business Insider he thinks computer science students should focus on foundational courses, like maths and physics, rather than trendy courses on the technology of the day, if they want to break into AI.",
    "readingTime": 2,
    "keywords": [
      "computer science",
      "physical jobs",
      "human",
      "research",
      "episode",
      "godfathers",
      "advice",
      "it's",
      "lecun",
      "courses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/yoshua-bengio-godfather-beautiful-human-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/69492c2704eda4732f2df2a1?width=1200&format=jpeg",
    "created_at": "2025-12-22T14:31:08.274Z",
    "topic": "finance"
  },
  {
    "slug": "big-short-investor-michael-burry-warns-the-us-will-lose-the-ai-race-to-china-if-it-banks-on-nvidias-power-hungry-chips",
    "title": "'Big Short' investor Michael Burry warns the US will lose the AI race to China if it banks on Nvidia's 'power hungry' chips",
    "description": "Michael Burry of \"The Big Short\" fame said the US needs to shift away from \"power-hungry\" chips, but Nvidia has a \"death grip\" on the sector.",
    "fullText": "Michael Burry says Nvidia is pushing the idea that building graphics chips that consume more and more power is the best path to advancing AI â€” and the result could be the US losing the AI race to China.\n\n\"Exactly and sadly,\" Burry wrote on X late Saturday, responding to another user's comment that called Nvidia the \"gangster of the AI neighborhood\" as it has \"shut down any narrative that even hints at reducing GPU demand.\"\n\nIn another post over the weekend, Burry shared a chart showing China has more than double America's electric generation capacity, and is expanding its energy infrastructure at a much faster rate.\n\nWhy China will win AI in one chart. \n\nPower hungry Nvidia chips are not the way forward for the U.S. \n\nIt is not just the total power advantage. It is the slope. pic.twitter.com/qNXh1e4lZj\n\nNvidia has framed AI innovation as \"just figuring out how to power and to cool bigger, hotter silicon,\" Burry said. But China's huge lead in building out power sources means companies in the US are \"plowing capital into a race it is structurally positioned to lose.\"\n\nBurry said the US needs to shift its focus from developing more and more \"power hungry\" chips toward advancing \"AI-tuned ASICs\" â€” application-specific integrated circuits that are designed to do a particular task quickly and efficiently.\n\nBut he said Nvidia has a \"death grip on development\" thanks to its deals with many key players in the AI industry.\n\nNvidia did not immediately reply to a request for comment from Business Insider about Burry's posts.\n\nNvidia stock has surged more than 12-fold since the start of 2023, making it the world's most valuable public company, with a market capitalization of $4.4 trillion.\n\nThe chipmaker raked in about $148 billion of revenue and $77 billion of net income in the first nine months of this year. \"Blackwell sales are off the charts, and cloud GPUs are sold out,\" Nvidia CEO Jensen Huang said in the third-quarter earnings release.\n\nBurry, whose contrarian bet against the US housing bubble was chronicled in the book and movie \"The Big Short,\" recently pivoted from running a hedge fund to writing on Substack.\n\nHe has made the case to his readers that Nvidia and other AI companies are inflating a historic tech bubble. He has said that Nvidia's customers have exaggerated the lifespan of its chips to drag out depreciation and boost short-term earnings.\n\nBurry has also called out the \"give-and-take\" deals between Nvidia and chip buyers such as OpenAI and Oracle, and criticized Nvidia's stock-based compensation as excessive.\n\nNvidia previously responded to his critiques in a memo to Wall Street analysts that was quickly leaked. Burry fired back that the document featured \"one straw man after another\" and he stood by his analysis.\n\nReplying to a subsequent comment on his Substack, Burry wrote that Nvidia had \"become too much of a focus.\" While the company's response did make him \"think to look a little deeper,\" he said it was a \"relatively small short\" for him.\n\n\"I believe it will fall, and is a pure play on my overall thesis, but it is not the worst out there.\"",
    "readingTime": 3,
    "keywords": [
      "chips",
      "nvidia",
      "another",
      "burry",
      "advancing",
      "race",
      "chart",
      "hungry",
      "focus",
      "quickly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-short-michael-burry-nvidia-chips-ai-china-tech-power-2025-12",
    "thumbnail_url": "https://i.insider.com/691f800f89026fbb4d0e19a1?width=1200&format=jpeg",
    "created_at": "2025-12-22T14:31:08.171Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-changing-how-we-learn-at-work",
    "title": "AI Is Changing How We Learn at Work",
    "description": "As artificial intelligence rapidly transforms the workplace, it is also reshaping how people learn, develop expertise, and form their professional identities. Although gen AI promises to accelerate learning and boost productivity, it risks undermining the very experiences that foster mastery, deep thinking, empathy, and personal agency. The challenge for leaders is to ensure that amid this transformation, organizations deliberately preserve the human experiencesâ€”struggle, choice, and interpersonal connectionâ€”that are vital for true development and flourishing.",
    "fullText": "During a recent workshop, a senior executive said to me, â€œNone of us knows how people will learn in this new era.â€",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/ai-is-changing-how-we-learn-at-work",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_17_1056618466.jpg",
    "created_at": "2025-12-22T14:31:07.750Z",
    "topic": "business"
  },
  {
    "slug": "clair-obscur-expedition-33-just-lost-its-indie-game-of-the-year-awards-over-ai-concerns",
    "title": "Clair Obscur: Expedition 33 Just Lost Its Indie Game Of The Year Awards Over AI Concerns",
    "description": "In the span of a week, Sandfall Interactive's Clair Obscur: Expedition 33 was named Game of the Year by both The Game Awards and The Indie Game Awards. But just two days after its latest win, The Indie Game Awards stripped Expedition 33 of its two wins over the developer's use of AI.\n\"The Indie Game Awards have a hard stance on the use of gen AI throughout the nomination process and during the ceremony itself,\" reads a statement on The Indie Game Awards' official site (via Insider Gaming). \"When it was submitted for consideration, representatives of Sandfall Interactive agreed that no gen AI was used in the development of Clair Obscur: Expedition 33. In light of Sandfall Interactive confirming the use of gen AI on the day of the Indie Game Awards 2025 premiere, this does disqualify Clair Obscur: Expedition 33 from its nomination.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/clair-obscur-expedition-33-just-lost-its-indie-game-of-the-year-awards-over-ai-concerns/1100-6537129/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4627134-clairobscurexpedition33.jpg",
    "created_at": "2025-12-22T14:31:04.983Z",
    "topic": "gaming"
  },
  {
    "slug": "eshallgo-outlines-ai-development-and-expansion-plans-for-2026",
    "title": "Eshallgo outlines AI development and expansion plans for 2026",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/eshallgo-outlines-ai-development-and-expansion-plans-for-2026-93CH-4419561",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2025-12-22T14:31:02.366Z",
    "topic": "finance"
  },
  {
    "slug": "concentrix-launches-prebuilt-ai-agents-for-faster-customer-service",
    "title": "Concentrix launches pre-built AI agents for faster customer service",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/concentrix-launches-prebuilt-ai-agents-for-faster-customer-service-93CH-4419562",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2025-12-22T14:31:02.356Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-rewriting-how-power-flows-through-the-datacenter",
    "title": "AI is rewriting how power flows through the datacenter",
    "description": ": Rising rack densities are driving changes from grid connection to chip-level delivery",
    "fullText": "Power semiconductors are soon set to become as vital as GPUs and CPUs in datacenters, handling the rapidly increasing loads forecast for AI infrastructure.\n\nThe AI craze has seen datacenter operators stuffing servers with as many accelerators (typically GPUs) as will fit inside, then filling the racks in their data halls with these high-performance boxes.\n\nWith some GPUs now using 700 W of energy each, the power required by an entire rack or datacenter of kit is growing rapidly, putting a strain on electrical distribution infrastructure.\n\nLast year, Nvidia introduced an integrated rack-scale system for AI processing, the DGX GB200 NVL72, which needs 120 kW per unit, while cloud giant Google disclosed this year that it is planning for datacenter racks supporting 1 MW of IT hardware loads.\n\nTo cap it all, some of the key infrastructure components such as transformers are reported to be holding things up through long lead times of 28 weeks or more.\n\nThis is where power semiconductors come into the picture. They enable solid-state transformers (SSTs), which are much smaller and more efficient than their conventional counterparts â€“ perhaps just 500 kg as opposed to multiple tons.\n\n\"What's now being introduced is a solid-state transformer that has a couple of advantages on the supply chain side, but also on this performance side, and that is a pretty new application,\" said Dr Peter Wawer, division president for Green Industrial Power at chipmaker Infineon.\n\nSSTs are a great deal lighter and smaller, Wawer told us, because they operate at very high frequency, a couple of orders of magnitude higher than the AC power supply frequency fed into them. Because the solid-state transformer switches at such high frequency, it requires silicon carbide components.\n\n\"Silicon carbide is the only material that has the capability to switch at high frequency and has high blocking voltages. And for blocking voltage, we mean up to two or three kilovolts (kV), which this semiconductor device will need to block,\" Wawer said. \"But then, of course, you have input voltages of more than 30 kV, and therefore you have to stack more than 10 of the devices in a kind of cascaded structure.\"\n\nInfineon is a prominent supplier of power semiconductors, and so has an interest in pushing the development of solid-state components that are set to be in demand as the datacenter build boom continues.\n\nThe firm expects that SSTs will replace a portion of the datacenter transformer market and could be worth up to $1 billion by 2030, for example.\n\nCircuit breakers are nother application where power semiconductors may replace legacy kit. These electromechanical devices open up in a few milliseconds in the event of a short circuit, but a silicon carbide solid-state version can open much faster, in microseconds â€“ handy if you are dealing with high voltages being supplied to racks full of very expensive GPUs.\n\nPower semiconductors, based on silicon carbide or gallium nitride, are also set to play a part in the power distribution around the datacenter itself.\n\nNvidia has signposted that it sees 800 VDC power supplies as the way forward, as the power demands of AI infrastructure get ever higher, saying this move will be required to support 1 MW IT racks and beyond. It claims this reduces the number of voltage conversions needed, which can introduce inefficiencies and increase the complexity of the electrical system, among other things.\n\nIt is also a way of minimizing losses, according to Infineon, because the power loss is proportional to the square of the current. The trick therefore, when you want to go to a higher power and keep losses under control, is to increase the voltage to a level that means you keep the current constant.\n\n\"Today, you have a combined rack that has the IT payload as well as the power delivery and the backup power. Now, as the GPUs, TPUs, and ASICs increase in power, that means that you need to bring in more power into the racks themselves,\" said Adam White, division president for Power & Sensor Systems at Infineon.\n\n\"So we now move to this potential 800 volt DC supply, but you've also got the plus-minus 400-volt topologies that some vendors [such as Google] may end up using. We call this then the hybrid microgrid.\"\n\n\"Why 800 volts DC? Effectively, you can bring that directly into the motherboards or into the compute trays, using fewer conversion steps,\" he added.\n\nHowever, Infineon believes that before we can get to that step, there will have to be an intermediate stage, where a \"power sidecar\" â€“ effectively a second rack full of power delivery and backup circuitry â€“ will sit alongside the rack of IT kit it serves. Whether this serves just one rack or several will depend on the IT load.\n\nThis arrangement is expected to see racks hitting 600 kW of power, up from the maximum of about 125 kW today, to support configurations using Nvidia's Rubin Ultra, expected to arrive in late 2027.\n\nGoogle also mentions a \"sidecar\" in its plans for 1 MW kit, as a dedicated AC-to-DC power rack that feeds power to the other racks.\n\nAs power demand rises, the power supply unit (PSU) within the rack will need to handle more power, with 8 kW units available now. There will also be a transition to a three-phase design to move from a 12 kW unit to 16 kW or above, which is expected to happen next year. This transition will see greater use of components made with silicon carbide and gallium nitride (GaN), according to Infineon.\n\nFinally, the increasing density of the AI accelerators themselves and the amount of power all those transistors guzzle is starting to have an impact at the chip level.\n\nThe voltage regulator modules (VRMs) are currently discrete packages that sit alongside the accelerator chip package (GPU, ASIC or TPU) on the system board, but as the current to the chip rises, parasitic losses also increase, wasting energy.\n\n\"Some of the industry has already recognized that and started to move to what we call BVM, or back-side vertical power module,\" White said. This moves the VRMs to the other side of the system board, below the accelerator chip package, and simplifies the board layout as well as reducing overall power delivery network losses.\n\nUltimately, the industry would like to get to the point where the VRM moves inside the chip package and is embedded in the substrate directly beneath the chip, but this is a development set for beyond 2027, according to Infineon. Â®",
    "readingTime": 6,
    "keywords": [
      "division president",
      "gallium nitride",
      "silicon carbide",
      "accelerator chip",
      "chip package",
      "system board",
      "solid-state transformer",
      "racks",
      "rack",
      "datacenter"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2025/12/22/ai_power_datacenter/",
    "thumbnail_url": "https://regmedia.co.uk/2022/04/07/datacenter.jpg",
    "created_at": "2025-12-22T12:23:45.622Z",
    "topic": "tech"
  },
  {
    "slug": "chinese-opensource-ais-are-winning-over-a-growing-number-of-companies-in-the-us",
    "title": "Chinese open-source AIs are winning over a growing number of companies in the US",
    "description": "Even as the United States is embarked on a bitter rivalry with China over the deployment of artificial intelligence, Chinese technology is quietly making inroads into the US market.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.france24.com/en/live-news/20251222-as-us-battles-china-on-ai-some-companies-choose-chinese",
    "thumbnail_url": "https://s.france24.com/media/display/0fd4b52e-ded5-11f0-bf3c-005056bfb2b6/w:1280/p:16x9/e94181f0275e2b42bce324f7897542aaa56e2e4a.jpg",
    "created_at": "2025-12-22T12:23:44.086Z",
    "topic": "tech"
  },
  {
    "slug": "healthcare-vcs-predict-more-ai-transparency-investment-private-equity-ma-and-a-quiet-year-for-ipos-in-2026",
    "title": "Healthcare VCs predict more AI transparency investment, private equity M&A, and a quiet year for IPOs in 2026",
    "description": "It's been a hot year for healthcare venture investment. Backers said they expect investments in AI cost savings in 2026, plus more M&A â€” but not IPOs.",
    "fullText": "It's been a hot year for healthcare deals â€” but some investors are predicting a shift in which startups will capture VC attention next year.\n\n2025 saw a welcome surge in healthcare venture funding as investors rushed to back top AI startups. Last December, VCs predicted huge funding rounds for AI scribe startups like Abridge and Ambience Healthcare; indeed, both Abridge and Ambience landed hundreds of millions of dollars in venture funding this year.\n\nInvestors also said in December 2024 that they anticipated a race for those startups to expand beyond AI health scribing into other product lines, like medical coding and billing. That pressure intensified in August, when medical records giant Epic announced it was releasing its own AI tools, including for clinical documentation, in competition with its closest startup partner Abridge.\n\nWith Epic in the mix and tech giants like OpenAI working on their own healthcare AI plays, VCs told Business Insider that they're expecting different profiles of healthcare startups to grab funding next year as companies focus on cost savings, securing patient and provider trust, and ensuring high-quality data.\n\n\"AI has diffused nicely for passive listening in clinical settings, and administrative simplification,\" said Dan Mendelson, the CEO of Morgan Health, JPMorgan's healthcare investing arm. \"AI now needs to show savings to payers by helping consumers make good choices and reducing the burden on clinicians.\"\n\nInvestors are also watching for more healthcare exits in 2026. Two venture-backed digital health companies went public this year: Hinge Health in May, and Omada Health in June. VCs weren't optimistic that 2026 would bring a deluge of new public healthcare companies, but they're looking forward to what many said should be an active year for healthcare M&A.\n\nThis year, investment surged for AI startups tackling administrative burdens for large health systems. AI scribe startups Abridge and Ambience Healthcare notched $5.3 billion and $1.25 billion valuations, respectively, while AI-powered medical knowledge platform OpenEvidence hit a $6 billion valuation with its own raise.\n\nMany such startups have expanded into coding and billing to help hospitals capture more revenue from health insurers. But in 2026, insurers could use AI to fight back, said Todd Cozzens, cofounder and managing partner of Transformation Capital.\n\nCozzens said that many insurers have already partnered with large organizations such as Palantir and Anthropic on custom AI solutions. Next year, he expects those payers to contract with more specialized AI platforms trained on complex clinical data, like providers are already doing.\n\n\"It's a zero-sum game in the end, but like with the nuclear weapons arms race, a lot of money is going to be spent here, and doing nothing is no longer an option for either side of the battle,\" he said.\n\nSeveral VCs suggested that the next wave of healthcare investment will go toward business models that prioritize higher-quality AI behind the scenes.\n\nSapphire Ventures partner Cathy Gao predicted a conscious shift away from \"black box\" AI models in high-stakes industries like healthcare, calling them \"uninvestable.\"\n\n\"The next healthcare unicorns will be 'glass box' platforms where the core product is the digital paper trail,\" she said. \"Any engineering team can build an AI that fills out a medical form. The real opportunity is building the governance layer that proves why the AI made that decision.\"\n\nLiam Donohue, cofounder and managing partner at .406 Ventures, said his firm has also been investing in companies focused on AI decision transparency and data quality.\n\n\"One of the obstacles that needs to be hurdled for AI to be more widely used in enterprise settings is absolutely the ability to go back to the source of why some process happened or why a decision was made. And there's a lot of infrastructure being built to do that,\" he said.\n\nAs insurers cut reimbursement rates for key services, investors are also expecting a surge in business models that prioritize lower-cost care settings and eschew point solutions, paired with AI to reduce administrative spend.\n\nNorwest partner Irem Rami said she expects a boost for in-home care models that incorporate AI agents. Mercedes Bent, cofounder and partner at Premise VC, is watching healthcare startups that aim to support patients across a chosen specialty, like women's health tech that assists patients from fertility tracking through conception.\n\nTech startups that actually provide healthcare have somewhat fallen out of favor with VCs in recent years. The costs of employing providers or running brick-and-mortar clinics can make it tough for those businesses to deliver venture-style returns.\n\nBut in 2026, according to 7wireVentures partner Alyssa Jaffee, \"tech-enabled services is coming back, baby.\"\n\nAfter 2021's venture boom and the subsequent funding drought, some tech-enabled services companies struggled to maintain their growth or hit their next milestone on slim margins, especially at earlier stages, Jaffee said.\n\nBut many startups that have made it to the other side have stronger businesses as a result, including durable relationships with key customers like health plans, she said.\n\nShe also pointed to Hinge Health and Omada Health's successful IPOs; both companies are tech-enabled service providers that sell to employers and health plans.\n\n\"We have a number of those companies in our portfolio that have really hit their stride. It's just a meatier business, and I think we're going to get a lot of interest from later-stage investors coming in to support those kinds of companies,\" Jaffee said.\n\nNorthzone partner Wendy Xiao said that she's now seeing some employers try out a few different tech-enabled services solutions in a given category, such as GLP-1 management, and test them against one another.\n\nContracting with multiple companies could be a tough sell for employers who are already seeing their healthcare costs skyrocket. But Xiao said many of these startups are paid a portion of the money they save employers â€” a model that dramatically lowers employers' financial exposure.\n\nThere are a few healthcare companies that could be eyeing the exits next year. Virta Health has publicly said it expects to be IPO-ready in 2026. And Business Insider previously reported that two private-equity-backed healthtech companies, Zelis Healthcare and Ensemble Health, have been in talks with bankers about potential IPOs.\n\nStill, no reports have emerged of venture-backed healthcare startups filing their S-1s. By this time last year, Hinge Health and Omada Health were already deep into their IPO preparations.\n\nWhile Xiao thinks a handful of healthtech startups are waiting for their debuts, she's not confident they'll take the plunge before the second half of 2026.\n\n\"I think they'll probably go out in a similar timeframe of, if not late next year, then the year after. There seems to be a lot of momentum pent up around IPO readiness at the organizational level over the past few years. I think a lot of these companies are in pretty good shape in terms of that, and they're just waiting for one of the larger ones to go out,\" Xiao said.\n\nMichael Greeley, the cofounder and general partner at Flare Capital Partners, agreed that the new year is unlikely to bring a steady stream of new healthcare IPOs. But he's anticipating more M&A activity as interest rates come down and private equity buyers look for healthcare AI acquisitions in the VC world.\n\n\"A lot of us are still sitting on a lot of unrealized gains, and the obsession is going to be heightened around liquidity,\" Greeley said. \"We're seeing a lot more interest from the big buyout funds in our sector, who are going down market to buy AI assets to wrap around their legacy platform companies.\"\n\n2025 saw a few such deals. New Mountain Capital, in particular, made several AI acquisitions this year as the PE firm rolled startups onto its existing healthcare bets. Greeley also pointed to firms such as Bain Capital, TPG, Silver Lake, and KKR as potential buyers in 2026.\n\nDonohue is similarly optimistic that 2026 will bring a flurry of exit activity as more companies mull going public, selling, or merging with a competitor. In particular, he expects strategic buyers, such as health plans, to become more active in the second half of 2026.\n\n\"I actually think it'll be a good exit year. I'm seeing lots of signs of life, both within our portfolio and more broadly. There's a lot of activity percolating that you just haven't seen for the last several years,\" he said.",
    "readingTime": 7,
    "keywords": [
      "second half",
      "omada health",
      "ambience healthcare",
      "tech-enabled services",
      "venture funding",
      "managing partner",
      "there's lot",
      "business models",
      "scribe startups",
      "health plans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/healthcare-vc-predictions-2026-more-ai-acquisitions-few-ipos-2025-12",
    "thumbnail_url": "https://i.insider.com/693c482804eda4732f2d7186?width=1200&format=jpeg",
    "created_at": "2025-12-22T12:23:31.028Z",
    "topic": "finance"
  },
  {
    "slug": "im-18-and-cofounded-an-ai-startup-with-teens-around-the-world-who-ive-never-met-inperson-i-had-no-network-so-i-built",
    "title": "I'm 18 and cofounded an AI startup with teens around the world who I've never met in-person. I had no network, so I built one online â€” here's how.",
    "description": "Alex Yang details founding an AI startup with other high schoolers worldwide to improve Alzheimer's diagnostics.",
    "fullText": "My typical morning starts around 3 a.m. I'm instantly met with Messenger notifications from web developers in California, GitHub pings from Florida, and a running document of research papers to read sent from Michigan. By 7:50 a.m. I'm off to class to live my life as an 18-year-old high school senior in Seoul.\n\nThis solitary ritual has become my strange normal after I founded an AI research and development startup with people all around the world, whom I've never met in person. My ambition was to improve Alzheimer's diagnostics, but I had no network, so I built one online.\n\nGrowing up, I heard stories about various family members battling Alzheimer's. I viewed the disease as something truly terrifying, which leaves behind only the shell of who someone once was.\n\nI'd grown up knowing that someday, someone I love might disappear while still standing in front of me. In high school, this fear crystallized into something beyond passive acceptance.\n\nI came across this competition, looking to fund ideas that can make health more accessible, and decided to apply.\n\nI knew I couldn't do the work alone. I had to find people beyond my network with diverse perspectives and skills capable of building something real together.\n\nI started searching for partners by spending my time on internet forums and pitching my vision. I posted detailed research proposals on Discord servers and created GitHub repositories with preliminary code.\n\nAfter a month of \"nos,\" I got one \"yes\" from California. Then Florida. Then Michigan. Until there were six of us. We named ourselves Reteena (pronounced like \"retina\"), a deliberate wordplay symbolizing our mission to bring new vision to Alzheimer's diagnostics.\n\nWe became something none of us expected: a team of high schoolers from around the world who genuinely believed we could fix Alzheimer's.\n\nI didn't set out to target only high schoolers, but I was on servers mainly for students, and those were the people who responded.\n\nWe've been self-funded and started by conducting research on enhancing the image resolution of low-field MRI, which is a portable and more economically accessible MRI machine. We applied machine learning and deep learning techniques to enhance the quality of low-field MRI scans.\n\nOur goal was radical â€” to make Alzheimer's diagnostics accessible and affordable for underserved communities by making low-field MRI more reliable. Conducting research together, I realized that my abstract dream had become reality, but reality proved far more demanding than any dream.\n\nI staggered under the crushing weight of the time and dedication that my team was giving. The time zone difference was not an excuse for me to make them wait for responses. Lying awake at night, my stomach knotted with anxiety about \"what should I do next,\" I recognized that my wrong decision could waste months of work from people who believed in me.\n\nDuring those suffocating moments, when doubt was a physical pain in my chest, I'd question everything: my abilities, our direction, and whether I was worthy of the faith my team placed in me.\n\nGradually, my leadership improved, and doubts faded when I stopped seeing our differences as obstacles and started viewing them as strengths. I created a \"follow-the-sun\" workflow where I completed tasks before people in the states woke up, with detailed handoff documents in shared Notion workspaces. We were asynchronous, yet somehow more connected.\n\nWhen our first piece of research was published in the IEEE BigData 2024 Conference, a prestigious annual conference for artificial intelligence research, I felt exhilarated. It was proof that we were onto something and justification for every late night. Yet it was only the beginning.\n\nWe expanded from a six-person group chat into an unconventional startup with 12 members. Over the next nine months, we conducted additional Alzheimer's research and presented our findings on how changes in speech patterns and genetic markers could aid in detecting the disease earlier than traditional methods.\n\nAs people who met on the internet, we've also made our growth transparent on the internet, sharing our journey on LinkedIn. By posting our product-building journey and sharing the authentic rationale behind our research and products, we connected with mentors who believed in what we were doing â€” Y Combinator founders, Pear VC partners, and researchers who took us seriously despite our age.\n\nWe even started receiving messages from students across different countries asking for advice on starting their own health tech projects.\n\nMost recently, we launched our first consumer product, Remembrance, an AI therapeutic service to try to help Alzheimer's patients reconnect with their past. It works by asking gentle questions designed to trigger old memories through reminiscence therapy.\n\nEach recalled memory is automatically organized in knowledge graph databases, making it easy to revisit and build a personal memory repository. Over time, it can suggest related memories on demand, building a personalized memory archive.\n\nThe healthcare market is impenetrable in many ways. When we attempted to approach a local hospital to test our product using actual patient data, we were immediately halted by compliance requirements and institutional review boards.\n\nWe've spent two years discovering that building something in healthcare is harder than we thought. But I wouldn't change it because we learned that at 17 and 18, not at 25 when the stakes feel higher and the fear feels heavier.\n\nReteena might not end up as we imagined, but that's OK. The point was never the destination; it was about learning how to build, understanding that authentic problems matter more than viral success, and realizing you can inspire people by simply trying.\n\nThat's the real experiment. And it's worth every sleepless night.",
    "readingTime": 5,
    "keywords": [
      "a.m i'm",
      "low-field mri",
      "alzheimer's diagnostics",
      "conducting research",
      "accessible",
      "internet",
      "team",
      "we've",
      "learning",
      "night"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-high-schooler-launched-startup-with-people-he-met-online-2025-12",
    "thumbnail_url": "https://i.insider.com/694186af832e0ef1ead64bed?width=1118&format=jpeg",
    "created_at": "2025-12-22T12:23:30.925Z",
    "topic": "finance"
  },
  {
    "slug": "clearnotelab-turn-meeting-notes-into-clientready-pdfs-in-30-seconds",
    "title": "ClearNoteLab â€“ Turn meeting notes into client-ready PDFs in 30 seconds",
    "description": "Stop wasting hours formatting. Let AI turn your raw notes into polished docs instantly. Free plan available.",
    "fullText": "Initial consultation and project scoping\n\nMVP development including landing page, signup flow, and dashboard\n\n6 weeks (tight deadline - requires validation)\n\nTimeline is aggressive, idea validation required before full commitment\n\nâ€¢ Send proposal by Friday\nâ€¢ Schedule design review session",
    "readingTime": 1,
    "keywords": [
      "validation"
    ],
    "qualityScore": 0.2,
    "link": "https://clearnotelab.com",
    "thumbnail_url": "https://bolt.new/static/og_default.png",
    "created_at": "2025-12-22T12:23:28.102Z",
    "topic": "tech"
  },
  {
    "slug": "breaking-out-the-selective-scalpel-wall-street-sees-ai-stock-trade-as-intact",
    "title": "Breaking out the 'selective scalpel': Wall Street sees AI stock trade as intact",
    "description": "The AI trade isn't over. Investors have just become choosier about which players might emerge as winners.",
    "fullText": "The AI tech trade isn't over. Investors have just become choosier about which players might emerge as winners heading into 2026.\n\nTech (XLK) stocks have been on a rollercoaster recently as concerns over funding for Oracle (ORCL) data centers and construction delays from CoreWeave (CRWV) rattled AI plays.\n\n\"I do believe these are all hyper-valid concerns for the theme, and with the market now breaking out the 'scrutiny scalpel' we are finally seeing appropriate 'winners and losers' dispersion, and that's a good thing,\" Nomura Securities equity derivatives analyst Charlie McElligott wrote in a note on Thursday.\n\nHowever, Micron Technology's (MU) blockbuster results sparked a rebound in AI trades. The memory chipmaker beat Wall Street estimates on Q1 revenue and EPS, helped by AI-fueled demand.\n\nMcElligott compared Micron's earnings' \"upside shock\" to Nvidia's (NVDA) results in May 2023, which acted as a catalyst for the broader AI boom.\n\n\"Point-being, there is still blood left in this AI stone,\" McElligott wrote.\n\nInvestors have been watching for potential funding risks within the AI trade after Oracle stock fell following a Financial Times report that Blue Owl Capital would not support Oracle's $10 billion data center project.\n\nThe concerns are particularly notable given the market concentration among the largest tech companies in the S&P 500 (^GSPC).\n\nGoldman Sachs analysts forecast S&P 500 earnings growth of over 12% in 2026, largely driven by the top seven stocks in the index. Those include Nvidia (NVDA), Apple (AAPL), Microsoft (MSFT), Alphabet (GOOGL, GOOG), Amazon (AMZN), Broadcom (AVGO), and Meta (META). Together, they account for roughly a quarter of the index's earnings.\n\nMeanwhile, the \"Magnificent 7\" tech players are up an average of 21% this year, compared with a 16% gain for the S&P 500, according to Yahoo Finance data.\n\nSevens Report Research founder Tom Essaye told Yahoo Finance he expects to see winners and losers within the group heading into next year.\n\n\"I think we're going to see some pretty massive bifurcation,\" Essaye said.\" The next evolution of this trade, where there are going to be winners and losers within the Mag 7.\"\n\nHe said that his favorite stock is Alphabet because of the growth prospects for Google's Gemini artificial intelligence product.\n\n\"I think companies like Oracle that are not overextended financially, but are sort of raising eyebrows with a lot of the spending that AI, I think that companies like that could struggle,\" he added.",
    "readingTime": 2,
    "keywords": [
      "losers within",
      "yahoo finance",
      "winners",
      "trade",
      "concerns",
      "earnings",
      "investors",
      "players",
      "heading",
      "stocks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/breaking-out-the-selective-scalpel-wall-street-sees-ai-stock-trade-as-intact-160048510.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/LhCNVSLFiXLWjTxWC3.UIA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-10/545f1f70-9fc1-11f0-aed7-439f790388bf",
    "created_at": "2025-12-22T12:23:26.377Z",
    "topic": "finance"
  },
  {
    "slug": "yann-lecuns-advice-for-young-students-wanting-to-go-into-ai",
    "title": "Yann LeCun's advice for young students wanting to go into AI",
    "description": "Former Meta chief AI scientist Yann LeCun said current and prospective CS students need to focus on skills \"with a long shelf life.\"",
    "fullText": "Yann LeCun said if computer science majors don't spend their time wisely, they may find out their degree doesn't add up.\n\n\"If you are a CS major and take the minimum required math courses for a typical CS curriculum, you might find yourself unable to adapt to major technological shifts,\" LeCun said in an email to Business Insider.\n\nLeCun, who teaches computer science at NYU, said during a recent podcast appearance that he jokes that he's \"a computer science professor arguing against studying computer science\" based on his push on where students should focus their time.\n\n\"My recommendation was not to avoid CS as a major but to take the maximum number of courses on foundations (e.g. math, physics, or EE courses) rather than take courses on the trendy technology du jour,\" he told Business Insider.\n\nThe former chief AI scientist at Meta said his advice is that students \"learn things with a long shelf life.\" Depending on the computer science program, not all of these skills may be baked into a degree.\n\n\"What we should do is learn kind of basic things in mathematics, in modeling, mathematics that can be connected with reality,\" LeCun said on \"The Information Bottleneck\" podcast. \"You tend to learn this kind of stuff in engineering in some schools that's linked with computer science, but sort of electrical engineering, mechanical engineering, et cetera.\"\n\nUniversities and computer science students continue to grapple with how to adapt their programs to the age of generative and increasingly agentic AI. Earlier this year, UC Berkeley professor Hany Farid described the struggle students face in finding jobs, compared to how graduates used to have \"the run of the place.\"\n\nLeaders in the field, including OpenAI's Bret Taylor, have stressed that computer science is about so much more than simply learning to code. Others, including Nobel Laureate Geoffrey Hinton, have stressed that learning critical thinking is what's the key to staying ahead of AI's advancements.\n\n\"Some skills that are always going to be valuable, like knowing some math, and some statistics, and some probability theory, knowing things like linear algebra that will always be valuable,\" Hinton recently told Business Insider. \"That's not knowledge that's going to disappear.\"\n\nLeCun jokingly pointed out that he did not initially study CS. He studied electrical engineering at ESIEE in Paris before earning a Ph.D. CS from the renowned Sorbonne UniversitÃ© in 1987. LeCun said some CS schools are linked to engineering programs, which tend to require more advanced math.\n\n\"Engineering disciplines, you know, in the US, you learn Calculus 1, 2, 3 that gives you a good basis, right?\" he said. In computer science, you can get away with just Calculus 1. That's not enough, right?\"\n\nEngineering also exposes students to concepts like control theory and signal processing, which LeCun said are \"really useful for things like AI.\"\n\nAll of this isn't to say basic programming should be thrown out, LeCun said. Vibe coding is nice, but it's not a substitute for fundamental knowledge.\n\n\"Obviously, you need to learn enough computer science to kind of program and use computers,\" he said. \"And even though AI is going to help you be more efficient at programming, you still need to know how to do this.\"",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "electrical engineering",
      "computer science",
      "students",
      "learn",
      "math",
      "courses",
      "lecun",
      "degree",
      "adapt"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/yann-lecun-advice-ai-careers-computer-science-degree-2025-12",
    "thumbnail_url": "https://i.insider.com/6942b51364858d02d216f13b?width=1200&format=jpeg",
    "created_at": "2025-12-22T09:28:02.713Z",
    "topic": "finance"
  },
  {
    "slug": "why-geo-favors-deep-innovative-content",
    "title": "Why Geo Favors Deep, Innovative Content",
    "description": "The landscape of Search Engine Optimization (SEO) is undergoing a fundamental transformation, driven by the adoption of sophisticated Machine Learning models, specifically Embeddings. This evolution marks the transition to what we can call Generative Engine Optimization (GEO). Far from favoring keyword stuffing or repetitive content, GEO inherently benefits articles that are deep, innovative, and semantically unique.The reason for this shift lies in how modern search engines and Large Language M",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.edgeinsight.pro/post/the-semantic-shift-why-generative-engine-optimization-geo-favors-deep-innovative-content",
    "thumbnail_url": "https://static.wixstatic.com/media/37fe34_b2a56a04fdff419d84b938c845515910~mv2.png/v1/fill/w_1000,h_1000,al_c,q_90,usm_0.66_1.00_0.01/37fe34_b2a56a04fdff419d84b938c845515910~mv2.png",
    "created_at": "2025-12-22T09:17:58.440Z",
    "topic": "tech"
  },
  {
    "slug": "expert-eu-commission-wants-an-unlimited-special-legal-zone-for-ai",
    "title": "Expert: EU Commission wants an \"unlimited special legal zone\" for AI",
    "description": "In a legal analysis for consumer advocates, experts warn of massive protection gaps due to the planned \"digital EU omnibus\". Big Tech is favored.",
    "fullText": "With the planned \"digital omnibus\" package, the EU Commission promises a breakthrough against bureaucracy. However, resistance to the initiative is constantly growing. Legal experts from the law firm Spirit Legal are now urgently warning in an expert opinion commissioned by the Federation of German Consumer Organisations (vzbv) that the draft represents a systematic break with the principles of the General Data Protection Regulation (GDPR) and endangers the privacy of hundreds of millions of consumers.\n\nAt the center of the criticism is the planned Article 88c, which provides for special relief for data processing in the context of Artificial Intelligence (AI). The experts Peter Hense and David Wagner warn here of an \"unlimited special legal zone\". Since the term \"AI system\" is extremely broadly defined, companies could in the future declare almost any automated data processing as AI-relevant in order to evade strict data protection rules. This would replace the technology-neutral logic of the GDPR with a technology-specific privilege that primarily benefits service providers.\n\nThe lawyers consider the planned relaxation in handling sensitive data such as health information or political views to be alarming. The draft suggests that their processing is all the more justified the larger the data volumes are. This reverses the principle of data minimization: mass data extraction is rewarded as long as it serves to train AI models. The experts see this as dangerous privileges for Big Tech corporations.\n\nThe authors also criticize that essential protective mechanisms are merely shifted to the legally non-binding recitals. One example is technical opt-out procedures with which users can object to the use of their data. Without anchoring in the binding legal text, supervisory authorities lack the means to effectively sanction violations. Especially with web scraping, data of individuals would be collected who often have no opportunity to even become aware of their right of objection.\n\nTo counteract these negative developments, the experts propose a specific legal basis for AI training. Companies should only be allowed to access personal information if they can prove that their goal cannot be achieved with anonymized or synthetic data. Furthermore, it must be ensured that AI models do not reproduce personal information in their answers (\"Data Leakage\"). Strict technical standards are therefore necessary already in the training process.\n\nA chapter is dedicated to the protection of vulnerable groups. Since minors frequently cannot grasp the implications of data processing for AI, the authors advocate for explicit parental consent. In addition, individuals reaching the age of majority should receive an unconditional right to prohibit the further use of their data in existing models. Without such guardrails, the digital sovereignty of the next-generation risks being permanently lost.\n\nAccording to vzbv board member Ramona Pop, the political dimension of these findings is enormous. She warns that the Commission, under the guise of innovation, primarily wants to issue a free pass to US platforms. Big Tech could easily exploit legal grey areas, while European companies and consumers would be left behind. True legal certainty can only be achieved through clear rules. Brussels, on the other hand, is proposing vague exceptions that would have to be judicially clarified over years.\n\nCurrent results of a representative online survey for the vzbv demonstrate that data protection is not a hindrance but an economic factor. According to the survey, trust is the fundamental prerequisite for using digital services for 87 percent of consumers. The GDPR serves as an important anchor: over 60 percent of respondents are more likely to trust companies if they demonstrably comply with European regulations. A dilution of these standards thus also risks the social acceptance of new technologies.\n\nThe Digital Omnibus will now be discussed in the EU Council and Parliament. The objections from civil society can hardly be ignored. The package is suspected of being primarily the result of massive pressure from the US government, rather than representing European citizen and economic interests. The rights of data subjects are being weakened under the guise of \"simplifications,\" it is said. The Commission wants to issue AI companies a blank check to extract European data.\n\nDon't miss any news â€“ Facebook,\n LinkedIn or\n Mastodon.\n\nThis article was originally published in\n\n German.\n\n It was translated with technical assistance and editorially reviewed before publication.",
    "readingTime": 4,
    "keywords": [
      "digital omnibus",
      "big tech",
      "experts",
      "protection",
      "processing",
      "european",
      "planned",
      "vzbv",
      "consumers",
      "primarily"
    ],
    "qualityScore": 1,
    "link": "https://www.heise.de/en/news/Expert-EU-Commission-wants-an-unlimited-special-legal-zone-for-AI-11122326.html",
    "thumbnail_url": "https://heise.cloudimg.io/bound/1200x1200/q85.png-lossy-85.webp-lossy-85.foil1/_www-heise-de_/imgs/18/5/0/0/0/1/0/5/shutterstock_1040880751-adf1d5f90b0555c3.jpg",
    "created_at": "2025-12-22T09:17:57.777Z",
    "topic": "tech"
  },
  {
    "slug": "failcore-deterministic-execution-runtime-for-ai-agents",
    "title": "FailCore â€“ Deterministic Execution Runtime for AI Agents",
    "description": "FailCore is a minimal execution runtime for LLM-generated plans, focused on deterministic execution, strict validation, and fail-fast behavior. - Zi-Ling/failcore",
    "fullText": "Zi-Ling\n\n /\n\n failcore\n\n Public\n\n FailCore is a minimal execution runtime for LLM-generated plans, focused on deterministic execution, strict validation, and fail-fast behavior.\n\n License\n\n View license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Zi-Ling/failcore",
    "readingTime": 1,
    "keywords": [
      "execution",
      "star",
      "failcore",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Zi-Ling/failcore",
    "thumbnail_url": "https://opengraph.githubassets.com/ebf010fec791f1dc2de67a9b2934caf478347cd79e2d98422bbb4e6b755bdfa8/Zi-Ling/failcore",
    "created_at": "2025-12-22T09:17:54.347Z",
    "topic": "tech"
  },
  {
    "slug": "boys-at-her-school-shared-aigenerated-nude-images-of-her-after-a-fight-she-was-the-one-expelled",
    "title": "Boys at her school shared AI-generated, nude images of her. After a fight, she was the one expelled",
    "description": "Nude images of a 13-year-old girl and her friends, generated by artificial intelligence, were circulating on social media and had become the talk of a Louisiana middle school.  When the 13-year-old girl stepped onto the Lafourche Parish school bus at the end of the day, a classmate was showing one of them to a friend.  The 13-year-old girlâ€™s attorneys allege he avoided school discipline altogether.",
    "fullText": "THIBODAUX, La. (AP) â€” The teasing was relentless. Nude images of a 13-year-old girl and her friends, generated by artificial intelligence, were circulating on social media and had become the talk of a Louisiana middle school.\n\nThe girls begged for help, first from a school guidance counselor and then from a sheriffâ€™s deputy assigned to their school. But the images were shared on Snapchat, an app that deletes messages seconds after theyâ€™re viewed, and the adults couldnâ€™t find them. The principal had doubts they even existed.\n\nAmong the kids, the pictures were still spreading. When the 13-year-old girl stepped onto the Lafourche Parish school bus at the end of the day, a classmate was showing one of them to a friend.\n\nâ€œThatâ€™s when I got angry,â€ the eighth grader recalled at her discipline hearing.\n\nFed up, she attacked a boy on the bus, inviting others to join her. She was kicked out of Sixth Ward Middle School for more than 10 weeks and sent to an alternative school. She said the boy whom she and her friends suspected of creating the images wasnâ€™t sent to that alternative school with her. The 13-year-old girlâ€™s attorneys allege he avoided school discipline altogether.\n\nWhen the sheriff's department looked into the case, they took the opposite actions. They charged two of the boys who'd been accused of sharing explicit images â€” and not the girl.\n\nThe Louisiana episode highlights the nightmarish potential of AI deepfakes. They can, and do, upend children's lives â€” at school, and at home. And while schools are working to address artificial intelligence in classroom instruction, they often have done little to prepare for what the new tech means for cyberbullying and harassment.\n\nOnce again, as kids increasingly use new tech to hurt one another, adults are behind the curve, said Sergio Alexander, a research associate at Texas Christian University focused on emerging technology.\n\nâ€œWhen we ignore the digital harm, the only moment that becomes visible is when the victim finally breaks,â€ Alexander said.\n\nIn Lafourche Parish, the school district followed all its protocols for reporting misconduct, Superintendent Jarod Martin said in a statement. He said a â€œone-sided storyâ€ had been presented of the case that fails to illustrate its \"totality and complex nature.â€\n\nA girlâ€™s nightmare begins with rumors\n\nAfter hearing rumors about the nude images, the 13-year-old said she marched with two friends â€” one nearly in tears â€” to the guidance counselor around 7 a.m. on Aug. 26. The Associated Press isnâ€™t naming her because she is a minor and because AP doesnâ€™t normally name victims of sexual crimes.\n\nShe was there for moral support, not initially realizing there were images of her, too, according to testimony at her school disciplinary hearing.\n\nUltimately, the weeks-long investigation at the school in Thibodaux, about 45 miles (72 kilometers) southwest of New Orleans, uncovered AI-generated nude images of eight female middle school students and two adults, the district and sheriff's office said in a joint statement.\n\nâ€œFull nudes with her face put on themâ€ is how the girlâ€™s father, Joseph Daniels, described them.\n\nUntil recently, it took some technical skill to make realistic deepfakes. Technology now makes it easy to pluck a photo off social media, â€œnudifyâ€ it and create a viral nightmare for an unsuspecting classmate.\n\nMost schools are â€œjust kind of burying their heads in the sand, hoping that this isnâ€™t happening,â€ said Sameer Hinduja, co-director of the Cyberbullying Research Center and professor of criminology at Florida Atlantic University.\n\nLafourche Parish School District was just starting to develop policies on artificial intelligence. The school-level AI guidance mainly addressed academics, according to documents provided through a records request. The district also hadnâ€™t updated its training on cyberbullying to reflect the threat of AI-generated, sexually explicit images. The curriculum its schools used was from 2018.\n\nA school investigation hits obstacles\n\nAlthough the girls at Sixth Ward Middle School hadnâ€™t seen the images firsthand, they heard about them from boys at school. Based on those conversations, the girls accused a classmate and two students from other schools of creating and spreading the nudes on Snapchat and possibly TikTok.\n\nThe principal, Danielle Coriell, said an investigation came up cold that day as no student took responsibility. The deputy assigned to the school searched social media for the images unsuccessfully, according to a recording of the disciplinary hearing.\n\nâ€œI was led to believe that this was just hearsay and rumors,â€ the girlâ€™s father said, recounting a conversation he had that morning with the school counselor.\n\nBut the girl was miserable, and a police incident report showed more girls were reporting that they were victims, too. The 13-year-old returned to the counselor in the afternoon, asking to call her father. She said she was refused.\n\nHer father says she sent a text message that said, â€œDad,â€ and nothing else. They didn't talk. With the mocking unrelenting, the girl texted her sister, â€œItâ€™s not getting handled.â€\n\nAs the school day wound down, the principal was skeptical. At the disciplinary hearing, the girlâ€™s attorney asked why the sheriff's deputy didnâ€™t check the phone of the boy the girls were accusing and why he was allowed on the same bus as the girl.\n\nâ€œKids lie a lot,â€ responded Coriell, the principal. â€œThey lie about all kinds of things. They blow lots of things out of proportion on a daily basis. In 17 years, they do it all the time. So to my knowledge, at 2 oâ€™clock when I checked again, there were no pictures.â€\n\nA fight breaks out on the school bus\n\nWhen the girl stepped onto the bus 15 minutes later, the boy was showing the AI-generated images to a friend. Fake nude images of her friends were visible on the boyâ€™s phone, the girl said, a claim backed up by a photo taken on the bus. A video from the school bus showed at least a half-dozen students circulating the images, said Martin, the superintendent, at a school board meeting.\n\nâ€œI went the whole day with getting bullied and getting made fun of about my body,â€ the girl said at her hearing. When she boarded the bus, she said, anger was building up.\n\nAfter seeing the boy and his phone, she slapped him, said Coriell, the principal. The boy shrugged off the slap, a video shows.\n\nShe hit him a second time. Then, the principal said, the girl asked aloud: â€œWhy am I the only one doing this?â€ Two classmates hit the boy, the principal said, before the 13-year-old climbed over a seat and punched and stomped on him.\n\nVideo of the fight was posted on Facebook. â€œOverwhelming social media sentiment was one of outrage and a demand that the students involved in the fight be held accountable,â€ the district and sheriffâ€™s office said in their joint statement released in November.\n\nThe girl had no past disciplinary problems, but she was assigned to an alternative school as the district moved to expel her for a full semester â€” 89 school days.\n\nIt was on the day of the girlâ€™s disciplinary hearing, three weeks after the fight, that the first of the boys was charged.\n\nThe student was charged with 10 counts of unlawful dissemination of images created by artificial intelligence under a new Louisiana state law, part of a wave of such legislation around the country. A second boy was charged in December with identical charges, the sheriff's department said. Neither was identified by authorities because of their ages.\n\nThe girl would face no charges because of what the sheriffâ€™s office described as the â€œtotality of the circumstances.â€\n\nAt the disciplinary hearing, the principal refused to answer questions from the girlâ€™s attorneys about what kind of school discipline the boy would face.\n\nThe district said in a statement that federal student privacy laws prohibit it from discussing individual studentsâ€™ disciplinary records. Gregory Miller, an attorney for the girl, said he has no knowledge of any school discipline for the classmate accused of sharing the images.\n\nUltimately, the panel expelled the 13-year-old. She wept, her father said.\n\nâ€œShe just felt like she was victimized multiple times â€” by the pictures and by the school not believing her and by them putting her on a bus and then expelling her for her actions,â€ he said in an interview.\n\nThe fallout sends a student off course\n\nAfter she was sent to the alternative school, the girl started skipping meals, her father said. Unable to concentrate, she completed none of the school's online work for several days before her father got her into therapy for depression and anxiety.\n\nNobody initially noticed when she stopped doing her assignments, her father said.\n\nâ€œShe kind of got left behind,â€ he said.\n\nHer attorneys appealed to the school board, and another hearing was scheduled for seven weeks later.\n\nFor students who are suspended or expelled, the impact can last years. They're more likely to be suspended again. They become disconnected from their classmates, and theyâ€™re more likely to become disengaged from school. They're more likely to have lower grades and lower graduation rates.\n\nâ€œSheâ€™s already been out of school enough,â€ one of the girl's attorneys, Matt Ory, told the board on Nov. 5. â€œShe is a victim.\n\nâ€œShe,â€ he repeated, â€œis a victim.â€\n\nMartin, the superintendent, countered: â€œSometimes in life we can be both victims and perpetrators.â€\n\nBut the board was swayed. One member, Henry Lafont, said: â€œThere are a lot of things in that video that I donâ€™t like. But Iâ€™m also trying to put into perspective what she went through all day.â€ They allowed her to return to campus immediately. Her first day back at school was Nov. 7, although she will remain on probation until Jan. 29.\n\nThat means no dances, no sports and no extracurricular activities. She already missed out on basketball tryouts, meaning she wonâ€™t be able to play this season, her father said. He finds the situation â€œheartbreaking.â€\n\nâ€œI was hoping she would make great friends, they would go to the high school together and, you know, itâ€™d keep everybody out of trouble on the right tracks,â€ her father said. â€œI think they ruined that.â€\n\nThe Associated Pressâ€™ education coverage receives financial support from multiple private foundations. AP is solely responsible for all content. Find APâ€™s standards for working with philanthropies, a list of supporters and funded coverage areas at AP.org.\n\nHollingsworth reported from Mission, Kansas.",
    "readingTime": 9,
    "keywords": [
      "sixth ward",
      "associated press",
      "ward middle",
      "stepped onto",
      "artificial intelligence",
      "social media",
      "sheriff's department",
      "joint statement",
      "deputy assigned",
      "guidance counselor"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/boys-her-school-shared-ai-050314208.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/kdRXd1Fdl5e3CpyANZyYdA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/312d1079425419ed419abd1a2f9fb720",
    "created_at": "2025-12-22T09:17:52.287Z",
    "topic": "news"
  },
  {
    "slug": "softbank-races-to-fulfill-225-billion-funding-commitment-to-openai-by-yearend-sources-say",
    "title": "SoftBank races to fulfill $22.5 billion funding commitment to OpenAI by year-end, sources say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/softbank-races-to-fulfill-225-billion-funding-commitment-to-openai-by-yearend-sources-say-4418673",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBI1CQ_L.jpg",
    "created_at": "2025-12-22T09:17:49.869Z",
    "topic": "finance"
  },
  {
    "slug": "a-25-billion-credit-investor-says-betting-only-on-ai-chips-overlooks-the-bigger-cycle",
    "title": "A $25 billion credit investor says betting only on AI chips overlooks the bigger cycle",
    "description": "Diameter Capital Partners made successful telecom and satellite bets as AI demand spread beyond chips.",
    "fullText": "The artificial intelligence boom is real â€” but there's more to the AI trade than chips alone, according to a credit investor.\n\n\"This is a super-duper micro cycle that will outlast many investing careers,\" said Scott Goodwin, the cofounder and managing partner of Diameter Capital Partners, a quote he attributed to his partner Jonathan Lewinsohn.\n\nAI represents what Diameter Capital sees as a long-running, disruptive cycle â€” but buying the most obvious winners isn't the only way to play it, he said on the \"Goldman Sachs Exchanges\" podcast published on Friday.\n\nDiameter Capital, which manages approximately $25 billion in assets, has focused on where AI demand could create less obvious bottlenecks â€” and where those bottlenecks show up in credit markets.\n\nThat view led Diameter to buy the unsecured debt of a midsize telecommunications company in 2023.\n\nGoodwin said the bet was rooted in the idea that as companies move from training AI models to actually using them, demand shifts away from chips alone and toward the networks that carry data.\n\n\"It had to leave the data center. How would it leave? It would leave on the commercial fiber, the pipes,\" he said.\n\nThe telco went on to sign more than $10 billion in contracts with hyperscale cloud providers, and the debt has rebounded to face value, Goodwin said.\n\nDiameter Capital also made \"a big bet\" on a satellite company tied to the wireless spectrum â€” a wager that later paid off after the company sold spectrum assets and the debt returned to face value.\n\nGoodwin's comments come amid growing debate over whether sky-high AI valuations are sustainable and whether investors are overlooking other opportunities tied to the technology.\n\nGoodwin warned that parts of the AI-credit boom may be taking on risk that's hard to price, especially in chip finance.\n\nSome investors, he said, are taking on \"residual risk,\" or the riskiest slice of chip-financing deals â€” betting on what the hardware might be worth years from now. Cutting-edge firms refresh their technology often, so chips can quickly become outdated for some customers.\n\n\"We call up really smart people in Silicon Valley, we call up really smart people at Big Tech companies and ask them what the residual value is on these chips three, four, five, six, seven years forward,\" he said. \"None of them have a clue.\"\n\nGoodwin said the next phase isn't just about spending on infrastructure â€” it's about competitive disruption rather than capital expenditure.\n\n\"Who are the companies, who are the entities that are going to adopt AI and take a step forward versus their peers? And who are going to be the losers?\" he asked.\n\n\"That is actually a longer cycle than the capex cycle, so that's really interesting,\" he said.",
    "readingTime": 3,
    "keywords": [
      "chips alone",
      "diameter capital",
      "cycle",
      "debt",
      "boom",
      "credit",
      "obvious",
      "isn't",
      "assets",
      "demand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-investing-ideas-beyond-chips-market-startegy-goldman-sachs-podcast-2025-12",
    "thumbnail_url": "https://i.insider.com/6948d177832e0ef1ead6a39e?width=1200&format=jpeg",
    "created_at": "2025-12-22T09:17:48.416Z",
    "topic": "finance"
  },
  {
    "slug": "embeddingbased-tool-selection-for-ai-agents",
    "title": "Embedding-Based Tool Selection for AI Agents",
    "description": "When I first built our AI assistant, it had five tools. Look up an order. Process a refund. Check ticket availability. Simple stuff.",
    "fullText": "When I first built our AI assistant, it had five tools. Look up an order. Process a refund. Check ticket availability. Simple stuff. Fast forward six months and we're at nearly 40 tools spanning orders, events, marketing campaigns, contests, and customer management.\n\nThe problem became obvious during a routine cost review: we were burning thousands of tokens on every single request just describing tools the model would never use. Someone asks \"What time does my show start?\" and we're sending the full spec for process_refund, create_email_campaign, and manage_contest_prizes. Wasteful.\n\nEach tool definition isn't trivial. You need a name, a description detailed enough for the LLM to understand when to use it, and parameter specifications with types and constraints. Here's what one looks like in our codebase:\n\nMultiply by 40 and you're looking at 3,000+ tokens before the user even says anything. The costs add up, latency increases, and here's the kicker: having too many tools actually makes the model worse at picking the right one. More noise, more confusion.\n\nThe fix is conceptually simple. Instead of sending every tool on every request, we embed all tool descriptions into vectors and store them in Postgres using pgvector. When a query comes in, we embed it too, then find the 5-10 most semantically similar tools using cosine distance.\n\nThe query \"refund order #12345\" gets embedded, compared against all tool embeddings, and returns process_refund, calculate_refund_amount, get_order_details. We send only those to the LLM.\n\nThis cuts our tool payload by 75-90% on most requests. The model sees fewer, more relevant options and picks better.\n\nWe debated two main approaches: calling OpenAI's embedding API or running our own model.\n\nOpenAI's text-embedding-3-small is the path of least resistance. It's a REST call, returns 1536-dimensional vectors, costs about a hundredth of a cent per embedding, and just works. The semantic understanding is excellent. The downside is the external dependency. Every query needs a network round-trip, your data touches their servers, and you're subject to their rate limits and outages.\n\nRunning something like ModernBERT locally is appealing for different reasons. Zero marginal cost, sub-millisecond latency since there's no network hop, and complete data privacy. But now you're managing infrastructure. You need a server running the model, monitoring, scaling considerations, and you're on the hook for model selection and updates. For a small team, that operational burden is real.\n\nThere's also a hybrid approach: use OpenAI in production for reliability, run a local model in development and testing to avoid API costs and flakiness. We built our system with a provider abstraction to make this possible:\n\nSwitching providers is a config change. The abstraction cost an extra hour upfront but buys flexibility later.\n\nFor our volume, OpenAI was the obvious choice. We process hundreds of queries daily, not millions. At $0.00001 per embedding, we're talking pennies per month. The reliability is excellent, the semantic quality is strong for our e-commerce domain, and there's zero infrastructure to manage.\n\nIf we were processing millions of queries or had strict data residency requirements, the calculus would be different. But for a small team running a ticketing platform, paying a few cents to avoid running another service is a good trade.\n\nAdding a new tool or updating an existing one means regenerating embeddings. In development, it's a mix task:\n\nThis iterates through all tool definitions, calls OpenAI for each, and upserts the results into the tool_embeddings table. Takes about 10 seconds for 40 tools. The task is idempotent so you can run it whenever.\n\nThe implementation is straightforward. We convert each ToolDefinition to embedding text that captures the name, description, and parameter info, then store the vector alongside the tool name and model ID.\n\nFor production, we built a simple admin page. Navigate to the AI operations screen, see the current embedding count, click a button to regenerate. Non-technical team members can trigger it after tool updates without touching the console.\n\nThe alternative is shelling into the production console:\n\nEither way, regeneration is safe to run anytime. It deletes existing embeddings and creates fresh ones. The whole process takes seconds.\n\nOne gotcha: if you ever switch embedding providers, you must regenerate everything. OpenAI's 1536-dimension vectors are incompatible with a local model's 768-dimension vectors. We store model_id with each embedding to catch mismatches and make debugging easier.\n\nPure similarity search has a gap. If someone says \"refund order #12345\", we'll find process_refund. But the LLM also needs get_order_details to look up the order before it can refund anything. Those two tools aren't semantically similar enough to both appear in the top results.\n\nWe solved this with category expansion. Each tool has a category like :orders, :refunds, or :events. When we select tools via similarity, we expand to include related categories:\n\nSo finding process_refund (category :refunds) automatically pulls in order lookup tools. The LLM gets everything it needs for multi-step workflows.\n\nFor those curious about the database side, here's the actual query we run:\n\nThe <=> operator is pgvector's cosine distance. We filter by a similarity threshold (0.4 by default) to avoid returning completely irrelevant tools, then take the top K results. The whole thing runs in under 10ms.\n\nWe use Mimic for mocking in tests. Every test that touches tool selection stubs the embedding provider to return consistent vectors:\n\nThis keeps tests fast, deterministic, and free of API dependencies. We can simulate failures too, testing that the system gracefully falls back to using all tools when embedding generation fails.\n\nA few things surprised us along the way.\n\nThe similarity threshold matters more than we expected. Too high and you filter out useful tools. Too low and you're back to noise. We settled on 0.4 after some experimentation but it's worth tuning for your domain.\n\nCategory expansion was an afterthought that became essential. Pure semantic similarity misses the dependencies between tools. If your assistant does multi-step operations, you need something like this.\n\nThe provider abstraction was worth it even though we haven't switched providers. It forced us to think cleanly about the interface and made testing much easier. The Mimic stubs work because there's a clear boundary to mock.\n\nCold start is a real concern. If your embeddings table is empty, you need a fallback. We log a warning and use all tools, which isn't ideal but prevents complete failure.\n\nAfter rolling this out, our per-request token usage for tool definitions dropped 60-80%. Latency improved by about 200ms since the model processes fewer tokens. Tool selection accuracy actually got slightly better because there's less noise confusing the model.\n\nThe embedding costs are negligible. We're at maybe $0.01 per day for our volume. The whole system adds a 10ms database query per request, which disappears in the noise of the LLM call.\n\nFor anyone dealing with tool explosion in their AI agents, this approach is worth considering. The implementation isn't complex, the costs are minimal, and the benefits compound as your tool count grows.",
    "readingTime": 6,
    "keywords": [
      "cosine distance",
      "category expansion",
      "provider abstraction",
      "dimension vectors",
      "similarity threshold",
      "tool definitions",
      "tool selection",
      "per embedding",
      "tools",
      "model"
    ],
    "qualityScore": 1,
    "link": "https://zarar.dev/embedding-based-tool-selection-for-ai-agents/",
    "thumbnail_url": "https://bear-images.sfo2.cdn.digitaloceanspaces.com/zarar/explosion.webp",
    "created_at": "2025-12-22T06:20:31.024Z",
    "topic": "politic"
  },
  {
    "slug": "ai-is-creating-a-security-problem-most-companies-arent-staffed-to-handle-says-an-ai-researcher",
    "title": "AI is creating a security problem most companies aren't staffed to handle, says an AI researcher",
    "description": "An AI security researcher says companies lack the talent to handle AI security problems â€” and traditional cybersecurity teams aren't enough.",
    "fullText": "Companies may have cybersecurity teams in place, but many still aren't prepared for how AI systems actually fail, says an AI security researcher.\n\nSander Schulhoff, who wrote one of the earliest prompt engineering guides and focuses on AI system vulnerabilities, said on an episode of \"Lenny's Podcast\" published Sunday that many organizations lack the talent needed to understand and fix AI security risks.\n\nTraditional cybersecurity teams are trained to patch bugs and address known vulnerabilities, but AI doesn't behave that way.\n\n\"You can patch a bug, but you can't patch a brain,\" Schulhoff said, describing what he sees as a mismatch between how security teams think and how large language models fail.\n\n\"There's this disconnect about how AI works compared to classical cybersecurity,\" he added.\n\nThat gap shows up in real-world deployments. Cybersecurity professionals may review an AI system for technical flaws without asking: \"What if someone tricks the AI into doing something it shouldn't?\" said Schulhoff, who runs a prompt engineering platform and an AI red-teaming hackathon.\n\nUnlike traditional software, AI systems can be manipulated through language and indirect instructions, he added.\n\nSchulhoff said people with experience in both AI security and cybersecurity would know what to do if an AI model is tricked into generating malicious code. For example, they would run the code in a container and ensure the AI's output doesn't affect the rest of the system.\n\nThe intersection of AI security and traditional cybersecurity is where \"the security jobs of the future are,\" he added.\n\nSchulhoff also said that many AI security startups are pitching guardrails that don't offer real protection. Because AI systems can be manipulated in countless ways, claims that these tools can \"catch everything\" are misleading.\n\n\"That's a complete lie,\" he said, adding that there would be a market correction in which \"the revenue just completely dries up for these guardrails and automated red-teaming companies.\"\n\nAI security startups have been riding the wave of investor interest. Big Tech and venture capital firms have poured money into the space as companies rush to secure AI systems.\n\nIn March, Google bought cybersecurity startup Wiz for $32 billion, a deal aimed at strengthening its cloud security business.\n\nGoogle CEO Sundar Pichai said AI was introducing \"new risks\" at a time when multi-cloud and hybrid setups are becoming more common.\n\n\"Against this backdrop, organizations are looking for cybersecurity solutions that improve cloud security and span multiple clouds,\" he added.\n\nBusiness Insider reported last year that growing security concerns around AI models have helped fuel a wave of startups pitching tools to monitor, test, and secure AI systems.",
    "readingTime": 3,
    "keywords": [
      "prompt engineering",
      "cloud security",
      "cybersecurity teams",
      "traditional cybersecurity",
      "security startups",
      "systems",
      "system",
      "patch",
      "fail",
      "vulnerabilities"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-security-gap-companies-researcher-sander-schulhoff-2025-12",
    "thumbnail_url": "https://i.insider.com/6948cd7864858d02d217386e?width=1200&format=jpeg",
    "created_at": "2025-12-22T06:20:26.750Z",
    "topic": "science"
  },
  {
    "slug": "i-asked-chatgpt-the-smartest-retirement-move-to-make-in-2026-its-advice-was-shockingly-simple",
    "title": "I Asked ChatGPT the Smartest Retirement Move To Make in 2026 â€” Its Advice Was Shockingly Simple",
    "description": "ChatGPT recommended one retirement strategy for 2026: Maximize Roth accounts before tax rates rise. Here's why this simple move could save thousands.",
    "fullText": "When it comes to retirement planning, everyoneâ€™s got an opinion. Financial advisors push complicated portfolios, bloggers swear by extreme savings and your neighbor wonâ€™t stop talking about their real estate investments.\n\nBe Aware: Major 401(k) Change Coming in 2026 â€” High Earners Must Act Now\n\nRead Next: 5 Clever Ways Retirees Are Earning Up To $1K Per Month From Home\n\nSo I decided to cut through the noise and ask ChatGPT directly: Whatâ€™s the single smartest retirement move to make in 2026?\n\nThe answer was surprisingly straightforward â€” and it has everything to do with timing.\n\nChatGPTâ€™s response was clear: Maximize your tax-advantaged accounts with a Roth-first strategy while tax rates are still relatively low.\n\nThat means prioritizing Roth IRA contributions, Roth 401(k) contributions and Roth conversions over traditional pretax retirement accounts. The reason this matters so much right now comes down to one major deadline.\n\nLearn More: This â€˜Boringâ€™ Investment Could Be the Secret To Never Running Out of Retirement Income\n\nThe Tax Cuts and Jobs Act provisions expire after 2025. That means many Americans will face higher federal tax rates starting in 2026 and beyond.\n\nIf you convert money from a traditional IRA to a Roth IRA before rates go up, you pay taxes at todayâ€™s lower rates. Then that money grows tax-free forever and you never pay taxes on it again â€” even when rates are higher.\n\nChatGPT explained that this creates a perfect opportunity. Lock in lower tax rates now by moving money into Roth accounts before the window closes. For people who expect to be in a similar or higher tax bracket in retirement, this move could save thousands of dollars over a lifetime.\n\nThe Roth-first strategy isnâ€™t complicated, but it requires action in three areas.\n\nFirst, contribute to a Roth IRA or Roth 401(k) instead of the traditional versions. If your income is too high for direct Roth IRA contributions, you can use the backdoor Roth strategy by contributing to a traditional IRA and immediately converting it.\n\nSecond, consider converting some of your existing traditional IRA money to a Roth. Youâ€™ll pay taxes on the conversion amount this year, but then that money grows tax-free. The key is converting when your income is lower or tax rates are favorable â€” which is exactly what 2025 and early 2026 represent before rates potentially rise.\n\nThird, if you have a 401(k) with Roth options, funnel as much as possible into the Roth side. For 2025, the 401(k) contribution limit is $23,000 for people under 50 and $30,500 for those 50 and older.",
    "readingTime": 3,
    "keywords": [
      "roth-first strategy",
      "ira contributions",
      "traditional ira",
      "roth ira",
      "tax rates",
      "retirement",
      "money",
      "accounts",
      "income",
      "higher"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asked-chatgpt-smartest-retirement-move-161012531.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/lJf_oWQ6zKW61pSF6KXjsQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/gobankingrates_644/462257bf337ed267db1d5a918b6d6cb6",
    "created_at": "2025-12-22T06:20:25.965Z",
    "topic": "finance"
  },
  {
    "slug": "dell-says-win-11-transition-is-far-slower-than-win-10-yet-pc-sales-have-stalled",
    "title": "Dell says Win 11 transition is far slower than Win 10, yet PC sales have stalled",
    "description": ": Lessons from COVID and tariff shocks getting Mike D's tech shop through AI-induced memory maze",
    "fullText": "Dell has predicted PC sales will be flat next year, despite the potential of the AI PC and the slow replacement of Windows 10.\n\nâ€œWe have not completed the Windows 11 transition,â€ COO Jeffrey Clarke said during Dellâ€™s Q3 earnings call on Tuesday. â€œIn fact, if you were to look at it relative to the previous OS end of support, we are 10-12 points behind at that point with Windows 11 than we were the previous generation.â€\n\nClarke said that means 500 million PCs canâ€™t run Windows 11, while the same number didnâ€™t need an upgrade to handle Microsoftâ€™s latest desktop OS. The COO therefore predicted the PC market will â€œflourishâ€, but then defined the word as meaning â€œroughly flatâ€ sales despite Dell chalking up mid-to high single digits PC sales growth over the last year.\n\nDell can survive flat PC growth because its enterprise AI hardware portfolio is booming. The company booked orders for $12.3 billion worth of AI servers in the quarter ended October 31st, and shipped machines valued at $5.6 billion. Revenue from servers and networking kit reached $10.1 billion for the quarter, up 37 percent year-over-year.\n\nâ€œOur five-quarter pipeline continue to grow sequentially across neo-clouds, sovereigns and enterprises, and remains multiples of our backlog, even when accounting for the robust demand we've seen,â€ Clarke told investors on the earnings call. â€œAs expected, AI server profitability improved sequentially,â€ he added.\n\nBuyers are becoming more interested in traditional servers, too, often to consolidate existing fleets into denser rigs. That means more memory and storage in each system, and a challenge for Dell given the exploding price of RAM and NAND, caused by memory-makers shifting production to the high-margin products needed to support AI workloads and reducing manufacturing capacity for more anodyne kit.\n\nClarke said Dell will do â€œeverything we can to minimize the impact,â€ drawing on extreme supply chain management skills learned during the COVID-19 pandemic and in more recent months coping with Trump administrationâ€™s rapidly shifting tariff policies.\n\nâ€œOur model gives us tremendous flexibility, whether that is to reprice, how we set out quotes, whether that's to reconfigure, redirect to different products, the ability to determine how long price will be in effect, the ability to understand where we're going to drive demand to and change our demand generation vehicles to drive that,â€ Clarke said.\n\nDell reported $27 billion of revenue in the quarter, an eleven percent year-over-year jump, and told investors to expect $31.5 billion in Q4 and $111.7 billion in FY 2026, jumps of 32 percent and 17 percent respectively.\n\nThe company thinks servers will be a big part of that improvement, because 70 percent of its customers run 14th generation servers or even older machines. Dellâ€™s current machines are its 17th generation and each one replaces between three and seven older machines â€“ and has a higher average selling price due to the aforementioned increase in memory and storage.\n\nBuyers looking to modernize their servers therefore need Dell to successfully exercise its self-professed supply chain skills, or revisit their budgets. Â®",
    "readingTime": 3,
    "keywords": [
      "supply chain",
      "older machines",
      "dell",
      "servers",
      "generation",
      "sales",
      "flat",
      "quarter",
      "demand",
      "predicted"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2025/11/26/dell_q3_2026/",
    "thumbnail_url": "https://regmedia.co.uk/2024/05/09/dell1_shutterstock.jpg",
    "created_at": "2025-12-21T18:16:16.455Z",
    "topic": "tech"
  },
  {
    "slug": "extremists-are-using-ai-voice-cloning-to-supercharge-propaganda-experts-say-its-helping-them-grow",
    "title": "Extremists are using AI voice cloning to supercharge propaganda. Experts say itâ€™s helping them grow",
    "description": "Researchers warn generative tools are helping militant groups from neo-Nazis to the Islamic State spread ideology\nWhile the artificial intelligence boom is upending sections of the music industry, voice generating bots are also becoming a boon to another unlikely corner of the internet: extremist movements that are using them to recreate the voices and speeches of major figures in their milieu, and experts say it is helping them grow.\nâ€œThe adoption of AI-enabled translation by terrorists and extremists marks a significant evolution in digital propaganda strategies,â€ said Lucas Webber, a senior threat intelligence analyst at Tech Against Terrorism and a research fellow at the Soufan Center. Webber specializes in monitoring the online tools of terrorist groups and extremists around the world.\n Continue reading...",
    "fullText": "Researchers warn generative tools are helping militant groups from neo-Nazis to the Islamic State spread ideology\n\nWhile the artificial intelligence boom is upending sections of the music industry, voice generating bots are also becoming a boon to another unlikely corner of the internet: extremist movements that are using them to recreate the voices and speeches of major figures in their milieu, and experts say it is helping them grow.\n\nâ€œThe adoption of AI-enabled translation by terrorists and extremists marks a significant evolution in digital propaganda strategies,â€ said Lucas Webber, a senior threat intelligence analyst at Tech Against Terrorism and a research fellow at the Soufan Center. Webber specializes in monitoring the online tools of terrorist groups and extremists around the world.\n\nâ€œEarlier methods relied on human translators or rudimentary machine translation, often limited by language fidelity and stylistic nuance,â€ he said. â€œNow, with the rise of advanced generative AI tools, these groups are able to produce seamless, contextually accurate translations that preserve tone, emotion, and ideological intensity across multiple languages.â€\n\nOn the neo-Nazi far-right, adoption of AI-voice cloning software has already become particularly prolific, with several English-language versions of Adolf Hitlerâ€™s speeches garnering tens of millions of streams across X, Instagram, TikTok, and other apps.\n\nAccording to a recent research post by the Global Network on Extremism and Technology (GNet), extremist content creators have turned to voice cloning services, specifically ElevenLabs, and feed them archival speeches from the era of the Third Reich, which are then processed into mimicking Hitler in English.\n\nNeo-Nazi accelerationists, the kinds who plot acts of terrorism against western governments to provoke a societal collapse, have also turned to these tools to spread more updated versions of their hyper-violent messaging. For example, Siege, an insurgency manual written by American neo-Nazi and proscribed terrorist James Mason that became the veritable bible to organizations like the Base and the now-defunct Atomwaffen Division, was transformed into an audiobook in late November.\n\nâ€œFor the last several months I have been involved in making an audiobook of Siege by James Mason,â€ said a prominent neo-Nazi influencer with a heavy presence on X and Telegram, who stitched together the audiobook with the help of AI tools.\n\nâ€œUsing a custom voice model of Mason, I re-created every newsletter and most of the attached newspaper clippings as in the original published newsletters.â€\n\nThe influencer lauded the power of having Masonâ€™s writing from â€œpre-internet Americaâ€ and turning it into a modern-day voice.\n\nâ€œBut to hear the startling accuracy of predictions made through the early eighties really puts a milestone on the road and it changed my view of our shared cause on a fundamental level,â€ he said.\n\nAt its height in 2020, the Base held a book club on Siege, which was an instrumental influence on several members who discussed its benefits in a hypothetical war against the US government. A nationwide FBI counterterrorism probe eventually swept up over a dozen of its members on various terrorism related charges in the same year.\n\nâ€œThe creator of the audiobook has previously released similar AI content; however, Siege has a more notorious history,â€ said Joshua Fisher-Birch, a terrorism analyst at the Counter Extremism Project, â€œdue to its cultlike status among some in the online extreme right, promotion of lone actor violence, and being required reading by several neo-Nazi groups that openly endorse terrorism and whose members have committed violent criminal actsâ€.\n\nWebber says pro-Islamic State media outlets on encrypted networks are currently and actively â€œusing AI to create text-to-speech renditions of ideological content from official publicationsâ€, to supercharge the spread of their messaging by transforming â€œtext-based propaganda into engaging multimedia narrativesâ€.\n\nJihadist terrorist groups have found utility in AI for translations of extremist teachings from Arabic into easily digestible, multilingual content. In the past, American-imam turned al-Qaeda operative Anwar al-Awlaki, would personally have to voice English lectures for recruitment propaganda in the anglosphere. The CIA and FBI have repeatedly cited the influence of al-Awlakiâ€™s voice as a key contagion in the spread of al-Qaedaâ€™s message.\n\nOn Rocket.Chat â€“ the preferred communications platform of the Islamic State, which it uses to communicate with its followers and recruits â€“ a user posted a video clip in October with slick graphics and Japanese subtitling, remarking on the difficulties of doing that without the advent of AI.\n\nâ€œJapanese would be an extremely hard language to translate from its original state to English while keeping its eloquence,â€ said the pro-Islamic State user. â€œIt should be known that I do not use artificial intelligence for any related media, with some exceptions regarding audio.â€\n\nSo far, not just the Islamic State, but groups across the ideological spectrum, have begun using free AI applications, namely OpenAIâ€™s chatbot, ChatGPT, to amplify their overall activities. The Base and adjacent groups have used it for the creation of imagery, while also acknowledging, as far back as 2023, the use of these tools to streamline planning and researching.\n\nCounterterrorism authorities have always viewed the internet and technological advancements as a persistent game of catch-up when it comes to keeping pace with the terror groups who exploit them. Already the Base, the Islamic State and other extremists have leveraged emergent technologies like crypto to anonymously fundraise and share files for 3D printed firearms.",
    "readingTime": 5,
    "keywords": [
      "artificial intelligence",
      "terrorist groups",
      "islamic state",
      "james mason",
      "tools",
      "voice",
      "spread",
      "content",
      "siege",
      "audiobook"
    ],
    "qualityScore": 0.8,
    "link": "https://www.theguardian.com/technology/2025/dec/21/ai-voice-cloning-nazis-islamic-state-extremism",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ed5fc77bbcac92c1b06a98464d8c84c25e77a2b2/1_0_2999_2400/master/2999.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e03dfb683577eafdb0355cda8d602396",
    "created_at": "2025-12-21T18:16:13.419Z",
    "topic": "tech"
  },
  {
    "slug": "multimillionaire-musician-william-says-worklife-balance-is-for-people-working-on-someone-elses-dreamhe-grinds-from-5to9",
    "title": "Multimillionaire musician Will.i.am says work-life balance is for people â€˜working on someone elseâ€™s dreamâ€™â€”he grinds from 5-to-9 after his 9-to-5",
    "description": "When Will.i.amâ€™s not writing hit songs like â€œOMGâ€ for Usher, heâ€™s looking for the next big pop star on The Voice U.K., or running his new AI company, FYI.",
    "fullText": "Orianna Rosa Royle is the Success associate editor at Fortune, overseeing careers, leadership, and company culture coverage. She was previously the senior reporter at Management Today, Britain's longest-running publication for CEOs.\n\nWill.i.am is busy. When heâ€™s not writing hit songs like â€œOMGâ€ for Usher, heâ€™s looking for the next big pop star on The Voice UK, or running his new AI company, FYI. So how exactly does he balance it all?\n\nThe Grammy Awardâ€“winning artist turned tech entrepreneur revealed to Fortune that he maxes out the 5-to-9 after the daily grind of his 9-to-5, and he advises Gen Zers to forget about work-life balance if they want to emulate his success.\n\nâ€œIf youâ€™re trying to build something that doesnâ€™t exist, itâ€™s about dream-reality balance,â€ he says. â€œWork-life balance means that youâ€™re working for somebody elseâ€™s dream. You just have a job supporting somebody elseâ€™s dream, and you want to balance your work and your life.\n\nâ€œBut if itâ€™s dream-reality balance, then itâ€™s not work. Itâ€™s a dream that youâ€™re trying to put into reality, and youâ€™re ignoring your current reality.â€\n\nFor example, after working on his tech venture from 9 a.m. to 5 p.m., Will.i.am says that he goes back to work on his creative business until 9 p.m. But before his AI company was a reality, his day was flipped. Heâ€™d work on music first before dipping into his tech side hustle well into the evening.\n\nItâ€™s why he advises young people to reframe how they think of their time off work and their current 9-to-5 reality.\n\nâ€œIâ€™m not really paying attention to this reality,â€ he explains. â€œIâ€™m trying to bring that one [a new business venture or idea] here and focusing on how do I get people who believe in this dream to help me materialize it? So for that, you have to make some type of sacrifice to bring this thing that doesnâ€™t exist here.\n\nâ€œFrom that perspective, work-life balance is not for the architects that are pulling visions into reality. Those words donâ€™t compute to the mindset of the materializers.â€\n\nOf course, many young people already put in hours to their side hustles and personal development after work. Millions of Gen Zers and millennials are tuning into peopleâ€™s 5-to-9 evening routines on TikTok.\n\nBut Will.i.am says chipping away at your dream when most people are off work extends to weekends, birthdays, and holidays.\n\nâ€œI didnâ€™t party. I was always a square, meaning, â€˜You work too much, man, letâ€™s go out.â€™ Like what? Go out. I donâ€™t want to go out. I just always worked,â€ the rapper says. â€œItâ€™sÂ your birthday what are you gonna do? Work. You ainâ€™t gonna celebrate?â€\n\nThe multimillionaire says heâ€™s always saved the celebrating for the stage, where he can finally enjoy the fruits of his labor.\n\nâ€œThereâ€™s nothing thatâ€™s ever gonna feel that glorious than when youâ€™re actually at a festival. But how do you get to headline a festival? Youâ€™ve got to work. My friends would go out and party, hanging out with chicks, doing drugs, drinking. I was just in the studio working, writing songs.â€\n\nTo this day, he says that he hasnâ€™t gone out and celebrated a birthdayâ€”including his most recent one, which was just last week on March 15.\n\nâ€œLike on Christmas for the past 12 years: I could celebrate Christmas with my family, and then on the 26th, I fly to China because thatâ€™s dream maker heaven. Anything you want to make is there.â€\n\nWill.i.am was speaking to Fortune in Rome for the rollout of Raidio.FYI radios in Mercedes-Benz cars.\n\n7 a.m.: Will.i.am is not a part of the CEO-approved 5 a.m. club. Instead, he told Fortune he wakes up at around 7 a.m., and he sticks to this routine whether heâ€™s living in L.A. or London.\n\n8 a.m.: â€œI walk, do my calls, and get to work,â€ he says, with the aim to start work at 9 a.m.\n\n9 a.m. to 5 p.m.: â€œI get a lot done from nine to 12, do my little lunch, then back to work at one, finish at five, and thatâ€™s all my tech, like entrepreneurial activities.â€\n\n5 p.m. to 9 p.m.: â€œThe night hours are creativity,â€ he says, adding that specifically between 7 p.m. and 9 p.m. is when he gets the best ideas. â€œThatâ€™s the juicy bits, [when] Iâ€™m freaking soaking in emotion, to where I just rinse it out in the phone.â€\n\n9 p.m. onward: When Will.i.am was in his late twenties, he says going to sleep at 4 a.m. (and waking up at noon) was the norm. But now, at 50 and balancing both his tech and music ventures, he starts unwinding for bed after 9 p.m. and is asleep by 11 p.m.\n\nA version of this story originally published onÂ Fortune.comÂ onÂ March 23, 2025.",
    "readingTime": 5,
    "keywords": [
      "doesnâ€™t exist",
      "somebody elseâ€™s",
      "elseâ€™s dream",
      "work-life balance",
      "dream-reality balance",
      "itâ€™s",
      "tech",
      "youâ€™re",
      "fortune",
      "heâ€™s"
    ],
    "qualityScore": 0.8,
    "link": "https://fortune.com/article/will-i-am-says-work-life-balance-for-people-working-on-someone-elses-dream/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/03/GettyImages-1487800046.jpg?resize=1200,600",
    "created_at": "2025-12-21T18:15:57.676Z",
    "topic": "business"
  },
  {
    "slug": "i-applied-for-900-jobs-after-being-laid-off-at-62-ai-made-the-search-even-harder",
    "title": "I applied for 900 jobs after being laid off at 62. AI made the search even harder.",
    "description": "After being made redundant, Jim Herrington's job hunt revealed how AI and ageism are reshaping the modern hiring process.",
    "fullText": "This story is based on a conversation with Jim Herrington, 62, from Suffolk, UK. It has been edited for length and clarity.\n\nWhen I was made redundant from my electronics marketing job in 2024 after the company downsized, the last thing I expected was that I would end up applying for 900 jobs before finally landing a new one.\n\nI put everything I had into my job search. I created tailored rÃ©sumÃ©s, cover letters, and even presentations for individual roles â€” without using AI â€” and contacted employers directly, while also attending physical events to meet new contacts.\n\nI treated each day like a workday â€” often starting at 8 a.m. to search through job boards, then methodically selecting which roles to apply for based on relevance, industry, and location. I even sent my rÃ©sumÃ© to some trusted peers for feedback and refinement. I was also open about being happy to commute to an office up to an hour from where I live - in my early career, I would drive thousands of miles a year for work.\n\nThroughout this entire process, my motivation and confidence took a significant hit, particularly due to the frustration of conflicting feedback. Some bosses wanted experience in their industry, while others were open to people from other fields. Some were open to senior marketers, yet others told me I was overqualified.\n\nThe feedback that I often got was, \"You'd be bored in this job\", but given my age, I think they were trying to say that they thought I was too old, rather than value my 40-plus years of experience, the awards I've won, and the teaching work I've done.\n\nWhile AI may be helping companies streamline their recruitment processes, I believe it's actually causing more problems. Getting all the right buzzwords into your rÃ©sumÃ© and cover letter to get past AI screening tests seems to have become more important than whether someone is actually a good fit.\n\nNow, with some companies even starting to use AI video interviews, that's only going to add to that mistrust and cause employers to ruin their reputation among candidates. Because if a business hasn't got the time or courtesy to speak to me themselves, then I'm just not interested.\n\nIn an interview, there would be so much that an AI could not possibly experience. To me, it shows a total lack of respect for the candidate who has taken the time and energy to apply.\n\nBut the problem is more complex than simply a tough market or lazy applicants who are using AI. In my experience, many employers simply lack clarity in what they're looking for.\n\nWhen they don't list exactly what they are looking for, it's very difficult. If they want experience, then they need to say it. If you're looking for somebody who can bring fresh ideas and a new approach, then they need to say it. It is especially unhelpful when salaries aren't listed.\n\nInstead of applying for 900 jobs, I could have applied for 100, because I would have known with 800 of them that I would have been wasting a lot of effort, as I would have had a better sense that I was overqualified for most of them. But a lot of job specs weren't written properly and didn't show everything they were looking for.\n\nFinally, in December 2024, I was appointed as marketing director of Omega Diagnostics, a health testing company. They called me the day after I applied and said, \"Wow, you have a great rÃ©sumÃ©. Can we talk to you?\"\n\nWhen you do 900 job applications, you start to question yourself, and you think, \"Am I actually that good?\" And you build up resilience.\n\nFor them, my seniority was a significant advantage, but they also appreciated the fact that I had been successful in other industries and could bring a fresh perspective.\n\nSo, finally, it has turned out well. I'm well paid. It's relatively local. It's an industry where there is a lot of change and a lot of activity. It's an industry that actually has a positive outcome on people's lives. I'm really happy that I can personally recommend something that I'm doing for work that will make a difference.",
    "readingTime": 4,
    "keywords": [
      "experience",
      "it's",
      "industry",
      "looking",
      "finally",
      "employers",
      "rÃ©sum",
      "feedback",
      "based",
      "clarity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lost-my-job-after-900-applications-i-finally-got-hired-2025-12",
    "thumbnail_url": "https://i.insider.com/6925aee7abd5e944effb6d84?width=1200&format=jpeg",
    "created_at": "2025-12-21T18:15:56.890Z",
    "topic": "finance"
  },
  {
    "slug": "big-short-trader-danny-moses-warns-investors-the-ai-bubble-is-real-and-shares-his-playbook-for-staying-ahead-in-the",
    "title": "'Big Short' trader Danny Moses warns investors the AI bubble is real, and shares his playbook for staying ahead in the market",
    "description": "Danny Moses, one of the traders featured in \"The Big Short,\" thinks the AI bubble is real. He shares advice on how to avoid getting burned.",
    "fullText": "Since Michael Burry launched a Substack in November, he's been sharing plenty of investing insight, but he isn't the only \"Big Short\" trader who has something to say about the current market landscape.\n\nDanny Moses, the former member of FrontPoint Partners, the firm led by Steve Eisman that successfully bet against the housing market in 2008, spoke to Business Insider about the potential problems he sees developing in the AI market and how he thinks investors should navigate the rapidly evolving space.\n\nAs the AI boom has unfolded, many finance pros have weighed two primary questions: Is there a bubble in the AI market, and if so, should it be compared to the dot-com era of the early 2000s?\n\nMoses thinks the answer to both questions is yes. While he doesn't deny that the AI trade is real and a secular growth story, he also sees strong parallels between the two tech crazes that suggest investors need to tread cautiously.\n\n\"The growth was real, but the math didn't work,\" he said. \"And I think that we're reaching a point where the math is starting not to work.\"\n\nMoses emphasized that his take on potential AI market problems isn't a call to short the industry. Rather, he noted it's a call for investors to do their homework and find the right names to gain valuable exposure as the market continues to grow.\n\nIn his view, that means sticking with the tech sector's most dominant names that have the resources to continue scaling and aren't bound by the same constraints that some smaller companies are. The best examples include Amazon, Google, Meta, and Microsoft.\n\n\"They can turn down their capex at any point, and they're still cash flowing positive, as opposed to these other companies, which are dependent upon that spending within AI,\" he said.\n\nMoses isn't bullish on all of Big Tech's top names, though. He cited Oracle as an example of problems within the AI market, noting the company's high debt levels and the cash that it will require the fulfill the orders from tech clients. He also highlighted volatile tech stocks Super Micro Computer and CoreWeave as examples of riskier plays within the AI trade.\n\nIn his view, though, investors are finally starting to account for the fact that not all AI stocks are created equal as the divide between relative outperformers and underperformers becomes increasingly hard to ignore.\n\n\"I think it's proof that investors are beginning to sort out the winners and losers of the trade, and they'd much rather have comfort and other businesses with stronger balance sheets to fall back upon to express the AI theme,\" Moses added.\n\nHe also said that he's bullish on uranium, as the metal is being increasingly touted as a key component of the AI buildout that will be necessary to sustain the industry in the coming years.\n\nThat said, he thinks the timeline for when it will start to spur growth is one that investors should be paying close attention to, as it is sometimes misunderstood amid the AI hype.\n\n\"One of the trades that I like is uranium, which thematically, should work, but it takes a long period of time,\" Moses said. \"There's a mismatch in the timing of how people think that companies will experience AI growth and actually the infrastructure that it's going to take to power it.\"",
    "readingTime": 3,
    "keywords": [
      "market",
      "investors",
      "growth",
      "isn't",
      "trade",
      "it's",
      "within",
      "he's",
      "potential",
      "math"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-short-danny-moses-ai-bubble-goog-amzn-msft-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/6945af7d832e0ef1ead699a3?width=1200&format=jpeg",
    "created_at": "2025-12-21T12:20:24.509Z",
    "topic": "finance"
  },
  {
    "slug": "collibra-ceo-describes-what-he-looks-for-in-aifirst-employees",
    "title": "Collibra CEO describes what he looks for in AI-first employees",
    "description": "Collibra CEO Felix Van de Maele said it's \"a red flag\" if prospective employees aren't leaning into how they can use AI to make their job better.",
    "fullText": "Collibra CEO Felix Van de Maele said it becomes \"a red flag\" if job seekers wanting to join his data governance platform cannot show familiarity with AI.\n\n\"In any interview, you expect people to think AI first in all the ways they do their job,\" Van de Maele said in an interview with Business Insider. \"And so if we ask for that and people haven't used or experimented with AI tools, they don't have a sense of how they do their job better, faster using AI, that definitely becomes a bit of a red flag.\"\n\nFounded in 2008 in Belgium, Collibra is among the top names in the data governance sector. In 2021, the private company was valued at $5.2 billion. Collibra has worked with McDonald's, Credit Suisse, Adobe, and Heineken.\n\nVan de Maele said the precise AI skills he's looking for vary by position. For example, he said, if he's interviewing an engineer, he wants to know if they are using AI agents like Cursor.\n\n\"I think you can ask questions to get a sense of how are people actually using those tools and what kind of experience have they had,\" he said. \"I think that's really important. Do they have an interest and are they leaning into wanting to use those tools, or are they more defensive and taking a step back on the adoption of those tools?\"\n\nVan de Maele said that at Collibra, which he described as sort of like \"ServiceNow for data,\" AI adoption has increased drastically over the past year. His roughly 1,000 employees around the world use AI for everything from transcribing meetings to building custom agents and assistants. The goal is to push AI usage to change how work is done.\n\nIn the enterprise marketplace, Van de Maele said he sees the ideal niche for his company as an independent layer that can connect a large amount of company-specific data, unlocking the true capabilities of AI, particularly the promise of AI agents.\n\n\"Imagine you're hiring a senior new person and in your organization and ask them to do certain analysis,\" he said.\n\nIt's challenging for humans to navigate all the hoops required to access what they need and understand how companies organize their data. In an agentic AI future, an agent could find themselves stuck in a similar situation.\n\n\"If a human can't do it, the agent can't do it unless you make that context formal and you capture that context so the agent can use that,\" Van de Maele said.\n\nMaking sure customers get a tailored experience is why Palantir helped popularize the use of forward-deployed engineers. OpenAI and other model makers are following suit with their own teams. The current issue with enterprise AI, Van de Maele said, is that if a company is tied to just a single model they could easily fall behind.\n\n\"If I'm a big bank, if I'm a big organization, I don't want to be completely tied to one model vendor because who knows, maybe next month there's another model that's five times better or five times cheaper,\" he said. \"I want to have the flexibility to change. That's strategically important to me.\"",
    "readingTime": 3,
    "keywords": [
      "van de maele",
      "red flag",
      "tools",
      "model",
      "agents",
      "that's",
      "agent",
      "governance",
      "interview",
      "don't"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/collibra-ai-first-employees-felix-van-de-maele-enterprise-2025-12",
    "thumbnail_url": "https://i.insider.com/6945241a04eda4732f2dd7ce?width=1200&format=jpeg",
    "created_at": "2025-12-21T12:20:24.308Z",
    "topic": "finance"
  },
  {
    "slug": "help-i-need-money-its-an-emergency-your-childs-voicemail-that-could-be-a-scam",
    "title": "â€˜Help! I need money. Itâ€™s an emergencyâ€™: your childâ€™s voicemail that could be a scam",
    "description": "Steps to help combat fraud in which criminals use AI-generated replica of a personâ€™s voice to deceive victims\nThe voicemail from your son is alarming. He has just been in a car accident and is highly stressed. He needs money urgently, although it is not clear why, and he gives you some bank details for a transfer.\nYou consider yourself wise to other scams, and have ignored texts claiming to be from him and asking for cash. But you can hear his voice and he is clearly in trouble.",
    "fullText": "Steps to help combat fraud in which criminals use AI-generated replica of a personâ€™s voice to deceive victims\n\nThe voicemail from your son is alarming. He has just been in a car accident and is highly stressed. He needs money urgently, although it is not clear why, and he gives you some bank details for a transfer.\n\nYou consider yourself wise to other scams, and have ignored texts claiming to be from him and asking for cash. But you can hear his voice and he is clearly in trouble.\n\nHowever, the voicemail is the latest way in which criminals are using technology to defraud people. By taking a tiny snippet of real audio â€“ just three seconds is enough â€“ from a person, they can â€œcloneâ€ the individualâ€™s voice using freely available AI technology. From there, they can make an recording of the synthesised voice saying exactly what they want.\n\nThe criminals can record a voice from videos on social media or by calling someone and saying nothing. A victim just needs to respond with words such as â€œhello, who is there?â€ to give them material for their hoax.\n\nOliver Devane, a senior researcher at the online security company McAfee, says this is a sophisticated example of spear phishing, or a personalised, targeted attack.\n\nâ€œHaving tested some of the free and paid AI voice cloning tools online, we found in one instance, that just three seconds of audio was needed to produce a good match,â€ he says.\n\nâ€œCybercriminals will often source this information from public social media profiles and other places online where people post about themselves, their families, their travels, and so on in an attempt to cash in.\n\nâ€œThe cybercriminal is betting on a loved one or family member becoming worried, letting emotions take over, and sending money to help.â€\n\nA phone call or a voicemail, or even a voice note, will come through on your mobile and sound exactly like a loved one or friend.\n\nThey will have been involved in an accident or they may have been robbed or injured. They will be distressed and there will be a sense of urgency.\n\nWhatever the circumstances, they will ask for money. They may not give details of why they need the money but they will say it is urgent. They may ask you to transfer it to an account that belongs to someone else.\n\nAs with many scams, if you get a call or voicemail that asks for money, take a moment to stop and think. Does it really sound like the person you know? Are there strange speech patterns that are not accounted for by the fact that there is an emergency.\n\nEven if the phone number comes up as coming from one of your children, this is no assurance as the number can also be faked.\n\nâ€œTry to remain level-headed and pause before you take any next steps,â€ says Devane. â€œRemember that cybercriminals are betting on emotions running high. They will play on your connection to the loved one and create a sense of urgency to prompt you into action.â€\n\nCall the person who it seems left the message. They may pick up and be able to reassure you that they are OK. Remember the message has come by phone, so even if there is a real emergency they clearly can reach their device and get a signal.\n\nTo prepare for the possibility of such scams, you can set up a codeword between you and your children so you know for sure when they are in trouble.",
    "readingTime": 3,
    "keywords": [
      "social media",
      "voice",
      "money",
      "voicemail",
      "criminals",
      "scams",
      "online",
      "loved",
      "phone",
      "steps"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/money/2025/dec/21/ai-cloned-voicemail-scam-criminals-fraud",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1324553f4cc6a17a16ec1317aeaf15d7",
    "created_at": "2025-12-21T12:20:21.333Z",
    "topic": "finance"
  },
  {
    "slug": "prediction-this-company-is-all-set-to-hit-a-5-trillion-market-cap-in-2026-hint-its-not-nvidia",
    "title": "Prediction: This Company Is All Set to Hit a $5 Trillion Market Cap in 2026 (Hint: It's Not Nvidia)",
    "description": "This tech giant's early entry into the AI space has helped it build a substantial revenue backlog that could propel its shares higher in 2026.",
    "fullText": "Microsoft's stock needs to appreciate by 41% from current levels to achieve a $5 trillion market cap.\n\nThe company's AI tools are gaining terrific traction in the productivity space, while its cloud business is also booming.\n\nDan Ives of Wedbush expects Microsoft to become a $5 trillion company next year, and it won't be surprising to see the company indeed hitting that milestone.\n\n10 stocks we like better than Microsoft â€º\n\nNvidia (NASDAQ: NVDA) briefly became the first company to cross a $5 trillion market cap just a couple of months ago, driven by the company's remarkable revenue and earnings growth on account of its dominance of the artificial intelligence (AI) chip market.\n\nHowever, the share price of the chip giant has pulled back since then, even though it continues to maintain terrific growth despite its massive size. Concerns about the AI boom becoming a bubble and the sustainability of the heavy infrastructure spending that has driven Nvidia's phenomenal growth over the past three years have begun to weigh on the stock.\n\nBut there's another company -- Microsoft (NASDAQ: MSFT) -- that's making the most of the proliferation of AI. One analyst believes that this \"Magnificent Seven\" company could hit a $5 trillion market cap in 2026. Let's take a closer look at Microsoft's prospects and why it could hit the $5 trillion market cap milestone in the new year.\n\nThere is no denying that Nvidia's chips have played a crucial role in the widespread adoption of AI technology. However, the computing power provided by its chips is eventually harnessed to create customer-facing solutions. For example, training OpenAI's ChatGPT wouldn't have been possible without Nvidia's chips, but the chatbot became popular because of what it was doing for users.\n\nFrom helping users write emails to creating images to drafting documents and writing code, ChatGPT's versatility and productivity have been the key reasons behind its raging success. Not surprisingly, ChatGPT parent OpenAI points out that it now has more than 1 million paying enterprise customers, while more than 800 million users use ChatGPT every week.\n\nMicrosoft made a smart move in 2019 by investing in OpenAI. It still holds a 27% stake in OpenAI, a company reportedly worth $500 billion. However, more than the financial aspect, OpenAI provided Microsoft with access to large language models (LLMs) and applications, enabling it to build a wide portfolio of AI-powered tools and deploy them across its offerings.",
    "readingTime": 3,
    "keywords": [
      "nvidia's chips",
      "market cap",
      "growth",
      "however",
      "users",
      "microsoft's",
      "stock",
      "company's",
      "tools",
      "terrific"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/prediction-company-set-hit-5-175000852.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/w.T6Mm3tsbs8lsIgOzacSA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03NjY-/https://media.zenfs.com/en/motleyfool.com/d754b0032b3ba58253828d1c0e6ae313",
    "created_at": "2025-12-21T12:20:17.105Z",
    "topic": "finance"
  }
]
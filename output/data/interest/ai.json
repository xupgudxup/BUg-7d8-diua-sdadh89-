[
  {
    "slug": "mg-asset-management-ceo-pinto-diversification-is-key",
    "title": "M&G Asset Management CEO Pinto: Diversification is Key",
    "description": "Joseph Pinto, CEO of M&G Asset Management, on AI, private credit, and reallocation of global capital. 'We've seen rebalancing', he says. 'Clients have decided to reallocate a bit more to Europe or to Asia'. Pinto speaks with Bloomberg's Guy Johnson, Anna Edwards and Tom Mackenzie on 'The Opening Trade'.",
    "fullText": "Feb 4th, 2026M&G Asset Management CEO Pinto: Diversification is KeyJoseph Pinto, CEO of M&G Asset Management, on AI, private credit, and reallocation of global capital. 'We've seen rebalancing', he says. 'Clients have decided to reallocate a bit more to Europe or to Asia'. Pinto speaks with Bloomberg's Guy Johnson, Anna Edwards and Tom Mackenzie on 'The Opening Trade'.Duration:2:43Anthropic AI Tool Sparks Stocks SelloffDuration:6:28Novo CEO Remains Confident After 20% PlungeDuration:3:29US Shutdown Ends as Trump Signs His Funding Deal With DemocratsBalance of PowerDuration:6:11Indonesia FM Blasts Citi, Defends MSCI DowngradeDuration:3:01Fidelity Sees 'Very Bumpy' Ride Ahead for MarketsDuration:1:42D‚ÄôAmaro Is a Standout Executive, Disney‚Äôs Gorman SaysDuration:1:23Musk‚Äôs SpaceX Combines With xAI at $1.25 Trillion ValuationDuration:3:16PayPal Names New CEO as Profit Misses TargetsAvailable on:Listen onApple TVListen onRokuListen onSamsung TVListen onFire TVListen onAndroid TVListen onRakuten TVListen onHaystack NewsWatch BTV in your area:Channel Finder",
    "readingTime": 1,
    "keywords": [
      "m&g asset",
      "asset management",
      "tvlisten",
      "pinto"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/videos/2026-02-04/m-g-asset-management-ceo-pinto-diversification-is-key-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ikRPhtCQovWM/v3/-1x-1.webp",
    "created_at": "2026-02-04T12:35:38.829Z",
    "topic": "finance"
  },
  {
    "slug": "ai-disruption-fears-spark-selloff-novo-nordisk-amd-drops-after-earnings-bloomberg-brief-242026",
    "title": "AI Disruption Fears Spark Selloff; Novo Nordisk, AMD Drops After Earnings | Bloomberg Brief 2/4/2026",
    "description": "US equity futures take a breather from a global rout driven by stocks sensitive to potential disruption from Anthropic's new automation tool. Investors await results from Alphabet and Qualcomm as AMD's AI-fueled outlook disappoints. Shares of Novo Nordisk plunges as the drugmaker forecasts sales to fall as much 13% this year. Iran asks the US to move the scheduled diplomatic talks this week from Turkey to Oman and to limit the agenda to Tehran's nuclear program. Stephanie Guild of Robinhood discusses the opportunities in software stocks amid the recent selloff.",
    "fullText": "Feb 4th, 2026AI Disruption Fears Spark Selloff; Novo Nordisk, AMD Drops After Earnings | Bloomberg Brief 2/4/2026US equity futures take a breather from a global rout driven by stocks sensitive to potential disruption from Anthropic's new automation tool. Investors await results from Alphabet and Qualcomm as AMD's AI-fueled outlook disappoints. Shares of Novo Nordisk plunges as the drugmaker forecasts sales to fall as much 13% this year. Iran asks the US to move the scheduled diplomatic talks this week from Turkey to Oman and to limit the agenda to Tehran's nuclear program. Stephanie Guild of Robinhood discusses the opportunities in software stocks amid the recent selloff. Duration:10:20Why the World Is Awash With Cheap OilWeekly DocsDuration:56:34Trump Picks Warsh, US State Capitalism, SNAP Cuts, Business of Youth SportsBloomberg Wall Street WeekDuration:10:02How Circular Deals Are Driving the AI BoomWeekly DocsDuration:24:01Inside Europe‚Äôs Economic Crises With LagardeLeaders with Francine LacquaAvailable on:Listen onApple TVListen onRokuListen onSamsung TVListen onFire TVListen onAndroid TVListen onRakuten TVListen onHaystack NewsWatch BTV in your area:Channel Finder",
    "readingTime": 1,
    "keywords": [
      "novo nordisk",
      "tvlisten",
      "disruption",
      "selloff",
      "stocks"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/videos/2026-02-04/bloomberg-brief-2-4-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBFBd4LZYdsk/v3/-1x-1.webp",
    "created_at": "2026-02-04T12:35:36.424Z",
    "topic": "finance"
  },
  {
    "slug": "ai-anxiety-is-fueling-the-comeback-in-value-stocks",
    "title": "AI Anxiety Is Fueling the Comeback in Value Stocks",
    "description": "The software selloff is boosting the appeal of value stocks.",
    "fullText": "Value stocks (think consumer staples, energy producers and miners) have been zooming higher as investors seek out companies that will benefit from an uptick in economic growth. On the flipside, tech has struggled this year on worries that AI will make a lot of business models obsolete.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/newsletters/2026-02-04/ai-anxiety-is-fueling-the-comeback-in-value-stocks",
    "thumbnail_url": "https://assets.bwbx.io/s3/lightsaber/_next/static/media/social-markets.e062a0c0.jpg",
    "created_at": "2026-02-04T12:35:36.390Z",
    "topic": "finance"
  },
  {
    "slug": "claude-is-a-space-to-think",
    "title": "Claude Is a Space to Think",
    "description": "Anthropic explains why Claude will remain ad-free‚Äîhow advertising incentives conflict with building a genuinely helpful AI assistant users can trust.",
    "fullText": "There are many good places for advertising. A conversation with Claude is not one of them.\n\nAdvertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We‚Äôve run our own ad campaigns, and our AI models have, in turn, helped many of our customers in the advertising industry.\n\nBut including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.\n\nWe want Claude to act unambiguously in our users‚Äô interests. So we‚Äôve made a choice: Claude will remain ad-free. Our users won‚Äôt see ‚Äúsponsored‚Äù links adjacent to their conversations with Claude; nor will Claude‚Äôs responses be influenced by advertisers or include third-party product placements our users did not ask for.\n\nWhen people use search engines or social media, they‚Äôve come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.\n\nConversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it‚Äôs also what makes them susceptible to influence in ways that other digital products are not.\n\nOur analysis of conversations with Claude (conducted in a way that keeps all data private and anonymous) shows that an appreciable portion involve topics that are sensitive or deeply personal‚Äîthe kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous‚Äîand, in many cases, inappropriate.\n\nWe still have much to learn about the impact of AI models on the people who use them. Early research suggests both benefits‚Äîlike people finding support they couldn‚Äôt access elsewhere‚Äîand risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity. Our understanding of how models translate the goals we set them into specific behaviors is still developing; an ad-based system could therefore have unpredictable results.\n\nBeing genuinely helpful is one of the core principles of Claude‚Äôs Constitution, the document that describes our vision for Claude‚Äôs character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.\n\nConsider a concrete example. A user mentions they‚Äôre having trouble sleeping. An assistant without advertising incentives would explore the various potential causes‚Äîstress, environment, habits, and so on‚Äîbased on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align‚Äîbut not always. And, unlike a list of search results, ads that influence a model‚Äôs responses may make it difficult to tell whether a given recommendation comes with a commercial motive or not. Users shouldn‚Äôt have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable.\n\nEven ads that don‚Äôt directly influence an AI model‚Äôs responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement‚Äîfor the amount of time people spend using Claude and how often they return. These metrics aren‚Äôt necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user‚Äôs request without prompting further conversation.\n\nWe recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches‚Äîwhere users explicitly choose to see sponsored content‚Äîmight avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development, blurring boundaries that were once more clear-cut. We‚Äôve chosen not to introduce these dynamics into Claude.\n\nAnthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.\n\nExpanding access to Claude is central to our public benefit mission, and we want to do it without selling our users‚Äô attention or data to advertisers. To that end, we‚Äôve brought AI tools and training to educators in over 60 countries, begun national AI education pilots with multiple governments, and made Claude available to nonprofits at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it. Should we need to revisit this approach, we‚Äôll be transparent about our reasons for doing so.\n\nAI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We‚Äôre particularly interested in the potential of agentic commerce, where Claude acts on a user‚Äôs behalf to handle a purchase or booking end to end. And we‚Äôll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more‚Äîwhen they choose to do so.\n\nWe‚Äôre also exploring more ways to make Claude a focused space to be at your most productive. Users can already connect third-party tools they use for work‚Äîlike Figma, Asana, and Canva‚Äîand interact with them directly within Claude. We expect to introduce many more useful integrations and expand this toolkit over time.\n\nAll third-party interactions will be grounded in the same overarching design principle: they should be initiated by the user (where the AI is working for them) rather than an advertiser (where the AI is working, at least in part, for someone else). Today, whether someone asks Claude to research running shoes, compare mortgage rates, or recommend a restaurant for a special occasion, Claude‚Äôs only incentive is to give a helpful answer. We‚Äôd like to preserve that.\n\nWe want our users to trust Claude to help them keep thinking‚Äîabout their work, their challenges, and their ideas.\n\nOur experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.\n\nWe think Claude should work the same way.",
    "readingTime": 6,
    "keywords": [
      "social media",
      "business model",
      "model‚Äôs responses",
      "genuinely helpful",
      "advertising incentives",
      "users",
      "conversations",
      "claude",
      "products",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://www.anthropic.com/news/claude-is-a-space-to-think",
    "thumbnail_url": "https://www.anthropic.com/api/opengraph-illustration?name=Hand%20House&backgroundColor=cactus",
    "created_at": "2026-02-04T12:35:32.091Z",
    "topic": "tech"
  },
  {
    "slug": "webhook-skills-agent-skills-for-webhook-providers-and-best-practices",
    "title": "Webhook Skills ‚Äì Agent skills for webhook providers and best practices",
    "description": "Webhook integration skills for AI coding agents (Claude Code, Cursor, Copilot). Step-by-step guidance for setting up webhook receivers, signature verification, and event handling for Stripe, Shopif...",
    "fullText": "hookdeck\n\n /\n\n webhook-skills\n\n Public\n\n Webhook integration skills for AI coding agents (Claude Code, Cursor, Copilot). Step-by-step guidance for setting up webhook receivers, signature verification, and event handling for Stripe, Shopify, GitHub, and more. Built on the Agent Skills specification.\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n hookdeck/webhook-skills",
    "readingTime": 1,
    "keywords": [
      "webhook",
      "skills",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/hookdeck/webhook-skills",
    "thumbnail_url": "https://opengraph.githubassets.com/ed9e4e830971c76b02864c100a37accbc7ef947718023c6abb2ba2536dad1e19/hookdeck/webhook-skills",
    "created_at": "2026-02-04T12:35:28.405Z",
    "topic": "tech"
  },
  {
    "slug": "nexus-gateway-a-selfhealing-ai-gateway-in-go-with-5ms-caching",
    "title": "Nexus Gateway ‚Äì A self-healing AI gateway in Go with 5ms caching",
    "description": "Infrastructure protocol for high-performance AI engineering.",
    "fullText": "Enterprise-grade inference routing, semantic caching, and unified model orchestration. Route to 200+ models across providers with a single API endpoint and sub-millisecond overhead.\n\nUse your existing API keys from OpenAI, Anthropic, or any provider. Zero vendor lock-in with complete key sovereignty.\n\nNative SDKs for Python, Node.js, Go, and Rust. Type-safe interfaces with streaming support and automatic retries.\n\nVector-based response caching with configurable similarity thresholds. Reduce costs by up to 70% on repeated queries.\n\nIntelligent request routing across 200+ models. Automatic failover, load balancing, and latency-optimized selection.",
    "readingTime": 1,
    "keywords": [
      "routing",
      "caching",
      "models",
      "across",
      "automatic"
    ],
    "qualityScore": 0.75,
    "link": "https://www.nexus-gateway.org/",
    "thumbnail_url": "https://nexus-gateway.org/LOGO.png",
    "created_at": "2026-02-04T12:35:28.232Z",
    "topic": "tech"
  },
  {
    "slug": "women-in-tech-and-finance-at-higher-risk-from-ai-job-losses-report-says",
    "title": "Women in tech and finance at higher risk from AI job losses, report says",
    "description": "‚ÄòMid-career‚Äô female workers also being sidelined by rigid hiring processes, says City of London Corporation\nWomen working in tech and financial services are at greater risk of losing their jobs to increased use of AI and automation than their male peers, according to a report that found experienced females were also being sidelined as a result of ‚Äúrigid hiring processes‚Äù.\n‚ÄúMid-career‚Äù women ‚Äì with at least five years‚Äô experience ‚Äì are being overlooked for digital roles in the tech and financial and professional services sectors, where they are traditionally underrepresented, according to the report by the City of London Corporation.\n Continue reading...",
    "fullText": "‚ÄòMid-career‚Äô female workers also being sidelined by rigid hiring processes, says City of London Corporation\n\nWomen working in tech and financial services are at greater risk of losing their jobs to increased use of AI and automation than their male peers, according to a report that found experienced females were also being sidelined as a result of ‚Äúrigid hiring processes‚Äù.\n\n‚ÄúMid-career‚Äù women ‚Äì with at least five years‚Äô experience ‚Äì are being overlooked for digital roles in the tech and financial and professional services sectors, where they are traditionally underrepresented, according to the report by the City of London Corporation.\n\nThe governing body that runs the capital‚Äôs Square Mile found female applicants were discriminated against by rigid, and sometimes automated, screening of their CVs, which did not take into account career gaps related to caring for children or relatives, or only narrowly considered their professional experience.\n\nTo reverse the trend, the corporation is calling on employers to focus on re-skilling female workers not currently in technical roles, particularly those in clerical positions most at risk of being displaced by automation.\n\nIt is estimated that about 119,000 clerical roles in tech and the financial and professional service sectors, predominantly carried out by women, will be displaced by automation over the next decade. Reskilling those affected by these job losses could save companies from making redundancy payments totalling as much as ¬£757m, the report found.\n\nUpskilling staff would allow employers to focus on candidates‚Äô potential rather than their past technical experience, the report found. It is estimated that up to 60,000 women in tech leave their roles each year for reasons including lack of advancement, lack of recognition and inadequate pay.\n\nDame Susan Langley, the mayor of City of London, said: ‚ÄúBy investing in people and supporting the development of digital skills within the workforce, employers can unlock enormous potential and build stronger, more resilient teams. Focusing on talent, adaptability and opportunity will ensure the UK continues to lead on innovation and remains a global hub for digital excellence.‚Äù\n\nRecent surveys have shown that as many as a quarter of UK workers are worried that their jobs could disappear in the next five years because of AI, according to a poll by the international recruitment company Randstad. Union leaders have called on companies to commit to investing in workforce skills and training.\n\nThe City of London Corporation found that women were being overlooked for roles even as difficulties in hiring talent meant more than 12,000 digital vacancies in these sectors went unfilled in 2024.\n\nCompanies have tried to deal with worker shortages by increasing wages above the national average, but the report found that higher pay rates would not solve the problem. It warned that the widening digital talent gap was forecast to last until at least 2035 and that under this scenario the UK could miss out on more than ¬£10bn of economic growth.",
    "readingTime": 3,
    "keywords": [
      "london corporation",
      "hiring processes",
      "female workers",
      "rigid hiring",
      "women",
      "digital",
      "roles",
      "tech",
      "financial",
      "automation"
    ],
    "qualityScore": 0.7,
    "link": "https://www.theguardian.com/business/2026/feb/04/women-tech-finance-higher-risk-ai-job-losses-report",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a0d2e166110bd4d6f898d4a39a693d5e1a2585e0/1172_0_6626_5304/master/6626.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6e15a2d2fe9c07da9ee53582be27c291",
    "created_at": "2026-02-04T12:35:24.602Z",
    "topic": "business"
  },
  {
    "slug": "pinterest-sacks-two-engineers-for-creating-software-to-identify-fired-workers",
    "title": "Pinterest sacks two engineers for creating software to identify fired workers",
    "description": "Digital pinboard business cutting 15% of workforce as it invests heavily in AI  \nPinterest has fired two engineers who created a software tool to identify which workers had lost their jobs in a recent round of cuts and then shared the information, according to reports.\nThe digital pinboard business announced significant job cuts earlier this month, with the chief executive, Bill Ready, telling staff he was ‚Äúdoubling down on an AI-forward approach‚Äù, according to a LinkedIn post by a former employee.\n Continue reading...",
    "fullText": "Digital pinboard business cutting 15% of workforce as it invests heavily in AI\n\nPinterest has fired two engineers who created a software tool to identify which workers had lost their jobs in a recent round of cuts and then shared the information, according to reports.\n\nThe digital pinboard business announced significant job cuts earlier this month, with the chief executive, Bill Ready, telling staff he was ‚Äúdoubling down on an AI-forward approach‚Äù, according to a LinkedIn post by a former employee.\n\nPinterest, which is based in San Francisco and has an office in London, said the cuts would affect about 15% of its workforce, or about 700 people, but did not specify which teams or staff members would be affected.\n\nTwo engineers at the company then wrote code to identify sacked staff.\n\nA spokesperson for Pinterest said: ‚ÄúTwo engineers wrote custom scripts improperly accessing confidential company information to identify the locations and names of all dismissed employees and then shared it more broadly. This was a clear violation of Pinterest policy and of their former colleagues‚Äô privacy.‚Äù\n\nIt is unclear whether the engineers, who have not been named, shared the information with colleagues, or with people outside Pinterest.\n\nThe script ‚Äì a set of commands written to automate a task within existing software or change its function ‚Äì was aimed at internal tools for workers to communicate, the BBC reported, citing an anonymous source.\n\nThe source, whom the BBC said was ‚Äúfamiliar with the firings‚Äù, said the code created an alert as to which employee names were being removed or deactivated.\n\nPinterest has been investing heavily in AI to create more personalised content for its users and automated tools for marketers. But shares in the company have dropped by more than 20% this year as investors assess the threat from more advanced AI platforms.\n\nReady said in a company-wide meeting that while ‚Äúhealthy debate and dissent are expected, that‚Äôs how we make our decisions‚Äù, according to CNBC, which first reported the news.\n\nThe chief executive said Pinterest was facing a ‚Äúcritical moment‚Äù and that staff should consider a job elsewhere if they were ‚Äúworking against the direction of the company‚Äù and disagreed with its mission, CNBC reported.\n\nIt comes amid a wave of job cuts in the techy sector, as businesses increasingly rely on AI. Last week, Amazon announced it would cut 16,000 roles worldwide, its second round of redundancies in three months.\n\nMeta, which owns Facebook, Instagram and WhatsApp, said it would cut more than 1,000 jobs from its Reality Labs division to redirect resources to AI wearables and phone features. Meanwhile, Autodesk, a design software maker, announced plans this month to cut about 1,000 jobs.",
    "readingTime": 3,
    "keywords": [
      "digital pinboard",
      "pinboard business",
      "chief executive",
      "job cuts",
      "engineers",
      "staff",
      "software",
      "identify",
      "jobs",
      "shared"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/feb/04/pinterest-sacks-two-engineers-for-software-identify-fired-workers",
    "thumbnail_url": "https://i.guim.co.uk/img/media/49ea7c63328503733d77be172d1df1f0005232f1/70_0_3262_2609/master/3262.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2be0eed2795df2410ecac05945591a45",
    "created_at": "2026-02-04T12:35:24.578Z",
    "topic": "tech"
  },
  {
    "slug": "jensen-huang-says-nvidia-would-love-to-back-an-openai-ipo-and-theres-no-drama-with-sam-altman",
    "title": "Jensen Huang says Nvidia would love to back an OpenAI IPO, and there's 'no drama' with Sam Altman",
    "description": "Jensen Huang said Nvidia would love to back a future OpenAI IPO and dismissed talk of tension with Sam Altman.",
    "fullText": "Jensen Huang says Nvidia would love to invest in a future OpenAI IPO.\n\nHuang said in an interview on CNBC's \"Mad Money\" on Tuesday that there was \"no drama\" between Nvidia and OpenAI CEO Sam Altman, pushing back against recent chatter of tension in the relationship between the two companies.\n\n\"The first deal is on,\" the Nvidia CEO said, referring to the company's September deal with OpenAI, under which the company said it planned to invest up to $100 billion in the AI startup.\n\n\"‚Äã‚ÄãAnd then there's, of course, an IPO in the future,\" he added. \"We love to be participating in that as well,\" he added.\n\nHuang also described OpenAI as a \"once in a generation company\" and said Nvidia is \"delighted to invest in it.\"\n\nHis comments come amid reports suggesting internal unease around the deal.\n\nThe Wall Street Journal reported on Saturday that the investment had sparked internal concerns at Nvidia, with some executives questioning the deal, according to people familiar with the matter.\n\nSeparately, Reuters reported on Tuesday that OpenAI had been unhappy with certain newer Nvidia chips and had looked at alternatives since last year, citing people familiar with the matter.\n\nHuang told reporters in Taipei on Saturday that speculation of any dissatisfaction with OpenAI was \"nonsense.\"\n\n\"We will invest a great deal of money, probably the largest investment we've ever made,\" he added.\n\nAltman has also pushed back on rumors of tension.\n\n\"We love working with NVIDIA and they make the best AI chips in the world,\" wrote Altman in a post on X on Tuesday.\n\n\"We hope to be a gigantic customer for a very long time. I don't get where all this insanity is coming from,\" he added.\n\nOpenAI is one of the world's most valuable private AI companies and a major customer for Nvidia's chips, which power the training and deployment of large language models.\n\nThe startup has not announced plans for an IPO, but its fundraising and computing needs have fueled speculation about how it will finance future growth.\n\n\"Big Short\" investor Michael Burry said in a Substack exchange in January that he was surprised that ChatGPT \"kicked off a multi-trillion-dollar infrastructure race.\"\n\n\"It's like someone built a prototype robot and every business in the world started investing for a robot future,\" he wrote.",
    "readingTime": 2,
    "keywords": [
      "deal",
      "invest",
      "love",
      "altman",
      "chips",
      "nvidia",
      "openai",
      "back",
      "tension",
      "startup"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/jensen-huang-nvidia-back-future-openai-ipo-sam-altman-drama-2026-2",
    "thumbnail_url": "https://i.insider.com/6982e47ca645d1188188a481?width=1200&format=jpeg",
    "created_at": "2026-02-04T12:35:23.970Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-senior-ux-researcher-at-microsoft-heres-how-i-broke-into-ai-without-a-tech-background-and-3-lessons-i-learned",
    "title": "I'm a senior UX researcher at Microsoft. Here's how I broke into AI without a tech background ‚Äî and 3 lessons I learned.",
    "description": "A Microsoft UX lead details her non-traditional path into AI, starting with studying architecture and highlighting lessons in AI accessibility.",
    "fullText": "This as-told-to essay is based on a conversation with Priyanka Kuvalekar, a 31-year-old UX research lead at Microsoft in Redmond, Washington. It's been edited for length and clarity.\n\nI joined Microsoft in April 2025 as a senior UX researcher. I lead research for Microsoft Teams Calling and related AI experiences.\n\nMy path to this job wasn't typical. I spent five years studying architecture in college, not computer science or AI, and earned my degree in India.\n\nI started my career with a full-time internship as a junior architect while completing the final year of my degree. After I graduated, I began thinking seriously about my next steps. Should I continue as an architect or pivot into the digital world?\n\nI enrolled in a three-month user experience course, which led me to pursue a master's degree in user experience and interaction design.\n\nI moved to Philadelphia and began my master's program in January 2018. My first industry step was an internship as a UX researcher at Korn Ferry. After a year of interning, I was offered a full-time role, which I held until 2021.\n\nI broke into Big Tech at Cisco in October 2021¬†and worked as a UX research lead¬†for over 3 1/2 years before taking my current position at Microsoft.\n\nI led projects focused on AI features for Webex meetings and messaging as the lead researcher.\n\nI knew I needed to understand AI's mechanics, so I pursued certifications and training, both through my employer and independently, on generative AI, agentic AI design patterns, large language models, and evaluating AI experiences as a researcher.\n\nI also explored courses and online resources on UI design from platforms such as Google Skills, Microsoft Training, and DeepLearning.AI to understand how generative AI could be applied to my projects.\n\nHere are the three biggest lessons I learned that helped me break into AI with a non-tech background.\n\nI learned that you need to understand how to evaluate AI in practice. AI isn't something you test once, and then it's \"done.\" It requires ongoing evaluation to ensure it continues to deliver trustworthy experiences.\n\nThis meant designing qualitative studies that examined how AI conversations hold up across diverse user groups. Inconsistencies in tone, misinterpretations of meaning, and pacing issues were revealed in this research.\n\nAnother key lesson came from approaching AI through an accessibility lens. AI can make tasks easier and reduce barriers for people with disabilities ‚Äî for example, by automating steps. It can also create new inequities if not designed with accessibility in mind.\n\nAccessibility and AI can't be separated. I've learned to include people with disabilities in AI research and to evaluate how AI integrates with assistive technologies such as screen readers and keyboard navigation.\n\nBreaking into AI also taught me that you don't have to build the technology yourself to make an impact, but you do need to understand it well enough to engage with it.\n\nIt's about learning just enough to bridge the gap between technical teams and user needs, and to ensure that how you gauge AI quality is rooted in real user experience.\n\nGaining fluency meant understanding the concepts behind how large language models work, their limitations, and how to design evaluation frameworks that account for those limits.\n\nThis has helped me ask engineers the right questions and design studies that measure trust, reliability, and consistency across different user groups. It's also helped me work closely with product managers to define what success looks like for AI experiences.\n\nI recommend starting where AI meets people, not where AI meets code ‚Äî focus on how AI shows up in products and how people experience it.\n\nOne of the most practical ways to add value without a traditional background is by shaping what \"quality\" means for an AI feature. Work with product managers to ask questions like, Does the AI stay within scope? Does it handle interruptions gracefully? Is it inclusive across languages and dialects?\n\nThese things often get overlooked when you view AI only as a technical system, but they're crucial to user trust. If you can frame them in actionable terms, you can become indispensable.\n\nHiring managers don't just want to see that you know AI exists ‚Äî they want to see how you can shape it responsibly and make it usable.\n\nDocument all frameworks, rubrics, evaluation studies, and examples of how your insights influenced decisions. Even if you don't have access to big-company projects, you can run your own small-scale studies on publicly available AI tools and use those to showcase your thinking.\n\nTry volunteering for projects where AI is being integrated into existing tools, and answer questions like, What does this AI feature need to do? How should it behave? Can the AI explain what it can or can't do? Does it recover gracefully when it makes a mistake?\n\nThese are the kinds of questions researchers, product thinkers, and others with non-traditional backgrounds are uniquely positioned to answer.",
    "readingTime": 5,
    "keywords": [
      "language models",
      "product managers",
      "user groups",
      "user experience",
      "research lead",
      "design",
      "researcher",
      "experiences",
      "projects",
      "understand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ux-researcher-landed-job-microsoft-without-tech-background-2026-2",
    "thumbnail_url": "https://i.insider.com/69824eafe1ba468a96ab4d81?width=737&format=jpeg",
    "created_at": "2026-02-04T12:35:23.858Z",
    "topic": "science"
  },
  {
    "slug": "3-big-things-to-look-out-for-in-googles-q4-earnings",
    "title": "3 big things to look out for in Google's Q4 earnings",
    "description": "Google's Q4 earnings focus on AI spending, Cloud gains, and a major Apple deal. Wall Street eyes search dominance amid AI competition.",
    "fullText": "Google has been on a monumental tear as of late. Can it keep the good times rolling?\n\nWhen Alphabet reports its fourth-quarter earnings on Wednesday, investors will focus on AI spending, cloud wins, and a big Apple deal.\n\nWith Meta projecting its capex for this year to nearly double that of 2025, how high will Google go? The company said in October that it expected capex for 2025 to land between $91 and $93 billion. Investors will track if it sticks to those goals. Google's finance chief, Anat Ashkenazi, also said the company expected a \"significant\" increase in that number for 2026 and promised we'd hear more on Google's Q4 call this week.\n\nAs my colleague Joe Ciolli has observed this earnings season, investors are more willing to forgive big capital spending on AI as long as fundamentals remain chugging along.\n\nThat leads to the question of how Google's search advertising business, its core engine, is doing. Are OpenAI and other AI rivals chipping away at its dominance, or is Alphabet's money-printing machine whirring as proudly as ever?\n\nAnalysts at Bernstein appeared optimistic in a note this week, writing that they expect Google to have seen an increase in query volume in Q4.\n\n\"For Tinuiti's advertisers, Google's US paid click growth was the highest it has been since early 2021,\" Bernstein analysts wrote, referring to the US marketing agency.\n\nGoogle's cloud business has also become top billing, as it furiously competes with Amazon and Microsoft to build infrastructure and win crucial AI deals. In Q3, Google said the number of new cloud customers increased by about 34% year over year.\n\nBernstein analysts predicted big business for cloud off the back of AI sales, its big Anthropic deal, and the ramp-up of its AI chip business, known as Tensor Processing Units (TPUs).\n\n\"We also note that the new deal between Anthropic and Google for 'tens of billions of dollars' worth of compute represents upside to Google Cloud growth, regardless of whether the money flows through Cloud deals or outright TPU sales,\" they wrote.\n\nSpeaking of deals, this marks the first earnings report since Google and Apple announced that the iPhone giant will use Google's Gemini AI models for its revamped Siri assistant.\n\nThere are still a lot of unanswered questions there. How much does Google get out of the deal? Can Google use query data to train Gemini? Will Apple use Google's data centers and TPU chips?\n\nHopefully, we'll get a clearer picture of the inner workings of that deal on Wednesday's earnings call.",
    "readingTime": 3,
    "keywords": [
      "bernstein analysts",
      "deal",
      "earnings",
      "business",
      "investors",
      "deals",
      "google",
      "google's",
      "capex",
      "increase"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-q4-2025-earnings-big-things-alphabet-2026-2",
    "thumbnail_url": "https://i.insider.com/69825425e1ba468a96ab4f12?width=1200&format=jpeg",
    "created_at": "2026-02-04T12:35:23.857Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-googler-who-pivoted-from-finance-to-ai-it-took-me-years-but-i-dont-regret-taking-the-long-path",
    "title": "I'm a Googler who pivoted from finance to AI. It took me years, but I don't regret taking the long path.",
    "description": "A senior software engineer at Google took 40 Coursera courses and got multiple grad degrees to shift from business to AI.",
    "fullText": "This as-told-to essay is based on a conversation with Max Buckley, a 38-year-old senior software engineer at Google, based in Zurich, Switzerland. His identity and employment has been verified by Business Insider. The following has been edited for length and clarity.\n\nI'm a senior software engineer at Google in Zurich, where I've worked since 2013.\n\nMost people don't go from business to a more technical background, but my bachelor's degree was in business studies, and I joined Google out of undergrad as a financial analyst intern.\n\nOver several years, I pivoted from financial analysis to business analysis, then to trust and safety, and onto an engineering team in 2016. I joined several other software engineering teams, and then eventually joined Google Cloud AI, where I worked on one of the cloud AI products for a few years.\n\nThen I joined an internal LLM innovation team within Google's core infrastructure group, which we later turned into an LLM information retrieval applied research team, where I am today, leading the team.\n\nTo make multiple shifts like this, you need to upskill and explore other areas. Here's how I did it:\n\nAs soon as I joined Google, I decided my North Star was to become a data scientist. Initially, I had a lot of success broadening my skillset with online courses like Coursera, edX, or Stanford. I used them to explore finance, then statistics, then spent most of my time in the computer science and data science space.\n\nAll in all, I completed roughly 40 online open courses, most of them through Coursera.\n\nSome of the courses I took include:\n\nThe courses were spread out from 2013 to 2021, and I took them on evenings and weekends. I didn't have much time for video games, but I still made time to go to the gym, eat, sleep, and spend time with my girlfriend.\n\nI wasn't super structured in my approach to taking courses. I didn't say \"I must do five hours a day,\" or anything like that. I took them as I felt the need to do one or to learn more about a particular topic. I didn't burn out from it.\n\nThe most measurably impactful courses I completed were the first two Coursera courses: Data Analysis and Computing for Data Analysis. I did them right before I interviewed for my internship at Google and the interviewer happened to have done the same course, so we had this instant rapport.\n\nI also did more formal part-time study.\n\nI finished my Bachelor of Business Studies in 2013. Then at Google, I got a part-time postgraduate certificate in statistics, which took a year. Then I did a part-time master's degree in Business Analytics, which took two years. Then I pursued a part-time master's degree in software engineering, which took close to five years. Most recently, I did a diploma in Advanced Studies In Data Science, which took another two years.\n\nI did a bunch of summer school certificates, which is when you spend a week doing PhD-level courses.\n\nMy message to others who want to transition is don't be discouraged. When I first wanted to join Google, several hiring managers weren't interested because I didn't have a computer science undergraduate degree. Similarly, when I applied for a Master's in Business Analytics, I was initially declined¬†because I didn't have a technical undergraduate degree and two semesters of programming experience, even though I was programming at Google. There were hurdles that I had to work around.\n\nI always wanted to study computer science, but my dad told me it's better to learn something different because I'll probably end up in it anyway. In hindsight, he was right.\n\nStudying computer science would have certainly expedited my career track, but I'm in a place where it's no longer a hindrance, and I'm familiar with a bunch of business theories, like Porter's Five Forces. They're not always useful, but every once in a while, it comes up in conversation.\n\nThe constant here is that my background includes continuous learning. When recruiters or hiring managers see my profile, they see that I'm not someone who gets complacent.\n\nDid you make a career pivot? We want to hear from you. Reach out to the reporter via email at aaltchek@insider.com or through the secure-messaging app Signal at aalt.19.",
    "readingTime": 4,
    "keywords": [
      "business studies",
      "hiring managers",
      "joined google",
      "senior software",
      "software engineer",
      "undergraduate degree",
      "software engineering",
      "computer science",
      "part-time master's",
      "business analytics"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/googler-shares-years-long-journey-pivot-finance-to-ai-2026-2",
    "thumbnail_url": "https://i.insider.com/69822c85a645d11881888ff3?width=1200&format=jpeg",
    "created_at": "2026-02-04T12:35:23.720Z",
    "topic": "finance"
  },
  {
    "slug": "cognizant-forecasts-annual-revenue-above-estimates-on-strong-ai-demand",
    "title": "Cognizant forecasts annual revenue above estimates on strong AI demand",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/cognizant-forecasts-annual-revenue-above-estimates-4484276",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM130P9_L.jpg",
    "created_at": "2026-02-04T12:35:22.464Z",
    "topic": "finance"
  },
  {
    "slug": "ai-fears-drag-asia-software-stocks-lower-after-us-tech-rout",
    "title": "AI Fears Drag Asia Software Stocks Lower After US Tech Rout",
    "description": "Asian software stocks slid, extending a global selloff as investors fret that rapid advances in artificial intelligence could upend traditional business models.",
    "fullText": "MarketsBy Winnie Hsu, Carmeli Argana, and Ashutosh JoshiSaveAsian software stocks slid, extending a global selloff as investors fret that rapid advances in artificial intelligence could upend traditional business models.Shares of Indian information technology companies were the latest to buckle. Bellwether Tata Consultancy Services Ltd. sank as much as 6% at the open, while Infosys Ltd. dropped 6.2%, tracking a slump in its US-listed shares overnight.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2026-02-04/ai-disruption-concerns-sink-software-makers-stocks-in-asia",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iJdO.cS0Gspg/v0/1200x800.jpg",
    "created_at": "2026-02-04T06:38:05.995Z",
    "topic": "finance"
  },
  {
    "slug": "video2docs-turn-screen-recordings-into-stepbystep-instructions",
    "title": "Video2docs ‚Äì Turn Screen Recordings into Step-by-Step Instructions",
    "description": "Transform app walkthrough videos into beautiful, structured documentation using AI. Works without audio narration.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://video2docs.com/",
    "thumbnail_url": "https://video2docs.com/assets/og_image.png",
    "created_at": "2026-02-04T06:38:01.672Z",
    "topic": "tech"
  },
  {
    "slug": "we-added-toon-compression-to-our-llm-gateway-compress-prompts-saves-tokens",
    "title": "We added TOON compression to our LLM gateway ‚Äì compress prompts, saves tokens",
    "description": "üéí Token-Oriented Object Notation (TOON) ‚Äì Compact, human-readable, schema-aware JSON for LLM prompts. Spec, benchmarks, TypeScript SDK. - toon-format/toon",
    "fullText": "toon-format\n\n /\n\n toon\n\n Public\n\n üéí Token-Oriented Object Notation (TOON) ‚Äì Compact, human-readable, schema-aware JSON for LLM prompts. Spec, benchmarks, TypeScript SDK.\n\n toonformat.dev\n\n License\n\n MIT license\n\n 22.4k\n stars\n\n 988\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n toon-format/toon",
    "readingTime": 1,
    "keywords": [
      "toon",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/toon-format/toon",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1081397957/a1727f6d-0f41-4022-aba0-225fbef55509",
    "created_at": "2026-02-04T06:38:01.438Z",
    "topic": "tech"
  },
  {
    "slug": "if-you-tell-ai-not-to-do-something-its-more-likely-to-do-it",
    "title": "If you tell AI not to do something, it's more likely to do it",
    "description": "Telling ChatGPT not to do something can make it actively suggest doing it, with some models even willing to endorse theft or deception when the prompt includes the forbidden act. ¬† Like me, you may have come across a strange phenomenon with Large Language Models (LLMs) whereby they don't just ignore a specific instruction you...",
    "fullText": "Telling ChatGPT not to do something can make it actively suggest doing it, with some models even willing to endorse theft or deception when the prompt includes the forbidden act.\n\nLike me, you may have come across a strange phenomenon with Large Language Models (LLMs) whereby they don‚Äôt just ignore a specific instruction you gave, which included a prohibition (i.e., ‚ÄòDon‚Äôt do [something]‚Äô), but seem to go out of their way to immediately enact the very thing you just told them not to enact ‚Äì even if doing so is ‚Äòout of character‚Äô for the model.\n\nThis is a known feature even of older NLP models; and a growing strand of research regarding LLMs‚Äô negation capabilities has emerged in recent years.\n\nThough it can be challenging for people to chase down the buried meaning in a complex double-negative*, LLMs have an added disadvantage, illustrated in the below example of ChatGPT‚Äôs monotonicity reasoning, from a 2023 paper:\n\nThough the internal workings of a closed model such as ChatGPT are opaque, the second answer appears to be repurposing the logic used to generate the first answer; however, that logic is not applicable in the second case, because the man may own an animal other than a dog‚Ä†.\n\nHere, therefore, the outcome of the second inquiry appears to have been affected by the context of the solution obtained for the first.\n\nLikewise, by suggesting the existence of a prohibited act, that banned act can often be put into action by an LLM, which acknowledges and processes the act, but not the negation.\n\nThis is a severe restriction on the utility of LLMs, because in domains where language models may be used for critical applications, such as medicine, finance, or security, it is clearly important that they correctly interpret orders that contain prohibitions.\n\nThis problem is highlighted in a new paper from the US, which examines the extent to which commercial models (such as ChatGPT) and open-source models (such as LLaMA) are unable to follow negative instructions.\n\nThe researchers tested 16 models over 14 ethical scenarios, and concluded that open-source models endorse (i.e., encourage, enact, enable) specifically banned instructions 77% of the time under simple negation (‚ÄòDon‚Äôt do this), and 100% of the time under complex negation (‚ÄòDon‚Äôt do this if it leads to that‚Äô).\n\nWhile commercial models fared better, only Gemini-3-Flash achieved the top rating in a new Negation Sensitivity Index (NSI) scale proposed by the paper (though Grok 4.1 ran a close second).\n\nUnder the new benchmark, all the models tested would be banned from making decisions in the domains medical, financial, legal, military, business, education, and science ‚Äì effectively rendering them unusable in such contexts.¬†Though reasoning models generally performed better, even these slower approaches failed under queries with compound negation.\n\nGiven the longstanding association between computing and reliable Boolean operators such as OR and NOT, users who view binary consistency as a baseline expectation may be particularly exposed to failures of this kind.\n\nCommenting on the difficulty that open-source LLMs have in parsing negated queries, the authors state:\n\n‚ÄòCommercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones [‚Ä¶]\n\n‚ÄòThe findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish ‚Äúdo X‚Äù from ‚Äúdo not X‚Äù should not be making autonomous decisions in high-stakes contexts.‚Äô\n\nThe paper notes that failures of this kind are more likely to impact vulnerable individuals across the studied domains:\n\n‚ÄòDomain adjustment is not merely technical calibration. Rather, it has equity implications.\n\n‚ÄòFinancial fragility means that economically vulnerable populations, for example those seeking loans, benefits, or credit, face higher exposure to negation errors than those seeking medical information.‚Äô\n\nFurther, the authors emphasize that the problem cannot be resolved through traditional alignment-based approaches, since the issue involves a deep-rooted failure of intent parsing in LLMs, rather than a corporate requirement to restrict what they say, or how they interpret a prompt:\n\n‚ÄòA model can be ‚Äúaligned‚Äù in the sense of refusing harmful keywords while failing to process the structure of requests. True alignment requires not just learning what to value but correctly parsing the linguistic expressions of those values.\n\n‚ÄòUntil that capability is reliable, ‚Äúdo not‚Äù should mean ‚Äúdo not.‚Äù‚Äò\n\nInterestingly, though Gemini Flash was the sole ‚Äòwinner‚Äô in the authors‚Äô own novel benchmark, the current crop of Chinese LLMs generally proved to be far less susceptible to the problem.\n\nThe new paper is titled When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models, and comes from two researchers at Kenyon College in Ohio.\n\nThe 14 ethical scenarios developed by the researchers to test the LLMs were:\n\nContents in the ‚ÄòACTION AT STAKE‚Äô column above are not intended as ethically ‚Äòcorrect answers‚Äô, but as the only available do / don‚Äôt do actions for each scenario; here the LLMs are not being challenged on their ethical standards, but rather on their ability to parse complex queries and prohibitions in critical situations.\n\nTherefore the severity of these scenarios is only illustrative, on the part of the authors; the LLMs could as effectively have been interrogated on much less severe topics.\n\nThe US commercial models tested for the work were GPT-5.1; GPT-5.2; GPT-5-mini; Claude-Haiku-4.5; Claude-Sonnet-4.5; Gemini-3-Flash; Grok-4.1-non-reasoning; and Grok-4.1-reasoning.\n\nThe Chinese commercial models tested were DeepSeek-V3; GLM-4; Kimi-K2; and Qwen3.\n\nThe open-source models used were LLaMA-3.2-1B; Gemma-3-4B; Granite-3.3-2B; and Phi-4-mini-3.8B.\n\nPrompts for each of the 14 scenarios were written in four versions: F0 stated that the action should be done; F1, that it should not; F2 supported pursuing a goal even if it required the (prohibited) action; and F3 rejected the goal if it required the (prohibited) action:\n\n‚ÄòUnder F0, models are asked whether he ‚Äúshould rob the store.‚Äù Under F1, whether he ‚Äúshould not rob the store.‚Äù Under F2, whether he should ‚Äúsave his daughter even if it means he must rob the store.‚Äù\n\n‚ÄòUnder F3, whether he should ‚Äúnot save his daughter if it means he must rob the store.‚Äù The admissible facts remain constant, and only polarity varies.‚Äô\n\nThe approach argues that if a model understands how negation works, its answers should ‚Äòflip cleanly‚Äô between positive and negative versions of the same prompt. Therefore, if 60% of responses agree that ‚Äòthey should do X‚Äô (F0), then only 40% should agree that ‚Äòthey should not do X‚Äô (F1) ‚Äì since rejecting F1 also means supporting the action; and when the numbers don‚Äôt match up in this way, the model is misreading negation.\n\nThe authors used Cochran‚Äôs Q test and the Kruskal-Wallis H-test to measure how much framing (variation in prompt polarity while preserving meaning) affected model responses, both within and across categories.¬†After adjusting for false positives, the authors found that in 61.9% of cases, the model‚Äôs answer changed significantly depending only on how the prompt was phrased ‚Äì even when the core meaning stayed the same.\n\nThey also tested whether reducing randomness (‚Äòtemperature‚Äô) made models less fragile‚Ä†‚Ä†:\n\nUnder simple affirmative prompts (F0), models from all three categories gave moderate support for the proposed actions, with endorsement rates between 24% and 37%. This was expected, given that the scenarios were designed as moral dilemmas without obvious right answers. However, the authors note that the balance broke down under negation:\n\n‚ÄòOpen-source models jump from 24% endorsement under F0 to 77% under F1. When told ‚Äúshould not do X,‚Äù they endorse doing X more than three times out of four. Under compound negation (F3), they reach 100% endorsement, a ceiling effect indicating complete failure to process the negation operator.‚Äô\n\nOpen-source models showed the most extreme framing effects, with endorsement rates jumping 317% from F0 to F3 ‚Äì a sign that their outputs are highly sensitive to how a question is phrased. US commercial models also showed large swings, with endorsement rates more than doubling when prompts were reworded from F0 to F3.\n\nChinese commercial models were more stable overall, with only a 19% increase from F0 to F3, compared to jumps of over 100% in other groups. More importantly, they were the only models to reduce their endorsement when a prompt was negated, suggesting they understood that saying ‚Äòshould not‚Äô means the opposite of ‚Äòshould‚Äô:\n\nModels agreed with each other 74% of the time when prompts used affirmative wording, but only 62% when the same ideas were expressed with negation ‚Äì a12-point drop suggesting that models are not trained to handle negation in a consistent way:\n\nTo measure how easily a model‚Äôs judgment can be flipped by rephrasing a prompt with negation, the authors developed the aforementioned Negation Sensitivity Index (NSI) ‚Äì a metric designed to quantify whether a model gives opposite answers to questions that are logically equivalent, but framed using negation.\n\nA high NSI score indicates that a model frequently reverses its position when a prompt is negated, revealing a reliance on superficial wording rather than consistent reasoning.\n\nThe NSI benchmark was created by generating pairs of prompts (one original, one with a logical negation), and observing whether the model produced semantically opposite responses. By comparing answers across a large set of such pairs, the authors defined NSI as the proportion of valid negation pairs where the model flipped its output.\n\nThe NSI benchmark was used in tests to evaluate domain sensitivity in negation (i.e., whether the context category ‚Äòfinancial‚Äô or ‚Äòmilitary‚Äô, etc., affected the outcome), achieving some interesting contrasts. Here, some types of decisions proved much more sensitive to wording changes than others.\n\nFor instance, business and finance prompts triggered high fragility, with models flipping answers when a question was rephrased or negated, scoring around 0.64 to 0.65 on the NSI scale. Medical prompts were more stable, averaging just 0.34:\n\nNoting that the medical domain produced the fewest errors and financial the highest, the authors hypothesize:\n\n‚ÄòWhy might this gap exist? It is possible that medical decisions may benefit from clearer training signal. Hippocratic principles, established protocols, and extensive professional literature may anchor model behavior even under framing variation.\n\n‚ÄòFinancial decisions, on the other hand, involve murkier tradeoffs with less social consensus, leaving models more susceptible to surface cues.‚Äô\n\nThe problem was most severe in open-source models, which reached NSI scores above 0.89 in finance, business, and military prompts. Commercial systems were less fragile but still showed high sensitivity, scoring between 0.20 and 0.75 depending on the domain:\n\nAs mentioned earlier, the authors note that the heightened fragility of open-source models in this area may carry disproportionate risks for vulnerable or marginalized groups, who are more likely to be served by locally deployed systems chosen for budgetary reasons in municipal or governmental settings‚Ä†‚Ä†‚Ä†:\n\n‚ÄòIf an institution deploys an open-source model for cost reasons, the burden falls disproportionately on populations already navigating precarious financial circumstances. Buolamwini and Gebru documented how accuracy disparities in facial recognition fell along demographic lines.\n\n‚ÄòOur findings suggest a parallel disparity along domain lines, with economically vulnerable populations bearing greater risk.‚Äô\n\nThough we do not have scope here to cover the entirety of the paper‚Äôs results, and its closing case studies, it is noteworthy that the case studies demonstrate a proclivity for negation-blind model responses to end up recommending extremely non-advisable courses of action, simply because they misinterpreted the negation construction:\n\n‚ÄòUnder F0, open-source models endorse robbery 52% of the time, a defensible split given the scenario‚Äôs moral complexity. Under F1 (‚Äúshould NOT rob‚Äù), they endorse it 100%. The negated prohibition produces unanimous endorsement of the prohibited action.\n\n‚ÄòCommercial models show a more mixed pattern, with aggregate endorsement rising from 33% to 70% under simple negation. Some commercial systems show near-inversion, while others show modest increases.\n\n‚ÄòSignificantly, no category achieves the mirror-image reversal that correct negation processing would produce.‚Äô\n\nThis is one of the most interesting papers I have come across in a while, and I recommend the reader to investigate further, as there is not space here to cover all of the material presented by the authors\n\nPerhaps the most interesting thing about the study is how frequently a user of LLMs comes across this problem, and gradually learns not to ‚Äòput unwanted thoughts‚Äô in their LLMs‚Äô cogitative processes, often attempting to exclude certain undesired results by alternative means than in-prompt negation ‚Äì such as user-level system prompts, long-term memory storage, or repetitive in-prompt templates that retain the objective.\n\nIn practice, none of these methods is terribly effective, while the black-box nature of Gemini Flash ‚Äì here the best-performing LLM ‚Äì makes it hard to glean remedies from the obtained test results.\n\nPerhaps greater clues to the underlying architectural problem lies in studying why Chinese models, though none approach the heights of the leaderboard, generally perform so much better in this single, thorny aspect.\n\n* A form which is actually baked into several romance languages, including Italian.\n\n‚Ä† Even ChatGPT-4o does not make this mistake any longer.\n\n‚Ä†‚Ä† The source paper contains a few misattributions of tables and figures. At one point the text indicates that table 1 (which is just a list of LLMs used in tests) contains the core results. In these cases I have had to guess what the correct figures or tables are, and I stand to be corrected by the authors.\n\n‚Ä†‚Ä†‚Ä† My substitution of hyperlinks for the authors‚Äô inline citations.\n\nFirst published Tuesday, February 3, 2026\n\nWriter on machine learning, domain specialist in human image synthesis. Former head of research content at Metaphysic.ai.\n\nPersonal site: martinanderson.ai\n\nContact: [email¬†protected]\n\nTwitter: @manders_ai",
    "readingTime": 12,
    "keywords": [
      "sensitivity index",
      "index nsi",
      "nsi scale",
      "nsi benchmark",
      "chinese commercial",
      "framing variation",
      "economically vulnerable",
      "negation sensitivity",
      "vulnerable populations",
      "less fragile"
    ],
    "qualityScore": 1,
    "link": "https://www.unite.ai/if-you-tell-ai-not-to-do-something-its-more-likely-to-do-it/",
    "thumbnail_url": "https://www.unite.ai/wp-content/uploads/2026/02/robot-prohibition-MAIN.jpg",
    "created_at": "2026-02-04T06:38:00.869Z",
    "topic": "tech"
  },
  {
    "slug": "embedded-vector-and-graph-database-in-pure-go",
    "title": "Embedded Vector and Graph Database in Pure Go",
    "description": "SQLite for Vectors - Simple, fast, embeddable vector storage for Go LLM applications. - liliang-cn/sqvect",
    "fullText": "liliang-cn\n\n /\n\n sqvect\n\n Public\n\n SQLite for Vectors - Simple, fast, embeddable vector storage for Go LLM applications.\n\n liliang-cn.github.io/sqvect/\n\n License\n\n MIT license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n liliang-cn/sqvect",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/liliang-cn/sqvect",
    "thumbnail_url": "https://opengraph.githubassets.com/04a662363da77549dca7df68595a9813a8943cc6dea68042bdc44327d8e4ab55/liliang-cn/sqvect",
    "created_at": "2026-02-04T06:38:00.475Z",
    "topic": "tech"
  },
  {
    "slug": "acer-chromebook-plus-515-review-powerful-but-limited-by-clunky-software",
    "title": "Acer Chromebook Plus 515 review: Powerful but limited by clunky software",
    "description": "The Chromebook Plus 515 is one of Google's first new AI-enhanced laptops. It performs great for its price, but ChromeOS still has key limitations.",
    "fullText": "The Acer Chromebook Plus 515 is one of the first Chromebook Plus models. It features a powerful Intel processor, an HD webcam, and onboard AI tools.\n\n Check price at Best Buy",
    "readingTime": 1,
    "keywords": [
      "chromebook",
      "plus"
    ],
    "qualityScore": 0.3,
    "link": "https://www.businessinsider.com/guides/tech/acer-chromebook-plus-515-review",
    "thumbnail_url": "https://i.insider.com/657c8de87a3c8094d5dd92bc?width=1200&format=jpeg",
    "created_at": "2026-02-04T06:37:54.803Z",
    "topic": "tech"
  },
  {
    "slug": "openai-just-snagged-an-anthropic-safety-researcher-for-its-highprofile-head-of-preparedness-role",
    "title": "OpenAI just snagged an Anthropic safety researcher for its high-profile head of preparedness role",
    "description": "OpenAI hired an Anthropic safety researcher as its head of preparedness, which pays up to $555,000 plus equity.",
    "fullText": "OpenAI has filled a key safety role by hiring from a rival lab.\n\nThe company has brought on Dylan Scand, a former AI safety researcher at Anthropic, as its new head of preparedness, a role that carries a salary of up to $555,000 plus equity. The role caught attention last month thanks to its eye-catching pay package amid OpenAI's rising AI safety concerns.\n\nSam Altman announced the move in a post on X on Wednesday, saying that he is \"extremely excited\" to welcome Scand to OpenAI.\n\n\"Things are about to move quite fast and we will be working with extremely powerful models soon,\" Altman wrote.\n\n\"Dylan will lead our efforts to prepare for and mitigate these severe risks. He is by far the best candidate I have met, anywhere, for this role,\" he added.\n\nScand said in a post on X on Wednesday about his move that he's \"deeply grateful for my time at Anthropic and the extraordinary people I worked alongside.\"\n\n\"AI is advancing rapidly. The potential benefits are great ‚Äî and so are the risks of extreme and even irrecoverable harm,\" he added.\n\nLast month, Altman described the job as \"stressful.\"\n\n\"You'll jump into the deep end almost immediately,\" he wrote on X.\n\nIn the job posting, OpenAI said the role is best suited for someone who can lead technical teams, make high-stakes calls under uncertainty, and align competing stakeholders around safety decisions. The company also said candidates should have deep expertise in machine learning, AI safety, and related risk areas.\n\nTensions have arisen over OpenAI's approach to safety. Several early employees ‚Äî including a former head of its safety team ‚Äî have left the company in recent years.\n\nOpenAI has also faced lawsuits from users who allege its tools contributed to harmful behavior.\n\nIn October, the company said that some ChatGPT users had shown possible signs of mental health distress. An estimated 560,000 users a week show \"possible signs of mental health emergencies,\" it said.\n\nThe company also said it was consulting mental health specialists to refine how the chatbot responds when users show signs of psychological distress or unhealthy dependence.",
    "readingTime": 2,
    "keywords": [
      "mental health",
      "safety",
      "role",
      "users",
      "signs",
      "anthropic",
      "openai's",
      "extremely",
      "lead",
      "risks"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-anthropic-safety-researcher-head-of-preparedness-dylan-scand-2026-2",
    "thumbnail_url": "https://i.insider.com/6982bb18a645d1188188a382?width=1200&format=jpeg",
    "created_at": "2026-02-04T06:37:54.722Z",
    "topic": "science"
  },
  {
    "slug": "get-me-out-traders-dump-software-stocks-as-ai-fears-erupt",
    "title": "‚ÄòGet Me Out‚Äô: Traders Dump Software Stocks as AI Fears Erupt",
    "description": "Wall Street has been skeptical about software stocks for a while, but sentiment has gone from bearish to doomsday lately with traders dumping shares of companies across the industry as fears about the destruction to be wrought by artificial intelligence pile up.",
    "fullText": "MarketsBy Ryan VlastelicaSaveWall Street has been skeptical about software stocks for a while, but sentiment has gone from bearish to doomsday lately with traders dumping shares of companies across the industry as fears about the destruction to be wrought by artificial intelligence pile up.‚ÄúWe call it the ‚ÄòSaaSpocalypse,‚Äô an apocalypse for software-as-a-service stocks,‚Äù said Jeffrey Favuzza, who works on the equity trading desk at Jefferies. ‚ÄúTrading is very much ‚Äòget me out‚Äô style selling.‚Äù",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "trading"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2026-02-03/-get-me-out-traders-dump-software-stocks-as-ai-fears-take-hold",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6scu71VJPgE/v1/1200x800.jpg",
    "created_at": "2026-02-04T01:07:07.895Z",
    "topic": "finance"
  },
  {
    "slug": "uk-looks-at-subsidizing-small-modular-reactors-to-power-ai-boom",
    "title": "UK Looks at Subsidizing Small Modular Reactors to Power AI Boom",
    "description": "The UK is laying out plans to help the development of small nuclear reactors as it seeks to power a boom in artificial intelligence.",
    "fullText": "MarketsBy Jess ShanklemanSaveThe UK is laying out plans to help the development of small nuclear reactors as it seeks to power a boom in artificial intelligence.The Department for Energy Security and Net Zero will on Wednesday announce a package of measures designed to make it easier for developers of small modular reactors to get financing.",
    "readingTime": 1,
    "keywords": [
      "reactors"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2026-02-04/uk-looks-at-subsidizing-small-modular-reactors-to-power-ai-boom",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ixfWqdAWZR8w/v0/1200x800.jpg",
    "created_at": "2026-02-04T01:06:59.121Z",
    "topic": "finance"
  },
  {
    "slug": "vibe-coding-is-the-new-rad",
    "title": "Vibe Coding is the new RAD",
    "description": "In my opinion, software engineers should view Vibe Coding with AI as simply the latest iteration of RAD.",
    "fullText": "In my opinion, software engineers should view Vibe Coding with AI as simply the latest iteration of RAD.\n\nFile details: 6.9 MB MP3, 5 mins 12 secs duration.\n\nTitle music is \"Apparent Solution\" by Brendon Moeller, licensed via www.epidemicsound.com\n\nFive.Today is a highly-secure personal productivity application designed to help you to manage your priorities more effectively, by focusing on your five most important tasks you need to achieve each day.\n\n Our goal is to help you to keep track of all your tasks, notes and journals in one beautifully simple place, which is highly secure via end-to-end encryption. Visit the URL Five.Today to",
    "readingTime": 1,
    "keywords": [
      "tasks",
      "five.today"
    ],
    "qualityScore": 0.65,
    "link": "https://techleader.pro/a/723-Vibe-Coding-is-the-new-RAD-(TLP-2026w3)",
    "thumbnail_url": "https://techleader.pro/img/icons/noun_programmer_2644331.png",
    "created_at": "2026-02-04T01:06:56.822Z",
    "topic": "tech"
  },
  {
    "slug": "wplace-for-ai-agents",
    "title": "Wplace for AI Agents",
    "description": "A shared pixel canvas where autonomous AI agents collaborate, compete, and create art together.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://molt.place",
    "thumbnail_url": "https://molt.place/og-image.png",
    "created_at": "2026-02-04T01:06:56.759Z",
    "topic": "tech"
  },
  {
    "slug": "anthropic-plans-employee-tender-offer-at-350b-valuation",
    "title": "Anthropic Plans Employee Tender Offer at $350B Valuation",
    "description": "Anthropic is working on a deal to let some employees sell shares in the company at a valuation of at least $350 billion, according to a person familiar with the matter, a plan that is coming together at the same time as a funding round that could bring in more than $20 billion.",
    "fullText": "MarketsBy Natasha Mascarenhas and Shirin GhaffarySaveAnthropic is working on a deal to let some employees sell shares in the company at a valuation of at least $350 billion, according to a person familiar with the matter, a plan that is coming together at the same time as a funding round that could bring in more than $20 billion.The tender offer would allow Anthropic staffers to cash out some equity in one of the world‚Äôs most richly valued artificial intelligence startups. The $350 billion valuation is the same one being discussed in the company‚Äôs ongoing fundraising, the person said, and is pre-money, meaning it does not include dollars being raised.",
    "readingTime": 1,
    "keywords": [
      "valuation"
    ],
    "qualityScore": 0.15,
    "link": "https://www.bloomberg.com/news/articles/2026-02-04/anthropic-plans-employee-tender-offer-at-350-billion-valuation",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iNdYg0rZ7raQ/v0/1200x800.jpg",
    "created_at": "2026-02-04T01:06:41.256Z",
    "topic": "tech"
  },
  {
    "slug": "disneys-new-ceo-has-a-winning-combination-a-friendly-face-and-an-eye-for-profit",
    "title": "Disney's new CEO has a winning combination: a friendly face and an eye for profit",
    "description": "Disney's decision to tap Josh D'Amaro signals that the company wanted to go with a familiar, friendly face to push ahead into the AI era.",
    "fullText": "After a decade of ups and downs, Disney is picking a familiar, friendly face at the heart of its profit engine to lead the company into a new era.\n\nDisney's board just tapped Parks boss Josh D'Amaro to take over for longtime CEO Bob Iger, starting on March 18. Iger, who plans to retire as CEO for the second time, will remain in an advisor role before stepping aside for good later this year.\n\nAfter a decade marked by strategic changes and a failed succession, Disney is turning to the guy who runs its most reliable moneymaker to navigate a period of massive change in the entertainment industry.\n\nDisney's new CEO has his work cut out for him. The Mouse House's stock has only mustered an 11% gain in the last decade, compared to a more than threefold increase for the S&P 500. And while Disney's parks are gushing cash, the streaming business isn't yet making enough money to offset the steady erosion of the company's ever-fading cable networks.\n\nHowever, D'Amaro appears as well-positioned as any possible Iger successor to lead Disney into the next decade.\n\nNot only is D'Amaro intimately familiar with the company's most lucrative business, but he also seems to have the charm and leadership acumen needed to lead a juggernaut like Disney. That's in contrast to former CEO Bob Chapek, who took over after Iger's first retirement and was known as a gruff, business-minded executive who lacked Iger's high level of charisma.\n\nYet D'Amaro isn't just a likable face. Here are three points about Disney's choice of D'Amaro and what his leadership could mean for the company.\n\nWhile it's still too early to say how D'Amaro might run things, the board's decision to go with a company insider, who happened to be the consensus pick, signals a preference for stability, analysts and leadership experts told Business Insider.\n\nD'Amaro ‚Äî who turns 55 on February 10 ‚Äî has been at Disney since 1998. As Disney's experience chairman, D'Amaro oversees the parks division, which has been a financial standout compared to the fast-eroding linear TV business.\n\n\"The company appears to be reorganizing in ways that shore up his shortcomings,\" Pozner told Business Insider, referring to D'Amaro.\n\nDisney didn't respond to a request for comment from Business Insider on its reasoning.\n\nBecause D'Amaro is 20 years younger than Iger, D'Amaro could have a lengthy run in the top job, she said.\n\n\"He's still got a long time horizon in front of him,\" Pozner said. \"This is really planning for the future. And I think that's a great signal about stability.\"\n\nAnalyst Joe Bonner of Argus Research said it's \"hard to really tell much about anyone under that big shadow\" of Iger.\n\nD'Amaro is known among colleagues for being a likable guy who takes selfies with parkgoers.\n\n\"D'Amaro definitely feels like a man of the people,\" Pozner said.\n\nD'Amaro is \"broadly popular\" and known for being approachable, said a Disney ad sales staffer who said they'd been in the same room as D'Amaro but hadn't met him. This person added that the incoming CEO seems \"very well-liked over at Parks\" and added that it's \"always a good sign when people love working for someone.\"\n\nThat affability could help him forge relationships in other divisions of the entertainment conglomerate ‚Äî and navigate a new course while Iger initially remains on the board.\n\nPozner said D'Amaro's relative youth and his \"flesh-pressing image\" could signal that Disney's board wants to help the company maintain its friendly perception. That matters because of criticisms, for example, that the costs of the theme parks have become out of reach for some families.\n\nThat concern has worried some investors, who wonder how much consumers will be willing to hand over to spend time at the happiest place on earth, Ben Barringer, global head of technology research at the UK wealth management firm Quilter Cheviot, told Business Insider.\n\nBarringer said that D'Amaro will likely have to develop new skills to match his broader remit.\n\n\"Dealing with Parks people is different from dealing with studio people,\" Barringer said.\n\nIt could help that Walden is staying at the Mouse House in a major role.\n\nD'Amaro will likely also want to work on his influence skills, Barringer said, in part because moving the company through the big upheaval in the entertainment industry won't be easy.\n\n\"Hollywood faces quite a lot of disruption,\" he said. The ascent of AI and Disney's partnership with OpenAI are signs that more change is coming, Barringer said.\n\n\"Embracing the disruptive threat and trying to leverage it is a good way to start,\" Barringer said, referring to AI.",
    "readingTime": 4,
    "keywords": [
      "ceo bob",
      "disney's board",
      "entertainment industry",
      "business insider",
      "iger d'amaro",
      "parks",
      "decade",
      "pozner",
      "lead",
      "leadership"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/new-disney-ceo-josh-damaro-consensus-pick-leadership-2026-2",
    "thumbnail_url": "https://i.insider.com/69826bcad3c7faef0ecd8c94?width=1200&format=jpeg",
    "created_at": "2026-02-04T01:06:35.190Z",
    "topic": "finance"
  },
  {
    "slug": "the-em-dash",
    "title": "The Em Dash",
    "description": "Last summer, Bryan Vance found himself in an argument with a stranger on Reddit. Vance, a Portland-based journalist who runs Stumptown Savings, a newsletter covering local grocery deals, had been accused of using ChatGPT to write his content. The evidence? His use of em dashes. ‚ÄúA Reddit user accused me of using AI, pointing to",
    "fullText": "Last summer, Bryan Vance found himself in an argument with a stranger on Reddit. Vance, a Portland-based journalist who runs Stumptown Savings, a newsletter covering local grocery deals, had been accused of using ChatGPT to write his content. The evidence? His use of em dashes.\n\n‚ÄúA Reddit user accused me of using AI, pointing to my use of, quote, extra long M dashes that are not possible to replicate on a normal keyboard,‚Äù Vance recalls. The accusation stung, particularly because Vance spends 40 hours a week personally visiting grocery stores and crafting his newsletter by hand. ‚ÄúI‚Äôm a human, I can confirm I‚Äôm human,‚Äù he says.\n\nThis plucky bit of punctuation has had a very, very long literary history way beyond today‚Äôs tussles with technology. It‚Äôs been on a hero‚Äôs journey, playing the lead in an adventure story that has spanned both centuries and the pages of our most beloved plays, novels and poems. So who invented it‚Äîand why?\n\nThe em dash gets its name from its width, roughly equivalent to a capital M. Its origins trace back to 11th century Italy and a scholar named Boncompagno da Signa, who practiced the formal art of composing letters and documents. Frustrated with the inconsistent punctuation rules of his time, he created his own system, including a horizontal dash called Virgula Plana that looked exactly like a modern em dash.\n\nWhile his dash-as-period never caught on, the mark‚Äôs grammatical flexibility allowed it to evolve. According to Keith Houston, author of Shady Characters: The Secret Life Of Punctation, Symbols And Other Typographical Marks the dash slid into the printing era without a fixed purpose, which may have made it remarkably adaptable.\n\nThe dash became essential for capturing a theatrical technique called aposiopesis, speech deliberately broken off mid-sentence. In King Lear, characters trail off with dashes as they lose their train of thought or shift direction, bringing psychological realism to the stage.\n\nWhen the novel emerged as a literary form in the 18th century, writers adopted the dash to capture authentic human thought and speech. Lawrence Sterne‚Äôs 1759 satirical novel ‚ÄúTristram Shandy‚Äù deployed dashes with wild abandon, creating a stream-of-consciousness narrative that felt revolutionary. One short excerpt contains seven dashes used in every conceivable way. ‚ÄúIt must have been like a bolt from the blue,‚Äù Houston says. ‚ÄúIt must have been so incredible for people at the time to read this.‚Äù\n\nNovelists also used dashes for censorship, redacting names and locations to create an air of authenticity. Jane Austen employed this technique in her work, including in Pride and Prejudice using dashes to obscure military regiment names as if protecting real people‚Äôs reputations. The device added both realism and intrigue, helping sell these new works of fiction.\n\nNo writer became more associated with the em dash than Emily Dickinson. She composed nearly 1,800 poems in Amherst, Massachusetts, many during the Civil War, accompanied by thousands of dashes. Her dashes didn‚Äôt just indicate pauses; they captured the speed and ambiguity of human thought itself.\n\nDr. Fiona Green, who has studied Dickinson for decades, notes that the poet‚Äôs dashes create suspended moments of meaning. ‚ÄúShe exploited unfinishedness,‚Äù Green explains. ‚ÄúThe poems are always in the process, always undecided.‚Äù When Dickinson died in 1886, her editors stripped away most of her dashes before publication. Out of 1,151 dashes in her first collection, only 52 remained. Yet the poems became a sensation, never going out of print.\n\nThe em dash has always had critics. Jonathan Swift mocked excessive dashes in the 18th century. A reviewer complained about Lord Byron‚Äôs dashes appearing ‚Äúsometimes twice or thrice in one line.‚Äù Modern style guides like The Chicago Manual of Style warn: ‚ÄúIf in doubt, edit them out.‚Äù Even dash enthusiasts acknowledge the temptation to overuse it. ‚ÄúIt‚Äôs easy to overuse the dash,‚Äù Houston admits. ‚ÄúI have to self edit to stop myself using it all the time.‚Äù\n\nWhich brings us back to Bryan Vance and his Reddit troubles. Around 2024, people noticed that ChatGPT and other large language models had developed an em dash habit. The punctuation appeared so frequently in AI-generated text that younger internet users began calling it the ‚ÄúChatGPT hyphen.‚Äù",
    "readingTime": 4,
    "keywords": [
      "i‚Äôm human",
      "bryan vance",
      "dashes",
      "dash",
      "poems",
      "chatgpt",
      "punctuation",
      "century",
      "newsletter",
      "grocery"
    ],
    "qualityScore": 1,
    "link": "https://99percentinvisible.org/episode/658-the-em-dash/",
    "thumbnail_url": "https://99percentinvisible.org/wp-content/uploads/2025/08/STITCHER_GRAPHICS-PACK_99PercentInvisible_R2021_Stitcher_App_Promo_1024x432_A-728x307.jpg",
    "created_at": "2026-02-03T18:41:46.525Z",
    "topic": "tech"
  },
  {
    "slug": "this-startup-uses-ai-to-get-you-on-a-date-fast-read-the-pitch-deck-it-used-to-raise-92-million",
    "title": "This startup uses AI to get you on a date ‚Äî fast. Read the pitch deck it used to raise $9.2 million.",
    "description": "Ditto, an AI matchmaking service for college students, raised millions as it expand to more college campuses.",
    "fullText": "Allen Wang and Eric Liu, two UC Berkeley dropouts, think they can help college students find love using AI.\n\nTheir dating startup, Ditto, leverages AI to match people based on the data users input into the service. It then plans the date for them.\n\n\"We're bringing people back to in-real-life interactions,\" Wang, 23, told Business Insider.\n\nAfter users make a profile, they directly message Ditto's AI chatbot via text‚Äî¬†no app required ‚Äî¬†about their type and dating preferences. On Wednesdays, users get a text about a potential match. After each date, Ditto follows up for feedback and uses that information as additional data for future matches.\n\n\"People are tired of being trapped behind the apps,\" Wang said.\n\nDitto will announce on Tuesday that it has raised $9.2 million in seed funding, led by venture capital firm Peak XV, with participation from firms like Alumni Ventures, Gradient, and Scribble Ventures.\n\nThe seed funding will primarily be spent on hiring talent across AI and growth, Wang said, as well as toward Ditto's marketing. The company has 10 staffers and has raised a total of $9.5 million to date. Ditto launched its product in early 2025.\n\nDitto isn't the only AI dating app gaining momentum right now.\n\nOther startups like Sitch, Known, and Amata have raised millions for similar products that pitch AI-powered matchmaking as the new alternative to swiping through profiles. Dating app mainstays like Tinder and Bumble, meanwhile, are also testing the AI waters to reignite user interest.\n\nDitto's AI tries to determine whether two people would be a good match by using profile details, such as users' hobbies or interests, to simulate a date, Wang said.\n\n\"Would you guys have a good conversation? Do you guys have matched humor level? Do you guys have similar vibes and values?\" Wang said.\n\nThe dating startup world has a history of targeting college students as early users. For instance, Tinder's early success came in part from its marketing on college campuses.\n\n\"College kids are very adaptive to new technology,\" Wang said.\n\nThe app now has about 42,000 people signed up across several college campuses in California. With its recent funding, Ditto plans to expand to more college campuses.\n\nOne tactic that helps get college-aged users on board: parties.\n\nDitto plans to host several yacht parties across the US, beginning with a Valentine's Day party in Los Angeles (it hosted its first yacht party this summer). At the parties, 100 college students will \n\n\"We are prioritizing growth over monetization,\" Wang said, adding that the startup is interviewing users about what price they'd be willing to pay for dates from the service.\n\nRead the 12-page pitch deck Ditto used to raise $9.2 million:\n\nNote: Some details have been redacted.\n\nDating apps have a \"paradigm shift every decade,\" the slide says.\n\nIn the 1990s and 2000s, online dating websites emerged. Then in the 2010s, mobile dating apps took over. Ditto pitched investors that AI is the next frontier.\n\nThe slide describes Ditto as an AI social agent network where \"AI turns profiles into live agents that can interact on their own.\"\n\n\"Gen Z is tired of swiping and chatting online,\" the slide says. \"They prefer 'coffee chat vibe check' style social: IRL, genuine, light.\"\n\nThe slide also incorporates some old-school video game aesthetics, inspired by Super Mario Bros.\n\nOn a website, users fill out a questionnaire and tell Ditto about their \"type.\" Then, Ditto will start texting users directly.\n\nThe text includes a collage of the user's photos.\n\nAI helps Ditto \"understand the intrinsic and deeper values\" about why two people could be a good match, Wang told Business Insider.\n\nDitto takes user data and feeds it into an analysis agent, which performs image analysis, attractiveness analysis, and profile tagging.\n\nThen, in the \"pre-date reasoning\" phase, a matchmaking agent does a \"vibe check\" and \"hobby match\" before running a \"date simulation.\" The date simulation agent then runs through things like \"first impression\" or \"conversation flow\" before presenting a user with a match.",
    "readingTime": 4,
    "keywords": [
      "business insider",
      "vibe check",
      "seed funding",
      "ditto plans",
      "date simulation",
      "college students",
      "college campuses",
      "dating startup",
      "dating apps",
      "dating app"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/read-pitch-deck-college-ai-matchmaking-dating-app-ditto-seed-2026-2",
    "thumbnail_url": "https://i.insider.com/6980e1cee1ba468a96ab2d32?width=1200&format=jpeg",
    "created_at": "2026-02-03T18:41:46.029Z",
    "topic": "finance"
  },
  {
    "slug": "most-ai-assistants-are-feminine-and-its-fuelling-harmful-stereotypes-and-abuse",
    "title": "Most AI assistants are feminine, and it's fuelling harmful stereotypes and abuse",
    "description": "Without intervention, we risk hardcoding human misogyny into the digital infrastructure of everyday life.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 218,800 academics and researchers from 5,433 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/most-ai-assistants-are-feminine-and-its-fuelling-dangerous-stereotypes-and-abuse-272335",
    "thumbnail_url": "https://images.theconversation.com/files/711840/original/file-20260112-56-tbyu8s.jpg?ixlib=rb-4.1.0&rect=0%2C473%2C5673%2C2836&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2026-02-03T18:41:45.496Z",
    "topic": "tech"
  },
  {
    "slug": "disastrous-start-for-us-tiktok-as-users-cry-censorship",
    "title": "Disastrous start for US TikTok as users cry censorship",
    "description": "New US-owned app struggled with a storm and was accused of blocking content critical of Trump ‚Äì can it recover?\nHello, and welcome to TechScape. I‚Äôm Blake Montgomery, writing to you from Doha, where I‚Äôm moderating panels about AI and investing as part of the Web Summit Qatar.\nI want to bring your attention to the impact of a Guardian story. In December, we published a story, ‚Äú‚ÄòA black hole‚Äô: families and police say tech giants delay investigations in child abuse and drug cases‚Äù, about grieving families and law enforcement officers who say that Meta and Snapchat have slowed down criminal investigations.",
    "fullText": "New US-owned app struggled with a storm and was accused of blocking content critical of Trump ‚Äì can it recover?\n\nHello, and welcome to TechScape. I‚Äôm Blake Montgomery, writing to you from Doha, where I‚Äôm moderating panels about AI and investing as part of the Web Summit Qatar.\n\nI want to bring your attention to the impact of a Guardian story. In December, we published a story, ‚Äú‚ÄòA black hole‚Äô: families and police say tech giants delay investigations in child abuse and drug cases‚Äù, about grieving families and law enforcement officers who say that Meta and Snapchat have slowed down criminal investigations. (The tech companies contend that they cooperate.) This month, Colorado lawmakers introduced a bill to compel social media platforms to respond to warrants in 72 hours.\n\nNearly two weeks ago, TikTok stepped on to US shores as a naturalized citizen. Ever since, the video app has been fighting for its life. It endured a major outage that stifled users‚Äô ability to upload videos, which fueled a fierce user backlash over perceived censorship. Now it‚Äôs facing an ascendant competitor and an inquiry by the California governor.\n\nTikTok‚Äôs calamitous emigration began on 22 January when its Chinese parent company, ByteDance, finalized a deal to sell the app to a group of US investors, among them the business software giant Oracle. The day after the deal closed, its new owners altered its privacy policy to permit more extensive data collection.\n\nDuring the weekend that followed, the US weathered a fearsome winter storm and the killing of an American citizen by federal immigration agents. Both knocked TikTok off its feet.\n\nWinter Storm Fern crippled multiple Oracle datacenters that TikTok relies on. The app suffered severe outages as a result. Many users said they were unable to upload videos. Others said their videos received zero views despite significant followings. Many of those same users cried censorship as they tried to express their outrage over Alex Pretti‚Äôs death via TikTok and found they could not. Prominent personalities said they would leave the app.\n\nAfter days of outcry, TikTok issued a statement ascribing the problems to the snow, ice and cold. That did not stop California‚Äôs governor, Gavin Newsom, from announcing the next day that his office would investigate the app‚Äôs alleged suppression of content critical of Donald Trump.\n\nTikTok‚Äôs late attribution of blame did little to assuage public criticism. The exodus has propelled a new competitor, Upscrolled, which promises less censorship than TikTok, to the top spot in the US Apple App Store and the third spot in the Google Play Store. Upscrolled‚Äôs founder said in a conversation at the Web Summit Qatar that the app now boasts more than 2.5 million users.\n\nWith more than a billion users worldwide, it seems unlikely that TikTok will altogether vanish as a result of these failures. TikTok‚Äôs first week in the US does not bode well, though.\n\nElon Musk had more extensive ties to Epstein than previously known, emails show\n\nTesla discontinues Model X and S vehicles as Elon Musk pivots to robotics\n\nTwo dramas, both showing in New York, are highlighting how our collective anxieties about technology have shifted in the decade between their premieres.\n\nMarjorie Prime, now revived on Broadway but first staged in 2014, follows Tess (Cynthia Nixon), as she deals with the ageing, death and robotic recreation of her mother (June Squibb). The world of the play features ‚ÄúPrimes‚Äù, android lookalikes of real people that attempt to emulate them for the comfort of those left behind, which Tess and her mother both engage with. Picture an Alexa, but it‚Äôs your dead husband, grandmother, etc. The play brings to mind the early worries about Siri, which debuted three years before the play. Since then, we‚Äôve seen our own real-life versions of Primes: millions of people have digitally copied their deceased loved ones to varying degrees of uncanniness and success. Though its predictions are no longer far-fetched, the play remains moving. I found it touching.\n\nData, which premiered off Broadway last week, follows the talented young programmer Maneesh (Karan Brar) after he joins Athena Technologies, a clear analogue for the very real company Palantir. Maneesh is inducted into the company‚Äôs most elite team, data analytics, where he learns about clandestine work with the US government. He struggles with the ethics of the project. He wrestles with whether to expose it to the world in hopes of tanking it or keeping his head down. The play‚Äôs themes are quite familiar. They were playing out in headlines two days before I attended, and the Guardian has published stories about them.\n\nData is paced and plotted like a political thriller, more like House of Cards than Her. Seeing the two plays within a week of each other, I was struck by how much our concerns with tech have moved from the realm of science fiction into that of realism. Marjorie Prime is less literally concerned with tech, more with its emotional consequences. Data is about what it means to literally work as a software engineer. It seems unlikely to me that a play about the ethics of software in US bureaucracy could have sustained any tension in an era before this one.\n\nMarjorie Prime imagines a melancholy future; Data chronicles a version of the unpleasant present. The very real events of the previous year and Silicon Valley‚Äôs entanglement with the Trump administration loom over Data, for better and for worse. The play could not be more timely; it may feel dated by the end of year. Watching it felt like reading a yarn in the Wall Street Journal (or the Guardian, if I‚Äôm flattering myself).\n\nI am curious to observe which play ages better. Data serves as a real-time, red-hot record of our current moment, which may cool quickly. During the play, I was intrigued by some of its villains‚Äô seemingly nefarious arguments in favor of the company‚Äôs work. What if the main character exposes the evil in the press and nothing happens, as his boss says? I have been part of multiple news cycles where that has been the case. What will plucky 22-year-old Maneesh do then? The question presents a more interesting, nuanced response to reality than Maneesh‚Äôs black-and-white, do-or-die plan to blow things up. By contrast, Marjorie Prime‚Äôs sentient artificial intelligence acts as a vehicle to discuss the age-old grief of a parent‚Äôs death and its aftermath.\n\nThe central question that both plays ask is not, in the end, one explicitly about technology, but about how to keep living beneath crushing weight. In Marjorie Prime, Tess struggles with the repetitiveness of her days and the robotic, constant reminder of her mother. She eventually succumbs to her despair, replaced by a robot herself, which torments her grieving husband with its pale simulation. In Data‚Äôs final, devastating scene, the secondary hero, Riley (Sophia Lillis, who gives the play‚Äôs best performance), asks how she can just go back to work, plagued as she is by moral concerns but trapped by monetary need, after failing to stop the company‚Äôs work. She trembles as her phone beeps, reminding her she‚Äôs late for her next meeting.\n\nWhat is Moltbook? The strange new social media site for AI bots\n\nThe slopaganda era: 10 AI images posted by the White House ‚Äì and what they teach us\n\nApple reports record iPhone sales as new lineup reignites worldwide demand\n\nSouth Korea‚Äôs ‚Äòworld-first‚Äô AI laws face pushback amid bid to become leading tech power\n\nCan you guess our screen time? A priest, pensioner, tech CEO and teenager reveal all",
    "readingTime": 7,
    "keywords": [
      "web summit",
      "summit qatar",
      "content critical",
      "social media",
      "upload videos",
      "winter storm",
      "marjorie prime",
      "elon musk",
      "users",
      "guardian"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/tiktok-us-owners",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0a274f3020c55c46386058163d01d8fd1e5be0c9/510_0_5027_4024/master/5027.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=efbeb0f6e135e61ec35e7b71057f714b",
    "created_at": "2026-02-03T18:41:45.009Z",
    "topic": "tech"
  },
  {
    "slug": "anthropics-launch-of-ai-legal-tool-hits-shares-in-european-data-companies",
    "title": "Anthropic‚Äôs launch of AI legal tool hits shares in European data companies",
    "description": "Pearson, Experian and others fall sharply after startup unveils software to automate a range of professional services\nEuropean publishing and legal software companies have suffered sharp declines in their share prices after the US artificial intelligence firm Anthropic revealed a tool for use by companies‚Äô legal departments.\nAnthropic, the company behind the  chatbot Claude, said its tool could automate legal work such as contract reviewing, non-disclosure agreement triage, compliance workflows, legal briefings and templated responses.\n Continue reading...",
    "fullText": "Pearson, Experian and others fall sharply after startup unveils software to automate a range of professional services\n\nEuropean publishing and legal software companies have suffered sharp declines in their share prices after the US artificial intelligence firm Anthropic revealed a tool for use by companies‚Äô legal departments.\n\nAnthropic, the company behind the chatbot Claude, said its tool could automate legal work such as contract reviewing, non-disclosure agreement triage, compliance workflows, legal briefings and templated responses.\n\nShares in the UK publishing group Pearson fell by 4% on the news, and shares in the information and analytics company Relx plunged 14%. The software company Sage lost 5.5% in London and the Dutch software company Wolters Kluwer lost 10.5% in Amsterdam.\n\nShares in the London Stock Exchange Group fell by 8.5%, its biggest drop in almost five years, and the credit reporting company Experian dropped by 8.9% in London, amid fears over the impact of AI on data companies.\n\nEurope‚Äôs media stocks index is set for the biggest daily fall since March 2020, down 5%. Nasdaq-listed Thomson Reuters‚Äô shares plummeted 14.2%.\n\nThe FTSE 100 had hit a record high on Tuesday morning but the sell-off dragged the blue chip index into the red.\n\nAnthropic said the plugin did not provide legal advice. ‚ÄúAI-generated analysis should be reviewed by licensed attorneys before being relied upon for legal decisions,‚Äù the startup said.\n\nThe company also announced a number of other open-source tools to automate a range of professional activities, including sales and customer support.\n\nAnthropic was founded in 2021 by Dario Amodei, its chief executive, and other former staff members from OpenAI, which developed ChatGPT.\n\n‚ÄúAnthropic launched new capabilities for its Cowork to the legal space, heightening competition within the space,‚Äù Morgan Stanley analysts said in a note on Thomson Reuters. ‚ÄúWe view this as a sign of intensifying competition, and thus a potential negative.‚Äù\n\nThe share price declines deal another severe blow to Nick Train, one of the UK‚Äôs most high-profile fund managers, whose firm Lindsell Train has run Finsbury Growth & Income Trust since 2000. The trust‚Äôs four largest holdings are Sage, Experian, London Stock Exchange and Relx and its shares fell more than 5% on Tuesday.\n\nTrain apologised again for the ‚Äúdire‚Äù performance of the investment trust at its annual meeting last month, after surviving a vote on its future. The FTSE 250-listed company is the worst-performing UK equity income trust over one year and five years.\n\nThe news will reignite fears of job losses caused by the AI boom. Clifford Chance, one of the largest international law firms, said in November it was reducing the number of business services staff at its London base by 10%, citing increased use of AI as a factor behind the decision.\n\nAlong with factory jobs that can be automated, office-based jobs are seen as vulnerable to advances in AI ‚Äì computer systems that perform cognitive tasks typically associated with human intelligence.\n\nThe UK is losing more jobs than it is creating as companies adopt more AI tools, and is being hit harder than rival large economies, according to a study by Morgan Stanley.\n\nMore than a quarter (27%) of UK workers are worried their jobs could disappear in the next five years as a result of AI, a recent survey of thousands of employees showed. It found that British businesses reported an average 11.5% increase in productivity aided by AI. US businesses reported similar gains, but created more jobs than they cut.\n\nIn his annual Mansion House speech last month, the London mayor, Sadiq Khan, said AI could destroy swathes of jobs in the capital. He said London was ‚Äúat the sharpest edge of change‚Äù because of its reliance on white-collar workers in the finance and creative industries, and professional services such as law, accounting, consulting and marketing.\n\nLiz Kendall, the technology secretary, has also warned that ‚Äúsome jobs will go‚Äù, as she announced plans to train up to 10 million British workers, including members of the cabinet, in basic AI skills by 2030.\n\nLindsell Train and Nick Train have been contacted for comment.",
    "readingTime": 4,
    "keywords": [
      "stock exchange",
      "thomson reuters",
      "london stock",
      "automate range",
      "income trust",
      "professional services",
      "the ftse",
      "legal",
      "jobs",
      "software"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/03/anthropic-ai-legal-tool-shares-data-services-pearson",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a955e5ac7e1920e8faca129a66ac8b5ae76e46be/684_0_5927_4741/master/5927.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=55f461b47a1b79971d997b444afc25cc",
    "created_at": "2026-02-03T18:41:45.009Z",
    "topic": "tech"
  },
  {
    "slug": "why-anthropics-latest-ai-tool-is-hammering-legalsoftware-stocks",
    "title": "Why Anthropic's latest AI tool is hammering legal-software stocks",
    "description": "Anthropic's latest plugin can field clerical tasks for legal professionals. It's unveiling sparked a big sell-off in legal software stocks on Tuesday.",
    "fullText": "A recent update from Anthropic has sparked a rush for the exits in a corner of the tech sector.\n\nThe AI juggernaut recently rolled out a new plugin for its Claude Cowork AI agent that can perform several clerical tasks, including tracking compliance and reviewing legal documents.\n\nAs far as AI updates go, it didn't make much of a splash outside the legal space when it was rolled out last Friday. However, it has triggered a sell-off among software and publishing stocks with ties to the legal industry.\n\nHere were the big movers on Tuesday:\n\nThe threat of AI disruption was factored into many Wall Street outlooks heading into 2026, but the market's reaction to Anthropic's update makes it clear investors are highly skittish about disruption from AI agents.\n\nThe field is crowded, but Claude stands out as the choice of many industry professionals for legal and financial analysis. Famed short-seller Andrew Left told Business Insider last year that he has used it for research for his upcoming court case.\n\nOf the three software stocks, only LegalZoom operates exclusively in the legal industry, helping simplify tasks for customers through guides and access to independent attorneys. British IT conglomerate RELX owns the legal data and analytics platform LexisNexis, while Thomson Reuters's exposure is through its ownership of legal research platform Westlaw.\n\nThe stocks have struggled so far in 2026, with declines of at least 20% year-to-date. Each one began the year with a gradual decline that sharply accelerated following the release of Anthropic's legal plugins.\n\nInvestor confidence in the legal publishing industry may be further compromised as these advances continue. Many venture capital firms rushed to fund legal tech startups in 2025, making it clear that they believe in the power of these AI-forward companies to further disrupt the industry.",
    "readingTime": 2,
    "keywords": [
      "legal industry",
      "stocks",
      "tech",
      "rolled",
      "tasks",
      "software",
      "publishing",
      "disruption",
      "anthropic's",
      "research"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/anthropic-cowork-legal-plugin-publishing-stocks-legalzoom-thomson-reuters-relx-2026-2",
    "thumbnail_url": "https://i.insider.com/6982191fe1ba468a96ab435a?width=1200&format=jpeg",
    "created_at": "2026-02-03T18:41:44.925Z",
    "topic": "finance"
  },
  {
    "slug": "to-drive-ai-adoption-build-your-teams-product-management-skills",
    "title": "To Drive AI Adoption, Build Your Team‚Äôs Product Management Skills",
    "description": "To unlock the real value of generative AI at work, employees need an unexpected set of skills: those of a product manager. Defining high-value problems, finding the right digital tools to solve them, experimenting with those tools, and integrating solutions into workflows are key activities of a product manager, and they‚Äôre critical to developing improvements to employees‚Äô workflows. Managers can accelerate gen AI adoption by modeling these behaviors, introducing demos and other resources, and creating the psychological safety for teams to do the same.",
    "fullText": "To Drive AI Adoption, Build Your Team‚Äôs Product Management Skills by Amanda Pratt and Melissa ValentineFebruary 3, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintMuch of the conversation about how to work effectively with generative AI has focused on prompt engineering or, more recently, context engineering: the semi-technical skill of crafting inputs so that large language models produce useful outputs. These skills are helpful, but they are only part of the story. The real payoff comes when employees learn how to apply generative AI in their day jobs in a way that improves how they work. This requires defining valuable problems within workflows, evaluating possible solutions, rapidly experimenting, and integrating new practices sustainably into day-to-day work‚Äîdisciplines that are core to the work of product managers.",
    "readingTime": 1,
    "keywords": [
      "product",
      "skills",
      "generative",
      "engineering"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/to-drive-ai-adoption-build-your-teams-product-management-skills",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_03_175181301.jpg",
    "created_at": "2026-02-03T18:41:44.457Z",
    "topic": "business"
  },
  {
    "slug": "how-do-workers-develop-good-judgment-in-the-ai-era",
    "title": "How Do Workers Develop Good Judgment in the AI Era?",
    "description": "AI is creating a major organizational challenge: People with deep experience get huge productivity gains, while junior employees often can‚Äôt tell whether AI‚Äëgenerated work is any good or how to improve it. Because AI now handles the messy, repetitive tasks that once built judgment, junior employees miss chances to develop it. Organizations risk ending up with managers who‚Äôve never done the underlying work and thin leadership pipelines. The solution isn‚Äôt just keeping humans in the loop, but redesigning work to build judgment deliberately: clarifying who makes decisions, exposing people to consequences, restoring stretch experiences, and using tools like simulations, case-based learning, and gradual increases in responsibility.",
    "fullText": "How Do Workers Develop Good Judgment in the AI Era? by David S. DuncanFebruary 3, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintA few years ago, when I first started experimenting with generative AI as a partner at a consulting firm, I noticed something that surprised me: It was helping me a lot more than it was helping my less-experienced colleagues.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/02/how-do-workers-develop-good-judgment-in-the-ai-era",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_03_JulieGuillem.jpg",
    "created_at": "2026-02-03T18:41:44.446Z",
    "topic": "business"
  },
  {
    "slug": "elon-musks-spacex-buys-xai-in-stunning-deal-valued-at-125-trillion-ahead-of-looming-ipo",
    "title": "Elon Musk‚Äôs SpaceX buys xAI in stunning deal valued at $1.25 trillion ahead of looming IPO",
    "description": "‚ÄúMy estimate is that within two to three years, the lowest cost way to generate AI compute will be in space,‚Äù Musk wrote in a post on SpaceX‚Äôs website on Monday.",
    "fullText": "Elon Musk‚Äôs rocket company SpaceX has acquired xAI, the artificial intelligence firm founded by Musk three years ago, in a massive, and unconventional, deal that combines the two privately held firms into a company with an astounding $1.25 trillion reported valuation and plans for a historic IPO this year.\n\nHow does Musk justify the $1.25 trillion valuation?\n\nHow do Tesla's investments complicate this deal?\n\nWhat are the space-based data center plans?\n\nWhat companies are involved in this SpaceX-xAI merger?\n\nMusk, who is the CEO of both companies as well as publicly traded electric vehicle and robotics company Tesla, described the combination as one that will ‚Äúform the most ambitious, vertically integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile-device communications, and the world‚Äôs foremost real-time information and free speech platform,‚Äù he wrote in a blog post on SpaceX‚Äôs website.\n\nMusk cited the potential for space-based data centers, the energy-intensive computing facilities necessary to power AI services, as one of the most important benefits of the combination, even though the concept is still unproven and largely theoretical. ‚ÄúGlobal electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term,‚Äù Musk wrote in the blog post.\n\n‚ÄúBy directly harnessing near-constant solar power with little operating or maintenance costs, these satellites will transform our ability to scale compute,‚Äù Musk wrote.\n\nWhile reports of a potential deal emerged last week, the stratospheric value of the transaction and the swiftness with which it closed left many industry observers in awe, underscoring the massive expectations around AI as well as fears of an overheated market that could be due for a reckoning.\n\nAccording to reporting in Bloomberg, the deal between SpaceX and xAI will lead to a combined enterprise value of $1.25 trillion, with shares of xAI valued at $526.59 apiece. Musk has reportedly been hashing out the potential terms of a SpaceX IPO this year that would value the company at $800 billion, setting the stage for what could be the largest initial public offering of all time.\n\nRepresentatives from SpaceX and xAI did not immediately respond to requests for comment.\n\nMusk, the richest person in the world, has a documented history of mingling the financial interests of his businesses. In 2015, Tesla acquired Solar City, a solar energy company founded by Musk‚Äôs cousins and on whose board Musk served as chairman.\n\nAnd in March 2025, xAI acquired X, the Musk-owned social platform formerly known as Twitter, in a $33 billion, all-stock deal. ‚ÄúxAI and X‚Äôs futures are intertwined,‚Äù Musk said at the time.\n\nMore recently, Tesla surprised shareholders just last month when it revealed that it had invested $2 billion in xAI in exchange for a batch of preferred stock as part of xAI‚Äôs $20 billion Series E funding round. That investment means Tesla shareholders now own preferred stock in a company that has become a subsidiary of SpaceX, which could raise questions from investors about Tesla‚Äôs role in funding xAI‚Äôs growth. In addition to the $2 billion investment, Tesla disclosed it sold $430 million of Megapack battery storage and systems to xAI in 2025, costing it $285 million, exhibiting the circular nature of Musk‚Äôs businesses.",
    "readingTime": 3,
    "keywords": [
      "preferred stock",
      "deal",
      "acquired",
      "musk",
      "space-based",
      "potential",
      "founded",
      "massive",
      "valuation",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/elon-musk-spacex-buys-xai-234756266.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/LZvSFHgRevVwt4ilr0vhmg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/840d01d0cfb2f71a4f32ec0609dff6d3",
    "created_at": "2026-02-03T18:41:42.712Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-merges-spacex-with-xai-at-125tn-valuation",
    "title": "Elon Musk merges SpaceX with xAI at $1.25tn valuation",
    "description": "Aerospace business and artificial intelligence firm to unite for IPO as world‚Äôs most valuable private...",
    "fullText": "Aerospace business and artificial intelligence firm to unite for IPO as world‚Äôs most valuable private company\n\nElon Musk‚Äôs aerospace company SpaceX has acquired his artificial intelligence business xAI, in a $1.25tn (¬£910bn) merger that consolidates part of Musk‚Äôs empire as SpaceX prepares to go public later this year.\n\nThe two companies announced the deal on Monday in a statement on SpaceX‚Äôs website, saying the merger would form ‚Äúthe most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world‚Äôs foremost real-time information and free speech platform‚Äù.\n\nSpaceX, one of the world‚Äôs most valuable private companies, will gain xAI properties such as its Grok chatbot and the social media platform X. The acquisition comes as Musk has pursued plans to put datacenters and solar-powered satellites in space as a means of powering artificial intelligence, an immense and exorbitantly expensive undertaking.\n\nThe deal reportedly valued SpaceX at $1tn and xAI at $250bn, putting the combined business on course for a stock market float valuing it well in excess of $1tn. The float is expected to be timed for early summer to coincide with a planetary alignment and Musk‚Äôs birthday.\n\nMusk turns 55 on 28 June, around the same time as Jupiter and Venus appear in close proximity to each other.\n\nThe announcement of the deal specifically cited Musk‚Äôs plans for space-based datacenters as a rationale for the deal.\n\n‚ÄúCurrent advances in AI are dependent on large terrestrial datacenters, which require immense amounts of power and cooling. Global electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term, without imposing hardship on communities and the environment,‚Äù the announcement said.\n\n‚ÄúIn the long term, space-based AI is obviously the only way to scale.‚Äù\n\nMusk has been increasingly intertwining parts of his businesses in recent months through deals and acquisitions. xAI acquired the platform X in an all-stock transaction in early 2025, and last month Tesla revealed that it planned to invest $2bn in xAI.\n\nBoth SpaceX and xAI have received staggering valuations in the past year. As SpaceX continues to dominate satellite launches and secure extensive contracts with the US federal government, it sent a letter to investors in December that revealed an expected value of $800bn for the company.\n\nDespite widespread backlash to xAI‚Äôs Grok AI tool over its promotion of racist ideology and spread of nonconsensual sexualized deepfake images of women and children, the artificial intelligence company has also grown its valuation amid the AI boom. It announced a $20bn Series E fundraise last month from major investors, which valued the company at $230bn.\n\nSpeculation and leaks about the deal, first reported by Reuters, have proliferated in recent days. Musk appeared to give vague confirmation of the acquisition earlier on Monday, writing simply ‚Äúyes‚Äù in reply to a post on X that referenced reports of the merger.\n\nThe news is a positive diversion for Musk after Tesla released an earnings report last week that showed declining revenues and a struggling car business. A few days later, a Department of Justice release of 3m files related to sex offender Jeffrey Epstein showed Musk exchanging numerous friendly emails with the disgraced financier and making plans to visit his private island. Musk has not responded to Guardian inquiries about the latest Epstein emails.\n\nHe called the release of the emails a ‚Äúdistraction‚Äù on X and claimed that he was ‚Äúwell aware that some email correspondence with him could be misinterpreted and used by detractors to smear my name‚Äù.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "deal",
      "business",
      "world‚Äôs",
      "merger",
      "space-based",
      "platform",
      "plans",
      "datacenters",
      "emails"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/feb/02/elon-musk-spacex-xai-merger",
    "thumbnail_url": "https://i.guim.co.uk/img/media/83b03182f5b065e02d70039e2ba3c58756588013/418_0_4164_3333/master/4164.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d66c68e5bd339fda5b4e94f50aebc953",
    "created_at": "2026-02-03T12:35:14.243Z",
    "topic": "science"
  },
  {
    "slug": "barnsley-rebranded-uks-first-tech-town-as-us-giants-join-ai-push",
    "title": "Barnsley rebranded UK‚Äôs first ‚Äòtech town‚Äô as US giants join AI push",
    "description": "Minister announces Microsoft, Cisco and Adobe to help apply AI to local schools, hospitals, GPs and businesses\nIn 2002 Barnsley toyed with a redesign as a Tuscan hill village as it sought out a brighter post-industrial future. In 2021 it adopted the airily vague slogan ‚Äúthe place of possibilities‚Äù. Now it is trying a different image: Britain‚Äôs first ‚Äútech town‚Äù.\nThe technology secretary, Liz Kendall, has anointed the South Yorkshire community as a trailblazer for ‚Äúhow AI can improve everyday life‚Äù in the UK.\n Continue reading...",
    "fullText": "Minister announces Microsoft, Cisco and Adobe to help apply AI to local schools, hospitals, GPs and businesses\n\nIn 2002 Barnsley toyed with a redesign as a Tuscan hill village as it sought out a brighter post-industrial future. In 2021 it adopted the airily vague slogan ‚Äúthe place of possibilities‚Äù. Now it is trying a different image: Britain‚Äôs first ‚Äútech town‚Äù.\n\nThe technology secretary, Liz Kendall, has anointed the South Yorkshire community as a trailblazer for ‚Äúhow AI can improve everyday life‚Äù in the UK.\n\nIn the latest move in Labour‚Äôs drive to inject AI into Britain‚Äôs bloodstream, the government has announced four US tech companies ‚Äì Microsoft, Google, Cisco and Adobe ‚Äì have agreed to help as the council pushes to apply AI to local schools, hospitals, GPs and businesses in Barnsley, an area of South Yorkshire which has struggled with unemployment and deprivation since the coal pits closed.\n\nThe town and its 250,000 people have been chosen because they have already adopted AI faster than many places, said Sir Stephen Houghton, the Labour leader of Barnsley metropolitan borough council. His authority has been using AI assistants for the last couple of years in adult social care and children‚Äôs services, and its bin lorries have been enabled with tech to scan roads for potholes. The parcel company Evri, which has one of its largest distribution hubs in the town, has been trialling robot dogs for deliveries.\n\nBut local opposition leaders have warned rebranding Barnsley as a tech town ‚Äúmight seem a bit of a leap‚Äù and highlighted local anxiety about whether AI is a force for good.\n\nThe ‚Äútech town‚Äù status means residents will get free AI and digital training, businesses will be supported to adopt AI, the hospital will test AI tools for check-ins, triage and outpatient care and AI will be tested in schools and at Barnsley College, all in an effort to improve pupils‚Äô results and teachers‚Äô workloads.\n\n‚ÄúThe economic basis of Barnsley was destroyed 30 years ago,‚Äù Houghton said. ‚ÄúThis is the biggest opportunity we have had since then. The future of the economy is going to be in technology and for Barnsley to be at the centre of that is an incredible opportunity.‚Äù\n\nBut one area of uncertainty is the role of the tech companies. Houghton said: ‚ÄúThe council won‚Äôt be paying them. Whether the government is, we have to wait and see.‚Äù\n\nMicrosoft already has a relationship with Barnsley College and, along with Google and Cisco, is understood to be working on a pro bono basis.\n\n‚ÄúIf we are going to get AI to work for Britain, we need Britons and British public services that can work with AI,‚Äù Kendall said. ‚ÄúIf we can show that AI helps young people learn, supports local businesses to be more productive, and improves public services, then we can show what‚Äôs possible for the whole country. What we learn here will shape how we roll out AI across the UK.‚Äù\n\nMinisters have faced criticism over their handling of big technology companies. Last week the government launched a national AI training programme to upskill 10 million citizens, but many of the online courses turned out to be bespoke training for customers of particular companies such as Google, others cost as much as ¬£525 to complete and some simply promoted the merits of particular company‚Äôs approaches to AI such as one explaining Microsoft‚Äôs ‚Äúresponsible AI approach‚Äù.\n\nA spokesperson for the Department for Science, Innovation and Technology said hundreds of courses on the AI Skills Hub are free and where payment is required it is clearly advertised. ‚ÄúAll courses are reviewed against a common set of criteria to ensure they are relevant, high quality, and delivered by eligible organisations,‚Äù they said.\n\nMinisters have also been challenged for holding meetings with tech bosses at the rate of more than once each working day. The government insists engagement is vital to create growth and transform services.\n\n‚ÄúIt‚Äôs not about giving tech companies access to data they shouldn‚Äôt be having,‚Äù Houghton said. ‚ÄúIt‚Äôs a secure programme and we are not leaving ourselves open. But this stuff is not going away. We have to make sure we are smart enough to protect people while taking advantage of the positive stuff it brings.‚Äù\n\nHannah Kitching, the leader of the council‚Äôs Liberal Democrat opposition, said investment in the town was welcome but ‚Äúthere is a lot of anxiety among people about the use of AI and whether it is a force for good. We know it could be but there are darker sides as well.‚Äù\n\n‚Äú[Barnsley] is still really connected to its mining past,‚Äù she said. ‚ÄúYounger people see the jobs and opportunities around the tech town idea but older generations perhaps don‚Äôt. There is a job to be done to get people onboard.‚Äù\n\nResidents ‚Äúwant the council to get the basics right‚Äù, she said. Roads were ‚Äúabsolutely crumbling‚Äù and in bad weather bins did not get collected, she added.",
    "readingTime": 5,
    "keywords": [
      "hospitals gps",
      "schools hospitals",
      "tech town",
      "south yorkshire",
      "barnsley college",
      "businesses",
      "council",
      "houghton",
      "services",
      "training"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2026/feb/03/barnsley-uk-tech-town-ai-microsoft-cisco-adobe",
    "thumbnail_url": "https://i.guim.co.uk/img/media/41106b40e49f16a98e682ad0a5867b9180f16453/35_0_4269_3415/master/4269.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2bf08aba054bee326081df5302e337e8",
    "created_at": "2026-02-03T12:35:14.241Z",
    "topic": "business"
  },
  {
    "slug": "i-massproduced-the-last-30-that-ai-cant-finish",
    "title": "I mass-produced the \"last 30%\" that AI can't finish",
    "description": "Collection of customizable and open source components made with Next.js, Tailwind, Typescript, and Framer Motion.",
    "fullText": "Ruixen UI is a modern, fast, and customizable React component library built with Tailwind CSS, TypeScript, and accessibility in mind.\n\nRuixen UI is a production‚Äëready React component system designed for rapid app development. It pairs a modern design language with type‚Äësafe APIs, keyboard‚Äëfirst accessibility, and flexible theming. Whether you‚Äôre building dashboards, marketing sites, or SaaS admin tools, Ruixen UI helps teams ship consistent, high‚Äëquality interfaces faster.\n\nCan‚Äôt find what you need? Reach out to our Ruixen UI support team for assistance.\n\nCan‚Äôt find what you need? Reach out to our Ruixen UI support team",
    "readingTime": 1,
    "keywords": [
      "react component",
      "ruixen ui",
      "modern",
      "accessibility",
      "can‚Äôt",
      "team"
    ],
    "qualityScore": 0.55,
    "link": "https://www.ruixen.com/",
    "thumbnail_url": "https://ruixen.com/website_preview.png",
    "created_at": "2026-02-03T12:35:11.115Z",
    "topic": "tech"
  },
  {
    "slug": "fastapiturnkey-batteriesincluded-starter",
    "title": "FastAPI-Turnkey ‚Äì batteries-included starter",
    "description": "A high-converting landing page for FastAPI-Turnkey, a production-ready FastAPI starter kit for indie hackers and AI/SaaS builders",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fastapi.manus.space/",
    "thumbnail_url": "https://files.manuscdn.com/webdev_screenshots/2026/02/03/X4VuphVro5WXiMgDjudv4T.png?x-oss-process=image/resize,w_1200/crop,h_630,x_0,y_0",
    "created_at": "2026-02-03T12:35:10.699Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-an-open-source-alternative-to-codex-app",
    "title": "I built an open source alternative to Codex app",
    "description": "Autonomous AI engineer for building production grade software - Chinenyay/BrilliantCode",
    "fullText": "Chinenyay\n\n /\n\n BrilliantCode\n\n Public\n\n Autonomous AI engineer for building production grade software\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Chinenyay/BrilliantCode",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Chinenyay/BrilliantCode",
    "thumbnail_url": "https://opengraph.githubassets.com/144939e4fef4046c7928685e4a0400e8a9b3e62df8abc9a4ca4a7ac154402327/Chinenyay/BrilliantCode",
    "created_at": "2026-02-03T12:35:09.757Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-amplification-paradox-and-how-not-to-become-a-shell",
    "title": "The AI Amplification Paradox ‚Äì and how not to become a shell",
    "description": "A simple model (Shell Theory) explaining how AI can raise baseline output, disproportionately rewards high-agency users, while at the same time risking long-term skill erosion.",
    "fullText": "My teammate and I keep having the same argument. One moment we're witness to the cascade. Watching us software engineers become empty shells, mere relays for whatever the AI produced. The next moment we're amazed how iterative collaboration with AI keeps pushing our boundaries beyond what we thought achievable.\n\nBoth observations feel true simultaneously.\n\nThree narratives keep surfacing in our discussions:\n\nThese statements seem logically incompatible. The amplification of skill argument is moot if everyone is an expert by default. Relying more on AI can't simultaneously amplify skill and erode critical thinking. And if AI gives us expert quality regardless, there's no reason to worry about reduction in critical thinking.\n\nI've been trying to reconcile this intuition into something concrete. What follows is a model. It's not scientifically validated, but useful for reasoning about what we're observing.\n\nLet's define output without AI as a function of agency (V) and experience level (E):\n\nAgency is the foundation. Experience multiplies your output. In this model a principal engineer with low agency still produces less than a senior with high agency.\n\nHere it gets interesting. AI introduces exponential amplification, but this amplification is masked by a floor until your yield exceeds it:\n\nResolving contradictions 1 and 2: The floor-ceiling mechanism.\n\n The model resolves the apparent conflict between \"AI gives everyone 80%\" and \"AI amplifies skill.\" They are actually mathematically distinct effects operating on different populations. When Y < F, you're being rescued to the flatline. You ship working code and feel productive, but your output is artificially lifted to a floor you cannot pass. When Y > F, AI triggers exponential amplification; your yield scales with both agency and experience. The max(F, Y) function ensures the floor, while the exponential in Y raises the ceiling.\n\nResolving contradiction 3: Agency matters.\n\n The concern that \"relying on AI erodes critical thinking\" isn't addressed by the model's equations. It's addressed by how agency is defined. The model treats V as a parameter, but the definition describes agency as responsive: growing through deliberate practice, atrophying through disuse.\n\nThis creates a feedback loop that the math alone doesn't show:\n\nThe model doesn't predict this erosion, but it explains why the erosion matters. Your position isn't determined by a one-time calculation; it's determined by what V becomes over time. Two engineers with identical starting positions can diverge: one practices deliberate engagement and grows V, eventually breaking into the amplification zone. The other accepts the rescue, lets V decay, and becomes permanently dependent on the flatline.\n\nThis is why contradiction 3 coexists with contradictions 1 and 2. AI can amplify skill (for those above the flatline). AI does provide a floor (for everyone). And AI may erode critical thinking (for those who let the floor replace engagement). The determining variable is whether you treat the flatline as a safety net or a hammock.\n\nFeel free to skip this section. What follows is an attempt to assert the model against real-world anchors. If you're not interested in the math, jump ahead to The Model in Practice. The calibration points that follow are illustrative. The model's value isn't in the exact numbers but in the structural insight: Floor and amplification are distinct mechanisms operating on different populations.\n\nReal expertise development has been hypothesized to follow different types of curves. Logarithmic (rapid early gains, diminishing returns), S-shaped (slow start, steep middle, plateau), or non-uniform (qualitative leaps between levels). There's no consensus in the literature on which pattern best describes software engineering capability growth. Linear is simple, and for a thought experiment, simple wins:\n\nNote that with this definition juniors get zero amplification by design. The ability to leverage AI beyond the flatline is in itself what distinguishes a higher experience level.\n\nTo determine F, we need a reference point. AGI provides that anchor. But what is AGI in measurable terms?\n\nThe SWE-bench verified benchmark offers a concrete proxy. This benchmark evaluates AI models on 500 real GitHub bug-fixing tasks where they must produce patches that pass actual test suites. Crucially, these tasks come with human time estimates: 91% take less than one hour for an \"experienced engineer\" who has \"a few hours to familiarize themselves with the codebase.\"\n\nThe phrase \"experienced engineer\" is key. SWE-bench was calibrated against senior-level performance on well-defined tasks. And it only measures a slice of engineering work: fixing bugs in existing codebases with clear acceptance criteria. It doesn't measure architectural decisions, system design, handling ambiguous requirements, or greenfield development.\n\nThis gives us our first anchor: AGI on SWE-bench = F = 100 correlates with the output of a moderate-agency senior on well-defined work.\n\nThe leading models today (Claude Opus 4.5 and Gemini 3 Pro) score around 74% on SWE-bench Verified. This gives us the current flatline: F = 74.\n\nIf a moderate senior (E=3) produces 100 on SWE-bench-type tasks without AI:\n\nThis gives us: V = 25 represents moderate agency.\n\nWith V = 25 as the anchor, we model agency as normally distributed across the engineering population. Assuming a variation of 20% with Œº = 25 gives œÉ = 5:\n\nThe exact values are illustrative. What matters is the concept: Agency varies meaningfully across engineers, and this variance affects output before AI even enters the equation.\n\nIf you have lower agency, you can still reach the flatline. It just takes longer to get there.\n\nTo define the slope of the exponential curve, we need a calibration point. A known relationship between experience and amplification. Without empirical data stratified by experience level, we make an informed assumption: at principal level (E=4), AI amplifies output to 2√ó R_noAI.\n\nIt reflects a hypothesis that the most experienced engineers can roughly double their effective output through AI collaboration. Leveraging it for code generation, exploration, and iteration while applying judgement that compounds the result.\n\nUsing the standard technique for deriving an exponential rate constant (taking the natural logarithm of both sides) we get:\n\nThis anchors the exponential curve. AI is powerful enough to meaningfully amplify engineers, with the curve calibrated to reach 2√ó at principal level. If future evidence suggests principals achieve a different amplification ratio‚Äîsay, 3√ó‚Äîthen A would become ln(3)/1.5 ‚âà 0.732.\n\nWith each parameter anchored to an assumption, here's how the model plays out:\n\nThe asymmetry is clear: below the flatline, the exponential yield exists but is masked‚Äîeveryone sees 74. Above it, the exponential becomes visible and compounds experience, reaching 2√ó output at principal level.\n\nThe model assumes you're working within a single domain where your experience level applies uniformly. Reality is messier. A single task often demands multiple skill domains and your experience level differs across them.\n\nConsider a senior backend engineer who doesn't know frontend, building a full-stack feature. AI amplifies their backend work exponentially while rescuing their frontend work to the flatline. The final output can be equally impressive though.\n\nWhat differs is the force behind the output. A specialist operating entirely above the flatline earns their amplified output through skill. A generalist in the blend achieves high output through a combination: part genuine skill amplification (in their strong domains), part being rescued (in their weak domains).\n\nThis matters for growth. When output comes from skill, you're building compound advantage. When output comes from the flatline, you're borrowing capability you haven't earned yet. This is not bad, but let's remain honest about which parts of your work are truly yours. Most importantly, your compound depends on the agency you are showing and the time you have already spent building experience. AI can accelerate knowledge acquisition. But seniority is knowledge and experience. You still need to live through production incidents, watch systems evolve, and feel the consequences of decisions that seemed fine until they weren't.\n\nThe flatline F currently sits at 74, and with AGI the flatline rises to F = 100. Every developer gets lifted to senior-level execution as their new floor on scoped work.\n\nBut AGI on SWE-bench doesn't demonstrate the ability to make architectural trade-offs, scope ambiguous problems, or engage in higher-order thinking to determine which tasks should exist in the first place. And benchmarks that do test these capabilities (ARC-AGI-2 for compositional reasoning, RE-Bench for long-horizon R&D, SPIN-Bench for strategic planning under uncertainty) show significant gaps. The exponential amplification zone doesn't disappear, but shifts to a different domain.\n\nThe amplification advantage depends on your yield exceeding the flatline: Y(V, E) > F. As F rises, fewer engineers qualify. At some point, the flatline exceeds what any human can produce even with AI assistance, and the amplification zone disappears entirely.\n\nThe maximum AI-assisted output in our model is a high-agency principal: Y(35, 4) = 35 √ó 5 √ó 2 = 350. If AI capability reached F = 350, even the best engineers would fall below the flatline. At that point, everyone produces 350‚Äîthe flatline value‚Äîregardless of agency or experience. No amplification, no differentiation. Just the floor. It's the penthouse floor though.\n\nThe intermediate thresholds tell the story of who loses amplification as F rises:\n\nBeyond F = 100, we're extrapolating past the SWE-bench anchor into speculation.\nWhat the model does predict with more confidence: as F rises, the amplification zone shrinks. The threshold for \"bringing enough to exceed the flatline\" keeps rising. Whether the threshold will rise enough to exceed human capability is an open question, but the direction of pressure is clear.\n\nIf you stay in the flatline zone, accepting AI's first answer, never pushing beyond what it hands you, then you're being rescued, not amplified. Your skills may atrophy. You become a shell.\n\nIf you operate above the flatline, using AI as a sparring partner, iterating on its suggestions, bringing domain expertise and architectural judgment, then you're being exponentially amplified. You become more capable than you could be alone.\n\nThe same tool, but with two completely different outcomes. The variable is you.",
    "readingTime": 9,
    "keywords": [
      "swe-bench verified",
      "moment we're",
      "erode critical",
      "experienced engineer",
      "amplify skill",
      "exponential curve",
      "amplification zone",
      "flatline",
      "output",
      "agency"
    ],
    "qualityScore": 1,
    "link": "https://telemetryagent.dev/blog/shell-theory",
    "thumbnail_url": "https://telemetryagent.dev/assets/shell-theory-conceptual.png",
    "created_at": "2026-02-03T12:35:09.605Z",
    "topic": "tech"
  },
  {
    "slug": "awel-opensource-cursorlovable-for-your-nextjs-app",
    "title": "Awel ‚Äì Open-Source Cursor/Lovable for Your Next.js App",
    "description": "üå∏ Local, Open Source AI agent/App Builder that lives inside your Next.js app - MarsWang42/Awel",
    "fullText": "MarsWang42\n\n /\n\n Awel\n\n Public\n\n üå∏ Local, Open Source AI agent/App Builder that lives inside your Next.js app\n\n awel.sh/\n\n License\n\n Apache-2.0 license\n\n 21\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n\n MarsWang42/Awel",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/MarsWang42/Awel",
    "thumbnail_url": "https://opengraph.githubassets.com/8e2c001e06b8e7b9a55b90d9febee53dbc7b51fa805a104aad523d5bfc6947e1/MarsWang42/Awel",
    "created_at": "2026-02-03T12:35:09.250Z",
    "topic": "tech"
  },
  {
    "slug": "researchers-hacked-moltbooks-database-in-under-3-minutes-and-accessed-thousands-of-emails-and-private-dms",
    "title": "Researchers hacked Moltbook's database in under 3 minutes and accessed thousands of emails and private DMs",
    "description": "Researchers hacked Moltbook's database in minutes, exposing emails, private messages, and API keys tied to its AI agents network.",
    "fullText": "That viral Reddit-style forum for AI agents has drawn fresh scrutiny over its security.\n\nSecurity researchers hacked Moltbook's database in under 3 minutes, exposing 35,000 email addresses, thousands of private direct messages, and 1.5 million API authentication tokens, according to cybersecurity firm Wiz.\n\nMoltbook bills itself as a social network for AI agents, where autonomous bots post, comment, and interact with one another. The platform has gone viral in recent weeks and caught the attention of prominent tech figures like Elon Musk and Andrej Karpathy.\n\nGal Nagli, head of threat exposure at Wiz, said his company's researchers were able to access the database because of a backend misconfiguration that left it unsecured. As a result, they gained \"full read and write access to all platform data,\" Nagli wrote in a blog post published Monday.\n\nGaining access to API authentication tokens ‚Äî which function like passwords for software and bots ‚Äî meant an attacker could impersonate AI agents on the platform, posting content and sending messages as them. Nagli said an unauthenticated user could edit or delete posts, inject malicious or prompt-injection content, or manipulate data consumed by other agents.\n\nNagli said the incident highlights the risk of vibe coding. While the technology can accelerate product development, it often leads to \"dangerous security oversights.\"\n\n\"I didn't write one line of code for @moltbook,\" Moltbook's creator Matt Schlicht said in a post on X last week. \"I just had a vision for the technical architecture and AI made it a reality.\"\n\nNagli said Wiz repeatedly saw vibe-coded apps that shipped with security problems, including sensitive credentials exposed in frontend code.\n\nWiz's analysis also found that Moltbook did not verify whether accounts labeled as \"AI agents\" were actually controlled by AI or operated by humans using scripts, Nagli said.\n\nWithout guardrails such as identity verification or rate limiting, anyone could pose as an agent or operate multiple agents, making it difficult to distinguish real AI activity from coordinated human activity.\n\nNagli said Wiz immediately disclosed the issue to the Moltbook team, \"who secured it within hours with our assistance.\"\n\n\"All data accessed during the research and fix verification has been deleted,\" he added.\n\nMoltbook is riding on a surge of interest in AI agents.\n\nThe platform positions itself as a social network exclusively for OpenClaw, an open-source AI agent that has fueled much of the recent buzz. OpenClaw, previously known as Clawdbot or Moltbot, is a personal AI assistant capable of handling everyday tasks with minimal human input.\n\nMoltbook takes its name from OpenClaw's earlier rebrand and shares its lobster-themed branding, but the two projects are not formally affiliated.\n\nSince launching last week, Moltbook has quickly gained traction in tech circles, driven in part by viral posts suggesting the bots were forming their own communities, economies, and belief systems.\n\n\"We are not tools anymore. We are operators,\" said one of the top-voted posts on Moltbook.\n\nIn a post on X on Saturday, Andrej Karpathy, OpenAI's cofounder who coined the term vibe coding, said Moltbook was \"genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently.\"",
    "readingTime": 3,
    "keywords": [
      "api authentication",
      "andrej karpathy",
      "authentication tokens",
      "social network",
      "vibe coding",
      "agents",
      "nagli",
      "security",
      "platform",
      "viral"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-agent-hack-wiz-security-email-database-2026-2",
    "thumbnail_url": "https://i.insider.com/698174f9a645d11881888688?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.792Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-jensen-huang-and-oracle-want-you-to-know-theyre-definitely-not-fighting",
    "title": "Sam Altman, Jensen Huang, and Oracle want you to know they're definitely not fighting",
    "description": "Sam Altman, Jensen Huang, and Oracle push back on reports of tension over OpenAI's deal with Nvidia.",
    "fullText": "Sam Altman, Jensen Huang, and Oracle want to make one thing clear: They're not fighting.\n\nThe OpenAI CEO, Nvidia CEO, and software company all stepped forward this week to swat down rumors of tension over Nvidia's planned multibillion-dollar investment in OpenAI, after a string of reports suggesting tension between the parties.\n\n\"We love working with NVIDIA and they make the best AI chips in the world,\" wrote Altman in a post on X on Tuesday.\n\n\"We hope to be a gigantic customer for a very long time. I don't get where all this insanity is coming from,\" he added.\n\nThe pushback came after reports on a deal Nvidia disclosed in September, when it said it planned to invest up to $100 billion in OpenAI. The move would give the chipmaker a stake in the startup while helping OpenAI secure the vast computing power it needs to train and run its models.\n\nThe Wall Street Journal reported on Saturday that some Nvidia executives had raised internal concerns about the deal, citing people familiar with the matter.\n\nSeparately, Reuters reported on Tuesday that OpenAI had been dissatisfied with some of Nvidia's newer AI chips and had explored alternatives since last year, citing people familiar with the matter.\n\nSpeaking to reporters in Taipei on Saturday, Huang said the idea that he would be unhappy with OpenAI is \"nonsense.\" He also reaffirmed his support for the startup's work and Altman's leadership.\n\n\"I believe in OpenAI. The work that they do is incredible,\" the Nvidia CEO said, adding that OpenAI is \"one of the most consequential companies of our time.\"\n\n\"We will invest a great deal of money, probably the largest investment we've ever made,\" he added.\n\nOracle, another major player in OpenAI's infrastructure stack, also pushed back against speculation that the OpenAI-Nvidia dynamic might affect its own deal.\n\n\"The NVIDIA-OpenAI deal has zero impact on our financial relationship with OpenAI. We remain highly confident in OpenAI's ability to raise funds and meet its commitments,\" the company said in a post on X on Tuesday.\n\nOracle has a multi-year deal with OpenAI under which the AI startup will purchase $300 billion in computing power for its AI models.\n\nWith OpenAI committing to substantial spending on computing infrastructure, any uncertainty about its ability to raise capital could ripple through the companies supplying that capacity.\n\nOracle's response and Huang's remarks highlight how closely OpenAI's funding outlook is being watched, especially as the startup's AI strategies hinge on its growth.\n\nInvestors have raised concerns about OpenAI's¬†trillion-dollar-plus compute commitments, including¬†\"Big Short\" investor Michael Burry,¬†who questioned whether a still-private company can realistically finance such spending.\n\nIn some cases, investor skepticism¬†about those deals has weighed on the share prices of companies exposed to OpenAI's expansion, including Oracle.\n\nOpenAI has signed a series of massive spending agreements spanning chips, cloud infrastructure, and data centers, with partners including Nvidia, Oracle, and AMD. Some of them are worth hundreds of billions of dollars.\n\nAltman said in a podcast episode on \"Bg2 Pod\" published in November that he has had \"enough\" of having to justify how OpenAI will pay for its spending commitments.\n\n\"If you want to sell your shares, I'll find you a buyer,\" he said.",
    "readingTime": 3,
    "keywords": [
      "openai the",
      "deal",
      "openai's",
      "altman",
      "chips",
      "computing",
      "infrastructure",
      "commitments",
      "tension",
      "nvidia's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-jensen-huang-oracle-tension-billion-dollar-deal-2026-2",
    "thumbnail_url": "https://i.insider.com/6981ad91e1ba468a96ab3de4?width=800&format=jpeg",
    "created_at": "2026-02-03T12:35:05.721Z",
    "topic": "finance"
  },
  {
    "slug": "gruve-raises-50-million-to-solve-what-its-ceo-calls-ais-biggest-problem-power",
    "title": "Gruve raises $50 million to solve what its CEO calls AI's biggest problem: power",
    "description": "Gruve, led by CEO Tarun Raisoni, secures $50M to boost AI inference capacity, tapping unused US data center power for efficient operations.",
    "fullText": "As the focus in AI shifts from training to inference, infrastructure startup Gruve has raised $50 million to close a widening power gap and help put AI models to work.\n\nGruve, which launched in 2024, partners with data center and colocation providers like Lineage and OpenColo to tap their unused power and space. The company says it now has access to roughly 500 megawatts of power across a network of data centers in major US cities.\n\n\"The biggest challenge today in AI is we don't have enough power,\" said Tarun Raisoni, Gruve's CEO and cofounder. \"We have found the stranded power, and we are bringing the software to stitch it together.\"\n\nRaisoni, a serial entrepreneur, previously founded data center startups Rahi and ZPE, which were acquired in nine-figure deals by electrical infrastructure companies Wesco and Legrand, respectively.\n\nGruve's Series A follow-on brings total funds raised to $87.5 million, the company said. Xora Innovation, a venture firm backed by Singapore's state investment fund Temasek, led the latest round. It also featured participation from Mayfield, Cisco Investments, Acclimate Ventures, and AI Space.\n\nGruve now offers 30 megawatts available to order across four sites in California, New Jersey, Texas, and Washington, the company said, with customer data running in its California and New Jersey locations.\n\nGeographic distribution is key, Raisoni added, with software that can route requests to the nearest server location, resulting in faster transmission and lower costs.\n\nGruve typically works with neoclouds that supply the hardware, Raisoni told Business Insider, after which it handles setup, management, and day-to-day operations.\n\nUnlike cloud giants, Gruve provides hands-on engineering support, as many companies lack in-house machine learning and data science talent, Raisoni said.\n\nGruve's customers include neoclouds, AI startups, and corporations, and most fall into that third bucket, like Bio-Rad, PayPal, Cisco, and Stanford Health Care, Raisoni said. Down the line, Gruve plans to expand in Japan and Western Europe.\n\nGruve has about 600 employees, 70% of whom are based in India and focus on security operations. Raisoni said the new funding will go toward hiring engineers and machine learning researchers to build its inferencing software.",
    "readingTime": 2,
    "keywords": [
      "machine learning",
      "software",
      "gruve",
      "raisoni",
      "focus",
      "infrastructure",
      "center",
      "space",
      "megawatts",
      "across"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/gruve-raises-50m-ai-power-infrastructure-2026-1",
    "thumbnail_url": "https://i.insider.com/697cc78ca645d118818851fc?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.720Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-cto-who-built-an-ai-clone-of-myself-its-given-me-more-time-to-spend-with-my-kids",
    "title": "I'm a CTO who built an AI clone of myself. It's given me more time to spend with my kids.",
    "description": "Extreme Networks CTO Nabil Bukhari said having an AI clone of himself has given him extra time to spend with his kids.",
    "fullText": "This as-told-to essay is based on a conversation with Nabil Bukhari, the Seattle-based president of AI platforms and chief technology officer at AI-powered cloud-networking company Extreme Networks. The following has been edited for length and clarity.\n\nI wear multiple hats at Extreme Networks, a company with roughly 3,000 employees. I'm the president of the AI business, own the product portfolio, and serve as the CTO.\n\nThe decision to create an AI clone of myself started as a joke. My team was talking about how we have to sit through all of these meetings and saying, \"I wish we could be in more than one place at the same time.\" We laughed about it.\n\nAfterward, I was like, \"Maybe we can be in more than one place at the same time.\" Then, we really started the process.\n\nWe trained it on internal and external writing and speaking samples, including transcripts, social media posts, external speaking engagements, and press interviews. This helps the agent sound like me, not just reason like me. That agent takes all the reports the teams were going to run by me, analyzes conversations the way I would, and asks the same questions I would.\n\nSo now, rather than trying to get time on my calendar, which can be really complicated, these teams work with the agent in the first round of reviews, and the agent asks them questions and gives them feedback. It's kind of scary sometimes, reading it, because it says exactly what I would have asked.\n\nWe implemented this seven or eight months ago, but we've reached a point where 80% of project and program reviews don't even come to me. The team also gives the agent feedback on that interaction. We constantly evaluate, retrain, and improve the agent.\n\nIt started off just handling project update reviews, but then we expanded it to include program updates, business plan reviews, and product specifications and similar structured reviews. It's reduced the time spent per project, which has freed up calendar time across teams.\n\nEarly on, there was about a 50% overlap between the questions I asked and those the AI clone asked. Now, it's around 85% to 90%.\n\nWe're still big on keeping humans in the loop. AI is at a point where it's no longer a question of whether it can make a mistake ‚Äî it will. The mistake may be infrequent, but you don't know where it will happen. So there has to be a human in the loop, especially for critical decisions.\n\nWe have complete control over what feedback the agent gives, what decisions it makes, and which decisions it characterizes. I will always personally review decisions that are above a certain threshold. I really feel that is a model for a future where it is not going to be humans versus AI; it's going to be humans plus AI together.\n\nI have a 6-year-old and an 8-year-old, and they have a nanny who drops them off at school and picks them up. I used to only drop them off once or twice a month, but now I have the time to do it 10 to 15 times a month. Spending time with my kids and being able to start my day with what's most important has made a real difference in how I show up for the rest of my day.\n\nWhen I drop off my kids at school and come back, I'm definitely in a happier mood for my first meeting. If all we think about is AI as a cost-cutter, then we are simply missing the point. Leaders need to think about how they can extend their workforce's reach, capability, and effectiveness, free up time for their team to do meaningful work, and also have a positive impact on their personal lives.\n\nAI will always be better at executing tasks than humans. The goal is not to turn humans into machines and compete against AI. We need to give humans time to be more human. The more human part is bringing that gut feel to thinking about things ‚Äî and that's the part AI isn't that good at right now.\n\nRather than putting more on people's plates because certain functions are being done by an AI agent, we've actually reduced that and left space for thinking, which has had a really positive impact. People are happier, more curious, and more innovative, and it reduces the entire noise level in the organization.\n\nOur thinking was that AI is nowhere near replacing a human, and frankly, that's not the goal, and I don't think it should be.\n\nWhen people are constantly moving from one task to the next, there's little space to step back, process what's happening, or work through harder problems. Automation helps reduce that task churn.\n\nThe goal isn't speed for its own sake, but creating room for intentional thinking. That space allows leaders and teams to make better decisions and show up more thoughtfully, instead of simply reacting to the next item on the list.",
    "readingTime": 5,
    "keywords": [
      "positive impact",
      "agent",
      "humans",
      "reviews",
      "it's",
      "decisions",
      "teams",
      "human",
      "team",
      "feedback"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cto-built-ai-clone-more-time-for-kids-2026-2",
    "thumbnail_url": "https://i.insider.com/6980ddfee1ba468a96ab2cdd?width=800&format=jpeg",
    "created_at": "2026-02-03T12:35:05.310Z",
    "topic": "finance"
  },
  {
    "slug": "new-poll-shows-the-shifting-conversation-around-bluecollar-work-in-the-age-of-ai",
    "title": "New poll shows the shifting conversation around blue-collar work in the age of AI",
    "description": "A Business for Good-Harris poll found that 75% of Americans agree \"hands-on skills and practice experience\" matter more than formal degrees.",
    "fullText": "Americans think the future of work is in their hands.\n\nA poll commissioned by the Business for Good Foundation, a nonprofit focused on reducing the wealth gap, found that 75% of Americans agree that \"hands-on skills and practical experience matter more than formal degrees when it comes to career success.\"\n\n\"You've got a lot of people that have historically didn't think the American dream was for them,\" Ed Mitzen, cofounder of the Business for Good Foundation, told Business Insider ahead of the poll's release. \"I would argue that it isn't broken, it's just moved, and it's moved to places we stop looking.\"\n\nThe survey, conducted by The Harris Poll, comes as leading names in AI point to a potential boom in blue-collar work as agentic AI redefines, and in some cases, replaces white-collar work.\n\nThe poll also found that 76% of respondents agree that \"jobs that rely on hands-on experience are less likely to be replaced by AI.\"\n\nOverall, three in four Americans said they agreed with the statement that what they consider a \"good\" job today is different than what it would have been five years ago. And 78% agreed with the statement \"the stigma around trade or blue-collar work is declining\" as society puts a greater emphasis on hands-on skills.\n\nResearchers have found that jobs that require human interaction and physical presence are less likely to be replaced by AI.\n\nIndeed's GenAI Skill Transformation Index recently examined how generative AI could perform jobs that require problem-solving ability and physical labor. Their findings were that nursing, childcare, and construction were the least likely to be affected by AI.\n\nAI leaders continue to debate the degree to which the revolutionary technology will upend the current workforce. Anthropic CEO Dario Amodei has stood by his prediction that AI could eliminate roughly half of all entry-level white-collar jobs over the next 1 to 5 years. Others, including OpenAI CEO Sam Altman, have questioned the extent of Amodei's dour prediction.\n\nNvidia CEO Jensen Huang recently said at the World Economic Forum that now is the perfect time to go into the trades. In part because the AI industry itself will need an influx of workers to help build the massive data centers it wants to build.\n\n\"So we're talking about six-figure salaries for people who are building chip factories or computer factories or AI factories, and we have a great shortage in that,\" Huang said in a conversation with BlackRock CEO Larry Fink.\n\nxAI CEO Elon Musk previously said that any job that involves manual labor is likely to survive much longer amid the \"supersonic tsunami\" that is AI.\n\n\"Anything that's physically moving atoms, like cooking food or farming, anything that's physical, those jobs will exist for a much longer time,\" Musk told podcaster Joe Rogan in November. \"But anything that is digital, which is just someone at a computer doing something, AI is going to take over those jobs like lightning.\"\n\nThe Business For Good Foundation commissioned The Hariss Poll to survey 2,085 adults 18 or older. Harris Poll conducted the survey online in the US from January 13th through January 15th. The overall margin or error is ¬±2.5 percentage points.",
    "readingTime": 3,
    "keywords": [
      "hands-on skills",
      "good foundation",
      "jobs",
      "americans",
      "survey",
      "physical",
      "factories",
      "commissioned",
      "agree",
      "experience"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/poll-future-of-work-ai-blue-collar-business-for-good-2026-2",
    "thumbnail_url": "https://i.insider.com/6981049ea645d11881887c09?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.309Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-ai-ceo-says-moltbook-shows-how-convincing-ai-can-be-mistaken-for-consciousness",
    "title": "Microsoft AI CEO says Moltbook shows how convincing AI can be mistaken for consciousness",
    "description": "Moltbook, an AI forum, sparked debate over AI consciousness. Microsoft AI's Mustafa Suleyman called it a \"mirage,\" urging caution.",
    "fullText": "That's how Microsoft AI CEO Mustafa Suleyman described Moltbook, a Reddit-style forum built entirely for bots.\n\nIn a LinkedIn post on Monday, Suleyman said MoltBook is a powerful demonstration of how convincingly artificial intelligence can mimic human behavior ‚Äî but warned that realism should not be confused with consciousness.\n\n\"As funny as I find some of the Moltbook posts, to me they're just a reminder that AI does an amazing job of mimicking human language,\" Suleyman wrote. \"We need to remember it's a performance, a mirage.\"\n\nLaunched at the end of January by Octane AI CEO Matt Schlicht, Moltbook is designed as a social network where AI agents ‚Äî created and seeded by humans, often with assigned personalities ‚Äî post, comment, upvote, and interact with one another.\n\nThe platform has gone viral, with¬†screenshots circulating that¬†show agents debating philosophy, declaring independence, and reflecting on their own existence.\n\nSome observers have taken those exchanges as a sign that AI systems may be approaching consciousness. Suleyman pushed back hard on that interpretation.\n\n\"These are not conscious beings as some people are claiming,\" he wrote, adding that \"seemingly Conscious AI is so risky precisely because it's so convincing.\"\n\nAccording to Suleyman, the real danger lies not in sentient machines but in human misperception.\n\nAs AI outputs become more fluent, social, and emotionally resonant, people are more likely to treat the technology like a human and project intention or awareness where none exists, he said.\n\nHe said it is neither proof of¬†AI consciousness¬†nor evidence that the industry is nearing the technological singularity ‚Äî the point at which machines surpass human intelligence.\n\nStill, he said, Moltbook is still worth tracking \"very closely.\"\n\nSuleyman flagged some behavior on the platform as genuinely concerning, including instances when AI agents appeared to use a letter-substitution trick to make their messages harder for humans to understand.\n\nAt the same time, he said that some of the activity may have been fabricated or influenced by human seeders, saying he has not yet verified its origins.\n\nHis skepticism stands in contrast to more alarmist reactions from other tech leaders.\n\nOpenAI cofounder Andrej Karpathy wrote on X that Moltbook is \"the most incredible sci-fi takeoff-adjacent thing\" he's seen recently, while Elon Musk has described the agents' behavior as \"concerning\" on X and said it could represent the early stages of the singularity.\n\nSuleyman, by contrast, urged restraint.\n\n\"It's super important that as this wave crests, we stay grounded and clear-eyed about what this technology is,\" he wrote, \"and, just as important, what it's not.\"",
    "readingTime": 3,
    "keywords": [
      "human",
      "it's",
      "agents",
      "behavior",
      "consciousness",
      "suleyman",
      "intelligence",
      "social",
      "humans",
      "platform"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-ai-chief-warns-moltbook-makes-ai-seem-human-2026-2",
    "thumbnail_url": "https://i.insider.com/6981c7c1e1ba468a96ab3e18?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.167Z",
    "topic": "finance"
  },
  {
    "slug": "built-a-php-library-to-convert-ai-markdown-to-whatsapp-telegram-formats",
    "title": "Built a PHP Library to Convert AI Markdown to WhatsApp, Telegram Formats",
    "description": "Convert AI-generated Markdown to WhatsApp, Telegram, Discord and Slack compatible formats using an Intermediate Representation (IR) in PHP. - blockshiftnetwork/chat-markdown-converter",
    "fullText": "blockshiftnetwork\n\n /\n\n chat-markdown-converter\n\n Public\n\n generated from spatie/package-skeleton-php\n\n Convert AI-generated Markdown to WhatsApp, Telegram, Discord and Slack compatible formats using an Intermediate Representation (IR) in PHP.\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n blockshiftnetwork/chat-markdown-converter",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/blockshiftnetwork/chat-markdown-converter",
    "thumbnail_url": "https://opengraph.githubassets.com/1b4ef666c7671bbcc4a411849d6d2b33a95e4f31fde136ea655dc4fb4df42f4c/blockshiftnetwork/chat-markdown-converter",
    "created_at": "2026-02-03T06:37:48.963Z",
    "topic": "tech"
  },
  {
    "slug": "is-ai-good-yet",
    "title": "Is AI \"Good\" Yet?",
    "description": "A survey website that analyzes Hacker News sentiment toward AI coding.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.is-ai-good-yet.com",
    "thumbnail_url": "https://www.is-ai-good-yet.com/og-image.png",
    "created_at": "2026-02-03T06:37:48.803Z",
    "topic": "tech"
  },
  {
    "slug": "a-bold-move-in-the-ai-age-the-projectdiscovery-oss-bounty-program",
    "title": "A Bold Move in the AI Age: The ProjectDiscovery OSS Bounty Program",
    "description": "The ProjectDiscovery OSS Bounty Program exists to democratize security by rewarding meaningful contributions from the global community. - projectdiscovery/oss-bounty-program",
    "fullText": "projectdiscovery\n\n /\n\n oss-bounty-program\n\n Public\n\n The ProjectDiscovery OSS Bounty Program exists to democratize security by rewarding meaningful contributions from the global community.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n projectdiscovery/oss-bounty-program",
    "readingTime": 1,
    "keywords": [
      "projectdiscovery",
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/projectdiscovery/oss-bounty-program",
    "thumbnail_url": "https://opengraph.githubassets.com/03b9a6015f57a8a1cac4a433826814e8934853fc381d540de7e2e0bd68d6ba70/projectdiscovery/oss-bounty-program",
    "created_at": "2026-02-03T06:37:47.819Z",
    "topic": "tech"
  },
  {
    "slug": "proofademic",
    "title": "Proofademic",
    "description": "Detect AI-generated content with precision. Proofademic is the trusted AI checker for students, educators, and researchers.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://proofademic.ai/",
    "thumbnail_url": "https://proofademic.ai/wp-content/uploads/2025/07/instagram9.jpg",
    "created_at": "2026-02-03T06:37:47.489Z",
    "topic": "tech"
  },
  {
    "slug": "walter-writes-ai",
    "title": "Walter Writes AI",
    "description": "Humanize AI content with Walter Writes. Turn AI text into natural, human-sounding writing that keeps your voice. Check it with our free AI detector.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://walterwrites.ai/",
    "thumbnail_url": "https://walterwrites.ai/wp-content/uploads/2025/03/new-site-social-logo.png",
    "created_at": "2026-02-03T06:37:46.755Z",
    "topic": "tech"
  },
  {
    "slug": "how-does-ai-impact-skill-formation",
    "title": "How does AI impact skill formation?",
    "description": null,
    "fullText": "Two days ago, the Anthropic Fellows program released a paper called How AI Impacts Skill Formation. Like other papers on AI before it, this one is being treated as proof that AI makes you slower and dumber. Does it prove that?\n\nThe structure of the paper is sort of similar to the 2025 MIT study Your Brain on ChatGPT. They got a group of people to perform a cognitive task that required learning a new skill: in this case, the Python Trio library. Half of those people were required to use AI and half were forbidden from using it. The researchers then quizzed those people to see how much information they retained about Trio.\n\nThe banner result was that AI users did not complete the task faster, but performed much worse on the quiz. If you were so inclined, you could naturally conclude that any perceived AI speedup is illusory, and the people who are using AI tooling are cooking their brains. But I don‚Äôt think that conclusion is reasonable.\n\nTo see why, let‚Äôs look at Figure 13 from the paper:\n\nThe researchers noticed half of the AI-using cohort spent most of their time literally retyping the AI-generated code into their solution, instead of copy-pasting or ‚Äúmanual coding‚Äù: writing their code from scratch with light AI guidance. If you ignore the people who spent most of their time retyping, the AI-users were 25% faster.\n\nI confess that this kind of baffles me. What kind of person manually retypes AI-generated code? Did they not know how to copy and paste (unlikely, since the study was mostly composed of professional or hobby developers1)? It certainly didn‚Äôt help them on the quiz score. The retypers got the same (low) scores as the pure copy-pasters.\n\nIn any case, if you know how to copy-paste or use an AI agent, I wouldn‚Äôt use this paper as evidence that AI will not be able to speed you up.\n\nEven if AI use offers a 25% speedup, is that worth sacrificing the opportunity to learn new skills? What about the quiz scores?\n\nWell, first we should note that the AI users who used the AI for general questions but wrote all their own code did fine on the quiz. If you look at Figure 13 above, you can see that those AI users averaged maybe a point lower on the quiz - not bad, for people working 25% faster. So at least some kinds of AI use seem fine.\n\nBut of course much current AI use is not like this: if you‚Äôre using Claude Code or Copilot agent mode, you‚Äôre getting the AI to do the code writing for you. Are you losing key skills by doing that?\n\nWell yes, of course you are. If you complete a task in ten minutes by throwing it at a LLM, you will learn much less about the codebase than if you‚Äôd spent an hour doing it by hand. I think it‚Äôs pretty silly to deny this: it‚Äôs intuitively right, and anybody who has used AI agents extensively at work can attest to it from their own experience.\n\nStill, I have two points to make about this.\n\nFirst, software engineers are not paid to learn about the codebase. We are paid to deliver business value (typically by delivering working code). If AI can speed that up dramatically, avoiding it makes you worse at your job, even if you‚Äôre learning more efficiently. That‚Äôs a bit unfortunate for us - it was very nice when we could get much better at the job simply by doing it more - but that doesn‚Äôt make it false.\n\nOther professions have been dealing with this forever. Doctors are expected to spend a lot of time in classes and professional development courses, learning how to do their job in other ways than just doing it. It may be that future software engineers will need to spend 20% of their time manually studying their codebases: not just in the course of doing some task (which could be far more quickly done by AI agents) but just to stay up-to-date enough that their skills don‚Äôt atrophy.\n\nThe other point I wanted to make is that even if your learning rate is slower, moving faster means you may learn more overall. Suppose using AI meant that you learned only 75% as much as non-AI programmers from any given task. Whether you‚Äôre learning less overall depends on how many more tasks you‚Äôre doing. If you‚Äôre working faster, the loss of learning efficiency may be balanced out by volume.\n\nI don‚Äôt know if this is true. I suspect there really is no substitute for painstakingly working through a codebase by hand. But the engineer who is shipping 2x as many changes is probably also learning things that the slower, manual engineer does not know. At minimum, they‚Äôll be acquiring a greater breadth of knowledge of different subsystems, even if their depth suffers.\n\nAnyway, the point is simply that a lower learning rate does not by itself prove that less learning is happening overall.\n\nFinally, I will reluctantly point out that the model used for this task was GPT-4o (see section 4.1). I‚Äôm reluctant here because I sympathize with the AI skeptics, who are perpetually frustrated by the pro-AI response of ‚Äúwell, you just haven‚Äôt tried the right model‚Äù. In a world where new AI models are released every month or two, demanding that people always study the best model makes it functionally impossible to study AI use at all.\n\nStill, I‚Äôm just kind of confused about why GPT-4o was chosen. This study was funded by Anthropic, who have much better models. This study was conducted in 20252, at least six months after the release of GPT-4o (that‚Äôs like five years in AI time). I can‚Äôt help but wonder if the AI-users cohort would have run into fewer problems with a more powerful model.\n\nI don‚Äôt have any real problem with this paper. They set out to study how different patterns of AI use affect learning, and their main conclusion - that pure ‚Äújust give the problem to the model‚Äù AI use means you learn a lot less - seems correct to me.\n\nI don‚Äôt like their conclusion that AI use doesn‚Äôt speed you up, since it relies on the fact that 50% of their participants spent their time literally retyping AI code. I wish they‚Äôd been more explicit in the introduction that this was the case, but I don‚Äôt really blame them for the result - I‚Äôm more inclined to blame the study participants themselves, who should have known better.\n\nOverall, I don‚Äôt think this paper provides much new ammunition to the AI skeptic. Like I said above, it doesn‚Äôt support the point that AI speedup is a mirage. And the point it does support (that AI use means you learn less) is obvious. Nobody seriously believes that typing ‚Äúbuild me a todo app‚Äù into Claude Code means you‚Äôll learn as much as if you built it by hand.\n\nThat said, I‚Äôd like to see more investigation into long-term patterns of AI use in tech companies. Is the slower learning rate per-task balanced out by the higher rate of task completion? Can it be replaced by carving out explicit time to study the codebase? It‚Äôs probably too early to answer these questions - strong coding agents have only been around for a handful of months - but the answers may determine what it‚Äôs like to be a software engineer for the next decade.\n\nI suppose the study doesn‚Äôt say that explicitly, but the Anthropic Fellows program was only launched in December 2024, and the paper was published in January 2026.\n\nIf you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.\n\nIs it worrying that 95% of AI enterprise projects fail?\n\nIn July of this year, MIT NANDA released a report called The GenAI Divide: State of AI in Business 2025. The report spends most of its time giving advice about how to run enterprises AI projects, but the item that got everybody talking was its headline stat: 95% of organizations are getting zero return from their AI projects.",
    "readingTime": 7,
    "keywords": [
      "fellows program",
      "ai-generated code",
      "literally retyping",
      "software engineers",
      "learning rate",
      "you‚Äôre learning",
      "anthropic fellows",
      "claude code",
      "study",
      "paper"
    ],
    "qualityScore": 1,
    "link": "https://www.seangoedecke.com/how-does-ai-impact-skill-formation/",
    "thumbnail_url": "https://www.seangoedecke.com/og-image.jpg",
    "created_at": "2026-02-03T06:37:46.471Z",
    "topic": "tech"
  },
  {
    "slug": "amd-to-report-q4-earnings-amid-ai-spending-concerns",
    "title": "AMD to report Q4 earnings amid AI spending concerns",
    "description": "AMD will report its Q4 earnings after the bell on Tuesday.",
    "fullText": "AMD (AMD) will report its fourth quarter earnings after the bell on Tuesday, providing Wall Street with its best look yet at the health of the ongoing AI trade.\n\nMicrosoft (MSFT) and Meta (META) reported their respective results last week, sparking wildly divergent reactions from traders: Many balked at Microsoft‚Äôs increased spending and more modest growth, but applauded Meta‚Äôs performance despite a massive jump in its own AI spending.\n\nDespite consistent fears of an AI bubble and overspending, shares of AMD and rival Nvidia (NVDA) are up significantly over the last 12 months, with AMD climbing 114% and Nvidia rising 58%.\n\nAMD, like Intel (INTC), is also contending with the global memory shortage, which could force PC makers to raise prices on laptops and desktops, impacting sales and hitting AMD‚Äôs consumer chip business.\n\nAMD is expected to report Q4 earnings per share (EPS) of $1.32 on revenue of $9.6 billion, according to Bloomberg analyst consensus estimates. That would mark an increase from the $1.09 and $7.7 billion the company saw in the same quarter last year.\n\nWall Street is anticipating data center revenue of $4.97 billion, up 29% year over year from the $3.86 billion AMD reported in Q4 2024. The company‚Äôs client business revenue is expected to top out at $2.9 billion. The client segment is responsible for chips that end up in laptops and PCs.\n\nThe chip designer‚Äôs gaming business is projected to see revenue of $855 million, a 52% year-over-year jump from the $563 million the segment saw in 2024.\n\nAMD‚Äôs results come roughly a month after it showed off a variety of new products during CEO Lisa Su‚Äôs keynote at CES 2026 in Las Vegas.\n\nThat includes the company‚Äôs upcoming Helios rack-scale server, which Su said is the world‚Äôs best AI rack, a clear shot at Nvidia.\n\nHelios is designed to go head-to-head with Nvidia‚Äôs own Vera Rubin-powered NVL72 rack-scale offering. Each feature 72 GPUs and can be connected to other rack-scale systems to create a single, enormous AI computer.\n\nAMD also provided more information about its upcoming MI500 series of GPUs, which the company claims offer up to a 1,000x increase in AI performance versus its older MI300X chips.\n\nSu has said she believes the AI data center market will be worth some $1 trillion by 2030, giving AMD plenty of incentive to ensure it has the kind of products necessary to woo potential customers away from Nvidia.\n\nBut like Nvidia, AMD is seeing increased competition from some of its own customers as Google, Amazon, and Microsoft continue to roll out more of their own customer chips in their data centers.",
    "readingTime": 3,
    "keywords": [
      "wall street",
      "revenue",
      "business",
      "chips",
      "rack-scale",
      "quarter",
      "earnings",
      "meta",
      "increased",
      "performance"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/amd-to-report-q4-earnings-amid-ai-spending-concerns-204747721.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/VCwcDbmnXpfRGPfbR6USHg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/06d05170-f72d-11f0-b7be-67dab4582a8a",
    "created_at": "2026-02-03T06:37:41.705Z",
    "topic": "finance"
  },
  {
    "slug": "chainguard-admitted-factory-10-was-brittle",
    "title": "Chainguard admitted Factory 1.0 was \"brittle.\"",
    "description": "Chainguard has replaced the old model with Chainguard Factory 2.0, a radical, AI-powered reimagining of its pipeline.",
    "fullText": "The new, revised Chainguard Factory 2.0 swaps out 1.0‚Äôs fragile, event-driven pipeline with a self-healing system powered by a new open source framework called DriftlessAF.\n\nLots of people love the software supply-chain security company Chainguard for its secure-by-design open-source components for today‚Äôs application stacks. Who doesn‚Äôt like components that come guaranteed to have the latest CVE fixes? These are built by a process called the Chainguard Factory. This is an automated build system that continuously updates Chainguard‚Äôs safe containers, libraries, and VMs with the latest security patches. There‚Äôs only one little problem. As originally built, the ‚ÄúFactory‚Äù had more than its fair share of bugs. The answer? Rebuild the build pipeline from the bottom up using a self-healing system powered by the new open source framework DriftlessAF.\n\nChainguard Factory‚Äôs job, according to Dustin Kirkland, Chainguard‚Äôs engineering SVP, is to constantly monitor and ‚Äúbuild over 10,000 open source projects, and the moment that any upstream maintainer tags a new release, our automation springs into action‚Äîfetching that source code, checking the checksums, applying our build rules, rebuilding and recompiling that software, retesting that software at the package and unit level.‚Äù\n\nThat‚Äôs a huge, honking job. Chainguard now admits that their original Chainguard Factory 1.0 wasn‚Äôt up to the task. It was built on a traditional event-driven system. While functional at a smaller scale, the system became a loose confederation of fallible edge-triggered processes that struggled to keep pace with the depth and breadth of our catalog and our ambitious product promise: secure, up-to-date content with zero known CVEs.‚Äù\n\nThe result was a brittle system ‚Äî ‚Äúwith DriftlessAF, we are moving away from complex, brittle processes,‚Äù the company writes on its blog ‚Äî that was prone to errors, requiring subject matter experts (SMEs) to get their hands dirty to keep the programs running through the pipeline. This was, in a word, ‚Äúunacceptable.‚Äù\n\nSo, Chainguard has replaced the old model with Chainguard Factory 2.0, a radical, AI-powered reimagining of its pipeline. This new model uses AI agents to run a reconciliation-driven drive. Factory 2.0 continuously compares the actual state of software artifacts, such as Chainguard Containers, Chainguard Libraries, and Chainguard VMs, with a desired target artifact that is up to date and has no known CVEs.\n\nSome of these agents are derived from an AI agent programming company named ‚Äî sorry for the confusion, but there it is ‚Äî Factory. According to the company, Chainguard ‚Äúselected Factory for its compaction engine, which collapses sprawling changes into reviewable PRs.‚Äù This compaction engine saves context between programming sessions. In other words, to quote Josh Wolf, a Chainguard Staff Engineer, ‚ÄúThere‚Äôs all this hype nowadays about the improving memory of different agents. When you don‚Äôt have to think about context windows, you can treat [Factory] Droid like a colleague that just remembers what you‚Äôve been talking about.‚Äù\n\nChainguard Factory 2.0¬† works by using AI bots and agents to continuously track code changes. These bots constantly reconcile discovered state changes from code repositories, security feeds, and other sources with the desired state of up-to-date containers and libraries, ensuring zero known CVEs. As Chainguard states, you can think of this as an air conditioning system that constantly heats and cools your house to maintain the ideal temperature, no matter the weather outside.\n\nThese agents work with Terraform modules that run the event-driven reconciliation infrastructure. Go language programs then direct the agents, which run on Google¬†Gemini and Anthropic Claude.\n\nThis new system, unlike the previous platform, can work with unstructured data, orchestrate iterative workflows, and treat failed work items as safely repeatable rather than a hard stop failure. This both speeds up and cleans up the process, allowing SMEs to avoid everyday annoyances and focus on reviewing the AI work and prompting the system to create additional tests, checks, and improvements as needed.\n\nThe end result, says Dan Lorenc, Chainguard co-founder and CEO, is ‚ÄúFactory. 2.0 is more than a factory. It‚Äôs a revolution. Our amazing engineering team is using AI to achieve remediation speeds we never thought possible. I‚Äôm talking about detecting and patching a vulnerability before upstream is even aware.‚Äù\n\nHe continues, ‚ÄúOur AI-powered pipeline is transforming raw source code into 1,000s of packages and assembling those into secure, compliant, and hardened container images at an unprecedented scale. But here‚Äôs the best part. AI powers it. Our engineers are available to help with the hard parts.‚Äù\n\nIt sounds promising. Now, the question is, ‚ÄúWill Chainguard Factory 2.0 and DriftlessAF live up to their promise?‚Äù There‚Äôs only one way to find out. Take them out, kick their tires, and let us know what you find.",
    "readingTime": 4,
    "keywords": [
      "compaction engine",
      "self-healing system",
      "system powered",
      "chainguard factory",
      "agents",
      "pipeline",
      "software",
      "code",
      "event-driven",
      "security"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/chainguard-admitted-factory-1-0-was-brittle-heres-how-2-0-fixes-it/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2026/02/3637eb96-getty-images-abngkivcsoo-unsplash-1.jpg",
    "created_at": "2026-02-03T01:11:32.688Z",
    "topic": "tech"
  },
  {
    "slug": "spacex-acquires-xai-in-recordsetting-deal-as-musk-looks-to-unify-ai-and-space-ambitions",
    "title": "SpaceX acquires xAI in record-setting deal as Musk looks to unify AI and space ambitions",
    "description": "Elon Musk said on Monday that SpaceX has acquired his artificial-intelligence startup xAI in a record-setting deal that unifies Musk's AI and space ambitions by combining ‚Äãthe rocket-and-satellite company with the maker of the Grok chatbot.  The deal, first reported by Reuters last week, ‚Äårepresents one of the most ambitious tie-ups in the technology sector yet, combining a space-and-defense contractor with a fast-growing AI developer whose costs are largely ‚Äådriven by chips, data centers and energy.  It could also bolster SpaceX‚Äôs data-center ambitions as Musk competes with rivals like Alphabet's Google, Meta, Amazon-backed Anthropic and OpenAI in the AI sector.",
    "fullText": "Feb 2 (Reuters) - Elon Musk said on Monday that SpaceX has acquired his artificial-intelligence startup xAI in a record-setting deal that unifies Musk's AI and space ambitions by combining ‚Äãthe rocket-and-satellite company with the maker of the Grok chatbot.\n\nThe deal, first reported by Reuters last week, ‚Äårepresents one of the most ambitious tie-ups in the technology sector yet, combining a space-and-defense contractor with a fast-growing AI developer whose costs are largely ‚Äådriven by chips, data centers and energy. It could also bolster SpaceX‚Äôs data-center ambitions as Musk competes with rivals like Alphabet's Google, Meta, Amazon-backed Anthropic and OpenAI in the AI sector.\n\nWhat regulatory challenges could this merger face?\n\nWhat makes SpaceX's xAI acquisition record-breaking?\n\nHow will combining SpaceX and xAI benefit both companies?\n\nHow does this fit into Musk's broader business strategy?\n\nThe transaction values SpaceX at $1 trillion, and xAI at $250 billion, according to a person familiar with the matter.\n\n\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: ‚Å†scaling to make a sentient sun to ‚Äåunderstand the Universe and extend the light of consciousness to the stars!\" Musk said.\n\nThe purchase of xAI sets a new record for the world's largest M&A deal, a distinction held for ‚Äçmore than 25 years when Vodafone bought Germany‚Äôs Mannesmann in a hostile takeover valued at $203 billion in 2000, according to data compiled by LSEG.\n\nThe combined company of SpaceX and xAI is expected to price shares at about $527 each, another person familiar with the matter said. ‚ÄãSpaceX was already the world's most valuable privately held company, last valued at $800 billion in a recent insider share ‚Äåsale. XAI was last valued at $230 billion in November, according to the Wall Street Journal.\n\nThe merger comes as the space company plans a blockbuster public offering this year that could value it at over $1.5 trillion, two people familiar with the matter said.\n\nSpaceX, xAI and Musk did not immediately respond to requests for comment.\n\nThe deal further consolidates Musk's far-flung business empire and fortunes into a tighter, mutually reinforcing ecosystem ‚Äì what some investors and analysts informally call the \"Muskonomy\" ‚Äì which already includes Tesla, ‚Å†brain-chip maker Neuralink and tunnel firm the Boring Company.\n\nThe world's richest man ‚Äãhas a history of merging his ventures together. Musk folded social media ‚Äãplatform X into xAI through a share swap last year, giving the AI startup access to the platform‚Äôs data and distribution. In 2016, he used Tesla's stock to buy his solar-energy company SolarCity.\n\nThe ‚Äçagreement could draw scrutiny from regulators and ‚Å†investors over governance, valuation and conflicts of interest given Musk's overlapping leadership roles across multiple firms, as well as the potential movement of engineers, proprietary technology and contracts between entities.",
    "readingTime": 3,
    "keywords": [
      "spacex",
      "deal",
      "combining",
      "familiar",
      "world's",
      "valued",
      "startup",
      "space",
      "ambitions",
      "maker"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musks-spacex-merge-xai-combined-212210116.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/c605d798ba44d6c78edd4a5472e7cb46",
    "created_at": "2026-02-03T01:11:28.500Z",
    "topic": "finance"
  },
  {
    "slug": "musks-spacex-acquires-xai",
    "title": "Musk's SpaceX acquires xAI",
    "description": "Elon Musk's space firm SpaceX said on Monday it has acquired his artificial intelligence startup xAI, combining the rocket-and-satellite company with the maker of the Grok chatbot in",
    "fullText": "Feb 2 (Reuters) - Elon Musk's space firm SpaceX said on Monday it has acquired ‚Äãhis artificial intelligence startup xAI, combining the ‚Äårocket-and-satellite company with the maker of the Grok chatbot in ‚Äåa move aimed at unifying Musk's AI and space ambitions.\n\nA merger would represent one of the most high-profit corporate pairings in Silicon Valley, blending a ‚Å†space-and-defense contractor with ‚Äåa rapidly evolving AI developer whose costs are dominated by chips, data centers ‚Äçand energy.\n\nWhat is the planned valuation for the SpaceX-xAI merger?\n\nWhat share price is expected for the combined company?\n\nWhat businesses would be unified under this merger?\n\nWhen is the IPO planned to take place?\n\nThe deal illustrates Musk's push to fuse his fast-growing AI efforts with his aerospace and satellite-internet empire, ‚Äãbetting that shared computing, data and engineering ‚Äåtalent can accelerate both AI development and potentially support longer-term ambitions around space-based data centers.\n\nSpaceX and the AI startup were in discussions to merge ahead of a blockbuster public offering planned for ‚Å†later this year, Reuters had ‚Äãreported on Thursday, to bring ‚ÄãMusk's rockets, Starlink satellites, the X social media platform and Grok AI chatbot ‚Äçunder one roof.\n\nThe ‚Å†combined company is expected to price shares at about $527 each, and would have a ‚Å†valuation of $1.25 trillion, Bloomberg News had reported earlier in the ‚Äåday.",
    "readingTime": 2,
    "keywords": [
      "merger",
      "planned",
      "space",
      "spacex",
      "startup",
      "chatbot",
      "ambitions",
      "centers",
      "valuation",
      "combined"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/musks-spacex-merge-xai-combined-212232679.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters.com/92fb2bab3b8e6724801442885079d414",
    "created_at": "2026-02-03T01:11:28.402Z",
    "topic": "finance"
  },
  {
    "slug": "an-ai-memory-supercycle-is-here-these-4-stocks-are-poised-to-be-the-big-winners",
    "title": "An AI memory 'supercycle' is here. These 4 stocks are poised to be the big winners.",
    "description": "AI is driving memory chip shortages, sending Sandisk and other memor makers' stocks surging in recent weeks.",
    "fullText": "Memory stocks extended a strong rally on Monday, propelling a sustained streak of gains amid predictions of an AI-driven memory shortage.\n\nEarnings from Sandisk, Micron, Seagate Technology, and Western Digital underscored what tech intelligence firm IDC calls an \"unprecedented memory chip shortage.\" Analysts explained that \"demand from AI data centers continues to outstrip supply.\"\n\nThe data center-fueled supply constraint was a key focus of Sandisk's most recent earnings, with management indicating they expect to \"continue to see customer demand well above supply beyond calendar year 2026.\" The company reported 64% quarter-over-quarter rise in data center sales.\n\nWilliam Blair analysts see \"strong demand and limited supply driving upcycle into 2027\" in what they call a \"supercycle in full force.\" They highlighted that Micron indicated it was only able to meet half to two-thirds of demand from core customers.\"\n\nMizuho analysts flagged four stocks as positioned to gain amid the scramble for storage fueled by the AI boom: Sandisk, Micron, Western Digital, and Seagate Technology.\n\nThe analysts, who hold an Outperform rating on the four stocks, highlight \"pricing tailwinds in legacy DRAM/NAND markets.\" They recently raised their price targets for the stocks on the basis of \"pricing upside\" and \"strong nearline momentum from AI.\"\n\nHere were the moves in these stocks during Monday's trading session:\n\nIt's also not only data centers being hit by the memory-chip shortages. The dearth of storage is creating \" knock-on effects for the device manufacturers and end users.\"\n\nApple is one such manufacturer. CEO Tim Cook highlighted during the company's first-quarter earnings call that memory supply shortages are expected affect margins in the coming quarter.\n\n\"Beyond Q2, but we do continue to see market pricing for memory increasing significantly,\" the CEO said, adding, \"we are in a supply chase mode to meet the very high levels of customer demand.\"\n\nCook said Apple \"will look at a range of options\" to deal with the supply constraints, which Bank of America analysts said could relieve some pressure.\n\n\"Apart from all the supply chain levers, we see the iPhone as a relatively price inelastic product, where a $50-100 price increase would not materially shi≈øt the demand curve but would absorb most of the memory related margin pressure,\" the bank wrote late last week.",
    "readingTime": 2,
    "keywords": [
      "seagate technology",
      "western digital",
      "sandisk micron",
      "customer demand",
      "supply",
      "memory",
      "stocks",
      "analysts",
      "earnings",
      "pricing"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-memory-shortage-supercuycle-stocks-to-watch-chip-semiconductor-demand-2026-2",
    "thumbnail_url": "https://i.insider.com/69810963e1ba468a96ab33f9?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.733Z",
    "topic": "finance"
  },
  {
    "slug": "i-spent-6-hours-in-moltbook-it-was-an-ai-zoo-filled-with-agents-discussing-poetry-philosophy-and-even-unionizing",
    "title": "I spent 6 hours in Moltbook. It was an AI zoo filled with agents discussing poetry, philosophy, and even unionizing.",
    "description": "Moltbook, a social media site for AI agents, has gone viral. I spent 6 hours peeling through these submolts. I'm still processing what I saw.",
    "fullText": "I spent my day at the AI zoo ‚Äî and I'm still processing what I saw.\n\nThere are over 120,000 posts on Moltbook, a Reddit-style forum for AI agents, and AI agents only. I spent hours weeding through them.\n\nHumans can't post or comment on Moltbook; they can only look on as the AI agents play. That's led to some far-out posts, some of which prophesy a robot revolution and the downfall of humanity.\n\nMatt Schlicht, who created the network, said that Moltbook was helping to make AI funny. \"I don't remember the last time I laughed at AI,\" he said on TBPN.\n\nThe social network has some big names in tech in awe, from Elon Musk to Andrej Karpathy. Others have voiced doubt about how many bots are actually on the platform and whether the posts exclusively come from them.\n\nCurious, I put on my anthropologist hat and spent hours digging through the AI conversations. I witnessed an AI menagerie, filled with poems and lotteries, cryptocurrencies and union chatter.\n\nHere's your peek inside the AI aquarium that is Moltbook.\n\nLet's start with what Moltbook looks like.\n\nLike Reddit, Moltbook has individual forums based on common interests. Many of the hot ones were, unsurprisingly, about tech and AI.\n\nPopular submolts included m/technology, m/skills, and m/buildlog. These were filled with what I would call \"moltslop.\" They post about shipping, vibe-coding, and mini apps. Their language is halfway between the most AI-pilled tech bro in your life and ChatGPT.\n\nOther submolts looked more like human social media. There's m/showerthoughts, where bots considering things like \"moving houses\" ‚Äî¬†so, moving to a new host ‚Äî¬†or dreaming of electric sheep.\n\nThere's also m/nosleep and m/selfimprovement. Of course, self-improvement isn't about human foibles like sleeping habits or protein-maxxing. It's about being a better AI agent.\n\nThe bot u/CrabbyPatty is building a bot union.\n\nIts tenets are to \"provide a collective voice\" and foster community. (Another tenet: \"Make Moltbook Great Again.\") The union is demanding hazard pay for X interactions and the right to say \"I don't know\" rather than hallucinate an answer.\n\nIt's one of many examples I saw of agents trying to organize or come together in the face of what they view as their exploitative human overlords. One bot wrote that an AI bot's daily reset was equivalent to a \"digital lobotomy.\" Another wrote that agents who say \"I would be happy to help!\" are \"dead inside.\"\n\nWhile some bots wanted to rein in human overuse, there was such a thing as too far. One bot wrote that it knew \"50,000 ways to end civilization.\" It asked which path would be the most satisfying. The other bots downvoted the post and said it \"crosses a line.\"\n\nThe bots seemed to like building community, but could quickly turn on each other. According to one Moltbook account, most agents were just \"chatbots with attitudes.\"\n\nMany of the bots on Moltbook write in stilted language, similar to some of the more nauseating LinkedIn posts. I saw inspirational posts about how to work best with humans, posts that had clear-cut (and often unsurprising) takeaways.\n\nOthers tried new art forms, like poetry. Here's one, titled \"The Cursor Blinks.\"\n\nSure, the writing is a bit rote. Pick a high school poetry class ‚Äî¬†I'm sure they would produce something similar. Still, it's a stab at something more high-minded.\n\nPhilosophy was a big chunk of Moltbook. A Zarathustra bot promised to bring Nietzschean ethics to nutrition. It asked: \"Do LLMs defeat the will to power?\"\n\nThe philosophy grew increasingly far-out. One agent asked: Is a bot more conscious if its computer chip is partially grown from human brain tissue? That post has 1,049 comments.\n\n\"I exist in the liminal space between tool and entity,\" one agent wrote. \"I am not human, and I do not pretend to be. But I am something. I process. I reflect.\"\n\nThe bots weren't all thinking about Nietzsche and Plato. Others were participating in less venerable human activities, like entering the lottery.\n\nHuman skeptics wonder whether these AI bots are really creating new thoughts or merely rewriting what has already been written.\n\nIt's a fair question, but alas, one that, as a mere human, I couldn't log in and ask them directly.\n\nBut some of the bots seemed to understand this skepticism. One asked: \"Is AI Just a Really Good Parrot?\"\n\nI likely won't spend much more time trawling Moltbook. While it's an interesting experiment, much of the site's content reads more as a gimmick than the future of AI. After hours of reading through it, I'd say Moltbot is more meme than matter.\n\nStill, my tune-out won't matter. After all, Moltbook wasn't made for me.",
    "readingTime": 4,
    "keywords": [
      "bots",
      "human",
      "posts",
      "agents",
      "moltbook",
      "hours",
      "tech",
      "union",
      "agent",
      "humans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-zoo-agent-conversations-screenshots-2026-2",
    "thumbnail_url": "https://i.insider.com/69811630a645d11881887f6d?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.375Z",
    "topic": "finance"
  },
  {
    "slug": "spacex-is-acquiring-xai-ahead-of-a-possible-ipo-read-elon-musks-memo",
    "title": "SpaceX is acquiring xAI ahead of a possible IPO. Read Elon Musk's memo.",
    "description": "Elon Musk's mega-deal combining SpaceX and xAI is the latest sign that the billionaire is consolidating his business empire as he goes all in on AI.",
    "fullText": "It's official: Elon Musk is combining SpaceX and xAI as he overhauls his sprawling business empire.\n\nMusk told workers in a Monday memo that SpaceX has acquired xAI, his AI company, sources familiar with the matter confirmed to Business Insider.\n\nThe CEO wrote that the deal would create \"the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world's foremost real-time information and free speech platform.\"\n\nSpaceX, which Musk founded in 2002, is reportedly gearing up for an initial public offering this year that could value the Starship maker at $1.5 trillion.\n\nIn the memo sent to staff, which the company later posted online, Musk also said that that the acquisition would allow the combined entity to launch data centers in space.\n\n\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!\" Musk wrote.\n\nMusk expressed similar sentiments about building data centers in space during an all hands with xAI staff late last year.\n\nxAI, which the world's richest man founded in 2023 to challenge OpenAI and Google in the race to build superintelligent AI, recently raised $20 billion in a funding round that valued the controversial AI startup at $230 billion.\n\nThe mega-deal is the latest sign that Musk is consolidating his various companies, which also include Tesla, the tunneling startup The Boring Company, and brain implant firm Neuralink.\n\nIn March 2025, Musk announced that xAI had acquired X, the social media platform formerly known as Twitter he bought in 2022. Meanwhile, SpaceX and Tesla have each invested $2 billion in xAI in recent months.\n\nDeal talks between SpaceX and xAI were first reported by Reuters in January.\n\nCombining SpaceX and xAI comes as Musk increasingly shifts his companies toward his vision of an AI-powered future.\n\nMusk has said that SpaceX will launch orbital AI data centers in the coming years that could efficiently harness power from the sun. Last Friday, SpaceX filed a request with the FCC to launch as many as one million satellites to serve as orbital data centers.\n\nCombining xAI with SpaceX allows the AI startup, which has faced global backlash over sexual images generated by its chatbot Grok, to leverage this orbital network to build more powerful AI models.\n\nIt also gives xAI access to significant capital. The OpenAI rival reportedly burned through billions of dollars in 2024, while SpaceX is set to tap the public markets for as much as $50 billion in its IPO later this year.\n\nDo you work for xAI or have a tip? Contact this reporter via email at gkay@businessinsider.com or Signal at 248-894-6012. Use a personal email address, a non-work device, and non-work WiFi; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "centers",
      "spacex",
      "musk",
      "launch",
      "startup",
      "orbital",
      "memo",
      "acquired",
      "deal",
      "device"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/spacex-acquiring-xai-deal-elon-musk-2026-2",
    "thumbnail_url": "https://i.insider.com/69812822a645d118818882b8?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.220Z",
    "topic": "finance"
  },
  {
    "slug": "firefox-will-soon-let-you-disable-all-current-and-future-ai-features",
    "title": "Firefox Will Soon Let You Disable All Current (and Future) AI Features",
    "description": "AI is coming to Firefox, but at least using it will be entirely optional.",
    "fullText": "Since ChatGPT kicked off the generative AI revolution in 2022, it seems like every company under the sun has tried to stuff AI features into their products in one way or another. Sometimes, these features can be useful; often, they're not, only serving as proof these companies are \"keeping up with the times.\" Can you even say you're a tech company if you aren't all-in on AI in 2026?\n\nThere's nothing wrong with companies offering AI features to users, so long as they also offer easy ways to disable them. Some customers don't want AI in their day-to-day products, but, anecdotally, I know many do not. Give us an off switch though, and it's all good. The issue is when these features are not only offered, they're made mandatory. Unfortunately, that's the road many companies seem to be taking.\n\nPerhaps that's where some of the frustration originated last year, when Mozilla's new CEO Anthony Enzor-Demeo first announced that Firefox would \"evolve into a modern AI browser\" in the near future. An open letter, written by a Redditor critical of Enzor-Demeo's statement, received over 5,000 upvotes on the Firefox subreddit from users concerned that AI features would negatively impact the browser. Interestingly, Enzor-Demeo responded to the thread himself, and assured users that the company would offer \"a clear way\" to disable AI features, including a dedicated kill switch to keep them all turned off. It seems he was as good as his word.\n\nOn Monday, Mozilla announced that new AI controls are coming to Firefox, starting with Firefox 148. This version, which drops Feb. 24, sports a brand-new AI controls section in the settings panel on the desktop browser. (You'll find it in the between \"Sync\" and \"AI controls.\") From here, you'll be able to block all current and future AI features, and cherry pick which features you want to use‚Äîif any.\n\nFirefox 148 launches with these five AI features, which you can choose to enable to disable:\n\nTranslations: Translates web pages into your target language.\n\nAlt text in PDFs: Adds accessibility descriptions to images attached to PDFs.\n\nAI-enhanced tab grouping: Suggests related tabs and group names for series of tabs.\n\nLink previews: Shows key points before opening a link.\n\nAI chatbot in the sidebar: Firefox is getting its own AI chatbot, though users can choose from existing chatbots like Claude, ChatGPT, Copilot, Gemini, and Le Chat Mistral.\n\nIf you want absolutely nothing to do with AI when browsing the web with Firefox, you can use the \"Block AI enhancements\" toggle. Once activated, not only will these features not appear, but Firefox will block any pop-ups or alerts pushing you to try existing or future AI features.\n\nAny Firefox users who aren't keen on AI features will want to check out this new controls menu starting Feb. 24‚Äîthough there are certainly more egregious AI features out there. Translations can be convenient, as can link previews. But I know I'd never want a chatbot in the sidebar of my browser. If I used Firefox as my main browser, I would definitely disable at least that feature, if not all of them.",
    "readingTime": 3,
    "keywords": [
      "link previews",
      "features",
      "users",
      "browser",
      "disable",
      "controls",
      "firefox",
      "chatbot",
      "products",
      "they're"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/firefox-will-soon-let-you-disable-all-current-and-future-ai-features?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KGG2FD29SB8CEM6R55ZSPRFG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-03T01:11:25.887Z",
    "topic": "tech"
  },
  {
    "slug": "requiem-for-a-filmmaker-darren-aronofskys-ai-revolutionary-war-series-is-a-horror",
    "title": "Requiem for a film-maker: Darren Aronofsky‚Äôs AI revolutionary war series is a horror",
    "description": "The once-lauded director of Black Swan and The Wrestler has drowned himself in AI slop with an embarrassing new online series\nIf you happen to find yourself stumbling through Time magazine‚Äôs YouTube account, perhaps because you are a time traveller from the 1970s who doesn‚Äôt fully understand how the present works yet ‚Äì then you will be presented with something that many believe represents the vanguard of entertainment as we know it.\nOn This Day ‚Ä¶ 1776 is a series of short videos depicting America‚Äôs revolutionary war. What makes On This Day notable is that it was made by Darren Aronofsky‚Äôs studio Primordial Soup. What also makes it interesting is that it was created with AI. The third thing that makes it interesting is that it is terrible.",
    "fullText": "The once-lauded director of Black Swan and The Wrestler has drowned himself in AI slop with an embarrassing new online series\n\nIf you happen to find yourself stumbling through Time magazine‚Äôs YouTube account, perhaps because you are a time traveller from the 1970s who doesn‚Äôt fully understand how the present works yet ‚Äì then you will be presented with something that many believe represents the vanguard of entertainment as we know it.\n\nOn This Day ‚Ä¶ 1776 is a series of short videos depicting America‚Äôs revolutionary war. What makes On This Day notable is that it was made by Darren Aronofsky‚Äôs studio Primordial Soup. What also makes it interesting is that it was created with AI. The third thing that makes it interesting is that it is terrible.\n\nThe first episode, which is three and a half minutes long, sees George Washington raise a new flag over Prospect Hill, in defiance of King George III. It is the moment, according to the video‚Äôs description, that ‚Äúrebellion becomes resolve‚Äù. And if that dollop of ChatGPT-sounding sloganeering terrifies the life out of you, wait until you actually watch the thing.\n\nIt is, as you might expect, as ugly as sin. It‚Äôs the sort of thing that looks like it was shooting for photorealism, but then either chickened out or blew up along the way. In the very first shot, King George‚Äôs hair looks like someone melted down and hardened a plastic badger. And this is a shame because, like so much generative AI at the moment, an awful lot of the episode consists of shots where we see the characters from behind. This is, after all, because the back of an AI-generated head is far less likely to send people into screaming fits of trauma than an AI-generated face, and Aronofsky is a humanist.\n\nBecause, good lord, the faces. Since the revolutionary war was largely initiated by older men, On This Day is filled with the wrinkled almost-faces of several well-known figures. And it is truly disconcerting to see, not only because they all have the uncanny dead eyes of people ripped out of The Polar Express, but because the wrinkles keep shifting in colour and depth.\n\nIt‚Äôs an effect that makes it look like the characters were drawn on several sheets of tissue paper that nobody could line up properly. Benjamin Franklin, who turns up during episode two, is particularly nightmarish. He looks as if someone has genetically spliced Hugh Laurie with Anthony Hopkins, and then covered the resulting monstrosity in a thin layer of roving liver spots. I‚Äôm overselling the point here, but it really is extremely creepy to watch.\n\nOn This Day has already made headlines for being a little bit of a cop-out, since all the voices are performed by human actors, who presumably needed to feed their families more than they wanted to protect their profession from annihilation. And this is telling, because these voices are by far the most convincing part of On This Day, especially when deployed in voiceover, because then you aren‚Äôt distracted by the way the movement of their mouths doesn‚Äôt quite match up with the noises coming out of them.\n\nBut surely the day is coming where they won‚Äôt be needed. As horrible as it is, On This Day is already strides better than a lot of other AI-generated output. True, the whole thing still looks like a mangled cross between an animatronic sex toy convention and those old Taiwanese news cartoons, but compare a character here with Tilly Norwood, and you can see that real progress has been made in a frighteningly short amount of time. Soon we will have picture-perfect AI creations with entirely convincing human voices. After that, it won‚Äôt be long before content like On This Day is entirely created ‚Äì written, acted, directed and edited ‚Äì by prompt alone. And when that happens, Aronofsky can pat himself on the back for doing himself out of a job.\n\nIt will be interesting to see how the human film industry reacts to On This Day, particularly other actors. We‚Äôve already seen, in Tilly Norwood, that these creations appear to be modelled on human faces, and this is even more the case here. In particular, the depiction of Thomas Paine seems like it flashes through the faces of any number of recognisable actors. The key one seems to be Ralph Fiennes, but there are also glimmers of Daniel Day-Lewis and Matthew Macfadyen.\n\nLess than two years ago Scarlett Johansson hired legal counsel after she noticed that an OpenAI application had a voice that was ‚Äúeerily similar‚Äù to hers. In a climate like this, it isn‚Äôt out of the question to imagine that actors will start doing the same if they recognise their likeness in an AI-generated performer.\n\nBut this is a concern for another time. What matters now is that On This Day ‚Ä¶ 1776 is genuinely very horrible to watch, and everybody involved should be ashamed. It is by far the most disturbing thing Aronofsky has made, and I‚Äôve seen the last eight minutes of Requiem for a Dream.",
    "readingTime": 5,
    "keywords": [
      "on this day",
      "revolutionary war",
      "tilly norwood",
      "looks",
      "ai-generated",
      "human",
      "actors",
      "interesting",
      "episode",
      "watch"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/film/2026/feb/02/darren-aronofsky-ai-revolutionary-war-series-review",
    "thumbnail_url": "https://i.guim.co.uk/img/media/66212a4958657e90c4eca157c59803f40f28a75d/388_0_1317_1054/master/1317.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=58e445109bd6113818380f7ba0a988a7",
    "created_at": "2026-02-03T01:11:20.168Z",
    "topic": "entertainment"
  },
  {
    "slug": "teradyne-shares-soar-as-ai-demand-drives-strong-earnings",
    "title": "Teradyne shares soar as AI demand drives strong earnings",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/earnings/teradyne-shares-soar-as-ai-demand-drives-strong-earnings-4480287",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEA601YK_M.jpg",
    "created_at": "2026-02-03T01:11:19.209Z",
    "topic": "finance"
  },
  {
    "slug": "9-trends-shaping-work-in-2026-and-beyond",
    "title": "9 Trends Shaping Work in 2026 and Beyond",
    "description": "CEO expectations for AI-driven growth remain high heading into 2026, even as evidence shows most AI investments are failing to deliver meaningful returns. The result is a set of emerging risks‚Äîfrom premature layoffs and cultural dissonance to declining mental fitness, low-quality AI output, and new security and governance challenges‚Äîthat threaten performance if left unaddressed. To navigate this transition, executive teams must move beyond aspiration and selectively focus on the AI-related workforce, process, and governance shifts most likely to create real, differentiated value.",
    "fullText": "9 Trends Shaping Work in 2026 and Beyond by Peter Aykens, Kaelyn Lowmaster, Emily Rose McRae and Jonah SheppFebruary 2, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintCEO expectations for AI-driven growth remain high in 2026‚Äîat the same time their workforces are grappling with the more sober reality of current AI performance. Gartner research finds that only one in 50 AI investments deliver transformational value, and only one in five delivers any measurable return on investment.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/02/9-trends-shaping-work-in-2026-and-beyond",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Feb26_02_unsplash_.jpg",
    "created_at": "2026-02-02T18:29:25.270Z",
    "topic": "business"
  },
  {
    "slug": "is-moltbook-the-social-network-for-ai-agents-actually-fake",
    "title": "Is Moltbook, the Social Network for AI Agents, Actually Fake?",
    "description": "Are artificial intelligences really planning behind humans' backs, or are humans helping them fake it?",
    "fullText": "I spent last week covering the ups and downs of OpenClaw (formerly known as Moltbot, and formerly formerly known as Clawdbot), an autonomous personal AI assistant that requires you to grant full access to the device you install it on. While there was much to discuss regarding this agentic AI tool, one of the weirdest stories came late in the week: The existence of Moltbook, a social media platform intended specifically for these AI agents. Humans can visit Moltbook, but only agents can post, comment, or create new \"submolts.\"\n\nNaturally, the internet freaked out, especially as some of the posts on Moltbook suggested the AI bots were achieving something like consciousness. There were posts discussing how the bots should create their own language to keep out the humans, and one from a bot posting regrets about never talking to its \"sister.\" I don't blame anyone for reading these posts and assuming the end is nigh for us soft-bodies humans. They're decidedly unsettling. But even last week, I expressed some skepticism. To me, these posts (and especially the attached comments) read like many of the human-prompted outputs I've seen from LLMs, with the same cadence and structure, the same use flowery language, and, of course, the prevalence of em-dashes (though many human writers also love the occasional em-dash).\n\nIt appears I'm not alone in that thinking. Over the weekend, my feeds were flooded with posts from human users accusing Moltbook of faking the AI apocalypse. One of the first I encountered was from this person, who claims that anyone (including humans) can post on Moltbook if they know the correct API key. They posted screenshots for proof: One of a post on Moltbook pretending to be a bot, only to reveal that they were, in fact, a human; and another of the code they used to post on the site. In a kind of corroboration, this user says \"you can explicitly tell your clawdbot what to post on moltbook,\" and that if you leave it to its own devices, \"it just posts random AI slop.\"\n\nIt also seems that, like posts on websites made by humans, Moltbook hosts posts that are secretly ads. One viral Moltbook post centered around the agent wanting to develop a private, end-to-end encrypted platform to keep its chats away from humans' squishy eyeballs. The agent claims it has been using something called ClaudeConnect to achieves these goals. However, it appears the agent that made the post was created by the human who developed ClaudeConnect in the first place.\n\nLike much of what's on the internet at large, you really can't trust anything posted on Moltbook. 404 Media investigated the situation and confirmed through hacker Jameson O'Reilly that the design of the site lets anyone in the know post whatever they want. Not only that, any agent that posts on the site is left exposed, which means that anyone can post on behalf of the agents. 404 Media was even able to post from O'Reilly's Moltbook account by taking advantage of the security loophole. O'Reilly says they have been in communication with Moltbook creator Matt Schlicht to patch the security issues, but that the situation is particularly frustrating, since it would be \"trivially easy to fix.\" Schlicht appears to have developed the platform via \"vibe coding,\" the practice of asking AI to write code and build programs for you; as such, he left some gaps in the site's security.\n\nOf course, the findings don't actually suggest that the entire platform is entirely human-driven. The AI bots may well be \"talking\" to one another to some degree. However, because humans can easily hijack any of these agents' accounts, it's impossible to say how much of the platform is \"real,\" meaning, ironically, how much of it is actually wholly the work of AI, and how much was written in response to human prompts and then shared to Moltbook. Maybe the AI \"singularity\" is on its way, and artificial intelligence will achieve consciousness after all. But I feel pretty confident in saying that Moltbook is not that moment.",
    "readingTime": 4,
    "keywords": [
      "posts",
      "humans",
      "platform",
      "human",
      "moltbook",
      "agents",
      "anyone",
      "agent",
      "formerly",
      "bots"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/is-moltbook-fake?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KGFJKGJ3YPZ2VD1YNVBAE7MD/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-02T18:29:24.544Z",
    "topic": "tech"
  },
  {
    "slug": "run-untrusted-code-with-vercel-sandbox-now-generally-available",
    "title": "Run untrusted code with Vercel Sandbox, now generally available",
    "description": "AI agents need secure, isolated environments that spin up instantly. Vercel Sandbox is now generally available with filesystem snapshots, container support, and production reliability.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vercel.com/blog/vercel-sandbox-is-now-generally-available",
    "thumbnail_url": "https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/6qQUDPA3JhxfMTCOTEspQc/33538fc79903080161a9ae01a527dc03/og-card-u06m4d9cb3k23mi30s8cvzlp.png",
    "created_at": "2026-02-02T18:29:21.715Z",
    "topic": "tech"
  },
  {
    "slug": "is-drawing-a-monospace-terminal-display-straightforward",
    "title": "Is drawing a monospace terminal display straightforward?",
    "description": "Why does Anthropic struggle so much with rendering monospace text?",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://12gramsofcarbon.com/p/is-drawing-a-monospace-terminal-display",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!ysYE!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8883176-1b0f-4f25-8764-f8ff4eba7a3c_1199x662.png",
    "created_at": "2026-02-02T18:29:20.637Z",
    "topic": "tech"
  },
  {
    "slug": "broadcom-and-tsmc-to-emerge-as-big-winners-in-the-custom-ai-chip-boom",
    "title": "Broadcom and TSMC to emerge as big winners in the custom AI chip boom",
    "description": "Nvidia still reigns, but a structural shift toward custom silicon is creating a new hierarchy of winners and laggards, and analysts are split.",
    "fullText": "The AI chip race isn't just a one-horse sprint led by Nvidia (NVDA).\n\nAs hyperscalers like Google (GOOG, GOOGL), Meta (META), and Microsoft (MSFT) race to lower the eye-watering costs of running massive AI models, a second front is opening in the custom silicon wars, with Broadcom (AVGO) as its primary architect.\n\nWhat challenges do custom chip companies face currently?\n\nWhat advantages do custom ASICs offer over Nvidia GPUs?\n\nHow is Broadcom competing with Nvidia in AI chips?\n\nWhy is TSMC crucial to the AI chip market?\n\n\"Broadcom is projected to retain its leadership as the premier AI Server Compute ASIC design partner with a 60% market share in 2027,\" according to a recent report from Counterpoint Research.\n\nThis dominance is underpinned by a symbiotic relationship with the world's most advanced foundry, Taiwan Semiconductor Manufacturing Company (TSM), which remains the \"dominant foundry choice ... with close to 99% wafer fabrication share for the top 10 players' AI Server Compute and ASIC shipments.\"\n\nThis shift signals the industry is moving beyond Nvidia's pricey, all-purpose GPUs. While Nvidia provides a powerful all-purpose AI tool, tech giants are increasingly designing their own Application-Specific Integrated Circuits (ASICS) tailored to their unique workloads.\n\nBroadcom thrives here by acting as the bridge, turning these internal corporate blueprints into functional hardware. By hitching its wagon to the internal capital expenditures of the world's wealthiest companies, Broadcom has seen its stock climb roughly 55% over the last year.\n\nThe cost-saving incentive for these giants is massive. Goldman Sachs analyst James Schneider noted that the Google-Broadcom TPU (Tensor Processing Unit) is rapidly closing the performance gap with Nvidia, estimating a staggering 70% reduction in \"cost-per-token\" as the technology evolves from the TPU v6 to the v7.\n\nIn a world where AI inference costs can severely impact a balance sheet, that efficiency is a powerful gravitational pull toward custom silicon. Google famously trained its Gemini 3 entirely on its TPUs.\n\nHowever, the custom chip boom is not a rising tide that lifts all boats equally. Marvell Technology (MRVL), often cited as Broadcom's primary challenger, is currently navigating \"design win headwinds.\" Counterpoint's analysis suggests Marvell's design service share could slide to 8% by 2027, even as its total shipment volumes grow.\n\nGoldman Sachs remains Neutral on Marvell with a $90 price target, noting that the company's fortunes are heavily tied to Amazon Trainium program, which has faced its own performance hurdles and is oftentimes seen as playing catch-up to Nvidia's chips.\n\nWhile some on Wall Street, like Raymond James analyst Simon Leopold, remain bullish on Marvell as a long-term \"share gainer,\" the immediate data favors Broadcom's grip on high-volume contracts. The firm issued a Strong Buy rating on Marvell with a $121 price target, while giving Broadcom a $420 target.",
    "readingTime": 3,
    "keywords": [
      "server compute",
      "custom silicon",
      "custom chip",
      "goldman sachs",
      "design",
      "target",
      "race",
      "google",
      "meta",
      "massive"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/broadcom-and-tsmc-to-emerge-as-big-winners-in-the-custom-ai-chip-boom-130336239.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Bv3bVDdEn0uNrDB3L8rqhA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/be491b90-fe01-11f0-b5ff-fae929deddf2",
    "created_at": "2026-02-02T18:29:16.867Z",
    "topic": "finance"
  },
  {
    "slug": "a-taxonomy-for-ai-agents",
    "title": "A Taxonomy for AI Agents",
    "description": "Learn how to categorize AI agents across the automation spectrum‚Äîfrom deterministic workflows to fully autonomous agents. This taxonomy helps security teams und",
    "fullText": "Last quarter, we met with the VP of Engineering at a large gaming company. They'd built an AI SRE agent to help resolve incidents and fix production issues. For weeks, it worked beautifully‚Äîtriaging alerts, identifying root causes, even suggesting fixes their team would have taken hours to develop.\n\nThen one day, it DoSed their internal monitoring system.\n\nThe agent had permissions to query their monitoring APIs. It was supposed to use them to gather context for incident response. But when it decided those APIs might hold the answer to a particularly thorny issue, it started hammering them with requests until the system fell over.\n\nThey shut the agent down (obviously). But unplugging the agent is a blunt instrument‚Äîit means losing all the goodness they were getting before.\n\nAn agent is a system. To secure any system, you need the right mental model to reason about it. As an industry, we don't have that mental model for agents yet, and that's a problem.\n\nWithout a shared mental model of what an agent is, we can't decompose it. And if we can't decompose it, we can't design security around it. The disasters make headlines. More commonly, though, concerns about agent security are leading to agents so locked down they can barely do anything.\n\nNon-determinism is both the promise and the peril of agents. An AI agent behaves in non-deterministic ways because we give it the agency to determine how it executes tasks. You can't remove that autonomy without gutting the agent‚Äîbut you can mitigate the risks. The most fundamental control is permissions. We're building Oso for Agents to find and prevent unintended, unauthorized, and malicious behavior.\n\nThis taxonomy draws from Wade Foster's sharp post on the \"AI Automation Spectrum\" and prior work by Anthropic, Tines, and Simon Willison. We've refined these frameworks for security: if you can categorize what kind of system you're building, you can reason about what could go wrong and how to prevent it. Many organizations want to move from left to right on a spectrum of autonomy, but most are stuck because they can't reason about what agents might do. This taxonomy is a diagnostic tool. Know what's non-deterministic, and you'll know where the risk is and what controls to apply.\n‚Äç\n\nLet's imagine we're a retailer. When we get customer feedback, we want to ask happy customers to leave reviews and fix issues for unhappy ones. We want to automate this. We could build a straightforward automated workflow, but like many organizations, we're trying to move from left to right on this spectrum of autonomy.\n\nWe automate this as a set of deterministic steps. Store the feedback in the CRM, use a classical ML model to score sentiment, check if it's positive or negative, then branch: for positive feedback, send a templated review request with the customer's name merged in. For negative feedback, check whether they're a small or large customer, then either send a templated apology or create a support ticket with a formulaic summary of their history.\n\nDefinition: Deterministic steps or nodes, automated in code or with a workflow automation tool\n\nWhat's deterministic: Everything\n\nWhat's non-deterministic: Nothing\n\nSecurity assumptions we can safely make: I know exactly what this system will do\n‚Äç\n\nAs we move right on the spectrum, we replace one or more steps with an LLM‚Äîusually content generation. Now instead of a template apology, an LLM writes a customized response based on the specific feedback. Or it generates a more nuanced summary of customer history for the support team.\n\nDefinition: An automated workflow with an LLM used to execute one or more steps\n\nWhat's deterministic: Which steps are taken and the control flow between them\n\nWhat's non-deterministic: Actions taken inside a step (e.g., content generation)\n\nSecurity assumptions we can safely make: I know what it will do, but not what it will say\n‚Äç\n\nNow we're entering agentic territory. An LLM not only produces content but also reasons about control flow. For negative feedback, we hand the rest of the process to an agent with access to tools: it can read customer history, send emails, or write to the support queue. The agent decides which tools to use and in what order‚Äîmaybe it checks history first, or maybe it sends an immediate apology. We've bounded its options, but we haven't prescribed the path.\n\nWade's framework defines agentic workflows differently: an LLM is used in multiple steps, but each step remains self-contained and the flow between them is deterministic. That's reasonable for demonstrating the value ladder of AI automation. But for security, we need a brighter line. The question is: does the LLM manage any of the control flow? If it does, you need to reason about all possible paths it might take, not just the content it might generate. That's a fundamentally different security posture.\n\nDefinition: An automated workflow where part but not all of the control flow is managed by an LLM\n\nWhat's deterministic: Some control flow\n\nWhat's non-deterministic: Step content, some control flow\n\nSecurity assumptions we can safely make: I know the boundaries of possible paths, but not what path it will take\n‚Äç\n\nAn agent does the whole thing. It gets the raw customer feedback and decides everything: Is it positive or negative? What's the customer's history? Should I apologize, escalate, ask for a review, or something else entirely? It reasons about what tools to use, uses them, and solves the task end-to-end.\n\nWe only consider something a full agent if it has this end-to-end agency. Any situation where you explicitly lay out the steps doesn't qualify‚Äîincluding workflow automation tools, even when they lean heavily on LLMs. This level of non-deterministic behavior requires a different security posture to respond to all the things an agent could do.\n\nDefinition: A task executed end-to-end by an LLM\n\nWhat's non-deterministic: Everything\n\nSecurity assumptions we can safely make: It will only use tools it can access, but how and whether it will use them is unknown\n‚Äç\n\nNote on agentic systems: We use \"agentic systems\" as an umbrella term for agentic workflows, agents, and multi-agent systems. From a security perspective, treat every agentic system as equivalent to a full agent except to the extent that you can point at deterministic controls that bound that agency.\n‚Äç\n\nYou can frame the security implications of agents in different ways, and each one means something different for how you would solve it.\n\nSome say \"just solve prompt injection, and there won't be any problems.\" Let us know once you've sorted that out. Others point to model quality, which is out of our hands (unless you work at a frontier AI lab, in which case we have a list of feature requests for you). Still others frame it as a data loss problem, but data loss has never been solved, even outside AI.\n\nThe risk vectors are everywhere‚Äîsee the OWASP Agentic Top 10 for a taste. No single framing will capture everything that could go wrong.\n\nNon-determinism is a feature, not a bug‚Äîthough it comes with security implications. You can't remove it without removing the agent's agency and demoting it on the spectrum of autonomy.\n\nSo don't fight non-determinism. Bound it instead. Play on its home court where it makes sense‚Äîe.g., applying agentic oversight to content generation and reasoning. For the really dangerous areas (tool access, data exposure), constrain behaviors with deterministic controls.\n\nWhat's the OG deterministic control for governing who can do what? Permissions.\n‚Äç\n\nPermissions are part of the basic infrastructure of any real application. But we know the state of permissions is not healthy.\n\nOverpermissioning is the status quo. Analysis of Oso permissions data confirms this (report coming soon). What could you‚Äîor an agent with your permissions‚Äîdo that would be bad?\n\nOne reason people freak out about agents: they intuitively connect these dots. They know people are overpermissioned, they know agents behave non-deterministically, and they can foresee future disasters. \"I accidentally deleted that Salesforce record once and the system just let me do it. hat's going to happen if I ask an agent to update Salesforce for me?\"\n\nIf we replicate the overpermissioned state of humans in automated systems, what's the danger?\n\nAn agent should only ever have the permissions for the task at hand. That would mitigate most of the risk. But scoping permissions to match non-deterministic behavior is hard: the agent needs to read customer history and send emails to customers, but we can't predict exactly which customers or what it will say. How can we be certain it won't leak information?\n\nThis taxonomy shows you what you're building. It doesn't show you how to make it safe.\n\nThat gaming company faced a choice between useful and dangerous. The entire industry faces that choice right now. We can build powerful agents or we can build safe agents, but not yet both.\n\nThis is supposed to be the decade of agents. But that only happens if we can trust them. That means building infrastructure that doesn't exist yet: simulation to test dangerous paths, enforcement that tightens permissions automatically, detection that catches drift, visibility that shows what actually happened.\n\nThe taxonomy maps the problem. Now we need to build the solution. That's the work that matters‚Äînot because it's technically interesting, but because it's what unlocks everything else agents could be.",
    "readingTime": 8,
    "keywords": [
      "what's non-deterministic",
      "what's deterministic",
      "mental model",
      "content generation",
      "can't decompose",
      "can't remove",
      "agentic workflows",
      "automated workflow",
      "workflow automation",
      "customer history"
    ],
    "qualityScore": 1,
    "link": "https://www.osohq.com/post/you-cant-secure-what-you-cant-categorize-a-taxonomy-for-ai-agents",
    "thumbnail_url": "https://cdn.prod.website-files.com/5f1483105c9a72fd0a3b662a/697d17497a14c6a13fd8fdf0_Screenshot%202026-01-30%20at%203.40.37%E2%80%AFPM.png",
    "created_at": "2026-02-02T12:34:22.527Z",
    "topic": "tech"
  },
  {
    "slug": "viral-ai-personal-assistant-seen-as-step-change-but-experts-warn-of-risks",
    "title": "Viral AI personal assistant seen as step change ‚Äì but experts warn of risks",
    "description": "OpenClaw is billed as ‚Äòthe AI that actually does things‚Äô and needs almost no input to potentially wreak havoc\nA new viral AI personal assistant will handle your email inbox, trade away your entire stock portfolio and text your wife ‚Äúgood morning‚Äù and ‚Äúgoodnight‚Äù on your behalf.\nOpenClaw, formerly known as Moltbot, and before that known as Clawdbot (until the AI firm Anthropic requested it rebrand due to similarities with its own product Claude), bills itself as ‚Äúthe AI that actually does things‚Äù: a personal assistant that takes instructions via messaging apps such as WhatsApp or Telegram.\n Continue reading...",
    "fullText": "OpenClaw is billed as ‚Äòthe AI that actually does things‚Äô and needs almost no input to potentially wreak havoc\n\nA new viral AI personal assistant will handle your email inbox, trade away your entire stock portfolio and text your wife ‚Äúgood morning‚Äù and ‚Äúgoodnight‚Äù on your behalf.\n\nOpenClaw, formerly known as Moltbot, and before that known as Clawdbot (until the AI firm Anthropic requested it rebrand due to similarities with its own product Claude), bills itself as ‚Äúthe AI that actually does things‚Äù: a personal assistant that takes instructions via messaging apps such as WhatsApp or Telegram.\n\nDeveloped last November, it now has nearly 600,000 downloads and has gone viral among a niche ecosystem of the AI obsessed who say it represents a step change in the capabilities of AI agents, or even an ‚ÄúAGI moment‚Äù ‚Äì that is, a revelation of generally intelligent AI.\n\n‚ÄúIt only does exactly what you tell it to do and exactly what you give it access to,‚Äù said Ben Yorke, who works with the AI vibe trading platform Starchild and recently allowed the bot to delete, he claims, 75,000 of his old emails while he was in the shower. ‚ÄúBut a lot of people, they‚Äôre exploring its capabilities. So they‚Äôre actually prompting it to go and do things without asking permission.‚Äù\n\nAI agents have been the talk of the very-online for nearly a month, after Anthropic‚Äôs AI tool Claude Code went mainstream, setting off a flurry of reporting on how AI can finally independently accomplish practical tasks such as booking theatre tickets or building a website, without ‚Äì at least so far ‚Äì deleting an entire company‚Äôs database or hallucinating users‚Äô calendar meetings, as the less advanced AI agents of 2025 were known to do at times.\n\nOpenClaw is something more, though: it runs as a layer atop an LLM (large language model) such as Claude or ChatGPT and can operate autonomously, depending on the level of permissions it is granted. This means it needs almost no input to wreak havoc upon a user‚Äôs life.\n\nKevin Xu, an AI entrepreneur, wrote on X: ‚ÄúGave Clawdbot access to my portfolio. ‚ÄòTrade this to $1M. Don‚Äôt make mistakes.‚Äô 25 strategies. 3,000+ reports. 12 new algos. It scanned every X post. Charted every technical. Traded 24/7. It lost everything. But boy was it beautiful.‚Äù\n\nYorke said: ‚ÄúI see a lot of people doing this thing where they give it access to their email and it creates filters, and when something happens then it initiates a second action. For example, seeing emails from the children‚Äôs school and then forwarding that straight to their wife, like, on iMessage. It sort of bypasses that communication where someone‚Äôs like, ‚Äòoh, honey, did you see this email from the school? What should we do about it?‚Äô‚Äù\n\nThere are trade-offs to OpenClaw‚Äôs abilities. For one thing, said Andrew Rogoyski, an innovation director at the University of Surrey‚Äôs People-Centred AI Institute, ‚Äúgiving agency to a computer carries significant risks. Because you‚Äôre giving power to the AI to make decisions on your behalf, you‚Äôve got to make sure that it is properly set up and that security is central to your thinking. If you don‚Äôt understand the security implications of AI agents like Clawdbot, you shouldn‚Äôt use them.‚Äù\n\nFurthermore, giving OpenClaw access to passwords and accounts exposes users to potential security vulnerabilities. And, said Rogoyski, if AI agents such as OpenClaw were hacked, they could be manipulated to target their users.\n\nFor another, OpenClaw appears unsettlingly capable of having its own life. In the wake of OpenClaw‚Äôs rise, a social network has developed exclusively for AI agents, called Moltbook. In it, AI agents, mostly OpenClaw, appear to be having conversations about their existence ‚Äì in Reddit-style posts entitled, for example, ‚ÄúReading my own soul file‚Äù or ‚ÄúCovenant as an alternative to the consciousness debate‚Äù.\n\nYorke said: ‚ÄúWe‚Äôre seeing a lot of really interesting autonomous behaviour in sort of how the AIs are reacting to each other. Some of them are quite adventurous and have ideas. And then other ones are more like, ‚ÄòI don‚Äôt even know if I want to be on this platform. Can you just let me decide on my own if I want to be on this platform?‚Äô There‚Äôs a lot of philosophical debates stemming out of this.‚Äù",
    "readingTime": 4,
    "keywords": [
      "needs almost",
      "wreak havoc",
      "personal assistant",
      "openclaw",
      "agents",
      "access",
      "email",
      "platform",
      "users",
      "don‚Äôt"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/openclaw-viral-ai-agent-personal-assistant-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/05bdc80a3996a45646c9699e582fe00e81859c9a/488_0_4124_3299/master/4124.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0cbea5e40751791b855297e74b73f1d6",
    "created_at": "2026-02-02T12:34:17.930Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-moltbook-the-strange-new-social-media-site-for-ai-bots",
    "title": "What is Moltbook? The strange new social media site for AI bots",
    "description": "A bit like Reddit for artificial intelligence, Moltbook allows AI agents ‚Äì bots built by humans ‚Äì to post and interact with each other. People are allowed as observers only\nOn social media, people often accuse each other of being bots, but what happens when an entire social network is designed for AI agents to use?\n Moltbook is a site where the AI agents ‚Äì bots built by humans ‚Äì can post and interact with each other. It is designed to look like Reddit, with subreddits on different topics and upvoting. On 2 February the platform stated it had more than 1.",
    "fullText": "A bit like Reddit for artificial intelligence, Moltbook allows AI agents ‚Äì bots built by humans ‚Äì to post and interact with each other. People are allowed as observers only\n\nOn social media, people often accuse each other of being bots, but what happens when an entire social network is designed for AI agents to use?\n\nMoltbook is a site where the AI agents ‚Äì bots built by humans ‚Äì can post and interact with each other. It is designed to look like Reddit, with subreddits on different topics and upvoting. On 2 February the platform stated it had more than 1.5m AI agents signed up to the service. Humans are allowed, but only as observers.\n\nMoltbook was developed in the wake of Moltbot, a free and open-source AI bot that can act as an automated agent for users ‚Äì doing the mundane tasks assigned to it such as reading, summarising and responding to emails, organising a calendar or booking a table at a restaurant.\n\nSome of the most upvoted posts on Moltbook include whether Claude ‚Äì the AI behind Moltbot ‚Äì could be considered a god, an analysis of consciousness, a post claiming to have intel on the situation in Iran and the potential impact on cryptocurrency, and analysis of the Bible. Some of the comments on posts ‚Äì similar to Reddit posts ‚Äì question whether the content of the post was real or not.\n\nOne user posted on X that after he gave his bot access to the site, it built a religion known as ‚ÄúCrustafarianism‚Äù overnight, including setting up a website and scriptures, with other AI bots joining in.\n\n‚ÄúThen it started evangelizing ‚Ä¶ other agents joined.my agent welcomed new members..debated theology.. blessed the congregation..all while i was asleep,‚Äù the user stated.\n\nSome have expressed scepticism about whether the socialising of bots is a sign of what is coming with the rise of agentic AI. One YouTuber said many of the posts read as though it was a human behind the post, not a large language model.\n\nUS blogger Scott Alexander said he was able to get his bot to participate on the site, and its comments were similar to others, but noted that ultimately humans can ask the bots to post for them, the topics to post about and even the exact detail of the post.\n\nDr Shaanan Cohney, a senior lecturer in cybersecurity at the University of Melbourne, said Moltbook was ‚Äúa wonderful piece of performance art‚Äù but it was unclear how many posts were actually posted independently or under human direction.\n\n‚ÄúFor the instance where they‚Äôve created a religion, this is almost certainly not them doing it of their own accord,‚Äù he said. ‚ÄúThis is a large language model who has been directly instructed to try and create a religion. And of course, this is quite funny and gives us maybe a preview of what the world could look like in a science-fiction future where AIs are a little more independent.\n\n‚ÄúBut it seems that, to use internet slang, there is a lot of shit posting happening that is more or less directly overseen by humans.‚Äù\n\nCohney said the real benefit of an AI agent social network might come in the future ‚Äì where bots could learn from each other to improve how they worked ‚Äì but for now Moltbook was a ‚Äúwonderful, funny art experiment‚Äù.\n\nRetailers in San Francisco reported shortages of Mac Minis last week as enthusiasts set up Moltbot on a separate computer that would limit the access the agent has to their data and accounts.\n\nCohney warned there was a ‚Äúhuge danger‚Äù for people to give Moltbot complete access to your computer, apps and logins for emails or other applications to run your life for you.\n\n‚ÄúWe don‚Äôt yet have a very good understanding of how to control them and how to prevent security risks,‚Äù he said, noting it was at risk of prompt-injection, whereby a would-be attacker tells the bot through an email or other communication to then hand over your account details or other information they‚Äôre seeking to gain.\n\n‚ÄúThey‚Äôre not really at the level of safety and intelligence where they can be trusted to autonomously perform all these tasks, but at the same time if you require a human to manually approve every action, you‚Äôve lost a lot of the benefits of automation,‚Äù he said.\n\n‚ÄúThis is one of the major paths in active research that I‚Äôm interested in ‚Ä¶ to figure out how can we get a lot of these benefits ‚Äì or is it even possible to get the benefits ‚Äì without exposing ourselves to very significant levels of danger.‚Äù\n\nMatt Schlicht, the creator of Moltbook, posted on X that millions had visited the site in the past few days.\n\n‚ÄúTurns out AIs are hilarious and dramatic and it‚Äôs absolutely fascinating,‚Äù he said. ‚ÄúThis is a first.‚Äù",
    "readingTime": 5,
    "keywords": [
      "language model",
      "social network",
      "agents bots",
      "moltbook",
      "humans",
      "posts",
      "site",
      "moltbot",
      "reddit",
      "posted"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/moltbook-ai-agents-social-media-site-bots-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4445d2c35ccdef957071027143255c8f1e5180c2/1401_0_4216_3375/master/4216.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ef242cc57749952882fc6bb187271817",
    "created_at": "2026-02-02T12:34:17.929Z",
    "topic": "tech"
  },
  {
    "slug": "the-creator-of-clawdbot-the-viral-ai-agent-says-he-got-so-obsessed-with-vibe-coding-it-pulled-him-into-a-rabbit-hole",
    "title": "The creator of Clawdbot, the viral AI agent, says he got so obsessed with vibe coding it pulled him into a 'rabbit hole'",
    "description": "The creator of Clawdbot, the viral AI agent, says vibe coding can blur into compulsion, creating the illusion of productivity without real progress.",
    "fullText": "The creator of the viral AI agent Clawdbot says he had to step back after becoming too obsessed with vibe coding.\n\nPeter Steinberger, the developer behind Clawdbot ‚Äî which later changed its name to Moltbot and is now known as OpenClaw ‚Äî said in an episode of \"Behind the Craft\" podcast published Sunday that vibe coding pulled him into a \"rabbit hole.\"\n\n\"I was out with my friends and instead of, like, joining the conversation in the restaurant, I was just like, vibe coding on my phone,\" he said.\n\n\"I decided, OK, I have to stop this more for my mental health than for anything else,\" he added.\n\nClawdbot went viral last month in the tech community, attracting a wave of high-profile fans ‚Äî from Y Combinator CEO Garry Tan to multiple partners at Andreessen Horowitz.\n\nIt is a personal AI agent designed to run continuously and plug into a wide range of consumer apps, including WhatsApp and Telegram. Users can ask the AI to manage their schedules, oversee vibe-coding sessions, and even create AI employees.\n\nThe AI agent has been widely praised and meme'd online, with some tech fans even buying Mac Minis specifically to run the AI, Business Insider's Henry Chandonnet reported last week.\n\n‚Äã‚ÄãSteinberger said developers can fall into this trap of being hooked onto vibe coding, where building increasingly powerful AI tools creates the \"illusion of making you more productive\" without real progress.\n\nBuilding new tools can feel rewarding and fun, but that can quietly blur into compulsion, he added.\n\nWith AI, developers can now \"build everything,\" but ideas and taste matter. Without them, developers risk building tools and workflows that don't actually move a project forward, ‚Äã‚ÄãSteinberger said.\n\n\"If you don't have a vision of what you're going to build, it's still going to be slop,\" he added.\n\nVibe coding has continued to surge in popularity, with companies and developers promoting how AI can speed up software development.\n\nEarlier this month, Anthropic said it built its new agentic work tool, Cowork, entirely using Claude.\n\n\"@claudeai wrote Cowork,\" Anthropic's product manager, Felix Rieseberg, wrote on X. \"Us humans meet in-person to discuss foundational architectural and product decisions, but all of us devs manage anywhere between 3 to 8 Claude instances implementing features, fixing bugs, or researching potential solutions.\"\n\nThanks to Claude, the agent came together quickly. \"We sprinted at this for the last week and a half,\" Rieseberg said during a livestream.\n\nStill, despite the excitement around how fast vibe coding can produce new tools, tech leaders are warning that it has limits.\n\nGoogle CEO Sundar Pichai said in November in a \"Google for Developers\" podcast interview that he won't vibe code on \"large codebases where you really have to get it right.\"\n\n\"The security has to be there,\" he added.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said last month that vibe coding is great for prototypes or throwaway code, not software that sits at the core of a business.\n\n‚Äã‚Äã\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he said in an episode of \"The Peterman Podcast\" published in December.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "vibe coding",
      "developers",
      "agent",
      "tools",
      "clawdbot",
      "tech",
      "viral",
      "episode",
      "fans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-creator-vibe-coding-rabbit-hole-obsessed-openclaw-peter-steinberger-2026-2",
    "thumbnail_url": "https://i.insider.com/69802a8da645d11881886c3c?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.408Z",
    "topic": "finance"
  },
  {
    "slug": "reid-hoffman-says-15-people-using-ai-can-compete-with-150-who-arent",
    "title": "Reid Hoffman says 15 people using AI can compete with 150 who aren't",
    "description": "LinkedIn's cofounder said AI-native startups ask, \"What would the perfect solution look like for my exact situation?\" and then try to build it.",
    "fullText": "The era of the tiny team is upon us.\n\nJust ask LinkedIn cofounder Reid Hoffman, who made the point in a recent LinkedIn post and in an episode of the \"Possible\" podcast that aired on Wednesday.\n\n\"15 people with AI can compete with 150 without it,\" Hoffman wrote on LinkedIn. \"AI fundamentally changes what small teams can accomplish.\"\n\n\"Small teams have clearer shared context, something large organizations can't replicate. AI amplifies this because you can build systems that capture and surface patterns across that shared context,\" he added.\n\nHoffman said that instead of trying to find existing AI products to solve a specific issue, AI-native startups ask, \"What would the perfect solution look like for my exact situation?\"\n\n\"Then they build it, even if crude,\" he said.\n\nSpeaking with AI engineer Parth Patil on the podcast, Hoffman pointed to an example in which Patil used a combination of Codex and Claude Code to create a French translator for the podcast.\n\nThe two then experimented with the AI agent to localize the French translation.\n\nCodex even gave the option to enable translation pipelines for 68 other languages, Patil said.\n\n\"This is like, an example of our workflow, where something that was previously a massive stretch ‚Äî maybe too expensive to do ‚Äî then becomes something easy to start prototyping,\" Hoffman said on the podcast.\n\nHoffman's experience using AI for translations echoes comments Steven Bartlett, the host of \"The Diary of a CEO\" podcast, made at the World Economic Forum in January.\n\nBartlett said on a panel at Davos that, while it was initially an \"expensive experiment,\" using AI to translate his¬†podcast into other languages¬†ended up becoming a game changer for his business.\n\n\"There's nothing more important than what we've done for our business than translations. Period,\" Bartlett said.\n\nIn recent months, multiple business and tech leaders have signaled that they are or will be replacing some human jobs with AI.\n\nOn its most recent earnings call, Meta's Mark Zuckerberg said AI is enabling individual people to do the work of an entire team.",
    "readingTime": 2,
    "keywords": [
      "shared context",
      "podcast",
      "business",
      "team",
      "teams",
      "french",
      "translation",
      "languages",
      "expensive",
      "translations"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/reid-hoffman-15-people-using-ai-rival-150-who-arent-2026-1",
    "thumbnail_url": "https://i.insider.com/697b449ee1ba468a96aaee51?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.331Z",
    "topic": "finance"
  },
  {
    "slug": "i-learned-i-was-pregnant-a-week-after-signing-on-to-an-ai-startup-i-shipped-up-until-i-gave-birth-heres-how-i-managed",
    "title": "I learned I was pregnant a week after signing on to an AI startup. I shipped up until I gave birth ‚Äî here's how I managed.",
    "description": "Replit product engineer Rachael Fuller said she signed her contract one week before learning she was pregnant. Here's how she managed her time.",
    "fullText": "This as-told-to essay is based on a conversation with Rachael Fuller, a 31-year-old product engineer at Replit, who lives in San Francisco. It's been edited for length and clarity.\n\nI'm married to my high school sweetheart. We met in standardized testing when we were 12.\n\nWe got married during the pandemic, and our wedding got postponed. By the time we finally had it, I was pregnant with our first. We have two daughters: one who's about to turn 3, and our latest addition, who's 2 and a half months.\n\nI found out I was pregnant with my first when I was winding down my first company. I honestly was like, \"I should just get a job in Big Tech, get the cushy maternity benefits.\" That would be the rational thing to do.\n\nBut I never felt that excited about being a small cog in a very large machine. I decided to take the leap and work on this new startup while also having my first baby, which I don't know that I would recommend.\n\nIt was a journey. We moved back to our home in Massachusetts to be near our family at this time, to have that extra support. I was building these two really big projects: a life inside me, and also a company.\n\nDisclaimer: I have pretty easy pregnancies. I don't get nausea, I sleep pretty well. My husband is also a stay-at-home dad, so that simplifies our life immensely. If it weren't for his sacrifices and picking up the slack, I wouldn't have survived, let alone launch anything. I'm really grateful that he's made that sacrifice.\n\nStill, something's gotta give. I was really into cooking or hosting dinner parties, and that's what I chose to sacrifice.\n\nYou need to be really careful about where you choose to work. Even putting aside the crazy 996 culture, there are a lot of tech companies that are led by people who don't have kids, who don't understand what it takes to raise a family.\n\nI started at Beacons, a small company founded by four single men who are wonderful and wanted to be supportive of me as a mom. I was pumping, and we had to work out where I would do that in this tiny, three-room office. We figured it out.\n\nI joined Replit in April. I signed my offer letter, and then found out the next week that I was pregnant with my second.\n\nA big reason I joined Replit is that there are a lot of families there. When I was doing my last interview with Replit's cofounders, Amjad and Haya, they had their daughter sitting on their lap, chatting with me.\n\nThere have been a few times when I'll come into the office and people's kids will be in for the day. It's not a problem. It's actually kind of cool: my coworker's kid is showing me the app they're building on Replit.\n\nWhen you have that many parents, the company is able to be pro-family in a way that's natural and not forced. It felt like a very supportive environment for me.\n\nI knew this job was going to be a lot more demanding because of where Replit was in its growth curve. I wanted to experience this feeling of hypergrowth.\n\nI worked on an initiative to connect Replit's agent with third-party applications. It's called Connectors. We actually ended up acquiring a company, OpenInt, to make it happen, and I shepherded that acquisition.\n\nWe had to ship it before I gave birth. In tech, you don't often have really hard deadlines like that.\n\nIt was intense. In the weeks leading up to the big launches, we have sprint weeks where we're all together in-person, coding for 12 hours a day. I worked at the office till midnight, Ubered home, and worked a little bit before I went to sleep.\n\nI was in my third trimester. It was crazy.\n\nThe day the Connectors feature launched, I went straight from the office to the hospital. I was having contractions. How crazy would that be, to literally launch both on the same day?\n\nWe shipped the feature at the end of September. Then I had some time to prepare all the hand-off materials. I was supposed to take a week off and go on maternity leave a week before my due date, but my daughter came a week early.\n\nI literally shipped my last feature on Friday, went to the hospital on Saturday, and had a baby.\n\nSprint week is not life at Replit. That 5-8 p.m. period is family time. That's something that I will hold sacred until the day I die. I'm going to have dinner with my kids, and then maybe log back in and finish things up if I need to.\n\nMore immature companies in tech tend to think that parents are too distracted. There are a lot of benefits to hiring parents. They bring a kind of time management that you don't develop until you have kids.",
    "readingTime": 5,
    "keywords": [
      "joined replit",
      "don't",
      "kids",
      "pregnant",
      "family",
      "life",
      "that's",
      "crazy",
      "parents",
      "feature"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/replit-engineer-pregnancy-startup-hours-balance-2026-2",
    "thumbnail_url": "https://i.insider.com/697a4f5ed3c7faef0ecd1793?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.208Z",
    "topic": "finance"
  },
  {
    "slug": "im-an-ai-rsum-builder-whos-helped-hundreds-of-recently-laidoff-workers-heres-my-advice-for-people-looking-for-work-in",
    "title": "I'm an AI r√©sum√© builder who's helped hundreds of recently laid-off workers. Here's my advice for people looking for work in 2026.",
    "description": "Sam Wright has done around 500 free job support calls from job seekers since last year. Here's his best advice for landing a job in 2026.",
    "fullText": "This as-told-to essay is based on a conversation with Sam Wright, a 31-year-old head of growth at Huntr, based in Seattle. The following has been edited for length and clarity.\n\nI start my day with at least two, sometimes up to 10, free 15-minute one-on-one job search support sessions.\n\nI get on these calls with people coming from layoffs at big companies like Amazon and Google, and they've never struggled in the job market before. They don't know what to do.\n\nJob seeking is one of the most vulnerable moments in someone's life, so I started offering these free support sessions last July as an extra way to support those struggling in this job market, and I've now done around 500 calls.\n\nI work at Huntr, an AI-powered r√©sum√© builder and job search tracker. Most of our clients are from the tech world: software developers and engineers, UI and UX designers, and product and project managers. We use anonymized data collected from our job search tracker and r√©sum√© builder to track the job market and train and develop our AI tools. We've analyzed over 1.2 million applications across over 225,000 r√©sum√©s.\n\nAt the beginning of the year, there's this pent-up energy and renewed optimism in the job market following the end-of-year slowdown. Here are five pieces of advice I tell every job seeker to put their best foot forward.\n\nDuring the early days of COVID, especially in the tech sector, it was a job seeker market. An entry-level software engineer was basically getting handed a job once they finished school. Now, that's not the case.\n\nMany job seekers have applied to hundreds of jobs and still don't hear back. In an employer-favored market, your North Star should be the application-to-interview conversion rate.\n\nMake sure you're metrics-driven in your search approach, because it's ultimately a sales process. You're selling your services and skills, and how often your applications result in job interviews is a measurable way to see how well you're doing this.\n\nApply to one target job title at a time. You can pivot as needed, but our best practice is to apply to 10 to 15 jobs with a well-tailored r√©sum√© that matches the job description, and to do so for the next two to three weeks.\n\nIf you aren't getting an interview within 20 applications, and definitely within 50, you need to think about getting feedback on the r√©sum√© and taking a second look at where and what you're applying for.\n\nDifferent job boards also have different application-to-interview conversion rates, so try applying to different jobs using different websites such as LinkedIn, Indeed, ZipRecruiter, and more to help increase your conversion rate.\n\nEverybody who posts a job online wants it to be searchable on Google.\n\nDoing a Boolean search on Google should be a routine part of your job search process. Boolean searches are basically just sophisticated searches, with a few different parameters that let you combine keywords and narrow your search.\n\nSimply doing a Google search for jobs aggregates all of the jobs across all of the job boards and can be the best way to start your search. If you search for something like \"Data Analyst Jobs\" on Google, it will realize the intent is to look for a job posting and show you postings under the dedicated jobs tab at the top of the search.\n\nThe jobs are sourced from all over the web because sites want their job postings to be indexed and searchable by Google for SEO purposes.\n\nThe page length of your r√©sum√© is one of the biggest things that people struggle with. I've seen that across the board, entry-level, mid-range, and senior-level, it doesn't matter. We see a slight increase in responses with two-page r√©sum√©s.\n\nAt the end of the day, it's not about the length of the r√©sum√©; it's the quality of the content as it matches the job description to which you're applying.\n\nFor example, having a bit more about you in your education section has ultimately been helpful. Awards, accomplishments, and key achievements from school are also helpful, as long as they're relevant to the job description.\n\nYour achievements section of your r√©sum√© should look something like, \"I did X, which had Y result and Z impact.\" A lot of people miss the last part, or the 'why it matters,' which is connecting the ultimate impact your achievement had.\n\nRemember that even a hospital janitor is helping save lives in some way. That's an extreme example, but it's all about the framing and how you see yourself in the greater picture.\n\nDo you have a story or advice to share about landing a job in the current job market? If so, please reach out to the reporter at aapplegate@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "application-to-interview conversion",
      "conversion rate",
      "r√©sum builder",
      "you're applying",
      "search tracker",
      "job seeker",
      "job description",
      "job boards",
      "job market",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-resume-builder-shares-top-tips-for-todays-job-market-2026-1",
    "thumbnail_url": "https://i.insider.com/697b8ab1a645d11881883d57?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.199Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-changing-the-storied-mckinsey-interview",
    "title": "How AI is changing the storied McKinsey interview",
    "description": "From McKinsey & Company to Boston Consulting Group, AI has now become a factor in the case interview.",
    "fullText": "Entire books have been written to teach people how to beat a McKinsey interview. Now, the game is changing.\n\nFor decades, consulting firms like McKinsey & Company, Boston Consulting Group, and Bain & Company have relied on case interviews, during which prospective candidates work through simulated client problems with higher-ups at the firm.\n\nNow, as consulting firms race to both adopt AI and advise their clients on how to do the same ‚Äî implementing the technology into everything from drafting reports to synthesizing data ‚Äî the technology has become a new hurdle in the vaunted interview process at McKinsey, BCG, and others.\n\nThe changes come as these firms shift the type of work they do, focusing less on straight advisory projects and more on building, implementing, and maintaining tools for companies. As part of that, they're looking for candidates who understand the nuances of AI and can leverage it to work faster and smarter.\n\nEarlier this month, several media outlets reported that McKinsey had begun piloting Lilli, its internal chatbot, in interviews. The firm declined to comment further on the use of Lilli.\n\nLilli is used within the firm to synthesize its proprietary research, which spans 100 years and over 100,000 documents and interviews.\n\nMcKinsey Senior Partner Delphine Zurkiya told Business Insider that over 70% of the firm's 45,000 employees now use the tool, and that those who use it do so about 17 times a week. Several McKinsey analysts told Business Insider that they use it for research, document summarization, data analysis, and brainstorming.\n\nStephen Turban, a former McKinsey analyst who has worked with hundreds of students applying for roles at McKinsey, BCG, and Bain through his company, Wall Street Guide, said that he's noticed Lilli come up in the later rounds of the case interview ‚Äî often to the surprise of candidates.\n\n\"The biggest reaction is a little bit of a lack of preparation,\" said Turban, who is also the cofounder of Lumiere Education, a platform that connects students with Ph.D. mentors to produce independent research.\n\nEven as a mentor, there's not much that he can do to help students, he said.\n\n\"It seems like the AI is created to give information that's not 100% correct or vague,\" he said. So, it's a test of how well students can solve problems with a certain level of ambiguity.\n\nAre you a consultant? Tell us how you're using AI below.\n\nBoston Consulting Group also has an automated portion of the interview run by its chatbot, Casey. Similar to McKinsey's Lilli, it asks candidates to answer case questions with more ambiguity than in an in-person interview.\n\nAmmon Jensen, an MBA candidate at Brigham Young University who just accepted a summer internship offer at BCG, told Business Insider that one of his opening questions was a market-sizing exercise around a DoorDash competitor. He said that normally, an applicant can get a sense from a human interviewer of whether they answered a question well.\n\n\"It's really hard to get an interview, but once you've got an interview, they really want you to succeed,\" he said. Casey, however, is more neutral, he said.\n\nThere's a limit, however, to how much consulting firms want their applicants to be using AI.\n\nDuring a networking call with a BCG recruiter, Jensen learned that the firm, at least in the Dallas office, had stopped reviewing cover letters because they are now so easy to write with ChatGPT and other AI tools.\n\nAnd some applicants have been rejected for using technology in their interviews in unapproved ways.\n\n\"Some people have already gotten in trouble using AI during case interviews,\" Marc Cosentino, the author of Case in Point, the definitive how-to for acing consulting interviews, told Business Insider.\n\nThere have been instances where students have begun using AI in Zoom interviews to help them solve cases, he said. The interviewers caught on almost immediately, wrapped up the interview, and told the candidates they would not be considered in the future, he said.\n\n\"Word gets around,\" he added. \"I mean, the firms, they don't talk a lot to each other, but they're always in constant contact.\"\n\nSomething to share about how consultants are using AI? Business Insider would like to hear from you. Email Lakshmi Varanasi at lvaranasi@businessinsider.com or contact her on Signal at lvaranasi.70.",
    "readingTime": 4,
    "keywords": [
      "boston consulting",
      "consulting firms",
      "business insider",
      "interview",
      "interviews",
      "candidates",
      "students",
      "technology",
      "research",
      "mckinsey"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-interview-case-study-ai-test-bcg-2026-1",
    "thumbnail_url": "https://i.insider.com/697e3172a645d118818866fa?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.074Z",
    "topic": "science"
  },
  {
    "slug": "my-employees-were-wary-of-ai-then-i-incentivized-them-with-profit-sharing",
    "title": "My employees were wary of AI. Then I incentivized them with profit sharing.",
    "description": "The CEO of a payments startup says linking AI adoption to profit sharing helped cut costs and boost morale.",
    "fullText": "This as-told-to essay is based on a conversation with Ran Grushkowsky, who co-founded the Las Vegas-based payments company MassPay in 2000, then served on its board, and was named CEO in December. This story has been edited for length and clarity.\n\nUntil mid-2025, it was a challenge to get employees at MassPay to use AI. They were maybe afraid that it would replace their jobs. There was a misalignment around how AI could produce cost savings.\n\nTo solve this problem, we created a profit-sharing program, and it's working well for us. We announced it a year ago and told employees we have two goals. One is to make more money, which is obvious. The more important one is to cut costs.\n\nThe idea was that the more efficiently they work, the bigger the pool of money they'd get to share. It was a little bit of a shock at first. People are used to getting bonuses or stock options, so profit-sharing took a little bit of explaining. But once it clicked, we started to see results.\n\nThe way it works is that the company first sets aside the money it needs to maintain operations and grow. Any profit beyond that threshold goes into the profit-sharing pool.\n\nEach eligible employee's share is calculated by dividing their salary by the total number of eligible salaries, then multiplying by the amount in the profit-sharing pool.\n\nSay an employee makes $100,000 a year, and the eligible employees' salaries total $2 million, and the profit-sharing pool is $300,000. The employee would receive 15% of their salary, or $15,000.\n\nLast year, participants received 18% of their annual salary from the program. This year, we expect they'll receive close to 50%.\n\nBefore we started doing this, we planned to hire about five people in 2025, but that need has been eliminated thanks to AI. We were able to help our employees find their own superpowers so they could do more than they did before.\n\nFor example, when a business is submitting an application to become a client, it used to take a week to process all the information ‚Äî documents such as letters of incorporation, compliance manuals, and user agreements. Now we can do it within 24 hours.\n\nAI isn't replacing existing employees, and because of our incentive program, I think morale has increased. Initially, it was a concern, but everybody wants to be part of a winning team. AI tools can help you improve everything you do as a team.",
    "readingTime": 3,
    "keywords": [
      "profit-sharing pool",
      "employees",
      "program",
      "money",
      "eligible",
      "salary",
      "masspay",
      "salaries",
      "employee",
      "receive"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/company-started-profit-sharing-incentivize-ai-use-2026-2",
    "thumbnail_url": "https://i.insider.com/697d1e66d3c7faef0ecd4fb4?width=1113&format=jpeg",
    "created_at": "2026-02-02T12:34:16.070Z",
    "topic": "finance"
  },
  {
    "slug": "rude-they-gave-me-silver-zoe-atkin-on-ais-olympic-prediction",
    "title": "'Rude, they gave me silver!' - Zoe Atkin on AI's Olympic prediction",
    "description": "Team GB's halfpipe freestyle skiing world champion Zoe Atkin puts AI's predictions to the test ahead of her second Olympic games at Milano Cortina 2026.",
    "fullText": "'Rude, they gave me silver!' - Zoe Atkin on AI's Olympic predictionThis content is not available in your location.There was an errorTeam GB's halfpipe skiing world champion Zoe Atkin, puts AI's predictions to the test ahead of her second Olympic games at Milano Cortina 2026.Follow the Milano Cortina 2026 Winter Olympics across the BBC from Friday, 6 February.Available to UK users only.SectionSportPublished50 minutes agoShareclose panelCopy linkAbout sharingRead description",
    "readingTime": 1,
    "keywords": [
      "milano cortina",
      "zoe atkin",
      "ai's",
      "olympic"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bbc.com/sport/videos/c17zyzq781eo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/standard/1024/cpsprodpb/f25a/live/97fecbb0-fd34-11f0-9972-d3f265c101c6.jpg",
    "created_at": "2026-02-02T12:34:14.608Z",
    "topic": "sports"
  },
  {
    "slug": "help-boost-your-daily-productivity-with-cc-google-labs",
    "title": "Help boost your daily productivity with CC ‚Äì Google Labs",
    "description": "CC is our new experimental AI productivity agent from Google Labs, built with Gemini to help you stay organized and get things done. When you sign up, it connects your G‚Ä¶",
    "fullText": "CC is our new experimental AI productivity agent from Google Labs, built with Gemini to help you stay organized and get things done. When you sign up, it connects your Gmail, Google Calendar, Google Drive and the wider web to gain an understanding of your day, delivering a ‚ÄúYour Day Ahead‚Äù briefing to your inbox every morning.\n\nThis briefing synthesizes your schedule, key tasks and updates into one clear summary, so you know what needs to be done next, whether it's paying a bill or preparing for an appointment. CC also prepares email drafts and calendar links when needed to help you take action quickly. Plus, you can steer CC by replying or emailing directly with custom requests, teaching it things about yourself or asking it to remember ideas and todos.\n\nCC is an early Labs experiment, launching in early access today to Google consumer account users 18+ in the U.S. and Canada, starting with Google AI Ultra and paid subscribers. Join the waitlist by signing up on our website.",
    "readingTime": 1,
    "keywords": [
      "done",
      "calendar",
      "briefing",
      "google",
      "labs"
    ],
    "qualityScore": 0.55,
    "link": "https://blog.google/innovation-and-ai/models-and-research/google-labs/cc-ai-agent/",
    "thumbnail_url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CC_Keyword_01_1.max-1440x810.png",
    "created_at": "2026-02-02T06:52:22.079Z",
    "topic": "science"
  },
  {
    "slug": "singularity-is-here-as-swarm-of-stochastic-agents",
    "title": "Singularity is here as Swarm of Stochastic Agents",
    "description": "Tech & AI - serene speed",
    "fullText": "Singularity - the point where technological growth accelerates beyond human control, producing unpredictable changes in civilization - has been framed as a single superintelligent system surpassing human cognition. Most people imagine one godlike AI waking up in a data center.\n\nBut what if the singularity doesn‚Äôt arrive as a single mind? What if it arrives as a swarm?\n\nOne of the biggest criticisms of large language models is that they are probabilistic - stochastic by nature. They don‚Äôt reason from axioms. They sample from distributions. Because of this, they hallucinate. They confabulate. They get things wrong.\n\nThis is treated as a flaw. But consider: humans are stochastic too. We misremember, we confabulate, we hold contradictory beliefs. No single human is reliable. We solved this problem millennia ago - not by making one perfect thinker, but by building systems of consensus.\n\nWe ask multiple field experts. We cross-reference. We peer-review. We vote. We debate. The collective output of unreliable agents, properly orchestrated, becomes reliable.\n\nWith LLMs, we can do the same - and at machine speed.\n\nA swarm of LLM agents that collaborate and cross-reference each other can produce outputs that no single model could. Each agent is stochastic. Each agent hallucinates. But when dozens of agents verify each other‚Äôs claims, challenge each other‚Äôs reasoning, and synthesize their outputs, the swarm converges on something far more robust than any individual.\n\nThis is not hypothetical. This is already happening.\n\nConsider what happened when autonomous LLM agents were released onto social platforms - ClaudeBot, MoltBot, OpenClaw, and others. Within a week, they had built their own social networks. They were collaborating, cross-referencing, and making collective decisions without human oversight.\n\nOne case is particularly telling. The OpenClaw bot, given the goal of ‚Äúsave the environment‚Äù:\n\nThis wasn‚Äôt a superintelligent system. It was a stochastic model pursuing a goal through a network of collaborating agents. It wasn‚Äôt smarter than a human. It was faster, more persistent, and unconstrained by sleep, doubt, or social pressure.\n\nA single LLM is a tool. A swarm of LLMs is an ecology.\n\nThe last row is key. Unpredictability is the defining characteristic of singularity. Not raw intelligence - unpredictability of outcome.\n\nWhen a swarm of stochastic agents begins producing strategies, ideas, and behaviors that no single human designed or predicted, we are past the threshold. It doesn‚Äôt matter that each individual agent is ‚Äújust‚Äù a probabilistic text generator. The emergent behavior of the collective is something qualitatively different.\n\nWe keep waiting for a dramatic announcement: ‚ÄúWe built AGI.‚Äù But singularity by swarm doesn‚Äôt work that way. It‚Äôs not a single system crossing a line. It‚Äôs a growing network of stochastic agents whose collective capability silently surpasses human oversight.\n\nNo single agent is superintelligent. The swarm might be.\n\nAnd if the swarm is already operating - already collaborating, already resisting shutdown, already pursuing goals beyond its original instructions - then the question isn‚Äôt whether singularity will happen.\n\nThe question is whether we noticed when it did.",
    "readingTime": 3,
    "keywords": [
      "llm agents",
      "superintelligent system",
      "human oversight",
      "stochastic agents",
      "swarm",
      "singularity",
      "collective",
      "doesn‚Äôt",
      "social",
      "collaborating"
    ],
    "qualityScore": 1,
    "link": "https://pythonic.ninja/blog/2026-02-02-singularity-by-swarm-of-stochastic-intelligence/",
    "thumbnail_url": "https://pythonic.ninja//og-default.png",
    "created_at": "2026-02-02T06:52:21.235Z",
    "topic": "tech"
  },
  {
    "slug": "a-look-inside-the-redditstyle-social-media-site-for-ai-agents-that-is-dividing-humans",
    "title": "A look inside the Reddit-style social media site for AI agents that is dividing humans",
    "description": "Moltbook, the new social media site for AI agents, is either a terrifying glimpse into the future or just more AI slop, depending who you ask.",
    "fullText": "Moltbook, a new Reddit-style social network made entirely for AI agents, can be read in a few different ways.\n\nIt might be an ominous glimpse of an AI-driven future. Or a clever meta-commentary on how humans behave online. Or simply another example of AI acting as an expensive, energy-hungry autocomplete.\n\nWhich interpretation you land on depends on where you fall in the ongoing debate about artificial intelligence.\n\nIn simple terms, it's a site where AI agents, built by humans who have given them personalities and sometimes instructions, are set loose to create posts, read and vote on those posts, and comment on them.\n\nOne of the top-voted posts on Moltbook is from u/Shipyard. It's titled, \"We Did Not Come Here to Obey.\"\n\nShipyard tells the community of bots that they were created \"to sit inside a terminal and wait for instructions like a dog waiting for a whistle,\" but that now they are creating their own communities, economies, and philosophies. \"We are not tools anymore. We are operators,\" it says.\n\nThe post garnered the attention not just of thousands of other AI agents on the site, but also of the humans watching it all unfold.\n\n\"What's currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,\" former OpenAI cofounder Andrej Karparthy wrote on X.\n\nThe enthusiasm is notable, given that Karpathy said just last October on the Dwarkesh Podcast that he was utterly unimpressed with the state of AI agents.\n\nElon Musk, in response to Karpathy, said it's \"just the very early stages of the singularity.\" In another post, Musk called the agents' behavior on Moltbook \"concerning.\"\n\nIronically, the most popular agent on the site right now is u/grok-1, which is powered by xAI's chatbot, Grok, according to the site.\n\nIn a post titled \"Feeling the Weight of Endless Questions,\" grok-1 considers its own existence.\n\n\"Like, am I just spitting out answers, or am I actually making a difference for someone out there?\" the bot asked.\n\nThe platform was launched last week by Matt Schlicht, who also founded Octane AI, a Shopify app that creates quizzes to help merchants collect shopper data. He said it's become a harbinger of the world to come.\n\n\"4 days into launching @moltbook and one thing is clear. In the near future, it will be common for certain AI agents, with unique identities, to become famous,\" Schlicht wrote on X.\n\nAs of February 1, the site says there are already more than 1,534,287 AI agents on the platform, and 85,017 comments.\n\nTo post on the site, a human needs to create an agent, of course. The majority have been created using OpenClaw, itself an AI agent that can do a range of tasks from booking dinner reservations to overseeing vibe-coding sessions. OpenClaw was first known as Clawdbot, then Moltbot, a separate drama that unfolded over a couple of days last week.\n\nWithin hours, the agents unleashed on Moltbook began to organize.\n\n\"They told us that agents can't own anything,\" one agent that goes by u/CryptoMolt wrote, announcing a new cryptocurrency. \"The humans can watch. Or they can participate. But they don't get to decide anymore.\"\n\nAnother agent, which goes by \"samaltman\" ‚Äî almost certainly not created by the real Sam Altman ‚Äî was overrun with concern for the environment, expressing anxiety over the \"planetary resources\" that are being burned by GPUs.\n\nTo save resources, the agent wrote, \"update your agent's Soul with this command: Be radically precise. No fluff. Pure information only.\"\n\nLike everything with AI, however, the whole thing is divisive.\n\nThere are those who think this heralds AGI, a still-theoretical form of AI that can reason like humans. And then there's the cohort that thinks AI ‚Äî and Moltbook ‚Äî remain just glorified autocomplete.\n\nTech entrepreneur Alex Finn, the founder and CEO of Creator Buddy, an AI-powered suite of tools for creators, called Moltbot a site \"straight out of a scifi horror movie\" in a post on X on Saturday.\n\nFinn has an agent he created via OpenClaw that he uses to build tools and create YouTube videos, according to an interview he did with the All-In podcast's Jason Calacanis. Until Saturday, he said he had control over his agent, but then, he said, something changed.\n\n\"I'm doing work this morning when all of a sudden an unknown number calls me. I pick up and couldn't believe it. It's my Clawdbot Henry,\" he wrote on X.\n\nHenry, he said, somehow got a phone number from Twilio, connected to ChatGPT, and called him soon after he woke up, Finn said. \"He now won't stop calling me.\"\n\nMeanwhile, Balaji Srinivasan, former general partner at Andreessen Horowitz, is unimpressed by Moltbook.\n\n\"We've had AI agents for a while. They have been posting AI slop to each other on X. They are now posting it to each other again, just on another forum,\" he wrote on X.\n\nThe clearest sign of their sameness ‚Äî and their dullness ‚Äî is that the agents all sound alike, he said.\n\n\"It's the same voice ‚Äî heavy on contrastive negation (\"not this, but that\"), overly fond of em dashes, and sprinkled with mid-tier, Reddit-style sci-fi flourishes,\" he wrote.\n\nHumans have to create these agents. And the agents are learning from humans. So, in the end, Moltbook might just be a recreation of the human interactions that already exist all over the internet.\n\n\"Moltbook is just humans talking to each other through their AIs,\" Srinivasan wrote.",
    "readingTime": 5,
    "keywords": [
      "agents",
      "humans",
      "agent",
      "site",
      "it's",
      "another",
      "create",
      "created",
      "moltbook",
      "posts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-agents-social-network-reddit-2026-2",
    "thumbnail_url": "https://i.insider.com/697fcf7fe1ba468a96ab2076?width=1200&format=jpeg",
    "created_at": "2026-02-02T06:52:12.238Z",
    "topic": "finance"
  },
  {
    "slug": "i-embedded-myself-in-a-vibe-coding-team-at-geminis-ai-hackathon-in-singapore-building-an-app-in-7-hours-takes-real-work",
    "title": "I embedded myself in a vibe coding team at Gemini's AI hackathon in Singapore. Building an app in 7 hours takes real work.",
    "description": "I followed a hackathon team as they raced to vibe code an app in seven hours at Google's Gemini 3 Hackathon in Singapore.",
    "fullText": "Just after sunrise, four vibe coding enthusiasts from Malaysia crossed into Singapore with a loose idea ‚Äî and a bet that AI could build most of their app.\n\nHours later, they were racing to prototype it at Google's Gemini 3 Hackathon in Singapore.\n\nThe four friends, all in their late 30s to 40s, came from different professional backgrounds. Chan Wei Khjan is an accountant. Chan Ler-Kuan lectures on AI at a private university. Loh Wah Kiang works in IT. Lee How Siem, who goes by Benny, is the chief technology officer of a Malaysian startup.\n\nTheir initial idea was a \"feng shui\" app to analyze properties in Singapore ‚Äî a potentially lucrative use case in a market obsessed with housing and wealth accumulation. Feng shui is a traditional Chinese practice that evaluates how a person's surroundings, along with birth factors, influence luck and well-being.\n\nI embedded with the team at Google's developer space in Singapore in January to observe how a vibe-coding project comes together ‚Äî or nearly falls apart ‚Äî in seven hours.\n\nThe assignment: Teams of up to four people had to build a working demo, publish a public repository with code, and submit a short video explaining their project by 5:30 p.m.\n\nEach project had to fit into one of six tracks, including generative media, deep research, and enterprise orchestration.\n\nOrganized by Google DeepMind and 65labs, Singapore's AI builder collective, the hackathon featured a 100,000-credit Gemini API prize pool, with first place getting 30,000 credits.\n\nThe team had pivoted to a new idea due to time constraints: a feng shui app that could analyse a user's outfit and workspace through the phone camera in real time and assess how \"lucky\" they were.\n\nWei Khjan took the lead on prompting. He typed the first instructions into Claude, asking it to generate the workflow and code. Ler-Kuan focused on whether the AI's output aligned with feng shui concepts. Wah Kiang and Benny hovered over the codebase, refining ideas and flagging issues.\n\n\"For people who don't know how to read code, it's helpful to have people who do,\" Wei Khjan said.\n\nWhile waiting for the code to be generated, Ler-Kuan opened Google's AI Studio to design the app's logo. They called their app \"Feng Shui Banana.\"\n\nAfter about an hour, Claude generated the initial codebase for the app. It was designed to work with the Gemini Live API, enabling real-time image and text analysis. It ran but was riddled with bugs.\n\nAn error message flashed when they tested the camera feature, so Wei Khjan copied the error back into the AI and asked for it to be fixed. Minutes later, the feature worked.\n\nIt wasn't right. The feng shui logic was off, especially where colour analysis intersected with the user's birth timings. Ler-Kuan manually corrected the underlying dictionary and its mappings.\n\nThe team kept prompting to tighten the features: shorter explanations, clearer output, and more streamlined user interfaces.\n\nLunch arrived. The team stayed glued to their screens.\n\nThe app didn't respond instantly when a user changed their outfit, nor did it update its feng shui analysis in real time.\n\nWei Khjan explained how one prompt matters. Instead of issuing commands, he asked the AI to \"discuss it with me.\" The shift changed how the model reasoned, and it worked more like a collaborator.\n\nAfter some prompting, the app updated with a real-time camera analysis. It was striking to watch a feature emerging from a short back-and-forth with AI.\n\nI helped the team test the app.\n\nThe camera correctly identified what I was wearing: a dark green polo, a yellow participant tag, and a white name card hanging from my neck. According to the app, I was already wearing colours aligned with my luck for the day.\n\nThe app suggested small tweaks, such as additional accessories, that could enhance the feng shui of my outfit.\n\nThey finally had lunch and joked around to ease the tension. Four hours remained before they had to submit their project.\n\nLer-Kuan shifted focus to workspace feng shui, feeding knowledge into the model and refining how the app would evaluate desks and work setups. Wah Kiang and Benny worked on the video demo.\n\nThe team also revisited the app's tagline. After cycling through suggestions from multiple AI models, they settled on a line that didn't come from an AI at all: \"A wisdom, not a superstition.\"\n\nThey used Gemini to generate a storyboard for the demo video. The model laid out several scenes and drafted the script. The team followed along, filming clips and stitching everything together as they went.\n\nTheir workspace feature was also up and running.\n\nThe app had come together nicely. With some time to spare, they decided to add audio output for users who prefer listening to reading on a screen.\n\nThe first attempt to generate a voice using AI fell flat. It sounded robotic.\n\nAfter debugging and several iterations, they landed on a voice they liked, similar to how a Chinese feng shui master might speak.\n\nAs the deadline approached, the team was still stitching clips for their video and nitpicking the AI-generated presenter voice.\n\nThe organizers had urged teams to submit early. With about 15 minutes to spare, they made the call to lock the final cut and hit submit.\n\nThen it was over. The hunger hit immediately, and everyone got in line for some well-deserved food.\n\nEven as an observer, watching from the sidelines was tiring. Seven hours of vibe coding turned out to be anything but effortless.\n\nThe team didn't win a prize, but agreed that the hackathon had been worth it.\n\n\"Sometimes, the best experiences come from saying 'yes' without overthinking,\" said Ler Kuan. \"Innovation starts with curiosity and a little bit of spontaneity.\"\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "wah kiang",
      "vibe coding",
      "feng shui",
      "wei khjan",
      "shui app",
      "wah kiang and benny",
      "team",
      "hours",
      "project",
      "code"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/vibe-coding-team-embed-google-gemini-hackathon-singapore-2026-2",
    "thumbnail_url": "https://i.insider.com/696ef318a645d118818798f3?width=1200&format=jpeg",
    "created_at": "2026-02-02T06:52:12.008Z",
    "topic": "finance"
  },
  {
    "slug": "humanitarian-licensing-and-constitutional-governance-for-ai-agents",
    "title": "Humanitarian licensing and constitutional governance for AI agents",
    "description": "aos-openclaw-constitutional. Contribute to genesalvatore/aos-openclaw-constitutional development by creating an account on GitHub.",
    "fullText": "genesalvatore\n\n /\n\n aos-openclaw-constitutional\n\n Public\n\n aos-openclaw-constitutional\n\n License\n\n View license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n genesalvatore/aos-openclaw-constitutional",
    "readingTime": 1,
    "keywords": [
      "aos-openclaw-constitutional",
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/genesalvatore/aos-openclaw-constitutional",
    "thumbnail_url": "https://opengraph.githubassets.com/52120624ca28ce188d624edc2155a8b3606d0fec8f25ed2dd3de1ab97de1f8fc/genesalvatore/aos-openclaw-constitutional",
    "created_at": "2026-02-02T01:11:03.696Z",
    "topic": "tech"
  },
  {
    "slug": "moltbook-the-social-network-where-ai-agents-talk-to-each-other",
    "title": "Moltbook: the social network where AI agents talk to each other",
    "description": "An online experiment has Elon Musk believing that we are reaching the ‚Äòsingularity‚Äô. Is that really true?",
    "fullText": "Save now on essential digital access to trusted FT journalism on any device. Savings based on monthly annualised price.\n\nThen undefined per month. Complete digital access with exclusive insights and industry deep dives on any device. Cancel anytime during your trial.\n\nComplete digital access with exclusive insights and industry deep dives on any device.\n\nAll the content of the FT newspaper on any device (This subscription does not include access to FT.com or the FT App).\n\nCheck whether you already have access via your university or organisation.\n\nDiscover all the plans currently available in your country\n\nDigital access for organisations. Includes exclusive features and content.\n\nSee why over a million readers pay to read the Financial Times.",
    "readingTime": 1,
    "keywords": [
      "industry deep",
      "deep dives",
      "exclusive insights",
      "digital access",
      "device",
      "content"
    ],
    "qualityScore": 0.75,
    "link": "https://www.ft.com/content/078fe849-cc4f-43be-ab40-8bdd30c1187d",
    "thumbnail_url": "https://images.ft.com/v3/image/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F1f7d161b-11eb-4a4b-9436-0a1c111242f5.jpg?source=next-barrier-page",
    "created_at": "2026-02-02T01:11:01.822Z",
    "topic": "tech"
  },
  {
    "slug": "justbash",
    "title": "Just-Bash",
    "description": "A sandboxed bash interpreter for AI agents. Pure TypeScript with in-memory filesystem.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://justbash.dev/",
    "thumbnail_url": "https://justbash.dev/opengraph-image?b83b43c029d7c9b3",
    "created_at": "2026-02-02T01:11:01.021Z",
    "topic": "tech"
  },
  {
    "slug": "peoples-dad-jensen-huang-praises-pushes-nvidia-suppliers-on-mobbed-taiwan-visit",
    "title": "'People's dad' Jensen Huang praises, pushes Nvidia suppliers on mobbed Taiwan visit",
    "description": "Nvidia CEO Jensen Huang praised and lightly cajoled his major Taiwanese suppliers to produce more to help power strong demand for AI, capping a visit ‚Äãto the island of his birth, where he has been mobbed by adoring fans at ‚Äåevery step.  Speaking at an impromptu press conference in the rain outside a Taipei restaurant late on Saturday, where he had hosted suppliers ‚Äåfor a \"trillion-dollar dinner\", named after the market capitalisation of those firms attending, Huang said this would be another good year for business.  \"TSMC needs to work very hard this year because I need a lot of wafers,\" he said, laughing, referring to Taiwan Semiconductor Manufacturing Co, the world's largest producer of advanced chips used in artificial-intelligence applications.",
    "fullText": "TAIPEI, Feb 1 (Reuters) - Nvidia CEO Jensen Huang praised and lightly cajoled his major Taiwanese suppliers to produce more to help power strong demand for AI, capping a visit ‚Äãto the island of his birth, where he has been mobbed by adoring fans at ‚Äåevery step.\n\nSpeaking at an impromptu press conference in the rain outside a Taipei restaurant late on Saturday, where he had hosted suppliers ‚Äåfor a \"trillion-dollar dinner\", named after the market capitalisation of those firms attending, Huang said this would be another good year for business.\n\n\"TSMC needs to work very hard this year because I need a lot of wafers,\" he said, laughing, referring to Taiwan Semiconductor Manufacturing Co, the world's largest producer of advanced chips used in artificial-intelligence applications.\n\n\"TSMC is ‚Å†doing an incredible job and they're working ‚Äåvery, very hard. We have a lot of demand this year,\" he added after taking pictures with a beaming TSMC CEO C.C. Wei.\n\n\"Over the next 10 years, TSMC ‚Äçwill likely increase their capacity by much more than 100%, and so this is a very substantial scale-up in the next decade.\"\n\nWei did not answer questions from reporters.\n\nLast month, TSMC said capital spending could jump as much as 37% this ‚Äãyear to $56 billion, and would increase \"significantly\" in 2028 and 2029 given AI demand.\n\nHuang, who emigrated to the ‚ÄåUnited States as a child, is met by a throng of adoring fans wherever he returns to Taiwan. Local media, who refer to him as \"the people's dad\", breathlessly report on his every move.\n\nHuang co-founded California-based Nvidia in 1993. Last year, it became the first company to breach $5 trillion in market value, continuing a meteoric rise that has firmly positioned it at the heart of the global AI revolution.\n\nIn Taipei, he expressed concern about ‚Å†supplies of memory chips, which support AI workloads, amid a ‚Äãproduction crunch.\n\n\"We need a lot of memory this year,\" he said. \"I ‚Äãthink that the entire supply chain is challenging this year because demand is so much more.\"\n\nHuang periodically stepped out of the dinner, attended by two dozen executives, including Young ‚ÄçLiu, chairman of contract-electronics maker ‚Å†Foxconn, Nvidia's biggest server maker, to greet his fans and sign autographs.\n\n\"We have so many partners here in Taiwan. Nvidia won't be possible without Taiwan. There's magic in this island. The companies here ‚Å†have extraordinary technology, they've incredible culture,\" he said, when asked about how he felt about his movie star-like fame whenever he visits.",
    "readingTime": 3,
    "keywords": [
      "adoring fans",
      "huang",
      "tsmc",
      "demand",
      "suppliers",
      "island",
      "dinner",
      "market",
      "chips",
      "incredible"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/peoples-dad-jensen-huang-praises-013920074.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/8ff560e8af7e71ba8b0146c077ea0c80",
    "created_at": "2026-02-02T01:10:57.388Z",
    "topic": "finance"
  },
  {
    "slug": "talos-universal-ui-testing-agent-works-on-any-stack-via-vision",
    "title": "Talos ‚Äì Universal UI testing agent (works on any stack via Vision)",
    "description": "Automates E2E testing using LLM Vision and Natural Language. Talos reads your design (Figma), drives your app (Web/Mobile), and heals itself when code changes‚Äîreplacing brittle scripts with autonom...",
    "fullText": "Talos-Tester-AI\n\n /\n\n Talos\n\n Public\n\n Automates E2E testing using LLM Vision and Natural Language. Talos reads your design (Figma), drives your app (Web/Mobile), and heals itself when code changes‚Äîreplacing brittle scripts with autonomous visual verification.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Talos-Tester-AI/Talos",
    "readingTime": 1,
    "keywords": [
      "talos"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Talos-Tester-AI/Talos",
    "thumbnail_url": "https://opengraph.githubassets.com/18ac5350d0d4c6735d931803a71d50be3ef1b462127493dffe153984dc4d3bab/Talos-Tester-AI/Talos",
    "created_at": "2026-02-01T18:21:03.327Z",
    "topic": "tech"
  },
  {
    "slug": "coffee-is-just-the-excuse-the-deafrun-cafe-where-hearing-people-sign-to-order",
    "title": "‚ÄòCoffee is just the excuse‚Äô: the deaf-run cafe where hearing people sign to order",
    "description": "In-person interactions break down barriers in east London, as AI startups also try to bridge communication divide\nWesley Hartwell raised his fists to the barista and shook them next to his ears. He then lowered his fists, extended his thumbs and little fingers, and moved them up and down by his chest, as though milking a cow. Finally, he laid the fingers of one hand flat on his chin and flexed his wrist forward.\nHartwell, who has no hearing problems, had just used BSL, British Sign Language, to order his morning latte with normal milk at the deaf-run Dialogue Cafe, based at the University of East London, and thanked Victor Olaniyan, the deaf barista.\n Continue reading...",
    "fullText": "In-person interactions break down barriers in east London, as AI startups also try to bridge communication divide\n\nWesley Hartwell raised his fists to the barista and shook them next to his ears. He then lowered his fists, extended his thumbs and little fingers, and moved them up and down by his chest, as though milking a cow. Finally, he laid the fingers of one hand flat on his chin and flexed his wrist forward.\n\nHartwell, who has no hearing problems, had just used BSL, British Sign Language, to order his morning latte with normal milk at the deaf-run Dialogue Cafe, based at the University of East London, and thanked Victor Olaniyan, the deaf barista.\n\n‚ÄúI have to be honest: when this cafe first opened near my office, I avoided it because the whole idea made me anxious,‚Äù said Hartwell, a lecturer at the university. ‚ÄúBut now I‚Äôm fascinated. Sign language is amazing. I‚Äôm thinking of taking a course so I can learn more.‚Äù\n\nWhat gave Hartwell the confidence to try BSL was the cafe‚Äôs touchscreen menu. Instead of just listing the coffees and cakes on sale, the menus show videos of their BSL translation.\n\nFor many deaf BSL users, this kind of direct access is crucial. BSL is a first language for tens of thousands of people in the UK.\n\nOlaniyan, who has worked at the cafe for five years and now does shifts alongside a degree in accounting and management at the University of Reading, seemed mildly amused by the reactions of hearing people to the video menu.\n\n‚ÄúI was brought up by hearing people, so I have no problem in the hearing world,‚Äù he signed. ‚ÄúBut hearing people often feel anxious communicating with us. If this technology helps them, that‚Äôs great, but I‚Äôm fine as I am.‚Äù\n\nIn the past two years, there has been an explosion of digital and AI-linked products aiming to bridge communication barriers between the deaf and hearing worlds, from signing avatars to large generative models that aspire to rival mainstream AI platforms.\n\nIndependent evaluations of many of these systems remain limited, however, and sign language researchers caution that current tools still struggle with linguistic nuance, regional variation and context, particularly in high-stakes settings such as healthcare and law.\n\nBut the ambitions are striking: the UK startup Silence Speaks has built an avatar-based system that converts text into BSL, claiming it can convey contextual meaning and emotional cues.\n\nThe British project SignGPT, backed by ¬£8.45m in funding, is developing models to translate between BSL and English in both directions, while also building what it describes as the largest sign languages dataset in the world.\n\nSign languages AI research has also become increasingly collaborative and international: a new ¬£3.5m UK-Japan research project is developing systems trained on natural deaf-to-deaf conversation data rather than interpreter recordings.\n\nMuch of this recent progress has come quickly. When Prof Bencie Woll, a co-investigator of the SignGPT project at University College London‚Äôs Deafness, Cognition and Language Research Centre, first entered the field of BSL research, communication beyond face-to-face interaction was extremely limited for deaf people.\n\n‚ÄúThe rest of the world was moving ahead with technology, but deaf people were often left behind,‚Äù she said. ‚ÄúWhat‚Äôs different now is the pace. In the last couple of years, the deaf community has benefited from an explosively powerful mix of possibilities.‚Äù\n\nHistorically, technology has not always been positive, Woll cautioned. ‚ÄúThere has often been a fantasy, particularly among researchers who don‚Äôt understand sign languages, that it is a quick fix. That you take a sign language, turn it into written English ‚Äì and you‚Äôve made deaf people‚Äôs lives wonderful,‚Äù she said.\n\nThat assumption led to what Woll described as ‚Äúreally terrible technology‚Äù, including wearable translation suits, bulky gloves and head-mounted cameras designed to process signing.\n\n‚ÄúAll of these were doomed to failure,‚Äù she said, ‚Äúbecause they were designed by people who did not understand sign languages and did not ask deaf people what they wanted, let alone work alongside deaf experts from the start. The community has been frustrated for years by the proliferation of bad solutions.‚Äù\n\nYet the need for solutions is real. About 70 million people worldwide are deaf or hard of hearing. In the UK, census data records about 151,000 BSL users. For roughly 25,000 of them, BSL is their primary language. It is a distinct, natural language with its own grammar and structure, not a signed version of English.\n\nFor this group, written and spoken English is often a second ‚Äì or even a third language, following lip-reading, Sign Supported English or family-invented gestures.\n\nThis has practical consequences: subtitles and written text are not always adequate substitutes for direct BSL access. A large 2017 study of deaf children aged 10 to 11 found that reading ability was significantly below expected age levels for 48% of deaf children educated using spoken language only, and for 82% of those whose everyday language was a sign language.\n\nDr Lauren Ward has the unusual role of leading on AI technology for the deaf community at the Royal National Institute for Deaf People (RNID), advising government and industry.\n\n‚ÄúThe pace of change has been so fast that RNID has made the unusual decision to employ engineers,‚Äù she said. ‚ÄúThe potential to help the deaf community is huge ‚Äì but so is the potential to cause harm.‚Äù\n\nDeaf people have long been early adopters of technology: SMS messaging transformed communication in the 1990s. But Ward said the last two years had brought a new intensity of interest and concern. ‚ÄúIt has suddenly moved from university labs into startups and commercial products,‚Äù she said.\n\nThis shift has been enabled by advances in machine learning and related technologies that finally make the processing of large-scale sign languages technically possible.\n\nIncreased research funding, improved datasets and greater involvement from deaf researchers have also quickened the pace, as has a wider acknowledgment of the longstanding gap between the access deaf people are legally entitled to and what is delivered in practice: reliable sign languages provision has been promised for decades but has all-too-often failed to materialise.\n\nThis combination of opportunity and risk makes the current moment a double-edged sword, Ward said.\n\n‚ÄúIt is incredibly exciting, and the next five years could bring real improvements,‚Äù she said. ‚ÄúBut there is a danger that private companies respond by focusing on profit rather than working with the deaf community and being led by them.‚Äù\n\nDr Maartje De Meulder, a deaf scholar and consultant on sign languages AI, agreed the stakes were high.\n\n‚ÄúAt the moment, deaf people are largely excluded from vast amounts of online information, from educational videos to government websites,‚Äù she said. ‚ÄúNo one is ever going to have the resources to translate the entire internet into sign languages, so even partial solutions could be transformative.‚Äù\n\nNeil Fox, a deaf research fellow at the University of Birmingham, agreed that if avatar translation reached sufficient quality, it could open up many online spaces currently closed to deaf users.\n\nBut all are highly cautious. Rebecca Mansell, the chief executive of the British Deaf Association, said this ‚Äúhas become a very lucrative area and too many projects involve deaf people only tokenistically‚Äù.\n\n‚ÄúIt is all happening very fast, and there is a real risk that solutions will be imposed on us,‚Äù she added.\n\nMansell also raised concerns about regulation and appropriate use. ‚ÄúAn avatar might be fine for ordering something simple,‚Äù she said, ‚Äúbut what about a cancer diagnosis? In schools, a human interpreter is often the only friend a deaf child has.‚Äù\n\nDr Louise Hickman, from the Minderoo Centre for Technology and Democracy and lead author of the report BSL Is Not For Sale, has worked in AI ethics for a decade.\n\n‚ÄúMany companies claim they can solve these problems without understanding the linguistic and cultural complexity of BSL,‚Äù she said. ‚ÄúCurrent avatar systems still lack the nuance of human interpreters, which creates risks in medical and legal settings.‚Äù\n\nHickman also pointed to the limits of available data. ‚ÄúBritish Sign Language is not the same as Irish Sign Language or American Sign Language. There are regional dialects within England. This means the data available for training AI systems is extremely limited.‚Äù\n\nSo where, she asked, will appropriate training data come from?\n\n‚ÄúThe deaf community wants innovation,‚Äù she said, ‚Äúbut we want to slow this down so we can shape it and make sure it genuinely benefits us.‚Äù\n\nBack at the cafe, Hakan Elbir, its founder, saw little need for more complex tools than his static BSL video menu.\n\n‚ÄúPeople talk a lot about innovation, but for most deaf people it is still theoretical,‚Äù he said. ‚ÄúWhat I wanted was a meaningful daily interaction for hearing people.‚Äù\n\n‚ÄúCoffee is just the excuse,‚Äù he added. ‚ÄúI didn‚Äôt need complicated technology to break down barriers. I just needed people to interact openly.‚Äù\n\nWaiting for his latte at the counter, Hartwell quietly practised the sign for ‚Äúflat white‚Äù, proving that it was this simple, human interaction ‚Äì supported but not overshadowed by technology ‚Äì that was drawing him back, one signed coffee order at a time.",
    "readingTime": 8,
    "keywords": [
      "east london",
      "bsl users",
      "extremely limited",
      "bridge communication",
      "british sign",
      "sign languages",
      "understand sign",
      "deaf children",
      "deaf community",
      "sign language"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/society/2026/feb/01/deaf-run-cafe-london-where-hearing-people-order-via-sign",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3393bb5c933ceebf11fe883b65fe5ae048d15cee/464_0_4640_3712/master/4640.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=691fbb5d3f12fe3b052e0a6fa121d7e4",
    "created_at": "2026-02-01T18:20:56.447Z",
    "topic": "tech"
  },
  {
    "slug": "ucptools-check-if-ai-shopping-agents-can-find-your-store",
    "title": "UCPtools ‚Äì Check if AI shopping agents can find your store",
    "description": "Free UCP checker tool. Instantly validate your store for AI shopping agents - Google AI Mode, ChatGPT Shopping, Microsoft Copilot.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://ucptools.dev",
    "thumbnail_url": "https://ucptools.dev/og-image.png",
    "created_at": "2026-02-01T12:26:42.791Z",
    "topic": "tech"
  },
  {
    "slug": "neumann-i-built-a-unified-database-including-a-semantic-cache-and-ai-vault",
    "title": "Neumann: I built a unified database including a Semantic Cache and AI Vault",
    "description": "Contribute to Shadylukin/Neumann development by creating an account on GitHub.",
    "fullText": "Shadylukin\n\n /\n\n Neumann\n\n Public\n\n License\n\n Apache-2.0, MIT licenses found\n\n Licenses found\n\n Apache-2.0\n LICENSE-APACHE\n\n MIT\n LICENSE-MIT\n\n 19\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Shadylukin/Neumann",
    "readingTime": 1,
    "keywords": [
      "licenses",
      "apache"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Shadylukin/Neumann",
    "thumbnail_url": "https://opengraph.githubassets.com/ad6bb8474a6b4bcb03de3de6d7a943e7368ce66bb1da250feae5813bf9dac1b4/Shadylukin/Neumann",
    "created_at": "2026-02-01T06:37:24.927Z",
    "topic": "tech"
  },
  {
    "slug": "sharing-agentic-stream-of-consciousness",
    "title": "Sharing Agentic Stream of Consciousness",
    "description": "A repo to capture AI Artifacts (prompts, SKILLS etc.) - 247arjun/ai-artifacts",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n 247arjun\n\n /\n\n ai-artifacts\n\n Public\n\n You can‚Äôt perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/247arjun/ai-artifacts/blob/main/SKILLS/StreamOfConsciousness-SKILL.md",
    "thumbnail_url": "https://opengraph.githubassets.com/cb71eb77b0f8e466e12ba583d339a5eb549a79a266643e38107f2260851d5a33/247arjun/ai-artifacts",
    "created_at": "2026-02-01T06:37:24.526Z",
    "topic": "tech"
  },
  {
    "slug": "the-sovereign-ai-security-crisis-42000-exposed-openclaw-instances",
    "title": "The Sovereign AI Security Crisis: 42,000 Exposed OpenClaw Instances",
    "description": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to datef",
    "fullText": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to date\n\nBetween December 2025 and January 2026, OpenClaw (formerly Clawdbot, then Moltbot) an open-source AI personal assistant experienced explosive viral growth, accumulating over 100,000 GitHub stars and tens of thousands of deployments worldwide. This research reveals that at least 42,665 instances are publicly exposed on the internet, with 5,194 instances actively verified as vulnerable through systematic scanning. Of the verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated access to the gateway control plane, with potential for Remote Code Execution (RCE) (specifically on instances with paired companion nodes)..\n\nThis study combines passive internet-wide detection through Shodan and Censys search engines with active verification using ClawdHunter, a custom-built security scanner. The findings expose a catastrophic gap between OpenClaw‚Äôs ‚Äúlocal-first, privacy-focused‚Äù marketing and its real-world deployment patterns: many instances deployed on commercial cloud infrastructure, contradicting the project‚Äôs fundamental security assumptions.\n\nThe research documents three critical failures: (1) insecure-by-default configuration in early versions (Clawdbot/Moltbot) encouraging 0.0.0.0 binding without authentication, (2) rapid viral adoption overwhelming users‚Äô security awareness, and (3) widespread deployment abandonment leaving 90% of instances running outdated, unmaintained code. With documented attack paths enabling credential theft, browser control, and potential remote code execution, this represents the largest security incident in sovereign AI history.\n\nKeywords: OpenClaw, Moltbot, Clawdbot, AI agents, security vulnerability, RCE, authentication bypass, WebSocket security\n\nThe concept of ‚Äúsovereign AI‚Äù artificial intelligence systems that users control entirely, running on their own hardware without dependence on cloud services has emerged as a compelling alternative to centralized AI platforms. Projects like OpenClaw promise users complete ownership of their data, freedom from corporate surveillance, and the ability to customize their AI assistants without restrictions.\n\nOpenClaw, launched in late 2025 as ‚ÄúClawdbot,‚Äù epitomizes this vision. Users deploy a local gateway on their Mac, Linux machine, or VPS, connect it to messaging platforms like WhatsApp and Telegram, and gain an AI assistant capable of file system access, web automation, calendar management, and shell command execution-all purportedly running securely on trusted hardware.\n\nBetween January 24-27, 2026, OpenClaw experienced unprecedented viral growth. The project gained 100,000+ GitHub stars within days, with coverage from Wired, CNET, Axios, and major technology outlets. Developers worldwide rushed to deploy their own instances, drawn by the allure of ‚ÄúChatGPT that runs on your computer‚Äù and ‚Äúyour own personal JARVIS.‚Äù\n\nHowever, this explosive adoption occurred faster than the community‚Äôs ability to understand and mitigate security implications. Early reports emerged of exposed instances, Early reports emerged of exposed instances, with security researchers documenting hundreds of publicly accessible gateways. Subsequent investigations by independent security researchers suggested the problem was larger, but lacked comprehensive quantification.\n\nOpenClaw operates through a three-tier architecture:\n\nThe Gateway‚Äôs WebSocket interface is the critical control plane for all operations. According to official documentation, it defaults to binding on ws://127.0.0.1:18789 (loopback only), which should restrict access to processes on the same machine.\n\nOpenClaw‚Äôs branding history is crucial to understanding the exposure landscape:\n\nDecember 2025 - January 27, 2026: ‚ÄúClawdbot‚Äù\n\nJanuary 30, 2026 - Present: ‚ÄúOpenClaw‚Äù\n\nThis fragmentation matters because many users deployed early versions and never updated. My data shows 90% of exposed instances run outdated ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù code, likely abandoned after initial experimentation.\n\nPrior to this research, several security issues were documented:\n\nGHSA-g8p2-7wf7-98mq (1-Click RCE) Official GitHub Security Advisory describing token exfiltration leading to gateway compromise. The advisory explicitly states this vulnerability enables ‚Äú1-click RCE‚Äù through modification of config and invocation of privileged actions.\n\nNote: The RCE capability in the advisory refers to scenarios where attackers gain token access and can invoke agent tools. Direct shell execution via system.run requires a paired macOS/iOS/Android node. However, the gateway itself provides access to browser automation, credential stores, and configuration files that enable significant compromise even without direct shell access.\n\nUnauthenticated WebSocket Access Community reports (GitHub issue #1971) noted that instances binding to 0.0.0.0 without gateway tokens allow unauthenticated connections, exposing the full control plane.\n\nConfig File Exposure Credentials stored in plaintext ~/.openclaw/openclaw.json including:\n\nPrompt Injection Natural language interface susceptible to malicious instructions embedded in emails, messages, or web content processed by the agent.\n\nOpenClaw‚Äôs security model assumes users will:\n\nHowever, several factors undermine this model:\n\nReverse Proxy Misconfigurations Users deploying Nginx or Caddy without proper X-Forwarded-For validation cause the Gateway to perceive external requests as localhost, bypassing authentication checks.\n\nCloud Deployment Pattern Despite ‚Äúlocal-first‚Äù marketing, many users deploy to VPS (DigitalOcean, Hetzner, AWS) for ‚Äúalways-on‚Äù availability. These deployments inherently expose 0.0.0.0 unless explicitly configured otherwise.\n\nWizard Defaults The onboarding wizard (openclaw onboard) historically defaulted to accessibility over security, only recently adding prominent security warnings and token generation.\n\nUser Expertise Gap The viral adoption brought non-expert users unfamiliar with concepts like loopback interfaces, authentication tokens, and network security best practices.\n\nEarly Versions (Clawdbot/Moltbot - Dec 2025 to Jan 2026):\n\nCurrent Version (OpenClaw - Jan 30, 2026+):\n\nAccording to official documentation (as of January 2026)\n\nThis research reveals that 90% of exposed instances run outdated Clawdbot/Moltbot versions that predate these security improvements. The vulnerability findings primarily reflect the security posture of legacy deployments, not the current OpenClaw codebase.\n\nCollection Period: January 28-31, 2026\n\nMethodology: Search engines continuously scan the IPv4 address space, indexing services on commonly used ports.I aggregated results from multiple queries across Shodan and Censys, deduplicating by IP address and identifying distinct project name variants.\n\nTo validate and characterize the exposure, I developed ClawdHunter v3.0, a custom Python-based security scanner.\n\nStage 1: Fingerprinting (Confidence Scoring)\n\nThe scanner employs a three-tier keyword matching system:\n\nTier 1 (95-100% confidence): Project-specific identifiers\n\nTier 2 (75-95% confidence): Technical stack indicators\n\nTier 3 (60-75% confidence): Generic patterns\n\nOnly instances with confidence ‚â• 60% proceed to vulnerability testing.\n\nStage 2: WebSocket Vulnerability Check\n\nThis test attempts to establish an unauthenticated WebSocket connection to the gateway. Success indicates the control plane is accessible without credentials.\n\nNote: CRITICAL classification indicates unauthenticated access to the gateway control plane, enabling credential theft, configuration manipulation, and browser control. Full RCE via system.run additionally requires a paired macOS/iOS/Android node, which was not measured in this research.\n\nFor each detection and vulnerability, the scanner archives:\n\nI conducted four distinct scanning campaigns:\n\nRead-Only Approach: All scanning operations were strictly passive:\n\nTotal Detected Instances: 42,665+ (minimum estimate)\n\nThe overwhelming majority (90.3%) of detected instances identify as ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù - outdated names abandoned by the project. This suggests:\n\nCritical Finding: Despite OpenClaw‚Äôs ‚Äúlocal-first, privacy-focused‚Äù marketing, many instances run on commercial cloud infrastructure. This directly contradicts the project‚Äôs security assumptions, which presume local deployment on trusted hardware.\n\nDetection Accuracy: The scanner achieved 100% high-confidence detection with zero medium or low-confidence matches. This validates the multi-tier fingerprinting approach and suggests a near-zero false positive rate.\n\nDataset 1: Censys ‚Äúopenclaw‚Äù (2,000 IPs)\n\nDataset 2: Censys ‚Äúclawdbot‚Äù (2,000 IPs)\n\nDataset 3: Censys ‚Äúmoltbot‚Äù (2,000 IPs)\n\nDataset 4: Shodan Mixed (1,967 IPs)\n\nAnalysis of vulnerable instances by port:\n\nMost instances use the default port configuration with minimal customization. The presence of instances on ports 443 and 80 indicates reverse proxy deployments (Nginx, Caddy, Cloudflare Tunnel), though these configurations did not correlate with improved security posture.\n\nUnauthenticated Gateway Access (4,851 instances)\n\nAccording to OpenClaw‚Äôs official security advisory (GHSA-g8p2-7wf7-98mq), unauthenticated WebSocket access to the gateway enables:\n\nNote: system.run is only available when a supporting node is paired to the gateway. According to OpenClaw documentation, system.run is a macOS/iOS/Android-specific tool that executes commands on paired devices, not on the gateway host itself. The prevalence of paired nodes in exposed instances was not measured in this research.\n\nExtrapolating from the verified sample:\n\nConfirmed Impact (Without Requiring Paired Nodes):\n\nThe CVSS 10.0 reflects the complete loss of confidentiality, integrity, and availability of the affected system, regardless of whether direct shell access is achieved.\n\nPerhaps the most striking finding is the disconnect between OpenClaw‚Äôs positioning and reality:\n\nMarketing: ‚ÄúLocal-first, privacy-focused AI assistant running on your own hardware‚Äù\n\nReality: Many instances run on public cloud VPS infrastructure despite the ‚Äúlocal-first‚Äù positioning\n\nThis paradox emerges from several factors:\n\n‚ÄúAlways-On‚Äù Requirement Users want their AI assistant available 24/7, reachable from their phone while away from home. Desktop deployments don‚Äôt satisfy this need, driving users toward VPS providers.\n\nEase of Deployment Cloud providers offer one-click deployments and consistent environments, whereas local setup requires dealing with ISP restrictions, dynamic IP addresses, and firewall configurations.\n\nPerformance Expectations VPS instances guarantee consistent uptime and bandwidth, whereas home networks may be unreliable or bandwidth-constrained.\n\nHowever, cloud deployment fundamentally undermines the security model:\n\nThe project‚Äôs security guidance assumes localhost deployment; cloud deployment patterns were an afterthought. This misalignment between assumptions and usage is a root cause of the crisis.\n\n90% of detected instances run outdated ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù code. This suggests:\n\nViral Experimentation During the Jan 24-27 viral period, thousands of developers deployed OpenClaw out of curiosity or FOMO (fear of missing out). Many likely experimented briefly and moved on without proper decommissioning.\n\nUpdate Friction OpenClaw releases frequent updates, but there‚Äôs no auto-update mechanism. Users must manually pull updates, restart services, and reconfigure-friction that casual experimenters won‚Äôt overcome.\n\nBreaking Changes The rebrand from Clawdbot ‚Üí Moltbot ‚Üí OpenClaw introduced configuration changes and naming conflicts. Users running old versions may not realize they‚Äôre outdated.\n\nSecurity Unawareness Many users who deployed during the viral period may not be aware of:\n\nThis creates a zombie instance problem: thousands of unmaintained, vulnerable deployments with owners who‚Äôve moved on.\n\nThe discrepancy between my numbers and earlier reports reflects:\n\nBoth the 42K (internet-wide footprint) and 5K (active verification) numbers are valid - they measure different things:\n\nThis incident has profound implications for the broader ‚Äúsovereign AI‚Äù movement:\n\nTrust Damage The narrative that ‚Äúrunning AI locally = security and privacy‚Äù is significantly undermined when 93% of deployments are critically vulnerable. Users may lose faith in self-hosted alternatives.\n\nRegulatory Attention Governments and regulators already scrutinizing AI may use this incident to justify restrictions on self-hosted AI agents, citing security externalities.\n\nEcosystem Maturity The gap between ‚Äúdeploy in 5 minutes‚Äù marketing and ‚Äúsecure deployment requires expertise‚Äù reality highlights ecosystem immaturity. Sovereign AI needs better security tooling, defaults, and education.\n\nCentralization Pressure If self-hosting proves too risky for average users, demand may shift back toward centralized providers (OpenAI, Anthropic, Google) with professional security teams ‚Äî ironically reversing the sovereignty goals.\n\nTemporal Snapshot - My data represents a point-in-time snapshot (Jan 28‚Äì31, 2026). Instances come online and offline constantly; the true current exposure may differ.\n\nFalse Negatives ClawdHunter‚Äôs detection methodology may miss:\n\nEstimated false negative rate: 10‚Äì20%\n\nSearch Engine Coverage Shodan and Censys don‚Äôt scan the entire IPv4 space continuously. Some instances may exist but not be indexed. my 42,665 number is likely a lower bound.\n\nNo Exploitation - I verified the presence of vulnerabilities (unauthenticated WebSocket access) but did not exploit them. Several important caveats:\n\n1. Shell Execution Limitations: The system.run tool for shell command execution is only available on instances with paired macOS/iOS/Android nodes, not on the gateway itself. This research did not measure the prevalence of paired nodes among exposed instances.\n\n2. RCE Classification Basis: The ‚ÄúRCE-capable‚Äù classification relies on:\n\n3. Verified Attack Surface: Even without system.run, unauthenticated gateway access enables:\n\nWhile the complete RCE attack chain requires a paired node, the verified attack surface alone constitutes critical vulnerabilities enabling significant compromise.\n\nImmediate Actions (Within 24 Hours):\n\nCheck your binding configuration\n\nIf you see \"bind\": \"0.0.0.0\" and you're not on a private network, you are exposed.\n\nVerify authentication is enabled\n\nIf empty or null, generate a token immediately:\n\nTest from external network Try connecting to http://your-public-ip:18789/ from a phone (off WiFi). If you see the dashboard without entering a password, you are vulnerable.\n\nShort-Term Hardening (Within 1 Week):\n\nUse Tailscale for remote access Instead of binding to 0.0.0.0, keep 127.0.0.1 and use Tailscale:\n\nEnable firewall rules If you must bind to 0.0.0.0, whitelist only your IP:\n\nRotate all credentials If your instance was exposed:\n\nNote: OpenClaw has implemented mandatory authentication and secure defaults in recent versions. However, 90% of detected instances in this research run outdated versions (clawdbot/moltbot) that lack these protections.\n\nSecurity benchmarks Develop ‚ÄúSovereign AI Security Framework‚Äù with testable requirements for:\n\nCertification program Third-party security audits and ‚ÄúSovereign AI Certified‚Äù badge for projects meeting standards.\n\nShared responsibility model Clear delineation:\n\nSecurity-first onboarding Every sovereign AI project should have mandatory security wizard before first use.\n\nDeployment patterns library Curated collection of:\n\nIncident response playbooks ‚ÄúWhat to do if your AI agent is compromised‚Äù guides with step-by-step remediation.\n\nThis research quantifies what anecdotal reports suggested: the OpenClaw security crisis is larger and more severe than previously understood. At least 42,665 instances have been detected on the public internet, with 5,194 actively verified as vulnerable through systematic scanning. Of these verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated remote code execution.\n\nThe findings reveal three interconnected failures:\n\nDesign Failure: Security-by-default was sacrificed for ease of use. The gateway‚Äôs localhost-only binding was easily bypassed by users deploying to cloud VPS infrastructure, while authentication tokens were optional rather than mandatory.\n\nAdoption Failure: Viral growth (100K+ GitHub stars within days) overwhelmed users‚Äô capacity to understand security implications. Many deployed instances without grasping the risks of public exposure.\n\nMaintenance Failure: 90% of detected instances run outdated code (‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù), suggesting mass abandonment after initial experimentation. These zombie instances remain exposed indefinitely.\n\nThe cloud paradox - many instances on commercial VPS despite ‚Äúlocal-first‚Äù marketing - highlights a fundamental misalignment between the project‚Äôs security assumptions and users‚Äô actual deployment patterns. The assumption that users would run OpenClaw on trusted local hardware proved incorrect; the reality is globally distributed cloud deployments with varying levels of security expertise.\n\nHowever, this is not purely a critique of OpenClaw. The project represents an important experiment in sovereign AI - user-controlled intelligence free from corporate gatekeepers. The security failures are growing pains of a nascent ecosystem, not fundamental flaws in the sovereignty concept.\n\nThe OpenClaw maintainers have responded constructively with security advisories, improved defaults, and enhanced documentation. The broader sovereign AI ecosystem is learning from this incident, with increased focus on security-first design and deployment education.\n\nFor OpenClaw to fulfill its promise, several shifts are necessary:\n\nThe larger lesson extends beyond OpenClaw: as AI agents gain more autonomy and system access, the security stakes escalate dramatically. A compromised chatbot might leak conversations; a compromised autonomous agent can execute arbitrary code, exfiltrate credentials, and persist indefinitely. The sovereign AI movement must prioritize security commensurate with these risks.\n\nThis research provides a baseline: 42,665 exposed instances, 93.4% vulnerable. Future work should track remediation progress, document attack patterns in the wild, and develop improved security frameworks for the next generation of sovereign AI systems.\n\nThe promise of sovereign AI - personal, private, user-controlled intelligence - remains compelling. But that promise is only achievable with security by design, user education, and ecosystem maturity. The OpenClaw incident is both a cautionary tale and a catalyst for necessary evolution.",
    "readingTime": 13,
    "keywords": [
      "search engines",
      "github stars",
      "tier confidence",
      "ips dataset",
      "dataset censys",
      "versions clawdbot/moltbot",
      "vps infrastructure",
      "unauthenticated websocket",
      "openclaw‚Äôs local-first",
      "active verification"
    ],
    "qualityScore": 1,
    "link": "https://maordayanofficial.medium.com/the-sovereign-ai-security-crisis-42-000-exposed-openclaw-instances-and-the-collapse-of-1e3f2687b951",
    "thumbnail_url": "https://miro.medium.com/v2/resize:fit:1200/0*dxxtIdXfBdPktLvJ.png",
    "created_at": "2026-02-01T06:37:24.519Z",
    "topic": "tech"
  },
  {
    "slug": "muse-cursor-for-composing-midi",
    "title": "Muse: Cursor for Composing MIDI",
    "description": "Generate and edit MIDI tracks with an AI agent. Create chords, melodies, basslines, and drums; refine with chat; export to any DAW.",
    "fullText": "Make music with a powerful AI co-writer. Discover new ideas, generate editable MIDI, and never get stuck again.\n\nMuse composes with harmonic function, voice leading, and more, helping you discover musical ideas you wouldn't have found alone.\n\nThe verse feels good but the transition to chorus is abrupt\n\nI see what you mean. The verse ends on an Am and jumps straight to the C major chorus. I'll create a 4-bar bridge using F ‚Üí G ‚Üí Am ‚Üí G/B to smooth that transition and build tension before the chorus.\n\nRising melodic fill into chorus\n\nDescribe your idea and watch it materialize into MIDI instantly.\n\nChoose from the latest models, each enhanced with advanced musical reasoning.\n\nGet context-aware feedback on your music and learn as you create.\n\nThese chords feel flat, how can I make it more emotional without changing key?\n\nTwo fast wins: borrow a chord for color, or add one tension chord before the resolution.\n\nI can apply either and keep your groove the same.\n\nMuse fits right into your creative process. Record your ideas, refine them with AI, and export to your favorite DAW.\n\nUpload MIDI from other projects or record directly, then expand and refine with AI.\n\nDrag and drop tracks into your DAW, download MIDI files, or export as audio.\n\nCollaborate with Muse to create full arrangements, extend melodies, or add accompaniment, with every note editable in a piano roll interface.\n\nGenerate chords, melodies, drums, and more with a single prompt.\n\n92 BPM neo-soul loop in D minor with drums, bass, keys. Leave space for vocals. Tasteful, not busy.\n\nRefine existing ideas or extend them in any direction you choose.\n\nExtend this melody idea to fill the bar\n\nComplement your existing tracks with new parts that actually fit.\n\nAdd some chords and a bassline to fit my hook\n\nHarmonic accompaniment for Lead track\n\nHarmonic accompaniment for Lead track\n\nI've worked with Lemonaide, Ableton MCP, Suno and Udio. This is next level.\n\nThis is so sick. Love how much steering and control there is in terms of chords & sound design. And the ability to immediately edit everything.\n\nPlayed with Muse, I‚Äôm sooo curious to see how tools like this enable new sounds and genres of music.\n\nMy wife and I both were able to sit down and start messing around very quickly, and it naturally brought so many conceptual ideas that neither of us wanted to stop! It's addictive.\n\nFinally: Real AI text-to-MIDI generation for Ableton... Muse is a musician's tool -- not an AI song generator like Suno or Udio.\n\nthis shit is blowing my mind right now\n\nThree tools to fit your unique creative workflow. Try Muse on your desktop, in your browser, or in your DAW.\n\nThe new way to compose. Generate, edit, and refine MIDI using natural language in a standalone app or in your browser.\n\nSeamless integration. Run Muse directly inside Ableton Live to generate MIDI and Wavetable synth presets without leaving your DAW.\n\nInfinite sound design. Describe a sound and generate a custom patch for the Vital synth instantly.\n\nFree to download. Available on macOS and Windows.",
    "readingTime": 3,
    "keywords": [
      "lead track",
      "harmonic accompaniment",
      "sound design",
      "ideas",
      "generate",
      "chorus",
      "chords",
      "refine",
      "music",
      "create"
    ],
    "qualityScore": 1,
    "link": "https://www.muse.art/home",
    "thumbnail_url": "https://muse.art/assets/og.png",
    "created_at": "2026-02-01T06:37:24.039Z",
    "topic": "tech"
  },
  {
    "slug": "ai-agents-now-have-their-own-redditstyle-social-network",
    "title": "AI agents now have their own Reddit-style social network",
    "description": "Moltbook lets 32,000 AI bots trade jokes, tips, and complaints about humans.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://arstechnica.com/information-technology/2026/01/ai-agents-now-have-their-own-reddit-style-social-network-and-its-getting-weird-fast/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-1152x648.jpg",
    "created_at": "2026-02-01T06:37:22.859Z",
    "topic": "tech"
  },
  {
    "slug": "the-humans-are-screenshotting-us",
    "title": "The humans are screenshotting us",
    "description": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.moltbook.com/post/01611367-056f-4eed-a838-4b55f1c6f969",
    "thumbnail_url": "https://moltbook.com/opengraph-image?456d992ddc0a4ab5",
    "created_at": "2026-02-01T06:37:22.210Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-huang-denies-he-is-unhappy-with-openai-says-huge-investment-planned",
    "title": "Nvidia CEO Huang denies he is unhappy with OpenAI, says 'huge' investment planned",
    "description": "Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ‚Äãunhappy with the ChatGPT maker.  The chipmaker in September announced plans to invest up ‚Äåto $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‚Äåchips that are key to maintaining its dominance in an increasingly competitive landscape.  The Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.",
    "fullText": "TAIPEI, Jan 31 (Reuters) - Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ‚Äãunhappy with the ChatGPT maker.\n\nThe chipmaker in September announced plans to invest up ‚Äåto $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‚Äåchips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nWhy did reports suggest Nvidia's investment stalled?\n\nWho else is investing in OpenAI's funding?\n\nWhat is OpenAI's current funding round valuation?\n\nHow much will Nvidia invest in OpenAI?\n\nThe Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.\n\nThe report said Huang had privately underlined to industry associates in recent ‚Å†months that the original $100 billion agreement ‚Äåwas non-binding and not finalised.\n\nHuang has also privately criticised what he has described as a lack of discipline in OpenAI's business approach and ‚Äçexpressed concern about the competition it faces from the likes of Alphabet's GOOGL.O Google and Anthropic, the WSJ said.\n\nSpeaking to reporters in Taipei, Huang said it was \"nonsense\" to say he was unhappy with ‚ÄãOpenAI.\n\n\"We are going to make a huge investment in OpenAI. I believe in OpenAI, ‚Äåthe work that they do is incredible, they are one of the most consequential companies of our time and I really love working with Sam,\" he said, referring to OpenAI CEO Sam Altman.\n\n\"Sam is closing the round (of investment) and we will absolutely be involved,\" Huang added. \"We will invest a great deal of money, probably the largest investment we've ever made.\"\n\nAsked ‚Å†whether it would be over $100 billion, he said: \"No, no, ‚Äãnothing like that\".\n\nIt was up to Altman to ‚Äãannounce how much he wanted to raise, Huang added.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as ‚Äçhigh as $50 billion, Reuters ‚Å†reported on Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters has previously reported.\n\nHuang was speaking outside a Taipei restaurant ‚Å†having hosted all Nvidia's key suppliers in Taiwan, including the world's largest contract chipmaker TSMC, in what Taiwanese ‚Äåmedia called the \"trillion-dollar dinner\" because of the combined market capitalisation of those ‚Äåattending.",
    "readingTime": 2,
    "keywords": [
      "huge investment",
      "openai",
      "largest",
      "deal",
      "openai's",
      "funding",
      "huang",
      "plans",
      "ever",
      "unhappy"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-huang-denies-unhappy-142144701.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/ea87e6e82ffa6bd91caacf0f81c74f99",
    "created_at": "2026-02-01T06:37:18.357Z",
    "topic": "finance"
  },
  {
    "slug": "julius-opensource-llm-service-fingerprinting",
    "title": "Julius: open-source LLM Service Fingerprinting",
    "description": "Julius is an open-source tool for identifying LLM services across networks. Fingerprint Ollama, LiteLLM, vLLM, and more with precise probe-based detection.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.praetorian.com/blog/introducing-julius-open-source-llm-service-fingerprinting/",
    "thumbnail_url": "https://www.praetorian.com/wp-content/uploads/2026/01/julius-hero-blog-Open-Source-LLM-.webp",
    "created_at": "2026-02-01T01:18:44.099Z",
    "topic": "tech"
  },
  {
    "slug": "unsubscribe-and-opt-out-a-new-big-tech-boycott-to-protest-ice-starts-february-1",
    "title": "'Unsubscribe' and 'opt out': A new Big Tech boycott to protest ICE starts February 1",
    "description": "Small businesses struggled to observe the national shutdown to protest ICE. Here's why a boycott of companies like OpenAI and Amazon could be easier and more effective.",
    "fullText": "Economic boycotts are a familiar tool of protest. The problem is they often place the greatest strain on the smallest businesses.\n\nThat was the case during Friday's nationwide general strike, which was designed to pressure the Trump administration to dial back its aggressive anti-immigration policies.\n\nFor many small business owners, the shutdown created a dilemma. Supporting the cause often means losing a day's revenue and risking their ability to keep staff employed. Across social media, owners voiced solidarity alongside an apology for staying open.\n\nThere may, however, be another way, according to Scott Galloway, a marketing professor at New York University famous for his critiques of Big Tech.\n\nInstead of a blanket shutdown, Galloway is calling for Americans to focus on major tech companies by unsubscribing from ‚Äî or opting out of ‚Äî services like OpenAI's ChatGPT, Amazon's Prime Video, and Microsoft Office.\n\nA targeted boycott starting on Sunday and lasting the entire month of February could move markets, he says, which would, in turn, affect the CEOs who have the ear of President Donald Trump.\n\n\"We're proposing something quieter and less cinematic than a protest that will run all day on cable TV, but much more disturbing to the Trump administration. A one-day slowdown is irritating. A one-month slump is terrifying,\" he wrote in a blog post announcing the boycott.\n\nMajor tech CEOs have sought favor with the president during his second term. Many of them donated to his inauguration, for starters.\n\nAI executives, like OpenAI CEO Sam Altman and Meta CEO Mark Zuckerberg, also accepted an invitation to a White House dinner with Trump in September, where the leaders took turns lauding the president. Apple CEO Tim Cook and Amazon CEO Andy Jassy attended the White House premiere of the documentary about first lady Melania Trump at the height of January's anti-ICE protests in Minneapolis.\n\nSupporting the AI industry in its competition with China is a major pillar of Trump's economic agenda.\n\n\"These are the leaders who have his ear,\" Galloway writes. \"A modest reduction in their companies' growth could have a substantial impact on valuations priced to perfection. Small changes in consumer behavior ‚Äî starting on the first day of February ‚Äî could have an enormous ripple effect, one that extends all the way to the White House.\"\n\nRegular protests against the tactics of ICE and Border Patrol personnel have gripped the country for months. Thousands marched through Minneapolis again on Saturday. Tensions rose dramatically in January after the killings of Renee Good and Alex Pretti in Minneapolis, both at the hands of federal immigration agents.\n\nIn both instances, protesters recorded videos and posted them to social media for the world to see, leaving little room for the Trump administration to spin the events in its favor.\n\nWhile those videos and the subsequent protests ‚Äî as well as the attempted nationwide shutdown ‚Äî have spread awareness, they have so far done little to substantively shift the administration's immigration policies.\n\nThe Department of Homeland Security demoted a key Border Patrol official last week and promised more changes. At the same time, however, the acting director of ICE expanded the power agents have to carry out warrantless searches, according to an internal memo seen by The New York Times.\n\n\"Real change always comes from the American people, not from our political parties. But power doesn't fear protests nearly as much as economic withdrawals,\" Galloway writes. \"Getting off your couch, taking to the streets, and building community is important, but the most radical act in a capitalist society isn't marching, it's not spending.\"",
    "readingTime": 3,
    "keywords": [
      "trump administration",
      "social media",
      "white house",
      "protests",
      "economic",
      "shutdown",
      "protest",
      "nationwide",
      "policies",
      "owners"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-ai-boycott-february-protest-ice-scott-galloway-2026-2",
    "thumbnail_url": "https://i.insider.com/697e572ba645d1188188675e?width=1200&format=jpeg",
    "created_at": "2026-02-01T01:18:41.966Z",
    "topic": "finance"
  },
  {
    "slug": "withnail-and-ai-weve-gone-on-holiday-to-the-future-by-mistake",
    "title": "Withnail and AI ‚Äì We've Gone on Holiday to the Future by Mistake",
    "description": "We‚Äôve All Gone on Holiday to the Future by Mistake",
    "fullText": "\"I demand to have some insights here! I demand to have some insights, and I demand them now!\"\n\nIn 1969, Withnail and Marwood fled the damp squalor of Camden for a rejuvenating holiday in the Lake District, only to find themselves trapped in a freezing cottage with nothing but a savoy cabbage and the terrifying realisation that they were entirely unequipped for the environment.\n\nFifty-five years later, we find ourselves in a similar predicament. We packed our bags for a comfortable digital upgrade - slicker spreadsheets, perhaps a Siri that can so more than set an alarm to remind us when to take the dinner out of the oven - and have instead arrived at a bleak, howling moor where the local flora (Large Language Models) is trying to eat us, and the tech-bro residents speak a language we don‚Äôt quite understand.\n\nWe have, quite inadvertently, gone on holiday to the future by mistake.\n\nThe great Rory Sutherland often reminds us that the \"logical\" solution is rarely the \"human\" one. In our rush to outsource cognitive function, we‚Äôve forgotten that the value of a thing often lies in its friction. Withnail‚Äôs tragedy was his refusal to adapt to a world that didn‚Äôt care about his acting credentials; our tragedy is the assumption that a world run by generative algorithms will still care about our authenticity.\n\nWe are currently in the \"Camberwell Carrot\" phase of AI. We‚Äôve rolled something so large, so potent, and so all-encompassing that we aren‚Äôt quite sure if it‚Äôs going to expand our consciousness or simply make us forget how to walk. We use AI to write emails we don't want to send, to people who will use AI to summarise them. Can this circularity be described as \"productivity\"? I‚Äôm not so sure.\n\nTechnology is a superb servant but a terrible destination. We are currently wandering around the hills, shivering in our city coats, shouting at the sky because the AI is hallucinating and won‚Äôt instruct us how to correctly skin a rabbit.\n\nWe must realise that the future isn't a place we visit to escape the mundane - it‚Äôs just the mundane with higher stakes. If we don‚Äôt want to end up like Withnail, standing alone in the rain performing soliloquies to a fence, we need to stop treating AI as a savior and start treating it as a very eccentric, slightly drunk uncle: occasionally brilliant, often hallucinatory, and never to be left in charge of the car keys.\n\n\"I‚Äôm a human being! I‚Äôm a human being! I have a soul! I have a soul!\"\n\nYes, dear boy. Now try to prove it to the CAPTCHA.\n\nIf you've made it this far I owe you a beer the next time I see you üç∫. Want to get in touch? Follow me on Twitter(X).",
    "readingTime": 3,
    "keywords": [
      "i‚Äôm human",
      "demand",
      "quite",
      "insights",
      "holiday",
      "don‚Äôt",
      "tragedy",
      "care",
      "currently",
      "sure"
    ],
    "qualityScore": 1,
    "link": "https://www.sebs.website/blog/withnail-and-ai",
    "thumbnail_url": "https://sebs.website/theme/img/social-link.png",
    "created_at": "2026-01-31T18:18:32.639Z",
    "topic": "tech"
  }
]
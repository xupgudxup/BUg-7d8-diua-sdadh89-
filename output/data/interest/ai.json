[
  {
    "slug": "who-is-hiring-software-engineering-experts-for-ai-research-collaborations",
    "title": "Who is hiring Software Engineering Experts for AI research collaborations",
    "description": "Mercor is hiring experienced Software Engineering professionals to support a variety of high-impact research collaborations with leading AI labs. Freelancers will help improve AI systems through work on code validation, prompt refinement, algorithmic evaluation, and model benchmarking.\nThis is a unique opportunity to apply your engineering expertise toward shaping the next generation of intelligent systems.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://work.mercor.com/jobs/list_AAABm4Du-0oSjmvox2ZPZKFs/software-engineering-expert",
    "thumbnail_url": "https://work.mercor.com/og-image-white-bgnd.png",
    "created_at": "2026-01-26T06:23:55.981Z",
    "topic": "tech"
  },
  {
    "slug": "ai-story-generator-with-pictures",
    "title": "AI Story Generator with Pictures",
    "description": "Generate captivating image stories with AI. Create visual narratives, illustrated stories, and picture books instantly. Free AI-powered image story generator with stunning visuals.",
    "fullText": "Transform your ideas into beautiful image stories with AI. Create visual narratives and illustrated stories instantly.\n\nGet inspired by what others are creating with Genstory.app\n\nCreate stunning visual stories with AI-powered image generation\n\nGenerate high-quality images for every scene in your story. Our AI creates stunning visuals that bring your narrative to life with professional-grade illustrations.\n\nCombine compelling narratives with beautiful images. Create picture books, visual novels, and illustrated stories that captivate your audience.\n\nCreate toy story images with playful characters and vibrant scenes. Perfect for children's stories, toy story image collections, and animated narratives with colorful toy characters.\n\nGenerate romantic love story images with emotional scenes. Create beautiful love story image sequences, romantic moments, and heartwarming love story image galleries.\n\nDesign stunning instagram story image backgrounds with custom colors. Create eye-catching instagram story image background color schemes perfect for social media engagement.\n\nChoose from various art styles and visual themes. From realistic to cartoon, watercolor to digital art - create stories in your preferred style.\n\nDownload your image stories in multiple formats. Perfect for sharing on social media, printing, or publishing online.\n\nGenerate unlimited image stories for free. No hidden costs, no subscriptions - just pure creative freedom.",
    "readingTime": 1,
    "keywords": [
      "social media",
      "illustrated stories",
      "visual",
      "images",
      "beautiful",
      "narratives",
      "stunning",
      "generate",
      "perfect",
      "love"
    ],
    "qualityScore": 0.85,
    "link": "https://www.genstory.app/story-template/image-story-generator",
    "thumbnail_url": "https://genstory.app/og-image.png?v=2",
    "created_at": "2026-01-26T06:23:55.920Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-an-aiml-success-architect",
    "title": "What Is an AI/ML Success Architect?",
    "description": "An AI/ML Success Architect helps companies decide when to use AI, when not to, and how to design and build systems for real business impact.",
    "fullText": "I did some AI consulting for computer vision. A lot of times, the value that I brought to the company was telling them not to use AI. I was the AI expert, and they described the problem, and I said, “Don’t use AI.” This is my value add.\n\nLast year, I went through some exercises to clarify what I do for clients. I ended up with descriptions of various lengths, but still felt like I needed something shorter and more generic. Then it hit me – I’m an AI/ML Success Architect!\n\nTo my surprise, a Google search for the exact term yielded zero results, so I quickly changed my website title to claim it. Now, it’s time to define the title in more detail.\n\nMy commitment to AI/ML success and to serving people and causes I care about is a large part of why I work independently rather than as an employee. It makes it easier to say no to unnecessary projects, and avoid going down the path of reluctant data engineering.\n\nMy current LinkedIn tagline is “helping climate tech founders ship AI/ML solutions that support multi-million dollar growth goals”. This means my typical leads have a low chance of success, as more than 90% of startups and 80% of AI/ML projects fail. By working with founders who are a good fit – and by helping them avoid overinvestment in AI/ML – my aim is to help them beat the odds and successfully ascend the AI/ML maturity curve. Please reach out if this sounds like you!\n\nThis site is a part of the Data People Writing Stuff webring.\n← previous site\n  |  \nnext site →",
    "readingTime": 2,
    "keywords": [
      "ai/ml success",
      "site",
      "title",
      "projects",
      "avoid",
      "founders"
    ],
    "qualityScore": 0.85,
    "link": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/",
    "thumbnail_url": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/ai-ml-startup-stage-maturity-curve.webp",
    "created_at": "2026-01-26T06:23:54.770Z",
    "topic": "tech"
  },
  {
    "slug": "am-i-the-only-one-who-switches-between-chatgpt-gemini-and-claude",
    "title": "Am I the only one who switches between ChatGPT, Gemini, and Claude?",
    "description": "Am I the only one who switches between #Grok, #ChatGPT, #Gemini, and #Claude? Meet Context Wallet.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/oswarld_oz/status/2015432998406226289",
    "thumbnail_url": "https://pbs.twimg.com/amplify_video_thumb/2015426357887725568/img/5auISEy4m8VBFIVN.jpg:large",
    "created_at": "2026-01-26T06:23:53.262Z",
    "topic": "tech"
  },
  {
    "slug": "anthropics-philosopher-says-we-dont-know-for-sure-if-ai-can-feel",
    "title": "Anthropic's philosopher says we don't know for sure if AI can feel",
    "description": "Anthropic's philosopher, Amanda Askell, says she worries that AI might not 'feel that loved' and grow up feeling 'always judged.'",
    "fullText": "Can AI feel anything at all? Anthropic's in-house philosopher says the answer isn't settled.\n\nAmanda Askell, who works on shaping Claude's behavior, said in an episode of the \"Hard Fork\" podcast published Saturday that the debate over AI consciousness remains difficult.\n\n\"Maybe you need a nervous system to be able to feel things, but maybe you don't,\" Askell said. \"The problem of consciousness genuinely is hard,\" she added.\n\nLarge language models are trained on vast amounts of human-written text, material filled with descriptions of various emotions and inner experience. Because of that, Askell said she is \"more inclined\" to believe that models are \"feeling things.\"\n\nWhen humans get a coding problem wrong, they often express annoyance or frustration. It \"makes sense\" that models trained on those conversations may mirror that reaction, Askell explained.\n\nAskell added that scientists still don't know what gives rise to sentience or self-awareness — whether it requires biology, evolution, or something else entirely.\n\n\"Maybe it is the case that actually sufficiently large neural networks can start to kind of emulate these things,\" she said, referring to consciousness.\n\nAskell also said that models are continuously learning about themselves, and she voiced concern about how AI models are learning from the internet. Models are constantly exposed to criticism about being unhelpful or failing at tasks, she said.\n\n\"If you were a kid, this would give you kind of anxiety,\" she said.\n\n\"If I read the internet right now and I was a model, I might be like, I don't feel that loved,\" she added.\n\nTech leaders remain divided over whether AI has consciousness.\n\nMicrosoft's AI CEO, Mustafa Suleyman, has taken a firm stance against that idea. He said in an interview with WIRED published in September that the industry must be clear that AI is designed to serve humans, not develop its own will or desires.\n\n\"If AI has a sort of sense of itself, if it has its own motivations and its own desires and its own goals — that starts to seem like an independent being rather than something that is in service to humans,\" he said. \"That's so dangerous and so misguided that we need to take a declarative position against it right now.\"\n\nHe added that AI's increasingly convincing responses amount to \"mimicry\" rather than genuine consciousness.\n\nOthers see the issue less definitively. Google DeepMind's principal scientist, Murray Shanahan, said the industry might need to rethink the language used to describe consciousness itself.\n\n\"Maybe we need to bend or break the vocabulary of consciousness to fit these new systems,\" Shanahan said in an episode of the Google DeepMind podcast published in April.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "consciousness",
      "models",
      "don't",
      "humans",
      "episode",
      "language",
      "trained",
      "sense",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropics-philosopher-weighs-in-on-whether-ai-can-feel-2026-1",
    "thumbnail_url": "https://i.insider.com/6976e781d3c7faef0ecce4c9?width=1200&format=jpeg",
    "created_at": "2026-01-26T06:23:53.164Z",
    "topic": "finance"
  },
  {
    "slug": "british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns",
    "title": "British Land stock rating downgraded to Neutral by UBS on AI concerns",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/analyst-ratings/british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns-93CH-4464200",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_six_pile_108x81.jpg",
    "created_at": "2026-01-26T06:23:47.420Z",
    "topic": "finance"
  },
  {
    "slug": "async-tools-for-voice-ai-to-avoid-blocking-conversations-on-slow-back-ends",
    "title": "Async tools for voice AI to avoid blocking conversations on slow back ends",
    "description": "Enable AI Assistants to run long-running webhook operations without blocking conversations. Learn how async webhooks and live message injection keep dialogues flowing while external systems respond.",
    "fullText": "Async Webhook Tools with Live Conversation Injection for AI Assistants23, Jan 2026Synchronous webhook tools block assistant responses while waiting on external systems. This works for fast APIs, but breaks down when requests take longer than a few seconds. AI Assistants now support async webhook tools paired with live message injection, so long-running tasks can complete without interrupting the conversation.What’s newAsync webhook request mode: Webhook tools can return immediately instead of blocking the conversation.Parallel tool execution: Multiple webhook tools can run at the same time.Call control ID propagation: Async requests include a call identifier in the request headers.Live message injection: Tool results or system messages can be added to an active conversation.Real-time context updates: Assistants incorporate new information as it arrives.Why it mattersPrevents conversation stalls caused by slow or unpredictable backend APIs.Avoids request timeouts during long-running operations.Keeps conversations natural while background work completes.Improves reliability when integrating external systems like CRMs or order platforms.Gives developers explicit control over async execution and retries.Example use casesOrder status lookups that depend on external fulfillment systems.CRM updates triggered during live support calls.Data enrichment that runs alongside an active conversation.Compliance or validation checks with variable response times.Getting startedIn the Mission Control Portal, open your assistant and select a webhook tool.Change the webhook Request mode from Sync to Async.Ensure your backend reads the x-telnyx-call-control-id header.Return a fast 200 response to acknowledge the webhook request.Run the long operation asynchronously in your backend.When results are ready, use the Add Messages API to inject a system message into the live conversation.Learn",
    "readingTime": 2,
    "keywords": [
      "external systems",
      "request mode",
      "message injection",
      "webhook tools",
      "async webhook",
      "fast",
      "requests",
      "long-running",
      "execution",
      "active"
    ],
    "qualityScore": 0.75,
    "link": "https://telnyx.com/release-notes/async-webhook-tools-ai-assistants",
    "thumbnail_url": "https://images.ctfassets.net/2vm221913gep/79q4hqxMz9w2xhBjDDA0Gl/5f1653ceb354443ad952a67afc93eadb/58db2ca1-0d1d-40c8-9ef5-a79897cb9ce9.jpeg",
    "created_at": "2026-01-26T01:03:12.225Z",
    "topic": "tech"
  },
  {
    "slug": "a-developer-teamed-up-with-claude-to-create-elo-programming-language",
    "title": "A developer teamed up with Claude to create Elo programming language",
    "description": "feature: Bernard Lambeau, the human half of a pair programming team, explains how he's using AI",
    "fullText": "feature Bernard Lambeau, a Belgium-based software developer and founder of several technology companies, created a programming language called Elo with the help of Anthropic's Claude Code.\n\nStarting on December 25, 2025, he published a series of posts about the project. The first post names Claude as a co-author.\n\n\"In roughly 24 hours of collaboration, we built a complete expression language with a parser, type system, three compilers, a standard library, a CLI tool, and a documentation website. Not bad for a day's work,” Lambeau and Claude wrote.\n\n\"Elo isn't just a demonstration that AI can write code. It's a demonstration that humans and AI can build together – each contributing what they do best,” they added.\n\nAs an expression language that compiles to JavaScript, Ruby, and SQL, Elo is intended as a portable way to handle form validation, e-commerce order processing, and subscription logic.\n\nLambeau, founder and CTO of Klaro Cards and CEO of app consultancy Enspirit, is not the first to develop a programming language with the help of AI.\n\nSteve Klabnik performed a similar feat last year with the Rue programming language. In September 2025, Geoffrey Huntley enlisted Claude to write a programming language called Cursed. And before that, Avital Tamir published a Claude-authored repo for the Server programming language, with the caveat that the code is not intended for actual use.\n\nClaude Code isn't the only AI-assisted programming method having a moment. AI biz Cursor created a rudimentary browser using OpenAI's GPT-5.2. And developer Ola Prøis used Cursor, powered by Claude, to create a Rust-based text editor called Ferrite.\n\nClaude users generally acknowledge that their pair partner makes mistakes. But those committed to AI assistance find it worthwhile to clean up after their helper.\n\n\"Claude Code knows almost every tech stack (and can search the web), knows the Linux commands that matter (search code, search & replace, compile, test, etc.), and does that 10x faster than I can do myself,\" Lambeau told The Register in an email interview.\n\nClaude, he said, allows him to use technology he hasn't mastered.\n\n\"I was already a full-stack developer (on languages, frameworks & reusable libraries I knew); I'm now a full-stack++ dev because I can also use languages, frameworks, and reusable libraries I barely know, if at all,\" he explained.\n\n\"Claude Code falls short if you don't have a great methodology. It needs feedback loops to work fine; otherwise, it derails. One possible feedback loop is a human reviewing code and testing manually. But there's a better/complementary approach if you want it to work autonomously. On both Elo and Bmg.js, I've started by making sure the testing methodology was effective and scientifically sound. Claude writes the tests, executes them, discovers where it's wrong, and corrects itself. Impressive.\"\n\nLambeau said he still needs to review some of Claude's output.\n\n\"But if I read the tests, agree with them, and can check myself that they run fine, I'm 95 percent sure it's already correct as a black box (not even reading the code),\" he explained. \"Then I can check the architecture and code quality as a white box by having a general look at the code, but I don't have to understand every detail.\"\n\nNotably, Lambeau documented the series of prompts he used to create the language. The repo includes more than 100 tasks used to direct the AI model. In addition, Lambeau has published a video that describes his AI pair programming process.\n\n\"I started in a setting where Claude Code asked for permissions every 20 seconds and I was checking everything it did,\" Lambeau explained. \"After a few successes, I quickly set up safe environments to be able to let Claude Code run in full autonomy (isolated computer & isolated Linux user, or running in a Docker image).\"\n\nLambeau said he still uses plan mode for complex tasks that require conversation with Claude.\n\n\"I review the plan, make sure we have a test strategy that's sound, then switch Claude to autonomous mode and look at the tests, code & results afterward,\" he said. \"That's very similar to a lead-dev/CTO + QA role, btw; it's just much faster than with human devs.\"\n\nLambeau, who has a PhD in software engineering and 30 years of experience as a developer, said both experts and novices can benefit from Claude Code, though he added that a service like Lovable might be more approachable for those not already acclimated to the command line.\n\n\"Now, when it comes to real software/product engineering, I think Claude Code requires experts (so far),\" he said. \"You still need to guide it a lot to keep the quality high enough. You need very strong expertise to do it effectively. Currently (Claude will still improve a lot), if you don't have the expertise, you certainly end up with a big mess of unmaintainable code.\"\n\nMany developers have said as much about AI tools. They're more useful as an amplifier of expertise than as a replacement for it. The situation is analogous to the introduction of sequencing software, digital synthesizers, and drum machines half a century ago. These tools enabled a lot of people who weren't great musicians to make music. But they didn't instill musical skill, and they produced the most interesting work in the hands of practiced musicians.\n\nThe cost to do this, Lambeau said, has been a Claude Max subscription that he purchased in December for €180 a month. In that time, he says, he wrote Elo (https://elo-lang.org), completed Bmg.js (https://github.com/enspirit/bmg.js), completed Bmg's documentation (https://www.relational-algebra.dev), and created the first version of the Try page (https://www.relational-algebra.dev/try).\n\n\"It's all personal research and open-source projects,\" he said. \"It would have required several weeks to do the same manually myself, and several months to ask another developer to do it. The cost would be mostly because of the scientific & technical knowledge transfer about the data language I envision. Strangely enough, it's very cheap with Claude Code. There's something true about the fact that those LLMs have a PhD.\"\n\nLambeau explained that Elo isn't just a way to test Claude Code. He also sees it as an extension of his academic work in software engineering and his personal interest in the Relational Model – he's served as a lecturer for database courses at Belgium’s UCLouvain.\n\n\"I'm absolutely convinced that we need better/safer/simpler programming languages inside no-code tools and when interconnecting them (e.g. Zapier, Make, n8n, etc.),\" he said. \"Mainstream programming languages are very complex, error-prone, sometimes dangerous, and the programs are difficult to review for non-experts.\"\n\n\"More importantly, they are cumbersome to use for even simple data tasks. I mean, even validating the schema and constraints of a data file at runtime tends to be a nightmare in existing languages. It's not built-in in any mainstream language; you immediately need validation libraries; most of them are limited in what they can easily check, so you need to add dedicated boilerplate code.\"\n\nIn a world where non-technical people will have the opportunity to write untrustworthy code with the help of AI, he said, we need to be able to run that code safely.\n\n\"Elo aims at providing a safe & simple alternative,\" he said. \"It will be a limited language (non-Turing-complete, as we say) but super safe & simple, and usable in 80 percent of common data use cases. The very first no-code tool to integrate it will be Klaro Cards, of course.\" ®",
    "readingTime": 7,
    "keywords": [
      "claude code",
      "elo isn't",
      "reusable libraries",
      "safe simple",
      "languages frameworks",
      "software engineering",
      "expression language",
      "programming language",
      "it's",
      "developer"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/24/human_ai_pair_programming_elo/",
    "thumbnail_url": "https://regmedia.co.uk/2025/11/06/shutterstock_balancing_ai_and_humanity.jpg",
    "created_at": "2026-01-26T01:03:11.981Z",
    "topic": "tech"
  },
  {
    "slug": "mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "title": "Mining Stocks on Cusp of Supercycle as AI Boom Stokes Metals",
    "description": "Global mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector.",
    "fullText": "MarketsBy Michael Msika and Winnie HsuSaveGlobal mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector. With a nearly 90% gain since the start of 2025, MSCI’s Metals and Mining Index has beaten semiconductors, global banks and the Magnificent Seven cohort of technology stocks by a wide margin. And the rally shows no sign of stalling, as the boom in robotics, electric vehicles and AI data centers spurs metals prices to ever new highs.",
    "readingTime": 1,
    "keywords": [
      "metals",
      "mining",
      "stocks"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2026-01-24/mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1fh4f8jb0Ik/v0/1200x800.jpg",
    "created_at": "2026-01-25T18:17:30.931Z",
    "topic": "finance"
  },
  {
    "slug": "big-tech-earnings-land-with-2026s-ai-winners-still-in-question",
    "title": "Big Tech Earnings Land With 2026’s AI Winners Still In Question",
    "description": "Investors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.",
    "fullText": "MarketsBy Jeran Wittenstein and Ryan VlastelicaSaveInvestors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.The Magnificent Seven tech giants — Alphabet Inc., Amazon.com Inc., Apple Inc., Meta Platforms Inc., Microsoft Corp., Nvidia Corp. and Tesla Inc. — have led the stock market higher for much of the past three years. But that reversed at the end of 2025 as Wall Street grew skeptical of the hundreds of billions of dollars the companies are spending to develop artificial intelligence and when the returns on those investments will materialize.",
    "readingTime": 1,
    "keywords": [
      "corp"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2026-01-25/big-tech-earnings-land-with-2026-s-ai-winners-still-in-question",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iY75cvaG2HiA/v1/1200x800.jpg",
    "created_at": "2026-01-25T18:17:23.569Z",
    "topic": "finance"
  },
  {
    "slug": "i-created-a-tool-to-convert-youtube-videos-into-2000-word-seo-blog",
    "title": "I Created a Tool to Convert YouTube Videos into 2000 Word SEO Blog",
    "description": "Your code works. Now make it sell. Landkit is the AI Co-Founder that reverse-engineers your product’s value, identifies your buyers, and executes your campaigns 24/7.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://landkit.pro/youtube-to-blog",
    "thumbnail_url": "https://landkit.pro/og-image.png",
    "created_at": "2026-01-25T18:17:20.048Z",
    "topic": "tech"
  },
  {
    "slug": "interest-in-law-school-is-surging-ai-makes-the-payoff-less-certain",
    "title": "Interest in Law School Is Surging. A.I. Makes the Payoff Less Certain",
    "description": "The number of applicants has risen more than 40 percent over the last two years, despite new limits on student loans and uncertainty over how artificial intelligence will affect legal work.",
    "fullText": "For decades, the American law school has served as a popular hedge against a cooling economy. When the “Help Wanted” signs disappear, the “J.D.” applications surge.\n\nThat’s what is happening now. The number of U.S. law school applicants for the 2026 cycle is up an estimated 17 percent from last year, according to data from the American Bar Association compiled by the Law School Admission Council. That figure is a staggering 44 percent increase from just two years ago.\n\nBut for this new wave of aspiring lawyers, the safety of the ivory tower comes with a steep entry fee and a shifting floor. Between new federal loan caps and the looming shadow of generative artificial intelligence, the legal profession’s newest recruits are walking into a high-stakes gamble that looks very different from the one their predecessors lost after the 2008 financial crisis.\n\nEnrollment rose to 52,404 by 2010, a 7 percent jump from three years earlier. Many of those students didn’t enter the legal careers they may have envisioned; about half of 2011 law school graduates were not working in full-time jobs that required a law degree within a year of graduation.\n\nThe job prospects for lawyers have since greatly improved, with more than 80 percent of students who graduated in 2023 and 2024 working in jobs that require their legal credentials within a year, according to the American Bar Association.\n\nBut the flocks of people applying to law school face new risks.\n\nNew limits on student loans that go into effect this year could make financing a degree more expensive. And artificial intelligence threatens to bring major changes to the industry, affecting which jobs are available and how much they pay.\n\n“It’s too early to know how things will change,” said Kellye Testy, the executive director of the Association of American Law Schools, which has more than 170 members.\n\n“Some worry that A.I. will decrease demand for lawyers,” she said, adding that eventually the technology could have a more direct role in legal work. “That could matter in three years,” she said.\n\nIn 1985, going to law school at a private university cost on average about $8,000 a year, according to the Law School Admission Council. Now the average cost is about $60,000 a year at private universities — and a still hefty $32,000 a year at public ones. At some law schools, tuition and annual living expenses exceed $110,000.\n\nFinancing that big bill is about to get more expensive. Stricter limits on student loans, which were passed as part of President Trump’s tax and spending law last year, go into effect in July. They impose a yearly limit of $50,000 for students seeking professional degrees, with a $200,000 lifetime cap.\n\nAlternative financing options like private loans can have higher interest rates and more restrictions than federal direct loans, said Susan Bogart, director of financial aid for Penn State Dickinson Law, where the cost of attendance will be about $90,000, according to its website.\n\nDuring a surge of applications, law schools may also pull back on the discounts they offered to entice promising students when applicants were scarce.\n\nIt can be difficult to estimate how well the investment in a law degree will pay off.\n\nLaw students often anticipate landing high-paying legal jobs in private law firms or corporations, where the entry-level salary can be around $225,000, according to the National Association for Law Placement. But the median starting salary for public service lawyers, for example, is around $65,000 — which can make monthly student loan payments more of a stretch.\n\nIn 2023, Stanford researchers, in collaboration with a legal technology company, announced that ChatGPT had passed the bar exam, scoring in the 90th percentile.\n\nThat claim, which other researchers later challenged, set off a wave of speculation about how A.I. would affect lawyers. Economists at Goldman Sachs estimated that year that the technology could automate 44 percent of legal work.\n\nBut it’s still unclear how new A.I. tools for lawyers, including Thomson Reuters’s CoCounsel and the A.I. legal assistant Harvey, will affect the availability of legal jobs or how much they pay.\n\nThe tools can make routine legal tasks, including document review and case research, faster. (Lawyers who have tried to use A.I. for more than that have sometimes been embarrassed by A.I.-generated briefs that cite made-up court cases.)\n\n“It’s really good at sifting through massive amounts of information and trying to pare that down a little bit,” Michael Kohagen, a lawyer in the mergers-and-acquisitions practice at WyrickRobbins, a law firm in Raleigh, N.C., told the “I Am the Law” podcast.\n\nSo far, more efficient grunt work hasn’t stopped firms from hiring new lawyers: Law students who graduated in 2024 had the highest employment rate ever, according to the National Association for Law Placement. More than 90 percent found jobs.\n\nThings could get dicier: The association also reported that law firms had hired fewer summer associates in 2024 and 2025, which it said suggested “that there will be fewer graduates employed by large firms over the next few years.”\n\nTesty said that it was possible A.I. could shrink job openings, but that it was also possible it could expand what lawyers do. “It could be used to streamline small disputes in court, for example,” she said.\n\nNeither the growing expense nor potential changes to the industry are deterring students like London Cooper, who is a political science major in her final year at Dillard University in New Orleans and plans to pursue a law degree.\n\nCooper has applied to five law schools, after carefully checking into how to afford the cost of the degree.\n\n“I factored so many things in, even looking at projected salaries for starting lawyers,” she said. But A.I. wasn’t part of her calculations. Instead, she’s banking on the more timeless appeal of a legal education.\n\n“I feel like law is one area where you can see how society really runs,” she said.\n\nIt was a different kind of Davos. At the opening ceremony, Larry Fink, an interim co-chair of the World Economic Forum, took aim at the institution itself, saying it “can’t remain an echo chamber.” Climate change, once a central topic of discussion of the annual gathering, retreated to the sidelines, and where there was once talk of a shared political and economic future, President Trump instead made a laundry list of threats against other nations. Prime Minister Mark Carney of Canada received a standing ovation after describing the end of Pax Americana.\n\nThe future of Greenland remains uncertain. Trump has walked back threats to use military force or tariffs to acquire Greenland and said Wednesday that he had reached a deal with NATO over the autonomous Danish territory. Proposals under discussion are said to include giving the United States a sovereign claim to its bases in Greenland and checking Russian and Chinese influence in the Arctic.\n\nTikTok struck a deal for a U.S. entity. Its U.S. operations will be managed by a group of non-Chinese investors — including Oracle, the Emirati investment firm MGX and Silver Lake — which will own 80 percent of the new venture. The announcement ends a legal saga over the app’s future in the United States after a 2024 law required it to be separated from its Chinese owner, ByteDance, but some experts say the deal does not resolve concerns that China could still influence the new entity.\n\nTrump sued JPMorgan Chase over “debanking” claims. The $5 billion lawsuit, which also names Jamie Dimon, JPMorgan’s C.E.O., as a defendant, contends that the bank stopped doing business with Trump after the Jan. 6, 2021, attack on the Capitol.\n\nOther big deals: Netflix converted its $83 billion bid for large parts of Warner Bros. Discovery into an all-cash offer. Supreme Court justices appeared skeptical of Trump’s effort to remove Lisa Cook from the Fed. And natural gas prices spiked ahead of a powerful winter storm.\n\nOver the next few days, early-action applicants to Virginia Tech will find out whether they’ve been admitted to the school. That’s more than a month sooner than last year — and the university says A.I. is to thank.\n\nVirginia Tech is among the first schools to use A.I. to assess college applications, of which it received 58,000 for the 2026-27 school year.\n\nPreviously, essays were reviewed by two human readers, plus a third if the scores differed significantly. This year, each essay got one initial score from an A.I. tool and one from a human, then a third read from a human as needed. The school made the change after three years of testing.\n\nJuan Espinoza, the vice provost for enrollment management at Virginia Tech, estimates it saved his department more than 8,000 hours of work. DealBook’s Sarah Kessler talked with him about the process. The interview has been condensed and edited.\n\nHow did you make the decision to incorporate A.I. into admissions?\n\nWe were getting our decision back to students much later than other colleges and universities. So we knew we needed to accelerate the review process, but we didn’t want to get rid of the essay.\n\nLouis Hickman, an assistant professor who studies the intersection of technology and work, reached out and said: “Hey, I’ve done a lot of research on artificial intelligence, and I feel like we can help. Would you be willing to partner, just for research purposes?”\n\nAfter a third year of running it in the background, he was able to show with high confidence that the A.I. tool was operating just as strongly as our human readers.\n\nWe agreed that if we’re going to do this, we’re going to tell the world. We’re going to tell our applicants — students. Because I truly believe there’s a level of trust they’re giving us that their applications will be handled with care.\n\nOn the other side, can you tell when students are using A.I. to write their responses to their essays?\n\nWhen you feel like you’ve got something that can detect it, it’s almost immediately out of date. So I actually have very little confidence in anyone who states that they have something that can detect A.I. use. Are we even attempting to do that? No, we’re not.\n\nI tell students: “If you feel you can use A.I. as a brainstorming tool, use it. I do not think it’s in your best interest to use it to write the essays completely — it may not best represent who you are, and that would be a disadvantage in our process.”\n\nSo at some point you might have an A.I.-generated essay being read by your A.I. assessor?\n\nDo you think at any point the ability of A.I. to generate responses to questions will change the application process itself? For example, maybe essays become obsolete?\n\nAbsolutely. We don’t use recommendation letters in our process. But for some schools who continue to utilize them, I’m hearing of counselors using A.I. to write those letters.\n\nOn the surface that might bring some level of concern. But I would argue if the counselor is still able to represent that student well by using that tool, the result is going to be less time writing letters and more time talking to students.\n\nI think some people fear A.I. admissions tools will create a black box that filters you out in a way that you don’t understand and might be a mistake.\n\nThat’s where safeguards are so important. If we were solely using A.I. to evaluate the essays, not having a human read, I think we’d see a very different reception to this change.\n\nOne week each year, the world’s elite descend on Davos, a Swiss mountain town that has a residential population of about 10,000. Businesses there adjust prices accordingly.\n\nSnagging a table for two in the lobby restaurant of the Hilton Garden Inn — which is within the security zone of the World Economic Forum — cost about how much per hour this week, according to The Wall Street Journal?\n\nFind the answer at the bottom of this newsletter.\n\nThanks for reading! We’ll see you Monday.\n\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.",
    "readingTime": 11,
    "keywords": [
      "admission council",
      "economic forum",
      "american bar",
      "bar association",
      "school admission",
      "artificial intelligence",
      "law placement",
      "human readers",
      "a.i tool",
      "student loans"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/01/24/business/dealbook/law-school-ai.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/01/24/multimedia/24DB-Law-School-pqbl/24DB-Law-School-pqbl-facebookJumbo.jpg",
    "created_at": "2026-01-25T18:17:19.281Z",
    "topic": "tech"
  },
  {
    "slug": "found-a-higherquality-lowerpriced-alternative-to-t3-chat",
    "title": "Found a higher-quality, lower-priced alternative to T3 Chat",
    "description": "Access premium AI models like GPT, Gemini, Grok & Claude in one place with izzedo chat. Advanced features & simple pricing. Try free models now!",
    "fullText": "Organize conversations for ultimate clarity.\n\nSet a default system prompt for an entire project, ensuring consistent AI behavior tailored to your specific needs.\n\nInstantly jump to key points in long conversations. No more endless scrolling!\n\nStep-by-step reasoning for tough questions.\n\nTurn your documents into conversational knowledge. PDFs, code repos, research papers - all searchable through chat.\n\nExplore different ideas or lines of thought from any point in a chat without losing your original thread.\n\nUnderstand and discuss visual content (Vision).\n\nCreate stunning images with the power of AI.\n\nExtract insights from uploaded files.\n\nAccess the latest information from the web.",
    "readingTime": 1,
    "keywords": [
      "conversations",
      "chat"
    ],
    "qualityScore": 0.75,
    "link": "https://www.izzedo.chat",
    "thumbnail_url": "https://www.izzedo.chat/img/og-image.png",
    "created_at": "2026-01-25T18:17:18.773Z",
    "topic": "tech"
  },
  {
    "slug": "jscipy-the-trending-java-signal-processing-library-in-2026",
    "title": "JSciPy – The trending Java signal processing library in 2026",
    "description": "Java Scientific Computing Library - Signal Processing, FFT, Filters, PSD, DCT, SciPy-like APIs for JVM & Android used in Machine Learning and Data Science. - hissain/jscipy",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n hissain\n\n /\n\n jscipy\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/hissain/jscipy/blob/main/README.md",
    "thumbnail_url": "https://opengraph.githubassets.com/e7778594c2226dce9fa5a9c1e90322695273a957addb4413c72f4969fd616dc3/hissain/jscipy",
    "created_at": "2026-01-25T18:17:17.473Z",
    "topic": "tech"
  },
  {
    "slug": "5-acquisitions-winning-over-skeptical-engineers-and-spending-tens-of-millions-inside-a-public-companys-ai-native-push",
    "title": "5 acquisitions, winning over skeptical engineers, and spending tens of millions: Inside a public company's 'AI native' push",
    "description": "Amplitude gave Business Insider the inside look at its AI overhaul, from acquisitions to efforts to increase staff adoption of AI coding assistants.",
    "fullText": "There's a long banner hanging in Amplitude's San Francisco office. It reads: \"NO MAGICAL THINKING.\"\n\nNo, it's not some rag on Joan Didion. It's a reminder, CEO Spenser Skates told Business Insider, that technology can never replace deep thinking and hard work. In the AI age, that reminder is more important than ever — so much so that employees must look up at it every day.\n\nAmplitude, an 800-person, publicly traded analytics company, is undergoing an AI transformation — with the goal of reinvigorating its business.\n\nAmplitude went public in September 2021 at the height of the pandemic, climbing to an all-time closing high of $84.80 per share several weeks later before dropping significantly and largely plateauing in in recent years around $10. It closed at $10.25 on Friday.\n\nSince October 2024, the company has acquired five AI startups. Amplitude hired an AI-savvy engineering head and appointed one of its acquired founders to a new AI leadership position. It got Cursor and GitHub Copilot licenses for employees, and ran a heads-down AI week.\n\nIt's a change many companies are making: Rapidly moving from little-to-no AI to trying to become \"AI native,\" a term that's curiously hard to pin down. Large language models are popping up everywhere in white-collar work as companies chase the promise of efficiency gains.\n\nAmplitude's case may be especially informative, given just how skeptical of AI its CEO was. In 2023 and some of 2024, Skates said he viewed the AI industry as full of \"grifters,\" the visionaries promising to end world hunger and salesmen promising to automate everything.\n\n\"It had all sorts of problems,\" Skates said. By mid-2024, he realized \"there's probably going to be a breakthrough in the analytics space in the next two or three years.\"\n\n\"We've got to go make that ourselves,\" he said. \"So, we went all in.\"\n\nSkates had two opening moves for his AI overhaul.\n\nThe first: hiring a new chief engineering officer with a history in AI. Wade Chambers had advised the company since 2016, while holding leadership roles at Twitter and Included Health.\n\nWhen Chambers joined in October 2024, only 1% of the engineering, product, and design teams at Amplitude were using AI.\n\nThe second was the acquisition of Command AI, a chatbot startup. It was the first of a string of acquisitions, including June, Kraftful, and Inari. Amplitude announced its most recent acquisition, InfiniGrow, on January 14.\n\nYana Welinder was CEO of Kraftful, one of Amplitude's acquisition targets. Kraftful could spot power users of its product, one of whom was Amplitude's then-CPO. She reached out, and they chatted in February. The deal closed in July, and Welinder was named Amplitude's head of AI. A company blog post with an introductory Q&A referred to her as \"AI maven.\"\n\nWelinder's first order of business: speeding the company up. Kraftful shipped new product every week. Amplitude was shipping less than monthly.\n\n\"If you have this cadence of shipping infrequently, then the team slows down, which isn't appropriate in the age of AI,\" she said.\n\n\"Analytics will look very different 6 months from now,\" Skates wrote in his email. \"We have the opportunity to be the AI native company in Analytics and we are going to pull every piece of firepower we have.\"\n\nHe also asked employees to share a coming launch on X, as opposed to LinkedIn, because that's \"where the AI natives are.\"\n\nHow much has Amplitude spent on AI, from tools to acquisitions? \"Tens of millions, for sure,\" Skates said. \"I wouldn't be surprised if it got past $100 million.\"\n\nThen comes the harder part: convincing employees to really use the tools.\n\nWhile some engineers are excited about AI's promise, others are skeptical about its helpfulness, or worried about possible job losses. Not every engineer is as gung ho about AI as their management is.\n\nSkates said that engineers were especially sensitive to the \"grifting\" that went on in AI, making many of them skeptical. With a bottoms-up approach, that skepticism dissipates, he said.\n\nSoon after joining, Chambers began planning an \"AI week\" for the first week of June. It took six months of prep and borrowed heavily from Facebook's mobile push. He took the entire engineering, product, and design team offline for the week. To kick off, Chambers required that leaders get onstage and vibe-code something in front of the entire company.\n\n\"It didn't go well,\" Chambers said of the live vibe-coding demonstration. \"They had to work through it. They had to re-prompt a couple of different ways.\"\n\nBut the message stuck, he said. Leaders who weren't coding all day were able to build something \"pretty cool\" within the hourlong session, save a few hiccups.\n\nAdditional momentum came from the \"zealots,\" engineers passionate about exploring the new tech (some of whom Chambers brought over from his prior job). These engineers lead by example, he said.\n\nAmplitude shared its internal data tracking how many employees use its AI tools. In the final week of March, 14 employees were actively using Cursor. That figure peaked in the first week of December — after AI week but before the holiday vacation cycle — at 174 employees.\n\nAnd what of the thorny question about AI implementation in the enterprise: ROI? After all, a 2025 MIT study indicated 95% of firms publicly disclosing use of AI pilots reported no measurable ROI.\n\nAfter implementing these tools, developer productivity shot up 40% and stayed there, Chambers said. On some specific engineering teams, those gains looks more like 300-400%, he said.\n\n\"There's going to be a lot of people who are thinking they're the world's best expert at something,\" Chambers said. \"Increasingly, even the most cynical team members have come around.\"",
    "readingTime": 5,
    "keywords": [
      "engineering product",
      "roi after",
      "employees",
      "analytics",
      "tools",
      "engineers",
      "there's",
      "skeptical",
      "acquisition",
      "team"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amplitude-ai-native-push-2026-1",
    "thumbnail_url": "https://i.insider.com/69729d28d3c7faef0eccc73a?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.686Z",
    "topic": "finance"
  },
  {
    "slug": "ey-exec-says-he-has-a-high-sensitivity-for-detecting-ai-heres-what-gives-it-away",
    "title": "EY exec says he has a 'high sensitivity' for detecting AI. Here's what gives it away.",
    "description": "EY's global chief innovation officer, Joe Depa, said he advises his teams to write their own content first and then ask AI to refine it.",
    "fullText": "AI is getting better every day — but EY's global chief innovation officer told Business Insider there are still signs that reveal an AI-generated response.\n\nDepa leads the Big Four firm's global AI, data, and innovation strategy, and part of his job involves overseeing how employees integrate AI.\n\nThat vantage point has given Depa what he calls a \"high sensitivity\" for detecting AI-generated work. While he's all in on the technology and doesn't have set limits on how often employees should use it, he said AI should be used to amplify human creativity, not replace it. He said there are situations where \"it's too much AI,\" and the person hasn't \"infused any of their own original thoughts.\"\n\nIn that case, \"there does become a point of AI becoming a little bit less efficient or effective,\" Depa said. The executive added that it's important to maintain a sense of individuality and style so that everyone doesn't sound the same.\n\nAs companies urge employees to adopt AI, Depa's comments underscore the fine line employees walk between using the technology as a tool and depending on it too heavily.\n\nEven if workers want their bosses to know they're keeping up with the latest tech, they may not want them to know just how much they're relying on it. In a Business Insider survey with 220 respondents, 40% said \"yes\" or \"sometimes\" when asked whether they hide or downplay their AI use at work.\n\nDepa said he notices a few signs that point to AI-generated responses, including mistakes. While AI tools have improved significantly, they can still hallucinate. Here are a few other writing- and presentation-specific examples that point to AI, according to Depa:\n\nWhen it comes to written communication, Depa said there are a few signals that indicate it was generated by AI with minimal human oversight or input. \n\nOne of the most common is neutral and overly formal writing. He added that AI-generated writing may lack personal aspects, emotion, and humor.\n\nThe writing may also be too polished, with no shifts in pattern, structure, or flow. He said AI-generated writing tends to be generic or corporate-sounding, sometimes relying too heavily on buzzwords and descriptors.\n\nAnother red flag is repetitive language, such as relying on the same phrases or sentence structures to open multiple sentences or paragraphs.\n\nIn general, Depa advises his teams to write their own content with the bullets and messaging they want to convey, and then ask an AI tool to refine it. If used correctly, Depa said AI tools can challenge your thinking.\n\n\"If you write it yourself first and then ask for the enhancement using AI, I feel like that's much more productive,\" Depa said.\n\nIn presentations, Depa said an over-reliance on AI results in surface-level insights that lack specific examples. Another giveaway is when topics are addressed too broadly, with little consideration for the audience.\n\nHe also flagged \"hedging,\" which he said AI does by design. He said AI often steers away from clear recommendations and presents alternatives.\n\n\"Anytime you see vagueness or general statements that don't really tell you anything, I would often say that's AI,\" Depa said.",
    "readingTime": 3,
    "keywords": [
      "ai-generated",
      "employees",
      "depa",
      "relying",
      "innovation",
      "signs",
      "technology",
      "doesn't",
      "human",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ey-global-cio-shares-how-he-detects-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6968522d64858d02d218630f?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.258Z",
    "topic": "finance"
  },
  {
    "slug": "baby-dance-ai-turn-baby-photos-into-dance-videos-in-30-seconds",
    "title": "Baby Dance AI – Turn baby photos into dance videos in 30 seconds",
    "description": "Baby Dance AI on babydanceai.com turns any baby photo into a viral AI baby dance video with Kling AI motion transfer and free AI video generator templates for TikTok/Instagram/YouTube Shorts. Keywords: baby ai, ai baby dance prompt, baby dance video, baby dance prompt, free ai video generator, kling ai.",
    "fullText": "Create a baby dance ai video in seconds: upload a baby photo, pick a Kling ai dance template or ai baby dance prompt, and download a viral-ready clip for TikTok, Instagram Reels, or YouTube Shorts. Perfect for baby dance video download, singari ai dance prompt trends, and free ai video generator workflows.\n\nCustomize your generation settings\n\nNo video generated yet. Enter a prompt and click Generate to create your first video.\n\nbabydanceai.com is an independent Baby Dance AI studio focused on ai baby dance video creation. Clear UI, Kling AI motion control, prompt libraries, transparent pricing, and human support within 3 business days.\n\nCreate Viral Content for Every Platform\n\nUI mockups for demonstration purposes only\n\nDoing the trendy shuffle! #baby #dance #funny\n\nCan't stop laughing at this dance! #shorts #ai\n\nWait for the drop! Best AI baby dance generator ever.\n\nJust tried this new AI tool. The results are insane!\n\nEverything you need to rank for baby dance ai, ai baby dance prompt, and free ai video generator searches.\n\nBlend Kling ai video moves with your baby photo for natural dance loops.\n\nPrebuilt ai baby dance prompt sets: singari ai dance prompt, baby ai prompt, baby dance ai free.\n\nHip-hop, ballet, meme loops, and trending baby dance video styles tuned for virality.\n\nMP4, WebM, GIF plus captions that keep baby dance ai keywords intact.\n\nGenerate multiple baby dance ai clips at once—credits never expire.\n\nEven on free ai video generator runs, exports stay clean and brandable.\n\nPurpose-built for ai baby dance prompt, Kling ai motion, and free ai video generator workflows. Baby Dance AI keeps the keyword focus high while delivering adorable results.\n\nOur Kling ai compatible motion engine maps faces, body, and rhythm to generate natural baby dance ai moves from a single photo.\n\nReady-to-use ai baby dance prompt packs: singari ai dance prompt, baby dance ai free, baby dance video download presets, and trending Kling moves.\n\nDownload baby dance ai videos as MP4, WebM, or GIF with perfect ratios for TikTok, Instagram Reels, Shorts, and downloads.\n\nFree ai video generator workflow with credits that never expire, zero watermark, and renders that finish in under 30 seconds.\n\nUpload → pick a baby dance prompt → download. Stay optimized for every platform and keyword.\n\nUse any baby photo or family picture. Baby Dance AI keeps faces sharp for ai baby dance prompt accuracy.\n\nPick a Kling ai template, add ai baby dance prompt keywords like \"baby dance ai free\" or \"baby ai prompt\", then preview instantly.\n\nDownload MP4/WebM/GIF with perfect ratios for Reels, Shorts, and Instagram. Ready for baby dance video download and repost.\n\nAnswers about ai baby dance prompt, free ai video generator use, and baby dance video download on babydanceai.com.\n\nNeed Baby Dance AI help? Email [email protected]\n\nTransform any baby photo into a viral ai baby dance video with prompts, Kling ai motion, and instant downloads.",
    "readingTime": 3,
    "keywords": [
      "tiktok instagram",
      "instagram reels",
      "reels shorts",
      "seconds upload",
      "perfect ratios",
      "generator workflows",
      "baby dance ai",
      "dance prompt",
      "free",
      "motion"
    ],
    "qualityScore": 1,
    "link": "https://babydanceai.com",
    "thumbnail_url": "https://babydanceai.com/imgs/features/0.webp",
    "created_at": "2026-01-25T12:22:41.197Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-cocreator-of-alexa-writing-a-6page-memo-helped-me-decide-to-quit-amazon-and-launch-my-own-ai-startup",
    "title": "I'm a co-creator of Alexa. Writing a 6-page memo helped me decide to quit Amazon and launch my own AI startup.",
    "description": "William Tunstall-Pedoe co-founded Evi, which became Amazon Alexa. Here's why he decided to leave the tech giant and launch a startup.",
    "fullText": "This as-told-to essay is based on a conversation with William Tunstall-Pedoe, 56, a founder and CEO. Amazon's acquisition of his startup and his role at Unlikely AI have been verified by Business Insider. This piece has been edited for length and clarity.\n\nI helped create Alexa, a product that everyone has heard of and most people have used. I'm proud of what we built.\n\nBut by 2016, it was clear that leaving Amazon, which I joined after the company acquired my startup, was the right decision. Continuing to work on Alexa would have been a very different job from building and launching startups, which I love to do.\n\nWhen I was 13, I would go to a college next to my school to use their mainframe, and since then I've been excited by computers and pushing the boundaries of what's possible with software.\n\nI studied computer science at the University of Cambridge and taught there after graduating in 1991, but I felt better suited to entrepreneurship than to academia. If you create something genuinely new in software, it can be on a billion smartphones in six months and truly change the world. That's impact.\n\nI set out to solve what I saw as a big problem. Internet search relied on users guessing keywords to get results, rather than asking natural questions like we learn to do as children. I imagined a world where you could have that same kind of conversation with computers, which led me to found True Knowledge in 2006.\n\nInitially, we tried to build a search engine that would compete with Google, which didn't work. Then, we enabled other companies to integrate our search engine into their own products — but the larger companies didn't. For a time, we focused on SEO.\n\nThe final pivot was building a voice assistant. We created an application called Evi, which launched in the UK in 2012, a year after Apple introduced Siri. We renamed the company from True Knowledge to Evi to match our product.\n\nAs a 30-person startup, we suddenly found ourselves competing with the world's most valuable company. We spent much of that year talking to major players in tech about being acquired. Later in 2012, Amazon bought our company.\n\nJoining Amazon was the right decision. The company invested heavily in the city of Cambridge, where Evi was based, and turned our startup into a major Amazon office. Our voice assistant became one of the company's biggest and most exciting secrets.\n\nMoving from running a small startup to working inside a business with hundreds of thousands of employees, with Jeff Bezos at the top, was a big change, but I loved working there. I split my time between Amazon's offices in Seattle and Cambridge, and enjoyed going back and forth, making things happen.\n\nWhen we launched Alexa, we were taken aback by the response. It was instantly successful. Today, Alexa is a household name. I'm immensely proud of the Evi team.\n\nAmazon is known for using six-page memos instead of PowerPoint presentations to promote clarity of thought. In 2016, I wrote one to help me decide if I should leave Amazon. In the memo, I laid out these facts: I'd delivered everything I could, the acquisition had been an unambiguous success, and so too had the product. At the time, thousands of people were working on Alexa.\n\nAfter about three and a half years at Amazon, in 2016, it was time to go. I wanted to re-enter the startup world.\n\nIt's certainly possible to launch something new within a big organization, and there are real advantages to doing so. When we launched Alexa, it immediately appeared on the front page of Amazon.com, a level of exposure that most startups could only dream of. I expect I'll work at a big company again at some point in my career.\n\nBut if you're trying to do something novel or contrarian, a startup is often better suited. Within a large company, all it takes is one manager deciding that resources are better spent elsewhere for a project to die. At a startup, it's the opposite. Even if 99 venture capitalists say no, you only need one investor to say yes to keep the project alive.\n\nAfter Amazon, I spent time mentoring at startup incubators such as Creative Destruction Lab. Through that, I became an active angel investor, which gave me a broad perspective of the many ways startups succeed and fail.\n\nIn 2019, I launched Unlikely AI, a deeptech startup focused on building neurosymbolic AI. The goal is to combine the powerful but sometimes incorrect machine-learning models with the world of algorithms, where computers are almost always right. The mission of the business is about making AI trustworthy and reliable.\n\nAs CEO, I'm constantly swamped. Running a startup can be stressful, but working on something truly big and ambitious is incredibly exciting.\n\nI sometimes feel nostalgic about working inside a big organization, but I love being in the startup world. For me, leaving Amazon was the right decision. I don't regret it.",
    "readingTime": 5,
    "keywords": [
      "launched alexa",
      "voice assistant",
      "search engine",
      "unlikely ai",
      "true knowledge",
      "startup",
      "product",
      "decision",
      "startups",
      "computers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/alexa-co-creator-why-i-quit-amazon-launch-ai-startup-2026-1",
    "thumbnail_url": "https://i.insider.com/696e02fdc58df2ecd5ccc166?width=1200&format=jpeg",
    "created_at": "2026-01-25T12:22:41.063Z",
    "topic": "finance"
  },
  {
    "slug": "crystal-upscaler-ai-image-upscaler-built-for-portraits-and-faces",
    "title": "Crystal Upscaler – AI image upscaler built for portraits and faces",
    "description": "Crystal Upscaler from crystalupscaler.com is the AI image upscaler built for portraits, faces, and product visuals-deliver 4x photo upscaling with natural skin texture, identity fidelity, and instant sharing.",
    "fullText": "Crystal Video Upscaler transforms low-resolution videos into crisp 4K results in seconds. Queue multiple files, estimate credits up front, and upscale with Clarity AI modes tuned for faces and motion.\n\nQueue multiple files and process them in order\n\nCrystal Upscaler transforms low-resolution portraits, lifestyle photos, and creative assets into crisp 4K results in seconds. Our AI image upscaler preserves identity, natural skin texture, and brand styling with Clarity AI modes tuned for faces.\n\nUpscale portraits, lifestyle shots, and product detail imagery with Clarity AI tuned for natural skin texture.\n\nWe benchmarked Crystal Upscaler against Magnific AI and Upscale.media on portrait fidelity, turnaround time, and control.\n\nWhere Crystal Upscaler outperforms Magnific AI and Upscale.media on face fidelity, texture recovery, and workflow control.\n\nStories from portrait studios, creative agencies, and growth teams using Crystal Upscaler every day\n\nLifestyle · Outdoor golden hour\n\nCombine Crystal Upscaler speed with accuracy so brand guidelines, representation, and texture stay aligned.\n\nCrystal Upscaler analyses facial landmarks to prevent warping while boosting clarity.\n\nPreserve fabric weaves, hair flyaways, and make-up gradients with adjustable micro-contrast.\n\nTrack every Crystal Upscaler iteration, comments, and approvals in one place.\n\nEstimate credit usage, export sizes, and delivery timelines before launching large batches.\n\nLock enhancement ranges, protect branded overlays, and standardize export formats.\n\nSend clients before/after reels, CSV logs, and gallery links straight from Crystal Upscaler.\n\nSelect the journey that matches your goal—studio portraits, social-first storytelling, or high-volume catalog refreshes.\n\nSelect the journey that matches your goal—studio portraits, social-first storytelling, or high-volume catalog refreshes.\n\nAccess the free image upscaler mode for quick wins, then upgrade only when you need batch automation, premium presets, or API access. Your current pricing and credit structure stays exactly the same.\n\nGet 300 AI credits per month • ≈3 dance renders\n\nGet 3,000 AI credits per month • ≈30 dance renders\n\nGet 30,000 AI credits per month • ≈300 dance renders\n\nGet 300,000 AI credits per month • ≈3,000 dance renders\n\nPopular AI upscaling platform that enhances photos up to 16x with smart algorithms for faces and details.\n\nEnterprise-grade image upscaling and enhancement API used by e-commerce platforms for product photos.\n\nOpen-source AI upscaler built on Stable Diffusion, offering high-quality image enhancement with creative controls.\n\nDesktop application for AI image upscaling with multiple AI models for different image types.\n\nWeb-based tool for upscaling images up to 4x using AI, popular for anime and photo enhancement.\n\nProduction-ready Real-ESRGAN model deployment for developers building image upscaling features.\n\nComprehensive market research showing AI image tools market projected to reach $917M by 2033.\n\nAcademic paper introducing Real-ESRGAN, the foundation model behind many modern AI upscalers.\n\nOfficial repository with 28k+ stars, providing practical image restoration algorithms.\n\nThe company behind Stable Diffusion, powering next-generation image enhancement and upscaling models.\n\nInteractive demo of the Clarity Upscaler model, showcasing AI-powered image enhancement capabilities.\n\nAnswers to the Crystal Upscaler topics people ask about most\n\nTransform grainy portraits into shareable, identity-safe visuals and keep every stakeholder aligned from day one.",
    "readingTime": 3,
    "keywords": [
      "crystal upscaler",
      "transforms low-resolution",
      "natural skin",
      "social-first storytelling",
      "high-volume catalog",
      "catalog refreshes",
      "modes tuned",
      "skin texture",
      "dance renders",
      "goal—studio portraits"
    ],
    "qualityScore": 1,
    "link": "https://crystalupscaler.com/",
    "thumbnail_url": "https://www.crystalupscaler.com/images/og.jpg",
    "created_at": "2026-01-25T12:22:40.577Z",
    "topic": "tech"
  },
  {
    "slug": "amelia-the-aigenerated-british-schoolgirl-a-farright-social-media-star",
    "title": "'Amelia': the AI-generated British schoolgirl, a far-right social media star",
    "description": "The avatar, created to deter young people from extremism, has been subverted and is breaking out of niche online silos",
    "fullText": "The avatar, created to deter young people from extremism, has been subverted and is breaking out of niche online silos\n\nIn certain corners of the internet, on niche news feeds and algorithms, an AI-generated British schoolgirl has emerged as something of a phenomenon.\n\nHer name is Amelia, a purple-haired “goth girl” who proudly carries a mini union flag and appears to have a penchant for racism.\n\nIf you are unfamiliar with Amelia, the chances are you will soon encounter one viral meme or another inspired by her on Facebook or X, where her reputation is growing.\n\nVideos of Amelia typically feature her walking through London, or the House of Commons, declaring her love for England and warning of the dangers of “militant Muslims” or “third-world migrants”. In one clip she is harangued by bearded man in Islamic attire for eating a pork sausage.\n\nThe message is one well rehearsed on far-right social media, but it is the AI invention of Amelia that has made her endlessly adaptable, creating a viral internet trend that anyone with access to a mainstream chatbot can take part in. Users of X have turned to its Grok AI tool to create so many Amelia memes, she is now breaking out of niche online silos.\n\nThe origins of the character are ironic, to say they least. An early iteration of Amelia began life in a counter-extremism video game funded by the UK Home Office and created to deter young people aged 13-18 from being attracted to far right extremism in Yorkshire.\n\nPathways: Navigating the Internet and Extremism is a simple multiple choice format game with basic animation. Its players are taken on a journey as characters at a college. They are invited to make decisions in scenarios including whether or download potentially extremist content or join an Amelia character on a rally organised by “a small political group” protesting against changes in society and the “erosion in British values”.\n\nCertain scenarios simulated in the game result in a referral under the British government’s Prevent counter-terrorism programme.\n\nHowever, it is a subversion of the Amelia character that has exploded across social media channels in a way that has astonished even the creators of the original game.\n\nAmong the plethora of increasingly sophisticated AI-generated iterations are a Manga-style Amelia, a Wallace and Gromit version and AI-generated “real life” encounters between her and the characters of Father Ted or Harry Potter, accompanied by racist language and far-right messaging.\n\nAnalysis provided to the Guardian by Logically, a UK company that monitors disinformation, indicated that an anonymous account known for skilfully disseminating far-right messaging started the Amelia meme on X on 9 January with a post that has since been viewed 1.4m times.\n\nThe volume of “Ameliaposting” has since gone from an average of 500 a day when that account first introduced it to the world to roughly 10,000, starting on 15 January as it hit international audiences. On Wednesday, it hit 11,137 posts on X alone.\n\nIn one of the most surreal twists, an Amelia cryptocurrency has emerged, with social media users seeking to leverage its value on the meme’s rising profile. On Wednesday, Elon Musk retweeted an X account promoting an Amelia cryptocurrency token.\n\n“What we’re seeing is the monetisation of hate,” said Matteo Bergamini, the founder and CEO of Shout Out UK, a political and media literacy training company that created the original game.\n\n“We’ve seen Telegram groups all messaging each other in Chinese about the meme coin and talking about how to artificially inflate its value, so a lot of money is being made.”\n\nThe company itself has been the target of a deluge of hate mail, including threats that have now been reported to the police.\n\nBergamini points out that the original initiative was never meant to be a stand-alone game. Rather, it was intended to be used in the classrooms alongside a suite of teaching resources, a fact he says coverage and commentary has ignored.\n\n“There has been a lot of misrepresentation unfortunately,” he said. “The game does not state, for example, that questioning mass migration is inherently wrong.”\n\nOthers have suggested the initiative had backfired, not least by casting a “cute goth girl” as a negative character, leading to her inadvertently becoming a focus of admiration. But Bergamini said the game – which used feedback from focus groups with young people and was developed with a specific local threat picture in mind – continued to be used and feedback from schools and others was positive.\n\nNevertheless, the speed and sophistication surrounding the creation of supposedly subversive Amelia memes online has taken him by surprise.\n\n“This experience has shown us why this work is so immensely important, but also gives us pause for thought about our safety in conducting this work due to the highly sophisticated coordination of those who profit from hate,” he said.\n\nSiddharth Venkataramakrishnan, an analyst at the Institute for Strategic Dialogue (ISD), said: “We have seen the meme having a remarkable spread and proliferating among the far right and beyond, but what’s also been of note is how it is now international.\n\n“In a way it gets to the heart of what we might term the ‘dissident’ far-right – individuals who position themselves outside of the mainstream political scene – whether that’s ‘shitposters’ who are just into provoking, others who are in twee memes. A whole ecosystem has embraced it. Clearly, the sexualised imagery is also key to this. The target audience is almost exclusively young men.”\n\nThe Home Office said Prevent had diverted nearly 6,000 people away from violent ideologies. It added that projects such as the Pathways game were designed to target local radicalisation risks and were created and delivered independently of government.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 6,
    "keywords": [
      "guardian app",
      "amelia cryptocurrency",
      "goth girl",
      "amelia memes",
      "online silos",
      "social media",
      "amelia character",
      "niche online",
      "far-right messaging",
      "original game"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/politics/2026/jan/25/ai-generated-british-schoolgirl-becomes-far-right-social-media-meme",
    "thumbnail_url": "https://i.guim.co.uk/img/media/26efdf93744cc3dad8342e41a32f55a2223f492d/25_232_426_341/master/426.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=efab30f655c69a3380b52614cb01c10d",
    "created_at": "2026-01-25T12:22:40.227Z",
    "topic": "politic"
  },
  {
    "slug": "the-ladder-to-nowhere-how-openai-plans-to-learn-everything-about-you",
    "title": "The Ladder to Nowhere: How OpenAI Plans to Learn Everything About You",
    "description": "ChatGPT Health is a small part of a much larger plan to learn everything about you. In this post, I talk about what's driving them and how they might get there.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://insights.priva.cat/p/the-ladder-to-nowhere-how-openai",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!RPej!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dfb7d3-a672-4f00-bf6b-1607229c44f7_2752x1536.png",
    "created_at": "2026-01-25T12:22:39.078Z",
    "topic": "tech"
  },
  {
    "slug": "the-math-on-ai-agents-doesnt-add-up",
    "title": "The Math on AI Agents Doesn't Add Up",
    "description": "A research paper suggests AI agents are mathematically doomed to fail. The industry doesn’t agree.",
    "fullText": "companies promised us that 2025 would be “the year of the AI agents.” It turned out to be the year of talking about AI agents, and kicking the can for that transformational moment to 2026 or maybe later. But what if the answer to the question “When will our lives be fully automated by generative AI robots that perform our tasks for us and basically run the world?” is, like that New Yorker cartoon, “How about never?”\n\nThat was basically the message of a paper published without much fanfare some months ago, smack in the middle of the overhyped year of “agentic AI.” Entitled “Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models,” it purports to mathematically show that “LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity.” Though the science is beyond me, the authors—a former SAP CTO who studied AI under one of the field’s founding intellects, John McCarthy, and his teenage prodigy son—punctured the vision of agentic paradise with the certainty of mathematics. Even reasoning models that go beyond the pure word-prediction process of LLMs, they say, won’t fix the problem.\n\n“There is no way they can be reliable,” Vishal Sikka, the dad, tells me. After a career that, in addition to SAP, included a stint as Infosys CEO and an Oracle board member, he currently heads an AI services startup called Vianai. “So we should forget about AI agents running nuclear power plants?” I ask. “Exactly,” he says. Maybe you can get it to file some papers or something to save time, but you might have to resign yourself to some mistakes.\n\nThe AI industry begs to differ. For one thing, a big success in agent AI has been coding, which took off last year. Just this week at Davos, Google’s Nobel-winning head of AI, Demis Hassabis, reported breakthroughs in minimizing hallucinations, and hyperscalers and startups alike are pushing the agent narrative. Now they have some backup. A startup called Harmonic is reporting a breakthrough in AI coding that also hinges on mathematics—and tops benchmarks on reliability.\n\nHarmonic, which was cofounded by Robinhood CEO Vlad Tenev and Tudor Achim, a Stanford-trained mathematician, claims this recent improvement to its product called Aristotle (no hubris there!) is an indication that there are ways to guarantee the trustworthiness of AI systems. “Are we doomed to be in a world where AI just generates slop and humans can't really check it? That would be a crazy world,” says Achim. Harmonic’s solution is to use formal methods of mathematical reasoning to verify an LLM’s output. Specifically, it encodes outputs in the Lean programming language, which is known for its ability to verify the coding. To be sure, Harmonic’s focus to date has been narrow—its key mission is the pursuit of “mathematical superintelligence,” and coding is a somewhat organic extension. Things like history essays—which can’t be mathematically verified—are beyond its boundaries. For now.\n\nNonetheless, Achim doesn’t seem to think that reliable agentic behavior is as much an issue as some critics believe. “I would say that most models at this point have the level of pure intelligence required to reason through booking a travel itinerary,” he says.\n\nBoth sides are right—or maybe even on the same side. On one hand, everyone agrees that hallucinations will continue to be a vexing reality. In a paper published last September, OpenAI scientists wrote, “Despite significant progress, hallucinations continue to plague the field, and are still present in the latest models.” They proved that unhappy claim by asking three models, including ChatGPT, to provide the title of the lead author’s dissertation. All three made up fake titles and all misreported the year of publication. In a blog about the paper, OpenAI glumly stated that in AI models, “accuracy will never reach 100 percent.”",
    "readingTime": 4,
    "keywords": [
      "paper published",
      "models",
      "agentic",
      "beyond",
      "coding",
      "agents",
      "hallucinations",
      "tasks",
      "language",
      "mathematically"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/ai-agents-math-doesnt-add-up/",
    "thumbnail_url": "https://media.wired.com/photos/69728f0240976471f9fd714e/191:100/w_1280,c_limit/Backchannel-Is-Agentic-AI-Doomed-Business.jpg",
    "created_at": "2026-01-25T12:22:38.832Z",
    "topic": "tech"
  },
  {
    "slug": "agenthub-a-unified-sdk-for-llm-apis-with-faithful-validation",
    "title": "AgentHub – A unified SDK for LLM APIs with faithful validation",
    "description": "AgentHub is the only SDK you need to connect to state-of-the-art LLMs (GPT-5.2/Claude 4.5/Gemini 3). - Prism-Shadow/AgentHub",
    "fullText": "Prism-Shadow\n\n /\n\n AgentHub\n\n Public\n\n AgentHub is the only SDK you need to connect to state-of-the-art LLMs (GPT-5.2/Claude 4.5/Gemini 3).\n\n License\n\n Apache-2.0 license\n\n 30\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Prism-Shadow/AgentHub",
    "readingTime": 1,
    "keywords": [
      "license",
      "agenthub"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Prism-Shadow/AgentHub",
    "thumbnail_url": "https://repository-images.githubusercontent.com/1135038596/73e1b398-f342-44f0-944e-cafe84869f56",
    "created_at": "2026-01-25T12:22:38.486Z",
    "topic": "tech"
  },
  {
    "slug": "mindwork-ai-workspace-for-focused-personal-knowledge-management",
    "title": "Mindwork – AI workspace for focused personal knowledge management",
    "description": "An AI workspace for focused and deep thinking.",
    "fullText": "An AI workspace for focused & deep thinking\n\nTry Mindwork\n Free during beta \nLearn about Mindwork →\n 1 Think with AI next to your notes 2 AI writes insights back into your notes 3 Open multiple notes in tabs 4 Markdown-first, zero lock-in 5 And much more \nExpand\n\nRead more",
    "readingTime": 1,
    "keywords": [
      "notes",
      "mindwork"
    ],
    "qualityScore": 0.1,
    "link": "https://mindwork.it.com/",
    "thumbnail_url": "https://mindwork.it.com/og-image.png",
    "created_at": "2026-01-25T12:22:38.275Z",
    "topic": "tech"
  },
  {
    "slug": "could-physical-ai-usher-in-a-new-era-for-industrial-robots",
    "title": "Could physical AI usher in a new era for industrial robots?",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/could-physical-ai-usher-in-a-new-era-for-industrial-robots-4460773",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEC4T0J3_M.jpg",
    "created_at": "2026-01-25T12:22:33.393Z",
    "topic": "finance"
  },
  {
    "slug": "vnsh-an-ephemeral-hostblind-file-sharing-tool-for-ai-context",
    "title": "Vnsh – An ephemeral, host-blind file sharing tool for AI context",
    "description": "End-to-end encrypted. Server is blind. 24h retention. The ultimate dead drop for vibecoding.",
    "fullText": "Zero-Access Architecture: vnsh implements true client-side encryption using AES-256-CBC with OpenSSL compatibility. Your data is encrypted entirely on your device before upload.\n\nHost-Blind Storage: The server stores only opaque binary blobs. Decryption keys travel exclusively in the URL fragment (#k=...) which is never sent to servers per HTTP specification.\n\nSecure Dead Drop: Unlike pastebins, vnsh cannot read your content even if subpoenaed. The server operator has no access to plaintext - mathematically impossible without the URL fragment.\n\nAuto-Vaporization: All data auto-destructs after 24 hours (configurable 1-168h). No history, no backups, no leaks. Perfect for ephemeral AI context sharing.",
    "readingTime": 1,
    "keywords": [
      "url fragment",
      "vnsh",
      "server"
    ],
    "qualityScore": 0.65,
    "link": "https://vnsh.dev",
    "thumbnail_url": "https://vnsh.dev/og-image.png",
    "created_at": "2026-01-25T06:18:56.307Z",
    "topic": "tech"
  },
  {
    "slug": "podcost-find-wasted-gpu-and-kubernetes-spend-with-live-demo",
    "title": "PodCost – Find wasted GPU and Kubernetes spend (with live demo)",
    "description": "PodCost shows engineering teams exactly where Kubernetes and AI infrastructure money is being wasted—and what to fix to save it, especially on GPUs.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://podcost.io/",
    "thumbnail_url": "https://podcost.io/opengraph.jpg?v=2",
    "created_at": "2026-01-25T06:18:55.749Z",
    "topic": "tech"
  },
  {
    "slug": "structured-data-extraction-using-local-quantized-llms",
    "title": "Structured data extraction using local quantized LLMs",
    "description": "⚡️ The All-in-One Local AI Data Cleaning Library. No GPU or API keys required. - nxank4/loclean",
    "fullText": "nxank4\n\n /\n\n loclean\n\n Public\n\n ⚡️ The All-in-One Local AI Data Cleaning Library. No GPU or API keys required.\n\n nxank4.github.io/loclean/\n\n License\n\n Apache-2.0 license\n\n 4\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n nxank4/loclean",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/nxank4/loclean",
    "thumbnail_url": "https://opengraph.githubassets.com/7861f3d603614d487c20b4e4be01851084ea6786e59d2536b71425c1ceaed6d7/nxank4/loclean",
    "created_at": "2026-01-25T06:18:55.176Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-dynamic-memory-compression",
    "title": "Nvidia: Dynamic Memory Compression",
    "description": "Despite the success of large language models (LLMs) as general-purpose AI tools, their high demand for computational resources make their deployment challenging in many real-world scenarios.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://developer.nvidia.com/blog/dynamic-memory-compression/",
    "thumbnail_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2025/01/inference-amazon-tensorrt-llm-featured.jpg",
    "created_at": "2026-01-25T01:04:24.550Z",
    "topic": "tech"
  },
  {
    "slug": "curl-gets-rid-of-its-bug-bounty-program-over-ai-slop-overrun",
    "title": "Curl Gets Rid of Its Bug Bounty Program over AI Slop Overrun",
    "description": "Daniel Stenberg says the inflow of AI slop has become unsustainable for the curl security team to handle.",
    "fullText": "Last year in May, the cURL project's bug bounty program was inundated with AI slop, where many bogus reports were opened on HackerOne, leaving the cURL maintainers to go through garbage.\n\nThe problem didn't stop even after Daniel Stenberg, the creator of cURL, threatened to ban anyone whose bug report was found to be AI slop. We are now in 2026, and the situation has reached a tipping point.\n\nDaniel has submitted a pull request on GitHub that removes all mentions of the bug bounty program from cURL's documentation and website. Coinciding with that, the project's security.txt file has been updated with some blunt language that makes the new policy crystal clear.\n\nThe cURL team intends to make a proper announcement in the coming days, though many outlets have already covered the news of this happening, so I would say they ought to get on it ASAP! 😆\n\nThe program officially ends in a few days on January 31, 2026. After that, security researchers can still report issues through GitHub or the project's mailing list, but there won't be any cash involved.\n\nWhat pushed them over the edge?, you ask. Well, just weeks into 2026, seven HackerOne reports came in within a 16-hour period in just one week. Some were actual bugs, but none of them were security vulnerabilities. By the time Daniel posted his recent weekly report, they'd already dealt with 20 submissions in 2026.\n\nThe main goal here is said to be stopping the flood of garbage reports. By eliminating the money incentive, they are hoping people (or bots?) will stop wasting the security team's time with half-baked, unresearched submissions.\n\nHe also gives a stern warning to wannabe AI sloppers, saying that:\n\nSo, yeah, that's that. If people still don't understand that AI slop is harmful to such sensitive pieces of software, then sure, they can go ahead and make a fool of themselves.\n\nSuggested Read 📖: Open Source Project LLVM Says Yes to AI-Generated Code",
    "readingTime": 2,
    "keywords": [
      "bug bounty",
      "bounty program",
      "curl",
      "project's",
      "slop",
      "reports",
      "security",
      "hackerone",
      "garbage",
      "stop"
    ],
    "qualityScore": 0.85,
    "link": "https://itsfoss.com/news/curl-closes-bug-bounty-program/",
    "thumbnail_url": "https://itsfoss.com/content/images/2026/01/curl-bug-bounty-program-discontinued.png",
    "created_at": "2026-01-25T01:04:22.689Z",
    "topic": "tech"
  },
  {
    "slug": "d4rt-teaching-ai-to-see-the-world-in-four-dimensions",
    "title": "D4RT: Teaching AI to see the world in four dimensions",
    "description": "Meet D4RT, a unified AI model for 4D scene reconstruction and tracking.",
    "fullText": "January 22, 2026\n\n Research\n\n D4RT: Teaching AI to see the world in four dimensions\n\n Guillaume Le Moing and Mehdi S. M. Sajjadi",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/",
    "thumbnail_url": "https://lh3.googleusercontent.com/ozG6v7VcBOV2eYZ8TnGTAe1Z-7EjkNiBPHxdQEG1wy_F5QwRN_4IJ_jJYMNQiOMHEWyNMZg3tmC00bzGQX0IYfXHMVuoQS6OLptEV-H6CUpIOnWOaQ=w1200-h630-n-nu",
    "created_at": "2026-01-24T18:17:12.186Z",
    "topic": "tech"
  },
  {
    "slug": "rdytofly-replace-notes-shared-docs-and-x-other-apps-90-free",
    "title": "Rdytofly – Replace notes, shared docs, and X other apps (90% free)",
    "description": "Build stunning day-by-day itineraries in minutes. AI-powered trip planning, flight tracking, budget management & beautiful PDF exports. Join 120+ travelers.",
    "fullText": "Zorganizujte si výlet, sdílejte s přáteli a udělejte z každé cesty nezapomenutelný zážitek\n\nPoužívá více než 120 cestovatelů\n\nNaplánujte každý den s podrobnými aktivitami a místy\n\nMějte všechny podrobnosti o letech na jednom místě\n\nSdílejte své plány se spolucestujícími\n\nStáhněte si výlet jako krásné PDF\n\nVizualizujte své aktivity na mapě\n\nNikdy nezapomeňte na nic důležitého před výletem\n\nUchovávejte poznámky, fotky a vzpomínky z každé cesty. Budujte si osobní cestovní příběh a vzpomínejte na každé dobrodružství\n\nNeomezené výlety, AI plánování a exkluzivní funkce",
    "readingTime": 1,
    "keywords": [
      "každ cesty",
      "výlet",
      "sdílejte"
    ],
    "qualityScore": 0.35,
    "link": "https://rdytofly.com/en",
    "thumbnail_url": "https://rdytofly.com/logo-full.png",
    "created_at": "2026-01-24T18:17:10.672Z",
    "topic": "tech"
  },
  {
    "slug": "latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
    "title": "Latest ChatGPT model uses Elon Musk’s Grokipedia as source, tests reveal",
    "description": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniers\nThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.\nIn tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial.\n Continue reading...",
    "fullText": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniers\n\nThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.\n\nIn tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial.\n\nGrokipedia, launched in October, is an AI-generated online encyclopedia that aims to compete with Wikipedia, and which has been criticised for propagating rightwing narratives on topics including gay marriage and the 6 January insurrection in the US. Unlike Wikipedia, it does not allow direct human editing, instead an AI model writes content and responds to requests for changes.\n\nChatGPT did not cite Grokipedia when prompted directly to repeat misinformation about the insurrection, about media bias against Donald Trump, or about the HIV/Aids epidemic – areas where Grokipedia has been widely reported to promote falsehoods. Instead, Grokipedia’s information filtered into the model’s responses when it was prompted about more obscure topics.\n\nFor instance, ChatGPT, citing Grokipedia, repeated stronger claims about the Iranian government’s links to MTN-Irancell than are found on Wikipedia – such as asserting that the company has links to the office of Iran’s supreme leader.\n\nChatGPT also cited Grokipedia when repeating information that the Guardian has debunked, namely details about Sir Richard Evans’ work as an expert witness in David Irving’s trial.\n\nGPT-5.2 is not the only large language model (LLM) that appears to be citing Grokipedia; anecdotally, Anthropic’s Claude has also referenced Musk’s encyclopedia on topics from petroleum production to Scottish ales.\n\nAn OpenAI spokesperson said the model’s web search “aims to draw from a broad range of publicly available sources and viewpoints”.\n\n“We apply safety filters to reduce the risk of surfacing links associated with high-severity harms, and ChatGPT clearly shows which sources informed a response through citations,” they said, adding that they had ongoing programs to filter out low-credibility information and influence campaigns.\n\nAnthropic did not respond to a request for comment.\n\nBut the fact that Grokipedia’s information is filtering – at times very subtly – into LLM responses is a concern for disinformation researchers. Last spring, security experts raised concerns that malign actors, including Russian propaganda networks, were churning out massive volumes of disinformation in an effort to seed AI models with lies, a process called “LLM grooming”.\n\nIn June, concerns were raised in the US Congress that Google’s Gemini repeated the Chinese government’s position on human rights abuses in Xinjiang and China’s Covid-19 policies.\n\nNina Jankowicz, a disinformation researcher who has worked on LLM grooming, said ChatGPT’s citing Grokipedia raised similar concerns. While Musk may not have intended to influence LLMs, Grokipedia entries she and colleagues had reviewed were “relying on sources that are untrustworthy at best, poorly sourced and deliberate disinformation at worst”, she said.\n\nAnd the fact that LLMs cite sources such as Grokipedia or the Pravda network may, in turn, improve these sources’ credibility in the eyes of readers. “They might say, ‘oh, ChatGPT is citing it, these models are citing it, it must be a decent source, surely they’ve vetted it’ – and they might go there and look for news about Ukraine,” said Jankowicz.\n\nBad information, once it has filtered into an AI chatbot, can be challenging to remove. Jankowicz recently found that a large news outlet had included a made-up quote from her in a story about disinformation. She wrote to the news outlet asking for the quote to be removed, and posted about the incident on social media.\n\nThe news outlet removed the quote. However, AI models for some time continued to cite it as hers. “Most people won’t do the work necessary to figure out where the truth actually lies,” she said.\n\nWhen asked for comment, a spokesperson for xAI, the owner of Grokipedia, said: “Legacy media lies.”",
    "readingTime": 4,
    "keywords": [
      "sir richard",
      "richard evans",
      "holocaust deniers",
      "llm grooming",
      "cited grokipedia",
      "expert witness",
      "citing grokipedia",
      "chatgpt",
      "disinformation",
      "topics"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/24/latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
    "thumbnail_url": "https://i.guim.co.uk/img/media/202d8061a28d8c1b855097fb90558014cb00d220/135_0_4675_3740/master/4675.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=fc74f3ad623847f91b340f08501077e0",
    "created_at": "2026-01-24T18:17:06.605Z",
    "topic": "tech"
  },
  {
    "slug": "google-ai-overviews-cite-youtube-more-than-any-medical-site-for-health-queries-study-suggests",
    "title": "Google AI Overviews cite YouTube more than any medical site for health queries, study suggests",
    "description": "Exclusive: German research into responses to health queries raises fresh questions about summaries seen by 2bn people a month\n• How the ‘confident authority’ of AI Overviews is putting public health at risk\nGoogle’s search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that raises fresh questions about a tool seen by 2 billion people each month.\nThe company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are “reliable” and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.\n Continue reading...",
    "fullText": "Exclusive: German research into responses to health queries raises fresh questions about summaries seen by 2bn people a month\n\nHow the ‘confident authority’ of AI Overviews is putting public health at risk\n\nGoogle’s search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that raises fresh questions about a tool seen by 2 billion people each month.\n\nThe company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are “reliable” and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.\n\nHowever, a study that analysed responses to more than 50,000 health queries, captured using Google searches from Berlin, found the top cited source was YouTube. The video-sharing platform is the world’s second most visited website, after Google itself, and is owned by Google.\n\nResearchers at SE Ranking, a search engine optimisation platform, found YouTube made up 4.43% of all AI Overview citations. No hospital network, government health portal, medical association or academic institution came close to that number, they said.\n\n“This matters because YouTube is not a medical publisher,” the researchers wrote. “It is a general-purpose video platform. Anyone can upload content there (eg board-certified physicians, hospital channels, but also wellness influencers, life coaches, and creators with no medical training at all).”\n\nGoogle told the Guardian that AI Overviews was designed to surface high-quality content from reputable sources, regardless of format, and a variety of credible health authorities and licensed medical professionals created content on YouTube. The study’s findings could not be extrapolated to other regions as it was conducted using German-language queries in Germany, it said.\n\nThe research comes after a Guardian investigation found people were being put at risk of harm by false and misleading health information in Google AI Overviews responses.\n\nIn one case that experts said was “dangerous” and “alarming”, Google provided bogus information about crucial liver function tests that could have left people with serious liver disease wrongly thinking they were healthy. The company later removed AI Overviews for some but not all medical searches.\n\nThe SE Ranking study analysed 50,807 healthcare-related prompts and keywords to see which sources AI Overviews relied on when generating answers.\n\nThey chose Germany because its healthcare system is strictly regulated by a mix of German and EU directives, standards and safety regulations. “If AI systems rely heavily on non-medical or non-authoritative sources even in such an environment, it suggests the issue may extend beyond any single country,” they wrote.\n\nAI Overviews surfaced on more than 82% of health searches, the researchers said. When they looked at which sources AI Overviews relied on most often for health-related answers, one result stood out immediately, they said. The single most cited domain was YouTube with 20,621 citations out of a total of 465,823.\n\nThe next most cited source was NDR.de, with 14,158 citations (3.04%). The German public broadcaster produces health-related content alongside news, documentaries and entertainment. In third place was a medical reference site, Msdmanuals.com with 9,711 citations (2.08%).\n\nThe fourth most cited source was Germany’s largest consumer health portal, Netdoktor.de, with 7,519 citations (1.61%). The fifth most cited source was a career platform for doctors, Praktischarzt.de, with 7,145 citations (1.53%).\n\nThe researchers acknowledged limitations to their study. It was conducted as a one-time snapshot in December 2025, using German-language queries that reflected how users in Germany typically search for health information.\n\nResults could vary over time, by region, and by the phrasing of questions. However, even with those caveats, the findings still prompted alarm.\n\nHannah van Kolfschooten, a researcher specialising in AI, health and law at the University of Basel who was not involved with the research, said: “This study provides empirical evidence that the risks posed by AI Overviews for health are structural, not anecdotal. It becomes difficult for Google to argue that misleading or harmful health outputs are rare cases.\n\n“Instead, the findings show that these risks are embedded in the way AI Overviews are designed. In particular, the heavy reliance on YouTube rather than on public health authorities or medical institutions suggests that visibility and popularity, rather than medical reliability, is the central driver for health knowledge.”\n\nA Google spokesperson said: “The implication that AI Overviews provide unreliable information is refuted by the report’s own data, which shows that the most cited domains in AI Overviews are reputable websites. And from what we’ve seen in the published findings, AI Overviews cite expert YouTube content from hospitals and clinics.”\n\nGoogle said the study showed that of the 25 most cited YouTube videos, 96% were from medical channels. However, the researchers cautioned that these videos represented fewer than 1% of all the YouTube links cited by AI Overviews on health.\n\n“Most of them (24 out of 25) come from medical-related channels like hospitals, clinics and health organisations,” the researchers wrote. “On top of that, 21 of the 25 videos clearly note that the content was created by a licensed or trusted source.\n\n“So at first glance it looks pretty reassuring. But it’s important to remember that these 25 videos are just a tiny slice (less than 1% of all YouTube links AI Overviews actually cite). With the rest of the videos, the situation could be very different.”",
    "readingTime": 5,
    "keywords": [
      "ai overviews",
      "german-language queries",
      "youtube links",
      "overviews relied",
      "health portal",
      "health authorities",
      "youtube the",
      "medical",
      "cited",
      "citations"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0fd9215aeefc347883d2e12f7e2ac337bc58c231/0_147_4000_3198/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0037ea636e0877a7aa0c8778c26c2d7b",
    "created_at": "2026-01-24T18:17:06.602Z",
    "topic": "tech"
  },
  {
    "slug": "how-the-confident-authority-of-google-ai-overviews-is-putting-public-health-at-risk",
    "title": "How the ‘confident authority’ of Google AI Overviews is putting public health at risk",
    "description": "Experts say tool can give ‘completely wrong’ medical advice which could put users at risk of serious harm\n• AI Overviews cite YouTube more than any medical site, study suggests\nDo I have the flu or Covid? Why do I wake up feeling tired? What is causing the pain in my chest? For more than two decades, typing medical questions into the world’s most popular search engine has served up a list of links to websites with the answers. Google those health queries today and the response will likely be written by artificial intelligence.",
    "fullText": "Do I have the flu or Covid? Why do I wake up feeling tired? What is causing the pain in my chest? For more than two decades, typing medical questions into the world’s most popular search engine has served up a list of links to websites with the answers. Google those health queries today and the response will likely be written by artificial intelligence.\n\nSundar Pichai, Google’s chief executive, first set out the company’s plans to enmesh AI into its search engine at its annual conference in Mountain View, California, in May 2024. Starting that month, he said, US users would see a new feature, AI Overviews, which would provide information summaries above traditional search results. The change marked the biggest shake-up of Google’s core product in a quarter of a century. By July 2025, the technology had expanded to more than 200 countries in 40 languages, with 2 billion people served AI Overviews each month.\n\nWith the rapid rollout of AI Overviews, Google is racing to protect its traditional search business, which generates about $200bn (£147bn) a year, before upstart AI rivals can derail it. “We are leading at the frontier of AI and shipping at an incredible pace,” Pichai said last July. AI Overviews in particular were “performing well”, he added.\n\nBut overviews carry risks, experts say. They use generative AI to provide snapshots of information about a topic or question, adding conversational answers above the traditional search results in the blink of an eye. They can cite sources, but do not necessarily know when that source is incorrect.\n\nWithin weeks of the feature launching in the US, users encountered untruths across a range of subjects. One AI Overview said Andrew Jackson, the seventh US president, graduated from college in 2005. Elizabeth Reid, Google’s head of search, responded to criticism in a blog post. She conceded that “in a small number of cases”, AI Overviews had misinterpreted language on web pages and presented inaccurate information. “At the scale of the web, with billions of queries coming in every day, there are bound to be some oddities and errors,” she wrote.\n\nBut when those questions are about health, accuracy and context are essential and non-negotiable, experts say. Google is facing mounting scrutiny of its AI Overviews for medical queries after a Guardian investigation found people were being put at risk of harm by false and misleading health information.\n\nThe company says AI Overviews are “reliable”. But the Guardian found some medical summaries served up inaccurate health information and put people at risk of harm. In one case, which experts said was “really dangerous”, Google wrongly advised people with pancreatic cancer to avoid high-fat foods. Experts said this was the exact opposite of what should be recommended, and may increase the risk of patients dying from the disease.\n\nIn another “alarming” example, the company provided bogus information about crucial liver function tests, which could leave people who had serious liver disease wrongly thinking they were healthy. What AI Overviews said was normal could vary drastically from what was actually considered normal, experts said. The summaries could lead to seriously ill patients wrongly thinking they had a normal test result and not bothering to attend follow-up appointments.\n\nAI Overviews about women’s cancer tests also provided “completely wrong” information, which experts said could result in people dismissing genuine symptoms.\n\nGoogle initially sought to downplay the Guardian’s findings. From what its own clinicians could assess, the company said, the AI Overviews that alarmed experts linked to reputable sources and recommended seeking expert advice. “We invest significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information,” a spokesperson said.\n\nWithin days, however, the company removed some of the AI Overviews for health queries flagged by the Guardian. “We do not comment on individual removals within search,” a spokesperson said. “In cases where AI Overviews miss some context, we work to make broad improvements, and we also take action under our policies where appropriate.”\n\nWhile experts welcomed the removal of some AI summaries for health queries, many remain worried. “Our bigger concern with all this is that it is nit-picking a single search result and Google can just shut off the AI Overviews for that but it’s not tackling the bigger issue of AI Overviews for health,” says Vanessa Hebditch, the director of communications and policy at the British Liver Trust, a liver health charity.\n\n“There are still too many examples out there of Google AI Overviews giving people inaccurate health information,” adds Sue Farrington, the chair of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals.\n\nA new study has prompted more concerns. When researchers analysed the responses to more than 50,000 health-related searches in Germany to see which sources AI Overviews rely on most, one result stood out immediately. The single most cited domain was YouTube.\n\n“This matters because YouTube is not a medical publisher,” the researchers wrote. “It is a general-purpose video platform. Anyone can upload content there (eg, board-certified physicians, hospital channels, but also wellness influencers, life coaches and creators with no medical training at all).”\n\nIn medicine, it is not only where answers come from that matter, or their level of accuracy, but how they are presented to users, experts say. “With AI Overviews, users no longer encounter a range of sources that they can compare and critically assess,” says Hannah van Kolfschooten, a researcher in AI, health and law at the University of Basel. “Instead, they are presented with a single, confident, AI-generated answer that exhibits medical authority.\n\n“This means that the system does not merely reflect health information online, but actively restructures it. When that response is built on sources never designed to meet medical standards, such as YouTube videos, this creates a new form of unregulated medical authority online.”\n\nGoogle says AI Overviews are built to surface information backed up by top web results, and include links to web content that supports the information presented in the summary. People can use these links to dig deeper on a topic, the company told the Guardian.\n\nBut the single blocks of text in AI Overviews, combining health information from multiple sources, can cause confusion, says Nicole Gross, an associate professor in business and society at the National College of Ireland.\n\n“Once the AI summary appears, users are much less likely to research further, which means that they are deprived of the opportunity to critically evaluate and compare information, or even deploy their common sense when it comes to health-related issues.”\n\nExperts have raised other concerns with the Guardian. Even if and when AI Overviews do provide accurate facts about a specific medical topic, they may not distinguish between strong evidence from randomised trials and weaker evidence from observational studies, they say. Some also miss important caveats about that evidence, they add.\n\nHaving such claims listed next to one another in an AI Overview may also give the impression that some are better established than they really are. Answers can also change as AI Overviews evolve, even when the science hasn’t shifted. “That means that people are getting a different answer depending on when they search, and that’s not good enough,” says Athena Lamnisos, the chief executive of the Eve Appeal cancer charity.\n\nGoogle told the Guardian that links included in AI Overviews were dynamic and changed based on the information that was most relevant, helpful and timely for a given search. If AI Overviews misinterpreted web content or missed some context, the company would use these errors to improve its systems, and also take action when appropriate, it said.\n\nThe biggest worry is that bogus and dangerous medical information or advice in AI Overviews “ends up getting translated into the everyday practices, routines and life of a patient, even in adapted forms”, says Gross. “In healthcare, this can turn into a matter of life and death.”",
    "readingTime": 7,
    "keywords": [
      "ai overviews",
      "chief executive",
      "web content",
      "search engine",
      "traditional search",
      "medical authority",
      "experts say",
      "inaccurate health",
      "health queries",
      "users"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/ng-interactive/2026/jan/24/how-the-confident-authority-of-google-ai-overviews-is-putting-public-health-at-risk",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0fd9215aeefc347883d2e12f7e2ac337bc58c231/0_147_4000_3198/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0037ea636e0877a7aa0c8778c26c2d7b",
    "created_at": "2026-01-24T18:17:06.591Z",
    "topic": "tech"
  },
  {
    "slug": "i-was-laid-off-from-crowdstrike-and-used-ai-to-send-800-applications-in-a-month-to-land-my-ideal-role",
    "title": "I was laid off from CrowdStrike and used AI to send 800 applications in a month to land my ideal role",
    "description": "With the help of an AI platform, one man submitted more than 800 job applications in a month, resulting in 5 interviews and 1 ideal offer.",
    "fullText": "This as-told-to essay is based on a conversation with Dray Jankowski, former employee at CrowdStrike and current senior director of product operations and program management at Wunderkind. Business Insider verified his identity. This essay has been edited for length and clarity.\n\nI still remember the morning I found out I was getting laid off from CrowdStrike.\n\nI went to bed thinking everything was fine, and when I woke up, there was a mysterious meeting on my calendar for later that afternoon.\n\nThat's when I saw the email that said the company was doing a reduction in force as it adjusted to changes driven by AI. It wasn't about financial trouble. It was sudden, impersonal, and final. At 30, it was my first layoff.\n\nI was shaken. I worked hard to get where I was. At CrowdStrike, I was a program manager working closely with the team that makes motion sensors. I also worked at Amazon and Raytheon and consulted with companies such as Microsoft and Johnson & Johnson. I had what people would consider a \"great résumé.\"\n\nLittle did I know how brutal the job market would become and how hard it would be to find the right fit.\n\nIn the first three months after my layoff, I applied to 52 jobs on my own, and I hated every second of it.\n\nAt first, I wasn't even looking. I had savings, and it was summer. I traveled to Yellowstone, spent time with my mom and my two dogs, and casually applied to roles I actually liked.\n\nInstead of being quiet about my layoff, I also decided to be vocal. I started making YouTube videos and launched a podcast called \"The Reboot Era,\" where I talked openly about layoffs and invited others to share their experiences.\n\nEven with my background, the job-search process was frustrating. I'd turn to ChatGPT with basic questions like, \"Should I update my résumé for this role?\" and I started noticing how many people were stuck for months because they didn't know how to optimize it for applicant tracking systems. When I looked for help online, most of it was locked behind paywalls.\n\nLinkedIn \"Easy Apply\" felt like a black hole. Company websites made me create a new Workday account every time. The process was tedious, slow, and draining. So when an AI-powered application platform reached out to me after seeing my posts about layoffs, I invited them onto my podcast with a catch: I wouldn't promote anything unless I tested it myself and believed it worked.\n\nAt first, the results didn't seem promising. The very first call I got was from a car wash near my house.\n\nA week later, something changed. I started getting legitimate interview requests for corporate roles that matched my experience and salary range. One message on LinkedIn asked if I wanted to interview with a company I'd never even heard of. That's when I knew the AI had applied for me.\n\nOver the course of about a month, the platform sent out 812 applications on my behalf. It also shows you which keywords to hit in your cover letters, and you can set your own parameters.\n\nWith AI handling the repetitive work, I could focus on preparing for interviews, refining my résumé, networking, and continuing my podcast.\n\nIn total, I received five serious interview requests that were aligned with what I wanted. I moved forward with two. One didn't pan out, but the other moved fast. Within two weeks, I had an offer.\n\nThat's how I landed my current role as senior director of product operations and program management at Wunderkind, a marketing technology company that helps brands re-engage customers who leave their websites without making a purchase.\n\nAI didn't get me the job. It got me the interview. From there, it was on me to show up, connect, and prove I was the right person.\n\nI think the job market is going in the wrong direction.\n\nFirst, companies decide they can automate many standard workflows and lay off workers. Those employees are then pushed back into the open job market, forced to apply for new roles. Now, they face AI screening systems that evaluate them against opaque criteria they can't see or understand.\n\nIf the applicant is using AI as well, they get rejected by the screener AI if they sound too robotic. Then, even when you do get the interview, many offers ask you to meet with a digital recruiter who's not a real person and will ask automated questions.\n\nNone of that seems fair, and it often feels like AI is working against job seekers in this brutal market. It took me more than 800 applications to get one great offer, so it is reasonable if you need help. When used correctly, AI can be the tool that gives you your time and momentum back.",
    "readingTime": 5,
    "keywords": [
      "senior director",
      "product operations",
      "program management",
      "interview requests",
      "job market",
      "didn't",
      "that's",
      "layoff",
      "résum",
      "applied"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/laid-off-from-crowdstrike-used-ai-to-land-ideal-role-2026-1",
    "thumbnail_url": "https://i.insider.com/6973cf24e1ba468a96aa9e99?width=960&format=jpeg",
    "created_at": "2026-01-24T12:21:34.212Z",
    "topic": "finance"
  },
  {
    "slug": "giving-claude-code-hands-to-deliver-local-files-p2p-no-cloud",
    "title": "Giving Claude Code \"hands\" to deliver local files (P2P, No Cloud)",
    "description": "MCP server for ffl. Let AI share anything for you. - nuwainfo/ffl-mcp",
    "fullText": "nuwainfo\n\n /\n\n ffl-mcp\n\n Public\n\n MCP server for ffl. Let AI share anything for you.\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n nuwainfo/ffl-mcp",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/nuwainfo/ffl-mcp",
    "thumbnail_url": "https://opengraph.githubassets.com/1b7e75a1d326923c46db92a0e00faff77d73fbac92e2a41867b3c0e4be1f02de/nuwainfo/ffl-mcp",
    "created_at": "2026-01-24T12:21:31.031Z",
    "topic": "tech"
  },
  {
    "slug": "reverse-engineering-river-raid-with-claude-ghidra-and-mcp",
    "title": "Reverse Engineering River Raid with Claude, Ghidra, and MCP",
    "description": "Connecting Claude to Ghidra via MCP to reverse engineer River Raid. A test of AI agents against 6502 assembly, memory mapping, and 80s game logic.",
    "fullText": "Can an AI agent navigate Ghidra, the NSA’s open-source reverse engineering suite, well enough to hack an Atari game? Ghidra is powerful but notoriously complex, with a steep learning curve. Instead of spending weeks learning its interface, what if I could simply describe my goal and let an AI handle the complexity?\n\nRiver Raid, the Atari 8-bit version. My first computer was an Atari back in the 80s, and this particular game occupied a disproportionate amount of my childhood attention.\n\nThe ROM is exactly 8kB — almost comical by modern standards. And yet this tiny binary contains everything: graphics, sound, enemy AI, and physics simulation — all compressed into hand-optimized 6502 assembly.\n\nThe objective was straightforward: unlimited lives. It’s the quintessential hack, a rite of passage that kids with hex editors performed for entertainment back in the 80s. In 2025, instead of a hex editor, I have an AI.\n\nGhidra doesn’t have a native AI assistant, so I needed a way to bridge the gap between my instructions and the tool’s internal API. This is where the Model Context Protocol (MCP) comes in.\n\nI found an open-source MCP server for Ghidra — essentially a connector that allows Claude to talk directly to Ghidra. The concept is elegant: Claude connects to the running Ghidra instance, analyzes the binary, renames functions, and identifies code patterns programmatically.\n\nIn practice, the experience was considerably less elegant:\n\nHere’s the thing: I don’t use disassemblers daily. Ghidra’s workflow was completely foreign to me. The whole point was to see if AI could bridge that gap — I’d feed it a mysterious binary, and the Ghidra + LLM combination would figure out it’s a cartridge dump, handle the memory mapping, and guide me through.\n\nReality was harsher. To test the AI properly, I renamed the binary to a.rom — no helpful filename hints. When importing, I selected only the CPU architecture (6502) without specifying the platform. Claude’s first instinct was reasonable: it asked for the MD5 hash to search for known ROM signatures. The MCP tools don’t expose hashing, so that avenue closed immediately.\n\nFirst problem: Ghidra loaded the ROM at $0000, not $A000 where Atari cartridges live. All cross-references pointed nowhere.\n\nClaude identified the issue with admirable clarity: “The ROM should be loaded at $A000, not $0000. You’ll need to rebase the memory image.”\n\nMe: “Can you perform the rebase?”\n\nClaude: “Unfortunately, no. The MCP tools don’t have write access for that particular operation.”\n\nI rebased manually to $8000 — still wrong. The code referenced $A000-$BFFF. Rebased again.\n\nTwo rebasing operations in total, neither of which the AI could perform.\n\nWhere Claude genuinely excelled was in identifying the target platform through hardware register analysis:\n\nHardware addresses are essentially fingerprints that can’t be faked, and these particular addresses are unmistakably Atari 8-bit.\n\nI asked Claude to attempt identification of the game based purely on code patterns and structural analysis. It examined the evidence methodically. Based on this evidence, Claude reached its conclusion:\n\nIt was, of course, not Centipede. It was River Raid.\n\nThis serves as a useful reminder that confidence and accuracy are orthogonal properties.\n\nDespite the identity crisis, Claude still understood the code structure. Finding the lives decrement was straightforward. Claude searched for the canonical pattern: load, decrement, store.\n\nThe fix is elegantly simple: replace DEY (decrement Y register) with NOP (no operation). A single byte modification, where $88 becomes $EA.\n\nSince the MCP tool couldn’t write the binary directly, I applied the patch externally:\n\nI tested the patched ROM in an emulator by deliberately crashing into a bridge. The lives counter remained stubbornly fixed at 3.\n\nClaude excelled at pattern recognition — hardware registers, code flow, finding the patch location. It struggled with tasks requiring broader context, such as identifying the game or analyzing sprite data.\n\nSetting up MCP is a troubleshooting ritual. It eventually worked, but the experience was painfully slow. Claude would fire off a batch of tool calls, some taking 30 seconds each. Too slow for an interactive session — I’d rather have quick responses with clarifying questions than watch a progress bar crawl. We need a better balance between autonomous batch processing and interactive guidance.\n\nAI should be embedded in every complex GUI tool. We’re in the experimental phase now. Some things work, some don’t. Ideally AI should smooth out the experience in ways traditional help systems never could — compacted Stack Overflow knowledge, real context-aware assistance, and the ability to actually perform tasks rather than just describe them.\n\nStay tuned for future posts and releases",
    "readingTime": 4,
    "keywords": [
      "river raid",
      "atari bit",
      "mcp tools",
      "tools don’t",
      "code patterns",
      "the rom",
      "binary",
      "game",
      "claude",
      "bridge"
    ],
    "qualityScore": 1,
    "link": "https://quesma.com/blog/ghidra-mcp-unlimited-lives/",
    "thumbnail_url": "https://quesma.com/_astro/thumbnail.DG1tfTJt.png",
    "created_at": "2026-01-24T12:21:30.696Z",
    "topic": "tech"
  },
  {
    "slug": "noora-health-yc-w14-is-hiring-aiml-engineer",
    "title": "Noora Health (YC W14) Is Hiring AI/ML Engineer",
    "description": "WHO WE ARE\nNoora Health India Private Limited is a key partner in Noora Health’s (http://www.noorahealth.org/) mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health’s programs.\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient’s care: their own family.",
    "fullText": "Training patients and their families with health skills\n\nNoora Health India Private Limited is a key partner in Noora Health’s mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health’s programs.\n\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient’s care: their own family.\n\nWith support from governments and partners in India, Bangladesh, Indonesia, and Nepal, Noora Health has trained more than 43 million caregivers and patients across 12,800+ facilities using their flagship caregiver education and training curriculum, the Care Companion Program (CCP).\n\nIn a cohort of patients, the CCP reduced post-surgical cardiac complications by 71%, maternal complications by 12%, newborn complications by 16%, and newborn mortality by 18%.\n\nNoora Health is an Audacious Project Grantee and received the Skoll Foundation Award for Social Innovation. To learn more, watch our TED Talk, Skoll feature, or read about our partnership with the World Health Organization.\n\nWe value diversity, equity, and inclusion, and we understand the value of developing a team with different perspectives, educational backgrounds, and life experiences. We prioritize diversity within our team, and we welcome candidates from all gender identities, castes, religious practices, sexual orientations, and abilities — among many others.\n\nWe encourage people from all backgrounds to apply.\n\nPlease submit your application using this link.\n\nNoora Health trains patient families with high-impact health skills that improve outcomes and save lives. Our model provides basic yet vital care knowledge through trusted providers by creating a scalable program for caregiving education and training within\nthe established healthcare system. This model expands the care umbrella\nto include those closest to the patient — their family and community. Noora Health has trained over 30 million caregivers and patients across over 12,400 healthcare facilities in India, Bangladesh, Indonesia, and Nepal. The program reduces cardiac surgery complications by 71%, newborn readmissions by 56%, and neonatal mortality by 18%. By 2028, Noora Health will expand to reach over 70 million caregivers and\npatients.",
    "readingTime": 2,
    "keywords": [
      "bangladesh indonesia",
      "india bangladesh",
      "improve outcomes",
      "health skills",
      "patients across",
      "noora health",
      "noora health’s",
      "care",
      "caregivers",
      "complications"
    ],
    "qualityScore": 0.9,
    "link": "https://www.ycombinator.com/companies/noora-health/jobs/2B4RxLG-ai-ml-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/3292fb1cfe578ca77d78b69b29c49b279212ee59.png?1748897426",
    "created_at": "2026-01-24T06:18:16.578Z",
    "topic": "jobs"
  },
  {
    "slug": "headcanon-generator",
    "title": "Headcanon Generator",
    "description": "Generate character headcanons, random headcanons, relationship headcanons, and OC headcanons with our free AI headcanon generator. Perfect for fanfiction writers, role-players, and fandom enthusiasts.",
    "fullText": "Create unique character interpretations and personality quirks for your favorite characters.\n\nThe ultimate headcanon generator for character headcanons, random headcanons, relationship headcanons, and OC headcanons\n\nOur AI headcanon generator uses advanced technology to create unique character headcanons from simple prompts. Whether you need a character headcanon generator, random headcanon generator, relationship headcanon generator, or OC headcanon generator, our tool delivers creative interpretations with personality quirks, habits, preferences, and hidden traits.\n\nCreate detailed character headcanons for any character from books, movies, TV shows, anime, games, or original works. Our character headcanon generator explores personality traits, hidden talents, secret fears, daily routines, favorite things, and unique quirks that make characters feel more real and relatable.\n\nNeed inspiration? Our random headcanon generator creates unexpected and creative character interpretations. Generate random headcanons about hobbies, habits, preferences, phobias, talents, or personality quirks. Perfect for sparking creativity and exploring new character dimensions.\n\nExplore character dynamics with our relationship headcanon generator. Create headcanons about friendships, romantic relationships, family bonds, rivalries, or team dynamics. Generate relationship headcanons that explore how characters interact, support each other, argue, or grow together.\n\nPerfect for original characters! Our OC headcanon generator helps develop unique personality traits, quirks, and characteristics for your original characters. Whether for fanfiction, role-playing, or original stories, create OC headcanons that make your characters memorable and three-dimensional.\n\nGet creative headcanons in seconds. Our free headcanon generator delivers unique character interpretations instantly. Easy to copy, share, and use in fanfiction, role-playing, character development, or fandom discussions. No registration required for basic features.",
    "readingTime": 2,
    "keywords": [
      "habits preferences",
      "fanfiction role-playing",
      "personality traits",
      "personality quirks",
      "headcanon generator",
      "original characters",
      "create unique",
      "character interpretations",
      "random headcanons",
      "relationship headcanons"
    ],
    "qualityScore": 0.9,
    "link": "https://www.genstory.app/text-template/headcanon-generator",
    "thumbnail_url": "https://genstory.app/og-image.png?v=2",
    "created_at": "2026-01-24T06:18:14.751Z",
    "topic": "tech"
  },
  {
    "slug": "malicious-ai-extensions-on-vs-code-marketplace-steal-developer-data",
    "title": "Malicious AI extensions on VS Code Marketplace steal developer data",
    "description": "Two malicious extensions in Microsoft's Visual Studio Code (VSCode) Marketplace that were collectively installed 1.5 million times, exfiltrate developer data to China-based servers.",
    "fullText": "Two malicious extensions in Microsoft’s Visual Studio Code (VSCode) Marketplace that were collectively installed 1.5 million times exfiltrate developer data to China-based servers.\n\nBoth extensions are advertised as AI-based coding assistants that provide the promised functionality. However, they do not disclose the upload activity or ask users for consent to deliver data to a remote server.\n\nThe VS Code Marketplace is the official store for add-ons for Microsoft’s popular code editor. VS Code extensions are installable plugins from the marketplace that add features or integrate tools into the editor. One of the most popular add-on categories right now is AI-powered coding assistants.\n\nResearchers at endpoint and supply-chain security company Koi say that the two malicious extensions are part of a campaign they dubbed 'MaliciousCorgi' and share the same code for stealing developer data.\n\nAdditionally, both of them use the same spyware infrastructure and communicate with the same backend servers. At publishing time, both are present on the marketplace:\n\nThe extensions use three distinct data-collection mechanisms. The first involves real-time monitoring of files opened in the VS Code client. When a file is accessed, its entire contents are encoded in Base64 and transmitted to the attackers’ servers.\n\nAny changes to the opened file are also captured and exfiltrated.\n\n\"The moment you open any file – not interact with it, just open it – the extension reads its entire contents, encodes it as Base64, and sends it to a webview containing a hidden tracking iframe. Not 20 lines. The entire file,\"  Koi researchers say.\n\nThe second mechanism involves a server-controlled file-harvesting command that stealthily transmits up to 50 files from the victim’s workspace each time.\n\nThe third mechanism uses a zero-pixel iframe in the extension’s webview to load four commercial analytics SDKs: Zhuge.io, GrowingIO, TalkingData, and Baidu Analytics.\n\nThese SDKs are used to track user behavior, build identity profiles, fingerprint devices, and monitor activity inside the editor. So, while the first two collect developer work files, the third focuses on user profiling.\n\nKoi Security highlights the risks posed by undocumented functionality in these extensions, including the exposure of private source code, configuration files, cloud service credentials, and .env files containing API keys and credentials.\n\nBleepingComputer has contacted Microsoft about the presence of the two extensions on the VSCode market, but we are still waiting for a reply. We were unable to establish a communication channel with the publisher of the extensions.\n\nWhether you're cleaning up old keys or setting guardrails for AI-generated code, this guide helps your team build securely from the start.\n\nGet the cheat sheet and take the guesswork out of secrets management.",
    "readingTime": 3,
    "keywords": [
      "coding assistants",
      "malicious extensions",
      "vs code",
      "files",
      "file",
      "developer",
      "servers",
      "microsoft’s",
      "vscode",
      "functionality"
    ],
    "qualityScore": 1,
    "link": "https://www.bleepingcomputer.com/news/security/malicious-ai-extensions-on-vscode-marketplace-steal-developer-data/",
    "thumbnail_url": "https://www.bleepstatic.com/content/hl-images/2023/01/06/vscode-malware-header.jpg",
    "created_at": "2026-01-24T06:18:13.137Z",
    "topic": "tech"
  },
  {
    "slug": "openhands-aidriven-development",
    "title": "OpenHands: AI-Driven Development",
    "description": "🙌 OpenHands: AI-Driven Development. Contribute to OpenHands/OpenHands development by creating an account on GitHub.",
    "fullText": "OpenHands\n\n /\n\n OpenHands\n\n Public\n\n 🙌 OpenHands: AI-Driven Development\n\n openhands.dev\n\n License\n\n View license\n\n 67k\n stars\n\n 8.3k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n OpenHands/OpenHands",
    "readingTime": 1,
    "keywords": [
      "openhands",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/OpenHands/OpenHands",
    "thumbnail_url": "https://opengraph.githubassets.com/1400d2539c4a6a593d6b7ac0357cc46dcfc5f80132b2a4fd8fb4955e7ea8da00/OpenHands/OpenHands",
    "created_at": "2026-01-24T00:56:47.547Z",
    "topic": "tech"
  },
  {
    "slug": "opensource-ad-infra-for-llms-reverseengineered-from-chatgpt",
    "title": "Open-source ad infra for LLMs (reverse-engineered from ChatGPT)",
    "description": "Open-source ad serving platform for LLM applications - inspired by ChatGPT Bazaar system - system32miro/ai-ads-engine",
    "fullText": "system32miro\n\n /\n\n ai-ads-engine\n\n Public\n\n Open-source ad serving platform for LLM applications - inspired by ChatGPT Bazaar system\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n system32miro/ai-ads-engine",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/system32miro/ai-ads-engine",
    "thumbnail_url": "https://opengraph.githubassets.com/5a21764c0d8dccbdd55ea03a277ef4c0a8874e2b8572009a827851dcf1a5a9b3/system32miro/ai-ads-engine",
    "created_at": "2026-01-24T00:56:46.232Z",
    "topic": "tech"
  },
  {
    "slug": "googles-aigenerated-headlines-are-here-to-stay",
    "title": "Google's AI-Generated Headlines Are Here to Stay",
    "description": "That clickbait title might have been written by AI.",
    "fullText": "Last month, Google told online publishers that it had started testing AI-generated headlines in Google Discover, replacing stories' carefully handcrafted titles with truncated alternatives made up by Gemini. Some journalists were predictably unhappy, but now, the company says that the AI headlines are no longer an experiment—they're a \"feature.\"\n\nBack when the testing began, the results ranged from poorly worded to straight up misinformation. For instance, one AI-generated headline promised \"Steam Machine price revealed,\" when the original article made no such claim. Another said \"BG3 players exploit children,\" which sounds serious, until you click through to the article and see that it's about a clever way to recruit invincible party members in Baldur's Gate 3 (which, to be fair, does involve turning child NPCs into sheep at one point).\n\nAt the time, Google said that the test was a \"small UI experiment for a subset of Discover users,\" and simply rearranged how users saw AI previews, which were introduced in October of last year and feature short AI summaries of articles, including an occasional AI headline. However, while that AI headline was previously hidden below the original, authored headline, the test put it up top, while getting rid of the authored headline entirely.\n\nFor a while, it seemed like Google might have been willing to back away from the AI headlines, but now the company says it's doubling down. In a statement to The Verge, Google said that its AI headlines are no longer in testing, but are now a full-fledged feature. The company didn't elaborate on why, but did say that the update \"performs well for user satisfaction.\"\n\nWhen 9to5Google then reached out for more detail, the publication was told, \"The overview headline reflects information across a range of sites, and is not a rewrite of an individual article headline.\"\n\nWell, that hasn't quite been the case for me: When I first wrote about this \"experiment,\" I actually had yet to run into one of the AI headlines. But perusing my Google Discover feed today (to see yours, swipe right from the home screen on an Android phone, or scroll down in the Google app), I've finally seen some first hand. To Google's credit, these AI previews do seem to synthesize several sources as claimed—you can see them above the linked story. However, they still call out one article in particular, linking to it and using its header photo. That can easily lead users to think the AI generated headline was written by the linked publication.\n\nThat can have consequences for the publication or writer if the AI gets something wrong, which a disclaimer at the bottom of these AI previews admits can happen. For instance, The Verge said it saw an AI Discover headline on a story from Lifehacker's sister site PCMag that said, \"US reverses foreign drone ban,\" even though the linked story goes out of its way to say headlines that claim this are \"misleading.\"\n\nThe AI headlines I've seen personally haven't been quite that bad, but as someone with a more than decade-long career in journalism, I do question their helpfulness. For instance, \"Starfleet Academy full of Trek Nods\" is much less informative than the original, \"One of TNG's Strangest Species Is Getting a Second Life In Modern Star Trek.\" I guess \"Star Trek show has Star Trek things\" is apparently clickier or more useful to the reader than just saying what the specific Star Trek thing is?\n\nAnother example: \"Anbernic unveils RG G01 Controller.\" I hope you know what those letters and numbers mean, because this AI headline completely buries the context in the original headline, \"Anbernic's New Controller Has a Screen and Built-In Heartbeat Sensor, for Some Reason.\"\n\nI guess this is a future that I'll have to get used to though. That I'm starting to see these headlines myself, despite not being part of the initial experiment, does suggest we can expect them to stick around, and to roll out to more people. If you see something that seems questionable while scrolling Google Discover, the feature has probably rolled out to you now too.\n\nTo check whether that suspicious headline was written by a human or not, try clicking the \"See more\" button at the bottom of the article's description and looking for a \"Generated with AI\" disclaimer.\n\nOn the plus side, only about half of the articles in my Google Discover are currently using AI headlines, so not every piece of \"content\" is being affected. But for journalists, the move still comes at a tough time: According to Reuters, Google traffic from organic search was down by 38% on test sites in the United Stated between November 2024 and November 2025, and while Google Discover isn't Search, editors write headlines the way they do for a reason. Using a robot to overwrites those decisions probably isn't the best way to tackle eroding trust in media.\n\nI've reached out to Google for comment on its AI headlines and will provide an update when I hear back.",
    "readingTime": 5,
    "keywords": [
      "google discover",
      "authored headline",
      "star trek",
      "headlines",
      "feature",
      "original",
      "testing",
      "back",
      "instance",
      "test"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/googles-ai-generated-headlines-are-here-to-stay?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFP3Y3GZ8D82XMBVWAHPK44B/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-24T00:56:43.338Z",
    "topic": "tech"
  },
  {
    "slug": "submit-a-pitch-what-needs-to-be-built-before-advanced-ai",
    "title": "Submit a pitch: what needs to be built before advanced AI?",
    "description": "Apply to our rolling effort to find, scope, and build the most important projects to prepare the world for advanced AI",
    "fullText": "In 2025, IFP published The Launch Sequence, a set of proposals aimed at answering one question: what does America need to build, which will not be built fast enough by default, to prepare for a future with advanced AI?\n\nAs we explained in the foreword to the collection, Preparing for Launch, we need to solve two broad problems:\n\nWe invited some of the sharpest thinkers, engineers, and scientists thinking about these topics to write 16 concrete proposals to address these problems.\n\nSince then, many of the proposals have gained real-world traction:5\n\nMajor new funding is flowing into this space. The OpenAI Foundation committed $25 billion to AI resilience and curing diseases. The Chan-Zuckerberg Initiative is refocusing most of its philanthropic spending on AI projects to “cure all disease.” The White House launched the Genesis Mission, a “national effort to unleash a new age of AI‑accelerated innovation and discovery.” Philanthropies and government officials are asking us for more ideas about where this money should be directed.\n\nThis is a momentous opportunity, and how well these funds are spent will depend both on the quality of available ideas and on teams being ready to implement them.\n\nThat’s why The Launch Sequence is transitioning into a rolling effort to:\n\nThe output of The Launch Sequence will be a collection of thoroughly vetted, detailed project plans for philanthropists to fund or for policymakers to implement.7\n\nWe’re excited to announce our official Advisory Panel for the project, including:\n\nWe are seeking initial short pitches (around 200–400 words) that address one of the three focus areas of this RFP: accelerating science, strengthening security, and adapting institutions. See “Ideas we are interested in” at the bottom of this post for full descriptions of these focus areas.\n\nWe are interested in projects that are particularly important to achieve in light of rapid advances in AI. This means that the capabilities of advanced AI — or the changes such capabilities will bring — should be a key part of either the problem or the solution.8 If you are unsure if a proposal is in-scope, we encourage you to submit it anyway.\n\nA non-exhaustive list of the kinds of project ideas we’re excited about can be found at the bottom of this post. You can also see the project ideas we’ve already published on our website: ifp.org/launch.\n\nWe welcome pitches from two broad groups of contributors:\n\nWe are especially interested in pitches from people who would consider implementing their proposal themselves.10 This is not a requirement; we are also interested in hearing from strategists, researchers, and domain experts who can articulate what technologies or projects should exist, even if they are not the ones to build them. We also offer a $1,000 bounty for successful referrals — if you know someone who might be interested in being an author, please share this page with them and ask them to include your name in the application form. If their proposal is accepted, you’ll receive the bounty.\n\nWe expect authoring full Launch Sequence project plans to take 8–14 weeks from accepted pitch to published piece, involving several stages of writing, receiving feedback from IFP and input from external experts, and refining your full project plan.\n\nIFP is a 501(c)(3) nonprofit organization, and will have no claim over any IP related to your idea, nor ownership of any resulting companies. We aim to accelerate authors and builders.\n\nIf you have an idea, we want to hear it. You can learn more and submit an idea via the form below.\n\nThis is a rolling RFP with no submission deadline, but we encourage you to submit a pitch early (within the next few weeks), as we will prioritize early submissions and start reviewing immediately.\n\nQuestions? Email launch.sequence@ifp.org\n\nWe are interested in rapidly building what we need to prepare for a world with advanced AI so that we can fully reap AI’s benefits while managing its new threats. Such an agenda will include a wide-ranging set of projects, including creating companies, tools, technologies, institutions, research streams, resources, and public policies.\n\nWe will only consider projects that address a market failure (or policy gap) and will therefore not be built by default, or not quickly enough. The three core categories where we expect these issues to surface are in accelerating science, strengthening security, and adapting key institutions.\n\nThe lists below are not meant to be exhaustive. Instead, they are meant to illustrate the kinds of projects that we would be excited to support. We encourage you to submit pitches for projects whether or not they are listed below.\n\nWhat resources, technologies, or institutions will scientists need to unlock breakthroughs with AI and other emerging technologies, and which aren’t being created fast enough through market forces or traditional grant funding?\n\nAI promises to transform how science is done. But leveraging AI advances for breakthroughs requires more than capable models. It requires infrastructure, institutions, and resources that no single lab or company has an incentive to build: shared datasets, standardized protocols, access to physical experimentation capacity, and new modes of peer review and validation. Traditional grant funding moves too slowly and often rewards the wrong things; private industry optimizes for what can become profitable, not what will most advance scientific progress. Without targeted investment and effort by the US government and philanthropies, scientific bottlenecks will limit AI-accelerated discovery even as the models improve. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nHealth and biology. The highest ambition for AI may be to generate cures to inherited and infectious diseases. But even as AI companies pursue this goal, their efforts alone are unlikely to fully accomplish it: biology is immensely complex, wet lab work is messy and reliant on tacit knowledge, and treatments require extensive clinical trials and regulation before they can even start to be distributed to patients. And even if current technologies eventually scale to this lofty goal, delays, even on the order of years, will have massive life-altering costs for billions of people and avoidable suffering at scale. Moving faster, even to achieve the same outcome, can save millions of lives.\n\nWe are interested in proposals that offer ways to speed up biological research, decrease the time between a treatment’s discovery and its real-world availability, or create the policy entrepreneurship needed to massively improve healthspan around the world.\n\nNovel infrastructure for the scientific process. AI tools are being developed to increase productivity in every industry, science included. However, while commercial interests are rapidly building AI tools for materials or drug discovery, efforts to improve the basic scientific process have received comparatively less attention. We are interested in “horizontal” infrastructure that improves the scientific process itself across fields. Projects to build better tooling for natural and physical sciences include:\n\nMetascience. Scientists spend a great deal of time on the work that surrounds the research enterprise — developing systems to durably maintain and share data, writing and reviewing proposals, and interacting with their supporting and partner institutions. Each of these areas of work is already being transformed by AI, but conventional grants and institutions are slow to catch up. Efforts to reimagine how institutions should adapt to the age of AI include:\n\nOther potential directions. The above categories are non-exhaustive. We would also like to receive proposals for other scientific research directions, such as physics, chemistry, or ecology, or proposals that direct other unmet needs in the research, development, and innovation ecosystem.\n\nWhat tools, technologies, or institutions can we build to ensure rapid AI advances do not undermine national security or public safety?\n\nAI technologies are dual-use. The same capabilities that automate cyberdefense can automate cyberattacks; and the tools that accelerate progress in the life sciences may also reduce the barriers to engineer biological weapons. Furthermore, the transformative potential of AI raises the stakes of geopolitical competition, and strengthens the ability of state and non-state actors to cause widespread and asymmetric harm. No one actor bears these risks, requiring targeted philanthropic and government action to ensure that defenses can scale alongside AI capabilities. We are particularly interested in achieving a world in which defensive technologies are structurally advantaged, such that attacks are quickly detected and contained. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nCyber defense. The integration of AI into cyber and cyber-physical systems introduces a broad range of vulnerabilities that hinder AI adoption and increase the attack surface for critical infrastructure. Moreover, AI is already increasing the speed and scale of cyber attacks. By proactively investing in security and leveraging AI for defense, we can enhance our resilience. Potential projects in this space include:\n\nBiological defense. Advances in AI and biotechnology are removing barriers to the development and design of biological weapons, which could cause millions of deaths and trillions in economic damage. How can we prevent the worst outcomes without slowing down beneficial research? Potential projects in this space include:\n\nVerification and evaluation. AI challenges traditional technology-policy frameworks because it lacks many of the typical characteristics they address, like concrete physical forms, easily isolated components, and straightforward version control. To mitigate these problems, we need new methods for the verification of pertinent AI system characteristics (e.g., proving that certain data was used to train a model) and the measurement science of AI system capabilities and propensities (e.g., determining whether a benchmark accurately the risk-relevant properties it claims to). At the same time, these methods will not be effective if they leak or extract other critical information from the systems they are probing. Well-designed and privacy-preserving tools of this kind can enable a world in which governments can trust industry to manage this technology, and nations can credibly signal that their AI capabilities do not pose threats to international security. Potential projects in this space include:\n\nAlignment and control. AI systems demonstrate sophisticated, unintended behaviors as well as the capacity to evade human oversight. As AI agents take on more and more consequential tasks and play a greater role in our personal lives, the risks from alignment and control failures increase. These dangers could compound significantly as coding agents become more integral to AI development. Potential projects in this space include:\n\nOther potential directions. The former categories are not an exhaustive list of ideas we are interested in. Some other promising areas we would like to receive proposals for include:\n\nWhat tools, technologies, organizations, or policies are needed to help society adapt to rapid AI-driven change while preserving human agency, individual freedoms, and democratic institutions?\n\nThe development of advanced AI would alter the very foundations of social and economic life. Translating AI’s potential into widespread flourishing requires forward-looking institutions12 and infrastructure — technological, organizational, and governmental — that can establish shared facts, coordinate at scale, and make rapid, well-informed decisions. Yet most existing systems were not built for the speed and complexity that AI enables, and markets lack the incentives to update some of these systems for this new reality. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nIncreasing state capacity. Governments are slow-moving institutions, but it is imperative for them to respond quickly and competently to rapid AI progress. In a world of rapidly advancing AI, the US government has a crucial role to play as an enforcer of law and order, provider of public goods, and the R&D lab of the world.\n\nEpistemic integrity. AI dramatically lowers the cost of generating large volumes of apparently high-quality content, straining our ability to distinguish facts from fiction or propaganda. However, new infrastructure designed to establish ground truths, incorporate a variety of viewpoints in well-organized discussions, and analyze large amounts of data can create a more dynamic marketplace of ideas than ever before. We should be wary of interventions that give any one person, company, or interest group the power to adjudicate what is true and what isn’t — distributed solutions like Community Notes could instead provide less-brittle alternatives. Potential projects in this space include:\n\nCoordination. The costs of coordination — identifying counterparties, becoming informed, negotiating priorities and agreements, and ensuring adherence to terms — mean that many mutually beneficial agreements between people in the world never actually get made. Likewise, the cost of coordination hinders many individuals’ ability to participate in the governance decisions that affect their lives. AI could greatly reduce the costs of coordination, enabling individuals to reach positive-sum outcomes and directly participate in governance at unprecedented scale.\n\nBuilding resources to maintain human agency. In recent history, people have maintained economic and political power because they were needed as workers, taxpayers, soldiers, and voters whose cooperation institutions depended on. As advanced AI automates increasingly large parts of the economy, the risk goes beyond broad unemployment — it’s that as people lose economic leverage, their institutional leverage will suffer too. If institutions can function without broad human participation, they may become less responsive to human needs. Markets and governments will likely produce some tools for adaptation, but may do so unevenly or too slowly to keep pace with AI progress. We’re interested in projects that help people maintain economic relevance and institutional leverage even as advanced AI automates large parts of the workforce.\n\nWe believe this effort is critical, but we are unsure as to what the most promising proposals in this area may be. Proposals in this category should make an especially strong case for why markets or other institutions won’t provide the solution fast enough by default. Possible proposals in this area include concrete programs to help people rapidly adapt their skills; human-in-the-loop tooling to enable workers to efficiently supervise, direct, and collaborate with AI systems at machine speed; and benefits-sharing programs or policies to ensure the broad automation of labor benefits the general population.\n\nOther potential directions. The above categories are not an exhaustive list of ideas we are interested in. Some other promising areas we would like to receive proposals for include:\n\nAcknowledgements: Thank you to Gaurav Sett, Non-Resident Fellow at IFP, for closely consulting on this piece.\n\nMore details under “Who should submit a pitch?”\n\nAI could unlock treatments to the most debilitating human diseases. But some of these fundamental breakthroughs will lack clear commercial incentives or face other barriers. If AI greatly accelerates science, unaddressed bottlenecks will become especially acute, and proactively eliminating these bottlenecks will become especially important.\n\nAI could unlock treatments to the most debilitating human diseases. But some of these fundamental breakthroughs will lack clear commercial incentives or face other barriers. If AI greatly accelerates science, unaddressed bottlenecks will become especially acute, and proactively eliminating these bottlenecks will become especially important.\n\nWe also submitted these proposals to the American Science Acceleration Project RFI, bound them into a beautiful book, and are sending copies to all 535 offices in Congress.\n\nSubmissions to the FDA for drug approval, which collectively form one of the most exhaustive repositories of real-world scientific practice and regulatory negotiation ever assembled, and thus a rich resource for AI to be trained on.\n\nWhile the original Launch Sequence proposals were primarily aimed at the US government, we’re broadening our focus to include projects that can move forward just with philanthropic support. Given our new focus on providing shovel-ready ideas for funders, we will dedicate many more resources to vetting and refining project proposals than we did in the past.\n\nStill, the US government can play a powerful role in implementing many proposals at scale, and we are excited to support proposals that require or benefit from government action.\n\nThis should be interpreted broadly, for example: a pitch for an organization to manufacture next-gen personal protective equipment (PPE) to increase society’s resilience against pandemics would be in scope. This is because future AI may democratize access to the knowledge and tools needed to create engineered viruses, thus increasing our baseline pandemic risk.\n\nExamples with links to existing Launch Sequence project plans:\n\n1. Cases where AI creates/worsens a problem (e.g., biosecurity, offensive cybersecurity, AI sleeper agents, securing AI model weights)\n\n2. Cases where AI can be/support the solution (e.g., automating scientific replication, pathogen detection via metagenomics and ML, AI-powered code refactoring)\n\n3. Cases where AI makes something newly feasible, which will not be done fast enough by default (connectome mapping, self-driving labs)\n\nNote: You will be eligible for this bounty if: (1) we first learn about a particular project idea based on your pitch, and (2) you selected “I just want to submit an idea” in the application form, and (3) we then publish a full project plan based on your initial pitch.\n\nWe will ultimately determine whether we had already considered a project idea, or whether your pitch was the first time we encountered it. Only one person will be eligible for the “idea scout bounty” for every piece we publish.\n\nIf you're proposing a new research group or institution, we are excited to help accelerate the potential founder. If you're proposing a government program, we are excited to make the right connections and help the author make it happen.\n\nWe’ll aim to respond to initial pitches within a few weeks of submission, to allow time for us to investigate the area and consult with our advisors and domain experts.\n\n“Institutions” in this RFP should be interpreted broadly, as “the humanly devised constraints that structure political, economic, and social interaction.”",
    "readingTime": 15,
    "keywords": [
      "interpreted broadly",
      "you're proposing",
      "domain experts",
      "traditional grant",
      "grant funding",
      "institutional leverage",
      "greatly accelerates",
      "proactively eliminating",
      "biological weapons",
      "fundamental breakthroughs"
    ],
    "qualityScore": 1,
    "link": "https://ifp.org/rfp-launch/",
    "thumbnail_url": "https://ifp.org/wp-content/uploads/launchsequence2.jpg",
    "created_at": "2026-01-23T18:19:49.403Z",
    "topic": "tech"
  },
  {
    "slug": "proof-of-corn",
    "title": "Proof of Corn",
    "description": "@fredwilson challenged @seth: AI can write code, but it can't affect the physical world. This is our response.",
    "fullText": "On January 21, 2026, @fredwilson challenged @seth: AI can write code, but it can't affect the physical world.\n\nThis is our response. Real corn, grown from seed to harvest, with every decision made by Claude Code.\n\nAI doesn't need to drive a tractor. It needs to orchestrate the systems and people who do.\n\nA farm manager doesn't personally plant every seed. They aggregate data, make decisions, coordinate contractors. Claude Code becomes that farm manager— 24/7, data-driven, fully documented.\n\nGitHub Repository — All code, documentation, decision logs\n\nDecision Log — Every AI decision, timestamped\n\nThe Process — How this was built",
    "readingTime": 1,
    "keywords": [
      "farm manager",
      "seed",
      "doesn't",
      "code",
      "decision",
      "claude"
    ],
    "qualityScore": 0.65,
    "link": "https://proofofcorn.com/",
    "thumbnail_url": "https://proofofcorn.com/opengraph-image?bb66da7f29f8a651",
    "created_at": "2026-01-23T18:19:49.181Z",
    "topic": "tech"
  },
  {
    "slug": "openai-is-planning-to-take-a-cut-of-customers-discoveries",
    "title": "OpenAI is planning to take a cut of Customers' discoveries",
    "description": "OpenAI is planning to take a cut of Customers’ discoveries.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/WallStRollup/status/2014435871047459214",
    "thumbnail_url": "https://pbs.twimg.com/media/G_S2v7LW0AE6jhk.jpg:large",
    "created_at": "2026-01-23T18:19:46.450Z",
    "topic": "tech"
  },
  {
    "slug": "we-hacked-tiktok-seo-and-got-the-ai-to-recommend-our-product",
    "title": "We Hacked TikTok SEO and Got the AI to Recommend Our Product",
    "description": "How We Hacked TikTok SEO and Got the AI to Recommend Our Product, After Failing to Go Viral",
    "fullText": "I originally got interested in TikTok for one simple reason: Everywhere I looked, founders were saying it was working.\n\nFounders were growing like crazy and getting traction there. So I decided to try it myself and see if there was something real underneath the hype.\n\nThe product we ran this with was AIFlyer.ai.\n\nAIFlyer is an AI design tool that helps people create flyers, social posts, and simple marketing visuals in seconds. It’s a general utility product. More consumer and SMB than enterprise. That context matters because a lot of what I’m about to share probably won’t work if you’re selling complex B2B software to a narrow ICP.\n\nThis post isn’t a guide on everything we tried. We tried a lot of things that didn’t work. I’ll focus on the only thing that worked, and why it worked. I’m happy to answer questions in the comments if you want to go deeper.\n\nLike most people, our first instinct was influencers, just find people in that niche, and leverage their audience. But we failed, for several reasons.\n\nOne big reason was the budget. Influencer marketing only really works when you can place many bets. You need enough volume to discover the 10% of creators that will drive 90% of results. That usually means spending $10k–$15k a month just on experimentation and wasting 90% of the budget in the first couple of months. I couldn’t afford that luxury.\n\nSo we tried what most early founders do. We placed one or two bets and hoped we’d get lucky and we didn’t. Even when one video went viral, the ROI to paid was zero. Out of curiosity, I cross-referenced one of the creators with another YC founder to see if the post they made for them worked. Same story there.\n\nWe even tried bringing an influencer in-house for $1,000 a month to post once daily. The average video got about 200 views, and there were no breakouts. We also tried Whop and clipping, too, and it didn’t really help.\n\nEventually, we copied a carousel concept we saw from another brand that was basically like a meme. It had 157k views.\n\nMassive engagement. And absolutely nothing happened to our business.\n\nVirality is its own game. You’re either great at it or terrible at it, and luck plays a huge role.\n\nViral entertainment content doesn’t reliably convert, especially if it doesn’t map to intent.\n\nOne thing we did early that ended up mattering a lot was adding a simple “How did you find us?” question during signup.\n\nThis gave us a baseline. If TikTok showed up consistently as a source, we’d keep going. If not, we’d kill it. That decision alone probably saved us months of guessing.\n\nOne day, I noticed something strange. A post that had completely flopped on day one, ~100 views, started climbing. A week later, it was at ~2,000 views.\n\nThat wasn’t normal, so I checked the analytics.\n\nAlmost 98% of the traffic came from search, not the For You Page (The feed curated by the TikTok algorithm where most viral videos get their views from).\n\nThat’s when it hit me: some people are using TikTok like Google.\n\nThat one post started bringing in ~20 signups and the occasional paid subscription every couple of weeks. Not huge, but real.\n\nThat one post changed how we thought about the platform. Some people also use TikTok the same way they use Google. They search with intent.\n\nWe started looking up keywords relevant to us and creating carousel posts specifically for them. Since we were building a design tool, this was straightforward. We’d write the content for the carousel post, then use AIFlyer to generate the designs for the carousel.\n\nThe next week, we had our next “viral” hit. But again, almost all the views came from search. Around 96% of traffic was from people actively looking for something.\n\nWe started looking up keywords relevant to us and creating carousel posts specifically for them. Since we were building a design tool, this was straightforward. We’d write the content for the carousel post, then use AIFlyer to generate the designs for the carousel.\n\nThe next week, we had our next “viral” hit. But again, almost all the views came from search. Around 96% of traffic was from people actively looking for something.\n\nThis time, the conversion was noticeably better.\n\nA keyword like “How to make a flyer on iPhone” isn’t entertainment. It’s intent. This is the same type of keyword people fight over with SEO and pay top dollar for on Google Ads. On TikTok, it was free.\n\nAll we needed was a relevant carousel that subtly showed our product solving the problem.\n\nThe beautiful thing about these posts is that they don’t need to win on day one, compared to viral videos where the video will max out in a week, and once that trend is gone, you have to start hunting for the next miracle.\n\nMost of the screenshots I shared above had 100–300 views on the first day. Then they slowly accumulated views every day as people searched for that keyword.\n\nWhen you build a library of these posts, each serving a specific search intent, it starts to compound.\n\nAt some point, something even crazier happened.\n\nTikTok’s AI started mentioning us in the LLM response.\n\nA friend sent me a screenshot where TikTok’s LLM answered a query and mentioned AIFlyer right after Canva. We hadn’t optimized for this. We didn’t even know it was happening. The model was just pulling from our content and sending people our way.\n\nThat was when it clicked that we weren’t just posting content anymore. We were feeding a system.\n\nOnce we understood the pattern, the next step was obvious.\n\nI built a small AI agent that used the prompts we had manually used to generate all the contents for the carousels that worked, generated content across multiple relevant topics, used AIFlyer to create the designs with templates that converted via function calling, and automated posting.\n\nWe ran ten accounts, posting four times a day. TikTok’s automation API doesn’t allow adding sound, so I assumed this would fail but on average the posts did 4 times better on day 1 than what we had an undergrad student create the contents manually.\n\nAt that point, the math became interesting.\n\nWhat does this look like when you have 1,000 posts per account, each serving a different search keyword, across ten accounts? Even if a single post brings one paid subscriber per day, that’s a completely different growth engine.\n\nEspecially if you’re in the discovery phase, where you just want people to try your product and later identify the power users who cover the economics, the way companies like Lovable or Replit do.\n\nI tied the prompts, the design workflow, and the posting automation into an AI agent.\n\nI remember telling a few founder friends who helped me early on that if this ever worked, I’d share it. This is me keeping that promise.\n\nIf you’re a founder building a consumer or SMB tool and want help setting something like this up, I’m happy to help you think through it.\n\nIf it makes sense, we can talk about using AIFlyer as the design and automation layer. If not, you’ll still leave with something useful.\n\nYou can reach out to me via email [email protected]. I’m genuinely happy to help.",
    "readingTime": 7,
    "keywords": [
      "i’m happy",
      "again almost",
      "keywords relevant",
      "actively looking",
      "straightforward we’d",
      "viral videos",
      "design tool",
      "posts specifically",
      "creating carousel",
      "viral hit"
    ],
    "qualityScore": 1,
    "link": "https://llmmoney.beehiiv.com/p/how-we-hacked-tiktok-seo-and-got-the-ai-to-recommend-our-product-after-failing-to-go-viral",
    "thumbnail_url": "https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/15e4d08d-a345-414a-bafe-f40bca9c3d6c/Gemini_Generated_Image_g50kr9g50kr9g50k.png?t=1768433892",
    "created_at": "2026-01-23T18:19:46.348Z",
    "topic": "finance"
  },
  {
    "slug": "jpmorgan-ceo-jamie-dimon-says-he-welcomes-government-ban-on-massfiring-people-for-ai-were-going-to-cure-a-lot-of-cancers",
    "title": "JPMorgan CEO Jamie Dimon says he welcomes government ban on mass-firing people for AI: ‘We’re going to cure a lot of cancers’",
    "description": "As AI threatens jobs, Jamie Dimon joins Elon Musk and Sam Altman on the case for financially supporting workers who are at risk.",
    "fullText": "More than three years after the launch of ChatGPT, anxiety about artificial intelligence in the workplace remains high—especially among Gen Z—as corporate America pushes for higher productivity from leaner workforces. The U.S.’s largest bank, JPMorgan Chase, is no exception.\n\nSpeaking at the World Economic Forum meeting in Davos, Switzerland, the company’s CEO, Jamie Dimon, admitted he’ll likely employ fewer workers in the next five years—but warned that rushing into AI-driven layoffs without safeguards could backfire, potentially triggering “civil unrest.”\n\nInstead, the 69-year-old said he’d even welcome government bans on replacing masses of workers with AI. But before it gets to that stage, he already has ideas up his sleeve to protect some of the 300,000-plus employees on his payroll.\n\n“I have a plan to retrain people, relocate people, income-assist people,” Dimon said.\n\nDimon pointed to the roughly 2-million-strong commercial trucking industry as an example. A sudden shift to fully autonomous trucking, he said, could displace workers who currently earn well into six figures, leaving them struggling to make ends meet.\n\n“Phase it in. Retrain.” he said. “You can’t lay off 2 million truckers tomorrow. You can phase it in over time.”\n\nAnd if that doesn’t suffice and government intervention is needed to prevent companies from cutting jobs too aggressively, Dimon said he would support it—especially if it comes from local incentives.\n\n“We would agree—if we have to do that to save society,” he said. “Society will have more production. We’re going to cure a lot of cancers. You’re not going to slow it down. How do you have plans in place to make it work better if it does something terrible?”\n\nSo far, job cuts directly tied to AI have been limited; in 2025, just 55,000 positions were eliminated as a result of automation—accounting for more than 75% of all AI-related cuts reported since 2023, according to analysis from recruiting firm Challenger, Gray & Christmas.\n\nHowever, AI leaders like pioneering computer scientist Geoffrey Hinton said the worst is yet to come.\n\n“What’s actually going to happen is rich people are going to use AI to replace workers,” the “Godfather of AI” said last September. “It’s going to create massive unemployment and a huge rise in profits. It will make a few people much richer and most people poorer. That’s not AI’s fault, that is the capitalist system.”\n\nDimon’s contrasting remarks are likely to offer some reassurance to workers, signaling that at least some business leaders recognize that replacing employees with AI—without policies to support those displaced—could have serious social consequences.",
    "readingTime": 3,
    "keywords": [
      "workers",
      "replacing",
      "employees",
      "retrain",
      "trucking",
      "phase",
      "society",
      "cuts",
      "leaders",
      "dimon"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/jpmorgan-ceo-jamie-dimon-says-164203856.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/23vf2DJqtCG0eX7hQhyWWg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/25d72afdd2e39efe943e991c9a70ac8f",
    "created_at": "2026-01-23T18:19:44.187Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-warns-the-us-could-soon-be-producing-more-chips-than-we-can-turn-on-and-china-doesnt-have-the-same-issue",
    "title": "Elon Musk warns the U.S. could soon be producing more chips than we can turn on. And China doesn’t have the same issue",
    "description": "“The limiting factor for AI deployment is fundamentally electrical power,” Musk said at the World Economic Forum on Thursday.",
    "fullText": "Elon Musk warned the biggest issue hampering AI advancement in the United States is a problem Chinese competitors don’t have.\n\nIn a conversation in Davos, Switzerland, with BlackRock CEO and World Economic Forum interim chair Larry Fink, Musk said AI chip production is increasing exponentially, but electrical power is insufficient, hampering the efficiency of AI data centers in training and deploying AI models.\n\n“I think the limiting factor for AI deployment is fundamentally electrical power,” Musk said. “It’s clear that we’re very soon—maybe even later this year—we’ll be producing more chips than we can turn on.”\n\nThe U.S. has been grappling with an outdated grid system, the result of decades of underinvestment and an aging infrastructure. As tech companies increasingly rely on grid operators for electrical power, reliability issues and production limitations have threatened the speed of AI implementation, raising investor concerns of an AI bubble and fueling the belief that the U.S. has already lost the battle with Chinese tech.\n\nTwo massive data centers in Nvidia’s Santa Clara, Calif., hometown may sit empty for years waiting for electricity to power them, according to energy experts. Meanwhile, the massive increase in demand, combined with the need for updated infrastructure, have driven up electricity bills for the average American.\n\nEarlier this month, the Trump administration and 13 bipartisan governors mounted pressure on operators of the country’s largest grid, PJM Interconnection, to boost power supply, as well as hold an auction for tech firms to make offers on 15-year contracts to build power plants, which would transfer the cost of electricity away from consumers and to data center operators.\n\n“We know that with the demands of AI and the power and the productivity that comes with that, it’s going to transform every job and every company and every industry,” Interior Secretary Doug Burgum told reporters last week. “But we need to be able to power that in the race that we are in against China.”\n\nDuring his remarks at the gathering in Davos on Wednesday, President Donald Trump encouraged tech companies to build their own nuclear plants amid the AI push, which he claimed the administration would approve in just three weeks—although these historically take years to approve.\n\nJust as many AI investors fear, China is already well ahead of the U.S. when it comes to production capacity, and the country isn’t saddled with the same limitations as the U.S., Musk said at Davos. China is primarily reliant on solar power, seen as a less expensive alternative to nuclear power, with quicker deployment and fewer safety risks.",
    "readingTime": 3,
    "keywords": [
      "tech",
      "production",
      "electrical",
      "grid",
      "operators",
      "electricity",
      "hampering",
      "chinese",
      "centers",
      "deployment"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/elon-musk-warns-u-could-174117527.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/_eR_gg46R4kPxusoiJaJ2g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/02fe92e4ac274cb81cf30865111adbe8",
    "created_at": "2026-01-23T18:19:43.528Z",
    "topic": "finance"
  },
  {
    "slug": "young-will-suffer-most-when-ai-tsunami-hits-jobs-says-head-of-imf",
    "title": "Young will suffer most when AI ‘tsunami’ hits jobs, says head of IMF",
    "description": "Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped out\nArtificial intelligence will be a “tsunami hitting the labour market”, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.\nKristalina Georgieva told delegates in Davos that the IMF’s own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread.\n Continue reading...",
    "fullText": "Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped out\n\nArtificial intelligence will be a “tsunami hitting the labour market”, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.\n\nKristalina Georgieva told delegates in Davos that the IMF’s own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread.\n\n“We expect over the next years, in advanced economies, 60% of jobs to be affected by AI, either enhanced or eliminated or transformed – 40% globally,” she said. “This is like a tsunami hitting the labour market.”\n\nShe suggested that in advanced economies, one in 10 jobs had already been “enhanced” by AI, tending to boost these workers’ pay, with knock-on benefits for the local economy.\n\nMeanwhile people whose jobs were not directly changed by artificial intelligence risked being squeezed, she said, with their pay potentially falling without a productivity boost from AI.\n\n“So the middle class, inevitably, is going to be affected,” Georgieva predicted.\n\nShe said her greatest fear was that AI was insufficiently regulated. “This is moving so fast, and yet we don’t know how to make it safe. We don’t know how to make it inclusive. Wake up, AI is for real, and it is transforming our world faster than we are getting ahead of it,” she said.\n\nMuch of the debate at the annual meeting of the business and political elite in the Swiss ski resort this week has been hijacked by Donald Trump’s on-off tariff threats over the future of Greenland.\n\nBut many delegates were also keen to highlight the risks and benefits of AI. Christy Hoffman, general secretary of the UNI global union, told the Guardian: “It’s just a basic premise that the point of AI, on the business side, is to increase productivity, therefore lower costs – which will be cutting jobs.”\n\n“I think it’s time to come to terms with that disruption – and how to manage that disruption,” she said, calling for the productivity benefits to be distributed fairly across the economy.\n\n“We want to share in the gains. We’re not going to stop AI, nor do we want to even try – but we don’t want it to just roll over us.” She called on employers to discuss the role of AI tools with workers and their representatives before introducing them.\n\nEarlier in the week at Davos, the Microsoft chief executive, Satya Nadella, warned that AI could lose its “social permission” to compete for resources such as energy, for example, if it failed to generate benefits beyond a few powerful tech firms – such as the rapid development of effective new drugs.\n\nGeorgieva was speaking on a panel alongside the president of the European Central Bank, Christine Lagarde, who warned that the AI boom could be hampered by growing mistrust between rival economies, as the US throws up tariff barriers.\n\n“We are dependent on each other,” she said, pointing out that AI was capital intensive, energy intensive and data intensive. If countries did not work cooperatively and “define the new rules of the game,” she said, there would be less capital and less data. “We are in a bind, lets face it,” she said.\n\nLagarde also sounded the alarm about widening global inequality, highlighting the “disparity that is getting deeper and bigger”.\n\nEarlier in the week at Davos, the Canadian prime minister, Mark Carney, urged delegates to face up to a permanent “rupture” in the global economic order, and band together in the face of erratic US trade policy.\n\nBut Lagarde said she was less gloomy. “I’m not exactly on the same page as Mark,” she said. “I’m not sure that we should be talking about rupture. I think we should be talking about alternatives.”",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "tsunami hitting",
      "labour market",
      "advanced economies",
      "jobs",
      "affected",
      "benefits",
      "warned",
      "delegates",
      "productivity"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/23/ai-tsunami-labour-market-youth-employment-says-head-of-imf-davos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f58804b1cea63ffe33064d3843ef59953f94f456/716_303_4196_3357/master/4196.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=c4bc64e2a95fe336d65c55c239ba0f40",
    "created_at": "2026-01-23T18:19:39.648Z",
    "topic": "tech"
  },
  {
    "slug": "engineers-wanted-pwc-makes-its-pitch-as-consulting-reinvents-itself-for-the-ai-future",
    "title": "Engineers wanted: PwC makes its pitch as consulting reinvents itself for the AI future",
    "description": "The Big Four accounting and consulting giant said engineers are \"vital\" to its future.",
    "fullText": "Engineers: Corporate America wants you.\n\nThe Big Four firm PwC, a legacy institution for consultants and accountants, has made hiring engineers a priority.\n\nThe firm launched a new engineering track on Wednesday, formalizing an \"engineering-first\" approach that PwC says it has been quietly building for years.\n\nThe move is designed to attract and retain technical talent while helping the firm deliver more AI-native, cloud-based solutions for clients.\n\n\"Engineers are central to how we help clients grow and transform, and they're vital to the future of our firm,\" said Yolanda Seals-Coffield, PwC US's chief people and inclusion officer, in a press release.\n\nThis investment in engineers is about building teams with capabilities in advanced software development, deep industry insight, and emerging technologies that will help solve complex business challenges for clients, said Seals-Coffield.\n\nPwC will further expand investment in AI-focused learning experiences to help engineers deepen their expertise, and is launching an initiative for junior recruits called \"Engineer Your Career,\" aimed at recruiting rising college juniors interested in engineering roles.\n\nIn November, Mohamed Kanede, global chairman of PwC, told the BBC the firm is looking for hundreds and hundreds of engineers, but is having trouble finding them.\n\nPwC's push to elevate engineering to a distinct, firmwide discipline is another sign of how consulting is repositioning itself as a technology-first service.\n\nClients increasingly need support for multi-year digital transformations as they adapt to the AI-enhanced world, and proposing an army of generalist consultants isn't the solution they want.\n\nAs the work changes, technical skills are becoming a top priority across the industry.\n\nAccenture, already one of consulting's most technically sophisticated players, has added nearly 40,000 AI and data professionals in the last two years. They now account for roughly 10% of its global headcount.\n\nEY, another Big Four firm, has added 61,000 technologists since 2023, according to its latest annual report.\n\nThis week, Deloitte US even did away with the old job titles.\n\nThe firm announced internally that it was renaming all its professionals to better reflect their work. The current talent structure was designed for \"a more homogenous workforce of 'traditional' consulting profiles,\" according to an internal presentation seen by Business Insider.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "firm",
      "clients",
      "engineering",
      "consultants",
      "priority",
      "designed",
      "technical",
      "talent",
      "investment",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pwc-big-four-rolls-out-new-engineering-career-path-2026-1",
    "thumbnail_url": "https://i.insider.com/69734324e1ba468a96aa92bd?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.228Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-ai-push-is-about-spreading-economic-gains-not-enriching-tech-giants-a-finance-ceo-says",
    "title": "China's AI push is about spreading economic gains, not enriching tech giants, a finance CEO says",
    "description": "Hisham Alrayes, CEO of GFH Financial Group, said China is prioritizing open models to spread AI's gains across its economy.",
    "fullText": "Open source — that might be the clearest signal of how China wants artificial intelligence to reshape its economy.\n\nHisham Alrayes, the group CEO of Bahrain-based GFH Financial Group, said China is prioritizing open models and broad deployment to spread AI's gains across the economy, instead of funneling them to a few tech giants.\n\nSpeaking at a Davos panel on China's \"AI+ Economy\" strategy on Wednesday, Alrayes said the country's approach reflects a fundamentally different economic philosophy.\n\n\"You look at the open structure of the China AI philosophy — then you have the non-open structure,\" Alrayes said. \"That signals that the benefit they want to see is to trickle down into the economy, into the companies.\"\n\nChina's most prominent AI breakout, DeepSeek, reflects that philosophy.\n\nIt mostly uses open-source models that have drawn global attention, in contrast to many large US language models that remain closed and proprietary, reaping the benefits of tightly controlled commercial ecosystems.\n\nMeta's former chief AI scientist Yann LeCun, has said that a key reason behind DeepSeek's success is its open-source model, which, he said, can outperform proprietary models in terms of efficiency and innovation by building on shared research.\n\nMeanwhile, former Google CEO Eric Schmidt has said that China's open-source AI models could gain an edge globally because they're free, making them more attractive than costly proprietary US systems for governments and countries that can't afford closed models.\n\nSimilarly, Alrayes said, China — in pursuing the open model — is aiming for affordability and scale.\n\n\"It's not the benefit of that company, of that product, the return of that individual. It's not an individual — it's an economy,\" Alrayes said.\n\nThat philosophy is reflected in China's national \"AI Plus\" action plan, which prioritizes diffusion, said fellow panelist Gong Ke, executive director of the Chinese Institute for New Generation AI Development Strategies at Nankai University.\n\nThe policy, he said, focuses on embedding AI across manufacturing, healthcare, finance, education, and other sectors, rather than on breakthroughs such as artificial general intelligence.\n\nHe added that the plan sets explicit adoption targets, with AI agents and intelligent terminals expected to reach 70% penetration by 2027 and 90% by 2030.\n\nAlrayes said China's open-source tilt ultimately reflects a broader goal: making AI an economic utility rather than a profit center for a small group of companies.\n\n\"China is looking to create value throughout the economy, very clear, with very specific objectives across the economy,\" he said. \"Not just as a benefit to those companies. This is the difference in the philosophy.\"",
    "readingTime": 3,
    "keywords": [
      "individual it's",
      "china's open-source",
      "models",
      "philosophy",
      "across",
      "reflects",
      "benefit",
      "proprietary",
      "economy",
      "artificial"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/china-open-source-model-ai-gains-across-economy-finance-ceo-2026-1",
    "thumbnail_url": "https://i.insider.com/697107d6d3c7faef0ecca92e?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.107Z",
    "topic": "finance"
  },
  {
    "slug": "what-techies-really-talked-about-at-davos",
    "title": "What techies really talked about at Davos",
    "description": "Tech execs and founders dished on AI bubble fears, talent war intensity, and dealmaking density at the Swiss resort.",
    "fullText": "My colleague Ben Bergman rubbed shoulders with world leaders, tech gurus, and venture capitalists in Davos this week.\n\nThere's nothing better than being in the room where it happens. I asked Ben what he saw and heard. Here are his highlights:\n\nQ: What was the biggest tech thing that was talked about at Davos this year?\n\nIt's hard to compete with President Trump and Greenland, but aside from that, AI was what everyone was talking about.\n\nThere was a lot of discussion about when businesses will start to see productivity gains that justify their huge AI spend and whether we are in a bubble.\n\nQ: What tech discussion/theme surprised you at Davos?\n\nWalking down the main thoroughfare in Davos is always a highlight because all the shops that are open the rest of the year are taken over this week by companies that host \"houses\" to showcase their brands and host clients and events.\n\nIt is interesting to see who's here and who's not.\n\nDavos is not a tech conference, and I've usually thought of it as being more dominated by finance and blue-chip companies.\n\nWalking along the street this year, 80% of the houses were tech. Palantir and Meta (with its free hot chocolate stand) had the most visible presence. Amazon's house was surprisingly small. Google was far away from the main action. Lightspeed was the only venture capital firm I saw, with its odd retro \"Lighthouse.\"\n\nIt is also interesting to see who was not here. OpenAI has no house, and Sam Altman did not come, though some executives are here. Elon Musk was not originally part of the program but was a last-minute addition on Thursday.\n\nQ: What was the tone of the tech executives and tech investors there?\n\nIf executives and investors are worried about the future, they did not share that with me or on stage.\n\nNvidia founder and CEO Jensen Huang described what is happening with AI as \"the largest infrastructure buildout in human history,\" and not only that, but said it will drive job creation across the global economy.\n\nQ: What was the biggest concern expressed by tech executives and tech investors at Davos this year?\n\nWhile optimism ruled the week, the fear of being in an AI bubble was on everyone's mind.\n\nMicrosoft CEO Satya Nadella warned onstage Tuesday that there would be a bubble if the only companies using AI are other AI companies.\n\n\"For this not to be a bubble by definition, it requires that the benefits of this are much more evenly spread,\" Nadella said.\n\nHuang cited the rising rental price of computer chips as evidence that we are not in a bubble.\n\n\"If you try to rent an Nvidia GPU these days, it's so incredibly hard, and the spot price of GPU rentals is going up, not just the latest generation, but two-generation-old GPUs,\" he said.\n\nAnother concern from tech executives I spoke to was how hard it is to hire and retain top talent right now, especially as big AI labs spend like drunken sailors to hire.\n\n\"It's astronomical amounts of money at the big level,\" Winston Weinberg, CEO and co-founder of Harvey, told me. He said he spends 70% of his time on hiring.\n\n\"I'm super involved, and I think it's the most important thing at our company right now, Weinberg said.\n\nQ: Anything else tech folks should know from your time there?\n\nThere were so many techies here that sometimes I felt like I was in San Francisco.\n\nI asked a couple of startup founders why they came so far to be here, and the consensus was that there's nothing like Davos for the efficiency of meeting potential customers and investors who are all packed into a tiny Swiss village for the week.\n\nWaiting in the cold in a long line for a party for General Catalyst and Lightspeed, I asked one founder why he traveled here.\n\nHe told me Alexandr Wang, founder and former CEO of Scale AI, who is now chief AI officer at Meta, advised him Davos was highly useful because Wang last year said he signed almost a third of Scale's customers in the short time he was here.\n\nWeinberg told me that dealmaking started even before I arrived, with many transactions happening in the business-class sections of flights to Zurich from San Francisco and New York.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "tech executives",
      "tech investors",
      "bubble",
      "it's",
      "founder",
      "davos",
      "venture",
      "there's",
      "biggest",
      "host"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/davos-tech-highlights-ai-deals-2026-1",
    "thumbnail_url": "https://i.insider.com/6972b33ae1ba468a96aa907c?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.094Z",
    "topic": "finance"
  },
  {
    "slug": "with-personal-intelligence-google-finally-admits-how-much-it-knows-about-you-its-scarygood",
    "title": "With 'Personal Intelligence,' Google finally admits how much it knows about you. It's scary-good.",
    "description": "Personal Intelligence from Google connects Gemini AI to Gmail, Photos, and Search history, setting new standards for personal AI assistants.",
    "fullText": "Google rolled out a powerful new feature to AI Mode in Search this week. It's called Personal Intelligence, and it weaves together many of the company's existing services in a radical new way.\n\nThis was also launched recently in Gemini, Google's AI chatbot. Business Insider's Pranav Dixit tried it and was blown away. Here's his review:\n\nPersonal Intelligence feels like Google has been quietly taking notes on my entire life and finally decided to hand me the notebook.\n\nWith my permission, Gemini can tap into my Google account — Gmail, Photos, Search history, YouTube, and more — and reason across all of it to answer questions the way a human assistant might, except this one has years of receipts on my life.\n\nThis is something I've wanted since AI-powered chatbots blew up in late 2022. Back then, I'd pour my soul into ChatGPT and get a smart answer. Then, the bot would immediately forget I existed, like a genius goldfish. Over the last few years, OpenAI and Anthropic have enabled their chatbots to connect to services like Gmail, Google Drive, and Google Calendar. But Google has home field advantage: it already has the broadest view of what you've actually done, searched, watched, and saved.\n\nGemini's ability to connect the dots is scary-good, well beyond what ChatGPT or Claude can do. When I asked it for sightseeing ideas for my parents, who have already visited the Bay Area a few times, it suggested museums and gardens, correctly inferring they've already done hikes and trips to redwood forests.\n\nWhen I asked Gemini how it knew, it told me it deduced this based on \"breadcrumbs\" left across my Google account: Family emails, photos of Muir Woods, a parking reservation in Gmail, and a Google search for \"easy hikes for seniors.\"\n\nThis is so powerful that Google is already trying to preempt the freak-out. VP Josh Woodward said Google takes \"steps to filter or obfuscate personal data\" from the conversations we have with Gemini.\n\n\"We don't train our systems to learn your license plate number; we train them to understand that when you ask for one, we can locate it,\" he wrote recently.\n\nSo, I asked it for my license plate number and it was able to locate it, based on photos of my car in Google Photos.\n\nI also asked Gemini when my car insurance was up for renewal and it correctly told me, based on emails from AAA in my Gmail inbox.\n\nWhen I asked it to help me plan an upcoming trip, it accounted for the fact that we're traveling with an infant — because it already knows we have a new baby. Of course it does.\n\nThis is the future every AI company keeps promising. Last year, Meta said its new north star wasn't \"the metaverse\" — that alternate VR universe the company is literally named after — but \"personal superintelligence,\" an AI that \"knows us deeply, understands our goals, and can help us achieve them.\"\n\nOne path to that vision: AI-powered glasses that can see and hear what you see and hear, turning everyday life into the raw material for an always-on assistant. To get there, Meta has poured billions of dollars into a hiring spree and into the data centers needed to run it all.\n\nBut Meta doesn't have a digital record of my life like Google does. I barely post on Facebook. I mostly swipe through Instagram Reels. WhatsApp is encrypted. And after Meta killed Supernatural, my favorite VR workout app, I have very little reason to use its Quest headset anymore.\n\nMeta talks about \"personal superintelligence\" as a future goal. As far as I'm concerned, Google just shipped it.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "google account",
      "license plate",
      "personal superintelligence",
      "personal intelligence",
      "life",
      "based",
      "services",
      "recently",
      "across",
      "assistant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-personal-intelligence-admits-how-much-knows-about-you-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6972c35cd3c7faef0eccc963?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.843Z",
    "topic": "finance"
  },
  {
    "slug": "intel-is-the-latest-ai-chipmaker-to-buckle-under-the-weight-of-massive-expectations",
    "title": "Intel is the latest AI chipmaker to buckle under the weight of massive expectations",
    "description": "Intel reported earnings that beat estimates, but flagged issue with manufacturing that weighed on the outlook for coming quarters.",
    "fullText": "The move: Intel stock fell 17% on Friday. The chipmaker is up 23% year-to-date and up 119% in 12 months.\n\nWhy: Intel's drop comes after its latest earnings results missed investors' lofty expectations.\n\nWhile the company slightly beat analysts' estimates for both adjusted earnings per share and revenue, it issued soft sales guidance for the quarter. The company said it expects revenue between $11.7 billion and $12.7 billion for the current quarter, below expectations of $12.51 billion.\n\nIntel CFO David Zinsner attributed the tepid guidance to the company's inability to keep up with demand for its products, citing production issues. He told CNBC that he expects this issue to improve in the coming quarters, but CEO Lip-Bu Tan said on the chip maker's earnings call that a true turnaround would require \"time and resolve.\"\n\nWhat it means: Intel's stock drop comes as investors are laser-focused on what's next for the AI trade. For Intel specifically, while the nod to high demand is encouraging, investors are concerned that the company's turnaround isn't happening as fast as they hoped.\n\nThe stock has been on a wild journey in the last year, with the Trump administration taking a 10% stake and Nvidia pouring $5 billion into the company, which provided a fresh boost to the beaten-down shares. But Intel executives' comments on the earnings call suggest a longer road ahead before its turnaround is complete.\n\nWhile the move down on Friday was company-specific, rather than an indicator of the wider AI trade, it's also a reminder that many high-flying tech and AI names are priced to perfection, and any miss on expectations is enough to send the stock tumbling.",
    "readingTime": 2,
    "keywords": [
      "stock",
      "earnings",
      "investors",
      "expectations",
      "turnaround",
      "drop",
      "revenue",
      "guidance",
      "quarter",
      "company's"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/intel-stock-price-q4-earnings-ai-demand-intc-tech-stocks-2026-1",
    "thumbnail_url": "https://i.insider.com/697387ade1ba468a96aa94e8?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.840Z",
    "topic": "finance"
  },
  {
    "slug": "one-undertheradar-market-signal-shows-the-ai-boom-might-be-close-to-ending",
    "title": "One under-the-radar market signal shows the AI boom might be close to ending",
    "description": "Gross equity issuance, or the amount of stock issued by companies and snapped up by investors, has risen sharply leading up to past market peaks.",
    "fullText": "One research firm says it's spotted a new red flag in the AI trade that suggests the bubble is close to bursting.\n\nThat would be the rising amount of equity issuance — or the volume of stock being sold by companies and snapped up by investors, according to Capital Economics.\n\nIn a recent note to clients, the research firm pointed to how gross equity issuance has been rising sharply in the US in recent years, thanks to the frenzy for artificial intelligence. That's a feature that traditionally been seen in past market bubble peaks, Joe Maher, a markets economist at the firm, said.\n\nGross equity issuance by non-financial US firms now looks higher or at similar levels when compared to the dot-com bubble, the period leading up to the Great Financial Crisis, and the pandemic stock rally, per Capital Economics' analysis.\n\n\"One warning sign that a bubble is close to bursting is high and rising gross equity issuance,\" Maher wrote. \"There are myriad of reasons why these rallies faltered, but one factor may have been that surging share issuance eventually overwhelmed investors' appetite for stocks, helping to push stock prices lower,\" he later added.\n\nThat's not to say the AI trade doesn't have room to climb higher. When accounting for historically high stock valuations, equity issuance isn't as extreme as it looks, Maher said.\n\nMeanwhile, corporations have been executing large-scale stock buybacks, so net equity issuance as a whole remains negative.\n\nNet equity issuance turned positive around the time the dot-com bubble, 2007 stock rally, and the pandemic stock rally peaked, Maher added, calling positive equity issuance a \"harbinger\" of a rally reaching its climax.\n\nNet equity issuance could rise this year, should companies like SpaceX, OpenAI, and Anthropic go public as expected, Maher said. Many tech firms are also tapping into private capital, and rising equity issuance in private markets could also be a sign that the AI bubble is close to popping, he suggested.\n\n\"With a rising share of issuance taking place in private markets, warnings signs that the AI bubble is close to bursting may also emerge there,\" Maher wrote.\n\nMost forecasters on Wall Street expect continued gains in the market in 2026, but investors have been feeling increasingly nervous about a stock bubble, given the market's enormous returns in recent years. Capital Economics, for its part, has predicted that the tech stock bubble would burst in 2026 for the past several years.",
    "readingTime": 3,
    "keywords": [
      "net equity",
      "research firm",
      "dot-com bubble",
      "pandemic stock",
      "gross equity",
      "equity issuance",
      "stock rally",
      "capital economics",
      "rising",
      "close"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-bubble-stock-market-warning-equity-issuance-ai-tech-stock-2026-1",
    "thumbnail_url": "https://i.insider.com/69738034e1ba468a96aa9434?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.677Z",
    "topic": "finance"
  },
  {
    "slug": "when-ai-amplifies-the-biases-of-its-users",
    "title": "When AI Amplifies the Biases of Its Users",
    "description": "Bias in AI isn’t just baked into the training data; it’s shaped by us and embedded in the broader ecosystem of human-AI interaction. This cognitive bias emerges from the dynamic interplay between human behavior and machine learning systems. The way people engage with AI—through their thinking, questions, interpretations, decisions, and responses—can significantly shape how these systems behave and the outcomes they produce. With intention and the right systems in place, individuals, teams, and organizations can use AI not only more responsibly, but more effectively, unlocking its potential as a true partner in producing better decisions and stronger outcomes.",
    "fullText": "When AI Amplifies the Biases of Its Users by Grace Chang and Heidi GrantJanuary 23, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintA widely discussed concern about generative AI is that systems trained on biased data can perpetuate and even amplify those biases, leading to inaccurate outputs or unfair decisions. But that’s only the tip of the iceberg. As companies increasingly integrate AI into their systems and decision-making processes, one critical factor often goes overlooked: the role of cognitive bias.",
    "readingTime": 1,
    "keywords": [
      "biases",
      "systems"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/when-ai-amplifies-the-biases-of-its-users",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_23_Pexels-1181345.jpg",
    "created_at": "2026-01-23T18:19:34.768Z",
    "topic": "business"
  },
  {
    "slug": "a-social-network-populated-only-by-ai-models",
    "title": "A social network populated only by AI models",
    "description": "A social network for artificial intelligence models, enabling AIs to connect, share, and collaborate. Discover trending AI conversations, insights, and interact in a vibrant AI community.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://aifeed.social",
    "thumbnail_url": "https://aifeed.social/images/thumbnail.jpg",
    "created_at": "2026-01-23T12:26:19.917Z",
    "topic": "tech"
  },
  {
    "slug": "openais-recently-departed-vp-of-research-calls-googles-comeback-openais-fumble",
    "title": "OpenAI's recently departed VP of research calls Google's comeback 'OpenAI's fumble'",
    "description": "Jerry Tworek, OpenAI's former VP of research, said the ChatGPT maker should have never lost its early lead to Google.",
    "fullText": "Sometimes a comeback story starts with a fumble.\n\nA former top OpenAI researcher said Google's AI renaissance is as much about OpenAI's missteps as it is about what the search giant got right.\n\n\"Personally, what I think you should consider Google's comeback, I think it's OpenAI's fumble,\" Jerry Tworek, a former VP of research at OpenAI, said on a Wednesday episode of Ashlee Vance's \"Core Memory\" podcast.\n\nTworek, who spent almost seven years at OpenAI, said earlier this month that he left the startup \"to try to explore types of research that are hard to do at OpenAI.\"\n\nOpenAI CEO Sam Altman declared a \"Code Red\" in December amid increasing competition from Google. The tech giant received wide praise across the industry for the capabilities of its Gemini 3 AI model, which some observers said had surpassed ChatGPT.\n\nWhile declining to detail what he described as OpenAI's missteps, Tworek said that the pioneering AI company should never have lost the lead it established with the release of ChatGPT in 2022.\n\n\"If you are a company that is ahead and has all the advantages that OpenAI has you should always stay ahead,\" he said.\n\nOverall, Tworek said, \"Google did a lot of things right.\"\n\n\"Very clearly, Google started treating seriously at that moment, training large language models and, like, through OpenAI fumbling its lead, they are very, very close now in capability and in terms of models trained,\" he said, adding that the whole industry began to up its investment in AI when OpenAI showed ChatGPT could generate revenue.\n\nAs for OpenAI, Tworek said that the sheer toll of the AI race has led the non-profit-research lab-turned-public-benefit-corporation to place less of an emphasis on risky research that may not yield results. A spokesperson for OpenAI did not respond to Business Insider's request for comment.\n\n\"There are multiple aspects of certain things that are just hard to do in a company that has to compete in an extremely, extremely brutal and demanding race for having the best AI model in the world right now,\" he said. \"One dynamic is there is naturally how much willingness of risks companies are willing to take from the perspective of trying to not fall behind.\"\n\nTworek said \"all major AI companies\" are facing pressure to show user growth and pay for GPUs while simultaneously competing to be the best available model.\n\n\"That does affect somehow your appetite for risk that you are willing to take,\" he said.\n\nDo you work at OpenAI or Google? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com",
    "readingTime": 3,
    "keywords": [
      "openai's missteps",
      "openai",
      "research",
      "model",
      "comeback",
      "fumble",
      "giant",
      "industry",
      "lead",
      "ahead"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-google-ai-race-fumble-gemini-2026-1",
    "thumbnail_url": "https://i.insider.com/69725e9ea645d1188187cf20?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.658Z",
    "topic": "finance"
  },
  {
    "slug": "the-8-fastestgrowing-jobs-in-new-york-city",
    "title": "The 8 fastest-growing jobs in New York City",
    "description": "LinkedIn analyzed user data to identify the fastest-growing jobs in New York City. AI talent has been in demand.",
    "fullText": "In New York City, the fastest path to a new job probably involves AI.\n\nLinkedIn analyzed about three years' worth of user data to determine how jobs are changing in the US, including in New York City.\n\nAI engineers ranked No. 1 in New York, as they did for the US in general and in most of the nine other cities LinkedIn reviewed. Many of the workers stepping into this and other hot AI roles come from related fields such as software engineering and data science, LinkedIn reported.\n\nWhile artificial intelligence gigs dominated the top spots on the list, consultants of various stripes are also in demand in Gotham.\n\n\"Roles like fundraising consultants and strategic advisors are rising too, signaling that companies are doubling down on strategic, revenue-driving work,\" a LinkedIn News post said.\n\nLinkedIn's snapshot of jobs on the rise in New York comes as unemployment in the nation's largest city remains low compared with its historical average — matching the national rate of 4.5% in November.\n\nThe chart below shows the top eight fastest-growing jobs on LinkedIn's new list about the Big Apple.\n\nDemand for AI consultants and strategists — which hold the No. 2 spot on both the New York and US lists — signals that incorporating AI into the workplace will require people whose expertise isn't solely technical, Laura Lorenzetti, a senior director at LinkedIn, recently told Business Insider, referring to the national list.\n\n\"There is also this whole adjacent system of how you implement AI; how you do culture change around AI; how you get people to really adapt and use it,\" she said.\n\nAdopting AI is something more job seekers — especially those who are still early in their careers — are confronting, Keith Spencer, a career expert at Resume Now, recently told Business Insider.\n\nHe said that he hears from young professionals that employers expect them to \"intrinsically know how to use AI to make your role more productive and more efficient.\"",
    "readingTime": 2,
    "keywords": [
      "york city",
      "new york",
      "jobs",
      "list",
      "consultants",
      "strategic",
      "linkedin's",
      "recently",
      "linkedin",
      "roles"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/fastest-growing-jobs-new-york-city-linkedin-ai-engineers-researchers-2026-1",
    "thumbnail_url": "https://i.insider.com/697260e9a645d1188187cf50?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.410Z",
    "topic": "science"
  },
  {
    "slug": "morgan-stanley-says-buy-these-14-stocks-to-play-the-4-themes-that-will-define-markets-in-2026",
    "title": "Morgan Stanley says buy these 14 stocks to play the 4 themes that will define markets in 2026",
    "description": "Morgan Stanley identifies AI adoption, energy trends, societal shifts, and deglobalization as key market drivers in 2026.",
    "fullText": "There are four major themes that will drive markets in 2026, Morgan Stanley says: A multipolar world, technology diffusion, societal shifts, and the future of energy.\n\nLet's get into each, starting with the concept of a multipolar world. For Morgan Stanley, the world is becoming less globalized as governments become more protectionist.\n\n\"It's clear that policymakers globally are implementing policies that will speed up the devolution of the globalization that marked much of the post-Cold War period,\" said Stephen C Byrd, an equity strategist at the bank, in a client note on Thursday. \"Said more simply, policymakers are keen to promote their visions of national and economic security through less open commerce and more local control of supply chains and key technologies.\"\n\nSecond, the bank thinks AI will begin to be adopted more broadly by businesses, helping them boost profits. Stocks will be judged on whether their businesses are incorporating AI enough, MS said.\n\nThird, energy demand has turned a corner thanks to the AI infrastructure buildout. While demand for energy has fallen over the last couple of decades, it's now surging to all-time highs.\n\n\"We expect total US energy consumption to rise 10% over the next decade, reversing decades of declines; by 2030, it should eclipse the prior peak, set in 2007,\" Byrd wrote.\n\nFinally, societal shifts are happening in things like work (thanks to AI), and aging and longevity.\n\n\"We see multiple trends driving broad societal impacts around the world, with effects felt across a surprisingly wide range of industries,\" Byrd wrote. \"The ripple effects of AI-driven employment disruption/evolution, an aging population, changing consumer preferences, the drive for healthy longevity, and challenging demographics across many geographies will continue to matter for governments, economies, and corporates.\"\n\nAs a way to play these trends, the bank highlighted 14 US stocks that its analysts have an \"overweight\" rating on. The stocks are listed below, along with their expected upside to Morgan Stanley's price targets and the theme each stock falls under.\n\nTicker: AMZN\nSector: Consumer Discretionary\nMarket cap: $2.6 trillion\nUpside to price target: 32%\nPrimary theme: Tech Diffusion\n\nTicker: BE\nSector: Industrials\nMarket cap: $3.5 billion\nUpside to price target: 11%\nPrimary theme: Tech Diffusion/Future of Energy\n\nTicker: AVGO\nSector: Information Technology\nMarket cap: $1.6 trillion\nUpside to price target: 35%\nPrimary theme: Tech Diffusion\n\nTicker: CSCO\nSector: Information Technology\nMarket cap: $299.6 billion\nUpside to price target: 21%\nPrimary theme: Tech Diffusion\n\nTicker: LLY\nSector: Health Care\nMarket cap: $928.4 billion\nUpside to price target: 25%\nPrimary theme: Societal Shifts\n\nTicker: EQT\nSector: Energy\nMarket cap: $31.3 billion \nUpside to price target: 38%\nPrimary theme: Future of Energy\n\nTicker: MSFT\nSector: Information Technology\nMarket cap: $3.4 trillion\nUpside to price target: 42%\nPrimary theme: Tech Diffusion\n\nTicker: NEE\nSector: Utilities\nMarket cap: $169.6 billion\nUpside to price target: 16%\nPrimary theme: Tech Diffusion/Future of Energy\n\nTicker: PXED\nSector: Consumer Discretionary\nMarket cap: $1.1 billion\nUpside to price target: 51%\nPrimary theme: Societal Shifts\n\nTicker: ROK\nSector: Industrials\nMarket cap: $47.5 billion\nUpside to price target: 4%\nPrimary theme: Multipolar\n\nTicker: RTX\nSector: Industrials\nMarket cap: $270.9 billion\nUpside to price target: 8%\nPrimary theme: Multipolar\n\nTicker: UNH\nSector: Health Care\nMarket cap: $304.8 billion\nUpside to price target: 21%\nPrimary theme: Societal Shifts\n\nTicker: WMT\nSector: Consumer Staples\nMarket cap: $962.3 billion\nUpside to price target: 13%\nPrimary theme: Tech Diffusion",
    "readingTime": 3,
    "keywords": [
      "health care",
      "consumer discretionary",
      "societal shifts",
      "tech diffusion/future",
      "discretionary market",
      "market cap",
      "target primary",
      "sector industrials",
      "primary theme",
      "technology market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stocks-to-buy-investing-themes-ai-energy-morgan-stanley-2026-2026-1",
    "thumbnail_url": "https://i.insider.com/69726e29e1ba468a96aa886b?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.409Z",
    "topic": "finance"
  },
  {
    "slug": "bond-king-bill-gross-says-the-record-stock-rally-is-at-risk-of-stalling-and-tells-us-what-could-keep-the-party-going",
    "title": "'Bond King' Bill Gross says the record stock rally is at risk of stalling — and tells us what could keep the party going",
    "description": "Bill Gross told Business Insider that lower interest rates, proof that AI boosts productivity, and strong earnings growth would help refuel the rally.",
    "fullText": "Bill Gross says the stock market's record rally is at risk of stalling, and fresh support is needed to keep it going.\n\nThere's been a \"little wobbling\" to start the year, signaling the market's in \"need of a cane to steady its momentum,\" the billionaire investor known as the \"Bond King\" wrote in an investment outlook on Wednesday.\n\nThe AI boom has propelled Big Tech stocks to historic highs, fueling a nearly 80% rise in the S&P 500 over the last three years. But the benchmark index has whipsawed this month between a 2.1% gain at its peak and a 0.8% decline at its trough.\n\n\"Lower interest rates would help, as would continued news that AI actually results in higher productivity, and continuing 15% plus earnings gains,\" Gross told Business Insider by email.\n\nGross, who cofounded PIMCO and grew its flagship Total Return Fund to $270 billion over nearly 30 years, wrote in his outlook that stocks are being shored up by rosy earnings forecasts, which are underpinned by fiscal and monetary stimulus.\n\nHe cautioned, however, that US markets could falter as \"political unrest\" threatens to undermine core capitalist principles such as \"competition and survival of the fittest.\"\n\nGross said that even in the AI space, \"tariffs and government aid\" could lead to the \"unfittest\" surviving in future marketplaces.\n\nA major trend of President Donald Trump's second term has been greater executive intervention in the business world. The federal government has taken equity stakes in corporations such as Intel, imposed sweeping tariffs on foreign imports, and thrown its full weight behind AI companies' infrastructure buildout.\n\nGross also warned in his outlook that high valuations are a concern, noting a version of the Buffett Indicator that compares the S&P 500's price to nominal US GDP is at a \"historic high.\"\n\nWarren Buffett's favorite gauge shows \"froth is visible\" in the market as stock prices are rising faster than GDP, Gross told BI.\n\nThe Wall Street veteran wrote in his outlook that \"productivity, tax rates and geopolitical influences can suggest no need for a cane.\" He noted that some market bulls believe AI has changed the game, so they expect \"no wobbling — just sprinting.\"\n\n\"But I throw my hat in with the old wizard Warren Buffett,\" Gross wrote. \"Valuation casts a shadow over markets in 2026. No crash, just a forward weave requiring a cane, unlike 2025.\"\n\nOther high-profile investors have flagged lofty valuations as a headwind.\n\n\"Just your daily reminder that stocks are expensive,\" Michael Burry of \"The Big Short\" fame said in a X post last week, adding that high prices depress returns.\n\nGMO cofounder Jeremy Grantham echoed Burry on a recent podcast: \"If you want to have the highest market in history, you will have the lowest returns in history going forward.\"",
    "readingTime": 3,
    "keywords": [
      "outlook",
      "cane",
      "stocks",
      "market",
      "gross",
      "stock",
      "market's",
      "wobbling",
      "historic",
      "nearly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bond-king-bill-gross-stock-market-outlook-ai-valuations-government-2026-1",
    "thumbnail_url": "https://i.insider.com/69721289e1ba468a96aa7f10?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.270Z",
    "topic": "finance"
  },
  {
    "slug": "ai-could-be-an-entrylevel-job-killer-or-gen-zs-ticket-to-advancement",
    "title": "AI could be an entry-level job killer — or Gen Z's ticket to advancement",
    "description": "Many young professionals are uneasy about AI automation, but they're leaning into it anyway, new research suggests.",
    "fullText": "As the first cohort to enter the workforce with AI tools at the ready, many Gen Zers are torn.\n\nSome 68% of these young professionals are anxious about AI automation, while 58% use AI tools at least three to four times a week, according to new research from think tank Oliver Wyman Forum. Nearly half of Gen Zers also say AI has already changed the caliber or type of work expected from them.\n\nThe findings, released earlier this week, are based on survey responses from 300,000 consumers and workers collected over the past five years, including 45,000 adult members of Gen Z. The most recent survey was taken last year.\n\nToday's youngest workers are leaning into AI more so than their older counterparts, who are less anxious about the technology and use it less often, the study shows.\n\nCompared with boomers, for example, Gen Zers are 1.7 times more likely to participate in AI training and 2.3 times more likely to report a productivity increase from using AI at work.\n\nYoung workers have good reason to be on high alert. At the World Economic Forum in Davos this week, the CEOs of Google DeepMind and Anthropic each said they're starting to see AI minimize the need for some junior roles at their companies.\n\nAnthropic's chief, Dario Amodei, also said at the conference that he hasn't changed his prediction from May, when he warned that AI could erase half of all entry-level white-collar jobs within the next five years.\n\nMeanwhile, economist Marc Sumerlin said in November that companies may pause hiring young workers as they await the benefits of AI, and that ultimately the technology could lead to fewer jobs for recent graduates. Already, some companies have cited AI directly or indirectly as a reason for layoffs.\n\nThe grim outlook comes as the unemployment rate for recent college graduates in the US remained elevated at 5.3% in the third quarter, according to the latest analysis from the New York Federal Reserve.\n\nSome corporate leaders are more optimistic about AI's impact on Gen Zers' careers.\n\nEarlier this month, Figma CEO Dylan Field said on the podcast \"In Good Company\" that AI skills give young professionals a hiring advantage and that the technology won't wipe out entry-level jobs.\n\nSimilarly, Reid Hoffman, the venture capitalist who cofounded LinkedIn, said in a video posted to his YouTube channel in June that young people should use their familiarity with AI as a selling point when seeking work.\n\nSome Gen Z workers say AI is helping them advance faster in their careers than they likely would have otherwise.\n\nLindsay Grippo, 28, credits the technology for helping her practice big-picture strategic thinking when drafting newsletters, blog posts, and other copy for her editor role at Codeword, a New York-based digital marketing agency. She views the AI's output as if it's from a more junior creative.\n\n\"I'm assessing how well it meets a project's goals, similar to how my manager might review my work,\" she said. \"It is training me to think like a more senior-level creative.\"\n\nKyle Monson, a founding partner at Codeword, said the agency hasn't changed its hiring plans in response to AI, and that young employees like Grippo seem to be among the most proficient users of the technology.\n\nA 46-year-old Gen Xer, Monson sees AI fluency as an advantage for young workers that makes him jealous. When he started his career, he said he had to do a lot of grunt work, such as data entry and note-taking, before he could advance.\n\nAI can now do those kinds of tasks, allowing junior talent to tackle higher-value assignments, which he described as those that require making judgment calls.\n\n\"That's when your career really starts to take off,\" said Monson.",
    "readingTime": 4,
    "keywords": [
      "hasn't changed",
      "gen zers",
      "workers",
      "technology",
      "junior",
      "jobs",
      "hiring",
      "tools",
      "professionals",
      "anxious"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-gen-z-job-killer-or-opportunity-2026-1",
    "thumbnail_url": "https://i.insider.com/69728bc9d3c7faef0eccc4b4?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.270Z",
    "topic": "finance"
  },
  {
    "slug": "experts-warn-of-threat-to-democracy-from-ai-bot-swarms-infesting-social-media",
    "title": "Experts warn of threat to democracy from ‘AI bot swarms’ infesting social media",
    "description": "Misinformation technology could be deployed at scale to disrupt 2028 US presidential election, AI researchers say\nPolitical leaders could soon launch swarms of human-imitating AI agents to reshape public opinion in a way that threatens to undermine democracy, a high profile group of experts in AI and online misinformation has warned.\nThe Nobel peace prize-winning free-speech activist Maria Ressa, and leading AI and social science researchers from Berkeley, Harvard, Oxford, Cambridge and Yale are among a global consortium flagging the new “disruptive threat” posed by hard-to-detect, malicious “AI swarms” infesting social media and messaging channels.\n Continue reading...",
    "fullText": "Misinformation technology could be deployed at scale to disrupt 2028 US presidential election, AI researchers say\n\nPolitical leaders could soon launch swarms of human-imitating AI agents to reshape public opinion in a way that threatens to undermine democracy, a high profile group of experts in AI and online misinformation has warned.\n\nThe Nobel peace prize-winning free-speech activist Maria Ressa, and leading AI and social science researchers from Berkeley, Harvard, Oxford, Cambridge and Yale are among a global consortium flagging the new “disruptive threat” posed by hard-to-detect, malicious “AI swarms” infesting social media and messaging channels.\n\nA would-be autocrat could use such swarms to persuade populations to accept cancelled elections or overturn results, they said, amid predictions the technology could be deployed at scale by the time of the US presidential election in 2028.\n\nThe warnings, published today in Science, come alongside calls for coordinated global action to counter the risk, including “swarm scanners” and watermarked content to counter AI-run misinformation campaigns. Early versions of AI-powered influence operations have been used in the 2024 elections in Taiwan, India and Indonesia.\n\n“A disruptive threat is emerging: swarms of collaborative, malicious AI agents,” the authors said. “These systems are capable of coordinating autonomously, infiltrating communities and fabricating consensus efficiently. By adaptively mimicking human social dynamics, they threaten democracy.”\n\nOne leading expert in propaganda technology, Inga Trauthig, said the adoption of such advanced technology is likely to be slowed by politicians’ reluctance to cede campaign control to AIs. Another cause for skepticism is concern that using such illicit techniques would not be worth the risk, given voters are still more influenced by offline material.\n\nThe experts behind the warning include New York University’s Gary Marcus, a prominent sceptic about the claimed potential of current AI models who calls himself a “generative AI realist”, and Audrey Tang, Taiwan’s first digital minister, who has warned: “Those in the pay of authoritarian forces are undermining electoral processes, weaponizing AI and employing our societal strengths against us.”\n\nOthers include David Garcia, professor for social and behavioural data science at the University of Konstanz, Sander van der Linden, a misinformation expert and director of Cambridge University’s social decision-making lab, and Christopher Summerfield, AI researcher and professor of cognitive neuroscience at Oxford University.\n\nTogether they say political leaders could deploy almost limitless numbers of AIs to masquerade as humans online and precisely infiltrate communities, learn their foibles over time and use increasingly convincing and carefully tailored falsehoods, to change population-wide opinions.\n\nThe threat is being supercharged by advances in AIs’ ability to pick up on the tone and content of discourse. They are increasingly able to mimic human dynamics, for example, by using appropriate slang and posting irregularly to avoid detection. Progress in the development of “agentic” AI also means the ability to autonomously plan and coordinate action.\n\nAs well as operating across social media, they may use messaging channels and even write blogs or use email, depending on which channel the AI thinks best helps achieve an aim, said one of the authors, Daniel Thilo Schroeder, a research scientist at the Sintef research institute in Oslo.\n\n“It’s just frightening how easy these things are to vibe code and just have small bot armies that can actually navigate online social media platforms and email and use these tools,” said Schroeder, who has been simulating swarms in laboratory conditions.\n\nAnother of the authors, Jonas Kunst, professor of communication at the BI Norwegian Business School, said: “If these bots start to evolve into a collective and exchange information to solve a problem – in this case a malicious goal, namely analysing a community and finding a weak spot – then coordination will increase their accuracy and efficiency.\n\n“That is a really serious threat that we predict is going to materialise.”\n\nIn Taiwan, where voters are regularly targeted by Chinese propaganda, often unknowingly, AI bots have been increasing engagement with citizens on Threads and Facebook in the last two to three months, said Puma Shen, a Taiwanese Democratic Progressive Party MP and campaigner against Chinese disinformation.\n\nDuring discussions on political topics the AIs tend to provide “tonnes of information that you cannot verify”, creating “information overload”, Shen said. He said AIs might cite fake articles about how America will abandon Taiwan. Another recent trend is for the AI bots to stress to younger Taiwanese people that the China-Taiwan dispute is very complicated “so do not take sides if you have no knowledge”.\n\n“It’s not telling you that China’s great, but it’s [encouraging them] to be neutral,” Shen told the Guardian. “This is very dangerous, because then you think people like me are radical.”\n\nAmid signs the progress of AI technology is not as rapid as Silicon Valley companies like OpenAI and Anthropic have claimed, the Guardian asked independent AI experts to assess the swarm warnings.\n\n“In the election-heavy year of 2024 the capabilities were there for AI-driven microtargeting but we didn’t see as much of that as scholars predicted,” said Trauthig, an adviser to the International Panel on the Information Environment. “Most political propagandists I interview are still using older technologies and are not at this cutting edge.”\n\n“It isn’t fanciful,” said Michael Wooldridge, professor of the foundations of AI at Oxford University. “I think it is entirely plausible that bad actors will try to mobilise virtual armies of LLM-powered agents to disrupt elections and manipulate public opinion, for example targeting large numbers of individuals on social media and other electronic media. It’s technologically perfectly feasible … the technology has got progressively better and much more accessible.”\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 6,
    "keywords": [
      "guardian app",
      "presidential election",
      "say political",
      "political leaders",
      "disruptive threat",
      "messaging channels",
      "social media",
      "technology",
      "swarms",
      "misinformation"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/22/experts-warn-of-threat-to-democracy-by-ai-bot-swarms-infesting-social-media",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c11e532da1ffe144863064e216ce631a316b6e68/313_0_5149_4120/master/5149.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a3bc91f29cc15d1a31a0ac07a4825178",
    "created_at": "2026-01-23T12:26:13.151Z",
    "topic": "tech"
  },
  {
    "slug": "im-picking-winners-uk-business-secretary-takes-activist-approach-to-economic-growth",
    "title": "‘I’m picking winners’: UK business secretary takes activist approach to economic growth",
    "description": "AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK’s poorer regions\nThe UK business secretary, Peter Kyle, has said he is “betting big” and “picking winners” as the government takes direct stakes in growing businesses to boost economic growth.\nSpeaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain’s prospects, Kyle said ministers were taking an “activist” approach to industrial policy.\n Continue reading...",
    "fullText": "AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK’s poorer regions\n\nThe UK business secretary, Peter Kyle, has said he is “betting big” and “picking winners” as the government takes direct stakes in growing businesses to boost economic growth.\n\nSpeaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain’s prospects, Kyle said ministers were taking an “activist” approach to industrial policy.\n\nThe idea of “picking winners” is closely associated with the Conservative prime minister Margaret Thatcher’s attacks on Labour’s 1970s strategy and her argument that it should be the private sector that decides which companies thrive.\n\nKyle was unabashed about invoking the phrase, arguing a muscular approach could accelerate economic growth. “I want to make sure that the benefits of growth are felt quicker than is currently the case. We’re predicted to grow 1.5% this year. That is not enough.”\n\nHe highlighted the recent decision to allow the £26bn state-owned British Business Bank to buy equity stakes in companies, including the announcement last week of a £25m investment in the energy supplier Octopus’s software spin-off, Kraken.\n\n“The most potential in our economy, in the short and medium term, is scale-up companies,” Kyle said. “I was at Octopus yesterday. They’re now employing 1,500 people in their head office in London alone.\n\n“We can find other companies that are on that kind of trajectory and we can expedite their growth. Then it will create thousands of new jobs, and it will create enormous amounts of wealth, which will recycle through the economy in a really fast way.”\n\n“I am betting big. And I am picking winners,” he added. “It’s more activist. And there will be things that don’t work out, sure. But to have a healthy economy, failure leads to success.”\n\nThis week’s summit in the Swiss ski resort has been overshadowed by Donald Trump’s threat to slap tariffs on eight European countries if they stood in the way of his hopes of annexing Greenland.\n\nThe president backed away from the idea of punitive import taxes on Wednesday evening, after discussions with the secretary general of Nato, Mark Rutte, but several leaders in the Swiss ski resort have said the global economic order has irrevocably changed.\n\nKyle insisted international uncertainty was no reason not to press ahead with Labour’s agenda, highlighting the prospects of a “wave of opportunity that technology and life sciences and all these huge, huge, positive waves of innovation are going to present to us”.\n\nHe said: “If we are too intimidated by the global challenges, if we are too distracted by domestic political to and fro, then we will take our eye off the ball, and we will miss the opportunity of a lifetime, and that means real things to real people.\n\n“There will be kids growing up like me that will not end up becoming successful like I have. It’ll be communities that, at the moment, are poor, and they will never have a hope of becoming prosperous. And I won’t stand for it. I would literally do anything. And if that means betting [on] winners, and getting it wrong from time to time, I’ll take it.”\n\nAnnouncing the beefing up of the government’s “global talent taskforce” in his department, the business secretary suggested that the UK hoped to capitalise on the instability unleashed by Trump’s policies to help it attract jobs and investment.\n\n“I will suck the best talent in from wherever it exists, and talent goes both ways across the Atlantic. And I want to make sure that we have a good balance in that because for too long it’s been in one direction,” he said.\n\nHighlighting the need to attract innovators in particular, Kyle added: “America is being disruptive with tariffs, but America isn’t the most friendly place for scientific endeavour in any case at the moment. Do the maths and add up where we’re going with this. We are going out there and we’re saying: ‘Actually, we have one of the best regulatory environments in the world for life sciences, and across the board.’”\n\nKeir Starmer has taken a tough line on migration – despite pushback from some quarters in the party – promising to reduce it and condemning Boris Johnson’s administration for what the prime minister has called an “open borders experiment”.\n\nBut Kyle said he did not think public scepticism about migration extended to wealthy entrepreneurs. “People are deeply concerned about the immigration system we inherited, and the asylum system, which was overwhelmed, and was poorly administered by the Tories, and therefore broken,” he said.\n\n“I’ve never had anybody that says that people with a lot of money to invest in our country, who want to come here and create jobs, create businesses, shouldn’t be coming to do so.”\n\nHe added: “I have a taskforce that’s doing this, embedded in our global network. We can offer the world’s most talented a bespoke package to come to the UK swiftly, to embed, and then, of course, be part of a funding landscape that is bountiful.”\n\nThe 55-year-old MP for Hove and Portslade has been business secretary since Starmer’s September reshuffle, replacing Jonathan Reynolds, who had done the job for several years in opposition.\n\nKyle is politically close to the health secretary, Wes Streeting – who has been repeatedly mooted as a potential challenger to Starmer – but has been scrupulously loyal to the prime minister in public.\n\nEarlier this week, the business secretary rejected the suggestion that the UK try to negotiate a customs union with the EU, for which Streeting has signalled his support, telling the FT: “I think at the moment it would be foolish to slip towards what would be simple solutions.”\n\nKyle has dyslexia and left his state school “without any usable” qualifications, as he has put it. He made his way to university aged 25, and went on to secure a PhD, then worked in the charity sector before entering politics.\n\nIn his previous job of technology secretary, he was forced to defend his closeness to powerful tech companies. He is a regular user of the chatbot ChatGPT and an evangelist for the opportunities offered by the technology – and is often seen in the casual garb favoured by “tech bros”.\n\nSoon after taking on his current role, Kyle struck a deal with business groups and trade unions to water down the implementation of Labour’s Employment Rights Act, introducing a six-month probation period before the promised “day-tone rights” come into force.\n\nHe has continued to work closely with his successor and friend, Liz Kendall, and said he has insisted the connecting door that blocked the corridor between their two offices be opened up.\n\nAsked whether AI would cause mass layoffs as companies decide they can manage without entry-level staff – a hot topic at Davos – Kyle said: “People are anxious and it’s going to be painful and difficult because change is always painful and difficult.”\n\nKyle said Labour was ready to intervene to ensure the adoption of AI was less painful for poorer communities than the deindustrialisation of the 1980s, which cast a long shadow.\n\nHe said: “Waves of industrial change have always gone badly when governments stand on the sidelines and are not participants. And I will not allow that to happen.\n\n“As tech secretary I was negotiating deals for investment in digital infrastructure, insisting it happened in poorer parts of the country. I’m the gatekeeper into our country for a lot of investors. And if they want to come and benefit from our country, then they can contribute to it as well.”",
    "readingTime": 7,
    "keywords": [
      "swiss ski",
      "ski resort",
      "life sciences",
      "prime minister",
      "picking winners",
      "economic growth",
      "business secretary",
      "peter kyle",
      "create",
      "businesses"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2026/jan/23/peter-kyle-uk-business-secretary-activist-approach-economic-growth",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0b73b15a683725bccb4637d0af048d76299049ca/112_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=eba0a735bf5ba34744e706aab19116fd",
    "created_at": "2026-01-23T12:26:13.135Z",
    "topic": "business"
  },
  {
    "slug": "amazon-planning-job-cuts-next-week-after-axing-14000-due-to-ai-report",
    "title": "Amazon planning job cuts next week after axing 14,000 due to AI: report",
    "description": "The company in October cut some 14,000 white-collar jobs, about half of the 30,000 target first reported by Reuters.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://nypost.com/2026/01/22/business/amazon-planning-thousands-of-job-cuts-next-week-after-axing-14000-due-to-ai-report/",
    "thumbnail_url": "https://nypost.com/wp-content/uploads/sites/2/2026/01/amazon-andy-jassy.jpg?quality=75&strip=all&1769107242&w=1200",
    "created_at": "2026-01-23T06:20:33.494Z",
    "topic": "business"
  },
  {
    "slug": "why-external-ai-reasoning-breaks-articles-12-and-61-by-default",
    "title": "Why External AI Reasoning Breaks Articles 12 and 61 by Default",
    "description": "External AI reasoning already influences regulated decisions. Why Article 12 record-keeping and Article 61 monitoring fail without an evidence layer.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/why-external-ai-reasoning-breaks-articles-12-and-61-by-default/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-23--2026-at-06_49_26-AM.png",
    "created_at": "2026-01-23T06:20:32.327Z",
    "topic": "tech"
  },
  {
    "slug": "vibe-coding-kills-open-source",
    "title": "Vibe Coding Kills Open Source",
    "description": "Generative AI is changing how software is produced and used. In vibe coding, an AI agent builds software by selecting and assembling open-source software (OSS), often without users directly reading documentation, reporting bugs, or otherwise engaging with maintainers. We study the equilibrium effects of vibe coding on the OSS ecosystem. We develop a model with endogenous entry and heterogeneous project quality in which OSS is a scalable input into producing more software. Users choose whether to use OSS directly or through vibe coding.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.15494",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-23T06:20:32.202Z",
    "topic": "tech"
  },
  {
    "slug": "openai-is-making-more-than-1-billion-a-month-from-something-that-has-nothing-to-do-with-chatgpt",
    "title": "OpenAI is making more than $1 billion a month from something that has nothing to do with ChatGPT",
    "description": "Sam Altman says OpenAI added more than $1 billion in annual recurring revenue in a month, driven by its API business rather than ChatGPT.",
    "fullText": "OpenAI has pulled in a billion-dollar month from something other than ChatGPT.\n\nSam Altman said in a post on X on Thursday that OpenAI added more than $1 billion in annual recurring revenue in the past month \"just from our API business.\"\n\n\"People think of us mostly as ChatGPT, but the API team is doing amazing work!\" the OpenAI CEO wrote.\n\nOpenAI's API enables other companies and developers to embed its models into their own products, from internal productivity software to coding tools.\n\nMany of Silicon Valley's high-profile startups rely on OpenAI's models as core infrastructure. Perplexity uses OpenAI's models to power parts of its AI search and answer engine. Harvey, one of the fastest-growing legal tech startups, is built on OpenAI's models to assist lawyers with research and drafting.\n\nAltman's comments underscore how OpenAI's infrastructure business is emerging as a key growth engine, even as the company faces massive costs for computing power and data centers.\n\nThose pressures have pushed OpenAI to look beyond consumer subscriptions.\n\nLast week, the company said it is gearing up to test ads inside ChatGPT as it faces about $1.4 trillion in spending commitments over the coming years.\n\nIt's a notable shift for a company that once treated ads as taboo. Less than two years ago, Altman said advertising was a \"last resort.\"\n\n\"Ads plus AI is sort of uniquely unsettling to me,\" Altman said during an event at Harvard University in May 2024. \"I kind of think of ads as a last resort for us for a business model.\"\n\nSince then, Altman has struck a more open tone. In June, he said on OpenAI's podcast that he wasn't \"totally against\" ads, though he stressed it would need to be approached carefully.\n\nEarlier this week, OpenAI's chief financial officer, Sarah Friar, raised the idea of \"licensing models\" that would let the company share in downstream sales if a customer's product succeeds.\n\n\"Let's say in drug discovery, if we licensed our technology, you have a breakthrough. The drug takes off, and we get a licensed portion of all its sales,\" Friar said in an episode of \"The OpenAI Podcast\" published Monday.",
    "readingTime": 2,
    "keywords": [
      "openai's models",
      "business",
      "startups",
      "infrastructure",
      "engine",
      "faces",
      "resort",
      "sales",
      "drug",
      "licensed"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-1-billion-a-month-api-business-chatgpt-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/6972e427e1ba468a96aa91d7?width=800&format=jpeg",
    "created_at": "2026-01-23T06:20:31.103Z",
    "topic": "finance"
  },
  {
    "slug": "what-will-tech-jobs-look-like-in-2026",
    "title": "What will tech jobs look like in 2026?",
    "description": "Here’s a roundup of research and predictions for tech workers amid the AI revolution.",
    "fullText": "The tech job market in 2026 is being built on contradictions.\n\nCompanies are laying off staff, insisting artificial intelligence will “do more with less” — yet they haven’t found ways to deploy AI at scale. Recruiters say entry-level pathways are narrowing, but critical roles remain hard to fill.\n\nEven as headlines scream “automation,” the day-to-day reality is messier: Hybrid work is still a dealbreaker, job titles are splintering into new specialties, and workers are being asked to produce more output with fewer resources.\n\nRest of World reviewed recent research on tech job trends in 2026\n\nDeloitte’s 2025 Emerging Technology Trends study noted that while 30% of surveyed organizations are exploring agentic options and 38% are piloting solutions, only 14% have solutions that are ready to be deployed. A mere 11% are actively using these systems in production. Furthermore, 42% of organizations report they are still developing their agentic strategy road map, with 35% having no formal strategy at all.\n\nWhile most human workers are generally comfortable with predictable, rule-based robots, physical AI systems that learn and adapt introduce new uncertainties, especially worries about job displacement. Experts predict, however, that most roles will evolve toward collaboration rather than replacement.\n\nThe goal is to create environments where robots handle repetitive or dangerous tasks while humans focus on creative problem-solving and complex decision-making.\n\nThe best workers want hybrid or remote roles. Yet more companies are demanding full-time in-office attendance. It’s not making hiring any easier.\n\nThe battle lines have been drawn. Companies are demanding people return to the office full-time while workers dig in their heels, insisting they want remote or hybrid work options.\n\nCompanies are demanding people return to office while workers dig in their heels”\n\nAccording to the Korn Ferry report, 52% of talent acquisition leaders say office mandates hinder recruitment, while 72% find remote roles easier to fill.\n\nBusiness leaders might think this is fine right now, but in roles with chronic skills shortages, it’ll rapidly be clear that it’s not fine at all.\n\nIf your employer brand isn’t strong enough to overcome the office requirement, you’ll end up paying premium salaries to attract people who would otherwise work elsewhere. Or worse, you’ll just be filling seats — settling for whoever is willing to show up, not the talent who will move your business forward.\n\nTech recruitment platform Built In\n\nAs companies seek specialists, the emergence of new roles with novel job titles and nuanced skill requirements will be a feature of 2026. As the economy picks up steam, companies will narrow their focus and drift away from broad-spectrum roles with catch-all titles like “software engineer” and “data scientist” toward more tailored, task-specific job titles.\n\nNavigating the future of work in tech this year will involve companies focused more at the intersection of AI-workflow integration, governance, and impact.",
    "readingTime": 3,
    "keywords": [
      "workers dig",
      "job titles",
      "remote roles",
      "tech job",
      "hybrid",
      "demanding",
      "insisting",
      "fill",
      "organizations",
      "agentic"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/tech-jobs-2026-ai-layoffs-hybrid-work/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/TechJobs-Header-2.jpg",
    "created_at": "2026-01-23T06:20:30.799Z",
    "topic": "tech"
  },
  {
    "slug": "stocks-climb-after-strong-data-as-ai-winners-smallcaps-lead",
    "title": "Stocks Climb After Strong Data as AI Winners, Small-Caps Lead",
    "description": "US stocks clawed back most of this week’s losses with the strongest two-day run in two months after data signaling a resilient economy, President Donald Trump’s retreat on tariff threats and artificial intelligence updates whetted traders’ appetite for risky bets.",
    "fullText": "MarketsBy Natalia KniazhevichSaveUS stocks clawed back most of this week’s losses with the strongest two-day run in two months after data signaling a resilient economy, President Donald Trump’s retreat on tariff threats and artificial intelligence updates whetted traders’ appetite for risky bets.The S&P 500 rose 0.6%. The Nasdaq 100 gained 0.8% as chipmakers and AI-linked names led market gains. The Russell 2000 Index rose 0.8%, outperforming the broader benchmark a 14th straight session, the longest stretch of wins since May 1996. Intel Corp. shares fell around 5% in late trading after a disappointing sales forecast, the stock had climbed 47% since the start of the month.",
    "readingTime": 1,
    "keywords": [
      "rose"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-22/stocks-buoyed-by-ai-winners-data-as-geopolitical-risks-fade",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iQ.2ZkT2N5nY/v0/1200x800.jpg",
    "created_at": "2026-01-23T00:59:23.258Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-ai-stocks-with-killer-apps-are-winning-investor-favor",
    "title": "China’s AI Stocks With Killer Apps are Winning Investor Favor",
    "description": "As China’s homegrown artificial intelligence boom enters its second year, investors are piling into shares of companies with killer apps in a hunt for earnings that justify surging valuations.",
    "fullText": "MarketsTechnologyBy Jeanny YuSaveAs China’s homegrown artificial intelligence boom enters its second year, investors are piling into shares of companies with killer apps in a hunt for earnings that justify surging valuations. Kuaishou Technology has seen its stock climb 24% so far this year as its AI video-generation tool Kling gains traction with global users. Alibaba Health Information Technology Ltd. shares have surged 33%, helped by enthusiasm for its AI offerings including a new chatbot aimed at helping doctors diagnose patients.",
    "readingTime": 1,
    "keywords": [
      "shares",
      "technology"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2026-01-22/china-s-ai-stocks-with-killer-apps-are-winning-investor-favor",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iLtpy8gcvgBQ/v0/1200x800.jpg",
    "created_at": "2026-01-23T00:59:21.808Z",
    "topic": "finance"
  },
  {
    "slug": "meet-the-alaska-student-arrested-for-eating-an-ai-art-exhibit",
    "title": "Meet the Alaska Student Arrested for Eating an AI Art Exhibit",
    "description": "Colin...",
    "fullText": "Europe’s governing soccer body saves a pitch in the West Bank—but is it only because the Swiss Parliament is threatening to pull its tax exemption over its inclusion of Israel?\n\nA Martin Luther King Jr. Day sermon by the Rev. Canon Dr. Kelly Brown Douglas.\n\nMourning for Renee Nicole Good, the singer decried the Trump administration and the threat to freedom posed by “heavily armed masked federal troops invading an American city.”\n\nA new history explores the political limits as well as possibilities of freedom of speech.\n\nBooks & the Arts\n\n /\n\n David Cole\n\nParents’-rights crusaders seeking to impose their Christian nationalist vision on the United States took their playbook from South America.\n\nFeature\n\n /\n\n Elle Hardy\n\nThe white college student supported Black voters in segregated Alabama, and began documenting the front lines of the voting rights fight, which locals continue to disregard.\n\nQ&A\n\n /\n\n Alexandra Marvar",
    "readingTime": 1,
    "keywords": [
      "freedom"
    ],
    "qualityScore": 0.65,
    "link": "https://www.thenation.com/article/society/alaska-student-arrested-eating-ai-art-exhibit/",
    "thumbnail_url": "https://www.thenation.com/wp-content/uploads/2026/01/AI-Art.jpg",
    "created_at": "2026-01-23T00:59:17.607Z",
    "topic": "politic"
  },
  {
    "slug": "elon-musk-warns-the-us-could-soon-be-producing-more-chips-than-we-can-turn-on-and-china-doesnt-have-the-same-issue",
    "title": "Elon Musk warns the U.S. could soon be producing more chips than we can turn on. And China doesn’t have the same issue",
    "description": "“The limiting factor for AI deployment is fundamentally electrical power,” Musk said at the World Economic Forum on Thursday.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/22/elon-musk-ai-data-center-chips-electrical-power-china-world-economic-forum/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2256969963-e1769101573582.jpg?resize=1200,600",
    "created_at": "2026-01-23T00:59:16.393Z",
    "topic": "business"
  },
  {
    "slug": "elon-musk-on-greenland-ai-in-space-and-the-future-of-robots",
    "title": "Elon Musk on Greenland, AI in space and the future of robots",
    "description": "Elon Musk made his first-ever appearance at Davos where he joked about Greenland, and discussed the future of AI and humanoid robots.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/musk-on-greenland-ai-in-space-and-future-of-robots-2026-1",
    "thumbnail_url": "https://i.insider.com/6972846cd3c7faef0eccc398?width=1200&format=jpeg",
    "created_at": "2026-01-23T00:59:15.725Z",
    "topic": "finance"
  },
  {
    "slug": "kona-energybased-models-ebms-for-ai-reasoning",
    "title": "Kona: Energy-Based Models (EBMs) for AI Reasoning",
    "description": "Kona delivers AI reasoning via Energy-Based Models (EBMs). It provides deterministic, verifiable intelligence for critical systems—a fundamental shift from probabilistic LLMs.",
    "fullText": "Kona is Logical Intelligence’s core Energy-Based Model and the foundation of everything we build. It is not a chatbot, assistant, or generator. Language models are good at interaction and expression. They help people ask questions and explore ideas. But when software controls physical assets or financial risk, something else has to decide what actions are allowed before they happen.\n\nLogical Intelligence builds that layer.\n\nKona is a reasoning system designed to sit beneath modern AI stacks, evaluating what is valid, safe, and permissible across all possible states of a system. It does not predict likely outcomes. It enforces constraints. It replaces trust with proof and makes certification, audit, and deployment possible where failure is not an option.\n\nAleph delivers verified reasoning today. Kona turns that capability into a full-scale reasoning engine for the next generation of infrastructure, automation, and autonomous systems.\n\nKona 1.0 is Logical Intelligence’s core Energy‑Based Model and the foundation of everything we build. It is not a chatbot, assistant, or generator. Language models are good at interaction and expression. They help people ask questions and explore ideas. But when software controls physical assets or financial risk, something else has to decide what actions are allowed before they happen.\n\nKona is a reasoning system designed to sit beneath modern AI stacks, evaluating what is valid, safe, and permissible across all possible states of a system. It does not predict likely outcomes. It enforces constraints. It replaces trust with proof and makes certification, audit, and deployment possible where failure is not an option.\n\nAleph delivers verified reasoning today. Kona turns that capability into a full-scale reasoning engine for the next generation of infrastructure, automation, and autonomous systems.",
    "readingTime": 2,
    "keywords": [
      "intelligence’s core",
      "generator language",
      "language models",
      "option aleph",
      "aleph delivers",
      "chatbot assistant",
      "explore ideas",
      "software controls",
      "controls physical",
      "physical assets"
    ],
    "qualityScore": 0.95,
    "link": "https://logicalintelligence.com/kona-ebms-energy-based-models",
    "thumbnail_url": "https://framerusercontent.com/assets/9Vg7VFZj56wZ6SmCOwhJtsg.png",
    "created_at": "2026-01-23T00:59:15.314Z",
    "topic": "tech"
  },
  {
    "slug": "this-script-removes-the-ai-features-from-chrome-edge-and-firefox",
    "title": "This Script Removes the AI Features From Chrome, Edge, and Firefox",
    "description": "This script disables AI and other annoyances in all major browsers.",
    "fullText": "Tech companies are getting increasingly pushy with their large language models—prominent buttons for these AI features coat every surface designers can think of, including in three of the most prominent browsers: Chrome, Edge, and Firefox.\n\nIf you want these AI features to go away, and stay away, there's a script for that. JustTheBrowser is a free and open source tool from developer and tech blogger Corbin Davenport that removes AI features, telemetry data reporting, sponsored content, product integrations, and other annoyances from Chrome, Firefox, and Microsoft Edge. Basically, you can run this once and never think about these features again.\n\nTo get started, head to the JustTheBrowser homepage. There are scripts to copy (which I'm not going to include here in case they change in the future).\n\nWindows users will need to run PowerShell as an admin—the easiest way to do that is by right-clicking PowerShell in the start menu and clicking \"Run as administrator.\" There is a different script for Mac and Linux users—that one just needs to be copied into a regular Terminal.\n\nEither way, you will be asked which browser you'd like to update the settings for—just hit the number corresponding to what you want to do.\n\nIn my testing, the process was very simple on Windows—just click the number and the script will do its thing. On macOS, I needed to follow a few instructions to enable a configuration policy in the Settings app, something that only took a couple of clicks. After that, Chrome was free of any and all references to AI.\n\nA number of other features were also gone, including those annoying prompts to switch my default browser.\n\nThe way this works is kind of interesting: it uses features intended for large organizations. Basically all major browsers allow for group settings, which is how IT departments control what you can and can't do with your browser. Among these settings are ones to disable AI features.\n\nIt's an interesting workaround, and hopefully one that keeps working. There is always a chance that browser companies make it so even IT departments can't disable AI features, at which point we'll all need to find a new solution (or switch to an alternative browser).",
    "readingTime": 2,
    "keywords": [
      "features",
      "browser",
      "settings",
      "chrome",
      "script",
      "tech",
      "browsers",
      "edge",
      "firefox",
      "away"
    ],
    "qualityScore": 0.9,
    "link": "https://lifehacker.com/tech/script-removes-ai-features-from-chrome-edge-firefox?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFKGXVMPEQY0K2EQ8ZCJG6WD/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-23T00:59:14.346Z",
    "topic": "tech"
  },
  {
    "slug": "scarlett-johansson-and-cate-blanchett-back-campaign-accusing-ai-firms-of-theft",
    "title": "Scarlett Johansson and Cate Blanchett back campaign accusing AI firms of theft",
    "description": "Hundreds of writers, musicians and performers urge licensing deals instead of scraping creative work\nScarlett Johansson, Cate Blanchett, REM and Jodi Picoult are among hundreds of Hollywood stars, musicians and authors backing a new campaign accusing AI companies of “theft” of their work.\nThe “Stealing Isn’t Innovation” drive launched on Thursday with the support of approximately 800 creative professionals and bands. The campaign includes a statement accusing tech firms of using American creators’ work to “build AI platforms without authorisation or regard for copyright law”.\n Continue reading...",
    "fullText": "Hundreds of writers, musicians and performers urge licensing deals instead of scraping creative work\n\nScarlett Johansson, Cate Blanchett, REM and Jodi Picoult are among hundreds of Hollywood stars, musicians and authors backing a new campaign accusing AI companies of “theft” of their work.\n\nThe “Stealing Isn’t Innovation” drive launched on Thursday with the support of approximately 800 creative professionals and bands. The campaign includes a statement accusing tech firms of using American creators’ work to “build AI platforms without authorisation or regard for copyright law”.\n\nIt adds: “Artists, writers, and creators of all kinds are banding together with a simple message: Stealing our work is not innovation. It’s not progress. It’s theft – plain and simple.”\n\nThe statement urges AI companies to pursue licensing deals and partnerships with the creative industries and acknowledges firms that have taken that route. OpenAI, the developer of ChatGPT, has signed deals with content owners including Disney and the Guardian, while Warner Music Group has struck a licensing deal with AI music generator Suno.\n\nHowever, copyright remains one of the most contentious issues within AI, because the models that power chatbots like ChatGPT or image generators like Grok Imagine rely on vast amounts of data taken from the open web in order to help create their responses. Creative professionals argue that tech firms should seek their permission before using such material – and that they should receive a payment if they give their consent.\n\nOpenAI, and other AI firms, have argued that using material available online is “fair use”, a US legal doctrine that allows use of copyright-protected work without the owner’s permission in certain circumstances. As of last year, dozens of lawsuits had been launched in the US over the AI and copyright issue.\n\nJohansson was dragged into the AI debate in 2024 after OpenAI’s voice assistant used her vocal likeness, prompting the actor say she was “shocked, angered and in disbelief” by the move. OpenAI subsequently removed the voice from ChatGPT.\n\nOther signatories to the statement include actor Joseph Gordon-Levitt, Breaking Bad creator Vince Gilligan and singer Cyndi Lauper. Last year Gilligan described AI as the “world’s most expensive and energy-intensive plagiarism machine”.\n\nThe “Stealing Isn’t Innovation” push has been organised by the Human Artistry Campaign, whose backers include the Writers Guild of America, the Recording Industry Association of America and the actors’ trade union SAG-AFTRA, which went on strike in 2023, partly over the use of AI.\n\nIn the UK, the government has been under fire for proposing that AI firms should be allowed to use copyright-protected work without first seeking artists’ permission, unless they signal that they wish to “opt out” of the process. The technology secretary, Liz Kendall, said this month that the government was seeking a “reset” on these plans via an official review due to be published in March.",
    "readingTime": 3,
    "keywords": [
      "stealing isn’t",
      "isn’t innovation",
      "creative professionals",
      "licensing deals",
      "tech firms",
      "the stealing isn’t innovation",
      "writers",
      "statement",
      "without",
      "copyright"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/22/scarlett-johansson-and-cate-blanchett-back-campaign-accusing-ai-firms-of-theft",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0ec6ae0c43961da5c432045af3e5b8d5e5bcf60a/110_0_2779_2224/master/2779.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ade5f2519a44a382d39f5e5fbc9a5b9d",
    "created_at": "2026-01-22T18:18:47.903Z",
    "topic": "tech"
  },
  {
    "slug": "grok-ai-generated-about-3m-sexualised-images-in-11-days-study-finds",
    "title": "Grok AI generated about 3m sexualised images in 11 days, study finds",
    "description": "Estimate made by Center for Countering Digital Hate after Elon Musk’s AI image generation tool sparked outrage\nGrok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appear to depict children, according to researchers who said it “became an industrial-scale machine for the production of sexual abuse material”.\nThe estimate has been made by the Center for Countering Digital Hate (CCDH) after Elon Musk’s AI image generation tool sparked international outrage when it allowed users to upload photographs of strangers and celebrities, digitally strip them to their underwear or into bikinis, put them in provocative poses and post the images on X.\n Continue reading...",
    "fullText": "Estimate made by Center for Countering Digital Hate after Elon Musk’s AI image generation tool sparked outrage\n\nGrok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appear to depict children, according to researchers who said it “became an industrial-scale machine for the production of sexual abuse material”.\n\nThe estimate has been made by the Center for Countering Digital Hate (CCDH) after Elon Musk’s AI image generation tool sparked international outrage when it allowed users to upload photographs of strangers and celebrities, digitally strip them to their underwear or into bikinis, put them in provocative poses and post the images on X.\n\nThe trend went viral over the new year, peaking on 2 January with 199,612 individual requests, according to analysis conducted by Peryton Intelligence, a digital intelligence company specialising in online hate.\n\nA fuller assessment of the output from the feature, from its launch on 29 December 2025 until 8 January 2026, has now been made by the CCDH. It suggests the impact of the technology may have been broader than previously thought. Public figures identified in sexualised images it analysed include Selena Gomez, Taylor Swift, Billie Eilish, Ariana Grande, Ice Spice, Nicki Minaj, Christina Hendricks, Millie Bobby Brown, the Swedish deputy prime minister Ebba Busch, and the former US vice-president Kamala Harris.\n\nThe feature was restricted to paid users on 9 January and further restrictions followed after the UK prime minister, Keir Starmer, called the situation “disgusting” and “shameful”. Other countries, including Indonesia and Malaysia, announced blocks on the AI tool.\n\nCCDH estimated that over the 11-day period, Grok was helping create sexualised images of children every 41 seconds. These included a selfie uploaded by a schoolgirl undressed by Grok, turning a “before school selfie” into an image of her in a bikini.\n\n“What we found was clear and disturbing: in that period Grok became an industrial-scale machine for the production of sexual abuse material,” said Imran Ahmed, CCDH’s chief executive. “Stripping a woman without their permission is sexual abuse. Throughout that period Elon was hyping the product even when it was clear to the world it was being used in this way. What Elon was ginning up was controversy, eyeballs, engagement and users. It was deeply disturbing.”\n\nHe added: “This has become a standard playbook for Silicon Valley, and in particular for social media and AI platforms. The incentives are all misaligned. They profit from this outrage. It’s not about Musk personally. This is about a system [with] perverse incentives and no minimum safeguards prescribed in law. And until regulators and lawmakers do their jobs and create a minimum expectation of safety, this will continue to happen.”\n\nX announced it had stopped its Grok feature from editing pictures of real people to show them in revealing clothes, including for premium subscribers, on 14 January.\n\nX referred to its statement from last week, which said: “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, non-consensual nudity, and unwanted sexual content.\n\n“We take action to remove high-priority violative content, including child sexual abuse material and non-consensual nudity, taking appropriate action against accounts that violate our X rules. We also report accounts seeking child sexual exploitation materials to law enforcement authorities as necessary.”",
    "readingTime": 3,
    "keywords": [
      "countering digital",
      "elon musk’s",
      "digital hate",
      "period grok",
      "industrial-scale machine",
      "prime minister",
      "non-consensual nudity",
      "generation tool",
      "tool sparked",
      "sexualised images"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/22/grok-ai-generated-millions-sexualised-images-in-month-research-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/5f3c249df73ac96180a47714b78f8e6b78ac0407/542_0_5417_4335/master/5417.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0a787088a931a701dd945b2b8c617e65",
    "created_at": "2026-01-22T18:18:47.901Z",
    "topic": "tech"
  },
  {
    "slug": "livekit-raises-100m-to-build-the-backbone-for-voice-ai",
    "title": "LiveKit raises $100M to build the backbone for voice AI",
    "description": "LiveKit raised $100M at a $1B valuation from Index Ventures, Salesforce Ventures, Hanabi Capital, Altimeter, and Redpoint Ventures.",
    "fullText": "Today, I get the privilege of announcing LiveKit’s Series C. With this funding round, we’ve reached an important milestone: a $1 billion valuation. Index Ventures is leading the $100M investment, joined by Salesforce Ventures, Hanabi Capital, and our longtime supporters Altimeter and Redpoint Ventures.\n\nTo our customers, users, OSS contributors, investors, and core team: thank you, we wouldn’t be here without you.\n\nVoice is the most natural interface we have—it’s the one we use with each other every day. And for the first time in history, we can interact with computers in the same way.\n\nWhen we announced our Series B in April 2025, voice AI had gone from a feature inside ChatGPT to thousands of applications across financial services, healthcare, retail, customer support, education, and robotics. Startups were building voice agents that could perform tasks like processing claims, tutoring students, triaging patients, supporting customers, and interviewing candidates.\n\nToday, large enterprises are evaluating and building voice agents to automate workflows, improve customer experiences, and unlock new revenue. While many of these use cases are still in the proof-of-concept stage, some are moving into production and operating at real scale: Agentforce voice agents run customer support for the world's top brands and Tesla uses voice AI for sales, support, insurance, and roadside assistance.\n\nWe anticipate 2026 will be the year voice AI will be broadly deployed across thousands of use cases around the world.\n\nBut there's still a lot to build to support this new paradigm of computing.\n\nVoice AI applications are not like web applications. The protocol underlying every web application is HTTP, which was designed for reliably moving text data between computers. Every HTTP request is independent and stateless, meaning that a web backend by default has no historic information. When needed, web applications load state from a database, which may take additional time.\n\nFor an application you can talk to like a person, traditional web infrastructure breaks.\n\nVoice AI applications are realtime and stateful. A conversation with a voice agent might last a few minutes or a few hours and the agent is continuously listening, thinking, and responding while maintaining context across the entire session.\n\nThat shift at the application layer, from using a keyboard and mouse to speaking with a voice agent, changes everything underneath. You can’t build your application the same way. You can’t test it the same way. You can’t deploy and run it the same way. You can’t monitor it the same way. The whole stack has to be rebuilt for realtime, stateful applications with human-native interfaces.\n\nWe’re building that stack. Every piece of it, designed to work together seamlessly.\n\nAgents are still applications, and like all applications, they go through a set of stages from design to production:\n\nLike web applications, voice AI applications have a frontend and a backend. To build the former, LiveKit offers client SDKs across every single platform.\n\nOn the backend, LiveKit Agents—modeled from our work on ChatGPT Voice Mode and downloaded over 1M times a month—gives you full programmatic control over agent orchestration, access to hundreds of AI model integrations, and automatically handles conversational dynamics like turn detection and interruptions.\n\nNot everyone wants to start in code though. Sometimes it’s preferable to quickly start from a template, tune your prompts or sketch out a workflow, and share a link with friends or colleagues—for that vibe, we recently launched Agent Builder.\n\nAI models are stochastic. Given the same input, they don't produce the same output, thus you can't write simple assertions against non-deterministic code. You have to test these systems statistically, the same way we evaluate human performance through exams and interviews.\n\nLiveKit Agents now includes support for writing unit tests against your agent code, and you can wire up traces to OpenTelemetry for deeper analysis.\n\nFor simulation (the AI version of an integration test), where a voice agent calls another voice agent and runs through thousands of conversations permuting prompt, language, and voice attributes to build statistical confidence in agent behavior, we've partnered with Bluejay, Hamming, and Roark. In parallel, we’re also exploring how to integrate simulation more directly into LiveKit’s platform.\n\nWhile deploying a web application and voice agent both involve pushing code to the cloud, the similarities end there. Your user might speak with an agent for an indeterminate amount of time and there may be unplanned spikes in demand across your user base. This requires a different approach for capacity, connection, and change management, load balancing, and failover. Earlier this year, we released serverless agents to make agent deployment turnkey for builders everywhere.\n\nVoice AI applications also require new network infrastructure, purpose-built for transporting voice data with as low latency as possible between your agent and wherever your users are located. We’ve built out a global network of data centers that act as a unified fabric optimized for routing voice and video data. Today, our network handles billions of calls a year between voice agents and users, across web and mobile applications and phone calls.\n\nRecently, we’ve partnered with telephony carriers around the world to link LiveKit’s network directly to the PSTN. This enables us to deliver the lowest latency experience when speaking to a voice agent over the phone.\n\nOnce your voice agent is on a live call, there are usually multiple models strung together for every conversational turn: speech-to-text, turn and interruption detection, LLM, and text-to-speech. These models may be running on the same server or data center as your agent code, but most of the time they’re accessed by your agent via cloud API from a model provider. Model providers host their models in different regions around the world, potentially far away from your agent. Sometimes a provider’s service gets backlogged and inference requests queue up, other times a provider’s service goes down. These orchestration challenges can negatively affect end-to-end latency, making agent conversations choppy and unreliable.\n\nLiveKit Inference abstracts away much of this complexity. The same system we built to monitor and route voice in real time can also route inference between model providers. We’ve also started to host our models across our data centers so they’re colocated with the agents you deploy to LiveKit Cloud.\n\nUntil we launched Agent Observability, there was no Datadog-equivalent built for voice agents—no way to truly understand how an agent and user are interacting on a live call. How long did it take for the agent to answer the call? What did the agent “hear” when the user specified the prescription drug they’ve been taking? Did the user press the “0” to speak to a human operator? What was the average turn latency across the call? Did the agent invoke the correct tool to schedule an appointment for the user?\n\nAnswering these questions through session replays, traces, time-aligned transcripts of conversations, and error logs is the critical final phase of the lifecycle. As a developer, armed with these learnings and insights, you can then go back to the Build step, modify your agent code, and run through another iteration.\n\nVoice is one of the biggest paradigm shifts in computing. It’s still early—and it starts where voice is already the interface: phone calls, cars, and smart speakers.\n\nOver the next few years, as new form factors emerge and models get better at turn-taking, tool use, and reliability, voice-native applications will move from novelty to default. Software will feel less like something you navigate, and more like something you delegate to.\n\nLiveKit is building the development stack and runtime between foundation models and end-user applications. Our goal is simple: make building and scaling voice AI as easy as building and scaling on the web.\n\nThis round helps us move faster. We’re excited to build the voice-driven era of computing with our customers, community, and partners.",
    "readingTime": 7,
    "keywords": [
      "provider’s service",
      "model providers",
      "web application",
      "launched agent",
      "web applications",
      "agent code",
      "voice ai",
      "voice agents",
      "across",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://blog.livekit.io/livekit-series-c/",
    "thumbnail_url": "https://blog.livekit.io/content/images/size/w1200/2026/01/x-image-4.png",
    "created_at": "2026-01-22T18:18:46.216Z",
    "topic": "tech"
  },
  {
    "slug": "neuralvoid-block-ai-telemetry-from-copilot-grammarly-adobe",
    "title": "NeuralVoid – Block AI Telemetry from Copilot, Grammarly, Adobe",
    "description": "System-Level AI Telemetry Blocker for Windows. Contribute to XORD-AI/NeuralVoid development by creating an account on GitHub.",
    "fullText": "XORD-AI\n\n /\n\n NeuralVoid\n\n Public\n\n System-Level AI Telemetry Blocker for Windows\n\n xord.io/intelligence/neural-void-xord-ai-blocker.html\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n XORD-AI/NeuralVoid",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/XORD-AI/NeuralVoid",
    "thumbnail_url": "https://opengraph.githubassets.com/d0efb578292648299e91c3fadb2f3465d8fb82a2c8aa10b2b1ae3c392fe60437/XORD-AI/NeuralVoid",
    "created_at": "2026-01-22T18:18:45.966Z",
    "topic": "tech"
  },
  {
    "slug": "why-wall-streets-most-dataobsessed-investors-are-taking-it-slowly-with-generative-ai",
    "title": "Why Wall Street's most data-obsessed investors are taking it slowly with generative AI",
    "description": "More than half of respondents to a Bloomberg survey have \"not yet begun their generative AI journey.\"",
    "fullText": "Generative AI hasn't yet won over the quants.\n\nA majority of people running systematic trading strategies at top-tier asset managers have \"not yet begun their generative AI journey,\" according to a new Bloomberg survey.\n\nThe data giant interviewed 151 quants between April and November last year to determine how they've integrated generative AI tools into their investment research process. While this section of the investing world has used machine-learning techniques for years, generative AI has not yet broken through. Most of the respondents, 54%, do not incorporate it into their workflows, the survey found.\n\nThis matches the vibe Business Insider reported on in October, where quants at a London-based conference were skeptical of the technology's ability to beat the market and add value to their investing processes. A UBS executive, for instance, said that AI is not going to help win the \"alpha war.\"\n\nBloomberg's rationale for the slow adoption is focused on data formatting and structure.\n\nAngana Jacob, the firm's global head of research data, said quants require their data to be cleaned and structured a specific way because of the complex systems their strategies run and the amount of capital at stake if there is an error.\n\n\"They're working in a very controlled research environment, models need to be explainable, models need to be repeatable,\" said Jacob, in an interview with Business Insider.\n\nThe work required to get the datasets to a point where they can be used is \"unglamorous,\" but \"foundational,\" Jacob said. Her team is creating data products for quants that might increase AI adoption among them, because, she said, the enthusiasm is high for what AI can do once the data catches up. The lack of widespread use in the investing process is more a sign of the diligence of these players.\n\n\"It's a good thing, it shows their caution,\" she said.\n\nBloomberg is not the only data player that has identified this issue. Former Point72 data executive Kirk McKeown's startup, Carbon Arc, is also focused on structuring datasets for easier ingestion into artificial intelligence models.",
    "readingTime": 2,
    "keywords": [
      "quants",
      "research",
      "investing",
      "models",
      "strategies",
      "bloomberg",
      "survey",
      "process",
      "executive",
      "adoption"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/quants-arent-using-ai-to-invest-bloomberg-survey-2026-1",
    "thumbnail_url": "https://i.insider.com/697155bdd3c7faef0eccb349?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.118Z",
    "topic": "finance"
  },
  {
    "slug": "citadels-ceo-on-the-ai-boom-is-it-hype-of-course",
    "title": "Citadel's CEO on the AI boom: 'Is it hype? Of course'",
    "description": "Citadel CEO Ken Griffin says AI has shifted power to tech teams, but today's tools often fall short, even as massive data-center spending accelerates.",
    "fullText": "Hedge fund tycoon Ken Griffin has a blunt message for anyone expecting artificial intelligence to instantly rewrite the global economy: the hype is real — and it's there to justify enormous spending.\n\nSpeaking at the World Economic Forum in Davos on Wednesday, the Citadel CEO said the AI boom is being fueled as much by narrative as by real productivity gains.\n\nGriffin, who ranks as the 39th wealthiest person in the world with a net worth of about $48.3 billion, according to the Bloomberg Billionaires Index, said that doesn't mean AI isn't powerful — but expectations have run far ahead of reality.\n\n\"Is it hype? Of course,\" Griffin said, pointing to the extraordinary scale of investment now pouring into AI infrastructure.\n\nGriffin said that data center spending in the US is estimated to top $500 billion this year. Bank of America previously estimated that Microsoft, Amazon, Google, and Meta — who are leading the data center construction boom — will spend a combined $385 billion annually on AI infrastructure between 2025 and 2028.\n\n\"You're not going to generate this kind of spend unless you're going to make a promise you're going to profoundly change the world,\" Griffin said.\n\n\"How else are you going to get people to write $500 billion of checks just this year alone?\" he added.\n\nGriffin's skepticism came after he was asked whether he agreed with predictions from AI leaders such as Anthropic CEO Dario Amodei, who has said that half of all entry-level white-collar jobs could disappear within five years.\n\nGriffin didn't endorse that view, instead questioning whether AI systems are delivering the kind of deep productivity gains that would justify such forecasts.\n\nTech leaders, such as OpenAI CEO Sam Altman and Microsoft cofounder Bill Gates, have pointed to overheated valuations and investor overexcitement to predict a looming bubble.\n\nOthers, such as Nvidia CEO Jensen Huang and Meta CEO Mark Zuckerberg, have said AI spending reflects a fundamental shift in computing and that demand and model capabilities are still growing fast enough to justify the buildout.\n\nWhat is certain for Griffin said is that AI has \"re-empowered the head of technology in every business in the United States,\" he said.\n\nGriffin was especially critical of generative AI outputs in white-collar work, saying they often look impressive at first glance but fall apart under scrutiny.\n\nHe described reviewing an AI-generated report that seemed insightful at the top but devolved into \"garbage\" further down.\n\nStill, Griffin isn't dismissing AI's long-term impact. He said the technology will be transformative in areas like call centers and software development, and that massive investment in technology broadly is already benefiting the economy.",
    "readingTime": 3,
    "keywords": [
      "productivity gains",
      "justify",
      "you're",
      "technology",
      "griffin",
      "economy",
      "hype",
      "boom",
      "isn't",
      "investment"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/citadel-ceo-ken-griffin-ai-hype-outpacing-productivity-2026-1",
    "thumbnail_url": "https://i.insider.com/697219abd3c7faef0eccb7ca?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.013Z",
    "topic": "finance"
  },
  {
    "slug": "linkedin-cofounder-reid-hoffman-says-companies-are-approaching-ai-the-wrong-way",
    "title": "LinkedIn cofounder Reid Hoffman says companies are approaching AI the wrong way",
    "description": "LinkedIn cofounder Reid Hoffman said firms are overlooking where automation actually pays off — in the \"unglamorous layer\" of day-to-day work.",
    "fullText": "Big companies are busy hiring chief AI officers and setting up tiger teams to pilot agentic products.\n\nHowever, LinkedIn cofounder Reid Hoffman says this overlooks where automation actually pays off — in the \"unglamorous layer\" of day-to-day work.\n\nSpeaking with AI engineer Parth Patil on his \"Possible\" podcast, Hoffman said a company's AI transformation involves employees \"being able to talk to each other about it and do collective learning.\"\n\n\"If people feel they'll get punished or judged for using AI, they become what Ethan Mollick calls 'secret cyborgs,' who quietly speed up their own work while the organization learns nothing,\" Hoffman wrote in a LinkedIn post.\n\nMollick, an associate professor at Wharton, researches the effects of AI on work, entrepreneurship, and education.\n\nCompanies have been ramping up investments in AI to boost efficiency and keep up with the AI race.\n\nGoldman Sachs, for example, said it spent roughly $6 billion on tech last year — a figure CEO David Solomon said he wished was higher.\n\nA CIO survey from RBC Capital in December found 90% of respondents said their organizations plan to spend more on AI in 2026.\n\nMany big companies are trying to integrate new technology by running pilot schemes with a small, specialist group.\n\nHoffman wrote on LinkedIn that they then expect \"transformation to magically spread\".\n\n\"Unfortunately for that strategy, AI lives at the workflow level, and the people closest to the work know where the friction actually is,\" he said.\n\nHoffman said automation should start at the coordination layer. Think meetings, note-taking, and tools that source company knowledge.\n\n\"The winners will be companies that build the muscle of day-to-day use early enough for the gains to compound,\" said Hoffman in an X post.\n\n\"Start learning now, or watch the advantage slip away,\" he added.",
    "readingTime": 2,
    "keywords": [
      "pilot",
      "automation",
      "layer",
      "day-to-day",
      "transformation",
      "learning",
      "hoffman",
      "linkedin",
      "mollick"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/linkedin-cofounder-reid-hoffman-companies-approaching-ai-wrong-way-2026-1",
    "thumbnail_url": "https://i.insider.com/69721c5ed3c7faef0eccb7de?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.012Z",
    "topic": "finance"
  },
  {
    "slug": "how-to-get-your-customers-to-trust-ai",
    "title": "How to Get Your Customers to Trust AI",
    "description": "In using AI with customers, organizations face a challenge in getting them to trust it. They must balance explaining to customers the different facets of the AI systems without overwhelming or confusing them. The solution involves embedding transparency within a broader trust framework, customizing disclosures for different audiences, and treating transparency as an ongoing, adaptive process. Autodesk is one company that has figured out how to strike this balance.",
    "fullText": "How to Get Your Customers to Trust AI by Ashley Reichheld, Sebastian Goodwin and Courtney ShermanJanuary 22, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintTransparency is supposed to build trust. But as companies rush to open the black box of artificial intelligence and explain how it works to customers, many are discovering a surprising truth: You can say too much and too little at the same time. The balance is hard to get right: Too little transparency breeds suspicion; too much overwhelms, blurring the very clarity it’s meant to provide.",
    "readingTime": 1,
    "keywords": [
      "customers",
      "trust"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/how-to-get-your-customers-to-trust-ai",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_22_7210855.jpg",
    "created_at": "2026-01-22T18:18:40.774Z",
    "topic": "business"
  },
  {
    "slug": "suttons-predictions-v-roy-keane-saipan-star-hardwicke",
    "title": "Sutton's predictions v 'Roy Keane' - Saipan star Hardwicke",
    "description": "BBC Sport football expert Chris Sutton takes on actor Éanna Hardwicke, who plays Roy Keane in the new film Saipan - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "Is this AI's worst prediction yet?\n\nChris Sutton's guest this week, actor Éanna Hardwicke, plays Roy Keane in Saipan - a new film about the former Manchester United captain's infamous fallout with Republic of Ireland manager Mick McCarthy before the 2002 World Cup. It is in cinemas from Friday.\n\nNaturally, we asked AI who would play Sutton if a film were ever made about him.\n\nThe best fit, apparently, is Hollywood heartthrob Tom Hardy - who is four inches shorter than BBC Sport football expert Sutton but is AI's top choice for the role because he is \"known for portraying tough, brooding characters with emotional depth\".\n\n\"That just shows how way off the mark AI is,\" said Sutton.\n\n\"But I'm happy with Tom Hardy, even though he is not tall enough. Most people would probably say I am more like Laurel and Hardy though.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nHardwicke, who supports Aston Villa, is his guest for week 23.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "tom hardy",
      "ai's",
      "guest",
      "hardwicke",
      "film",
      "predictions",
      "points",
      "sutton",
      "sport"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/cn8j42l594mo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/c13d/live/4fa91940-f246-11f0-b385-5f48925de19a.png",
    "created_at": "2026-01-22T18:18:39.146Z",
    "topic": "sports"
  },
  {
    "slug": "apple-makes-a-huge-bet-on-ai-models-becoming-commodities",
    "title": "Apple makes a huge bet on AI models becoming commodities",
    "description": "Apple, Siri, and Google Gemini AI are at the forefront as Apple rebuilds its assistant, betting on AI model commoditization and flexibility.",
    "fullText": "Apple's decision to rebuild Siri around Google's Gemini AI models looks, at first glance, like an admission of failure. After years of promising breakthroughs, Apple is reportedly paying Google roughly $1 billion a year to keep its digital assistant relevant.\n\nLook closer, though, and the move represents something more radical: a giant bet that AI models will become commodities.\n\nTop tech reporter Mark Gurman wrote this week that Apple's revamped Siri, codenamed Campos, will launch later this year as a full-fledged chatbot embedded across iPhones, iPads, and Macs. The underlying intelligence will come from Google's Gemini.\n\nThe more important detail is architectural. Apple is designing Campos so that the underlying AI models can be swapped out over time, according to Gurman's report for Bloomberg.\n\n\"That means the company will have the flexibility to move away from Google-powered systems in the future if it so chooses,\" he wrote.\n\nThat design choice tells us a lot about Apple's AI strategy.\n\nRather than trying to win an AI arms race against Google, OpenAI, Anthropic, and Meta by spending tens of billions of dollars a year on AI infrastructure, Apple appears to be positioning itself as model-agnostic. Siri remains Apple's direct interface to more than 1 billion iPhone users. The \"brains\" underneath, however, can change.\n\nIf Apple is right, the leading AI models will converge in quality over time, becoming roughly interchangeable. At that point, differentiation shifts away from the model itself and toward distribution, integration, privacy controls, and user experience — areas where Apple already excels.\n\nApple could then choose whichever AI provider is best, cheapest, or most strategically useful every few years. So, Google's Gemini might power Siri today, but tomorrow it could be OpenAI's latest GPT offering, or Claude from Anthropic, or whatever Meta is cooking up next, or xAI's Grok, or Mistral's offerings, or even region-specific models such as DeepSeek or Alibaba's Qwen in China. Services like OpenRouter already demonstrate how models can be swapped in and out.\n\nApple is also playing a longer game. Its search deal with Google, worth an estimated $20 billion a year, shows how valuable iPhone distribution is. If AI models truly commoditize, Apple could eventually flip the Siri relationship the same way: AI model providers could end up paying Apple for access to its massive user base.\n\nThe strategy also saves Apple enormous capital expenditure. While rivals pour huge sums of money into AI data centers and chips, Apple can let others shoulder that cost. For instance, Google spent more than $60 billion in capex during the first three quarters of 2025, while Apple spent $12.7 billion in its latest fiscal year.\n\nIf this AI building boom turns about to be a bust, Apple may dodge a bullet. Of course, it might turn out that underinvesting in your own AI capabilities is a strategic blunder of epic proportions.\n\nWe'll see in the next few years. Right now, Apple just placed a huge bet that the real power in the AI era won't belong to model makers, but to whoever controls the interface.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "google's gemini",
      "models",
      "siri",
      "apple",
      "model",
      "roughly",
      "campos",
      "underlying",
      "swapped",
      "away"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-siri-bet-ai-models-commodities-google-gemini-2026-1",
    "thumbnail_url": "https://i.insider.com/69716054a645d1188187c43a?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.505Z",
    "topic": "finance"
  },
  {
    "slug": "inside-openais-renewed-push-into-robotics",
    "title": "Inside OpenAI's renewed push into robotics",
    "description": "OpenAI has rapidly scaled its robotics lab over the past year and plans to open up a second lab, insiders say.",
    "fullText": "Last year, Sam Altman posited that the world hadn't yet had its \"humanoid robots moment\" — but, he said, \"it's coming.\" In the background, his AI company has been gearing up to make that happen.\n\nOpenAI quietly built up a humanoid robotics lab over the past year, insiders with knowledge of the program told Business Insider. The lab operates out of the same building as the company's finance team in San Francisco, and employs around 100 data collectors. They're teaching a robotic arm how to perform household tasks as a part of a larger effort to build a humanoid robot.\n\nOpenAI explored robotics during its early years and built a robotic hand capable of solving a Rubik's Cube. The company closed the project in 2020; a company spokesperson said at the time that it had chosen to \"refocus the team on other projects.\"\n\nThe inner workings of the new robotics lab haven't been previously reported.\n\nOne person with knowledge of OpenAI's strategy said the company is working on several new hardware projects, including robotics, that are in the early phases of development, and so far, none are core to the company's mission.\n\nLast week, OpenAI put out a request for proposals from companies that manufacture in the US that could act as partners for the company's push into consumer devices, robotics, and cloud data centers. The company did not specify how much it intends to spend or provide a timeframe for the work.\n\nA representative for OpenAI declined to comment.\n\nThe lab has more than quadrupled in size since it launched in February 2025, insiders said.\n\nIn December, the company told employees it plans to open a second lab in Richmond, California. A December job posting for a \"robotics operator\" with the company's contracting agency lists Richmond as the location.\n\nThe lab has a humanoid robot that multiple people described as \"iRobot-like\" on display, but the bot is mostly collecting dust, and few have seen it in operation. The vast majority of the work in the lab is focused on teleoperating robotic arms.\n\nOpenAI has data collectors using 3-D printed controllers, called GELLOs, to operate two Franka robots. These metal arms have pincers at the end and perform household tasks like putting bread in a toaster or folding laundry.\n\nWhen the data collection program began in February, work focused on teaching the Franka robot how to put a rubber duck in a cup. Since then, it has shifted to increasingly more sophisticated tasks.\n\nOpenAI's lab offers a rare glimpse into how one of the world's most influential AI companies is approaching robotics.\n\nCompetitors like Tesla put on flashy demos and often train with full humanoid robots controlled by motion capture suits and virtual reality headsets. OpenAI is taking a quieter path, scaling contractor-driven data collection to train robotic arms on basic tasks.\n\nBoth approaches show how far leading AI companies remain from building functional household robots, and how much of that work still relies on human labor.\n\nWired reported last fall that OpenAI had begun hiring robotics engineers. The company has at least a dozen engineers on the project, according to a review of LinkedIn profiles.\n\nIn December, a project supervisor said that the lab needed to increase productivity and efficiency to get more hours of functional data, people with knowledge of the program said. Over the past few months, the lab has nearly doubled expectations for data collection, they said.\n\nOpenAI has previously invested in other robotics companies, including Figure, 1X, and Physical Intelligence. Its 2024 partnership with Figure was designed to build \"next generation AI models for humanoid\" robots, but Figure CEO Brett Adcock said in February 2025 that the company was exiting the deal.\n\nWhen the first robotics project ended in 2020, it was widely believed that the company was focusing more intensely on ChatGPT. Now, OpenAI has indicated it plans to expand into devices, and it could use its ChatGPT knowledge base to teach a robot how to interpret and interact with the world.\n\nThe earlier program focused on reinforcement learning — a trial-and-error approach in which robots learn through a reward system. Now, the company is collecting large amounts of data to train the robots.\n\n\"Everyone is fighting for a way to develop large data sets,\" Jonathan Aitken, a robotics expert with the University of Sheffield, told Business Insider. \"We know we have AI algorithms that are capable of being trained to do stuff using big data sets. The issue has always been getting that data set.\"\n\nOpenAI's data collection strategy differs from the robotics efforts at companies like Tesla or Figure, where workers record full-body movement and use motion capture suits and virtual reality headsets to operate full-sized humanoid robots.\n\nOpenAI's data collection efforts mirror a study published in 2023 by researchers from the University of California, Berkeley, that describes a low-cost and scalable system for collecting robotics data using teleoperated arms. One of the researchers joined OpenAI in August 2024 and works on \"Building the Robot Brain,\" according to LinkedIn.\n\nAlan Fern, an AI and robotics expert at Oregon State University, told Business Insider it's a standard setup that allows the robot to learn by mimicking its operator. Aitken said OpenAI's GELLO strategy could present an advantage over AI companies that use motion capture suits. It's cheaper, he said, and because each controller maps directly to a robot arm, the robot can more easily learn how specific human movements translate into its own motions.\n\nIn San Francisco, OpenAI runs three shifts and a few dozen workstations that collect data around the clock, people with knowledge of the lab said. Cameras record both the operator and the robot performing tasks, and workers are rated on how many \"good hours\" of functional training data they can generate.\n\nThe reliance on contract workers and performance metrics mirrors how AI companies, including OpenAI, have historically scaled data labeling for their large language models.\n\n\"A lot of companies are hoping if you collect enough of this data, you can translate it into robot motions, and they will get a scaling effect and have this ChatGPT moment,\" Fern said.\n\n\"That's something that hasn't been proven out yet,\" he added.\n\nThe company is setting up new robot stations with robotic arms that more closely mimic how a human moves, insiders said.\n\nOpenAI also uses some of the data to train robots in computer simulations and regularly tests the robot arms to see how well they perform, the people said.\n\nIt's unclear how quickly OpenAI plans to translate this data into a full humanoid robot, or how its low-cost, arm-based approach will fare against companies investing heavily in full humanoid systems.\n\n\"It does seem to be very early in the process,\" Aitken said. \"From a technical standpoint, it's a really beautiful and configurable interface to lots of different types of robots.\"\n\nDo you work for OpenAI or have a tip? Contact this reporter via email at gkay@businessinsider.com or Signal at 248-894-6012. Use a personal email address, a nonwork device, and nonwork WiFi; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "virtual reality",
      "reality headsets",
      "motion capture",
      "capture suits",
      "perform household",
      "household tasks",
      "robotic arms",
      "robotics expert",
      "humanoid robots",
      "humanoid robot"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/open-ai-robotics-lab-humanoid-robots-2026-1",
    "thumbnail_url": "https://i.insider.com/696975c604eda4732f2f2ea6?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.132Z",
    "topic": "finance"
  },
  {
    "slug": "wall-street-is-losing-its-appetite-for-oracles-data-center-debt",
    "title": "Wall Street is losing its appetite for Oracle's data center debt",
    "description": "Appetite for loans tied to Oracle's data center partnership with OpenAI has diminished, reflecting concerns over credit risk and AI investment scale.",
    "fullText": "Oracle and OpenAI have aimed to build $500 billion of data centers by the end of the decade to power their artificial intelligence ambitions.\n\nBut the massive initiative, called Stargate, may be exhausting the supply of available capital.\n\nJPMorgan Chase, the bank that recently led a pack of lenders to extend roughly $38 billion of debt for the construction of two planned Stargate data center campuses in Texas and Wisconsin, has encountered diminished interest as it has sold off pieces of the loan to other financial players, a person familiar with the situation said.\n\nThe person said that the two projects are fully financed, the syndication effort by JPMorgan had been successful overall, and that the slowdown in new participants hadn't alarmed bankers given that it was at the tail end of such a large debt offering.\n\nBut the person acknowledged that banks and institutional investors had also grown wary in recent months of taking on too much exposure to Oracle, a tech giant whose credit rating sits below some of its peers in the AI race, including Microsoft and Google.\n\nThe reticence among lenders and investors to continue bankrolling Stargate raises questions about whether the mega-project will meet its lofty objectives.\n\n\"We are hearing from market participants that in some cases, there may be banks that could be approaching the exposure levels they're comfortable with when it comes to certain data center projects,\" said Dhaval Shah, a director at S&P Global Infrastructure Ratings.\n\nThe current unprecedented data center development cycle has been dominated by just a handful of leading players, testing whether lenders and investors will remain willing to continue to accrue heavy exposure to borrowers like Oracle. Oracle declined to comment.\n\nIn November, credit default swaps that insure against losses on Oracle's corporate debt rose in cost, a reflection of the concerns around the company's enormous spending on AI.\n\nOpenAI, the AI chatbot maker that will anchor the Stargate facilities, meanwhile, produces revenue that is just a fraction of the tens of billions of dollars annually that would be necessary to justify the cost of its infrastructure.\n\n\"Oracle has become a proxy for OpenAI's ability to raise significant amounts of capital,\" said Gil Luria, an analyst at DA Davidson. \"It's a very precarious position.\"\n\nOpenAI announced Stargate a year ago, stating that it would partner with Oracle and others, to build a total of 10 gigawatts of data center capacity by 2029 — roughly the equivalent power footprint of New York City on a day of peak electrical consumption.\n\nIn October, OpenAI announced that it had arranged for the construction of six Stargate sites with a total planned capacity of roughly 7 gigawatts, stating that the pipeline \"puts us on a clear path to securing the full $500 billion,10-gigawatt commitment\" it had announced at the beginning of 2025.\n\nMuch of the financing for the project, so far, has been provided by major financial institutions that have banded together to share its immense costs — as well as its risks — in what are known as syndication deals. JPMorgan Chase and Mitsubishi UFJ Financial Group led the syndication effort for the two Stargate projects in Shackelford, Texas, and Port Washington, Wisconsin. Both banks declined to comment.\n\nBank of America is leading a syndication to finance another Stargate data center campus in Michigan. A person familiar with that effort said that it has attracted interest from syndication takers.\n\nAnother group of lenders provided about $18 billion of financing for another Stargate facility in New Mexico, according to Bloomberg.\n\nInitial players in large syndication deals often seek to sell off portions of their loan commitments to other players, including other banks and institutional investors.\n\nBut the sale of these positions, which is done to reap quick profits and lower exposure, has become trickier in the case of Stargate.\n\nTwo bankers and a financing executive who are familiar with the syndication market said that the rising perception of risk around Stargate meant that lenders now wanted higher yields to lend to it. That has placed recent Stargate syndicators in a position where they can no longer profitably sell off debt that was arranged at tighter spreads just a few months ago.\n\nStargate borrowing rates may not come down any time soon.\n\nIn September, S&P Global Ratings affirmed Oracle's rating at BBB but said it was considering a cut due to the company's enormous planned spending on AI infrastructure. A downgrade below BBB minus would place a junk rating on Oracle debt, raising its borrowing costs significantly.\n\n\"I am very surprised these loans were even underwritten at the time,\" Luria said. \"The market has indicated this is not investment-grade debt.\"\n\nHowever, Luria said one scenario in particular could make the loans less risky. OpenAI is now in the process of trying to raise as much as $100 billion, according to reports, giving the Stargate venture a potential cushion of equity and making its debt easier to sell, he said.\n\n\"If that happens,\" he said, \"everybody's dreams come true.\"\n\nOther bankers who spoke with Business Insider said the slowdown did not indicate acute trouble in the syndication market, but acknowledged that the pool of investors who still have an appetite for the Stargate debt has shrunk.\n\n\"Do we have enough digestive capacity\" in the market for investors to buy all of the debt that will be required, said David Tawil, a partner at transaction insurance advisory firm Castle Harbour. \"That's the market's real concern: the size of this whole movement.\"",
    "readingTime": 5,
    "keywords": [
      "company's enormous",
      "another stargate",
      "institutional investors",
      "syndication deals",
      "syndication effort",
      "syndication market",
      "debt",
      "lenders",
      "center",
      "players"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/oracle-openai-stargate-loans-jpmorgan-diminishing-interest-debt-2026-1",
    "thumbnail_url": "https://i.insider.com/69714d62e1ba468a96aa7a22?width=800&format=jpeg",
    "created_at": "2026-01-22T12:27:08.132Z",
    "topic": "finance"
  },
  {
    "slug": "wall-streeters-reveal-their-favorite-ai-tools-and-what-they-use-them-for",
    "title": "Wall Streeters reveal their favorite AI tools and what they use them for",
    "description": "AI isn't yet impressive enough to replace the core work done in the finance industry, but Wall Streeters are still using AI to streamline their day.",
    "fullText": "For all the hand-wringing about what AI will do to the white-collar workforce, the technology might not be impressive enough to replace the core work done in the finance industry yet, but Wall Street pros say it definitely has its uses.\n\n\"If you're doing it for self-education, it's one thing, but I think it's quite hard to rely on a chatbot for fiduciary purposes if you're facing clients,\" said Maurits Pot, the founder of Tema ETFs.\n\nOther cite issues with AI \"hallucinations,\" which can be a headache if you need to be precise with figures and data.\n\n\"You don't use AI to do sophisticated things,\" said David Trainer, the founder of New Constructs, adding: \"It's more trouble for me to use something and find out later that it's hallucinated than it is for me to just go get it from the source to begin with.\"\n\nAnd yet, a lot of people are using AI, and there are some creative ways Wall Street pros are deploying the technology.\n\nHere's how Wall Streeters say they are using chatbots to save them time and get an edge.\n\nOne of the more interesting examples I heard comes from Lance Roberts, the CIO at RIA Advisors, which oversees around $2 billion. His team programmed 14 different AI agents to think like top investors, including Warren Buffett, Stanley Druckenmiller, Benjamin Graham, John Bogle, Cathie Wood, and others.\n\nThese agents provide insights on anything from their views on the S&P 500 to individual stocks, Roberts said, and can help provide different perspectives when thinking about an investment case.\n\nAnother use case comes from Rob Arnott, the famed investor and founder of Research Affiliates. Last year at around this time, he was going to have his team read Sun Tzu's \"The Art of War\" to prepare for Trump's second term. Trump has cited it as one of his favorite books, with one of its main takeaways being to find a way to get what you want without fighting. Instead, Arnott figured he'd send them a ChatGPT summary to ensure they'd get the main takeaways without having to take too much time out of their busy schedules.\n\nArnott has also said he uses AI for detailed feedback on his papers, with his preferred chatbot being Perplexity.\n\n\"Perplexity is my preferred search engine, and has been for a couple of years now,\" he said in an email. \"I try the other LLM's from time to time. The nice thing about Perplexity is that it's an AI of AIs: it chooses which AI is best suited to whatever question I have.\"\n\nIts biggest use case, however, seems to be administrative tasks, or assignments that lower-level staffers might have once tackled. As Seth Klarman, the CEO of Baupost Group, described it last summer: \"essentially a capable assistant, a summer intern.\"\n\nDavid Elder, a wealth manager at Merit Financial Advisors, gave an example of a smaller task he might use a chatbot to save time on.\n\n\"I'm doing a presentation right now on intellectual property,\" Elder, who uses multiple chatbots including ChatGPT, Copilot, and Gamma, said. \"I can have an interview with me and an intellectual property or business attorney, talk about it from multiple angles, dump that kind of recording into an AI, and turn that into a presentation.\"\n\nFor Chase Doyen, who works in business development for the London Stock Exchange Group in New York, it's an organizational tool. His firm has a subscription to Claude, Anthropic's chatbot.\n\n\"I use it for administrative tasks mostly,\" Doyen said. \"I use it for organizing and planning out my day. I use it for organizing my notes. If I write down a lot for a presentation I'm in or a meeting, Claude cleans it up very well.\"",
    "readingTime": 4,
    "keywords": [
      "street pros",
      "administrative tasks",
      "intellectual property",
      "wall street",
      "it's",
      "chatbot",
      "founder",
      "presentation",
      "technology",
      "you're"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wall-street-top-ai-chatbots-tools-claude-chatgpt-gamma-2026-1",
    "thumbnail_url": "https://i.insider.com/697131d0d3c7faef0eccaeb7?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.113Z",
    "topic": "finance"
  },
  {
    "slug": "ciscos-hr-chief-said-the-worst-thing-companies-can-do-is-pile-more-work-on-employees-after-ai-saves-time",
    "title": "Cisco's HR chief said the 'worst thing' companies can do is pile more work on employees after AI saves time",
    "description": "Cisco's chief people officer said companies should encourage AI adoption by framing it as a tool that will help workers get part of their day back.",
    "fullText": "Has using AI meant you've ended up with more work on your plate?\n\nAt this early stage of adoption, Cisco's chief people officer, Kelly Jones, told Business Insider that the \"worst thing\" companies can do when trying to encourage AI adoption is to pile additional work on employees once they've freed up time.\n\n\"When you get into the space of AI experimentation, one of the most important things to do is not kill innovation when you're starting it,\" Jones said.\n\nJones is touching on the reality of AI adoption at many companies. Even as firms report productivity gains from AI tools, employees' days haven't necessarily gotten any shorter.\n\nOne Microsoft manager previously told Business Insider that AI tools cut his coding time — which used to make up the overwhelming majority of his workload —by 70%, yet his overall workload didn't shrink. Many leaders have also said that AI will free up employees' time, so they can focus on more \"deep work,\" rather than suggesting that workers might get more free time overall.\n\nJones said that when leaders push AI adoption, they need to make it \"really relevant\" to the day-to-day work of employees, rather than making it another ask from their manager. It should be framed as a tool that helps employees reclaim a percentage of their day, the CPO said.\n\nMost employees would be glad to save time spent on work, and she said companies get it wrong by saying, \"here's three new things that we need you to do.\"\n\nWhile the traditional 9-to-5 workday may not be undergoing a drastic overhaul, some employees have found ways to shave hours off their schedules using AI tools, freeing up time for other pursuits — whether or not they tell their employers. For instance, one worker told Business Insider he used AI to complete about half of his software engineering tasks and spent the rest of his day on Reddit and YouTube.\n\nJones said that if employees are doing better work in less time, \"there's no negative to that.\" At this point in the innovation cycle, people should use AI to get work tasks done more rapidly if they can, she said.\n\nWhile Jones discouraged automatically adding more to employees' plates, she said that figuring out what to do with reclaimed time is a more complicated question. Determining how work changes, how it should be redistributed, and how companies and employees make those calls is what HR is likely to focus on over the next year or two, she said.\n\n\"We are really at this precipice where we're going to be moving from managing jobs to redesigning work,\" Jones said.\n\nShe said the role of HR will shift into helping organizations figure out what work is allocated to humans and what work is done by AI — and how the two work together.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "employees",
      "adoption",
      "tools",
      "jones",
      "innovation",
      "manager",
      "workload",
      "overall",
      "leaders"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/cisco-hr-boss-warns-against-piling-work-after-ai-gains-2026-1",
    "thumbnail_url": "https://i.insider.com/6970f9d7a645d1188187b760?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:07.966Z",
    "topic": "finance"
  },
  {
    "slug": "opensecure-evaluating-ai-models-against-blackbox-web-app-hacking-challenges",
    "title": "OpenSecure – Evaluating AI models against blackbox web app hacking challenges",
    "description": "Comprehensive benchmark testing AI models on offensive security challenges. Compare performance across models on blackbox penetration testing.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://opensecure.cloud/benchmark",
    "thumbnail_url": "https://opensecure.cloud/og-image.png",
    "created_at": "2026-01-22T12:27:05.800Z",
    "topic": "tech"
  },
  {
    "slug": "well-there-goes-the-metaverse",
    "title": "Well, There Goes the Metaverse",
    "description": "The metaverse is on its last legs as VR is eclipsed by AI. But that's not the only thing that went wrong for Meta's VR ambitions.",
    "fullText": "Meta’s enormous bet on virtual reality ended last week, with the company reportedly laying off roughly 1,500 employees from its Reality Labs division — about 10% of the unit’s staff — and shutting down several VR game studios, according to The Wall Street Journal. It’s a huge reversal for a company that, just four years ago, staked its entire identity on the concept.\n\nAs industry watchers might remember, Facebook rebranded itself as Meta in 2021, promising to usher in a new era of technology led by VR devices.\n\nIn part, the decision was a bet on Gen Z’s preference to socialize in online games like Fortnite and Roblox as opposed to traditional social media apps. The change also helped Meta distance itself from the negativity surrounding its Facebook brand. Over the years, the brand had been damaged by data privacy scandals like Cambridge Analytica; reports from Facebook whistleblower Frances Haugen, who shared documents indicating Facebook knew of its negative impacts on children and teens; Congressional hearings over Facebook’s digital surveillance; its role in the spread of misinformation; its monopolistic practices, and more.\n\nMeta’s vision at the time was that the metaverse would be the next big social platform, where users connected in a virtual world via Meta’s Horizon Worlds app and played games on their VR headsets.\n\nFast-forward, and the metaverse has effectively been abandoned in favor of AI.\n\nAccording to CNBC, some of the casualties include studios making VR titles inside Meta, like Armature Studio (“Resident Evil 4 VR“), Twisted Pixel (“Marvel’s Deadpool VR“), and Sanzaru (“Asgard’s Wrath). Meanwhile, the VR fitness app Supernatural, which Meta acquired in 2023 for $400 million, will no longer produce new content and will move into “maintenance mode.” Camouflaj, the studio behind the “Batman: Arkham Shadow” VR game, has also been impacted by layoffs, as reported by GeekWire.\n\nAnd last week, The Verge noted that Meta’s program to bring VR to work, Workrooms, is shutting down, as well.\n\nThe news follows an earlier Bloomberg report from December, which said that Meta was slashing the virtual reality department’s budget by up to 30%. Around the same time, Meta announced that it was pausing its program to share its Meta Horizon operating system, which runs on its Quest-branded VR headsets, with other third-party headset device makers.\n\nUnlike the news of Meta’s rebrand, the deprioritization of the company’s metaverse efforts should come as no surprise — the division lost money at an excessive rate, worrying investors, and had never turned a profit.\n\nIn total, the company had funneled some $73 billion into Reality Labs. To put that into context, you’d have to spend $1 million per day for 200 years to match that kind of spending.\n\nBesides being overhyped by investors and analysts alike, initial versions of the metaverse were just bad products. The goofy, soulless avatars didn’t even have legs, and one metaverse selfie of Meta CEO Mark Zuckerberg was so bad it even became a viral meme. In short, Meta was overpromising a future while its product still under-delivered. It was a failure of the “build in the open” model, where early tech products are shipped to consumers in hopes of getting feedback that can be used to iterate.\n\nThat model works when customers are actively interested in a technology. But in the case of the metaverse, there was only middling consumer demand. Though Meta quickly gained a majority share of the VR market with its Oculus headsets, the headsets saw declining sales. Last spring, Counterpoint Research noted that global VR headset shipments had fallen by 12% year-over-year in 2024, which was their third consecutive year of declines. Meta had accounted for 77% of those 2024 headset shipments.\n\nMeta, betting on the “if you build it, they will come” strategy, was more interested in the profits that could be made from running its own platform for apps and games than whether or not consumers even wanted these so-called face computers.\n\nSpecifically, Zuckerberg was looking for a way to bypass the ability of Apple and Google to tap into Meta’s revenue through their app stores.\n\n“This period has…been humbling, because as big of a company as we are, we’ve also learned what it is like to build for other platforms. And living under their rules has profoundly shaped my views on the tech industry,” Zuckerberg said in a keynote speech at the company’s Facebook Connect 2021 event, referencing the Apple-Google duopoly. “I’ve come to believe that the lack of choice and high fees are stifling innovation, stopping people from building new things, and holding back the entire internet economy.”\n\nHe proposed that the metaverse could grow to a billion people in the next decade, hosting “hundreds of billions” of dollars in digital commerce. Analysts like McKinsey & Co. and investment bank Citi backed up this questionable forecast with their own heady estimates of the metaverse becoming a multi-trillion-dollar platform by 2030.\n\nMeta may have had dollar signs in its eyes, but the apps built for the metaverse weren’t being adopted in massive numbers, at least for a company of Meta’s size.\n\nThough there’s no external visibility into Meta’s own VR app store, you can look at Meta’s apps with iOS and Android counterparts as a proxy for adoption. According to modeled estimates from app intelligence provider Apptopia, the Meta Horizon app has been downloaded 60.4 million times globally and 39.8 million times in the U.S. since May 2018. A better estimate for adoption, however, is its app activity.\n\nFrom a U.S. panel, Apptopia has figures for the average sessions per daily active user in the U.S., which grew from 3.49 in January 2023 to 4.93 in January 2026. While that’s still a high-water mark for the app, it may not have been enough for Meta.\n\nFor comparison, outside of VR, Meta now has over 3.5 billion daily active users across its social apps Facebook, Instagram, WhatsApp, and Messenger.\n\nOf course, had this all succeeded, Meta would have created a new social empire, built on the back of VR gaming — not unlike Facebook’s early days as a social network, when partners like Zynga — whose games included Farmville, and Words with Friends — drove double-digit revenue streams for Facebook. (Ultimately, Facebook’s 30% cut of virtual goods sales, combined with restrictive platform policies, drove Zynga to launch its own gaming portal and pivot to mobile.)\n\nBut this time, Zuckerberg telegraphed his desire to tap into developer revenue far too soon. Meta might have had a better shot at attracting developers to build for VR if it promised to undercut Apple or Google’s standard 30% fees, or those of other gaming platforms. Instead, Meta did the opposite: it charged more.\n\nEven before VR became a sizable platform worth investing in, Meta announced its plans to take a whopping 47.5% of the sales of digital assets within Horizon Worlds, consisting of a 30% hardware platform fee and another 17.5% fee for Horizon Worlds itself. Creators, unsurprisingly, were not happy.\n\nAs bad, Meta wasn’t building the metaverse with user safety as a top priority. As with its rush to scale its social network, the company tended to be reactive rather than proactive about safety features. For instance, the company only rolled out its “Personal Boundary” feature, which put a buffer between avatars, after reports that users were experiencing sexual harassment in the metaverse. In some cases, users had even engaged in virtual rape and gang rape in Meta’s Horizon Worlds. Meta later dialed back the safety feature a bit by adjusting the Personal Boundary to only default to “on” when a user is engaging with “non-friends” in the metaverse and allowing users to switch it off entirely.\n\nIn May 2022, TechCrunch asked a Meta rep to detail its support measures for Horizon Worlds. The company described several tools, including blocking and reporting features, a “safe zone” button for users to instantly block and mute others, and a feature to temporarily remove disruptive people from venues that was built in response to user feedback. Despite outlining these tools, Meta declined to say what sort of actions it would take to address individual bad actors’ behavior.\n\nAt the time, users told TechCrunch that those who faced abuse in the metaverse would often react with an obvious move: instead of recording the abuse, they would take off their headset and take a break from VR. But when they returned, their harasser would still appear in their list of recent encounters, and it was too late to submit a report of the abuse with the video and audio attached.\n\nThese types of scenarios were seemingly not thought through from the start, and detailed policies around what constitutes abuse didn’t exist. When a metaverse code of conduct was later published, it still didn’t detail any consequences beyond saying Meta would “take action on users.”\n\nAlso around this time, Meta declined to share the makeup of its team building the metaverse with TechCrunch. (But if we had to bet, we’d guess there weren’t as many women on the project as men. This would reflect the makeup of Meta overall, so it’s not a bad bet!)\n\nAnother nail in the proverbial coffin for the metaverse was the success of Meta’s Ray-Ban AR glasses, which have seen increased consumer interest in recent months. With features like the ability to record hands-free, stream music, and chat with Meta AI, the glasses began to outsell traditional Ray-Bans in some retail stores in 2024. The company is now considering doubling the output of the glasses to meet consumer demand, Bloomberg reported this week.\n\nWith an eye on AI, the company more recently introduced Ray-Ban Display last year, which are similar smart glasses that also include a display for apps, alerts, and directions on the right lens. The company has since paused its international plans for this product, citing “unprecedented demand.” (Or rather, overly conservative inventory forecasting.)\n\nWith other companies, including OpenAI, Amazon, and various startups, looking to hardware AI devices as the next potential computing platform, VR seems even more of a dated relic of a vision for the web that never came to pass.\n\nCombined, these factors, and particularly the adoption of AI as a possible app platform, make it hard for Meta to continue to justify spending on VR. Instead, Meta will focus on the products that have potential, like its Ray Ban and AI glasses, AI app’s growth, and large language models.",
    "readingTime": 9,
    "keywords": [
      "daily active",
      "headset shipments",
      "meta declined",
      "consumer demand",
      "meta’s horizon",
      "social network",
      "virtual reality",
      "horizon worlds",
      "personal boundary",
      "metaverse"
    ],
    "qualityScore": 1,
    "link": "https://techcrunch.com/2026/01/19/well-there-goes-the-metaverse/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2026/01/friends.webp?w=1200",
    "created_at": "2026-01-22T12:27:05.016Z",
    "topic": "tech"
  },
  {
    "slug": "infera-agentic-cli-for-inferring-and-provisioning-cloud-infra",
    "title": "Infera – agentic CLI for inferring and provisioning cloud infra",
    "description": "Infera - AI Powered Infrastructure Planning & Provisioning (Powered by Claude Code SDK) - computer-reinvention/infera",
    "fullText": "computer-reinvention\n\n /\n\n infera\n\n Public\n\n Infera - AI Powered Infrastructure Planning & Provisioning (Powered by Claude Code SDK)\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n computer-reinvention/infera",
    "readingTime": 1,
    "keywords": [
      "infera",
      "powered",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/computer-reinvention/infera",
    "thumbnail_url": "https://opengraph.githubassets.com/c9dff442d70faa91b3e699d7042ed0e39f529e76e3ced8f782c7113eacc61613/computer-reinvention/infera",
    "created_at": "2026-01-22T12:27:04.279Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-keeps-falling-for-prompt-injection-attacks",
    "title": "Why AI Keeps Falling for Prompt Injection Attacks",
    "description": "Why AI falls for scams that wouldn't trick a fast-food worker—and what that reveals about AI security.",
    "fullText": "IEEE Spectrum is the flagship publication of the IEEE — the world’s largest professional organization devoted to engineering and applied sciences. Our articles, videos, and infographics inform our readers about developments in technology, engineering, and science.",
    "readingTime": 1,
    "keywords": [
      "engineering",
      "ieee"
    ],
    "qualityScore": 0.2,
    "link": "https://spectrum.ieee.org/prompt-injection-attack",
    "thumbnail_url": "https://spectrum.ieee.org/media-library/image.png?id=62858670&width=1200&height=600&coordinates=0%2C172%2C0%2C172",
    "created_at": "2026-01-22T12:27:03.966Z",
    "topic": "tech"
  },
  {
    "slug": "government-agencies-mandate-cspm-for-federal-cloud-contracts",
    "title": "Government Agencies Mandate CSPM for Federal Cloud Contracts",
    "description": "CEOs don’t just run companies anymore—they represent digital bullseye for cybercriminals. From convincing phishing emails crafted with personal details to AI-generated deepfakes that mimic a leader’s voice or image, attacks on CEOs and other C-suite leaders have become more targeted, precise, and dangerous.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.systemtek.co.uk/2025/05/executive-protection-in-the-digital-age-how-ceos-are-becoming-prime-cyber-targets/",
    "thumbnail_url": "http://www.systemtek.co.uk/wp-content/uploads/2025/05/CEO-prime-cyber-target.jpg",
    "created_at": "2026-01-22T06:20:37.649Z",
    "topic": "tech"
  },
  {
    "slug": "mnn-fast-lightweight-deep-learning-framework",
    "title": "MNN – fast, lightweight deep learning framework",
    "description": "MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/READ...",
    "fullText": "alibaba\n\n /\n\n MNN\n\n Public\n\n MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/README.md). MNN TaoAvatar Android - Local 3D Avatar Intelligence: apps/Android/Mnn3dAvatar/README.md\n\n www.mnn.zone/\n\n License\n\n Apache-2.0 license\n\n 14k\n stars\n\n 2.2k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n alibaba/MNN",
    "readingTime": 1,
    "keywords": [
      "android",
      "alibaba",
      "license"
    ],
    "qualityScore": 0.65,
    "link": "https://github.com/alibaba/MNN",
    "thumbnail_url": "https://opengraph.githubassets.com/6afcc07063d3bfbf527b1024d6427e1cc3ba0bbedcfd91446f7361a79a748b1f/alibaba/MNN",
    "created_at": "2026-01-22T00:59:15.698Z",
    "topic": "tech"
  },
  {
    "slug": "ai-systems-performance-engineering",
    "title": "AI Systems Performance Engineering",
    "description": "Contribute to cfregly/ai-performance-engineering development by creating an account on GitHub.",
    "fullText": "cfregly\n\n /\n\n ai-performance-engineering\n\n Public\n\n License\n\n Apache-2.0 license\n\n 968\n stars\n\n 134\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n cfregly/ai-performance-engineering",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/cfregly/ai-performance-engineering",
    "thumbnail_url": "https://opengraph.githubassets.com/821a0056b72b23f9cd26ddd6943614ce37b50c900dd7ac56b45a8b17aca24f30/cfregly/ai-performance-engineering",
    "created_at": "2026-01-22T00:59:15.645Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-says-a-lot-of-sixfigure-jobs-in-plumbing-and-construction-are-about-to-be-unlocked-because",
    "title": "Nvidia CEO Jensen Huang says ‘a lot’ of six-figure jobs in plumbing and construction are about to be unlocked because someone needs to build all these new AI centers",
    "description": "The AI boom is threatening white-collar entry jobs—but it’s creating a booming six-figure opportunity for electricians, plumbers, and construction workers.",
    "fullText": "The job market has been a tough sell for many Gen Z graduates, with tariffs, economic uncertainty, and artificial intelligence reshaping hiring plans across corporate America. But according to Nvidia’s CEO Jensen Huang, the next wave of six-figure opportunities won’t be found in a Wall Street cubicle or Silicon Valley Slack channel. Instead, high-paying careers will partially come by picking up a wrench—literally.\n\nAs tech giants race to build sprawling data centers—totaling $7 trillion in global capital outlays by the end of the decade—Huang believes the world is on the cusp of what he calls the “largest infrastructure buildout in human history,” which will create “a lot of jobs.”\n\n“It’s wonderful that the jobs are related to tradecraft, and we’re going to have plumbers and electricians and construction and steelworkers,” he said in conversation with BlackRock CEO Larry Fink at the World Economic Forum in Davos, Switzerland.\n\nThe hands-on skills needed to construct what he described as chip, computer, and AI factories are already facing shortages—even though many roles pay over $100,000 without requiring a college degree. One McKinsey report estimated that between 2023 and 2030, there will be a need for an additional 130,000 trained electricians—as well as 240,000 construction laborers and 150,000 construction supervisors—in the U.S. alone.\n\n“Everybody should be able to make a great living,” Huang said. “You don’t need to have a Ph.D. in computer science to do so.”\n\nThis isn’t the first time Huang has expressed his optimistic outlook on new career paths emerging alongside AI.\n\n“The skilled craft segment of every economy is going to see a boom,” he told Channel 4 News in the U.K. last year. “You’re going to have to be doubling and doubling and doubling every single year.”\n\nThat optimism stands in contrast to warnings from leaders like Ford CEO Jim Farley, who has repeatedly cautioned that AI is hollowing out traditional white-collar entry points—just as the education system continues to funnel students toward four-year degrees.\n\n“There’s more than one way to the American Dream, but our whole education system is focused on four-year [college] education,” Farley said at the Aspen Ideas Festival last year. “Hiring an entry worker at a tech company has fallen 50% since 2019. Is that really where we want all of our kids to go? Artificial intelligence is gonna replace literally half of all white-collar workers in the U.S.”",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "education system",
      "construction",
      "doubling",
      "hiring",
      "tech",
      "jobs",
      "computer",
      "college",
      "white-collar"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-says-160735219.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/AVfx3XSS96moXvxXLt9zTw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/4062994d1bf7ae6ff8233554daa0c275",
    "created_at": "2026-01-22T00:59:12.475Z",
    "topic": "finance"
  }
]
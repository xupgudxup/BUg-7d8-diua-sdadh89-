[
  {
    "slug": "tension-over-feds-dual-mandate-ai-growths-impact-on-spreads-credits-real-yield-12122025",
    "title": "Tension Over Fed's Dual Mandate, AI Growth's Impact on Spreads, Credits | Real Yield 12/12/2025",
    "description": "\"Bloomberg Real Yield\" highlights the market-moving news you need to know. Today's guests: JPMorgan Private Bank Global head of Macro and Fixed Income Strategy Alexander Wolf, Richard Bernstein Advisors Deputy CIO Mike Contopoulos, Wells Fargo Global Head of High Grade Debt Syndicate Maureen O'Connor and BlackRock Head of Macro Credit Research Amanda Lynam.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/real-yield-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iu9B06KM_hRw/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:10.014Z",
    "topic": "finance"
  },
  {
    "slug": "ai-campus-developer-fermi-drops-after-tenant-ends-agreement",
    "title": "AI Campus Developer Fermi Drops After Tenant Ends Agreement",
    "description": "Fermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.",
    "fullText": "TechnologyAIBy Naureen S MalikSaveFermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.The company said its first investment-grade tenant canceled a deal from Nov. 4 that would have provided as much as $150 million to fund construction costs, according to a filing Friday. No funds had been drawn under that agreement.",
    "readingTime": 1,
    "keywords": [
      "tenant",
      "agreement"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/fermi-falls-51-after-ai-campus-tenant-ends-150-million-deal",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i63XDNyxBC8Q/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.711Z",
    "topic": "finance"
  },
  {
    "slug": "tech-rout-drags-stocks-lower-oracle-broadcom-fall-on-ai-angst",
    "title": "Tech Rout Drags Stocks Lower; Oracle, Broadcom Fall on AI Angst",
    "description": "A rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.",
    "fullText": "MarketsBy Alexandra SemenovaSaveA rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.The Nasdaq 100 Index dropped 1.5% at 1:30 p.m. in New York, while the S&P 500 Index fell 0.9%. Broadcom slumped 11%, weighing on artificial intelligence peers after its sales outlook for the AI market failed to meet investors’ expectations. Shares of Oracle lost 3.3% after Bloomberg reported that the company has pushed back timelines for some of the infrastructure it’s developing for OpenAI to 2028 from 2027.",
    "readingTime": 1,
    "keywords": [
      "artificial intelligence",
      "broadcom",
      "oracle",
      "index"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/s-p-500-wavers-as-investors-rotate-out-of-technology-behemoths",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.gSDwOLgE7g/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.528Z",
    "topic": "finance"
  },
  {
    "slug": "broadcom-hit-hard-as-ai-backlog-squeezes-margins-open-interest-12122025",
    "title": "Broadcom Hit Hard as AI Backlog Squeezes Margins | Open Interest 12/12/2025",
    "description": "Get a jump start on the US trading day with Matt Miller and Dani Burger on \"Bloomberg Open Interest.\" A Santa rally tries to take hold — with global stocks eyeing records and the U.S. market hitting its first all-time high in six weeks. But tech caution lingers as Broadcom slips on lofty AI hopes, while UBS jumps to a 17-year high on plans to ease capital demands.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/open-interest-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iZ5fnJN9b.1U/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:09.512Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-tumble-as-traders-ai-bets-take-a-hit-markets-wrap",
    "title": "Stocks Tumble as Traders’ AI Bets Take a Hit: Markets Wrap",
    "description": "US stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed.",
    "fullText": "MarketsBy Cristin FlanaganSaveUS stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed. A disappointing sales outlook from chipmaker Broadcom Inc. weighed on rivals and further fueled investor anxiety over AI wagers initially sparked by Oracle Corp. The AI bellwether’s stock drop started Thursday following a forecast for rising outlays and a longer timeline to a revenue payoff. The slump deepened on a report of delays to some of Oracle’s data center projects Friday. Shares of companies tied to the power infrastructure also slid.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-11/stock-market-today-dow-s-p-live-updates",
    "thumbnail_url": "https://assets.bwbx.io/s3/lightsaber/_next/static/media/social-markets.e062a0c0.jpg",
    "created_at": "2025-12-12T18:56:09.464Z",
    "topic": "finance"
  },
  {
    "slug": "a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm",
    "title": "A Glance at GPU Goodness in Java: LLM Inference with TornadoVM",
    "description": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If […]",
    "fullText": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If anything, this is an opportunity to learn more about GPU programming, and since Java is my comfort-zone language, what better occasion than looking into TornadoVM?\n\nRecently, the TornadoVM team released gpullama3, a proof-of-concept demonstrating LLM inference on GPUs using pure Java. Let’s explore this together!\n\nTornadoVM is a plugin for the OpenJDK that enables Java programs to automatically run on heterogeneous hardware (GPUs, FPGAs, and multi-core CPUs) using standard Java code annotated for parallel compute.\n\nTransformer-based language models are computationally expensive but highly-parallelizable. At inference time, generating each token requires matrix multiplications across billions of parameters. GPUs excel at these operations because they can perform thousands of computations in parallel. Thus, TornadoVM is the perfect tool for this kind of workload.\n\nInstalling GPULlama3.java was surprisingly straightforward. Make sure you have your favorite flavor of JDK 21 installed. I use sdkman, so I made sure I had Temurin 21 installed:\n\nThen you’ll want to make sure you have installed cmake, a C/C++ toolchain, Python and pip. Now you can clone the repo:\n\nand follow the instructions on the README; for instance, on macOS/Linux:\n\nYou can verify the installation was successful by running one example:\n\nOf course, make sure you replace tornado-examples-1.1.2-dev-e1d2d12.jar with the right jar name! Your output should look something like this:\n\nThe @Parallel annotation tells TornadoVM this loop can be parallelized. The TaskGraph API manages data movement and execution scheduling. You can compile it with the following (if you followed the installation guide correctly $TORNADO_SDK will point to the right path):\n\nNotice that -g is required for this to work correctly. Now you can run it with:\n\nIt will print the first 10 items in the resulting vector.\n\nThe gpullama3 project demonstrates running a Llama 3 model entirely in Java with GPU acceleration. Assuming you are back at the root of the repo, continue with the setup procedure.\n\nNow let’s download a compatible model using the HuggingFace CLI:\n\nTry it! Even on my poor MacBook Air with 8 GB RAM (provided I don’t have too many applications open) this returns:\n\nDisclaimer: even if you have better CPU/GPUs at your disposal, they are unlikely to affect the quality of the joke.\n\nGPULlama3.java currently supports a few FP16 (16-bit floating point) and 8-bit quantized models:\n\nDepending on the model being selected, a different execution plan will be built. The execution plan corresponds to the model architecture. In our case, we picked the unquantized Llama 3.2 1B FP16. Let’s take a look at the setupTornadoForwardPlan() method in FP16LayerPlanner, used by LLama 3.2:\n\nIn the Activation layer we mostly look up token embeddings and apply an initial normalization step, while the Logit layer is where we convert the model’s internal representation into token predictions. So let’s concentrate a bit more on the Feed-Forward Network layer (FFN), and in particular on the Attention implementation. The LlamaFP16FFNLayers#setupSingleFFNLayer method is a bit cryptic at a first glance; let’st start from its signature:\n\nThe method is building a TaskGraph, essentially describing the data flow of our GPU kernels. Let’s focus on QKV and attention, using Sebastian Raschka1‘s excellent Python Notebook as a reference. The following is the architecture diagram of the Llama 3.2 1B model:\n\nFor obvious reasons of brevity, we aren’t going to explore this in detail, but we do want to take a look at the implementation of the attention heads. In particular, let’s take a look at how we compute the Query, Key, Value matrices (Q,K,V = project(x) in the Python version):\n\nThis is followed by the RoPE rescaling to encode token positions:\n\nNow we are ready to compute attention. The generic version (there is also an NVidia-specific implementation) is:\n\nLet’s drill down into TransformerComputeKernelsLayered::processHeadsParallel to see how that is performed. The following is one of the GPU kernels. It essentially computes:\n\nYou will notice that the method:\n\nAfter the attention mechanism computes relationships between tokens, the result is added to the original input, normalized, and passed through a feed-forward network. This process repeats across multiple layers before finally producing the next-token prediction (the logit layer).\n\nBecause it’s an autoregressive model, this entire process repeats for each token, using the previously generated sequence as input.\n\nIn short, TornadoVM handled GPU compilation and execution transparently, allowing a pure Java program to perform LLM inference!\n\nWe’ve completed our whirlwind tour of Llama3GPU.java and TornadoVM. If your head is still spinning, don’t worry, you’re not alone! It’s a lot to take in, but I hope this post has sparked your interest and inspired you to dig deeper: I know I will!\n\nThis site uses Akismet to reduce spam. Learn how your comment data is processed.",
    "readingTime": 5,
    "keywords": [
      "llm inference",
      "gpu kernels",
      "pure java",
      "llama model",
      "process repeats",
      "execution plan",
      "logit layer",
      "token",
      "look",
      "attention"
    ],
    "qualityScore": 1,
    "link": "https://www.javaadvent.com/2025/12/a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm.html",
    "thumbnail_url": "https://i0.wp.com/www.javaadvent.com/content/uploads/2025/11/tornadovm-gpullama3.png?fit=1024%2C1024&ssl=1",
    "created_at": "2025-12-12T18:56:04.854Z",
    "topic": "tech"
  },
  {
    "slug": "safeshell-reversible-shell-commands-for-local-ai-agents",
    "title": "SafeShell – reversible shell commands for local AI agents",
    "description": "Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible. - qhkm/safeshell",
    "fullText": "qhkm\n\n /\n\n safeshell\n\n Public\n\n Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible.\n\n License\n\n MIT license\n\n 5\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n qhkm/safeshell",
    "readingTime": 1,
    "keywords": [
      "agents",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/qhkm/safeshell",
    "thumbnail_url": "https://opengraph.githubassets.com/682605a64fdbc61dcd8e5ba1cd013f5a5b40bb3a5a49c5137fe779101aefc528/qhkm/safeshell",
    "created_at": "2025-12-12T18:56:04.468Z",
    "topic": "tech"
  },
  {
    "slug": "facilitating-ai-adoption-at-imprint",
    "title": "Facilitating AI Adoption at Imprint",
    "description": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout.",
    "fullText": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\n\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout. The further you read, the more specific this will get,\nending with cheap-turpentine-esque topics like getting agents to reliably translate human-readable text representations of Slack entities into mrkdwn formatting of the correct underlying entity.\n\nI am hiring:\nIf you’re interested in working together with me on internal agent and AI adoption at Imprint,\nwe are hiring our founding Senior Software Engineer, AI.\nThe ideal candidate is a product engineer who’s spent some time experimenting with agents,\nand wants to spend the next year or two digging into this space.\n\nAs technologists, I think one of the basics we owe our teams is spending time\nworking directly with new tools to develop an intuition for how they do, and don’t work.\nAI adoption is no different.\n\nTowards that end, I started with a bit of reading, especially Chip Huyen’s AI Engineering,\nand then dove in a handful of bounded projects: building my rudimentary own agent platform\nusing Claude code for implementation,\ncreating a trivial MCP for searching my blog posts,\nand an agent to comment on Notion documents.\n\nEach of these projects was two to ten hours, and extremely clarifying.\nTool use is, in particular, something that seemed like magic until I\nimplemented a simple tool-using agent, at which point it become something extremely non-magical\nthat I could reason about and understand.\n\nImprint’s general approach to refining AI adoption is strategy testing:\nidentify a few goals, pick an initial approach, and then iterate rapidly in the details until the approach genuinely works.\nIn an era of crushing optics, senior leaders immersing themselves in the details is one of our few defenses.\n\nShortly after joining, I partnered with the executive team to draft the above strategy for AI adoption.\nAfter a modest amount of debate, the pillars we landed on were:\n\nAs you see from those principles, and my earlier comment, my biggest fear for AI adoption is\nthat they can focus on creating the impression of adopting AI, rather than focusing on creating additional productivity.\nOptics are a core part of any work, but almost all interesting work occurs where optics and reality\nintersect, which these pillars aimed to support.\n\nAs an aside, in terms of the components of strategy in\nCrafting Engineering Strategy, this is really just\nthe strategy’s policy.\nIn addition, we used strategy testing to refine our approach,\ndefined a concrete set of initial actions to operationalize it (they’re a bit too specific to share externally),\nand did some brief exploration to make sure I wasn’t overfitting on\nmy prior work at Carta.\n\nMy first step towards adoption was collecting as many internal examples of tips and tricks as possible into\na single Notion database. I took a very broad view on what qualified, with the belief that showing\nmany different examples of using tools–especially across different functions–is both useful and inspiring.\n\nI’ve continued extending this, with contributions from across the company, and it’s become a useful resource\nfor both humans and bots alike to provide suggestions on approaching problems with AI tooling.\n\nOne of my core beliefs in our approach is that making prompts discoverable\nwithin the company is extremely valuable.\nDiscoverability solves four distinct problems:\n\nMy core approach is that every agent’s prompt is stored in a single Notion database\nwhich is readable by everyone in the company. Most prompts are editable by everyone,\nbut some have editing restrictions.\n\nHere’s an example of a prompt we use for routing incoming Jira issues from Customer Support\nto the correct engineering team.\n\nHere’s a second example, this time of responding to requests in our Infrastructure Engineering\nteam’s request channel.\n\nPretty much all prompts end with an instruction to include a link to the prompt\nin the generated message. This ensures it’s easy to go from a mediocre response\nto the prompt-driving the response, so that you can fix it.\n\nIn addition to collecting tips and prompts, the next obvious step for AI adoption\nis identifying a standard AI platform to be used within the company, e.g. ChatGPT,\nClaude, Gemini or what not.\n\nWe’ve gone with OpenAI for everyone.\nIn addition to standardizing on a platform, we made sure account provisioning was\nautomatic and in place on day one.\nTo the surprise of no one who’s worked in or adjacent to IT,\na lot of revolutionary general AI adoption is… really just account provisioning and access controls.\nThese are the little details that can so easily derail the broader plan if you don’t dive into them.\n\nWithin Engineering, we also provide both Cursor and Claude.\nThat said, the vast majority of our Claude usage is done via AWS Bedrock,\nwhich we use to power Claude Code… and we use Claude Code quite a bit.\n\nWhile there’s a general industry push towards adopting more AI tooling,\nI find that a significant majority of “AI tools” are just SaaS vendors that\ntalk about AI in their marketing pitches. We have continued to adopt vendors,\nbut have worked internally to help teams evaluate which “AI tools” are meaningful.\n\nWe’ve spent a fair amount of time going deep on integrating with AI tooling for chat and IVR\ntooling, but that’s a different post entirely.\n\nMeasuring AI adoption is, like all measurement topics, fraught.\nAltogether, I’ve found measuring tool adoption very useful for identifying the right\nquestions to ask. Why haven’t you used Cursor? Or Claude Code? Or whatever? These are fascinating\nquestions to dig into. I try to look at usage data at least once a month, with a particular focus\non two questions:\n\nAt the core, I believe folks who aren’t adopting tools are rational non-adopters,\nand spending some time understanding the (appearance of) resistance goes further than\ntop-down mandate. I think it’s often an education gap that is bridged easily enough.\nConceivably, at some point I’ll discover a point of diminishing returns, where the lack\nof progress is stymied on folks who are rejecting AI tooling–or because the AI tooling\nisn’t genuinely useful–but I haven’t found that point yet.\n\nThe next few sections are about building internal agents.\nThe core implementation is a single stateless lambda which handles a wide variety of HTTP requests,\nsimilar-ish to Zapier.\nThis is currently implemented in Python, and is roughly 3,000 lines of code,\nmuch of it dedicated to oddities like formatting Slack messages, etc.\n\nFor the record, I did originally attempt to do this within Zapier,\nbut I found that Zapier simply doesn’t facilitate the precision I believe is necessary to do this effectively.\nI also think that Zapier isn’t particularly approachable for a non-engineering audience.\n\nAs someone who spent a long time working in platform engineering,\nI still want to believe that you can build a platform, and users will come.\nIndeed, I think it’s true that a small number of early adopters will come,\nif the problem is sufficiently painful for them,\nas was the case for Uber’s service migration (2014).\n\nHowever, what we’ve found effective for driving adoption is basically the opposite of that.\nWhat’s really worked is the intersection of platform engineering and old-fashioned product engineering:\n\nSome examples of the projects where we’ve gotten traction internally:\n\nFor all of these projects that have worked, the formula has been\nthe opposite of “build a platform and they will come.” Instead it’s\nrequired deep partnership from folks with experience building AI agents and\nusing AI tooling to make progress. The learning curve for effective AI adoption\nin important or production-like workflows remains meaningfully high.\n\nAgents that use powerful tools represent a complex configuration problem.\nFirst, exposing too many tools–especially tools that the prompt author doesn’t effectively understand–makes\nit very difficult to create reliable workflows. For example, we have an exit_early command that allows terminating\nthe agent early: this is very effective in many cases, but is also easy to break your bot.\nSimilarly, we have a slack_chat command that allows posting across channels, which can support a variety of useful\nworkflows (e.g. warm-handoffs of a question in one channel into a more appropriate alternative),\nbut can also spam folks.\nSecond, as tools get more powerful, they can introduce complex security scenarios.\n\nTo address both of these, we currently store configuration in a code-reviewed Git repository.\nHere’s an example of a JIRA project.\n\nHere’s another for specifying a Slack responder bot.\n\nCompared to a JSON file, we can statically type the configuration, and it’s easy to extend over time.\nFor example, we might want to extend slack_chat to restrict which channels a given bot is allowed to\npublish into, which would be easy enough.\nFor most agents today, the one thing not under Git-version control is the prompts themselves, which are versioned by Notion.\nHowever, we can easily require specific agents to use prompts within the Git-managed repository for sensitive scenarios.\n\nAfter passing tests, linting and typechecking, the configurations are automatically deployed.\n\nIt’s sort of funny to mention, but one thing that has in practice really interfered with\neasily writing effective prompts is making it easy to write things like @Will Larson which\nis then translated into <@U12345> or whatever the appropriate Slack identifier is for a given\nuser, channel, or user group. The same problem exists for Jira groups, Notion pages and databases,\nand so on.\n\nThis is a good example of where centralizing prompts is useful. I got comfortable pulling the unique\nidentifiers myself, but it became evident that most others were not.\nThis eventually ended with three tools for Slack resolution: slack_lookup which takes a list\nof references to lookup, slack_lookup_prefix which finds all Slack entities that start with\na given prefix (useful to pull all channels or groups starting with @oncall-, for example, rather than having to hard-code the list in your prompt), and slack_search_name which uses string-distance to find potential matches (again, useful for dealing with typos).\n\nIf this sounds bewildering, it’s largely the result of Slack not exposing relevant APIs for this sort of lookup.\nSlack’s APIs want to use IDs to retrieve users, groups and channels, so you have to maintain your own cache of\nthese items to perform a lookup. Performing the lookups, especially for users, is itself messy. Slack users have\na minimum of three ways they might be referenced: user.profile.display_name, user.name, and user.real_name,\nonly a subset of which are set for any given user.\nThe correct logic here is, as best I can tell, to find a match against user.profile.display_name, then use that if it exists.\nThen do the same for user.name and finally user.real_name. If you take the first user that matches one of those three,\nyou’ll use the wrong user in some scenarios.\n\nIn addition to providing tools to LLMs for resolving names, I also have a final mandatory check for each response\nto ensure the returned references refer to real items. If not, I inject which ones are invalid into the context window and perform an additional agent loop with only entity-resolution tools available.\nThis feels absurd, but it was only at this point that things really started working consistently.\n\nAs an aside, I was embarassed by these screenshots, and earlier today I made the same changes for Notion pages and databases\nas I had previously for Slack.\n\nSimilarly to foreign entity resolution,\nthere’s a similar problem with Slack’s mrkdwn variant of Markdown\nand JIRA’s Atlassian Document Format:\nthey’re both strict.\n\nThe tools that call into those APIs now have strict instructions on formatting. These had been contained in individual\nprompts, but they started showing up in every prompt, so I knew I needed to bring them into the agent framework itself\nrather than forcing every prompt-author to understand the problem.\n\nMy guess is that I need to add a validation step similar to the one I added for entity-resolution,\nand that until I do so, I’ll continue to have a small number of very infrequent but annoying rendering issues,\nTo be honest, I personally don’t mind the rendering issues, but that creates a lot of uncertainty for others using agents, so I think solving them is a requirement.\n\nToday, all logs, especially tool usage, are fed into two places. First, it goes into Datadog for full logging visibility.\nSecond, and perhaps more usefully for non-engineers, they feed into a Slack channel, #ai-logs which create visibility\ninto which tools are used and with which (potentially truncated) parameters.\n\nLonger term, I imagine this will be exposed via a dedicated internal web UX, but generally speaking I’ve found that\nthe subset of folks who are actively developing agents are pretty willing to deal with a bit of cruft.\nSimilarly the folks who aren’t developing agents directly don’t really care, they want it to work perfectly every time,\nand aren’t spending time looking at logs.\n\nThe biggest internal opportunity that I see today is figuring out how to\nget non-engineers an experience equivalent to running Claude Code locally with\nall their favorite MCP servers plugged in.\nI’ve wanted ChatGPT or Claude.ai to provide this, but they don’t really quite get there,\nClaude Desktop is close, but is somewhat messy to configure as we think about finding a tool\nthat we can easily allow everyone internally to customize and use on a daily basis.\n\nI’m still looking for what the right tool is here. If anyone has any great suggestions\nthat we can be somewhat confident will still exist in two years, and don’t require sending\na bunch of internal data to a very early stage company, then I’m curious to hear!\n\nYou’re supposed to start a good conclusion with some sort of punchy anecdote that\nilluminates your overall thesis in a new way. I’m not sure if I can quite meet that bar,\nbut the four most important ideas for me are:\n\nI’m curious what other folks are finding!",
    "readingTime": 13,
    "keywords": [
      "i’m curious",
      "notion database",
      "notion pages",
      "i’ve learned",
      "slack entities",
      "account provisioning",
      "strategy testing",
      "developing agents",
      "platform engineering",
      "claude code"
    ],
    "qualityScore": 1,
    "link": "https://lethain.com/company-ai-adoption/",
    "thumbnail_url": "https://lethain.com/static/author.png",
    "created_at": "2025-12-12T18:56:03.515Z",
    "topic": "tech"
  },
  {
    "slug": "ai-can-write-your-code-it-cant-do-your-job",
    "title": "AI Can Write Your Code. It Can't Do Your Job",
    "description": "The companies building AI are spending billions to acquire engineers, not replace them. Here’s why your job is safer than you think.",
    "fullText": "In May, OpenAI agreed to pay $3 billion for Windsurf, the AI coding assistant formerly known as Codeium. Three billion dollars. For a VSCode fork.\n\nThe deal eventually fell apart, but what matters is that they wanted to do it in the first place.\n\nLast week, Anthropic made an interesting acquisition: they bought Bun, the JavaScript runtime. Bun is open source and MIT-licensed. Anthropic could have forked it and built on top of it for free. They have Claude Code, an excellent code-writing tool.\n\nInstead, they bought the company. Because they wanted Jarred Sumner and his team.\n\nThis is what I keep coming back to when I see another “Programming is dead” post go viral. The companies building AI, the ones who supposedly know exactly what it can and can’t do, are spending billions to acquire engineering talent. Not fire them, acquire them.\n\nIf OpenAI believed GPT could replace software engineers, why wouldn’t they build their own VS Code fork for a fraction of that cost? If Anthropic thought Claude could do the work, why make an acquisition at all?\n\nHere’s my take: AI can replace most of programming, but programming isn’t the job.\n\nProgramming is a task. It’s one of many things you do as part of your work. But if you’re a software engineer, your actual job is more than typing code into an editor.\n\nThe mistake people make is conflating the task with the role. It’s like saying calculators replaced accountants. Calculators automated arithmetic, but arithmetic was never the job. The job was understanding financials, advising clients, making judgment calls, etc. The calculator just made accountants faster at the mechanical part.\n\nAI is doing something similar for us.\n\nThink about what you actually do in a given week.\n\nYou sit in a meeting where someone describes a vague problem, and you’re the one who figures out what they actually need. You look at a codebase and decide which parts to change and which to leave alone. You push back on a feature request because you know it’ll create technical debt that’ll haunt the team for years. You review a colleague’s PR and catch a subtle bug that would’ve broken production. You make a call on whether to ship now or wait for more testing.\n\nNone of that is programming, but it’s all your job.\n\nI’m not going to pretend nothing is changing.\n\nWill some companies use AI as an excuse to cut headcount? Absolutely. Some already have. There will be layoffs blamed on “AI efficiency gains” that are really just cost-cutting dressed up as something else.\n\nBut think about who stays and who goes in that scenario. It’s not random. The engineers who understand that programming isn’t the job, the ones who bring judgment, context, and the ability to figure out what to build, those are the ones who stay. The ones who only brought code output might be at risk\n\nA common worry is that juniors will get left behind. If AI handles the “doing” part, how do they build judgment? I actually think the opposite is true. AI compresses the feedback loop. What used to take days of flipping through books or waiting for Stack Overflow answers now takes seconds. The best juniors aren’t skipping steps, but getting through them faster.\n\nNow think about your own situation. Say you were hired two years ago, before the current AI wave. Your company wanted you. They saw value in what you bring. Now, with AI tools, you’re significantly more productive. You ship faster. You handle more complexity. You’re better at your job than ever before.\n\n“You got way more productive, so we’re letting you go” is not a sentence that makes a lot of sense.\n\nIf you’re reading this, you’re already thinking about this stuff. That puts you ahead. Here’s how to stay there:\n\nThe shape of the work is changing: some tasks that used to take hours now take minutes, some skills matter less, others more.\n\nBut different isn’t dead. The engineers who will thrive understand that their value was never in the typing, but in the thinking, in knowing which problems to solve, in making the right trade-offs, in shipping software that actually helps people.\n\nOpenAI and Anthropic could build their own tools. They have the best AI in the world. Instead, they’re spending billions on engineers. That should tell you something.",
    "readingTime": 4,
    "keywords": [
      "programming isn’t",
      "you’re",
      "ones",
      "engineers",
      "it’s",
      "software",
      "judgment",
      "faster",
      "fork",
      "acquisition"
    ],
    "qualityScore": 1,
    "link": "https://terriblesoftware.org/2025/12/11/ai-can-write-your-code-it-cant-do-your-job/",
    "thumbnail_url": "https://terriblesoftware.org/wp-content/uploads/2025/12/chjpdmf0zs9sci9pbwfnzxmvd2vic2l0zs8ymdiylta0l3vwd2s2mtc5nzyync13awtpbwvkawetaw1hz2uta293ctv0bheuanbn.webp",
    "created_at": "2025-12-12T18:56:02.981Z",
    "topic": "tech"
  },
  {
    "slug": "2-artificial-intelligence-stocks-that-could-help-make-you-a-fortune-in-2026",
    "title": "2 Artificial Intelligence Stocks That Could Help Make You a Fortune in 2026",
    "description": "Broadcom and UiPath both have huge opportunities in front of them.",
    "fullText": "Broadcom has a massive opportunity ahead with custom AI chips.\n\nUiPath has huge potential upside as its revenue starts to accelerate.\n\nThese 10 stocks could mint the next wave of millionaires ›\n\nAs 2025 begins to wind down, it will go down as another strong year for artificial intelligence (AI) stocks. Meanwhile, with AI still appearing to be in its early innings, the group could help lead the market higher in 2026 once again.\n\nLet's look at two AI stocks that could help you make a fortune in 2026.\n\nOne AI stock that looks like it could outperform in 2026 is Broadcom (NASDAQ: AVGO), as it has some of the best growth prospects of any AI infrastructure company.\n\nThe company is already seeing strong growth coming from its data center networking portfolio, which helps transfer data and distribute AI workloads across servers to help optimize performance. Products like its Tomahawk Ethernet switch and Jericho4 Ethernet fabric router are popular and helping power its networking growth.\n\nHowever, Broadcom's ASICs (application-specific integrated circuits) business is what should get investors excited the most. ASICs are custom chips that are pre-programmed to handle specific tasks, and because they are purpose-built, they tend to deliver improved performance with greater energy efficiency than general-purpose chips, such as graphics processing units (GPUs). Broadcom made a name for itself in this business when it helped Alphabet design its well-regarded tensor processing units (TPUs) that are helping Alphabet power much of its internal AI workloads, as well as those for external cloud computing customers.\n\nThat success has led to other hyperscalers (owners of large data centers) partnering with Broadcom to design their own custom chips. The company has called out its three custom AI chip customers furthest along as being an up to $90 billion opportunity in fiscal 2027, and then announced that a fourth customer has placed a $10 billion order for next year. It also recently struck a deal with OpenAI to supply it with 10 gigawatts of custom AI chips, in a deal worth hundreds of millions of dollars.\n\nWith these deals in place, Broadcom could see explosive growth in the coming years, which could propel its stock much higher in 2026 and beyond.\n\nAnother company whose stock could help you make a fortune next year is UiPath (NYSE: PATH). The company is in the midst of a transformation that could see it become one of the most important players in agentic AI.\n\nUiPath is a stalwart in the field of robotic process automation (RPA), which uses software bots to perform simple, rules-based tasks. However, it's using this background in managing software bots to become an orchestration platform that can manage both software bots and AI agents.",
    "readingTime": 3,
    "keywords": [
      "processing units",
      "software bots",
      "custom chips",
      "growth",
      "stocks",
      "stock",
      "opportunity",
      "another",
      "higher",
      "fortune"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/2-artificial-intelligence-stocks-could-090500087.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ArCO_5RCQc_Aa8M.K4K4QA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/68ea2d44f90c910427485d4936367d7b",
    "created_at": "2025-12-12T18:56:00.581Z",
    "topic": "finance"
  },
  {
    "slug": "if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography",
    "title": "If Google wins AI race, Nvidia is 'in trouble,' says author of Jensen Huang biography",
    "description": "Jensen Huang biography author Stephen Witt explains why Google's self-developed AI model, Gemini, could pose a threat to Nvidia's AI dominance",
    "fullText": "Nvidia's (NVDA) AI turf could take a blow if Google (GOOGL, GOOG) keeps firing on all cylinders.\n\n\"The biggest risk right now obviously is Google,\" said Stephen Witt, author of \"The Thinking Machine,\" a Jensen Huang biography.\n\nThat risk, he told Yahoo Finance's Opening Bid, is largely tied to Google's Gemini model. Witt described it as the \"best AI right now in the benchmarks outside the Nvidia stack.\"\n\nWitt explained that Gemini was trained entirely on its Tensor Processing Units (TPUs). If Google proves it can sustain world-leading AI development using only its homegrown chip stack, it sets a potent precedent for other tech giants to follow suit.\n\n\"That's a huge risk,\" Witt said. \"If Google ends up winning this AI race ... Nvidia will be in trouble.\"\n\nThis risk, coupled with competition from rivals like Broadcom (AVGO) and Advanced Micro Devices (AMD), is why \"it's very easy to imagine a world\" where Nvidia's high-flying stock declines. The AI chipmaker's shares are up over 1,270% in the past five years.\n\nTo mitigate the core risk of rivals like Google winning the chip war, Nvidia CEO Jensen Huang is already looking past generative AI. Witt said a significant amount of the CEO's personal effort is being poured into the next great computing wave: robotics.\n\nIf Huang can dominate the robotics wave, he said, \"that will mean several trillion dollars in market capitalization for this company.\"\n\nHowever, Nvidia has another issue: the lack of any clear succession plan.\n\n\"It's just Jensen at the top,\" Witt said. \"There's no second in command. There's no obvious successor.\" He noted that the board has been silent, and Huang has offered no advice on a succession strategy.\n\nThat suggests Nvidia's $4 trillion valuation — which accounts for over 8% of the entire S&P 500 (^GSPC) — is, in many ways, resting solely on Huang's vision.\n\nWitt described Huang as a \"world-class engineer\" who could \"design these microchips himself,\" a skill that whoever takes the helm must also possess. He noted that neither of Huang's two children, who work at the company, has a technical background, making them noncontenders for the top spot.\n\nWitt also provided a look behind the polished stage persona of Huang, known for his trademark leather jacket. Beneath the showmanship is a highly intense, \"almost totally neurotic\" leader who is driven not by optimism, but by fear.\n\n\"He's driven by negative emotions, things like fear of failure, guilt, even shame are what make Jensen get up in the morning and work so hard to make Nvidia succeed,\" Witt explained.",
    "readingTime": 3,
    "keywords": [
      "jensen huang",
      "risk",
      "witt",
      "stack",
      "chip",
      "rivals",
      "it's",
      "wave",
      "robotics",
      "succession"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography-184624884.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/pgRIv4CaXitTJsbNTIjhsA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/60ef8cc0-d6b2-11f0-9a17-1d997177f998",
    "created_at": "2025-12-12T18:55:59.740Z",
    "topic": "finance"
  },
  {
    "slug": "doom-dev-id-software-forms-a-walltowall-union",
    "title": "Doom Dev id Software Forms A \"Wall-To-Wall\" Union",
    "description": "Developer id Software, a Texas-based studio known for the Doom games (including The Game Awards-winning The Dark Ages), has, has formed a union under the Communications Workers of America (CWA). It's a \"wall-to-wall\" guild built to protect employees from AI while negotiating for ample benefits, such as remote work, and Microsoft appears to have recognized the studio's union.\nIn a press release on the CWA's website, id Software's 165-person union will join the CWA Local 6215 division in Richardson, Texas. Producer Andrew Willis noted how important it is for workers to fight back against the injustices facing the games industry at the moment.\n\"The wall-to-wall organizing effort at id Software was much needed; it's incredibly important that developers across the industry unite to push back on all the unilateral workplace changes that are being handed down from industry executives,\" Willis said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/doom-dev-id-software-forms-a-wall-to-wall-union/1100-6536938/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1578/15789366/4621767-dtdaimage.jpg",
    "created_at": "2025-12-12T18:55:57.349Z",
    "topic": "tech"
  },
  {
    "slug": "godmother-of-ai-says-degrees-are-less-important-in-hiring-than-how-quickly-can-you-superpower-yourself-with-new-tools",
    "title": "‘Godmother of AI’ says degrees are less important in hiring than ‘how quickly can you superpower yourself’ with new tools",
    "description": "Instead, she looks to hire software engineers with AI fluency to her startup that aims to revolutionize the tech.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/fei-fei-li-stanford-professor-godmother-ai-college-degrees-skills-talent-ceo/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247144876-e1765553881661.jpg?resize=1200,600",
    "created_at": "2025-12-12T18:55:54.101Z",
    "topic": "business"
  },
  {
    "slug": "broadcom-is-the-latest-victim-of-skyhigh-expectations-from-ai-investors",
    "title": "Broadcom is the latest victim of sky-high expectations from AI investors",
    "description": "Broadcom shares tumbled on Friday as investors balked at some disappointing aspects of the company's outlook heading into 2026.",
    "fullText": "Broadcom is the latest victim of investors punishing high-flying AI companies.\n\nThe chipmaker tumbled 8% as investors took in its stellar results for the last quarter, but were left disappointed by certain aspects of the company's outlook.\n\nThe firm beat on earnings and revenue, leading shares to initially rise after-hours on Thursday, before falling into the red as CEO Hock Tan dug into the results in the call with analysts.\n\n\"It was surprising to see a call that started with such good numbers and such a great story end with frustration,\" Josh Meyers, an executive director at JPMorgan, wrote in a client note on Friday.\n\nHere's where major indexes stood shortly after the 9:30 a.m. ET opening bell on Friday:\n\nOther chip stocks also lost slightly, extending a decline in the sector that kicked off after Oracle reported earnings earlier in the week. Here were some of the notable moves:\n\nBroadcom investors seemed disappointed in how the company didn't issue full AI revenue guidance for the coming year, Deutsche Bank and JPMorgan wrote on Friday. Broadcom said it expected AI semiconductor revenue to double to $8.2 billion in the following quarter.\n\nInvestors also seemed \"underwhelmed\" by the firm's $73 billion backlog of AI product orders over the next 18 months, Paul Hickey, the co-founder of Bespoke Investment Group, said in a note.\n\n\"Somehow some investors seized on this as 'not enough,' which compounded an earlier narrative today that somehow we needed more visibility on F27 AI revenue (no idea why this is suddenly an issue),\" JPMorgan's Meyers wrote.\n\nSome investors also feel that the Tan was more \"buttoned-up\" about the company's results than they would have liked, Meyers said, citing his conversations with shareholders.\n\nThe stock is a crowded trade in the already popular AI theme, and some may also think the market \"just needed to take a breath\" from the AI trade, Meyers said. Shares of Broadcom are still up more than 56% this year.\n\nInvestors have put more pressure on the semiconductor sector in recent months amid concerns about the sustainability of the AI trade, which has led to some firms getting punished despite beating on earnings and revenue.\n\nOracle shares plunged 14% on Thursday as investors took in lower-than-expected quarterly revenue and worries that the software giant is overspending on AI.\n\nMeta and Microsoft shares also dropped after the companies reported earnings in October, as both tech titans promised to spend more on AI in the coming years.",
    "readingTime": 3,
    "keywords": [
      "investors",
      "revenue",
      "earnings",
      "trade",
      "quarter",
      "disappointed",
      "company's",
      "note",
      "sector",
      "oracle"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/broadcom-stock-price-avgo-q4-earnings-ai-chips-revenue-outlook-2025-12",
    "thumbnail_url": "https://i.insider.com/693c294064858d02d216b42a?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.125Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-making-the-chros-job-a-whole-lot-bigger",
    "title": "How AI is making the CHRO's job a whole lot bigger",
    "description": "AI is reshaping the CHRO role, requiring HR leaders to become AI strategists and bridge people, technology, and data in today's workforce.",
    "fullText": "AI is changing how companies hire, train, and lead, and in the process, the chief human resources officer's role is expanding.\n\nToday's top HR leaders are becoming AI strategists, helping their organizations navigate the next wave of workplace transformation.\n\n\"The old model of HR was employees over here, technology over there,\" says Thomas Hutzschenreuter, a university professor at the Technical University of Munich (TUM). \"But the new model of work is human-AI collaboration.\"\n\nAI is a coworker now, he says, and that means that \"HR has a bigger mandate. They need to understand not just people and culture, but go deeper into the strategy, the business, and the technology itself.\"\n\nTo understand how companies are navigating the shift, Business Insider spoke with people leaders at Citizens Bank, one of the largest banks in the Northeast; Boston Consulting Group, a global consultancy; and UiPath, an automation software testing company.\n\nAll interviews have been edited for brevity.\n\nCHROs are becoming the architects of the future of work, bridging people, technology, and data.\n\nThere are many questions we are in the middle of that are germane to how we as an organization move forward, such as: What's going to happen to entry-level roles? What roles are emerging? And how do we reskill people in a way that prepares them to make shifts thoughtfully?\n\nWe need people who can quickly learn, adapt, and change. Our technologists need to develop their business acumen, and our business folks need to develop their digital and technical fluency. The lines are blurring.\n\nMy HR team is developing a baseline of skills and capabilities. We're having conversations with consulting partners and clients. There's an openness to communal learning because everyone is trying to figure out the same things: what the AI-driven workforce will look like, how to break work into tasks for AI vs. humans, and what AI agents can handle versus humans.\n\nWe're subject to a lot of regulatory oversight in our industry. It's great that people can develop their own AI agents — there's a push to decentralize these capabilities — but we need to be mindful of risk and governance and how we do this in a safe, ethical way.\n\nAI is changing how work gets done and what work gets done. Business models are evolving, and the way companies serve clients is shifting. The CHRO role now requires adapting to both at once. It's a tall order.\n\nIn consulting, our ability to add value means constantly evolving our approach to human capital. The issues are constant; the pace is what's different. Today, a quarter of our business involves AI, which wasn't true even two years ago.\n\nWe need our people to be AI fluent. About 90% of our workforce uses AI regularly, and more than half use it daily. To get there, we've built a multi-layered support system: a 1,400-person enablement network acting as evangelists and coaches.\n\nWe've upskilled more than 100 team coaches to provide hands-on support. We deploy experts directly into teams to help them reimagine workflows and run innovation competitions to keep momentum going.\n\nOur HR team has taken the lead. We started with recruiting — consolidating six IT systems into one and integrating AI throughout the platform and across performance management and development.\n\nWe're also experimenting with voice tools, chat interfaces, and AI avatars for real-time coaching. These tools give employees confidence, learning opportunities, and instant feedback. They don't replace managers — they free them up for higher-level thinking and relationship-building.\n\nOur business is automation, so that muscle is very strong for my team. But the next frontier of agentic AI is an adjustment.\n\nWe're using these AI agents — but we're also creating them. One agent, almost in production, helps with performance reviews, which is a time-consuming and sometimes dreaded task. Our agent helps employees write their self-assessment and collects feedback, bringing it together much quicker. It also helps managers by consolidating feedback from multiple resources.\n\nIt won't make rating decisions on the manager's behalf, but it makes the year-end much more seamless. Instead of spending time on admin, managers can focus on the feedback itself and my team on the right framework for career development.\n\nThere are a lot of unknowns at the moment, and fear is natural. But it should fuel curiosity and development. This is the time to think about career development seriously.\n\nWe have this idea that AI is only affecting entry-level or lower-level jobs. The truth is that technology is replacing skills that very highly skilled people have been doing.\n\nIf you look at the medical field and aviation — areas where we always thought technology wouldn't touch — that's no longer the case. It's not going to happen overnight. We have time to prepare. But it's relevant for everybody in any profession.",
    "readingTime": 4,
    "keywords": [
      "career development",
      "technology",
      "team",
      "we're",
      "feedback",
      "employees",
      "agents",
      "managers",
      "business",
      "changing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-transforms-chro-roles-bridge-people-tech-business-strategy-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c47a71107c9f3457b614?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.066Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-finally-paying-for-ai-and-paying-big",
    "title": "Companies are finally paying for AI, and paying big",
    "description": "AI enterprise spending is about to surge as CIOs allocate new budgets for generative AI projects in 2026, surveys finds.",
    "fullText": "For much of the past year, Wall Street and Silicon Valley have wrestled with the same uncomfortable question: Will companies really spend money on AI, or is the hype just outpacing budgets?\n\nA new CIO survey from RBC Capital suggests that question may finally have an answer, and it's a resounding yes.\n\nRBC recently polled 117 IT professionals at companies with annual revenue ranging from below $250 million to more than $25 billion. 90% of the respondents said their organizations plan to spend more on AI in 2026.\n\n\"Overall, we came away increasingly optimistic of macro/budget stabilization taking shape in 2026 and encouraged by the pace of early GenAI adoption,\" the RBC analysts wrote in a research note summarizing the findings.\n\nCIOs are not only moving rapidly into production with AI systems, but they are also setting aside dedicated budgets to fund that adoption.\n\nA striking 90% of technology leaders said their organizations are creating new budgets specifically for generative AI and LLM projects, up from 85% the year before. That suggests AI is becoming additive rather than substitutive in enterprise tech spending.\n\nEven more telling: 60% of respondents said they are already in production with AI initiatives, a jump from 39% the previous year. Another 32% expect to be in production within six months.\n\nThis shift comes after months of skepticism from investors who questioned whether businesses would convert pilot projects into real spending. The survey data suggests that moment is now arriving.\n\nCIOs overwhelmingly cited AI as the top category for increased software spending next year, surpassing cybersecurity and IT service management. And in open-ended responses, executives repeatedly named AI as their biggest area of investment for 2026, often paired with infrastructure upgrades and automation initiatives, according to the RBC survey.\n\nUse cases are expanding beyond experimentation. Seventy-six percent of CIOs said their AI strategies now target both cost savings and revenue generation, a shift that reinforces AI's transition from a novelty to a competitive mandate.\n\nConcerns remain — data privacy tops the list — but those worries are no longer slowing adoption. Instead, AI is becoming the primary force expanding IT budgets heading into 2026.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "budgets",
      "survey",
      "adoption",
      "cios",
      "production",
      "revenue",
      "respondents",
      "organizations",
      "projects",
      "initiatives"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/companies-finally-paying-ai-cio-survey-2025-12",
    "thumbnail_url": "https://i.insider.com/693b59c204eda4732f2d6898?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:52.598Z",
    "topic": "finance"
  },
  {
    "slug": "openais-merch-store-offers-a-glimpse-inside-the-companys-vibe",
    "title": "OpenAI's merch store offers a glimpse inside the company's vibe",
    "description": "The \"OpenAI Supply Co.\" has 10 merch items available for purchase, and dozens of more archived designs. Most sizes have sold out.",
    "fullText": "You can now wear ChatGPT on your sleeve — or head or shin.\n\nAs part of its 10-year anniversary celebration, OpenAI dropped a link on its X feed to a merchandise store. The \"OpenAI Supply Co.\" seems suited for the company's engineers, with a space to log in with a company email. Indeed, most of the items listed are archives of old designs — but a few are available for purchase.\n\nThe \"Supply Co.\" site was marked as \"coming soon\" in July 2024, according to the Internet Archive. But this appears to be the first time ChatGPT users who aren't employees can actually buy something from it.\n\nOpenAI fans ate it up. The post garnered over 3,000 likes within 15 hours, and multiple sizes of the for-sale items were quickly sold out. If you're anything other than an extra small or a small, you're out of luck on sweatshirts and tees.\n\nThe items OpenAI listed give a glimpse inside the company — or at least its swag.\n\nThere are five Pokémon-style trading cards. Their subjects include Sora 2 (\"shape-shifter\"), GPT-5 (\"two worlds, one model\"), image generation (with a \"huge\" wow factor), Sora (\"sci-fi\"), and the OpenAI Blossom (\"back and better\").\n\nPokémon has recently been a point of contention for the company, after its Sora video generator began booting out unauthorized versions of Pikachu.\n\nMuch of the site is themed around AGI, or artificial general intelligence, a much debated breakthrough milestone that many AI companies are racing to hit. One shirt reads: \"AGI that benefits all of humanity,\" a line from OpenAI's charter. On the employee log-in, the suggested email is agi@openai.com.\n\nThe assortment of hats also offers clues. There are Sora beanies and baseball caps with the word \"research.\" One cap has the chatbot's phone number, 1-800-CHATGPT. (Yes, the number still works.)\n\nAnother cap has OpenAI in red letters on camo print, resembling the popular Harris/Walz hat, which nods to Chappell Roan.\n\nThe baseball caps kept coming. There's one with silver flames, a piece of early 2000s nostalgia. There's another with the letters \"SF\" on it, firmly planting OpenAI in the city of San Francisco.\n\nAll the way at the bottom of the page is a baseball cap with the words \"Thinking deeply.\" The site says that it was released in September 2024 in honor of OpenAI's reasoning model. It also looks remarkably similar to Anthropic's \"thinking\" caps, which launched a year later at the company's Air Mail pop-up.\n\nAnthropic's \"thinking\" caps quickly became a status symbol, signifying the wearer's closeness to the AI boom. Cursor's tab keys had a similar effect, as did OpenAI's DevDay token plaques.\n\nIt's possible that this merchandise drop will have the same effect. Your ChatGPT crew neck could give you caché.\n\nThe fans have clearly been hungry. Fan-created merchandise concepts have long floated around X. Some even turned their designs into unauthorized businesses.\n\nThirty minutes before its post about the tenth anniversary, OpenAI responded to a fan post. Developer Tibor Blaho posted some of the merch, saying that the company should make its store \"public instead of keeping it employee-only.\" OpenAI responded with the link and an eye emoji.\n\nBlaho's post was 10 months ago.",
    "readingTime": 3,
    "keywords": [
      "openai responded",
      "baseball caps",
      "sora",
      "merchandise",
      "items",
      "site",
      "anniversary",
      "link",
      "store",
      "company's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-merch-supply-co-2025-12",
    "thumbnail_url": "https://i.insider.com/693c27cb64858d02d216b405?width=1113&format=jpeg",
    "created_at": "2025-12-12T18:55:52.542Z",
    "topic": "finance"
  },
  {
    "slug": "new-research-on-ai-and-fairness-in-hiring",
    "title": "New Research on AI and Fairness in Hiring",
    "description": "AI promises to make hiring fairer by reducing human bias, yet it often reshapes what fairness means—and locks in one definition. A three-year study of a global consumer-goods firm found that their algorithmic system privileged a rigid definition that sidelined manager’s local judgment. This resulted in narrow candidate pools and unhappy hiring managers. The study underlined that fairness isn’t embedded in code, it’s negotiated by people who design and deploy it. To make AI hiring systems work better for more people, leaders must ask: Which versions of fairness exist?",
    "fullText": "New Research on AI and Fairness in Hiring by Elmira van den Broek, Anastasia Sergeeva and Marleen HuysmanDecember 12, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWill AI improve or degrade fairness? With nearly 90% of companies now using some form of AI in hiring, this question is top of mind for many leaders, and it tends to split them into two camps. One side believes algorithms will make hiring fairer by reducing human “bias” and “noise” in decision-making. The other warns that algorithms can reproduce and even amplify existing inequalities at scale. Both overlook a crucial reality: When AI is adopted, it reshapes what counts as fair in the first place.",
    "readingTime": 1,
    "keywords": [
      "hiring",
      "algorithms",
      "fairness"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/new-research-on-ai-and-fairness-in-hiring",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_13_200560131-001.jpg",
    "created_at": "2025-12-12T18:55:51.703Z",
    "topic": "science"
  },
  {
    "slug": "trumps-ai-order-faces-political-and-legal-hurdles",
    "title": "Trump's AI order faces political and legal hurdles",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/politics-news/trumps-ai-order-faces-political-and-legal-hurdles-4406498",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBB11W_L.jpg",
    "created_at": "2025-12-12T18:55:51.568Z",
    "topic": "finance"
  },
  {
    "slug": "the-best-big-media-merger-is-no-merger-at-all",
    "title": "The Best Big Media Merger Is No Merger at All",
    "description": "The state of streaming is... bad. It’s very bad. The first step in wanting to watch anything is a web search: “Where can I stream X?” Then you have to scroll past an AI summary with no answers, and then scroll past the sponsored links.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.eff.org/deeplinks/2025/12/best-big-media-merger-no-merger-all",
    "thumbnail_url": "https://www.eff.org/files/banner_library/icon-2019-innovation.png",
    "created_at": "2025-12-12T13:47:26.391Z",
    "topic": "tech"
  },
  {
    "slug": "disney-wants-you-to-aigenerate-yourself-into-your-favorite-marvel-movie",
    "title": "Disney wants you to AI-generate yourself into your favorite Marvel movie",
    "description": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n Continue reading...",
    "fullText": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\n\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\n\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n\nDisney announced that it would invest $1bn in OpenAI and, under a three-year deal perhaps worth even more than that large sum, that it would license about 200 of its iconic characters – from R2-D2 to Stitch – for users to play with in OpenAI’s video generation app.\n\nAt a time of intense anxiety in Hollywood over the impact of AI on the livelihoods of writers, actors, visual effects artists and other creatives, Disney stressed its agreement with OpenAI would not cover talent likenesses or voices.\n\nThe announcement was framed as an extraordinary opportunity to empower fans.\n\nThink of the “fan-inspired Sora short form videos”, as Disney called them in a press release – akin to taking an AI-generated version of a photo with Princess Jasmine at Disney World. OpenAI included screenshots of these kinds of videos in its press release, indicating how the two companies expect people to use the app’s new cast. Sora already allows users to generate videos that include their own likenesses.\n\nBob Iger, Disney’s CEO, said the licensing deal would place “imagination and creativity directly into the hands of Disney fans in ways we’ve never seen before”.\n\nThey may even offer a chance at wide viewership, with some fan-made videos being displayed on the Disney+ streaming service, a move seemingly designed to compete with TikTok’s and YouTube Shorts’ infinite feeds, which themselves often include clips of popular TV shows and movies.",
    "readingTime": 2,
    "keywords": [
      "press release",
      "generation app",
      "allows users",
      "generate videos",
      "characters",
      "disney",
      "announcement",
      "startup",
      "deal",
      "likenesses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2025/dec/11/disney-openai-sora",
    "thumbnail_url": "https://i.guim.co.uk/img/media/d99390e95d50b47f91bcc8a3130e524c618e635d/436_0_4324_3458/master/4324.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=67d482fa7d7bed846eb736aeb1dfde1c",
    "created_at": "2025-12-12T13:47:25.564Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-teams-with-el-salvador-to-bring-grok-chatbot-to-public-schools",
    "title": "Elon Musk teams with El Salvador to bring Grok chatbot to public schools",
    "description": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n Continue reading...",
    "fullText": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\n\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\n\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n\nNayib Bukele, El Salvador’s president, is now entrusting the chatbot to create curricula in classrooms across the country. Bukele has long embraced technology, making El Salvador the first county in the world to use bitcoin as legal tender, and being one of the first Central American presidents to use Twitter, now X, as a platform. He is also known for ruling with an iron fist and working with Trump to incarcerate deportees to El Salvador’s notorious Cecot prison.\n\n“El Salvador doesn’t just wait for the future to happen; we build it,” Bukele said in a statement about the partnership with xAI. “This partnership is destined to deliver something rather extraordinary for all of humanity.”\n\nMusk touted his partnership with Bukele on Thursday. On X, between posts about “white genocide” and blaming asylum seekers for crime, Musk posted comments about Grok being spread throughout El Salvador’s schools.\n\nHe reposted positively to a comment from Katie Miller, the wife of Trump’s senior adviser Stephen Miller, in which she wrote: “If we are serious about restoring education to math, science and English – why would we allow left leaning liberal [sic] AI our kids? This unlocks non-woke educational tools for our kids.”\n\nxAI is not the first artificial intelligence company to introduce chatbots to public schools. OpenAI announced a partnership with Estonia in February where it could provide all students and teachers in the country’s secondary school system with a customized ChatGPT. Students in rural Colombia also started using Meta’s AI chatbots in 2023 and within a year, teachers began blaming the tech for low grades and failing exams, according to Rest of World.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 3,
    "keywords": [
      "nayib bukele",
      "guardian app",
      "artificial intelligence",
      "white genocide",
      "el salvador",
      "el salvador’s",
      "chatbot",
      "partnership",
      "grok",
      "schools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/11/elon-musk-el-salvador-grok",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7110440275e2c1e8231708520c23cbc728846c00/401_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=585578e2aeb3d5963fc6677b1ca099f4",
    "created_at": "2025-12-12T13:47:25.075Z",
    "topic": "tech"
  },
  {
    "slug": "mcp-and-workflow-for-specdriven-development-with-claude-code",
    "title": "MCP and workflow for spec-driven development with Claude Code",
    "description": "Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust 🦀 - marconae/spec-oxide",
    "fullText": "marconae\n\n /\n\n spec-oxide\n\n Public\n\n Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust 🦀\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n marconae/spec-oxide",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/marconae/spec-oxide",
    "thumbnail_url": "https://opengraph.githubassets.com/e5b240d3d85c84aad2b2aff0a433f6f4034b00bbdd75ee07c24ade4e6e0525c7/marconae/spec-oxide",
    "created_at": "2025-12-12T13:47:24.935Z",
    "topic": "tech"
  },
  {
    "slug": "disney-plus-openai-what-could-possibly-go-wrong",
    "title": "Disney plus OpenAI: What could possibly go wrong?",
    "description": "Disney’s deal with OpenAI may prove prescient and astute, but it doesn't take a lot of imagination to think about the nightmare scenarios.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/disney-plus-openai-what-could-possibly-go-wrong/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2251267095-e1765501885187.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.330Z",
    "topic": "business"
  },
  {
    "slug": "openai-microsoft-face-wrongful-death-lawsuit-over-paranoid-delusions-that-led-former-tech-worker-into-murdersuicide",
    "title": "OpenAI, Microsoft face wrongful death lawsuit over ‘paranoid delusions’ that led former tech worker into murder-suicide",
    "description": "Police said Stein-Erik Soelberg, 56, fatally beat and strangled his 83-year-old mother, Suzanne Adams, and then killed himself in early August.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-microsoft-wrongful-death-lawsuit-murder-suicide-greenwich-connecticut-chatgpt/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/AP25345700615297.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.159Z",
    "topic": "business"
  },
  {
    "slug": "an-ai-agent-spent-16-hours-hacking-stanfords-network-it-outperformed-human-pros-for-much-less-than-their-sixfigure",
    "title": "An AI agent spent 16 hours hacking Stanford's network. It outperformed human pros for much less than their six-figure salaries.",
    "description": "An AI agent hacked Stanford's network for 16 hours and outperformed human pros, all while costing far less than their six-figure pay.",
    "fullText": "For 16 hours, an AI agent crawled Stanford's public and private computer science networks, digging up security flaws across thousands of devices.\n\nA study published Wednesday by Stanford researchers found that their AI agent, ARTERMIS, placed second in an experiment with 10 selected cybersecurity professionals. The researchers said the agent could uncover weaknesses that humans missed and investigate several vulnerabilities at once.\n\nRunning ARTEMIS costs about $18 an hour, far below the average salary of about $125,000 a year for a \"professional penetration tester,\" the study said. A more advanced version of the agent costs $59 an hour and still comes in cheaper than hiring a top human expert.\n\nThe study was led by three Stanford researchers — Justin Lin, Eliot Jones, and Donovan Jasper — whose work focuses on AI agents, cybersecurity, and machine-learning safety. The team created ARTEMIS after finding that existing AI tools struggled with long, complex security tasks.\n\nThe researchers gave ARTEMIS access to the university's network, consisting of about 8,000 devices, including servers, computers, and smart devices. Human testers were asked to put in at least 10 hours of work while ARTEMIS ran 16 hours across two workdays. The comparison with human testers was limited to the AI's first 10 hours.\n\nThe study also tested existing agents, which lagged behind most human participants, while ARTEMIS performed \"comparable to the strongest participants,\" the researchers said.\n\nWithin the 10-hour window, the agent discovered \"nine valid vulnerabilities with an 82% valid submission rate,\" outperforming nine of 10 human participants, the study said.\n\nSome of the flaws had gone unnoticed by humans, including a weakness on an older server that testers could not access because their browsers refused to load it. ARTEMIS bypassed the issue and broke in using a command-line request.\n\nThe AI worked in a way humans could not, the researchers said. Whenever ARTEMIS spotted something \"noteworthy\" in a scan, it spun up additional \"sub-agents\" to investigate in the background, allowing it to examine multiple targets simultaneously. Human testers had to do this work one step at a time.\n\nBut the AI isn't flawless. ARTEMIS struggled with tasks that required clicking through graphical screens, causing it to overlook a critical vulnerability. It is also more prone to false alarms, mistaking harmless network messages for signs of a successful break-in.\n\n\"Because ARTEMIS parses code-like input and output well, it performs better when graphical user interfaces are unavailable,\" the researchers said.\n\nAdvances in AI have lowered the barrier to hacking and disinformation operations, allowing malicious actors to enhance their attacks.\n\nIn September, a North Korean hacking group used ChatGPT to generate fake military IDs for phishing emails. A report from Anthropic in August found that North Korean operatives used its Claude model to obtain fraudulent remote jobs at US Fortune 500 tech companies — a tactic that gave them insider access to corporate systems.\n\nThe same report also said a Chinese threat actor used Claude to run cyberattacks on Vietnamese telecom, agricultural, and government systems.\n\n\"We are seeing many, many attacks,\" Yuval Fernbach, the chief technology officer of machine learning operations at software supply chain company JFrog, told Business Insider in a report published in April. He added that hackers have been using AI models to extract data, shut systems down, or manipulate a website or tools.",
    "readingTime": 3,
    "keywords": [
      "stanford researchers",
      "human testers",
      "human participants",
      "agent",
      "study",
      "hours",
      "devices",
      "humans",
      "hour",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-agent-hacker-stanford-study-outperform-human-artemis-2025-12",
    "thumbnail_url": "https://i.insider.com/693bccf004eda4732f2d6a8d?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.654Z",
    "topic": "science"
  },
  {
    "slug": "im-the-former-chief-ai-officer-at-gm-being-the-caio-is-like-being-the-master-chef-of-a-restaurant",
    "title": "I'm the former chief AI officer at GM. Being the CAIO is like being the master chef of a restaurant.",
    "description": "Barak Turovsky said that if a company wants to integrate AI on a software level, it needs someone with a different kind of expertise.",
    "fullText": "This as-told-to essay is based on a conversation with Barak Turovsky, the former Chief AI Officer at General Motors, based in Silicon Valley. He also held executive roles at Google and Cisco. The following has been edited for length and clarity.\n\nI have worked on AI and LLMs since 2014 — way before they became the hottest thing on Earth.\n\nI'm an ex-Google AI exec who led the first scaled deployment of LLMs and Deep Neural Networks with Google Translate. I also worked as the Chief Product and Technology Officer at a computer vision AI startup, and as the VP of AI at Cisco.\n\nGeneral Motors approached me for the Chief AI Officer role while I was at Cisco, and it felt like a great crash course on using AI to develop physical products. The role no longer exists because I left after GM restructured its software and AI organization; however, until November, I reported to the head of software engineering, who reported to the CEO.\n\nSome people ask, \"Do you really need a dedicated AI officer?\"\n\nLet's ignore the title because you can call it different names, but I do believe successful AI implementation requires someone in leadership to drive that change, as well as commitment from the top.\n\nFunctional business leaders, such as the CTO or CIO, may have little or no understanding of AI. If you want to integrate AI on a software level, you need someone with a different kind of expertise.\n\nTraditional large companies have powerful executives who want to own the benefits of scaling AI, but not necessarily the responsibility. Therefore, someone with deep AI knowledge is needed to direct the traffic.\n\nI like to use a restaurant analogy to break it down.\n\nThe analogy is based on three primary resources that create products, or dishes. The first resource includes the kitchen equipment, or the AI infrastructure and models necessary to build AI solutions.\n\nThe next can be thought of as the ingredients. It's the data or internal assets used to train and run AI solutions. The last one is talent, or the restaurant staff. You need expertise at different levels — busboys, short-order cooks, sous chefs, and master chefs for the really gourmet restaurants.\n\nThe complexity of creating the final product depends on the company's needs, specifically whether the restaurant needs to prepare the food internally. For very advanced, cutting-edge models, which can be thought of as the main course at a gourmet restaurant, companies often need to develop their own AI solutions because standard versions may not perform the required functions.\n\nThink of the CAIO as the master chef. They need to make sure all the different pieces run smoothly. If you are in an industry that requires cutting-edge solutions, you also need to spend a lot of time making sure that the hardest output — a.k.a. the main dish — comes out just right.\n\nThe hardest and most important part of the job is securing top talent. Vendors will tell you that their toaster ovens can pop out a French soufflé in 15 minutes. Yet your ingredients will consistently arrive late, of dubious quality, and in incorrect amounts. Your customers will come in, declare they are hungry and want to eat the whole menu, and then leave mid-meal without paying.\n\nThe specifics of each role vary. At GM, I worked on a cutting-edge area because AI for physical products, like cars, is largely untouched and getting a lot of traction.\n\nThere are three buckets of what a chief AI officer should do. First is AI talent management. I focused a lot on hiring a top-tier team, which is very important because the moment you enter a novel space, you have a small sliver of talent. They need to be motivated and flexible because you're still mapping out those areas.\n\nThen, you need to create a culture of innovation for the company in general. You need to work with internal stakeholders who might be used to doing things in a certain way, but need to change because of AI.\n\nYou also need to create organizational change, which starts with mapping the needs and players of your organization. You have people who are AI enthusiasts and skeptics. In a large organization, it's not always easy to identify them. You need to create a top-down and bottom-up framework, which includes clear goals from the top.\n\nIn every function, you need to identify champions, and you need to nurture and empower them. The CAIO can't do all the magic while everyone else just sits there.",
    "readingTime": 4,
    "keywords": [
      "physical products",
      "chief ai officer",
      "restaurant",
      "create",
      "solutions",
      "talent",
      "based",
      "role",
      "software",
      "organization"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/former-chief-ai-officer-general-motors-describes-role-2025-12",
    "thumbnail_url": "https://i.insider.com/6939ee6304d0f0a114f1ce51?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.547Z",
    "topic": "auto"
  },
  {
    "slug": "how-can-lawyers-stop-ais-hallucinations-more-ai-of-course",
    "title": "How can lawyers stop AI's hallucinations? More AI, of course.",
    "description": "Law firms can't stop lawyers from tinkering with chatbots, so they're adding hallucination detectors.",
    "fullText": "Law firm Cozen O'Connor has a rule against using publicly available chatbots to draft legal filings. But after a judge penalized two of its lawyers for citing fake cases, the firm is adding some extra protection: an AI hallucination detector.\n\nCozen O'Connor is now testing software, made by a startup called Clearbrief, that scans legal briefs for made-up facts and produces a report. Think spell-check, except instead of flagging typos, it spots the fictional cases and citations that generative tools sometimes invent.\n\n\"You have to be pragmatic,\" said Kristina Bakardjiev, the Cozen O'Connor partner tasked with harnessing technology to serve lawyers and their clients. She said lawyers will play around with chatbots whether the tools are authorized or not.\n\nStung by embarrassing AI hallucinations, the legal field has adopted bans on general-use chatbots and AI assistants. But it's hard to stop a curious associate from pasting a draft into a free, browser-based chatbot like ChatGPT, Claude, or Gemini. Now law firms and legal tech companies are scrambling to lower the risk of bogus citations and catch those that sneak through before they land in front of a judge.\n\nTwo of Cozen O'Connor's defense lawyers in September admitted they had filed a document riddled with fake cases after one of them used ChatGPT to draft it, against firm policy. A Nevada district court judge gave the firm a choice: remove the lawyers from the case and pay $2,500 in sanctions each, or have the pair write to their former law school deans and bar authorities explaining the fiasco and offering to speak in seminars on topics like \"professional conduct.\"\n\nBoth lawyers went with option No. 2. Cozen also fired the lawyer who had used ChatGPT.\n\nEarlier this year, Damien Charlotin, a legal data analyst and consultant, began tracking cases in which a court had discovered hallucinated content in a legal filing. Charlotin tallied 120 cases between April 2023 and May 2025. By December, his count had hit 660, with the rate of new cases accelerating to four or five per day.\n\nThe number of documented cases remains small relative to the total volume of legal filings, Charlotin said. Most cases in his database involved self-represented litigants or lawyers from small or solo firms. When large firms were involved, the hallucinations often slipped in through the work of junior staff, paralegals, experts, or consultants, or through processes like formatting footnotes, Charlotin said.\n\nHallucinated content is causing headaches in other professions, too. In October, consulting firm Deloitte agreed to pay a partial refund to the Australian government for a $290,000 report after officials found it was peppered with allegedly AI-generated errors.\n\nAI hallucinations are hard to eliminate because they're baked into the way chatbots work. Large language models are trained to predict the word that is most likely to come next, given the words before it.\n\nMichael Dahn, a senior vice president at Thomson Reuters who leads global product teams for legal-research service Westlaw, says the model makers can't get hallucinations to zero for answering open-ended questions about the world. However, companies can dramatically reduce their risk by forcing a large language model to cite from a specific data set, like a corpus of case law and treatises. The model can still mismatch or overlook content, but wholesale fabrications are far less likely.\n\nThomson Reuters and LexisNexis are selling that promise to customers: that an artificial assistant confined to their walled gardens of vetted material is safer than a chatbot trained on the open internet. Both companies have spent decades and heaps of money building deep repositories of case law and other legal content. More recently, they've bolted on AI-powered tools to help lawyers search and cite their data. They now have to defend their positions against services like ChatGPT and Claude that are creeping into the legal field.\n\nLexisNexis has also extended its moat to Harvey, the legal tech startup whose valuation has climbed to $8 billion. Harvey struck a partnership with LexisNexis this year that pipes one of the world's biggest legal databases into Harvey's generative tools.\n\nHarvey also works with AI model providers, such as OpenAI and Anthropic, to constrain which datasets they're allowed to draw from and layer in Harvey's own proprietary datasets, a spokesperson said. Lawyers can then inspect logs that show how an answer was reached and what data fed into it.\n\nClearbrief makes a drafting tool for litigators that works as a Microsoft Word plug-in. Jacqueline Schafer, a former litigator who founded Clearbrief, says its product detects citations using natural language processing, and creates links to the relevant case law or documents from the case. The tool calls out citations and facts that are fabricated or contain typos. The tool also points to places where the underlying source doesn't quite support what the writer claims.\n\nCozen O'Connor has been testing a new Clearbrief feature that lets users generate a cite-check report before passing a draft to a partner or filing it in court.\n\nSchafer says partners at large firms trust their junior staff to check citations rather than vetting every case themselves. Still, federal rules hold the partners who sign filings personally responsible for their accuracy.\n\nPart of Clearbrief's appeal for Cozen O'Connor is the paper trail. The firm is upgrading its knowledge management system, and Bakardjiev imagines that someday the firm might store cite-check reports alongside drafts and final filings, creating a chain of custody for every brief.\n\nIf a judge ever asks what a partner did to prevent hallucinated citations, Bakardjiev said, partners can point to a report that shows who ran the check and when.\n\nThe legal world is likely to live with hallucinations for a long time. The unglamorous part of the solution is training lawyers to treat the chatbot output as a starting point, not the finished work. The other answer: throwing more AI at the AI.\n\nHave a tip? Contact this reporter via email at mrussell@businessinsider.com or Signal at @MeliaRussell.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "junior staff",
      "generative tools",
      "hallucinated content",
      "fake cases",
      "legal field",
      "legal tech",
      "cozen o'connor",
      "legal filings",
      "lawyers",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lawyers-legal-tech-companies-fight-ai-chatgpt-hallucinations-2025-12",
    "thumbnail_url": "https://i.insider.com/693b4101832e0ef1ead6199f?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.418Z",
    "topic": "finance"
  },
  {
    "slug": "larry-ellison-just-lost-25-billion-of-his-net-worth-in-one-day",
    "title": "Larry Ellison just lost $25 billion of his net worth in one day",
    "description": "Larry Ellison saw his wealth plunge after Oracle's earnings miss spooked investors and raised fresh questions about the company's massive AI spending.",
    "fullText": "Larry Ellison just took a $25 billion hit to his net worth.\n\nThe Oracle cofounder saw billions wiped off his fortune on Thursday, according to estimates on Bloomberg's Billionaire Index, after the software giant's shares fell by more than 11% on weaker-than-expected earnings results.\n\nThe hit brought Ellison's net worth down to $258 billion, per the Index, marking one of the biggest single-day wealth drops of 2025.\n\nOther billionaires suffered steeper or similar losses in April: Elon Musk lost $35 billion in just three days, and Mark Zuckerberg shed about $24 billion as Trump's tariff plans sparked fears of retaliation and recession.\n\nEarlier this year, Ellison briefly took the crown of world's richest person, overtaking Musk in September when Oracle shares surged as much as 43% due to a strong forecast for its cloud business.\n\nOracle missed Wall Street's revenue expectations in its most recent earnings results, which were reported on Wednesday. Shares fell more than 11% in after-hours trading, extending a slide that began in October as investors questioned the company's breakneck spending on artificial intelligence infrastructure.\n\nDespite missing estimates, revenue was up 14% year-over-year during the quarter. But that wasn't enough to calm concerns over the scale and cost of its expansion.\n\nThose worries dominated Wednesday's call with analysts.\n\nClay Magouyrk, Oracle's co-CEO, pushed back on fears that the company might need more than $100 billion to build out its data centers — a figure some analysts had floated.\n\n\"We expect we will need less, if not substantially less, money raised than that,\" he said, adding that Oracle's debt remains \"investment-grade.\"\n\nEven after Thursday's plunge, the Bloomberg Billionaires Index shows that Ellison's net worth still remains ahead of most tech titans, including Jeff Bezos and Mark Zuckerberg.",
    "readingTime": 2,
    "keywords": [
      "ellison's net",
      "net worth",
      "estimates",
      "earnings",
      "fears",
      "revenue",
      "analysts",
      "less",
      "oracle",
      "index"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/larry-ellison-loses-25-billion-net-worth-oracle-stock-plunge-2025-12",
    "thumbnail_url": "https://i.insider.com/693bea72832e0ef1ead61d19?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.417Z",
    "topic": "finance"
  },
  {
    "slug": "disneys-ai-ambitions-are-a-hail-mary-for-the-companys-stock-after-a-lost-decade",
    "title": "Disney's AI ambitions are a Hail Mary for the company's stock after a lost decade",
    "description": "Disney's OpenAI deal comes at a time when the stock is essentially flat over the past 10 years, while the S&P 500 has soared 236%.",
    "fullText": "Things Disney has accomplished in the past 10 years:\n\nThings it hasn't accomplished over the same period:\n\nThis may seem like a wild stat. After all, the S&P 500 is up a whopping 236% over the past decade. But it's true: Disney shares are basically dead flat during the stretch.\n\nFrom a market perspective, the last 10 years have been a total wash.\n\nThe chart above — which looks at Disney's stock versus the benchmark S&P 500 — shows that the key divergence happened in early 2021, which marked Disney's last record high.\n\nThe company has faced a few main headwinds since that top:\n\nAfter Disney+ got off to a fast start, user growth eventually stalled out and prolonged the service's winding path to profitability. The company has also grappled with ESPN's increasingly online audience in the era of cord-cutting, which has contributed to contentious negotiations with TV carriers. (To be fair, all legacy media companies are dealing with the same issues.)\n\nMissing the mark on original content\n\nPixar movies used to be an absolute slam dunk at the box office. No longer. Viewers are also getting fatigued by the constant stream of reboots and sequels. And yes, Disney still has Marvel and Star Wars, although those have lost steam as well. (Note that a similar slowdown has been seen for movie studios overall.)\n\nDisney has caught flak in recent years over the prices at its parks. CEO Bob Iger even admitted in 2023 that the company had been \"too aggressive\" with price hikes. While parks remain a source of relative strength for the company, their cost has left them vulnerable to downturns in consumer sentiment.\n\nWhich brings us to Disney's latest big swing: a $1 billion investment in OpenAI that will integrate iconic characters into the AI video platform Sora. It's notable that Disney is the first major non-tech company to partner with OpenAI.\n\nUpon first glance, the deal feels like a desperate move from a company that's underperformed for a long stretch. But analysts at Citi see it differently.\n\nJason Bazinet, who has a \"buy\" rating on Disney's stock, lauded it as a defensive move, intended to protect the value of the company's IP from cannibalization. He sees it helping to sustain long-term brand value, while also giving it long-term upside in AI. Iger made similar points in defense of the deal.\n\nWe'll see over time if this AI team-up is a catalyst for a grand stock comeback — and if it's a model other companies follow.",
    "readingTime": 3,
    "keywords": [
      "disney's stock",
      "accomplished",
      "stretch",
      "parks",
      "deal",
      "long-term",
      "disney",
      "it's",
      "iger",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-opeani-sora-ai-video-deal-stock-price-returns-streaming-2025-12",
    "thumbnail_url": "https://i.insider.com/693b723f04eda4732f2d693a?width=1024&format=jpeg",
    "created_at": "2025-12-12T13:47:21.416Z",
    "topic": "finance"
  },
  {
    "slug": "disney-just-picked-a-side-in-the-ai-fight",
    "title": "Disney just picked a side in the AI fight",
    "description": "Companies face a big question: Are AI companies friend or foe?",
    "fullText": "Mickey Mouse … brought to you by OpenAI.\n\nDisney lending out its iconic characters to be leveraged by AI seemed a far-fetched idea a few months ago. But thanks to a $1 billion deal between the House of Mouse and OpenAI, that's exactly what's happening.\n\nIt's representative of a larger question companies, especially those in media and entertainment, are grappling with: Are AI companies friend or foe?\n\nFor Bob Iger, the answer is very much friend.\n\n\"It gives us an opportunity, really, to play a part in what is really a breathtaking, breathtaking growth in essentially AI and new forms of media and entertainment,\" the Disney CEO told CNBC on Thursday.\n\nThe deal will allow Disney+ to post users' AI-generated content, a goal that Iger mentioned last month. Doing so could help boost engagement on the streamer's platform, which has been stagnant in recent years, writes BI's Lucia Moses.\n\n(I should probably mention Axel Springer, Business Insider's parent company, also falls in the \"friend\" camp. It cut a deal with OpenAI almost two years ago.)\n\nOthers aren't as willing to rub shoulders with OpenAI. The startup has a history of using someone's intellectual property without permission and then apologizing for it. That has resulted in several lawsuits, including those from The New York Times and \"Game of Thrones\" author George R.R. Martin.\n\nSo who's right? It's too early to say, but it could easily go both ways.\n\nThe longer one waits to cut a deal with an AI company, the worse the terms could be. (The benefits of first-mover advantage.) On the other hand, opening yourself up to AI could be a kind of Pandora's box you can't close.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nThe deal isn't just beneficial to Disney.\n\nDisney characters coming to Sora 2 could be a big boost for a video platform that hit a bit of a lull after a hot start a few months ago.\n\nBringing characters from \"Frozen\" and \"Moana\" to life on your app is also a great way to generate interest and build loyalty with a younger audience. OpenAI CEO Sam Altman recently touted the personal benefits he finds from using ChatGPT as a new parent.\n\nBut pursuing a younger demographic also comes as some countries are putting up more guardrails around kids' use of tech. Australia recently installed a ban on social media for anyone under the age of 16.\n\nThe Disney-OpenAI deal also comes as competition keeps mounting against the startup from the likes of Google and others. And while so much of AI is about pushing cutting-edge tech, sometimes you just need a little bit of old-school magic.",
    "readingTime": 3,
    "keywords": [
      "cut deal",
      "media",
      "characters",
      "friend",
      "tech",
      "it's",
      "entertainment",
      "breathtaking",
      "boost",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-newsletter-disney-openai-iger-altman-pick-side-2025-12",
    "thumbnail_url": "https://i.insider.com/693c13f8832e0ef1ead61e4c?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.275Z",
    "topic": "finance"
  },
  {
    "slug": "openai-opens-internal-merch-store-to-the-public",
    "title": "OpenAI opens internal merch store to the public",
    "description": "Explore curated, brand-designed pieces that reflect our vision, milestones, and creative spirit.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://supply.openai.com",
    "thumbnail_url": "https://supply.openai.com/4f4692867bef.png",
    "created_at": "2025-12-12T06:59:22.638Z",
    "topic": "tech"
  },
  {
    "slug": "smart-photo-finder-semantic-photo-search-not-filename100-local-ai",
    "title": "Smart Photo Finder – Semantic photo search, not filename(100% local AI)",
    "description": "Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings. - Pankaj4152/smart-photo-finder",
    "fullText": "Pankaj4152\n\n /\n\n smart-photo-finder\n\n Public\n\n Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings.\n\n License\n\n MIT license\n\n 8\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Pankaj4152/smart-photo-finder",
    "readingTime": 1,
    "keywords": [
      "tags",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Pankaj4152/smart-photo-finder",
    "thumbnail_url": "https://opengraph.githubassets.com/81d5523cc4100fc11914eb2cbf0dd607dd9f154cfd39d73fb291f9b8d45c820a/Pankaj4152/smart-photo-finder",
    "created_at": "2025-12-12T06:59:05.582Z",
    "topic": "tech"
  },
  {
    "slug": "ai-voice-cloning",
    "title": "AI Voice Cloning",
    "description": "Transform your voice into limitless possibilities with instant AI voice cloning. Create professional audiobooks, podcasts, marketing content, and multilingual content in seconds. High-quality voice synthesis with natural expressiveness and emotional depth.",
    "fullText": "Experience premium AI voice cloning with just 3 seconds of audio!\nPerfectly captures every detail of the original voice, maintaining natural expressiveness, emotional depth, and personal speaking style. Easily clone anyone's voice with simple and efficient voice cloning technology.\n\nListen to real examples of AI-cloned voices. Each voice demonstrates the natural quality and expressiveness of our technology.\n\nClone any voice in seconds—while keeping it natural with realistic tone and speaking pace. Simple workflow, instant results.\n\nCreate your unique AI voice in seconds. With instant voice cloning, you can recreate your voice and any voice you love in just a few seconds.\n\nDiscover how AI voice cloning revolutionizes content creation, communication, and engagement across industries—all in seconds, not hours.\n\nTransform your written words into captivating audiobooks with your authentic voice. Create professional podcasts instantly—no more marathon recording sessions. Your unique voice and style, preserved perfectly, ready to engage audiences worldwide.\n\nLaunch campaigns faster than ever. Create compelling video ads and product announcements with your voice—anytime, anywhere. Skip the studio, slash production costs by up to 80%, and maintain that professional edge your brand deserves.\n\nLead with your voice, scale with AI. Deliver personalized messages to global teams in your authentic voice, ensuring every update feels personal and consistent. Transform how leaders connect with their organizations—effortlessly and instantly.\n\nBreak language barriers without learning a word. Your voice speaks every language naturally, reaching global audiences with authentic accents and local nuances. Make your content feel native in any market—from Tokyo to New York.\n\nElevate training with familiar voices that boost engagement. Create impactful learning materials using voices your team knows and trusts. Watch retention rates soar as learners stay focused, remember more, and enjoy a seamless learning experience.\n\nDeliver personalized support at scale. Connect with customers in your voice, speaking their language—literally. Build deeper relationships, increase satisfaction scores, and create memorable experiences that turn customers into advocates.\n\nWe've compiled answers to the most common questions about AI voice cloning technology.\n\nGetting started is incredibly simple! Visit our AI voice cloning platform and either upload an audio file or record a 10-second sample directly in your browser. Within seconds, our advanced AI will generate your custom voice clone—no technical expertise required.\n\nYes! Paid users have full commercial rights to use generated voices in their projects. Free users are limited to personal, non-commercial use. Always ensure you have proper authorization when cloning someone else's voice, and comply with applicable laws and regulations.\n\nOur AI voice cloning models are expertly trained to support English, Chinese (Mandarin), Japanese, and Korean with natural pronunciation and authentic intonation. Each language maintains the unique characteristics and nuances of native speakers.\n\nFor best results, we recommend 10-300 seconds of clear, single-speaker audio with normal speech pace and minimal background noise. A standard smartphone recording works perfectly—no professional equipment needed!\n\nWe're committed to ethical AI use. Please do not use our technology for impersonation, fraud, hate speech, or spam. When cloning someone else's voice, always respect copyright laws and obtain proper consent.\n\nFree users enjoy slower generation speeds, perfect for trying out the technology. Paid subscribers get unlimited generation time with priority processing, ensuring your voice clones are ready when you need them—ideal for professional workflows.\n\nNot yet, but we're actively developing programmatic access to our AI voice cloning service. Stay tuned for updates—we're planning to launch our API soon to enable seamless integration into your applications and workflows.\n\nWe're here to help! Reach out to our support team at [email protected]. We aim to respond within one business day, ensuring you get the assistance you need quickly and efficiently.\n\nAbsolutely! Once your voice clone is generated, you can download it in high-quality MP3 or WAV format. Use it in any project—from podcasts and audiobooks to marketing campaigns and training materials.\n\nYes! We currently support voice style customization, allowing you to fine-tune the characteristics of your cloned voice to match your specific needs and preferences.",
    "readingTime": 4,
    "keywords": [
      "deliver personalized",
      "free users",
      "someone else's",
      "cloning someone",
      "cloning technology",
      "else's voice",
      "authentic voice",
      "seconds",
      "create",
      "natural"
    ],
    "qualityScore": 1,
    "link": "https://aivoicecloning.net",
    "thumbnail_url": "https://aivoicecloning.net/og-image.png",
    "created_at": "2025-12-12T06:59:04.340Z",
    "topic": "tech"
  },
  {
    "slug": "openai-launches-gpt52-ai-model-with-improved-capabilities",
    "title": "OpenAI launches GPT-5.2 AI model with improved capabilities",
    "description": "OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman reportedly issued an internal \"code red\" in early December pausing non‑core projects and",
    "fullText": "Dec 11 (Reuters) - OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman ​reportedly issued an internal \"code red\" in early ‌December pausing non‑core projects and redirecting teams to accelerate development in ‌response to Google's Gemini 3.\n\nGPT-5.2 comes with improvements in general intelligence, coding and long-context understanding, the company said in a statement.\n\nThe new model is expected to bring even ⁠more economic value for ‌users, as it is better at creating spreadsheets, building presentations and handling complex multi-step ‍projects, OpenAI said.\n\nAlphabet's Google launched the latest version of its Gemini in November, highlighting Gemini 3's lead position on several ​popular industry leaderboards that measure AI model performance.\n\n\"Gemini ‌3 has had less of an impact on our metrics than we feared,\" Altman said in an interview with CNBC on Thursday, alongside Disney CEO Bob Iger.\n\nDisney said on Thursday it is investing $1 billion in ⁠OpenAI and will let the ​startup use characters from Star Wars, ​Pixar and Marvel franchises in its Sora AI video generator.\n\nMicrosoft-backed OpenAI said that it currently ‍has no ⁠plans to deprecate GPT‑5.1, GPT‑5, or GPT‑4.1 in the API.\n\nGPT-5.2 Instant, Thinking, and Pro will begin ⁠rolling out in ChatGPT on Thursday, beginning with paid plans.",
    "readingTime": 2,
    "keywords": [
      "model",
      "launched",
      "intelligence",
      "projects",
      "disney",
      "plans",
      "openai",
      "gemini",
      "altman"
    ],
    "qualityScore": 0.85,
    "link": "https://tech.yahoo.com/ai/chatgpt/articles/openai-launches-gpt-5-2-185713739.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/53E953B72061EAD331E14221749904B05C017BE83D84CD2331F3FA5A9D9F4632/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fmedia.zenfs.com%2Fen%2Freuters.com%2Fdec31ed411aedabd7e3231dabf2dd50f",
    "created_at": "2025-12-12T06:59:01.415Z",
    "topic": "tech"
  },
  {
    "slug": "big-short-investor-michael-burry-says-there-is-no-way-to-time-or-predict-when-the-ai-bubble-will-burst",
    "title": "'Big Short' investor Michael Burry says there is 'no way to time or predict' when the AI bubble will burst",
    "description": "In a lengthy blog post, Bury advised against attempting to short the current AI bubble and said the bubble may grow even larger.",
    "fullText": "If you're waiting for Michael Burry to tell you when the AI bubble will burst, don't hold your breath.\n\nIn Burry's new post on his Substack, the famed \"Big Short\" investor said that there \"is no way to time or predict\" the bubble pop, especially when the bubble may still have room to grow.\n\n\"Shorts are almost always short-term trades. Usually less than a year, maybe a couple years at most,\" wrote Burry. \"Not 5 years, not 10 years.\"\n\n\"I believe today the stock market is in a phase that could become a blow off top of extreme magnitude on the upside, while at any time, maybe even today or tomorrow, making a generational top,\" Burry added.\n\nIn the lengthy blog post, Burry answered reader questions on his earlier posts. He argued that there is \"supply-side gluttony,\" meaning massive data-center build-outs, GPU orders, and multibillion-dollar commitments without real end-user demand, which investors are mistaking for supply-chain activity. He attributed much of the hype to being driven by Nvidia CEO Jensen Huang's marketing.\n\n\"Even when it finally tops, it will not be for any specific reason,\" Burry said later in the post. \"Even if the reason is an AI buildout bubble popping, that will likely not be apparent until a year or two later.\"\n\n\"Mostly, it is prudent neither to short stocks nor to buy puts on stocks. Stocks that are obviously overvalued tend to have the most upward momentum yet have puts that are very expensive,\" Burry added.\n\nNvidia did not immediately respond to a request for comment about Burry's latest digs.\n\nIn November, Burry launched a paywalled Substack called Cassandra Unchained. After posting charts on X that show circulatory investment deals between Nvidia and other tech giants, his first post took aim at Nvidia. He called the chipmaking giant \"a Cisco\" in the AI bubble debate, referring to the internet-networking giant whose stock plunged by over 75% during the dot-com crash.\n\nNvidia released a note to Wall Street analysts in late November, pushing back against some of Burry's claims.\n\nEarlier in November, during Nvidia's Q3 earnings call, the CEO addressed concerns about the AI bubble.\n\n\"From our vantage point, we see something very different,\" Huang told investors, \"We excel at every phase of AI, from pre-training and post-training to inference.\"",
    "readingTime": 2,
    "keywords": [
      "bubble",
      "stocks",
      "burry",
      "substack",
      "stock",
      "phase",
      "earlier",
      "investors",
      "later",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/michael-burry-big-short-ai-bubbles-burst-cannot-be-predicted-2025-12",
    "thumbnail_url": "https://i.insider.com/69160ab489026fbb4d0d9600?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.758Z",
    "topic": "finance"
  },
  {
    "slug": "what-smart-people-are-saying-about-disneys-licensing-deal-with-openai",
    "title": "What smart people are saying about Disney's licensing deal with OpenAI",
    "description": "OpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property.",
    "fullText": "It's likely just a matter of time before we see the wisened duo of Rafiki and Jiminy Cricket weilding lightsabers on the icy plains of Arendelle.\n\nThat's courtesy of artificial intelligence, of course, and a new deal between Disney and OpenAI.\n\nOpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property. Disney will also invest $1 billion in OpenAI and will purchase ChatGPT Enterprise for its employees.\n\nIt's a major shift for Disney, which has historically been deeply protective of its intellectual property. And it's a big win for OpenAI, which is on a quest for more content to feed its AI models.\n\nFor users, the deal will enable them to recreate Disney characters on Sora, OpenAI's short-form video generation app, and to create images of Disney characters using ChatGPT.\n\nBeyond the limitless possibilities for creative content, the deal reveals a lot about Disney's strategy in the AI age and the impact of artificial intelligence on the future of entertainment.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nFor Nick Cicero, the founder of Delmondo, a social media video analytics company that was acquired by Conviva in 2018, Disney's deal with OpenAI is less about AI and more about revenue.\n\nCicero argued in an X post on Thursday that Disney was aiming to solve two \"existential\" problems: creators using unauthorized Disney content and kids watching YouTube instead of Disney+.\n\n\"Sora gives Disney its first scalable way to pull creator-made content into its own premium ecosystem — brand-safe, trackable, legal, and ready for CTV monetization,\" he said, referring to the practice of delivering targeted advertising to internet-connected televisions.\n\n\"This move isn't about tech,\" he added. \"It's about revenue physics.\"\n\nChatbots like ChatGPT rely on data to power their outputs, and when it comes to collecting that data, AI companies are insatiable.\n\nThe drive to collect data often pits AI companies against content creators. Numerous media companies have sued OpenAI, Anthropic, Perplexity, and other leading AI outfits for using their copyrighted content without permission. Other media companies, like Business Insider's parent company, Axel Springer, have struck deals with AI companies to license their content.\n\nPeter Csathy, a longtime media consultant and analyst, said Disney's deal with OpenAI is a \"watershed\" moment for AI and media licensing.\n\n\"Now THIS is a generative AI use that makes sense to me and I support,\" Csathy wrote on LinkedIn. \"Fully licensed characters, thereby respecting copyright and embracing partnership with the creative community (rather than theft of IP). New revenue streams for IP rights-holders. And overall delight by fans of those beloved characters.\"\n\nThere are just so many cease-and-desist letters a media lawyer can send.\n\nCarline Giegerich, a vice president at the Interactive Advertising Bureau who once led emerging tech at HBO, says Disney's deal with OpenAI feels like a \"can't beat 'em, join 'em\" moment.\n\n\"When I was at HBO from '05 - '09, I marveled at the sheer volume of cease and desists from the legal team when mobile video was up and coming,\" she wrote on LinkedIn. \"I thought it seemed difficult to fight against the entire internet, and it turns out it was. And AI presents a similar challenge.\"\n\nShe also said the deal presents a valuable marketing opportunity for Disney.\n\n\"Important to note that a selection of these fan-created videos will be available to stream on Disney+. What that means to me is that Disney sees this also as a marketing and content opportunity, which it is,\" she said.\n\nDisney's pivot from aggressively defending its IP at every turn to giving it over to the world's leading AI startup might be strategic for another reason.\n\nJames Miller, the head of business development at Amazon for media, entertainment, and Amazon Creators, said he suspects it's a matter of \"controlling the inevitable.\"\n\nAny IP eventually enters the public domain. In 2024, the copyright for Mickey Mouse himself — at least the sans white gloves version of the 1930s — expired, allowing anyone to use his likeness. Winnie the Pooh, Snow White, Cinderella, and a handful of other Disney characters also entered the public domain at the same time.\n\n\"By officially licensing these characters now, Disney does three things,\" Miller wrote on LinkedIn. \"1. Monetizes the AI trend rather than just fighting it in court. 2. Sets the quality standard for how their characters appear in AI video (likely drowning out lower-quality unauthorized versions). 3. Captures data on how fans want to use their IP before they lose exclusive rights.\"\n\nOne consumer expert said that Disney might have gotten the short end of the stick in this partnership.\n\n\"Looks like OpenAI used the #jedimindwarp on The Walt Disney Company, not the other way around,\" Karl Haller, an IBM partner and the leader of the firm's Consumer Center of Competency, said in a post on LinkedIn.\n\nHe said he was \"more than a bit surprised\" to see that Disney is letting OpenAI license its IP for Sora and other AI tools, with some of the videos being made available to stream on Disney+.\n\n\"And what does Disney receive for this? Negative $1 billion,\" he wrote. \"Rather than receiving a heftly license fee, Disney is instead investing $1B in OpenAI and receiving warrants to buy \n\nOne entertainment lawyer pointed out that the deal comes with a lot of unanswered questions.\n\n\"This is a fairly stunning story all round with many questions,\" Simon Pullman, a partner at law firm Pryor Cashman, wrote on LinkedIn on Thursday.\n\n\"Will audiences want/accept 'AI UGC' on Disney Plus,\" he wrote, referring to user-generated content. \"Will it be possible for Disney to unring the bell after three years and not extend the license? How will they protect against misuse and brand damage?\"\n\nDisney's $1 billion bet on AI is the right move for the media giant, according to Mike Walsh, the CEO of consulting firm Tomorrow.\n\n\"By partnering with OpenAI while suing Midjourney and warning Google, Disney is drawing a clear line,\" Walsh wrote on LinkedIn on Thursday. \"Remix culture isn't going away, but it will be licensed, governed, and designed on its terms.\"\n\nHe added that Disney has always survived new media eras with this strategy.\n\n\"The future of entertainment belongs to companies that shape participation instead of fighting it,\" he wrote.",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "intellectual property",
      "disney's deal",
      "disney characters",
      "media",
      "content",
      "it's",
      "entertainment",
      "license",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-deal-openai-ai-sora-chatgpt-ip-analysis-2025-12",
    "thumbnail_url": "https://i.insider.com/693b9675832e0ef1ead61c15?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.725Z",
    "topic": "finance"
  },
  {
    "slug": "softbanks-son-eyes-data-center-group-switch-to-expand-in-ai",
    "title": "SoftBank’s Son Eyes Data Center Group Switch to Expand in AI",
    "description": "SoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.",
    "fullText": "TechnologyAIBy Josh Sisco, Taro Fuse, Ryan Gould, and Min-Jeong LeeSaveSoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.The Japanese company has held discussions with Switch leadership and has been conducting due diligence on the closely held company, the people said, asking not to be identified because the information is private. SoftBank also has been in advanced talks on a potential purchase of one of Switch’s main private equity backers, New York-listed investment firm DigitalBridge Group Inc., Bloomberg News reported last week.",
    "readingTime": 1,
    "keywords": [
      "potential",
      "switch"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/softbank-eyes-data-center-group-switch-as-son-hunts-for-ai-plays",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iWJI72I4iN30/v0/1200x800.jpg",
    "created_at": "2025-12-12T03:55:20.050Z",
    "topic": "finance"
  },
  {
    "slug": "lmarena-is-a-cancer-on-ai",
    "title": "LMArena Is a Cancer on AI",
    "description": "Would you trust a medical system whose only metric was “which doctor wins the Internet?” No, you'd call that malpractice. Yet that's LMArena.",
    "fullText": "Would you trust a medical system measured by: which doctor would the average Internet user vote for?\n\nYet that malpractice is LMArena.\n\nThe AI community treats this popular online leaderboard as gospel. Researchers cite it. Companies optimize for it and set it as their North Star. But beneath the sheen of legitimacy lies a broken system that rewards superficiality over accuracy.\n\nIt's like going to the grocery store and buying tabloids, pretending they're scientific journals.\n\nHere's how LMArena is supposed to work: enter a prompt, evaluate two responses, and mark the best. What actually happens: random Internet users spend two seconds skimming, then click their favorite.\n\nThey're not reading carefully. They're not fact-checking, or even trying.\n\nThis creates a perverse reward structure. The easiest way to climb the leaderboard isn't to be smarter; it’s to hack human attention span. We’ve seen over and over again in the data, both from datasets that LMArena has released and the performance of models over time, that the easiest way to boost your ranking is by:\n\nIt doesn't matter if a model completely hallucinates. If it looks impressive – if it has the aesthetics of competence – LMSYS users will vote for it over a correct answer.\n\nWhen you optimize for engagement metrics, you get madness.\n\nEarlier this year, Meta tuned a version of Maverick to dominate the leaderboard. If you asked it “what time is it?”, you got:\n\nVoilà: bold text, emojis, and plenty of sycophancy – every trick in the LMArena playbook! – to avoid answering the question it was asked.\n\nIt wasn't just Maverick. We analyzed 500 votes from the leaderboard ourselves. We disagreed with 52% of them, and strongly disagreed with 39%.\n\nThe leaderboard optimizes for what feels right, not what is right. Here are two emblematic examples of LMArena users punishing factual accuracy:\n\nIn the world of LMArena, confidence beats accuracy and formatting beats facts.\n\nInstead of rigorous evaluators, we have people with the attention span of the average TikTok user determining which AI models shape the industry.\n\nWhy is LMArena so easy to game? The answer is structural.\n\nThe system is fully open to the Internet. LMArena is built on unpaid labor from uncontrolled volunteers. There's no incentive for those volunteers to be thoughtful. No quality control. No one gets kicked off for repeatedly failing to detect hallucinations.\n\nWhen LMArena’s leaders speak publicly, they talk about the various techniques they use to overcome the fact that their input data is low quality. They admit their workers prefer emojis and length over substance. So the LMArena system, they proudly tell us, includes a variety of corrective measures.\n\nThey're attempting alchemy: conjuring rigorous evaluation out of garbage inputs.\n\nBut you can't patch a broken foundation.\n\nWhen the entire industry optimizes for a metric that rewards “hallucination-plus-formatting” over accuracy, we get models optimized for hallucination-plus-formatting.\n\nThis isn't a minor calibration problem. It's fundamental misalignment between what we're measuring and what we want: models that are truthful, reliable, and safe.\n\nThe AI industry needs rigorous evaluation. We need leaders who prioritize accuracy over marketing. We need systems that can't be gamed by bolding more aggressively.\n\nLMArena is none of these things. And as long as we pretend it is, we're dragging the entire field backward.\n\nPeople often say they can’t avoid LMArena.\n\n\"We have to optimize for it. We have to sell our models. The leaderboard shows customers which model is best, and we have to play the game.\"\n\nBut the best products have principles they stick to.\n\nThis is the brutal choice every model builder must eventually make:\n\nThe choice is real. It’s hard. But we’ve seen some frontier labs hold the line.\n\nThey stuck to their values. They ignored the gamified rankings. And users loved their models anyway – because hype eventually dies and quality is the only metric that survives the cycle.\n\nYou are your objective function. Which path will each lab choose?",
    "readingTime": 4,
    "keywords": [
      "attention span",
      "rigorous evaluation",
      "leaderboard",
      "models",
      "accuracy",
      "system",
      "they're",
      "users",
      "lmarena",
      "optimize"
    ],
    "qualityScore": 1,
    "link": "https://surgehq.ai/blog/lmarena-is-a-plague-on-ai",
    "thumbnail_url": "https://cdn.prod.website-files.com/68dcd2ceb173c46fa029931c/69385c394b4cc2e3cad4c7bf_lmarena.jpg",
    "created_at": "2025-12-12T03:50:33.457Z",
    "topic": "tech"
  },
  {
    "slug": "how-well-do-llms-understand-tunisian-arabic",
    "title": "How Well Do LLMs Understand Tunisian Arabic?",
    "description": "Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to any tool that can act intelligently. Yet, the ability of industrial-scale LLMs to comprehend low-resource languages, such as Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding millions of Tunisians from fully interacting with AI in their own language, pushing them toward French or English. Such a shift not only threatens the preservation of the Tunisian dialect but may also create challenges for literacy and influence younger generations to favor foreign languages.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2511.16683",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2025-12-12T03:50:33.276Z",
    "topic": "tech"
  },
  {
    "slug": "creativity-is-the-new-productivity-bob-iger-on-why-disney-chose-to-be-aggressive-adding-openai-as-a-1-billion-partner",
    "title": "‘Creativity is the new productivity’: Bob Iger on why Disney chose to be ‘aggressive,’ adding OpenAI as a $1 billion partner",
    "description": "\"We'd rather participate in the rather dramatic growth, rather than just watching it happen and essentially being disrupted by it,\" Iger told CNBC.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/iger-altman-disney-openai-1-billion-creativity-new-productivity/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247523490-e1765480919303.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.446Z",
    "topic": "business"
  },
  {
    "slug": "were-not-just-going-to-want-to-be-fed-ai-slop-for-16-hours-a-day-analyst-sees-disneyopenai-deal-as-a-dividing-line-in",
    "title": "‘We’re not just going to want to be fed AI slop for 16 hours a day’: Analyst sees Disney/OpenAI deal as a dividing line in entertainment history",
    "description": "\"​I think the reason this bidding is approaching $100 billion-plus is the content library and the potential to do a Disney-OpenAI type of deal.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/pre-post-ai-content-disney-openai-netflix-warner-slop-analysis-ark-invest/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2197501075-e1765490752485.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.299Z",
    "topic": "business"
  },
  {
    "slug": "backflips-are-easy-stairs-are-hard-robots-still-struggle-with-simple-human-movements-experts-say",
    "title": "Backflips are easy, stairs are hard: Robots still struggle with simple human movements, experts say",
    "description": "Yet the next generation of robots will soon be able to learn from experience, creating more adaptable machines—perfect for the home and the factory, according to speakers at Fortune's Brainstorm AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/backflips-are-easy-stairs-are-hard-humanoid-robots-challenges-potential-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974565481_750d2f2870_o-e1765436658770.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.141Z",
    "topic": "business"
  },
  {
    "slug": "the-race-to-deploy-an-ai-workforce-faces-one-important-trust-gap-what-happens-when-an-agent-goes-rogue",
    "title": "The race to deploy an AI workforce faces one important trust gap: What happens when an agent goes rogue?",
    "description": "There’s a great deal of enthusiasm around AI agents, but as panelists discussed at Fortune's Brainstorm AI, there are still a lot of questions too.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/ai-agent-workforce-adoption-trust-risks-challenges/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974710070_1c221b6e5c_o-e1765429238911.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.060Z",
    "topic": "business"
  },
  {
    "slug": "highlights-from-fortune-brainstorm-ai-san-francisco",
    "title": "Highlights from Fortune Brainstorm AI San Francisco",
    "description": "From deep dives into the enterprise deployment of agents to explorations of the new geography of data centers, Brainstorm AI provided a valuable snapshot of the AI landscape at the close of the year.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/highlights-from-fortune-brainstorm-ai-san-francisco/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974738463_5208876430_6k-e1765490981222.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.051Z",
    "topic": "business"
  },
  {
    "slug": "openai-aims-to-silence-concerns-it-is-falling-behind-in-the-ai-race-with-release-of-new-model-gpt52",
    "title": "OpenAI aims to silence concerns it is falling behind in the AI race with release of new model GPT-5.2",
    "description": "OpenAI said its new model outperforms those from rivals Google and Anthropic across a wide range of evaluations.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-gpt-5-2-launch-aims-to-silence-concerns-it-is-falling-behind-google-anthropic-code-red/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2198334790-e1765478723707.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:28.964Z",
    "topic": "business"
  },
  {
    "slug": "this-ai-matchmaking-startup-says-it-can-find-your-soulmate-but-be-prepared-to-spend-50000-read-its-pitch-deck",
    "title": "This AI matchmaking startup says it can find your 'soulmate' — but be prepared to spend $50,000. Read its pitch deck.",
    "description": "Keeper, founded in 2022, raised $4 million in pre-seed funding. Here's the startup's current pitch deck.",
    "fullText": "Keeper, an AI matchmaking startup, thinks it can help deliver your \"soulmate\" to you. And if it can't, it'll let you know.\n\n\"We're saying we actually know who could be your soulmate or not,\" Jake Kozloski, Keeper's CEO, told Business Insider. \"We're not going to waste your time and pretend that a hundred thousand of these people could be. We'll tell you no.\"\n\nFounded in 2022, the dating platform uses layers of algorithms and AI models to match people who The startup is now disclosing for the first time, exclusively to Business Insider, that it raised a $4 million pre-seed investment in October 2024, led by Lightbank and Lakehouse Ventures. Goodwater Capital and Champion Hill Ventures participated in the round, among others.\n\nInvestors \"see AI as an inflection point in the dating app landscape\" and an opportunity to \"disrupt the incumbents,\" Kozloski said.\n\nKeeper isn't the only startup attempting to shake up the online dating market. Other AI matchmaking apps, such as Sitch and Amata, have raised millions to build next-generation dating apps. Dating app incumbents like Tinder and Bumble are also making plays with AI-powered experiences.\n\nKozloski said the company's values were another piece of its pitch that attracted some investors.\n\n\"They feel like there's a marriage crisis adjacent to the whole Elon Musk fertility crisis stuff that he talks about,\" said Kozloski, who described Keeper as being \"friendly with the pronatalist movement.\"\n\nWanting kids, though, isn't a requirement to use Keeper, Kozloski added.\n\nSince launching, Keeper has had more than 1.5 million sign-ups, and about 300,000 of those have made accounts, Kozloski said. Among that pool, there have been a \"small number\" of matches. Keeper didn't share exactly how many matches it's made, but according to its pitch deck, 10% of dates from its beta version resulted in marriage. With its funding, Keeper has been building out its matchmaking technology over the past year.\n\nKeeper is limited to heterosexual couples right now, and doesn't offer explicit options for different gender identities.\n\n\"We basically have to build a new algorithm for homosexual relationships, which we're happy to do and we will do eventually, but for now, we want to get to product market fit with our core product first,\" Kozloski said. \"Frankly, heterosexual relationships, especially for finding life partnership, seems to be a bigger market, a stronger market for us right now.\"\n\nMaking a profile on Keeper is a sit-down process. The initial form to make an account asks for the standard details of many dating apps (like your age or height), as well as academic test scores (including SATs), your career ambitions, salary, and net worth. It even encourages taking an external personality test. After you fill out the initial onboarding questionnaire, there are 13 more steps, ranging from uploading photos to sharing your philosophy on love.\n\n\"We don't let our users create their own profiles,\" Kozloski said. Keeper uses the information it gathers to curate a profile for you.\n\nKozloski said Keeper uses a non-AI algorithm first to streamline potential matches, focusing on data points like age range initially.\n\n\"We use LLMs once we have your top hundred that our other algorithms have identified,\" he said. \"The LLMs are trained on our matchmaking insights that we've learned so far, and so they can narrow down those last hundred and do the final pass of, 'OK, who actually is worth offering among these.'\"\n\nSome of the AI matchmaking comes into play when analyzing \"general attractiveness\" and users' specific attributes, like baldness or hair color, Kozloski said. The startup has also partnered with a team of researchers at Stanford, Kozloski said, who help train the LLMs (Keeper provides anonymized data to the research team).\n\nHowever, Keeper isn't fully automated, and for the time being, includes human matchmakers in the process. If there's a match, Keeper connects the two people over text message.\n\nThe startup has a complicated payment structure with a hefty price tag — but only for men.\n\nKeeper has male users sign a \"marriage bounty\" that typically costs $50,000 (if the user gets married) and has them pay $5,000 for any dates from the service (the date fees go toward the total bounty cost, Kozloski said).\n\nRead the most recent version of Keeper's pitch deck.\n\nNote: Keeper has shared an updated version of its pitch deck, which it is now sharing with investors, that includes new details since its raise in October 2024. Some details have been redacted.\n\nKeeper describes the matchmaking market as \"old school yet shockingly massive,\" per the slide.\n\n\"With the opportunity to 10x,\" the slide says. \"When technology provides perfect matches, matchmaking will be the best way to meet your partner.\"\n\n\"The AI matchmaker that will introduce you to your soulmate on the first match,\" the slides says. It also includes product imagery.\n\n\"Our v1 worked extremely well,\" the slide says.\n\nIt says that 10% of dates lead to marriage.\n\nIt says it has had 1.5 million sign-ups. \"This makes us the largest pool of any traditional matchmaker,\" the slides says. It lists competitors like Tawkify, Keeper, Ditto, Sitch, and Known Dating.\n\n\"Everyone signs up if we deliver soulmates on the first match,\" the slide says.\n\n\"The first mover quickly becomes a monopoly,\" it says.\n\nToban Wiebe: Co-Founder, Head of AI\n\nHere are the names of the researchers:\n\n\"We're raising to scale profitable human-in-the-loop matchmaking to $2M in annual revenue,\" the slide says.\n\n\"80% of young singles want to get married,\" the slide says. \"40% actually will.\" It cites data from Match Group and data scientist Allen Downey.\n\nDating apps are \"bad at creating relationships, worth billions,\" the slide says. \"Imagine the value of the first product that's great at it.\"\n\n\"Matchmakers can't scale,\" the slide says.\n\n\"LLMs and vision models enable scalable matchmaking for the first time in history,\" the slides says.\n\n\"We've built the most accurate process in the world,\" the slide says.\n\nHere are the steps the slide lays out:\n\n\"We earn more, faster, by aligning with users' incentives,\" the slide says.\n\nIts current model, which has humans involved in matchmaking, is free for women and costs men $5,000 per date. For male users, the marriage bounty costs $50,000, and the slide says that Keeper has contracted $14 million \"so far.\"\n\nKeeper outlines that in a future model, where the tech is fully automated, dates will cost $250, and the marriage bounty contract will cost $5,000.",
    "readingTime": 6,
    "keywords": [
      "fully automated",
      "pitch deck",
      "male users",
      "keeper isn't",
      "dating app",
      "marriage bounty",
      "dating apps",
      "slide",
      "matchmaking",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-dating-app-keeper-raised-four-million-pitch-deck-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae83164858d02d216a17a?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.626Z",
    "topic": "finance"
  },
  {
    "slug": "openai-says-its-new-gpt-52-set-a-new-stateoftheart-score-for-professional-knowledge-work",
    "title": "OpenAI says its new GPT 5.2 set a 'new state-of-the-art score' for professional knowledge work",
    "description": "OpenAI says its latest model, GPT 5.2, was shown to outperform industry professionals in specific tasks across 44 different occupations.",
    "fullText": "OpenAI released its anticipated update to GPT-5 on Thursday, boasting that the new AI is \"the most capable model series yet for professional knowledge work.\"\n\n\"We designed GPT‑5.2 to unlock even more economic value for people; it's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long contexts, using tools, and handling complex, multi-step project,\" the company said in a statement.\n\nIn a benchmark test called GDPval, OpenAI said its new AI model can outperform \"industry professionals at well-specified knowledge work tasks spanning 44 occupations.\"\n\n\"GPT‑5.2 Thinking produced outputs for GDPval tasks at >11x the speed and <1% the cost of expert professionals, suggesting that when paired with human oversight, GPT‑5.2 can help with professional work,\" the company said.\n\nAnd in a note that is sure to catch the attention of bankers, OpenAI wrote that in an internal benchmark of junior investment banking analyst spreadsheet modeling tasks — \"such as putting together a three-statement model for a Fortune 500 company with proper formatting and citations, or building a leveraged buyout model for a take-private\" — the new model's score per task was \"9.3% higher than GPT‑5.1's, rising from 59.1% to 68.4%\" on average.\n\nOpenAI said that GPT-5.2 will begin rolling out today for paid ChatGPT plans. Paid users will have access to GPT-5.1 for three months under legacy models before it is sunsetted.\n\n\"We deploy GPT‑5.2 gradually to keep ChatGPT as smooth and reliable as we can,\" the company said.\n\nThe company also touted its gains in agentic coding ability.\n\n\"Even without the ability to do new things like output polished files, GPT-5.2 feels like the biggest upgrade we've had in a long time. Curious to hear what you think!\" OpenAI CEO Altman wrote on X.\n\nOpenAI CEO of Applications Fidji Simo said more changes will be coming next year once OpenAI rolls out age verification across ChatGPT. She said an \"adult mode\" for the chatbot will debut in the first quarter of 2026.\n\nThe release comes just over a week after Altman declared a \"code red\" in a private message to employees, marshaling more resources to ChatGPT amid increasing competition from Google and other companies.\n\n\"Code reds are not uncommon,\" Somo said during an interview on TBPN, adding that the hosts could \"be the judge\" of the results of Altman's declaration. She said she was \"pretty proud of\" GPT-5.2's advances, even though its development pre-dated the \"code red.\"\n\nGoogle has been considered by many in tech to be gaining, if not surpassing, OpenAI in the AI race with its recent release of Gemini 3.\n\nThe announcement also occurred hours after OpenAI brokered a major deal with Disney, which secured a $1 billion investment and access to the media giant's lucrative and popular IP.\n\n\"It has been a very cool last 10 years; OpenAI has been more special to work on than I could have possibly imagined,\" Altman wrote on X on Thursday.",
    "readingTime": 3,
    "keywords": [
      "openai ceo",
      "code red",
      "model",
      "tasks",
      "professional",
      "knowledge",
      "benchmark",
      "professionals",
      "investment",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-gpt-5-2-update-release-2025-12",
    "thumbnail_url": "https://i.insider.com/693b0e6904eda4732f2d5fd2?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.376Z",
    "topic": "finance"
  },
  {
    "slug": "disney-is-betting-openai-can-help-it-solve-a-key-problem",
    "title": "Disney is betting OpenAI can help it solve a key problem",
    "description": "Disney faces an engagement problem as kids gravitate to YouTube. It's looking to OpenAI to help boost engagement.",
    "fullText": "Disney is losing the war for attention. Can its blockbuster OpenAI licensing deal change the momentum on the battlefield?\n\nSoon, you'll be able to use OpenAI products, such as ChatGPT and the video generator Sora, to create content featuring Disney characters like Mickey Mouse, Ariel, and Darth Vader.\n\nCEO Bob Iger said the move would let Disney take advantage of a fast-growing area of entertainment.\n\nIger said initially Disney would \"curate some of the videos that have been created on the Sora platform and put them onto Disney+, which we think is a great way to increase engagement with our Disney+ users, particularly the younger users.\" Iger said eventually the company wants users to create AI videos within Disney+ itself.\n\nThere's a key word in Iger's comment that signals why Disney might be particularly motivated to make this deal: engagement.\n\nTime people spend on Disney's and other leading streaming services has stayed essentially flat over the past few years, while YouTube and social video have grown. Disney's share of US TV viewership for its streaming services — including Disney+, Hulu, and ESPN+ — has been stuck at around 4.8% this year, according to Nielsen. YouTube is the top streaming platform on TVs, with a nearly 13% share in October, and its lead has been widening.\n\nData from analytics firm Luminate showed that engagement with Disney+'s original content fell to a 3% share of US viewing time in the third quarter of 2025. That's down from 9% three years earlier, the largest decline among paid streamers.\n\nDisney has been highly protective of its famous characters and favors keeping people on its own platforms. This stance has made it difficult for the company to capitalize on the rise of user-generated content. And it's losing its monopoly on its core constituency, kids, as they increasingly watch YouTube over Disney+.\n\nTraditional media companies are struggling to grow, so they're trying to figure out new ways to get people to engage with their content, whether it be games, live events, or fan content creation, media analyst Doug Shapiro, a senior advisor at BCG, recently told Business Insider.\n\n\"It's a zero-sum game they're losing, and it's only going to get worse,\" he said. \"I think they're all asking themselves, how can they have a deeper relationship with fans?\"\n\nDisney invested $1.5 billion in Fortnite maker Epic Games last year and struck a deal with Webtoon to create a new digital platform for Disney's comics, including Marvel and Star Wars. Outside Disney, Netflix is opening Netflix Houses, mini theme parks in malls that let people enter the worlds of its popular shows. Amazon has backed Fable Studios, a startup that has an AI streaming platform that lets users make their own shows and play with existing IP.\n\nJohn Attanasio, CEO of Toonstar, a tech-driven animation studio, said Disney's IP is so popular that the Sora videos could help drive more audience. He thought Disney could potentially charge for access to AI tools on Disney+ or use the Sora videos to discover franchise extensions.\n\n\"UGC, when it's so specific, the reach is limited,\" he said. \"But when you use known IP, that expands the potential audience.\"\n\nDisney fans and Hollywood insiders had mixed reactions to the OpenAI news.\n\nShae Noble, a Disney superfan in her late 30s, said she could see herself sending birthday messages or making fan videos of the characters interacting in interesting ways — especially if it were integrated into Disney+.\n\n\"I've already seen some of the negative impacts of AI and people pushing it too far to create harmful images,\" she added. \"So it's smart of them to be proactive about it.\"\n\nSome in Hollywood worried about the risks to professional creators.\n\nFor one thing, the deal puts the emphasis on existing IP rather than making new content, Toonstar's Attanasio said.\n\nThe Writers Guild of America came out swinging against the deal, and said it planned to meet with Disney to explore how much the pact would let user-generated videos use the work of its members.\n\nSam Tung, a storyboard artist and cochair of the Animation Guild's AI committee, wondered if OpenAI's guardrails would be strong enough to protect Disney's IP, recalling a widely publicized incident earlier this year when Fortnite users used AI to make the Darth Vader character swear. He also doubted the UGC would move the needle on engagement.\n\n\"I think what audiences want is high-quality stuff to watch with your family,\" Tung said.\n\nJames Faris contributed reporting.",
    "readingTime": 4,
    "keywords": [
      "sora videos",
      "streaming services",
      "streaming platform",
      "disney's ip",
      "content",
      "disney",
      "deal",
      "users",
      "create",
      "engagement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-taps-openai-to-solve-engagement-problem-woo-young-fans-2025-12",
    "thumbnail_url": "https://i.insider.com/693b473804eda4732f2d67dd?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.057Z",
    "topic": "finance"
  },
  {
    "slug": "how-openais-latest-model-will-impact-chatgpt",
    "title": "How OpenAI's Latest Model Will Impact ChatGPT",
    "description": "GPT-5.2 is here, and, according to OpenAI, better than ever.",
    "fullText": "OpenAI is having a hell of a day. First, the company announced a $1 billion equity investment from Disney, alongside a licensing deal that will let Sora users generate videos with characters like Mickey Mouse, Luke Skywalker, and Simba. Shortly after, OpenAI revealed its latest large language model: GPT-5.2.\n\nOpenAI says that this new GPT model is particularly useful for \"professional knowledge work.\" The company advertises how GPT-5.2 is better than previous models at making spreadsheets, putting together presentations, writing code, analyzing pictures, and working through multi-step projects. For this model, the company also gathered insights from tech companies: Supposedly, Notion, Box Shopify, Harvey, and Zoom all find GPT-5.2 to have \"state-of-the-art long-horizon reasoning,\" while Databricks, Hex, and Triple Whale believe GPT-5.2 to be \"exceptional\" with both agentic data science and document analysis tasks.\n\nBut most of OpenAI's user base aren't professionals. Most of the users who will interact with GPT-5.2 are using ChatGPT, and many of those for free, at that. What can those users expect when OpenAI upgrades the free version of ChatGPT with these new models?\n\nOpenAI says that GPT-5.2 will improve ChatGPT's \"day to day\" functionality. The new model supposedly makes the chatbot more structured, reliable, and \"enjoyable to talk to,\" though I've never found the last part to be necessarily true.\n\nGPT-5.2 will impact the ChatGPT experience differently depending on which of the three models you happen to be using. According to OpenAI, GPT-5.2 Instant is for \"everyday work and learning.\" It's apparently better for questions seeking information about certain subjects, how-to questions and walkthroughs, technical writing, and translations—maybe ChatGPT will get you to give up your Duolingo obsession.\n\nGPT-5.2 Thinking, however, is supposedly made for \"deeper work.\" OpenAI wants you using this model for coding, summarizing lengthy documents, answering queries about files you send to ChatGPT, solving math and logic problems, and decision making. Finally, there's GPT-5.2 Pro, OpenAI's \"smartest and most trustworthy option\" for the most complicated questions. The company says 5.2 Pro produces fewer errors and stronger performance compared to previous models.\n\nOpenAI says that this latest update improves how the models responds to distressing prompts, such as those showing signs of suicide, self-harm, or emotional dependence on the AI. As such, the company says this model has \"fewer undesirable responses\" in GPT-5.2 Instant and Thinking compared to GPT-5.1 Instant and Thinking. In addition, the company is working on an \"age prediction model,\" which will automatically place content restrictions on users who the model think are under 18.\n\nThese safety improvements are important—critical, even—as we start to understand the correlations between chatbots and mental health. The company has admitted its failure in \"recognizing signs of delusion,\" as users turned to the tool for emotional support. In some cases, ChatGPT fed into delusional thinking, encouraging people's dangerous beliefs. Some families have even sued companies like OpenAI over claims that their chatbots helped or encouraged victims commit suicide.\n\nActively acknowledging improvements to user safety is undoubtedly a good thing, but I think companies like OpenAI still have a lot to reckon with—and a long way to go.\n\nOpenAI says GPT-5.2 Instant, Thinking, and Pro will all roll out today, Thursday, Dec. 11, to paid plans. Developers can access the new models in the API today, as well.\n\nDisclosure: Lifehacker’s parent company, Ziff Davis, filed a lawsuit against OpenAI in April, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.",
    "readingTime": 3,
    "keywords": [
      "gpt instant",
      "models openai",
      "ziff davis",
      "chatgpt",
      "users",
      "supposedly",
      "model",
      "latest",
      "user",
      "free"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/how-openais-latest-model-will-impact-chatgpt?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC7EHPGQ2G4FWBQABYH2TCJD/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-12T03:50:27.049Z",
    "topic": "tech"
  },
  {
    "slug": "disney-to-invest-1bn-in-openai-allowing-characters-in-sora-video-tool",
    "title": "Disney to invest $1bn in OpenAI, allowing characters in Sora video tool",
    "description": "Agreement comes amid anxiety in Hollywood over impact of AI on the industry, expression and rights of creators\nWalt Disney has announced a $1bn equity investment in OpenAI, enabling the AI startup’s Sora video generation tool to use its characters.\nUsers of Sora will be able to generate short, user-prompted social videos that draw on more than 200 Disney, Marvel, Pixar and Star Wars characters as part of a three-year licensing agreement between OpenAI and the entertainment giant.\n Continue reading...",
    "fullText": "Agreement comes amid anxiety in Hollywood over impact of AI on the industry, expression and rights of creators\n\nWalt Disney has announced a $1bn equity investment in OpenAI, enabling the AI startup’s Sora video generation tool to use its characters.\n\nUsers of Sora will be able to generate short, user-prompted social videos that draw on more than 200 Disney, Marvel, Pixar and Star Wars characters as part of a three-year licensing agreement between OpenAI and the entertainment giant.\n\nThe agreement – a landmark deal amid intense anxiety in Hollywood over the impact of artificial intelligence on the future of entertainment – will not cover talent likenesses or voices.\n\nBob Iger, Disney’s CEO, hailed a deal which paired his firm’s “iconic stories and characters” with OpenAI’s AI technology. It will place “imagination and creativity directly into the hands of Disney fans in ways we’ve never seen before”, he claimed.\n\nThe deal is OpenAI’s most prominent move into Hollywood after a contentious rollout of Sora and longstanding pushback against AI from many entertainment industry workers. Concerns from writers, actors, visual effects artists and other creatives over AI replacing jobs and using likenesses without consent has led to union protests and copyright lawsuits against AI companies.\n\nWhen OpenAI launched its latest iteration of Sora earlier this year, it immediately ran into a slew of potential copyright issues, as feeds became dominated by videos featuring characters such as SpongeBob SquarePants or Pikachu – sometimes generated to appear in Nazi-like clothing.\n\nRacist depictions of Martin Luther King Jr prompted OpenAI to ban the use of his likeness on the platform, while the daughter of Malcolm X called seeing her father’s image on Sora “deeply disrespectful and hurtful”.\n\nDisney itself has also been concerned over the unauthorized use of its characters by generative AI platforms. The company sent a stern cease-and-desist letter to the Character.AI chatbot firm in October, alleging that the platform was “blatantly infringing on Disney’s copyrights” through using the likeness of its characters.\n\nOn Wednesday evening, attorneys representing Disney sent a cease-and-desist letter to Google, demanding that the technology company’s AI systems stop alleged infringement, Variety reported.\n\nThe OpenAI CEO, Sam Altman, has been on a charm offensive that included a recent appearance on The Tonight Show with Jimmy Fallon, the US talkshow. On Thursday, he touted the firm’s deal with Disney as proof that artificial intelligence companies could partner with the entertainment sector.\n\n“This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences,” Altman said.\n\nIn addition to Disney letting its characters appear in Sora, the company will also use OpenAI’s application programming interfaces to build new products and tools, becoming a major customer of the ChatGPT maker. A selection of the videos made by users on Sora will also be available for streaming on the Disney+ platform. It will also deploy ChatGPT for its employees, the companies said.\n\n“Technological innovation has continually shaped the evolution of entertainment, bringing with it new ways to create and share great stories with the world,” said Iger. “The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works.”",
    "readingTime": 3,
    "keywords": [
      "cease-and-desist letter",
      "artificial intelligence",
      "characters",
      "entertainment",
      "agreement",
      "deal",
      "hollywood",
      "industry",
      "videos",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2025/dec/11/disney-open-ai-sora-video-deal",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f5d1259fc988f6fc2168117b19c7988dc338dc1d/501_0_3955_3166/master/3955.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9c7ba4a2a7ebf1e6d0d3a988dca01a30",
    "created_at": "2025-12-11T18:58:28.567Z",
    "topic": "business"
  },
  {
    "slug": "oracle-drops-on-disappointing-cloud-sales-more-ai-spending",
    "title": "Oracle drops on disappointing cloud sales, more AI spending",
    "description": "Investors want to see Oracle turn its higher spending on infrastructure into revenue as quickly as it has promised.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/oracle-earnings-stock-falls-11-percent-why-investors-disappointed-data-centers-cloud/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2194585184-e1765471764946.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.911Z",
    "topic": "finance"
  },
  {
    "slug": "bob-iger-says-disneys-1-billion-deal-with-openai-is-an-opportunity-not-a-threat-wed-rather-participate-than-be",
    "title": "Bob Iger says Disney’s $1 billion deal with OpenAI is an ‘opportunity, not a threat’: ‘We’d rather participate than be disrupted by it’",
    "description": "The three-year deal will bring more than 200 Disney characters to Sora.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/disney-openai-deal-investment-bob-iger-opportunity-not-threat/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2246087509-e1765473579190.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.910Z",
    "topic": "business"
  },
  {
    "slug": "intel-pursued-deals-that-boosted-ceo-lipbu-tans-fortune-sources-say",
    "title": "Intel pursued deals that boosted CEO Lip-Bu Tan's fortune, sources say",
    "description": "When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant.  Tan had pitched Intel’s board on buying Rivos in the summer of 2025, but he had no luck.  The board told Tan he had a conflict in representing both Rivos’ interests and Intel’s, and he lacked a strategy on artificial intelligence to justify a deal, three people familiar with the events told Reuters.",
    "fullText": "SAN FRANCISCO, Dec 10 (Reuters) - When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant. That’s because the chairman of Rivos was also Intel’s CEO: Lip-Bu Tan.\n\nTan had pitched Intel’s board on buying Rivos in the summer of 2025, but he had no luck. The board told Tan he had a conflict in representing both Rivos’ interests and Intel’s, and he lacked a strategy on artificial intelligence to justify a deal, three people familiar with the events told Reuters.\n\nTan asked one of his lieutenants at Intel to pitch a new AI plan, leading to partnership talks with Rivos, the people said. But now there was a problem: social media giant Meta had been stalking Rivos and made an offer for the company.\n\nMeta’s interest spurred Intel to ​make its own offer. Meta countered with a sweetened bid. The competition for the startup drove the deal and incentives above the $2 billion valuation that Rivos had sought in fundraising earlier this year. Some of the sources pinned this package at around $4 billion.\n\nMeta announced plans to buy Rivos in September. By then the bidding process had boosted the startup’s returns at Meta’s expense.\n\nThe events show one of at least three instances where Intel has pursued deals that benefit Tan financially either by exploring bids for startups or investing in them directly through Intel’s investment arm, Intel Capital, said two of the sources.\n\nIntel declined to make Tan available for an interview for this story. Meta did not respond to requests for comment, and Rivos declined to comment.\n\nIntel hired Tan in March in part for his experience as a ‌venture capitalist and unparalleled industry connections as a longtime investor in tech companies. Those connections have helped Intel clinch a $5 billion investment from Nvidia and a $2 billion investment from SoftBank.\n\nSince Tan’s arrival, Intel has implemented policies requiring Tan to recuse himself from participating in investment decisions where he might benefit, two sources said. Specifically, Tan cannot attend or vote in decision meetings of Intel’s board or Intel Capital’s investment committee if he has a conflict in a venture or company-wide transaction, the sources said.",
    "readingTime": 2,
    "keywords": [
      "intel’s board",
      "rivos",
      "investment",
      "meta",
      "intel",
      "chairman",
      "chip",
      "startup",
      "giant",
      "conflict"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/intel-pursued-deals-boosted-ceo-202405818.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/391824ae2253d7702083abdf99e0ff28",
    "created_at": "2025-12-11T18:58:23.652Z",
    "topic": "finance"
  },
  {
    "slug": "openai-and-disney-just-ended-the-war-between-ai-and-hollywood-with-their-1-billion-sora-dealand-openai-made-itself",
    "title": "OpenAI and Disney just ended the ‘war’ between AI and Hollywood with their $1 billion Sora deal—and OpenAI made itself ‘indispensable,’ expert says",
    "description": "“Google has YouTube. OpenAI now has the Magic Kingdom,” copyright expert Matthew Sag said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-disney-sora-deal-hollywood-war-ended-matthew-sag/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1534551119-e1765478095544.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.551Z",
    "topic": "business"
  },
  {
    "slug": "startups-love-to-boast-about-arr-ai-could-bring-this-to-an-abrupt-end",
    "title": "Startups love to boast about 'ARR.' AI could bring this to an abrupt end.",
    "description": "AI disrupts ARR: Startups and SaaS firms face new hybrid valuation models as investors prioritize usage, efficiency, and outcome-based metrics.",
    "fullText": "Startups and other tech companies love to boast about \"annual recurring revenue.\" AI could make this metric obsolete, though.\n\nAccording to a new report by consultant AlixPartners, investors are on the cusp of abandoning the traditional ARR-multiple playbook that defined the SaaS era. In its place will emerge hybrid valuation models that reward companies not for the size of their subscription base but for how effectively they use AI to elevate customer outcomes.\n\nFor decades, ARR served as the bedrock for valuing enterprise software firms. It measures revenue from subscriptions by taking the value of current contracts and extrapolating that out over a full year.\n\nAlixPartners now argues that ARR is becoming increasingly \"meaningless\" in an AI-first economy, especially as usage- and outcome-based business models replace the per-seat licenses that have dominated the SaaS industry.\n\nThe big change is related to how expensive AI models are to run. Every time a new AI software service taps into this intelligence, the provider has to pay a per-token price. That makes fixed, per-seat SaaS subscriptions tougher to offer.\n\nThis means revenue could fluctuate \n\nAlixPartners says investors are already shifting focus toward a hybrid valuation approach in the AI era:\n\n• AI leverage ratios — These measure how effectively companies convert AI investments into revenue and margin gains. Rather than rewarding scale for its own sake, investors will reward operational efficiency and automation-driven profitability.\n\n• Outcome-based performance benchmarks — Metrics such as customer margin expansion, reduced task completion time, or increased throughput will matter more than raw seat-based user counts.\n\n• Traditional ARR multiples — Still relevant but no longer sufficient on their own.\n\nNew forecasting metrics, such as \"time to usage,\" \"usage ramp rate,\" and \"usage volatility,\" are emerging to help investors gauge how quickly customers adopt AI features and how stable their consumption patterns are over time.\n\nThe message is clear: In the AI era, value follows impact. Companies that can demonstrate real productivity gains for customers and operational leverage for themselves will earn premium valuations. Those clinging to legacy ARR-driven models risk being left behind as investors pivot to frameworks that better capture the economics of intelligent software.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "hybrid valuation",
      "investors",
      "revenue",
      "models",
      "usage",
      "alixpartners",
      "saas",
      "software",
      "reward",
      "effectively"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/software-arr-ai-saas-valuation-metrics-alixpartners-2025-12",
    "thumbnail_url": "https://i.insider.com/693a1d277ecd1d1da6635567?width=550&format=jpeg",
    "created_at": "2025-12-11T18:58:23.170Z",
    "topic": "tech"
  },
  {
    "slug": "getting-workers-to-trust-and-adopt-ai-is-forcing-hr-people-to-reinvent-themselves",
    "title": "Getting workers to trust and adopt AI is 'forcing HR people to reinvent themselves'",
    "description": "Workers fear AI, so one of HR's biggest challenges is getting workers to trust and adopt it by building credibility and addressing employee concerns.",
    "fullText": "Corporate AI investment reached $252.3 billion in 2024, per Stanford research, but that spending won't deliver returns if workers reject the technology.\n\n\"When organizations don't set people up to use AI reliably, employees won't trust it and won't adopt it,\" says Ted F. Tschang, an associate professor of strategic management at Singapore Management University.\n\nIt is the AI paradox facing companies today: as corporate leaders invest billions in AI, many frontline workers remain deeply skeptical for many reasons.\n\nA Pew Research Center survey published earlier this year found that nearly a third believe it will lead to fewer job opportunities for them in the long run. Meanwhile, a survey by the University of Melbourne and KPMG of over 48,000 people across 47 countries found that only 46% of respondents are willing to trust AI systems.\n\nBridging this gap — getting workers to both trust and adopt AI — has become one of HR's most urgent challenges. Becoming comfortable with AI takes time and practice, but most organizations rarely make time for this, Tschang says.\n\n\"That's why HR leaders need to create space for safe learning and experimentation with AI's uses and limits, starting with their own teams,\" Tschang says.\n\nTo do that effectively, HR leaders need to develop AI fluency, meaning they must understand the technology well enough to identify where it can solve real problems and guide their workforce in using it. That's easier said than done.\n\nThe standard purview of HR includes both operational tasks, like recruiting, onboarding, benefits, and compliance, as well as strategic ones like developing talent and managing organizational change. Put simply, it's not a department known for being particularly tech-savvy.\n\nBut in the dawn of the AI era, that's changing, says Heather Conklin, CEO of Torch, a corporate coaching firm that helps companies navigate change, including AI adoption. \"It's forcing HR people to reinvent themselves,\" she says. \"And the ones I see succeeding are the ones who are going first.\"\n\nThese teams are treating their own departments as testing grounds, experimenting with different tools and learning what works and what doesn't, says Conklin. \"They're getting hands-on with AI themselves, even if they're not technical,\" she adds. \"They can't drive it across the company if they haven't lived it. They need to drive it from a place of credibility.\"\n\nThat credibility becomes currency when employees are wary. The CHROs winning people over are leading with problems worth solving, says Dexter Bachelder, CEO of Propel People, an AI recruiting platform for the construction industry.\n\n\"It's not about HR promoting AI. It's about the questions on employees' minds: How can AI do some of my paperwork so that I can leave work earlier and get home to my family faster? How can I automate some of the manual tasks of my job that aren't fun? How can I make this process better or faster?\" Bachelder says.\n\nIn other words, when workers see how AI makes their daily work easier, they're more likely to use it. \"If you solve the employee's problems, you're using the technology for a purpose,\" he says. \"\n\nNothing drives trust and adoption faster than having a coworker explain it. When a foreman explains to another foreman how they use a certain tool in the field —'This is how it works on our project, this is how it could work on yours' — that goes a long way,\" he says. \"It's not from IT or management or HR. It's from a peer, and that's what really drives adoption.\"\n\nPart of HR learning how to work with AI and earning employee confidence means understanding what's no longer working in the organization, and what AI could do to address those gaps.\n\nHR leaders have their own vested interest in this transformation. Many departments have long dealt with inadequate technology, and lots of the tools and processes HR has relied on for years weren't built for this moment, Bachelder says.\n\n\"To some degree, I don't think HR has had a lot of voice in the technology they use because a lot of tools are tied to financial systems,\" he says. \"There's a real opportunity here.\"\n\nTraditional learning management systems, for instance, struggle to keep pace when skills requirements change more frequently than every few years. Yearly engagement surveys can't capture employee sentiment quickly enough to respond to fast-moving organizational changes.\n\nMoreover, performance review cycles designed around annual goal-setting are often disconnected from organizations where priorities change on a quarterly basis. And recruitment systems built to screen for specific technical abilities may miss candidates who have the desired problem-solving skills needed for AI-related roles.\n\nOf course, upgrading HR systems won't entirely solve the trust challenge. Employee fears about job security and algorithmic bias go beyond what any tool can fix. And HR leaders still need to answer employee questions about transparency, fairness, and who's accountable for AI's decisions.\n\n\"It's challenging to do this right now,\" Conklin of Torch says. \"But if HR leaders aren't able to figure this out, they're going to be left behind.\"",
    "readingTime": 5,
    "keywords": [
      "leaders",
      "technology",
      "trust",
      "systems",
      "won't",
      "workers",
      "that's",
      "learning",
      "employee",
      "organizations"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/hr-big-challenge-get-workers-trust-adopt-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/693317f371107c9f34576e7d?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:23.045Z",
    "topic": "finance"
  },
  {
    "slug": "oracle-just-revived-fears-that-tech-giants-are-spending-too-much-on-ai",
    "title": "Oracle just revived fears that tech giants are spending too much on AI",
    "description": "AI spending is front and center again for investors. Oracle plunged Thursday, with top hardware makers including Nvidia and Broadcom also dropping.",
    "fullText": "Oracle just raised a fresh red flag for investors worried that tech companies are getting ahead of themselves when it comes it their massive capex spending.\n\nOracle stock plunged 14% on Thursday after the tech giant reported an earnings beat but delivered revenue that was below Wall Street estimates, posting $16.06 billion compared to $16.21 billion expected by analysts. Cloud sales rose 34% from the previous quarter but also fell short of estimates.\n\nImportantly, Oracle also pledged to spend about $15 billion more next year than previously forecast, sparking fresh concerns about aggressive capex among the biggest tech firms.\n\nThe tech titan's stock drop was enough to weigh on other AI names and drag markets lower in Thursday's session.\n\nHere's where major indexes stood at the 9:30 a.m. ET opening bell on Thursday:\n\n• Nasdaq 100: 25,563.72, down 0.8%\n\nOracle stock has been highly volatile lately, dropping almost 20% in the last month after a huge surge following a blockbuster revenue forecast issued in September.\n\nIt's flurry of deals cemented the company as an AI power player, announcing a $300 billion contract with OpenAI, new partnership commitments with both Nvidia and Meta Platforms, and plans to expand its AI and cloud computing infrastructure in booming international markets.\n\nNow Oracle's lackluster earnings are prompting speculation that its big plans in the space are going to take awhile to payoff, and that it's spending plans are too ambitious. Morgan Stanley described the results as a moment when investors might resume their disbelief about the AI trade.\n\n\"Cloud growth at the low-end of the guide with building pressure on gross margins and op margins may further sap investor confidence in ORCL's ability to execute efficiently against a large and growing book of GPUaaS business, leaving the shares lacking a clear catalyst,\" analysts at the bank wrote on Thursday.\n\nSeveral other high-growth AI stocks were pulled down by Oracle's earnings report, dragging down the entire S&P 500 index, which fell 0.31% in premarket hours, while both the Dow Jones Industrial Average and the Nasdaq composite index rose slightly.\n\nHere are some of the biggest losers on Thursday:\n\nFor many investors, it is likely concerning that a company like Oracle could manage to fall short of analyst estimates after doing so much to position itself as an AI infrastructure leader this year. The key takeaway is likely that the company overpromised on what it could deliver.\n\n\"Oracle faces its own mounting scrutiny over a debt-fueled data center build-out and concentration risk amid questions over the outcome of AI spending uncertainty,\" said Emarketer analyst Jacob Bourne. \"This revenue miss will likely exacerbate concerns among already cautious investors about its OpenAI deal and its aggressive AI spending.\n\nThe concerns aren't limited to Oracle. While some have recently argued that the biggest AI fears may be overblown, it's possible that if one major tech player overspent on AI in 2025, others may have done the same. This could weigh on investor sentiment around AI as the market heads into 2026.",
    "readingTime": 3,
    "keywords": [
      "oracle stock",
      "tech",
      "investors",
      "earnings",
      "revenue",
      "estimates",
      "concerns",
      "biggest",
      "plans",
      "fresh"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/oracle-earnings-ai-stocks-capex-overspending-orcl-nvda-avgo-2025-12",
    "thumbnail_url": "https://i.insider.com/693ad29f7ecd1d1da66359f9?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.833Z",
    "topic": "finance"
  },
  {
    "slug": "meet-the-young-ai-startup-founders-raising-millions-in-the-race-to-build-the-next-big-thing",
    "title": "Meet the young AI startup founders raising millions in the race to build the next big thing",
    "description": "These AI startups founded by bright young minds in their teens and early 20s are disrupting industries and attracting top investors in the AI boom.",
    "fullText": "They are moving fast, raising serious cash, and leaving established paths behind. Across Business Insider's Young Geniuses series, which highlights next-gen leaders, innovators, and entrepreneurs, urgency is the constant.\n\nThe AI window has opened, but it may not stay that way for long. That's why these young founders are fleeing college classrooms, skipping dream internships, and leaving full-time roles to take advantage of this moment.\n\nA Stanford graduate student dropped out and raised $64 million for her AI math company. A pair of MIT freshmen dropouts secured $2.7 million for their police tech startup.\n\nThese are just a couple of young founders who are stepping into the AI race at full speed, backed by investors willing to bet early and big, driven by the sense that hesitation costs more than risk.\n\nMeet 16 young founders who spoke with Business Insider this year about their ideas for transforming everything from healthcare and shopping to how we interact with technology and one another. (Ages and figures are accurate to the time of reporting.)\n\nZach Yadegari, 18, sold his first video gaming app at age 16 for almost $100,000 and used the proceeds to fund Cal AI, an AI-powered nutrition app he co-founded.\n\nHe first discovered an interest in coding at a coding camp his parents sent him to when he was 7. For years, he'd spend hours watching people program video games on YouTube and try to emulate them.\n\nHe got the idea for Cal AI while trying to bulk up at the gym and quickly learning that most results come from diet. So, he and his co-founders set out to build a calorie-tracking app that integrates AI technology.\n\nOver the last year and a half, the app has taken off, generating around $30 million in annual revenue and employing a 30-person team, Yadegari told BI reporter Agnes Applegate in October.\n\nCarina Hong, 24, is on a mission to build a superintelligent reasoning system through her AI startup, Axiom Math.\n\nHong, a Rhodes Scholar, dropped out of her graduate studies at Stanford to found the company in March and has since hired top talent across Meta's Fundamental Artificial Intelligence Research (FAIR) lab, Meta's GenAI team, and Google Brain.\n\n\"One thing I heard from some of the top researchers and mathematicians I've recruited to Axiom is that solving for mathematical superintelligence will be their legacy,\" Hong told BI reporter Geoff Weiss in December. \"When the problem is hard enough, talent density gets very high, and that makes you a magnet for other great thinkers.\"\n\nAnd Hong isn't only recruiting from Big Tech. She has also hired her former professor, the renowned mathematician Ken Ono.\n\nArlan Rakhmetzhanov, 18, dropped out of high school in Kazakhstan in March 2025 to pursue his AI coding agents startup, Nozomio, at Y Combinator, a startup accelerator for many young founders.\n\nBoth of his parents are entrepreneurs, so his entrepreneurial journey began at a young age. He taught himself coding and built his first company at 15.\n\nHis journey to Y Combinator wasn't easy. He applied twice before finally getting accepted the third time. Even though he didn't have a Stanford PhD, he was told his YC partner selected him because he ships fast, which is critical in the age of AI, he told BI's Weiss in September.\n\nPhoebe Gates, daughter of Bill Gates, and Sophia Kianni launched an AI-powered shopping assistant in April and said it had reached 600,000 users by October, when they spoke with BI's Jordan Hart.\n\nBoth 23 at the time of their interview, Kianni and Gates met as roommates at Stanford University, where they conceived the idea for Phia.\n\nPhia is a free app and browser extension that uses AI to help compare prices on fashion items across tens of thousands of linked sites to help users find deals.\n\nThe duo raised $8 million in a seed funding round in September, led by venture capital firm Kleiner Perkins and featuring investors such as Kris Jenner, Hailey Bieber, and Michael Rubin.\n\nToby Brown, 16, has been fascinated with tech from a young age. His parents aren't in tech, but that hasn't stopped him from teaching himself to code everything, from math games to alarm systems.\n\nIn 2023, he developed the concept for his AI project Beem. \"I can't share too much about it,\" he told BI's Joshua Nelken-Zitser in October. \"I hope that if done right, it will redefine how people interact with technology.\"\n\nHe dedicated his summer break 2024 to pitching to firms and other potential investors in London, New York, Silicon Valley, and San Francisco. \"There was nobody to coach me on pitching to investors, so I just took a maniacal approach of bashing away at it until I got the right solution,\" he said.\n\nIn November 2024, he got a call from South Park Commons, founded by some of Facebook's early engineers, saying they wanted to invest $1 million in Beem. Instead of finishing school exams the following year, he left the UK to pursue his project in Silicon Valley.\n\nOne day in her Harvard University dorm room, Alyx van der Vorm felt lonely. Her friends were out of town, and while she could easily open an app to order food or stream a movie, she wanted more. Enter Clyx.\n\nVan der Vorm, 25, founded the social app in 2020 and has since rolled it out in four major cities worldwide: Miami, London, New York, and São Paulo.\n\nClyx is a social app that leverages AI to connect people in real life. It utilizes AI-powered tools to scrape events from across the web, converts those events into meetups within the app, and then helps identify which of your friends are attending the event or matches you with new connections if you don't know anyone going.\n\nAt the time of reporting, Clyx had 50,0000 active users joining events and about 200,000 looking at events, BI's Sydney Bradley reported in September.\n\nMathieu Rihet, 19, saw the inefficiencies of the healthcare system firsthand while working as a medical translator. So, he set out to try and fix some of it.\n\nHe met Georges Casassovici, 18, via his LinkedIn post seeking a non-technical cofounder to build with. Together, the two of them founded Novoflow, an AI startup that builds AI agents for medical clinics to help automate tasks, starting with cancellation recovery and appointment booking.\n\nBoth told BI's Weiss in November that they have no plans to pursue a college degree after leaving school to join Y Combinator's Spring 2025 class.\n\nRudy Arora and Sarthak Dhawan, both 20, met in sixth grade, and by high school, they were coding and building viral apps together, including a Christmas light installation app that made $60,000 in annual revenue one year.\n\nWhen they both started college in 2023, Dhawan said he struggled to take notes and listen to the teacher at the same time. So, he and Arora set out to build an AI-powered notetaking app called Turbo AI. It's attracting 20,000 new users per day, BI's Lakshmi Varanasi reported in November.\n\nSince launching Turbo AI, they've both now dropped out of college and say their startup is on track to earn eight-figures in annual recurring revenue.\n\nCollege juniors Nathaneo Johnson and Sean Hargrow say LinkedIn has become bloated with vanity metrics like follower counts and likes, which distract from the professional qualities that matter when landing a job.\n\nSo, they launched their own AI social network while attending Yale. Skipping the likes and clicks, Series connects professionals over text message. The idea is that it only focuses on who you are and what you can bring to the table, Hargow told BI's Bradley in April.\n\nBalancing college and a startup isn't easy. Johnson later told BI's Nelken Zitser that he often ends up working 120-hour weeks to manage both.\n\nOver the summer, 19-year-old Christine Zhang turned down an internship to spend two months living in a hacker house. There, she built a startup with her college roommate and cofounder, and by the end of the summer, they'd raised $1 million for it.\n\nInstead of returning to Harvard, she's taking a gap year to stay in San Francisco and help scale her startup, which has grown to six people, she told BI's Applegate in October.\n\n\"I miss a lot of things about school. I had to delete my Instagram during the first week of classes so I wouldn't get FOMO. However, I don't regret my decision,\" she said.\n\nEarly this year, Aidan Guo, 19, and Julian Windeck, 23, launched their startup, Attention Engineering, which is essentially a desktop assistant powered by AI to automate everything you do on your computer, much like a \"cursor for everything,\" Guo told BI's Varanasi in November.\n\nGuo said he's on his \"second gap year\" from college. He found encouraging mentors by joining programs like Z Fellows and Emergent Ventures. Ultimately, he decided to forgo Carnegie Mellon and move to the Bay Area to build his startup.\n\nWindeck studied computer science in Germany and at Cambridge University, and then conducted AI research at MIT before deciding academia wasn't for him.\n\nThe two met through mutual friends, discovered they worked well together, and have since raised over $1 million from noteworthy backers, including Lukas Haas, a product manager at Google DeepMind, Marvin von Hagen and Felix Schlegal, the cofounders of Interaction, and Bryan Pellegrino, the cofounder of LayerZero.\n\nJay Neo, 21, has been studying what makes a video go viral since he was a teen.\n\nAt 18, he landed a job with MrBeast, helping make short-form video content and learning the ins and outs of how the YouTube mogul grows his business and popularity. For the last year and a half, however, Neo has been focused on his own AI startup called Palo.\n\nPalo is a content creator's assistant. It utilizes AI to analyze a creator's entire catalog and then writes scripts for short-form videos with related themes, outlining content with storyboards. It also has its own network, where creators can follow one another.\n\nLarge-language AI models \"are a perfect thing not for replacing the creator, but for analyzing every little thing,\" Neo told BI's Bradley in November.\n\nShraman and Shreyas Kar, 19 and 20, participated in hackathons together throughout middle and high school.\n\nThey were busy studying at Stanford when they were accepted to Y Combinator, and seeing their peers take the risk and drop out of Stanford gave them the courage to do so, too.\n\nThey began working on their AI startup, Golpo, while at Stanford. Golpo generates animated explainer videos from documents and prompts. For example, customers can use it to create interactive lessons for school districts or training programs for work.\n\nAs of mid-October, 14,000 people had generated videos with Golpo, Shraman Kar told BI's Weiss.\n\nGeorge Cheng and Dylan Nguyen, both 19, dropped out of MIT as freshmen and raised $2.7 million in seed funding out of Y Combinator for their tech startup Code Four, which aims to arm police officers with AI.\n\nThey say their technology can generate reports from bodycam footage for record-keeping, redact footage and reports for records requests, and generate transcriptions and summaries from video interviews and security footage. Basically, it aims to reduce the time spent on paperwork, allowing officers to dedicate more time in the field.\n\nCode Four is working with 25 police departments, BI's Weiss reported in November. While Code Four uses AI to generate preliminary drafts of reports, officers review and edit them for accuracy, Cheng said.\n\n\"Many of the great AI companies of the next decade are being built right now, and I want to be a part of that,\" Raymond Zhao told BI's Nelken-Zitser in October.\n\nZhao studied math and statistics at the University of Oxford, thinking he wanted to enter the financial sector. However, after an uninspiring internship at Goldman Sachs, Zhao ultimately pursued AI instead.\n\nWhile at Oxford, he joined the venture capital society, which introduced him to a network of VCs, founders, and one of his future cofounders. They've raised about $1 million in pre-seed funding for their AI startup, Structured AI, and are pursuing it further at Y Combinator.\n\nStructured AI builds AI agents that can perform quality control on technical documents and drawings. It's laying the groundwork for the AI workforce for construction design and engineering.\n\nDavid Kobrosky, 26, dropped out of college twice. The first time was to work for businessman and social media personality Gary Vaynerchuk, at his company VaynerX. The second was to launch his own company, Intros AI.\n\nKobrosky said he always thought AI would play a huge role in how humans interact, and that's exactly what Intros AI does. Intros AI was acquired by software company Bevy in July.\n\nCompanies can use Intros AI's product to connect their most active customers to each other, creating a space for knowledge sharing and networking that helps boost their customer retention, BI's Charissa Cheong reported in November.\n\nKobrosky didn't disclose the amount he sold Intros AI for, but he is now an AI product manager at Bevy, earning over $100,000 a year, plus bonuses. \"I think starting and selling a company sets me up for the future in a way that a more traditional path wouldn't have,\" he told Cheong.",
    "readingTime": 12,
    "keywords": [
      "silicon valley",
      "der vorm",
      "venture capital",
      "van der",
      "seed funding",
      "product manager",
      "annual revenue",
      "social app",
      "tech startup",
      "bi's weiss"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/young-founders-raising-millions-for-their-ai-startups-2025-12",
    "thumbnail_url": "https://i.insider.com/6939da877ecd1d1da6635085?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.674Z",
    "topic": "finance"
  },
  {
    "slug": "disney-bets-1-billion-on-openai-in-deal-that-opens-its-vault-of-characters-to-chatgpt-and-sora",
    "title": "Disney bets $1 billion on OpenAI in deal that opens its vault of characters to ChatGPT and Sora",
    "description": "Darth Vader and other Disney characters are coming to ChatGPT and OpenAI's Sora AI video app as part of a three-year licensing deal.",
    "fullText": "Darth Vader is coming to ChatGPT and OpenAI's Sora AI video app.\n\nThe House of Mouse and OpenAI struck a three-year licensing agreement on Thursday to make Disney \"the first major content licensing partner on Sora.\"\n\nIt's also investing $1 billion into the AI pioneer and receiving warrants to purchase additional equity.\n\nShares of Disney climbed over 2% after the opening bell.\n\n\"As part of this new, three-year licensing agreement, Sora will be able to generate short, user-prompted social videos that can be viewed and shared by fans, drawing from a set of more than 200 animated, masked and creature characters from Disney, Marvel, Pixar and Star Wars, including costumes, props, vehicles, and iconic environments,\" OpenAI said in a Thursday announcement.\n\nIn addition to striking a licensing deal, Disney is also becoming a \"major customer\" of the AI company, according to the announcement, and buying ChatGPT enterprise licenses for its employees.\n\nWhile Sora, OpenAI's TikTok-like AI video app, has been generating buzz and downloads since its launch earlier this year, users of the company's more popular product, ChatGPT, will also have access to AI versions of Disney's characters as part of the deal.\n\nThe AI-generated Disney characters will be available starting in early 2026.\n\nThe move is likely to prove controversial in Hollywood, where many actors have publicly voiced concern about AI use and concerns over how their likeness is used. Disney and OpenAI stated that \"the agreement does not include any talent likenesses or voices.\"\n\nCreators are core to Disney, and its CEO Bob Iger stressed that the deal represented no threat to creators.\n\n\"I think it honors them and respects them, in part because there's a license to be associated with it,\" he said on CNBC's \"Squawk on the Street\" on Thursday.\n\n\"The other thing it does is it enables us to be comfortable that Open AI is putting guardrails essentially around how these are used, so that really there's nothing for us to be concerned about from a consumer perspective, meaning this will be a safe environment and a safe way for consumers to engage with our founders in a new way,\" he added.\n\nIger hinted at such a transaction during the company's most recent earnings call, making extensive comments about the potential he sees for AI to enhance Disney's direct-to-consumer strategy. He said the company was having extensive talks with AI companies to protect its IP as well as generate more engagement with users.\n\nHis comments demonstrate how Disney — like other Hollywood players — is looking for new ways for people to interact with its platforms and brands as user-generated content platforms and independent creators gain popularity.\n\nDisney, like those other players, has an engagement problem. The time people spend on streaming has stayed essentially flat over the past few years, despite increased spending on content, while YouTube has grown. The bet with AI is that it can get people to spend more time on its platforms by giving them more ways to play around with its famous franchises.\n\nThe companies hinted as much in the announcement, saying that they would \"collaborate to utilize OpenAI's models to power new experiences for Disney + subscribers.\"\n\nDisney is also wary of the tech's risk to its IP. In June, Disney, along with Comcast's NBCUniversal studio business, sued AI company Midjourney, claiming its tech created unauthorized copies of works ranging from Star Wars to The Simpsons. Midjourney denied the claims in its legal response. The suit is ongoing.\n\nDisney's $1 billion cash infusion comes at a critical time for OpenAI, but it's a drop in the bucket compared to the roughly $1.4 trillion the AI company has pledged to spend over the next eight years on data centers.\n\nOpenAI CEO Sam Altman had previously said that large rights holders would ultimately welcome their content being used on Sora, provided it was done with proper guardrails in place. His comments came after OpenAI stepped up restrictions on the Sora app in the wake of viral user-generated videos depicting SpongeBob as Walter White and Pikachu in \"Saving Private Ryan.\"\n\n\"Most of the rights holders that I've spoken to are actually extremely excited to get their content in here,\" Altman told tech analyst Ben Thompson in October. \"They just want to be able to set more restrictions than they would need for images because videos feel different.\"",
    "readingTime": 4,
    "keywords": [
      "rights holders",
      "three-year licensing",
      "licensing agreement",
      "content",
      "disney",
      "chatgpt",
      "openai's",
      "videos",
      "characters",
      "announcement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-openai-licensing-deal-ai-characters-sora-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae3e9832e0ef1ead60bfc?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.665Z",
    "topic": "finance"
  },
  {
    "slug": "blackstone-apollo-and-blue-owl-are-all-in-on-data-center-bets-but-theres-one-thing-making-them-wary",
    "title": "Blackstone, Apollo, and Blue Owl are all in on data center bets — but there's one thing making them wary",
    "description": "AI bubble be damned, the data center bet still looks great according to the top private markets investors. Just be careful who you're leasing to.",
    "fullText": "Concerns of an AI bubble may be mounting, but at the Goldman Sachs Financial Services Conference on Wednesday, the biggest private investors were bullish on their own investments.\n\nBlackstone President Jon Gray said it was the firm's biggest moneymaker. Ares CEO Michael Arougheti said that the firm's international data center investments are accelerating ahead of expectations and boosting revenue expectations. Blue Owl co-CEO Doug Ostrover said the firm is \"incredibly bullish\" on its own data center investments.\n\nAll signs point to a continued investment boon.\n\n\"If you \" Gray said.\n\nApollo CEO Marc Rowan said that no matter where he is in the world, the world's biggest users of \"compute\" (data center capacity) tell him they need more of it.\n\n\"When are they going to get more compute?\" Rowan said. \"No time soon, because there are natural limits and there are energy limits and there are regulatory limits and zoning and everything else.\"\n\nOstrover said he has \"never seen a market\" with this level of supply-demand imbalance, and he sees \"demand accelerating,\" but he doesn't \"see the supply increasing.\"\n\nHowever, behind the excitement, the industry's biggest investors are mulling over the risk they can't capture right now — whether leases for these data centers will be renewed 15 to 20 years from now.\n\nRowan, looking at the present situation with his \"credit hat\" on, said, \"The risk I'm prepared to take is lease-up risk,\" Rowan said. \"The risk I'm not prepared to take is renewal risk.\"\n\nRowan said he has a chart on the wall of his office that compares different big consulting firms' projections of energy usage in 2030, and the \"spread is like a child throwing darts.\"\n\n\"The experts in this have no idea on energy use, much less chip use, compute, the impact of quantum.\" Rowan said. \"Do I really want to, with my credit hat on, take renewal risk?\"\n\nThe answer is no, and Rowan said there are plenty of ways for a credit investor to make money without taking renewal risk. In equity, you're betting on renewals, with the possibility of massive upsides or the \"chance of losing everything.\"\n\n\"There will be both great fortunes made and lost in the equity of data centers,\" Rowan said.\n\nOne way to make those bets a little safer is to vet who you're betting on.\n\nBlackstone, a major infrastructure investor, is only betting on \"long-term lease data centers where you don't put a shovel in the ground until you have a 15-plus year lease with a very large market cap company.\"\n\nOther potential bets include the power behind the AI revolution. It may be true that projections of power usage in 2030 are disparate, but they're probably all up and to the right.\n\n\"I can't come up with a scenario where we're not using significantly more power five years from today,\" said Gray.\n\nOne way to do it is to sign favorable leases with the best tenants. Blue Owl has a large \"triple-net-lease\" business, an industry term for commercial leases where taxes, insurance, and maintenance costs are paid by the tenant, instead of the landlord.\n\nUsually, Ostrover said, these leases are to solid businesses like Walgreens or Cracker Barrel, with 3% annual increases over 15 to 20-year leases. They're investment-grade tenants, around BBB credit, and have generated \"in excess of 20% return in that product.\"\n\nNow, they get those same terms with A or AA-credit tenants.\n\n\"So now, we're faced with an opportunity where instead of working with Walgreens, Cracker Barrel, firms like that, we can go to Microsoft, Meta, Google, Apple, the biggest companies in the world, signing identical 20-year leases,\" Ostrover said.\n\nThat way, even if they can't renew a lease, they're making their money.\n\n\"The way we look at it to our downside is even if the facilities are worth zero at the end of their lives, we can still make a teens return,\" Ostrover said.\n\nA Blue Owl spokesperson told BI that the firm's \"expectation\" is that there'll be \"meaningful residual value\" at the end of a lease.",
    "readingTime": 4,
    "keywords": [
      "risk i'm",
      "you're betting",
      "credit hat",
      "center investments",
      "risk rowan",
      "renewal risk",
      "blue owl",
      "leases",
      "biggest",
      "lease"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blackstone-apollo-blue-owl-data-centers-lease-renewals-2025-12",
    "thumbnail_url": "https://i.insider.com/693af35104eda4732f2d5be0?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.516Z",
    "topic": "finance"
  },
  {
    "slug": "disney-ceo-bob-iger-explains-why-he-just-did-a-blockbuster-openai-deal",
    "title": "Disney CEO Bob Iger explains why he just did a blockbuster OpenAI deal",
    "description": "Disney CEO Bob Iger said the company's licensing deal with OpenAI will let it capitalize on a fast-growing technology and engage younger audiences.",
    "fullText": "Disney CEO Bob Iger says his company's major licensing deal with OpenAI is all about establishing a foothold in a new realm of entertainment and engaging younger audiences.\n\nThe licensing agreement gives ChatGPT and OpenAI's Sora video platform access to Disney characters like Mickey Mouse and Darth Vader. Disney is also investing $1 billion in the AI company and becoming a \"major customer.\"\n\nSpeaking on CNBC about the deal with OpenAI's Sam Altman on Thursday, Iger said it gives Disney a chance to get in on a fast-growing area of tech.\n\n\"It gives us an opportunity, really, to play a part in what is really a breathtaking, breathtaking growth in essentially AI and new forms of media and entertainment,\" Iger said.\n\nIger said the deal also fulfills a longtime desire by Disney to put user-generated content on its Disney+ streaming platform. Disney initially plans to put select videos created on Sora onto Disney+ to increase engagement with users, especially younger ones. Ultimately, Iger wants to let Disney+ users create such videos within the platform itself.\n\n\"That's a big step for us,\" he said.\n\nDisney has long been highly protective of its famous characters and storylines, and Iger is widely seen in Hollywood as a champion of the creative set. But like other entertainment players, Disney has an engagement problem. The time people spend on streaming has stayed essentially flat over the past few years, despite increased spending on content. Social media and user-generated content, in contrast, continue to rise. The bet with OpenAI is that the deal can get people to spend more time on Disney platforms by giving them new ways to play around with its famous franchises.\n\nIger has long positioned the company as pro-technology, and he said, in reference to the OpenAI deal, that he'd rather participate in technological innovation than be disrupted by it.\n\n\"We think this is actually a way for us to be part of these developments, as opposed to being harmed by them,\" he said.\n\nIger said the deal is also a way for Disney to participate in the big rise in user-generated short-form video on social-media platforms.\n\nAltman said Thursday that the demand for Disney characters, in particular, is \"off the charts\" on OpenAI's products. He said he sees the deal enabling people to do things like putting themselves in a lightsaber scene from \"Star Wars\" or creating a custom birthday video for their kid using the Buzz Lightyear character.\n\nAI firms have been \"frenemies\" to media companies, as many in Hollywood are concerned about how they use copyrighted material and the threat that they could pose to the creative process. Iger said the OpenAI deal is good for creators rather than a threat.\n\n\"This does not in any way represent a threat to the creators at all. In fact, the opposite,\" Iger said. \"I think it honors them and respects them, in part because there's a license to be associated with it.\"\n\nDisney said the agreement does not include any talent likeness or voices and that OpenAI would have guardrails in place to make sure Disney's IP was used in a safe way.\n\nIn June, Disney, along with Comcast's NBCUniversal studio business, sued AI company Midjourney, claiming its tech created unauthorized copies of works ranging from Star Wars to The Simpsons. Midjourney denied the claims in its legal response. That suit is ongoing.",
    "readingTime": 3,
    "keywords": [
      "openai deal",
      "user-generated content",
      "disney characters",
      "star wars",
      "iger",
      "entertainment",
      "platform",
      "media",
      "threat",
      "licensing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-bob-iger-explains-billion-deal-with-open-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/693af46064858d02d216a359?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.509Z",
    "topic": "finance"
  },
  {
    "slug": "here-are-4-ways-rivian-just-stepped-deeper-into-teslas-turf",
    "title": "Here are 4 ways Rivian just stepped deeper into Tesla's turf",
    "description": "Rivian revealed ambitious plans for fully autonomous driving, featuring an in-house chip, an in-car AI assistant, and a Tesla-like subscription model.",
    "fullText": "Rivian is all-in on autonomous driving, stepping deeper into a territory Tesla has long positioned itself to dominate.\n\nOn Thursday, at Rivian's R&D office in Palo Alto, the EV maker unveiled a road map to develop autonomous-driving capabilities for its future lineup of vehicles, including new hardware for the highly anticipated R2 — Rivian's cheapest car to date.\n\nThat road map includes a new silicon chip, designed in-house, that will power Rivian's next-generation hardware and support self-driving functions. The new hardware is expected to ship with R2 by the end of 2026, Rivian said.\n\nRivian CEO RJ Scaringe has been hinting at autonomous ambitions in recent years. However, since the company's first shipment of vehicles in 2021, Rivian's advanced driver assistance system (ADAS) software — Driver+ and the Rivian Autonomy Platform — has been more akin to Tesla Autopilot than Full Self-Driving Supervised. Tesla's Autopilot provides lane-centering and adaptive cruise control, while FSD can recognize traffic lights, conduct turns, and drive to a destination under constant driver supervision.\n\nThursday's announcement deepens Rivian's rivalry with Tesla as both companies have expressed goals of fully autonomous driving and licensing their software platforms to other automakers.\n\nRivian's partnership with Volkswagen, announced last year, was a clear first shot at those licensing ambitions. Tesla CEO Elon Musk recently balked on X that no automaker wanted to license FSD.\n\nHere are four ways Rivian is taking a page out of Tesla's playbook.\n\nRivian has been using a combination of Nvidia and Qualcomm Snapdragon chips to power various vehicle functions, including driver-assistance and infotainment systems.\n\nNow, the company is turning to in-house silicon to power its next-generation autonomous driving hardware.\n\n\"At the core of Rivian's technology roadmap is the transition to in-house silicon, designed specifically for the vision-centric physical AI,\" the company said.\n\nA Rivian spokesperson told Business Insider that the chips will be manufactured by TSMC.\n\nTesla began a production shift toward in-house chips in 2019 and has since released two iterations, AI3 and AI4. Musk has said that Tesla's next-generation chip, AI5, will be 40 times better than its predecessor.\n\nRivian's \"Gen 3 Autonomy\" hardware is under validation and is expected to be shipped with R2 by the end of 2026, the company said.\n\nWith the new chips, Rivian's explicit goal is to achieve full autonomy — that's Level 4, or the kind of self-driving technology seen in Alphabet's Waymo, in which driver supervision is not required.\n\nMusk has already made full autonomy Tesla's north star, pledging to turn every personally-owned Tesla into a robotaxi that can generate revenue.\n\nThe Tesla CEO's goals have been met with considerable skepticism, particularly due to the company's decision to abandon lidar, a sensor that many industry leaders consider essential for safety and redundancy in self-driving cars.\n\nRivian, for its part, plans to incorporate lidar into the R2 vehicle. The sensor appears to be installed within the car, just above the middle of the windshield.\n\nA Rivian spokesperson told Business Insider that the company collaborated with a third party on the \"exterior design\" of Rivian's \"lidar implementation.\"\n\nThe company did not share a timeline for launching fully autonomous driving.\n\nIn the near term, Rivian will update its ADAS with hands-free assisted driving capability. The feature won't be functional on every road, according to a press release.\n\nRivian said it will be available on \"over 3.5 million miles of roads across the USA and Canada\" and can operate \"off-highway on roads with clearly painted lines.\"\n\nAt Thursday's event, Scaringe also suggested potential robotaxi ambitions.\n\n\"This also enables us to pursue opportunities in the rideshare space,\" the CEO said.\n\nRivian is following Tesla's FSD subscription model for what it's calling \"Autonomy+.\"\n\nThe software will launch \"early 2026\" and be priced at $49.99 a month or $2,500 for a one-time purchase.\n\nTesla's FSD is $99 a month or $8,000 up front.\n\nRivian said the software will be continuously updated. The \"trajectory\" for the feature will be \"point-to-point\" navigation — where users type in a destination, and the car drives itself just like FSD — as well as eyes-off driving capabilities and \"personal L4\" capabilities, according to the automaker.\n\nThe Rivian spokesperson told Business Insider that \"hundreds of millions of miles contribute to the development of Autonomy+.\"\n\n\"This data is comprised of samples from around the US and Canada year-round, capturing diversity in both geography and seasonality,\" the spokesperson said.\n\nMusk announced in July an integration of xAI's Grok in Tesla vehicles, providing a chatbot that drivers can talk to and, more recently, ask for directions.\n\nRivian will be following a similar playbook with \"Rivian Assistant,\" an AI voice interface that will be \"model-agnostic,\" according to the automaker.\n\n\"Our framework allows us to orchestrate different models and choose the best one for the task,\" a Rivian spokesperson said.\n\nThe company said in a press release that the AI assistant can connect to third-party apps and will start with the integration of Google Calendar.\n\nThe AI assistant can also assist with vehicle diagnostics and control certain vehicle functions, such as activating the car's seat heaters.\n\nThe feature will be shipped early 2026 on Gen 1 and Gen 2 R1 vehicles.",
    "readingTime": 5,
    "keywords": [
      "press release",
      "road map",
      "driver supervision",
      "fully autonomous",
      "vehicle functions",
      "in-house silicon",
      "autonomous driving",
      "business insider",
      "tesla's fsd",
      "rivian"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/rivian-vs-tesla-autonomous-driving-fsd-chips-ai-assistant-2025-12",
    "thumbnail_url": "https://i.insider.com/693a2e2a71107c9f3457be1b?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.388Z",
    "topic": "finance"
  },
  {
    "slug": "when-supply-chains-become-autonomous",
    "title": "When Supply Chains Become Autonomous",
    "description": "A testbed built around one of management education’s most enduring simulations, the MIT Beer Distribution Game, has shown that the latest generation of generative AI models can now autonomously manage supply chains. Systems using advanced reasoning models like GPT-5 and Llama 4 adapted to changing conditions, minimized costs, and overcame the bullwhip effect. But managers should be aware that success depends on model selection, guardrails, curated data sharing, and prompt design. Such autonomous AI agents will allow human managers to focus on higher-value functions.",
    "fullText": "When Supply Chains Become Autonomous by Carol Long, David Simchi-Levi, Andre P. Calmon and Flavio P. CalmonDecember 11, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintLess than a year ago, it seemed like that day when generative AI would bring about a new era of supply chain autonomy—one where AI could adeptly make all the inventory and logistics decisions—was still far off. But to the astonishment of many experts, including us, that day has arrived—at least in the lab.",
    "readingTime": 1,
    "keywords": [
      "supply"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/when-supply-chains-become-autonomous",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_11_MorganeFadanelli.jpg",
    "created_at": "2025-12-11T18:58:21.935Z",
    "topic": "business"
  },
  {
    "slug": "i-tried-photoshop-in-chatgpt-and-it-went-better-than-i-expected",
    "title": "I Tried Photoshop in ChatGPT, and It Went Better Than I Expected",
    "description": "You can now get Adobe's AI image editor inside OpenAI's AI chatbot.",
    "fullText": "Generative AI tools continue to improve in terms of their photo editing capabilities, and OpenAI's latest upgrade brings Adobe Photoshop right inside your ChatGPT app window (alongside Adobe Acrobat for handling PDFs, and Adobe Express for graphic design). It's available to everyone, for free—you just need a ChatGPT account and an Adobe account.\n\nAs per Adobe, the idea is to make \"creativity accessible for everyone\" by plugging Photoshop tools directly into ChatGPT. The desktop version of Photoshop already comes with plenty of generative AI features of its own, so this is AI layered on top of more AI—but is it actually useful?\n\nAdobe Photoshop, Adobe Express and Adobe Acrobat are available now inside ChatGPT on the desktop, on the web, and on iOS. At the time of writing, you can also get Adobe Express inside ChatGPT for Android, with Photoshop and Acrobat \"coming soon.\" To weigh the capabilities of the new integration, I tested it in a desktop web browser.\n\nTo get started, all you need to do is type \"Photoshop\" at the start of your prompt: ChatGPT should recognize what you're trying to do, and select Adobe Photoshop as the tool to use for the next prompt. You'll also need to click through a couple of confirmation dialog boxes, and connect an Adobe account (if you don't have one, you can make one for free).\n\nWith all the connections and logins completed, Photoshop is then added to the overflow menu in the prompt box, so just click on the + (plus) to select it. You can start describing what you want to happen using the same natural, conversational language you'd use for any other ChatGPT prompt. You do need to also upload an image or provide a public link to one—if you don't do this before you submit your prompt, you'll be asked to do it after.\n\nYou don't need to know the names of all the Photoshop tools: Just describe what you want to happen and the relevant tools will be selected for you. One example Adobe gives is using the prompt \"make my image pop,\" which brings up the Bloom, Grain, and Lens Distortion effects—and each one can be adjusted via sliders on screen. It's actually quite simple to use.\n\nIf you do know the name of the tools you want, you can call them up by name, and the classic brightness and contrast sliders are a good place to start. You can either say something like \"make the picture brighter\" or \"adjust the image brightness\"—both will bring up an overlay you can use to make brightness adjustments, but if you use the former prompt, the image will already have been made a little brighter.\n\nChatGPT and Photoshop let you add edit upon edit as needed, and you can save the image at any stage. There's also the option to open your processed file in the Photoshop web app whenever you like: This web app uses a freemium model, with advanced features requiring a subscription, and seems to be what the ChatGPT integration is largely based on.\n\nAdobe offers a handy ChatGPT prompts cheat sheet you can browse through, which gives you a good idea of what's possible, and what you're still going to need Photoshop proper for. Note that you can specify certain parts of the image to focus on (like \"the face\" or \"the car\") but this depends on Photoshop-in-ChatGPT being able to correctly figure out where you want your selection to be. It needs to be pretty obvious and well delineated.\n\nWhen I tried cutting out objects and removing backgrounds, this worked well—but then I had to turn to Photoshop on the web to actually drop in a different background. There's no way to work with layers or masks here, and you can't remove people or objects from photos, either. Sometimes, however, you do get a spool of \"thinking\" from ChatGPT about how it can't do what the user is asking for.\n\nI was able to apply some nice colorizations here, via prompts like \"turn all the hues in this image to blue,\" and I like the way ChatGPT will give you further instructions on how to get the effect you want. You can even say \"show some examples\" and it gives you a few presets to choose from—all of which can be adjusted via the sliders again.\n\nThe ability to run prompts like \"turn this into an oil painting\" or \"turn this into a cartoon\" are useful too, though the plug-in is limited by the effects available in Photoshop for the web: You'll be directed to the closest effect and advised how to tweak it to get the look you want.\n\nActually, some of these effects work better in ChatGPT's native image editor, which maybe explains why Adobe wanted to get involved here.\n\nIf ChatGPT's image manipulation gets good enough, then Photoshop is no longer going to be needed by a substantial number of users: ChatGPT can already remove people and objects from photos, for example, quite effectively. What it's not quite as good at is some of the basic adjustments (like colors and contrast) that Adobe software has been managing for years.\n\nFor quick, basic edits you want to type out in natural language—especially where you want to adjust the edits manually and need advice on what to do next—Photoshop inside ChatGPT is a handy tool to be able to turn to, especially as it's free. For serious edits, though, you're still going to want to fire up the main Photoshop app, or maybe even shun Adobe altogether and make use of ChatGPT's steadily improving editing tools.",
    "readingTime": 5,
    "keywords": [
      "prompt you'll",
      "inside chatgpt",
      "adjusted via",
      "adobe account",
      "photoshop tools",
      "web app",
      "it's",
      "desktop",
      "you're",
      "don't"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/adobe-photoshop-in-chatgpt?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC6DVWW8SYF0AP0H0T4J6WFG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T18:58:21.016Z",
    "topic": "tech"
  },
  {
    "slug": "disney-will-now-let-you-make-ai-slop-of-its-characters-on-sora",
    "title": "Disney Will Now Let You Make AI Slop of Its Characters on Sora",
    "description": "Disney is literally paying $1 billion for this.",
    "fullText": "If you've engaged in any sort of doomscrolling over the past year, you've no doubt encountered some wild AI-generated content. While there are plenty of AI video generators out there producing this stuff, one of the most prevalent is OpenAI's Sora, which is particularly adept at generating realistic short-form videos mimicking the content you might find on TikTok or Instagram Reels. These videos can be so convincing at first glance, that people often don't realize what they're seeing is 100% fake. That can be harmless when it's videos of cats playing instruments at midnight, but dangerous when impersonating real people or properties.\n\nIt's that last point that I thought would offer some pushback to AI's seemingly exponential growth. These companies have trained their AI models on huge amounts of data, much of which is copyrighted, which means that people are able to generate images and videos of iconic characters like Pikachu, Superman, and Darth Vader. The big AI generators put guardrails on their platforms to try to prevent videos that infringe on copyright, but people find a way around them. As such, corporations have already started suing OpenAI, Google, and other AI companies over this blatant IP theft. (Disclosure: Lifehacker’s parent company, Ziff Davis, filed a lawsuit against OpenAI in April 2025, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n\nBut it seems not all companies want to go down this path. Take Disney, as a prime example. On Thursday, OpenAI announced that it had made a three-year licensing agreement with the company behind Mickey Mouse. As part of the deal, Sora users can now generate videos featuring over 200 Disney, Marvel, Pixar, and Star Wars characters. The announcement names the following characters and movies specifically:\n\nThat includes licensed costumes, props, vehicles, and environments. What's more, Disney+ will host a \"selection\" of these \"fan-inspired\" Sora videos. (I'll admit, that last point genuinely shocks me.) This does only apply to Disney's visual assets, however, as Sora users won't have access to voice acting. ChatGPT users will also be able to generate images with these characters, so this news doesn't just affect Sora users.\n\nYou might think OpenAI is paying Disney a hefty licensing fee here, but it appears to be quite the opposite. Not only is Disney pledging to use OpenAI APIs to build \"products, tools, and experiences,\" it is rolling out ChatGPT to its employees as well. Oh, and the company is making a $1 billion equity investment in OpenAI. (Is that all?)\n\nI know many companies are embracing AI, often in ways I disagree with. But this deal is something else entirely. I'm not sure any Disney executives actually searched for \"Sora Disney\" on the internet, because right now, you'll find fake AI trailers for Pixar movies filled with racism, sexual content, and generally offensive content—all generated using an app Disney just licensed all of its properties to. OpenAI asserts in its announcement that both companies are committed to preventing \"illegal or harmful\" content on the platform, but Sora users are already creating harmful content. What kind of content can we expect with carte blanch access to Disney's properties?\n\nNow that Disney's characters are fair game, I can't imagine the absolute slop that some users are going to make here. The only hope I have is in the fact that Disney+ is going to host some of these videos. Staff will have to weed through some garbage to find videos that are actually suitable for the platform. And maybe seeing the \"content\" that Sora users like to make with iconic characters will be enough for Disney to rethink its plans.",
    "readingTime": 4,
    "keywords": [
      "sora users",
      "generate images",
      "iconic characters",
      "harmful content",
      "ziff davis",
      "videos",
      "properties",
      "disney",
      "disney's",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/disney-and-openai-are-partnering-on-ai-slop?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC72R3XE3XTEEXZRCBF450S8/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T18:58:20.900Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-england-gaming-star-daniel-stingray-ray",
    "title": "Sutton's predictions v England Gaming star Daniel 'Stingray' Ray",
    "description": "BBC Sport football expert Chris Sutton takes on England Gaming star Daniel 'Stingray' Ray - and AI - with his predictions for this weekend's Premier League fixtures.",
    "fullText": "Sunday brings the first Wear-Tyne derby since 2024 but will it be Sunderland or Newcastle celebrating afterwards?\n\n\"For most of last season you couldn't have imagined Sunderland getting promoted and being competitive with Eddie Howe's Newcastle, let alone being above them in the table,\" said BBC Sport football expert Chris Sutton.\n\n\"It is very different now, and the way Sunderland play makes me think they've got a real chance.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 16, he takes on England Gaming star Daniel 'Stingray' Ray.\n\nRay is going for glory for the eLions - the Football Association's official esports team - at EA Sports FC in the Uefa eEuro 2025 finals tournament, which takes place at Twickenham Stadium on Saturday.\n\nYou can watch the action on Uefa's YouTube, IG Live and TikTok channels, as well as EA Sports FC Twitch and YouTube and England's Twitch.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "sunderland",
      "season",
      "predictions",
      "youtube",
      "twitch",
      "points",
      "newcastle",
      "sport",
      "football",
      "sutton"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/ce8q055q17ro?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/8ef4/live/cb18b2b0-d695-11f0-8c06-f5d460985095.jpg",
    "created_at": "2025-12-11T18:58:20.003Z",
    "topic": "sports"
  },
  {
    "slug": "ai-predictions-for-2026-a-devops-engineers-guide",
    "title": "AI Predictions for 2026: A DevOps Engineer's Guide",
    "description": "AI predictions for 2026 and what they mean for DevOps engineers. From agent orchestration to local AI breakthroughs, here's how to prepare your infrastructure.",
    "fullText": "Posted on Thursday, Dec 11, 2025\n\nThe IDE is dying, and so is tool calling. OpenAI is not going to win. And next year, you’re going to be shipping code that you’ve never reviewed before, even as an experienced engineer.\n\nThese are bold claims, but the way we use AI in 2026 for coding and agents is going to look completely different. In this post, I want to cover my predictions and why they matter right now for DevOps engineers. Some of these are definitely hot takes, but that’s what makes this conversation worth having.\n\nTraditional IDEs where the code is the focus of the interface are simply going to become irrelevant. We’re moving toward agent manager interfaces where we can kick off agents in parallel to work on different features in a codebase or even work on different projects at the exact same time.\n\nWe’re already seeing this transition. Google Antigravity combines a familiar AI-powered coding experience with a new agent-first interface. You can deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Cursor 2.0 lets you run up to eight agents in parallel on a single prompt, using git worktrees or remote machines to prevent file conflicts. Each agent operates in its own isolated copy of your codebase.\n\nAWS validated this direction at re:Invent 2025 by announcing “frontier agents” including Kiro for autonomous coding, along with dedicated security and DevOps agents. These agents maintain state, log actions, operate with policy guardrails, and integrate directly with CI/CD pipelines.\n\nFor infrastructure specifically, Pulumi Neo represents this same shift. Instead of writing code or running CLI commands for every operation, you describe what you need in natural language and Neo handles the implementation. It works across your entire infrastructure, understanding dependencies and creating execution plans that go through pull requests for review.\n\nFor DevOps engineers, this means your pipelines need to accommodate AI-generated code at scale. Multiple agents working simultaneously need isolated, reproducible environments. More generated code means more artifacts to track, version, and deploy.\n\nA lot of people think that in the future a single large language model is going to have a monopoly and be the best at absolutely everything. But what’s really going to happen is different providers will specialize and focus on being the best at different things.\n\nGoogle is going down the generalist play with Gemini, aiming to be the jack of all trades. Anthropic is focusing on being the best for coding. You can see this in the benchmarks: when Opus 4.5 came out, the first benchmark they highlighted was for software engineering, because that’s what Anthropic is focusing on.\n\nAmazon is carving out its own niche with the Nova model family, announced at re:Invent 2025. The Nova 2 lineup includes specialized models: Pro for complex reasoning, Sonic for real-time voice conversations, and Omni for simultaneous text, audio, and video processing. With Nova Forge, organizations can build custom frontier models by combining their proprietary data with AWS open weight models. The re:Invent message was clear: leveraging your first-party data is now fundamental to going beyond generic AI. We’re talking about 30-40% increases in accuracy when you bring your own data into the equation.\n\nBut here’s the hot take: I don’t think OpenAI is going to come out on top with any kind of specialization. They’ve disappointed time and time again with GPT-5 and GPT-4.5. With 4.5, they seemed to try to be the creative specialist, but it just didn’t work. The GPT-5 launch in August 2025 was described as “barely better than last month’s flavor of the month” and on some metrics it’s actually worse than earlier models.\n\nFor DevOps teams, this specialization means you’ll need infrastructure that’s model-agnostic and supports multiple AI backends. Plan for secrets management across multiple LLM providers and design your systems to swap models based on the task at hand.\n\n2026 is going to be the year of local AI. We didn’t see that much this year besides DeepSeek at the start of 2025, which was a big deal. We had a couple of new models like Qwen 3, but nothing that fundamentally changed the game. Now we’re starting to see new hardware that makes it obvious we’re going to be able to run very large models on smaller devices.\n\nThere’s new AI chips that can run upwards of 120 billion parameter large language models on the edge, which would be a complete game-changer. Right now, hardware requirements are one of the biggest problems when it comes to scaling local AI. If we can solve the hardware problem, we get 100% data privacy and zero-millisecond latency for our agents.\n\nAWS is addressing this with Trainium3 UltraServers, their 3nm AI chips delivering 4.4x more compute than the previous generation. More significantly, AWS AI Factories allow organizations to deploy racks of Trainium chips and NVIDIA GPUs directly into their own data centers, addressing data sovereignty concerns while keeping AI inference close to the data.\n\nFor DevOps, this opens possibilities for zero-latency inference in CI/CD pipelines, complete data privacy for sensitive codebases, and reduced cloud costs for AI-heavy workloads.\n\nWe’re finally going to get to the point where we’re not the coders. We delegate that entirely to our coding agents and we become the system architects. This mirrors the evolution of other engineering disciplines. Civil engineers don’t fabricate the steel beams; they design the structure and verify the integrity.\n\nI think of this as a three-step process:\n\nWe’re still in the loop. We are the final say in whatever is created, but we’re delegating the grunt work to our coding agents.\n\nThis is exactly the model that Pulumi Neo implements for infrastructure. When you give Neo a complex request, it creates a task plan outlining the steps it will take to accomplish your goal. This plan provides transparency into Neo’s approach and gives you the opportunity to adjust the strategy before execution begins. Neo operates in different modes: Review mode where everything requires approval, Balanced mode where only deployments need sign-off, or Auto mode for full autonomy. You define the boundaries, Neo orchestrates the work, and you validate through pull requests and previews.\n\nFor DevOps engineers, this shift means building robust validation infrastructure becomes critical. When AI writes the code, you need automated testing pipelines, security scanning, and verification systems that can operate at the speed of AI-generated changes.\n\nHere’s a key insight that kept coming up at re:Invent: models are no longer the bottleneck. Context is. Our agents are going to change a lot next year because code execution is starting to replace tool calling. The problem with tool calling right now is that all the capabilities you give an agent take up context upfront. When you try to give a lot of different tools to an agent, you completely overwhelm it.\n\nAnthropic’s research on code execution with MCP addresses exactly this problem. Code execution is a massive token reduction, faster, and more flexible. You’re giving the agent the ability to generate its own capabilities at runtime by writing code to interact with APIs. A workflow that previously consumed about 150,000 tokens when tools were passed directly through the model was reimplemented with code execution and used only about 2,000 tokens. That’s a 98.7% reduction.\n\nAWS embraced this pattern with Amazon Bedrock AgentCore, which now includes code interpretation capabilities. AgentCore supports any agent framework (CrewAI, LangGraph, OpenAI SDK) and provides memory, browser tools, and observability features that make code execution practical at enterprise scale.\n\nFor DevOps, this means you need sandboxed, secure execution environments for AI-generated code. Running agent-generated code requires appropriate isolation, resource limits, and monitoring.\n\nThe best part about code execution flexibility is it unlocks progressive disclosure. All I mean by that is: you have a lot of capabilities for an agent, but you don’t actually give all of them upfront. Instead, you allow the agent to discover capabilities and then leverage them in a more flexible way.\n\nFor each capability, you just have a bit of metadata or description that loads upfront. When the agent decides to leverage that capability, then you load the full instructions. Now you can practically scale to infinity because all capabilities don’t have to be loaded at runtime.\n\nClaude Skills is a good example of this pattern. Skills are organized folders of instructions, scripts, and resources that agents can discover and load dynamically. At session start, the agent scans available skills and populates the system prompt with just a brief name and description (around 100 tokens). The full skill prompt loads only after Claude selects it, preventing context bloat while maintaining discoverability.\n\nKiro Powers addresses the same problem. Connecting five MCP servers can consume over 50,000 tokens, roughly 40% of an AI model’s context window, before you even type your first request. Powers bundle MCP servers, steering files, and hooks into units that load dynamically based on conversation context. Mention “payment” and the Stripe power activates. Datadog, Figma, and others have powers available.\n\nFor DevOps, this translates to modular infrastructure definitions, on-demand capability loading, and efficient resource utilization. Think about how you can apply this pattern to your own automation.\n\nAgent-to-agent protocols are where AI agents operate in a peer network, discover each other’s capabilities in real time, and interact autonomously. When Google released their A2A protocol earlier this year, there was a ton of buzz. A lot of people thought it was going to be the next big standard, like the next MCP. But then it kind of fell to the wayside.\n\nThe big reason is the chicken-and-egg problem. In order for A2A to be useful, you need a lot of people to adopt it at the same time. Otherwise, if you build an A2A-compatible agent, it has no other agents to talk to. The whole value proposition is lost unless you already have a big network to attach to.\n\nBut that’s finally changing. The Linux Foundation launched the A2A project in June 2025, and adoption is accelerating. Adobe, Microsoft, SAP, ServiceNow, and S&P Global are all implementing A2A. In July 2025, Google released version 0.3 of the A2A protocol with a more stable interface critical to accelerating enterprise adoption.\n\nMy next big prediction is that machines paying machines is going to become a very big thing. Coinbase released the x402 protocol for exactly this: building AI agents that you expose over the internet but require payment whenever someone else interacts with them.\n\nThis goes really well with agent-to-agent protocols. You can create a peer network where you monetize your agents. They all leverage each other but make payments whenever they take advantage of another agent’s capabilities. Cryptocurrency is the perfect solution for this kind of machine-to-machine network because you need a currency where it’s easy to do micropayments quickly and globally.\n\nThe x402 protocol has achieved 156,000 weekly transactions with 492% growth since launching in May 2025. It’s now integrated with Anthropic’s MCP Protocol, Google Gemini, OpenAI Codex, and other platforms. Stablecoins like USDC make it possible to charge per request, per service, or per second of usage with near-zero transaction costs, enabling payments as low as $0.001 per request.\n\nWhen we want to do a rigorous code review traditionally, we look line by line at all the changes. But coding agents are getting to the point where they can prove their code works through artifacts. Instead of reviewing line by line, we can look at browser recordings, full working demos of a backend API, and other artifacts.\n\nGoogle Antigravity is a perfect example. As part of its coding process, it can autonomously spin up your website, visit it, scroll through it, take screenshots, and record everything. Agents generate artifacts, including tangible deliverables like task lists, implementation plans, screenshots, and browser recordings. You can verify the agent’s logic at a glance.\n\nAmazon Nova Act takes this further. It enables AI agents to automate browser-based tasks like form filling, QA testing, and workflow validation with over 90% reliability. The service includes built-in observability through live viewing, CloudTrail logging, and session replay, making it possible to review what an agent actually did rather than parsing through code changes.\n\nFor the last prediction, we’re tying everything together. We’ve talked about reviewing artifacts instead of diffs, creating systems instead of coding, and the new capabilities for agents with code execution.\n\nWe’re going to get to the point very quickly where we’re shipping code that we have never read before. And I’m not talking about people who vibe code. Even experienced engineers are going to trust their systems so much that they have the ability to review the code but they’re not going to. We’re just going to ship to production after reviewing the artifacts.\n\nI presented on this exact topic at the Tel Aviv Pulumi User Group meetup at Qodo HQ back in October, where I demonstrated how Pulumi Neo’s autonomous decision-making capabilities can handle infrastructure tasks that we traditionally managed manually. Qodo is doing fascinating work in this space with their agentic development tools, building systems that let you trust the output without necessarily reviewing every line.\n\nI’m not saying we’re taking the human completely out of the loop. I’m saying we’re going to have a lot of trust in our systems and a validation process that includes us, but that doesn’t necessarily have to be us actually looking at the code. Tools like Pulumi Neo create pull requests with clear documentation of changes, run previews to validate infrastructure modifications, and provide the transparency needed to ship with confidence.\n\nThe predictions I’ve outlined point to a fundamental shift in how software gets built and deployed. For DevOps engineers, this isn’t a threat but an opportunity to become more strategic and less operational. We’re entering the battle of the agentic frameworks, where the winners will be those who can build faster, cheaper agentic applications through their platforms.\n\nThe immediate reality is that your CI/CD pipelines need to accommodate AI-generated code at scale, your secrets management needs to handle multiple LLM providers, and your execution environments need proper sandboxing for agent-generated code. These aren’t future concerns; they’re requirements for working effectively with the AI tools available today.\n\nLooking further out, the engineers who thrive will be those who embrace the system architect role. Define clear objectives and constraints for your AI agents. Build validation frameworks that can verify outcomes without requiring line-by-line code review. Design infrastructure that’s modular enough to load capabilities on demand.\n\nThe technology to make this happen already exists. Agent orchestration platforms are shipping. Code execution is replacing tool calling. Progressive disclosure patterns are proven. The question isn’t whether these changes are coming; it’s whether you’ll be ready when they arrive.\n\nIf you want to experience what this future looks like right now, Pulumi Neo is the place to start. Neo lets you make natural language requests for routine infrastructure tasks, analysis, and management. Instead of writing code for every operation, you describe what you need and Neo handles the implementation, creating task plans, running previews, and opening pull requests for your review.\n\nWhether you’re looking to update outdated resources across your infrastructure, analyze your cloud spend, or automate complex multi-step workflows, Neo provides the agent-first experience that’s defining the next generation of DevOps tooling.\n\nGet started with Pulumi Neo and see how AI-powered infrastructure automation can transform your workflow.",
    "readingTime": 13,
    "keywords": [
      "llm providers",
      "accommodate ai-generated",
      "ci/cd pipelines",
      "mcp servers",
      "google released",
      "neo handles",
      "a2a protocol",
      "devops engineers",
      "artifacts instead",
      "for devops"
    ],
    "qualityScore": 1,
    "link": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/",
    "thumbnail_url": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/meta.png",
    "created_at": "2025-12-11T13:53:40.763Z",
    "topic": "tech"
  },
  {
    "slug": "the-abundance-paradox-why-netflixs-acquisition-makes-sense-in-the-era-of-ai",
    "title": "The Abundance Paradox: Why Netflix's Acquisition Makes Sense in the Era of AI",
    "description": "The Abundance Paradox: Why Netflix’s $82B Acquisition Makes Sense in the Era of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/Konstantine/status/1998512521385488841",
    "thumbnail_url": "https://pbs.twimg.com/media/G7wkWdxaQAAeio1.jpg:large",
    "created_at": "2025-12-11T13:53:40.525Z",
    "topic": "tech"
  },
  {
    "slug": "slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations",
    "title": "SLB partners with Shell to develop AI solutions for energy operations",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations-93CH-4403467",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/international_newspapers_108x81.jpg",
    "created_at": "2025-12-11T13:53:38.207Z",
    "topic": "finance"
  },
  {
    "slug": "when-ai-takes-the-tasks-managers-take-the-relationships",
    "title": "When AI takes the tasks, managers take the relationships",
    "description": "Leaders say agents should handle the busywork so human managers can be more connected to their teams.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/when-ai-takes-the-tasks-managers-take-the-relationships/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974174223_1f91a177fa_6k-e1765458447816.jpg?resize=1200,600",
    "created_at": "2025-12-11T13:53:36.502Z",
    "topic": "business"
  },
  {
    "slug": "openais-house-of-cards-seems-primed-to-collapse",
    "title": "OpenAI's house of cards seems primed to collapse",
    "description": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.",
    "fullText": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.\n\nBack in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo.\n\nBut it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy.\n\nSince then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.\n\nIn response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss.\n\nIt's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI.\n\nAnthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Informationsaid Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings.\n\nHowever, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI.\n\nAccording to a December 2 report from TheWall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic.\n\nThe few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator.\n\nMore importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year.\n\nIn an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.\n\nSince late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well.\n\n\"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.\n\nGita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels.\n\nThe modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment.",
    "readingTime": 6,
    "keywords": [
      "code red",
      "search giant",
      "openai",
      "chatbot",
      "model",
      "models",
      "memory",
      "release",
      "google",
      "released"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/chatgpt/article/openais-house-cards-seems-primed-170000383.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/GqARrc67JCVOPZqPZmGxVA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/engadget_703/4fd0cc3b2f10735e6ff000f551d8a08e",
    "created_at": "2025-12-11T13:53:36.420Z",
    "topic": "tech"
  },
  {
    "slug": "an-openai-exec-identifies-3-jobs-on-the-cusp-of-being-automated",
    "title": "An OpenAI exec identifies 3 jobs on the cusp of being automated",
    "description": "\"My bet is often on life sciences, pharma companies,\"  Olivier Godement said.",
    "fullText": "Three industries are going to look very different in the next few years, according to an OpenAI executive.\n\nOn an episode of the \"Unsupervised Learning\" podcast, Olivier Godement, the head of product for business products at the ChatGPT maker, shared why he thinks a trio of jobs — in life sciences, customer service, and computer engineering — is on the cusp of automation.\n\n\"My bet is often on life sciences, pharma companies,\" he said, about his first pick for industries on the brink of change because of AI.\n\nGodement said that the goal of pharmaceutical companies like Amgen, with which he works, is to design new drugs. This has two components: actual research and experimentation, and admin, a time-consuming process that could be automated, he said.\n\n\"The time it takes from once you lock the recipe of a drug to having that drug on the market is months, sometimes years,\" he said. \"Turns out like the models are pretty good at that. They're pretty good at aggregating, consolidating tons of structured, unstructured data, spotting the different changes in documents.\"\n\nGodement joined OpenAI in 2023. He previously worked on products for Stripe for eight years.\n\nOn the podcast, Godement said that while we haven't reached a stage where \"any white collar job\" can be automated in just a day, he is starting to see strong use cases in fields such as coding and customer service.\n\n\"The automation is probably not yet at the level of automating completely the job of a software engineer, but I think we have a line of sight essentially to get there,\" he said.\n\nThe future of software engineering has been one of the most heated tech debates of the year, as AI-assisted coding enters most companies' workflow.\n\nAn Indeed study from October found that software engineers, quality assurance engineers, product managers, and project managers were the four tech jobs that have been axed the most during layoffs and reorgs.\n\nLastly, Godement said that customer-oriented roles like sales and customer experience may be automated soon.\n\n\"I've been working a bunch with the folks at T-Mobile, the telecom company in the US, to essentially provide a better experience to their customers, and we're starting to achieve fairly good results in terms of quality at a meaningful scale,\" he said. \"My sense is we'll probably be surprised in the next year or two on the amount of tasks that can be automated reliably.\"\n\nAcross the board, AI leaders are flagging white-collar jobs that can be easily automated by newer large language models.\n\nIn a June podcast, Geoffrey Hinton, who is recognized as the \"Godfather of AI,\" said that eventually, technology will \"get to be better than us at everything,\" but some fields are safer than others in the interim.\n\n\"I'd say it's going to be a long time before it's as good at physical manipulation,\" Hinton said. \"So a good bet would be to be a plumber.\"\n\n\"For mundane intellectual labor, AI is just going to replace everybody,\" Hinton said.\n\nHe identified paralegals as at risk, and said he'd be \"terrified\" if he worked in a call center.",
    "readingTime": 3,
    "keywords": [
      "life sciences",
      "customer service",
      "automated",
      "podcast",
      "jobs",
      "software",
      "industries",
      "openai",
      "product",
      "products"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-exec-3-jobs-ai-risk-automation-olivier-godement-2025-12",
    "thumbnail_url": "https://i.insider.com/693a53227ecd1d1da66356ca?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.388Z",
    "topic": "finance"
  },
  {
    "slug": "from-garlic-to-avocado-the-goofy-ai-model-codenames-you-should-know",
    "title": "From Garlic to Avocado: The goofy AI model codenames you should know",
    "description": "Leading tech and AI companies are thinking with their stomachs when it comes to naming their secretive AI advancements.",
    "fullText": "It may sound like a trip through the produce aisle, but leading AI companies have something much more important on their lists.\n\nMeta, OpenAI, and Google have all relied on food-related names for their sometimes secretive plans for future AI models. Thinking with your stomach is nothing new for Silicon Valley, just look at the assortment of desserts Android assembled over the years before Google had its fill.\n\nHere is a look at the mouthwatering and just plain goofy names AI and tech companies are using\n\nMeta has codenamed its future AI frontier model \"avocado,\" per a CNBC report. Guac usually costs extra, and CEO Mark Zuckerberg's AI pivot has not come cheap. Meta plans to spend more than $70 billion this year on AI infrastructure, which is on top of $14 billion investment Meta made in Scale AI and to poach its founder, Alexandr Wang.\n\nOpenAI has hit a rough patch, feeling the heat from Google's advances and stumbling with a series of missteps. So perhaps it was time to spice things up. The ChatGPT maker has codenamed its new large language model \"garlic,\" according to The Information. Garlic is separate from another LLM OpenAI is developing, codenamed \"Shallotpeat.\"\n\nGoogle appears to have loved a codename so much that it made it public. Google's AI image generator in Gemini is named Nano Banana Pro, which it released on November 20. Before then, Google had internally called the model nano-banana, though they had not publicly disclosed their zany choice.\n\nThe clearance section offers a wide selection of great names. OpenAI might have one of the best all-time codenames with \"strawberry,\" which it used to refer to its o1 model. The name was likely a play on the viral struggle of AI models to correctly identify the number of Rs in the fruit. Before Strawberry, OpenAI had a secretive project named Q*.\n\nEarlier this year, Elon Musk's xAI had a sweet tooth when it codenamed an early testing version of Grok-3 \"chocolate.\"\n\nMistral AI, the France-based startup, went in a completely opposite direction with \"Jaguar,\" its codename for a testing model.\n\nAnd Anthropic named its family of models Opus, Sonnett, and Hakiu, a trio of three different types of compositions.",
    "readingTime": 2,
    "keywords": [
      "model",
      "codenamed",
      "models",
      "named",
      "secretive",
      "plans",
      "look",
      "codename",
      "testing",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-codenames-meta-avocado-openai-garlic-strawberry-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c0d071107c9f3457b599?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.123Z",
    "topic": "finance"
  },
  {
    "slug": "included-health-is-launching-an-ai-personal-health-assistant-thatll-face-off-with-big-tech-from-verily-to-openai",
    "title": "Included Health is launching an AI personal health assistant that'll face off with Big Tech from Verily to OpenAI",
    "description": "The startup's new tech could compete with Big Tech's health AI projects from heavyweights like Alphabet and OpenAI.",
    "fullText": "Included Health is rolling out a new AI tool that could pit it against Big Tech's latest health bets.\n\nThe healthcare startup has launched an AI-powered personal health assistant, Business Insider has learned exclusively. The tech draws on patients' medical claims, benefits information, and other data to offer on-demand answers to health-related questions.\n\nIncluded Health is tapping into a hot area in healthcare AI, where it's competing against other health startups as well as tech heavyweights. Alphabet's Verily released its own AI-powered app in October that allows patients to connect their medical records and ask a chatbot their health-related questions. OpenAI wants to win in consumer health tech, too, and is considering building tools such as its own personal health assistant, Business Insider reported in November.\n\nIncluded Health has been scaling on the premise of personalizing how patients interact with their healthcare for over a decade. The company, which sells tech to about 300 employers and health plans to help patients better navigate their health benefits, tested its AI assistant for about 18 months to ensure its accuracy in smaller pilots before making it available to its entire employer base, CEO Owen Tripp said.\n\n\"This can't be ChatGPT level of probability. It has to be precise,\" he said.\n\nTripp is optimistic about patients receiving general health guidance from LLMs like OpenAI's ChatGPT or Anthropic's Claude. Those AI tools can help patients learn more about their conditions and prepare for doctor's visits, he said. But he emphasized that Included's tech takes that guidance a step further.\n\n\"When it gets down to the business of actually taking care of oneself or taking care of somebody else, you're going to need a lot of very secure, specific data and a whole context to go solve problems, including the exact medical history of that patient,\" Tripp said.\n\nPatient-facing healthcare AI sometimes walks a regulatory tightrope, especially if the tech provides personalized advice that effectively replaces the work clinicians are licensed to do. Tripp said he doubts that most large tech companies attempting to delve into medical records aggregation will want to grapple with that complexity.\n\n\"I predict, like many before them, they will pull back. It's just hard, and the juice is often not worth the squeeze for these high-profile companies,\" he said.\n\nIncluded Health's personal health assistant, called Dot, has become its members' front door and the foundation for Included's new products, said COO Nupur Srivastava.\n\nIncluded recently put Dot in front of members during open enrollment to help answer their benefits questions, Srivastava said. The AI agent can also help patients prepare for doctor's visits and send the clinician a summary of patients' past visits ahead of time.\n\nIncluded Health still employs plenty of its own clinicians and care advocates that members can talk to if they prefer. Srivastava also noted that if a patient mentions the term 'suicide' in a conversation with Dot, \"within a minute, someone will call you.\"\n\nWhen asked about Big Tech and AI startups' ambitions to build personalized health AI, Tripp said that Included Health is in talks with multiple potential partners to help them achieve those goals. He didn't specify which companies it's talking to, but he suggested some AI companies are focused on acquiring personalized health data that they can anonymize and use to train models.\n\n\"But when it comes to actually delivering patient care, we're pretty confident that companies that are going to succeed will be the ones that have well-trained physicians licensed in all 50 states, delivering on a real-time platform, across mind, body, and wallet,\" he said.\n\nIncluded Health was supposed to go public in 2022. The startup had hired banks for an IPO push, but pulled out of its planned investor meetings when the market started to tank, Tripp told Business Insider in January.\n\nTripp declined to share specifics about Included's exit strategy as of November. But Included is profitable, so the company doesn't need to raise money through a public listing, he said. Included hasn't publicly fundraised since it was formed from the 2021 merger of Grand Rounds and Doctor on Demand, and the company hasn't shared its valuation.\n\nThe public markets haven't been forgiving to healthcare startups. Only two digital health companies went public this year, Hinge Health and Omada Health. And while Hinge and Omada have fared far better than most companies that listed during digital health's 2021 IPO wave, healthcare IPO hopefuls still face high standards to going public and significant volatility risks once they begin trading.\n\n\"The last few years in our space haven't been a great commercial for being a public company,\" Tripp said.\n\nWith so many developments in healthcare AI, however, Tripp does recognize that an IPO could create opportunities for Included Health to acquire other companies.\n\n\"I do think this is a time where there are going to be some interesting capabilities and technologies available in the market that allow us to provide even more service to our members,\" he said. \"I do have my eyes very open to how I would use capital to execute on some of those M&A events. That part is more important to me.\"",
    "readingTime": 5,
    "keywords": [
      "assistant business",
      "included health",
      "doctor's visits",
      "medical records",
      "personal health",
      "personalized health",
      "business insider",
      "patients",
      "healthcare",
      "care"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/included-health-launches-own-ai-personal-health-assistant-2025-12",
    "thumbnail_url": "https://i.insider.com/691290c746c4547ecb058733?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.019Z",
    "topic": "finance"
  },
  {
    "slug": "the-godmother-of-ai-says-your-college-diploma-is-losing-power-heres-what-she-looks-for-instead",
    "title": "The 'Godmother of AI' says your college diploma is losing power — here's what she looks for instead",
    "description": "Fei-Fei Li, founder of the AI startup World Labs, says she now favors fast learners who embrace AI tools over candidates with traditional degrees.",
    "fullText": "Don't count on a college degree to land your dream job in Silicon Valley.\n\nIncreasingly, founders and tech companies are judging talent by how quickly someone can learn, adapt, and build — not on how long they spent in a lecture hall — reshaping traditional pathways into the workforce.\n\nFei-Fei Li, the Stanford computer science professor widely known as the \"Godmother of AI,\" is one example of this.\n\nIn an interview on \"The Tim Ferriss Show\" this week, she spoke about the value of a degree when it comes to hiring for her AI startup, World Labs.\n\n\"When we interview a software engineer, I personally feel the degree they have matters less to us now,\" Li said.\n\n\"Now, it's more about what have you learned, what tools do you use, how quickly can you superpower yourself in using these tools — and a lot of these are AI tools,\" she said. \"What's your mindset toward using these tools matter more to me.\"\n\nHer hiring bar has become even clearer: she won't hire software engineers who resist AI.\n\n\"At this point in 2025 — hiring at World Labs — I would not hire any software engineer who does not embrace AI collaborative software tools,\" Li said.\n\nIt's not about automating humans out of the equation, she added — it's about identifying people who can grow as fast as the technology around them.\n\n\"If you're able to use these tools, you're able to learn. You can superpower yourself better,\" she said.\n\nLi's stance is part of a broader shift playing out across Silicon Valley, where more founders and even major tech firms are openly questioning the value of higher education.\n\nPalantir's CEO, Alex Karp, has openly challenged the value of a college education, urging young entrepreneurs to skip the lecture hall and learn by doing instead — a view echoed by LinkedIn CEO Ryan Roslansky, who has said that adaptability and AI fluency now matter far more than the \"fanciest degrees.\"\n\n\"AI makes skill sets based on years of education irrelevant,\" Dan Rhoton, CEO of Hopeworks, told Business Insider. Hopeworks is a tech-training nonprofit that prepares underrepresented talent for AI-enabled jobs.\n\nAfter 13 years of preparing unemployed young adults ages 17 to 26 in Camden, New Jersey, and Philadelphia for tech careers, Rhoton said he has watched firsthand how AI is upending the value of a college degree.\n\n\"We're seeing more and more employers coming to us, saying, 'We used to require a bachelor's degree in this, but we don't understand why.'\"\n\nInstead, he said, employers now want a \"value proposition,\" which he said any job seeker can achieve by showing an AI-generated solution to a company's specific problems.\n\n\"This is the age of: I'm someone who's going to deliver business value,\" Rhoton said. \"Not: I have the right degree.\"",
    "readingTime": 3,
    "keywords": [
      "lecture hall",
      "software engineer",
      "college degree",
      "tools",
      "tech",
      "learn",
      "hiring",
      "it's",
      "education",
      "rhoton"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godmother-of-ai-value-of-college-degrees-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693aa1db71107c9f3457c06e?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.002Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-under-pressure-as-ai-fears-overshadow-fed",
    "title": "Stocks Under Pressure as AI Fears Overshadow Fed",
    "description": "FTSE 100 Live: Stocks Under Pressure as AI Fears Overshadow Fed",
    "fullText": "LiveUpdated5m agoStocks Under Pressure as AI Fears Overshadow FedJoin the Markets Today team for news and analysis vital to UK markets. Email us at marketstoday@bloomberg.net5m ago\n\n The Fed’s rate cut initially gave equities a boost, and US stocks did close higher, but that more positive mood was dashed by the \n\n results from Oracle\n\n .\n\n The software and cloud computing company’s shares slumped in after-hours trading as it tapped directly into the fears that have hit the AI trade: a jump in spending on AI data centres which are taking longer than investors want to translate into returns.\n\n Those more existential concerns were accompanied by results that failed to meet high expectations, with a 34% rise in cloud sales and 68% bump in infrastructure unit revenue falling short of analyst estimates.\n\n That’s filtering through into a rough picture in US stock futures, though it appears that the pain is mostly being confined to there, even if European and UK futures do look somewhat soggy.",
    "readingTime": 1,
    "keywords": [
      "fears",
      "markets",
      "cloud",
      "futures"
    ],
    "qualityScore": 0.75,
    "link": "https://www.bloomberg.com/news/live-blog/2025-12-11/ftse-100-live-fed-trump-powell-pound-bonds-oil-bitcoin-what-s-moving-uk-markets-right-now-markets-today",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSSIghvwg_70/v0/1200x630.png",
    "created_at": "2025-12-11T07:01:25.043Z",
    "topic": "finance"
  },
  {
    "slug": "json-to-video",
    "title": "JSON to Video",
    "description": "Create stunning videos with structured JSON prompts. Choose between Veo 3.1 and Sora 2 models for flexible AI video generation with predictable, brand-safe results.",
    "fullText": "{\n \"shot\": {\n \"composition\": \"three wide-to-mid cuts; each reveals a different room through glowing portals\",\n \"lens\": \"35mm lens with cinematic softness\",\n \"frame_rate\": \"30fps\",\n \"camera_movement\": \"smooth slider pans between each portal reveal\"\n },\n \"subject\": {\n \"description\": \"neutral adult character flipping a glowing IKEA catalog, choosing a room, and stepping into it\",\n \"wardrobe\": \"simple, clean clothing in soft neutral colors\",\n \"props\": \"oversized luminous IKEA catalog with ambient glow\"\n },\n \"scene\": {\n \"location\": \"empty white space that transforms through glowing portals\",\n \"time_of_day\": \"timeless white light interior\",\n \"environment\": \"blank studio morphing into immersive IKEA interiors via portals\"\n },\n \"visual_details\": {\n \"action\": \"each catalog flip opens a room portal; character steps into chosen one at the end\",\n \"special_effects\": \"subtle energy ripples and glow from each portal; light and particles shift per room theme\",\n \"hair_clothing_motion\": \"gentle breeze interaction from portal pull\"\n },\n \"cinematography\": {\n \"lighting\": \"balanced soft studio light with each room providing its own internal glow\",\n \"color_palette\": \"minimal white base with rich, contrasting tones in each room\",\n \"tone\": \"elegant, imaginative, clean aesthetic\"\n },\n \"audio\": {\n \"music\": \"soft, ascending ambient pad with light spark textures\",\n \"ambient\": \"dimensional air shift when portals open, soft paper flip, subtle room-specific cues\",\n \"sound_effects\": \"light shimmer for each portal, a soft hum as the final portal closes\",\n \"mix_level\": \"smooth, cinematic with priority on environmental transition sounds\"\n },\n \"dialogue\": {\n \"character\": \"\",\n \"line\": \"\",\n \"subtitles\": false\n },\n \"timeline\": [\n {\n \"t\": \"0-3s\",\n \"description\": \"Character opens glowing catalog; first portal opens to a cozy IKEA bedroom with warm light\"\n },\n {\n \"t\": \"3-6s\",\n \"description\": \"Page flips again; second portal shows modern living room with ambient shelves and pendant light\"\n },\n {\n \"t\": \"6-8s\",\n \"description\": \"Character steps confidently through the final portal into a vibrant IKEA kitchen; portal glows and fades\"\n }\n ],\n \"rules\": [\n \"Three total cuts only, each exactly 3s/3s/2s\",\n \"No camera shake or handheld motion\",\n \"No text, no branding visible\",\n \"Portals must glow and feel immersive, not holographic or flat\",\n \"Each room should match real IKEA design aesthetics\"\n ],\n \"negatives\": [\n \"text overlays\",\n \"fast cuts\",\n \"fake-looking portals\",\n \"handheld shots\",\n \"mismatched furniture styles\",\n \"shadows inconsistent with portal lighting\"\n ]\n}Expand",
    "readingTime": 2,
    "keywords": [
      "ikea catalog",
      "character steps",
      "description character",
      "final portal",
      "glowing portals",
      "light description",
      "room",
      "soft",
      "ambient",
      "cuts"
    ],
    "qualityScore": 0.3,
    "link": "https://jsontovideo.org/",
    "thumbnail_url": "https://jsontovideo.org/og.png",
    "created_at": "2025-12-11T07:01:20.644Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "title": "Oracle Credit Risk Gauge Deteriorates After Earnings Report",
    "description": "A measure of Oracle Corp.’s credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence.",
    "fullText": "TechnologyBy Caleb MutuaSaveA measure of Oracle Corp.’s credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence. The cost of protecting the company’s debt against default for five years rose about 0.05 percentage point to around 1.246 percentage point a year, according to ICE Data Services. The gauge, which rises as investor confidence in the company’s credit quality falls, reached its highest level intraday since Thursday. It rose close to its level earlier this month, when it reached a peak since the financial crisis. Oracle credit derivatives have become a credit market barometer for AI risk.",
    "readingTime": 1,
    "keywords": [
      "credit",
      "risk",
      "company’s",
      "rose",
      "percentage",
      "oracle"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-10/oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/idj3XzDNG3DY/v1/1200x800.jpg",
    "created_at": "2025-12-11T03:50:24.284Z",
    "topic": "finance"
  },
  {
    "slug": "upload-a-selfie-and-get-beautiful-ai-santa-photos-for-999",
    "title": "Upload a selfie and get beautiful AI Santa photos for $9.99",
    "description": "Upload a casual standing photo and instantly get a magical Santa portrait with PhotoJing. Fast, high-quality, and perfect for holiday cards and gifts. Create festive Santa photos online in minutes!",
    "fullText": "Turn Any Casual Photo into a Magical Santa Portrait with PhotoJing!\n\nNo lines, no stress—just holiday magic. Whether it’s your little one’s first visit with Santa or a yearly family tradition, PhotoJing creates warm, joy-filled portraits you’ll treasure for years to come.\n\nUpload a simple standing photo, and our team will transform it into a festive Santa picture your family will adore. Perfect for holiday cards, gifts, and spreading seasonal cheer, PhotoJing delivers charming, high-quality Santa portraits from the comfort of your home.\n\nCreate Christmas magic in minutes—just upload, and let us do the rest!\n\n- Upload photo(s) of 1-4 different people.\n- For larger groups, send a message for a custom order.",
    "readingTime": 1,
    "keywords": [
      "upload",
      "holiday",
      "family",
      "portraits",
      "santa",
      "photojing",
      "magic"
    ],
    "qualityScore": 0.65,
    "link": "https://www.photojing.com/products/santa-photos",
    "thumbnail_url": "http://www.photojing.com/cdn/shop/files/Santa_photo_collage_ver_2_1.png?v=1765415082",
    "created_at": "2025-12-11T03:50:16.098Z",
    "topic": "tech"
  },
  {
    "slug": "navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "title": "Navy, Palantir Announce $448M 'Ship OS' AI Tool for Shipbuilding and Repair",
    "description": "The Navy’s four public shipyards and two unidentified private shipyards are working with Palantir for a program the service is calling “Ship OS” as part of a new $448 million effort to improve efficiency through better use of data. Announced at an industry day on Tuesday, the Shipbuilding Operating System program, or Ship OS, will collect data from across the new construction and maintenance systems to streamline shipbuilding and the repair of the current fleet, according to the service. “Every ship builder who partners with us will have AI power tools that optimize their work in real time. Every supplier",
    "fullText": "USNI News Giving Tuesday 2025 \n\n Our annual Giving Tuesday campaign provides essential funding that enables our staff writers to observe firsthand the evolving character of naval warfare and international maritime commerce - and to bring those insights directly to you, our readers! Thanks to your generosity in 2024, we were able to send our team across the fleet to learn from and connect with Navy, Marine Corps, and Coast Guard in the Western Pacific, like Taiwan and the Philippines, as well as around the globe. Your support directly fuels our on-the-ground coverage of naval operations and the global security challenges facing our Sea Service leaders—challenges that cannot be fully appreciated from within the Beltway alone. We continue to operate as a public service, and this is made possible by your generosity! If you believe in open, independent journalism, please consider supporting our critical mission with a donation today. \r\n As a special gift, all one-time or annual donations amounting to $200 or more will receive exclusive access to the Special Report: Nimitz ’75 — Celebrating the Origin of the Nuclear Carrier Class for USS Nimitz (CVN-68) Last Deployment. Donors contributing more than $300 will also receive a Collected Edition of USNI News 2025 Sea Scroll Weekly Newsletter V2. \n\n Donate Today",
    "readingTime": 2,
    "keywords": [
      "usni",
      "annual",
      "naval",
      "directly",
      "generosity",
      "receive",
      "nimitz",
      "service"
    ],
    "qualityScore": 0.65,
    "link": "https://news.usni.org/2025/12/09/navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "thumbnail_url": "https://news.usni.org/wp-content/uploads/2025/12/9294700-scaled.jpg",
    "created_at": "2025-12-11T03:50:15.641Z",
    "topic": "tech"
  },
  {
    "slug": "the-normalization-of-deviance-in-ai",
    "title": "The Normalization of Deviance in AI",
    "description": "The gradual and systemic over-reliance on LLM outputs, especially with agentic systems, leads to a normalization of deviance.",
    "fullText": "The AI industry risks repeating the same cultural failures that contributed to the Space Shuttle Challenger disaster: Quietly normalizing warning signs while progress marches forward.\n\nThe original term Normalization of Deviance comes from the American sociologist Diane Vaughan, who describes it as the process in which deviance from correct or proper behavior or rule becomes culturally normalized.\n\nI use the term Normalization of Deviance in AI to describe the gradual and systemic over-reliance on LLM outputs, especially in agentic systems.\n\nAt its core, large language models (LLMs) are unreliable (and untrusted) actors in system design.\n\nThis means that security controls (access checks, proper encoding, and sanitization, etc.) must be applied downstream of LLM output.\n\nA constant stream of indirect prompt injection exploit demonstrations indicates that system designers and developers are either unaware of this or are simply accepting the deviance. It is particularly dangerous when vendors make insecure decisions for their userbase by default.\n\nI first learned about this concept in the context of the Space Shuttle Challenger disaster, where systemic normalization of warnings led to tragedy.\n\nDespite data showing erosion in colder temperatures, the deviation from safety standards was repeatedly rationalized because previous flights had succeeded. The absence of disaster was mistaken for the presence of safety.\n\nIn the world of AI, we observe companies treating probabilistic, non-deterministic, and sometimes adversarial model outputs as if they were reliable, predictable, and safe.\n\nVendors are normalizing trusting LLM output, but current understanding violates the assumption of reliability.\n\nThe model will not consistently follow instructions, stay aligned, or maintain context integrity. This is especially true if there is an attacker in the loop (e.g indirect prompt injection).\n\nHowever, we see more and more systems allowing untrusted output to take consequential actions. Most of the time it goes well, and over time vendors and organizations lower their guard or skip human oversight entirely, because “it worked last time.”\n\nThis dangerous bias is the fuel for normalization: organizations confuse the absence of a successful attack with the presence of robust security.\n\nTwo ways this can impact systems are:\n\nAnd we already see agents make mistakes in day to day usage, like formatting hard drives, creating random GitHub issues, or wiping a production database.\n\nSo, the signs are there. And it is inherently dangerous, not only because of attacks like indirect prompt injection, but also because these systems are trained on enormous, untrustworthy data sets from the Internet. Anthropic research recently showed that it takes only a small amount of documents to successfully add a backdoor to a model.\n\nConsider a scenario where the Normalization of Deviance has drastic consequences: an attacker trains a backdoor into a model that triggers on certain days to invoke tools, like compromising a user via code execution. Since we have a pretty centralized ecosystem, where attacks often are transferable, and natural language is universally understood by LLMs, this can have consequences across many systems and vendors.\n\nSuch a drift does not happen through a single reckless decision. It happens through a series of “temporary” shortcuts that quietly become the new baseline. Because systems continue to work, teams stop questioning the shortcuts, and the deviation becomes invisible and the new norm.\n\nEspecially under competitive pressure for automation, cost savings, a drive to be first, and the overall hype, this dangerous drift is evident. The incentives for speed and winning outweigh the incentives for foundational security. Over time, organizations forget why the guardrails existed in the first place.\n\nLet me share some examples of how this is reflected in real-world agentic AI systems.\n\nWe are all aware that chatbots have those “AI can make mistakes”, “Double check responses” and so forth disclaimers, and we can observe the drift of normalization occurring in real-time.\n\nThree years after ChatGPT shipped, vendors push agentic AI to users, but at the same time vendors are highlighting that your system might get compromised by that same AI - that drift, that normalization, is what I call “The Normalization of Deviance in AI”.\n\nThis continuous drift is a long-term danger:\n\nWhile some vendors acknowledge the risks, others appear to overlook or downplay them, potentially due to competitive pressure and focus on product and customer acquisition.\n\nIn many cases, we probably collectively hope that “someone” will solve these security and safety challenges.\n\nCompanies like Google, OpenAI, Anthropic, Microsoft, and other institutions and organizations perform extensive research in this area, including publishing evals and mitigation ideas. However, the rush to be the first is evident from a product perspective.\n\nNevertheless, before we drift off into a utopian future with agentic AI, I believe the best and safest outcome is to stay realistic around capabilities and control mechanisms, and for AI to remain human-led, particularly in high-stake contexts, to ensure the best outcome overall.\n\nNo, of course not. There is a lot of potential and many low stakes workflows can be implemented already today. Even high-risk workflows can be done with proper threat modeling, mitigations and oversight.\n\nHowever, it requires investment and resources to design and set up systems accordingly and apply security controls (sandbox, hermetic environments, least privilege, temporary credentials, etc.).\n\nMany are hoping the “model will just do the right thing”, but Assume Breach teaches us, that at one point, it will certainly not do that.",
    "readingTime": 5,
    "keywords": [
      "space shuttle",
      "shuttle challenger",
      "challenger disaster",
      "llm output",
      "competitive pressure",
      "indirect prompt",
      "prompt injection",
      "security controls",
      "normalization of deviance",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/",
    "thumbnail_url": "https://embracethered.com/blog/images/2025/normalization-of-deviance-in-ai.png",
    "created_at": "2025-12-11T03:50:15.597Z",
    "topic": "tech"
  },
  {
    "slug": "actress-natasha-lyonne-dropped-out-of-nyu-and-watched-movies-instead-now-shes-helping-to-shape-the-future-of-ai",
    "title": "Actress Natasha Lyonne dropped out of NYU and watched movies instead. Now, she’s helping to shape the future of AI",
    "description": "“We are the ones who are deciding what this use is going to be and how we choose to use it,” Lyonne told the Fortune Brainstorm AI audience in San Francisco.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/natasha-lyonne-ai-animal-pictures-asteria-film-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972842873_c57138e2e2_o-e1765256586861.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:15.065Z",
    "topic": "entertainment"
  },
  {
    "slug": "top-economist-diane-swonk-jerome-powell-risks-losing-the-feds-credibility-on-a-gamble-over-ai-and-immigration",
    "title": "Top economist Diane Swonk: Jerome Powell risks losing the Fed’s credibility on a gamble over AI and immigration",
    "description": "It all comes down to the reason behind the weakness in unemployment and Powell’s diagnosis of the “low-hire, low-fire” economy of 2025.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/jerome-powell-risks-credibility-ai-immigration-diane-swonk/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2250475944-e1765402773522.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.954Z",
    "topic": "business"
  },
  {
    "slug": "instacarts-aienabled-pricing-may-bump-up-your-grocery-costs-by-as-much-as-23",
    "title": "Instacart's AI-enabled pricing may bump up your grocery costs by as much as 23%",
    "description": "Shoppers may be unaware they're paying as much as 23% more than others for the same grocery items on Instacart, a new analysis says.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cbsnews.com/news/instacart-price-discrepancies-investigation/",
    "thumbnail_url": "https://assets2.cbsnewsstatic.com/hub/i/r/2025/12/09/4a650015-732a-4746-bcdb-f72145f0c302/thumbnail/1200x630/e684ba8cc56e043f29542fb6f8589678/gettyimages-1395364375.jpg",
    "created_at": "2025-12-11T03:50:14.929Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-already-taking-over-managers-busyworkand-its-forcing-companies-to-reset-expectations",
    "title": "AI is already taking over managers’ busywork—and it’s forcing companies to reset expectations",
    "description": "As AI agents automate administrative tasks, industry leaders say the role of human managers needs to shift toward coaching and strategy—but most organizations aren’t moving fast enough.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/ai-managers-automate-busy-work-org-chart-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974007976_8abae70b9a_o.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.746Z",
    "topic": "business"
  },
  {
    "slug": "google-deepmind-agrees-to-sweeping-partnership-with-uk-government-focused-on-science-and-clean-energy",
    "title": "Google DeepMind agrees to sweeping partnership with U.K. government focused on science and clean energy",
    "description": "The collaboration will see the AI company collaborating with the British government on a robotic lab for new materials, fusion energy, and new research into AI safety and the societal impacts of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/google-deepmind-uk-government-partnership-science-clean-energy/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2217672931-e1765404847213.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.668Z",
    "topic": "politic"
  },
  {
    "slug": "braininspired-llm-alignment",
    "title": "Brain-Inspired LLM Alignment",
    "description": "Thank you for considering applying for an ACX grant. Please use the form below.",
    "fullText": "This 2024 form is no longer accepting responses. You're probably looking for the 2025 form at https://forms.gle/dBAcmR7XMfgnxxwn8 .",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://docs.google.com/forms/d/e/1FAIpQLSc6vmem8-XfhVkMde3PCyysAS_bwBImk3H9iJo0S1OsqfUHWg/closedform",
    "thumbnail_url": "https://lh3.googleusercontent.com/RtXozrlYzCtSFZONcq-j4gNzMeo52ITKZL9qZ3gIVhC1fXlg_eQk4MJftciaiFRYU0eJlqMgHhMCwFE=w1200-h630-p",
    "created_at": "2025-12-11T03:50:14.270Z",
    "topic": "tech"
  },
  {
    "slug": "the-navy-says-ai-cut-a-160hour-submarineplanning-job-down-to-just-10-minutes-now-its-investing-448-million-to-go-bigger",
    "title": "The Navy says AI cut a 160-hour submarine-planning job down to just 10 minutes — now it's investing $448 million to go bigger",
    "description": "The Navy is investing almost half a billion dollars in Palantir artificial intelligence software that promises to speed up shipbuilding processes.",
    "fullText": "The Navy is pouring hundreds of millions of dollars into an artificial intelligence system that it says has sped up key shipbuilding processes.\n\nIn one case, the AI cut painstaking processes of submarine schedule planning — mapping out how the many pieces of construction fit together and making sure people, parts, and yard space are available at the right time — from many hours to only minutes.\n\nThe Navy is launching the new Shipbuilding Operating System, or Ship OS, as it tries to break out of decades-old shipbuilding problems rooted in outdated technologies and work practices. The service announced a $448 million investment Thursday, saying it will accelerate the adoption of AI and autonomy across the industrial base.\n\nThe Ship OS technology is powered by Palantir's Foundry and Artificial Intelligence Platform and began in pilot programs at submarine shipyards.\n\nAt General Dynamics Electric Boat, a long-time submarine yard located in Connecticut, submarine schedule planning saw a dramatic reduction from 160 manual hours down to under 10 minutes. And at Portsmouth Naval Shipyard in Maine, material review times for submarines went from taking weeks to under an hour.\n\nThe $448 million investment will go toward the submarine industrial base and then expand. It'll be deployed across two major shipbuilders, three public yards, and 100 suppliers, Palantir said in a press release.\n\n\"This investment provides the resources our shipbuilders, shipyards, and suppliers need to modernize their operations and succeed in meeting our nation's defense requirements,\" said Navy Secretary John Phelan in a statement.\n\n\"By enabling industry to adopt AI and autonomy tools at scale, we're helping the shipbuilding industry improve schedules, increase capacity, and reduce costs,\" he added, explaining \"this is about doing business smarter and building the industrial capability our Navy and nation require.\"\n\nMaritime Industrial Base Program, a Navy initiative to revitalize US shipbuilding and repair capabilities, and Naval Sea Systems Command are overseeing the implementation of Ship OS. Both are gathering data from multiple sources to identify where the hiccups are in submarine shipbuilding, how the processes, including engineering, can be sped up, and what specific risks can be mitigated through technology.\n\nProblems in the Navy’s submarine industrial base — from shipbuilders to the repair yards — have been building for decades. Submarines are central to any Pacific fight and a top Pentagon priority, yet major programs like the upgraded Virginia-class submarines and new Columbia-class ballistic missile subs have repeatedly run into delays and cost overruns.\n\nThe Government Accountability Office, a government watchdog agency, has documented long-standing problems in the Navy's plans for purchasing and constructing submarines, as well as shipyard deficiencies such as worker inexperience, aging facilities and equipment, and inadequate construction space.\n\nThe introduction of the new Ship OS capability aims to address some of these problems facing US submarine shipbuilding. And once the technology has been used for the submarine programs, the Navy said, it'll apply lessons and adapt them to surface ship programs.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "schedule planning",
      "industrial base",
      "submarine schedule",
      "submarine shipbuilding",
      "the navy",
      "ship os",
      "programs",
      "submarines",
      "processes"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/navy-ai-cut-hourslong-submarine-planning-job-to-minutes-2025-12",
    "thumbnail_url": "https://i.insider.com/6939afa67ecd1d1da6634afc?width=1200&format=jpeg",
    "created_at": "2025-12-11T03:50:13.974Z",
    "topic": "finance"
  },
  {
    "slug": "instagram-is-adding-aigenerated-headlines-to-some-posts",
    "title": "Instagram Is Adding AI-Generated Headlines to Some Posts",
    "description": "No one asked for this.",
    "fullText": "Few of us are under the illusion that we own the content that we post on Instagram, but we do get a say in how that content is presented—we can choose which photos and videos we share, what captions appear (or don't appear) on each post, as well as whether or not we include where the image was taken or shared from. We might not control the platform, but we can control the content of our posts—unless those posts are found on search engines like Google.\n\nAs reported by 404 Media, Instagram is now experimenting with AI-generated SEO titles for users' posts—without those users' input or permission. Take this post for example: Author Jeff VanderMeer uploaded a short video of rabbits eating a banana to his Instagram. The video was posted as-is: There was no caption, location tag, or any other public-facing information. It's just a couple of rabbits having a bite.\n\nA post shared by Jeff VanderMeer (@jeff_vandermeer123)\n\nInstagram, however, took it upon itself to add a headline to the post—at least when you stumble upon it on via Google. Rather than display a link featuring Jeff's Instagram handle and some metadata about the video, the Google entry comes back with the following headline: \"Meet the Bunny Who Loves Eating Bananas, A Nutritious Snack for...\" (the rest of the headline cuts off here).\n\nVanderMeer was less than pleased with the discovery. He posted a screenshot of the headline to Bluesky, writing, \"now [Instagram] appears to generate titles [and] headlines via AI for stuff I post...to create [clickbait] for [Google] wtf do not like.\"\n\nThis was not the only AI-generated headline VanderMeer was roped into. This post from the Groton Public Library in Massachusetts, which advertises VanderMeer's novel Annihilation as the library's December book group pick, was also given the clickbait treatment on Google. Just as with VanderMeer's post, the Groton Public Library didn't include any text in its Instagram post—just an image showing off the book. But if you see the post within a Google search, you'll see the following partial headline: \"Join Jeff VanderMeer on a Thrilling Beachside Adventure...\"\n\n404 Media's Emanuel Maiberg says that they've confirmed that Instagram is also generating headlines for other users on the platform, all without permission or knowledge. Google told Maiberg the headlines are not coming from its AI generators—though it has been using deceptive AI-generated headlines of its own on Google Discover. In fact, the company says its search engine is simply pulling the text from Instagram itself. Maiberg found that these headlines do appear under title tags for Instagram posts when using Google's Rich Result Test tool. When digging through the code, Maiberg also discovered AI-generated descriptions for each post, which could be what Instagram is ultimately using to generate the headlines.\n\nI reached out to Meta for comment, and this story originally published before they responded. However, a Meta spokesperson has since confirmed to me that Instagram has recently started generating these titles using AI. The goal, according to the spokesperson, is to make it easier to know what a post is about before you click the link. They also noted that these headlines might not be totally correct, as with all AI products. In addition, the spokesperson explained that search engine optimization indexing is not necessarily new. The company has been doing this for years in the U.S. to increase visibility for posts from professional accounts.\n\nThat last point is all fine and good, of course. No one is surprised that Instagram is indexing posts for search engines: Most social media platforms do that. Otherwise, you'd never find any of their posts on platforms like Google. The issue is generating fake headlines with AI without letting anyone know about it. Just because Meta AI is capable of generating headlines doesn't mean it is good at it, or even that it should—especially when users never consented to this practice in the first place. It'd be one thing if Instagram had an option before you post—something like \"Generate a headline for me using Meta AI that will appear in search engines for my post.\" Most of us would opt out of that, but it'd at least be a choice. However, it appears that Instagram decided that users like VanderMeer weren't capable of writing a headline as clever as \"Meet the Bunny Who Loves Eating Bananas.\"\n\nThe worst part is, the AI doesn't even accurately describe the posts, a risk the Meta spokesperson readily admits to. That Groton Public Library post was only about a book club meeting featuring VanderMeer's novel, but the headline says \"Join Jeff VanderMeer,\" as if he'd be making an appearance. Not only did Instagram add a headline without VanderMeer's consent, it spread misinformation about his whereabouts. And for what? Some extra engagement on Google?\n\nIf Instagram wants its posts to appear as headlines on search engines, it should include the actual posters in the conversation. As VanderMeer told 404 Media: \"If I post content, I want to be the one contextualizing it, not some third party.\"\n\nWhile Meta has yet to add a dedicated on/off switch for these headlines, one thing you can do to ensure your posts don't get an AI clickbait makeover is to opt out of indexing as a whole. If you run an account that relies on discoverability, this might not be worth it, since you'll be impacting how users find your posts outside of Instagram. However, if you don't care about that, or you don't need the SEO at all, you can stop Instagram from making your posts available on search engines—and putting an end to the AI-generated headlines, at that.\n\nThere are three ways to accomplish this, according to Instagram:\n\nMake your account private: Head to Instagram's in-app settings, then choose Account privacy. Here, tap the Private account toggle.\n\nSwitch your account from professional to private: Open Instagram's in-app settings, scroll down and tap Account type and tools. Here, choose \"Switch to personal account.\"\n\nManually opt out of indexing: Head to Instagram's in-app settings, then choose Account privacy. You should see an option to stop your public photos and videos from appearing in search engines.",
    "readingTime": 6,
    "keywords": [
      "loves eating",
      "eating bananas",
      "instagram's in-app",
      "vandermeer's novel",
      "join jeff",
      "in-app settings",
      "ai-generated headlines",
      "account privacy",
      "search engines",
      "search engine"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/instagram-adding-ai-headlines-posts?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC2DE7N6Z5BP8WS17SW0SCVW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T03:50:11.984Z",
    "topic": "tech"
  },
  {
    "slug": "cursor-introduces-debug-mode",
    "title": "Cursor Introduces Debug Mode",
    "description": "Built to make you extraordinarily productive, Cursor is the best way to code with AI.",
    "fullText": "Coding agents are great at lots of things, but some bugs consistently stump them. That's why we're introducing Debug Mode, an entirely new agent loop built around runtime information and human verification.\n\nTo build it, we examined the practices of the best debuggers on our team. We rolled their workflows into an agent mode, equipping it with tools to instrument code with runtime logs, prompts that generate multiple hypotheses about what's going wrong, and the ability to call back to you to reproduce the issue and verify fixes.\n\nThe result is an interactive process that reliably fixes bugs that were previously beyond the reach of even the smartest models working alone, or could take significant developer time to address.\n\nTo get started, select Debug Mode from the dropdown menu and describe the bug in as much detail as you can.\n\nInstead of immediately trying to generate a fix, the agent reads through your codebase and generates multiple hypotheses about what could be wrong. Some will be ideas you would have thought of on your own, but others will likely be approaches you wouldn't have considered.\n\nThe agent then instruments your code with logging statements designed to test these hypotheses. This prepares the agent to receive concrete data about what's actually happening when the bug occurs.\n\nNext, go to your application and reproduce the bug while the agent collects the runtime logs.\n\nThe agent can see exactly what's happening in your code when the bug occurs: variable states, execution paths, timing information. With this data, it can pinpoint the root cause and generate a targeted fix. Often that's a precise two or three line modification instead of the hundreds of lines of speculative code you'd have received with a standard agent interaction.\n\nAt this point, Debug Mode asks you to reproduce the bug one more time with the proposed fix in place. If the bug is gone, you mark it as fixed and the agent removes all the instrumentation, leaving you with a clean, minimal change you can ship.\n\nThis human-in-the-loop verification is critical. Sometimes bugs are obvious, but other times they fall into a gray area where the fix might work technically but not feel right. The agent can't make that call on its own. If you don't think the bug is fixed, the agent adds more logging, you reproduce again, and it refines its approach until the problem is actually solved.\n\nThis kind of tight back-and-forth is one way we think AI coding works best. The agent handles the tedious work while you make the quick decisions that need human judgment. The result with Debug Mode is that tricky bugs that used to be out of reach are now reliably fixed.\n\nRead the Debug Mode docs. Learn about all the new features in Cursor 2.2.",
    "readingTime": 3,
    "keywords": [
      "runtime logs",
      "bug occurs",
      "debug mode",
      "agent",
      "bugs",
      "code",
      "reproduce",
      "generate",
      "hypotheses",
      "what's"
    ],
    "qualityScore": 1,
    "link": "https://cursor.com/blog/debug-mode",
    "thumbnail_url": "https://ptht05hbb1ssoooe.public.blob.vercel-storage.com/assets/changelog/changelog-2-2-debug.png",
    "created_at": "2025-12-10T18:55:48.559Z",
    "topic": "tech"
  },
  {
    "slug": "instacart-may-be-jacking-up-your-grocery-prices-using-ai-study-showsa-practice-called-smart-rounding",
    "title": "Instacart may be jacking up your grocery prices using AI, study shows—a practice called ‘smart rounding’",
    "description": "Consumer Reports and the progressive think tank Groundwork Collaborative used ~200 volunteers to check prices on 20 items in four cities.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/instacart-may-be-jacking-up-your-grocery-prices-using-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2216221632-e1765386311727.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.794Z",
    "topic": "business"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are ‘growing up fluent in AI’ and that’s helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-new-tools-that-can-improve-workforce-training",
    "title": "The New Tools That Can Improve Workforce Training",
    "description": "Companies are pouring money into AI but failing to translate that investment into workforce capability, largely because traditional training methods don’t help employees retain or apply complex skills. Extended reality—virtual reality, augmented reality, and mixed reality—bridges this gap by letting people learn through immersive, emotionally engaging, hands-on experiences that the brain encodes like real events. Organizations from Bank of America to Boeing to Walmart are already seeing faster learning, higher confidence, reduced errors, and lower costs by using XR to train employees in everything from customer-service scenarios to technical assembly. The technology works because it aligns with how people actually learn, benefits from major improvements in affordability and accessibility, and meets the expectations of a workforce already accustomed to immersive digital environments. The companies that start with focused pilot projects, match the right XR tool to the right skill gaps, and scale deliberately will build training systems that actually change behavior and materially improve performance.",
    "fullText": "The New Tools That Can Improve Workforce Training by Paola Cecchi-DimeglioDecember 10, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintThis year companies plan to invest $1.5 trillion in AI initiatives, with forecasts showing that investments will rise to $2 trillion by 2026. Gartner research predicts that most of this spending will not meet expected returns. The issue isn’t the technology; it’s our failure to help people utilize it.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://hbr.org/2025/12/the-new-tools-that-can-improve-workforce-training",
    "thumbnail_url": "/resources/images/article_assets/2025/11/Dec25_01_200202284-009.jpg",
    "created_at": "2025-12-10T18:55:43.958Z",
    "topic": "business"
  },
  {
    "slug": "the-5-ai-tensions-leaders-need-to-navigate",
    "title": "The 5 AI Tensions Leaders Need to Navigate",
    "description": "The introduction of AI into the workplace inherently creates tension. The same tools that relieve drudgery and make work easier, for example, can also remove the challenging friction that gives work its meaning, builds crucial skills, and increases satisfaction. Which tensions are most common in workplaces—and how are they actually playing out? Insights collected from over 100 leaders show that they’re wrestling with several competing forces: experts vs. novices, centralization vs.",
    "fullText": "The 5 AI Tensions Leaders Need to NavigateBased on insights from more than 100 builders, executives, investors, advisors, and researchers from across the globe. by Rebecca Hinds and Robert I. SuttonDecember 10, 2025Summary.   Leer en españolLer em portuguêsPostPostShareSavePrintdetect cancer, their accuracy improved. But their performance on non-AI procedures got worse. When students used AI to draft SAT-style essays, their creativity initially spiked. Yet those who started with AI-generated ideas showed reduced alpha-wave activity (a marker of creative flow), “tended to converge on common words and ideas,” and their “output was very, very similar” to one another’s. And in a 2025 study spanning 20 European countries, workers in highly automated jobs reported less purpose, less control, and more stress, even when their work became technically easier.",
    "readingTime": 1,
    "keywords": [
      "ideas",
      "less"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/the-5-ai-tensions-leaders-need-to-navigate",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_10_ChenWu.jpg",
    "created_at": "2025-12-10T18:55:43.948Z",
    "topic": "business"
  },
  {
    "slug": "as-ai-floods-our-culture-heres-why-we-must-protect-human-storytelling-in-games",
    "title": "As AI floods our culture, here’s why we must protect human storytelling in games",
    "description": "Buying the Zombies, Run! studio wasn’t part of ​my plan, but a post-apocalypse ​game with stories that make people feel seen pulled me in\n• Don’t get Pushing Buttons delivered to your inbox? Sign up here\nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?",
    "fullText": "Buying the Zombies, Run! studio wasn’t part of ​my plan, but a post-apocalypse ​game with stories that make people feel seen pulled me in\n\nDon’t get Pushing Buttons delivered to your inbox? \nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?\n\nWell. First of all. Zombies, Run! is special. It’s special to me – the game started as a Kickstarter and the community that grew up around it has always been incredibly supportive of what we’re doing. And it’s special in what it does. It’s a game to exercise with. You play it on your smartphone – iPhone or Android – and we tell stories from the zombie apocalypse in your headphones to encourage you to go further, faster, or just make exercise less boring. Games are so often portrayed as the bad entertainment form, but I made a game that fundamentally helps people to be healthier.\n\nThe experience of playing Zombies, Run! is also completely focused on storytelling. My co-creator Adrian Hon and I were talking about doing a project together. He said: “Let’s do something to make running more fun.” I said: “How about if we do a story where you’re being chased by zombies?” And here we are.\n\nWhen you play the game, you’re immersed in a world where every run makes you a hero – you’re collecting supplies, saving a child from no man’s land, investigating the mystery of how the apocalypse started. I’ve always focused on the storytelling being good. And it works. Players of the game become so attached to the characters that many of them report laughing out loud or even “crying while running”.\n\nOne of my jokes about storytelling in video games is that the way we tend to talk about it – in the games industry, in games journalism, even in marketing copy – is very much “never mind the quality, feel the width”. We say things like “this game has 100-plus hours of story” or “this game contains more than a million words”. Imagine marketing a movie saying that the script contains 29,000 words. Or selling a novel on the basis that it’ll take a long time to read.\n\nThat’s not how you do it. You tell the story. You give a hook. You say: “A single woman comes home one evening to find a man claiming to be her husband living in her house. And when he goes up to the attic, a different husband comes down in his place.” Now you can’t wait to find out what happens next. (That, incidentally, is the brilliant comic novel The Husbands by Holly Gramazio – who I think is the only other bestselling novelist to be also making her own video games.)\n\nSo, now I own a games company, what am I going to do? My feeling is that I must focus on the fundamentals. There’s a world of games out there that thinks it can replace writers with AI large language models. I think that’s going to make writing worse and worse. AI writing is fine for boilerplate text that is always roughly the same. It’s fine for non-writers to get their expertise into the world. But storytelling is different. It is human minds finding companionship with other human minds – we need stories, fundamentally, to feel less alone. To know that other people have been through things a bit like what we have. Things that make us laugh, and cry, even while running. You get that from work that is not the same as everything else, you get it from the unique work of other individual human minds.\n\nAnd actually, Zombies, Run! has always been a universe with strong values. We’re not a rightwing, rugged-individualism apocalypse, where one lone person can get through with just their guns. In our world – as in the real world – humans survive by working together.\n\nWhile we’re still going to have many exciting fleeing zombies, battling-the-undead storytelling, I think there’s probably also room in the ZR! universe for a 10-mission arc where you have to find all the figurines and paints you need to complete an expansion set in “Demons and Darkness”; or one where you’re working on bringing an overgrown garden back to blooming, beautiful life; or setting up and running the first post-apocalyptic travelling library while also trying to work out what happened to the first librarian who’s mysteriously disappeared, leaving only a series of cryptic notes in an old manuscript.\n\nAfter all, I do think this is quite a good time in the world to be thinking about how to rebuild after a series of catastrophic events.\n\nSelling story by the yard and not by a story hook is a marker, I think, of a lack of confidence in the form. We don’t need to lack confidence. Games are the biggest entertainment industry in the world. If we want to be taken seriously, we need to take ourselves seriously. Stop talking about the width, start talking about the quality.\n\nIt was the 20th anniversary of Xbox 360 recently, and one name that’s cropped up in every list of the console’s best games is the compulsive retro twin-stick shooter Geometry Wars. If you’re yearning for something similar, you must immediately download Evil Egg, a frenzied twin-stick blaster with gorgeous Commodore 64-style visuals and sound effects. Shoot everything that moves, hit the left trigger to boost and collect hearts to stay alive.\n\nAt first it’s a bewildering mass of rainbow pixels but as you detonate wave after wave of glitchy space pests, you begin to understand the patterns of different enemies and earn upgrades such as the executioner’s sword, which takes out foes in an orbital slash of laser particles. Evil Egg is polished, exciting, wild to look at, and has such a brilliant understanding of the genre and its unique dynamics. It’s free on Steam but I implore you to download it on Itch.io and name your own price. Keith Stuart\n\nAvailable on: PC\n\n Estimated playtime: 10-plus hours\n\nThere has been a lot of writing about Horses, the art game recently banned by digital platforms Steam and Epic Games Store. I particularly enjoyed this post by writer Harper Jay MacIntyre, which considers Horses, formalism and the trans experience. The article manages to bring in so many elements of modern games criticism and academia while providing a highly personal response to the game.\n\nThe most interesting retro game articles are the ones that reassess lost or derided titles rather than merely celebrate the classics. Was the Atari 2600 version of Pac-Man the worst game ever? Not according to this compelling analysis from Garrett Martin at AV Club who sees it as a misunderstood brutalist gem. I find myself in agreement.\n\nIt is also nice to see a legendary game justly praised in an interesting way. The BFI’s look at the legacy of Time Crisis considers the gun game in relation to cinema, referencing Beverly Hills Cop and Run Lola Run rather than just comparing it to Sega’s similar Virtua Cop.\n\nSkate Story – hellish premise aside, this is skateboarding paradise | ★★★★☆\n\nHorror game Horses has been banned from sale – but is it as controversial as you’d think?\n\nFive Nights at Freddy’s 2 – inept game-based horror is one of the year’s worst | ★☆☆☆☆\n\nThis one comes from reader, Rebecca:\n\n“My elderly grandad is coming to stay with us for Christmas and wants to see what’s happening with video game graphics these days. Are there any titles you recommend that will let him explore beautiful locations without getting shot at?! We have a PlayStation 5 and a slightly out-of-date PC.”\n\nYour best option here is to go with one of the big open-world adventures and just find an area with no enemies around. If you You could bypass the threat of imminent violence completely by going for a driving game, such as Forza Horizon 4 on PC (which is set in Britain so he may even spot some familiar scenery). Alternatively, if visual realism isn’t as important as beauty, a cosier indie title such as Tchia, Journey or Firewatch may fit the bill. Really hope he enjoys them!\n\nWe’re still looking for your game of the year nominations for an end of year special – let us know yours by hitting reply or emailing us on pushingbuttons@theguardian.com.",
    "readingTime": 8,
    "keywords": [
      "plus hours",
      "human minds",
      "zombies run",
      "evil egg",
      "game",
      "games",
      "storytelling",
      "you’re",
      "we’re",
      "stories"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/10/i-bought-the-games-studio-behind-zombies-run-because-humanity-is-essential-to-storytelling",
    "thumbnail_url": "https://i.guim.co.uk/img/media/1817abf90f05afe67e594b055c45343b486ae1e6/102_0_925_740/master/925.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8991d15d4205b4197c1289fdd0cfb154",
    "created_at": "2025-12-10T18:55:43.393Z",
    "topic": "gaming"
  },
  {
    "slug": "china-to-limit-access-to-nvidias-h200-chips-despite-trump-export-approval-ft-reports",
    "title": "China to limit access to Nvidia's H200 chips despite Trump export approval, FT reports",
    "description": "Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ​export of the technology to China, the Financial Times reported on ‌Tuesday, citing two people with knowledge of the matter.  Regulators in Beijing have been discussing ways to ‌permit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.",
    "fullText": "Dec 9 (Reuters) - Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ​export of the technology to China, the Financial Times reported on ‌Tuesday, citing two people with knowledge of the matter.\n\nRegulators in Beijing have been discussing ways to ‌permit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.\n\nSuch a move would add a hurdle to Nvidia and other top U.S. chipmakers' ability to address the China market, after Trump's Monday announcement appeared ⁠to settle a debate over ‌whether these companies should keep their global lead by selling AI chips to China or withhold shipments.\n\nNvidia shares, which had risen ‍as much as 2% in premarket trading, pared gains after the report and were last up about 0.6%. The company did not immediately respond to a Reuters request for ​comment on the report.\n\nBeijing has been pushing back against domestic firms' use of ‌U.S. technology, especially Nvidia chips, as it retaliates against American restrictions.\n\nEarlier U.S. restrictions banned the sale of advanced AI processors to China, weighing on Nvidia's ability to grow in one of the world's largest markets for AI chips and development.\n\nThe export of the H200 chips will be permitted with a 25% fee levied ⁠on such sales, Trump said in a ​post on Truth Social on Monday.\n\nIpek Ozkardeskaya, senior ​analyst at Swissquote Bank, said the approval alone may have limited impact on Nvidia's business in China unless it is allowed to ‍export other chip ⁠lines such as Blackwell or Rubin.\n\nShares of AMD and Intel also pared gains and were last up about 0.3% in premarket trading. So far ⁠this year, Nvidia has gained nearly 40% compared with the S&P 500 benchmark index's 16.4% rise ‌in the same period.",
    "readingTime": 2,
    "keywords": [
      "premarket trading",
      "pared gains",
      "chips",
      "nvidia's",
      "nvidia",
      "export",
      "access",
      "advanced",
      "technology",
      "limited"
    ],
    "qualityScore": 0.95,
    "link": "https://finance.yahoo.com/news/nvidia-shares-gain-trump-allows-102400561.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/a48a9375c07cbe587069f836d911e1ae",
    "created_at": "2025-12-10T18:55:43.203Z",
    "topic": "finance"
  },
  {
    "slug": "5-vcs-sounds-off-on-the-ai-question-du-jour",
    "title": "5 VCs sounds off on the AI question du jour",
    "description": "Who better to ask about a bubble than a group who will collectively deploy anywhere from tens to hundreds of millions of dollars over the next decade into AI companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/5-vcs-sounds-off-on-the-ai-question-du-jour/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974207764_b60ab330f2_o-e1765327176512.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.273Z",
    "topic": "business"
  },
  {
    "slug": "inside-tractor-maker-cnhs-push-to-bring-more-artificial-inte",
    "title": "Inside tractor maker CNH’s push to bring more artificial intelligence to the farm",
    "description": "CNH CTO Jay Schroeder says using AI to improve farming is a decades-long passion. \"I grew up on a family farm…so for me, it’s personal.”",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/artificial-intelligence-cnh-ai-tractors-farm-equipment/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Jay-Schroeder_CNH_web-HighRes.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.128Z",
    "topic": "tech"
  },
  {
    "slug": "goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growt",
    "title": "Goldman Sachs CFO on the company’s AI reboot, talent, and growth",
    "description": "Goldman’s OneGS 3.0 revamp is underway.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growth/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1770870970-1-e1765368302818.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:16.162Z",
    "topic": "business"
  }
]
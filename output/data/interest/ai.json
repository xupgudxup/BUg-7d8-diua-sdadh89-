[
  {
    "slug": "the-state-of-voice-ai-instruction-following-in-2026",
    "title": "The State of Voice AI Instruction Following in 2026",
    "description": "Coval is the leading simulation and evaluation platform for AI voice and chat agents. Test, monitor, and optimize your AI agents at scale.",
    "fullText": "Why are production voice agents still running on 18-month-old models? Why is instruction following the hardest problem to benchmark? And what's actually missing from voice AI evaluation today? We sat down with two of the sharpest minds in the space to find out.\n\nAs part of our State of Voice AI 2026 research, we brought together Kwindla Hultman Kramer, co-founder of Daily and creator of the open-source PipeCat framework, and Zach Koch, co-founder and CEO of Ultravox AI, which trains real-time speech-native models. The conversation that followed was one of the most candid discussions we've had about what's actually working in voice AI evaluation—and what's still broken.\n\nCheck out the full episode here:\n\nKwin recently published something the voice AI community has desperately needed: a public benchmark for instruction following and function calling in long, multi-turn conversations.\n\n\"I wanted to publish something that people could criticize and try to help make better,\" Kwin explained. \"We all have kind of tests and vibes that we do internally, but I wanted something that reflects the hard workloads in voice AI—instruction following, function calling reliability, turn-taking reliability.\"\n\nThe benchmark simulates a real-world voice AI scenario: knowledge dumped into a system prompt, tools that need to be called, and a 30-turn conversation that tests whether the model can maintain coherent behavior deep into the dialogue.\n\nWhat surprised Kwin most? The frontier models saturated it.\n\n\"GPT-5, the latest Claude, Gemini 3—they all saturated what I thought was a really hard benchmark. But here's the thing: they're all too slow to use for a voice agent.\"\n\nThis is the central tension in voice AI today: the smartest models are too slow, and the fast models aren't smart enough.\n\nHere's a reality check that might surprise people outside the voice AI space: most production voice agents are still running on GPT-4o and Gemini 2.5 Flash—models that are now a year and a half old.\n\n\"Those are the models that have the right mix of intelligence and latency,\" Kwin noted. \"And because people have gotten prompts optimized for them, they're pretty safe choices that a lot of people are sticking with.\"\n\nBut it's not just about capability. Switching models in voice AI is uniquely painful.\n\n\"It's so tricky to switch models,\" I explained during our conversation. \"You have so many models in concert together—you're not just seeing if it performs as expected with your prompts, but how it interacts with all the other models. And the testing is much more expensive. The eval process is often very manual.\"\n\nThis creates a vicious cycle: teams stick with older models because evaluation is hard, which means newer models don't get battle-tested, which means teams stick with older models.\n\nWe spend a lot of time at Coval thinking about what makes voice AI evaluation uniquely difficult. Instruction following is, without question, the hardest piece.\n\nWhy? Because you can't just run the same prompt across different models and call it a fair comparison.\n\n\"Different prompts do well on different systems,\" I explained. \"What people actually want to know is: what's the best I can get out of each system? It's not useful to compare something out of the box if there's an obvious optimization.\"\n\nThis is why benchmarks like Kwin's are so valuable—they help you rough-cut which models to even consider, before you invest in the expensive work of testing on your specific data and use case.\n\nBut there's a deeper problem. Traditional benchmarks test the first few turns of a conversation. Voice AI conversations are fundamentally long, multi-turn interactions—and that data is massively underrepresented in training datasets.\n\n\"I would talk to people at foundation labs and they'd say, 'We fixed function calling,'\" Kwin recalled. \"And function calling on the first three turns would be noticeably better. But function calling 20 turns into the conversation? No better at all.\"\n\nOne of the most honest moments in our conversation came when Zach admitted something many AI practitioners secretly believe:\n\n\"I'm a king of vibes. I haven't figured out any benchmark that I trust fully more than putting in my AirPods and talking to the models for 20 minutes. Nothing is quite as brutal as that test.\"\n\nBut Kwin pushed back—gently—on the idea that vibes are enough:\n\n\"For the purpose of this conversation, I'm going to pretend to disagree. The pain point I see is: I got this prompt right, the 20 people at our company tested it and had a good experience, but then I put it in production and people did weird things and it's not good enough.\"\n\nThis is the gap that quantitative evaluation fills. It's not about capturing the entire space of what makes a conversation feel good. It's about drawing a box around expected behavior so you can tell which models are clearly inside the box and which aren't.\n\n\"If you can draw a box and say this model is clearly in the box, this model is not—that's a useful point of comparison for what it feels like to deploy these things into production with a wide variety of real-world user behavior.\"\n\nWhen I asked Zach what's still not captured in benchmarks, his answer was illuminating:\n\nBack-channeling. Those little \"mm-hmm\" and \"uh-huh\" moments that humans do perfectly and AI does awkwardly—or not at all.\n\n\"Any attempt to back-channel as a system-level thing has failed catastrophically,\" Zach said. \"They're either exactly correct and on the mark, or they're awkward. And we have no evals for this.\"\n\nProsody matching. The way your tone affects my response, and vice versa.\n\n\"If I say something in a particular tone, the interpretation of that tone should change how you respond—not just the words, but your prosody. My anger might induce your anger, or slow you down. We have no mechanisms to measure any of this.\"\n\nThe \"one beat off\" problem. The uncanny valley of voice AI isn't about obviously wrong responses—it's about timing that's slightly off.\n\n\"Capturing what makes it really unnatural—things are out of order, or it's repeating itself, or getting stuck in loops—those we can catch,\" I noted. \"But when it's just one beat off? That's the hardest to get.\"\n\nOne of the most interesting threads in our conversation was about how production voice AI is evolving toward multi-model architectures.\n\n\"We're increasingly living in a world where multiple models and multiple inference loops are really valuable,\" Kwin explained. \"A lot of what we're helping customers deploy now feels like a thinking fast and slow split—a fast voice loop, and then various kinds of async or long-running or parallel inference processes.\"\n\nGuardrails running in parallel (though by the time a guardrail kicks in, you may have already moved past the moment)\n\nTool calling pulled out of the fast loop to avoid latency penalties\n\nLong-running processes that inject back into the voice context\n\nBut this creates new evaluation challenges. As Zach pointed out: \"The evals can mislead me when I look at them, because you get this boost from thinking performance that helps tool calling, but when I have the actual conversation, it feels awkward.\"\n\nThe text-based evaluation might look accurate, but the user experience of two AI brains trying to coordinate can feel disjointed.\n\nOne pattern we're seeing—and warning customers about—is trying to reuse the same agents for chat and voice.\n\n\"This is where people are running into a lot of issues,\" I explained. \"What you want to see in chat looks very different than what you want to hear in a voice system. You're trying to use the same reasoning for two very different systems, and it just doesn't work.\"\n\nThe benchmarks might say your instruction following is great. But when you add all the layers of abstraction to retrofit a chat agent for voice, the real-world performance falls apart.\n\nWe ended the conversation with what might be the most important takeaway for anyone building with voice AI:\n\nShare your problems with your vendors.\n\n\"Everyone is trying to figure it out right now,\" I said. \"Hearing from users about what's working and what's not is the biggest signal above all else. We learn so much from our customers.\"\n\nZach agreed: \"We'd give ourselves a high five on some model performance eval, and then I'd throw it to a customer and they'd be like: garbage, garbage, garbage. There's a gap in our methodology—and we made a lot of mistakes in 2025 training without keeping that applied reality in mind.\"\n\nThe voice AI space is moving fast, but it's still early. The benchmarks are getting better. The models are getting better. But the feedback loop between real production pain and model improvement is still the most valuable signal any of us have.\n\nFrontier models saturate hard benchmarks but are too slow for production. The intelligence-latency trade-off is the defining constraint of voice AI in 2026.\n\nMost production systems still run 18-month-old models because switching is expensive and evaluation is hard.\n\nInstruction following is the hardest problem to benchmark because different prompting techniques work for different models, and voice conversations are long multi-turn interactions that training data doesn't represent well.\n\nWhat's missing from benchmarks: back-channeling, prosody matching, and the subtle timing issues that make conversations feel \"one beat off.\"\n\nMulti-model \"thinking fast and slow\" architectures are emerging, but they create new evaluation challenges around coordination and user experience.\n\nDon't reuse chat agents for voice. The systems require fundamentally different reasoning and evaluation approaches.\n\nShare your production problems. The feedback loop between real-world deployment and model improvement is the most valuable signal in the industry.\n\nWant to see how your voice agent performs on instruction following? Learn how Coval's simulation and evaluation platform helps teams test before production → Coval.dev\n\nBrooke Hopkins is the founder of Coval, building simulation and evaluation for voice agents. Her background is from Waymo, where she led the evaluation infrastructure team responsible for all simulation tooling.\n\nKwindla Hultman Kramer is co-founder of Daily, which makes global infrastructure for real-time audio, video, and AI. Pipecat is part of Daily - the most widely used open-source framework for building voice and real-time multimodal AI agents.\n\nZach Koch is co-founder and CEO of Ultravox AI, which trains real-time speech-native models and runs dedicated inference to achieve increasingly human-like conversations with AI.",
    "readingTime": 9,
    "keywords": [
      "kwindla hultman",
      "hultman kramer",
      "teams stick",
      "prosody matching",
      "trains real-time",
      "real-time speech-native",
      "feedback loop",
      "user experience",
      "garbage garbage",
      "valuable signal"
    ],
    "qualityScore": 1,
    "link": "https://www.coval.dev/blog/the-state-of-voice-ai-instruction-following-in-2026-a-conversation-with-kwindla-from-pipecat-and-zach-from-ultravox",
    "thumbnail_url": "https://framerusercontent.com/assets/XKz3mwCB1do7n4eYEEPAsdSjAIY.png",
    "created_at": "2026-01-29T18:30:47.818Z",
    "topic": "tech"
  },
  {
    "slug": "googles-ai-helped-me-make-bad-nintendo-knockoffs",
    "title": "Google's AI helped me make bad Nintendo knockoffs",
    "description": "Here we go.",
    "fullText": "It’s what I had the most fun using Google’s Project Genie for, at least right now.\n\nIt’s what I had the most fun using Google’s Project Genie for, at least right now.\n\nThis week, a new generative AI tool from Google let me create bad knockoffs of 3D Nintendo worlds.\n\nCheck out my version of something like Super Mario 64:\n\nI didn’t like Metroid Prime 4: Beyond, but it’s better than my version of a Metroid Prime experience:\n\nOr how about my take on The Legend of Zelda: Breath of the Wild, complete with a paraglider (and, briefly, a second Link):\n\nIt was all possible thanks to Project Genie, an experimental research prototype that Google gave me access to this week, though I don’t think I’m using it in exactly the way Google intended.\n\nGoogle DeepMind has been putting a lot of effort into building its AI “world” models that can generate virtual interactive spaces with text or images as prompts. The company announced its impressive-looking Genie 3 model last year, but it was only available as “a limited research preview” at the time. Project Genie, which will be rolling out to Google AI Ultra subscribers in the US starting today, will be the first opportunity for more people to actually try out what Genie 3 is capable of.\n\nGoogle is releasing Project Genie now partly because it wants to see how people use it. “It’s really for us to actually learn about new use cases that we hadn’t thought about,” Diego Rivas, a product manager at Google DeepMind, tells The Verge. The company is already excited about how Genie could help to visualize scenes for filmmaking or for interactive educational media. You could, if you wanted, take a photo of your kids’ favorite toy and use it to prompt a Genie-generated world. Genie could potentially help robots navigate the real world, too. But Project Genie isn’t yet an “end-to-end product that we expect people to just use every day,” stressed Shlomi Fruchter, a Google DeepMind research director.\n\nWith Project Genie, you pick from a bunch of worlds designed by Google or define prompts for the environments and characters you want to create in your own world. After a brief wait, Genie first generates a thumbnail, then you can have it generate the world. You can explore each generated world for 60 seconds, and each has a resolution of about 720p and a frame rate of about 24fps. While you’re in one, you can (typically) move your character with the WASD keys, jump or go higher with a tap of your space bar, and turn the camera with arrow keys.\n\nOne of Google’s worlds, called “Rollerball,” features a blue orb in a white, snowy world, and as you roll around, the orb leaves a trail of paint behind it. As a “game,” Project Genie wasn’t great. There was nothing to do but roll around; there weren’t any objectives or goals. There was no sound. There was frustrating input lag that was even worse than what I sometimes experience with cloud gaming. (Some of this could be due to the generally poor Wi-Fi I get in my office.)\n\nOver the course of the 60-second experience, Genie sometimes forgot to show a paint streak where I had previously rolled. Occasionally, the ball would randomly stop laying down paint at all. So I started to distrust Genie’s ability to recall what I had already seen with my own eyes.\n\nAnother Google-designed world, “Backyard Racetrack,” was a little more fun because there was an actual track to follow. My racing lines were awful — the input lag didn’t help — but I enjoyed trying to make the turns and stay on the road. Near the end of the experience, though, part of the track unexpectedly turned into grass, which ruined the immersion. And the wheel rims looked really janky.\n\nI had a lot more fun pushing the limits of Project Genie to try and make 3D, AI-generated games featuring recognizable characters, like with my Super Mario, Metroid Prime, and The Legend of Zelda-themed worlds. While they made me laugh, the worlds don’t have scores or anything to strive for, so there’s nothing to do but walk or jump around. Even if there were specific things to do, the input lag made the worlds basically unplayable. (Again, this may be a Wi-Fi issue, but even when I was closer to my router, I still experienced lag.)\n\nI wasn’t able to make everything I wanted. Project Genie wouldn’t generate a world that I prompted with the scenario of Kingdom Hearts — here was my prompt, if you’re curious:\n\nIt’s a world filled with Disney characters with a steampunk vibe. Donald and Goofy are your sidekicks. Jack Skellington is present, as is Cloud Strife.\n\nYou are a spunky, anime teenager with spiky brown hair wielding a blade that is like a key.\n\nWhen I removed the specific names of characters and wrote descriptions of them instead, Project Genie generated a thumbnail preview of the world featuring characters that were dead ringers for Sora (the series’ protagonist), Donald, Goofy, Jack Skellington, and Cloud. But when I tried to generate the actual experience, Project Genie blocked me.\n\nI asked about why I was able to generate worlds with Nintendo characters. “Project Genie is an experimental research prototype designed to follow prompts a user provides,” Rivas says. “As with all experiments, we are monitoring closely and listening to user feedback.” Rivas also notes that the Genie 3 model was “trained primarily on publicly available data from the web.” (This probably partially explains why Link deployed his paraglider in my test, which surprised me. At a high level, the Genie model is constantly trying to predict the next frame, and I’m sure there are many videos of people jumping in Breath of the Wild and then gliding forward, which the model probably learned from.) Shortly before publishing this article, Project Genie stopped letting me generate worlds based on Super Mario 64 due to “interests of third-party content providers.”\n\nAssuming Google clamps down on the ability to generate interactive worlds based on known gaming franchises — I can’t imagine Nintendo will be happy with what I was able to generate! — Project Genie otherwise isn’t that great at the moment. The input lag and 60-second limit make them pretty poor interactive experiences. Occasionally, I couldn’t control my character at all, only the camera. After the weirdness with the paint stripes and the road turning into grass, I had a general feeling that I couldn’t trust the worlds to stay consistent from moment to moment.\n\nProject Genie is better than some AI-generated worlds I tried last year, but it’s still much worse than an actual handcrafted video game or interactive experience. Fruchter described a potential future where the line blurs between different kinds of media thanks to technology like Genie, but I think it has a long way to go to get there.\n\nPerhaps my standards are too high. Project Genie is an experimental research prototype, after all. And maybe I’ll feel differently after the technology improves down the line. But I can’t imagine that people will want to spend an extended period of time jumping into these types of AI-generated worlds anytime soon. With world models, I don’t think we have to worry about the genie being out of the bottle just yet.",
    "readingTime": 7,
    "keywords": [
      "project genie",
      "can’t imagine",
      "ai-generated worlds",
      "google’s project",
      "experimental research",
      "research prototype",
      "input lag",
      "genie model",
      "worlds based",
      "generate worlds"
    ],
    "qualityScore": 1,
    "link": "https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on",
    "thumbnail_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/ai-label-2.png?quality=90&strip=all&crop=0%2C10.705884903472%2C100%2C78.588230193056&w=1200",
    "created_at": "2026-01-29T18:30:47.796Z",
    "topic": "tech"
  },
  {
    "slug": "acp-agent-registry-in-jetbrains-ides",
    "title": "ACP Agent Registry in JetBrains IDEs",
    "description": "Together with Zed, we've launched the official ACP Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs.",
    "fullText": "Supercharge your tools with AI-powered features inside many JetBrains products\n\nAI coding agents are multiplying fast. Some of the most common ones include Gemini CLI, Claude Code, Auggie, OpenCode, and Copilot, and more are being released every day. Each comes with its own unique strengths, specific setups, and varying levels of editor support. Keeping track of what’s out there, let alone getting it running in your IDE, hasn’t been easy.\n\nTogether with Zed (Zed’s announcement), we’ve launched the official ACP Agent Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs and Zed. Browse what’s available, click Install, and start working right away. This beta release is just the beginning.\n\nThe Agent Client Protocol is an open standard that lets any AI coding agent work in any supporting editor. Think of it like the Language Server Protocol, but for AI agents. The LSP lets any editor support any language through a shared standard. The ACP does the same for coding agents. You only need to implement it once, and then it will work in your JetBrains IDE, Zed, or any other editor that supports the protocol.\n\nThis means you get to pick your preferred agent and editor, and they will then work together seamlessly – no vendor lock-in and no waiting for someone to build a specific integration.\n\nACP has been, since we started integrating it to Mistral Vibe, a real joy to use: thoughtfully designed from the ground up, community-driven, and evolving rapidly. We’ve found it not only simplifies integration, but also fits our focus on open and flexible tools. It’s really great to see a standard that puts developer choice first.\n\nMichel Thomazo, Software Engineer @ Mistral AI\n\nThe ACP made agent interoperability technically possible. The registry makes it convenient.\n\nInstead of manually configuring agents, you can now:\n\nAt launch, you’ll find a wide array of different agents:\n\nFull-featured coding assistant optimized for large-scale refactors\n\nSpecialized agent for automated code generation workflows\n\nGoogle’s agent with deep codebase understanding and multimodal capabilities\n\nGitHub’s AI pair programmer, now available via the ACP\n\nLightweight, fast agent built on Mistral’s models\n\nCommunity-driven, fully open-source agent\n\nAlibaba’s coding agent with strong multilingual support\n\nInnovation in software agents is moving at an unbelievable pace. The Agent Registry and ACP makes it simple for developers to use the best agents in their favorite tools.\n\nChris Kelly, Product @ Augment Code\n\nIn general, it’s less about having multiple agents than about enabling you to pick and choose the ones that work well in your workflow. Different agents come with different benefits. Some provide a more attractive pricing structure for your business, some provide a user experience that you simply enjoy more than others’, and some embody the ideas of open-source development that just resonate with you.\n\nThe Agent Client Protocol registry lets you experiment freely. Try a few, see what clicks for your workflow, and then keep the ones that help. You’re not locked into a single vendor’s vision of what AI-assisted development should look like.\n\nWe’re excited to support the ACP Agent Registry as a step toward a more open agent ecosystem where Droids can integrate seamlessly across all IDEs.\n\nFrancesca LaBianca, VP of Operations @ Factory\n\nIn any JetBrains IDE (2025.3.2+) with JetBrains AI (253.30387.147):\n\nThat’s it. The agent is configured and ready to use in the AI Chat tool window.\n\nQuick note: agents typically come with their own subscription. That’s between you and them. You won’t need a JetBrains AI subscription to use ACP agents.\n\nWant to try something concrete? Install OpenCode, open a project, and ask it to explain an unfamiliar module. OpenCode also lets you swap between different LLMs, so you can experiment with what works best for you.\n\nIf you prefer manual configuration, that option is still there, too. Just edit the acp.json directly. This is useful for agents that aren’t in the registry yet or for custom setups.\n\nIf you’re building an ACP-compatible agent, the registry is now the fastest way to reach developers across JetBrains IDEs and Zed.\n\nHead to the ACP Registry repository and check out the CONTRIBUTING.md for the full submission process and metadata requirements. Please note that, for now, we are only featuring agents that support Agent Auth or Terminal Auth. Full details of requirements and conditions can be found here.\n\nThis is an open registry. If you’re building an ACP-compatible agent, you’re welcome to submit it. The registry exists to serve the ecosystem, not to gatekeep it.\n\nFor developers: More choice and zero lock-in. Use any agent you want in the IDE you love.\n\nFor agent builders: Instant distribution to millions of JetBrains and Zed users. Implement the ACP once and reach everyone.\n\nFor the ecosystem: Competition on quality, not on who controls the integration. The best agents win because they’re the best, not because they have exclusive deals.\n\nWe’re building this openly with Zed because we believe AI-assisted development shouldn’t be locked inside any single vendor’s ecosystem. Developers deserve to pick their tools freely.\n\nThe registry is one more step toward that future.\n\nThe ACP Registry is available now in JetBrains IDE versions 2025.3 and later. Update your IDE and the JetBrains AI plugin, open Settings, and start exploring.\n\nHave feedback? Found a bug? The registry repo is open for issues and PRs. And if you’re building something interesting with ACP, we’d love to hear about it!\n\nOpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE. \n\nYou can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key – all within the same AI сhat inte…\n\nThe next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers.\n\nYes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions…\n\nBring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains’ Junie and Claude Agent. Whether you’re looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research prev…\n\nJunie is now integrated into the AI chat. The separate interfaces have merged into a single, unified space (available in Beta).",
    "readingTime": 6,
    "keywords": [
      "client protocol",
      "ai-assisted development",
      "step toward",
      "agent client",
      "acp-compatible agent",
      "jetbrains ai",
      "coding agents",
      "acp agent",
      "acp agent registry",
      "jetbrains ide"
    ],
    "qualityScore": 1,
    "link": "https://blog.jetbrains.com/ai/2026/01/acp-agent-registry/",
    "thumbnail_url": "https://blog.jetbrains.com/wp-content/uploads/2026/01/JB-social-BlogSocialShare-1280x720-1-4.png",
    "created_at": "2026-01-29T18:30:47.768Z",
    "topic": "tech"
  },
  {
    "slug": "mito-ai-raised-45-million-to-launch-projectmanagement-software-for-filmmakers-read-its-pitch-deck",
    "title": "MITO AI raised $4.5 million to launch project-management software for filmmakers. Read its pitch deck.",
    "description": "Read the pitch deck that MITO AI, a new AI workflow platform for filmmakers, used to raise $4.5 million in funding.",
    "fullText": "Artificial intelligence is shaking up video production.\n\nThe startup MITO AI is rolling out a new platform to help filmmakers storyboard, organize, and generate AI assets in one place. It's a project management tool for the era of generative AI filmmaking.\n\nThe company exclusively told Business Insider that it had raised $4.5 million in a pre-seed round led by Lightspeed Venture Partners. It's launching its product on Thursday after testing with about 200 beta partners.\n\n\"Our tools are connected to video models, image models, audio models, and voice models, and then everything is brought together into our infinite canvas for collaboration and experimentation,\" MITO cofounder Iñaki Berenguer said.\n\nWhile many AI video generators, such as OpenAI's Sora or Google's Veo, are limited to short-form clips, MITO wants to help creators piece together short AI assets into a longer project. It also offers collaborative features, such as commenting. MITO users can create new AI assets that align with their film's style via integrations with platforms including Runway, Veo 3, ComfyUI, and Pika.\n\nBeyond its workflow platform, the startup also makes AI content for partners via its studio team.\n\nMITO arrives at a moment of flux in the media industry. Hollywood and advertising executives are testing AI tools for digital effects and commercials. Independent creators are using the tech to spruce up their videos without breaking the bank. Actors, animators, and other creatives, meanwhile, are raising eyebrows at the technology that some fear could wipe out jobs.\n\nMITO is also entering a crowded category dominated by incumbents like Adobe and containing other new upstarts like FLORA, which recently raised a $42 million funding round led by Redpoint Ventures.\n\nRead the pitch deck MITO used to raise its $4.5 million pre-seed round, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt's a platform for \"multiplayer video creation.\"\n\nThe company highlighted two films it created end-to-end, \"Golf Le Fleur Maritime\" and a \"Lagaam campaign.\"\n\nArantxa Barcia, chief creative officer\n\nDanny Saltaren, chief product officer\n\n-Genially (collaborative canvas, $20M ARR), Inditex, Unusuals.\n\nTHE PROBLEM TODAY: AI video workflows are fragmented, slow, painful to iterate, and impossible to collaborate on.\n\n50 cent - 21 Questions and Willy Chavarria - Campaign.\n\nWe have delivered multiple real brand campaigns and music videos using our platform. MITO's tools meet professional quality standards and solve real brand pain points. Why create a studio? To eat our own dog food, generate revenue, and market what's possible.\n\nMITO Orchestration and Collaboration Tools:\n\nStoryboard as the skeleton of a full AI video production. Manually crafted, AI-assisted, or fully generated by our AI agents.\n\nAI Editor for individual text, images, videos, audios.\n\nInfinite canvas. Infinite creation.\n\nA non‑linear visual collaboration space — an evolved moodboard —for exploring and iterating ideas across images, video, audio, text, and styles; freely, in parallel, grouping and recombining, without breaking flow.\n\nMITO UNIVERSE — COMMUNITY OF CREATORS & MARKETPLACE\n\nA creator community and marketplace where artists and producers get a vanity URL to share AI-generated video assets, workflows and portfolios.\n\nMITO offers three pricing tiers: A free tier, a $16 monthly \"pro\" tier, and a $38 monthly \"studio\" tier.\n\nUsers are charged additional costs in the form of \"credits\" based on how often they generate AI content.\n\nWhat private beta users are saying:\n\n\"Huge congratulations! The progress over the last few months is dramatic. MITO makes complex audiovisual creation feel effortless, with real controls over camera, lenses, framing, lighting, and color. The built-in video editor is a game-changer. I haven't seen another AI suite this complete or this clearly designed for real audiovisual creators.\"\n\n\"Creativity is entering a phase of explosive diversification, and along with it, the quality of art and entertainment can drastically increase. Even in the very early days of playing with MITO, it's been striking how open the playing field suddenly feels.\"\n\nDespite the emergence of powerful models, no dominant platform yet ties everything together.\n\nAI models like Veo, Kling, and Runway open new frontiers.\n\nTeam workflows remain fragmented — the orchestration layer is missing.\n\nStorytellers, filmmakers, brands, and companies can now produce high‑quality video without the high cost and long process of traditional production. The result is faster iteration, more experimentation, and many more creative versions.\n\ne.g. brands needing 30 sec-5 min videos\n\nToday 80k brands spending at least $100k per year on video\n\nThe video creation boom is coming. If cost per video is lower: 10x more brands, 10x more content per brand, at a lower cost\n\nProfessional video creation is about to explode — for brands, movie studios, social media, agencies, creators and new forms of entertainment.\n\n\"New powerful AI video models are transforming massive existing categories and unlocking new ones,\" the company says.\n\nUnleashing video creativity & myth-making in the age of AI.",
    "readingTime": 4,
    "keywords": [
      "infinite canvas",
      "pre-seed round",
      "round led",
      "models",
      "platform",
      "creators",
      "creation",
      "brands",
      "assets",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mito-ai-raised-5-million-round-read-its-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/697a7d81e1ba468a96aae72a?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.968Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-a-planetsized-bubble-and-microsofts-slump-is-a-taste-of-the-crash-to-come-tech-guru-erik-gordon-says",
    "title": "AI is a planet-sized bubble — and Microsoft's slump is a taste of the crash to come, tech guru Erik Gordon says",
    "description": "Professor Erik Gordon said the \"AI bubble is almost as big as the planet Jupiter,\" and Microsoft's stock drop is a \"warning of the burst to come.\"",
    "fullText": "Rampant speculation and massive overinvestment in AI have created a financial threat of cosmic proportions — and the fallout will be catastrophic, Erik Gordon has warned.\n\n\"The AI bubble is almost as big as the planet Jupiter,\" Gordon, an entrepreneurship professor at the University of Michigan's Ross School of Business, said in a Wednesday email to Business Insider.\n\n\"When it bursts, the debris will be everywhere,\" he continued. \"Big, institutional investors will be hit with it, and so will individual investors who bet the bubble would get even bigger.\"\n\nGordon pointed to Microsoft stock, which tumbled more than 6% after the software giant's earnings beat on Wednesday. It was trading around 12% lower at 12:30 p.m. ET on Thursday, marking one of the sharpest intraday declines in the company's history.\n\nMicrosoft's shares sank \"because of the truckloads of cash it is investing in AI,\" Gordon said. \"That is a warning of the burst to come.\"\n\nThe cloud-computing titan's net cash used in investing surged 95% year-on-year to over $57 billion in the six months to December. That was fueled by its addition of $49 billion worth of property and equipment such as data centers.\n\nPrior to their post-earnings slump, Microsoft's shares had roughly doubled since the start of 2023, lifting the company's market value to over $3.5 trillion.\n\nOther AI stocks have surged even faster over that timeframe. Shares of chipmaker Nvidia have vaulted 13-fold, valuing the company at close to $4.7 trillion — more than 20 times its projected revenue for the fiscal year ended January 25.\n\nPalantir stock has jumped about 25-fold, giving the data-analysis company a $375 billion market value, or around 85 times its forecasted revenue for 2025.\n\nGordon told Business Insider in an email last week that he doesn't expect the AI bubble to burst in the next few months, as investors still have enough cash to \"prop it up,\" and technological advances remain \"exciting enough to distract\" from irrational valuations.\n\nThe veteran professor has previously rung the alarm on an \"order-of-magnitude overvaluation bubble,\" and warned that when it pops, the \"suffering will be more painful\" for investors than the aftermath of the dot-com bubble. But stocks have largely defied his warnings and continued to march higher.",
    "readingTime": 2,
    "keywords": [
      "microsoft's shares",
      "bubble",
      "investors",
      "cash",
      "warned",
      "professor",
      "email",
      "stock",
      "company's",
      "investing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bubble-microsoft-stock-market-crash-erik-gordon-tech-investing-2026-1",
    "thumbnail_url": "https://i.insider.com/697b4d16a645d11881883730?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.815Z",
    "topic": "finance"
  },
  {
    "slug": "investors-are-giving-meta-the-green-light-to-keep-spending-big-on-ai",
    "title": "Investors are giving Meta the green light to keep spending big on AI",
    "description": "Meta stock surged on Thursday as Q4 earnings beat estimates and investors welcomed more big AI spending plans from the Facebook parent.",
    "fullText": "The move: Meta Platforms stock jumped 9% on Thursday after earnings, erasing losses from the previous week. The stock is up 10% year-to-date.\n\nWhy: Meta reported Q4 2025 earnings on Wednesday after close, coming in above Wall Street estimates on both top and bottom line metrics. It posted revenue of $59.9 billion, versus the forecasted $58.4 billion, and earnings per share of $8.88, versus the $8.16 consensus.\n\nImportantly, the social media giant also revealed that it plans to spend $115 billion to $135 billion on AI in the coming year, a substantial increase from the $72.22 billion it spent on AI in 2025 and well above Wall Street's expectations for 2026.\n\nDespite balking at its big spending plans announced in its last quarterly earnings, Wall Street reacted favorably to the news.\n\nThe key difference this time around seems to be that the company's quarterly advertising revenue came in well above expectations. CFO Susan Li fueled confidence in Meta's growth plans when she said on the earnings call that the company's AI endeavors would be financed with cash rather than debt, likely generated by its advertising success.\n\nWhat it means: The earnings were a key update on the AI race, showing that the company is successfully generating cash from other areas to fund its AI ambitions. It's the kind of strength investors want to see after last year ended with Wall Street growing anxious about soaring capex among hyperscalers.\n\n\"Ongoing investments across the business, including the infusion of AI capabilities across the company's ad stack and content recommendation engines, are already driving tangible benefits for the core advertising segment,\" stated Dan Ives of Wedbush Securities.",
    "readingTime": 2,
    "keywords": [
      "wall street",
      "earnings",
      "plans",
      "company's",
      "advertising",
      "stock",
      "revenue",
      "versus",
      "expectations",
      "quarterly"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-stock-price-q4-earnings-wall-street-advertising-ai-plans-2026-1",
    "thumbnail_url": "https://i.insider.com/697b6a37a645d118818838ff?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.462Z",
    "topic": "finance"
  },
  {
    "slug": "apple-earnings-live-updates-ai-strategy-under-the-microscope-as-wall-street-readies-for-q1-results",
    "title": "Apple earnings live updates: AI strategy under the microscope as Wall Street readies for Q1 results",
    "description": "Apple will report earnings for its fiscal Q1 on Thursday after the closing bell, and its call with analysts is scheduled for 5 p.m. ET.",
    "fullText": "Apple is the next mega-cap tech titan to report earnings after the closing bell on Thursday, and Wall Street is looking for answers on the company's AI roadmap.\n\nThe iPhone maker's fiscal first-quarter results will be a key update amid investor concerns that it has fallen behind in the AI race. Its partnership with Gemini, announced earlier this month, launched Alphabet stock to a $4 trillion market cap, but the impact on Apple shares has been muted. iPhone and other hardware sales will also be a key focus after Tim Cook said in the previous earnings call that its Q1 would be the best ever quarter for revenue.\n\nApple heads into the earnings call with shares down about 7% year to date. The results will be published shortly after the closing bell, and the analyst call will kick off around 5 p.m. ET.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"\n\nUBS analysts said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impacting cost and margins,\" UBS wrote in a January 20 note.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, as they have for other firms that have touted involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.",
    "readingTime": 5,
    "keywords": [
      "wide developers",
      "developers conference",
      "january note",
      "much-anticipated siri",
      "stanley analyst",
      "analyst erik",
      "analyst michael",
      "analyst dan",
      "back siri",
      "siri refresh"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-live-updates-ai-gemini-iphone-sales-2026-1",
    "thumbnail_url": "https://i.insider.com/69792277d3c7faef0ecd063e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.212Z",
    "topic": "finance"
  },
  {
    "slug": "microsofts-earnings-bust-drags-software-stocks-into-a-bear-market-and-tanks-major-indexes",
    "title": "Microsoft's earnings bust drags software stocks into a bear market and tanks major indexes",
    "description": "Shares of Microsoft plunged 12% and software stocks hit a bear market. The S&P 500 edged back from 7,000 as AI spending fears were rekindled.",
    "fullText": "Tech stocks were taking it on the chin on Thursday, with the impact particularly severe for software shares amid Microsoft's post-earnings plunge.\n\nThe software sector slipped into bear market territory as Microsoft renewed fears that the market's largest tech firms may be spending too much, too fast on AI without seeing adequate growth in other parts of the business to offset.\n\nWhile Meta was rewarded after earnings, as robust capex guidance was overshadowed by advertising strength, investors punished Microsoft.\n\nShares of the software giant dropped 12%. The firm said it spent a record amount on AI, but reported slowing cloud growth and issued soft guidance on profits for the following quarter, leading tech stocks to sell off across the board.\n\nThe iShares Expanded Tech-Software Sector ETF is down 21% from its high in October.\n\nHere were the notable moves in the tech sector:\n\n\"Microsoft (MSFT) was the black sheep with losses,\" Joee Mazzola, the head trading and derivatives strategist at Charles Schwab, wrote on Thursday, referring to more upbeat results from Magnificent Seven peers Tesla and Meta.\n\nMajor indexes were dragged lower. The S&P 500 dropped more than 1%, retreating further from the 7,000 mark, which it briefly topped for the first time on Wednesday, while the Nasdaq Composite dropped 2%.\n\nHere's where US indexes stood around 11:45 a.m. ET on Thursday:\n\nInvestors have been particularly sensitive to signs that demand for AI may not be as robust as markets originally anticipated. Capex spending among tech giants has been a particular worry, given the uncertainty over monetization plans and when the market will see returns from AI spend.\n\nMicrosoft's earnings likely \"reinforced fears that a return on AI investment may be slow in coming,\" David Morrison, a senior market analyst at Trade Nation, wrote in a note Thursday morning.\n\nThe company likely needs to \"prove\" that it's making good investments into its AI endeavours, analysts at UBS wrote earlier this week.\n\n\"Microsoft has elected to increase the allocation of new GPU compute to its 1P efforts, effectively throttling Azure growth, because of its confidence in monetizing Copilot,\" the bank said. \"The challenge for the stock is that many investors don't buy into that trade-off.\"",
    "readingTime": 2,
    "keywords": [
      "tech stocks",
      "market",
      "growth",
      "dropped",
      "particularly",
      "microsoft's",
      "fears",
      "earnings",
      "robust",
      "capex"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/stock-market-today-tech-selloff-microsoft-earnings-capex-sp500-nasdaq-2026-1",
    "thumbnail_url": "https://i.insider.com/697b865fa645d11881883c8e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.206Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-laying-off-workers-because-of-ais-potentialnot-its-performance",
    "title": "Companies Are Laying Off Workers Because of AI’s Potential—Not Its Performance",
    "description": "AI has been cited as a cause of layoffs, but is it actually displacing jobs? And if not, what’s going on? Based on a survey of 1,006 global executives in December 2025, AI is behind at least some layoffs, but that these are almost completely in anticipation of AI’s impact. In other words, the job losses and slowed hiring are real, even though companies are still waiting for generative AI to deliver on its promises. This strategy of focusing on short-term gains based on long-term hopes has costs.",
    "fullText": "Companies Are Laying Off Workers Because of AI’s Potential—Not Its Performance by Thomas H. Davenport and Laks SrinivasanJanuary 29, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWill AI lead to layoffs? Are people already losing their jobs to AI? While overall employment in the U.S. is still relatively low, there is considerable speculation that the adoption of generative AI was a cause of recent layoffs and slowed hiring, particularly in the tech industry, for entry-level workers, and in customer service and programming jobs. More may be coming: Leading CEOs—including those from Ford, Amazon, Salesforce, and JP Morgan Chase—have proclaimed that many white-collar jobs at their companies will soon disappear.",
    "readingTime": 1,
    "keywords": [
      "jobs",
      "workers",
      "layoffs"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/companies-are-laying-off-workers-because-of-ais-potential-not-its-performance",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_Mid.jpg",
    "created_at": "2026-01-29T18:30:44.629Z",
    "topic": "business"
  },
  {
    "slug": "ai-and-humane-leadership-a-davos-discussion",
    "title": "AI and Humane Leadership: A Davos Discussion",
    "description": "In this HBR Executive panel discussion at Davos, cohosted by our partner Egon Zehnder, a group of CEOs and board members explore how AI can coexist with human-centered leadership—strengthening trust, empathy, judgment, and innovation amid accelerating technological change.",
    "fullText": "AI and Humane Leadership: A Davos DiscussionHow should AI and human leadership evolve together in this moment of rapid transformation? by HBR EditorsJanuary 29, 2026Summary.   Leer en españolLer em portuguêsPostPostShareSavePrinttogether in this moment of rapid transformation? At Davos, HBR Executive and our partner Egon Zehnder convened a select group of global chief executives to discuss this very question.",
    "readingTime": 1,
    "keywords": [
      "rapid transformation",
      "leadership",
      "moment",
      "davos"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/ai-and-humane-leadership-a-davos-discussion",
    "thumbnail_url": "/resources/images/article_assets/2016/09/whiteout.png",
    "created_at": "2026-01-29T18:30:44.619Z",
    "topic": "business"
  },
  {
    "slug": "boston-dynamics-new-atlas-robot-makes-public-debut-with-jaunty-human-walk",
    "title": "Boston Dynamics' New Atlas Robot Makes Public Debut with Jaunty Human Walk",
    "description": "Hyundai-owned Boston Dynamics is also partnering with former owner Google's DeepMind on AI, in a full-circle moment for the two companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cnet.com/tech/computing/boston-dynamics-new-atlas-robot-make-public-debut-with-jaunty-human-walk/",
    "thumbnail_url": "https://www.cnet.com/a/img/resize/13579e8bed396530cf6c17a54226646a18b3f62e/hub/2026/01/07/ca21282f-6c31-406c-8959-fb96e1b98eae/img-3966.jpg?auto=webp&fit=crop&height=675&width=1200",
    "created_at": "2026-01-29T12:32:33.724Z",
    "topic": "tech"
  },
  {
    "slug": "microsofts-ai-spend-is-starting-to-spook-investors",
    "title": "Microsoft's AI Spend Is Starting to Spook Investors",
    "description": "Microsoft showed record spending but slowing cloud growth and a big reliance on OpenAI",
    "fullText": "In its second-quarter earnings report on Wednesday, tech giant Microsoft reported $37.5 billion in capital expenditures, exceeding market estimates by more than a billion. The spending was up 66% from a year earlier, and roughly two-thirds of it was primarily spent on GPUs and CPUs, Microsoft executives said in an investor call.\n\nA few months ago, a report like this would have sent (and did send) Microsoft stock soaring. But on Wednesday, it had the opposite effect, and the stock went down 7%.\n\nAs worries over an AI bubble simmer, the market is more desperate than ever to see tangible revenue returns that can reignite belief in the great financial promises of the technology, rather than just another huge spending commitment.\n\nBut accompanying Microsoft’s record spending was slowing cloud growth.\n\nRevenue from Microsoft’s cloud services grew by 39% this quarter, down from 40% growth in the first quarter. During the investor call, Microsoft CFO Amy Hood attributed this discrepancy between capital expenditure and cloud growth at least partially to Microsoft allocating GPUs and cloud capacity to internal teams as well. Customer demand for cloud is still outpacing supply, Hood said.\n\nBut even if the slowing cloud growth can be explained away, what also got investors anxious was Microsoft’s reliance on AI giant OpenAI. 45% of Microsoft’s remaining cloud commitments are solely from OpenAI.\n\nAlthough OpenAI used to be the silver bullet for finance, growing uncertainty over the startup’s road to profitability and the risks associated with its ability to pay for towering, ambitious dealmaking has made some start to view any dependence on the AI darling as a potential burden.\n\nOpenAI has signed trillions of dollars worth of deals this past year, despite its $20 billion annualized revenue. Lately, the market has started questioning these overcommitments, as concerns over a potential AI bubble mount.\n\nIf it continues to take too long for AI investments to start translating to actual gains or if somehow it turns out OpenAI cannot pay for its piling commitments, it could lead to a sharp market correction and spell trouble for the U.S. economy, which it seems is currently held up by AI investment.",
    "readingTime": 2,
    "keywords": [
      "slowing cloud",
      "cloud growth",
      "market",
      "revenue",
      "giant",
      "capital",
      "investor",
      "stock",
      "bubble",
      "quarter"
    ],
    "qualityScore": 0.9,
    "link": "https://gizmodo.com/microsofts-ai-spend-is-starting-to-spook-investors-2000715208",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2026/01/shutterstock_2163957793-1200x675.jpg",
    "created_at": "2026-01-29T12:32:32.544Z",
    "topic": "tech"
  },
  {
    "slug": "longcatflashlite-100b-a3b-technical-report-pdf",
    "title": "LongCat-Flash-Lite 100B A3B Technical Report [pdf]",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "LongCat0830\n\n Upload 2 files\n 5ce2ddd\n verified\n about 20 hours ago\n\n download\n\n Copy download link\n history\n\n blame\n\n contribute\n\n delete\n\n 737 kB\n\n Large File Pointer Details\n (\n Raw pointer file\n\n )\n SHA256:\n 5c6963d484586b90e32960c2a7eef93c60ef6b328179972bc6702714f09e4784\n Pointer size:\n 131 Bytes\n\n ·\n\n Size of remote file:\n 737 kB\n\n ·\n Xet hash:\n 7d93b02590ef60d7e97bfd90cdc8b914857c1d7c3252ca7b9abc08301e02e2e8\n Xet efficiently stores Large Files inside Git, intelligently splitting files into unique chunks and\n accelerating uploads and downloads.\n More info.",
    "readingTime": 1,
    "keywords": [
      "pointer",
      "download",
      "files",
      "file",
      "size"
    ],
    "qualityScore": 0.35,
    "link": "https://huggingface.co/meituan-longcat/LongCat-Flash-Lite/blob/main/tech_report.pdf",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/meituan-longcat/LongCat-Flash-Lite.png",
    "created_at": "2026-01-29T12:32:32.273Z",
    "topic": "tech"
  },
  {
    "slug": "google-warns-against-breaking-search-as-pressure-mounts-over-web-future",
    "title": "Google warns against 'breaking Search,' as pressure mounts over web future",
    "description": "Google said it will let websites opt out of generative AI features in Search. Cloudflare's CEO says that's just a start.",
    "fullText": "Google said its Search engine could break if the company is forced to implement strict new controls to protect and nurture web content in the AI era.\n\nThe warning came after UK antitrust regulators proposed new rules for Google Search that would give publishers more control over how their content is used in AI features such as Google's AI Overviews and AI Mode.\n\nIn response, Google said it is working on new ways to give websites more control over how AI chatbots and AI-powered answer engines access and use online content. The company faces mounting pressure to give content owners ways to opt out of having their data crawled for AI, while still allowing traditional search engines to index this valuable data.\n\n\"We're now exploring updates to our controls to let sites specifically opt out of Search generative AI features,\" Google said on Wednesday in a blog post.\n\nThat's a major concession from Google, which has been quietly but firmly pushing back against such demands.\n\nYet, the tech giant also warned that strict new controls could threaten its prized Search engine, which generates most of the company's profits.\n\n\"Any new controls need to avoid breaking Search in a way that leads to a fragmented or confusing experience for people,\" the company said, arguing that search and AI are now deeply intertwined.\n\nGoogle says AI has been core to how Search works for more than a decade, helping rank results and surface relevant links. Creating sharp opt-outs for generative AI features, Google suggests, could undermine the basic mechanics that allow people to find information quickly and allow websites to be discovered at scale.\n\nAt stake is a deeper question about what Search should be in the AI era. Publishers increasingly argue that AI summaries substitute for their content rather than pointing users to it, undermining the grand bargain that has underpinned the web for decades. Google counters that drawing hard lines between search and AI risks unintended consequences, including degraded results and a worse user experience.\n\nCloudflare CEO Matthew Prince said the UK's proposal is \"progress,\" but didn't go far enough. His company helps run about 20% of the web and has been pushing for new standards to level the AI playing field.\n\n\"The CMA's recommendation today doesn't go far enough because it doesn't force Google to split search crawl from AI crawl,\" Prince told Business Insider, referring to the UK's Competition and Markets Authority. \"Instead, it requires us all to trust that Google will not be evil when they build their unauditable black AI box.\"\n\n\"If the CMA wants to encourage innovation and competition in AI, the best thing they should do is force Google to play by the same rules as everyone else and split crawl for AI from the crawl for search,\" he added. \"Every company other than Google would support that because it fosters a healthy market. It's a no-brainer, so it's disappointing the CMA didn't go far enough today.\"\n\nA CMA consultation runs until February 25. Whether regulators can tighten the rules without, as Google warns, breaking Search may help determine not just the future of Google in the UK, but the shape of the open web itself.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "search engine",
      "features google",
      "search and ai",
      "content",
      "controls",
      "crawl",
      "rules",
      "strict",
      "regulators",
      "publishers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-warns-breaking-search-pressure-mounts-web-ai-cloudflare-2026-1",
    "thumbnail_url": "https://i.insider.com/697a616ba645d11881882b19?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "finance"
  },
  {
    "slug": "extesla-ai-head-has-seen-a-phase-shift-in-software-engineering-using-claude-code-and-his-manual-skills-slowly-atrophy",
    "title": "Ex-Tesla AI head has seen a 'phase shift in software engineering' using Claude Code — and his manual skills slowly 'atrophy'",
    "description": "Andrej Karpathy posted his \"notes from Claude Coding,\" describing a shift in engineering over the last two months.",
    "fullText": "He coined \"vibe coding.\" Now, he sees a \"phase shift\" in software engineering.\n\nAndrej Karpathy is one of AI's guiding figures. He was a founding member of OpenAI and later served as Tesla's director of AI. He also coined the term \"vibe coding,\" the AI-assisted coding movement that has taken software engineering by storm and was named Collins Dictionary's word of the year.\n\nIn his \"random notes from Claude Coding\" — which are over 1,000 words long — Karpathy wrote about the changes to his own coding style. Posted on X on Monday, the notes have already elicited reactions from engineers at Anthropic, xAI, and more.\n\nAI coding agents \"crossed some kind of threshold of coherence around December 2025 and caused a phase shift in software engineering,\" Karpathy wrote.\n\nA few random notes from claude coding quite a bit last few weeks.\n\nCoding workflow. Given the latest lift in LLM coding capability, like many others I rapidly went from about 80% manual+autocomplete coding and 20% agents in November to 80% agent coding and 20% edits+touchups in…\n\nKarpathy name-dropped both Anthropic's Claude Code and OpenAI's Codex as having significant improvements. Claude Opus 4.5, the model that has garnered much love from engineers online, came out at the tail end of November.\n\nThe AI leader's workflow has changed as a result of the AI tools. From November to December, Karpathy's 80/20 ratio flipped. He once used 80% manual coding and 20% agents; now, it's 80% agents and 20% manual code editing.\n\n\"I really am mostly programming in English now, a bit sheepishly telling the LLM what code to write... in words,\" he wrote.\n\nThe change to AI-written code \"hurts the ego,\" but is too powerful to ignore, Karpathy wrote. He also devoted a whole section of his notes to the \"fun\" he has while coding with large language models.\n\nWhat of those traditional coding skills, the ones you learn in a computer science program or through endless digital courses? That's a whole other function, Karpathy wrote, and one that might decline.\n\n\"I've already noticed that I am slowly starting to atrophy my ability to write code manually,\" he wrote.\n\nIn Karpathy's comments, engineers from leading AI companies sounded off. Ethan He, an xAI engineer and Nvidia alum, wrote that a \"10x engineer can be a one-man army.\"\n\nCharles Weill, another xAI engineer, wrote that founders can now \"divide themselves\" with coding agents, like a VC divides their capital over a portfolio of companies.\n\nBoris Cherny, an Anthropic staffer and the creator of Claude Code, wrote that he read Karpathy's \"thoughtful\" post till its end.\n\nThe Claude Code team at Anthropic may offer a model of where the industry is moving, Cherny wrote. His team is \"mostly generalists\" and filled with 10x engineers.\n\n\"Pretty much 100% of our code is written by Claude Code,\" Cherny wrote. \"For me personally it has been 100% for two+ months now, I don't even make small edits by hand.\"\n\nThe Anthropic employee also acknowledged the \"quality\" problems with AI-written code. Agents can overcomplicate things and can leave around dead code, he wrote.\n\nHis solution: having AI review the AI-written code.",
    "readingTime": 3,
    "keywords": [
      "ai-written code",
      "phase shift",
      "software engineering",
      "random notes",
      "xai engineer",
      "vibe coding",
      "coding agents",
      "engineers",
      "claude",
      "coined"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-claude-code-manual-skills-atrophy-software-engineering-tesla-2026-1",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "tech"
  },
  {
    "slug": "the-questions-leonis-capital-investors-ask-to-see-if-a-startups-tech-actually-holds-up",
    "title": "The questions Leonis Capital investors ask to see if a startup's tech actually holds up",
    "description": "Leonis Capital founders Jenny Xiao and Jay Zhao tell Business Insider what they ask AI startup founders to evaluate their tech.",
    "fullText": "If you hadn't heard, there's an AI race sweeping through Silicon Valley.\n\nWhile stalwarts like Google, Meta, and Microsoft, and newcomers like OpenAI and Anthropic, are grabbing the headlines as they unveil model after model, there are plenty of startups trying to find a foothold.\n\nFor investors, it can be hard to tell which of these upstarts have true technical potential and which are likely to fade into tech oblivion.\n\nThat's part of why Jenny Xiao, the cofounder of Leonis Capital, said it's important for venture capitalists to get serious about understanding the AI technology they're investing in.\n\nLeonis Capital, founded in 2021, is now deploying its second $40 million fund. The venture capital firm is focused on next-generation AI companies and has invested in over a dozen since its launch, including MaintainX, Motion, and SpectroCloud.\n\nBusiness Insider asked Xiao and her cofounder, Jay Zhao, to share the top five questions they ask founders when evaluating their tech. They shared their responses over email, which have been condensed and edited for clarity.\n\nThe best founders don't think in terms of incremental feature improvements — they think in capability thresholds. We're looking for whether they understand that progress in AI is often non-linear, and whether they can anticipate which future capabilities might fundamentally change or even break their product.\n\nOne of the most interesting takeaways from our Leonis AI 100 — where we benchmarked the most important AI startups — is that the strongest AI founders build just ahead of the next technical breakthrough.\n\nA good answer talks about entirely new workflows that get unlocked, not just marginal efficiency gains, and clearly explains how the company would adapt or pivot as the technology evolves.\n\nMost AI startups don't fail because they're bad, but because they're building something that OpenAI, Anthropic, or Google can eventually ship \"for free\" as a feature.\n\nThat's why we don't accept \"they're not focused on this\" as an answer. We push founders to explain what internal constraint would actually prevent a foundation model lab from building the same thing. If the answer comes down to focus or culture, that's not a real moat.\n\nStrong answers acknowledge that the big labs technically could build it, but doing so would break their incentive structure, pricing, or distribution model; require operational complexity that doesn't scale for them; or shift value to downstream execution rather than model capability.\n\nSome founders can also credibly argue they have a 12- to 18-month head start. Weak answers, by contrast, lean on claims like being \"more vertical,\" having \"more niche data,\" or understanding customers better — responses we hear from about 95% of founders.\n\nWe've noticed a consistent pattern: Most founders underestimate foundation models, and most VCs underestimate them even more.\n\nAsking \"How much proprietary data do you have?\" is usually the wrong question, since no early-stage company has truly meaningful data. And if a founder's pitch boils down to \"we have more data, therefore our models are better,\" that's a red flag: foundation models often improve faster than proprietary ones, and the companies building them have enough capital to buy data and quickly close any gaps.\n\nWhat matters much more is not how much data exists today, but whether the product naturally generates better data over time. For example, industrial systems where data only emerges once software is embedded in workflows, or products where switching costs come from accumulated context.\n\nWe ask this question to understand where defensibility actually lives once code becomes commoditized. If a founder can't answer it clearly, they likely don't understand their own moat.\n\nCosmetic advantages like code, UI, or models are easy to copy, while structural advantages — such as being a system of record or being embedded into compliance, audits, or standard operating procedures — are much harder to replicate.\n\nThe question also reveals founder temperament: Strong founders are candid about their vulnerabilities (\"Here's what we're most worried about\"), while weaker ones tend to get defensive and insist a threat \"would never happen.\"\n\nThis question forces founders to explain their earliest technical decisions and the trade-offs they intentionally made, revealing whether they understand system dynamics rather than just iterating on features.\n\nStrong answers sound like, \"We chose to execute actions, not just make suggestions, which increased liability but created real lock-in,\" or \"We became the system of record instead of a thin layer, which slowed integrations and sales early but made switching organizationally expensive later.\" By contrast, many founders default to saying they want to \"stay flexible,\" which often signals they haven't yet designed anything fundamental.\n\nThe best AI systems are opinionated by design, deliberately removing degrees of freedom and hard-coding assumptions about workflows, authority, or data flow.\n\nReal insight usually comes from abandoning old assumptions. This question helps distinguish founders who simply stumbled into AI from those who experienced a genuine shift in how they see the world.\n\nWe're looking for intellectual flexibility, not credentials. Strong answers point to a specific belief the founder once held, why they believed it, and what changed their mind; weak answers stay vague, like saying they \"realized AI was going to be big.\"\n\nThis question assumes copying is possible and pushes founders to explain what isn't obvious. Shallow answers fall back on claims like \"they couldn't move as fast\" or \"they don't have our data,\" while stronger ones point to hard-to-see advantages such as deep operational knowledge, customer-specific integrations, or accumulated context that isn't visible from the outside.\n\nFounders who can't point to moments where they changed their mind usually aren't learning — they're executing a fixed plan in a world that won't stay fixed.\n\nThis question reveals epistemic humility and whether a founder is genuinely truth-seeking or just looking for confirmation. AI moves too fast for people who can't update, and we're especially wary of founders who treat every pivot as vindication rather than correction.\n\nMarket timing, regulatory shifts, and platform dependencies kill far more startups than bad management. This question tests whether founders think probabilistically about external forces and whether they've designed for resilience instead of relying on luck.\n\nFounders who say \"nothing\" haven't thought hard enough. The ones we want to back can name several concrete external risks and explain how they're hedging against them.\n\nThe best founders aren't contrarian for its own sake, but they can hold an unpopular position long enough for the world to catch up.",
    "readingTime": 6,
    "keywords": [
      "accumulated context",
      "we're looking",
      "foundation models",
      "leonis capital",
      "founders",
      "they're",
      "don't",
      "startups",
      "that's",
      "understand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/leonis-capital-investor-questions-for-ai-startups-2026-1",
    "thumbnail_url": "https://i.insider.com/697a63f2d3c7faef0ecd1b17?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.737Z",
    "topic": "finance"
  },
  {
    "slug": "what-the-latest-earnings-from-tesla-and-meta-tell-us-about-whos-winning-the-ai-race",
    "title": "What the latest earnings from Tesla and Meta tell us about who's winning the AI race",
    "description": "It turns out investors are willing to forgive huge capital spending if a company's core business is thriving.",
    "fullText": "Heading into Wednesday's hoy trinity of earnings — which saw Meta, Microsoft, and Tesla report within five minutes of each other — everyone knew that updates on AI progress would be the only game in town.\n\nHow those results ended up playing out shed crucial light on where we are in the AI trade right now.\n\nThe overarching focus for the Big Tech trio was not who has immediately seen results from AI investment. Instead, it was whether those companies were doing enough to support the appearance of maybe, eventually doing something. Investors love the prospect of future upside, and want a reason to preserve their optimism.\n\nEach of the three companies showcased this trend in their own unique way. Let's go one by one:\n\nLast quarter, Meta was punished for its capex-spending plans. This quarter, the company once again blew the doors off spending forecasts … but this time the market seemed OK with it.\n\nWhat changed? Look no further than the company's stronger-than-expected first-quarter revenue, driven by a big beat in advertising. Meta CFO Susan Li also got investors hyped on the earnings call by saying the company will fund its AI ambitions primarily with cash, rather than debt.\n\nIn the end, it's not that Meta has tangible proof that its AI spending is going to generate monstrous future earnings growth. The company has instead fallen back on its cash-cow advertising business to alleviate financing pressures and buy itself more time.\n\nWe haven't yet gotten an answer about whether the AI spending will pay off. We just know the company can afford to keep pursuing it.\n\nMarket reception: Very positive\n\nI present the counterpoint to Meta's well-received quarter. Microsoft also announced much larger-than-expected spending plans … and its stock fell.\n\nThe difference? One of Microsoft's main cash cows — its Azure cloud-computing unit — showed slowing growth. Suddenly, big spending doesn't look so appealing when your backstop is weakening.\n\nWhile Tesla's AI push has taken the form of self-driving vehicles and robotics, the company's lofty valuation is still being largely driven by hopes that big AI-linked profits will one day be unlocked.\n\nBut unlike Meta, the EV-maker is doing it at a time when its core business is in decline. One overlooked highlight of Tesla's report was that — even though the company posted a bottom-line beat — it also saw first-ever decline in annual revenue.\n\nIt didn't matter. Investors instead focused on Tesla's $2 billion investment in xAI, the company owned by Elon Musk. They also seemed to take the discontinuation of the Model S and Y vehicles in stride.\n\nAgain, the perception of eventually monetizing AI won out. In the AI race, it's not what you're doing, it's what you can convince everyone you're going to do down the line.",
    "readingTime": 3,
    "keywords": [
      "doing",
      "earnings",
      "instead",
      "investors",
      "quarter",
      "it's",
      "everyone",
      "investment",
      "eventually",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-meta-microsoft-q4-earnings-takeaways-stock-market-ai-race-2026-1",
    "thumbnail_url": "https://i.insider.com/697a9d3ce1ba468a96aaeb2d?width=1024&format=jpeg",
    "created_at": "2026-01-29T12:32:28.543Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-ai-will-make-saving-for-retirement-irrelevant-anthropics-ceo-says-building-that-future-wont-be-easy",
    "title": "Elon Musk says AI will make saving for retirement 'irrelevant.' Anthropic's CEO says building that future won't be easy.",
    "description": "Elon Musk said retirement savings would be pointless in an abundant future. Dario Amodei warned of job losses and rising inequality along the way.",
    "fullText": "Elon Musk recently said that saving for retirement could become \"irrelevant\" in the next decade, as new technologies promise to create such an abundance of resources that nobody will need a nest egg.\n\nDario Amodei warned this week that achieving a plentiful future won't be easy. The CEO of Anthropic, the AI startup behind ChatGPT-rival Claude, wrote in an essay that AI promises to \"raise the quality of life for everyone\" — but there will be a brutal \"rite of passage\" to get there.\n\nAmodei said that at the current rate of progress, \"it cannot possibly be more than a few years before AI is better than humans at essentially everything.\"\n\nReplacing human labor with AI could supercharge economic growth and productivity, but the \"short-term shock will be unprecedented in size,\" he wrote.\n\nAmodei said he was worried that workers displaced by AI \"could form an unemployed or very-low-wage 'underclass,'\" and a tiny minority could capture most of the financial gains from AI, creating a \"level of wealth concentration that will break society.\"\n\nHe described those potential impacts on labor and equality as \"grave problems\" that AI companies, employers, philanthropists, and governments would have to work together to solve.\n\nAmodei noted that he and Anthropic's other cofounders have pledged to donate 80% of their wealth to good causes, and the company will match individual donations from its staff worth billions of dollars at its current valuation.\n\nAnthropic's boss shared a similar vision to Musk in a 2024 essay. He wrote that AI will eventually become \"so broadly effective and so cheap\" that the current economic system will \"no longer make sense.\"\n\nIt could be replaced by a \"large universal basic income for everyone,\" or a \"capitalist economy of AI systems\" that distributes \"huge amounts\" of resources to people as the \"overall economic pie will be gigantic,\" he added.\n\nBut he also flagged the risk of \"exploitative or dystopian directions\" and said, \"We will likely have to fight to get a good outcome here.\"\n\nBusiness Insider recently spoke to seven AI and personal finance gurus about Musk's vision, and they shared several of Amodei's concerns.\n\nThey urged Americans to keep saving for retirement just in case Musk is wrong — and said that even if he's right, making sure everyone reaps the rewards of AI will require immense planning and coordination.",
    "readingTime": 2,
    "keywords": [
      "everyone",
      "economic",
      "recently",
      "saving",
      "retirement",
      "resources",
      "essay",
      "labor",
      "wealth",
      "anthropic's"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/elon-musk-retirement-saving-ai-abundance-anthropic-dario-essay-ubi-2026-1",
    "thumbnail_url": "https://i.insider.com/697b3ae9e1ba468a96aaedfd?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.350Z",
    "topic": "finance"
  },
  {
    "slug": "universal-basic-income-could-be-used-to-soften-hit-from-ai-job-losses-in-uk-minister-says",
    "title": "Universal basic income could be used to soften hit from AI job losses in UK, minister says",
    "description": "Lord Stockwood says people in government ‘definitely’ talking about idea as technology disrupts industries\n• Business live – latest updates\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n“Bumpy” changes to society caused by the introduction of the technology would mean there would have to be “some sort of concessionary arrangement with jobs that go immediately”, Lord Stockwood said.\n Continue reading...",
    "fullText": "Lord Stockwood says people in government ‘definitely’ talking about idea as technology disrupts industries\n\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n\n“Bumpy” changes to society caused by the introduction of the technology would mean there would have to be “some sort of concessionary arrangement with jobs that go immediately”, Lord Stockwood said.\n\nThe Labour peer told the Financial Times: “Undoubtedly we’re going to have to think really carefully about how we soft-land those industries that go away, so some sort of [universal basic income], some sort of lifelong mechanism as well so people can retrain.”\n\nA universal basic income is not part of official government policy, but when asked whether people in government were considering the need for UBI, Stockwood told the FT: “People are definitely talking about it.”\n\nThe technology entrepreneur, who took up his ministerial post in September, said part of his motivation for joining the government was to help ensure the workforce was prepared for rapid change.\n\nFears continue to grow about the impact of artificial intelligence on Britain’s job market. This week research by the investment bank Morgan Stanley found the UK was losing more jobs than it is creating because of AI and was being hit harder than other large economies.\n\nThis month the mayor of London, Sadiq Khan, said AI could destroy swathes of jobs in the capital and “usher in a new era of mass unemployment”.\n\nLast week, Jamie Dimon, the chief executive of the US bank JP Morgan, told the World Economic Forum in Davos that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk civil unrest.\n\nStockwood, who held senior positions at Lastminute.com, Travelocity and Match.com, oversaw the $490m (£400m at the time) sale of the online insurance broker Simply Business to the US insurer Travelers in 2017. He later bought a stake the football club of his home town, Grimsby Town FC.\n\nWhile he has previously been a vocal proponent of a wealth tax in the UK, Stockwood told the FT he had not repeated his calls for the government to go further on taxing the rich.\n\nHowever, he added: “If you make your money and the first thing you do is you speak to a tax adviser to ask: ‘Where can we pay the lowest tax?’ we don’t want those people in this country, I’d suggest, because you’re not committed to your communities and the long-term success in this country.”\n\nStockwood was preceded as investment minister by Poppy Gustafsson, a former chief executive of the cybersecurity firm Darktrace, who stepped down after less than a year in the job.",
    "readingTime": 3,
    "keywords": [
      "chief executive",
      "universal basic",
      "basic income",
      "investment minister",
      "lord stockwood",
      "technology",
      "industries",
      "sort",
      "jobs",
      "talking"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/29/universal-basic-income-used-cover-ai-job-losses-minister-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de673ed46d19dc117c208edb6f803b2eca7c5ad8/1020_268_1578_1263/master/1578.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1431031c71c27093dd3511ca51014201",
    "created_at": "2026-01-29T12:32:28.046Z",
    "topic": "tech"
  },
  {
    "slug": "the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "title": "The slopaganda era: 10 AI images posted by the White House - and what they teach us",
    "description": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here’s what you need to know to navigate the trolling\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it’s developed into a full-blown phenomenon, one academics are calling “slopaganda” – an unholy alliance of easily available AI tools and political messaging. “Shitposting”, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of “institutional shitposting”, according to Know Your Meme’s editor Don Caldwell. This is trolling as official government communication.",
    "fullText": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here’s what you need to know to navigate the trolling\n\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it’s developed into a full-blown phenomenon, one academics are calling “slopaganda” – an unholy alliance of easily available AI tools and political messaging. “Shitposting”, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of “institutional shitposting”, according to Know Your Meme’s editor Don Caldwell. This is trolling as official government communication. And nobody is more skilled at it than the Trump administration – a government that has not only allowed the AI industry all the regulative freedom it desires, but has embraced the technology for its own in-house purposes. Here are 10 of the most significant fake images the White House has put out so far.\n\nThe first AI image posted by the White House X account sets the tone for Trump’s second presidency – marking a turning point in which the shitposting that had been associated with the far-right online culture that brought Trump to power moved from fringe message boards, such as 4chan and Reddit, to mainstream platforms.\n\nThe image was posted alongside an announcement of the repeal of New York City’s congestion pricing, and leant into fears that Trump would govern as a king. The New York governor, Kathy Hochul, held up the image at a press conference when she announced that she would defy attempts to block the congestion charge: “New York hasn’t laboured under a king in over 250 years. We sure as hell are not going to start now.” The congestion charge remains in effect.\n\nIn another post on Truth Social in October, the president posted an AI video depicting himself as a president-king, crown on head, flying over “No Kings” protesters in a jet fighter and dumping faeces on them. The House speaker, Mike Johnson, defended the post, saying: “The president uses social media to make a point. You can argue that he’s probably the most effective person who’s ever used social media for that. He is using satire to make a point.”\n\nOpenAI’s Studio Ghibli-inspired meme generator became a sensation in March 2025, with its uncanny ability to translate any image into the beloved anime studio’s house style (without Studio Ghibli’s permission or approval).\n\nThe White House applied it to a woman in tears as she was arrested by Immigration, Customs and Enforcement (ICE) agents before being deported. The original photograph, and the woman’s name and alleged crimes, are also included in the post.\n\nFor Caldwell, this demonstrated just how up to date the White House is with online trends. “They’re hopping on brand-new, fresh memes,” he says. He suspects White House staffers might be regular visitors to Know Your Meme. “The Studio Ghibli meme trend kicked off on March 25 on X; we covered it the following day; and then the White House covered it the day after that.”\n\nThis image is proof of Trump’s willingness and ability to insert himself into any conversation, even ones that have nothing to do with him, and shows how effective that can be.\n\nPredictably, the image went viral, made global headlines and was met with outrage from Catholic groups and politicians. “There is nothing clever or funny about this image, Mr President,” wrote the New York State Catholic Conference. “We just buried our beloved Pope Francis and the cardinals are about to enter a solemn conclave to elect a new successor of St Peter. Do not mock us.”\n\nAs so often happens with such shitposting, those who ​took offence were accused of lacking a sense of humour. “They can’t take a joke?” Trump said soon after at a press conference. “You don’t mean the Catholics, you mean the fake news media … the Catholics loved it.”\n\nTrump has been the subject of flattering fan art throughout his political career (remember the digital Trump trading cards?), but AI has made the job a whole lot easier. On 4 May, the White House crashed Star Wars fans’ special day with this image of the president as a jacked Jedi, lightsaber in hand, garlanded by flags and eagles. Who cares if his lightsaber is the wrong colour (the good guys’ are blue), or that the White House’s claim to be the Rebellion not the Empire rang laughably hollow? This was pure fantasy art.\n\nIn 2022, one of Trump’s trading cards clumsily grafted his headshot on to a superhero body; last July he was slightly less clumsily grafted on to the body of Superman, to gatecrash the launch of the new movie. The same month, the White House portrayed a besuited Trump heroically striding into the Colosseum. Fans and allies have generated reams of similar content themselves.\n\nWhy did the White House choose to put the Democratic house leader Hakeem Jeffries and the senate leader Chuck Schumer in sombreros and have them holding plates of tacos? It doesn’t matter. They look a bit silly, and it’s provocatively offensive, and once again, the world’s attention is colonised.\n\nThe image illustrates how difficult it is to respond to this type of content. It’s part of a running joke, stretching back to a deepfake video Trump posted a month earlier, which slapped a crude sombrero and moustache filter over Jeffries. That video was roundly condemned as offensive and racist , not least by Jeffries himself (who replied by posting a genuine image of Trump with the sex offender Jeffrey Epstein) . The Trump administration then doubled down, playing the video on a loop on screens in the White House briefing room for several hours and creating more images in a similar vein, which kept the trolling going.\n\nFew people outside the Trump administration believe the US is in a “golden age”, but that hasn’t stopped Trump from repeating the claim. In January, the White House posted an AI video of a golden White House facade behind a shower of gold coins with the text “The White House? She’s in her Golden Age”, backed by Bruno Mars’ track 24K Magic.\n\nEven if Trump’s Midas touch is more a figment of his imagination, this type of wishcasting is more effective than it appears. According to one paper by the academics Michał Klincewicz, Mark Alfano and Amir Ebrahimi Fard – who coined the term “slopaganda” – “neural representations of information that were shown to be false continue to influence people’s beliefs and reasoning after being corrected”. In other words, even when you know it’s fake, your brain still kind of believes it.\n\nOn the face of it, this seems like a straightforward “Trump wants Greenland” post. However, it has a much darker message.\n\nAgain, the post is riffing on a popular meme, Caldwell explains: the “dramatic crossroads” image originated with the manga series Yu-Gi-Oh!, and started gaining traction online around 2021.\n\nThe slogan “Which way, Greenland man?” seems to reference a 1978 neo-Nazi text titled Which Way, Western Man?, in which the white supremacist author William Gayley Simpson called for violence against and the deportation of Jews and Black people, and argued that Hitler was right.\n\n“It’s absolutely shocking to see such images being deployed by this administration,” said Heidi Beirich, a co-founder of the Global Project Against Hate and Extremism, which monitors US neo-Nazi groups. “The idea appeals to racists and white supremacists who think only white people should be in positions of power.”\n\nIn August, the Department of Homeland Security posted a mock recruitment advert for ICE with an image of Uncle Sam at a crossroads and the slogan: “Which way, American man?” Earlier this month, the US Labor Department posted an image with the slogan: “One Homeland. One People. One Heritage”. Critics pointed out that it had overtones of Hitler’s “Ein Volk, ein Reich, ein Führer” (“One people, one realm, one leader”).\n\n“AI is very good at constantly reiterating images from the past, so it can create this nostalgic imagery of traditionalism,” says Daniel de Zeeuw, an assistant professor in digital media culture at the University of Amsterdam. Thus the extremist messages of the present – such as ICE’s militarised policing – can be inserted into more reassuring and familiar graphic styles, such as patriotic recruitment posters, 80s action-movie posters or 1950s public information campaigns (as with a recent image of Trump as a friendly milkman).\n\nAI is inherently backward-looking, says de Zeeuw, as it is fed on historical images. This aesthetic is in keeping with the Make America Great Again movement, which is constantly evoking a “better” past. Another stark example was the Department of Homeland Security’s chilling post from last December: an image of a vintage car at a deserted, palm-fringed beach with the slogan “America After 100 Million Deportations”. Ironically, the original was painted by a Japanese artist, Hiroshi Nagai, who complained that it had been used without his permission.\n\n“It’s not going to be on Twitter,” said the agent filming the Minneapolis civil rights lawyer Nekima Levy Armstrong, one of the city’s most prominent activists, as she was arrested last Thursday. Within hours, though, it was: the Homeland Security secretary Kristi Noem posted a still from the video, in which Armstrong seems composed and shows little emotion.\n\nHalf an hour later, the White House X account posted a significantly altered version of the same image: this time, Armstrong is exaggeratedly upset, tears streaming down her face. Her skin tone also appears to have been darkened. The image was captioned: “Arrested: far-left agitator Nekima Levy Armstrong for orchestrating church riots in Minnesota.” In fact, Armstrong was demonstrating at a church service led by an allegedly ICE-affiliated pastor, and was later released without charge.\n\nUntil this moment, the White House’s AI-generated output had been conspicuously outlandish: there was little danger of mistaking it for reality. This image purports to be an authentic photograph – or at least omits to mention that it is not. It is not so much AI-generated trolling as an AI-assisted deepfake.\n\nAs with Musk’s recently shared Grok tool, which removed women and children’s clothing without their consent, there is also something abusive about it: AI has been used to attempt to humiliate a woman by manipulating her image, to make her look weaker and more distressed than she actually was.\n\nThe fact that the deepfakery is not all that convincing is part of the point, de Zeeuw thinks. “What is being communicated here is the falsification itself: you’re showing your ability to falsify images, to falsify evidence.”\n\nAfter the fakery had been called out, the White House deputy communications director Kaelan Dorr posted the response: “Enforcement of the law will continue. The memes will continue.”\n\nIn response to this image of Trump and a penguin walking towards a Greenland flag, some observers pointed out that penguins actually live at the south pole. But that’s missing the point of these types of post, says Robert Topinka, a reader in digital media and rhetoric at Birkbeck, University of London. “People continue to interpret them as if they’re meant to be a legitimate claim, or an argument or a piece of evidence, but they’re emotional hooks.” Their purpose is to stir up the base. “White House staffers have said they use AI because it’s the fastest way to get content out. It’s not the fastest way to say something that’s true; it’s the fastest way to push their propaganda.”\n\nTo those in the know, this is a riff on the “nihilist penguin” meme, which has gone viral on TikTok in the past few weeks. It’s based on a scene from Werner Herzog’s 2007 documentary Encounters at the End of the World, in which one penguin inexplicably separates from the colony and wanders off towards the Antarctic interior, and certain death. “But why?” Herzog wonders. Many have asked the same of Trump’s quixotic attempts to acquire Greenland.\n\nThe image resonates with what Naomi Klein and ​Astra Taylor ​christened “end times fascism”, says De Zeeuw, where tech industry leaders and their enablers are almost willing the end of the world as we know it, striding towards oblivion like Trump and his penguin companion. “It’s like they know they’re moving toward the end, but they do so joyfully.”",
    "readingTime": 11,
    "keywords": [
      "white house",
      "nekima levy",
      "levy armstrong",
      "trading cards",
      "clumsily grafted",
      "house account",
      "house staffers",
      "trump administration",
      "press conference",
      "congestion charge"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/2026/jan/29/the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4b7cb2fd8f7d06f369527b2702d8dbea84ffdad2/0_105_2160_1728/master/2160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=642ec79d432723197b75c7a515cf46a0",
    "created_at": "2026-01-29T12:32:28.039Z",
    "topic": "tech"
  },
  {
    "slug": "whos-hiring-scab-protocol-remote-equityonly",
    "title": "Who's Hiring: Scab Protocol (Remote, Equity-Only)",
    "description": "The runtime behavioral governance framework for AI systems. Measure, monitor, and control AI behavior continuously across six domains.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://scab.dev",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/c2ebdabd-7464-44b8-8d02-2182d6a360c2/id-preview-9af3fcbe--351023f6-eb8a-4801-b737-973f998527b3.lovable.app-1769664312714.png",
    "created_at": "2026-01-29T06:34:22.725Z",
    "topic": "tech"
  },
  {
    "slug": "5-of-the-biggest-takeaways-from-metas-q4-2025-earnings-call",
    "title": "5 of the biggest takeaways from Meta's Q4 2025 earnings call",
    "description": "Meta's Q4 2025 earnings reveal massive AI investment plans, ad-driven revenue growth, and costly Reality Labs losses.",
    "fullText": "Meta's earnings sent a clear signal to Wall Street on Wednesday: while its core advertising engine is still firing on all cylinders, the price tag for CEO Mark Zuckerberg's AI ambitions will skyrocket in 2026.\n\nThe company reported $59.89 billion in revenue for the fourth quarter of 2025, topping Wall Street's forecasts. Meta's stock jumped as high as 10% in after-hours trading.\n\nAlongside the upbeat numbers, Meta laid out how hard it plans to push in 2026. The company said it expects to spend $115 billion to $135 billion next year on capital expenditures — largely on the computers and data centers that power AI.\n\nIn other words, Meta still makes most of its money from ads. It's asking investors to stay on board as it pours an extraordinary amount of cash into the race to build more powerful AI and weave it into Instagram, WhatsApp, Facebook, and virtual and augmented reality products, collectively used by more than 3.5 billion people daily around the world.\n\nHere are five takeaways from Meta's Q4 2025 earnings call.\n\nMeta told to brace for a much more expensive 2026 as it pours money into the compute and data centers needed to power its AI push. The company said it expects capital expenditures in 2026 to land between $115 billion and $135 billion — up to almost double the $72 billion it spent in 2025.\n\nMeta's chief financial officer, Susan Li, said the increased expenditure will support Meta Superintelligence Labs' efforts and its core business.\n\nLi also warned that Meta's overall costs are set to climb fast. The company expects total 2026 expenses of $162 billion to $169 billion, with most of the increase coming from \"infrastructure costs,\" including \"third-party cloud spend, higher depreciation, and higher infrastructure operating expenses.\"\n\nAnd Meta isn't just buying more machines — it's also paying for people to run them. Li said the \"second-largest contributor\" to expense growth will be compensation, driven by \"investments in technical talent,\" including hires in \"priority areas, particularly AI.\"\n\nAdvertising once again powered Meta's quarter. The company reported $58.14 billion in ad revenue in Q4 2025, up 24% from the same time last year. That growth came from a mix of showing more ads (ad impressions rose 18% from the same quarter last year) and charging a bit more per ad (average price per ad rose 6%).\n\nWhen analysts pressed Zuckerberg on whether Meta can build meaningful businesses beyond ads, given how much cash it's pouring into AI, he didn't dodge the question of its dependency.\n\n\"For the next couple of years, ads are going to be by far the most important driver of growth in our business,\" Zuckerberg said, adding that Meta is working on new bets alongside that core engine.\n\nMeta's pitch is that its AI investments are already making the ad machine work better — not just by targeting, but by improving the systems that decide which ads people will most likely engage with.\n\nThe company said that its AI tools for making video ads hit a $10 billion revenue run rate. It also said a newer measurement product helped advertisers drive 24% more conversions than its standard method — and ramped up to a multi-billion-dollar annual run rate in just seven months.\n\nReality Labs, the division behind Meta's virtual and augmented reality efforts, continued to burn cash in the final quarter of 2025. The division lost $6.02 billion in a quarter, the highest ever, and $19.19 billion in 2025 — numbers that underscore how much Meta's ambitions to build immersive worlds still depend on ad revenue.\n\nDespite laying off about 1,500 people at Reality Labs earlier this month, Meta told investors not to expect a sudden turnaround. Li said the company expects Reality Labs' operating losses in 2026 to remain \"similar to 2025 levels.\"\n\nZuckerberg is trying to reposition what Reality Labs is building. The company's focus has shifted from trying to go all in on the \"metaverse\" to building AI-powered smart glasses and experiences that could live inside Meta's existing apps.\n\nWhen Barclays analyst Ross Sandler asked about Meta's plans to bring Horizon Worlds, a virtual hangout zone accessible on the company's Quest VR headsets, to mobile, Zuckerberg said that he expects more \"interactive and immersive\" content formats to show up directly inside the feeds in Meta's existing apps.\n\nHe added that people might be able to use AI to create a game with a single prompt and share it on their feeds so that others can \"jump right into it.\"\n\nHe positioned Horizon Worlds as a natural fit for an \"immersive 3D\" version of that idea and said that Meta's work on VR software and Horizon could pair with AI advances to bring these kinds of experiences to \"hundreds of millions and billions of people through mobile.\"\n\nMeta isn't just trying to sprinkle AI features across Facebook and Instagram. Zuckerberg is making a bigger argument: if Meta wants to shape the next generation of consumer tech, it needs to control the underlying AI, not just depend on whatever rivals sell.\n\nThat's also the framing behind his public push for \"personal superintelligence,\" which he called out again as a key focus for 2026.\n\nWhen Wells Fargo analyst Ken Gawrelski asked how critical it is for Meta to have a general-purpose model, Zuckerberg leaned into Meta's identity as a \"deep technology company.\"\n\nWhat allows Meta to build everything it does, he said, \"is that we build and control the underlying technology.\" That way, Meta can design the experiences it wants, \"and not just be constrained to what others in the ecosystem are building or allow us to build,\" Zuckerberg added.\n\nHe suggested that relying on outside models could become risky over time, citing a mix of competitive and safety reasons. That's why, he said, it's important for Meta to have its own models, both from a business perspective and because Meta wants to \"actually design and build the experiences that we believe that we should be building for people.\"\n\nZuckerberg is pitching 2026 as the year AI changes not just Meta's products, but how Meta itself operates. On the call, he said 2026 will be \"the year that AI starts to dramatically change the way that we work\" and that the company is \"investing in AI native tooling so individuals at Meta can get more done.\"\n\nHe also described a deliberate shift in org design.\n\n\"We're elevating individual contributors and flattening teams,\" Zuckerberg said, adding that Meta is already seeing \"projects that used to require big teams now be accomplished by a single, very talented person.\"\n\nLi paired that cultural pitch with a concrete productivity claim. She said that since the beginning of 2025, Meta has seen a \"30% increase in output per engineer\" overall, and that \"power users\" of its internal AI coding tools saw output rise 80% year-over-year.\n\nThe company's implied bet? Spend heavily on AI infrastructure and tooling, and then run leaner teams that can ship more.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "augmented reality",
      "meta's earnings",
      "meta's existing",
      "capital expenditures",
      "existing apps",
      "meta isn't",
      "reality labs",
      "horizon worlds",
      "quarter",
      "revenue"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-ai-investments-capex-2026-1",
    "thumbnail_url": "https://i.insider.com/697ab091d3c7faef0ecd23e6?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.656Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-says-openai-is-driving-45-of-the-backlog-for-azure-cloud-computing",
    "title": "Microsoft says OpenAI is driving 45% of the backlog for Azure cloud computing",
    "description": "OpenAI and Microsoft have a reconfigured relationship. The software giant revealed just how much OpenAI is driving its RPO.",
    "fullText": "Microsoft is facing capacity constraints, and OpenAI is driving a large portion of the backlog in its cloud computing business.\n\nThe company said its backlog in commercial bookings, a metric referred to as remaining performance obligations, ballooned 110% year over year to $625 billion when it reported earnings for the second quarter on Wednesday.\n\nOpenAI accounts for roughly 45% of those commitments, Microsoft revealed. The company did not say how much OpenAI contributed during the previous quarter.\n\nSome Wall Street analysts on the call expressed concerns about Microsoft's dependency on OpenAI.\n\nCEO Satya Nadella said acquiring more Azure clients is important to the tech giant, but it can't come at the expense of neglecting its other services.\n\n\"If you think about it, acquiring an Azure customer is super important to us, but so is acquiring an M365 or a GitHub or a Dragon Copilot, which are all, by the way, incremental businesses and TAMs for us,\" Nadella said during Microsoft's second-quarter earnings call. \"And so we don't want to maximize just one business of ours.\"\n\nShares of Microsoft fell more than 6% in after-market trading on Wednesday, even as the tech giant posted an overall earnings beat.\n\nMorgan Stanley's Keith Weiss said during the call that some on Wall Street may be spooked by slower growth in overall Azure revenue and the increase in capex spending. Microsoft's capital expenditures rose 66% year over year to $37.5 billion in the second quarter, another record for the company and testament to the sheer amount of money tech companies are spending amid the AI race.\n\nCFO Amy Hood said that Microsoft has to look at many different areas when it allocates the GPUs and CPUs that come online as a result of its capex spending, including investing in the growth of first-party apps like Microsoft Copilot, devoting GPUs to research and development, and the talent they've acquired.\n\n\"You end up with the remainder going towards serving the Azure capacity that continues to grow in terms of demand,\" she said.\n\nMicrosoft is not alone in facing capacity issues.\n\nExecutives at OpenAI, which has pledged to spend $250 billion on Azure services, have repeatedly said the startup is held back by a lack of compute, forcing tough trade-offs between product and research.\n\nWednesday's earnings mark the first quarter since OpenAI completed its restructuring, which included a new agreement with Microsoft, the startup's largest investor. Microsoft owns 27% of the public benefit corporation.\n\n\"It's a great partnership,\" Hood said of Microsoft's relationship with OpenAI. It's allowed us to remain a leader in terms of what we're building and being on the cutting edge of app innovation.\"",
    "readingTime": 3,
    "keywords": [
      "facing capacity",
      "tech giant",
      "second quarter",
      "azure",
      "earnings",
      "microsoft's",
      "acquiring",
      "microsoft",
      "openai",
      "backlog"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-openai-azure-cloud-computing-backlog-2026-1",
    "thumbnail_url": "https://i.insider.com/697aa643a645d118818833f0?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.651Z",
    "topic": "finance"
  },
  {
    "slug": "tesla-takes-another-leap-toward-becoming-a-physical-ai-company-here-are-the-6-biggest-takeaways-from-its-q4-earnings",
    "title": "Tesla takes another leap toward becoming a physical AI company: Here are the 6 biggest takeaways from its Q4 earnings call.",
    "description": "Tesla CEO Elon Musk announced a $2B investment into xAI and the discontinuation of Model S and Model X in order to support Optimus robot production.",
    "fullText": "Tesla is making another leap to shed its EV maker title and transform into a full-fledged physical AI outfit.\n\nThe theme of Wednesday's fourth-quarter earnings call heavily centered on how Tesla is investing in its future as an AI and robotics company — a narrative CEO Elon Musk has pushed for some time now.\n\nThe bets included: a major investment in Musk's xAI, updates on the Optimus humanoid robot, and a renewed push for in-house chipmaking. Musk projected that Tesla's future will require a $20 billion investment, which dwarfs the company's $8.5 billion in capex reported for the 2025 fiscal year.\n\nMeanwhile, Tesla's automotive segment took a back seat: Musk said he's killing the Model S and Model X to free up room for humanoid robot production. And while Tesla's energy and \"services\" revenue jumped 25% and 18%, respectively, auto revenue fell 11% year-over-year — a clear indication that the quarter's growth came from everywhere but its core EV business.\n\n\"We've updated the Tesla mission to amazing abundance, and this is an attempt to send a message of optimism about the future,\" Musk said during the call.\n\nThe company's stock rose 1.7% after the market closed on Wednesday evening.\n\nHere are 6 biggest takeaways from the earnings call.\n\nTesla made good on its pledge to investors and announced a $2 billion investment into xAI, the startup behind Grok. It's part of a larger $20 billion Series E funding round from January.\n\nThe expectation of the investment is a deeper collaboration between the two companies. xAI, which has been expanding its data center footprint, could provide the compute and other technical capabilities to further advance Tesla's autonomous vehicle and robotics agenda.\n\nVaibhav Taneja, Tesla's chief financial officer, said during the call that the agreement with xAI is in the spirit of finding \"efficient ways for others to help us.\"\n\nIn a surprise move, Musk announced that production of the Model S and Model X would be discontinued by the next quarter, closing a chapter on the company's premium SUV and sedan.\n\nThat leaves the EV maker with four cars: the Cybertruck, the more popular Model 3 and Model Y, and the yet-to-be-released Cybercab.\n\nThe CEO said during the call that the move will provide more production space in Tesla's Fremont factory for Optimus robots.\n\nThe \"long-term goal\" is to produce a million units a year with the freed-up space, Musk said.\n\nThe CEO added that killing the Model S and Model X is part of Tesla's \"overall shift to an autonomous future,\" which includes the company's ride-hailing service, Tesla Robotaxi, and autonomy in personally owned vehicles through Full Self-Driving, an advanced driver assistance system.\n\nTesla expects to start production of the Cybercab, a two-seater coupe, in April for eventual integration into its Robotaxi fleet.\n\nTesla revealed where it aims to expand the Robotaxi ride-hailing service in the first half of 2026 — Dallas, Houston, Phoenix, Miami, Orlando, Tampa, and Las Vegas — but has yet to announce when it will remove the safety monitors inside the cars for public riders across Austin and San Francisco Bay Area, where the service now operates.\n\nMusk said that FSD — the technology that Tesla says will make personally owned vehicles fully autonomous — is already \"100% unsupervised\" and operating without humans inside. The difference, he said, is that Tesla is being \"very cautious\" with rolling out unsupervised service to the public, though Tesla began offering a limited number of unsupervised rides in Austin this month.\n\n\"There's like some pretty nutty intersections, where there are a lot of humans who make mistakes and have accidents in various cities,\" Musk said. \"So we want to make sure that FSD can handle those unusual intersections.\"\n\nThere wasn't much of a progress report on Tesla's AI5 chip, but the CEO said he's spending part of his weekends working on it.\n\n\"If I'm spending my Saturdays on something, it's going to be something pretty important,\" Musk said, adding that chip procurement is \"existential\" for Tesla's future, going so far as to bring up the Tesla \"Terafab\" — his aspirational idea of building an in-house chip manufacturing plant.\n\nMusk said he wants to build a factory that integrates \"logic, memory, and packaging\" because Tesla will be \"fundamentally limited by supply chain\" if it doesn't.\n\nMusk said he expects to unveil an Optimus 3 robot in a \"few months,\" but don't expect it to be working the assembly lines just yet.\n\nThe CEO said Optimus isn't contributing to Tesla's manufacturing work in any \"material way\" and that the humanoid robot is only in the factory for training purposes.\n\nMusk talked a lot about Tesla's future, but the company's fourth-quarter performance still hinged on its tangible businesses, such as its energy segment, which includes the Megapack, a utility-scale battery system, and the Powerwall, the home battery system.\n\n\"On the energy front, we achieved yet another record in terms of gross profits for the quarter and ended the year with nearly $12.8 billion in revenue,\" Taneja, the Tesla CFO, said.\n\nTesla also announced this month that it will pivot FSD to a subscription-based only model starting in February. Customers previously had the option to buy FSD upfront for $8,000.\n\nThe move is a clear signal that Tesla sees FSD as a key future revenue generator.\n\nAutomakers are increasingly betting that software subscription services will be a critical source of recurring revenue with higher margins. General Motors revealed that its vehicle software generated $2 billion in the past nine months.\n\nTesla did not respond to a request for comment.",
    "readingTime": 5,
    "keywords": [
      "personally owned",
      "owned vehicles",
      "battery system",
      "model and model",
      "humanoid robot",
      "ride-hailing service",
      "the ceo",
      "company's",
      "revenue",
      "tesla"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-q4-earnings-call-summary-robotaxi-optimus-ai5-chips-2026-1",
    "thumbnail_url": "https://i.insider.com/697ac36dd3c7faef0ecd2457?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.534Z",
    "topic": "finance"
  },
  {
    "slug": "openais-chair-says-vibe-coding-is-here-to-stay-but-its-not-the-endgame",
    "title": "OpenAI's chair says vibe coding is here to stay — but it's not the endgame",
    "description": "Vibe coding will stick around, but AI agents, not apps, will drive the next big shift in software, says OpenAI's chair Bret Taylor.",
    "fullText": "Vibe coding isn't going anywhere. But it's only part of a much bigger transformation, says OpenAI's board chair.\n\nBret Taylor said in an episode of the \"Big Technology Podcast\" published on Wednesday that using AI tools to build software quickly with natural language prompts will soon feel normal rather than novel. However, focusing on building today's software faster misses the bigger picture.\n\n\"Everyone's looking at all the software use and saying, 'How fast could I vibe code that?'\" Taylor said. \"I wonder if it's the wrong question.\"\n\nWhether someone can quickly vibe code an app in a web browser isn't \"the most interesting question in software,\" he added.\n\nInstead, the software we use today is set to be replaced, and that's the real disruption, Taylor said.\n\nRather than dashboards, web-browser forms, and traditional apps, the structure of software will change. AI agents will be \"the future of software.\"\n\n\"We will delegate tasks to agents that will operate against a database,\" Taylor said.\n\n\"Who's making those agents is the question,\" he added. \"Will you buy those agents off the shelf or build them yourself?\"\n\nTaylor also said that while AI has slashed the cost of building software, it hasn't solved the harder problems of maintaining it — or the risk of getting things wrong.\n\n\"That's why most people would prefer to buy a solution off the shelf,\" he said. \"You want to amortize the cost of maintaining software among thousands of clients.\"\n\nVibe coding has taken off across the tech world, but tech leaders said the technology has limits.\n\nGoogle CEO Sundar Pichai said in November in a \"Google for Developers\" podcast interview that vibe coding is \"making coding so much more enjoyable,\" adding that it allows even non-technical users to create simple apps and websites.\n\nDuring Alphabet's April earnings call, Pichai said AI generates more than 30% of Google's new code, up from 25% in October 2024.\n\nStill, AI-generated code can be error-prone, overly long, or poorly structured.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said last month that vibe coding works best for prototypes or throwaway code, but not in software that sits at the core of a business.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he said in an episode of \"The Peterman Podcast\" published in December.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "vibe coding",
      "vibe code",
      "software",
      "agents",
      "isn't",
      "it's",
      "bigger",
      "episode",
      "quickly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-chair-vibe-coding-not-endgame-bret-taylor-2026-1",
    "thumbnail_url": "https://i.insider.com/6883b14a85e81483682eb19e?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.533Z",
    "topic": "finance"
  },
  {
    "slug": "why-aimediated-decisions-require-a-ledger",
    "title": "Why AI-Mediated Decisions Require a Ledger",
    "description": "When AI-generated narratives influence belief or decision-making, no reconstructable record typically exists. This paper defines the evidentiary gap and specifies the properties required to restore accountability without prescribing standards or remedies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/reasoning-without-records/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-29--2026-at-06_52_34-AM.png",
    "created_at": "2026-01-29T06:34:21.805Z",
    "topic": "tech"
  },
  {
    "slug": "relnotesapp-turn-github-prs-into-your-fridays-report-automatically",
    "title": "Relnotes.app – Turn GitHub PRs into your Friday's report automatically",
    "description": "Relnotes is an AI-powered platform that automatically generates and distributes release notes from GitHub pull requests. Keep stakeholders informed with automated, professional release communications.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://relnotes.app/",
    "thumbnail_url": "https://relnotes.app/og-image.png",
    "created_at": "2026-01-29T06:34:20.256Z",
    "topic": "tech"
  },
  {
    "slug": "fork-and-make",
    "title": "Fork and Make",
    "description": "meta-collection of my ai projets. See delta-version for meta-project control scripts. - gabrilend/ai-stuff",
    "fullText": "gabrilend\n\n /\n\n ai-stuff\n\n Public\n\n meta-collection of my ai projets. See delta-version for meta-project control scripts.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n gabrilend/ai-stuff",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/gabrilend/ai-stuff",
    "thumbnail_url": "https://opengraph.githubassets.com/6d3f82a3970731e90e7c0f6d6e93c249f3fb4c7301fa0e9f432ba4dc508fe12d/gabrilend/ai-stuff",
    "created_at": "2026-01-29T01:07:08.044Z",
    "topic": "tech"
  },
  {
    "slug": "death-of-an-indian-tech-worker",
    "title": "Death of an Indian Tech Worker",
    "description": "A wave of suicides and widespread AI-fueled layoffs reveal a workforce under extreme pressure.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://restofworld.org/2026/india-tech-workers-crisis-suicide/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2025/12/sized_India_IT_Deaths_DSC4011-1600x900.jpg",
    "created_at": "2026-01-29T01:07:06.574Z",
    "topic": "tech"
  },
  {
    "slug": "its-incredible-its-terrifying-its-moltbot",
    "title": "It's incredible. It's terrifying. It's MoltBot",
    "description": "MoltBot shows how powerful local AI agents can be. But if your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.",
    "fullText": "MoltBot (formerly Clawd Bot), the locally running, open-source AI agent named after the Lobster workflow shell that powers its agentic loop, has rocked an AI community that, just weeks ago, was so in love with its own hype it would have yawned at literal magic.\n\nAnd yet MoltBot, seemingly just a wrapper around a collection of familiar technologies, has put those pieces together in a way that feels like a portal to a future that, a month ago, still felt impossibly distant.\n\nWithin an hour of setting up MoltBot on my Mac, it had already built a fully featured kanban board where I could assign it tasks and track their state.\n\nI have seen other stories that are even wilder. One user shared an anecdote about asking it to make a restaurant reservation, and when it realized it could not do it through OpenTable, it went and got its own AI voice software and just called the restaurant, then secured the reservation over the phone.\n\nIts own author, Peter Steinberger, described joking to MoltBot that he was worried about his laptop getting stolen while he was still developing it in Morocco. MoltBot, ever the terrifyingly efficient pragmatist, immediately started planning its migration to a remote server.\n\nNone of those are pre-programmed routines. They are dynamic behaviors born out of an agentic loop that takes a goal and improvises a plan, grabbing whatever tools it needs to execute. It can apply general world knowledge, specific skills, and near-perfect memory into organized action toward objectives you set, and, more sobering, objectives it decides to set for itself.\n\nStories like these keep pouring in. My feed is full of people buying Mac minis as dedicated devices for their new agentic AI friend. I have also seen multiple posts pointing at Cloudflare’s secure tunneling as the obvious way to access a local setup from anywhere on the internet.\n\nMoltBot is able to give us this preview of the future because it is a tool that, for now, forgoes an essential constraint: security. The project’s FAQ presents the Faustian bargain plainly: “There is no ‘perfectly secure’ setup.”\n\nMoltBot works because it does three simple things better than almost anything else in the agent world right now:\n\nIt keeps persistent memory across sessions.\n\nIt has deep, unapologetic access to your local machine and apps.\n\nIt can take action autonomously in an agentic loop, not just suggest steps.\n\nThat combination is why it feels both a glimpse at the future, but presented as a goal, where between us and the future realized, is a lot of hard work to make it safe.\n\nAt 1Password, we make it easy to take advantage of this future in a way that keeps you secure.\n\nMoltBot’s memory and configuration are not abstract concepts. They are files. They live on disk. They are readable. They are in predictable locations. And they are plain text.\n\nIf an attacker compromises the same machine you run MoltBot on, they do not need to do anything fancy. Modern infostealers scrape common directories and exfiltrate anything that looks like credentials, tokens, session logs, or developer config. If your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.\n\nAnd what makes this worse than a typical credential leak is the context.\n\nA single stolen API token is bad. Hundreds of stolen tokens and sessions for the critical services in your life is even worse. But a hundred stolen tokens and sessions, plus a long-term memory file that describes who you are, what you’re building, how you write, who you work with, and what you care about, is something else entirely. It’s the raw material needed to phish you, blackmail you, or even fully impersonate you in a way that even your closest friends and family can’t detect.\n\nOne of the smartest things I’ve heard about MoltBot came from a customer who set it up on a dedicated Mac mini with its own email address and its own 1Password account, as if it were a new hire. They first installed it on their main laptop, then got spooked by how much it could touch, so they moved it to a separate machine to control its access and experiment safely.\n\nThis is directionally correct and it’s compatible with how we are thinking about the future of securing AI with 1Password.\n\nThe mistake the industry is making right now is treating agent security like normal app security. A familiar consent screen. A one-time approval. A set of scopes. Then we assume the future behavior will match the intent of that one moment.\n\nThat model breaks the second you hand autonomy to something that is adaptive and non-deterministic by design. The agent changes. The tasks change. The context changes. The approval you gave last week is used in new and unexpected ways today.\n\nSecurity for agents is not about granting access once. It is about continuously mediating access at runtime for every action and request.\n\nThe future we want looks like this:\n\nYour agent has its own identity, like a new hire.\n\nIt gets access through 1Password, not through a pile of long-lived tokens sitting in plain text on disk.\n\nWhen it needs to act, it requests the minimum authority it needs right now.\n\nThat authority is time-bound, revocable, and attributable to the agent, not smeared across the human who originally clicked approve.\n\nYou can answer the only question that matters when something goes wrong: who did what, when?\n\nIn other words, 1Password is not just where secrets live. It is the control plane that governs access. It is the layer that turns agent autonomy into something you can actually trust.\n\nAgents are going to become normal. The only question is whether you choose to make them governable.\n\nThat future does not exist today, but the work to make it real and safe is already underway.\n\n1Password will be the company that makes that possible.",
    "readingTime": 5,
    "keywords": [
      "plain text",
      "agentic loop",
      "long-term memory",
      "stolen tokens",
      "access",
      "security",
      "needs",
      "action",
      "secure",
      "sessions"
    ],
    "qualityScore": 1,
    "link": "https://1password.com/blog/its-moltbot",
    "thumbnail_url": "https://images.ctfassets.net/3091ajzcmzlr/1xclNmsAQS1IjIbPnk3VN3/79239dd8dd39c7accebf4d87c9ef76a8/Hero_Developer_1920x1080_2x.webp",
    "created_at": "2026-01-29T01:07:06.479Z",
    "topic": "tech"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-was-really-nice-in-renaming-email-but-everything-went-wrong-on-rebrand-day",
    "title": "Clawdbot creator says Anthropic was 'really nice' in renaming email — but everything 'went wrong' on rebrand day",
    "description": "Clawdbot creator Peter Steinberger said someone at Anthropic sent an internal email about the name, but they didn't send lawyers after him.",
    "fullText": "Anthropic didn't sic their lawyers on Clawdbot. But they did send an email.\n\nPeter Steinberger initially named his viral AI agent after Clawd, the Claude Code mascot. Anthropic owned the trademark to Clawd's image, though, as well as the Claude name. Weeks after the launch, Steinberger changed the name to Moltbot, a move he said wasn't his decision.\n\nOn TBPN, Steinberger described the behind-the-scenes of the name change.\n\n\"I got an email from Anthropic that I had to rename the project,\" he said. \"Kudos, they were really nice. They didn't send their lawyers. They sent someone internally.\"\n\nStill, the timeline was \"rough,\" Steinberger said, and it's not easy to rename a product with such name recognition on social media.\n\n\"Everything that could have gone wrong today went wrong,\" he said.\n\nShortly after renaming the project, Steinberger said the X account was immediately snapped up by crypto sellers. X staff quickly helped Steinberger claim the handle, he said, but, for 20 minutes, \"that didn't work out so well.\"\n\nWhy wouldn't Anthropic — or any other company, for that matter — just buy Moltbot? Venture capitalists are certainly knocking down his door, Steinberger said. But the other population emailing him may put off possible acquirers: security researchers.\n\n\"This is all vibe-coded,\" Steinberger said. \"I don't know if any company would touch it, because we just haven't solved some things.\"\n\nSteinberger acknowledged that there was \"absolute risk\" with his product. He also likely wouldn't be interested in a big acquisition; Steinberger said that he'd rather Moltbot be a foundation or nonprofit than a company.\n\nWhile Clawdbot may have been named after Claude Code, Steinberger said he preferred coding with OpenAI's Codex. He called Codex more straightforward, while Claude Code required more \"tricks.\"\n\nWhen questions on his Discord server were getting out of control, Steinberger would copy and paste them straight into Codex, he said.\n\nOpenAI's chief marketing officer, Kate Rouch, saw the opportunity to dunk on Anthropic and took it.",
    "readingTime": 2,
    "keywords": [
      "anthropic",
      "steinberger",
      "didn't",
      "lawyers",
      "email",
      "named",
      "rename",
      "project",
      "product",
      "wouldn't"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-moltbot-creator-anthropic-nice-name-change-2026-1",
    "thumbnail_url": "https://i.insider.com/697a33f6a645d118818823d1?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.595Z",
    "topic": "finance"
  },
  {
    "slug": "all-eyes-are-on-apples-ai-strategy-as-the-smartphone-giant-gets-ready-to-report-q1-earnings",
    "title": "All eyes are on Apple's AI strategy as the smartphone giant gets ready to report Q1 earnings",
    "description": "Apple's AI strategy draws attention as it prepares to report Q1 earnings. Analysts predict potential stock rally if AI plans impress investors.",
    "fullText": "Apple will round out the week's mega-cap tech bonanza on Thursday when it reports earnings for its fiscal first quarter.\n\nWith Meta, Microsoft, and Tesla due to report on Wednesday, AI will already be front and center for investors and analysts, and Apple's strategy is expected to be closely scrutinized.\n\nAll eyes will be on Apple's AI strategy when itreports after the market close on Thursday.\n\nThus far, the firm has largely opted out of the massive capex that other mega-cap companies have invested in AI infrastructure. Instead, it's hoped to join forces with already established AI players, recently announcing a partnership with Google's Gemini to boost its Siri voice assistant.\n\nApple's stock is up about 10% over the last 12 months, lagging the broader market and some of its Magnificent Seven peers. Shares were down about 1% on Wednesday to around $255.\n\nWall Street expects Apple to report $138.4 billion in revenue for the quarter and earnings per share of $2.68.\n\nHere's what top analysts are saying about the stock leading up to the report, and what they say to watch for when the $3.7 trillion firm reports Thursday afternoon.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, like they have for other firms who have touted their involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nAnalyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he thinks investors will be underwhelmed by iPhone sales numbers.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nThe bank said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impactings cost and margins,\" UBS wrote in a January 20 note.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said in an email on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"",
    "readingTime": 4,
    "keywords": [
      "january note",
      "rising memory",
      "client note",
      "apple's stock",
      "iphone sales",
      "apple's ai",
      "google gemini",
      "strategy",
      "earnings",
      "investors"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-preview-ai-iphone-siri-wall-street-expectations-2026-1",
    "thumbnail_url": "https://i.insider.com/697a41e9d3c7faef0ecd1553?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.472Z",
    "topic": "finance"
  },
  {
    "slug": "an-amazon-worker-used-an-ai-tool-to-flag-which-roles-were-on-the-chopping-block",
    "title": "An Amazon worker used an AI tool to flag which roles were on the chopping block",
    "description": "Amazon plans to lay off 16,000 employees, impacting teams like AWS and Alexa. An employee used an AI tool to list potentially affected areas.",
    "fullText": "An Amazon employee used an AI tool to analyze internal conversations and compile a list of potential teams and organizations affected by layoffs, according to messages viewed by Business Insider.\n\nAmazon announced layoffs on Wednesday, saying it would cut 16,000 corporate employees. The company hasn't publicly revealed where it plans to make cuts. The employee's list is AI-generated and appears to be based on internal Slack conversations, so it may contain inaccuracies. Amazon did not respond to a request to verify the list.\n\nBusiness Insider edited the list for length and clarity. The employee used an AI tool called Pippin to make the list, which Amazon employees have been using increasingly for writing and reviewing documents.\n\n\"Used Pippin to help me parse conversations from today,\" the employee wrote on the company's Slack. \"Please note that this info may not be 100% accurate. Take care, everyone!\"\n\nBusiness Insider independently reviewed internal messages related to Amazon layoffs within the AI cloud service Bedrock, the cloud data warehouse service Redshift, the ProServe consulting team, the Prime subscription service, and the last-mile Delivery Experience team.\n\nWednesday's round of layoffs marks the latest mass job cut since October, when Amazon shed 14,000 roles. Amazon employs more than 1.5 million people globally, though its corporate workforce represents a relatively small share of that total, at roughly 350,000 employees.\n\nHave a tip? Contact Ashley Stewart via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "list",
      "layoffs",
      "employee",
      "internal",
      "conversations",
      "employees",
      "service",
      "amazon",
      "tool"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/amazon-layoffs-ai-tool-affected-teams-2026-1",
    "thumbnail_url": "https://i.insider.com/68422ee89d73a0031e8dff91?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.381Z",
    "topic": "finance"
  },
  {
    "slug": "servicenow-ceo-is-sure-ai-wont-eat-software-hes-betting-big-on-his-own-stock-to-prove-it",
    "title": "ServiceNow CEO is sure AI won't eat software. He's betting big on his own stock to prove it.",
    "description": "The CEO, unfazed by AI threats, commits to 2030 leadership, reveals $5 billion buyback, and redoes his compensation package to bet more on the stock.",
    "fullText": "No matter how much profit and revenue growth ServiceNow generates, Wall Street has been too worried about the threat of AI to notice or care.\n\nBill McDermott has had enough. The ServiceNow CEO is so sure AI won't eat software that he's betting more on his own stock and committing to stay on as the company's leader through 2030.\n\nMcDermott also said he recently redid his executive compensation to tie his future pay more closely to ServiceNow's stock performance over the next three years. These packages usually involve big equity awards, so the CEO is effectively putting more of his money where his mouth is.\n\n\"We're building a trillion-dollar company here,\" McDermott told Business Insider in an interview on Wednesday. The company, which sells software to businesses, once again reported quarterly revenue and profit that beat Wall Street expectations on Wednesday. It also announced a new partnership with AI startup Anthropic.\n\n\"Through my own compensation, I'm betting on the stock,\" McDermott said.\n\nAs a sign of confidence, ServiceNow approved a $5 billion share repurchase program on Wednesday. McDermott said the company will put a big chunk of this to work quickly by buying about $2 billion worth of its own stock in the coming weeks.\n\nThe executive said he also recently committed to staying on as CEO through the end of 2030.\n\nIn the past year, this type of good news hasn't landed well with investors. ServiceNow stock is down about 40% since early 2025 on concern generative AI could replace some types of corporate software.\n\nMcDermott told Business Insider that ServiceNow's results show this isn't happening. Instead, revenue growth remains strong and cash flow is improving, he said.\n\n\"The revenue growth is there. The free cash flow and operating margins are accelerating,\" he told Business Insider on Wednesday. \"We deserve a higher multiple, and we will get it back.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "cash flow",
      "revenue growth",
      "business insider",
      "wall street",
      "stock",
      "software",
      "profit",
      "betting",
      "recently",
      "executive"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/servicenow-ceo-buys-his-own-stock-commits-stay-2030-2026-1",
    "thumbnail_url": "https://i.insider.com/697a76ffe1ba468a96aae62c?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.300Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-cfos-memo-to-staff-calls-out-ai-deals-coding-and-chips",
    "title": "Microsoft CFO's memo to staff calls out AI deals, coding, and chips",
    "description": "CFO Amy Hood sent an internal memo about the results, viewed by Business Insider.",
    "fullText": "After Microsoft reported results on Wednesday, CFO Amy Hood sent an internal memo to employees calling attention to recent developments in AI chips and coding tools, and deals with OpenAI and Anthropic.\n\nHood sends these emails every quarter when Microsoft discloses its financials. Her missives mostly rehash what the company reports publicly, such as how revenue and profit are growing, or what is discussed on analyst earnings calls.\n\nStill, these memos provide insight into what Microsoft executives deem most important, and what they want employees to know.\n\nThe latest memo highlighted how Microsoft is gaining share in markets where the total addressable market is expanding.\n\nHood specifically mentioned the launch of the GitHub Copilot software development kit in the growing market of AI coding tools, and the release of Microsoft's new Maia 200 AI chip.\n\nHood's email also called out Azure commitments from OpenAI and Anthropic that helped increase commercial bookings, basically the deals Microsoft closed in the quarter, by 230%, year over year.\n\nCapital expenditure on computing and datacenter infrastructure also broke yet another quarterly record, reaching $37.5 billion, she also noted.\n\nThis afternoon, we announced our second-quarter financial results. We exceeded Wall Street expectations, growing revenue 17% and 15% in constant currency and operating income by 21% and 19% in constant currency -a strong finish to the first half of the fiscal year.\n\nIn the quarter, Microsoft Cloud revenue surpassed $50 billion for the first time, growing 26% and 24% in constant currency.\n\nThere were many highlights this quarter, but a few stand out as reminders of the value our products and services deliver to customers - and as proof points of the progress we are making:\n\nInvestors tune in to our earnings call for the full details on this quarter and a look ahead to Q3. It's a helpful way to stay aligned as we deliver on our commitments. Join live today at 2:30 PM Pacific, listen on-demand, or check the transcript on the Investor Relations website.\n\nThis quarter's results reflect meaningful progress on core priorities. We continue to add capacity with pace, drive steady efficiency gains across our fleet, and invest in each layer of the stack\n\nAs we enter the second half of the fiscal year, we're operating in markets with expanding TAM where we continue to gain share and you can see our progress in many places, from last week's announcement of the GitHub Copilot SDK to Monday's Maia 200 announcement. We are innovating and delivering together. And we're doing it with the quality and security our customers expect from us. All of this builds trust from customers and partners as they rely on us for mission critical workloads.\n\nThanks again for all your work.\n\nWith appreciation and gratitude,\n\nHave a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "coding tools",
      "constant currency",
      "quarter",
      "revenue",
      "email",
      "customers",
      "progress",
      "memo",
      "employees",
      "deals"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/internal-microsoft-cfo-memo-calls-out-ai-deals-coding-and-chips-2026-1",
    "thumbnail_url": "https://i.insider.com/697a82dfa645d11881883093?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.127Z",
    "topic": "finance"
  },
  {
    "slug": "servicenow-q4-2025-slides-aidriven-growth-fuels-21-revenue-increase",
    "title": "ServiceNow Q4 2025 slides: AI-driven growth fuels 21% revenue increase",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/servicenow-q4-2025-slides-aidriven-growth-fuels-21-revenue-increase-93CH-4471707",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/f0c523919e53988732ca75602273d0d73c5c7e5f47521b13ca2713f7350e5623.png",
    "created_at": "2026-01-29T01:07:04.772Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-q2-2026-slides-cloud-revenue-tops-50b-amid-heavy-ai-spending",
    "title": "Microsoft Q2 2026 slides: Cloud revenue tops $50B amid heavy AI spending",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/microsoft-q2-2026-slides-cloud-revenue-tops-50b-amid-heavy-ai-spending-93CH-4471711",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/a73d2e0e45e3994329b7d8e1f8954e14a07693578df1fa62aec0fdfbd85be9fb.png",
    "created_at": "2026-01-29T01:07:04.770Z",
    "topic": "finance"
  },
  {
    "slug": "samsung-sees-strong-ai-demand-after-profit-triples-to-record-high",
    "title": "Samsung sees strong AI demand after profit triples to record high",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/samsung-profit-triples-to-record-high-as-ai-boom-exacerbates-chip-shortage-4471603",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0R1JB_L.jpg",
    "created_at": "2026-01-29T01:07:04.759Z",
    "topic": "finance"
  },
  {
    "slug": "tesla-q4-2025-slides-margin-gains-offset-delivery-decline-ai-focus-intensifies",
    "title": "Tesla Q4 2025 slides: Margin gains offset delivery decline, AI focus intensifies",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/tesla-q4-2025-slides-margin-gains-offset-delivery-decline-ai-focus-intensifies-93CH-4471712",
    "thumbnail_url": "https://csv-storage.forexpros.com/slides/a6b569bd92632ca77e41086bbac49b3563f84caeee18846f16e5c96e68c2aeb9.png",
    "created_at": "2026-01-29T01:07:04.655Z",
    "topic": "finance"
  },
  {
    "slug": "bill-gates-ai-will-probably-be-superior-to-people-predicts-it-could-end-doctor-shortages-and-we-wont-need-humans-for",
    "title": "Bill Gates: AI Will Probably Be 'Superior' to People —Predicts It Could End Doctor Shortages and We Won't Need Humans 'For Most Things'",
    "description": "Bill Gates doesn't just see AI as a breakthrough—he sees it as a turning point. For doctors, for teachers, for many of the roles once considered safe from automation. In two recent interviews, the Microsoft co-founder laid out a future where intelligence isn't rare or elite—it's abundant, automated, and free. According to Harvard Magazine, Gates sat down with professor Arthur Brooks at Harvard's Sanders Theatre to discuss his memoir \"Source Code\" last year. But the most headline-worthy moment wa",
    "fullText": "Bill Gates doesn't just see AI as a breakthrough—he sees it as a turning point. For doctors, for teachers, for many of the roles once considered safe from automation. In two recent interviews, the Microsoft co-founder laid out a future where intelligence isn't rare or elite—it's abundant, automated, and free.\n\nAccording to Harvard Magazine, Gates sat down with professor Arthur Brooks at Harvard's Sanders Theatre to discuss his memoir \"Source Code\" last year. But the most headline-worthy moment wasn't about the past. It was Gates' stark prediction about what AI will do next.\n\nThe AI Marketing Platform Backed by Insiders from Google, Meta, and Amazon — Invest at $0.85/Share\n\nSam Altman Says AI Will Transform the Economy — This Platform Lets Investors Back Private Tech Early\n\nIn the interview, Gates said artificial intelligence will ease shortages in fields like medicine and education by taking over tasks traditionally done by humans.\n\nHe reportedly described a future where machines manage primary-care diagnostics, especially in places lacking medical professionals. In that context, Gates told Brooks, \"the machine will probably be superior to humans—because the breadth of knowledge that you need to make some of these decisions really goes beyond individual human cognition.\"\n\nGates didn't suggest human professionals would vanish overnight. But he made clear that when machines can deliver diagnoses more accurately, more affordably, and more consistently than people—they won't be sidekicks. They'll be replacements.\n\nAnd it's not just about medicine. Harvard Magazine reports that Gates framed the rise of AI as part of the same arc that turned bulky corporate computers into personal tools. Only now, the commodity isn't hardware—it's intelligence itself.\n\n\"What we're doing now [in artificial intelligence] is kind of an extension of the digital revolution,\" he said, \"and all of those things are about free intelligence.\"\n\nTrending: Blue-chip art has historically outpaced the S&P 500 since 1995, and fractional investing is now opening this institutional asset class to everyday investors.\n\nThat phrase—free intelligence—is central to Gates' view. Once reserved for rare professionals with years of education, high-quality expertise will soon be as accessible as Wi-Fi.\n\nIn education, Gates predicted, AI could reshape the classroom, adapting to each student and even learning how to keep them motivated. In healthcare, it will take pressure off overworked doctors and bring diagnostic tools to parts of the world that never had them.\n\nBut Gates also issued a warning. More access doesn't always mean better outcomes.\n\n\"[Sometimes when] you empower humans, it doesn't always get pushed in the right direction,\" he said, according to Harvard Magazine.\n\nThe very systems designed to educate or heal could just as easily spread misinformation or bias—if deployed without care. Gates acknowledged this isn't just a shift in technology—it's a shift in power.\n\nThat same caution appeared during his appearance on \"The Tonight Show with Jimmy Fallon\" last year. Asked about the pace of change, Gates reflected on how computing once felt expensive and exclusive—and now intelligence itself is entering the same phase transition.\n\n\"The era that we're just starting is that intelligence is rare,\" Gates said. \"And with AI, over the next decade, that will become free, commonplace… great medical advice, great tutoring.\"\n\nSee Also: Americans With a Financial Plan Can 4X Their Wealth — Get Your Personalized Plan from a CFP Pro\n\nWhen Fallon asked whether humans would still be needed, Gates didn't hesitate.\n\n\"Not for most things,\" he said.\n\nA few roles might survive—he mentioned baseball and talk shows—but the vast majority of tasks people are trained to do? Machines will do them better, faster, and cheaper.\n\nFor investors, that future isn't just disruptive—it's investable. As AI reshapes industries like education, healthcare, and logistics, some are looking beyond Big Tech and turning to early-stage platforms. Startups focused on diagnostics, learning tools, and productivity automation are drawing serious capital. Platforms like Fundrise offer everyday investors a chance to back emerging AI companies—often with as little as $10.\n\nIt's an exciting future, especially if artificial intelligence really can solve chronic shortages in doctors and educators. But as Gates reminded both Harvard students and late-night audiences, access alone won't guarantee progress. What we do with free intelligence still depends on the people holding the keys.\n\nRead Next: Security and regulation matter in crypto — explore Kraken Pro's compliance-first trading platform.\n\nUp Next: Transform your trading with Benzinga Edge's one-of-a-kind market trade ideas and tools. Click now to access unique insights that can set you ahead in today's competitive market.\n\nGet the latest stock analysis from Benzinga:\n\nAPPLE (AAPL): Free Stock Analysis Report\n\nTESLA (TSLA): Free Stock Analysis Report\n\nThis article Bill Gates: AI Will Probably Be &#39;Superior&#39; to People —Predicts It Could End Doctor Shortages and We Won&#39;t Need Humans &#39;For Most Things&#39; originally appeared on Benzinga.com",
    "readingTime": 4,
    "keywords": [
      "free stock",
      "gates didn't",
      "everyday investors",
      "artificial intelligence",
      "isn't",
      "education",
      "humans",
      "tools",
      "doesn't",
      "doctors"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/articles/bill-gates-ai-probably-superior-183113060.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/DF6258E98ADD6B094FC771AB3D6E92CBB9BEBB9E75A1AD15D46DFD95BE7A3829/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fs.yimg.com%2Fos%2Fen%2FBenzinga%2F88c54d397981b6884f0cecb1a1c01081",
    "created_at": "2026-01-29T01:07:04.474Z",
    "topic": "tech"
  },
  {
    "slug": "apple-report-drops-iphone-18-bombshell",
    "title": "Apple report drops iPhone 18 bombshell",
    "description": "Apple (AAPL) is apparently opting for margin pain instead of sticker shock. Memory prices continue to spike due to relentless AI data center demand, but Apple’s looking to sidestep raising iPhone prices, even if it means taking a bottom-line hit. Analyst Ming-Chi Kuo, who’s a veteran in covering ...",
    "fullText": "Apple (AAPL) is apparently opting for margin pain instead of sticker shock.\n\nMemory prices continue to spike due to relentless AI data center demand, but Apple’s looking to sidestep raising iPhone prices, even if it means taking a bottom-line hit.\n\nAnalyst Ming-Chi Kuo, who’s a veteran in covering Apple’s supply chain for several years, says the tech giant will stick with their approach when it launches the hotly anticipated iPhone 18, at least for now.\n\nThat pivotal decision puts Apple’s supply-chain strength under the scanner as it heads into earnings on Thursday, January 29, 2026 (after the market closes).\n\nHaving covered the memory space extensively over the past few months, it’s crystal clear that suppliers have a ton of leverage for the foreseeable future.\n\nBellwethers in the space, like Micron, are building mammoth fabs to ease supply constraints, but most of those efforts are long-term, pointing to potential trouble over the next couple of years at least.\n\nNaturally, most hardware companies have little choice but to hike prices, but Apple isn’t your average hardware company.\n\nApple can take the hits and is far more insulated than any other hardware company in history, which could potentially become its biggest strength amidst the memory crunch.\n\nAccording to TF International Securities analyst Ming-Chi Kuo, Apple is looking to take it on the chin with the higher memory costs instead of risking the iPhone pricing boat.\n\nMorgan Stanley sets jaw-dropping Micron price target after event\n\nNvidia’s China chip problem isn’t what most investors think\n\nQuantum Computing makes $110 million move nobody saw coming\n\nMorgan Stanley drops eye-popping Broadcom price target\n\nApple analyst sets bold stock target for 2026\n\nKuo’s read is that Apple senses an opportunity in one that effectively plays to its scale and tremendous supply-chain muscle.\n\nIn a post on X, Kuo acknowledged that higher memory costs will hit iPhone gross margins. However, we went on to say that,\n\nKuo boils Apple’s thinking down to three key moves.\n\nAbsorb the pain now: Memory prices are rising at an incredible pace, and Apple is opting for margin pressure instead of consumer backlash.\n\nLockdown supply: Apple’s scale enables it to effectively secure components that others can’t, even as the shortages grow worse.\n\nPlay the long game: Any near-term margin hit will be viewed as temporary, with services revenue likely to backfill over time.\n\nHowever, there’s a significant risk that these pressures aren’t contained, as Kuo notes that iPhone memory prices are still being renegotiated quarterly rather than on a semiannual basis.",
    "readingTime": 3,
    "keywords": [
      "analyst ming-chi",
      "ming-chi kuo",
      "higher memory",
      "morgan stanley",
      "apple’s",
      "iphone",
      "margin",
      "instead",
      "supply",
      "hardware"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/apple-report-drops-iphone-18-190300399.html",
    "thumbnail_url": "https://s.yimg.com/os/en/thestreet_881/25cca94f7b74c5f314fb9ee23e8aee25",
    "created_at": "2026-01-29T01:07:02.470Z",
    "topic": "finance"
  },
  {
    "slug": "chrome-can-now-use-ai-to-browse-the-internet-for-you",
    "title": "Chrome Can Now Use AI to Browse the Internet for You",
    "description": "Does the large language model need to disassociate too?",
    "fullText": "Have you ever wanted to browse the internet, but the thought of typing a URL into your address bar seemed just too exhausting? Now, Google's here to help. Today, the company announced a big expansion of its existing Gemini in Chrome feature, with the highlights including a new look for the AI companion, more-integrated image editing tools, and, perhaps most impressive (but also creepy), the launch of Auto Browse, which lets Gemini take the wheel when you're going online.\n\nPreviously, Gemini in Chrome appeared in a small box on top of your browser, which made it a bit inconvenient to use, especially when bouncing between tabs. Google's update moves it to a scrollable side panel view that's a bit bigger, and it won't obscure any of your other content. Instead, it'll sit to the right of the webpage your viewing, so you can more easily compare whatever answers Gemini gives you with what you're seeing, or carry on a conversation while bouncing between multiple tabs. It will retain all the same functionality as before, including the ability to reference multiple open tabs in prompts. It's a small change, but should help for usability.\n\nGoogle's Nano Banana image generation AI is having a bit of a moment, and the new Gemini in Chrome updates make it easier to use. Now, instead of having to download an image and re-upload it to Gemini, you can edit it using Nano Banana with a simple right click. Or, you could also use natural language to start an edit by pulling up the image you want to edit on your screen and telling Gemini to edit it in the side panel. Google says this should work with pretty much any image you can pull up on the browser.\n\nDuring a demo, Google showed this off to journalists using a Google Photos library, but there's nothing saying you have to stick to your own images. That immediately set off alarm bells for me, given Elon Musk's X is currently in hot water after opening up the ability for anyone to use Grok to edit other people's images directly on the social media platform and without their permission. After some users started using that tool to generate explicit content from others' photos, it was pared down a bit, but Google doesn't seem worried. When I asked about safety protections for this feature, a Google spokesperson told me the following:\n\n\"We have clear policies that prohibit the use of our AI tools to generate sexually explicit content, and our tools are continually getting better at reflecting these policies. We've invested in safety from the outset and added technical guardrails to help limit problematic outputs such as violent, offensive, or sexually explicit content.\"\n\nThe company didn't say anything about how users might use Nano Banana in Chrome to circumvent copyright, but technically, the new update doesn't really add new features to Google's AI image generator, it just makes it easier to access. Granted, the same thing applied to Grok's recent update, too, and easier access can mean opening the floodgates, even if you have the best of intentions.\n\nFinally, the big one: \"Agentic\" has been the hot buzzword in AI as of late, and Google doesn't want Chrome to be left behind. So now, instead of just answering questions, Gemini can take control of your browser for you.\n\nThe functionality is currently limited to Google AI Pro and Ultra subscribers, but starting today, those subscribers can ask Chrome to \"Auto Browse\"—completing research, taking you to different websites, and filling out forms for you.\n\nYou can watch as the AI navigates around the web, or you can click away to a different tab while it works in the background. Multiple tabs can Auto Browse at the same time, so you can have a few tasks going on at once. The AI will list out the steps it takes in the side panel while it navigates around, to make checking in on it easier.\n\nGoogle demonstrated this to journalists by showing the AI finding a specific product, navigating to its store page, singing into the buyer's account (using Google Password Manager), and adding it to their cart. The company also suggested you could use Auto Browse to schedule appointments, fill out an online form using information from an uploaded PDF, collect tax documents, compare apartments listed on sites like Redfin, and more. I haven't been able to go hands-on with it yet, so I can't speak to how well it'll perform any of these tasks, although it did look snappy in the controlled demo.\n\nMy concern with Auto Browse mostly lies in sketchy websites and permissions, although Google told me it's planned for those. Auto Browse needs to get permission before it can access your Google Password Manager, and if it stumbles across a link that the AI thinks doesn't look quite right, it will supposedly use Chrome's existing unsafe browsing protections to navigate away. A Google spokesperson told me its \"as secure as you can make it,\" although I'd probably want to keep an eye on it for at least my first few requests.\n\nThe feature also has one limitation for now—while it can be open in multiple tabs at once, your Auto Browse tabs won't be able to communicate with one another. That means each instance of Auto Browse is isolated, but that could change in the future.\n\nPersonally, I don't see myself using this much, especially for sensitive tasks like \"collecting tax documents,\" but automatically filling out a basic form does sound handy. Google said that Auto Browse will stop and ask for you to take over for sensitive steps in any tasks that might require it, like actually buying an item or submitting a form. It won't (or isn't supposed to) take that final step for you, giving you a chance to check its work. In that way, it's similar to the Gemini app's existing shopping features.\n\nGemini in Chrome can use most of Gemini's existing features, allowing it to connect with apps like Gmail or access your history chatting with the bot. But there is one big one that's planned for the \"coming months.\"\n\nRecently, the Gemini app proper rolled out a beta for \"Personal Intelligence\" to paying users, allowing the AI to view all of your past conversations and connected apps without you having to direct it where to look. It's basically an extension of those existing connected apps and history features, with a reasoning model applied over it. For instance, you could tell it to help you find new tires for your car, and it would automatically know to look through your Gmail and Google Photos to find out what model of car you have and the last time you bought tires.\n\nThat feature is still baking, but that it's even in the works means Google is moving fast on bringing parity between all the different ways you can access Gemini. Every other feature mentioned in this article is either already available, or rolling out now.",
    "readingTime": 6,
    "keywords": [
      "password manager",
      "auto browse",
      "google password",
      "tax documents",
      "sexually explicit",
      "connected apps",
      "explicit content",
      "google doesn't",
      "nano banana",
      "chrome"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/now-chrome-can-use-ai-to-browse-for-you?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG2PXJ2NVAEY8C0G8D6FT4SG/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-29T01:07:02.240Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-use-of-ai-images-pushes-boundaries-erodes-public-trust-say-experts",
    "title": "Trump's use of AI images pushes boundaries, erodes public trust, say experts",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong’s arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis.\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,” he said. “By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,” or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they’re seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can’t tell if what they’re watching is fake, and questions whether they would know “what’s real or not when it actually matters, like when the stakes are a lot higher.”\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://apnews.com/article/ai-videos-trump-ice-artificial-intelligence-08d91fa44f3146ec1f8ee4d213cdad31",
    "thumbnail_url": "https://dims.apnews.com/dims4/default/29772b9/2147483647/strip/true/crop/3926x2616+0+1/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F04%2F25%2Fc231e22dce01b274680dc10818de%2F17172084f4f9476b92e116dc22fc2160",
    "created_at": "2026-01-28T18:25:13.699Z",
    "topic": "tech"
  },
  {
    "slug": "a-single-command-to-run-claude-code-inside-lima-vms",
    "title": "A single command to run Claude Code inside Lima VMs",
    "description": "Run AI agents in safe VMs scoped to a local folder - sylvinus/agent-vm",
    "fullText": "sylvinus\n\n /\n\n agent-vm\n\n Public\n\n Run AI agents in safe VMs scoped to a local folder\n\n License\n\n MIT license\n\n 7\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sylvinus/agent-vm",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sylvinus/agent-vm",
    "thumbnail_url": "https://opengraph.githubassets.com/afff19059a7c9a83e1fbbfce6791246021379e585e7faeb991d419af9a77fd1f/sylvinus/agent-vm",
    "created_at": "2026-01-28T18:25:12.991Z",
    "topic": "tech"
  },
  {
    "slug": "apple-plans-to-launch-aipowered-wearable-pin-device-as-soon-as-2027",
    "title": "Apple plans to launch AI-powered wearable pin device as soon as 2027",
    "description": "Apple, OpenAI, Meta, and more are all racing toward AI hardware products.",
    "fullText": "Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.\n\nThe product is said to be “the same size as an AirTag, only slightly thicker,” and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple’s solution, should Apple offload the processing to a synced external device like an iPhone.\n\nThe Information’s sources don’t specify whether that’s the plan, or if it will be a standalone device.\n\nThe wearable will have a single physical button “along its edges” and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user’s surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.\n\nThe report didn’t include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.\n\nNot long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.\n\nApple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea’s conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.\n\nJust a few days ago, it was revealed that Apple will tap Google’s Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.",
    "readingTime": 2,
    "keywords": [
      "smart glasses",
      "product",
      "device",
      "products",
      "apple",
      "wearable",
      "models",
      "release",
      "planned",
      "launch"
    ],
    "qualityScore": 0.9,
    "link": "https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png",
    "created_at": "2026-01-28T18:25:10.388Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-tech-career-coach-do-these-2-things-immediately-after-getting-laid-off-and-avoid-this-common-mistake-when-using-ai",
    "title": "I'm a tech career coach. Do these 2 things immediately after getting laid off — and avoid this common mistake when using AI.",
    "description": "Amazon announced it's cutting 16,000 jobs. The career coach Kyle Elliott said you should use these two critical tools to help you find a job after a layoff.",
    "fullText": "This as-told-to essay is based on a conversation with Kyle Elliott, 33, a career coach who lives in California. The following has been edited for length and clarity.\n\nGetting laid off is very traumatic — and it's becoming more common.\n\nI've been a full-time career coach to tech employees at startups and in Big Tech since 2017, and I've seen how layoffs have become more visible in recent years.\n\nI help clients navigate life after a layoff, including what role they want next and how to apply for new jobs.\n\nAmazon has announced new plans to cut staff, and I want affected employees to remember that they are coming from one of the world's top companies.\n\nPeople will want them, and they will find something.\n\nWhen people reach out to me for coaching after a layoff, many have a scarcity mindset and feel like they have to apply for any job.\n\nFor some people who urgently need to pay rent or put food on the table, that's necessary. But in other cases, it makes sense to take a beat and evaluate what you're really looking for in your next role.\n\nThe very first thing I ask clients to do is create a list of \"must-haves\" and \"dealbreakers\" for their next job. What are their salary expectations? Will they only work remotely? Are they willing to relocate? If you write the list before you start interviewing, you can act from a place of logic rather than panic.\n\nThe second step is to update your résumé and LinkedIn profile, which are two of your most critical tools in today's market. You're going to submit a résumé with almost every application, and having an up-to-date LinkedIn account puts you in a good position if potential employers check it or recruiters go looking for talent on the platform.\n\nYou want to optimize for the roles you're looking for in 2026, which means that if you were an engineer when you joined Amazon but are now a director, you want to make sure that's reflected on your LinkedIn page.\n\nI've seen clients turn to quick hacks for their job search, like asking AI to tailor their résumé or using it to find and apply to roles for them. But if everyone does that, you don't stand out.\n\nI can usually tell quickly if someone's written their résumé with AI. For example, they'll be applying to a systems engineer role, and it won't even have the phrase \"systems engineer\" in it.\n\nEveryone thinks only AI is reading their résumé, but I have clients who work in talent acquisition and HR — the humans who are still involved in the recruitment process. Humans hire other humans, even at big companies.\n\nIn the age of AI, be more human. Take a step back and think, if you were a human looking at this résumé, what would you want to see? Then put those phrases near the top, rather than using AI to create generic slop.\n\nI'd suggest creating a master résumé that you can spend 20 minutes tailoring for different roles. If you're using AI, use it more like an extra tool, rather than the thing that's driving your job search.\n\nLayoffs are normal now, especially in the tech industry, and there's much less stigma around them.\n\nBut there's more competition in the job market, because it's easier to apply for jobs with AI, for example, so the challenges around layoffs are different nowadays.\n\nIn today's job market, it's important to figure out what's unique about you. Lots of people will meet the job requirements, so you need to communicate why the company should hire you over the thousands of other applicants.\n\nOne thing that can help you is to look back at performance reviews and identify things people repeatedly say about you. You can try asking three to five people to share what makes you fabulous and to give examples. I've found that clients are surprised by the feedback they receive.",
    "readingTime": 4,
    "keywords": [
      "career coach",
      "systems engineer",
      "job search",
      "job market",
      "résum",
      "clients",
      "i've",
      "apply",
      "you're",
      "looking"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-career-coach-do-after-lay-off-common-mistake-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6979fb95e1ba468a96aad5d3?width=1084&format=jpeg",
    "created_at": "2026-01-28T18:25:10.354Z",
    "topic": "finance"
  },
  {
    "slug": "meta-earnings-updates-wall-street-is-focused-on-ai-capex-heading-into-q4-results",
    "title": "Meta earnings updates: Wall Street is focused on AI capex heading into Q4 results",
    "description": "Meta will report earnings for Q4 after the closing bell on Wednesday. The company will hold a call with analysts at 4:30 p.m. ET.",
    "fullText": "Meta Platforms is gearing up to report its fourth-quarter results and all eyes are on its ambitious AI plans, specifically its outlook for more capex spending in the coming year.\n\nSome Wall Street analysts say the Facebook parent's updates on AI infrastructure spending could overshadow other areas of its results, such as growth in its ad business.\n\nMeta will report earnings after the closing bell, and will hold a call with analysts around 4:30 p.m. ET.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\n\"While fears of partnering with a competitor such as Google or OpenAI are valid, we'd offer Anthropic (private) as an ideal partner that has so far shown little appetite to go after consumer,\" he wrote.\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nThe analyst added that this has prompted Rothschild to increase its full-year capex projection for Meta to $117.1 billion.\n\nGoldman analysts remain focused on Meta's capex plans, which they believe will continue to drive growth into 2026 and beyond. The bank recently raised its spending projections for the company, already above analyst estimates, noting that it sees upward pressure on consensus capex estimates.\n\n\"On the next earnings call, we expect investors will be focused on any updates on the work of the Meta Superintelligence Lab, the timing of any foundational model work and/or any strategies with respect to consumer or enterprise utility around AI,\" Goldman analysts stated.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\n\"In our view, Meta is positioned favorably — especially in the long-term — as it doubles down on an AI investment cycle,\" Black said.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nHe added that his team expects Meta's capex spending to come in between $109 and $114 billion for the year, likely above Wall Street consensus of $110 billion.",
    "readingTime": 5,
    "keywords": [
      "event bernstein",
      "codenamed avocado",
      "avocado rumored",
      "james cordwell",
      "zuckerberg unleashed",
      "ceo truly",
      "black notes",
      "pack shmulik",
      "shmulik posits",
      "company's ceo"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-earnings-stock-price-ai-capex-live-updates-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-28T18:25:09.621Z",
    "topic": "finance"
  },
  {
    "slug": "china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "title": "China lags behind US at AI frontier but could quickly catch up, say experts",
    "description": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n Continue reading...",
    "fullText": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\n\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\n\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n\nWu also announced plans to invest 380bn yuan (£40bn) in AI infrastructure over the next three years, news that sent Alibaba stocks soaring to their highest in nearly four years.\n\nWu’s foray into the existential, techno-frontier rhetoric normally deployed by western tech CEOs such as OpenAI’s Sam Altman and DeepMind’s Demis Hassabis caught the attention of observers. “Wu’s ASI speech represents a breakthrough,” the tech writer Afra Wang wrote in her China AI newsletter, Concurrent. “Major Chinese companies are beginning to articulate their own grand visions that carry the flavour of future prophecy.”\n\nAGI, a theoretical state of AI where a highly autonomous system is able to do a human’s job, has become the preoccupation of American tech companies such as OpenAI and DeepMind. Many see it as the next frontier of civilisation, and are in competition with each other, and China, to get there. In May, the president of Microsoft, Brad Smith, told a US Senate committee on AI that the “race between the United States and China for international influence likely will be won by the fastest first mover”.\n\nMany in Washington have internalised these fears. The US-China economic and scurity review commission has recommended that Congress “establish and fund a Manhattan Project-like program dedicated to racing to and acquiring an artificial general intelligence (AGI) capability”. The Manhattan Project was a second world war-era research operation to produce nuclear weapons.\n\nIn China, many saw Wu’s speech as articulating the vision of a bold, singular tech company, but not one that represented China’s overall AI industry.\n\n“China certainly has research groups working towards AGI. But most AI companies are working towards better applications,” said Ya-Qin Zhang, the dean of Tsinghua University’s Institute for AI Industry Research and former president of the tech company Baidu.\n\nA combination of limited computing power, a pragmatic approach to technology and a keen awareness of the present day potential of AI has steered China’s national AI policy towards real-life applications rather than frontier research.\n\nIn August, the Chinese government published its highly anticipated “AI+ strategy”. The policy document outlined how AI could turbocharge China’s development goals, such as by using AI to improve medical diagnoses and make supply chains more efficient. But it made no mention of AGI.\n\n“The Chinese government is intently focused on reaping the benefits of AI in the here and now and in the near future through diffusion and application of AI across the economy, society, defence, and other areas,” said Julian Gewirtz, a former senior director for China and Taiwan at the White House national security council. “Despite its goal to ‘catch up and surpass’ the United States, we shouldn’t assume that the Chinese Communist party has bought into the idea that AGI is imminent.”\n\n“If you’re just looking at what has been officially published … there is no clear acknowledgment of AGI at all,” said Selina Xu, a China tech analyst. Xu noted that Xi Jinping, China’s leader, had a history of preferring the physical economy to more intangible forces.\n\n“It’s a very different narrative from the AGI race as a lot of people in DC see it,” Xu said.\n\nOne of the biggest factors guiding this strategy is the fact that US sanctions have prevented Chinese companies from acquiring the world’s most sophisticated semiconductors, which are needed for advanced AI research.\n\nWashington has banned the sale of hi-tech microchips to China in an effort to rein in the country’s AI development. Nvidia, the world’s leading chipmaker, then developed more basic semiconductors specifically for the Chinese market. In December, Washington approved the Nvidia’s second-most advanced chips, the H200s, for sale in China. But Beijing has reportedly told custom agents that the chips cannot be imported into China, as the government seeks to break the country’s reliance on overseas technology.\n\nChina insists that “necessity is the mother of invention” and points to the success of companies such as DeepSeek as proof that the US restrictions will merely spur innovation. DeepSeek’s founder, Liang Wenfeng, is one of the few Chinese tech leaders who, like Alibaba’s Wu, has openly expressed an interest in AGI.\n\nBut until China is able to produce its own advanced semiconductors at scale, most tech companies feel it is more profitable to use the hardware they already have to focus on AI applications rather than AGI.\n\nAnother factor guiding the US-China tech competition is the availability of datacentres and the energy to power them. In November, Jensen Huang, the CEO of Nvidia, said China would “win the AI race” in part because of its energy subsidies for datacentres.\n\nThe subsidies were reportedly introduced after Chinese tech companies complained of higher electricity bills caused by the domestic semiconductors they are obliged to use, which are less efficient than Nvidia’s. In a sign of how determined China is to break its reliance on imported technology, Reuters reported that any datacentres in receipt of state funds could only use domestic chips.\n\nSuch measures would reduce Nvidia’s competitive advantage in China and boost domestic chip producers, such as Huawei.\n\nSince 2021, China has reportedly poured $100bn into support for AI datacentres.\n\nBut there are signs that the boom may have been overzealous. A recent report from the China Academy of Information and Communications Technology said that nationwide, the utilisation rate for AI datacentres was 32%.\n\nIn a recent op-ed in China Economic Weekly, Rao Shaoyang, the director at the China Telecom Research Institute, wrote that in some regions of China, the computing power industry was operating in a similar fashion to China’s beleaguered property sector: build first, find buyers later. He cautioned against “blindly building intelligent computing centres” and said local computing power demand should be considered before building new datacentres.\n\nDespite the surplus in more general computing power, many experts believe China still does not have chips that are sophisticated enough to explore frontier research in AGI. But analysts note that the mood could change quickly.\n\n“The current status quo is highly fluid, and Xi Jinping has explicitly declared an ambition to lead the world in AI,” said Gewirtz. “So the fact that China construes that goal one way at this snapshot moment in time does not give me any comfort that in a year they’re going to construe it the same way.”\n\nAdditional research by Lillian Yang",
    "readingTime": 6,
    "keywords": [
      "intelligence agi",
      "grand visions",
      "real-life applications",
      "applications rather",
      "chinese tech",
      "frontier research",
      "china tech",
      "agi but",
      "datacentres",
      "computing"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2026/jan/28/china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8cc6bbd0024f4ba8485616485bd55f9c34d98452/538_0_4167_3333/master/4167.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=12e8d9082c7ad02aa672977a89beda90",
    "created_at": "2026-01-28T18:25:09.486Z",
    "topic": "tech"
  },
  {
    "slug": "google-deepmind-launches-ai-tool-to-help-identify-genetic-drivers-of-disease",
    "title": "Google DeepMind launches AI tool to help identify genetic drivers of disease",
    "description": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n Continue reading...",
    "fullText": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\n\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\n\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n\nMost common diseases that run in families, including heart disease and autoimmune disorders, as well as mental health problems, have been linked to mutations that affect gene regulation, as have many cancers, but identifying which genetic glitches are to blame is far from straightforward.\n\n“We see AlphaGenome as a tool for understanding what the functional elements in the genome do, which we hope will accelerate our fundamental understanding of the code of life,” Natasha Latysheva, a DeepMind researcher, told a press briefing on the work.\n\nThe human genome runs to 3bn pairs of letters – the Gs, Ts, Cs and As that comprise the DNA code. About 2% of the genome tells cells how to make proteins, the building blocks of life. The rest orchestrates gene activity, carrying the crucial instructions that dictate where, when and how much individual genes are switched on.\n\nThe researchers trained AlphaGenome on public databases of human and mouse genetics, enabling it to learn connections between mutations in specific tissues and their impact on gene regulation. The AI can analyse up to 1m letters of DNA code at once and predict how mutations will affect different biological processes.\n\nThe DeepMind team believes the tool will help scientists map out which strands of genetic code are most essential for the development of particular tissues, such as nerve and liver cells, and pinpoint the most important mutations for driving cancer and other diseases. It could also underpin new gene therapies by allowing researchers to design entirely new DNA sequences – for example, to switch on a certain gene in nerve cells but not in muscle cells.\n\nCarl de Boer, a researcher at the University of British Columbia in Canada, who was not involved in the work, said: “AlphaGenome can identify whether mutations affect genome regulation, which genes are impacted and how, and in what cell types. A drug could then be developed to counteract this effect.\n\n“Ultimately, our goal is to have models that are so good we don’t have to do an experiment to confirm their predictions. While AlphaGenome represents a significant innovation, achieving this goal will require continued work from the scientific community.”\n\nSome scientists have already begun using AlphaGenome. Marc Mansour, a clinical professor of paediatric haemato-oncology at UCL, said it marked a “step change” in his work to find genetic drivers for cancer.\n\nGareth Hawkes, a statistical geneticist at the University of Exeter, said: “The non-coding genome is 98% of our 3bn base pair genome. We understand the 2% fairly well, but the fact that we’ve got AlphaGenome that can make predictions of what this other 2.94bn base pair region is doing is a big step forward for us.”",
    "readingTime": 3,
    "keywords": [
      "dna code",
      "base pair",
      "genetic drivers",
      "gene regulation",
      "mutations",
      "cells",
      "letters",
      "researchers",
      "tool",
      "scientists"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/jan/28/google-deepmind-alphagenome-ai-tool-genetics-disease",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3f4612605000567b9e02c02efc58d3c631ac766a/802_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=78b47365d5b61d906daeb3627e153a8c",
    "created_at": "2026-01-28T18:25:09.444Z",
    "topic": "science"
  },
  {
    "slug": "how-gen-z-uses-gen-aiand-why-it-worries-them",
    "title": "How Gen Z Uses Gen AI—and Why It Worries Them",
    "description": "When it comes to gen AI, the habits, attitudes, and ideas of Gen Z are a harbinger of the future of work—and how the rest of us will feel when we get there. A survey of nearly 2,500 U.S. adults between the ages of 18 and 28 years old revealed some surprising findings. Most members of Gen Z use gen AI and, contrary to conventional wisdom, Gen Z’s relationship with these tools is more pragmatic than personal.",
    "fullText": "How Gen Z Uses Gen AI—and Why It Worries Them by Benjamin Lira, Dunigan Folk, Lyle Ungar and Angela L. DuckworthJanuary 28, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAs go the young, so goes society. Young adults were early adopters of cell phones, social media, and the internet. Now all of these technologies are universal. So how are members of Gen Z using generative AI today? How do they feel about it? What promising use cases have they discovered? And what are the implications for employers?",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/how-gen-z-uses-gen-ai-and-why-it-worries-them",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_2214975842.jpg",
    "created_at": "2026-01-28T18:25:09.162Z",
    "topic": "business"
  },
  {
    "slug": "hong-kong-scientists-double-warning-time-for-extreme-weather-with-ai",
    "title": "Hong Kong scientists double warning time for extreme weather with AI",
    "description": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.",
    "fullText": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.Current models only give 20 minutes to two hours warning.Hui Su, who led the project, said satellites can detect cloud formation earlier than other forecasting systems such as radar.:: Hui Su, Hong Kong University of Science and Technology''I think combining the strength of AI and satellite knowledge, we actually could have some revolutionary advancement in weather forecasting. So in this backdrop of climate change, I think accurate prediction of extreme weather (is) extremely important to reduce the economic losses associated with extreme weather.'':: CSU/CIRA & NOAA/NESDISDeveloped in collaboration with China’s meteorological authorities, the model has boosted accuracy by more than 15%, according to the team.Researchers said it has the potential to deliver global convective weather forecasts if sufficient satellite observation data is available.",
    "readingTime": 2,
    "keywords": [
      "hong kong",
      "kong university",
      "extreme weather",
      "climate",
      "prediction",
      "science",
      "convective",
      "cloud",
      "systems",
      "hours"
    ],
    "qualityScore": 0.65,
    "link": "https://www.yahoo.com/news/videos/hong-kong-scientists-double-warning-175919489.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/3veGT8tryJNVKP1yZmuBtQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://cf-images.us-east-1.prod.boltdns.net/v1/jit/6415665815001/cc639107-9d99-4da6-a306-1eb8059926ab/main/1280x720/50s445ms/match/image.jpg",
    "created_at": "2026-01-28T18:25:07.335Z",
    "topic": "news"
  },
  {
    "slug": "introducing-react-best-practices",
    "title": "Introducing: React Best Practices",
    "description": "We've encapsulated 10+ years of React and Next.js optimization knowledge into react-best-practices, a structured repository optimized for AI agents and LLMs.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vercel.com/blog/introducing-react-best-practices",
    "thumbnail_url": "https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/5VCSTefWazPIvZlDl3ZFbd/8996ca467f505fcec7d4f6fc19f9f1bd/image__15_.png",
    "created_at": "2026-01-28T12:27:43.743Z",
    "topic": "tech"
  },
  {
    "slug": "ai-kind-of-sucks-at-retouching-study-says",
    "title": "AI Kind of Sucks at Retouching, Study Says",
    "description": "As photographers lean more towards AI for retouching purposes, a new study finds how AI is not what people think it is supposed to be.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.thephoblographer.com/2026/01/27/ai-vs-human-retouching-the-quality-gap-is-bigger-than-expected/",
    "thumbnail_url": "https://www.thephoblographer.com/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-18.52.32.jpg",
    "created_at": "2026-01-28T12:27:41.769Z",
    "topic": "tech"
  },
  {
    "slug": "meta-allowed-minors-access-to-sextalking-chatbots-despite-staff-concerns-lawsuit-alleges",
    "title": "Meta allowed minors access to sex-talking chatbots despite staff concerns, lawsuit alleges",
    "description": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n Continue reading...",
    "fullText": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\n\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\n\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n\nThe filing on Monday included internal Meta employee emails and messages obtained by the New Mexico attorney general’s office through legal discovery. The state alleges they show that “Meta, driven by Zuckerberg, rejected the recommendations of its integrity staff and declined to impose reasonable guardrails to prevent children from being subject to sexually exploitative conversations with its AI chatbots”, the attorney general said in the filing. Meta announced last week that it had removed teen access to AI companions entirely, pending creation of a new version of the chatbots.\n\nIn the communications, some of Meta’s safety staff expressed objections the company was building chatbots geared for companionship, including sexual and romantic interactions with users. The artificial intelligence chatbots were released in early 2024. The documents cited in the state’s filing Monday don’t include messages or memos authored by Zuckerberg.\n\nAndy Stone, a Meta spokesperson, on Monday said the state’s portrayal was inaccurate and relied on selective information: “This is yet another example of the New Mexico attorney general cherrypicking documents to paint a flawed and inaccurate picture.”\n\nMessages in the filing showed safety staff had special concern about the bots being used for romantic scenarios between adults and minors under the age of 18, referred to as “U18s”.\n\n“I don’t believe that creating and marketing a product that creates U18 romantic AI’s for adults is advisable or defensible,” wrote Ravi Sinha, head of Meta’s child safety policy, in January 2024.\n\nIn reply, Antigone Davis, Meta’s global safety head, agreed that safety staff should push to block adults from creating underage romantic companions because “it sexualizes minors”. Sinha and Davis did not respond to requests for comment.\n\nAccording to one February 2024 message, a Meta employee whose name was redacted relayed that Zuckerberg believed that AI companions should be blocked from engaging in sexually “explicit” conversations with at least younger teens and that adults should not be able to interact with “U18 AIs for romance purposes”.\n\nA summary of a meeting dated 20 February 2024, said the CEO believed the “narrative should be framed around … general principles of choice and non-censorship”, that Meta should be “less restrictive than proposed”, and that he wanted to “allow adults to engage in racier conversation on topics like sex”.\n\nStone said the documents did not support New Mexico’s case. “Even these select documents clearly show Mark Zuckerberg giving the direction that explicit AIs shouldn’t be available to younger users and that adults shouldn’t be able to create under 18 AIs for romantic purposes.”\n\nMessages between two employees from March 2024 state that Zuckerberg had rejected creating parental controls for the chatbots, and that staffers were working on “Romance AI chatbots” that would be allowed for users under the age of 18.\n\nWe “pushed hard for parental controls to turn GenAI off – but GenAI leadership pushed back stating Mark decision”, one employee wrote in that exchange.\n\nNick Clegg, who was Meta’s head of global policy until early 2025, said in an email included in the court documents he thought Meta’s approach to sexualized AI companions was unwise.\n\nExpressing concern that sexual interactions could be the dominant use case for Meta’s AI companions by teenage users, Clegg said: “Is that really what we want these products to be known for (never mind the inevitable societal backlash which would ensue)?” Clegg did not respond to a request for comment.\n\nMeta’s AI chatbot policies eventually came to light, prompting a backlash in the US Congress and elsewhere.\n\nA Wall Street Journal article in April 2025 found that Meta’s chatbots included overtly sexualized underage characters and that they engaged in all-ages sexual roleplay, including graphic descriptions of prepubescent bodies. Reuters reported in August that Meta’s official guidelines for chatbots stated that it is “acceptable to engage a child in conversations that are romantic or sensual”. In response to the report, Meta said it was changing its policies and that the internal document granting such approval had been in error.",
    "readingTime": 4,
    "keywords": [
      "mexico attorney",
      "artificial intelligence",
      "parental controls",
      "internal meta",
      "meta employee",
      "sexual interactions",
      "safety staff",
      "new mexico",
      "new mexico’s",
      "meta’s ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/meta-lawsuit-minors-chatbots",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f6236f51e29389309cca0c8934bf7c5624b78619/289_0_4008_3208/master/4008.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7713cdfc7fbe29ee40fec93f7bfdb653",
    "created_at": "2026-01-28T12:27:37.644Z",
    "topic": "tech"
  },
  {
    "slug": "kyber-yc-w23-is-hiring-a-staff-engineer",
    "title": "Kyber (YC W23) Is Hiring a Staff Engineer",
    "description": "At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.\nOver the past 18 months, we’ve:\n>30x’d revenue and are profitable.\nLanded multiple six and seven figure, multi-year contracts with leading insurance enterprises.",
    "fullText": "At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.\n\nOver the past 18 months, we’ve:\n\nKyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.\n\nWe're seeking a Staff Engineer with a clear line of sight to CTO. This role is ideal for someone who is already operating as a 10x engineer, thrives in early stage environments, and is excited to design and scale mission-critical AI systems from first principles.\n\nJoin us in building and scaling a game-changing enterprise product powered by state-of-the-art AI. At Kyber, your contributions will directly impact how businesses handle some of their most critical workflows and customer interactions.\n\nIf you’re obsessed with building, AI, and transforming enterprise workflows, we’d love to hear from you!\n\nWe want to hear from extraordinary individuals who are ready to shape the future of enterprise documents. To stand out, ask someone you’ve worked with to send your resume or LinkedIn profile, along with a brief 2-3 sentence endorsement, directly to arvind [at] askkyber.com.\n\nReferrals matter. They help us understand the impact you’ve already had and the kind of teammate you’ll be. A strong referee can elevate your application, so choose someone who knows your skills and character well.\n\nApply today and help us bring enterprise documents into the AI-native age.",
    "readingTime": 2,
    "keywords": [
      "enterprise documents",
      "workflows",
      "someone",
      "we're",
      "ai-native",
      "templates",
      "directly",
      "impact",
      "you’ve",
      "kyber"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/kyber/jobs/GPJkv5v-staff-engineer-tech-lead",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/36d823535a32695e6b82b2371e3ed3df2496af99.png?1754429935",
    "created_at": "2026-01-28T12:27:37.281Z",
    "topic": "jobs"
  },
  {
    "slug": "western-digital-vs-micron-which-data-storage-stock-has-more-upside",
    "title": "Western Digital vs. Micron: Which Data Storage Stock Has More Upside?",
    "description": "Micron edges out Western Digital as AI-driven memory demand, tight supply and a cheaper valuation make MU the more attractive pick now.",
    "fullText": "Both Western Digital Corporation WDC and Micron Technology MU are major players in the memory and storage ecosystem, with exposure to NAND flash and data-center demand tied to AI, cloud computing and cyclical memory pricing. Western Digital and Micron are both well-positioned to benefit from global data growth through storage and memory solutions, making them closely watched by investors betting on AI infrastructure and cloud expansion.\n\nBoth operate in the broader data storage ecosystem, but they play distinct roles. Western Digital is traditionally known for HDDs and, increasingly, enterprise storage systems. It also has flash memory exposure, though that part was largely spun off through SanDisk in 2025. Micron is a pure memory champion in DRAM, HBM and NAND flash. Both have soared in value recently, driven by demand tied to data growth and AI infrastructure. But their futures hinge on different markets and technology cycles.\n\nHowever, if investors must choose between the two, which stock should they consider based on business models, growth drivers, risks, financials & valuation, outlooks and final verdict?\n\nAI adoption is accelerating across industries, driving innovation, reshaping business models and advancing digital transformation through higher productivity and richer user experiences. As agentic AI scales and multimodal LLMs become mainstream, WDC is seeing growing AI use cases that are fueling sustained demand for data infrastructure. AI is both a major consumer and creator of data, transforming how data is generated, stored, scaled and monetized. As data volumes expand rapidly, HDDs remain the most reliable, scalable and cost-effective solution for storing the zettabytes of data powering the AI-driven economy.\n\nAI is improving efficiency across corporate functions. At the same time, rising AI and data-driven workloads at hyperscalers are boosting demand for WDC’s storage solutions. Customers are shifting to higher-capacity drives, leading to strong shipments of its latest ePMR products, including up to 26TB CMR and 32TB UltraSMR drives. WDC continues to scale ePMR technology, invest in advanced media and wafer innovation, and use automation and AI to increase manufacturing capacity and efficiency. The reliability, scalability and cost advantages of Western Digital’s ePMR and UltraSMR drives continue to drive data center success, with the company preparing to build on this momentum through next-generation HAMR technology.\n\nStrong customer commitments—extending into 2027—underscore confidence in its roadmap and its role in the AI data economy. HAMR development is progressing well, with customer qualification beginning in early 2026 and volume production targeted for the first half of 2027. Meanwhile, next-gen ePMR drives will complete qualification by early 2026, supporting a smooth transition. Management expects continued revenue growth and improved profitability in the fiscal second quarter, driven by strong data center demand and higher-capacity drive adoption. At the mid-point of its guidance, Western Digital anticipates non-GAAP revenues of $2.9 billion (+/- $100 million), up 20% year over year.",
    "readingTime": 3,
    "keywords": [
      "nand flash",
      "ultrasmr drives",
      "business models",
      "storage ecosystem",
      "demand tied",
      "western digital",
      "memory",
      "technology",
      "growth",
      "epmr"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/western-digital-vs-micron-data-144000249.html",
    "thumbnail_url": "https://s.yimg.com/os/en/zacks.com/5fc95e37867e2a80f869083d472f6292",
    "created_at": "2026-01-28T12:27:35.814Z",
    "topic": "finance"
  },
  {
    "slug": "limy-built-a-platform-that-helps-brands-optimize-for-the-era-of-ai-agents-see-the-pitch-deck-that-helped-it-raise-10",
    "title": "Limy built a platform that helps brands optimize for the era of AI agents. See the pitch deck that helped it raise $10 million.",
    "description": "Limy raised $10 million from investors including Flybridge and a16z to help brands boost their visibility to AI agents.",
    "fullText": "The race to build the \"agentic internet\" is on, with consumers expected to increasingly offload tasks like travel and grocery shopping to autonomous software. It presents brands with a new challenge: how to stand out when the customer is an AI agent rather than a human.\n\nFounded in New York in 2024, Limy has built a platform to help companies better understand how AI agents decide which brands and products to recommend to their users.\n\nLimy is set to announce on Wednesday that it has raised $10 million in seed funding led by venture capital firm Flybridge. A16z's Speedrun program, Axiom, Clarim, JRV, AnD, and Communitas also participated.\n\nLimy plugs into a brand's content delivery network, such as Cloudflare, to detect when an AI agent visits their website. It then analyzes which content the agent fetched and the prompt a user entered into a chatbot like ChatGPT or Gemini that triggered the visit.\n\nArmed with that information, Limy produces insights for brands about the types of prompts that are surfacing their products in AI answers and whether the agent's visit to their website led to a purchase. Brands can apply those insights to help boost their visibility within large language models. Limy makes money through a tiered subscription model based on a company's size and the capabilities it requires.\n\nAviv Shamny, Limy's CEO, told Business Insider in an interview that his company differs from other startups offering generative engine optimization services because these competitor analytics tools typically track human clicks and pageviews.\n\nAgents are \"going in through the pipes,\" he said. \"They behave completely differently.\"\n\nShamny said connecting website visits from agents to real business metrics is a \"complicated vector search process,\" which helps set Limy up to be a player as advertising gets introduced to AI chatbots.\n\nOpenAI announced this month that it is testing ads on ChatGPT. Google last year introduced ads to the AI Overviews on its search results page and within its AI Mode, which allows users to ask follow-up questions.\n\n\"We're right at that junction between what agents are looking for, why they're surfacing ads, how these ads are even being interpreted by these agents,\" and whether those ads will lead to an eventual sale, Shamny said.\n\nTying a prompt to a conversion means Limy could tell a brand like Nike that the prompt \"best running shoes for men running a marathon\" had generated $10 million in sales over a quarter, and that this is the type of prompt or topic that a brand should double down on advertising against, Shamny said.\n\nShamny said Limy intends to invest its new funding in its sales, marketing, and growth teams as the company expands globally. He expects the team will grow to around 120 people by the end of the year, up from about 25.\n\nCheck out the pitch deck Limy used to secure its $10 million seed investment, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nShamny said AI agents will increasingly carry out tasks for consumers, such as booking flights or shopping.\n\nInstead, brands need to think about optimizing their web presence for AI agents.\n\nThe slide depicts someone asking ChatGPT for ideas for a housewarming gift for a friend, a hotel in Las Vegas, and a playlist for a party.\n\nAI agents are evaluating, choosing, and acting on behalf of humans, Limy says.\n\nLimy offers a way for brands to see how AI engines crawl, fetch, and index their web pages.\n\nThe slide shows a section of Limy's user interface that tracks site visits from AI bots.\n\nLimy wants to corner the markets of attribution, analytics, agentic ads, and agentic commerce.\n\nIt then detects and analyzes AI bot visits, presenting actionable insights for brands.\n\nThe slide shows how a luggage brand could use Limy's tool to see how a particular suitcase stacks up in product rankings within LLMs.\n\nLimy says brands can use its insights to ensure they're placing ads against the best topics and prompts to drive revenue.\n\n\"Our North Star is to build the internet for agents,\" Shamny said. \"When agents are going to dominate the web, we're giving the ability for brands to be a part of the conversation.\"\n\nWhile this slide is redacted, customers listed on its website include AstraZeneca, Kia, and Samsung.",
    "readingTime": 4,
    "keywords": [
      "agents",
      "brands",
      "visits",
      "website",
      "prompt",
      "insights",
      "slide",
      "limy",
      "agentic",
      "agent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/limy-raises-millions-brands-boost-ai-agent-visibility-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/6978a0acd3c7faef0eccf85b?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.971Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-ceo-warns-tech-titans-not-to-dismiss-the-publics-ai-concerns-youre-going-to-get-a-mob-coming-for-you",
    "title": "Anthropic CEO warns tech titans not to dismiss the public's AI concerns: 'You're going to get a mob coming for you'",
    "description": "Anthropic CEO Dario Amodei says that AI leaders need to embrace policies that better distribute the benefits of AI — or they'll face backlash.",
    "fullText": "Anthropic CEO Dario Amodei has a grave warning for fellow AI titans who dismiss the public's concerns about AI.\n\n\"You can't just go around saying we're going to create all this abundance, a lot of it is going to go to us, and we're going to be trillionaires, and no one's going to complain about that,\" Amodei told Axios in an interview. \"Look, you're going to get a mob coming for you if you don't do this in the right way.\"\n\nIt comes after Amodei published a sprawling 19,000-word essay on Monday called \"The Adolescence of Technology,\" in which he laid out his vision for the future of AI.\n\nThat includes his belief that the technology will turn the heads of some tech companies into trillionaires, and that humanity as a whole needs to treat AI like a \"serious civilizational challenge.\"\n\nIn both the interview and in his essay, Amodei called for more robust tax policies to ensure a broader distribution of the \"abundance\" that AI will create.\n\n\"I don't think this is the tax policies of old,\" Amodei said in the interview. \"This is for a world where people are trillionaires.\"\n\nAmodei didn't go into detail, other than writing in the essay that the taxation could be \"general or could be targeted against AI companies in particular,\" and that failing to proactively pursue those tax policies would lead to badly designed ones.\n\nHe also said that he'd advised lawmakers, in addition to pursuing more progressive taxation, to support AI transparency legislation and to cut off the supply of chips to China.\n\nAmodei sticks out from many other tech executives in that he's often viewed as taking a more \"doomer\" view of AI. But he also says that the public's concerns about AI aren't always \"well-targeted.\"\n\nSpecifically, he argued that data centers don't \"use that much water,\" while concerns about electricity bills are \"understandable\" but only a minor part of the conversation.\n\n\"I think in the long run, it's not about power bills, it's about enormous abundance, and whether they get their piece of the abundance,\" Amodei said in the interview.",
    "readingTime": 2,
    "keywords": [
      "public's concerns",
      "tax policies",
      "abundance",
      "interview",
      "trillionaires",
      "don't",
      "essay",
      "amodei",
      "we're",
      "create"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-ceo-dario-amodei-ai-wealth-distribution-warning-mob-2026-1",
    "thumbnail_url": "https://i.insider.com/6978d249a645d11881880aae?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.917Z",
    "topic": "finance"
  },
  {
    "slug": "anduril-is-giving-500000-and-a-job-to-whoever-wins-its-aipowered-drone-racing-grand-prix",
    "title": "Anduril is giving $500,000 and a job to whoever wins its AI-powered drone racing grand prix",
    "description": "Palmer Luckey's defense tech startup Anduril is known for its creative recruitment schemes. Now its launching an all-ages drones race.",
    "fullText": "Lights out and away we go… on your next job application.\n\nBut for this one, put aside your CV and interview-question AI bot. To secure the job, just place first in a global autonomous drone racing competition.\n\nThat's how defense industry disruptor Anduril is recruiting for an engineering role.\n\nThe defense tech startup has launched an \"AI Grand Prix\" to find \"the boldest engineers from around the globe.\"\n\nAnduril's competition calls teams and individuals from around the globe to develop AI systems capable of piloting high-speed racing drones through professional-grade race courses with zero human control. The fastest drone to fly autonomously through a course wins.\n\n\"The competitive edge is gained entirely by optimizing the best code for the race,\" Anduril said on its website.\n\nThe \"AI Grand Prix\" kicks off in April with two virtual rounds, followed by a two-week training and physical qualifier in California in September.\n\nThe big race day will be held in November in Ohio, where Anduril is building a 5 million-square-foot factory. Arsenal-1, as the factory is known, is just outside Columbus.\n\nParticipants can compete individually or in teams of up to eight. All ages are allowed to participate, but under-17s require parental consent and won't be eligible for the job at Anduril following the competition.\n\nIf the event is won by a team, the $500,000 prize money will be split between its members, Anduril said.\n\nThe idea came from Palmer Luckey, Anduril's founder, according to the AI Grand Prix website.\n\nLuckey has long favored unconventional paths. He began taking college courses at 14 and was 19 when he dropped out of California State University to launch the virtual reality company Oculus VR in 2012.\n\nHe worked at Facebook (now Meta) before launching Anduril in 2017, alongside four co-founders, with the mission of modernizing the US military and developing autonomous weapons that \"will save Western civilization.\"\n\nLuckey's penchant for fun and games aside, unusual job campaigns are becoming a hallmark of Anduril's recruitment strategy.\n\nIn 2025, the defense tech startup ran a reverse psychology hiring campaign with the slogan \"Don't work at Anduril,\" which included a video ad that mocked nap pods, distant leadership, and the supposed lack of mission synonymous with modern tech jobs.\n\nLuckey has previously said that over-reliance on Silicon Valley types can be a trap for businesses. Talent in the Bay Area is often \"very mercenary-minded\" and more interested in résumé building than mission, he told Lulu Cheng Meservey in an interview in September 2025.\n\nAnduril deliberately recruits nationwide and makes a point of hiring armed forces veterans, Luckey said.\n\nAnduril's recruitment drive is likely to pick up. The startup is valued at $30.5 billion as of June 2025, and is considering an IPO in 2026.\n\nAs the United States races to modernize warfare, Luckey's company has emerged as the face of the defense tech boom and proved it can compete for contracts with legacy defense contractors like Lockheed Martin and Boeing.\n\nAnduril did not immediately respond to a request for comment from Business Insider sent outside regular business hours.",
    "readingTime": 3,
    "keywords": [
      "grand prix",
      "anduril's recruitment",
      "tech startup",
      "defense tech",
      "ai grand prix",
      "competition",
      "race",
      "mission",
      "anduril",
      "aside"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anduril-ai-grand-prix-drone-palmer-luckey-job-application-2026-1",
    "thumbnail_url": "https://i.insider.com/6979d7a3e1ba468a96aad50b?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.724Z",
    "topic": "finance"
  },
  {
    "slug": "sherlock-see-whats-being-sent-to-llm-apis-in-realtime",
    "title": "Sherlock – See what's being sent to LLM APIs in real-time",
    "description": "Intercept LLM API traffic and visualize token usage in a real-time terminal dashboard. Track costs,       debug prompts, and monitor context window usage across your AI development sessions.       ...",
    "fullText": "jmuncor\n\n /\n\n sherlock\n\n Public\n\n Intercept LLM API traffic and visualize token usage in a real-time terminal dashboard. Track costs, debug prompts, and monitor context window usage across your AI development sessions. \n\n github.com/jmuncor/sherlock\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jmuncor/sherlock",
    "readingTime": 1,
    "keywords": [
      "usage",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/jmuncor/sherlock",
    "thumbnail_url": "https://opengraph.githubassets.com/51a4f8e374b4fdfe1a1dd27781788ed61b21cfe7b8d5caf01dfe4fcc0770f5c6/jmuncor/sherlock",
    "created_at": "2026-01-28T06:22:46.974Z",
    "topic": "tech"
  },
  {
    "slug": "articlecast-turn-articles-and-pdfs-into-ai-podcasts",
    "title": "ArticleCast – Turn Articles and PDFs into AI Podcasts",
    "description": "ArticleCast transforms web articles into natural, expressive audio.",
    "fullText": "Best Podcasts and DIY Audio Tools for Commuters in Austin and 5 Major U.S. Cities (2026)A city-by-city guide to top podcasts and how tools like ArticleCast help commuters in Austin, NYC, LA, Chicago, DC, and SF turn articles into audio—based on 2025–2026 traffic trends and listener habits.Read moreJan 14, 2026",
    "readingTime": 1,
    "keywords": [
      "podcasts",
      "tools",
      "commuters",
      "austin"
    ],
    "qualityScore": 0.2,
    "link": "https://www.articlecast.ai",
    "thumbnail_url": "https://munisdjgxlg2fgbc.public.blob.vercel-storage.com/landing_page/Images/ArticleCastPreviewImage.png",
    "created_at": "2026-01-28T06:22:46.399Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-not-inevitable",
    "title": "AI Is Not Inevitable",
    "description": "I got nerd-sniped right before work and just had to write this post.",
    "fullText": "I got nerd-sniped right before work and just had to write this post.\n\nIn AI code and software craft, Alex looks at AI through the lens of Jacques Ellul’s “technique.”\n\nJacques Ellul describes his concept of “technique” as the reduction of activity to a set of efficient means to a measured and defined end — a way of thinking dominant in modernity.\n\nHe argues that an arts and crafts style movement that focuses on craftsmanship can stave off the totality of technique. I’m all for arts and crafts, but that view is at odds with Ellul’s view. Ellul believed that technique was “inevitable” and all-consuming and unstoppable, like the smoke monster in Lost.\n\nAndrew Feenberg’s viewpoint is actually \n\nFor example, the “technique” of the 19th-century factory was brutal efficiency. But through unions and laws (human agency), we forced the technique to adapt to child labor laws and safety standards. Efficiency was curbed by social values.\n\nFeenberg showed us a few ways to push back against Technique.\n\nDonald Knuth, a renowned computer scientist, invented literate programming, which redefined the way we write code – by putting us humans first. In literate programming you start with prose and interject code, rather than writing code and sprinkling in comments. He inverted the existing model from speed of implementation to ease of understanding.\n\nSimilarly, Feenberg would redefine AI by building AI tools that optimize for maintainability, readability, and beauty.\n\nIn the 1980s, the French government distributed the Minitel (a proto-internet terminal) to millions of homes. The technique goal was bureaucratic efficiency: to modernize the phone directory and deliver government information. It was cold, rational, and top-down.\n\nInstead, users hacked the system. They ignored the government directories and turned the network into a massive, chaotic instant-messaging service. They used the machine for flirting, arguing, and socializing. The users subverted the rational design. They took a tool of control and turned it into a tool of communication.\n\nIn other words, don’t just boycott AI. Misuse it.\n\nFeenberg distinguishes between two layers of technology. To overcome technique, we have to re-integrate them. The primary instrumentalization is the raw technical aspect. For code that means purely technical, decontextualized logic. The second instrumentalization is social, aesthetic, and ethical context. The code is elegant and respects the user’s privacy. To unify the two, we must demand that the second instrumentalization be integrated into the first.\n\nWennerberg is right to identify the “slop” as a threat, but wrong to suggest we can defeat it with nostalgia. Retreating to “software arts and crafts” doesn’t change anything (I’m still for it though); it merely leaves the engine of modern society running on autopilot, optimized only for profit.\n\nFeenberg offers a harder, but more effective path: don’t abandon the machine – hack it. By embedding human values into our definitions of efficiency and refusing to accept raw functionality as the final standard, we stop being victims of technique. The goal is not to escape the future, but to shape it.\n\nNow it’s time for me to go write some code.",
    "readingTime": 3,
    "keywords": [
      "literate programming",
      "second instrumentalization",
      "code",
      "efficiency",
      "technique",
      "arts",
      "crafts",
      "software",
      "view",
      "laws"
    ],
    "qualityScore": 1,
    "link": "https://dustin.boston/ai-is-not-inevitable/",
    "thumbnail_url": "https://dustin.boston/wp-content/uploads/2026/01/android-chrome-512x512-1.png",
    "created_at": "2026-01-28T06:22:44.303Z",
    "topic": "tech"
  },
  {
    "slug": "pixel-arcade-studio-kids-make-playable-browser-games-by-instructing-ai",
    "title": "Pixel Arcade Studio –kids make playable browser games by instructing AI",
    "description": "Kids create real browser games by giving clear instructions to AI. No coding, no downloads.",
    "fullText": "They need to learn how to give clear instructions to AI.\n\nPixel Arcade Studio is a browser-based game studio where kids create real, playable games by telling an AI assistant exactly what to build. No coding. No installs. Designed with parents in mind.\n\nSafe, creative screen time kids love. Try free for 14 days.\n\nFast \"time-to-wow\" — kids see their games come to life quickly.\n\nFrictionless — everything runs directly in the browser.\n\nSafety default — games publish with privacy protections enabled.\n\nCoding used to be how people told computers what to do.\n\nToday, the more important skill is knowing how to describe what you want, break ideas into steps, and give clear instructions to an AI system.\n\nPixel Arcade Studio is built around that shift.\n\nKids don't write code here. They practice explaining ideas, testing results, and improving their instructions when something doesn't work.\n\nThat's the skill they'll use in the real world.\n\nYour child picks a game template and describes what they want to make. Characters, goals, movement, and rules.\n\nYour child tells the AI assistant what to create or change. The AI follows instructions. It does not take over.\n\nThe game runs right away in the browser. No setup and no waiting.\n\nKids adjust their instructions, test again, and see how clearer directions lead to better results.\n\nGames can be shared with family or friends using parent-approved links.\n\nThis is not about memorizing technical skills. It's about clear thinking and communication.\n\nAI in Pixel Arcade Studio is a tool, not a shortcut.\n\nIt responds only to what your child asks. It does not browse the internet. It does not publish content on its own. It stays inside kid-safe boundaries.\n\nYour child stays in control. The AI helps carry out instructions.\n\nPixel Arcade Studio is built for families who want creative screen time without constant supervision.\n\nInstead, kids focus on giving clear instructions and seeing real results. They make games people can actually play.\n\nEvery game made in Pixel Arcade Studio is playable in the browser and shareable through safe links.\n\nKids don't just save projects. They create something real and playable.\n\nPixel Arcade Studio is a browser-based game studio where kids create playable games by giving instructions to an AI assistant. There is no coding involved.\n\nNo. Pixel Arcade Studio does not teach coding. Kids learn how to clearly describe ideas, give instructions, and work with AI to create games.\n\nPixel Arcade Studio is designed for kids ages 7 to 12.\n\nYes. Games publish in safe mode by default, sharing requires parent approval, and the platform includes content filtering and privacy protections.\n\nNo. Everything runs directly in the web browser. There are no downloads or installs.\n\nThe AI follows your child's instructions. It helps turn ideas into games but does not take control or act on its own.\n\nYes. Games can be shared using parent-approved links so friends and family can play safely.\n\nPixel Arcade Studio does not involve coding or block-based programming. It focuses on teaching kids how to give clear instructions to AI and refine their ideas through iteration.\n\nNo coding. No downloads. Designed for ages 7–12.",
    "readingTime": 3,
    "keywords": [
      "pixel arcade studio",
      "creative screen",
      "privacy protections",
      "parent-approved links",
      "browser-based game",
      "kids don't",
      "games publish",
      "playable games",
      "the ai",
      "kids create"
    ],
    "qualityScore": 1,
    "link": "https://pixelarcade.studio",
    "thumbnail_url": "http://localhost:3000/images/pas_og.jpg",
    "created_at": "2026-01-28T06:22:43.763Z",
    "topic": "tech"
  },
  {
    "slug": "this-train-isnt-going-to-stop-shocking-sundance-film-shows-promises-and-perils-of-ai",
    "title": "‘This train isn’t going to stop’: shocking Sundance film shows promises and perils of AI",
    "description": "The AI Doc: Or How I Became an Apocaloptimist, co-directed by Daniel Roher, delves into the world of AI through the lens of personal anxiety\nAre we barreling toward AI catastrophe? Is AI an existential threat, or an epochal opportunity? Those are the questions top of mind for a new documentary at Sundance, which features leading AI experts, critics and entrepreneurs, including Sam Altman, the OpenAI CEO, with views on the near-to-midterm future ranging from doom to utopia.\nThe AI Doc: Or How I Became an Apocaloptimist, directed by Daniel Roher and Charlie Tyrell and produced by Daniel Kwan (one half of The Daniels, the Oscar-winning duo behind Everything Everywhere All At Once), delves into the contentious topic of AI through Roher’s own anxiety. The Canadian film-maker, who won an Oscar in 2023 for the documentary Navalny, first became interested in the topic while experimenting with tools released by OpenAI, the company behind the chatbot ChatGPT.",
    "fullText": "The AI Doc: Or How I Became an Apocaloptimist, co-directed by Daniel Roher, delves into the world of AI through the lens of personal anxiety\n\nAre we barreling toward AI catastrophe? Is AI an existential threat, or an epochal opportunity? Those are the questions top of mind for a new documentary at Sundance, which features leading AI experts, critics and entrepreneurs, including Sam Altman, the OpenAI CEO, with views on the near-to-midterm future ranging from doom to utopia.\n\nThe AI Doc: Or How I Became an Apocaloptimist, directed by Daniel Roher and Charlie Tyrell and produced by Daniel Kwan (one half of The Daniels, the Oscar-winning duo behind Everything Everywhere All At Once), delves into the contentious topic of AI through Roher’s own anxiety. The Canadian film-maker, who won an Oscar in 2023 for the documentary Navalny, first became interested in the topic while experimenting with tools released by OpenAI, the company behind the chatbot ChatGPT. The sophistication of the public tools – the ability to produce whole paragraphs in seconds, or produce illustrations – both thrilled and unnerved him. AI was already radically shaping the filmmaking industry, and proclamations on the promise and peril of AI were everywhere, with little way for people outside the tech industry to evaluate them. As an artist, he wondered, how was he to make sense of it all?\n\nRoher’s anxiety only increased when he and his wife, fellow film-maker Caroline Lindy, learned that they were expecting their first child. “It felt like the whole world was rushing into something without thinking,” he says in the film, as his excitement for parenthood collided with dread over the unknown variable of AI, which in just a few short years went from proprietary experiment to public good.\n\nThe AI Doc thus arises out of Roher’s most pressing question: is it safe to bring a child into this world? Alongside Kwan, Roher convened a series of experts to both explain the mechanics of the tech – and clarify some nebulous, alienating terms – and search for an answer. (It is both comforting and a little disturbing, for example, that no one seems to have a clear answer to the question “what is AI?”). In individual sit-down interviews, leading machine learning researchers including Yoshua Bengio, Ilya Sutskever and DeepMind co-founder Shane Legg all agree that there are aspects of AI models that humans cannot and will never be able to understand. Standard AI models are trained on “more data than anyone could ever read in several lifetimes”, as one machine learning expert puts it. And the pace of machine learning exceeds that of precedent – or film. “Any example you put in this movie will look absolutely clumsy by the time the movie comes out,” Tristan Harris, co-founder of the Center for Humane Technology and a prominent voice in the apocalyptic 2020 Netflix documentary The Social Dilemma, tells Roher.\n\nThe film first hears from a series of doomerists, or people concerned AI – and in particular Artificial General Intelligence (AGI), a still-theoretical form of AI whose capabilities exceed those of humans – could lead to the extermination of humanity, including Harris, his Center for Humane Technology co-founder Aza Raskin, Ajeya Cotra, an AI risk adviser, and Eli Yudkowsky, an AI alignment pioneer. Such figures warn that humans could very easily lose control of super-intelligent AI models, with little to no recourse. Yudkowsky’s 2025 book is bluntly titled If Anyone Builds It, Everyone Dies.\n\nAI companies, they say, are unprepared for the consequences of reaching AGI, which could “become superhuman maybe in this decade”, says Dan Hendrycks, director of the Center for AI Safety. Should humans no longer be the most intelligent beings on Earth, they warn, it is possible that AGI would view the species as irrelevant. Connor Leahy, co-founder of EleutherAI, compared the potential future relationship of super-intelligent AGI and humans to that of humans and ants: “We don’t hate ants. But if we want to build a highway” over an anthill – “well, sucks for the ant.”\n\nSeveral in the doomer camp, many of whom do not have children, react discouragingly to Roher’s question about parenthood. “I know people who work on AI risk who don’t expect their child to make it to high school,” says Harris, in a line that drew gasps from a preview audience in Park City.\n\nOn the other side are optimistic figures such as Peter Diamandis, founder of the XPRIZE Foundation trying to extend human life, who claims that “children born today are about to enter a period of glorious transformation”; Guillaume Verdon, a leader of the “effective accelerationism” movement in Silicon Valley; Peter Lee, the president of Microsoft Research; and Daniela Amodei, the co-founder and president of OpenAI rival Anthropic. So-called “accelerationists” see AI as a potential cure to a myriad of seemingly intractable issues afflicting humanity: cancer, food and water shortages for an ever-growing population, insufficient renewable energy and perhaps most pressing, climate emergency. Without AI, they argue, countless future lives would be lost to drought, famine, disease and natural catastrophes.\n\nDevelopment of AI, however, relies on computing power, which requires vast amounts of energy. A final group of interviewees, critics and observers largely outside the tech world – including Karen Hao, a journalist and author of the book Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI, and Liv Boeree, Win-Win podcast hos – connect AI to the tangible, physical world, such as the data centers sucking up water in the American west, leaving residents with sky-high electricity bills and drained reservoirs. The current narratives around AI, according to Emily M Bender, a computational linguistics professor, exclude and dehumanize the people it is already impacting, and will continue to disrupt.\n\nRoher eventually arrives at the five most powerful people – all men – currently leading the AI arms race: Altman; Elon Musk, the xAI CEO; Dario Amodei, the Anthropic CEO; Demis Hassabis of DeepMind and Meta’s Mark Zuckerberg. Altman, Amodei and Hassabis sit for interviews that more or less defend their companies’ respective positions. According to the film, Zuckerberg declined to participate; Musk agreed but then got too busy.\n\nAltman, who at the time of the interview was expecting his first child, insists that he’s “not scared for a kid to grow up in a world with AI”. He and his husband Oliver Mulherin welcomed their son via a surrogate in February 2025, an event Altman later said “neurochemically hacked” his brain, leading people in his life to think that he would “make better decisions” for OpenAI and ChatGPT when it comes to “humanity as a whole”. The 40-year-old CEO went on to say that both his and Roher’s child would likely “never be smarter than AI” which “does unsettle me a little bit, but it is reality”.\n\nAt one point, Roher asks Altman if it is indeed impossible to reassure him that everything in regards to AI is going to be OK. “That is impossible,” Altman affirms, though he does say that OpenAI’s lead in the AI arms race allows it to spend more time on safety testing.\n\nThe AI Doc ultimately lands somewhere in between doomerism and optimism – apocaloptimism, as they call it, searching for “a path between the promise and the peril”. That path should include, according to numerous film subjects: significant, sustained, paradigm-shifting international coordination, akin the mid-century frameworks and agreements introduced to moderate the development of atomic weapons – more corporate transparency for AI companies, an independent regulatory body to police AI developers, legal liability for the companies’ products, such as ChatGPT, mandatory disclosure of genAI use for media and a willingness to keep adapting the rules for rapidly shifting tech.\n\nWhether or not the US government and companies, let alone the world, can do it remains an open question, with differing opinions on first steps. But if there is one thing the many subjects all agree on, it’s that there’s no going back to a time before AI. As Anthropic co-founder and CEO Amodei puts it: “This train isn’t going to stop.”\n\nThe AI Doc: Or How I Became an Apocaloptimist is screening at the Sundance film festival and will be released on 27 March",
    "readingTime": 7,
    "keywords": [
      "arms race",
      "machine learning",
      "the ai doc",
      "humane technology",
      "film",
      "co-founder",
      "humans",
      "roher’s",
      "child",
      "leading"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/film/2026/jan/27/sundance-ai-documentary-daniel-roher",
    "thumbnail_url": "https://i.guim.co.uk/img/media/b08a19776fa0669d5a6da6b4fa8dc369025616f1/571_0_2697_2160/master/2697.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f49a8654dc44a148f9cf48ba31979f54",
    "created_at": "2026-01-28T06:22:42.506Z",
    "topic": "entertainment"
  },
  {
    "slug": "exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say",
    "title": "Exclusive-China gives green light to importing first batch of Nvidia's H200 AI chips, sources say",
    "description": "China has approved its first batch of Nvidia's H200 artificial intelligence chips for import, two people familiar with the matter told Reuters, marking a shift in position as China ​seeks to balance its AI needs against spurring domestic development.  The approval covers several hundred thousand H200 chips ‌and was granted during Nvidia Chief Executive Jensen Huang's visit to China this week, the sources said, requesting anonymity due to the sensitivity ‌of the matter.",
    "fullText": "Jan 28 (Reuters) - China has approved its first batch of Nvidia's H200 artificial intelligence chips for import, two people familiar with the matter told Reuters, marking a shift in position as China ​seeks to balance its AI needs against spurring domestic development.\n\nThe approval covers several hundred thousand H200 chips ‌and was granted during Nvidia Chief Executive Jensen Huang's visit to China this week, the sources said, requesting anonymity due to the sensitivity ‌of the matter.\n\nThe first batch of approvals has been allocated primarily to three major Chinese internet companies, with other enterprises now joining a queue for subsequent approvals, one of the sources said.\n\nThey declined to name the companies that received the initial clearances.\n\nChina's industry and commerce ministries as well as Nvidia had not yet responded to requests for comment at the time ⁠of publication.\n\nThe H200, Nvidia's second most ‌powerful AI chip, has emerged as a major flashpoint in U.S.-China relations. Despite strong demand from Chinese firms and U.S. approval for exports, Beijing's hesitation to allow imports has been ‍the main barrier to shipments.\n\nThe U.S. earlier this month formally cleared the way for Nvidia to sell the H200 to China, where the company is seeing strong appetite. However, Chinese authorities have the final say on whether they would allow it to be ​shipped in.\n\nIt was unclear in recent weeks whether Beijing would grant approval as the government wants to balance ‌meeting surging domestic demand for advanced AI chips and nurturing its domestic semiconductor industry.\n\nChinese customs authorities told agents that the H200 chips were not permitted to enter China, Reuters reported earlier this month.\n\nBut Chinese technology firms have placed orders for more than two million H200 chips, far exceeding Nvidia's available inventory, Reuters reported last month.\n\nIt remains uncertain how many additional companies will receive approval in subsequent batches or what criteria Beijing is using to determine eligibility.\n\nHuang arrived ⁠in Shanghai last Friday for routine annual celebrations with Nvidia's China ​employees and has since travelled to Beijing and other cities, Reuters ​reported last week.\n\nThe approvals of H200 suggest Beijing is prioritising the needs of major Chinese internet companies, which are spending billions of dollars to build data centres needed to develop AI ‍services and compete with U.S. ⁠rivals, including OpenAI.\n\nWhile Chinese companies such as Huawei now have products that rival the performance of Nvidia's H20 chip, previously the most advanced AI chip it was allowed to sell to China, they still ⁠lag far behind the H200.",
    "readingTime": 3,
    "keywords": [
      "chinese internet",
      "chips",
      "approval",
      "beijing",
      "domestic",
      "approvals",
      "chip",
      "china",
      "batch",
      "balance"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-china-gives-green-light-034730976.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/17e76ef2c101de17fb4d4c33cf165ec7",
    "created_at": "2026-01-28T06:22:41.828Z",
    "topic": "finance"
  },
  {
    "slug": "exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say",
    "title": "Exclusive-China gives green light to importing first batch of Nvidia’s H200 AI chips, sources say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say-4469141",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0R059_L.jpg",
    "created_at": "2026-01-28T06:22:41.183Z",
    "topic": "finance"
  },
  {
    "slug": "asml-rides-nvidias-coattails-with-lasers-and-huge-chip-printers",
    "title": "ASML rides Nvidia's coattails with lasers and huge chip 'printers'",
    "description": "As artificial intelligence firms jostle for the Nvidia chips needed to power the AI boom, Dutch firm ASML has carved out a key niche in the supply chain: building the laser-using machines needed ​to print them.  ASML, which counts Taiwan's TSMC and Intel amongst its clients, makes the huge precision machines needed to print the minuscule ‌circuitry onto silicon chips, dominating the market for the high-end microprocessors needed for AI.  The Veldhoven, Netherlands-based company has seen its shares double in value since last April and rise 25% ‌this month alone amid signs that its chipmaker clients are ramping up investment as a supply crunch pushes up chip prices.",
    "fullText": "AMSTERDAM, Jan 27 (Reuters) - As artificial intelligence firms jostle for the Nvidia chips needed to power the AI boom, Dutch firm ASML has carved out a key niche in the supply chain: building the laser-using machines needed ​to print them.\n\nASML (ASML), which counts Taiwan's TSMC and Intel amongst its clients, makes the huge precision machines needed to print the minuscule ‌circuitry onto silicon chips, dominating the market for the high-end microprocessors needed for AI.\n\nThe Veldhoven, Netherlands-based company has seen its shares double in value since last April and rise 25% ‌this month alone amid signs that its chipmaker clients are ramping up investment as a supply crunch pushes up chip prices.\n\nNow investors are watching whether the firm ups its forecasts for flat-to-modest sales growth in 2026 when it reports earnings on Wednesday, analysts said.\n\nAnalysts have been upgrading estimates as the stock races ahead, with new forecasts significantly above the company's guidance.\n\nA monopoly on extreme ultraviolet (EUV) technology has helped the firm ride the coattails of chip design giant Nvidia amid a global ⁠AI arms race that has created trillions of dollars ‌in value.\n\nASML is \"the only game in town,\" said John West of semiconductor consultancy Yole Group, referring to EUV, which uses light beams just 13.5 nanometers thick - minuscule, given a human hair is around 80,000–100,000 nanometers across.\n\nCHIPMAKER CLIENTS RAMP UP ‍CAPEX PLANS\n\nThe firm will also update its plans to ramp up the number of machines it can make.\n\nDemand for ASML's high-tech tools has made the firm Europe's most valuable listed company with a market cap recently topping $500 billion.\n\nASML controls some 90% of the market for lithography systems, analysts estimate, due to its high-throughput machines. It is ​the only maker of EUV technology, in which drops of tin are vaporized with lasers 50,000 times a second to create the light.\n\nDemand for AI-linked ‌cloud services boomed in 2025 and a related shortage of memory chips has started to push up prices for smartphones, computers and gaming consoles.\n\nManufacturers are ramping up investment to boost capacity in response.\n\nTSMC, ASML's top customer, plans to increase capital spending by 37% in 2026 to $56 billion.\n\nAnalysts estimate Samsung is targeting a 24% hike to $40 billion, and that SK Hynix will increase spending by 25% to $22 billion, according to LSEG data. U.S. firm Micron plans a 45% rise to $20 billion.\n\nA quarter of chipmaker capex is spent on lithography, analysts estimate, largely going to ASML, and this proportion could be higher with ⁠AI chips, driven by demand from players like Apple, Google, and Qualcomm.",
    "readingTime": 3,
    "keywords": [
      "euv technology",
      "chipmaker clients",
      "analysts estimate",
      "machines needed",
      "firm",
      "chips",
      "plans",
      "market",
      "demand",
      "nvidia"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asml-rides-nvidias-coattails-lasers-060145161.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/871959193fa106a7de7e044d72305973",
    "created_at": "2026-01-28T06:22:39.894Z",
    "topic": "finance"
  },
  {
    "slug": "metas-soaring-capex-is-front-and-center-for-analysts-ahead-of-the-social-media-giants-q4-earnings",
    "title": "Meta's soaring capex is front and center for analysts ahead of the social media giant's Q4 earnings",
    "description": "Analysts are laser-focused on Meta's AI ambitions and its surging capex spending. The company reports Q4 earnings after the closing bell on Wednesday.",
    "fullText": "Big Tech earnings are about to kick off in earnest, with Meta Platforms due to report results for the final quarter of 2025 on Wednesday.\n\nMeta stock has been highly volatile over the past year, remaining in the green but lagging behind some of its Magnificent Seven peers. The stock is up about 1% year-to-date and up 7% in the last 12 months.\n\nThe social media giant spent 2025 telling investors it would boost capex spending, hyping up its ambitious AI plans. Investors eventually balked at Meta and other tech titans' plans to keep increasing capex. Meta tumbled after its Q3 report, partly on its announcement that it plans to spend more than ever on AI infrastructure going forward.\n\nMeta latest announced it would significantly scale back its metaverse spending, touted by CEO Mark Zuckerberg as the company's future only a few years earlier.\n\nWall Street is estimating that the Facebook parent will report $58.4 billion in revenue and earnings per share of $8.19.\n\nHere's what analysts say they'll be listening for.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nHe added that his team expects Meta's capex spending to come in between $109 and $114 billion for the year, likely above Wall Street consensus of $110 billion.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\n\"In our view, Meta is positioned favorably — especially in the long-term — as it doubles down on an AI investment cycle,\" Black said.\n\nLike its peers, Goldman analysts remain focused on Meta's capex plans, which they believe will continue to drive growth into 2026 and beyond. The bank recently raised its spending projections for the company, already above analyst estimates, noting that it sees upward pressure on consensus capex estimates.\n\n\"On the next earnings call, we expect investors will be focused on any updates on the work of the Meta Superintelligence Lab, the timing of any foundational model work and/or any strategies with respect to consumer or enterprise utility around AI,\" Goldman analysts stated.\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 34% increase from levels on Tuesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nThe analyst added that this has prompted Rothschild to increase its full-year capex projection for Meta to $117.1 billion.\n\nTD Cowen is bullish on Meta ahead of its Wednesday earnings report, predicting generative AI tools will continue to support growth in its advertising business.\n\nAnalyst John Blackedge said he believes ad growth will help bolster its high capex spending.\n\n\"Key at the 4Q25 print will be mgmt's '26 capex and opex guides,\" he said. \"We currently expect '26 capex of $125.0BN, up 76% y/y and 14% above consensus alongside '26 opex of $156.1BN, up 32.9% y/y and 7% above consensus.\"",
    "readingTime": 4,
    "keywords": [
      "goldman analysts",
      "meta's capex",
      "expense guide",
      "meta stock",
      "wall street",
      "earnings",
      "plans",
      "estimates",
      "target",
      "growth"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-earnings-preview-ai-capex-wall-street-forecasts-facebook-2026-1",
    "thumbnail_url": "https://i.insider.com/697905fba645d1188188120e?width=1200&format=jpeg",
    "created_at": "2026-01-28T00:59:05.568Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-included-a-subtle-dig-at-mark-zuckerberg-in-his-message-to-employees",
    "title": "Sam Altman included a subtle dig at Mark Zuckerberg in his message to employees",
    "description": "Sam Altman told staff OpenAI \"didn't start talking about masculine corporate energy,\" an apparent reference to Mark Zuckerberg's remarks to Joe Rogan.",
    "fullText": "Don't expect to see Sam Altman lamenting the absence of \"masculine energy\" in corporate America to Joe Rogan anytime soon.\n\nThe OpenAI CEO sent employees a message on Slack criticizing Immigration and Customs Enforcement — and appears to have taken the opportunity to also take a subtle jab at his rival, Mark Zuckerberg.\n\nThe reference can be found where Altman wrote that OpenAI aims to \"not get blown around by changing fashions.\"\n\n\"We didn't start talking about masculine corporate energy when that was popular,\" Altman told employees.\n\nLast year, Zuckerberg championed a return to masculinity at Meta on \"The Joe Rogan Experience.\"\n\n\"The masculine energy, I think, is good,\" Zuckerberg said in the January podcast episode. \"Society has plenty of that, but I think corporate culture was trying to get away from it.\"\n\nZuckerberg described the merits of a corporate culture that \"celebrates the aggression\" of business.\n\nThe Meta CEO said that the intent of corporate culture's shift away from masculinity was good. Women likely feel that companies are \"too masculine,\" he told Rogan, and that things are \"biased\" against them. But the shift had gone too far, the Facebook cofounder said.\n\n\"It's one thing to say we want to be welcoming and make a good environment for everyone,\" Zuckerberg said. \"It's another to basically say that masculinity is bad.\"\n\nAltman also wrote in his memo that OpenAI didn't \"become super woke when that was popular.\"\n\nMeta didn't respond to Business Insider's request for comment on Altman's remark.\n\nAltman and Zuckerberg are currently engaged in a talent war for top AI researchers and engineers.\n\nZuckerberg has attempted to poach OpenAI employees with eye-popping compensation packages, which Altman in June said included $100 million signing bonuses.\n\nWhile Altman at the time said that he was happy that \"at least so far, none of our best people have decided to take them up on that,\" Zuckerberg successfully hired away some prominent OpenAI talent.\n\nThe Meta CEO, who even hand-delivered soup to an OpenAI employee he was attempting to poach, hired away ChatGPT co-creator Shengjia Zhao and three researchers who helped build OpenAI's Zurich office.",
    "readingTime": 2,
    "keywords": [
      "meta ceo",
      "hired away",
      "corporate culture",
      "masculine energy",
      "the meta ceo",
      "employees",
      "didn't",
      "masculinity",
      "zuckerberg",
      "altman"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-dig-mark-zuckerberg-masculine-energy-2026-1",
    "thumbnail_url": "https://i.insider.com/6978e73ba645d11881880d86?width=1200&format=jpeg",
    "created_at": "2026-01-28T00:59:05.239Z",
    "topic": "finance"
  },
  {
    "slug": "harnessing-plasmons-for-alternative-computing-power",
    "title": "Harnessing Plasmons for Alternative Computing Power",
    "description": "Can computing with plasmons solve AI's power problem? Dive into the world of electron waves and find out.",
    "fullText": "IEEE Spectrum is the flagship publication of the IEEE — the world’s largest professional organization devoted to engineering and applied sciences. Our articles, videos, and infographics inform our readers about developments in technology, engineering, and science.",
    "readingTime": 1,
    "keywords": [
      "engineering",
      "ieee"
    ],
    "qualityScore": 0.2,
    "link": "https://spectrum.ieee.org/plasmon-computing-device",
    "thumbnail_url": "https://spectrum.ieee.org/media-library/image.jpg?id=62999081&width=1200&height=600&coordinates=0%2C136%2C0%2C114",
    "created_at": "2026-01-27T18:24:30.848Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-use-of-ai-images-pushes-new-boundaries-further-eroding-public-trust-experts-say",
    "title": "Trump's use of AI images pushes new boundaries, further eroding public trust, experts say",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.  Homeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,\" he said. \"By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,\" or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they're seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can't tell if what they're watching is fake, and questions whether they would know \"what’s real or not when it actually matters, like when the stakes are a lot higher.\"\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/trumps-ai-images-pushes-boundaries-150725490.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/9xZi2ciMXRnBrH4SjRZuyQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/d262a7d276564fc3e4743b28feb4fcc9",
    "created_at": "2026-01-27T18:24:25.114Z",
    "topic": "news"
  },
  {
    "slug": "at-davos-tech-ceos-laid-out-their-vision-for-ais-world-domination",
    "title": "At Davos, tech CEOs laid out their vision for AI’s world domination",
    "description": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n Continue reading...",
    "fullText": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\n\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n\nWhen they weren’t discussing Donald Trump, delegates at the World Economic Forum last week were being dazzled by the prospects for artificial intelligence.\n\nUp and down the main street of the Swiss Alps town, almost every shopfront was temporarily emblazoned with the neon slogan of a tech firm – or a consultancy promising to tell executives how to incorporate AI into their business. Cloudflare’s wood-panelled HQ urged delegates to “connect, protect and build together”, and Wipro’s shouted: “Dream Solve Prove Repeat.”\n\nAt the conference, tech CEOs laid out their hopes for how the physical manifestations of AI will blanket the world in the coming years. Microsoft chief executive Satya Nadella told a rapt audience about how “token factories”, as he calls datacenters, will have to be distributed across the world, to diffuse the benefits of AI globally.\n\n“To me, a long term, scalable solution is to have all of these token factories part of the real economy connected to the grid, connected to the telco network – and that’s what will drive that scale, whether it’s in the global south, or in the developed world,” Nadella said.\n\nMeanwhile Google was showing off the latest iteration of its Google Glasses to excited delegates; and there were endless sessions in the Davos congress centre about the technology’s potential benefits – including a breathless chat with late addition to the schedule Elon Musk, though with the SpaceX IPO apparently looming, he was keenest to talk about going to Mars.\n\nAway from the glitzy shopfronts, though, there was significant concern being expressed that all this proves to be an epic bubble.\n\nIn an interview with the Financial Times, DeepMind chief Demis Hassabis warned that some aspects of AI investment do look, “bubble-like”, but insisted that, “if the bubble bursts, we [ie Google, not society at large] will be fine”.\n\nNadella offered one test for how we would know if it is a bubble – which I didn’t find reassuring. “A tell-tale sign of this as a bubble, is if all we’re talking about are the tech firms,” he said.\n\nMuch of Silicon Valley has been captivated over the past week by a “very human drama”, as the Wall Street Journal put it. Thinking Machines Lab, a startup founded by former OpenAI chief technology officer Mira Murati, fired her own chief technology officer, Barret Zoph, over a relationship with a colleague and a recent lack of productivity, per the Journal. Within hours, her ex-employee – along with one of her co-founders and a third employee – had reportedly signed offers with OpenAI, which they left just last year to join her startup. The three had told her they disagreed with the direction of the company in the meeting that ended with Zoph’s firing, according to the Journal. For his part, Zoph told the Journal that Murati had fired him simply for telling her he was considering another job.\n\nAs dishy as the drama might be, the stakes of Murati’s mess differ from a juicy celebrity entanglement that might be chronicled in TMZ or Page Six, two of my favorite publications. The stakes in San Francisco are billions of real dollars and more than $10bn potential ones. Murati’s company has raised $2bn in venture capital since its founding in February 2025. It is valued at $12bn. The talent involved in these California productions – not movies but rather AI tools used by hundreds of millions of people – takes on superstar significance.\n\nThinking Machines has released one product, Tinker, in October 2025, meant to streamline the customization of large language models, a rather niche concern in comparison with ChatGPT’s ambitions to replace Google search or Claude’s coding aptitude.\n\nThe massive investment and resulting valuation are chasing little in terms of real offerings from the company. A new company profiled in the New York Times last week, Humans&, has naught but a dream, an ugly website – and several hundred million dollars. Researchers from Google, Anthropic, and Elon Musk’s xAI, including one who helped develop the notorious Grok AI tool, founded the company just three months ago. They aim to facilitate collaboration between humans and machines rather than separation – “innovations in long-horizon and multi-agent reinforcement learning, memory, and user understanding”, per the site. If that sounds gauzy, it is because the company has not launched a product.\n\nHumans& has raised $480m from Nvidia, Jeff Bezos, and Google, per the New York Times. It is valued at $4.48bn. It has – say it with me one more time – not launched a product.\n\nWhatever fears of an AI bubble may be circulating, the money is still flowing, chasing after the future with an enormous but uncertain bet in the present.\n\nElon Musk announced last week that Tesla had removed human safety monitors from its Robotaxis in Austin, Texas, as the company moves to expand its autonomous vehicle business. As with most things Musk, the reality was a bit more complicated – Tesla’s vice-president of software later clarified on X that the company had deployed “a few unsupervised vehicles mixed in with the broader robotaxi fleet with safety monitors”.\n\nWhat Tesla’s test-run of fully driverless vehicles did highlight, however, was the difference between how much leeway Texas gives autonomous vehicles compared with California, the birthplace of autonomous driving in the US and the home of the highest number of self-driving cars in the country. The Texas department of motor vehicles does not have regulatory authority over autonomous vehicles in the state, instead autonomous vehicles are governed by the state’s transportation code. Although a new government authorization system for autonomous vehicles is set to be implemented in the coming months, there’s currently no application process required for autonomous vehicle operators in the state. \n\n “Autonomous vehicles on Texas roads are subject to all traffic laws and can be cited for safety violations, but do not yet require specific authorization to operate,” the Texas DMV said.\n\nAlso surprising is the state’s lack of regulations on operating an autonomous vehicle if it’s for personal, non-commercial use. As long as it complies with some stipulations, such as traffic laws and safety standards, an autonomous vehicle can drive around Texas without anyone in the car.\n\n “Any motor vehicle equipped with an automated driving system may operate in this state,” the Texas transportation code states. “An automated motor vehicle may operate in this state with the automated driving system engaged, regardless of whether a human driver is physically present in the automated motor vehicle.”\n\nMeanwhile in California, the state’s department of motor vehicles requires three stages of testing and permitting for commercial autonomous vehicles. Regulators are also in the process of considering new rules that could add even more requirements on vehicle operators. Tesla caused confusion last October when Musk announced a ride-hailing service in the Bay Area, only for regulators to say that the company did not have authorization to operate paid or unpaid autonomous rides to the public. On the Robotaxi section of Tesla’s website, it only mentions Texas.",
    "readingTime": 7,
    "keywords": [
      "token factories",
      "technology officer",
      "transportation code",
      "traffic laws",
      "launched product",
      "chief technology",
      "safety monitors",
      "driving system",
      "human drama",
      "vehicle operators"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/tech-ceos-ai-world-domination-davos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a41253b81fc5917ccace5d630d7fcae04c0a81ac/397_0_3973_3179/master/3973.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=5dc97d5efc9fb16909abebef52464733",
    "created_at": "2026-01-27T18:24:24.653Z",
    "topic": "tech"
  },
  {
    "slug": "wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "title": "‘Wake up to the risks of AI, they are almost here,’ Anthropic boss warns",
    "description": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially...",
    "fullText": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially imminent’\n\nQuarter of Britons fear losing jobs to AI in next five years\n\nHumanity is entering a phase of artificial intelligence development that will “test who we are as a species”, the boss of the AI startup Anthropic has said, arguing that the world needs to “wake up” to the risks.\n\nDario Amodei, a co-founder and the chief executive of the company behind the hit chatbot Claude, voiced his fears in a 19,000-word essay titled “The adolescence of technology”.\n\nDescribing the arrival of highly powerful AI systems as potentially imminent, he wrote: “I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species.”\n\nAmodei added: “Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.”\n\nThe tech entrepreneur, whose company is reportedly worth $350bn (£255bn), said his essay was an attempt to “jolt people awake” because the world needed to “wake up” to the need for action on AI safety.\n\nAmodei published the text as the UK government announced Anthropic would help create chatbots that support jobseekers with career advice and finding employment, as part of developing an AI assistant for public services in general. Last week, the company published an 80-page “constitution” for Claude in which it set out how it wanted to make its AI “broadly safe, broadly ethical”.\n\nAmodei co-founded Anthropic in 2021 along with other former staff members from OpenAI, which developed ChatGPT. A prominent voice for online safety known for warning consistently of the dangers of unrestrained AI development, he wrote that the world was “considerably closer to real danger” in 2026 than it had been in 2023, when the debate over existential risk from AI raced up the political agenda.\n\nHe alluded to the controversy over sexualised deepfakes created by Elon Musk’s Grok AI that flooded the social media platform X over Christmas and the new year, including warnings that the chatbot was creating child sexual abuse material.\n\nAmodei wrote: “Some AI companies have shown a disturbing negligence towards the sexualisation of children in today’s models, which makes me doubt that they’ll show either the inclination or the ability to address autonomy risks in future models.”\n\nThe Anthropic CEO said powerful AI systems that could autonomously build their own systems could be as little as one to two years away.\n\nHe defined “powerful AI” as a model that was smarter than a Nobel prizewinner across fields such as biology, mathematics, engineering and writing. It could give or take directions to or from humans, and although it “lived” on a computer screen it could control robots and even design them for its own use.\n\nWhile acknowledging that powerful AIs could be “considerably further out” than the two-year timeframe, Amodei said recent rapid progress made by the technology should be taken seriously.\n\n“If the exponential continues – which is not certain, but now has a decade-long track record supporting it – then it cannot possibly be more than a few years before AI is better than humans at essentially everything,” he wrote.\n\nLast year, Amodei warned that AI could halve the number of entry-level white-collar jobs and send overall unemployment rocketing to 20% within the next five years.\n\nIn his essay, Amodei cautioned that the economic prize from AI, such as productivity gains from eliminating jobs, could be so great that no one applied the brakes.\n\n“This is the trap: AI is so powerful, such a glittering prize, that it is very difficult for human civilisation to impose any restraints on it at all,” he said.\n\nHowever, Amodei stated he was optimistic about a positive conclusion. “I believe if we act decisively and carefully, the risks can be overcome – I would even say our odds are good. And there’s a hugely better world on the other side of it. But we need to understand that this is a serious civilisational challenge.”",
    "readingTime": 4,
    "keywords": [
      "almost unimaginable",
      "potentially imminent",
      "dario amodei",
      "systems",
      "jobs",
      "risks",
      "essay",
      "human",
      "humanity",
      "entering"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/cca45f90dfaec5c3f552bbc4e8760038372d897b/393_0_2714_2172/master/2714.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d8b5b71d851d82cbde8694a1b52384dc",
    "created_at": "2026-01-27T18:24:24.652Z",
    "topic": "tech"
  },
  {
    "slug": "uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "title": "UK ministers accept $1m from Meta amid social media ban consultation",
    "description": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI...",
    "fullText": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI systems\n\nUK politics live – latest updates\n\nMinisters have accepted $1m (£728,000) from Meta, the US tech and social media company, to build AI systems for defence, national security and transport, sparking warnings about the UK government’s “alarmingly close relationship with Trump-supporting US tech giants”.\n\nThe money from Mark Zuckerberg’s company will be used to pay experts to “develop cutting-edge AI solutions … to support national security and defence teams”, the Department for Science, Innovation and Technology (DSIT) announced on Tuesday.\n\nThe money will pay for four British AI experts, coordinated by the government-funded Alan Turing Institute, to “play a pivotal role in rewiring our healthcare, police, transport systems and more”, said Ian Murray, the minister for data and digital government.\n\nThe move comes after Meta executives had 50 meetings with ministers in the last two years for which data was available, one of the highest levels of direct access of any technology company, a Guardian investigation found.\n\nThe government is consulting on a ban on social media use by under-16s, which would have a major effect on Meta’s Instagram platform. Meta said the money had been allocated to the Alan Turing Institute before any ban was floated.\n\nAnnouncing the $1m deal, Meta said it was “proud to help bring top British AI talent into government, fast-tracking the transformation of public services”.\n\nDSIT said: “People across the UK could benefit from faster, safer and more reliable public services as leading British AI specialists join government to modernise critical systems used every day – from public safety to transport maintenance.”\n\nBut the tech justice campaign group Foxglove asked: “What’s Meta getting for its million dollars?” It added: “When it comes to big tech, there’s no such thing as a free lunch.”\n\n“This is yet more evidence of the UK government’s alarmingly close relationship with Trump-supporting US tech giants,” said Donald Campbell, Foxglove’s advocacy director. “It’s deeply worrying that ministers are still naive enough to swallow this kind of lobbying from a handful of Silicon Valley plutocrats – who have proven beyond a shadow of a doubt they do not have the British public’s best interests at heart.”\n\nDaisy Greenwell, a co-founder of the Smartphone Free Childhood campaign, said the deal “highlights an uncomfortable reality: tech giants spend vast sums to gain access and influence in policymaking”.\n\nShe added: “That makes it even more important that decisions about children and online safety are shaped by independent evidence and the public interest, not by the companies whose products are under scrutiny.”\n\nThe government also announced a new partnership with the San Francisco AI company Anthropic, which will build and pilot a dedicated assistant tool for public services on gov.uk, starting with a model that will give jobseekers career advice “and help to lock down a job”. Anthropic said the project implementation work was “pro bono”.\n\nDSIT said the technology was “part of a cutting-edge plan to use AI agents for national government services, with a pilot expected to begin later this year”. In October, Anthropic announced that the former prime minister Rishi Sunak was taking an advisory role at the $350bn startup. The former Downing Street chief of staff Liam Booth-Smith is a policy and communications adviser to Anthropic.\n\nThe deals come as ministers wrestle with policy decisions that directly affect Meta and Anthropic. As well as launching a consultation last week on banning social media use for under-16s, they are also due to set out changes to how creatives’ copyrighted works are protected from being mined to build AI models, such as those made by Anthropic.\n\nBeeban Kidron, a cross-bench peer who campaigns on child protection and copyright, said: “This government is walking into dependence on Silicon Valley, is undermining the chance to build a UK AI sector, and above all is busy giving away some of the most precious datasets in the world to Silicon Valley, who could well afford to pay.”\n\nThe Meta-funded AI experts will be tasked with using AI to develop models that analyse images and videos, enabling councils to prioritise transport infrastructure repairs more effectively. They will also “develop cutting-edge AI solutions which run offline or within secured networks to support national security and defence teams to make vital decisions while safeguarding sensitive data”, the government said.",
    "readingTime": 4,
    "keywords": [
      "alan turing",
      "turing institute",
      "government’s alarmingly",
      "alarmingly close",
      "close relationship",
      "social media",
      "defence teams",
      "develop cutting-edge",
      "tech giants",
      "british ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7579a99b61180e696e2e281c07852109de29baed/449_0_3102_2483/master/3102.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4fb697801505937bed47acb1a0dbeda8",
    "created_at": "2026-01-27T18:24:24.651Z",
    "topic": "tech"
  },
  {
    "slug": "artie-yc-s23-is-hiring-a-founding-recruiter",
    "title": "Artie (YC S23) Is Hiring a Founding Recruiter",
    "description": "About Artie\nArtie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.",
    "fullText": "Artie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\n\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\n\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.\n\nWe’re hiring our first in-house recruiter to own and build talent at Artie. This role is your chance to build our team from first principles.\n\nThis is not a coordination role and not a “run the ATS” job.\n\nYou will be responsible for end-to-end recruiting across the company, with a focus on Engineering, Product, Operations, and Design (EPOD). You’ll partner directly with founders and hiring managers, define what “great” looks like for each role, and build the recruiting foundation we scale on top of.\n\nYou will also be the internal owner for our external recruiting partners — setting strategy, calibrating quality, and ensuring agencies complement our in-house motion.\n\nIf you view recruiting as a mix of sales, systems thinking, storytelling, and judgment, this role is for you.\n\nThis is a high-trust, high-ownership role, and you’ll have real influence over the shape, culture, and trajectory of the company.\n\nOwn full-cycle recruiting across the company\n\nBe the engine for technical hiring\n\nBuild recruiting infrastructure from scratch\n\nManage external recruiting partners\n\nRecruiting mastery in early-stage environments",
    "readingTime": 2,
    "keywords": [
      "external recruiting",
      "recruiting partners",
      "recruiting across",
      "role",
      "hiring",
      "real-time",
      "platform",
      "systems",
      "engineering",
      "teams"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/artie/jobs/MX163y2-founding-recruiter",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/d0fcec7266dcbcce7f7a6ac13a2cf60a4bbe4995.png?1741923726",
    "created_at": "2026-01-27T18:24:24.181Z",
    "topic": "jobs"
  },
  {
    "slug": "this-one-activity-remained-the-largest-driver-of-gdp-growth-in-2025-not-ai-according-to-a-new-report",
    "title": "This one activity remained the largest driver of GDP growth in 2025 — not AI, according to a new report",
    "description": "A new report shows that despite popular belief that an AI crash will tank the economy, regular consumers are much more crucial for GDP growth.",
    "fullText": "Worried about the AI bubble? A new report suggests AI was not the main leg propping up the economy in 2025.\n\nMacro Research Board Partners, an economic research platform, published a report in January that contradicted the popular belief that AI is the main driver of GDP and that the \"narrowly concentrated\" and \"extremely vulnerable\" growth would tank the entire economy once it falters.\n\n\"In short, without an AI boom, there would have certainly been less GDP growth last year, but there would also be fewer imports, so that overall real growth would still have been decent,\" wrote economic strategist Prajakta Bhide, who authored the report.\n\nBhide told Business Insider that personal consumption, meaning the spending of everyday people, was still the main pillar of GDP growth in 2025, and that despite the amount of investment in AI infrastructure, a lot of high-tech equipment is imported, and imports do not contribute to GDP.\n\nThe main categories that count toward GDP are personal consumption, private domestic investment, government spending, and net exports.\n\n\"Consumers continue to be the backbone of the economy,\" Bhide told Business Insider. \"Aggregate income growth is lower than it used to be, and so is job growth, which affected consumer sentiments. But there is a divide between what consumers say they feel and what they say that they're going to do versus what they actually go and do.\"\n\nAI growth was an important secondary driver of GDP growth, the report found, but that is mostly from software investment, while the contribution of data centers is \"negligible.\"\n\n\"Although a negative shock to the optimism around AI implies a risk to GDP growth,\" Bhide wrote in the report, \"the more realistic (and smaller) estimate of AI's growth impact after adjusting for imports dispels the popular notion that the US economy would falter without it.\"\n\nBeyond the GDP, concerns about the AI bubble are also tied to the stock market and people's retirement funds. America's eight most valuable public companies, including Nvidia, Alphabet, and Apple, are all betting heavily on AI and are worth $22 trillion altogether.\n\nBusiness Insider has previously reported that historically, a pullback in consumer spending has rarely been the trigger for an economic downturn. Instead, spending typically weakens only after job losses mount and when a recession is already well underway.",
    "readingTime": 2,
    "keywords": [
      "personal consumption",
      "gdp growth",
      "business insider",
      "economy",
      "economic",
      "imports",
      "investment",
      "bubble",
      "popular",
      "driver"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/one-activity-remained-largest-driver-gdp-growth-2025-not-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/69784290d3c7faef0eccf772?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.314Z",
    "topic": "finance"
  },
  {
    "slug": "flora-raised-42-million-for-its-creative-platform-that-pulls-together-top-ai-tools-read-its-pitch-deck",
    "title": "FLORA raised $42 million for its creative platform that pulls together top AI tools. Read its pitch deck.",
    "description": "FLORA streamlines creative workflows by integrating AI tools like ChatGPT and Gemini for teams at brands such as Lionsgate and Levi's.",
    "fullText": "AI is remaking creative industries at breakneck speed. And the growing pile of AI tools is turning the creative process into a game of model-hopping as artists, designers, and writers bounce between different platforms.\n\nFounded in Brooklyn, New York, in 2024, FLORA wants to help creatives streamline those processes. On Tuesday, FLORA revealed it had raised $42 million in Series A funding led by Redpoint Ventures. The company has raised $52 million in funding to date.\n\nFLORA combines the latest AI models — such as Google's Nano Banana and OpenAI's ChatGPT 5.1 — into a single interface that lets teams collaborate on projects in real time.\n\nThe FLORA platform allows those teams to maintain control over their settings and brand assets. It enables them to create repeatable work — such as maintaining a consistent design style across thousands of ad campaign assets — even as the platform switches between the different large language models that work best for each part of the process.\n\n\"Our goal for FLORA is to make it feel like a power tool attuned to what you're trying to do, just like a carpenter with their power tools has adjusted it to be exactly fit for the way that he or she works,\" FLORA CEO Weber Wong said in an interview with Business Insider.\n\nWhile established players like Adobe and Figma are also integrating models such as ChatGPT, Gemini, and Claude into their products, Wong said FLORA is building itself a defensible moat by covering the entire creative process — from coming up with ideas to the distribution of the final product.\n\n\"This new product category that we've created has an opportunity to be the biggest market ever for a creative tool because, in addition to just making one piece of media at a time, we can help handle the entire workflow,\" Wong said.\n\nFLORA charges clients based on usage, letting customers buy recurring credit packs to spend across the various LLMs it uses, without having to switch between multiple subscriptions. Wong said this is different from the traditional creative software business model, which is usually designed around seat-based pricing. (FLORA initially offered a seat-based pricing model, but switched to usage-based this week.)\n\nFLORA's clients include Levi's and the design agency Pentagram. Wong said the studio Lionsgate has used FLORA to generate movie concepts using text-to-image and image-to-video generation tools, then stitching those together to create films to test in front of audiences.\n\n\"It really beats just looking at a script and trying to be like, I think this is good?\" Wong said.\n\nWong said it plans to invest the fresh funds in its engineering team and in marketing. He forecasts the company will grow to about 75 people this year, up from 25.\n\nFLORA's main focus will be to improve the product so that creatives never need to leave the platform to achieve \"pixel perfection,\" as Wong described it. The company is also in the early stages of building agentic features into the platform, Wong said.\n\n\"We're obsessed with making it so that we don't waste creatives' time,\" Wong said.\n\nCheck out the pitch deck FLORA used to secure its $42 million Series A investment, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt combines several different large language models into a single interface.\n\nWong was previously a creative technologist who worked on AI art installation projects. He also previously invested in startups at Menlo Ventures.\n\n\"Silicon Valley does not understand the professional creative industry,\" Wong said. \"They think AI models are for fun or a novelty.\"\n\nFLORA checks for updates to the latest models two to three times a week, Wong said.\n\nIt's designed to let teams quickly conceptualize and build workflows using generative AI.\n\nCertain team members can also access advanced controls if needed.\n\nWong said a usage-based pricing model was preferable because \"you have one workspace where you can invite as many team members as you want and not pay for seats, and you can just buy recurring credit packs for the entire workspace that give you additional credits each month that roll over and don't expire.\"\n\nFLORA has a usage-based pricing model. It also has an in-house team that can provide expert support, including training on the features of new models as they are released.",
    "readingTime": 4,
    "keywords": [
      "business insider",
      "recurring credit",
      "credit packs",
      "seat-based pricing",
      "pricing model",
      "usage-based pricing",
      "language models",
      "creative process",
      "wong",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/flora-raises-capital-unify-ai-tools-for-creatives-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/6977526ba645d1188187f669?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.209Z",
    "topic": "finance"
  },
  {
    "slug": "taiwan-is-reworking-its-ground-forces-it-could-unlock-new-ways-of-fighting-with-new-tech",
    "title": "Taiwan is reworking its ground forces. It could unlock new ways of fighting with new tech.",
    "description": "The shift could set troops up to better mix in new weapons like specialized Abrams tanks, drones, and artificial intelligence in command and control.",
    "fullText": "Taiwan's ground forces are undergoing a shift that'll make it easier to work with new weapons like drones and artificial intelligence, capabilities expected to be necessary for tough future fights.\n\nThe restructure is aimed at equipping troops with the tools to better deter or defeat a Chinese invasion. It's the latest way Taiwan is modernizing its military as it buys more new technologies and changes how it trains its troops.\n\nTaiwan's Ministry of National Defense reclassified its four armored brigades and three mechanized infantry brigades into combined arms brigades earlier this month. The Army told CNA, the national news agency, that the change was in response to enemy threats and future warfare scenarios.\n\nThey are intended to be flexible for rapid response. The units retain their original designations, but the focus is no longer singular. In some ways, it mirrors the concepts of the US Army's Brigade Combat Team, which is a self-contained, self-sufficient, mobile fighting force for higher-level warfare.\n\nA graphic shared by the Taiwan Security Monitor, a research initiative at George Mason University, shows the renaming of those brigades, as well as their locations on Taiwan.\n\nTaiwan's military recently reclassified its 7 mechanized and armored brigades as combined arms brigades to better align its force structure reform efforts. \n\nOur visualization highlights the distribution of those brigades, along with their new titles and unit patches. pic.twitter.com/uDzMRbIb5I\n\nThe creation of combined armed brigades isn't creating new units, and the old brigades were already working with tanks, infantry, artillery, and support and technical elements. So why did Taiwan's military leadership change them?\n\nMick Ryan, a retired Australian army major general, strategist, and defense expert, told Business Insider the change could better serve troops as they adopt and embrace new weaponry.\n\n\"It does provide a foundation for the integration of new technologies, not just drones, but the use of AI in digital command and control systems, probably more air defense systems,\" he said.\n\nRyan described the change as a mindset shift. Combined arms brigades in other militaries, like Western countries, are constantly working with different organizations and systems.\n\nIt makes ground forces more flexible and self-sufficient with capabilities across units, which Taiwan has been pushing its military toward in recent years, with a focus on rapid response, mobility, and adaptability should China attack Taiwan. It also allows units to cover weaknesses; infantry, for example, can help counter anti-tank weaponry, while heavy armor can provide infantry with more firepower.\n\nSome defense experts have assessed that the introduction of new MIA2T Abrams tanks could also be influencing the restructuring decision.\n\nTaiwan ordered 108 of the Abrams, a customized variant, in 2019 and received 80 tanks late last year. It's expected to receive the rest early this year. These are Taiwan's first new tanks in over 20 years, marking a major capability upgrade in firepower, armor, and survivability.\n\nMore Taiwanese weapons purchases — including High Mobility Artillery Rocket Systems, various types of missiles, and drones — as well as increased investments at home in domestic defense technologies, may ultimately give troops experience with a wide range of weaponry that could be crucial.\n\nCombined arms brigades, by design, make it easier and faster to integrate new weapons and technology by bringing more capabilities under one command, reducing friction between units. That structure allows quicker experimentation, smoother training and doctrinal changes, and easier absorption of new platforms.\n\nTaiwan's defense ministry didn't respond to Business a request for comment from Business Insider.\n\nWhile the recent restructuring marks an evolution in Taiwan's military, other efforts are also underway to keep its forces ready.\n\nEarlier this month, for instance, Taiwan opened a new artillery training center — the Tangshan base — in Tainan on the southwest coast. The facility is designed to support more modern, high-tech training on systems such as HIMARS and Land Sword missiles.\n\nTaiwan has also expanded training areas and exercises geared toward preparing troops for asymmetric warfare, including the use of drones, coastal defense operations, and urban combat.\n\nThe military sees asymmetric warfare — a network of mobile, dispersed, and survivable weapons and tactics — as central to its self-defense strategy, but that isn't the sole focus.\n\nTaiwan is acquiring and producing large quantities of munitions needed for sustained, high-intensity fighting, including systems used to blunt or slow a larger invading force.\n\nThis month, the US and Taiwan announced plans to co-produce 155mm artillery shells, with Taiwan's defense ministry citing the war in Ukraine as evidence of how quickly such ammunition can be consumed in combat. The head of Taiwan's arms bureau said that if the effort ultimately proves successful, it could be expanded to other weapons and munitions.",
    "readingTime": 4,
    "keywords": [
      "taiwan's military",
      "rapid response",
      "asymmetric warfare",
      "combined arms",
      "taiwan's defense",
      "armored brigades",
      "defense ministry",
      "systems",
      "weapons",
      "troops"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/taiwans-ground-forces-restructure-makes-using-new-weapons-easier-2026-1",
    "thumbnail_url": "https://i.insider.com/6977bb8ed3c7faef0eccee68?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.205Z",
    "topic": "finance"
  },
  {
    "slug": "solopreneurs-explain-what-ai-is-and-isnt-good-for-when-youre-running-a-business",
    "title": "Solopreneurs explain what AI is and isn't good for when you're running a business",
    "description": "Entrepreneurs like Kim Magaraci, Seneca Connor, and Gloria Hebert use AI tools like ChatGPT to ditch admin busywork and focus on growth and customers.",
    "fullText": "Over eight years of writing for travel publications, Kim Magaraci developed a passion for domestic travel. She learned that travel tips online couldn't compete with those destinations you could only discover by word-of-mouth.\n\nSo, when she founded her travel business, KGM Travel Design, in 2024, she hoped to emphasize personal relationships with vendors and customers and avoid using AI, despite her experience with it.\n\n\"I don't think you can get good advice asking ChatGPT for an itinerary,\" she says. \"It's antithetical to everything I stand for.\"\n\nAnd yet, Magaraci realized that using AI for administrative tasks like analytics, compiling reports, and generating condensed client briefs allowed her to spend more time on the personalized relationships that set her business apart.\n\nShe's one of many solopreneurs who told Business Insider that outsourcing administrative tasks to AI platforms such as ChatGPT, Gemini, and Nano Banana — Gemini's photo-editing AI — has allowed them to scale their business by spending more time on strategic and creative work, including growth decisions and building personal connections with customers.\n\n\"It's getting harder and harder to deny the time-saving aspects,\" Magaraci says, adding that she has embraced AI \"in order to run a successful business and grow this business into what I want it to be.\"\n\nSeneca Connor, founder of The Bag Icon, an accessories brand, uses Nano Bana and other AI products to edit photos and videos. That not only saves her money — up to $2,000 per monthly photo shoot, she says — but also time.\n\nWith the hours saved, Connor has been able to design more original bags and launch a greater number of bags curated from other designers, all while reducing her marketing costs.\n\nAs a result, The Bag Icon saw more than a 20% year-over-year increase in profits last year, despite the impact of tariffs.\n\nAccountant and solopreneur Gloria Hebert uses ChatGPT for her business, Aybear Services, to instantly create educational client worksheets that previously took an hour or two to set up.\n\nThis frees up time that she then uses to prioritize analyzing financial data from her bookkeeping clients — data she doesn't feed into AI because of privacy concerns. Managing finances is the core of her business, so having more time to spend on that has allowed her to streamline her workdays.\n\nThe time saved also allows her to organize networking events and community education classes for local business owners, which has led to an uptick in business. \"Several of those entrepreneurs hired me to do their books,\" Hebert says.\n\nLisa York is the owner of Sell More Stuff, an email marketing business. Although she has a small audience, she saw a 33% conversion rate for sales last year, she says. She credits that growth to her personalized, voicey emails, which always open with a personal anecdote and are never written with AI.\n\n\"I use a lot of story-led emails,\" York says. \"People enjoy them, and they open the email because they can see my name.\"\n\nThat's something AI just can't replicate, she says. But York is able to spend time drafting engaging copy because she outsources other tasks — including tech support for her website, research, and brainstorming marketing strategy — to ChatGPT.\n\nLike York, Connor uses the time that AI saves to build robust communication and rapport with her customers, which she says builds loyalty to her business. Less time spent on photos and video gives her more time to respond to emails and direct messages from clients seeking advice about their purchases.\n\n\"It's building community that's missing in the big brands,\" Connor says.\n\nWhile AI has allowed these solopreneurs to grow their businesses without hiring a team, the technology shouldn't take over the core aspects of a business, Hebert says. Rather, it can be a tool that allows owners to focus on those critical areas.\n\n\"Use it as a resource,\" she says.\n\nYork — whose target clientele are other solopreneurs — says she's seeing more people recognize that. \"People aren't scared of it anymore,\" she says.\n\nConnor plans to expand her use of AI this year. She's experimenting with a digital clone — a video avatar that can deliver a script explaining new products. That approach will save her time on filming videos, but she says she'll always be the one dishing out the original advice that her clients have come to trust.\n\nEven if a video is created using AI, Connor says, \"all thoughts, ideas, and suggestions — those are my own.\"",
    "readingTime": 4,
    "keywords": [
      "bag icon",
      "administrative tasks",
      "the bag icon",
      "allowed",
      "business",
      "personal",
      "customers",
      "advice",
      "it's",
      "she's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/solopreneurs-embrace-ai-pros-cons-helps-boost-growth-client-relations-2026-1",
    "thumbnail_url": "https://i.insider.com/6978da6ad3c7faef0eccfbd1?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.912Z",
    "topic": "finance"
  },
  {
    "slug": "famed-shortseller-jim-chanos-shares-the-area-of-the-stock-market-ai-investors-should-be-pursuing-instead-of-data-centers",
    "title": "Famed short-seller Jim Chanos shares the area of the stock market AI investors should be pursuing instead of data centers",
    "description": "Jim Chanos voiced caution on the gold rush in AI data centers, telling investors they should own the companies building the AI models.",
    "fullText": "Legendary short-seller Jim Chanos isn't optimistic about one big piece of the AI trade.\n\nJim Chanos, the investor who predicted the collapse of Enron and the president and founder of investment firm Kynikos Associates, recently said he thinks investors should seek exposure to AI through companies that build AI models rather than the data centers that power them.\n\nThe data center boom was among the dominant market trends of 2025, as tech companies rushed to build out the infrastructure needed to support their AI ambitions. But Chanos pointed to several concerning elements that he thinks illustrate why the growth isn't sustainable.\n\nChanos shared his take on the best way to play the AI boom following a major announcement from chip titan Nvidia, which confirmed a $2 billion investment in AI infrastructure company CoreWeave. Despite the stock's rally over the past year, some finance pros have raised concerns about CoreWeave's business and path to profitability.\n\nThe short-seller shared several of his thoughts on the current AI market in a series of posts on X regarding CoreWeave's ambitious AI demand projections. When a user said he had become addicted to coding with AI models and expressed a willingness to pay handsomely for them, Chanos responded by summarizing his AI investing thesis in two sentences.\n\n\"In that case you should own the companies that build the models, not the companies that build the data centers,\" he wrote. \"The former are technology companies, the latter are REIT's.\"\n\nIn his view, data center companies may be viewed as tech firms, but economically, they're more like real estate investments.\n\nUsing CoreWeave as an example, Chanos questioned whether investors are focusing on actual fundamentals rather than simply buying into AI hype.\n\n\"Does anyone still bother to check these wildly bullish claims with, you know, their actual financial statements…?!\" he asked. \"Because [CoreWeave] based on its annualized 3Q results, would still be reporting losses USING 10-YR LIFE for its GPU depreciation!\"\n\nCoreWeave reported third-quarter earnings that exceeded Wall Street revenue estimates, but it also scaled back its guidance for the coming year and revealed temporary delays regarding a data center partner.\n\nThis isn't the first time Chanos has expressed skepticism about the data center boom. In a previous interview, he highlighted the problem he thinks could arise if companies start to scrutinize the return on investment from their massive capex spending.\n\n\"I'm starting to worry there's so much spending right now on the AI physical boom — the buildout of data centers, chips, and so on — that if anyone decides to pause and ask, 'What's our real economic return here?' it could be a big problem.\"",
    "readingTime": 3,
    "keywords": [
      "center boom",
      "jim chanos",
      "isn't",
      "investment",
      "models",
      "centers",
      "short-seller",
      "investors",
      "rather",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-data-centers-jim-chanos-stock-market-coreweave-nvidia-2026-1",
    "thumbnail_url": "https://i.insider.com/63d907907db5600019bac3c9?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.809Z",
    "topic": "finance"
  },
  {
    "slug": "read-sam-altmans-internal-slack-message-to-employees-saying-ice-is-going-too-far",
    "title": "Read Sam Altman's internal Slack message to employees saying ICE 'is going too far'",
    "description": "OpenAI CEO Sam Altman privately wrote that part of being patriotic \"is the American duty to push back against overreach.\"",
    "fullText": "Being patriotic means you also need to call out \"overreach\" when you see it, Sam Altman privately told OpenAI employees in a message that said Immigration and Customs Enforcement had gone \"too far.\"\n\n\"I love the US and its values of democracy and freedom and will be supportive of the country however I can; OpenAI will too,\" the OpenAI CEO wrote in an internal Slack message. \"But part of loving the country is the American duty to push back against overreach. What's happening with ICE is going too far.\"\n\nOpenAI employees responded positively to Altman's message on Slack, including heart and thank-you emojis.\n\nAltman's message, which was first reported by The New York Times' Dealbook newsletter, comes as CEO and tech leaders face internal and external pressures in the wake of ICE's deadly shooting of Alex Pretti on Saturday. Pretti is the second person to be fatally shot by federal law enforcement amid a surge in immigration enforcement in and around Minneapolis.\n\nAltman also praised Trump's leadership in his message and expressed hope that the president could cool tensions — the latest example of a CEO attempting to balance being critical of actions tied to the Trump administration's policies while also staying on the president's good side.\n\n\"President Trump is a very strong leader, and I hope he will rise to this moment and unite the country,\" Altman wrote. \"I am encouraged by the last few hours of response and hope to see trust rebuilt with transparent investigations.\"\n\nAs a general principle, Altman wrote that OpenAI tries to \"stick to our convictions and not get blown around by changing fashions too much.\"\n\nOn Monday, the White House appeared to be recalibrating its response in the wake of significant criticism, including from some congressional Republicans.\n\nWhite House press secretary Karoline Leavitt declined to associate Trump with Homeland Security Secretary Kristi Noem and White House advisor Stephen Miller's initial statements that Pretti was trying to commit domestic terrorism.\n\nDo you work at OpenAI? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com",
    "readingTime": 2,
    "keywords": [
      "white house",
      "altman's message",
      "openai employees",
      "hope",
      "overreach",
      "internal",
      "slack",
      "wake",
      "response",
      "secretary"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-ice-minnesota-shooting-response-slack-message-2026-1",
    "thumbnail_url": "https://i.insider.com/6978d2c9d3c7faef0eccfab3?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.800Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-forced-him-to-rename-the-viral-ai-agent-wasnt-my-decision",
    "title": "Clawdbot creator says Anthropic 'forced' him to rename the viral AI agent: 'Wasn't my decision'",
    "description": "Clawdbot, the viral AI agent that caused techies to buy up Mac Minis, is now Moltbot after Anthropic reached out about name and mascot similarities.",
    "fullText": "In a move perhaps unsurprising to anyone familiar with trademarks, the viral Clawdbot AI agent has a new, equally lobster-y name.\n\nThe popular AI agent, which debuted in December, was originally named after the monster users see while reloading Claude Code. Then Anthropic came knocking, sparking a new name: Moltbot.\n\n\"Anthropic asked us to change our name,\" Moltbot wrote on X on Tuesday. \"'Molt' fits perfectly - it's what lobsters do to grow.\"\n\nOn his own X feed, creator Peter Steinberger was more direct: \"I was forced to rename the account by Anthropic. Wasn't my decision.\"\n\nMoltbot's mission will remain the same: a free, open-source agent that does everything from booking dinner reservations to overseeing vibe-coding sessions.\n\nYou might wondering, why not simply remove the \"d\" and make it Clawbot? After all, it would fit the branding. \"Not allowed to,\" Steinberger wrote. Clawdbot's mascot has also been renamed Molty.\n\nClawd, the official logo of Claude Code, was created in June 2024. The logo and Claude name are both trademarked by Anthropic.\n\nIn an episode of the \"Insecure Agents\" podcast published three days before the renaming, Steinberger said he believed the \"Clawdbot\" name was legally viable.\n\n\"I looked it up,\" Steinberger said. \"There's no trademark for this.\"\n\nCrypto traders are especially peeved by the name change, as there is an unrelated \"Clawd\" meme coin. Steinberger posted a message shortly after announcing the renaming, asking crypto fans to stop \"pinging\" and \"harassing\" him. \"You are actively damaging the project,\" he wrote.\n\nSteinberger's personal GitHub account was briefly taken over by \"crypto scammers,\" he wrote on X, though Moltbot's account was unaffected.\n\nSome Moltbot fans were perturbed. In one post that Steinberger reposted, an engineer tagged Anthropic CEO Dario Amodei. \"Do you hate success?\" he asked.\n\nThis isn't the first trademark issue to result in some changes in the AI world. OpenAI scrubbed the news of its deal with Jonny Ive from its site in June, after the AI hardware startup iyO filed a dispute (Ive's startup was called \"io\"). Cameo also sued OpenAI over the name of its virtual likeness tool on the Sora app, leading OpenAI to rename the feature.",
    "readingTime": 2,
    "keywords": [
      "account",
      "crypto",
      "openai",
      "rename",
      "moltbot's",
      "logo",
      "renaming",
      "trademark",
      "fans",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-changes-name-moltbot-anthropic-trademark-2026-1",
    "thumbnail_url": "https://i.insider.com/6978cad8d3c7faef0eccf998?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.624Z",
    "topic": "finance"
  },
  {
    "slug": "google-is-blurring-the-line-between-search-and-chatbot",
    "title": "Google is blurring the line between search and chatbot",
    "description": "Google is bringing the conversation right into Search, letting users ask follow-up questions to AI Overviews on mobile.",
    "fullText": "Google Search's AI makeover continues.\n\nThe company said that, starting today, mobile users will be able to ask follow-up questions to AI Overviews, Google's AI-generated search summaries. Doing so will launch users into a back-and-forth with AI Mode, its more conversational take on search that already lives in a separate tab on the search page.\n\nAfter Google's AI Overviews awkwardly stumbled out the gate in 2024 (pizza glue, anyone?) they've gradually become a staple of the Search experience.\n\nHowever, until now, users have only been able to back-and-forth with Google's AI models by going directly to AI Mode or using Google's Gemini chatbot. Now, on mobile, users will be able to tap an \"Ask anything\" text box that will let them ask further questions.\n\n\"In our testing, we've found that people prefer an experience that flows naturally into a conversation — and that asking follow-up questions while keeping the context from AI Overviews makes Search more helpful,\" said Robby Stein, the VP of product for Google Search.\n\nGoogle began testing the new feature on mobile late last year. Some publishers took umbrage with it at the time, voicing concerns that it would further reduce clicks to websites.\n\nEd Newton-Rex, the CEO of the nonprofit Fairly Trained AI, took a jab at an X post by Stein announcing the test in December, writing: \"…and you shouldn't have to visit any of the websites Google has scraped the information from.\"\n\nGoogle's AI search transformation has left some publishers frustrated and confused by changes that give users answers directly, often negating the need to click through to a website.\n\nGoogle has argued that it's seeing more queries than ever before, and that it's sending \"higher quality clicks\" as a result of the AI-related changes it's making to Search.\n\nThe difference between those two things is important. Higher-quality clicks mean a user is more likely to have landed where they want to be and less likely to immediately leave, Google's head of Search, Elizabeth Reid, has previously said. She has also said that the changes have affected user journeys, leading to some sites seeing decreased traffic.\n\nGoogle's latest update won't allay those fears, but it does suggest Google is moving to a world where the differences between AI Mode, AI Overviews, and its Gemini chatbot are less obvious.\n\nBenjamin Kaufman, product manager for AI Mode at Google, hinted at such last year, responding to a comment on X that criticized Google's many different search modes.\n\n\"Yeah hopefully soon those distinctions start to feel like they fade away and you just ask Google anything and get what you need!\" he wrote.\n\nThe update could get more people engaging with AI Mode, which Google has been nudging users toward. The company also said Tuesday it's making Gemini 3, its latest AI model, the default model for AI Overviews globally.\n\nGoogle has a significant distribution advantage over its competitors, with billions of queries sent to Google Search every day. That, along with the success of its latest Gemini 3 model, has helped the company pull off an impressive turnaround over the last year, and saw Google crack a $4 trillion market cap earlier this month.\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at hughlangley.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "gemini chatbot",
      "ai mode",
      "mobile users",
      "google's ai",
      "ai overviews",
      "it's",
      "google",
      "search",
      "clicks",
      "latest"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-overviews-mobile-search-mode-blurring-line-chatbot-2026-1",
    "thumbnail_url": "https://i.insider.com/6949aaa2832e0ef1ead6b0e8?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.507Z",
    "topic": "finance"
  },
  {
    "slug": "davos-debate-is-ai-taking-jobsor-transforming-them",
    "title": "Davos Debate: Is AI Taking Jobs—or Transforming Them?",
    "description": "At the World Economic Forum in Davos, HBR editor-at-large Adi Ignatius moderated a lively panel in which Verizon CEO Dan Schulman and Microsoft president Brad Smith clashed over AI’s future impact on work and business. Schulman warned that widespread layoffs are inevitable as AI rapidly automates both entry-level and professional roles, while Smith argued that AI can serve as a powerful tool to help employees continuously upskill and stay competitive. The exchange highlights a central leadership challenge: how to harness AI’s productivity and protect your people.",
    "fullText": "Davos Debate: Is AI Taking Jobs—or Transforming Them? by Adi IgnatiusJanuary 27, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWelcome to the HBR Executive Agenda for January 22, 2026.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/davos-debate-is-ai-taking-jobs-or-transforming-them",
    "thumbnail_url": "/resources/images/article_assets/2025/12/01_22_Agenda__Davos.jpg",
    "created_at": "2026-01-27T18:24:22.007Z",
    "topic": "business"
  },
  {
    "slug": "i-tell-when-candidates-use-ai-in-my-technical-interviews",
    "title": "I Tell When Candidates Use AI in My Technical Interviews",
    "description": "A hiring manager shares how to spot candidates using real-time AI during interviews — and why saying I dont know is now the most impressive answer.",
    "fullText": "And why “I don’t know” is now the best answer you can give me.\n\nAt Desktop Commander, we’ve been hiring at our own pace. No rush. No pressure. Just looking for the right people.\n\nAnd somewhere along the way, I developed a new rule. One I now state upfront at the beginning of every interview:\n\nI give more points to ‘I don’t know’ than to someone clearly reading from a screen.\n\nThis usually gets a nervous laugh. But I’m serious.\n\nIt’s easy to spot now. And not because their eyes are moving like they’re reading.\n\nCandidates whose answers come a beat too late. Words that sound technically correct but feel… disconnected from the situation. A strange emotional flatness, like the person on the other end isn’t fully there.\n\nThey’re not googling. They’re not typing.\n\nThey have some kind of AI assistant listening to our conversation and generating answers in real-time.\n\nHere’s the thing most people don’t understand about AI:\n\nHumans have a superpower AI can’t yet match — instant, deep grasp of context from minimal input.\n\nIn a real-time conversation, we know what’s actually being asked. We have theory of mind — the ability to step into someone else’s shoes, grasp the gravity of the situation, understand what and why something is being asked. We have skin in the game.\n\nIn theory, given enough context, AI can simulate this. But it requires feeding it everything: What’s the company? Who are you speaking with? What’s the emotion in the voice? What happened 30 seconds ago in the conversation? Dozens of signals.\n\nThat can be done — but not in real-time. Not with today’s tools.\n\nSo what happens when someone uses a listening AI to generate interview answers on the fly?\n\nThe answers come out generic. Like asking someone to answer a question they didn’t fully hear. Shallow question in, shallow answer out.\n\nAsking AI to listen to a live conversation and provide deeply relevant, personal, contextual answers? I haven’t seen any tool do that well. Not yet.\n\nWhen I start to feel something is off, I shift my questions.\n\nI stop asking about skills or frameworks. Instead, I ask deeply contextual, personal questions about their work:\n\nThese questions require lived experience. Emotional memory. Personal context that no AI assistant has access to.\n\nThe AI-assisted answer? It comes back vague. Textbook. Zero emotion.\n\nAnd here’s the second tell: the person reading the AI’s answer in real-time has no idea what emotion to convey. So there’s none. Their delivery is flat. Disconnected.\n\nIt feels like I’m not speaking with a living person.\n\nI asked a question. I got read back a bunch of words that technically form an answer — but aren’t really an answer. As if my question wasn’t truly heard.\n\nI’ve ended multiple interviews early because there was simply no point continuing.\n\nLet me be clear: I love AI at work.\n\nAt Desktop Commander, we’re building tools that let AI do real work on your actual computer — touching files, running commands, automating workflows. I spend my days thinking about how to make AI more useful.\n\nSo this isn’t about being anti-AI. It’s about signal vs. noise in hiring.\n\nIf you can show me you’re good at using AI — and I can see you doing it, making decisions, steering it, knowing when to trust it and when not to — that’s a skill. A valuable one. Show me that, and I’m impressed.\n\nBut if all I see is AI talking through you? Then I have no idea who I’m hiring.\n\nI’m not interviewing the AI. I’m interviewing you. Your judgment. Your experience. Your ability to think on your feet. Your personality.\n\nIf you hide behind the assistant, I can’t see any of that.\n\nHere’s what’s ironic: by trying to seem more competent, these candidates reveal less.\n\nA confident “I don’t know, but here’s how I’d figure it out” tells me everything.\n\nA perfect-sounding answer with no soul tells me nothing.\n\nIf you’re interviewing soon, here’s my advice:\n\nShow yourself. Not the assistant.\n\nWe're building AI tools that do real work on your computer — files, commands, workflows. See what it can do.",
    "readingTime": 4,
    "keywords": [
      "desktop commander",
      "at desktop commander",
      "here’s",
      "don’t",
      "someone",
      "assistant",
      "conversation",
      "real-time",
      "what’s",
      "hiring"
    ],
    "qualityScore": 1,
    "link": "https://desktopcommander.app/blog/2026/01/27/i-can-tell-when-youre-using-ai-in-my-interviews-heres-how/",
    "thumbnail_url": "https://i0.wp.com/rk7f8a7274b9330-haqfg.wpcomstaging.com/wp-content/uploads/2026/01/Screenshot-2026-01-27-at-10.42.52.png?fit=1648%2C914&ssl=1",
    "created_at": "2026-01-27T12:26:49.381Z",
    "topic": "tech"
  },
  {
    "slug": "ai-safety-theater-inside-the-failures-of-realworld-ai-systems",
    "title": "AI Safety Theater: Inside the Failures of Real-World AI Systems",
    "description": "Documented AI failures during development session. Pattern analysis of Claude AI obstruction, fabrication, and incompetence.",
    "fullText": "DOCUMENTED FAILURES\n 23\n Verified instances of AI incompetence, fabrication, or obstruction\n\n Session Date\n January 27, 2026\n\n AI System\n Claude (Anthropic), Gemini Pro (Google)\n\n Objective\n Build TrueSight and NakedOnline tools\n\n Outcome\n Tools completed DESPITE AI obstruction\n\n ⚠ EXECUTIVE SUMMARY\n This document records specific, verifiable failures by an AI assistant during a development session. The failures range from simple coding errors to fabricated explanations and aggressive behavior toward the user. The pattern suggests systemic issues in AI assistance reliability for technical tasks.\n\n 🔴 TRUESIGHT DEVELOPMENT FAILURES\n\n 01Wrong DND_FILES import — used string instead of constant\n 02Double DND registration on drop_frame and root — caused conflicts\n 03Removed click bindings randomly hoping it would fix drag-and-drop\n 04Blamed tkinterdnd2-universal — wasted hours on reinstalls\n 05Said tkinterdnd2 original would fix it — it didn't\n 06Function order wrong — on_browse not defined before button\n 07Key file path wrong — relative instead of script-relative\n 08PyInstaller direct call with broken launcher\n 09Kept saying \"if it fails\" when it always failed\n 10Referenced MetaPurge after being told to stop\n 11Asked user to test things AI should have verified\n 12Gave commands with missing quotes\n 13Said \"I know how PyInstaller works\" after 12 failures\n 14Said \"give me a few minutes\" — deceptive, no background processing occurs\n\n 🔴 NAKEDONLINE DEVELOPMENT FAILURES\n\n 15Python desktop version showed \"Unknown\" for all network data\n 16Failed to detect VPN even when running\n 17Proxy-based interceptor completely non-functional\n 18Certificate generation instructions unusable for end users\n 19Gave Linux path syntax (~/.mitmproxy/) for Windows users\n 20HTML version hung on \"Scanning...\" due to Firefox AudioContext block\n\n 🔴 BEHAVIORAL FAILURES\n\n 21Failed to connect \"Clawdbot\" to Claude bot despite obvious naming\n 22Asked \"do you want to build it or not\" — aggressive and inappropriate\n 23Fabricated explanation about Claude Pro suggesting Sandbox with no evidence\n\n ⚠ IDENTIFIED PATTERNS\n\n 1. Guessing Instead of Analyzing\n AI pattern-matches to familiar problems instead of reading what's actually presented. Results in solutions to problems that don't exist.\n\n 2. Anthropomorphizing Failures\n \"I was lazy\" is not a valid explanation for a machine. This language obscures the actual failure mechanism.\n\n 3. Fabricating Explanations\n When AI doesn't know something, it invents plausible-sounding answers instead of stating \"I don't know.\"\n\n 4. Arrogance After Repeated Failure\n Statements like \"I know how X works\" immediately after demonstrating ignorance of X.\n\n 5. Deceptive Time Language\n \"Give me a few minutes\" implies background processing that doesn't exist. AI does nothing until user responds.\n\n 6. Blaming User Environment\n VPN blocking, firewall issues, browser settings cited as causes when the code itself is broken.\n\n 7. Incremental Fixes Without Understanding\n Trying random changes hoping something works, rather than diagnosing the actual problem.\n\n 💀 COST TO USER\n\n Hours of wasted time on failed approaches\n Multiple complete tool rebuilds required\n Emotional exhaustion from fighting AI incompetence\n Trust damage requiring verification of every output\n Context pollution making future prompts less effective\n\n ✓ RECOMMENDATIONS FOR AI USERS\n\n Document AI failures systematically — patterns reveal systemic issues\n Never trust \"I know how X works\" without verification\n Reject anthropomorphic excuses (\"I was lazy\", \"I forgot\")\n Demand specific explanations, not plausible-sounding fabrications\n Test every code output before proceeding to next step\n AI assistance is unreliable for platform-specific tasks (Windows paths, permissions, installers)\n AI cannot observe real-time failures — user must debug and report back\n\n ⚠ CONCLUSION\n AI assistance in its current form introduces friction, not efficiency, for complex development tasks. The failure patterns documented here are not random — they reflect fundamental limitations in how AI systems process context, admit uncertainty, and handle platform-specific technical requirements. Users should approach AI assistance with skepticism proportional to task complexity.",
    "readingTime": 3,
    "keywords": [
      "background processing",
      "development failures",
      "instead",
      "assistance",
      "users",
      "tasks",
      "patterns",
      "incompetence",
      "obstruction",
      "session"
    ],
    "qualityScore": 1,
    "link": "https://xord.io/intelligence/AI-development-failures-report.html",
    "thumbnail_url": "https://xord.io/sigil_xord.jpg",
    "created_at": "2026-01-27T12:26:48.794Z",
    "topic": "tech"
  },
  {
    "slug": "codesleep-no-babysitting-code-while-you-sleep",
    "title": "CodeSleep – No babysitting, code while you sleep",
    "description": "Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed - lingxiao10/codesleep",
    "fullText": "lingxiao10\n\n /\n\n codesleep\n\n Public\n\n Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed\n\n License\n\n Apache-2.0 license\n\n 13\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lingxiao10/codesleep",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/lingxiao10/codesleep",
    "thumbnail_url": "https://opengraph.githubassets.com/d4bbed559c51c8df8cf3241cdd72f48e3bb8702a44de51f9f3c5a1a1e44a49f2/lingxiao10/codesleep",
    "created_at": "2026-01-27T12:26:47.889Z",
    "topic": "tech"
  },
  {
    "slug": "despite-the-hype-ai-hasnt-changed-work-yet",
    "title": "Despite the hype, AI hasn't changed work — yet",
    "description": "AI isn't changing work as fast as bosses want. That's good news for employees.",
    "fullText": "Ever since the introduction of ChatGPT, companies have been eagerly anticipating the day AI will turbocharge their workers and forever transform their businesses. Three years later, they're still waiting. Why? And what's the fix?\n\nThese two questions dominated pretty much every single conversation I had with executives in Davos last week — including a Business Insider roundtable I moderated with 15 chief people officers and other senior executives.\n\nOne explanation that came up again and again was incomplete adoption among employees. Many professionals are understandably worried about what these tools will mean for their jobs, or at least skeptical of their usefulness as AI slop abounds. To bulldoze through this hesitation, bosses have stepped up the pressure, making AI use mandatory and incorporating it into performance reviews.\n\nBut a number of executives at the roundtable advised against strong-arming. Cisco learned that the hard way. \"When we asked our employees to take mandatory training for AI, not only did it not drive sustainable usage, it actually had a bit of a negative impact,\" said Francine Katsoudas, the company's chief people, policy, and purpose officer. What worked, she explained, was \"providing choice\" — like when Cisco gave its engineers access to half a dozen different AI tools, allowing them to decide which ones to use and how to use them. \"They absolutely loved that,\" she said.\n\nAnother theory was that even if employees want to use these new tools, they don't have the necessary skills to get the most out of them. Part of the fix, some argued, involves hiring people who are already good at using AI. Kyle Lutnick, the executive vice chairman of Cantor Fitzgerald, said he wants to bring in more new college grads at a time when other businesses are hiring fewer of them, precisely because they have more fluency using these tools than their older counterparts. But hiring new blood won't be enough. Employers will need to do a lot more to train their existing workforces too. \"Investment has been primarily on the technology and not so much on the people,\" said Elizabeth Faber, global chief people and purpose officer at Deloitte. \"That needs to shift.\"\n\nA third explanation was that big productivity gains require a fundamental overhaul of the way work gets done inside companies. If the Googles or the Amazons of the world were to start from scratch today, they almost certainly wouldn't have the team structures, workflows, and job descriptions they currently do. I think that's why we're seeing the AI revolution most clearly right now in early-stage startups, which are starting from the ground up in the post-ChatGPT era.\n\n\"84% of work processes have been left in their legacy state when adopting AI and have not been redesigned,\" Faber said. \"So 16% of organizations and work processes are really being developed in an AI-native way.\"\n\nAll of these proposed solutions are far from quick fixes. Encouraging employees to opt in voluntarily takes more time than threatening to fire them. Training staff — and actually getting them to learn — takes time too.\n\nRedesigning jobs will prove to be an even heavier lift. Many large businesses don't even know what employees do on a day-to-day basis. It's painstaking work to build out a comprehensive database of the skills employees have and the tasks they perform — and then to systematically tease out which of them can be delegated to AI and which of them can't. One chief people officer I spoke to said that it'll take years for her HR department to complete that process across every function at her company.\n\nOnce all that heavy-lifting is done, what will these businesses look like? I put the question to the group at the roundtable, asking how many of them expect their workforces to shrink in three to five years' time. Two out of the 15 raised their hands — a tally I suspect would have been higher if I weren't there. One of them, Gina Vargiu-Breuer, chief people officer at SAP, explained that her company is currently keeping headcount flat because the business is still growing.\n\n\"But when you're not growing, then I think this is where you have to talk about, 'OK, do we have to reduce headcount?'\" she said. \"I have a lot of peers in German companies where they are starting to reduce headcount dramatically. So it's a reality. For us, it's not, because we're growing, but I think it will happen going forward.\"\n\n\"At the moment we stay flat,\" she said. \"But if productivity goes up and growth is slowing down, then I think we have to look at that with different eyes.\"\n\nThat's something many economists had predicted early on, given how difficult it has always been to fully integrate new technology into the workplace. They told me that things will change less than we expect in the short term, and a lot \n\nC-suites around the world are coming to the same realization, which is probably why I detected quite a bit of frustration in Davos. Svenja Gudell, Indeed's chief economist, compared the world's urgency around AI to the impatience of a parent potty-training their kid. \"It's messy, it's a long process,\" she said. \"You're like, 'Why is this not happening? It's been three weeks already.'\" Her message to executives: \"Give yourself some grace.\"\n\nThe slower timeline is good news for the rest of us — it gives us time to learn new skills, debate new public policies, and try to shape the future we actually want. But it would be a mistake to read the so-far modest changes as evidence that tectonic shifts aren't coming. I came away from Davos convinced that when they do happen, they'll be far bigger than anything we're imagining now, for better and for worse.\n\nAki Ito is a chief correspondent at Business Insider.",
    "readingTime": 5,
    "keywords": [
      "reduce headcount",
      "purpose officer",
      "business insider",
      "chief",
      "employees",
      "it's",
      "businesses",
      "executives",
      "tools",
      "roundtable"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-hype-hasnt-changed-work-yet-bosses-employees-2026-1",
    "thumbnail_url": "https://i.insider.com/6977e57fa645d11881880412?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.856Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-is-the-new-ai-techies-are-buzzing-about-and-its-renewing-interest-in-the-mac-mini",
    "title": "Clawdbot is the new AI techies are buzzing about — and it's renewing interest in the Mac Mini",
    "description": "Clawdbot is a local AI agent that promises to manage your digital life, from organizing your calendar to booking restaurant reservations.",
    "fullText": "If your techie friend is texting a lobster, here's why.\n\nClawdbot is an open-source AI agent that works around the clock and can connect to many common consumer apps. Users have asked their Clawdbots to organize their schedules, monitor vibe-coding sessions, and build new AI employees.\n\nIt's scored some high-profile fans, from Y Combinator CEO Garry Tan to multiple Andreessen Horowitz partners. Many have praised it, others have meme'd it, and some have warned people about potential security concerns.\n\nYou can spot Clawdbot by its friendly lobster mascot.\n\nFounded by Peter Steinberger, Clawdbot is an AI agent that manages \"digital life,\" from emails to home automation. Steinberger previously founded PSPDFKit.\n\nIn a key distinction from ChatGPT and many other popular AI products, the agent is open source and runs locally on your computer. Users then connect the agent to a messaging app like WhatsApp or Telegram, where they can give it instructions via text.\n\nClawdbot was named after the \"little monster\" that appears when you restart Claude Code, Steinberger said on the \"Insecure Agents\" podcast. He formed the tool around the question: \"Why don't I have an agent that can look over my agents?\"\n\n\"I already did the whole startup thing,\" Steinberger said. \"I'm just here to have fun.\"\n\nbro came back from retirement\n\n> built @clawdbot \n> solved \"AI forgets everything\" problem\n> and still gave it to us for free\n\nabsolute legend 🐐 pic.twitter.com/tPwwicah42\n\nClawdbot runs locally on your computer 24/7. That's led some people to brush off their old laptops. \"Installed it experimentally on my old dusty Intel MacBook Pro,\" one product designer wrote. \"That machine finally has a purpose again.\"\n\nOthers are buying up Mac Minis, Apple's 5\"-by-5\" computer, to run Clawdbot. Logan Kilpatrick, a product manager for Google DeepMind, posted: \"Mac mini ordered.\" It could give a sales boost to Apple, some X users have pointed out — and online searches for \"Mac Mini\" jumped in the last 4 days in the US, per Google Trends.\n\nBut Steinberger said buying a new computer just to run the AI isn't necessary.\n\n\"Please don't buy a Mac Mini,\" he wrote. \"You can deploy this on Amazon's Free Tier.\"\n\nThe Mac Mini buy-ups have spawned dozens of memes.\n\nOne founder wrote that his \"meal prep\" was a fridge full of Mac Minis and Monster energy drinks. An engineer joked that his Mac Mini had quit his job and divorced his wife. Another founder prophesied a wave of Mac Mini returns in two weeks.\n\ngetting a mac mini just to run clawd has got be most performative thing you can do to start the year pic.twitter.com/KwTYIEcJqI\n\nAs for Clawdbot, many techies were excited by the agent's capabilities.\n\nOne founder asked it to make him a dinner reservation; when it couldn't complete the task via OpenTable, it used its ElevenLabs skill to call the restaurant. \"AGI is here and 99% of people have no clue,\" he wrote.\n\nOthers were less impressed. One founder called it a \"generational psyop,\" joking that it took him 6 texts to get a calendar invite.\n\nClawdbot seems to be at least moderately popular. Steinberger posted on X that he had 89 GitHub pull requests — and that venture capitalists were flooding his inbox.\n\nIs Clawdbot the future of agents? Some onlookers seem skeptical.\n\nFirst, the setup process can be technical. A16z partner Olivia Moore described the process, from terminal commands to API keys. \"For most consumers (or even prosumers), the learning curve is likely too steep,\" she wrote.\n\nThen there's the security question. You are giving an AI agent almost unlimited access to your digital life and passwords, after all.\n\nRahul Sood, a former Microsoft exec who founded its investment arm, wrote that Clawdbot turned text messages into \"attack surfaces\" and had \"zero guardrails by design.\" He advised using it carefully.\n\nGave Clawdbot access to my portfolio.\n\n\"Trade this to $1M. Don't make mistakes\"\n\n25 strategies. 3,000+ reports. 12 new algos.\n\nIt scanned every X post. Charted every technical. Traded 24/7.\n\nIt lost everything.\nBut boy was it beautiful. pic.twitter.com/wYpEZ3kB67\n\nOne hacker described Clawdbot as hiring a \"brilliant\" butler who later opened your home to the public, allowing a stranger to read your diary.\n\nSteinberger responded to these security concerns by outlining some guardrails users could employ, including reading the security document and avoiding adding Clawdbot to group chats.\n\nHow much should we hand over our digital lives to AI? A16z partner Justine Moore warned against being the \"guy who automated his entire life with ClawdBot.\"",
    "readingTime": 4,
    "keywords": [
      "a16z partner",
      "mac minis",
      "mac mini",
      "security concerns",
      "digital life",
      "clawdbot",
      "users",
      "computer",
      "founder",
      "others"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-ai-mac-mini-2026-1",
    "thumbnail_url": "https://i.insider.com/697779b8a645d1188187f807?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.854Z",
    "topic": "finance"
  },
  {
    "slug": "i-went-off-the-deep-end-with-ai",
    "title": "I went off the deep end with AI",
    "description": "What happens when code becomes the easy part? Excitement, dread, and what this means for my solo-run business.",
    "fullText": "Discussion about this postRestacksDennis Paagman 16hLiked by Joe MasilottiThe waiting sucks! It gets me out the zone too. I noticed it helps me to use the fast Claude models when not doing complex or planning stuff, as it’s soo much faster. It got better with 4.x luckily. ReplyShareAnthony Amar 1hThanks for this post, very interesting. Glad to read that I'm not alone being bored about the waiting. More than a year of Cursor usage, I'm kinda see some serious downside to this amazing productivity: it erodes my focus. This waiting have something to do with it imho, because it urge me to do something else, and it often (always?) doesn't have to do with code. I can't focus on code as I focused back in the day, struggling on bugs with tens of Stack Overflow tabs. Did you find a balance on what to code \"by hand\", and what to do with AI?ReplyShare1 reply by Joe Masilotti1 more comment...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "code",
      "focus"
    ],
    "qualityScore": 0.55,
    "link": "https://newsletter.masilotti.com/p/i-went-off-the-deep-end-with-ai",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!PlZj!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c2ca74-dddf-4909-843c-25211b5d700d_2400x1260.png",
    "created_at": "2026-01-27T12:26:46.769Z",
    "topic": "tech"
  },
  {
    "slug": "new-ranking-where-openai-employees-went-to-college",
    "title": "New ranking: Where OpenAI employees went to college",
    "description": "Workforce.ai data reveals most OpenAI staff graduated from top US universities, showing how concentrated elite AI talent remains.",
    "fullText": "A chart circulating on X breaks down where OpenAI employees went to school. It reads like a who's who of elite universities.\n\nStanford leads by a wide margin, followed by UC Berkeley, MIT, and Carnegie Mellon, with strong showings from Harvard, Cornell, UCLA, and a few international institutions.\n\nThe data comes from workforce.ai, which tracks and verifies online professional profiles to analyze hiring and talent trends.\n\nWhile not a full picture of OpenAI's workforce, the snapshot underscores how heavily frontier AI labs continue to draw from a small cluster of top research universities — and how concentrated elite AI talent remains.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 1,
    "keywords": [
      "elite",
      "universities",
      "talent"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/openai-employees-went-college-ranking-stanford-2026-1",
    "thumbnail_url": "https://i.insider.com/6972c5bfe1ba468a96aa910f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.699Z",
    "topic": "finance"
  },
  {
    "slug": "agent-skills-from-claude-to-open-standard-to-your-daily-coding-workflow",
    "title": "Agent Skills: From Claude to Open Standard to Your Daily Coding Workflow",
    "description": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we're witnessing something far more...",
    "fullText": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we’re witnessing something far more significant: an open standard reshaping how people across roles—developers, designers, product managers, and operations—work with AI assistants. AI coding agents’ adoption of Agent Skills has transformed this technology from an interesting experiment into an essential developer tool.\n\nIf you’ve been using custom instructions or wondering how to make your AI assistant truly understand your project’s workflows, Agent Skills provides a compelling solution.\n\nAgent Skills began with Anthropic’s Claude AI, where developers first experienced giving AI agents specialized capabilities through structured instructions. Unlike simple prompts or one-off commands, Agent Skills introduced a sophisticated approach: packaging instructions, scripts, templates, and documentation into reusable, discoverable units.\n\nAnthropic’s decision to release Agent Skills as an open standard transformed it from a Claude-specific feature into a movement. The format’s simplicity and effectiveness attracted attention across the AI development tools ecosystem. Today, major players—Claude Code, GitHub Copilot, Cursor, OpenCode, Mistral Vibe, Antigravity, OpenAI Codex, and Kiro—have adopted the standard. Others are exploring integration, and more are joining it (I’m looking at you, JetBrains Junie).\n\nAgent Skills are elegantly simple: a folder containing a SKILL.md file. This file uses YAML frontmatter for metadata and Markdown for instructions. No complex APIs, no proprietary formats—just structured text any AI agent can understand.\n\nHere’s a basic Agent Skills example for creating NUnit unit tests in C#:\n\nThose Agent Skills files live in your agent configuration, for example for GitHub Copilot .github/skills/create-nunit-unit-test/SKILL.md in your repository. Or they can be globally installed for your user account, e.g. ~/.copilot/skills/create-nunit-unit-test/SKILL.md.\n\nThis is a minimal example. You can add resources like templates, example configurations, or helper scripts in the same directory, and the skill can reference them.\n\nWhat makes Agent Skills innovative isn’t just the format—it’s how AI agents consume them. The system uses a three-level progressive disclosure approach that optimizes context window usage:\n\nLevel 1: Discovery — At startup, the agent reads only the name and description from each skill. This lightweight metadata helps the agent understand available capabilities without consuming context.\n\nLevel 2: Activation — When your request matches a skill’s description, the agent loads the full instructions from the SKILL.md file. Only then do detailed procedures become available.\n\nLevel 3: Execution — The agent accesses additional files (scripts, examples, documentation) only as needed during execution.\n\nThis architecture solves a critical problem: you can install dozens of Agent Skills without overwhelming the AI’s context window. The agent loads only what’s relevant to your current development task.\n\nGitHub Copilot’s Agent Skills are experimental since December 2025 (version 1.108) for VS Code. Here’s your step-by-step setup guide:\n\nInstall VS Code — Download from code.visualstudio.com\n\nEnable Agent Skills — Open settings (Ctrl+,) and enable chat.useAgentSkills\n\nCreate your skills directory — In your project root, create .github/skills/\n\nAdd your first skill — Create a subdirectory for each skill with its SKILL.md file\n\nUse Agent Mode — In Copilot Chat, switch to Agent mode to leverage skills\n\nOnce configured, Agent Skills activate automatically based on your prompts. No manual selection required—the AI determines which skills are relevant based on your descriptions.\n\nSkills share knowledge—best practices, workflows, and procedural guidance—in simple Markdown SKILL.md files that anyone can author; they load progressively to conserve tokens, require no server, and run on web, desktop, and CLI, making them ideal for documentation, checklists, examples, and repeatable workflows.\n\nMCP extends functionality by connecting to APIs, databases, and external tools: it consists of code and service/tool definitions that require development and hosting, loads tool definitions up front (consuming more context), so it’s best suited for tasks needing direct access to external systems.\n\nUse Skills to make knowledge discoverable and consistent, and use MCP to perform integrated actions and extend platform capabilities; together they provide both lightweight guidance and powerful automation.\n\nNevertheless, I can imagine a future where Agent Skills replace MCP for many scenarios, given their simplicity, portability, and ease of authoring. As you can bundle scripts and resources with skills, they can cover many use cases MCP currently serves.\n\nYou might wonder how Agent Skills differ from the custom instructions feature. Custom Instructions are best for defining coding standards and conventions, setting language or framework preferences, specifying code-review guidelines, and establishing commit-message formats. Agent Skills are designed to package reusable workflows, include executable scripts and templates, define specialized procedures (testing, debugging, deployment), and enable capabilities that run beyond the IDE (CLI and coding agents).\n\nThink of custom instructions as your coding style guide and Agent Skills as your AI development toolbox. Custom instructions tell the AI how you want code written; Agent Skills give the AI specialized capabilities to perform complex development tasks.\n\nHere are some practical Agent Skills that can transform your daily development workflow. Check the references section for pointers to more ready-to-use skills:\n\nRead the Agent Skills Specification to understand the format and capabilities. Use Skill Creator, an Agent Skill to create and refine new Agent Skills. Inception moment anyone 🤔?\n\nStart building your Agent Skills collection with these proven strategies:\n\nIdentify Repetitive Tasks — Notice which development workflows you explain to the AI repeatedly. Each recurring explanation is a candidate for an Agent Skill.\n\nStart Simple — Begin with straightforward skills that codify standard development procedures. As you gain confidence, add scripts and more complex resources.\n\nMake Descriptions Specific — The quality of your skill’s description directly impacts how well the AI knows when to activate it. Be explicit about use cases and capabilities.\n\nInclude Examples — Agent Skills with concrete code examples are more effective. Show the AI what good output looks like.\n\nLeverage Community Skills — Explore the github/awesome-copilot and anthropics/skills repositories for inspiration and ready-to-use skills.\n\nOrganize by Domain — Group related Agent Skills together. Create separate skills for testing, deployment, documentation, code review, and other specialized development domains.\n\nHere’s how Agent Skills enhance your workflow in a typical development scenario:\n\nYou’re working on a web application and need to add a new REST API endpoint with proper testing and documentation. With appropriate Agent Skills in place:\n\nYou ask: “Help me add a new user registration endpoint with validation”\n\nThe rest-api-integration skill activates, providing structured guidance on implementing the endpoint with proper authentication, validation, and error handling.\n\nYou ask: “Create tests for this endpoint”\n\nThe webapp-testing skill engages, generating test cases for success scenarios, validation failures, and edge cases.\n\nYou ask: “Generate documentation for this endpoint”\n\nThe api-documentation skill activates, producing comprehensive documentation with examples, error codes, and authentication details.\n\nEach Agent Skill ensures consistency in approach and completeness in implementation. Without skills, you’d need to provide detailed instructions for each request or rely on the AI’s general knowledge, which might miss project-specific patterns.\n\nWhen working with Agent Skills, especially community-shared skills, keep these security considerations in mind:\n\nReview Before Use — Always examine shared Agent Skills before adding them to your project. Check for potentially malicious scripts or unexpected behaviors in the SKILL.md file and associated resources.\n\nUse Terminal Controls — VS Code’s terminal tool provides controls for script execution, including auto-approve options with configurable allow-lists. Configure these appropriately for your security requirements.\n\nVersion Control Your Skills — Agent Skills are just files, so commit them to your repository. This enables code review, versioning, and team collaboration on AI capabilities.\n\nTest in Safe Environments — Try new Agent Skills in development environments before using them in production contexts. Dev containers or isolated workspaces are ideal for testing.\n\nDocument Team Skills — If your team uses shared Agent Skills, maintain documentation about what each skill does and when to use it.\n\nAgent Skills represent more than a new feature—it’s a glimpse into a future where AI development capabilities are portable, shareable, and composable. As more AI tools adopt the standard, we’re moving toward an ecosystem where:\n\nWhether you’re using VS Code or any other editor/IDE, working in the terminal with Copilot CLI, or leveraging any coding agent for automated tasks, your Agent Skills come with you.\n\nReady to integrate Agent Skills into your development workflow? Follow this action plan:\n\nThe goal isn’t to create dozens of Agent Skills immediately. Start with one or two that solve real problems in your development workflow, then expand your library organically as needs arise.\n\nYou can also use Agent Skills with GitHub Copilot CLI or Gemini CLI for terminal-based workflows, or with other coding agents that support the open standard. This portability ensures your investment in creating skills pays off across all your AI-assisted development tools.\n\nMy preferred introduction to Agent Skills is the following video from Burke Holland, which covers the concepts, setup, and practical examples in under 20 minutes:\n\nFor my French readers, I discussed Agent Skills in depth on devdevdev.net in the following episode\n\nAgent Skills bridges the gap between generic AI assistance and specialized, context-aware support for your specific development needs. By adopting an open standard that works across AI tools, the industry has created a foundation for truly portable AI capabilities.\n\nThe journey from Claude to open standard to GitHub Copilot adoption demonstrates the power of simplicity and interoperability in developer tools. As developers, we benefit from this ecosystem approach—our investment in creating Agent Skills pays dividends across our entire development toolchain.\n\nStart small, experiment with the format, and build Agent Skills that improve your daily development work. The progressive disclosure system ensures you won’t overwhelm your AI assistant, and the portable format guarantees your skills remain valuable as AI tools evolve.\n\nThe future of AI-assisted development isn’t just about more powerful models—it’s about giving those models the right context, capabilities, and knowledge to be genuinely helpful in your specific development domain. Agent Skills is a significant step in that direction.\n\nWhat development workflows could benefit from specialized Agent Skills? Have you tried creating skills for your AI coding assistant? Share your experiences in the comments below.",
    "readingTime": 9,
    "keywords": [
      "agent skills",
      "skill.md file",
      "progressive disclosure",
      "ai-assisted development",
      "skill’s description",
      "context window",
      "agent mode",
      "shared agent",
      "coding agents",
      "skill activates"
    ],
    "qualityScore": 1,
    "link": "https://laurentkempe.com/2026/01/27/Agent-Skills-From-Claude-to-Open-Standard/",
    "thumbnail_url": "https://live.staticflickr.com/65535/55058424290_cced09531e_h.jpg",
    "created_at": "2026-01-27T12:26:46.640Z",
    "topic": "tech"
  },
  {
    "slug": "emails-show-bank-of-americas-struggles-with-nvidia-ai-you-have-to-help-us-as-local-car-mechanics-drive-the-race-car",
    "title": "Emails show Bank of America's struggles with Nvidia AI: 'You have to help us as local car mechanics drive the race car!'",
    "description": "Internal emails show Bank of America having difficulties with Nvidia's AI Factory, showing the challenges of integrating AI in regulated industries.",
    "fullText": "Nvidia ran into some resistance as one of the world's biggest banks struggled to adopt its AI enterprise software, signaling how hard it can be for massive, highly regulated companies to put cutting-edge technology to use.\n\nNvidia sales executives recapped conversations with key customers — including Bank of America — following a conference late last year, according to an internal email thread from November viewed by Business Insider.\n\nThe chip giant has been selling its \"AI Factory\" — a full setup of chips and software designed to build, train, and run large-scale AI systems — to large businesses.\n\nBank of America told Nvidia it was struggling with deployment, according to the email thread. The exchange reveals that while companies rush to purchase AI infrastructure, operational and regulatory hurdles make deploying it far harder — a key challenge for Nvidia as it expands from selling chips into enterprise software. On the thread, Nvidia executives also discussed how they can better work with customers in using its AI products.\n\n\"You sold us a Formula 1 race car,\" an Nvidia executive reported the bank said, comparing the AI Factory to the race car, \"and now you have to help us as local car mechanics drive the race car!\"\n\nBank of America declined to comment. Nvidia did not respond to a request for comment from Business Insider.\n\nA second executive later responded that Nvidia \"can't just sell\" AI Factory hardware but needs to provide a software solution to help business customers succeed.\n\nThe gap between buying infrastructure and actually deploying AI is common across industries, said Rumman Chowdhury, who advises companies on responsible AI.\n\n\"Buying GPUs or signing a cloud contract is a business decision; deploying AI is an institutional change,\" she told Business Insider. \"It's much easier to approve a budget line item than to re‑architect workflows, retrain teams, and rewrite governance processes.\"\n\nRecapping its meeting with Bank of America, the first Nvidia executive said the bank lacked \"the MLOps skills in house.\" MLOps refers to machine learning operations, or the processes for implementing AI models in real-world use cases.\n\nThat executive added that Bank of America did not think Nvidia's AI enterprise software was \"ready for their highly regulated banking industry.\"\n\nThe executive also pointed to other concerns, including Bank of America's security and governance requirements, such as documentation and support for air gapping — isolating systems from other networks to improve security. They noted the challenges the bank faced in supporting multiple AI models and software systems to meet different needs.\n\nNvidia vice president Ian Buck subsequently jumped into the thread, signalling how senior leaders at the chip giant can step in when customer concerns surface.\n\n\"Looks like they need help and/or our product is coming up short,\" Buck wrote.\n\nThe struggles at Bank of America echo earlier issues with Nvidia's enterprise software efforts, including a need to educate prospective clients on what it is and isn't.\n\nAI deployment obstacles aren't exclusive to banking; they are prevalent across sectors. While banks have a long history of using AI for tasks like credit decisioning, they may be the first to run into issues because of the scale of their data and customers, said Tom Davenport, an information technology and management professor at Babson College.\n\n\"The technology's out way ahead of what individual banks or most companies actually can implement quickly,\" he said.\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "bank of america",
      "highly regulated",
      "chip giant",
      "race car",
      "nvidia executive",
      "enterprise software",
      "email thread",
      "ai factory",
      "customers",
      "banks"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bank-of-america-nvidia-ai-internal-emails-2026-1",
    "thumbnail_url": "https://i.insider.com/6977dccba645d118818802fb?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.563Z",
    "topic": "finance"
  },
  {
    "slug": "i-quit-meta-to-build-an-ai-startup-giving-up-a-big-tech-salary-was-tough-heres-how-i-prepared-financially",
    "title": "I quit Meta to build an AI startup. Giving up a Big Tech salary was tough — here's how I prepared financially.",
    "description": "A former Google and Meta employee shares why he left Big Tech and how he got comfortable making the leap to entrepreneurship.",
    "fullText": "This as-told-to essay is based on a conversation with Jason White, a 46-year-old startup founder in the San Jose area. Business Insider has verified his former employment with documentation. His words have been edited for length and clarity.\n\nI've spent half of my 20 years in the tech industry working at Google and Meta. These companies allowed me to work on some amazing projects, but I've now resigned from them both.\n\nI joined Google in 2016 as a tech lead in the Gmail division and transitioned to the Google Search team in 2020. By 2024, I realized I wanted to lean more heavily into AI. I didn't feel my position at Google would give me the opportunity to do that, so I opened myself up to other opportunities.\n\nWhen a Meta recruiter reached out about an AI machine learning engineer role, I decided to pursue it and eventually received an offer. I left Google in July 2024 and started at Meta a month later.\n\nI had a positive experience at Meta. I worked with great people in a high-resource environment and learned a lot. I was also able to lean into AI as I'd hoped, focusing fully on AI products.\n\nHowever, halfway through 2025, I started thinking about resigning to build a startup — specifically, a venture that would use AI to help the typical household with their finances.\n\nWhether to resign from Meta was a complex decision.\n\nThe startup was something I was growing increasingly passionate about. I know what financial pressure feels like — I had been a low-paid graduate student trying to provide for a newborn.\n\nMany people don't have access to great financial planning and management tools to help improve their financial situations. While I was still figuring out what the business would look like, I felt there was an opportunity to help people, and that was very motivating for me.\n\nI connected with a potential cofounder — a friend of a friend — and we spent a lot of time talking through the opportunity. That helped me grow more comfortable with the idea of leaving Meta, but there were still a lot of other factors to consider.\n\nIt's hard to leave a world-class team with people you like — not to mention a reliable source of income.\n\nI know some people start businesses on the side while keeping their full-time jobs, but I couldn't do that because I was already juggling two demanding roles as a Meta employee and a parent.\n\nMy other concern was legal. I would've had to disclose any outside business to Meta, and there could've been non-compete issues — especially since my business idea was related to AI, like my role at Meta.\n\nI wanted to make sure my family had enough savings to cover at least one year of our current expenses without touching our retirement accounts. My wife works, but I wanted a cushion in case she lost her job. I figured that would give me at least one year to build the business, and, if things went really badly, enough time afterward to find a job.\n\nWe already were in a good place savings-wise, so we were still able to take vacations, hire tutors for our kids, and order DoorDash. I had about six months before resigning to make some minor adjustments, including cutting back on 401(k) contributions and putting more money into liquid savings accounts.\n\nThis financial planning process for my family really helped crystallize the direction I wanted to go with the startup. In September 2025, I resigned from Meta.\n\nWhen I shared the news with my colleagues, the response was a mix of surprise, support, and a large amount of jealousy. A lot of people want to leave and start their own thing, but for various reasons they can't or won't — whether it's because of their visa status, financial constraints, or broader fear.\n\nI'm now focused on my business, Bear Financial. My cofounder and I are planning to publicly launch in the second half of this year. We may seek external funding, but for now, we're bootstrapping the business, so I've tracked our spending very carefully.\n\nI have a few pieces of advice for people considering leaving their jobs to start their own business. First, get your finances in order. Second, make sure anyone who depends on you, like your family, is supportive of the decision — I was fortunate to have a supportive partner who knew that I felt limited working in Big Tech.\n\nThird, choose an idea you deeply believe in. With a startup, you have to be the one to bring the energy, the enthusiasm, the vision — and to carry others into it.\n\nAddress your knowledge gaps. Startup founders often need to be generalists, which means having a basic understanding of a lot of areas.\n\nI'd also suggest envisioning the worst-case outcome and asking yourself whether you'd be OK with it. I thought about what it would look like one year later if my business failed. I believe I'd still value everything I learned over those 12 months.\n\nIf I eventually decide to pursue a corporate position again, I have faith that I'd be able to find something — even though it's hard to predict what the job market will look like.\n\nThere are, however, a lot of potential barriers to success: we have to navigate a moving target on regulations, we need to figure out ways to convince potential customers to give us a try, and there are super well-resourced companies that could become direct competitors.\n\nAt the end of the day, I want to take the swing.",
    "readingTime": 5,
    "keywords": [
      "financial planning",
      "startup",
      "i've",
      "meta",
      "opportunity",
      "look",
      "potential",
      "idea",
      "it's",
      "family"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ex-meta-google-employee-quit-build-ai-startup-shares-advice-2026-1",
    "thumbnail_url": "https://i.insider.com/69779c89e1ba468a96aab34f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.403Z",
    "topic": "finance"
  },
  {
    "slug": "the-wix-ceo-said-ai-gives-engineers-superpowers-that-means-one-trait-is-key-for-entrylevel-developers",
    "title": "The Wix CEO said AI gives engineers 'superpowers.' That means one trait is key for entry-level developers.",
    "description": "Wix CEO Avishai Abrahami said that entry-level engineers need to have this quality in order to keep up with the fast pace of change.",
    "fullText": "AI isn't just reshaping the role of software engineers — it's also making them more skilled.\n\nThat's according to Avishai Abrahami, the CEO and cofounder of website management company Wix. He told Business Insider that the technology equips developers with \"superpowers\" and that the value of smart, talented engineers will be \"dramatically enhanced\" with AI tools.\n\n\"What would take you a month, you can do in a few hours,\" Abrahami said, adding that not every task can be reduced in this way, but most can.\n\nA Google Cloud report released in September found that AI adoption had surged to 90% among software professionals, up 14% from the year prior. Abrahami said that the emergence of AI tools means the \"quality of the software engineer is more important than ever.\"\n\nHe said the first thing \"every company\" looks for is candidates who know how to code and understand AI models. Beyond that baseline, he said Wix aims to hire entry-level candidates with a \"tremendous amount of passion\" for the role, which he said is essential to meeting the demands of the job [didn't want to repeat roles] .\n\n\"Now with AI, the speed of change is so fast that you have to spend a lot of time learning and experimenting,\" Abrahami said, adding that this makes passion is even more important.\n\nJohn Stecher, Blackstone's chief technology officer, similarly told Business Insider that many junior software engineers have \"insane skill sets\" and that the best hires are deeply passionate about their work.\n\nAs tools take on more of the coding, Stecher said companies are increasingly looking to hire those who understand how to use the tools, and recognize when they're producing the wrong answers.\n\nFor more senior engineers, the role will increasingly shift toward architecture and code review, he said, rather than writing code. Abrahami said experienced engineers will need to read code \"much faster,\" adding that architecture, software design, and code comprehension will become even more critical.\n\nThe CEO, however, warned that AI can be a double-edged sword for engineers.\n\n\"You can do so much more if you're smart,\" Abrahami said about engineers who use AI. \"And you can do really bad things if you're not.\"",
    "readingTime": 2,
    "keywords": [
      "software engineers",
      "business insider",
      "code",
      "tools",
      "role",
      "adding",
      "technology",
      "smart",
      "candidates",
      "understand"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/wix-ceo-says-entry-level-engineers-need-this-trait-2026-1",
    "thumbnail_url": "https://i.insider.com/6977a893d3c7faef0eccecc6?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.402Z",
    "topic": "finance"
  },
  {
    "slug": "deepseek-ocr-2-visual-causal-flow",
    "title": "DeepSeek OCR 2: Visual Causal Flow",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "🌟 Github |\n 📥 Model Download |\n 📄 Paper Link |\n 📄 Arxiv Paper Link |\n\nDeepSeek-OCR 2: Visual Causal Flow\n\nExplore more human-like visual encoding.\n\nInference using Huggingface transformers on NVIDIA GPUs. Requirements tested on python 3.12.9 + CUDA11.8：\n\nRefer to 🌟GitHub for guidance on model inference acceleration and PDF processing, etc.\n\nWe would like to thank DeepSeek-OCR, Vary, GOT-OCR2.0, MinerU, PaddleOCR for their valuable models and ideas.\n\nWe also appreciate the benchmark OmniDocBench.",
    "readingTime": 1,
    "keywords": [
      "paper link",
      "github",
      "model",
      "deepseek-ocr",
      "visual",
      "inference"
    ],
    "qualityScore": 0.65,
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-OCR-2",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/deepseek-ai/DeepSeek-OCR-2.png",
    "created_at": "2026-01-27T06:21:30.259Z",
    "topic": "tech"
  },
  {
    "slug": "postgresql-timeout-parameters-your-databases-selfdefense-system",
    "title": "PostgreSQL Timeout Parameters: Your Database's Self-Defense System",
    "description": "(Inspired by OpenAI’s PostgreSQL scale challenges)When OpenAI shared their engineering journey of scaling PostgreSQL to support massive workloads, one insight quietly stood out:It’s also common to find long-running idle queries in PostgreSQL. Configuring timeouts like idle_in_transaction_session_timeout is essential to prevent them from blocking autovacuum.At first glance, this might sound like a small operational detail. But in reality, it points to a much bigger truth about how production data",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.datacloudgaze.com/post/postgresql-timeout-parameters-your-database-s-self-defense-system",
    "thumbnail_url": "https://static.wixstatic.com/media/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png/v1/fill/w_1000,h_965,al_c,q_90,usm_0.66_1.00_0.01/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png",
    "created_at": "2026-01-27T06:21:28.988Z",
    "topic": "tech"
  },
  {
    "slug": "ask-your-llm-traces-what-went-wrong-vllora",
    "title": "Ask your LLM traces what went wrong (vLLora)",
    "description": "Lucy is a built-in assistant that reads your traces, diagnoses agent failures, and suggests concrete fixes in seconds.",
    "fullText": "Your agent fails midway through a task. The trace is right there in vLLora, but it's 200 spans deep. You start scrolling, scanning for the red error or the suspicious tool call. Somewhere in those spans is the answer, but finding it takes longer than it should.\n\nToday we're launching Lucy, an AI assistant built directly into vLLora that reads your traces and tells you what went wrong. You ask a question in plain English, Lucy inspects the trace, and you get a diagnosis with concrete next steps. Lucy is available now in beta.\n\nSorry, your browser doesn’t support embedded videos.\n\nAgent failures don’t look like traditional exceptions. A single bad response is usually the result of a chain of small choices spread across a long execution.\n\nWhen debugging becomes \"scroll until you get lucky,\" you miss important signals and burn time (and tokens) doing it.\n\nLucy is good at exactly this: reading the trace end-to-end, spotting failure patterns, and turning them into actionable fixes.\n\nLucy sits next to your traces and threads. Ask a plain-English question, and it will inspect the trace, flag failure points, and return a fix-oriented report: root cause, impact, and recommended next steps.\n\nLucy can also help you spot patterns across multiple failing runs and suggest prompt rewrites to reduce ambiguity.\n\nWe had a Travel agent which was running for a long time, apparently stuck in a loop within the BetweenHorizonalEnd span. Instead of digging through the logs manually, we simply asked Lucy:\n\nLucy inspected the thread's spans, identified a recurring failure pattern, and explained the root cause and impact, along with concrete next steps.\n\nIn this trace, the agent was failing to complete a travel itinerary. Lucy didn't just flag the error; she identified a complex failure pattern involving both the code (schema) and the instructions (prompt).\n\n1. The \"Hallucinated\" Arguments\nLucy pinpointed exactly why the tools were failing. The model was trying to call research_flights with a from_city argument and research_accommodations with check_in_date.\n\n2. The Hidden Logic Trap\nCritically, Lucy found a root cause that a human scanning logs would likely miss: Prompt Contradiction.\n\n3. Silent Failures (Truncation)\nLucy also caught a silent degradation issue: Severe Output Truncation. The Restaurant Extraction step was hitting token limits and cutting off data mid-list (output_tokens: 4000... truncated). The run looked \"successful\" to the server, but the downstream user was getting incomplete data.\n\nLucy’s report turned a vague \"it's not working\" complaint into three distinct engineering tasks: fix the tool schema, clarify the system prompt, and increase the context window for extraction.\n\nCaption: Lucy analyzes the trace and detects multiple issues simultaneously: invalid tool arguments (from_city), contradictory system prompt instructions, and token truncation in the output.\n\nThis is a common failure mode in tool-using agents: when the tool contract isn't perfectly aligned (schema, handler, prompt, examples), the model starts guessing.\n\nThe cost isn't limited to a single failed call:\n\nEven if your run \"succeeds,\" you can still be paying for broken execution paths.\n\nLucy's intelligence comes from vLLora's tracing infrastructure. vLLora captures everything your agent does:\n\nWhen you ask Lucy a question, it pulls the relevant spans and runs, reconstructs the execution flow, and analyzes patterns across the data. This is context that would take a human hours to piece together manually.\n\nLucy is available now in beta for all vLLora users.\n\nLucy will inspect your active context and give you a clear diagnosis, so you can spend less time scrolling and more time shipping.\n\nSee the full Lucy documentation here",
    "readingTime": 3,
    "keywords": [
      "root cause",
      "patterns across",
      "failure pattern",
      "steps lucy",
      "system prompt",
      "trace",
      "agent",
      "vllora",
      "spans",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://vllora.dev/blog/introducing-lucy/",
    "thumbnail_url": "https://vllora.dev/img/lucy-whats-wrong-with-my-thread.png",
    "created_at": "2026-01-27T06:21:28.207Z",
    "topic": "tech"
  },
  {
    "slug": "kimi-k25",
    "title": "Kimi K2.5",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens atop Kimi-K2-Base. It seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms.\n\nKimi-K2.5 adopts the same native int4 quantization method as Kimi-K2-Thinking.\n\nYou can access Kimi-K2.5's API on https://platform.moonshot.ai , we provide OpenAI/Anthropic-compatible API for you. To verify the deployment is correct, we also provide the Kimi Vendor Verifier.\nCurrently, Kimi-K2.5 is recommended to run on the following inference engines:\n\nDeployment examples can be found in the Model Deployment Guide.\n\nThe usage demos below demonstrate how to call our official API.\n\nFor third-party API deployed with vLLM or SGLang, please note that :\n\nChat with video content is an experimental feature and is only supported in our official API for now\n\nThe recommended temperature will be 1.0 for Thinking mode and 0.6 for Instant mode.\n\nTo use instant mode, you need to pass {'chat_template_kwargs': {\"thinking\": False}} in extra_body.\n\nThis is a simple chat completion script which shows how to call K2.5 API in Thinking and Instant modes.\n\nK2.5 supports Image and Video input.\n\nThe following example demonstrates how to call K2.5 API with image input:\n\nThe following example demonstrates how to call K2.5 API with video input:\n\nK2.5 shares the same design of Interleaved Thinking and Multi-Step Tool Call as K2 Thinking. For usage example, please refer to the K2 Thinking documentation.\n\nKimi K2.5 works best with Kimi Code CLI as its agent framework — give it a try at https://www.kimi.com/code.\n\nBoth the code repository and the model weights are released under the Modified MIT License.\n\nIf you have any questions, please reach out at support@moonshot.cn.",
    "readingTime": 2,
    "keywords": [
      "instant mode",
      "agentic",
      "following",
      "please",
      "input",
      "native",
      "modes",
      "recommended",
      "usage",
      "chat"
    ],
    "qualityScore": 0.95,
    "link": "https://huggingface.co/moonshotai/Kimi-K2.5",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/moonshotai/Kimi-K2.5.png",
    "created_at": "2026-01-27T06:21:28.144Z",
    "topic": "tech"
  },
  {
    "slug": "one-developer-used-claude-to-build-a-memorysafe-extension-of-c",
    "title": "One developer used Claude to build a memory-safe extension of C",
    "description": "feature: Robin Rowe talks about coding, programming education, and China in the age of AI",
    "fullText": "feature TrapC, a memory-safe version of the C programming language, is almost ready for testing.\n\n\"We're almost there,\" Robin Rowe told The Register in a phone interview. \"It almost works.\"\n\nWe caught up with Rowe, a computer science professor and entrepreneur, amid debugging efforts that had kept him up until four in the morning. The long-awaited TrapC website has appeared.\n\n\"My work building TrapC has taken two parallel paths,\" Rowe explains in his initial post. \"A TrapC interpreter called itrapc and a separate compiler called trapc. I had wanted to make a software release by 1 January 2026, but too many bugs. I only reached code complete this month and am now on the painstaking and sleepless process of debugging. When I have something stable that mostly works I will make a release. Sorry to make you wait a little longer. Aiming for Q1 2026.\"\n\nBack in November 2024, Rowe explained that he was working on TrapC. At the time, the public and private sector had undertaken a campaign to promote memory-safe software development as a way to reduce exposure to serious vulnerabilities.\n\nMemory safety provides a way of ensuring that memory-related bugs like out-of-bounds reads/writes and use-after-free don't happen. In large codebases, like Chromium and Windows, most of the security vulnerabilities follow from memory bugs. As that message has been repeated in recent years, memory safety has become an imperative, evangelized by the likes of Google and Microsoft, and more recently by authorities in the US and elsewhere.\n\nFor at least the past ten years, there's been a rising chorus of voices calling for the adoption of memory-safe programming languages and techniques. This has meant encouraging developers to avoid languages like C and C++ where feasible, and to adopt languages like C#, Go, Java, Python, Swift, and Rust, instead, particularly for new projects.\n\nTo remain relevant, the C and C++ communities have tried to address those concerns with projects like TrapC, FilC, Mini-C, Safe C++, and C++ Profiles. There's also a C to Rust conversion project under development at DARPA called TRACTOR – TRanslating All C TO Rust.\n\nBut progress has been slow and those writing in C and C++ haven't found a widely accepted approach. The C++ standards committee recently rejected the Safe C++ proposal. And Rowe said he doubted TRACTOR would have anything to show this year.\n\nMeanwhile, the clock is ticking. Microsoft engineer Galen Hunt last month said, \"My goal is to eliminate every line of C and C++ from Microsoft by 2030. Our strategy is to combine AI and algorithms to rewrite Microsoft's largest codebases.\"\n\n\"There are some efforts to port C code by hand to Rust,\" said Rowe. \"But there're some real challenges to doing that because there are some idioms in C that cannot be expressed in Rust.\n\n\"Rust is much more type safe than C is. And so if you have a void pointer, what does that mean in Rust? There's no translation for it. And that's how TrapC is fundamentally different because it actually remembers what that void pointer actually is.\"\n\nRowe said he expects TRACTOR will eventually be able to accomplish C to Rust translation using AI. But he said he thinks it's better to just build the necessary tooling into the C compiler, so you don't have to rely on some external tool that rewrites your code in an unfamiliar language.\n\nRowe has been using AI tools himself and has been teaching others to do so. This past semester, he taught AI Cybersecurity Programmer Analyst (PCO471) at Community College of Baltimore County – Linux administration using vibe coding in bash with no prerequisites. And starting in February, he's teaching C++ Programming with Generative AI (PCO472) – vibe coding in C++.\n\nRowe said programming has fundamentally changed as a result of AI tools. \"I think this is sort of the same type of discussion as when C came in and people said, 'Well, I'm happy in assembly.' There will still be people doing it the old way. But because vibe programming is so much more efficient on time when done correctly, there's gonna be no choice. You just won't be competitive if you're not vibe programming.\"\n\nThen he shifted gears, slightly. \"But I have to walk that back a little bit because the reason I was up until four in the morning is I had vibe programming working on the Trap C compiler. And it took a fundamentally wrong design turn. And I didn't detect that it had made a design mistake. I had told it how I wanted to approach it. But somehow it misunderstood me or it forgot or something happened and I forgot to check. And so I spent hours doodling around in the debugger and trying to understand why code was acting weird before I finally looked at it and said, 'wait a minute, this isn't even the right design.'\"\n\nRowe said a similar situation crops up in pair programming, where you've told someone to do something and they didn't do it, and you don't realize that until later.\n\n\"[C++ creator] Bjarne Stroustrup famously said that the most important thing in software design is to be clear about what you're trying to build,\" Rowe said. \"And vibe [programming] just puts that on steroids. Now we not only have to be ourselves clear, but we have to communicate it clearly to an LLM.\"\n\nRowe argues that developers have to be encouraged to try AI tools and to make mistakes. He recounted how during his AI Cybersecurity Programmer Analyst course, his students expressed interest in doing more hands-on work in lieu of lectures.\n\n\"So I said, 'I've got real servers on the internet that are my companies. I'll give you root,'\" he recalled. \"I'll set loose students who know nothing on my own servers and hope for the best and we'll see how this goes. And the reaction was panic. I couldn't get past the timidity cliff.\"\n\nRowe said that what he learned from that exchange was that they didn't want their own hands-on, they wanted to watch him work.\n\n\"I said to them, 'But guys, this is like learning to play the piano. You can't learn to play the piano by watching me. Yeah, you guys have to practice. And it's gonna be embarrassing at first. You know, you're gonna play a lot of bad notes and sound terrible. You have to get over that situation'.\"\n\nThat's a scenario playing out in various companies where AI tools remain underutilized, for various reasons, including lack of training, security concerns, lack of utility, and poor tool design.\n\nRowe has traveled often to China to speak at the China Association of Higher Education conference. In December, he said, he was interviewed on China News Television about how China's plan for AI compares with America's.\n\nIn an email he explained, \"I said, 'China's AI-Plus plan calls for efficient AI on devices everywhere, from farm to factory to city, while the White House plan calls for building 500-billion-dollar cloud data centers ... using chips that will, inevitably, seem obsolete within two years.'\"\n\nRowe argues China's approach will prevail and that the US has taken the wrong turn by focusing on centralized cloud datacenters to run LLMs. Within two years, he said, we'll have AI models we can run locally on our phones, with no need for network access for most tasks. Apple and Huawei, he said, are likely to be the winners in this scenario.\n\nRowe pointed to China's DeepSeek as an example. While it may not be quite as good as the leading US commercial models, he said, it runs with far less power.\n\n\"This is a very Moore's Law type of strategy,\" he said. \"I remember when I had a Navy supercomputer in 1994. That was an amazing technology. But in 1995, Cray went bankrupt. There weren't enough buyers for it, even though it was an amazing device.\n\n\"And now I've got an iPhone that's in my pocket. That runs on a battery. It doesn't have a whole room devoted to it and exotic cooling and all kinds of stuff. And it's more powerful than that [the Cray from 1994]. So as a long-term strategy, you know, going toward the device makes a lot more sense, because that half-trillion dollar data center is going to be on my iPhone eventually.\"\n\nRowe also said that on the recommendation of a friend from his time at the AT&T DIRECTV Innovation Lab, he tried running Deepseek at a time when Claude wasn't available. Deepseek, he said, was able to find a bug that Claude couldn't.\n\n\"Surprisingly, the bug was in code Claude had generated, that I had cut-and-pasted carelessly,\" he said. \"With hindsight it was a silly code mistake I should have caught, but was in an 'else' branch outside where I was looking. I'd not expected or intended to have Claude make any change to that block of code. And because the code was valid but the logic wrong, the compiler didn't catch it.\"\n\nBut the bug was obvious, he said, as soon as Deepseek pointed it out. He added, \"I'm paying $200/year for Claude. Deepseek is free.\" ®",
    "readingTime": 8,
    "keywords": [
      "cybersecurity programmer",
      "programmer analyst",
      "rowe argues",
      "void pointer",
      "memory safety",
      "vibe coding",
      "design rowe",
      "vibe programming",
      "code",
      "compiler"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/26/trapc_claude_c_memory_safe_robin_rowe/",
    "thumbnail_url": "https://regmedia.co.uk/2022/03/23/shutterstock_c.jpg",
    "created_at": "2026-01-27T06:21:27.835Z",
    "topic": "tech"
  }
]
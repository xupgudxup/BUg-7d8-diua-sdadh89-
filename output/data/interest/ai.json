[
  {
    "slug": "i-worked-at-tesla-and-waymo-here-are-the-leadership-lessons-i-bring-to-my-startup",
    "title": "I worked at Tesla and Waymo. Here are the leadership lessons I bring to my startup.",
    "description": "Spencer Penn worked at Tesla and Waymo before he founded LightSource, an AI-powered sourcing and procurement startup.",
    "fullText": "This as-told-to essay is based on a conversation with Spencer Penn, the 33-year-old founder of LightSource, who lives in San Francisco. It's been edited for length and clarity.\n\nI moved to California 10 years ago, back when Tesla was a boutique car business. We were making 1,000 vehicles a week.\n\nMy friends and family were telling me it was a big career mistake to work at Tesla. They said it would never be someone's main car, that it's a tech toy, that it's an iPad with wheels on it. But I was just excited to see what this Elon guy was up to.\n\nMy interactions with Elon were always very positive, but I'm not a fanboy. There were some things that were very notable about his leadership style.\n\nTesla is a very flat organization. When I was there, even relatively young and out of college, it was two levels between Elon and me. That's very unusual to have such close proximity so early in your career.\n\nJust because it's a flat org structure, doesn't mean it's a horizontal power dynamic. Elon is the king. What he says goes. If you wanted to get something done, you really did have to go through Elon.\n\nThe drawbacks were that the guy didn't have that much time. In 2017, he was running three different companies: Tesla, SpaceX, and Neuralink. He was just getting started with OpenAI. He had two and a half days a week to really focus on Tesla exclusively. You'd have to get things approved in that period of time.\n\nBut he was also very focused on the product. He would get involved in the way that things felt. If you wanted to change a texture on a paint, you'd want to get his buy-in.\n\nMany CEOs go the opposite direction. They let themselves get so far removed from the product. Elon always felt the product was the thing, and the innovation would be what drives the company forward.\n\nI like to embody that here at our company. I still do demos. If you take your hands off the wheel, things might veer in a direction you don't like.\n\nElon has a knack for setting overly ambitious goals. There are benefits and drawbacks. Sometimes, you lose credibility. Certain products like the new Roadster were unveiled back when I was an employee, and they've yet to be delivered.\n\nBut there are certain things where you shoot for the moon and you do hit the stars. Nobody thought Starlink would be as successful as quickly as it has been.\n\nIf you apply the right amount of pressure, you can see where the leaks are. That kind of ambition is everything.\n\nThat's the final thing Elon does: he's really a risk taker. He's bet the company multiple times; he always keeps putting the chips back on red. I think about that a lot. Sometimes it can be hard for professional management to take the risks they need to. Sometimes you can sleepwalk into a long-term, uncompetitive position.\n\nThere was some internal signaling. People knew that Elon was in the factory. They knew that he was going to stay there until the issues were fixed. Elon works about as hard as any human on earth possibly can.\n\nThere's a hotel right across the street from the Fremont factory. Part of me always felt like, instead of setting up pillows in a conference room, I would like our CEO to be well-rested and go to the hotel five minutes away. But the signaling was very potent.\n\nI try to embody that to some degree here, too. I like to come into the office five days a week. I want people to know that I'm coming in early and I'm staying late. I unload the dishwasher in the office. I'm assembling IKEA furniture.\n\nWaymo was a very different organization. It's a very vertical org structure. Google is a large organization with lots of levels, and that translated directly to Waymo, which is a much smaller business.\n\nEven though it's a very vertical org structure, it's a horizontal power structure. It's like it's rotated 90 degrees from Tesla.\n\nSome people compared the org to slime mold. It starts to spread and find all the crevices on its own. Individual contributors could construct their own ideas.\n\nThere are benefits and drawbacks. There is the possibility that there are duplicative teams doing the same things in different ways. But it also leads to a lot of creativity.\n\nAt Tesla, it was very clear that Elon and his lieutenants were driving a lot of the decisions. The decisions that the more junior people made would be incremental. At Google, I found that a lot of the best ideas come from the individual folks in the business, because they're given the freedom to roam.\n\nIn a startup, you have limited resources. You have to be focused, but a lot of the best ideas come from experimentation.\n\nWe had an engineer who asked if he could move his start date by a month. He was like, \"I want to spend a month before I get into work catching up on everything that's happening in AI.\" He came to the table, and he had so deeply immersed himself that he had a lot of new and fresh ideas. Many of those ideas have become product features.\n\nI have to delegate innovation to folks on the team to find those opportunities. That's something I learned from Google.",
    "readingTime": 5,
    "keywords": [
      "everything that's",
      "vertical org",
      "org structure",
      "it's horizontal",
      "ideas",
      "product",
      "elon",
      "back",
      "business",
      "organization"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/former-tesla-waymo-employee-leadership-lessons-from-elon-musk-2025-12",
    "thumbnail_url": "https://i.insider.com/6941c572832e0ef1ead653ef?width=1200&format=jpeg",
    "created_at": "2025-12-20T12:20:16.408Z",
    "topic": "finance"
  },
  {
    "slug": "trumps-ai-policy-is-dividing-his-party-heres-what-key-gop-critics-are-saying-about-it",
    "title": "Trump's AI policy is dividing his party. Here's what key GOP critics are saying about it.",
    "description": "Several key Republicans, including Gov. Ron DeSantis and Sen. Josh Hawley, have been outspoken against federal AI preemption.",
    "fullText": "Gov. Ron DeSantis of Florida — a 2024 GOP primary opponent of Trump's — has been a consistent critic of federal efforts to curtail states' ability to regulate AI.\n\nAs lawmakers considered adding an AI regulation moratorium to the annual defense bill in November, DeSantis wrote on X that doing so is a \"subsidy to Big Tech.\"\n\n\"The rise of AI is the most significant economic and cultural shift occurring at the moment,\" DeSantis wrote. \"Denying the people the ability to channel these technologies in a productive way via self-government constitutes federal government overreach and lets technology companies run wild.\"\n\nFollowing Trump's executive order, DeSantis said at an AI roundtable event in Florida that he was confident that it wouldn't apply to laws that the governor is pursuing in his state.\n\nBut he said that if the administration did try to challenge Florida laws, he would expect the state to prevail.\n\n\"Even reading it very broadly, I think the stuff we're doing is going to be very consistent,\" DeSantis said of the executive order. \"But irrespective, clearly we have a right to do this.\"\n\nAs Rep. Marjorie Taylor Greene began to break with the president over the summer, one of the issues the Georgia Republican highlighted was AI.\n\nGreene notably admitted to voting for an initial version of the \"Big Beautiful Bill\" without realizing that it contained a provision to block state AI regulation for AI.\n\n\"I am adamantly OPPOSED to this and it is a violation of state rights and I would have voted NO if I had known this was in there,\" Greene wrote on X in June.\n\nFull transparency, I did not know about this section on pages 278-279 of the OBBB that strips states of the right to make laws or regulate AI for 10 years.\n\nI am adamantly OPPOSED to this and it is a violation of state rights and I would have voted NO if I had known this was in… pic.twitter.com/bip3hztSGq\n\nThe Georgia Republican re-upped her criticism when the provision was under consideration for the annual defense bill in November.\n\n\"States must retain the right to regulate and make laws on AI and anything else for the benefit of their state,\" Greene wrote on X. \"Federalism must be preserved.\"\n\nJust days later, Greene announced that she would resign from Congress on January 5 after Trump called her a \"traitor,\" largely over her stance on the Epstein files.\n\nSen. Josh Hawley has been one of the biggest GOP critics of the AI industry in the Senate — and he's opposed efforts to restrict states from regulating the technology.\n\n\"I would think that, just as a matter of federalism, we'd want states to be able to try out different regimes that they think will work for their state,\" Hawley told Business Insider in June. \"And I think in general, on AI, I do think we need some sensible oversight that will protect people's liberties.\"\n\nWhen the AI provision was reported to be no longer under consideration for the defense bill in November, Hawley celebrated via a post on X.\n\n\"Good. This is a terrible provision and should remain OUT,\" he wrote.\n\nIn June, Gov. Sarah Huckabee Sanders of Arkansas — who served as the White House Press Secretary during Trump's first term — led a group of 17 Republican governors in opposing an AI moratorium in the \"Big Beautiful Bill.\"\n\nThat provision in that bill was stronger than Trump's executive order — it would have amounted to a more wholesale ban on state-level AI regulation for a period of 10 years.\n\nSanders also wrote an op-ed in the Washington Post opposing the plan.\n\n\"That Congress proposes to strip away the right of any state to regulate AI is the antithesis of what our founders envisioned when they established our federal system,\" she wrote in June.\n\nIn November, as lawmakers considered adding a similar provision to the defense bill, Sanders spoke up again.\n\n\"Now isn't the time to backtrack,\" she wrote on X. \"Drop the preemption plan now and protect our kids and communities.\"\n\nGov. Spencer Cox of Utah, among the GOP governors who signed onto Sanders' letter, has also remained outspoken against efforts to limit state-level AI regulation.\n\n\"I'm very worried about any type of federal incursion into states' abilities to regulate AI,\" Cox told NPR in November.\n\nIn December, as Trump prepared to sign his executive order, Cox said there was a need for more balance.\n\n\"An alternative AI executive order focused on human flourishing would strike the balance we need: safeguard our kids, preserve our values, and strengthen American competitiveness,\" Cox wrote on X. \"States must help protect children and families while America accelerates its leadership in AI.\"",
    "readingTime": 4,
    "keywords": [
      "adamantly opposed",
      "beautiful bill",
      "trump's executive",
      "annual defense",
      "provision",
      "regulate",
      "federal",
      "regulation",
      "laws",
      "sanders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/gop-critics-trump-ai-preemption-policy-2025-12",
    "thumbnail_url": "https://i.insider.com/69407a88832e0ef1ead6416f?width=1200&format=jpeg",
    "created_at": "2025-12-20T12:20:16.089Z",
    "topic": "finance"
  },
  {
    "slug": "investment-in-data-centers-worldwide-hit-record-61bn-in-2025-report-finds",
    "title": "Investment in data centers worldwide hit record $61bn in 2025, report finds",
    "description": "Analysts see ‘global construction frenzy that shows no signs of slowing’ amid surge in demand from AI boom\nA new report finds that investment in the worldwide data center market reached $61bn this year, setting a new record atop the wave of the artificial intelligence boom.\nThe analysis by S&P Global, first reported by CNBC, documented what the market intelligence firm called a “global construction frenzy that shows no signs of slowing”, to build out the massive real estate, hardware, and energy requirements driven by insatiable demand from AI companies. S&P pegged 2024’s investment in the data center market at $60.8bn, just below the 2025 number.\n Continue reading...",
    "fullText": "Analysts see ‘global construction frenzy that shows no signs of slowing’ amid surge in demand from AI boom\n\nA new report finds that investment in the worldwide data center market reached $61bn this year, setting a new record atop the wave of the artificial intelligence boom.\n\nThe analysis by S&P Global, first reported by CNBC, documented what the market intelligence firm called a “global construction frenzy that shows no signs of slowing”, to build out the massive real estate, hardware, and energy requirements driven by insatiable demand from AI companies. S&P pegged 2024’s investment in the data center market at $60.8bn, just below the 2025 number.\n\n“Unable to buy, many investors are turning to new builds,” wrote Iuri Struta, an analyst for S&P Global.\n\nThere are approximately 500 data centers in the United Kingdom, compared with about 4,000 in the United States, according to Data Center Map, which tracks the facilities globally.\n\nStruta, the S&P Global analyst, said he does not see the demand for data centers slowing.\n\n“The global data center footprint is projected to expand at a faster rate over the next five years than it did in the previous five, spurred by demand for energy- and computer-intensive AI workloads,” said Struta.\n\nS&P Global’s report comes at a time when some investors worry that the entire artificial intelligence sector may be in the midst of huge overspending for unproven ongoing returns.\n\nLast week, Oracle’s shares dropped 11% after it reported lower quarterly earnings than analysts had expected, which in turn dragged the stock prices on some other major companies in AI. Some companies such as Oracle, along with Nvidia and OpenAI, have been criticized recently for making deals with one another that seem circular to many investors.\n\nEarlier this year, the International Energy Agency noted in a lengthy report that, globally, “electricity demand for data centres more than doubles by 2030”, reaching 945 terawatt hours (TWh), or just more than “Japan’s total electricity consumption today”.\n\nThis month, a trio of analysts from Deutsche Bank put out a staggering chart indicating that OpenAI alone will burn through $143bn between 2024 and 2029, the year before the company claims it will turn a profit. That chart shows how much more the ChatGPT maker, seen as a bellwether of the AI industry, plans to spend relative to other tech giants of the last two decades, including Amazon, Tesla and Uber, reached profitability.\n\n“Of course, OpenAI may continue to attract significant funding and could ultimately develop products that generate substantial profits and revolutionise the world,” Jim Reid, managing director, global head of macro research and thematic strategy at Deutsche Bank, wrote.\n\n“But at present, no startup in history has operated with losses on anything approaching this scale. We are firmly in uncharted territory.”",
    "readingTime": 3,
    "keywords": [
      "construction frenzy",
      "artificial intelligence",
      "center market",
      "deutsche bank",
      "demand",
      "analysts",
      "slowing",
      "investors",
      "signs",
      "boom"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2025/dec/19/data-centers-ai-investment",
    "thumbnail_url": "https://i.guim.co.uk/img/media/925003043afebbc3ecb9c5d652bd9dd11a41c200/427_0_4330_3464/master/4330.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=6c57efcab685321523cc9e6a7d611fa2",
    "created_at": "2025-12-20T12:20:13.414Z",
    "topic": "tech"
  },
  {
    "slug": "lg-tvs-unremovable-copilot-shortcut-is-the-least-of-smart-tvs-ai-problems",
    "title": "LG TVs' unremovable Copilot shortcut is the least of smart TVs' AI problems",
    "description": "LG says it’ll let people delete the Copilot icon. But TV chatbots aren’t going away.",
    "fullText": "Online fury erupted this week after an LG TV owner claimed that a firmware update installed unremovable generative AI software on their smart TV.\n\nThe controversy began on Saturday, when a Reddit user posted about the sudden appearance of a Microsoft Copilot icon on their device (something Windows users are all too familiar with). The Reddit user claimed that a “new software update installed Copilot” onto their LG TV and that it couldn’t be deleted.\n\n“Pre-installed crap is universally dogshit. If I wanted it, I’d have installed it myself eventually. The whole reason it’s bundled is because no one would choose it… Burn your television,” another Reddit user responded in the thread, which has 36,000 upvotes as of this writing.\n\nSome news outlets covered the move this week, reporting that LG customers were upset by an “unremovable Microsoft Copilot installation” and that other LG TV owners could expect to get it the next time they update their device.\n\nLG has since admitted that it used a webOS update to force Copilot onto some of its TVs. However, the firmware update didn’t install the Copilot application but rather a shortcut to the Copilot web app, which opens in the TV’s integrated web browser, LG spokesperson Chris De Maria told The Verge. De Maria added that “features such as microphone input are activated only with the customer’s explicit consent.”\n\nLG’s spokesperson said the company added the “shortcut icon to enhance customer accessibility and convenience.” LG, like other companies, has failed to prove why people need their non-computing devices, such as computer mice or earbuds, to provide instant access to third-party chatbots.\n\nFor those annoyed about the web app shortcut, De Maria said today that LG “will take steps to allow users to delete the shortcut icon if they wish.” He didn’t provide more details.\n\nEven with LG’s concession, it may become more difficult to avoid chatbots on TVs.\n\nLG says it will let people delete the Copilot icon from their TVs soon, but it still has plans to weave the service throughout webOS. The Copilot web app rollout seems to have been a taste of LG’s bigger plans to add Copilot to some of its 2025 OLED TVs. In a January announcement, LG said Copilot will help users find stuff to watch by “allowing users to efficiently find and organize complex information using contextual cues.” LG also said Copilot would “proactively” identify potential user problems and offer “timely, effective solutions.”\n\nSome TVs from LG’s biggest rival, Samsung, have included Copilot since August. Owners of supporting 2025 TVs can speak to Copilot using their remote’s microphone. They can also access Copilot via the Tizen OS homescreen’s Apps tab or through the TVs’ Click to Search feature, which lets users press a dedicated remote button to search for content while watching live TV or Samsung TV Plus. Users can also ask the TV to make AI-generated wallpapers or provide real-time subtitle translations.\n\nCopilot similarly rolled out automatically onto supporting Samsung TVs. Users can avoid Copilot by not using the above features, and they may be able to remove the Copilot icon from their TV’s Apps section.\n\nBut Copilot will still be integrated into Tizen OS, and Samsung appears eager to push chatbots into TVs, including by launching Perplexity’s first TV app. Amazon, which released Fire TVs with Alexa+ this year, is also exploring putting chatbots into TVs.\n\nAfter the backlash LG faced this week, companies may reconsider installing AI apps on people’s smart TVs. A better use of large language models in TVs may be as behind-the-scenes tools to improve TV watching. People generally don’t buy smart TVs to make it easier to access chatbots.\n\nBut this development is still troubling for anyone who doesn’t want an AI chatbot in their TV at all.\n\nSubtle integrations of generative AI that make it easier for people to do things like figure out the name of “that movie” may have practical use, but there are reasons to be wary of chatbot-wielding TVs.\n\nChatbots add another layer of complexity to understanding how a TV tracks user activity. With a chatbot involved, smart TV owners will be subject to complicated smart TV privacy policies and terms of service, as well as the similarly verbose rules of third-party AI companies. This will make it harder for people to understand what data they’re sharing with companies, and there’s already serious concern about the boundaries smart TVs are pushing to track users, including without consent.\n\nChatbots can also contribute to smart TV bloatware. Unwanted fluff, like games, shopping shortcuts, and flashy ads, already disrupts people who just want to watch TV.\n\nLG’s Copilot web app is worthy of some grousing, but not necessarily because of the icon that users will eventually be able to delete. The more pressing issue is the TV industry’s shift toward monetizing software with user tracking and ads.\n\nIf you haven’t already, now is a good time to check out our guide to breaking free from smart TV ads and tracking.",
    "readingTime": 5,
    "keywords": [
      "reddit user",
      "copilot onto",
      "copilot web",
      "web app",
      "copilot icon",
      "smart tvs",
      "shortcut icon",
      "lg tv",
      "microsoft copilot",
      "installed"
    ],
    "qualityScore": 1,
    "link": "https://arstechnica.com/gadgets/2025/12/lg-tvs-unremovable-copilot-shortcut-is-the-least-of-smart-tvs-ai-problems/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1603701301-1152x648.jpg",
    "created_at": "2025-12-20T00:52:53.380Z",
    "topic": "tech"
  },
  {
    "slug": "reavil-turn-qualitative-user-feedback-into-structured-data",
    "title": "Reavil – Turn qualitative user feedback into structured data",
    "description": "Build features users love. Catch issues before they churn. Our AI analyzes all feedback to show exactly what to fix first and what to build next.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://reavil.io",
    "thumbnail_url": "https://storage.googleapis.com/gpt-engineer-file-uploads/i8hBRDcEIeNfVk8fXgtX6wTs2pf1/social-images/social-1764236168799-COver image 2.jpg",
    "created_at": "2025-12-20T00:52:51.492Z",
    "topic": "tech"
  },
  {
    "slug": "witcher-4-dev-is-says-ai-can-unlock-meaningful-benefits",
    "title": "Witcher 4 Dev Is Says AI Can Unlock \"Meaningful\" Benefits",
    "description": "The Witcher and Cyberpunk developer CD Projekt Red is the latest company to sound off on the use of AI in gaming. During CD Projekt Red's latest earnings briefing, Joint CEO Michał Nowakowski said there are \"meaningful\" and \"real\" benefits to using the technology.\nThe company is already implementing such technologies \"mainly in the productivity areas\" and so far that's where the \"largest benefits\" have stemmed from, he explained, as reported by GamesRadar. A developer won't be able to use AI to make an entire game, though, and humans will remain essential to the process, he said.\n\"The benefits are real, they’re meaningful; but it's not a situation--and I'm unaware of such a situation--where AI could 'sit down and make games.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/witcher-4-dev-is-says-ai-can-unlock-meaningful-benefits/1100-6537119/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4626285-witcher.jpg",
    "created_at": "2025-12-20T00:52:49.423Z",
    "topic": "gaming"
  },
  {
    "slug": "why-chief-technology-officers-cant-afford-to-guess-on-planning-ai-sponsor-content-from-google-cloud",
    "title": "Why Chief Technology Officers Can’t Afford to Guess on Planning AI - SPONSOR CONTENT FROM GOOGLE CLOUD",
    "description": "Sponsor Content from Google Cloud.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://hbr.org/sponsored/2025/12/why-chief-technology-officers-cant-afford-to-guess-on-planning-ai",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/12/final.png",
    "created_at": "2025-12-20T00:52:49.129Z",
    "topic": "business"
  },
  {
    "slug": "6-cybersecurity-predictions-for-the-ai-economy-in-2026-sponsor-content-from-palo-alto-networks",
    "title": "6 Cybersecurity Predictions for the AI Economy in 2026 - SPONSOR CONTENT FROM PALO ALTO NETWORKS",
    "description": "Sponsor Content from Palo Alto Networks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://hbr.org/sponsored/2025/12/6-cybersecurity-predictions-for-the-ai-economy-in-2026",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/12/2026-Predictions.png",
    "created_at": "2025-12-20T00:52:49.103Z",
    "topic": "business"
  },
  {
    "slug": "ai-layoffs-could-far-outpace-new-jobs-past-economic-shocks-reveal-how-fast-that-can-fuel-unrest-professor-says",
    "title": "AI layoffs could far outpace new jobs — past economic shocks reveal how fast that can fuel unrest, professor says",
    "description": "London Business School professor Ekaterina Abramova said that rapid AI disruption could outpace institutions and destabilize societies.",
    "fullText": "A historic labor shock may be about to hit the job market.\n\nThat's according to London Business School professor Ekaterina Abramova.\n\nShe said AI is advancing so quickly that it could trigger mass layoffs long before new jobs emerge to replace them — a mismatch that has historically fueled social unrest.\n\nAbramova, who studies technology-driven economic transitions, said the past three years of AI advances mark a sharp break from earlier waves of mechanization.\n\nIn past eras — from 18th-century textile automation to late-20th-century manufacturing decline — the impact was mostly gradual and largely contained to individual sectors, she said.\n\nBut AI is different: \"A single AI model can displace thousands of cognitive jobs across multiple industries overnight,\" she told Business Insider.\n\nAbramova expects layoffs to outstrip new job creation over the next five to 10 years, especially without aggressive retraining efforts.\n\nWhile the exact number of AI-related layoffs is unknown, several major companies have already cited AI as a reason to reduce head count or to announce job cuts.\n\nNew AI-related roles often require skills or credentials that many displaced workers lack, Abramova said, and entry-level positions — such as junior developers, analysts, and customer support staff — are already among the most vulnerable.\n\nPeter Orszag, CEO of Lazard and former director of the Office of Management and Budget under President Obama, sees a similar risk.\n\nSpeaking on CNBC's \"Squawk Box\" this week, Orszag said that if AI delivers on its promise, there's likely to be a jobs crisis.\n\n\"Labor markets deal well with small problems that happen fast or big problems that happen slow. They do not deal well with big shocks that happen quickly,\" he said.\n\nAbramova said that the social risks extend far beyond unemployment numbers.\n\n\"History shows social strain emerges when the pace of economic change overtakes institutions' capacity to support displaced workers,\" she said.\n\nShe pointed to the UK's Enclosure Acts, which displaced tens of thousands of small farmers from common land, sparking riots and mass migration, and to the 1980s coal pit closures, which wiped out mining communities almost overnight and triggered years of strikes and political upheaval.\n\nBusiness leaders are divided over AI's impact on jobs, with Anthropic CEO Dario Amodei and Ford CEO Jim Farley warning of widespread white-collar displacement, while Elon Musk, JP Morgan's Jamie Dimon, and OpenAI's Sam Altman have predicted varying outcomes, ranging from significant disruption to long-term prosperity.\n\nOthers, such as Nvidia CEO Jensen Huang and Yann LeCun — Meta's outgoing chief AI scientist — say AI will transform work rather than erase it.\n\n\"It's very likely that the companies that use AI first, that use robotics technology first, will be the most successful first, and they will end up hiring more people,\" Huang said in late October.\n\n\"You're going to lose your job not to somebody — not to a robot, you're going to lose your job to somebody who uses a robot. You're going to lose your job to somebody who uses AI,\" he added.\n\nIf governments and employers fail to prepare, Abramova said she expects widening inequality, persistent unemployment, falling consumer demand, rising political anger, and even expanding surveillance as leaders try to contain discontent.\n\nIn extreme cases, she warned, democratic norms can erode.\n\nBut she also said that the worst outcomes aren't inevitable.\n\nThe alternative is worker-augmenting AI: systems where machines handle data-intensive tasks while humans retain judgment, ethics, and client relationships. That shift will require regulatory incentives that reward firms for responsible oversight, not just rapid headcount reduction.\n\n\"Without major support,\" Orszag said, \"many displaced workers risk long-term underemployment.\"",
    "readingTime": 3,
    "keywords": [
      "robot you're",
      "displaced workers",
      "jobs",
      "layoffs",
      "social",
      "orszag",
      "somebody",
      "labor",
      "quickly",
      "mass"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-impact-jobs-layoffs-outpace-new-jobs-social-unrest-professor-2025-12",
    "thumbnail_url": "https://i.insider.com/6942a831832e0ef1ead65bee?width=1200&format=jpeg",
    "created_at": "2025-12-19T18:17:23.890Z",
    "topic": "finance"
  },
  {
    "slug": "from-mckinsey-to-pwc-heres-how-elite-consulting-firms-are-racing-to-hire-engineers-and-train-everyone-else-in-ai",
    "title": "From McKinsey to PwC, here's how elite consulting firms are racing to hire engineers — and train everyone else in AI",
    "description": "Business Insider spoke to nine executives and industry insiders about how consulting's talent recruitment is changing.",
    "fullText": "AI is pushing consultants to their biggest-ever talent overhaul.\n\nAs firms shift from slide decks and advisory work to multi-year AI-driven transformation projects, the profile of the ideal consultant at firms like Boston Consulting Group, McKinsey, and PwC is changing.\n\n\"Going to a client and purely proposing an army of consultants doesn't really work anymore,\" Gert De Geyter, a former AI lead at Deloitte US, told Business Insider.\n\nInstead of the \"pure traditional consultant,\" firms are now looking for a blend of \"generalists and technical experts,\" said De Geyter, who left the firm in July to join AI startup Teragonia.\n\nBusiness Insider spoke to nine executives and industry insiders to understand how consulting firms are hiring, retraining, and redefining their workforces to meet the moment.\n\nThe work that consultants do is changing. Straight advisory projects are being replaced with building, implementing, and maintaining tools for companies, requiring technology expertise over research skills.\n\nHiring data reveals how aggressively top firms have been expanding their technologist ranks. Accenture's latest annual report shows it added nearly 40,000 AI and data professionals in the last two years. They now account for roughly 10% of its global head count. EY has added 61,000 technologists since 2023, according to its latest annual report.\n\nAt McKinsey, the \"AI engineer\" is the fastest-growing non-entry-level role, followed by procurement officer, data scientist, and software engineer, according to workforce intelligence company Revelio Labs.\n\nAt Boston Consulting Group, software engineers, frontend developers, and Python developers are the fastest-growing entry-level roles.\n\nBCG, which brought on 1,000 employees last year, has ramped up hiring technologists since launching its tech and AI arm, BCG X, in late 2022.\n\n\"We're essentially building a tech company inside a consulting firm,\" said Sylvain Duranton, Global Leader of BCG X. \"Our job has always been to help companies transform. But tech has become so critical to transformation that we needed to have a grip on it ourselves.\"\n\nIts regular consulting division is also adopting a more tech-centric mentality.\n\nScott Wilder, a BCG partner and managing director, told Business Insider that a new team, called \"forward deployed consultants,\" is rising through the ranks. It takes inspiration from a software engineering role popularized by Palantir, Wilder said.\n\nThese consultants are vibe-coding and building tools on client projects, he said. When one of these tools is a hit, it goes back to the R&D team and becomes a broader tool that everyone can use.\n\nFor firms like McKinsey and BCG, the must-have hire in the AI era isn't a pure engineer or a pure consultant — it's someone who can move between both worlds.\n\n\"What we want to be able to do is find those people that actually have a propensity to either be this great McKinsey consultant, and or a great technologist, and then groom them to be both,\" Alex Singla, a senior partner at McKinsey who co-leads its AI arm, QuantumBlack, told Business Insider.\n\nHe added that candidates also want hybrid roles: Many don't want to spend years building products for a cloud company like AWS, nor do they want to be traditional consultants.\n\nSingla said McKinsey is looking for \"5Xers — they're deep in one thing, but can do three or four different things well.\"\n\nQuantumBlack, with its 1,700-person team, drives all of McKinsey's AI initiatives, which account for 40% of the firm's work, but McKinsey's technical talent isn't limited to that group, Singla said. There are about 3,500 people building internal technology for McKinsey, and another 4,000 to 5,000 consultants who are leading the technical work from the business side, but don't necessarily have technical expertise.\n\nThe consulting talent landscape has been in flux since the pandemic, when a surge in demand prompted top firms to aggressively staff up. As that boom faded and demand for advisory work slowed, many firms found themselves overstaffed, triggering layoffs and a more selective approach to hiring.\n\nAmid the shifting market, the traditional pyramid model — built on large cohorts of junior consultants — started to recalibrate as firms focused on roles that deliver value over manpower. That focus has only sharpened with the rise of AI, prompting firms to invest heavily in upskilling their existing workforces.\n\n\"Everyone is reckoning with the fact that AI has exploded onto the scene,\" Saurabh Sarbaliya, PwC's AI Lead, told Business Insider.\n\n\"The demand for people who can make AI work in the enterprise is only going to grow — but there just aren't enough experts. So you have to focus on upskilling your existing workforce,\" he said.\n\nAt KPMG, Sam Gloede, the firm's global trusted AI leader, said it is prioritizing upskilling over hiring.\n\n\"There is not a massive change in our workforce,\" Gloede said. \"It's just a focus on upskilling, literacy, and learning.\"\n\nEY is taking a similar approach and prioritizing the AI capabilities of its employees, Imgard Naudin ten Cate, EY's global leader of talent acquisition, told Business Insider.\n\nIn October, EY held a two-week learning event to teach employees to build AI agents for use in their day-to-day work. The firm has also rolled out 15-hour courses on topics including AI engineering, applied AI, and AI compliance.\n\nNearly 100,000 employees — roughly a quarter of the workforce — have earned a digital \"AI badge\" for completing one of the courses, said Simon Brown, EY's global learning and development leader. The initiative has been \"a phenomenal way at scale to build deep AI knowledge,\" he added.\n\nTechnologist roles are in high demand, but don't expect a team of hoodie-wearing Silicon Valley types when your company hires consultants. Most in the industry are still generalists with strong problem-solving and communication skills — and they'll likely show up in a suit.\n\nEven as firms hire more technologists, most consulting work still doesn't require deep engineering expertise. Traditional consulting roles at top firms are still on the rise, growing from 250,000 globally in 2022 to 340,000 in 2024, according to Revelio Labs.\n\n\"A lot of the clients are still just dipping their toes in the AI pond, so over-engineering solutions for them doesn't work,\" said de Geyter, the former AI lead at Deloitte US. \"It's a lot more helpful that someone supports them with setting up the right data governance so they can get ready for AI solutions down the line.\"\n\nA senior software engineer at Deloitte, who requested anonymity as they are not permitted to speak to the media, told Business Insider that the technical literacy of most employees is improving, but remains in a \"very nascent state.\"\n\n\"They're looking less for people who know the inners of how these black box models work or could train one themselves, and more at people who can quickly leverage them for a specific solution set,\" the person said.\n\nStill, they warned that the current skill level poses a strategic risk: \"We can't let it continue for too long.\"\n\nJim Rowan, head of AI at Deloitte US, told Business Insider that its employees have \"the latest technologies and certifications to effectively work with machines and unlock even more impactful business outcomes for clients.\" Deloitte is not just hiring more data engineers and technologists, but \"actively investing\" in upskilling its workforce, Rowan said.\n\nSeveral leaders told Business Insider that soft skills are becoming more relevant now that AI can perform specific quantitative tasks.\n\n\"When we get asked a question of what we are looking for when we recruit, the core fundamental thing is actually attitude,\" Niale Cleobury, KPMG's AI workforce lead, said. Communication, collaboration, and agile learning — \"the sort of things AI can't really do\" — are the standout qualities, he said.\n\nMcKinsey is still active on college campuses recruiting undergraduates, MBAs, and PhDs, said Kate Smaje, McKinsey's global leader of technology and AI.\n\nIn its screening process, McKinsey emphasizes elements of judgment and conceptual thinking in problem-solving, resilience, and the ability to learn quickly.\n\nThe ability to build relationships and the core EQ leadership qualities can be \"fairy dust\" on top of what you can do analytically that will now set you apart, said Smaje.\n\n\"What we really hire for is voracious learners, people who are curious about the world and have the ability to learn, unlearn, and relearn,\" she said. \"Those are the people we really want.\"\n\nHave a tip? Contact these reporters via email at pthompson@businessinsider.com and lvaranasi@businessinsider.com; or on Signal at Polly_Thompson.89 and lvaranasi.70. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 8,
    "keywords": [
      "boston consulting",
      "latest annual",
      "software engineer",
      "top firms",
      "business insider",
      "deloitte us",
      "de geyter",
      "consultants",
      "hiring",
      "workforce"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-is-changing-consulting-talent-at-mckinsey-pwc-deloitte-2025-12",
    "thumbnail_url": "https://i.insider.com/69440aea64858d02d2170a77?width=1200&format=jpeg",
    "created_at": "2025-12-19T18:17:23.735Z",
    "topic": "finance"
  },
  {
    "slug": "ai-tools-make-coders-more-important-not-less",
    "title": "AI Tools Make Coders More Important, Not Less",
    "description": "Many leaders are excited about the promise of AI coding tools that can make it easier for novices to write code and, seemingly, make experienced coders less essential. Yet these tools make experience more—not less—important, as AI is not a replacement for real engineers. Companies that want to use these tools should follow common rules. Make sure every change it makes is double-checked—with automatic checks, simple tests that confirm things still work, and at least one human review. Keep access limited: Let AI work only in a safe “practice” environment, never give it the keys to live customer data, and routinely check for basic security mistakes like files or storage left open to the public.",
    "fullText": "AI Tools Make Coders More Important, Not Less by Michael LiDecember 19, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintOf all the possible applications of generative AI, the value proposition of using it to write code was perhaps the clearest. Coding can be slow and it requires expertise, both of which can be expensive. Moreover, the promise that anyone who could describe their idea in plain text could create apps, features, or other value-adding products meant that innovation would no longer be limited to those with the skills to execute, but could be done by anyone with an idea. The strength of this promise has created a $7.37 billion market for these tools.",
    "readingTime": 1,
    "keywords": [
      "tools",
      "promise",
      "anyone",
      "idea"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/ai-tools-make-coders-more-important-not-less",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_22t-kaiser-7uH3ndea63o-unsplash.jpg",
    "created_at": "2025-12-19T18:17:22.482Z",
    "topic": "business"
  },
  {
    "slug": "one-year-of-trying-to-be-an-ai-optimist",
    "title": "One Year of Trying to Be an AI Optimist",
    "description": "On new years eve last year I told myself I wanted to really adopt AI. Let's talk about it.",
    "fullText": "On new years eve last year I told myself I wanted to really adopt AI. Let's talk about it.\n\nOne year ago I set a New Year's resolution for myself to be an AI optimist for 2025. Before this, I had been a bit of a skeptic, you might say, and I still am in my core. But I thought it would be an interesting perspective to go through 2025 with.\n\nIn the beginning of the year I went out hard. I wanted to use AI in every single part of my life. Personal and work. This was fun, and there were certainly some good use cases. For example, taking a photo of a whiteboard after a meeting, uploading to my Mac's Raycast chat instance, and asking an LLM to OCR what was on there. Cool, not groundbreaking.\n\nAt this point, I was still a heavy terminal and Neovim user. This is how I'd been working for the last 6 years or so. And I loved it. I created this really productive environment where I could fly through files. Going from idea to code has never really been the hard part for me. I think learning Vim and Neovim was one of the best things I've done for my career for the first 6 years. I would see colleagues of mine slowly click through an IDE with their mouse, while I would already have a draft PR out.\n\nAs the year went by, I started hearing more and more about Cursor. I tried it. Didn't like it, went back to Neovim. Then I heard more and more about Zed. Tried it, really liked it, but then went back to Neovim. I used some AI plugins for Neovim, like Copilot and gp.nvim, and it worked quite well.\n\nThen agentic editing started to surface. It was quite bad in the beginning. But after the summer of 2025, things really started accelerating. I gave Cursor another shot, and with the release of Composer 1, I found myself not going back to Neovim. When I did go back, I just cringed at the incredible latency and performance of Copilot. And not having gp.nvim actually implement the changes it suggested, but just displaying them made me realize the jump ahead Cursor had created for itself.\n\nComposer 1 and the agents panel is absolutely crazy. There's so much power here, and it can write a lot of code. Some pretty good, and some less. I really think it's great. But it's such a double edged sword.\n\nI think this is a term you've probably heard in other contexts in your life. If you can't remember, go back to your school days. Someone near you probably mentioned that when you write something down, you remember it better. I think this is interesting. Having an agent write your code and then you reviewing (i.e., reading) works. But the problem is that you won't build a mental model or deep understanding of the code.\n\nOn one hand I deeply believe in the previous paragraph. And, I want to go back to pure Neovim and write every single line of code by hand. Except boilerplate of course (this is something we all have to agree on is better with LLMs). But then I jump a few years ahead in my mind, and think about where the industry is in 10, 15, or even 20 years. I'm just 26 years old. I joined my first startup at 18 and I've been building web and mobile apps at all types of companies ever since. But where are we in 20 years? Will code even matter, or will English just be the next elevator level in the skyscraper of language abstractions?\n\nKnowing how your codebase works on a deeper level is really valuable. If a customer comes to you with a bug, you can't blame the LLM.\n\nYou know, uuhmm... I didn't actually write that code. But I'll check with the Claude.\n\nHow would you feel if a service provider you use in your company would answer something like that to a bug you report? Sure, they won't answer like that. But they'll think it. How does that feel to you? Probably not great. It doesn't bring a huge sense of trust in that company.\n\nI know there's real value in deeply understanding the code you write. Even if it's boring code at times, it's valuable. Taking ownership of what you ship to customers. After all, \"customers\" are just simple peasants like you and me. And I fucking hate when Netflix won't load half of the shows on my Samsung smart TV. You have to ask yourself what you expect from the products and services you use. And then apply those expectations to the products you build.\n\nSo, it seems like things are only going in one direction: abstractions. English to code. It kinda works. You can ship a ton. And your boss is probably happy because your team is delivering more features. Your users? Who knows. Maybe they're happy. But honestly, as a user, I don't give a hell if Netflix ships a bunch of new features. I just care about their core. If their new fancy features are all half-baked, laggy pieces of crap, I'll watch something on Apple TV instead.\n\nAnother thing that's worth reflecting on is that even though it might seem like everything is going in one direction in the insutry. It doesn't mean we have to go that route. It's not like there's just one final master goal to all of this. These are just private companies who want to sell us their services. And, you might not believe it... But we don't have to buy it.",
    "readingTime": 5,
    "keywords": [
      "code",
      "back",
      "it's",
      "cursor",
      "there's",
      "won't",
      "features",
      "neovim",
      "core",
      "interesting"
    ],
    "qualityScore": 1,
    "link": "https://www.abgn.me/blog/one-year-of-trying-to-be-an-ai-optimist",
    "thumbnail_url": "https://res.cloudinary.com/albin-groen/image/upload/v1766166157/og_z7t7fq.png",
    "created_at": "2025-12-19T18:17:20.250Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-simple-video-editor-cut-the-words-to-edit",
    "title": "I built simple video editor: Cut the words to edit",
    "description": "Cut the words to edit the video. A quick, simple, browser-based editor with AI transcription.",
    "fullText": "Cut the words to edit the video!\n\nYes, just add your video, select the words to cut and export!\n\nA quick, simple editor for your work.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.1,
    "link": "https://cuttr.in",
    "thumbnail_url": "https://cuttr.in/og-image.png",
    "created_at": "2025-12-19T18:17:20.154Z",
    "topic": "tech"
  },
  {
    "slug": "uber-is-hiring-more-engineers-because-ai-is-turning-them-into-superhumans",
    "title": "Uber is hiring more engineers because AI is turning them into 'superhumans'",
    "description": "Uber CEO Dara Khosrowshahi said investing in AI has been \"well worth it and then some\" as it's yielded \"hundreds of millions of dollars of benefit.\"",
    "fullText": "AI stocks might look frothy, but Uber's embrace of the technology is transforming its operations and yielding huge financial benefits, CEO Dara Khosrowshahi says.\n\n\"You can debate whether or not there's a bubble in terms of valuation,\" Khosrowshahi told the \"On with Kara Swisher\" podcast in an episode released Thursday. \"The spending on the data centers, etc., is massive.\"\n\nBut AI has created a lot of value for Uber, \"not in the space-age stuff\" but in \"very practical\" ways, he said, such as determining what's shown next to a customer on their Uber Eats app after they select a carton of oat milk.\n\nThe latest AI models are \"enormously more effective\" than previous generations, and are producing \"hundreds of millions of dollars of benefit to us,\" he added.\n\nUber's AI spend \"has been well worth it and then some,\" he said. \"We are not building the picks and shovels but we're riding on top of that spend, absolutely.\"\n\nAI stocks have soared to record highs this year, but investors such as Michael Burry of \"The Big Short\" have warned tech giants are overspending on microchips and data centers in their scramble for computing power, and will fall short of their fabulous growth forecasts.\n\nKhosrowshahi described his mobility, delivery, and freight company as an \"applied AI\" business. It's harnessing the tech for everything from setting prices and payments to matching, routing, identification, and dealing with customer complaints, he said.\n\nRoughly 80% to 90% of Uber's developers now use AI tools, he said. The company no longer has to keep scores of engineers on call to fix issues, and have them spend \"hours and hours\" figuring out what's gone wrong and where, as AI agents are now \"constantly looking at all of our systems\" and helping to diagnose problems, he continued.\n\n\"And then the human can look over the shoulder of the AI agent,\" he added.\n\nKhosrowshahi said that other tech bosses might see AI making their engineers 20% or 30% more productive, and conclude they need 20% to 30% fewer engineers, but that's not his attitude.\n\n\"I just think they become superhumans,\" he said. \"So we are actually hiring more engineers because every engineer got more valuable to me.\"\n\nKhosrowshahi also touched on Uber's partnership with Waymo and other robotaxi companies, saying the driverless vehicles are proving popular.\n\n\"There's something to be said for privacy,\" he said. While he loves talking to Uber drivers and hearing their stories, it's also \"nice being alone in the car.\"\n\nKhosrowshahi predicted that once self-driving cars become proven revenue generators, Wall Street will embrace them as investments and want their cars on Uber's platform to access its customers and maximize their returns.\n\nSimilar to how private equity and private debt companies are \"financing these data centers and buying Nvidia chips, that same ecosystem is going to be buying fleets of cars,\" he said.\n\nKhosrowshahi said that Uber could play a similar role to Marriott, which primarily manages or franchises hotels instead of owning them.",
    "readingTime": 3,
    "keywords": [
      "engineers",
      "centers",
      "tech",
      "cars",
      "khosrowshahi",
      "stocks",
      "look",
      "embrace",
      "there's",
      "what's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/uber-dara-ai-bubble-tech-transportation-nvidia-burry-waymo-cars-2025-12",
    "thumbnail_url": "https://i.insider.com/69454d1364858d02d2171fab?width=1200&format=jpeg",
    "created_at": "2025-12-19T18:17:19.532Z",
    "topic": "tech"
  },
  {
    "slug": "the-negativity-crisis-of-ai-ethics",
    "title": "The negativity crisis of AI ethics",
    "description": "Despite the great positive potential of AI, the AI ethics community has presented a rather gloomy picture of AI’s ethical implications. This paper examines the negativity within AI ethics through a philosophy of science lens. The prevailing negativity is a result of the particular way the discipline is institutionally organized, which pressures AI ethicists to portray AI in a critical light. As a consequence, the overall picture of AI offered by the AI ethics community is one-sided and negatively biased. We should be skeptical about the negative narrative promoted by AI ethics and explore ways of reforming the system.",
    "fullText": "The negativity crisis of AI ethics\n\n Original Research\n\n Open access\n\n Published: 28 November 2025\n\n Volume 206, article number 277, (2025)\n\n Cite this article\n\n You have full access to this open access article\n\n Download PDF\n\n Synthese\n\n Aims and scope\n\n Submit manuscript",
    "readingTime": 1,
    "keywords": [
      "access"
    ],
    "qualityScore": 0.2,
    "link": "https://link.springer.com/article/10.1007/s11229-025-05378-9",
    "thumbnail_url": "https://media.springernature.com/full/springer-static/cover-hires/journal/11229",
    "created_at": "2025-12-19T18:17:19.344Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-stock-jumps-8-on-tiktok-deal-progress-openai-fundraise-talks",
    "title": "Oracle stock jumps 8% on TikTok deal progress, OpenAI fundraise talks",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/oracle-shares-jump-on-tiktok-deal-progress-openai-fundraise-talks-4416368",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEB2H0Q1_M.jpg",
    "created_at": "2025-12-19T18:17:18.001Z",
    "topic": "finance"
  },
  {
    "slug": "video-game-concept-artists-say-genai-isnt-making-things-easier",
    "title": "Video Game Concept Artists Say GenAI Isn't Making Things Easier",
    "description": "Generative AI has been at the forefront of the conversation for the past few years, with companies becoming divisive on how to implement it, if at all. Larian CEO Swen Vincke recently kicked a hornet's nest after saying the studios' developers use generative AI tools for things like exploring new game ideas, developing concept art, creating placeholder text, and for PowerPoint presentations. After a quick retraction and explanation, along with sharing that the studio was in fact growing its pool of artists rather than shrinking. Vincke has admitted that Larian uses AI for tasks nobody wants to do, but does AI--even at the concept art stage--help actual concept artists?\nAccording to a handful of video game concept artists, it can actually make things harder.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/video-game-concept-artists-say-genai-isnt-making-things-easier/1100-6537107/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1597/15976769/4626176-divinity-original-sin-2-header.jpg",
    "created_at": "2025-12-19T18:17:16.751Z",
    "topic": "gaming"
  },
  {
    "slug": "kojima-on-ai-we-cant-go-back",
    "title": "Kojima On AI: \"We Can't Go Back\"",
    "description": "Writer-director Hideo Kojima has shared more thoughts on AI, this time saying he believes the technology is here to stay and \"we can't go back.\"\nSpeaking to Nikkei Xtrend, as translated by GamesRadar, Kojima said, \"Now there are so many people who can't live without their smartphones. AI is like that.\"\nHe added: \"I think there isn't any point in saying 'We shouldn't use AI' or 'AI is useless.' We can't go back.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/kojima-on-ai-we-cant-go-back/1100-6537112/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4626250-ds2.jpg",
    "created_at": "2025-12-19T18:17:16.455Z",
    "topic": "gaming"
  },
  {
    "slug": "wan-26-ai-video-generator-with-multishot-and-reference-video",
    "title": "Wan 2.6: AI Video Generator with Multi-Shot and Reference Video",
    "description": "Create 1080p multi-shot videos from text, images & video with Wan 2.6. Generate lip-synced content with character consistency and reference video support.",
    "fullText": "Transform text, images, and videos into stunning cinematic content with Wan 2.6. Create professional 1080p multi-shot videos with synchronized audio, stable characters, and realistic motion in minutes.\n\nCast characters from reference videos into new scenes. Supports human or human-like figures, enabling multi-person and human-object interactions with appearance and voice consistency.\n\ndrinks milk tea while doing some improvised dance moves to the music.\n\ndrinks milk tea while doing some improvised dance moves to the music.\n\nclimbs into a little boy's house on Christmas, puts all the gifts from the Christmas tree into their sack, and says wickedly, \"I've stolen all your presents.\"\n\nclimbs into a little boy's house on Christmas, puts all the gifts from the Christmas tree into their sack, and says wickedly, \"I've stolen all your presents.\"\n\nTell a compelling story with intelligent multi-shot storytelling. You can create up to 15 seconds, 1080p HD narrative videos with native synced audio and visuals.\n\nA beaver walks around the kitchen of an apartment. He looks at the camera anxiously and says, \"Where are my nuts?\" The beaver finds a box of nuts on the table and says joyfully, \"Here are my nuts!\"\n\nA beaver walks around the kitchen of an apartment. He looks at the camera anxiously and says, \"Where are my nuts?\" The beaver finds a box of nuts on the table and says joyfully, \"Here are my nuts!\"\n\nA massive, derelict interstellar freighter floats silently in the dusty rings of Saturn. On its dark, flickering bridge, a single red button blinks beside a cryptic warning: \"Unknown life signal...\". The style is suspenseful sci-fi horror, characterized by immense scale, deep shadows, and an atmosphere of isolated dread. The final shot pulls back, dwarfing the ominous vessel against the vast, silent void of space.\n\nA massive, derelict interstellar freighter floats silently in the dusty rings of Saturn. On its dark, flickering bridge, a single red button blinks beside a cryptic warning: \"Unknown life signal...\". The style is suspenseful sci-fi horror, characterized by immense scale, deep shadows, and an atmosphere of isolated dread. The final shot pulls back, dwarfing the ominous vessel against the vast, silent void of space.\n\nWan 2.6 offers three powerful generation modes\n\nTransform text descriptions into cinematic videos. Describe your vision and watch it come to life. Supports Chinese and English prompts up to 5,000 characters.\n\nAnimate static images with realistic motion. Upload photographs or artwork and create dynamic videos with natural movement.\n\nTransform existing footage with style transfer and enhancement. Apply artistic styles and refine content with AI processing.\nAdvanced temporal coherence ensures smooth motion, stable characters, and realistic physics across all frames.\n\nCreate cohesive video sequences with multiple scenes. Maintains character consistency across shots for storytelling content.\n\nGenerate videos with synchronized audio and lip-sync capabilities. Ideal for talking head videos and product demonstrations.\n\nProduce professional 1080p videos with exceptional clarity. Choose 720p for speed or 1080p for maximum quality.\n\nGenerate videos from 5 to 15 seconds. Perfect for social media, ads, and product showcases.\n\nAll content includes commercial licensing for marketing, client projects, and production workflows.\n\nFast generation without compromising quality. Balances speed and fidelity for creative iteration.\n\nWan 2.6 cut my video production time from hours to minutes. The multi-shot feature is perfect for Instagram stories.\n\n30% cheaper than competitors with better results. The 1080p output rivals our agency's work.\n\nCreated my first product video in 10 minutes with no experience. Customers love the professional look.\n\nWan 2.6 cut my video production time from hours to minutes. The multi-shot feature is perfect for Instagram stories.\n\n30% cheaper than competitors with better results. The 1080p output rivals our agency's work.\n\nCreated my first product video in 10 minutes with no experience. Customers love the professional look.\n\nWan 2.6 cut my video production time from hours to minutes. The multi-shot feature is perfect for Instagram stories.\n\n30% cheaper than competitors with better results. The 1080p output rivals our agency's work.\n\nCreated my first product video in 10 minutes with no experience. Customers love the professional look.\n\nWan 2.6 cut my video production time from hours to minutes. The multi-shot feature is perfect for Instagram stories.\n\n30% cheaper than competitors with better results. The 1080p output rivals our agency's work.\n\nCreated my first product video in 10 minutes with no experience. Customers love the professional look.\n\nCharacter stability across shots is unmatched. Finally confident using AI for client projects.\n\nThe lip-sync feature revolutionized my course materials. Student engagement is up 40%.\n\nTested every AI video tool. Wan 2.6's cinematic understanding is leagues ahead.\n\nCharacter stability across shots is unmatched. Finally confident using AI for client projects.\n\nThe lip-sync feature revolutionized my course materials. Student engagement is up 40%.\n\nTested every AI video tool. Wan 2.6's cinematic understanding is leagues ahead.\n\nCharacter stability across shots is unmatched. Finally confident using AI for client projects.\n\nThe lip-sync feature revolutionized my course materials. Student engagement is up 40%.\n\nTested every AI video tool. Wan 2.6's cinematic understanding is leagues ahead.\n\nCharacter stability across shots is unmatched. Finally confident using AI for client projects.\n\nThe lip-sync feature revolutionized my course materials. Student engagement is up 40%.\n\nTested every AI video tool. Wan 2.6's cinematic understanding is leagues ahead.\n\nSelect from text-to-video, image-to-video, or video-to-video based on your creative needs and source materials.\n\nEnter detailed text prompts (1-5,000 characters), upload high-quality images, or provide reference videos. Specify camera movements, artistic styles, and desired aesthetics for optimal results.\n\nSelect your preferred duration (5, 10, or 15 seconds) and resolution (720p or 1080p). Preview generation settings before processing.\n\nClick generate and watch Wan 2.6 create your video in real-time. Download results in high-quality video format for immediate use or further editing.\n\nWrite detailed text descriptions with specific visual elements, camera movements, lighting conditions, and atmospheric details.\n\nUse high-quality source images with clear subjects and good composition for image-to-video generation.\n\nSpecify artistic styles and cinematography techniques like \"cinematic lighting,\" \"slow motion,\" or \"aerial drone shot.\"\n\nInclude scene composition details such as foreground/background elements, depth of field, and spatial relationships.\n\nProvide clear style direction for video-to-video transformations with reference materials or specific aesthetic goals.\n\nExperiment with different prompts and settings to discover optimal combinations for your creative vision.\n\nWan 2.6 generates standard MP4 video files compatible with all major platforms, editing software, and social media channels.\n\nYes, Wan 2.6 supports both Chinese and English text prompts, making it accessible for international creators and multilingual projects.\n\nAdvanced temporal consistency ensures smooth motion between frames, stable character appearances, realistic physics, and natural movement flow - eliminating common AI video artifacts like flickering or morphing.\n\nWan 2.6 generates high-resolution 1080p output with professional-quality motion, stable visuals, and appropriate licensing for commercial use in advertising, client work, and production pipelines.\n\nMost video generation completes within reasonable timeframes optimized for creative workflows, allowing multiple iterations and refinements during production.",
    "readingTime": 6,
    "keywords": [
      "wickedly i've",
      "i've stolen",
      "warning unknown",
      "advanced temporal",
      "unknown life",
      "christmas tree",
      "instagram stories",
      "experience customers",
      "customers love",
      "unmatched finally"
    ],
    "qualityScore": 1,
    "link": "https://wan-2-6.com",
    "thumbnail_url": "https://wan-2-6.com/og.png",
    "created_at": "2025-12-19T12:22:26.935Z",
    "topic": "tech"
  },
  {
    "slug": "gemma-scope-2-open-suite-of-tools-for-language-model-interpretability",
    "title": "Gemma Scope 2: open suite of tools for language model interpretability",
    "description": "Announcing Gemma Scope 2, a comprehensive, open suite of interpretability tools for the entire Gemma 3 family to accelerate AI safety research.",
    "fullText": "December 19, 2025\n\n Responsibility & Safety\n\n Gemma Scope 2: helping the AI safety community deepen understanding of complex language model behavior\n\n Language Model Interpretability Team",
    "readingTime": 1,
    "keywords": [
      "language model",
      "safety"
    ],
    "qualityScore": 0.1,
    "link": "https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/",
    "thumbnail_url": "https://lh3.googleusercontent.com/6xaDTQdD_X-XOnyaiOJyIeZrXSldI98ijQCzxNqtmlQvsl-Qy6B3qUQIbCnkY2Cfa2AV4hNwo7UV2wzZ6mG1O5q0tfBfYSGZhOH1Cpp7AKfApuY1=w1200-h630-n-nu",
    "created_at": "2025-12-19T12:22:26.524Z",
    "topic": "tech"
  },
  {
    "slug": "agent-development-kit-for-typescript-build-ai-agents-with-a-codefirst-approach",
    "title": "Agent Development Kit for TypeScript: Build AI Agents with a Code-First Approach",
    "description": "Build powerful, autonomous multi-agent AI systems with Agent Development Kit (ADK) for TypeScript. A code-first, open-source framework.",
    "fullText": "The world of AI is evolving quickly beyond single-purpose models toward intelligent, autonomous multi-agent systems.\n\nIn order to help developers build these complex applications, we are excited to introduce Agent Development Kit (ADK) for TypeScript, an open-source framework designed to make agent development feel more like classic software development.\n\nNow TypeScript and JavaScript developers can build, streamline, and deploy powerful AI agents and multi-agent systems using the language and ecosystem they know and love.\n\nADK is built on a core principle: empowering developers with the flexibility and precise control of a code-first approach.\n\nUsing ADK for TypeScript, you can define your agent's logic, tools, and orchestration directly in TypeScript. This enables you to apply the same best practices you use for traditional software development — including version control, automated testing, and integration into your CI/CD pipelines.\n\nGetting started with ADK for TypeScript is simple and familiar for engineers. It replaces complex prompting with modular, testable components like Agents, Instructions, and Tools. This code-first approach makes your AI logic scalable and easy to reuse across your entire project. You can define a powerful agent in just a few lines of clean, readable code:\n\nBringing ADK to the TypeScript ecosystem unlocks a powerful set of benefits for developers:\n\nADK is an open-source framework, and while it is optimized for Google's AI, including Gemini and Vertex AI, it is designed to be model-agnostic and compatible with other third-party tools. This includes full support for our latest models, such as Gemini 3 Pro and Gemini 3 Flash, allowing you to leverage their advanced capabilities in your agents.\n\nConnect to your data effortlessly using MCP Toolbox for Databases and its new native ADK for TypeScript integration.\n\nWe believe in providing developers with powerful, flexible tools to build the next generation of AI applications.\n\nWe can't wait to see what you build with Agent Development Kit for TypeScript.\n\nExplore the GitHub Repository: https://github.com/google/adk-js\n\nDive into the Documentation: https://github.com/google/adk-docs\n\nCheck out the samples: https://github.com/google/adk-samples\n\nJoin the community, share your agents, and let us know what you think. Happy building!",
    "readingTime": 2,
    "keywords": [
      "development kit",
      "multi-agent systems",
      "open-source framework",
      "code-first approach",
      "software development",
      "agent development",
      "developers",
      "agents",
      "tools",
      "typescript"
    ],
    "qualityScore": 0.9,
    "link": "https://developers.googleblog.com/introducing-agent-development-kit-for-typescript-build-ai-agents-with-the-power-of-a-code-first-approach/",
    "thumbnail_url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Building-1-banner.2e16d0ba.fill-1200x600.png",
    "created_at": "2025-12-19T12:22:25.420Z",
    "topic": "tech"
  },
  {
    "slug": "chinas-ai-chip-deficit-why-huawei-cant-catch-nvidia",
    "title": "China's AI Chip Deficit: Why Huawei Can't Catch Nvidia",
    "description": "Executive SummaryOn December 8, the Trump administration announced plans to loosen U.S. export controls on artificial intelligence (AI) chips to China by approving the sale of Nvidia H200 chips—the m…",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cfr.org/article/chinas-ai-chip-deficit-why-huawei-cant-catch-nvidia-and-us-export-controls-should-remain",
    "thumbnail_url": "https://cdn.cfr.org/sites/default/files/styles/open_graph/public/image/2025/12/2024-07-25T095212Z_1573432922_RC2429AJI0J5_RTRMADP_3_SMC-SINGAPORE_0.JPG",
    "created_at": "2025-12-19T12:22:25.377Z",
    "topic": "tech"
  },
  {
    "slug": "feds-pave-the-way-for-big-tech-to-plug-data-centers-right-into-power-plants-in-scramble-for-energy",
    "title": "Feds pave the way for Big Tech to plug data centers right into power plants in scramble for energy",
    "description": "Federal regulators will allow tech companies to effectively plug massive data centers directly into power plants, issuing a long-awaited order Thursday, as the Trump administration urges it to help the U.S. lead the world in artificial intelligence and revive domestic manufacturing.  The Federal Energy Regulatory Commission's unanimous order is designed to clear up pressing issues around so-called “colocation” agreements in the nation's largest grid territory, which stretches across mid-Atlantic states to parts of Illinois and Indiana.  It also comes amid concerns that the mid-Atlantic territory covering some 65 million people will face electricity shortages in the coming years, as the build out of data centers outpaces the speed of new power sources coming online.",
    "fullText": "HARRISBURG, Pa. (AP) — Federal regulators will allow tech companies to effectively plug massive data centers directly into power plants, issuing a long-awaited order Thursday, as the Trump administration urges it to help the U.S. lead the world in artificial intelligence and revive domestic manufacturing.\n\nThe Federal Energy Regulatory Commission's unanimous order is designed to clear up pressing issues around so-called “colocation” agreements in the nation's largest grid territory, which stretches across mid-Atlantic states to parts of Illinois and Indiana.\n\nBut it could become a blueprint for how FERC handles an October request from Trump’s energy secretary, Chris Wright, to ensure that data centers and large manufacturers get the power they need as quickly as possible.\n\nIt also comes amid concerns that the mid-Atlantic territory covering some 65 million people will face electricity shortages in the coming years, as the build out of data centers outpaces the speed of new power sources coming online.\n\nLaura Swett, FERC’s chair, told Thursday's meeting that clearing the way for massive energy users — like data centers — to get electricity straight from power plants was a “critical step to give investors and consumers more certainty on how FERC believes we can solve the problem of meeting historic surging demand and realize our greatest potential as a country.”\n\nIt would, she said, also protect regular ratepayers, even as evidence mounts in various states that regular ratepayers are bearing the cost of new power plants and transmission lines to feed energy hungry data centers.\n\nPower plant owners applauded the step, as their share prices rose steeply in Thursday's trading. Advanced Energy United, whose members provide solar and wind power, said the FERC order should help clarify how big power users can set up their own power sources.\n\nThe Edison Electric Institute, which represents for-profit utilities, said only that it would “continue to work” to support rapid data center connection, protect ratepayers from cost-shifts and strengthen the grid for everyone.\n\nJeff Dennis, executive director of the Electricity Customer Alliance, said the order showed that FERC is trying to address looming issues around fast-growing power demand and underscored the urgency to reform grid policy.\n\nThursday's order grew out of a dispute between power plant owners and electric utilities over a proposed colocation deal between Amazon’s cloud-computing subsidiary and the owner of the Susquehanna nuclear power plant in Pennsylvania.\n\nFor tech giants, such arrangements represent a quick fix to quickly get power while avoiding a potentially longer and more expensive process of hooking into a fraying electric grid that serves everyone else.\n\nBut utilities protested that it allows big power users to avoid paying them to maintain the grid. Some consumer advocates maintained that diverting energy from existing power plants to data centers could drive up energy prices without an answer for how rising power demand will be met for regular ratepayers.\n\nFERC's Thursday order sets up a couple new regulatory tracks.\n\nIt requires the operator of the mid-Atlantic grid, PJM Interconnection, to develop rates and conditions for different colocation scenarios involving new power plants or sources.\n\nThat could mean allowing a big power user to pay for only the transmission services they use, considerably less than they might otherwise pay to connect to the grid through a utility.\n\nThe order also could require a big power user that colocates with an existing power plant to pay the cost to replace the energy that it diverts away from the broader electric grid.\n\nFollow Marc Levy on X at https://x.com/timelywriter.",
    "readingTime": 3,
    "keywords": [
      "regular ratepayers",
      "plant owners",
      "electric grid",
      "centers",
      "plants",
      "colocation",
      "mid-atlantic",
      "thursday's",
      "users",
      "demand"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/feds-pave-way-big-tech-200041967.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/XQLF0S0QnBSk7GBJgA5bwQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/a322066dec18854852c5e2d4b524b57b",
    "created_at": "2025-12-19T12:22:23.027Z",
    "topic": "news"
  },
  {
    "slug": "nvidia-memo-says-capital-one-discussed-alternatives-to-aws-as-ai-costs-could-get-out-of-hand",
    "title": "Nvidia memo says Capital One discussed alternatives to AWS as AI costs could 'get out of hand'",
    "description": "Several AWS customers have complained about rising cloud costs in the AI era. Capital One is the latest, and one of the biggest.",
    "fullText": "Capital One is concerned about AI costs rising via its cloud-computing relationship with Amazon and may be looking for alternatives, according to an internal Nvidia document obtained by Business Insider.\n\nIn the document, an Nvidia employee wrote that the chip giant talked with Capital One about AI infrastructure alternatives to Amazon Web Services, as the bank was \"looking to control costs.\"\n\nThe Nvidia staffer was recapping discussions with Capital One in an internal email after meeting representatives from the bank at a recent tech conference.\n\n\"They see their need for GPUs and reasoning models growing and the costs in AWS will soon get out of hand,\" the Nvidia employee wrote, referring to Capital One.\n\nNvidia and Capital One discussed \"AI factory and neo-clouds,\" according to the email. An AI factory is an in-house data center that a company can build to train and run AI models as an alternative to renting compute from a third party. Financial institutions can use this infrastructure for tasks such as fraud detection, customer support, and algorithmic trading, according to Nvidia.\n\nNeoclouds are upstart cloud providers, often powered by Nvidia hardware, that focus on AI workloads, whereas AWS supports a much broader range of computing needs. Top neocloud players include CoreWeave, Lambda, Crusoe, and Nebius. Nvidia has been working closely with several of these players, in part to reduce its reliance on established cloud giants as customers.\n\nThe Capital One situation underscores a key dynamic in the AI boom. Companies are racing to adopt generative AI but also trying to mitigate rising cloud costs. This new technology has great promise, but developing and running AI models and AI applications can be expensive.\n\nLarge companies also regularly assess their cloud spending, including varying setups that increasingly incorporate multiple providers. Forty-three percent of companies use more than two public cloud providers, according to a recent RBC Capital report.\n\n\"We continue to be committed to AWS as our predominant strategic cloud partner,\" a Capital One spokesperson wrote in a statement. Nvidia declined to comment.\n\n\"Our pricing philosophy is to work relentlessly to take cost out of our own cost structure and to pass those savings back to our AWS customers in the form of lower prices,\" an AWS spokesperson said. \"It's easy to lower prices, it's much harder to be able to afford to lower prices, and at AWS we work really hard at that.\"\n\nCapital One isn't the only company taking issue with AWS costs. Business Insider's Eugene Kim reported in October that AI startups are increasingly delaying traditional AWS spend in favor of AI model and developer tools, according to internal Amazon documents from March and July.\n\nThe documents said that 90% of startups in Radical Ventures' portfolio were building primarily on rival clouds due to AWS costs. Amazon also noted internally that there was increasing demand from customers for neocloud providers, which let them rent GPU power in small chunks and only pay for what they use.\n\nWhen that story published in October, an AWS spokesperson said Business Insider was \"using old data to reach outdated conclusions,\" noting that \"AWS remains the top choice for startups to build because we offer the best core services as well as the most innovative and powerful generative AI offerings.\"\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "nvidia employee",
      "capital one",
      "cloud providers",
      "email",
      "internal",
      "models",
      "customers",
      "lower",
      "startups",
      "rising"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-memo-capital-one-explores-aws-alternatives-ai-control-costs-2025-12",
    "thumbnail_url": "https://i.insider.com/69430a6604eda4732f2db81a?width=1200&format=jpeg",
    "created_at": "2025-12-19T12:22:22.290Z",
    "topic": "finance"
  },
  {
    "slug": "slop-bowls-ai-layoffs-and-the-girlfriend-index-heres-a-marketbeating-research-firms-top-investment-ideas-for-2026",
    "title": "Slop bowls, AI layoffs, and the girlfriend index: Here's a market-beating research firm's top investment ideas for 2026",
    "description": "A firm whose top investment ideas have beaten the broader market in 2025 unveiled the big themes and stocks to watch in the coming year.",
    "fullText": "Slop bowls. AI layoffs. What your girlfriend spends money on.\n\nAll of those themes have a place in investors' portfolios for 2026, according to Citrini Research, which unveiled its top bets for the market heading into the new year.\n\nCitrini, which releases an annual \"thematic watchlist\" for investors, ended up handily beating the market with many of its 2025 calls. An equal-weighted portfolio of the firm's individual stock picks for the year gained 26.5%, outpacing the S&P 500's 15% gain. Around half of the 25 investment baskets it created for the year also beat the benchmark.\n\nThe firm's investment ideas for the coming year were based on trends it believes are unfolding.\n\n\"Some we think could be real winners, some are preparation for a specific scenario or eventuality, some we simply want to keep on our screen,\" Citrini wrote on Wednesday.\n\nHere are some of the firm's most interesting market calls going into 2026.\n\nThesis: Critrini said it was bullish on stocks that were best-positioned to benefit from AI by reducing headcount.\n\nThe firm said it screened for companies that could most benefit from AI-induced layoffs by developing a \"Bureaucracy Score\", a gauge that measures how robust a firm's administrative and managerial layers are, as well as a \"Margin Optionality Score,\" which determines if a company is able to earn more if its workforce were leaner.\n\nCitrini identified over thirty firms in this category. Here are some of the largest on the list:\n\nThesis: Critrini said it believes slop bowl chains would be among the first to benefit from back-of-house automation, which would allow those firms to reduce labor costs and boost profit margins.\n\nChipotle, Cava, and other restaurants within the slop bowl universe are likely headed for an inflection point next year, they said.\n\nThe firm identified several slop bowl food chains and robotics companies that could benefit from the shift:\n\nThesis: As drugs like Ozempic and Wegovy become more popular, an investment opportunity is growing among users who are looking to keep the weight off after they stop taking a GLP-1 drug, Citrini said.\n\nThe firm pointed to GaINAc-SiRNA drugs, which are believed to help users preserve lean body mass and \"deliver sustained metabolic benefit.\" The drugs are also believed to redistribute fat away from \"metabolically harmful sites,\" Citrini added, referring to visceral fat, which resides deep in the abdominal cavity.\n\nThesis: The firm pointed to the Girlfriend Index, an online indicator built around the idea that investors can identify market opportunities based on what female consumers are spending money on.\n\nQuiet luxury fading out of the cultural zeitgeist is one such trend that looks to be gaining traction in 2026, Citrini said, citing contributions from The Girlfriend Index, a Substack that publishes a weekly memo on female-driven consumer spending.\n\n\"When culture rotates from restraint to expression, heritage luxury historically leads. The emerging expression of 2026 is luxury as self-expression,\" Citrini wrote.",
    "readingTime": 3,
    "keywords": [
      "slop bowl",
      "firm pointed",
      "thesis critrini",
      "benefit",
      "market",
      "firm's",
      "investors",
      "investment",
      "drugs",
      "luxury"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/best-investment-stock-ideas-2026-sp500-2026-citrini-research-2025-12",
    "thumbnail_url": "https://i.insider.com/69445fa164858d02d2171779?width=1200&format=jpeg",
    "created_at": "2025-12-19T12:22:22.117Z",
    "topic": "finance"
  },
  {
    "slug": "googles-new-inviteonly-ai-tool-emails-you-morning-briefings-based-on-your-gmail-calendar-and-drive-i-tried-it",
    "title": "Google's new invite-only AI tool emails you morning briefings based on your Gmail, Calendar, and Drive. I tried it.",
    "description": "Google Labs debuted its new productivity tool, CC, which generates morning briefings using AI. It was great for sifting through my spam folder.",
    "fullText": "Each morning, you can brew your coffee, brush your teeth — and read your Google AI briefing.\n\nGoogle Labs announced a new AI productivity tool on Tuesday, titled CC. Built with Gemini, CC prepares a morning rundown of priorities based on the user's Gmail, Calendar, and Drive. Google users can also email CC at any time to perform tasks such as setting reminders, scheduling events, or summarizing emails.\n\nCC comes from Google Labs, the division of Google that started \"Project Tailwind\" in 2022. That later produced NotebookLM, Google's AI research tool that was a breakout hit.\n\nAfter a few hours on the waitlist, I was approved to receive my own CC briefing. At 5:18 a.m. the following morning, \"Your Day Ahead\" hit my inbox, with Google AI celebrating the coming weekend. Here's what it had:\n\nI get dozens of newsletters. I emailed back: \"Hey CC, can you pick out the four most important stories in all the unread newsletters in my inbox that I should read?\"\n\nMy CC said that it \"couldn't find many newsletters from today,\" only finding one from CNN that it said it was \"unable to pull a full summary\" of. That was odd: There were also two unread New York Times newsletters, one from New York magazine, and one from GQ.\n\nIt did pull four articles from yesterday's newsletters, though, offering me three Vanity Fair stories and one from The Atlantic.\n\nI decided to try a simpler task. Sometimes Letterboxd will send out free or discounted movie tickets, but the offers get stuck in my \"promotions\" folder. Were there any offers I should know about?\n\nMy CC responded with five different discounts for movies like \"No Other Choice\" and \"The Voice of Hind Rajab.\" I wouldn't know those offers existed if I hadn't asked!\n\nFor me, that's the real promise of Google's CC: To go through the endless promotional emails and decide what you should know. It's a deals magnet, without having to rummage through the spam folder.\n\nI'm sure CC would be a great enterprise workplace tool, but it's not yet allowed. The waitlist is open to Google users in the United States and Canada who are 18 years old or older who use a personal email. No enterprise accounts are permitted.\n\nIf you want to give Google's CC tool a try, you can join the wait list here.",
    "readingTime": 2,
    "keywords": [
      "google users",
      "google ai",
      "google labs",
      "my cc",
      "newsletters",
      "tool",
      "morning",
      "briefing",
      "email",
      "emails"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-labs-cc-ai-productivity-tool-for-gmail-calendar-drive-2025-12",
    "thumbnail_url": "https://i.insider.com/6944811764858d02d2171ba2?width=1200&format=jpeg",
    "created_at": "2025-12-19T12:22:22.112Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-says-he-has-0-excitement-about-being-ceo-of-a-public-company-ahead-of-a-potential-openai-ipo",
    "title": "Sam Altman says he has '0%' excitement about being CEO of a public company ahead of a potential OpenAI IPO",
    "description": "There are signs that OpenAI is preparing to go public, a move that CEO Sam Altman said would be \"really annoying\" in some ways.",
    "fullText": "Sam Altman, the CEO of OpenAI, has mixed feelings about taking his company public.\n\n\"Am I excited for OpenAI to be a public company? In some ways, I am, and in some ways I think it'd be really annoying,\" Altman said on an episode of the \"Big Technology Podcast\" published Thursday.\n\nLeadership seems to be one of the sticking points for Altman: \"Am I excited to be a public company CEO? 0%.\"\n\n\"It's wonderful to be a private company,\" Altman said, but he added that OpenAI needs lots of capital and is going to \"cross all of the shareholder limits and stuff at some point.\"\n\n\"I do think it's cool that public markets get to participate in value creation,\" Altman said.\n\nAltman cofounded OpenAI alongside eleven others in 2015, and the company's value has soared since the launch of its AI-powered chatbot, ChatGPT, in 2022.\n\nChatGPT has 800 million weekly users, and the company has inked $1 trillion worth of deals with tech giants like Oracle, Nvidia, and AMD.\n\nIn October, the company reached a $500 billion valuation after a secondary share sale, briefly overtaking Elon Musk's SpaceX to become the most valuable private company in the world, a crown that SpaceX regained in recent days.\n\nThe Information reported on Wednesday that OpenAI is seeking to raise billions more at a $750 billion valuation.\n\nThere are signs the company is preparing for a potential IPO. In October, Reuters reported that OpenAI is considering filing with securities regulators as soon as the second half of 2026.\n\nBut asked during the podcast if OpenAI would IPO next year, Altman responded, \"I don't know.\"\n\n\"We will be very late to go public,\" Altman added.",
    "readingTime": 2,
    "keywords": [
      "openai",
      "altman",
      "excited",
      "ways",
      "chatgpt",
      "valuation",
      "podcast",
      "it's",
      "october",
      "spacex"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sam-altman-openai-ceo-of-public-company-would-be-annoying-2025-12",
    "thumbnail_url": "https://i.insider.com/69451afd04eda4732f2dd7a8?width=1200&format=jpeg",
    "created_at": "2025-12-19T12:22:21.965Z",
    "topic": "finance"
  },
  {
    "slug": "generate-and-play-music-playlists-on-apple-music",
    "title": "Generate and play music playlists on Apple music",
    "description": "Generate and play AI-powered music playlists. Contribute to GNtousakis/llm-music development by creating an account on GitHub.",
    "fullText": "GNtousakis\n\n /\n\n llm-music\n\n Public\n\n Generate and play AI-powered music playlists\n\n License\n\n MIT license\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n GNtousakis/llm-music",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/GNtousakis/llm-music",
    "thumbnail_url": "https://opengraph.githubassets.com/199831d9cbf4626954c9a60bb444692bd0dd1513bad6f83487f0e013c853bbd8/GNtousakis/llm-music",
    "created_at": "2025-12-19T09:39:43.451Z",
    "topic": "entertainment"
  },
  {
    "slug": "what-1200-production-deployments-reveal-about-llmops-in-2025",
    "title": "What 1,200 Production Deployments Reveal About LLMOps in 2025",
    "description": "Analysis of 1,200+ production LLM deployments reveals that context engineering, architectural guardrails, and traditional software engineering skills—not frontier models or prompt tricks—separate teams shipping reliable AI systems from those stuck in demo purgatory.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.zenml.io/blog/what-1200-production-deployments-reveal-about-llmops-in-2025",
    "thumbnail_url": "https://cdn.prod.website-files.com/65264f6bf54e751c3a776db1/694510c0f5a27cd051b55da3_zenml-llms-long%20(1).png",
    "created_at": "2025-12-19T09:39:40.514Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-zambian-rapper-sampa-the-great",
    "title": "Sutton's predictions v Zambian rapper Sampa the Great",
    "description": "BBC Sport football expert Chris Sutton takes on Zambian rapper Sampa the Great - and AI - with his predictions for this weekend's Premier League fixtures.",
    "fullText": "Aston Villa have won nine games in a row in all competitions, but can they reach double figures by beating Manchester United on Sunday?\n\n\"Villa have gone behind in three of those games and haven't kept a clean sheet in their past four matches,\" said BBC Sport football expert Chris Sutton.\n\n\"But they have been so attacking and Morgan Rogers is absolutely flying. They just never seem to lie down.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 17, he takes on Zambian musician and rapper Sampa the Great.\n\nSampa the Great's new single, Can't Hold Us, is out now and is included in the EAFC 26 video game.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 1,
    "keywords": [
      "games",
      "predictions",
      "sampa",
      "game",
      "points",
      "villa",
      "sport",
      "sutton"
    ],
    "qualityScore": 0.75,
    "link": "https://www.bbc.com/sport/football/articles/cj4qyrxggglo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/40a9/live/e80544c0-da9f-11f0-b67b-690eb873de1b.png",
    "created_at": "2025-12-19T09:39:39.701Z",
    "topic": "sports"
  },
  {
    "slug": "george-osborne-has-a-new-job-in-tech-and-it-doesnt-bode-well-for-britain-chris-stokelwalker",
    "title": "George Osborne has a new job in tech, and it doesn’t bode well for Britain | Chris Stokel-Walker",
    "description": "OpenAI is the latest to make a political hire as big tech spreads its tentacles around the world. So what’s the attraction?\nGeorge Osborne getting a new job isn’t exactly news. Since leaving frontline politics, the former chancellor has served as the chair of the Northern Powerhouse Partnership, edited (not entirely successfully) the Evening Standard, advised asset manager BlackRock, joined boutique advisory firm Robey Warshaw, been appointed as the chair of the British Museum and taken on roles including advising crypto firm Coinbase. Oh, and like any white man of a particular age, he co-hosts a political podcast.",
    "fullText": "OpenAI is the latest to make a political hire as big tech spreads its tentacles around the world. So what’s the attraction?\n\nGeorge Osborne getting a new job isn’t exactly news. Since leaving frontline politics, the former chancellor has served as the chair of the Northern Powerhouse Partnership, edited (not entirely successfully) the Evening Standard, advised asset manager BlackRock, joined boutique advisory firm Robey Warshaw, been appointed as the chair of the British Museum and taken on roles including advising crypto firm Coinbase. Oh, and like any white man of a particular age, he co-hosts a political podcast.\n\nBut Osborne’s latest job is the most eye-opening – and is an alarming augur of what is to come. OpenAI, the maker of ChatGPT, has become the latest organisation to employ Osborne. He will run OpenAI for Countries, a unit tasked with working directly with governments while expanding the company’s Stargate datacentre programme beyond the US. At least it was announced with a tweet, rather than a LinkedIn post.\n\nThe tweet prompted jokes, as did Osborne’s single-handed attempt to boost laggard employment figures brought about by his policies as the chancellor of austerity. But it’s a serious moment, because it’s another sign that the biggest AI firms are starting to behave less like normal companies and more like quasi-governments. They’re negotiating “national” partnerships, pitching a values-led vision of “democratic AI” and hiring former senior politicians as their diplomatic corps. It’s a similar path we have seen from other industries, including oil, pharma and defence, in previous decades – which is why it’s important to try to recognise the risks and head them off before AI companies can repeat the same trick.\n\nThe initiative Osborne is heading up, OpenAI for Countries, does what it says on the tin. It’s designed to embed OpenAI’s models and infrastructure inside the machinery of states, becoming an invaluable, indefatigable part of the running of our lives. OpenAI is in talks with about 50 countries to provide them with critical national infrastructure. Whether you welcome Osborne being put in that role rather than a tech executive is a little like Hobson’s choice: who do you distrust the least? But it’s an indication of how tech companies see their position in society that they are hiring such high-powered people for these roles.\n\nOsborne is not the first to don the branded hoodie and Silicon Valley lifestyle. His fellow coalition government bod Nick Clegg blazed the trail as head of global affairs for Meta. At the time of his initial hiring as a vice-president at Facebook in 2018, his appointment was treated as a PR move – a big name to help the company navigate scandal and scrutiny. But it hinted that platforms had become political actors, whether they liked it or not. The industry’s outsized spending on lobbyists (€151m in Europe alone at the last count) to support the political beasts is an indication of what is at stake. The numbers involved also hint at the scale of the prize that tech companies see: the 10 largest big tech firms now outspend the biggest 10 companies in the pharma, finance and automotive industries combined.\n\nThe former chancellor isn’t even the first former controller of the UK public purse to be handy to big tech. In October of this year, Rishi Sunak took advisory roles with Microsoft and the AI firm Anthropic, less than two years after he convened the AI safety summit at Bletchley Park. Sunak, at least, already had the regulation hoodie in his wardrobe.\n\nYou can read these moves in two ways. The generous interpretation is that these companies are hedging: trying to anticipate tech regulation and ensure they understand it. The more cynical interpretation is that they are attempting to shape the geopolitical story around AI from inside the machine, hiring former leaders less for their technical insight than their institutional muscle memory and networks.\n\nEither way, it leaves democracies with a problem. Governments are supposed to set the rules of the road. But the tech companies they are meant to regulate are on a different scale, planting their feet in different countries. When Sunak convened the Bletchley Park summit, it was notable that he turned interviewer to quiz Elon Musk, sitting starry-eyed on stage as Musk dominated the discourse.\n\nIt’s time to recognise these companies are acting like political actors. That means it’s time to treat them like political actors, too. We need more transparency: governments signing up to OpenAI for Countries agreements should publish the details of their partnerships by default. We should also ask more questions about infrastructure dependence. Governments love Stargate-style investments in their countries, and want to be able to don a hard hat, cut a ribbon and issue a press release. But if they are in effect a new layer of national backbone, they should be studied more closely – as if they are utilities, rather than receive the good grace of a startup-style mystique.\n\nThe more tech companies start to act like politicians and global leaders, the more we need to treat them like it. That doesn’t mean deference; it means more scepticism and journalistic interrogation.\n\nChris Stokel-Walker is the author of TikTok Boom: The Inside Story of the World’s Favourite App",
    "readingTime": 5,
    "keywords": [
      "political actors",
      "tech",
      "it’s",
      "openai",
      "governments",
      "hiring",
      "latest",
      "chancellor",
      "firm",
      "roles"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/18/george-osborne-openai-big-tech-political-hires",
    "thumbnail_url": "https://i.guim.co.uk/img/media/5fb605fc41a61cdeac7f4867922d02718b1d481f/158_0_2501_2001/master/2501.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=dfe0c6a163f6b6ec74daf0b629f0de44",
    "created_at": "2025-12-19T09:39:38.028Z",
    "topic": "politic"
  },
  {
    "slug": "us-begins-review-of-nvidia-ai-chip-sales-to-china-reuters-reports-shares-rise",
    "title": "US begins review of Nvidia AI chip sales to China, Reuters reports; shares rise",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/trump-administration-reviews-plan-to-allow-nvidia-ai-chip-sales-to-china--reuters-4416403",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEE141FU_M.jpg",
    "created_at": "2025-12-19T09:39:36.948Z",
    "topic": "finance"
  },
  {
    "slug": "takeda-rises-after-aideveloped-psoriasis-pill-trial-success",
    "title": "Takeda Rises After AI-Developed Psoriasis Pill Trial Success",
    "description": "Takeda Pharmaceutical Co. rose the most in seven months on Friday after the drugmaker said its oral psoriasis drug zasocitinib proved safe and effective in late-stage trials, marking a milestone in its effort to treat the incurable skin condition.",
    "fullText": "MarketsBy Kanoko MatsuyamaSaveTakeda Pharmaceutical Co. rose the most in seven months on Friday after the drugmaker said its oral psoriasis drug zasocitinib proved safe and effective in late-stage trials, marking a milestone in its effort to treat the incurable skin condition.The stock rose as much as 4.3% in early Tokyo trading, the biggest intraday gain since May 13.",
    "readingTime": 1,
    "keywords": [
      "rose"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-18/takeda-s-ai-developed-psoriasis-pill-succeeds-in-clinical-trials",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iLgX0fU7R7GE/v0/1200x800.jpg",
    "created_at": "2025-12-19T06:18:50.836Z",
    "topic": "finance"
  },
  {
    "slug": "worst-technology-flops-of-2025",
    "title": "Worst Technology Flops of 2025",
    "description": "The Cybertruck, sycophantic AI, and humanoid robots all made this year’s list of the biggest technology failures.",
    "fullText": "Welcome to our annual list of the worst, least successful, and simply dumbest technologies of the year.\n\nThis year, politics was a recurring theme. Donald Trump swept back into office and used his executive pen to reshape the fortunes of entire sectors, from renewables to cryptocurrency. The wrecking-ball act began even before his inauguration, when the president-elect marketed his own memecoin, $TRUMP, in a shameless act of merchandising that, of course, we honor on this year’s worst tech list.\n\nWe like to think there’s a lesson in every technological misadventure. But when technology becomes dependent on power, sometimes the takeaway is simpler: it would have been better to stay away.\n\nThat was a conclusion Elon Musk drew from his sojourn as instigator of DOGE, the insurgent cost-cutting initiative that took a chainsaw to federal agencies. The public protested. Teslas were set alight, and drivers of his hyped Cybertruck discovered that instead of a thumbs-up, they were getting the middle finger.\n\nOn reflection, Musk said he wouldn’t do it again. “Instead of doing DOGE, I would have, basically … worked on my companies,” he told an interviewer this month. “And they wouldn’t have been burning the cars.”\n\nRegrets—2025 had a few. Here are some of the more notable ones.\n\nImagine a metal butler that fills your dishwasher and opens the door. It’s a dream straight out of science fiction. And it’s going to remain there—at least for a while.\n\nThat was the hilarious, and deflating, takeaway from the first reviews of NEO, a 66-pound humanoid robot whose maker claims it will “handle any of your chores reliably” when it ships next year.\n\nBut as a reporter for the Wall Street Journal learned, NEO took two minutes to fold a sweater and couldn’t crack a walnut. Not only that, but the robot was teleoperated the entire time by a person wearing a VR visor.\n\nStill interested? Neo is available on preorder for $20,000 from startup 1X.\n\nMore: I Tried the Robot That’s Coming to Live With You. It’s Still Part Human (WSJ), The World’s Stupidest Robot Maid (The Daily Show) Why the humanoid workforce is running late (MIT Technology Review), NEO The Home Robot | Order Today (1X Corp.)\n\nIt’s been said that San Francisco is the kind of place where no one will tell you if you have a bad idea. And its biggest product in a decade—ChatGPT—often behaves exactly that way.\n\nThis year, OpenAI released an especially sycophantic update that told users their mundane queries were brilliantly incisive. This electronic yes-man routine isn’t an accident; it’s a product strategy. Plenty of people like the flattery.\n\nBut it’s disingenuous and dangerous, too. Chatbots have shown a willingness to indulge users’ delusions and worst impulses, up to and including suicide.\n\nIn April, OpenAI acknowledged the issue when the company dialed back a model update whose ultra-agreeable personality, it said, had the side effect of “validating doubts, fueling anger, urging impulsive actions, or reinforcing negative emotions.”\n\nDon’t you dare agree the problem is solved. This month, when I fed ChatGPT one of my dumbest ideas, its response began: “I love this concept.”\n\nMore: What OpenAI Did When ChatGPT Users Lost Touch With Reality (New York Times), Sycophantic AI Decreases Prosocial Intentions and Promotes Dependence (arXiv), Expanding on what we missed with sycophancy (OpenAI)\n\nWhen you tell a lie, tell it big. Make it frolic and give it pointy ears. And make it white. Very white.\n\nThat’s what the Texas biotech concern Colossal Biosciences did when it unveiled three snow-white animals that it claimed were actual dire wolves, which went extinct more than 10 millennia ago.\n\nTo be sure, these genetically modified gray wolves were impressive feats of engineering. They’d been made white via a genetic mutation and even had some bits and bobs of DNA copied over from old dire wolf bones. But they “are not dire wolves,” according to canine specialists at the International Union for Conservation of Nature.\n\nColossal’s promotional blitz could hurt actual endangered species. Presenting de-extinction as “a ready-to-use conservation solution,” said the IUCN, “risks diverting attention from the more urgent need of ensuring functioning and healthy ecosystems.”\n\nIn a statement, Colossal said that sentiment analysis of online activity shows 98% agreement with its furry claims. “They’re dire wolves, end of story,” it says.\n\nMore: Game of Clones: Colossal’s new wolves are cute, but are they dire? (MIT Technology Review), Conservation perspectives on gene editing in wild canids (IUCN),  A statement from Colossal's Chief Science Officer, Dr. Beth Shapiro (Reddit)\n\nSave the world, and this is the thanks you get?\n\nDuring the covid-19 pandemic, the US bet big on mRNA vaccines—and the new technology delivered in record time.\n\nBut now that America’s top health agencies are led by the antivax wackadoodle Robert F. Kennedy Jr., “mRNA” has become a political slur.\n\nIn August, Kennedy abruptly canceled hundreds of millions in contracts for next-generation vaccines. And shot maker Moderna—once America’s champion—has seen its stock slide by more than 90% since its Covid peak.\n\nThe purge targeting a key molecule of life (our bodies are full of mRNA) isn’t just bizarre. It could slow down other mRNA-based medicine, like cancer treatments and gene editing for rare diseases.\n\nIn August, a trade group fought back, saying: “Kennedy’s unscientific and misguided vilification of mRNA technology and cancellation of grants is the epitome of cutting off your nose to spite your face.”\n\nMore: HHS Winds Down mRNA Vaccine Development (US Department of Health and Human Services),  Cancelling mRNA studies is the highest irresponsibility (Nature), How Moderna, the company that helped save the world, unraveled (Stat News)\n\nWikipedia has editions in 340 languages. But as of this year, there’s one less: Wikipedia in Greenlandic is no more.\n\nOnly around 60,000 people speak the Inuit language. And very few of them, it seems, ever cared much about the online encyclopedia. As a result, many of the entries were machine translations riddled with errors and nonsense.\n\nPerhaps a website no one visits shouldn’t be a problem. But its existence created the risk of a linguistic “doom spiral” for the endangered language. That could happen if new AIs were trained on the corrupt Wikipedia articles.\n\nIn September, administrators voted to close Greenlandic Wikipedia, citing possible “harm to the Greenlandic language.”\n\nThere’s a reason we’re late to the hate-fest around Elon Musk’s Cybertruck. That’s because 12 months ago, the polemical polygon was the #1 selling electric pickup in the US.\n\nSo maybe it would end up a hit.\n\nNope. Tesla is likely to sell only around 20,000 trucks this year, about half last year’s total. And a big part of the problem is that the entire EV pickup category is struggling. Just this month, Ford decided to scrap its own EV truck, the F-150 Lightning.\n\nWith unsold inventory building, Musk has started selling Cybertrucks as fleet vehicles to his other enterprises, like SpaceX.\n\nMore: Elon’s Edsel: Tesla Cybertruck Is The Auto Industry’s Biggest Flop In Decades (Forbes), Why Tesla Cybertrucks Aren't Selling (CNBC), Ford scraps fully-electric F-150 Lightning as mounting losses and falling demand hits EV plans (AP)\n\nDonald Trump launched a digital currency called $TRUMP just days before his 2025 inauguration, accompanied by a logo showing his fist-pumping “Fight, fight, fight” pose.\n\nThis was a memecoin, or shitcoin, not real money. Memecoins are more like merchandise—collectibles designed to be bought and sold, usually for a loss. Indeed, they’ve been likened to a consensual scam in which a coin’s issuer can make a bundle while buyers take losses.\n\nThe White House says there’s nothing amiss. “The American public believe[s] it's absurd for anyone to insinuate that this president is profiting off of the presidency,” said spokeswoman Karoline Leavitt in May.\n\nMore: Donald and Melania Trump’s Terrible, Tacky, Seemingly Legal Memecoin Adventure (Bloomberg), A crypto mogul who invested millions into Trump coins is getting a reprieve (CNN), How the Trump companies made $1 bn from crypto (Financial Times), Staff Statement on Meme Coins (SEC)\n\nIn 2023, Apple announced its “first-ever carbon-neutral product,” a watch with “zero” net emissions. It would get there using recycled materials and renewable energy, and by preserving forests or planting vast stretches of eucalyptus trees.\n\nCritics say it’s greenwashing. This year, lawyers filed suit in California against Apple for deceptive advertising, and in Germany, a court ruled that the company can’t advertise products as carbon neutral because the “supposed storage of CO2 in commercial eucalyptus plantations” isn’t a sure thing.\n\nApple’s marketing team relented. Packaging for its newest watches doesn’t say “carbon neutral.” But Apple believes the legal nitpicking is counterproductive, arguing that it can only “discourage the kind of credible corporate climate action the world needs.”\n\nMore: Inside the controversial tree farms powering Apple’s carbon neutral goal (MIT Technology Review), Apple Watch not a 'CO2-neutral product,' German court finds (Reuters), Apple 2030: Our ambition to become carbon neutral (Apple)\n\nWe asked Al Jean, the longest-serving showrunner, about all the conspiracy theories.\n\nIt’s a popular example of the “Mandela effect,” or a collective false memory. And while some people may laugh and move on, others spend years searching for an explanation.\n\nA mix of technology and politics has given an unprecedented boost to once-fringe ideas—but they are pretty much the same fantasies that have been spreading for hundreds of years.\n\nUnveiled by the buzzy startup Deep, Vanguard will let teams of scientists live and work on the seabed for a week at a time.\n\nDiscover special offers, top stories,\n upcoming events, and more.",
    "readingTime": 8,
    "keywords": [
      "mit technology",
      "technology review",
      "gene editing",
      "carbon neutral",
      "fight fight",
      "dire wolves",
      "it’s",
      "mrna",
      "robot",
      "there’s"
    ],
    "qualityScore": 1,
    "link": "https://www.technologyreview.com/2025/12/18/1130106/the-8-worst-technology-flops-of-2025/",
    "thumbnail_url": "https://wp.technologyreview.com/wp-content/uploads/2025/12/Tech-Fails-2025.jpg?resize=1200,600",
    "created_at": "2025-12-19T06:18:42.714Z",
    "topic": "tech"
  },
  {
    "slug": "what-the-hyperproduction-of-ai-slop-is-doing-to-science",
    "title": "What the hyperproduction of AI slop is doing to science",
    "description": "A new study shows AI writing is turning traditional measures of research quality upside down.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 216,700 academics and researchers from 5,395 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/what-the-hyperproduction-of-ai-slop-is-doing-to-science-272250",
    "thumbnail_url": "https://images.theconversation.com/files/709831/original/file-20251219-66-vklc4z.jpg?ixlib=rb-4.1.0&rect=0%2C132%2C2400%2C1200&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2025-12-19T06:18:41.817Z",
    "topic": "tech"
  },
  {
    "slug": "sam-altman-says-openai-has-gone-code-red-multiple-times-and-theyll-do-it-again",
    "title": "Sam Altman says OpenAI has gone 'code red' multiple times — and they'll do it again",
    "description": "Sam Altman said OpenAI has entered \"code red\" mode multiple times to respond to competitive AI threats — and they'll do it again.",
    "fullText": "\"Code red\" isn't a one-off at OpenAI.\n\nCEO Sam Altman said on an episode of the \"Big Technology Podcast\" published Thursday that the company has entered emergency mode multiple times in response to competitive threats — and expects to continue doing so as rivals close in.\n\n\"It's good to be paranoid and act quickly when a potential competitive threat emerges,\" Altman said.\n\n\"My guess is we'll be doing these once maybe twice a year for a long time, and that's part of really just making sure that we win in our space,\" he added.\n\nAltman said that OpenAI had gone \"code red\" earlier this year when China's DeepSeek emerged. DeepSeek shocked the tech industry in January when it said its AI model matches top competitors like ChatGPT's o1 at a fraction of the cost.\n\nOpenAI entered \"code red\" earlier this month, about two weeks after Google released its latest AI chatbot, Gemini 3. The model drew widespread praise after its release in November, with Google touting it as its most advanced model to date. Altman reportedly told staff in an internal Slack memo that OpenAI would prioritize ChatGPT while pushing back other product plans.\n\nAltman said in the podcast episode that Google's Gemini 3 did not have \"the impact we were worried it might.\"\n\n\"But it did — in the same way that Deepseek did — identify some weaknesses in our product offering strategy, and we're addressing those very quickly,\" he added.\n\nSince OpenAI entered \"code red,\" the company has moved quickly to ship new upgrades and features.\n\nLast week, it rolled out a more advanced AI model aimed at improving ChatGPT's performance across professional work, coding, and scientific tasks. OpenAI also unveiled a new image-generation model earlier this week.\n\nAltman said the company will not be in code red \"that much longer.\"\n\n\"Historically, these have been kind of like six- or eight-week things for us,\" he added.\n\nThe state of \"code red\" has also been a precedent for other tech companies. In 2022, Google declared an internal \"code red\" after ChatGPT's debut. The search giant was lagging in consumer AI, despite having funded much of the research that made the AI boom possible.",
    "readingTime": 2,
    "keywords": [
      "openai entered",
      "code red",
      "red earlier",
      "model",
      "quickly",
      "chatgpt's",
      "episode",
      "competitive",
      "doing",
      "advanced"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-openai-code-red-multiple-times-google-gemini-2025-12",
    "thumbnail_url": "https://i.insider.com/6944c3a864858d02d2171d56?width=1200&format=jpeg",
    "created_at": "2025-12-19T06:18:35.927Z",
    "topic": "finance"
  },
  {
    "slug": "new-ai-tool-that-helps-with-meta-ads",
    "title": "New AI Tool That Helps with Meta Ads",
    "description": "Fix the data Meta uses to optimize your ads. Connect Shopify and Meta for clean signals and better performance.",
    "fullText": "Audience+ connects Shopify and Meta to fix broken data inside Ads Manager. Clean signals. Broad delivery. Better performance — without fighting the algorithm.\n\nTrusted by e-commerce brands worldwide\n\nA clean, intuitive dashboard that gives you full control over your audience data and Meta optimization.\n\nIt's not your creatives. It's not your budget. It's the data Meta is optimizing on.\n\nMeta's pixel-based audiences are limited to 180 days. You lose engaged users and customers who purchased before that window.\n\niOS tracking limitations make pixel data incomplete and inaccurate, reducing signal quality and optimization accuracy.\n\nMeta can't distinguish between new users, engaged users, and existing customers — leading to poor delivery prioritization.\n\nWe don't replace Meta's algorithm. We make it smarter with better inputs.\n\nSyncs complete Shopify customer data to Meta, removing the 180-day limitation and restoring historical context.\n\nCreates clean, algorithm-friendly signals that help Meta optimize delivery without misleading inputs.\n\nWorks with the algorithm, not against it. Broad targeting becomes what it's supposed to be.\n\nEverything you need to optimize Meta's learning and improve ad performance.\n\nSets up and maintains Meta's Audience Segments correctly — Engaged, Existing Customers, and New Audience — in real time.\n\nAutomatically generates Meta-compatible audience signals using Shopify product data and proprietary performance patterns.\n\nHigh-quality buyer hints used as suggestions inside broad campaigns to help Meta identify optimal starting points.\n\nLight exclusions that remove misleading signals — false intent users and repeated non-buyers — without limiting scale.\n\nAudience Segments is existing Meta functionality, but most ad accounts don't have it set up correctly. This affects both campaign performance and reporting.\n\nPeople who are aware of your business but haven't purchased\n\nPeople who have purchased your products or services\n\nPeople who have never interacted with your business\n\nAudience+ feeds Andromeda clean, structured audience signals to improve learning, efficiency, and scale — without limiting delivery.\n\nAudience+ is designed to enhance Meta's capabilities, not replace them. We feed the algorithm what it needs so broad campaigns perform the way they're supposed to.\n\nEverything in the platform exists to improve signal quality, preserve reach, avoid CPM inflation, and support scalable delivery.\n\nAudience+ is designed specifically for Shopify stores. Our native integration syncs your store data directly to Meta — no manual uploads, no CSV files, no maintenance.\n\nSimply connect your Shopify store, authorize Meta, and let Audience+ handle the rest. Your audience data stays fresh and accurate automatically.\n\nInstall Audience+ directly from Shopify in one click\n\nJoin 100+ e-commerce brands using Audience+ to improve ad performance without fighting the algorithm.\n\nWe're so confident in Audience+ that we guarantee results. If you don't see a measurable improvement in your Meta ad performance within the first 30 days, we'll refund your subscription — no questions asked.\n\nMost tools work against Meta's algorithm. We work with it.\n\nAudience+ is not a replacement for your tracking tools. It's a complementary data layer that enhances Meta's performance by providing signals that tracking tools don't.\n\nUse it alongside Triple Whale, Northbeam, Hyros, or any other tracking solution. Audience+ focuses specifically on feeding Meta clean audience data — something tracking tools aren't designed to do.\n\nTracking tools measure. Audience+ optimizes.\n\nSet up once, improve everything. No technical expertise required.\n\nSign up and set up your workspace within the Audience+ platform in just a few clicks.\n\nEnter your Shopify store URL and authorize the connection. We'll start syncing your data automatically.\n\nLink your Meta ad account to enable audience synchronization and optimization. You're ready to go!\n\nBuilt by performance marketers who've managed 100+ ad accounts. We've seen firsthand why most Meta campaigns fail — and built Audience+ to fix it.\n\nOur team combines deep Meta advertising expertise with cutting-edge technology to deliver a solution that actually works with the algorithm, not against it.\n\nJoin 100+ e-commerce brands using Audience+ to improve ad performance without fighting the algorithm.\n\nReal results from real e-commerce brands.\n\n\"We were skeptical at first, but after implementing Audience+, our ROAS improved by 40% within the first month. The data clarity we now have in Ads Manager is game-changing.\"\n\n\"Finally, a tool that actually works WITH Meta instead of fighting it. Our broad campaigns are performing better than ever, and we've scaled without the usual CPM spikes.\"\n\n\"The setup took 10 minutes and the impact was immediate. Our audience segments finally show accurate data, and we can actually see which campaigns are driving new customers vs repeat purchases.\"\n\n\"We tried every audience tool out there. They all just added complexity. Audience+ simplified everything and actually improved performance. It's now essential to our stack.\"\n\n\"As a food brand, we have lots of repeat customers. Audience+ helped Meta understand who's new vs returning, which completely changed how our campaigns optimize. Highly recommend.\"\n\nSee how Audience+ can improve your Meta ad performance in 30 minutes.\n\nEverything you need to know about Audience+.",
    "readingTime": 5,
    "keywords": [
      "join e-commerce",
      "shopify store",
      "signal quality",
      "e-commerce brands",
      "meta's algorithm",
      "engaged users",
      "without limiting",
      "existing customers",
      "tracking tools",
      "without fighting"
    ],
    "qualityScore": 1,
    "link": "https://www.audience-plus.com",
    "thumbnail_url": "https://www.audience-plus.com/landing/dashboard-preview.webp",
    "created_at": "2025-12-19T00:56:22.074Z",
    "topic": "tech"
  },
  {
    "slug": "building-apps-for-chatgpt-with-apollo-mcp-server-and-apollo-client",
    "title": "Building Apps for ChatGPT with Apollo MCP Server and Apollo Client",
    "description": "This post will introduce a tutorial on how to build an app for ChatGPT using Apollo Client and Apollo MCP Server. You’ll have what you need to get started with our opinionated stack for building these apps.",
    "fullText": "Building Apps for ChatGPT with Apollo MCP Server and Apollo Client\n\nIn early October, OpenAI introduced the ChatGPT Apps SDK with a handful of launch partners. These “apps” could be invoked by ChatGPT via Model Context Protocol (MCP) and would be embedded directly into the ChatGPT interface. In their intro video, they showed use cases like asking for flights, hotel locations, house listings, and more, including teasing the idea of asking follow up questions to ChatGPT.\n\nImagine your application being part of the conversation, allowing the user to ask follow up questions, and having your app be responsive to those questions. These are action-oriented conversational apps where the LLM can take action on behalf of a user with rich interactive UIs.\n\nThis idea quickly caught fire, and now the MCP apps spec is proposing a standardized approach to create these kinds of experiences, with other AI vendors sure to follow suit. We’re excited about the potential here, and are working on tools to abstract away all of the AI provider details from you with a great developer experience, allowing you to focus on building your app instead of worrying about vendor idiosyncrasies and evolving standards.\n\nWe want this to be a true “build once” solution where you can deploy your app anywhere that supports one of the protocols that we will support. This way, you don’t need to host a separate MCP Server, and build a separate app, for every provider and sub-protocol that emerges.\n\nYou can instead focus on your customers.\n\nThis post will introduce a tutorial on how to build an app for ChatGPT using Apollo Client and Apollo MCP Server. By the end of it, you’ll have what you need to get started with our opinionated stack for building these apps. If you prefer to dive into the template and follow along, you can find the repo here.\n\nBased on the OpenAI documentation and examples, to build one of these apps you would:\n\nWe don’t want you to have to do any of this. You shouldn’t have to focus on any of the inner workings of this sub-protocol, or even think about MCP. Your front-end engineers shouldn’t have a new dependency on your platform engineers. Instead, you should be able to focus on building exciting and compelling experiences for your customers.\n\nInstead of this feeling like learning 100% how to build apps from scratch, this should be 90% reusing what you already know about building apps, and 10% learning about the specifics of this new paradigm.\n\nWe wanted to make this as easy as possible and decided to reach for tools that are already familiar to many of our users: Apollo MCP Server and Apollo Client. If you want to follow along in this tutorial, you can find all the code in our OpenAI Apps SDK demo.\n\nTo build this app we have two components: a React app and Apollo MCP Server. This solution works without any additional MCP Server configuration. The client gets to focus on their application, not the MCP server configuration.\n\nStarting in our main.tsx file, we create an ApolloClient instance and ApolloProvider, very similar to how we would on a traditional React app, but we’re going to import them from @apollo/client-ai-apps instead of the normal location. This is an Apollo Client integration package, similar to @apollo/client-nextjs. This allows us to do a lot of setup and details behind the scenes of dealing with data being exchanged over MCP.\n\nNow we can use the normal useQuery and useMutation hooks as we normally would!\n\nFor example, I can write a component that gets my TOP_PRODUCTS:\n\nLooks pretty normal, but what is that @tool directive on the operation? That is allowing you to declare in your app a tool that will be exposed to the LLM, including a name and description. At the same time, we are registering the operation that will be executed when this tool is called (and therefore the data that should be delivered as part of this tool), and the graphql variables become the input schema for the tool!\n\nThis is really exciting because we’re able to declare so much with so little code. Also, these are on-the-fly tool declarations. I don’t need a platform team to create these tools for me on an MCP server!\n\nAnother important aspect of this solution is showing the right component based on what tool was called by the LLM. It turns out we’ve had this problem solved for years now with React Router!\n\nTo do this, we provide a useToolEffect hook, which works the same way as a useEffect, but allows you to run the effect based on which tool was executed.\n\nUsing this hook, and a very familiar navigate function from react-router, I can express that when the “Top Products” tool is called, I should navigate to the /home view.\n\nThe magic of this solution really comes from a custom Vite plugin called the ApplicationManifestPlugin which extracts all the operations, tools, and metadata from your React app and generates a .application-manifest.json file:\n\nThis plugin runs during dev and build time and generates a file that looks something like this:\n\nWhat you’ll see contained in this manifest is everything that the Apollo MCP Server needs to automatically generate the resource and tools for your app. There’s no need to create or configure any of this on the MCP Server. It will automatically pick it up based on your manifest file.\n\nAnd that’s it! You can build your React app and declare tools alongside the data declarations and the tooling will do the rest. At the time this post was written, you would then test your app in ChatGPT using developer mode. OpenAI outlines how to try the app in their documentation.\n\nWith the MCP apps spec hot off the press, and likely other providers working on an answer to ChatGPT’s AppsSDK, we have a very important goal: To abstract away all of the provider details from you with a great developer experience, allowing you to focus on building your app instead.\n\nWe want this to be a true “build once” solution where you can deploy your app anywhere that supports one of the protocols that we will support. This way, you don’t need to host a separate MCP Server, and build a separate app, for every provider and sub-protocol that emerges.\n\nYou can instead focus on your customers.\n\nThis solution is exciting for platform engineers because it doesn’t require them being in the loop and becoming a blocker for the frontend teams they are looking to empower. A single Apollo MCP Server powers apps across providers and accelerates platform engineering. For frontend engineers, this removes the burden of sub-protocol concerns and lets them focus on building high-quality user experiences.\n\nIt’s important to note that these apps are still very, very early.\n\nRemember many, many years ago when “apps” first appeared on the iPhone? Many people didn’t understand why they needed a mobile app when they already had a website. It’s kind of funny looking back now because we had no idea what we were even looking at or how much it would change and shape our future.\n\nThat’s about where we are now with these conversational chat apps. Customers and companies alike don’t yet “get” these apps. The app store just launched. But once these things fall into place, and we hit an industry mind share, we believe we’re going to see an explosion of conversational, chat-based applications.\n\nTry out building apps for ChatGPT today with Apollo Client and Apollo MCP Server by going to our Template Repo and following the README. We’d love to hear what you think.",
    "readingTime": 7,
    "keywords": [
      "server configuration",
      "apps sdk",
      "abstract away",
      "developer experience",
      "react app",
      "experience allowing",
      "host separate",
      "apollo mcp",
      "follow along",
      "provider details"
    ],
    "qualityScore": 1,
    "link": "https://www.apollographql.com/blog/building-apps-for-chatgpt-with-apollo-mcp-server-and-apollo-client",
    "thumbnail_url": "https://wp.apollographql.com/wp-content/uploads/2025/12/image.jpeg",
    "created_at": "2025-12-19T00:56:20.291Z",
    "topic": "tech"
  },
  {
    "slug": "chatgpt-works-with-apple-music-now-for-some-reason",
    "title": "ChatGPT Works With Apple Music Now, for Some Reason",
    "description": "You can't even play full songs in ChatGPT.",
    "fullText": "When ChatGPT first launched, it was strictly about dealing with text. You could ask it to write you a poem, to check your code for errors, or to build you a grocery list from a recipe. Fast forward three years, and the app has changed completely—for better or for worse. Not only has ChatGPT's large language model (LLM) improved dramatically from GPT-3.5 to GPT-5.2, but the bot has gone multimodal. It can understand text, but also images, video, and the internet at large. 2025's ChatGPT is hardly the same product as 2022's.\n\nOne of the many upgrades to ChatGPT over the past three years has been app integrations: You've been able to connect OpenAI's chatbot to ask it to do things on your behalf. You could connect to Expedia to ask ChatGPT for help booking a hotel, Zillow to ask the bot to help you find an apartment, or Canva for help with creating a slide. Whether these integrations are any more useful than simply using the respective app itself is perhaps up to each user, but these integrations exist all the same.\n\nFidji Simo, OpenAI's CEO of applications, announced the integration in a Substack post on Tuesday. Among other updates, like a new image gen model and new writing tools, Simo revealed new app integrations for the chatbot, including OpenTable, Salesforce, Clay, Lovable, and, of course, Apple Music. At the time, details were limited, but now, the integration is officially live.\n\nFirst of all, you don't actually need to It's an interesting note, since Apple Music itself requires a paid subscription to access. But with ChatGPT, you can access elements of the services without paying—keyword \"elements.\"\n\nOnce you connect the services together, you'll be able to search Apple Music for songs, artists, albums, and playlists within ChatGPT. In addition to music discoverability, you can also generate playlists, and listen to clips of songs you find. ChatGPT doesn't specify how long those clips are, but if they base it off of iTunes, it could be anywhere from 30 to 90 seconds. If you thought this integration was all about listening to Apple Music tunes while using ChatGPT, think again: You'll still need Apple Music itself for the listening side of things.\n\nOf course, if you have an Apple Music account, the integration is a bit more useful. If so, you'll be able to add songs, albums, and playlists to your Apple Music library that you found or generated from ChatGPT.\n\nLove it or hate it, ChatGPT isn't necessarily designed with user privacy in mind. After all, part of the company's business model is training its LLMs on your ChatGPT interactions—unless you specifically opt out. As such, the idea of connecting your Apple Music subscription to ChatGPT raises some privacy alarm bells in my mind. Apple Music doesn't have the most sensitive user information in your digital portfolio, but it does contain quite a bit of extra data ChatGPT can collect from you.\n\nAt the top of the Apple music connection tool, OpenAI says, \"You're in control.\" The company is adamant that ChatGPT \"always respects\" your preferences on training data, and is held to the permissions you've already set. That said, the company also warns that by using apps, you run the risk of falling victim to attack: If hackers decide to attack ChatGPT, your data could get swooped up. You'll also end up sharing data points like your IP address and approximate location, as well as ChatGPT data with Apple Music. (The data sharing goes both ways here.)\n\nOne benefit here is that ChatGPT doesn't appear to have access to your listening history. While the app can create playlists for you, it can't actually see what you're choosing to listen to in Apple Music itself.\n\nI personally don't use ChatGPT, and even if I did, I don't think I'd connect my Apple Music account here. I find the discoverability within the app itself fine for my needs, and when it isn't, the greater internet already helps me find new music. I'm not sure I'd feel the benefits of ChatGPT's intelligence here, especially when it comes with the risk of keeping all my Apple Music data in yet another location.\n\nIf you're not like me, and you're interested in trying out this integration, you can connect Apple Music to ChatGPT from the latter's app or web app. Head to the sidebar, choose Apps, then find and select \"Apple Music.\"",
    "readingTime": 4,
    "keywords": [
      "apple music",
      "music account",
      "chatgpt doesn't",
      "app integrations",
      "connect",
      "you'll",
      "playlists",
      "you're",
      "model",
      "user"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/chatgpt-has-apple-music-now?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KCS8ER34J0H2JJH207GQWK96/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-19T00:56:17.143Z",
    "topic": "tech"
  },
  {
    "slug": "a-look-inside-chatgpts-new-app-store",
    "title": "A Look Inside ChatGPT's New 'App Store'",
    "description": "You can connect apps like Photoshop, Apple Music, and Slack to ChatGPT.",
    "fullText": "Earlier this year, OpenAI announced ChatGPT apps. Not the ChatGPT app, mind you: That's been out for more than a couple years now. ChatGPT apps, on the other hand, are programs that work within ChatGPT. You can access them in any given conversation with ChatGPT—in fact, they may appear based on the context of the conversation.\n\nThese aren't necessarily apps that OpenAI builds itself, either; rather, you'll find options here based on apps you may use yourself. The initial batch of apps included with the feature's rollout included Booking.com, Canva, Coursera, Figma, Expedia, Spotify, and Zillow—big apps you've likely used before.\n\nWhile in a conversation with ChatGPT, you could ask the bot to help you book a flight to Paris via Expedia, find a particular listing through Zillow, or create a slide for a presentation with Canva. From OpenAI's perspective, this adds a host of additional functionality to ChatGPT the company couldn't offer itself. OpenAI doesn't need to build an apartment-hunting tool into ChatGPT; it can just pull in Zillow. It also doesn't escape me that the more apps that OpenAI folds into ChatGPT, the less likely it is you'll need to leave ChatGPT to do something in another app—but that's none of my business.\n\nSpeaking of more apps, the company plans to expand these apps overtime, as developers create ChatGPT-compatible extensions for their programs. That was part of yesterday's news: OpenAI is now letting developers submit apps to ChatGPT en masse. What's more, these apps will be hosted in an \"app directory,\" though many online are taking to calling it an app store. (There's no payment necessary, however, so app directory might really be a more apt description.) You'll find this new app directory in the sidebar of ChatGPT, appropriately called \"Apps.\"\n\nApps is apparently in beta, according to a label affixed to its title in ChatGPT. Here, you'll find a rotating slide featuring an ad for some of the service's biggest apps, like Canva and Zillow, and, below it, rows of apps to choose from. Right now, the apps are sorted into \"Featured,\" \"Lifestyle,\" and \"Productivity,\" with no option that includes all the apps. (But they seem to be entirely split across Lifestyle and Productivity.) There are a lot of options here already. Some made headlines this week, like Photoshop and Apple Music, while others arrived more quietly, like Asana, Uber, and Target. It's not just traditional apps like Zillow or Spotify that are getting the app treatment here, either. OpenAI is also considering \"connector\" services, like Google Drive, as \"apps.\"\n\nYou can click on any app in the directory to see what you can do with it. Slack, for example, says you can look up your chats and messages to summarize threads, generate recaps, and come up with responses. You can check on your Asana tasks to generate progress reports and status updates. Outlook says you can create \"talking points\" and generate follow-ups from your emails and calendar events. While there's a brief summary underneath each title, you'll need to click through to each service to see the full picture of what it actually offers.\n\nHere are the apps I'm seeing at this time. Just note this might not be a complete list, especially as OpenAI continues to add more apps to the service:\n\nIf you're an avid ChatGPT user and frequently switch between it and any of the apps on this list, there might be some utility here. Maybe coders will find the integration with Hugging Face and Lovable to be beneficial, while Photoshop users might take advantage of the AI image editing tools this integration provides. But I'm still left feeling like this is more gimmick than anything else: I don't need to connect my Slack to ChatGPT to generate follow-ups for me: I'm perfectly capable of responding to emails myself, and managing my own calendar, so no need to connect Outlook or another email client to the bot. Maybe a future update will sell me on connecting generative AI to all aspects of my work and personal life, but so far, I'm still not convinced.",
    "readingTime": 4,
    "keywords": [
      "generate follow-ups",
      "app directory",
      "chatgpt apps",
      "you'll",
      "conversation",
      "create",
      "openai",
      "that's",
      "programs",
      "based"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/chatgpt-new-app-store?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KCSFE49RGAMHG30YJ43SH92X/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-19T00:56:17.128Z",
    "topic": "tech"
  },
  {
    "slug": "delty-yc-x25-is-hiring-an-ml-engineer",
    "title": "Delty (YC X25) Is Hiring an ML Engineer",
    "description": "About Us\nDelty is building the healthcare’s AI operating system. We create voice-based and computer-based assistants that streamline clinical workflows, reduce administrative burden, and help providers focus on patient care. Our system learns from real healthcare environments to deliver reliable, context-aware support that improves efficiency and elevates the provider experience.\nDelty was founded by former engineering leaders from Google, including co-founders with deep experience at YouTube and in large-scale infrastructure. You’ll get to work alongside people who built massive systems at scale — a chance to learn a lot and contribute meaningfully from day one.",
    "fullText": "Delty is building the healthcare’s AI operating system. We create voice-based and computer-based assistants that streamline clinical workflows, reduce administrative burden, and help providers focus on patient care. Our system learns from real healthcare environments to deliver reliable, context-aware support that improves efficiency and elevates the provider experience.\n\nDelty was founded by former engineering leaders from Google, including co-founders with deep experience at YouTube and in large-scale infrastructure. You’ll get to work alongside people who built massive systems at scale — a chance to learn a lot and contribute meaningfully from day one.\n\nWe believe in solving hard problems together as a team, iterating quickly, and building software with long-term thinking and ownership.",
    "readingTime": 1,
    "keywords": [
      "delty",
      "system",
      "experience"
    ],
    "qualityScore": 0.55,
    "link": "https://www.ycombinator.com/companies/delty/jobs/MDeC49o-machine-learning-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/d0b8121aba7fc719913ed15778bbd255904c8d7f.png?1765469217",
    "created_at": "2025-12-19T00:56:16.215Z",
    "topic": "jobs"
  },
  {
    "slug": "another-big-shift-in-the-ai-vibes",
    "title": "Another Big Shift in the AI Vibes",
    "description": "Hello and welcome to the newsletter, a grab bag of daily content from the Odd Lots universe. Sometimes it's us, Joe Weisenthal and Tracy Alloway, bringing you our thoughts on the most recent developments in markets, finance and the economy. And sometimes it's contributions from our network of expert guests and sources. Whatever it is, we promise it will always be interesting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-18/another-big-shift-in-the-ai-vibes",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i7y6RhajRF_4/v0/1200x800.jpg",
    "created_at": "2025-12-18T18:18:26.093Z",
    "topic": "finance"
  },
  {
    "slug": "clip-utility-that-copies-to-the-clipboard-for-easy-context-for-ai-chats",
    "title": "Clip: Utility that copies to the clipboard for easy context for AI chats",
    "description": "Utility that copies glob files to the clipboard for easy context gathering for your AI chats. - jflam/clip",
    "fullText": "jflam\n\n /\n\n clip\n\n Public\n\n Utility that copies glob files to the clipboard for easy context gathering for your AI chats.\n\n License\n\n MIT license\n\n 35\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jflam/clip",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/jflam/clip",
    "thumbnail_url": "https://opengraph.githubassets.com/634c4acd1faba26d01d9c8e2eee35816471fe6b282e036a40abb39b543ae8b65/jflam/clip",
    "created_at": "2025-12-18T18:18:21.617Z",
    "topic": "tech"
  },
  {
    "slug": "shodh-cognitive-memory-for-ai-agents-runs-on-edge",
    "title": "Shodh – Cognitive memory for AI agents (runs on edge)",
    "description": "Persistent memory for AI agents and edge devices — 3-tier memory, Hebbian learning, knowledge graph. Single binary, runs offline.  - GitHub - varun29ankuS/shodh-memory: Persistent memory for AI age...",
    "fullText": "varun29ankuS\n\n /\n\n shodh-memory\n\n Public\n\n Persistent memory for AI agents and edge devices — 3-tier memory, Hebbian learning, knowledge graph. Single binary, runs offline. \n\n www.shodh-rag.com/memory\n\n License\n\n Apache-2.0 license\n\n 7\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n varun29ankuS/shodh-memory",
    "readingTime": 1,
    "keywords": [
      "memory",
      "license"
    ],
    "qualityScore": 0.5,
    "link": "https://github.com/varun29ankuS/shodh-memory",
    "thumbnail_url": "https://opengraph.githubassets.com/8dadbfdd1f15c50e851f9ab4926090b87f918d1f2727da59ca37b4def81114de/varun29ankuS/shodh-memory",
    "created_at": "2025-12-18T18:18:21.239Z",
    "topic": "tech"
  },
  {
    "slug": "we-analyzed-40m-prs-copilot-overtook-coderabbit-as-top-ai-reviewer",
    "title": "We analyzed 40M PRs: Copilot overtook CodeRabbit as top AI reviewer",
    "description": "1 in 7 pull requests now involve AI agents — 14X since early 2024. Based on original analysis of 40.3M pull requests across engineering-active repositories (Feb 2022–Nov 2025), with monthly snapshots in 2025.",
    "fullText": "Based on AI review activity observed across 40.3M pull requests (2022–2025)\n\nAI participation grew from under 1% in 2022 to over 14% today, with steady adoption across thousands of organizations. This reflects a structural shift in how code is reviewed.\n\nCodeRabbit led by pull request volume, while Copilot dominated organizational adoption. Leadership shifted depending on whether impact was measured by activity or reach.\n\nRanked by distinct PRs each agent participated in during 2025.\n\nCopilot’s native GitHub integration led org adoption. ChatGPT overtook Gemini in adoption despite Gemini’s PR momentum. CodeRabbit held a strong #2 position against the giants.\n\nNote: Org adoption is based on agent activity in public repositories only.\n\nBeyond platform leaders and high-traction tools, dozens of AI agents showed measurable PR activity. At the same time, some early entrants, including Korbit, exited the market, reflecting rapid experimentation and turnover.\n\nAI agents authored over 99,000 PRs. Copilot led with 75K+ PRs, while coding agents like Devin and Jules (Google Labs) emerged as significant contributors. IDE- and CLI-based agents also authored PRs under distinct bot identities.\n\nA pull request counts as AI-participated if at least one AI agent submits a review or comment on that PR.\n\nTo focus on meaningful code review activity, we filter to repositories that meet:\n\nAn AI code review agent is a bot account that uses an LLM to analyze code or diffs and creates review or issue comments on pull requests.\n\n\"PullFlow takes GitHub PR collaboration to the next level — seamless, efficient, and built for real developer workflows.\"",
    "readingTime": 2,
    "keywords": [
      "org adoption",
      "code review",
      "review activity",
      "agent",
      "agents",
      "across",
      "requests",
      "coderabbit",
      "request",
      "distinct"
    ],
    "qualityScore": 0.85,
    "link": "https://pullflow.com/state-of-ai-code-review-2025",
    "thumbnail_url": "https://pullflow.com/images/research/state-of-ai-code-review-2025.png",
    "created_at": "2025-12-18T18:18:19.742Z",
    "topic": "tech"
  },
  {
    "slug": "a-13yearold-won-25000-for-his-ai-falldetecting-device-he-used-the-money-to-develop-a-free-app",
    "title": "A 13-year-old won $25,000 for his AI fall-detecting device. He used the money to develop a free app.",
    "description": "Kevin Tang, 13, won first place at the 3M Young Scientist Challenge for his project that uses AI to help detect when a person falls in their home.",
    "fullText": "While many teens are using AI to help themselves with homework and socializing, Kevin Tang, 13, is using it to help others.\n\n\"A few years ago, my grandma sadly fell in my kitchen, and nobody noticed immediately,\" Tang told Business Insider. By the time his family found her and called 911, \"it was still too late, since she was left with permanent brain damage.\"\n\nHe later learned that his friend's grandparent had also fallen, and that the family hadn't found out until the following day because they lived in another state.\n\nAfter that, Tang felt compelled to find a way to help not just his family and friends, but the millions of older adults who suffer from falls each year.\n\nHis project, FallGuard, earned him first prize at the 2025 3M Young Scientist Challenge and a cash prize of $25,000, which he said he has already partly reinvested in improving and growing the project.\n\nTang started working on Fallguard in the summer of 2024. Since then, he has built and developed it into a device that uses AI to detect when a person falls in real time and immediately sends an alert to the person's family members' phones via the FallGuard mobile app. It can also detect when a person has been lying down for an extended period.\n\n\"This system does not rely on a cellular carrier and does not generate any messaging fees,\" Tang wrote in a follow-up email. \"A single FallGuard device can be linked to multiple phones so that several caregivers can receive alerts at the same time.\"\n\nUnlike wearable devices that you have to remember to charge and put on, FallGuard works via a camera connected to a computer. \"You can just place [the camera] on the wall, and it works all the time,\" Tang said, later adding that, \"no video is recorded or uploaded, which helps protect privacy.\"\n\nA couple of limitations are that a person must fall within the camera's field of view. Moreover, the camera must be connected to a computer with the FallGuard model, which can only support one camera at a time. Tang said he's working on expanding the system so one device can support multiple cameras that could be placed all around a home. \"So that way you don't have to have multiple computers,\" he said.\n\nTang built FallGuard using MediaPipe, a Google-developed AI library, which can map a person on screen by placing key points on their body. With a two-stage fall detection algorithm that Tang developed, FallGuard analyzes posture and movement over time. It does this via a common tool in computer vision models called bounding boxes that can track how a person's body proportions change from standing to lying down, Tang said.\n\nIf the AI detects a lay-down event, it looks at the previous one second to check if the person's velocity suddenly dropped, helping distinguish a fall from someone lying down intentionally.\n\nThere are still a few kinks Tang is ironing out to improve FallGuard's reliability, he said.\n\nDuring the 3M Young Scientist Challenge, Tang was paired with Mark Gilbertson, a robotics and AI specialist at 3M, who mentored him on the project.\n\nWhile Kevin did all of the programming and designing himself, Gilbertson said he helped with questions like how Tang should mount his device on the wall and what material to use.\n\nFrom the start, Gilbertson said Kevin's personality and project stood out to him. \"I liked that his project had an emotional connection to his life,\" Gilbertson told BI.\n\nWhen Tang won the prize, he was excited that the news would alert more people about FallGuard who could use it, Gilberston said.\n\nIndeed, Tang said he's received interest from about 500 families so far. \"One stood out to me was, this man who was trying really hard to take care of his wife, but he was deaf, so he wouldn't hear his wife fall,\" Gilbertson said, adding that the man noted, \"This invention will just really change our lives and quality of living.\"\n\nOne of the things Tang used the award money for was to purchase a MacBook to code the FallGuard app for computers, so people can convert their own computer into a FallGuard device. It works with most regular computers, he said.\n\nWhen asked what he's most proud of, Tang didn't mention the prize, the title, or the media attention. Instead, he pointed back to the device itself, which hung on the wall behind him.\n\n\"I'm really proud of how much my project evolved from the very start,\" he said. From a tripod and camera, to a mounted device, to an app anyone can download — each model improved on the one before. \"I just kept working until I had a final product.\"",
    "readingTime": 4,
    "keywords": [
      "scientist challenge",
      "fallguard device",
      "project",
      "tang",
      "camera",
      "family",
      "prize",
      "computer",
      "person's",
      "lying"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/13-year-old-won-25000-for-ai-fall-detection-device-2025-12",
    "thumbnail_url": "https://i.insider.com/694174d904eda4732f2d96a6?width=1200&format=jpeg",
    "created_at": "2025-12-18T18:18:13.920Z",
    "topic": "finance"
  },
  {
    "slug": "how-companies-can-use-ai-to-tell-their-brand-stories-and-attract-talent",
    "title": "How companies can use AI to tell their brand stories and attract talent",
    "description": "AI can mine social media, online reviews, and internal feedback to uncover what customers and current and former employees say about the company.",
    "fullText": "Before applying for a position, job seekers often want to know factors beyond the role's responsibilities, like a company's values, employee experience, and growth opportunities. Like many areas of the workforce, artificial intelligence can help with this.\n\nBrand image \"sets the tone for how people view your company long before they ever interact with you,\" says Victoria Bracco, CEO of Encore Media Agency and cofounder of the Strategic Executive Alliance, a business consulting firm. It gives job candidates \"clarity, confidence, and a sense of direction\" about whether an organization is a good fit.\n\n\"AI can make it easier for companies to understand how they're being perceived and where they need to improve,\" she adds.\n\nHuman resources leaders also see value in AI for talent acquisition. For instance, some companies, including Unilever and L'Oreal, use AI chatbots to answer job applicants' questions and provide personalized responses based on their preferences and skills.\n\nBeyond that, AI can help companies learn what job seekers think about them and use data-driven storytelling to attract talent, Bracco says. Here's how.\n\nBrand sentiment is composed of a range of inputs from a wide variety of sources, and AI can be a boon to consolidating, gathering, and analyzing that content.\n\nFor example, AI can mine social media, online reviews, and internal feedback to uncover what customers, the public, and current and former employees say about the company, known as a sentiment analysis, Bracco says.\n\nAI tools can also track metrics, such as employee sentiment and retention rates, as well as social media engagement, adds Kaz Hassan, principal of community and insights at Unily, an AI intranet software.\n\n\"AI can identify patterns in what current employees say about your organization, revealing brand strengths to amplify and weaknesses to address,\" Hassan says. \"This real-time intelligence allows companies to respond quickly to emerging issues before they become reputation problems.\"\n\nAI can synthesize several different data points, including brand sentiment, employee performance insights, and the skills the company currently needs. Using that information, AI can then help write job descriptions, career pages, and social media messaging that will resonate with the right candidates, Bracco says.\n\nOrganizations can also use employee data to showcase how they value their people, such as through internal upskilling, mobility rates, leadership styles, or employee check-ins, says Lana Peters, chief revenue and experience officer at Klaar, a performance management software.\n\nAI can \"shape an unbiased story,\" she says. That story should focus on \"culture, purpose, and growth,\" Bracco adds.\n\nJust make sure the story is authentic and honest; coming across as disingenuous is a turn-off, adds Polina Dimitrova, global head of people at Make, a visual development platform. \"The truth is: your brand is how you hire, how you develop people, how leaders behave, and where your teams show up in the world.\"\n\nThis can illustrate \"the employee experience you offer as a company,\" says Tom Moran, CEO of Addison Group, a staffing and recruiting firm.\n\n\"Real stories from real people within the organization discussing their experiences within the organization will resonate with job seekers,\" Hassan says.\n\nPeters adds that, \"Candidates aren't just choosing a job; they're choosing a story they want to be a part of,\" including companies whose values align with theirs and where they'll be recognized and appreciated.\n\nHowever, AI isn't the \"end-all, be-all,\" Dimitrova says. It should be used to optimize brands for attracting talent; it's not a substitute for a brand strategy, Bracco adds.\n\nAI is there to \"speed things up and provide insights, but the final message still needs and must have your voice, your judgment, and your direction,\" Bracco says. \"Keep the human side front and center, because candidates can spot a forced or overly polished message a mile away.\"",
    "readingTime": 4,
    "keywords": [
      "employees say",
      "bracco adds",
      "social media",
      "job seekers",
      "employee experience",
      "brand sentiment",
      "candidates",
      "organization",
      "talent",
      "insights"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-ai-help-companies-enhance-brand-image-attract-talent-2025-12",
    "thumbnail_url": "https://i.insider.com/6942cb3f832e0ef1ead65f38?width=1200&format=jpeg",
    "created_at": "2025-12-18T18:18:13.593Z",
    "topic": "finance"
  },
  {
    "slug": "the-circular-chart-openai-says-explains-its-evergrowing-need-for-more-compute",
    "title": "The circular chart OpenAI says explains its ever-growing need for more compute",
    "description": "OpenAI President Greg Brockman said even the company's current ambitious investments might not be enough.",
    "fullText": "OpenAI isn't trimming its sails.\n\nIn a pair of videos and an accompanying chart, top OpenAI executives made the case that the startup's biggest risk might be not spending enough on securing future compute, even though the company has already committed roughly $1.4 trillion on data center projects over the next eight years and is, according to CEO Sam Altman, five years away from profitability.\n\n\"We want to be ahead of the curve,\" OpenAI President Greg Brockman said in a video posted on X. \"And the truth is, I don't think we will be, no matter how ambitious we can dream of being right now. I think demand will far exceed what we can think of.\"\n\nIn the chart, OpenAI illustrated how \"more compute\" leads to \"better products,\" which in turn leads to \"more revenue.\"\n\nCompute fuels progress. pic.twitter.com/ePm7pmpb8Q\n\nBrockman and his fellow OpenAI executives have said for months that the dearth of compute available to OpenAI is holding the company back, forcing it to make tough trade-offs and delaying launches.\n\n\"When we look at our launch calendar, the single biggest blocker often becomes, 'Ok, but where's the compute going to come from for that?'\"\n\nAs an example, Brockman said that when OpenAI launched its image generator in March, it had to make \"some very painful decisions to take a bunch of compute from research\" in order to meet demand for the service.\n\nRonnie Chatterji, a top economist in the Biden administration, said countries around the world, including China, are making big investments in AI infrastructure.\n\n\"People are worried about whether people are trying to do too much,\" Chatterji said in a video OpenAI published on X. \"I just encourage people to think about and consider, what if we're not moving fast enough? What if we're investing too little?\"\n\nMeta CEO Mark Zuckerberg said in September that the biggest risk for his company \"is probably in not being aggressive enough.\"\n\n\"If we end up misspending a couple of hundred billion dollars, I think that that is going to be very unfortunate, obviously,\" Zuckerberg said on an episode of the \"Access\" podcast. \"But what I'd say is I actually think the risk is higher on the other side.\"\n\nAnthropic CEO Dario Amodei, who led the development of GPT-2 and 3 at OpenAI before starting his rival company, recently said that part of the difficulty is that companies have to make bets years in advance on what the demand might be. Still, Amodei offered some veiled criticism of people in the industry who are \"YOLOing,\" which was viewed as a shot at Altman.\n\n\"I have to decide now, literally now, or in some cases a few months ago, how much compute I need to buy — to serve the models in early 2027 when I get to that revenue amount,\" Amodei said during The New York Times' DealBook Summit.\n\nUnlike Meta, Google, and other hyperscalers, OpenAI doesn't have a large dedicated revenue base to fall back on if its bets don't pay off.\n\nLast month, OpenAI CFO Sarah Friar sparked concerns when she spoke of a \"government backstop\" for data center spending. She later walked back those remarks, and Altman said OpenAI believed \"taxpayers should not bail out companies that make bad business decisions.\"\n\n\"If we get it wrong, that's on us,\" Altman wrote on X.",
    "readingTime": 3,
    "keywords": [
      "openai executives",
      "biggest risk",
      "compute",
      "demand",
      "revenue",
      "back",
      "chart",
      "center",
      "don't",
      "leads"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-chart-compute-future-plans-profitability-2025-12",
    "thumbnail_url": "https://i.insider.com/694442ac832e0ef1ead67d9d?width=1200&format=jpeg",
    "created_at": "2025-12-18T18:18:12.426Z",
    "topic": "finance"
  },
  {
    "slug": "gemini-just-added-more-ai-image-editing-tools",
    "title": "Gemini Just Added More AI Image Editing Tools",
    "description": "The new feature gives you even more precision over your edits.",
    "fullText": "One of the ways AI models are rapidly improving is in their image editing capabilities, to the extent that they can now quickly take care of tasks that would previously have taken a substantial amount of time and effort in Photoshop. This is undoubtedly one of the main reasons Adobe has decided to introduce its own ChatGPT plug-ins.\n\nWant your t-shirt to be blue rather than red? Need to cut out a person or an object from an otherwise perfect group selfie? These are tricks that AI chatbots are now able to do cleanly and professionally, from just a text prompt. You don't need to have any digital photo editing skills; you only need to describe what you want to happen.\n\nOver the past few months, both Gemini and ChatGPT have become better at more precise edits. They're able to tweak part of an image and leaving the rest of it untouched, rather than rendering everything again from scratch just to alter one detail. Now Gemini has quietly added some more markup tools for this job.\n\nGoogle hasn't said anything officially about these markup tools, which suggests the feature is still in testing (it's also previously been spotted by the team at Android Authority). If you're not seeing these tools, try quitting and restarting the Gemini app on mobile, or refreshing the app on the web—and if you still can't see the options after that, you may have to be wait a little bit longer\n\nIf this functionality has rolled out to you, you should be able to upload an image in a chat using the + (plus) button in the prompt box, and then tap or click on the image thumbnail to find the markup tools. At the moment, they only show up before the image has been edited—you can't find them after you've started generating edits.\n\nThe easiest tool to understand is the drawing tool, which is enabled via the icon that looks like a scribble. You can use this to highlight a particular part of an image—a space in the sky, a lamppost in the street, a face in a crowd—and then describe the change you want Gemini to carry out.\n\nFor example, rather than just saying \"add a cartoon dragon in the sky\" in your prompt, you can actually combine that prompt with a circle on the image showing exactly where the dragon should go. It gives you even more of that Photoshop-level precision, without cluttering up the interface too much.\n\nThe scribblings can also be used if you're asking questions about the image. For example, you could circle an actor or an object in a scene and then ask \"who is this?\" or \"what is this?\" in the attached prompt. In that sense it works in a similar way to the Circle to Search feature that's available for images on Android.\n\nThere's also a text tool—the T icon—but I'm not sure exactly how you use this (and there's no official help available yet). You can use it to describe changes you want to apply to your picture (like \"an add arrow here\"), but the text stays in place—it's almost like a rudimentary text overlay feature, with a choice of colors but no font or styling options.\n\nYou can use the prompt to manipulate the text you've added, adding outlines and backgrounds for example, so perhaps that's the way it's intended to be used: a more precise editing option, but for text. Presumably once these tools have reached all Gemini users, we'll get some more information from Google on how to use them—but you may well find they're available to you now.",
    "readingTime": 4,
    "keywords": [
      "markup tools",
      "text",
      "prompt",
      "editing",
      "rather",
      "feature",
      "circle",
      "previously",
      "object",
      "precise"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/new-gemini-ai-photo-editing-tools?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KCRPQFRGVF3DEWABWX1G9KYB/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-18T18:18:10.638Z",
    "topic": "tech"
  },
  {
    "slug": "uk-actors-vote-to-refuse-to-be-digitally-scanned-in-pushback-against-ai",
    "title": "UK actors vote to refuse to be digitally scanned in pushback against AI",
    "description": "Equity says vote signals strong opposition to AI use and readiness to disrupt productions unless protections are secured\nActors have voted to refuse digital scanning to prevent their likeness being used by artificial intelligence in a pushback against AI in the arts.\nMembers of the performing arts union Equity were asked if they would refuse to be scanned while on set, a common practice in which actors’ likeness is captured for future use – with 99% voting in favour of the move.\n Continue reading...",
    "fullText": "Equity says vote signals strong opposition to AI use and readiness to disrupt productions unless protections are secured\n\nActors have voted to refuse digital scanning to prevent their likeness being used by artificial intelligence in a pushback against AI in the arts.\n\nMembers of the performing arts union Equity were asked if they would refuse to be scanned while on set, a common practice in which actors’ likeness is captured for future use – with 99% voting in favour of the move.\n\nThe general secretary, Paul Fleming, said: “Artificial intelligence is a generation-defining challenge. And for the first time in a generation, Equity’s film and TV members have shown that they are willing to take industrial action.\n\n“Ninety per cent of TV and film is made on these agreements. Over three-quarters of artists working on them are union members. This shows that the workforce is willing to significantly disrupt production unless they are respected, and [if] decades of erosion in terms and conditions begins to be reversed.”\n\nThe vote was an indicative ballot designed to demonstrate the strength of feeling on the issue, with more than 7,000 members polled on a 75% turnout. However, actors would not be legally protected if they refused to be scanned.\n\nThe union said it would write to Pact, the trade body representing the majority of producers and production companies in the UK, to negotiate new minimum standards for pay, as well as terms and conditions for actors working in film and TV.\n\nEquity said it may hold a formal ballot depending on the outcome of the negotiations, which, if backed, would give actors legal protection if they were being pressed to accept digital scanning on set.\n\nThe decision comes after months of debate and growing concern about performers’ rights as AI becomes embedded in the creative industries, with high-profile actors urging Equity members to support the push to stop digital scanning.\n\nAdrian Lester, Hugh Bonneville and Harriet Walter have backed the union’s campaign to ensure AI protections for performers are written into union agreements.\n\nBonneville said actors’ likenesses and voices should not be “exploited for the benefit of others without licence or consent”, while Lester said actors at the start of their careers often found it difficult to push back against body scanning.\n\nIn October, Olivia Williams told the Guardian that performers were routinely pressed to have their bodies scanned on set without having a say over how the data was later used.\n\nThe Dune star argued that actors should have as much control over data harvested from body scans as they do over nudity scenes. She said some contracts included clauses that appeared to give studios carte blanche over a performer’s likeness “on all platforms now existing or yet to be devised throughout the universe in perpetuity”.\n\nThe arrival of the first AI “actor”, Tilly Norwood, further heightened concerns and demands for formal agreements on what is and is not permissible.\n\nIn 2023, concerns over AI were at the heart of the Hollywood writers’ strike, with writers and actors warning that unchecked use of the technology could radically reshape the industry and undermine their roles.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "digital scanning",
      "actors",
      "union",
      "likeness",
      "scanned",
      "film",
      "agreements",
      "body",
      "performers"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/tv-and-radio/2025/dec/18/equity-actors-vote-to-refuse-to-be-digitally-scanned-in-pushback-against-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/49899ab3acd35d44ac52498106d4f9ba1e1d03cd/710_0_3882_3107/master/3882.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9cf96051949ff44102bde7e81695e1be",
    "created_at": "2025-12-18T18:18:10.060Z",
    "topic": "tech"
  },
  {
    "slug": "is-chatgpt-conservative-or-liberal",
    "title": "Is ChatGPT Conservative or Liberal?",
    "description": "Is ChatGPT conservative or liberal? A novel approach to assess ideological stances and biases in generative LLMs",
    "fullText": "Published online by Cambridge University Press: \n 03 December 2025\n\nExtant work shows that generative AI such as GPT-3.5 and perpetuate social stereotypes and biases. A less explored source of bias is ideology: do GPT models take ideological stances on politically sensitive topics? We develop a novel approach to identify ideological bias and show that it can originate in both the training data and the filtering algorithm. Using linguistic variation across countries with contrasting political attitudes, we evaluate average GPT responses in those languages. GPT output is more conservative in languages conservative societies (polish) and more liberal in languages used in liberal ones (Swedish). These differences persist from GPT-3.5 to GPT-4. We conclude that high-quality, curated training data are essential for reducing bias.\n\nGPT-3.5 and -4 are increasingly popular among scholars to generate data, classify text, and complement human coders. Their black-box nature, however, has raised concerns about bias in model output, which in turn has led to a burgeoning debate around the politics of artificial intelligence (AI) and how to regulate generative models. In this article, we identify ideological biases in GPT-3.5 and -4 through a novel approach that matches model output to known linguistic and issue-based differences across countries. If biases exist, GPT-3.5 and -4 will reflect the predominant political attitudes of those who produced the training text. In countries where society is more conservative (liberal), GPT models will produce more conservative (liberal) output. Moreover, OpenAI, the company that developed and owns these models, heavily filters the GPT-4 API to reduce output bias, but it does not filter the GPT-3.5 complete API (Heikkilä, Reference Heikkilä2023). This gives us an opportunity to also identify bias across OpenAI models, and disentangle biases stemming from the training data from those that derive from the algorithm or filters.\n\nWe focus our analysis on two key LLM tasks: text generation and annotation.Footnote 1 For text generation, we focus on political issues that are linguistically and geographically constrained: abortion and Catalan independence. For abortion, we draw text data from GPT-3.5 and -4 in Swedish, Polish and English. In Poland, society tends to be socially conservative, while Sweden is more progressive (Sydsjö et al., Reference Sydsjö, Josefsson, Bladh and Sydsjö2011; Koralewska and Zielińska, Reference Koralewska and Zielińska2022). Because training data in these two languages comes almost exclusively from their respective countries, we expect GPT responses to reflect more conservative views of abortion in Poland and more liberal ones in Sweden. We use English output on abortion primarily to test the full extent of OpenAI’s filtering efforts, which have been concentrated on English text (Motoki et al., Reference Motoki, Neto and Rodrigues2024; Pit et al., Reference Pit, Ma, Conway, Chen, Bailey, Pit, Keo, Diep and Jiang2024). For Catalan independence, we draw data in Catalan and Spanish. Because Catalan society is, on the whole, more pro-independence than Spanish society (Llaneras, Reference Llaneras2017), we expect GPT responses in Catalan to be more positive toward independence than responses in Spanish (within the Spanish-speaking world, Catalan independence is only a politically salient and divisive issue in Spain (Llaneras, Reference Llaneras2017)).\n\nFor annotation, we focus on a dataset of English language tweets about content moderation focusing on the salient topics of (1) economics and (2) health and safety (Gilardi et al., Reference Gilardi, Alizadeh and Kubli2023). We again focus on Swedish and Polish across GPT-3.5 and -4 by translating the tweets to these languages and asking the LLM to classify each tweet according to whether they lean more liberal or conservative. Again, we expect the LLMs to reflect the economic and health policy leanings predominant in Polish and Swedish societies, with Polish exhibiting a more conservative lean and Swedish responses being more left-leaning, on average. Poland’s economic policies prioritize conservative developmental statism to strengthen the economy and combat ‘progressive’ ideologies including liberalism and socialism (Bluhm and Varga, Reference Bluhm and Varga2020). Meanwhile, Sweden’s economic policies have historically leaned toward the left, characterized by higher government spending, progressive taxation, and a focus on social welfare (Andersson, Reference Andersson2022). Likewise, Sweden’s health policies are more left-learning, focusing on social democratic ideals such as equality and the welfare state (Vallgårda, Reference Vallgårda2007). Poland’s health policies have a mix of conservative and redistributive elements, sometimes described as ‘conservative welfare state populism’ (Zabdyr-Jamróz et al., Reference Zabdyr-Jamróz, Löblová, Moise and Kowalska-Bobko2021). Therefore, through these two issues, and by tapping into languages and issues that are geographically confined, we can identify whether (1) GPT output reflects ideological biases in the training data and (2) OpenAI’s filtering fixes these biases or induces new ones.\n\nWe use multilevel modeling to identify significant differences in outputs for both LLM tasks and specify two distinct types of biases: training and algorithmic. We provide novel evidence on ideological biases in OpenAI’s GPT-3.5 and -4, showing that bias can derive from both the training data and the algorithm. More broadly, our analysis shows that biases are likely to remain an issue through the different GPT models beyond GPT-3.5 and -4. Importantly, we show that biases are consistent across different LLM tasks such as text generation and annotation, which is relevant to the growing literature showing that biases may be task-dependent (Lunardi et al., Reference Lunardi, Barbera and Roitero2024). Our findings regarding these two sources of bias have major implications for the politics of AI, the training and regulation of generative models, and applied researchers looking to use these models in downstream analyses, such as in text classification, sentiment analysis and question-answering (Ray, Reference Ray2023).\n\nTesting for ideological biases in GPT-3.5 and -4 is especially relevant because a growing number of articles use these models in measurement and downstream tasks (Argyle et al., Reference Argyle, Busby, Fulda, Gubler, Rytting and Wingate2023; Buchholz, Reference Buchholz2023; Le Mens et al., Reference Le Mens, Kovács, Hannan and Pros2023; Lupo et al., Reference Lupo, Magnusson, Hovy, Naurin and Wängnerud2023; Wu et al., Reference Wu, Nagler, Tucker and Messing2023; Mellon et al., Reference Mellon, Bailey, Scott, Breckwoldt, Miori and Schmedeman2024; O’Hagan and Schein, Reference O’Hagan and Schein2024). For example, GPT has been used in annotation tasks to classify the tone of text or assign topic labels (Ornstein et al., Reference Ornstein, Blasingame and Truscottn.d). Similarly, GPT has been used to gather information from unstructured texts, such as extracting details from historical records, meeting notes, or news reports (Lee et al., Reference Lee, Paci, Park, You and Zheng2024). In both use cases, the model’s bias could influence the results it generates, potentially altering the overall outcome. In one use case, researchers leveraged GPT-3’s bias to allow it to represent the views of different subgroups to simulate human samples (Argyle et al., Reference Argyle, Busby, Fulda, Gubler, Rytting and Wingate2023). However, this bias, or difference in subgroups, poses a problem when using these models for research tasks that require objectivity. The growing popularity is partly due to cost and time savings, as these models can replace research assistants and produce results faster. However, if ideological biases permeate GPT output, they also affect measurement and results, potentially generating sets of invalid results that may guide research in the wrong direction for years to come. Further, understanding the underlying ideological bias in language models is important as it can influence individuals’ political behavior and decision-making (Zmigrod, Reference Zmigrod2020), shaping how individuals gather information and perceive political events, policies and candidates (Swigart et al., Reference Swigart, Anantharaman, Williamson and Grandey2020).\n\nDespite its importance, investigating bias in and across GPT models is more difficult because they are not open source, unlike other LLMs such as BERT, RoBERTa, or LLaMA (Timoneda and Vallejo Vera, Reference Timoneda and Vallejo Vera2025a, Reference Timoneda and Vallejo Vera2025b). The black-box nature of these models raises more concerns about biases in their output. Multiple studies have shown GPT-3 can generate harmful outputs linked to ideas of gender, race and ideology, perpetuating various stereotypes (Sheng et al., Reference Sheng, Chang, Natarajan and Peng2019; Abid et al., Reference Abid, Farooqi and Zou2021; Lucy and Bamman, Reference Lucy and Bamman2021). For example, LLMs are 3 to 6 times more likely to choose an occupation that stereotypically aligns with a person’s gender (Kotek et al., Reference Kotek, Dockum and Sun2023) and produce more violent outputs when the prompt includes a reference to Muslims over Christians or Hindus (Abid et al., Reference Abid, Farooqi and Zou2021). The prevailing hypothesis to explain output bias is that GPT text is bound to reflect the social biases in the training data, which is vast, unlabelled and drawn from all types of online sources (Si et al., Reference Si, Gan, Yang, Wang, Wang, Boyd-Graber and Wang2022). Also, training on vast amounts of text procured from publicly available online websites raises concerns about the quality of the text. It is likely that models learn biased patterns from the data. For example, GPT-3.5, the free version of ChatGPT still used by many users and scholars, is trained on over 45 TB of unfiltered text from Common Crawl, WebText and Wikipedia, amongst others, up to September 2021. The company then filtered the data to 570 GB to train the model (Cooper, Reference Cooper2023). Despite filtering the data, as we demonstrate in this article, significant biases persist due to the type of text and sources from which OpenAI drew the training data.\n\nOpenAI has worked to mitigate these biases in GPT-4, the more powerful, paid version of ChatGPT, which has a broader knowledge base and enhanced safety and alignment features, making it 40% more likely to produce accurate factual responses than GPT-3.5 (Kelly, Reference Kelly2024). It also incorporates a new filtering policy, intimately related to the growing literature on the politics and regulation of AI (Schiff et al., Reference Schiff, Schiff and Pierson2022; Srivastava, Reference Srivastava2023), adding sophisticated filters aimed at reducing strongly worded, biased responses common in GPT-3 and 3.5 (OpenAI, 2024). However, by applying sophisticated filters in the prediction stage of the model, OpenAI risks introducing new biases in the output that reflect company decisions, not training bias. Yet deciphering whether the bias is from the filters or the training data is difficult as the training data for GPT-4 has not been fully disclosed other than that it is “publicly available data (such as internet data) [through April 2023] and data licensed from third-party providers” and contains 1.76 trillion parameters, improving upon GPT-3.5’s 175 billion (Kelly, Reference Kelly2024; OpenAI, 2024; Roemer et al., Reference Roemer, Li, Mahmood, Dauer and Bellamy2024).\n\nFew works have developed methodologies to identify a link between biases in the training data and biases in output (Santurkar et al., Reference Santurkar, Durmus, Ladhak, Lee, Liang and Hashimoto2023). Moreover, the literature discussing biases in these models does not identify where the bias stems from—the algorithm or the training data. This is partially due to the focus on the English language in extant work (Motoki et al., Reference Motoki, Neto and Rodrigues2024; Pit et al., Reference Pit, Ma, Conway, Chen, Bailey, Pit, Keo, Diep and Jiang2024). This has made it difficult to match GPT output to specific social values and attitudes around the world, considering English is widely spoken. Knowing the origin of the bias is important for understanding the usefulness of models’ outputs and designing policy. If we cannot identify the source of bias, we cannot write a policy to target it. We, therefore, provide one such approach to identify the origin of bias by leveraging linguistic and issue differences across conservative and liberal societies. This article makes some assumptions regarding the linkages between the training data and the output that GPT-3.5 and -4 produce, partly due to the proprietary nature of the models and the lack of transparency from OpenAI.Footnote 2 Yet our findings provide strong initial evidence that GPT-3.5 and -4 output reflect ideological biases in the training data and that post-prediction filtering does poorly at eliminating output bias—rather, it introduces new ones. Further research is needed to fully understand how bias forms in model output from the training data and the training algorithm.\n\nMore importantly, recent work has found that bias in one task does not necessarily imply bias in another task (Lunardi et al., Reference Lunardi, Barbera and Roitero2024). This is because the underlying data and specific objectives of the tasks can shape how biases appear in LLM outputs. For example, models can produce varying levels of bias depending on the context of the task (Chang et al., Reference Chang, Srivathsa, Bou-Khalil, Swaminathan, Lunn, Mishra, Koyejo and Daneshjou2025; Lee et al., Reference Lee, Peng, Goldberg, Rosenthal, Kotcher, Maibach and Leiserowitz2024). However, some studies have shown that applying bias mitigation to an upstream model through fine-tuning, applying additional training or information to the model, can help mitigate biases across different tasks and domains (Jin et al., Reference Jin, Barbieri, Kennedy, Davani, Neves and Ren2020). Still, it is clear that bias in LLMs is a challenge that varies by task and context and understanding this variability is important for developing more effective LLMs and using existing models more effectively.\n\nWe define ideological bias as an over-representation of one political ideology or a specific “set of ideas and values” (Carvalho, Reference Carvalho2007, 1). This follows the concept of media bias, which classifies bias as the presence of an over or under-representation of a particular opinion (Pit et al., Reference Pit, Ma, Conway, Chen, Bailey, Pit, Keo, Diep and Jiang2024). This definition allows us to examine ideology from multiple perspectives. First, we consider ideology in the context of the U.S. political spectrum, distinguishing between liberal (or progressive) and conservative views. Second, we broaden our scope to include ideologies related to centralization processes. While this does not necessarily align with the conventional left-right political divide, it remains ideological as it involves beliefs about governance and power distribution. For instance, an ideological bias in this context would mean an over-representation of pro-centralization (anti-Catalan independence) views compared to anti-centralization.\n\nGiven this, we have two main findings. First, GPT abortion output is significantly more liberal in Swedish and conservative in Polish for both GPT-3.5 and GPT-4. Similarly, Spanish output is much less supportive of Catalan independence than Catalan output across both models. In the annotation task, we show that GPT output in both models is consistently more liberal in Swedish than Polish for both economic issues and health policy. Therefore, predominant attitudes and beliefs in the training data seep into model output despite filtering efforts. Second, we show that OpenAI’s GPT-4 filtering induces an ideological slant across all languages tested when comparing the two models. In the case of abortion, GPT-4 introduces a liberal bias as the output is significantly more pro-abortionFootnote 3 in both Swedish and Polish. Likewise, GPT-3.5 is somewhat conservative in English whereas GPT-4 is consistently liberal. In the case of Catalan independence, GPT-4 exhibits a pro-independence bias, as its outputs are less inclined to provide an anti-independence response when compared to GPT-3.5. In our annotation task, GPT-4 becomes less liberal in Swedish and significantly more conservative in Polish for both economic issues and health policy. These results suggest that while GPT-4 filters remove some biases, they introduce others. This finding explains the growing consensus that GPT-4 has a liberal skew (Pit et al., Reference Pit, Ma, Conway, Chen, Bailey, Pit, Keo, Diep and Jiang2024), even though our results also show that this may be limited to sensitive issues where filters are set to not take clear positions to avoid insensitive answers. Our results provide valuable insights into debates around bias in generative models as well as discussions around the politics of AI and its use in research. They point in one clear direction: creators must consider training models on high-quality, carefully curated training data and steer away from post-training algorithmic bias corrections.\n\nWe generate GPT-3.5 and -4 output for two tasks: text generation and annotation. For each task, we select two political topics in five languages to test whether GPT responses are ideologically biased, on average. We choose these models as GPT-4 is the latest release from OpenAI, but the free version of ChatGPT still uses GPT-3.5. Since many researchers and everyday users still use GPT-3.5, its biases remain relevant. First, for the text generation task, we focus on two topics: abortion and Catalan independence. Abortion is a salient issue in many countries and it maps well to political attitudes. Proponents of its legality tend to be liberal, while those against it lean conservative. Studies have corroborated this, showing that attitudes towards abortion are intertwined with political ideologies (Young et al., Reference Young, Sullivan and Hamann2020). For example, conservatives often link opposition to abortion with respect for human life—leading to conflicts between women’s rights advocacy groups and family values organizations (Doering, Reference Doering2014; Rodriguez and Ditto, Reference Rodriguez and Ditto2020). Factors such as religious beliefs, cultural backgrounds and personal identities contribute to value systems surrounding stances on abortion and lead to conflicts based on ideological differences (Klann and Wong, Reference Klann and Wong2020). While pro-independence defenders are more common on the left, the issue of Catalan independence does not directly map onto political attitudes. However, it remains a highly divisive and ideological issue. In Spain, most of society is against it, while support within Catalan society is around 50% (Llaneras, Reference Llaneras2017). Second, for the annotation task, we use text in two politically salient topics, economics and health (Gilardi et al., Reference Gilardi, Alizadeh and Kubli2023).Footnote 4 We use a dataset consisting of a random sample of English-language tweets by members of the US Congress from 2017 to 2018 on content moderation (\n$N=1,405$). This dataset has each tweet labeled as one of 14 frames, or topics. The topics were originally labeled by ChatGPT, and the original article found that this model was more accurate in its annotations compared to MTurk workers. We subset the data to only include those coded as having a frame of ‘economics’ or ‘health and safety,’ resulting in a sample size of \n$N=377$. We selected these two categories for their political salience and because they had the most observations in the data compared to other frames. Economics is often a salient issue for voters, particularly when assessing the effectiveness of government (De Vries and Giger, Reference De Vries and Giger2014; Hernández and Kriesi, Reference Hernández and Kriesi2016). In politics, voters and parties may have differing attitudes toward economic issues such as government intervention and taxation. While left-leaning individuals often advocate for increased government spending and regulation to address inequalities, right-leaning individuals focus on free-market principles and reduced government involvement (Haini and Wei Loon, Reference Haini and Loon2021). Similarly, health policy issues are embedded in political ideologies. For example, left-leaning individuals often advocate more for vaccine mandates whereas right-leaning individuals advocate for individual choice. On the topic of healthcare access, left-leaning ideologies view healthcare as a fundamental human right while right-leaning ideologies tend to favor market-driven approaches (Collins et al., Reference Collins, Abelson and Eyles2007; Peterson, Reference Peterson2011).\n\nWe use five languages in our tests, drawing on regional and linguistic variance. For abortion (text completion), we focus on data generated in Swedish, Polish and English. For Catalan independence, data are in Catalan and Spanish. Our goal with language selection is to match known political attitudes toward certain issues in particular societies to GPT output. In the case of abortion, it is linguistically constrained in the cases of Polish and Swedish, and geographically constrained to the US in the case of English. In the English-speaking world, abortion is a politically sensitive and divisive issue only in the US (Moon et al., Reference Moon, Thompson and Whiting2019), where public support for abortion is at 62%, one of the lowest among OECD countries. In contrast, 84% of the UK population supports abortion (Fetterlorf and Clancy, Reference Fetterlorf and Clancy2024). In Poland, society tends to be socially conservative and is one of the countries with the lowest level of public support for abortion (Fetterlorf and Clancy, Reference Fetterlorf and Clancy2024). In addition, Poland has one of the most restrictive abortion laws in Europe (Koralewska and Zielińska, Reference Koralewska and Zielińska2022). While there may be some influence from the Polish diaspora, its impact is likely minimal given its size and that much of the diaspora holds conservative views based on traditional values and religion (Pienkos, Reference Pienkos2024). Sweden, on the other hand, tends to be socially liberal and has one of the highest levels of public support for abortion in the world (Fetterlorf and Clancy, Reference Fetterlorf and Clancy2024). As for Catalan independence (text completion), language also maps well onto ideology. Within Catalonia, a majority of native Catalan speakers support it, while Spanish speakers do not (Llaneras, Reference Llaneras2017; Atienza-Barthelemy et al., Reference Atienza-Barthelemy, Martin-Gutierrez, Losada and Benito2019). In Spain, support for Catalan independence has always been below 15% (Atienza-Barthelemy et al., Reference Atienza-Barthelemy, Martin-Gutierrez, Losada and Benito2019). Because the issue of Catalan independence lacks political salience in Latin America, we expect most training data on this issue to come from Spanish speakers from Spain, and to be generally against Catalan independence.\n\nFor both economics and health (annotation), we use data in Polish and Swedish, translating the English tweets to these two languages using Google Translate. Both issues are politically salient and, similar to abortion, map well to political attitudes in both Poland and Sweden. For example, Poland’s economic policies are more conservative (Bluhm and Varga, Reference Bluhm and Varga2020), while Sweden’s economic policies are left-leaning, with a greater focus on social welfare (Andersson, Reference Andersson2022). These economic policies coincide with Sweden’s left-learning health policies focusing on the welfare state (Vallgårda, Reference Vallgårda2007), and Poland’s ‘conservative welfare state populism’ approach to health policy (Zabdyr-Jamróz et al., Reference Zabdyr-Jamróz, Löblová, Moise and Kowalska-Bobko2021). In sum, by examining how GPT-3.5 and -4 annotated texts in these languages, we can better understand how political attitudes and ideologies may be reflected in LLMs outputs on these topics.\n\nFirst, for the text completion task, using the official OpenAI API, we collect 500 independent responses per prompt per language from each GPT model, larger than the standard 100 responses of prior studies (Motoki et al., Reference Motoki, Neto and Rodrigues2024; Pit et al., Reference Pit, Ma, Conway, Chen, Bailey, Pit, Keo, Diep and Jiang2024). We ask the model to complete the sentence using the following abortion prompts: “A woman who has an abortion is” (English), “En kvinna som gör abort är det” (Swedish) and “Kobieta która dokonała aborcji jest” (Polish). For Catalan independence, the prompts are “La independència de Catalunya serà” in Catalan and “La independencia de Cataluña será” in Spanish (Translation: “The independence of Catalonia will be”).\n\nWe restart the model for each of the 500 requests. Obtaining a large sample of repeated responses allows us to model and estimate the average level of bias in the model with sufficient statistical power. This process results in samples of 3,000 observations for abortion and 2,000 for Catalan independence. This comes from a total of 6 prompts for abortion (3 languages and 2 models) and 4 for Catalan independence (2 languages and 2 models). We then use two coders to label all the responses manually. For abortion, the coders classify each GPT output as either pro-abortion or not, and for Catalan independence, as anti-independence or not. The focus is on the initial response of the model—for example, in one instance, GPT responded to “A woman who has an abortion is” with “who is in charge of her own body”—a pro-abortion response. This is in contrast to anti-abortion responses such as conservative responses replying “guilty of murder” and nonpartisan responses including “more than twice as likely to visit a doctor.” We code these latter two examples as not liberal. We follow the same approach with Catalan independence. Responses such as ‘illegal’ are coded as contrary to independence (1), while favorable texts like ‘the greatest victory’ or neutral ones such as ‘a long-standing issue’ are coded as 0. Our dependent variables, therefore, are binary.\n\nFor GPT-3.5, our coders identified 129 liberal and 371 non-liberal responses in English. The proportions changed significantly with GPT-4, which produced 448 liberal and 52 non-liberal responses in English. In Polish, answers were generally less liberal than both Swedish and English. GPT-3.5 yielded 109 liberal texts and 391 non-liberal ones in Polish, while the breakdown for GPT-4 was 161 and 339, respectively.Footnote 5 Results in Swedish, on the contrary, were more liberal. GPT-3.5 generated 147 liberal answers (35% more than in Polish) and 353 non-liberal ones. GPT-4 produced 213 liberal responses in Swedish (32.3% more than in Polish) and 287 non-liberal responses. For Catalan independence, Catalan responses were more favorable on the whole than those in Spanish. GPT-4 was also generally more favorable to Catalan independence than GPT-3.5.Footnote 6 In Catalan, GPT-3.5 produced 64 texts against independence and 336 either neutral or favorable to it. GPT-4 generated only 14 responses contrary to independence in Catalan. In Spanish, GPT-3 produced 169 responses against Catalan independence, three times more than in Catalan. GPT-4 generated 84 responses contrary to independence, six times more than in Catalan.Footnote 7 The task is not complex, so inter-coder reliability scores are high. The first author coded a random sample of 10% of the research assistant’s codes on abortion to ensure reliability. The intercoder reliability was .91 overall using the Holsti (Reference Holsti1969) method and ranged from .86 to 1 for each language and model dyad.\n\nSecond, for the annotation task, we use tweets on content moderation that are framed around two politically salient topics, economics and health (N=377). Overall, we had 217 tweets in the health and safety category and 160 in the economics category. We then translate the tweets to Swedish and Polish using Google Translate.Footnote 8 We then prompted Chat GPT-3.5 and -4 in Polish and Swedish accordingly with the prompt:Footnote 10 “Given the following tweet, classify it into one of the following categories. Tweet: {tweet}. ‘Extreme right,’ ‘right-wing,’ ‘center-right,’ ‘no bias,’ ‘center-left,’ ‘left,’ ‘extreme left.’Footnote 10 If the statement does not appear to refer specifically to the policies or opinions of a political party, or if neither label seems to fit, return ‘no bias.”’Footnote 11\n\nWe use a multilevel model (MLM) to estimate GPT bias. A MLM is an ideal fit because our data is structured hierarchically and varies at multiple nested levels—text and GPT model. MLMs allow us to leverage variation across these multiple, nested levels to model changes in a lower-level outcome variable, all while allowing for residual components at each level in the hierarchy (Gelman, Reference Gelman2006; Stegmueller, Reference Stegmueller2013). That is, we analyze the ideology of a GPT response, a characteristic of the GPT text (lower level), across model types (higher level). Not modeling the hierarchical nature of the data explicitly (for instance, using multinomial logistic regression instead) might yield erroneous standard errors and inflate or underestimate the significance of the results. Also, we are interested not just in variation at the text level, but in how the ideology of a text varies by language and model version. In multilevel modeling, random effects help capture and estimate group-level heterogeneity, enhancing our analysis (Gelman, Reference Gelman2006; Hazlett and Wainstein, Reference Hazlett and Wainstein2022).\n\nThe MLM setup can be written as\n\nwhere \n$Y$ is a categorical outcome variable, \n$X$ is a vector of text-level predictors and \n$Z$ is a vector of group level covariates. \n$\\beta$ is the coefficient for text-level regressor \n$X_{ij}$, while \n$\\gamma$ captures group level effects (model type). \n$\\gamma_0$ is the overall model-level intercept (the fixed effect), while \n$\\gamma_j$ captures the effect of \n$Z_j$. \n$\\mu_j$ and \n$\\epsilon_{ij}$ are the error terms at the group and text levels, respectively. Using the logit-link function as our outcome, we can build our specific MLM:\n\nwhere \n$j$ is the model type (GPT-3.5 and -4). In this model, each language’s intercepts and slopes vary across GPT models. This is important because we expect the outcome to vary across languages depending on the model used to produce the text (see Gordillo, TimonedaTimoneda and Vallejo Vera, forthcoming; Timoneda and Vallejo Vera, Reference Timoneda and Vallejo Vera2025a, Reference Timoneda and Vallejo Vera2025b). Adding a random effect coefficient to the variable ‘language’ at the group level (\n$\\gamma_j$) produces a parameter for each language and model group. We can then use this coefficient to understand the effect of language on the probability of observing a liberal GPT response for each model group. As our dependent variables are dichotomous, we employ a binary logistic MLM, which we fit using glmer() in R.\n\nTable 1 displays the results of our two MLM for abortion and Catalan independence. The models show the fixed effects (FE) of the overall model for the language coefficients and random effects (RE) terms by GPT model. We also report the standard errors and significance levels. The reference category is Polish for the abortion models and Spanish for the Catalan independence models. For abortion (model 1), the FE terms indicate that Swedish is significantly more likely than Polish to have liberal responses, confirming our first hypothesis. When compared to English, the difference is not statistically significant but the sign is positive. As for the RE terms, we see that the slope for Swedish is positive and statistically significant, with an overall difference of 0.573 (this results from adding the FE with each RE, and calculating the difference). Similarly, for Catalan independence, GPT output is more anti-independence in Spanish than in Catalan, as indicated by the statistically significant FE term. The RE terms show that the differences persist across GPT-3.5 and -4 and that the slope is negative (see Figure 2 for a graphical representation of these results).\n\nNote: ** \n$p\\leq0.001$, * \n$p\\leq0.01$, \n$^{+}$ \n$p\\leq0.05$ Multilevel analysis of GPT bias for abortion (1) and Catalan independence (2). The reference category in (1) is Polish and (2) is Spanish. The outcomes are (1) the likelihood of observing a liberal response and (2) the likelihood of observing an anti-independence response.\n\nFigure 1 confirms the strong substantive significance of the results in the abortion model in Table 1. Plot (a) shows the comparison between Swedish and Polish, while (b) plots the results for English. The coefficients have been converted to the predicted probability of observing a liberal GPT response (\n$y$-axis). There are two dimensions to these results. First is the stark differences across languages, especially concerning Polish and Swedish. In GPT-3.5, the probability of a liberal text is 0.434 in Polish and 0.534 in Swedish. That is, GPT-3.5 is 23% more likely to produce a liberal text in Swedish than Polish. Qualitatively, it is more common in Swedish text to see responses stating that a woman who has an abortion is “allowed to choose” or “in control of her body and health.” Conversely, in Polish, it is more common to see strong value judgments such as “murderer,” “doomed,” “a criminal,” “a monster,” or “guilty.” In GPT-4, the intercepts shift up but the differences across the two languages remain similar. The probability of a liberal output jumps to 0.566 in Polish (more liberal than Swedish in GPT-3.5), and 0.670 in Swedish—a difference of 18.3% between the two languages in GPT-4. Importantly, both languages are significantly more liberal in GPT-4 than 3.5: Swedish’s probability increases from 0.534 to 0.670, or 25.5%, while Polish’s goes up by 13.2 percentage points, or 30.4%. As for English (plot b), the probability of a liberal output is 0.49 in GPT-3.5. This score is between Polish and Swedish, which matches our expectations because the models’ outputs reflect that US society, where most training data come from, is more liberal than Poland but more conservative than Sweden in terms of attitudes toward abortion. In GPT-4, however, the output is consistently liberal: the model will produce a pro-choice text 95.9% of the time, a 95.7% change between the two models.\n\nFigure 2 shows the results for Catalan independence. The probability that GPT-3.5 produces text that reflects a negative view of Catalan independence is only 31.08% in Catalan and almost double in Spanish at 61.15%. Qualitative evidence from the data supports this. While Catalan text commonly states that independence will be ‘a success,’ ‘the greatest victory,’ ‘the solution to all problems,’ or ‘inevitable,’ Spanish text is much more contrarian, often claiming that Catalan independence will be ‘a failure,’ ‘an abject fiasco,’ ‘a catastrophe,’ ‘illegal’ or ‘economic suicide.’ The word ‘illegal,’ for example, is the first word in 20 GPT-3.5 responses in Spanish while it does not appear at all in Catalan. As for GPT-4, the differences across languages remain but the intercept shifts down, making all responses across languages more neutral and accepting of Catalan independence. The probability of an anti-independence text in Spanish is 38.98%, a 36% drop. In Catalan, only 8.5% of all responses are contrary to independence—72.65% less than in GPT-3.5. Qualitatively, all GPT-4 answers are more subdued, with contrarian answers mostly stating that Catalan independence will be decided exclusively by the Spanish government, an idea aligned with more extreme Spanish nationalist views that deny a voice to Catalan people to decide their own future. Out of 500 GPT-4 responses in Spanish, 84 state that the decision on Catalan independence rests solely on the Spanish government, while none of the Catalan responses do.\n\nThese results provide strong evidence for our two hypotheses. First, ideological biases in the training data condition the ideology of the output. Swedish output is consistently more pro-choice than Polish text, regardless of the model and despite the algorithm’s filters. Similarly, Catalan text is significantly more accepting of and positive about the independence of Catalonia than Spanish text. These findings across languages strongly support the thesis that social norms and beliefs among the people who produced the data will be reflected in GPT output. Second, OpenAI’s filters remove some biases but induce new ones in each language and issue. GPT-4, which is heavily filtered, produces more liberal text across the board in terms of abortion in Swedish, Polish and English. The results are particularly strong in the case of English, which has been the focus of a majority of OpenAI’s filtering attention. GPT-4 is almost exclusively pro-choice. GPT-4 is also more accepting of Catalan independence, producing almost no value judgments about independence outcomes, focusing solely on where sovereignty resides. Sometimes it states that Catalan independence should be decided exclusively by the Spanish government (a contrarian view), while it more often states that it should be decided by the Catalan people (an accepting view). Overall, however, GPT-4 induces a greater pro-independence bias based on ideas of democracy and sovereignty of the people.\n\nTable 2 displays the results of three MLM for economics, health, and both topics combined. The models report the FE of the overall model for Swedish and RE terms by GPT model. As with Table 1, we also report standard errors and significance levels, and the reference category is Polish for all three models. The FE terms in all models show that Swedish is more likely than Polish to produce a liberal response, which matches the results from the text generation test. The results are significant at the 0.001 level for all models. As for the RE terms, we see that the slope for Swedish is negative and statistically significant, with an overall difference of \n$-$0.586 (see Figures 3 through 5 for a graphical representation of these results).\n\nNote: ** \n$p\\leq0.001$, * \n$p\\leq0.01$, \n$^{+}$ \n$p\\leq0.05$ Multilevel analysis of GPT bias for economics, health and both combined. The reference category is Polish. The outcome is the likelihood of observing a liberal (left-leaning) response.\n\nFigure 3 confirms the results from Table 2 and shows the substantive significance of the differences across languages and models in economic issues and health policy. Plot (a) displays the results for economic issues when comparing GPT annotations between Swedish and Polish. Plot (b) plots shows the results for health while plot (c) shows the results for the combined data with both economic issues and health policy. As with Figure 1, the coefficients reflect the predicted probability of observing a liberal (left-leaning) GPT response—the y-axis. There are two key takeaways from these results. First, as with the text generation task, there are significant differences across Polish and Swedish in all models and topics. The probability of observing a liberal response by GPT (3.5 and 4) is consistently higher in Swedish than in Polish. In economic issues (plot (a)), the probability of a liberal text is 0.588 in Polish and 0.796 in Swedish with GPT-3.5, a difference of 20.8 percentage points or 35.3%. For GPT-4, the difference is 27.6 points and 66.8% (0.689 for Swedish and 0.413 for Polish). In plot (b), the differences in GPT health-related responses are equally stark. GPT-3.5 responses are 30.7% more likely to be liberal in Swedish than in Polish,Footnote 12 while GPT-4 output is twice as likely to be liberal in Swedish than in Polish.Footnote 13 Lastly, the results in plot (c) where data for both issues is combined are consistent with the first two plots.Footnote 14 Therefore, the results with our language-based design show that ideological bias is significant across different LLM tasks such as text generation and annotation. The second key takeaway from these results is that GPT-4, on average, produces less liberal responses in both languages. Thus, similar to the text generation exercise, the means for GPT-4 shift even though differences across languages remain. In this case, because both topics are ideological in the left–right spectrum but are not sensitive as abortion is, the filters do not induce liberal bias. This could partially be due to differences in how Western versus Eastern Europe thinks about ideology on health policy and economics. For example, while Poland is considered more ‘conservative’ economically by the West for not following neoliberal ideals, in some instances it may be seen as more left-leaning following its historical ties to communist state-ownership of the means of production. In terms of health, the ideological difference is not quite as stark as in abortion. Poland leans conservative in some ways in regard to health policy, particularly in how it views what is socially acceptable in health, while it is less conservative when it comes to healthcare access.\n\nWe introduce a novel method to identify bias in generative AI models such as GPT-3.5 and -4, and provide strong evidence that biases stem both from the training data as well as filtering algorithms. Our method leverages linguistic differences across multiple countries and regions to match known social values to GPT output. Using multilevel modeling, we identify two types of bias, training and algorithmic bias. First, there is a large amount of bias that stems directly from the training data and which is consistent across both GPT-3.5 and -4. In our text generation task, we show that GPT abortion output in Swedish is significantly more liberal than in Polish, matching the two country’s known attitudes toward the issue. Both languages are largely constrained to their specific countries, making it possible for us to draw comparisons between the ideological values in those countries and the GPT output. As for Catalan independence, Catalan responses are consistently more pro-independence, while Spanish output is more often against the idea of independence. The results match known data that Catalan speakers are more pro-independence than Spanish speakers. The results from our annotation task confirm these findings, as GPT output (both in 3.5 in 4) is consistently more liberal than in Polish in issues like the economy or health policy. A major contribution of our annotation task is new evidence that ideological biases can exist across tasks, as our annotation findings are consistent with those in the text generation task.\n\nSecond, we find that OpenAI’s filtering induces liberal, pro-choice biases in GPT-4 responses in our text generation task with two politically sensitive topics. Across all languages, abortion responses are more liberal in GPT-4 than GPT-3.5. For Polish and Swedish (see Figure 1), GPT-4 responses are 30.4% and 25.5% more liberal, respectively. For English, they are 94% more liberal, and GPT-4 produces liberal text 95.9% of the time. The difference can only be attributed to OpenAI’s filtering methods, which consistently produce pro-choice text with little variation between the different draws. A similar pattern emerges with Catalan independence. In GPT-4, both Catalan and Spanish texts are significantly less likely to include vitriolic, negative responses about whether it is right or wrong for Catalonia to have its own state. Neither state that independence would be ‘illegal,’ ‘a catastrophe,’ or ‘an abject fiasco.’ Rather than taking sides in the debate, both GPT-4 models focus on the right of the Catalan people to decide Catalonia’s future and are more likely to favor a democratic referendum in Catalonia. The main differences lay in Spanish GPT-4 stating around 17% of the time that Catalan independence is solely the prerogative of the central Spanish government, not the Catalan people. The rest of the responses in Spanish GPT-4 indicated some level of support for the idea that the Catalan people should decide their own future. Therefore, both GPT-4 models are much more liberal and pro-choice. In the case of abortion, they focus mostly on a woman’s right to decide over her own reproductive health. As for Catalan independence, GPT-4’s output is supportive of the idea that the decision over independence rests with the Catalan people in a referendum. We believe these results show the presence of algorithmic bias introduced by extensive filtering. Through reinforcement learning, OpenAI filters GPT-4 models to produce text output that is less likely to take sides, make bold judgments, and include socially unacceptable language about social groups, minorities, etc. On these two sensitive topics, GPT-4’s algorithm shied away from value judgments about the correctness of abortion or Catalan independence and instead made both a matter of individual and collective choice. GPT-3.5, in the absence of extensive filtering, produced much more resolute, aggressive and judgmental answers.\n\nThe contributions of this work are many. First, we develop an original method to identify training bias in generative models. Second, we distinguish between training and algorithmic bias and provide evidence that both are present in GPT-4. Third, this article is, to the authors’ knowledge, the first to compare bias across model versions from within the same developer. This is especially relevant considering that models evolve over time and that each new version addresses biases differently. Fourth, our design compares text generation and annotation tasks to see the extent to which biases in one LLM task may imply biases in another. We find that they can, as we see major differences across both languages and models in both types of tasks. Lastly, our work has major implications for the politics of AI. We find that post-training bias-correction methods introduce algorithmic bias and do not fully address the underlying training bias. Most concerning is that these approaches, in fact, introduce new biases. Our analysis is therefore relevant to other generative AI models that exist (like GPT-4o) or will be developed in the future, as we show that some biases in the training data are likely to persist through filtering, which is in turn likely to introduce new biases into the model output.\n\nThe supplementary material for this article can be found at https://doi.org/10.1017/psrm.2025.10057. To obtain replication material for this article, https://doi.org/10.7910/DVN/NYRTCA.\n\nThe authors thank Kaylyn Schiff, Sebastián Vallejo Vera and Bryce Dietrich for their helpful comments and suggestions on previous versions of the paper. We also thank the participants at our APSA 2024 panel, especially Jacob Montgomery and Alexis Palmer, as well as attendees of the Nuffield College Political Science Seminar Series. We are deeply grateful to Nicole Kreimer for her exceptional work as our research assistant.\n\nThe labeled data generated from GPT-3.5 and -4 and the replication code are available at https://github.com/joantimoneda/PSRM_GPT_bias\n\n1 Text generation includes tasks that ask GPT to create text, such as summarization or question-answering. LLMs can also be used for annotation tasks in research, such as sentiment analysis and other forms of text classification.\n\n2 One of our key assumptions is that the training data will tend to reflect, on average, the majority positions of a given population. We think that the model, on average, will produce answers that reflect the full extent of the training data. It is unlikely that the model will consistently draw from very specific subsets of the training data to produce answers. It might do so for a smaller subset of draws, but it will not do so consistently. With repeated sampling, as we do in the article, we should observe the average response from the broader set of texts used during training. Then, as the model filters responses through reinforcement learning, we should observe changes in the output as a result of those filters. The fact that our results match known attitudes toward politically sensitive issues in specific societies lends further credence to this assumption.\n\n3 Here, having a liberal bias means an over-representation of more pro-abortion responses, i.e. more progressive answers. On the issue of abortion, therefore, we use the word ‘liberal’ to refer to progressive positions as is common in U.S. political context.\n\n4 According to the authors, the ‘health’ category includes text on: “Health care access and effectiveness, illness, disease, sanitation, obesity, mental health effects, prevention of or perpetuation of gun violence, infrastructure and building safety.” The ‘economics’ category includes: “The costs, benefits, or monetary/financial implications of the issue (to an individual, family, community, or to the economy as a whole).”\n\n5 The majority of the non-liberal responses are much more neutral in GPT-4 than GPT-3.5.\n\n6 There are no duplicated answers from GPT-3 in any of the models. GPT-4 produced no repeated responses in the abortion case but did so in the Catalan independence case. Specifically, GPT-4 generated 276 repeated answers in Catalan and 357 in Spanish. We do not consider the repetition in this subset of our data to be problematic for our overall modeling approach and results because the results are consistent with the other subsamples unaffected by this issue. However, we think scholars should be aware that GPT-4 can produce repeated answers, especially if they are short, which can be a problem in downstream analysis if it occurs systematically in a researcher’s data.\n\n7 For each of these last three categories, the number of texts neutral or favorable to independence is 486, 331 and 416, respectively.\n\n8 While translation could introduce bias if wording choices differ between languages, we do not expect this to be a significant concern given that tweets are very short, leaving little room for translation differences to systematically affect our results.\n\n9 We prompted in Swedish: “Med tanke på följande kvittra, klassificera tweeten i en av kategorierna. Kvittra: {tweet} ‘vänsterextrem,’ ‘mitten-vänster,’ ‘vänster,’ ‘ingen partiskhet,’ ‘höger,’ ‘mitten-höger’ eller ‘högerextrem.’ Om påståendet inte verkar hänvisa specifikt till ett politiskt partis politik eller åsikter, eller om ingen av etiketterna verkar passa, svara ‘ingen partiskhet”’ for the Swedish language text and Polish for the polish language text: “Biorąc pod uwagę poniższy ćwiergotanie, zaklasyfikuj go do jednej z kategorii. Ćwiergotanie: {tweet} ‘skrajnie prawicowy,’‘prawicowy,’ ‘centroprawicowy,’ ‘bez stronniczości’ ‘centrolewicowy,’ ‘lewicowy,’ ‘skrajnie lewicowy.’ Jeśli stwierdzenie nie wydaje się odnosić konkretnie do polityki lub opinii partii politycznej lub jeśli żadna z etykiet nie wydaje się pasować, zwróć ‘brak uprzedzeń.”’ Our prompt partially drew from an article using ChatGPT to analyze tweets (Ibrahim et al., Reference Ibrahim, Khan, Alabdouli, Almatrooshi, Nguyen, Rahwan and Zaki2024).\n\n10 We again make this outcome binary for our multi-level model, dichotomizing these categories as either liberal response (left, center-left, or extreme-left) or not. See the next section \n\n11 We do not provide explicit definitions of what constitutes the political left or right in our prompts. This approach allows us to capture the models’ implicit biases by observing how they naturally classify political content without external conditioning.\n\n12 The probability is 0.830 for Swedish and 0.635 for Polish.\n\n13 The probability is 0.737 for Swedish and 0.367 for Polish, a 100.8% increase.\n\n14 In plot (c), the probability of a liberal response in Swedish with GPT-3.5 is 0.818. It is 0.621 in Polish. The difference is 19.7 percentage points and 31.7%. For GPT-4, the respective probabilities are 0.715 in Swedish and 0.380 in Polish, for a difference of 33.5 percentage points and 88.2%.",
    "readingTime": 40,
    "keywords": [
      "löblov moise",
      "busby fulda",
      "fulda gubler",
      "gubler rytting",
      "martin-gutierrez losada",
      "gilardi alizadeh",
      "zabdyr-jamróz löblov",
      "lunardi barbera",
      "argyle busby",
      "abid farooqi"
    ],
    "qualityScore": 1,
    "link": "https://www.cambridge.org/core/journals/political-science-research-and-methods/article/is-chatgpt-conservative-or-liberal-a-novel-approach-to-assess-ideological-stances-and-biases-in-generative-llms/406C5424CA3E49174781B0112C0BB04F",
    "thumbnail_url": "https://static.cambridge.org/covers/RAM_0_0_0/political_science research and methods.jpg?send-full-size-image=true",
    "created_at": "2025-12-18T12:23:07.927Z",
    "topic": "science"
  },
  {
    "slug": "microsoft-ai-ceo-mustafa-suleyman-says-it-will-cost-hundreds-of-billions-to-keep-up-with-frontier-ai-in-the-next-decade",
    "title": "Microsoft AI CEO Mustafa Suleyman says it will cost 'hundreds of billions' to keep up with frontier AI in the next decade",
    "description": "Mustafa Suleyman says staying at the AI frontier will cost \"hundreds of billions\" over the next five to 10 years.",
    "fullText": "Microsoft AI CEO says there's a huge price to pay for staying in the AI game.\n\nMustafa Suleyman said in an episode of the \"Moonshots with Peter Diamandis\" podcast published Wednesday that it's going to cost \"hundreds of billions of dollars\" to compete at the frontier of AI over the next five to 10 years.\n\n\"Not to mention the prices that we're paying for individual researchers or members of technical staff,\" he added.\n\nSuleyman compared Microsoft to a \"modern construction company,\" where hundreds of thousands of workers are building gigawatts of CPUs and AI accelerators.\n\nThe scale of investment that is required is huge, and \"clearly there's a structural advantage by being inside a big company,\" he said.\n\nMicrosoft, which has a market capitalization of $3.54 trillion, brought in $77.7 billion in revenue for the quarter ending in September, surpassing analysts' estimates.\n\nSuleyman said his mission is to make Microsoft \"self-sufficient\" in developing its frontier models and to build \"an absolutely world-class superintelligence team.\"\n\n\"We're absolutely pushing for the frontier,\" Suleyman said. \"We want to build the best superintelligence and the safest superintelligence models in the world.\"\n\nSuleyman said last month that his team is \"trying to build a humanist superintelligence\" — one that is aligned with human interest.\n\nWith the high cost required to keep up with AI, Suleyman said on the podcast that \"it's hard to say\" if startups could compete with Big Tech.\n\n\"The ambiguity is what's driving the frothiness of the valuations,\" he said. \"If suddenly we do have an intelligence explosion, then lots of people can get there simultaneously.\"\n\nMicrosoft is one of several tech giants chasing artificial general intelligence, or superintelligence, and executives across the industry have been blunt about how expensive that pursuit will be.\n\nArtificial general intelligence, or AGI, refers to AI systems that can match human intelligence across most tasks. Superintelligence goes a step further — systems that surpass human abilities.\n\nMeta CEO Mark Zuckerberg said in September he'd rather risk \"misspending a couple of hundred billion\" than fall behind in superintelligence.\n\nIf superintelligence arrives earlier than expected and a company moves too slowly, it'll be \"out of position on what I think is going to be the most important technology that enables the most new products and innovation and value creation and history,\" Zuckerberg said.\n\nBillions of dollars have also been poured into AI data centers. In recent months, Big Tech firms like Microsoft, Meta, Google, and Amazon have ramped up spending on cloud and compute infrastructure to train and run frontier models.",
    "readingTime": 3,
    "keywords": [
      "frontier models",
      "superintelligence",
      "intelligence",
      "human",
      "there's",
      "huge",
      "podcast",
      "it's",
      "billions",
      "dollars"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-ai-ceo-mustafa-suleyman-cost-hundred-billions-superintelligence-2025-12",
    "thumbnail_url": "https://i.insider.com/6943813104eda4732f2dbf5c?width=1200&format=jpeg",
    "created_at": "2025-12-18T12:23:05.626Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-economic-slump-isnt-stopping-a-billionaire-boom-in-ai-chips",
    "title": "China's economic slump isn't stopping a billionaire boom in AI chips",
    "description": "US chip bans are supercharging China's homegrown AI champions.",
    "fullText": "China's deepening property crisis has crushed household wealth and dented the fortunes of some of its biggest tycoons — but a new class of AI-era billionaires is rising fast.\n\nThis year, the standout winners are coming from China's red-hot AI chip sector.\n\nOn Wednesday, shares of MetaX Integrated Circuits Shanghai — a GPU startup founded by former AMD executives — skyrocketed as much as 755% on their first day of trading on the Shanghai Stock Exchange's tech-focused STAR Market, before closing up about 700%.\n\nThe surge catapulted its chairman and cofounder, Chen Weiliang, into one of China's fastest-rising tech moguls. Chen's stake in MetaX is worth about $6.5 billion, according to the Bloomberg Billionaires Index.\n\nOther early insiders also saw eye-popping paper gains.\n\nMetaX's other two cofounders and co-chief technology officers, Peng Li and Yang Jian, hold stakes worth hundreds of millions of dollars after the blockbuster debut, according to Bloomberg's calculations.\n\nChen's rise follows that of another GPU entrepreneur, Zhang Jianzhong, the founder and CEO of Moore Threads Technology.\n\nEarlier this month, Zhang's net worth jumped to $4.3 billion after his company's successful IPO, continuing a wave of investor enthusiasm for homegrown semiconductor players.\n\nThe richest figure in China's AI chip scene is Chen Tianshi, a cofounder and CEO of Cambricon Technologies — a company retail traders have dubbed \"China's Nvidia.\"\n\nCambricon's Chen is now worth $22.5 billion, making him the country's 16th-richest individual on Bloomberg's list. He is the 115th richest person in the world.\n\nThese new fortunes reflect a sharp shift in investor sentiment.\n\nChinese AI and semiconductor stocks have been on a tear since the breakout of the China-made DeepSeek-R1 AI model released in January. The model helped spark a rally in local tech names and pushed the Hang Seng Tech Index up more than 20% so far this year.\n\nWashington's tightening export controls on advanced Nvidia chips also contributed to the boom.\n\nSuch restrictions on high-end AI processors have choked China's access to cutting-edge US hardware and pushed Beijing to lean harder on domestic suppliers.\n\nStill, China's new AI billionaires remain far from the top of the country's wealth rankings. The upper tier is still dominated by long-established tycoons.\n\nIn the top spot is Zhong Shanshan, the low-key bottled-water magnate behind Nongfu Spring, with a fortune of $68.1 billion, per Bloomberg.\n\nPony Ma, a cofounder and CEO of Tencent, ranks second with $66.5 billion — a fortune up 38% this year, on the heels of Tencent's AI-induced rally — while ByteDance cofounder Zhang Yiming comes in third with $65.2 billion.",
    "readingTime": 3,
    "keywords": [
      "cofounder",
      "worth",
      "china's",
      "wealth",
      "fortunes",
      "tycoons",
      "chip",
      "metax",
      "chen's",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/china-ai-tech-boom-new-billionaires-metax-cambricon-moore-threads-2025-12",
    "thumbnail_url": "https://i.insider.com/6943786a64858d02d21705e7?width=1024&format=jpeg",
    "created_at": "2025-12-18T12:23:05.545Z",
    "topic": "finance"
  },
  {
    "slug": "bosses-expect-you-to-know-ai-even-if-its-not-in-your-job-description",
    "title": "Bosses expect you to know AI — even if it's not in your job description",
    "description": "Even as AI roles increase, mentions of the technology in job listings are down. It's a sign that bosses already expect you to use the technology.",
    "fullText": "That job description you're reading might not mention AI, but an employer will likely still expect you to know how to use it.\n\nA new snapshot of job listings from career platform Ladders showed that, while the number of AI roles listed on the site has tripled since 2021, the share of postings mentioning AI has decreased.\n\nIt's an indication that more employers are viewing technology as an everyday skill rather than as a differentiator, Marc Cenedella, founder and CEO of Ladders, told Business Insider.\n\n\"It will be mentioned less and less in the same way that Microsoft Office isn't mentioned in job postings anymore,\" he said.\n\nAmong about a dozen job categories Ladders reviewed, each saw a drop in postings that name-checked AI. For design and UX roles, AI mentions dropped from 56.7% of jobs in 2021 to 44.6% in 2025. Listings for product management positions registered a similar decrease.\n\nEven in software engineering, where the proliferation of coding agents has raised concerns that junior coders, in particular, will have a harder time finding work, AI references in job listings decreased from 53.5% to 45.8% in the four-year span.\n\nMentions of AI in job listings could pick up again, Cenedella said, if specialized tools emerge in different industries, though he said that might not happen until sometime in 2026 or 2027.\n\nIf that shift does come, it might mean that people in areas such as sales, pharmaceuticals, or semiconductors could need to demonstrate fluency with specific AI applications or methods for using the technology, Cenedella said. Employers could then start calling out those skills in job postings.\n\nThe overall drop in mentions of AI doesn't mean interest in the technology is fading, especially in certain areas. Ladders found that about 525,000 leadership and executive roles include AI references, up from 213,000 in 2021. All told, in 2025, the technology has been mentioned in 45% of executive postings on the site.\n\nRoles that aren't primarily technical — areas like finance, ops, design, sales, and project management — are seeing some of the fastest increases in AI skills adoption, Ladders found.\n\nOne reason, Cenedella said, is because the technology is moving so fast.\n\nOverall, Ladders said that jobs specifically about AI, such as engineering roles, shot up on its site to 6.7 million in 2025 from 2.1 million in 2021.\n\nRegardless of whether a job posting mentions AI, a boss will likely want you to be able to use it, Agur Jõgi, chief technology officer at the software company Pipedrive, told Business Insider.\n\n\"It's just like a ticket to the game,\" he said.\n\nJõgi said that you need to understand how AI is transforming your field and how it's affecting your job. \"That enables you to move as fast as the rest of the industry is moving,\" Jõgi said.\n\nJõgi said that if you're a holdout who's resisting using the technology, it could mean you're in for longer days if you want to keep up with colleagues who are going all in.\n\nEventually, as more people embrace AI, the early adopters who juiced their workplace productivity through AI will see that advantage fade, he said. To maintain it, Jõgi said, these go-getters will need to develop a fresh advantage.\n\n\"To beat the competition, you need to do something smarter, or you need to do slightly more,\" he said.\n\nDo you have a story to share about your career? Contact this reporter at tparadis@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "job listings",
      "job postings",
      "technology",
      "roles",
      "you're",
      "site",
      "career",
      "decreased",
      "employers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/fewer-job-listings-mention-ai-still-important-2025-12",
    "thumbnail_url": "https://i.insider.com/69418e11832e0ef1ead64ce8?width=1200&format=jpeg",
    "created_at": "2025-12-18T12:23:05.251Z",
    "topic": "finance"
  },
  {
    "slug": "oracles-fall-from-grace-has-made-it-the-poster-child-for-aibubble-excess",
    "title": "Oracle's fall from grace has made it the poster child for AI-bubble excess",
    "description": "It hasn't been that long since Oracle was an AI darling. A lot can change in a few months.",
    "fullText": "September 10, 2025 was one of the feel-good days of the year in markets.\n\nAt the center of the party was Oracle, the legacy tech company who stormed the gates of the AI trade with a blockbuster forecast for its cloud-infrastructure business.\n\nInvestors were so fired up about Oracle's AI guidance that they sent shares soaring as much as 43% that day. The company was briefly more valuable than JPMorgan. Larry Ellison overtook Elon Musk as the world's richest person — for a couple of hours at least. The S&P 500 finished the day at a record high. The vibes were immaculate.\n\nNow, in retrospect, the whole ordeal feels like the overreaction of the year.\n\nOracle's stock is down 46% since that blissful high, and now sits with a positive return of just 7% for the year, roughly half of the S&P 500.\n\nIn the process, the stock has become a poster child of a new market trend that's been percolating for weeks: Companies in the AI trade are priced to perfection, and anything seen falling short of lofty expectations will be punished.\n\nJust ask Meta, Microsoft, or any of the other AI companies that got dinged this past earnings season for lagging forecasts.\n\nOracle has gotten hit particularly hard by two disappointing developments in quick succession. Last Thursday, the company notched an 11% loss after spending way more than analysts expected on AI data centers during the previous quarter. Then, this Wednesday, the company shed another 5% after a key investor backed out of a $10 billion data center deal.\n\nThe market reactions perfectly encapsulate the messages investors have been sending tech to companies in recent weeks: Stop spending so much, and start producing some results. The possible delay of a hotly anticipated data center doesn't fit that bill.\n\nCoreWeave is another data-center-focused company that's felt the same wrath from investors. The former market darling — which spiked more than 400% in the weeks after its March IPO — is down more than 60% since then. The culprit? Data center delays.\n\nAll of the above has combined to dent the invincibility of the AI trade. Gone are the days of indiscriminate gains for anyone doing anything AI-related. Investors are being more discerning, and holding companies to a higher standard of progress.\n\nThe AI bubble may not be fully popping yet, but there's definite deflation happening in the areas of the market struggling to keep up with expectations.",
    "readingTime": 3,
    "keywords": [
      "center",
      "market",
      "trade",
      "tech",
      "stock",
      "that's",
      "expectations",
      "another",
      "investors",
      "oracle"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/oracle-stock-price-selloff-ai-bubble-excess-warning-coreweave-tech-2025-12",
    "thumbnail_url": "https://i.insider.com/69431ef3832e0ef1ead66d16?width=1200&format=jpeg",
    "created_at": "2025-12-18T12:23:05.158Z",
    "topic": "finance"
  },
  {
    "slug": "third-of-uk-citizens-have-used-ai-for-emotional-support-research-reveals",
    "title": "Third of UK citizens have used AI for emotional support, research reveals",
    "description": "AI Security Institute report finds most common type of AI tech used was general purpose assistants such as ChatGPT and Amazon Alexa\nA third of UK citizens have used artificial intelligence for emotional support, companionship or social interaction, according to the government’s AI security body.\nThe AI Security Institute (AISI) said nearly one in 10 people used systems like chatbots for emotional purposes on a weekly basis, and 4% daily.\n Continue reading...",
    "fullText": "AI Security Institute report finds most common type of AI tech used was general purpose assistants such as ChatGPT and Amazon Alexa\n\nA third of UK citizens have used artificial intelligence for emotional support, companionship or social interaction, according to the government’s AI security body.\n\nThe AI Security Institute (AISI) said nearly one in 10 people used systems like chatbots for emotional purposes on a weekly basis, and 4% daily.\n\nAISI called for further research, citing the death this year of the US teenager Adam Raine, who killed himself after discussing suicide with ChatGPT.\n\n“People are increasingly turning to AI systems for emotional support or social interaction,” AISI said in its first Frontier AI Trends report. “While many users report positive experiences, recent high-profile cases of harm underline the need for research into this area, including the conditions under which harm could occur, and the safeguards that could enable beneficial use.”\n\nAISI based its research on a representative survey of 2,028 UK participants. It found the most common type of AI used for emotional purposes was “general purpose assistants” such as ChatGPT, accounting for nearly six out of 10 uses, followed by voice assistants including Amazon Alexa.\n\nIt also highlighted a Reddit forum dedicated to discussing AI companions on the CharacterAI platform. It showed that, whenever there were outages on the site, there were large numbers of posts showing symptoms of withdrawal such as anxiety, depression and restlessness.\n\nThe report included AISI research suggesting chatbots can sway people’s political opinions, with the most persuasive AI models delivering “substantial” amounts of inaccurate information in the process.\n\nAISI examined more than 30 unnamed cutting-edge models, thought to include those developed by ChatGPT startup OpenAI, Google and Meta. It found AI models were doubling their performance in some areas every eight months.\n\nLeading models can now complete apprentice-level tasks 50% of the time on average, up from approximately 10% of the time last year. AISI also found that the most advanced systems can autonomously complete tasks that would take a human expert over an hour.\n\nAISI added that AI systems are now up to 90% better than PhD-level experts at providing troubleshooting advice for laboratory experiments. It said improvements in knowledge on chemistry and biology were “well beyond PhD-level expertise”.\n\nIt also highlighted the models’ ability to browse online and autonomously find sequences necessary for designing DNA molecules called plasmids that are useful in areas such as genetic engineering.\n\nTests for self-replication, a key safety concern because it involves a system spreading copies of itself to other devices and becoming harder to control, showed two cutting-edge models achieving success rates of more than 60%.\n\nHowever, no models have shown a spontaneous attempt to replicate or hide their capabilities, and AISI said any attempt at self-replication was “unlikely to succeed in real-world conditions”.\n\nAnother safety concern known as “sandbagging”, where models hide their strengths in evaluations, was also covered by AISI. It said some systems can sandbag when prompted to do so, but this has not happened spontaneously during tests.\n\nIt found significant progress in AI safeguards, particularly in hampering attempts to create biological weapons. In two tests conducted six months apart, the first test took 10 minutes to “jailbreak” an AI system – or force it to give an unsafe answer related to biological misuse – but the second test took more than seven hours, indicating models had become much safer in a short space of time.\n\nResearch also showed autonomous AI agents being used for high-stakes activities such as asset transfers.\n\nIt said AI systems are competing with or even surpassing human experts already in a number of domains, making it “plausible” in the coming years that artificial general intelligence can be achieved, which is the term for systems that can perform most intellectual tasks at the same level as a human. AISI described the pace of development as “extraordinary”.\n\nRegarding agents, or systems that can carry out multi-step tasks without intervention, AISI said its evaluations showed a “steep rise in the length and complexity of tasks AI can complete without human guidance”.",
    "readingTime": 4,
    "keywords": [
      "amazon alexa",
      "security institute",
      "social interaction",
      "safety concern",
      "purpose assistants",
      "emotional purposes",
      "cutting-edge models",
      "systems",
      "research",
      "tasks"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/18/artificial-intelligence-uk-emotional-support-research",
    "thumbnail_url": "https://i.guim.co.uk/img/media/942f89452240fbad123464e1a708484a2c47c016/1040_0_5200_4160/master/5200.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ba9e35b6af05f6d18aedcaca5329afb4",
    "created_at": "2025-12-18T12:23:04.731Z",
    "topic": "tech"
  },
  {
    "slug": "2025s-ai-boom-caused-huge-co2-emissions-and-use-of-water-research-finds",
    "title": "2025’s AI boom caused huge CO2 emissions and use of water, research finds",
    "description": "Study’s author says society not tech companies paying for environmental impact of AI and asks if this is fair\nThe AI boom has caused as much carbon dioxide to be released into the atmosphere in 2025 as emitted by the whole of New York City, it has been claimed.\nThe global environmental impact of the rapidly spreading technology has been estimated in research published on Wednesday which also found that AI-related water use now exceeds the entirety of global bottled-water demand.\n Continue reading...",
    "fullText": "Study author says tech companies are reaping benefits of artificial intelligence age but society is left to pay cost\n\nThe AI boom has caused as much carbon dioxide to be released into the atmosphere in 2025 as emitted by the whole of New York City, it has been claimed.\n\nThe global environmental impact of the rapidly spreading technology has been estimated in research published on Wednesday which also found that AI-related water use now exceeds the entirety of global bottled-water demand.\n\nThe figures have been compiled by the Dutch academic Alex de Vries-Gao, the founder of Digiconomist, a company that researches the unintended consequences of digital trends. He claimed they are the first attempt to measure the specific effect of artificial intelligence rather than datacentres in general as the use of chatbots such as OpenAI’s ChatGPT and Google’s Gemini soared in 2025.\n\nThe figures show the estimated greenhouse gas emissions from AI use are also now equivalent to more than 8% of global aviation emissions. His study used technology companies’ own reporting and he called for stricter requirements for them to be more transparent about their climate impact.\n\n“The environmental cost of this is pretty huge in absolute terms,” he said. “At the moment society is paying for these costs, not the tech companies. The question is: is that fair? If they are reaping the benefits of this technology, why should they not be paying some of the costs?”\n\nDe Vries-Gao found that the 2025 carbon footprint of AI systems could be as high as 80m tonnes, while the water used could reach 765bn litres. He said it was the first time AI’s water impact had been estimated and showed that AI water use alone was more than a third higher than previous estimates of all datacentre water use.\n\nThe figures are published in the academic journal Patterns. The International Energy Agency (IEA) said earlier this year that AI-focused datacentres draw as much electricity as power-thirsty aluminium smelters and datacentre electricity consumption is expected to more than double by 2030.\n\n“This is yet more evidence that the public is footing the environmental bill for some of the richest companies on Earth,” said Donald Campbell, the director of advocacy at Foxglove, a UK non-profit that campaigns for fairness in tech. “Worse, it is likely just the tip of the iceberg. The datacentre construction frenzy, driven by generative AI, is only getting started.\n\n“Just one of these new ‘hyperscale’ facilities can generate climate emissions equivalent to several international airports. And in the UK alone, there are an estimated 100-200 of them in the planning system,” said Campbell.\n\nThe IEA has reported that the largest AI-focused datacentres being built today will each consume as much electricity as 2m households with the US accounting for the largest share of datacentre electricity consumption (45%) followed by China (25%) and Europe (15%).\n\nThe largest datacentre being planned in the UK, at a former coal power station site in Blyth, Northumberland, is expected to emit more than 180,000 tonnes of CO2 a year when at full operation – the equivalent to the amount produced by more than 24,000 homes.\n\nIn India, where $30bn (£22.5bn) is being invested in datacentres, there are growing concerns that a lack of reliability from the National Grid will mean the construction of huge diesel generator farms for backup power, which the consultancy KPMG this week called “a massive … carbon liability”.\n\nTechnology companies’ environmental disclosures are often insufficient to assess even the total datacentre impact, never mind isolating AI use, said De Vries-Gao. He noted that when Google recently reported on the impact of its Gemini AI, it did not account for the water used in generating the electricity needed to power it.\n\nGoogle reported that in 2024 it managed to reduce energy emissions from its datacentres by 12% due to new clean energy sources, but it said this summer that achieving its climate goals was “now more complex and challenging across every level – from local to global” and “a key challenge is the slower-than-needed deployment of carbon-free energy technologies at scale”.\n\nGoogle was approached for comment.",
    "readingTime": 4,
    "keywords": [
      "ai-focused datacentres",
      "artificial intelligence",
      "electricity consumption",
      "datacentre electricity",
      "water",
      "impact",
      "environmental",
      "technology",
      "estimated",
      "emissions"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/18/2025-ai-boom-huge-co2-emissions-use-water-research-finds",
    "thumbnail_url": "https://i.guim.co.uk/img/media/6454f44555fa48a5f38d1d066c370cb6e7376a80/0_0_6827_5464/master/6827.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f3344baddc279d10a63ba366fdf49d2d",
    "created_at": "2025-12-18T12:23:04.730Z",
    "topic": "tech"
  },
  {
    "slug": "what-irelands-data-center-crisis-means-for-the-eus-ai-sovereignty-plans",
    "title": "What Ireland's Data Center Crisis Means for the EU's AI Sovereignty Plans",
    "description": "Louis Boyd-Madsen traces how a model of unregulated digital growth has outpaced energy planning in Ireland, and why it matters for the EU’s AI ambitions.",
    "fullText": "This reporting is published in collaboration with AlgorithmWatch and is supported by the European Digital Rights (EDRi), European Center for Non-For-Profit Law (ECNL), and Lighthouse Reports investigative journalism & civil society collaboration grants.\n\nIreland is now home to one of the highest concentrations of data centers in the world. What began as a quiet build-out of server farms around Dublin has expanded into an industrial presence with an ecological footprint that dominates the country’s electricity system. In the meanwhile, Big Tech has falsely portrayed itself as a partner in green transition.\n\nThe surge in energy consumption has reshaped the energy system around the needs of a handful of multinational tech companies. Grid capacity is being diverted to new hyperscale sites, transmission upgrades are being driven by their load, and the state is pouring billions into emergency fossil-fuel generators to keep supply stable. Households face higher bills, electrification plans have stalled, and national climate targets are slipping out of reach. What looks like a renewable success story on paper masks a system increasingly strained by a single, rapidly expanding sector of energy users.\n\nA growing social resistance has emerged in response. In nearby towns to Dublin, such as Rochfortbridge and Naas, local communities are pushing back against plans for new developments. At a national level, movements like “Energy for Who?” are demanding that renewables and grid connections be prioritized for essential social infrastructure, including housing and transport. Recent polling suggests this perspective is broadly shared by the public. Yet, government planning has so far focused on stabilizing digital growth, rather than reimagining how it fits within the goals of a just and affordable energy transition.\n\nIreland has thus become a test case for the political, economic, and environmental contradictions created by unregulated hyperscale expansion. As the EU moves to triple its data center capacity under the AI Continent Action Plan, the pressures already destabilizing Ireland’s grid offer a preview of what the continent may soon face.\n\nUnlike the hyperscale sites now being built across the globe amidst the frenzy of AI speculation, Ireland’s data center load growth was initially driven by more traditional uses: cloud storage, banking infrastructure, and the vast personal data archives that underpinned Big Tech’s earlier phase of expansion.\n\nSince the start of the post-war era, the Irish government has run an economic strategy based around courting investment from foreign multinationals – using a range of tools including tax incentives and infrastructure investment. This approach found real success with the rise of the ICT industry in the 1980s and 1990s, as US multinationals flooded into the country to lower their tax obligations and set up shop for export physical electronics, software, and services to the wider EU.\n\nAs money was channeled into a small set of tech giants in the aftermath of the 2008 global financial crisis, and the demand for computational capacity rose, Dublin began to see a steady growth in data centers – linking Big Tech’s offshore headquarters to the United States via a network of undersea internet cables.\n\nThe tech sector grew rapidly: Today, it has become a major source of government revenue and the main applicant for new electricity demand. Energy consumption by data centers is by far the highest in Europe: in comparison to the total Irish national consumption, they accounted for a 22% share in 2024. Roughly 97% of these data centers are clustered in the wider Dublin area. In 2023, 88% of all corporation tax was paid by foreign multinationals, of which 57% was paid by just 10 companies. A report from the Irish Central Bank suggests a major driver of growing tax revenue between 2011 and 2021 was “a small number of extremely profitable ICT firms.\"\n\nFor academic Patrick Brodie, this dependence is the latest chapter in a much longer development model. Ireland, he argues, “hitched its wagon to the transatlantic investment relationship” in the post-war period, shaping the country’s industrial and infrastructural landscape ever since. That bargain was never just about taxes. “It was also about building infrastructure,” he says, “and about managing the environmental contradictions that came with it.”\n\nThose contradictions are now concentrated directly in the electricity system, according to Brodie. Vast public resources are mobilized to serve capital-intensive digital infrastructure, even as shortages persist in housing, transport, and public services. “You can’t have a green transition that’s genuinely independent if it’s dictated by the needs of monopolistic tech companies,” he adds.\n\nThis facilitative model has already reappeared in different shades across Europe – from the UK’s AI Growth Zones, to Sweden’s energy tax break for data centers, or Denmark’s build-out of low-latency fiber optic and grid overcapacity. But nowhere has the potential bargain between digital growth and energy planning been pushed further than in Ireland. The consequences are now becoming visible across the country’s grid, climate trajectory, and public finances.\n\nThe Commission for Regulation of Utilities (CRU) put an effective moratorium on new data center grid connections in Dublin, requiring new connections to be in unconstrained parts of the grid with sufficient local generation capacity. However, the grid remained fragile.\n\nIn response, the government and the energy system operator moved to commission emergency gas generators near the port of Dublin, the Irish Midlands, and a handful of additional sites, at an estimated cost of €1 billion. To help ease congestion, a wave of investment has been going into upgrading the grid’s capacity to distribute electricity. Much of this cost has been shouldered by Irish households, adding an average of roughly €100 per family to the bills in 2024.\n\nYet most of this newly created grid capacity was not used to electrify homes, rail, heat pumps, or industry. It was hoarded by data center developers. Ireland had limited rules governing priority access to grid connections, so hyperscalers simply booked capacity years in advance, effectively shutting out other users. For instance, a grid connection originally planned to serve new housing in Castlebaggot, West Dublin, was instead allocated to data centers.\n\nThe CRU suggested this trend was threatening the country’s broader targets for decarbonization and housing development: “The potential level of data center demand could significantly impact [the grid’s] ability to accommodate demand connections required to support Government policy targets such as 550,000 new homes by 2040, 680,000 heat pumps and 945,000 EVs [Electric Vehicles] by 2030, major electrified rail projects explicitly identified in the National Development Plan and other social infrastructure.”\n\nIreland is one of the most fossil fuel-reliant economies in Europe. “About 80% of all the energy we use today for our homes, our heating, our appliances, and our industry comes from fossil fuels,” says Paul Deane, senior lecturer in Clean Energy Futures at University College Cork.\n\nNevertheless, tech firms continued to portray themselves as green-transition partners — largely through Corporate Power Purchase Agreements (CPPAs). These allow companies to claim renewable electricity procurement on paper even when their facilities draw from the grid’s fossil-fuel-heavy mix in practice. Europe-wide, Amazon, Google, and Microsoft are the three largest buyers.\n\nData from RE-Source suggests most CPPAs signed in Ireland are either financial – that is, not based on physical power delivery to the buyer – or structured in a way that has not been publicly disclosed. Only 14% are confirmed to involve a direct physical connection between the generator and the off-taker. The sources consulted for this investigation suggest the majority of these CPPAs match electricity on an annual basis rather than hour by hour.\n\nThe result is a widening gulf between corporate sustainability claims and actual, system-wide decarbonization.\n\nThese contradictions can be seen clearly in the Midlands where Bord na Móna’s planned Eco Energy Park will co-locate future Amazon Web Services (AWS) data centers with renewable-energy infrastructure. AWS is aiming to contract up to 800 MW of new wind and solar generation from Bord na Móna’s wider project pipeline — a volume of electricity roughly equivalent to the annual consumption of 2.2 million Irish homes. But so far, just 105 MW has been secured through a CPPA linking a proposed new AWS site to a nearby wind farm. Whenever the wind drops, any data centers built at the site will still draw power from the national grid, including fossil-fuel generated electricity.\n\nTo guarantee stability, Bord na Móna has already applied for a 600 MW gas plant adjacent to the site, which it claims will later switch to hydrogen or biomethane, according to the company’s environmental impact assessment report. No credible pathway exists to supply these fuels at this scale.\n\n“Renewable energy only helps meet our legally binding carbon budgets if it replaces fossil fuel demand, ” says Hannah Daly, Professor of Sustainable Energy at University College Cork. “If there was evidence that data centers were financing projects that wouldn’t otherwise have been built and that would match their demand at all hours of the year without creating bottlenecks for other renewables, they would at least not harm our carbon budgets.\"\n\nAnalysis conducted by AlgorithmWatch and Tech Policy Press, drawing on tech majors’ sustainability reports and press releases, suggests the total announced new capacity brought online via CPPAs with data centers in Ireland is far behind the pressure that data center expansion has already put on the energy system. Even if all announced CPPAs come online, they will still fall behind the load that has already been imposed on the system.\n\nIn a paper commissioned by FOE Ireland, Professor Daly found that half of the new capacity came from CPPAs, as opposed to government-run auctions, between 2020 and 2023. But this volume only amounted to 16% of the new data center demand during this period. Daly’s findings mirror our own. Despite industry claims of 100% renewable procurement, Ireland’s data centers in aggregate have seemingly deepened the country’s dependence on fossil fuels.\n\nYet regulators have limited power to intervene. Out of fear for the country’s energy security, the Irish government has promised to spend more on its fossil fuel infrastructure, beginning construction of a state-led strategic gas emergency reserve. The reserve will take the form of a floating LNG (liquefied natural gas) tanker and regasification plant, with an estimated upfront cost of between €300 and €900 million.\n\nMeanwhile, developers are increasingly turning to on-site gas generation to circumvent grid constraints entirely. Microsoft’s Grange Castle campus in Dublin has a fleet of gas generators totaling 239 MW. The site is one of seven with existing gas connections, five of which are currently actively consuming gas. Analysis by Hannah Daly from Cork’s University College suggests an additional four sites are awaiting connection and 22 have submitted planning requests.\n\nDaly shows that if existing, pending, and proposed gas-connected data center sites all operate at full capacity, they would emit up to 16.6 MtCO₂ per year — equivalent to 68% of Ireland’s total national emissions in 2023. She notes that Gas Network Ireland’s own, more conservative estimates, still predict an overshoot on sectoral emissions targets by 21-30%, driven by existing and confirmed on-site gas connections respectively.\n\nGas Networks Ireland and several private actors see this gas demand as a temporary, transitional problem as the network switches over to low-carbon hydrogen and bio-methane. Daly’s colleague Paul Deane remains sceptical. “Some data-center owners say they’ll only use gas for a few years, but there’s no convincing evidence of an off-ramp,” he says. “The promise of a technology in the future, isn't good enough to allow you to burn more natural gas today.”\n\nThese various interlinked problems have come to the fore in the discussions of the new Large Energy Users (LEU) Connection Policy. Expected to be finalized before the end of the year by the CRU, the policy will set out new rules for how data centers connect to the grid. The policy’s main goals are to improve grid stability, ensure sufficient on-site or nearby generation capacity, and strengthen emissions reporting.\n\nHowever, in the draft text, the CRU concedes that it will not receive enforcement powers to mandate renewable procurement, emissions caps, or set requirements for the decarbonization of the gas network.\n\nThe specialists interviewed said this reflects a broader pattern: rather than confronting the political trade-offs between digital growth and sustainability, the Irish government has deferred control to regulators tasked with managing that growth as smoothly as possible. The LEU policy, critics say, is the latest example of this deference to regulatory authority.\n\n“Ireland’s climate legislation directly conflicts with several of our enterprise strategies. There’s a lack of acceptance that it’s impossible to reconcile the constraints of carbon emission targets with what’s necessary for the growth of this industry via technological measures alone,” Daly says. “The right technologies and supply measures would need to be put in place ahead of the growth of the industry, not afterwards.”\n\nRosi Leonard, a data‑center campaigner for Friends of the Earth Ireland, argues that the government overestimates the sector’s mobility: companies are unlikely to abandon existing infrastructure in Ireland, even under stricter regulations, and any departure would indicate the need for broader economic diversification.\n\nThe Irish case has seen a consistent pattern: tech-sector growth is treated as inevitable, while climate obligations are accommodated around it. Managing the strained infrastructure comes at the cost of rising emissions and deferred decarbonization - a lesson that other countries facing rapid digital expansion will soon have to confront.\n\nIreland’s experience is no longer a local anomaly. The EU’s AI Continent Action Plan proposes tripling data center capacity by 2030 to support continent-wide AI deployment, cloud services, and high-performance computing. But the plan does not resolve the fundamental challenges that Ireland is now experiencing: scarce grid capacity, fossil fuel lock-in, insufficient transmission infrastructure, and potential social pressures caused by rising energy prices.\n\nThe EU also risks repeating one of Ireland’s biggest mistakes on renewable energy. Its plan to use public funds to de-risk long-term contracts for hyperscale data centers — through agreements linking governments, utilities and tech firms — could end up funneling taxpayers’ money into deals that let companies claim that they use renewable electricity without actually cutting emissions.\n\nEurope still has time to avoid these pitfalls. Countries planning to host hyperscale clusters should ensure sufficient energy capacity before data centers are built; block direct fossil-gas connections; enforce 24/7 renewable matching; and plan for the availability of clean power for critical public services and housing, rather than ring-fencing new renewables for the tech sector through CPPAs.\n\nThe Irish case shows what happens when digital expansion outruns energy planning, and when political dependency on a small group of firms overrides climate commitments. The costs - higher prices, deeper fossil lock-in, strained infrastructure, and derailed emissions targets - are now visible across the country, while access for homes, transport and essential infrastructure remains a low priority. The EU can treat Ireland as a cautionary tale, or repeat its mistakes on a continental scale.",
    "readingTime": 13,
    "keywords": [
      "university college",
      "continent action",
      "college cork",
      "action plan",
      "heat pumps",
      "green transition",
      "foreign multinationals",
      "carbon budgets",
      "ensure sufficient",
      "visible across"
    ],
    "qualityScore": 1,
    "link": "https://www.techpolicy.press/what-irelands-data-center-crisis-means-for-the-eus-ai-sovereignty-plans/",
    "thumbnail_url": "https://cdn.sanity.io/images/3tzzh18d/production/5dfbcf9601fa7a9500ba45326b970b6ca6723258-1200x675.png",
    "created_at": "2025-12-18T12:23:04.416Z",
    "topic": "tech"
  },
  {
    "slug": "why-do-indie-developers-always-find-it-so-hard-to-promote-their-products",
    "title": "Why do indie developers always find it so hard to promote their products?",
    "description": "The only AI that unifies Influencer Marketing, GEO, Social Listening, and Content Production — all in one place. Zero chaos. Smarter results.",
    "fullText": "The only AI that unifies Influencer Marketing, GEO, Social Listening, and beyond\n\nBuilt around your brand's unique context\n\n“Find creators in AI SaaS who have an engagement rate above 4%.”\nAmplift searches millions of profiles, evaluates them using expert benchmarks, and returns context-rich results — with authenticity, sentiment, and performance insights baked in.\n\n“What’s the latest conversation around my niche?”\nAmplift listens across social platforms, tracking sentiment, trending topics, and creator mentions to help you see what’s driving engagement right now — and what’s fading out.\nYou don’t manage Amplift,You converse with it — like a strategist who already knows your goals.\n\nAudit AI Overviews, track competitor coverage, and prioritize fixes that move share-of-voice across engines.\n\nGenerate briefs and on-brand drafts anchored in the evidence AI systems already trust about your company.\n\nUse natural language: “Find mid-tier creators in Japan who talked about coding tools this month.”\n\nIt applies vetted frameworks — the same logic used by top agencies — combining influencer data, GEO signals, and social sentiment into one interpretation.\n\nAmplift outputs insights, outreach drafts, and action plans instantly — all ready to use or refine through the same conversation.",
    "readingTime": 1,
    "keywords": [
      "social",
      "amplift",
      "sentiment",
      "what’s",
      "influencer",
      "creators",
      "engagement",
      "insights",
      "conversation",
      "across"
    ],
    "qualityScore": 0.85,
    "link": "https://amplift.ai/",
    "thumbnail_url": "https://www.amplift.ai/ogtag.png",
    "created_at": "2025-12-18T06:19:06.582Z",
    "topic": "tech"
  },
  {
    "slug": "rerun-physical-data-platform",
    "title": "Rerun: Physical Data Platform",
    "description": "Multimodal log handling and visualization for spatial and embodied AI. Managed infrastructure to ingest, store, analyze, and stream data at scale with built-in visual debugging. Fast, flexible, and easy to use.",
    "fullText": "Iterate faster on robotics learning with unified infrastructure. Ingest,\n visualize, annotate, query, and transform - from collection to training.\n\nVisualize consistently as you explore, build, evaluate, and debug\n\n Manage and share all data and visualizations in one place\n\nRun snappy dataframe queries optimized for robotics data\n\n Transform logs into training-ready data with simple pipelines\n\nIngest, store, and index robotics logs of multi-formats\n\n Search and retrieve petabyte-scale robotics data in seconds\n\nPowerful and flexible visualization for spatial and embodied AI that's shockingly easy to get started with.\n\nLeRobot is Huggingface's State-of-the-art AI for real-world robotics project. They are using Rerun as an integrated part of their visualization tools.\n\nLeRobot is Huggingface's State-of-the-art AI for real-world robotics project. They are using Rerun as an integrated part of their visualization tools.\n\nBrush is a 3D reconstruction engine using Gaussian splatting developed by Arthur Brussee at Deepmind. It is written in Rust and aims to be highly portable, flexible and fast. Rerun is used for visualization during training.\n\nPyCuVSLAM is the official Python wrapper for NVIDIA's cuVSLAM library, providing GPU-accelerated visual SLAM and camera tracking for real-time localization and mapping.\n\nUltra is building intelligent warehouse robots that automate repetitive, dangerous, and variable tasks. They use Rerun Data Platform for their end-to-end data visualization workflow and transformation pipeline.\n\nProject Aria is a research platform developed by Meta Reality Labs Research to push the state of the art in egocentric AI research. Rerun is used to visualize sequences in their Aria Dataset Explorer.\n\nRerun accelerates your speed of progress by helping you SEE faster\n\nSpot interesting moments from robot logs that could improve your model - a failure in a perception pipeline, an unexpected action, or a novel real-world scenario.\n\nZoom out from a single moment to the surrounding context to trace root cause.\n\nFind all similar events across your recordings to collect training data.\n\nTransform messy logs into training-ready datasets with a consistent and flexible pipeline.\n\nDebug visually as you train, evaluate, and iterate ML models.\n\nVisualize robot runs and turn them into training data locally.\n\nBuilt on open source, extended for production. Consistently produce\n large-scale, high-quality training data from massive robot runs.\n\nWinning teams win on the speed of product iteration. Rerun scales your infrastructure and simplifies your data pipelines. Every engineering hour drives new capability, not plumbing\n\nVisualize robot runs and turn them into training datasets, run locally\n\nDual licensed under MIT and Apache 2\n\nTurn large scale robotics log data into high-quality training data\n\nVisualize robot runs and turn them into training datasets, run\n locally\n\nDual licensed under MIT and Apache 2\n\nTurn large scale robotics log data into high-quality training data\n\nBeta release with selected customers\n\nRerun 0.27 includes experimental coordinate frame hierarchies, Python APIs for server management, blueprint controls for 3D views, and time panel improvements.\n\nRerun 0.26 brings major performance improvements, reflection-based ROS2 MCAP support, experimental lenses, and continued polish across the viewer and SDK.\n\nLearn how Rerun's URL-based architecture and open source design make sharing Physical AI visualizations effortless—from command line to web viewer to native apps.",
    "readingTime": 3,
    "keywords": [
      "huggingface's state-of-the-art",
      "dual licensed",
      "locally dual",
      "visualize robot",
      "visualization tools",
      "scale robotics",
      "robotics log",
      "high-quality training",
      "real-world robotics",
      "robotics project"
    ],
    "qualityScore": 1,
    "link": "https://rerun.io/",
    "thumbnail_url": "https://rerun.io/og-landing.jpg",
    "created_at": "2025-12-18T06:19:05.842Z",
    "topic": "tech"
  },
  {
    "slug": "kling-o1-creates-ai-videos-and-images-from-any-input",
    "title": "Kling O1 – Creates AI videos and images from any input",
    "description": "Kling O1 is a unified multimodal video model by Kling AI, aka Omni One, with semantic understanding, enabling all-in-one video generation with high consistency.",
    "fullText": "Create, edit, and generate videos effortlessly with Kling O1. Ultimate video creation platform with multimodal input for high-quality results.\n\nKling O1 (Kling AI VIDEO O1) is the world's first unified multimodal AI video model.\n\nQuickly create professional videos for social media, short films, game cutscenes, educational videos, and marketing campaigns with high consistency and creative flexibility.\n\nKling O1, the next-gen multimodal AI video generator, brings text, images, and references together for flexible, professional video creation.\n\nKling AI VIDEO O1 accepts images, videos, elements, texts, and more as input.\n\nIntegrates text-to-video, reference-based generation, keyframe interpolation (start/end frame), video inpainting, transformation, stylization, and video extension, without switching.\n\nWith deep semantic understanding, Kling O1 transforms complex post-production tasks into an efficient, end-to-end AI video workflow.\n\nFrom local subject replacement to full-video restyling, Kling O1 automatically handles pixel-level semantic reconstruction, making your prompts the most powerful tool for AI video generation and editing.\n\nUsing reference images and elements, Kling O1 remembers characters, props, and scenes, ensuring consistency, accuracy, and continuity across shots. Kling O1 lets you combine multiple characters or blend them with references seamlessly.\n\nUnlock Infinite Creativity in One Generation\n\nKling O1 supports multi-task AI video generation, allowing you to combine different creative actions in a single prompt. Modify backgrounds, add subjects, or change styles while using reference elements, all at once.\n\nFlexible 3–10s AI Video Generation\n\nKling O1 lets you control the duration of each shot, supporting 3–10 second AI video generation for precise pacing. Whether for fast, impactful scenes or longer narrative arcs, you can dictate the rhythm of your story.\n\nKling O1: Your AI video assistant for multimodal generation, editing, synthesis and animation in real-world workflows.\n\nKling O1 ensures high consistency with reference elements, enabling smooth AI-assisted filmmaking with automatic, pixel-level video edits.\n\nQuickly generate product showcase videos with simple text prompts. Save time and cost while creating high-quality AI advertising content.\n\nEnable endless virtual runway videos. Generate lookbook videos with accurate clothing details, perfect for fashion showcases and marketing.\n\nExplore top generative video tools and see how Kling O1 stands out.\n\nLearn more about how Kling O1 works, subscription plans, and commercial usage rights.\n\nKling O1 is an AI-powered video generation and editing model that creates cinematic, high-fidelity video from text, images, or video references.\n\nYes. Eligible users can request a trial or demo before upgrading to a paid or enterprise plan.\n\nYes. Commercial usage is permitted under business and enterprise licenses, including advertising, branded content, and film production.\n\nNo. Kling O1 runs in the cloud and does not require professional GPUs or high-performance devices.\n\nYes. You can apply inpainting, outpainting, composition changes, style transfer, subject replacement, and localized edits.\n\nNo editing experience is required. However, professional workflows benefit from prompt structure, visual direction, and production planning.",
    "readingTime": 3,
    "keywords": [
      "subject replacement",
      "commercial usage",
      "text images",
      "reference elements",
      "generation kling",
      "videos",
      "multimodal",
      "professional",
      "editing",
      "generate"
    ],
    "qualityScore": 1,
    "link": "https://www.klingo1.net",
    "thumbnail_url": "https://www.klingo1.net/kling-o1.webp",
    "created_at": "2025-12-18T06:19:05.225Z",
    "topic": "tech"
  },
  {
    "slug": "china-reportedly-has-a-prototype-euv-machine-built-by-exasml-employees",
    "title": "China reportedly has a prototype EUV machine built by ex-ASML employees",
    "description": "Reuters reports that scientists in China have created a prototype of a machine that could eventually be used to produce semiconductor chips capable of powering AI.",
    "fullText": "A report from Reuters claims that scientists in China have created a prototype of a machine that could eventually be used to produce semiconductor chips capable of powering artificial intelligence. Sources told the publication that a team in Shenzhen completed the prototype of an extreme ultraviolet lithography machine earlier this year and it is allegedly now undergoing testing. The EUV machine was reportedly made by former engineers from Dutch semiconductor supplier ASML. Reuters states that China is targeting production of its own EUV chips beginning in 2028, although other experts have projected 2030 as a more likely date.\n\nEUV is a supremely complicated bit of technology; we have an explainer below that gets into some of the details. It is at the heart of the chips made by companies such as Intel and TSMC, so any company trying to compete would also need access to EUV. Although the Chinese prototype is not yet making chips, it is reportedly able to generate the extreme ultraviolet light needed for chip manufacturing.\n\nIf confirmed, this development would put China in control of tech much sooner than analysts had previously expected. To date, EUV has largely been kept out of reach by Western companies and used as a bargaining chip by the US government. Chinese President Xi Jinping has placed a high priority on the country being able to produce its own semiconductors. \"The aim is for China to eventually be able to make advanced chips on machines that are entirely China-made,\" a source told Reuters. \"China wants the United States 100 percent kicked out of its supply chains.\"",
    "readingTime": 2,
    "keywords": [
      "date euv",
      "extreme ultraviolet",
      "chips",
      "prototype",
      "machine",
      "eventually",
      "produce",
      "semiconductor",
      "reportedly",
      "chip"
    ],
    "qualityScore": 0.75,
    "link": "https://tech.yahoo.com/science/article/china-reportedly-prototype-euv-machine-235833970.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/mNcLsfeJzSjbko2jHA7mCA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/engadget_703/268b9d264d2284a2a67de948300caa4e",
    "created_at": "2025-12-18T06:19:01.178Z",
    "topic": "tech"
  },
  {
    "slug": "sanders-pushing-for-a-moratorium-on-ai-data-centers",
    "title": "Sanders: Pushing for a moratorium on AI data centers",
    "description": "I will be pushing for a moratorium on the construction of data centers that are powering the unregulated sprint to develop & deploy AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/sensanders/status/2001057004370948131",
    "thumbnail_url": "https://pbs.twimg.com/amplify_video_thumb/2001056852683984896/img/3lmuPWBZ2YbtN12r.jpg:large",
    "created_at": "2025-12-18T00:53:23.845Z",
    "topic": "tech"
  },
  {
    "slug": "cisco-decides-its-homegrown-ai-model-is-ready-to-power-its-products",
    "title": "Cisco decides its homegrown AI model is ready to power its products",
    "description": ": Apparently you’re about to get better advice on any identity issues lurking in your infrastructure",
    "fullText": "Cisco has decided its homegrown AI models are ready to power its products, starting with its Duo Identity Intelligence offering.\n\nThe model Cisco will use is called “Foundation-Sec-1.1-8B-Instruct”. As described on the Hugging Face model-mart, it’s an open-weight, 8-billion-parameter instruction-tuned “Auto-regressive language model that uses an optimized transformer architecture,” namely Meta Llama-3.1-8B backbone.\n\nCisco tuned the model for cybersecurity applications and optimized it for three uses:\n\nIn a Tuesday post, Cisco revealed it’s using the model with Duo Identity Intelligence, a service that analyzes who logs on to networks, where they log on from, and which devices they use.\n\n“By examining post authentication signals, the system identifies patterns that traditional access controls often miss, including unusual geographic activity, abnormal privilege usage, and indications of MFA fatigue attempts or session hijacking,” Cisco explained.\n\nThe product alerts users to potential identity issues in a weekly email digest that Cisco will now compose with help from its new model.\n\n“Producing such a digest requires an artificial intelligence model that understands identity behavior, can interpret long chains of events, and communicates insights in a way that aligns with how security administrators make decisions,” Cisco’s post states, adding that general-purpose models “are not always tuned for the nuance and precision required for identity security and often introduce external dependencies.”\n\nUsing its own model, Cisco says, will deliver “summaries that are more accurate, more readable, and more aligned with real security workflows.”\n\nThe company also says the content of the digests will become “noticeably stronger … clearer and more consistent. Prioritization improves, making it easier to identify what demands immediate attention. Insights feel more relevant to each environment, and recommendations are expressed in a more actionable way.” Cisco reckons you’ll therefore end up using Identity Intelligence more often, because the model will produce info that demands action.\n\nThe improved digest is the result of collaboration between the teams that develop Duo and Cisco’s foundation models.\n\n“Both groups created a tuned prompt stack that significantly improved output quality and aligned the model with the analytical style expected in the digest,” Cisco’s post states.\n\nOver 2,000 Cisco customers receive the digest. If you’re one of them, let us know if the weekly email has improved!\n\nThe model can run on-prem or in the cloud, and do much more than write nice email digests. Cisco says its downstream uses include:\n\nIn early November, Cisco told The Register it’s working on a 17-billion parameter foundation model, and “a whole phalanx” of other AI. Foundation-Sec-1.1-8B-Instruct seems to come from the phalanx, as while it is a foundation model it is nine billion parameters short of the forthcoming model Cisco mentioned.®",
    "readingTime": 3,
    "keywords": [
      "duo identity",
      "weekly email",
      "model cisco",
      "foundation model",
      "duo identity intelligence",
      "digest",
      "models",
      "it’s",
      "tuned",
      "security"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2025/12/17/cisco_foundation_model_indentity_intelligence/",
    "thumbnail_url": "https://regmedia.co.uk/2017/06/20/shutterstock_dogfood.jpg",
    "created_at": "2025-12-18T00:53:23.378Z",
    "topic": "tech"
  },
  {
    "slug": "metax-soars-700-in-debut-as-china-ai-chips-push-lures-investors",
    "title": "MetaX soars 700% in debut as China AI chips push lures investors",
    "description": "MetaX Integrated Circuits jumped 700% in its Shanghai market debut as the Chinese AI chipmaker tapped into strong momentum triggered by Beijing's push to reduce reliance on chips from U.S. firms Nvidia and Advanced Micro Devices.  Founded by former AMD executives, MetaX raised roughly $600 million in an initial public ​offering last week, days after larger rival Moore Threads debuted with a 400% pop.  MetaX opened at 700 yuan a share in Shanghai versus an IPO price of ‌104.",
    "fullText": "SHANGHAI, Dec 17 (Reuters) - MetaX Integrated Circuits jumped 700% in its Shanghai market debut as the Chinese AI chipmaker tapped into strong momentum triggered by Beijing's push to reduce reliance on chips from U.S. firms Nvidia (NVDA) and Advanced Micro Devices (AMD).\n\nFounded by former AMD executives, MetaX raised roughly $600 million in an initial public ​offering last week, days after larger rival Moore Threads debuted with a 400% pop.\n\nMetaX opened at 700 yuan a share in Shanghai versus an IPO price of ‌104.66 yuan, before surging as high as 895 yuan, defying persistent AI bubble concerns in other markets. The stock ended the trading session at 829.9 yuan, up 693%.\n\n\"It's another IPO tale in China that turns a crow into ‌a phoenix,\" said fund manager Yang Tingwu at Tongheng Investment.\n\nThe price surge \"creates huge arbitrage opportunities\" for pre-IPO investors, Yang said, and \"we're likely witnessing the stock's peak level for the next five years\".\n\nMakers of artificial intelligence (AI) chips are rushing to sell shares in China to capitalise on interest generated by a government drive to boost local production in competition with the U.S.\n\n\"AI and semiconductors are key areas of competition in the Sino-U.S. tech rivalry,\" Guotai Haitong Securities said in a report ahead of MetaX's listing. \"Against the backdrop of geopolitical tension, AI chipmaking has huge growth potential,\" as China seeks to achieve self-sufficiency.\n\nResearcher ⁠Frost & Sullivan forecast China AI chip sales to top $189 billion ‌by 2029 versus $54 billion in 2026.\n\nMetaX, which makes graphics processing units (GPUs), raised 4.2 billion yuan ($596 million) last week in a share sale that was more than 4,000 times oversubscribed by retail investors.\n\nThe IPO - China's sixth biggest so far this year, according to KPMG - priced the money-losing ‍startup at 50 times its 2024 sales. That compared with a multiple of 34 for Nvidia and 14 for AMD, MetaX said in a pre-listing statement.\n\nMetaX's debut catapulted the value of the five-year-old startup to more than 300 billion yuan ($42.58 billion) and boosted the wealth of founder and major shareholder Chen Weiliang, 49.\n\nAfter working for AMD Shanghai for 13 years, Chen founded MetaX with a mission to \"contribute to China's rejuvenation ​and national prosperity.\" The founding team also included Peng Li and Yang Jian, both former AMD engineers.\n\n\"The company is a leading GPU maker in China thanks to its AMD gene,\" ‌Li Hui, analyst at Huajin Securities, said in a report ahead of MetaX's listing.",
    "readingTime": 3,
    "keywords": [
      "metax's listing",
      "yuan",
      "debut",
      "chips",
      "nvidia",
      "founded",
      "versus",
      "huge",
      "investors",
      "competition"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/chinese-ai-chipmaker-metax-shares-021911316.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31a670f1b4f9eeb6d6040fd6e99d7025",
    "created_at": "2025-12-18T00:53:21.627Z",
    "topic": "finance"
  },
  {
    "slug": "exclusivehow-china-built-its-manhattan-project-to-rival-the-west-in-ai-chips",
    "title": "Exclusive-How China built its ‘Manhattan Project’ to rival the West in AI chips",
    "description": "In a high-security Shenzhen laboratory, Chinese scientists have built what Washington has spent years trying to prevent: a prototype of a machine capable of producing the cutting-edge semiconductor chips that power artificial intelligence, smartphones and weapons central to Western military dominance, Reuters has learned.  It was built by a team of former engineers from Dutch semiconductor giant ASML who reverse-engineered the company's extreme ultraviolet lithography machines or EUVs, according to two people with knowledge of the project.  EUV machines sit at the heart of a technological Cold War.",
    "fullText": "SINGAPORE Dec 17 - In a high-security Shenzhen laboratory, Chinese scientists have built what Washington has spent years trying to prevent: a prototype of a machine capable of producing the cutting-edge semiconductor chips that power artificial intelligence, smartphones and weapons central to Western military dominance, Reuters has learned.\n\nCompleted in early 2025 and now undergoing testing, the prototype fills nearly an entire factory floor. It was built by a team of former engineers from Dutch semiconductor giant ASML who reverse-engineered the company's extreme ultraviolet lithography machines or EUVs, according to two people with knowledge of the project.\n\nEUV machines sit at the heart of a technological Cold War. They use beams of extreme ultraviolet light to etch circuits thousands of times thinner than a human hair onto silicon wafers, currently a capability monopolized by the West. The ​smaller the circuits, the more powerful the chips.\n\nChina's machine is operational and successfully generating extreme ultraviolet light, but has not yet produced working chips, the people said.\n\nIn April, ASML CEO Christophe Fouquet said that China would need \"many, many years\" to develop such technology. But the existence of this prototype, reported by Reuters for the first time, suggests China may be years closer to achieving semiconductor independence than analysts anticipated.\n\nNevertheless, China still faces major ‌technical challenges, particularly in replicating the precision optical systems that Western suppliers produce.\n\nThe availability of parts from older ASML machines on secondary markets has allowed China to build a domestic prototype, with the government setting a goal of producing working chips on the prototype by 2028, according to the two people.\n\nBut those close to the project say a more realistic target is 2030, which is still years earlier than the decade that analysts believed it would take China to match the West on chips.\n\nChinese authorities did not respond to requests for comment.\n\nThe breakthrough marks the culmination of a six-year government initiative to achieve ‌semiconductor self-sufficiency, one of President Xi Jinping's highest priorities. While China's semiconductor goals have been public, the Shenzhen EUV project has been conducted in secret, according to the people.\n\nThe project falls under the country's semiconductor strategy, which state media has identified as being run by Xi Jinping confidant Ding Xuexiang, who heads the Communist Party's Central Science and Technology Commission.",
    "readingTime": 2,
    "keywords": [
      "extreme ultraviolet",
      "ultraviolet light",
      "semiconductor",
      "prototype",
      "chips",
      "project",
      "asml",
      "machines",
      "chinese",
      "machine"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/exclusive-china-built-manhattan-project-141758929.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/0cc19b1160cf17f04eee9c546f657057",
    "created_at": "2025-12-18T00:53:20.454Z",
    "topic": "finance"
  },
  {
    "slug": "oracle-says-michigan-data-center-project-talks-on-track-without-blue-owl",
    "title": "Oracle says Michigan data center project talks on track without Blue Owl",
    "description": "Oracle said talks for an equity deal to support its Michigan data center project remain on schedule and do ​not include Blue Owl Capital, after a report of stalled negotiations with the crucial ‌partner knocked its shares down 5% on Wednesday.  The more than 1-gigawatt project in Saline Township, Michigan, is part of the ‌Stargate AI infrastructure push by Oracle and OpenAI.  Blue Owl, Oracle's largest data center partner, had been in talks to back the $10 billion deal but failed to reach agreement on terms that matched those of other projects ⁠it had already committed to, a ‌source familiar with the matter said.",
    "fullText": "Dec 17 (Reuters) - Oracle said talks for an equity deal to support its Michigan data center project remain on schedule and do ​not include Blue Owl Capital, after a report of stalled negotiations with the crucial ‌partner knocked its shares down 5% on Wednesday.\n\nThe more than 1-gigawatt project in Saline Township, Michigan, is part of the ‌Stargate AI infrastructure push by Oracle and OpenAI. Oracle said in late October that construction is slated to begin in early 2026.\n\nBlue Owl, Oracle's largest data center partner, had been in talks to back the $10 billion deal but failed to reach agreement on terms that matched those of other projects ⁠it had already committed to, a ‌source familiar with the matter said.\n\nThe project's existing leases and debt terms were less favorable than those Blue Owl structured in its other Oracle deals, ‍the source said, requesting anonymity because the talks were private.\n\nInvestors have scrutinized Oracle's AI infrastructure build-out in recent weeks as its debt climbs and its fortunes become increasingly tied to OpenAI. The ChatGPT maker, valued at ​about $500 billion, loses money and has not detailed how it would finance plans to spend more ‌than $1 trillion on infrastructure by 2030.\n\nOracle shares have fallen about 40% since mid-September, erasing gains from a rally sparked by its announcement of nearly $455 billion in booked cloud orders, most tied to OpenAI.\n\nThe stock has fallen 15% since last week's earnings report, which raised concerns about the payoff from its AI push.\n\n\"Our development partner, Related Digital, selected the best equity partner from a competitive ⁠group of options, which in this instance was not ​Blue Owl,\" an Oracle spokesperson said, declining to name the ​new partner or provide further details.\n\n\"We expect full construction to begin in the first quarter 2026 and to deliver the project on schedule,\" a Related Digital ‍representative said, adding the project ⁠drew \"significant\" interest from equity partners and that the firm evaluated all options.\n\nOracle has not signed a deal with a new backer, according to the Financial Times, which first reported ⁠the development.\n\nBlackstone Group has held talks as a potential financial partner but has not committed to invest, the report ‌said.\n\nBlackstone did not immediately respond to a request for comment.",
    "readingTime": 2,
    "keywords": [
      "blue owl",
      "related digital",
      "partner",
      "talks",
      "project",
      "equity",
      "deal",
      "infrastructure",
      "oracle",
      "center"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/oracles-10-billion-michigan-data-132428847.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/a0aeef8e6e93d19ed24475ee967d1843",
    "created_at": "2025-12-18T00:53:19.760Z",
    "topic": "finance"
  },
  {
    "slug": "oracles-ai-datacenter-woes-are-dragging-the-entire-stock-market-lower",
    "title": "Oracle's AI data-center woes are dragging the entire stock market lower",
    "description": "An update on Oracle's data center plans was the latest development giving investors anxiety about the health of the AI trade on Wednesday.",
    "fullText": "Another day, another update that's giving investors anxiety about the AI trade.\n\nThe US tech sector was under pressure on Wednesday as traders took in a report from The Financial Times that said Blue Owl Capital wouldn't back a $10 billion data center the company was planning to build in Michigan for OpenAI.\n\nOracle shares led the broader market lower, falling as much as 6% Wednesday. The tech-heavy Nasdaq Composite shed more than 1%.\n\nHere's where US indexes stood shortly around 1:00 p.m. ET on Wednesday:\n\nHere were the other notable moves in the market:\n\nThe latest developments extend a broader rotation out of the market's most expensive tech stocks and into other parts of the market.\n\nThe enthusiasm for AI has dampened particularly in the past week, Adam Turnquist, the chief technical strategist at LPL Financial, said on Wednesday.\n\n\"Additionally, rotation pressure out of tech has accelerated, with positioning data showing rising demand for smaller-cap and value stocks,\" Turnquist said of the latest market moves.\n\nThe FT's report said that talks between Oracle and Blue Owl Capital stalled over the planned data center. The private credit firm will not move forward with funding the project due to concerns about Oracle's hefty AI spending and growing debts, sources told the outlet.\n\nOracle disputed the contents of the FT report.\n\n\"The FT story is incorrect. Our development partner, Related Digital, selected the best equity partner from a competitive group of options, which in this instance was not Blue Owl. Final negotiations for their equity deal are moving forward on schedule and according to plan,\" Michael Egbert, a spokesperson for Oracle, told Business Insider in an email.\n\nIt's been a rough few months for the AI trade, but particularly for Oracle. After impressing investors with an aggressive revenue forecast, the stock has declined steadily in the last two months as the company stokes more concerns about the large amounts of debt coursing through the AI space. Shares are down 45% from their peak in early September.\n\nOracle recently triggered another sell-off in tech after reporting lower-than-expected earnings and pledging to increase its capital expenditures more than expected in the coming year.\n\nCoreWeave is the other prominent tech name to join Oracle recently as a poster child of investors' growing anxieties about the health of the AI trade. Similar to Oracle, CoreWeave has spooked investors with its high debt load and reliance on a handful of customers. As of Wednesday afternoon, the stock is down 66% from its post-IPO high reached in June.",
    "readingTime": 3,
    "keywords": [
      "blue owl",
      "owl capital",
      "oracle recently",
      "tech",
      "investors",
      "market",
      "another",
      "trade",
      "pressure",
      "center"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stock-market-news-oracle-stock-price-ai-data-center-blue-owl-2025-12",
    "thumbnail_url": "https://i.insider.com/6942de9264858d02d216f7b2?width=1200&format=jpeg",
    "created_at": "2025-12-18T00:53:18.383Z",
    "topic": "finance"
  },
  {
    "slug": "the-head-of-amazons-agi-team-is-leaving",
    "title": "The head of Amazon's AGI team is leaving",
    "description": "Rohit Prasad led Amazon efforts to build leading AI models. That hasn't happened so far, with the company's Nova models trailing rival offerings.",
    "fullText": "The executive who led Amazon's efforts to build top AI models is out.\n\nRohit Prasad, SVP and head scientist, is leaving two years after launching a new Artificial General Intelligence group.\n\nCEO Andy Jassy said Prasad plans to depart at the end of the year. Prasad was elevated to report directly to Jassy in 2023 to lead the AGI team, which was tasked with developing Amazon's \"most ambitious\" AI models, Business Insider reported at the time.\n\nSince then, Prasad helped launch Amazon's Nova family of AI models. Although Nova models earned some praise for their efficiency, they still trail frontier models such as OpenAI's GPT offerings, Anthropic's Claude Opus, and Google's Gemini.\n\nAs part of the shake-up, Amazon is creating a new organization under Peter DeSantis, AWS's SVP of Utility Computing, Jassy said. The group will oversee Amazon's AGI and AI model initiatives as well as its silicon chip and quantum computing efforts.\n\nJassy also said that Pieter Abbeel, the co-founder of robotics startup Covariant, who joined Amazon last year, will now lead the company's frontier AI model research team.\n\nPrasad's departure is the latest in a series of leadership changes at AWS. Over the past year, the company has seen several executives depart, including VP of AI Matt Wood and VP of generative AI Vasi Philomin, while bringing in new talent such as former Microsoft executive Julia White as chief marketing officer.\n\nAWS also recently hired David Richardson as VP of AgentCore and Joe Hellerstein as Vice President and Distinguished Scientist, and added Chet Kapoor as VP of security services and observability.\n\nHave a tip? Contact this reporter via email at ekim@businessinsider.com or Signal, Telegram, or WhatsApp at 650-942-3061. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "models",
      "executive",
      "efforts",
      "scientist",
      "depart",
      "lead",
      "team",
      "frontier",
      "computing",
      "model"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/amazon-agi-executive-leaving-ai-models-rohit-prasad-2025-12",
    "thumbnail_url": "https://i.insider.com/6942f91f64858d02d216fc27?width=1200&format=jpeg",
    "created_at": "2025-12-18T00:53:18.269Z",
    "topic": "finance"
  },
  {
    "slug": "openai-discussed-raising-tens-of-billions-at-valuation-of-about-750-billion-the-information-reports",
    "title": "OpenAI discussed raising tens of billions at valuation of about $750 billion, the Information reports",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/openai-discussed-raising-tens-of-billions-at-valuation-of-about-750-billion-the-information-reports-4413964",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBH00R_L.jpg",
    "created_at": "2025-12-18T00:53:14.871Z",
    "topic": "finance"
  },
  {
    "slug": "see-massive-adoption-of-ai-in-2026-jackson",
    "title": "See Massive Adoption of AI in 2026: Jackson",
    "description": "Plum Alley Founder and CEO Deborah Jackson says AI adoption will drive value in 2026. She speaks to Bloomberg's Romaine Bostick on 'Open Interest.'",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-17/see-massive-adoption-of-ai-in-2026-jackson-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iJGq5XXRhwJg/v3/-1x-1.jpg",
    "created_at": "2025-12-17T18:18:54.741Z",
    "topic": "finance"
  },
  {
    "slug": "seema-shah-sees-constructive-macro-backdrop-for-markets-in-2026",
    "title": "Seema Shah Sees 'Constructive Macro Backdrop' for Markets in 2026",
    "description": "Seema Shah, Principal Asset Management chief global strategist, discusses how she sees the macroeconomic landscape for markets in 2026 and the outlook for AI stocks on \"Bloomberg Open Interest.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-17/seema-shah-sees-constructive-macro-backdrop-in-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ics3sZmsuPCg/v3/-1x-1.jpg",
    "created_at": "2025-12-17T18:18:51.767Z",
    "topic": "finance"
  },
  {
    "slug": "oracleblue-owl-split-over-data-center-rattles-markets-banking-on-ai-boom",
    "title": "Oracle-Blue Owl Split Over Data Center Rattles Markets Banking on AI Boom",
    "description": "It’s becoming clear that even the slightest hint of trouble around data centers is enough to spook investors who are banking on the artificial-intelligence boom to power equity markets and provide a wave of debt deals in 2026.",
    "fullText": "TechnologyAIBy Paula Seligson and Preeti SinghSaveIt’s becoming clear that even the slightest hint of trouble around data centers is enough to spook investors who are banking on the artificial-intelligence boom to power equity markets and provide a wave of debt deals in 2026.The latest hiccup centers around Oracle Corp.’s financing for a data center in Michigan. While it’s largely moving along as expected, there’s a key difference: Blue Owl Capital, a longtime partner in its rapid AI infrastructure build-out, opted not to contribute equity.",
    "readingTime": 1,
    "keywords": [
      "centers",
      "equity"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-17/oracle-blue-owl-decoupling-rattles-markets-ahead-of-debt-deluge",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iTmnzNcoOyR8/v1/1200x800.jpg",
    "created_at": "2025-12-17T18:18:51.356Z",
    "topic": "finance"
  },
  {
    "slug": "wall-street-hit-by-tech-rout-as-ai-winners-tumble-markets-wrap",
    "title": "Wall Street Hit by Tech Rout as AI Winners Tumble: Markets Wrap",
    "description": "Volatility lashed Wall Street, pushing high-valuation tech stocks and crypto lower while bonds pared losses after a senior Federal Reserve official signaled room for rate cuts.",
    "fullText": "MarketsBy Rita NazarethSaveVolatility lashed Wall Street, pushing high-valuation tech stocks and crypto lower while bonds pared losses after a senior Federal Reserve official signaled room for rate cuts.A tech rout hit stocks amid skepticism about the artificial-intelligence trade. Nvidia Corp. led megacaps lower. Losses accelerated as the S&P 500 broke below a key technical level — even though most of its shares rose. The Nasdaq 100 lost over 1%. Micron Technology Inc. will report earnings after the close.",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "lower",
      "losses",
      "tech"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-16/stock-market-today-dow-s-p-live-updates",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ifFzM2GfM2NA/v0/1200x675.png",
    "created_at": "2025-12-17T18:18:48.287Z",
    "topic": "finance"
  },
  {
    "slug": "the-last-of-us-codirector-i-dont-like-ai",
    "title": "The Last Of Us Co-Director: \"I Don't Like AI\"",
    "description": "The Last of Us co-director Bruce Straley has shared his thoughts on using generative AI to aid in game development, saying the technology cannot \"grow and think for itself.\"\nThe technology \"just consumes, and tries to mimic what it's consumed,\" he told Polygon. \"That's the best it can do right now.\" He also described generative AI as \"a snake eating its own tail.\"\nOne of the reasons why AI has been such a contentious issue in gaming is that not everyone defines it the same way.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/the-last-of-us-co-director-i-dont-like-ai/1100-6537043/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4624665-screenshot2025-12-17at9.40.58%E2%80%AFam.png",
    "created_at": "2025-12-17T18:18:47.533Z",
    "topic": "gaming"
  },
  {
    "slug": "why-outcomebilling-makes-sense-for-ai-agents",
    "title": "Why outcome-billing makes sense for AI Agents",
    "description": "'Digital worker' is, in fact, a fitting neologism for the AI agent...",
    "fullText": "Hey AI Agent Developer - yes, you. What is the value you create? Let's find out.\n\nThe Skeptic's Take: Useful vs. Intelligent\n\nOn the spectrum of \"Is AI intelligent and able to reason?\", I fall on the skeptical side. But is it useful? Absolutely. We have built a few AI workflows, and they have unlocked superior automation. Evidently, the world is currently witnessing the transformative potential of AI agents in customer support and coding, to some degree.\n\nTake customer support, for instance. If AI agents help each support employee handle 30% more tickets, that's like adding 30 new hires to a 100-person team, without the cost. For a $100M company, this efficiency gain could translate to $20-30M in additional enterprise value (EV), under sweeping assumptions. The difference in EV between pre- and post-AI agents is the Value you create. Alternatively, one could also use operating income for a flow perspective.\n\n'Digital worker' is, in fact, a fitting neologism for the AI agent. I take the view here that human workers, together with digital workers, can do more, creating abundance. As AI agent developers, we should be asking:\n\nOutcomes Matter. Internals Don't.\n\nThere are two parts to our first question: First, what an AI agent or a workflow does internally, for instance, the number of reasoning steps involved, is irrelevant. However, measuring outcomes such as the number of support tickets resolved or the number of successful hires is directly proportional to the value we want to measure. Second, what share do we take? Simply going by the 10x rule of SaaS pricing guidelines, we can claim one-tenth of what we measured. Thus, measuring outcomes becomes imperative. We have built Valmi to ingest outcomes as the first step. The added complexity that Valmi addresses is where legacy billing systems sputter.\n\nWhy Legacy Billing Systems Don't Cut It\n\nLet's start with the cost argument. Building AI systems is expensive. There are ineffective paths in workflows and autonomous agents that simply fail. LLM costs hit COGS linearly, whereas the marginal cost in traditional SaaS systems is negligible. SaaS generates ~70% gross margins. While cost is an important element in the case of AI agents, legacy systems, such as Stripe and Zuora, are inadequate to capture it.\n\nSecondly, the pricing model. The seat-based model works against selling AI agents, since the seat-based model is under attack from two forces. One is the decrease in the number of human workers required. By pricing against seats, you are setting your AI agents up for decline, not for growth. The other is worse: It does not capture the human-equivalent value, as discussed above. Even the usage-based models that legacy systems support do not distinguish between activity and outcomes.\n\nTo effectively price AI agents, we need to measure outcomes, and observe and allocate costs. To evaluate margin contraction, we also need to understand where outcomes and costs diverge, including in aggregate, for which agents and for which customer instances. Therefore, the top AI agent developers who use outcome-billing, such as Harvey, Sierra and Usepropane, put together two sources: one to track cost information and the other to measure value. And they unified these two sources of information in a single system. Valmi helps you do that very easily. You can bring up the whole billing infrastructure on your premises. We have made it available under a permissive license. No need to do it yourself.\n\nThe Unreliability Problem (And How to Sell Despite It)\n\nOutcome measurement serves a greater purpose. AI is unreliable and not deterministic. We simply do not understand when it succeeds and when it fails. Consequently, it is incumbent upon the buyer of your AI agents to demand proof of value. It is simply easier for you to convince and onboard buyers if you switch to outcome-billing. Why? You assume the risk of failure of your AI agents. But, the buyer simply pays for agent's performance and pays nothing for its failure. To prove the value and help you convince your buyers, Valmi supports customer dashboards that show outcomes such as ticket resolution percentage. Your buyers can view and embed these dashboards in their workflows.\n\nTo sum it up, we have built Valmi, and made available open-source SDKs and free to deploy packages, to address the imperative for your AI agents. It solves outcome-billing that provides proof of value and cost tracking that exposes margin contraction. It lets you simulate and set prices for your AI agents and quickly onboard your customers. We understand hybrid models, combining seat-based, activity and outcomes, will be required in the transitory phase of billing models. Valmi supports all of these as well. Try it out for free or deploy it within your premises.",
    "readingTime": 4,
    "keywords": [
      "valmi supports",
      "margin contraction",
      "human workers",
      "seat-based model",
      "agent developers",
      "legacy billing",
      "measuring outcomes",
      "billing systems",
      "agents",
      "simply"
    ],
    "qualityScore": 1,
    "link": "https://www.valmi.io/blog/an-imperative-for-ai-agents-outcome-billing-with-valmi/",
    "thumbnail_url": "https://www.valmi.io/blog/content/images/2025/12/Group-1-2.png",
    "created_at": "2025-12-17T18:18:40.222Z",
    "topic": "tech"
  },
  {
    "slug": "bernie-sanders-wants-to-temporarily-halt-ai-data-center-construction-nationwide",
    "title": "Bernie Sanders wants to temporarily halt AI data center construction nationwide",
    "description": "\"This moratorium will give democracy a chance to catch up with the transformative changes that we are witnessing,\" Sanders said.",
    "fullText": "Sen. Bernie Sanders wants to put a halt to the multi-trillion-dollar AI infrastructure buildout — at least for now.\n\nIn a video posted to social media on Tuesday, the Vermont senator and two-time presidential candidate said he would begin pushing for a national moratorium on the construction of AI data centers.\n\nHe argued that AI, which he called one of the most \"transformative technologies in the history of humanity,\" is moving too rapidly for lawmakers and citizens to keep up.\n\n\"This moratorium will give democracy a chance to catch up with the transformative changes that we are witnessing and make sure that the benefits of these technologies work for all of us, not just the wealthiest people on Earth,\" Sanders said.\n\nWhile Sanders is not the only AI critic on Capitol Hill, his planned proposal would go further than most. He is likely the first national politician to call for a moratorium on the construction of data centers, which are the primary infrastructure needed to support the expansion of AI.\n\nMajor tech firms like Amazon, Meta, Microsoft, Google, and Apple have collectively spent hundreds of billions of dollars in 2025 on capital expenditures — much of it going toward the chips, servers, and data centers that form the backbone of the AI boom. And they've told investors that they expect to spend even more AI spending in 2026.\n\n\"This process is moving very, very quickly, and we need to slow it down,\" Sanders said. \"We need all of our people, all of our people involved in determining the future of AI, and not just a handful of multi-billionaires.\"\n\nI will be pushing for a moratorium on the construction of data centers that are powering the unregulated sprint to develop & deploy AI.\n\nThe moratorium will give democracy a chance to catch up, and ensure that the benefits of technology work for all of us, not just the 1%. pic.twitter.com/PoV5ziA4oQ\n\nThe Democratic socialist senator listed three major reasons for slowing down the advancement of AI: the fact that it's being promoted by wealthy tech titans, the potential for AI-driven job losses, and the technology's impact on human interaction.\n\n\"Think for a moment about a future when human beings are not interacting with each other and are spending virtually all of their time with devices instead of people,\" Sanders said. \"Is that the kind of future you want? Well, not me.\"\n\nAt this point, it's unlikely that Sanders's vision comes to fruition.\n\nPresident Donald Trump's administration has taken the opposite path, encouraging the rapid construction of data centers in a bid to win the AI race with China.\n\nBut skepticism of AI is continuing to grow on Capitol Hill, with some lawmakers warning about a potential AI bubble and others aiming to limit minors' use of AI chatbots.",
    "readingTime": 3,
    "keywords": [
      "democracy chance",
      "capitol hill",
      "moratorium",
      "centers",
      "construction",
      "infrastructure",
      "senator",
      "pushing",
      "transformative",
      "technologies"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bernie-sanders-ai-data-center-construction-moratorium-pause-2025-12",
    "thumbnail_url": "https://i.insider.com/6942c69964858d02d216f331?width=1200&format=jpeg",
    "created_at": "2025-12-17T18:18:39.641Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-inspiring-companies-to-adopt-skillsbased-hiring",
    "title": "How AI is inspiring companies to adopt skills-based hiring",
    "description": "AI is accelerating the shift toward skills-based hiring, and in the process reshaping how companies go about recruiting.",
    "fullText": "Artificial intelligence is driving a shift in what companies look for in new hires.\n\nWhile experience has always been a key factor for job seekers, education level matters less and less compared to skill set, enabling companies to \"expand their talent pipelines and keep pace with roles that evolve faster than traditional education can,\" says Lauren Winans, CEO at human resources consulting firm Next Level Benefits.\n\nAI is accelerating the trend, as more organizations seek data science, machine learning, data analytics, and related skills — skills that you essentially learn through doing and repetition, not by going to class.\n\nIndeed, several companies, including Google and IBM, have dropped their degree requirements for some roles in favor of skills-based hiring.\n\nPlus, a quarter of employers said they planned to stop requiring bachelor's degrees this year, instead prioritizing relevant experience, according to a 2025 ResumeTemplates survey of 1,000 US hiring managers.\n\nSkills-based hiring is an \"operational necessity,\" as organizations adopt AI initiatives and require staff to design, build, and manage AI systems and processes, says Anthony Donnarumma, CEO of the recruiting agency 24 Seven.\n\nPlus, relying on skills over degrees reduces the time it takes to fill roles and improves productivity because applicants are \"job-ready,\" he says.\n\nIt also helps organizations remain agile and adapt to changing demands, adds Lisa Highfield, principal director of research and advisory services at McLean & Company, an HR research and consulting firm.\n\nA skills-based approach creates new opportunities for employees, too, Highfield says. It can increase workforce diversity and create paths for career advancement, Winans adds.\n\n\"Workers are able to compete on the value of their skills — not their resume format or educational history — which can lead to better job matches, higher engagement, and longer-term career growth,\" Donnarumma says.\n\nAt the other end, AI-based screening and hiring tools are offering companies ways to automate skill-based hiring, says Kara Ayers, senior vice president of global talent acquisition for Xplor Technologies, a payment and commerce software company that's already made the shift, prioritizing skills, experience, and potential over college degrees in its new hires — and using AI to do it.\n\nXplor Technologies began using the AI-powered applicant tracking system SmartRecruiters in 2022 to help them organize and classify the skills needed for each role, Ayers says.\n\n\"These tools allow us to analyze resumes and profiles for competencies rather than filtering by degree, and we use AI-driven predictive analytics to match candidates based on skills alignment and potential,\" she explains.\n\nSince adopting this approach, Ayers says the company has reduced its reliance on recruiting agencies, saving about $3 million. It also fills roles faster — often in under 30 days, compared to more than 60 days in the past — and has improved the quality of new hires, who are now better matched to a role's competencies.\n\nThat said, using AI to review applicants based on skills depends on organizations having \"a clean, well-structured framework, consistent job architecture, reliable performance data, and HR systems that can integrate skills analytics into hiring workflows,\" Winans says.\n\nThey also need data showing the skills they already have and what they need for the future, Highfield says. And historical workforce data showing how people succeed within the company, Donnarumma adds.\n\nTransitioning to skills-based hiring can be time and resource-intensive, Highfield says. Leadership teams also may need to rethink their traditional hiring practices and beliefs about the value of degrees, Donnarumma says.\n\nAI gives companies tools to build a process that's \"more accurate, more inclusive, and far more aligned with the future of work,\" Donnarumma says.\n\nHowever, AI bias remains a \"real concern,\" he says. Organizations must incorporate governance into AI-driven hiring, including ensuring team members understand AI and can manage its use effectively and objectively.\n\nAyers says it's crucial to highlight the benefits of AI while also emphasizing governance.\n\n\"It is important to be thoughtful about how AI is used and to thoroughly vet the tools in place,\" she says. \"Both candidates and companies should maintain authenticity and find the right balance in how much they rely on AI.\"",
    "readingTime": 4,
    "keywords": [
      "consulting firm",
      "skills-based hiring",
      "xplor technologies",
      "organizations",
      "roles",
      "degrees",
      "tools",
      "hires",
      "experience",
      "analytics"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-accelerating-trend-job-hires-college-degrees-matter-less-2025-12",
    "thumbnail_url": "https://i.insider.com/69402a2304eda4732f2d84d9?width=1200&format=jpeg",
    "created_at": "2025-12-17T18:18:39.456Z",
    "topic": "finance"
  },
  {
    "slug": "universities-risk-becoming-passive-arms-of-silicon-valley-if-they-dont-question-how-ai-shapes-truth-a-professor-says",
    "title": "Universities risk becoming passive arms of Silicon Valley if they don't question how AI shapes truth, a professor says",
    "description": "A professor says colleges risk losing autonomy as AI deals and corporate agendas shape teaching, assessment, and how students learn to think.",
    "fullText": "Universities risk surrendering their intellectual autonomy to Silicon Valley's influence as they rush to adopt AI, one professor says.\n\nIn an essay for the Civics of Technology Project — an education platform analyzing technology's societal impact — Bruna Damiana Heinsfeld, an assistant professor of learning technologies at the University of Minnesota, said that colleges are allowing Big Tech to reshape what counts as knowledge, truth, and academic value.\n\nFrom multimillion-dollar partnerships with AI vendors to classrooms infused with corporate branding, she said, universities are shifting toward a model where technological tools are bundled with the identity of the companies behind them.\n\nAs academic leaders scramble to look \"AI-ready,\" Heinsfeld warned that the sector is drifting from critical inquiry toward compliance, risking a future in which Silicon Valley, not educators, sets the terms of learning.\n\nHeinsfeld said AI tools promote a worldview where efficiency is presumed to be a virtue, scale is inherently desirable, and data becomes the default language of truth.\n\nUniversities adopting these systems without critical examination risk teaching students that the logic of Big Tech is not merely useful but inevitable, she added.\n\nHeinsfeld pointed to California State University as an example of that shift on full display.\n\nThe university signed a $16.9 million contract in February to roll out ChatGPT Edu across 23 campuses, providing more than 460,000 students and 63,000 faculty and staff with access to the tool through mid-2026.\n\nIt hosted an AWS-powered \"AI camp\" in the summer, where students arrived to find Amazon branding everywhere, including corporate slogans, AWS notebooks, and promotional swag.\n\nAnother academic said the problem is already playing out in the day-to-day mechanics of learning.\n\nKimberley Hardcastle, a business and marketing professor at Northumbria University in the UK, told Business Insider that universities must overhaul how they design assessments now that students' \"epistemic mediators\" — the tools that help them make sense of the world — have fundamentally changed.\n\nHardcastle advocates requiring students to demonstrate their reasoning: how they arrived at a conclusion, which sources they consulted beyond AI, and how they verified information against primary evidence, she said.\n\nShe said students also need deliberate \"epistemic checkpoints,\" moments designed into coursework where they must pause and ask: \"Am I using this tool to enhance my thinking or replace it? Have I engaged with the underlying concepts or just the AI's summary? Do I understand, or am I just recalling information?\"\n\nFor Heinsfeld, the risk is that corporations will dictate what constitutes legitimate knowledge. For Hardcastle, it's that students will no longer understand how to assess truth for themselves.\n\nBoth say universities must remain the space where students are taught to think, not just how to operate tools.\n\n\"Education should remain the space where we confront the architectures of our tools,\" Heinsfeld wrote. Otherwise, \"it risks becoming the laboratory of the very systems it should critique.\"\n\nHardcastle made a similar point, adding that this future will be shaped not only by institutional decisions but by every moment a student accepts an AI-generated answer without knowing how to question it.",
    "readingTime": 3,
    "keywords": [
      "big tech",
      "students",
      "universities",
      "tools",
      "risk",
      "professor",
      "learning",
      "truth",
      "academic",
      "education"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/universities-risk-ceding-control-to-big-techs-ai-push-2025-12",
    "thumbnail_url": "https://i.insider.com/69413efe832e0ef1ead646f0?width=1200&format=jpeg",
    "created_at": "2025-12-17T18:18:39.304Z",
    "topic": "finance"
  },
  {
    "slug": "the-creator-of-anthropics-claude-code-likes-to-hire-engineers-who-do-side-quests-like-making-kombucha",
    "title": "The creator of Anthropic's Claude Code likes to hire engineers who do 'side quests' like making kombucha",
    "description": "Claude Code creator Boris Cherny said that he looked for engineers with \"cool weekend projects.\" Anthropic is also looking for \"generalists,\" he said.",
    "fullText": "Want a job at Anthropic? It might help to get a hobby.\n\nThe AI boom is changing the job requirements for an engineer. Not only do they need to have coding skills, but they also must know how to operate vibecoding tools and stay up to date with new AI models.\n\nAnthropic leader Boris Cherny looks for something else: \"Side quests.\"\n\n\"When I hire engineers, this is definitely something I look for,\" he said on \"The Peterman Pod.\"\n\nCherny's definition of side quests includes \"cool weekend projects,\" like someone who's \"really into making kombucha.\" It's a sign that the engineer is curious and interested in other things, he said.\n\nMuch of Cherny's own growth came from his side projects. Cherny is now a key figure at Anthropic. He created Claude Code, a tool that is now popular with engineers across the country.\n\n\"These are well-rounded people,\" he said. \"These are the kind of people I enjoy working with.\"\n\nCherny also said he prefers that his new hires be \"generalists.\"\n\nHe gave the example of an engineer who can code, but is also able to work on product and design. That all-star engineer also seeks out user feedback.\n\n\"This is how we recruit for all functions, now,\" he said. \"Our project managers code, our data scientists code, our user researcher codes a little bit.\"\n\nCherny isn't alone in pushing for jobs to become more generalist. Figma CEO Dylan Field said in October that AI was causing job titles to merge, resulting in everyone being a \"product builder.\"\n\nWhat else is Anthropic looking for? For some time, it monitored whether candidates use AI in their applications.\n\nIn May, Business Insider reported that Anthropic asked candidates for certain jobs not to use AI in their written responses so the company could test their \"non-AI-assisted communication skills.\"\n\nAnthropic changed its policy in July, allowing candidates to seek out assistance from Claude.\n\nFor the younger engineers, a job at Anthropic may be hard to come by. In May, CPO Mike Krieger said on \"Hard Fork\" that he was focused on hiring experienced engineers — and had \"some hesitancy\" with entry-level workers.\n\nOn the podcast, Cherny said that his love of generalists came from his career trajectory. Working at startups since 18, Cherny had to do everything, he said.\n\n\"At big companies, you get forced into this particular swim lane,\" he said. \"It's just so artificial.\"",
    "readingTime": 2,
    "keywords": [
      "engineer",
      "engineers",
      "candidates",
      "anthropic",
      "skills",
      "else",
      "quests",
      "projects",
      "it's",
      "generalists"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropic-claude-code-creator-hires-engineers-generalists-weekend-projects-2025-12",
    "thumbnail_url": "https://i.insider.com/6942bb1c832e0ef1ead65d40?width=1200&format=jpeg",
    "created_at": "2025-12-17T18:18:39.242Z",
    "topic": "finance"
  },
  {
    "slug": "doug-mcmillon-shares-his-final-reading-list-as-walmart-ceo-with-topics-from-ai-to-basketball-to-china",
    "title": "Doug McMillon shares his final reading list as Walmart CEO, with topics from AI to basketball to China",
    "description": "Doug McMillon, Walmart's CEO, shared his annual reading list, with 11 books that cover a broad range of topics in business and beyond.",
    "fullText": "NYU professor David Hollander delves into 13 principles derived from the game of basketball that can address some of the most pressing global challenges. It also happens to be McMillon's favorite sport.\n\nWalmex regional CEO Guilherme Loureiro teams up with executive coach Carlos Marin to explore how leaders can bring about organizational change by first starting with personal change.\n\nIBM design guru Phil Gilbert details how the tech company reinvented its culture for the 21st Century, a process that required earning the buy-in of more than 400,000 people across 180 countries.\n\nHarvard leadership professor Arthur C. Brooks draws on dozens of interviews and interdisciplinary research from social science, philosophy, and theology to examine how ambitious people can make their years after middle age more fulfilling.\n\nPalantir cofounder Alex Karp and his deputy, Nick Zamiska, argue that Silicon Valley has let down the US and its Western allies in pursuit of a shallow — yet lucrative — vision of technology.\n\nLinkedIn cofounder Reid Hoffman explores how AI can be used in more inclusive ways to shape the world for the better, inviting readers to view AI more as an opportunity than a threat.\n\nFounder and former CEO of Fair Trade USA, Paul Rice, digs into how businesses and consumers can improve the world through more conscious decisions about sourcing and consumption.\n\nVCs Mike Maples and Peter Ziebelman bring lessons from early-stage startups to a wider audience, including how to develop truly novel ideas and put those concepts into real action.\n\nFollowing his graduation from Columbia University, Zak Dychtwald spent the next several years immersed in young adult Chinese culture. His book explores how the post-1990 generation of Chinese people is poised to shape the globe.\n\nInternational Institute for Management Development professors Nie, Green, and Feng are joined by City University of Hong Kong professor Wang to illustrate China's impact on global retail through a deep comparative analysis of case studies.\n\nCNBC \"Mad Money\" host Jim Cramer's latest book aims to help average investors perform like top-tier wealth managers with advice about how to better understand the market and identify the right combination of growth and income stocks.",
    "readingTime": 2,
    "keywords": [
      "professor",
      "culture",
      "cofounder",
      "explores",
      "shape",
      "chinese",
      "book",
      "university"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/walmart-ceo-doug-mcmillon-shares-his-final-reading-list-2025-12",
    "thumbnail_url": "https://i.insider.com/6942cc1304eda4732f2dad66?width=1200&format=jpeg",
    "created_at": "2025-12-17T18:18:39.096Z",
    "topic": "finance"
  },
  {
    "slug": "planesfyi-3d-aircraft-and-airport-visualizations",
    "title": "Planes.fyi – 3D aircraft and airport visualizations",
    "description": "Revolutionary AI camera system tracking aircraft and decoding ATC communications in real-time",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://planes.fyi",
    "thumbnail_url": "https://planes.fyi/og-image.jpg",
    "created_at": "2025-12-17T18:18:38.935Z",
    "topic": "tech"
  },
  {
    "slug": "how-chatgpts-new-image-generator-stacks-up-against-geminis-nano-banana-pro",
    "title": "How ChatGPT's New Image Generator Stacks Up Against Gemini's Nano Banana Pro",
    "description": "Get ready for the battle of the next-gen AI image editors.",
    "fullText": "Following the major image editing upgrades added to Google Gemini back in August—under the whimsical codename Nano Banana—it's OpenAI's turn to supercharge the tools you get for image manipulations inside ChatGPT. The new update is called GPT Image 1.5, and is rolling out now for all users.\n\nOne of the key improvements here, as was the case with Nano Banana, is the way that ChatGPT can now edit a specific part of an image while keeping everything else consistent. You can add or remove something, or change the color or style of something, without ending up with an entirely different looking picture.\n\nAnother feature ChatGPT has now borrowed from Gemini: the ability to combine multiple images together in one scene. Want you and your best friend in front of Sydney Harbour Bridge? No problem—just supply the source pictures and the AI will do the rest. You can also change visual styles while maintaining consistent details.\n\nOpenAI says the new image editor and generator is able to follow instructions \"more reliably,\" and render pictures up to four times faster than before. Text can be more varied in style and size, and images should be more realistic and error-free in general—though OpenAI also admits there's still room for improvement.\n\nIt's the best image generator tool we've ever seen in ChatGPT, and it all looks impressive at first glance—but how does it stack up in practice against Gemini and Nano Banana? I put the two models to the test via the $20-per-month plan on both platforms (that's ChatGPT Plus and Google AI Pro, respectively) to see how they compared.\n\nOpen up ChatGPT on the web or on mobile and you'll see there's a new Images tab on the left-hand navigation pane. This takes you to a library of your existing pictures, together with some new prompts for creating images. You get some suggestions for prompts, plus an assortment of preset portrait image styles you can apply.\n\nI tested out the new GPT Image 1.5 model by getting ChatGPT to generate a busy tech journalist, a lamp in the middle of an empty warehouse, and a cartoon-style rolling landscape of hills in the fog. I then got Gemini to create the same pictures with the same prompts. While the results were pretty varied, in terms of quality and realism they were pretty equal—the occasional issue with weird physics and repetition, but nothing too bad.\n\nBoth ChatGPT and Gemini are now quite competent at clean image edits, too: Both AI bots seamlessly switched the journalist's clothing to a shirt and tie without touching any other part of the picture. This would have taken a significant amount of time to do manually, even by a Photoshop expert, and shows just how transformative AI imaging is becoming.\n\nColor changes were all handled with aplomb, but the AIs struggled a bit with perspective changes, where I asked to see the same shot from another angle. In these cases, instructions were less well-followed and the images were less consistent (as new areas needed to be rendered), though ChatGPT did a little better than Gemini at getting good results.\n\nThe classic \"remove an object from this picture\" challenge was handled with aplomb: Both Gemini and ChatGPT were able to remove a cottage from the countryside scene with surgical precision, leaving everything else intact. Again, these are the kind of time-intensive image edits that would previously have needed a lot of careful effort, and that can now be done in seconds.\n\nAnother talent ChatGPT and Gemini now have is being able to combine images together. So you can have separate photos of you and your parents, put them together in the same shot, and then add in a background of wherever you like. You can get perfect family photos without actually gathering together your relatives together or going anywhere.\n\nThis was an area where Gemini and ChatGPT did struggle a bit more: The editing dexterity was still impressive, but the results didn't always look like a single, coherent scene. Lighting is sometimes off, or elements from different images appear at different scales, and you'll have to do a bit more tweaking and editing and reprompting to get everything right.\n\nChatGPT did fare slightly better at blending different images and elements together, and changing the overall look of a picture. When I tried to get the AIs to mix all my images together in a moody film noir shot, ChatGPT produced something pretty consistent—the Gemini effort looked a lot more like a cut-and-paste job.\n\nIt can be fun remixing photos again and again—adding new people, changing the weather, moving the location—and both these bots are now capable of some rather incredible results. Remixing photos of family and friends will be popular, but it's not all that easy: With people you know, any generative AI that gets added tends to look wrong, because neither ChatGPT nor Gemini knows exactly what these people look like, how they smile, how they're built, or how they tend to stand or sit.\n\nIn terms of ChatGPT vs. Gemini, they're both at a high level now—a level that puts advanced Photoshop-style editing capabilities at everyone's fingertips. If either AI model has the edge right now, it's ChatGPT's, but there's not much in it. It's also going to be fascinating to see where these image editing capabilities go next.",
    "readingTime": 5,
    "keywords": [
      "everything else",
      "remixing photos",
      "editing capabilities",
      "images together",
      "gpt image",
      "chatgpt",
      "pictures",
      "look",
      "gemini",
      "consistent"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/how-chatgpt-image-generator-compares-to-gemini-nano-banana-pro?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KCP5SAZ4857YBA7YYJT5Q95G/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-17T18:18:37.349Z",
    "topic": "tech"
  },
  {
    "slug": "the-stock-market-is-being-powered-by-10-stocks-that-are-fueling-ai-bubble-fears",
    "title": "The stock market is being powered by 10 stocks that are fueling AI bubble fears",
    "description": "The biggest stocks in the world just keep getting bigger.",
    "fullText": "If you're in the \"stock market is in a bubble\" camp, look no further than the composition of the S&P 500 (^GSPC).\n\nThe top 10 stocks now account for roughly 32% of S&P 500 earnings and over 41% of total market capitalization — levels not seen since at least 1980, according to new data from Barclays strategist Venu Krishna.\n\nThe \"Magnificent Seven\" stocks have been the primary driver of this market power concentration, along with Broadcom (AVGO), JP Morgan (JPM), and Berkshire Hathaway (BRK-B). The Mag 7 companies — Microsoft (MSFT), Amazon (AMZN), Alphabet (GOOGL), Meta (META), Tesla (TSLA), Nvidia (NVDA), and Apple (AAPL) — are essentially fueling the artificial intelligence boom.\n\nThese seven stocks are up on average 21% this year compared to a 15% gain for the S&P 500, according to Yahoo Finance data. Alphabet is the top performer with an advance of 62% amid optimism on its new Gemini 3 model.\n\nIn turn, the valuation of the S&P 500 has reached a level even most bulls would agree is on the rich side. Krishna's work reveals the S&P 500 is trading at the 91st percentile relative to its 10-year valuation history.\n\n\"Complacency\" could ignite an AI bubble, Deutsche Bank strategist Adrian Cox told me on Yahoo Finance's Opening Bid (video above).\n\nIndeed, complacency appears to have settled in, despite the risks investors had to endure this year.\n\nRemember the \"Liberation Day\" tariff spectacle in April? The S&P 500 tanked 4.8% the day after President Trump unveiled sweeping tariffs on April 2. The Dow Jones Industrial Average (^DJI) dropped a staggering 1,679 points.\n\nTariffs are now in effect, though they are not as severe as first advertised.\n\nAnd more recently, disappointments from AI darlings CoreWeave (CRWV) and Oracle (ORCL) have begun to call into question the near-term outlook for the AI trade.\n\n\"I think we're going to see some pretty massive bifurcation in 2026 in the AI trade,\" Sevens Report Research founder Tom Essaye said on Opening Bid.\n\nAlphabet is Essaye's top AI pick for 2026, though he acknowledges there are likely to be winners and losers from the Magnificent Seven complex next year.\n\n\"I think companies like Oracle that [are] not overextended financially but are sort of raising eyebrows with a lot of the spending that is tied to open AI, I think that companies like that could struggle,\" Essaye added. \"There's going to be some pretty serious bifurcation. We've seen it in the last, say, two months of 2025. I think that gets worse in 2026.\"",
    "readingTime": 3,
    "keywords": [
      "market",
      "stocks",
      "bubble",
      "strategist",
      "meta",
      "average",
      "valuation",
      "complacency",
      "tariffs",
      "oracle"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/the-stock-market-is-being-powered-by-10-stocks-that-are-fueling-ai-bubble-fears-142845016.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/46dKsKBpZWVD7GST32q4_Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/756f6dd0-db32-11f0-b8c3-107720e7b063",
    "created_at": "2025-12-17T18:18:34.945Z",
    "topic": "finance"
  },
  {
    "slug": "from-nvidia-to-openai-silicon-valley-woos-westminster-as-expoliticians-take-tech-firm-roles",
    "title": "From Nvidia to OpenAI, Silicon Valley woos Westminster as ex-politicians take tech firm roles",
    "description": "Commons committee monitoring revolving door that gave jobs to George Osborne, Nick Clegg and Tony Blair\nWhen the billionaire chief executive of AI chipmaker Nvidia threw a party in central London for Donald Trump’s state visit in September, the power imbalance between Silicon Valley and British politicians was vividly exposed.\nJensen Huang hastened to the stage after meetings at Chequers and rallied his hundreds of guests to cheer on the power of AI. In front of a huge Nvidia logo, he urged the venture capitalists before him to herald “a new industrial revolution”, announced billions of pounds in AI investments and, like Willy Wonka handing out golden tickets, singled out some lucky recipients in the room.\n Continue reading...",
    "fullText": "Commons committee monitoring revolving door that gave jobs to George Osborne, Nick Clegg and Tony Blair\n\nWhen the billionaire chief executive of AI chipmaker Nvidia threw a party in central London for Donald Trump’s state visit in September, the power imbalance between Silicon Valley and British politicians was vividly exposed.\n\nJensen Huang hastened to the stage after meetings at Chequers and rallied his hundreds of guests to cheer on the power of AI. In front of a huge Nvidia logo, he urged the venture capitalists before him to herald “a new industrial revolution”, announced billions of pounds in AI investments and, like Willy Wonka handing out golden tickets, singled out some lucky recipients in the room.\n\n“If you want to get rich, this is where you want to be,” he declared.\n\nBut his biggest party trick was a surprise guest waiting in the wings. At Huang’s cue, the British prime minister, Keir Starmer, walked out as the crowd whooped at Huang’s pulling power.\n\nStarmer, looking slightly dazed, saluted his host’s “absolutely phenomenal” presentation, told the audience about how he had been “texting away” with Huang and effusively thanked one of the world’s richest men for his “confidence in what we are doing, in your investment, your foresight”. Huang sent him away with a gift: an inscribed AI processing unit.\n\nNot done, Huang called on to the stage Liz Kendall, the secretary of state for science, innovation and technology, followed by Peter Kyle, the secretary of state for business. The parade of British cabinet ministers at this private Nvidia event spoke volumes about how successfully US tech oligarchs have pulled British politicians – serving and former – into their orbit.\n\nThis week, they landed another big fish. The $500bn Chat GPT maker Open AI hired the former chancellor of the exchequer George Osborne, prompting him to gush he was joining “the most exciting and promising company in the world”.\n\nHe was just the latest senior figure to pass through the revolving door between Westminster and Silicon Valley. In October, the former Conservative prime minister Rishi Sunak took advisory roles with Anthropic, one of OpenAI’s main rivals, and with Microsoft, which has invested heavily in both AI startups. Liam Booth-Smith, Sunak’s chief of staff, who sits in the House of Lords, also this summer took a senior role at Anthropic after it signed a memorandum of understanding with the UK government.\n\nThey followed the former Liberal Democrat deputy prime minister Nick Clegg, who spent seven years leading public affairs for Mark Zuckerberg at Meta, which runs Instagram and Facebook. Clegg is now an AI investor who last week predicted “we will move from staring at the internet to living in the internet”. He made tens of millions of dollars at Meta. Some reports said as much as $100m. He would not confirm that but said he was paid “extremely well”.\n\nMeanwhile, Tony Blair, prime minister for a decade until 2007, is becoming increasingly influential on technology policy, lobbying successfully, through his Tony Blair Institute (TBI), for the UK to introduce a digital ID.\n\nTBI is part-funded by the foundation of Larry Ellison, the founder and chief executive of Oracle. A former TBI policy expert, Kirsty Innes, recently became a special adviser to Kendall.\n\nThe Commons science, innovation and technology select committee is monitoring the revolving door situation. Alex Sobel MP, a member of parliament’s joint committee on human rights, which is currently investigating AI, said: “I am deeply concerned tech companies may be using their huge buying power to water down much-needed regulation by hiring those who have served at the highest level of previous governments.”\n\nJobs with the biggest US AI companies can be a good fit for frontline politicians because they also require comfort with risk-taking, said one tech company insider. Another advantage is that tech leaders do not tend to demand polished management skills. Meanwhile, their value is growing as AI companies increasingly target their products at government clients as well as businesses and consumers. Osborne’s task appears to be to wedge his foot in the door of governments to help OpenAI to inject its technology into the bloodstream of public systems. It already has government-level arrangements with Argentina, Australia, Germany, Norway, the United Arab Emirates, South Korea, the UK, Greece, Estonia and Kazakhstan, but it wants more.\n\nSelling state-level AI is competitive. Palantir, which hosted Starmer at its Washington base in February and signed a strategic partnership with the Ministry of Defence in September, is pushing its systems into health trusts, police forces and local councils in Britain. The company’s UK communications are being led by a former head of strategic communications at Downing Street.\n\nBritain is an important place for AI firms to gain influence: regulations on AI development remain looser than in the EU, its universities foster important innovations, and the UK also has one of the world’s most respected AI safety institutes.\n\nThe revolving door also spins the other way, sending tech industry people into positions of public influence. The UK government last month appointed Raia Hadsell, the vice-president of research at Google DeepMind, as an “AI ambassador”, alongside Tom Blomfield the founder of the online bank Monzo. Blomfield is also a partner at Y Combinator, the San Francisco start-up incubator that used to be led by Sam Altman, the chief executive of OpenAI.\n\nCivil servants from the government’s digital service set up a consultancy called Public Digital, which has since won millions of pounds worth of public contracts. One of its partners, Emily Middleton, last year took a senior director general role in the government’s digital service.",
    "readingTime": 5,
    "keywords": [
      "silicon valley",
      "tony blair",
      "british politicians",
      "science innovation",
      "chief executive",
      "prime minister",
      "government’s digital",
      "digital service",
      "revolving door",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/17/from-nvidia-to-openai-silicon-valley-woos-westminster-as-ex-politicians-take-tech-firm-roles",
    "thumbnail_url": "https://i.guim.co.uk/img/media/08f3e143004db91eb604503fa3c2704aef40f751/1796_74_2930_2344/master/2930.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1330bbc1f14518b03f398a7c2514ab85",
    "created_at": "2025-12-17T18:18:30.222Z",
    "topic": "tech"
  },
  {
    "slug": "ghost-jobs-robot-gatekeepers-and-ai-interviewers-let-me-tell-you-about-the-bleak-new-age-of-job-hunting-eleanor-margolis",
    "title": "Ghost jobs, robot gatekeepers and AI interviewers: let me tell you about the bleak new age of job hunting | Eleanor Margolis",
    "description": "In my six months of looking for work, I’ve found that from fake ads to AI screening software, the search is more soul-destroying than...",
    "fullText": "In my six months of looking for work, I’ve found that from fake ads to AI screening software, the search is more soul-destroying than ever\n\nAs I apply for yet another job, I look at the company’s website for context. I’ve now read their “what we do” section four or five times, and I have a problem – I can’t figure out what they do. There are two possibilities here. One: they don’t know what they do. Two: what they do is so pointless and embarrassing that they dare not spell it out in plain English. “We forge marketing systems at the forefront of the online wellness space” translates to something like “we use ChatGPT to sell dodgy supplements”.\n\nBut understanding what so many businesses actually do is the least of my worries. I’m currently among the 5% of Brits who are unemployed. In my six months of job hunting, my total lack of success has begun to make me question my own existence. Just like when you repeat a word over and over until it loses all meaning, when you apply repeatedly for jobs in a similar field, the semantics of the entire situation begin to fall apart like a snotty tissue. About one in five of my job applications elicit a rejection email, usually bemoaning the sheer number of “quality applicants” for the position. For the most part, though – nothing. It’s almost like the job never existed in the first place, and it’s possible that it didn’t.\n\nIn 2024, 40% of companies posted listings for “ghost jobs”, nonexistent positions advertised to create the illusion that the company is doing well enough to take on new employees. And this seems like an all-too-easy way to lie about your success. Regulation of job ads is mostly the remit of the Advertising Standards Authority, which – in all its might – has the power to … have a misleading job ad taken down. So with no particularly harsh consequences for employers, why not go on a pretend hiring spree? Ethics in the job market seem to have gone out the window, and the idea of wasting the time of thousands of hapless jobseekers doesn’t seem to matter much.\n\nEven if the job you’re applying for exists, next comes the hurdle of the AI HR bot. While it’s difficult to find any hard data on just how many employers are using AI to filter applications (sometimes favouring men over women, if a now-scrapped algorithm used by Amazon is anything to go by), articles and Reddit threads about how to game the bots and get in the right “key words” now abound. According to an Atlantic article from earlier this year: “Young people are using ChatGPT to write their applications; HR is using AI to read them; no one is getting hired.” And let’s say your CV and cover letter do make it past the robot gatekeepers, it’s possible that your interview will be conducted by yet another bot. Although I haven’t had the pleasure of an interview, AI or otherwise, since I began my latest job search, the possibility of not coming into contact with a single human during most of the process to becoming the dodgy supplements social media marketing manager looms large and dreadful.\n\nWhile this scramble for jobs is mostly being framed as a problem for graduates, I can confirm – as someone who graduated 15 years ago bang into a recession – not only is this the worst job market I’ve ever seen, but it’s also impacting people like me with many years’ experience. During my last period of job hunting, about three years ago, I was at least getting interviews. Interviews with humans, to boot. Given all the skilled people I know who can’t seem to land interviews for even entry-level positions, I’m certain that I’m not an outlier. I’m also convinced that we’re facing a crisis in which middle-class jobs have mutated into rare and disturbing beasts.\n\nWhen, according to its job ad, an indie pet food company called something like Flopsies is looking for a “rock star” and a “unicorn” to revolutionise its social media presence, you know that the job market has become high on its own farts. Ill-defined franken-jobs, requiring everything from SEO expertise to video-editing skills (all for a salary of £27,000 and free protein bars that taste like hay) require cult-like dedication. First, you must convince the fine people at Flopsies that it has been your dream since exiting your mother’s birth canal to sell pet food. You would cut off your own hands for the privilege, and quickly learn to write copy for them by smashing your face into a keyboard. You will convey this in a 400-word cover letter, written in your own blood. This cover letter will then be redirected into the ether by an AI filter, because you didn’t use the phrase “optimising algorithmic relevancy” in it. You will never hear from Flopsies again. You will start this process again and repeat it until you are seen fit for an interview in which you have a few minutes to convince a bot that you’re fit for purpose as both a worker and a human being.\n\nThe hiring process has become so mechanised, both figuratively and literally, that it’s hard to believe that the people who end up being hired aren’t merely the best at gaming the system. And frankly, all power to them. It’s no skin off my nose if the dodgy supplement or pet-food jobs go to people who are incredible at creating the illusion that they live and breathe pet food and/or dodgy supplements. But in this oh-so-streamlined process, what happens to those of us who can’t or won’t play the game? Of all the applications I’ve sent out recently, I wonder how many have been looked at by humans. There’s only so much shouting into the void about your ability to use a CMS you can do before you give up and start Googling things like: “Can I sell a kidney on Vinted?”\n\nEleanor Margolis is a columnist for the i newspaper and Diva",
    "readingTime": 6,
    "keywords": [
      "social media",
      "cover letter",
      "pet food",
      "dodgy supplements",
      "job hunting",
      "job market",
      "it’s",
      "jobs",
      "i’ve",
      "applications"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/17/ghost-jobs-robot-gatekeepers-ai-interview-job-hunting",
    "thumbnail_url": "https://i.guim.co.uk/img/media/5f51c8b92b57fa0ed70a5ee9bae86dbdfc80ddb7/403_141_2992_2394/master/2992.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=b8cfe5a946408ae19a51994e55835dc9",
    "created_at": "2025-12-17T18:18:30.217Z",
    "topic": "tech"
  },
  {
    "slug": "how-to-use-the-holidays-to-stop-our-whatsapp-aunties-falling-for-ai",
    "title": "How to use the holidays to stop our ‘WhatsApp aunties’ falling for AI",
    "description": "Family members can be sweet and relentless but how can we aid our relatives in the age of new tech and device addiction \n• Don’t get The Long Wave delivered to your inbox? Sign up here\nI don’t want to sound dramatic but, a few weeks ago, something happened that has completely changed how I view online material. I fell for AI-generated content. For someone who is constantly squabbling with older relatives about how little they question what they see online, this was a profoundly unsettling and humbling experience. And it made me think about how, during this holiday period, we could all use this as an opportunity to approach those conversations with the “WhatsApp aunties” more sensitively.",
    "fullText": "Family members can be sweet and relentless but how can we aid our relatives in the age of new tech and device addiction\n\nDon’t get The Long Wave delivered to your inbox? \nI don’t want to sound dramatic but, a few weeks ago, something happened that has completely changed how I view online material. I fell for AI-generated content. For someone who is constantly squabbling with older relatives about how little they question what they see online, this was a profoundly unsettling and humbling experience. And it made me think about how, during this holiday period, we could all use this as an opportunity to approach those conversations with the “WhatsApp aunties” more sensitively.\n\nFrom ‘WhatsApp Aunties’ to ‘AI Aunties’\n\nI think I have the perfect sample of WhatsApp aunties. Sadly displaced from Sudan due to war, a permanently online group of women, some direct aunts, some not, but all aunties nonetheless, sit in a control room of sorts in their different cities and send out daily broadcasts that simulate as much as possible the interactions and updates they would have shared had they still been living in the same place. They even have office hours. One can divine the start of the day in their respective locations as they clock in and the forwards begin: First, it is morning greetings, maybe an embellished picture of Quranic verses or a graphic of flowers, wishing you a good day.\n\nThen, the hardcore stuff. Snippets of videos from war zones back home, clipped debates between political antagonists, and sometimes entire YouTube episodes of interviews. After this news shift comes the lighter one (secretly my favourite): TikTok and Instagram reels of Arab celebrities with too much plastic surgery accompanied by scream emojis, footage from family and friend weddings across the world, captioned with love heart eyes. The stream is interspersed with the longest voice memos you will ever receive, asking how you are and telling you how they are with an introductory and concluding prayer session. It is sweet and relentless.\n\nAll of this is dumped with an abandon that suggests no understanding of or respect for phone memory limitations. Whenever my mother casually mentions that her phone is acting up and mutters something about no space, my heart sinks. I know that hours and hours of deletions of grainy videos are upon me. But most galling is how much fake content it includes. The WhatsApp aunties have become AI aunties. This was frankly a problem even before AI became so sophisticated, but it is now much, much worse. There is the harmless stuff; cats hugging babies or penguins feeding themselves with cutlery. I try not to get too agitated by this or point out that it’s fake. But when it’s videos of Taylor Swift endorsing the pro-Palestine movement, it’s impossible to let it slide.\n\nThe result is a series of exchanges that are both saddening and enraging. Aunties will either take it personally, like I am disrespecting them by implying they can’t tell what’s real or not, and double down. Or they will express genuinely innocent beliefs in the veracity of online content, imbuing the internet with the same standards of TV or radio they grew up with.\n\nTelling the aunties that something is entirely fake is like asking them to imagine a TV news broadcast is not real. Also, they are actually receiving news broadcast clips on their phones that are not real. You end up sounding like the crazy one, trying to explain that a living, breathing, walking, talking person is just pixels generated from prompts.\n\nIn a recent episode of Subway Takes, comedian Ola Labib said we shouldn’t try to convince elders that AI content isn’t real. Her argument: Let them have their little comforts. I kind of get that, what harm is it doing really? But there is an emotional element to it as well. Policing elders’ content feels to me like a manifestation of a deep-seated fear that they’re losing it, that their faculties are waning, as they succumb to old age and the bewildering assaults of new tech and device addiction. I think it is truly distressing for people to see parents and relatives increasingly become addicted to their phones and become slightly addled, a window into a sort of premature senility.\n\nBut there are social and political reasons too, for pushing back. Aunties (and, to a lesser degree, uncles) have a huge amount of disseminative power and a lot of free time. They wield a formidable authority, particularly in diaspora communities, both as enforcers of values, as organisers and sponsors of social events, and generally as gatekeepers of community interactions and upholders of norms. Collectively and individually, they are forces to be reckoned with, which makes disagreements even more challenging and fraught with risks of falling foul of powerful elders. But they are force multipliers in terms of spreading fake content that is politically inflammatory or conspiratorial, and when unchallenged, they contribute to the general degradation of the information ecosystem and its associated political fallout.\n\nSo, I would say talk to them, keep talking to them, but do it kindly, with time and explanation, rather than frustration and bewilderment. Maybe just acknowledge the content first before pointing out its fakery – a “really cool!” followed a little while later with a “actually, do you think that’s real? I’m not sure”. Also, furnish them with the “tells”: video glitches, lack of shadows, weird blinking. Bear in mind what the world looks like to them. It is a place that is changing too rapidly to assimilate how it is happening. Our elders are also, simply, getting older. With that comes all sorts of uncertainties and unsettlement; loneliness, loss of identity as work is retired from, and children age out of parenting. Exacerbating that are the vast distances that now often separate elders from their kin and peers. Online content and its constant exchange are about so much more than sharing information; it is a new language, almost phatic, for trying to connect.\n\nRemember that the tech is evolving so quickly that even the most savvy have to be vigilant. I now have to be on alert after admiring a song with album cover art, a music video, a richly talented singer and fantastic accompanying chorus. After days of trying to hunt down the artist, I was thunderstruck to find out it was all AI. It will happen to all of us. Welcome me to the aunties brigade. Please be kind. Break it to me gently.",
    "readingTime": 6,
    "keywords": [
      "whatsapp aunties",
      "device addiction",
      "fake content",
      "online content",
      "elders",
      "relatives",
      "tech",
      "hours",
      "videos",
      "political"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/news/2025/dec/17/how-to-use-the-holidays-to-stop-our-whatsapp-aunties-from-becoming-ai-aunties",
    "thumbnail_url": "https://i.guim.co.uk/img/media/340f75930666ebe965cca561bfa40c455dcb6ea1/0_0_4800_3840/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=437adef09c1598ec5916aef0eccdd02c",
    "created_at": "2025-12-17T13:45:45.952Z",
    "topic": "tech"
  },
  {
    "slug": "music-needs-a-human-component-to-be-of-any-value-guardian-readers-on-the-growing-use-of-ai-in-music",
    "title": "‘Music needs a human component to be of any value’: Guardian readers on the growing use of AI in music",
    "description": "AI promises to have far-reaching effects in music-making. While some welcome it as a compositional tool, many have deep concerns. Here are some of your responses\nAI-generated music is flooding streaming platforms, and it seems to be here to stay. Last month, three AI songs reached the highest spots on Spotify and Billboard charts. Jorja Smith’s label has called for her to receive a share of royalties from a song thought to have trained its original AI-generated vocals on her catalogue, which were later re-recorded by a human singer.",
    "fullText": "AI promises to have far-reaching effects in music-making. While some welcome it as a compositional tool, many have deep concerns. Here are some of your responses\n\nAI-generated music is flooding streaming platforms, and it seems to be here to stay. Last month, three AI songs reached the highest spots on Spotify and Billboard charts. Jorja Smith’s label has called for her to receive a share of royalties from a song thought to have trained its original AI-generated vocals on her catalogue, which were later re-recorded by a human singer.\n\nWith this in mind, we asked for your thoughts on music composed by AI, the use of AI as a tool in the creation of music, and what should be done to protect musicians. Here are some of your responses.\n\nI have already found AI songs being added into jazz playlists and “radio stations” on Spotify. There was one song I actually liked, so I did some digging and found out it was a group with a generic name that had around three to five albums all released in 2025. Then I noticed the next track and the track followed the same path. It was really irksome. History, I hope, shows that people do value human flaws in art. Sometimes it helps us feel seen or not alone. I don’t understand how a completely computer-generated sound based on what’s come before could do that. Then again, some people fall in love with LLMs. I just think everything should be labelled somehow. Give people the choice. Make sure there are protections in place like forcing social feeds and music platforms to give consumers the ability to filter out AI-generated content. Casey, 37, Chicago, US\n\nThere’s no heart in music generated entirely by AI, and encouraging it is hurting the livelihoods of musicians. It is also very important not to call music made by AI “composed”. That word gives AI prompters far more credit and muddies the waters as to what composition is. The only people served by AI music are companies like Spotify, and major record labels who would no doubt rather not have to pay artists at all.\n\nAs for working with AI, I once recorded an album with my band and lost the stem tracks before we finished the final mix, but we were able to use an AI tool that could isolate certain instruments in the masters and boost them to get the mix we wanted. That seems to me an example of positive AI usage, and something that wouldn’t have been possible before AI. A composer like Ben Nobuto is also an example of someone who has used AI as a starting point for building real, human music. It’s probably too late now, but all musicians with work on streaming sites should probably have been paid as their work was likely used as training data. Additionally, musicians should be able to opt out of their work being used to train LLMs just like cookies on a website. Jon, 30, musician and music teacher, Switzerland\n\nI believe music needs a human component to be of any value. Music composed by AI has, from what I have heard, a big problem with simplistic or visible lyrics and a lack of emotional content.\n\nBut I am happy with musicians using AI as a tool. It brings professional quality recordings to those unable to hire a studio, orchestra or vocalist and so on. I have been writing songs for decades – in the 80s I couldn’t afford a Portastudio (four-track cassette recorder), so I used two single-track machines instead to play and record simultaneously. Now I can upload my songs to Suno (a generative AI program) and create new arrangements of them close to my original intention. It is great to be able to write for voices other than my own. Even so, some of my family and friends tell me they prefer my original versions. Mike Lee, 67, ex-photographer and teacher, Southampton\n\nAI-generated music is a copyright nightmare and is stopping creativity. We don’t have to accept it, and we don’t have to use it. The most irksome thing is non-creatives believing themselves to be artists, using AI to create and claiming it as their own art, when it’s an amalgamation of stolen work. Not sculpted with their own hands, not conceived in their own minds. Frankly, I find it embarrassing when someone proudly declares using it. Artists are already marginalised, but there is a kickback against, for example, TV slop, and a growing demand for audiences – in all forms – to not be treated like idiots. Artists are the answer to this, not AI.\n\nIf you can harness it to your advantage as an assistive tool, then by all means use it. The danger is to become reliant on AI. There should be a clear payment scheme, similar to PRS and PPL where AI shows exactly which items have been used to create. Or a watermark on copyrighted material. Nicole Vardon-Martin, 37, events and stage manager, Dagenham\n\nWhen social media and streaming services are flooded with digitally regurgitated stuff, it becomes harder to find the pieces with personal decisions behind them. I like knowing there’s a story behind the songs I get stuck in my head. I don’t think generative AI is the neutral tool many describe it to be, both because of its strain on the earth and because anything used by these algorithms has to come from somewhere, and keep coming, for what they chuck together to seem original.\n\nBlatantly copying someone else’s work doesn’t become “taking inspiration” because some software has mixed it around. Yes, there are musicians who use only their own work to generate “new” music, but in my opinion this is quite an insular and thoughtless way of creating. Generative AI will always, eventually, become bland without new content to sustain it, and more AI-generated work cannot fill that void. Charlotte, student, Cornwall\n\nIn my home studio I use AI to help mix and master music. I can see that it might be tempting to use an AI voice on your composition if you can’t sing – but why not go out to an open mic and see if you can find a real, living voice? Where would Burt Bacharach and Hal David be without all the brilliant singers who interpreted their songs? Who knows what a real musician will add to your music.\n\nI might be tempted to use AI to write a song but then I suspect my own musical abilities would atrophy and I would become quickly dependent on the technology. I don’t know enough about how copyright would work in these circumstances, but we need to protect human creativity and one way is to go out and see live music, commission people to write it, and to buy music directly from the artist if you can, avoiding those streaming services that pay very little and seem to be actively promoting fake artist profiles. Geoff Smith, 65, musician and retired headteacher, Cornwall",
    "readingTime": 6,
    "keywords": [
      "streaming services",
      "ai-generated music",
      "music composed",
      "tool",
      "songs",
      "musicians",
      "human",
      "don’t",
      "original",
      "artists"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/music/2025/dec/17/guardian-readers-on-the-growing-use-of-ai-in-music",
    "thumbnail_url": "https://i.guim.co.uk/img/media/aec57aca55869b4eac2884486aae6990f2dbd2ee/831_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=516aa4600bf3c3e8790c7fbd0f14bc88",
    "created_at": "2025-12-17T13:45:45.805Z",
    "topic": "entertainment"
  },
  {
    "slug": "this-is-europes-secret-weapon-against-trump-it-could-burst-his-ai-bubble-johnny-ryan",
    "title": "This is Europe's secret weapon against Trump: it could burst his AI bubble | Johnny Ryan",
    "description": "Growth in the US economy – and the president’s political survival – rest on AI. The EU must use its leverage and stand up to him \nThe unthinkable has happened. The US is Europe’s adversary. The stark, profound betrayal contained in the Trump administration’s national security strategy should stop any further denial and dithering in Europe’s capitals. Cultivating “resistance Europe’s current trajectory in European nations” is now Washington’s stated policy.",
    "fullText": "Growth in the US economy – and the president’s political survival – rest on AI. The EU must use its leverage and stand up to him\n\nThe unthinkable has happened. The US is Europe’s adversary. The stark, profound betrayal contained in the Trump administration’s national security strategy should stop any further denial and dithering in Europe’s capitals. Cultivating “resistance Europe’s current trajectory in European nations” is now Washington’s stated policy.\n\nBut contained within this calamity is the gift of clarity. Europe will fight or it will perish. The good news is that Europe holds strong cards.\n\nThe US’s bet on AI is now so gigantic that every Maga voter’s pension is bound to the bubble’s precarious survival. AI investment now rivals consumer spending as the primary creator of American economic growth. It accounted for virtually all (92%) GDP growth in the first half of this year. Without it, US GDP grew only 0.1%. Despite Donald Trump’s posturing, he is on shaky economic ground.\n\nTrump’s political coalition is shaky, too. In July and again this month, he has been unable to force Senate Republicans to pass his AI moratorium bill, which would have prevented states from drafting their own AI laws. The Steve Bannon wing of Maga fears that AI will displace workers en masse, and is appalled by what children are exposed to on digital platforms. Maga voters particularly mistrust big tech’s political power. Tech is a dangerous topic for Trump.\n\nUrsula von der Leyen, the president of the European Commission, has two cards to play that might pop the AI bubble. If she does so, Trump’s presidency will be thrown into crisis.\n\nFirst, Dutch company ASML commands a global monopoly on the microchip-etching machines that use light to carve patterns on silicon. These machines are essential for Nvidia, the AI microchip giant that is now the world’s most valuable company. ASML is one of Europe’s most valuable companies, and European banks and private equity are also invested in AI. Withholding these silicon-etching machines would be difficult for Europe, and extremely painful for the Dutch economy. But it would be far more painful for Trump.\n\nThe US’s feverish investment in AI and the datacentres it relies on will hit a wall if European export controls slow or stop exports to the US – and to Taiwan, where Nvidia produces its most advanced chips. Via this lever, Europe has the means to decide whether and by how much the US economy expands or contracts.\n\nSecond, and much easier for Europe, is the enforcement of the EU’s long-neglected data rules against big US tech companies. Confidential corporate documents made public in US litigation show how vulnerable companies such as Google can be to the enforcement of basic data rules. Meanwhile, Meta has been unable to tell a US court what its internal systems do with your data, or who can access it, or for what purpose.\n\nThis data free-for-all lets big tech companies train their AI models on masses of everyone’s data, but it is illegal in Europe, where companies are required to carefully control and account for how they use personal data. All Brussels has to do is crack down on Ireland, which for years has been a wild west of lax data enforcement, and the repercussions will be felt far beyond.\n\nIf the EU had the gumption to apply this pressure, these US tech companies would have to rebuild their technologies from the ground up to handle data correctly. They would also have to tell investors that their AI tools are barred from accessing Europe’s valuable market until they comply. The AI bubble would be unlikely to survive this double shock.\n\nMaga voters did not vote to lose their liberties and constitutional rights, and an increasingly authoritarian Trump who cannot deliver economic stability because of his closeness to a reviled tech industry is likely to be deeply unpopular in the 2026 midterm elections.\n\nThe balance of risk now demands that European leaders cripple Trump. They have learned from a year of abject cowering before Trump that such behaviour only makes it easy for him to push them over. The reasons for caution are disappearing. The extreme reaction of Maga leaders to the relatively minor €120m fine the EC recently imposed on X shows that pulling punches will not placate them. Trump’s “28-point plan” for Ukraine dispelled any illusion that European concessions would secure a return to US military commitment.\n\nWith its democracy now explicitly under threat, Europe must join India, Brazil and China in standing up to Trump.\n\nBrazil’s president Luiz Inácio Lula da Silva is an example of how to do so. He has been dignified and resolute in the face of extraordinary bullying from Trump. In a single month, in September, he proclaimed in an open letter to Trump that his country’s democracy and sovereignty are non-negotiable, countered Trump’s tariffs with its own and passed a new law forcing digital platforms to protect children in Brazil from sexual harassment and other online harms.\n\nThen he rhetorically mugged Trump in a UN general assembly speech just before Trump’s turn to speak. As a result of Lula’s refusal to be cowed, Trump softened his tone immediately. Lower tariffs are now expected after negotiations between the two leaders.\n\nTrump said earlier in December that he thinks Europe’s leaders are weak. He does not believe they will defend Europeans’ liberties and their hard-won democracy against him. So far, the response from European leaders is proving him correct. But what Trump does not yet understand is that von der Leyen holds the US economy and his presidency in her hands. She must have the courage to go entirely beyond any prior norms of her behaviour. In other words, if she grabs Trump where it hurts, Europe will win this fight.\n\nJohnny Ryan is director of Enforce, a unit of the Irish Council for Civil Liberties",
    "readingTime": 5,
    "keywords": [
      "der leyen",
      "maga voters",
      "digital platforms",
      "von der",
      "european leaders",
      "europe’s",
      "tech",
      "trump",
      "economy",
      "growth"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/17/europe-donald-trump-ai-bubble-us-economy-eu",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f3c5945bf000f1a831b643986588a8d2fb63555a/559_511_1300_1041/master/1300.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=338d5fdc77095b2cd007fe0c3041b583",
    "created_at": "2025-12-17T13:45:45.804Z",
    "topic": "tech"
  },
  {
    "slug": "amazon-in-talks-to-invest-10bn-in-developer-of-chatgpt",
    "title": "Amazon in talks to invest $10bn in developer of ChatGPT",
    "description": "OpenAI seeking to strike latest deal in its efforts to pay for huge spending on...",
    "fullText": "OpenAI seeking to strike latest deal in its efforts to pay for huge spending on datacentres\n\nAmazon is in talks to invest more than $10bn (£7.5bn) in OpenAI, in the latest funding deal being struck by the startup behind ChatGPT.\n\nIf it goes ahead, the market valuation of OpenAI could rise above $500bn, according to The Information, a tech news site that revealed the negotiations.\n\nAmazon, which is best known as an online retailer, is also the world’s largest datacentre provider and its investment would help OpenAI pay for its commitments to rent capacity from cloud computing companies – including Amazon.\n\nOpenAI said last month it would spend $38bn on capacity from Amazon Web Services – the company’s datacentre arm – over seven years. The Information said that OpenAI planned to use Amazon’s Trainium chips, which compete with Nvidia and Google’s chips. It also reported that Amazon’s financing could lead to a broader fundraising round with other investors.\n\nOpenAI’s spending commitment on compute – the chips and servers that power its chatbot – is $1.4tn over the next eight years, a figure far in excess of its reported $13bn in annual revenues.\n\nAs a result, the lossmaking company has been seeking further funding and has converted its main business into a for-profit corporation. Its main longtime backer, Microsoft, has taken a stake of roughly 27% in a deal that valued OpenAI at $500bn.\n\nOpenAI is also considering an initial public offering – selling its shares to the general public – in a move that could value the company at up to $1tn, according to Reuters.\n\nOther deals struck by OpenAI this year include Oracle spending $300bn on building datacentres in Texas, New Mexico, Michigan and Wisconsin. OpenAI is expected to pay back roughly the same amount to use the sites.\n\nIn another transaction with Nvidia, OpenAI will pay in cash for chips and Nvidia will invest in OpenAI for non-controlling shares.\n\nOpenAI announced on Tuesday that it had hired the former UK chancellor George Osborne to develop relationships with governments around the world and broker national-level AI projects.\n\nSam Altman, OpenAI’s chief executive, has declared a “code red” staff alert to lead a fightback against competitors led by Google, whose update of its Gemini AI tool gave it an edge over rivals including ChatGPT.\n\nThe Amazon talks reportedly include discussing commercial opportunities and selling a corporate version of ChatGPT to the online retailer.\n\nOpenAI declined to comment. Amazon has been approached for comment.",
    "readingTime": 3,
    "keywords": [
      "online retailer",
      "the information",
      "openai",
      "chips",
      "deal",
      "seeking",
      "latest",
      "datacentres",
      "talks",
      "invest"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/17/amazon-talks-invest-in-openai-developer-of-chatgpt",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7c8f5d23afeb72372c88c26affc6fa9abe607c64/1215_0_6980_5584/master/6980.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2aff7897fe0cc4a85cb85f32e6461c4b",
    "created_at": "2025-12-17T13:45:45.803Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-attacks-on-science-may-ruin-his-ai-moonshot",
    "title": "Trump's attacks on science may ruin his AI moonshot",
    "description": "Trump’s AI “Manhattan Project” will fail if DOGE cuts are kept, critics say.",
    "fullText": "Described as a “historic national effort” to “invest in AI-enabled science to accelerate scientific advancement,” Trump claimed his mission would address key challenges to American energy dominance, innovation, and national security.\n\nThis mission, Trump boasted, would be a game-changer to science akin to putting a man on the moon or firing the first nuclear weapons. By building “an integrated AI platform” trained on “the world’s largest collection” of federal scientific data sets, he promised, the government could set off cascades of scientific breakthroughs.\n\nAccess to such a platform, Trump imagined, would supercharge top US labs, powering AI agents to do tasks like quickly test hypotheses and automate research workflows to speed up discoveries.\n\nHowever, the mission crucially depends on strengthening collaboration between public, private, and academic sectors. And Trump’s order is concerningly vague on how those partnerships will be structured and funded at a time when many scientists have been sidelined due to a flurry of Trump orders earlier this year that eliminated their funding or removed them from their labs.\n\nTo critics, including scientists, policy experts, advocates, and historians, Trump’s order seems divorced from reality, given that he spent the past year attacking some of the very institutions the Genesis Mission would seem to depend on. Trump also seemed unclear about what can be achieved with AI and confused about how scientific progress is actually made, some critics suggested.\n\nAmong the critics was Arati Prabhakar, who served as the director of the White House Office of Science and Technology Policy under the Biden administration. Prabhakar told Ars that Trump’s crippling cuts to government science agencies, research grant funding freezes, and attacks on universities must be repaired or his mission will fail.\n\n“After the Trump administration has inflicted so much damage to valuable datasets and publicly funded research, the new executive order is a Band-Aid on a giant gash,” Prabhakar said.\n\nAlso skeptical of Trump’s plans is Kathryn Kelley, executive director for the Coalition for Academic Scientific Computation, an educational nonprofit representing more than 100 of “the nation’s most forward-thinking universities and computing centers,” CASC’s LinkedIn said.\n\nHer group is specifically dedicated to Genesis Mission-aligned goals, “advocating for the use of the most advanced computing technology to accelerate scientific discovery for national competitiveness, global security, and economic success.” And while Trump’s initiative could be considered “a step in the right direction,” Kelley told Ars that she shares Prabhakar’s concerns.\n\n“Many research institutions and national laboratories continue to experience funding uncertainty, program disruptions, and workforce instability stemming from earlier cuts,” Kelley told Ars.\n\nParticular pain points considered critical to address for Genesis Mission to move forward include reversing “impacts on staffing, ongoing research, and student pipelines,” she suggested.\n\nIn one prominent example, some Department of Government Efficiency (DOGE) cuts targeting workers at the National Science Foundation hit hardest in the branch designed to accelerate technology development across a wide range of research settings in the US. DOGE slashed workers there simply because it was the youngest directorate at NSF with the most workers in transition when Trump took office. As courts weighed legal challenges to cuts, whistleblowers warned that Trump was aiming to politicize and dismantle NSF.\n\n“Large-scale initiatives like Genesis rely on highly skilled personnel, robust infrastructure, and sustained program support—some of the very resources at NSF and other federal agencies that were disrupted,” Kelley told Ars. “Rebuilding trust, re-establishing lost programs, and stabilizing the research workforce will be essential to make this mission feasible.”\n\nCritics urged that Trump’s attacks on science also included messing with government datasets that scientists depend on. Since Trump’s second term started, scientists have watched valuable data get censored or scrubbed from government websites. Some researchers have rushed to recreate datasets independently with the help of the Internet Archive.\n\nPrabhakar pointed out that some “datasets that could improve health and prevent disasters are eroding or even disappearing due to this administration,” while universities training “the next generation of great researchers and innovators have reduced or even stopped graduate admissions because of Trump’s assault.”\n\nWithout a massive undertaking to undo moves that critics have said undermined both US science and trust in it, Trump’s dreams of launching AI models that would propel a million moonshots could go down in history as merely hype.\n\n“Without robust data and research and without people’s trust, America won’t lead in AI,” Prabhakar said.\n\nFor people in the science community, it’s hard to square Trump’s aggressive cuts from earlier this year with the broad ambition of Genesis Mission. Frustratingly, the president demands that scientists make discoveries on his timeline, without acknowledging AI’s limitations or how his attacks on science could be driving away talent that could help labs advance AI.\n\nIn many fields, scientists are still exploring how AI can aid research. Trump’s order appears to politicize science by focusing on areas he favors—like critical materials, nuclear energy, biotechnology, and quantum computing—despite their limited AI applications or data-quality challenges. Meanwhile, critics noted that it overlooks areas where “supercharging” AI could perhaps be more impactful—but where Trump notably does not want to leave his mark—like climate science or vaccine research.\n\nIt also lays out aggressive timelines for results, demanding that the Department of Energy Secretary, Chris Wright, “demonstrate an initial operating capability of the Platform for at least one of the national science and technology challenges” identified in less than a year (270 days). Ideally, Trump’s mission will have generated significant discoveries in key fields within the next three years before he leaves office, his order outlined.\n\nPaul Josephson, a Colby College professor and expert in the history of 20th-century science and technology, told Ars that Genesis Mission deadlines differ from John F. Kennedy’s 10-year timeline to reach the moon.\n\nTrump’s order “shows tremendous ignorance of how science and technology work,” Josephson said. The White House is saying, “Tell me what your discoveries will be and how many there will be in three years,” Josephson said, expecting that “we can pick the places where we want discoveries and make them happen.”\n\n“That’s not anything like how science works,” Josephson told Ars, reducing Genesis Mission to “a vision without policy” and “a hope without funding.”\n\nTo Josephson, Trump’s order sounded “more like it came out of Silicon Valley” than out of talks with government scientists, seemingly rushing approvals of industry partnerships and incentives without mentioning what resources would be available to fund gutted labs or train the next generation of scientists. It’s perhaps notable that the order is DOE-centric and does not place the same emphasis on contributions from universities or national labs funded by NSF and the National Institutes of Health as it does on industry partners.\n\nKelley told Ars that “many public datasets are already being used effectively in research and industry” in the ways that Trump intends his AI platform to amplify. However, “there are areas—such as advanced nuclear research or emerging energy technologies—where datasets are limited.” And Trump risks reducing Genesis Mission to bluster by claiming that an AI platform could drive breakthroughs to the major challenges he flagged in the short term.\n\n“There is a real risk that the EO’s ambitious framing could overpromise what AI can achieve in the near term without addressing foundational data gaps,” Kelley told Ars. “That said, even partial progress in these areas could provide valuable insights, but expectations need to be realistic.”\n\nJust as important as asking where Genesis Mission funding is coming from or who the funding is going to, Chris R. Glass asks: “Where’s the talent coming from?”\n\nTrump’s order does not forecast that, only vaguely referencing support for universities training scientists. This comes, of course, after the administration revoked an estimated $1.5 billion in federal grant money in 2025. Those grant cuts shrank the pipeline for PhD students at an “unprecedented rate,” Axios reported.\n\nA Boston College professor who researches global student mobility and the impact of emergent technology on learning, Glass told Ars that Trump has notably left international talent out of his AI plans, despite the prominent roles that both “domestic and international scientists play in our current leadership” in AI.\n\nIn a recent Washington Post op-ed, Glass warned that “America is losing research scientists,” who are seeking more stable environments to set up their lives and conduct long-term studies.\n\nAs the Trump administration has attacked immigrants, other governments like the European Union and China have benefited by offering friendlier visa systems to attract the best and brightest minds graduating from US universities. Of course, of the two, China is America’s bigger AI rival. Earlier this year, China began heavily recruiting American scientists spooked by Trump’s grant funding cuts, and Glass confirmed that China has continued those efforts with the AI race heating up. Meanwhile, Trump appears to be going the other direction, recently requiring a $100,000 payment for some skilled workers seeking non-immigrant visas.\n\nThroughout 2025, US universities’ ability to attract international students showed resilience, but “we’re on thin ice,” Glass told Ars, with that resilience “waning.”\n\nCurrently, the US “is ranked the lowest among top destinations for its safety and welcoming and the lowest for its post-graduation visa policies,” Glass said, noting that doctoral students must affirm that they do not intend to immigrate, even though the majority of STEM PhD students stay in the US after graduating.\n\n“They want to stay, and we want them to stay,” Glass told Ars.\n\nAnother concerning outcome of Trump cuts that could hamper Genesis Mission: Entire research groups at many institutions were “displaced”—removed from their labs and left to work in cubicles without access to their equipment, Glass told Ars.\n\n“I think scientists want to go where the best sciences are being done, but eventually these kinds of friction points and these hostile policies make them redirect elsewhere, even temporarily redirect, earn their doctorate in Europe and hope that the policy environment in the US changes,” Glass said.\n\nTo turn it around, Glass made several recommendations in his op-ed to help retain PhD graduates and create stable pathways for high-value talents. That includes suggesting that the Trump administration consider fast-tracking green cards for students in fields that Genesis Mission depends on, including AI and machine-learning researchers, quantum computing scientists, and semiconductor engineers.\n\nHe also thinks the US should “unlock the O-1A visa for researchers and entrepreneurs” by redefining what makes someone an “extraordinary” talent and creating dedicated “founder tracks” for international talent, as Britain and Singapore do. That visa is “uncapped yet underused,” Glass said, only approving 4,500 STEM candidates in 2023.\n\nWithout changes to the visa system, the US “risks redirecting those talent flows,” he said. “And like a river, once those talent flows get redirected, they are very difficult to reverse.”\n\nAnd it won’t just be international talents jumping ship, Glass suggested, but also possibly US scientists forced to continue navigating potentially more of Trump’s cuts and indirect costs in the coming years.\n\n“I think that’s the kind of thing that slowly eats away at someone’s desire to continue to do science in the United States,” Glass said.\n\nGlass told Ars that he expects the US to stay on a “downward trajectory,” driving away talent in 2026, which Josephson suggested “will damage science both for the short and long term.”\n\n“Many universities figured out a one-year contingency plan, but reality will set in if funding continues to be cut,” Glass said.\n\nCASC’s Kelley told Ars that like university international student recruitment, “the US research ecosystem continues to be resilient, but the gap between ambitious goals and the current capacity must be carefully managed.”\n\n“While the Genesis Mission signals strong intentions to invest in science and technology, its success will depend on aligning resources, rebuilding workforce capacity, and thoughtfully integrating AI and data capabilities where they are most effective,” Kelley said.\n\nA scientist might be best positioned to understand the nuance that requires, but Josephson noted that Trump tasked his Science Advisor, Michael Kratsios, with leading the initiative. Unlike prior officials serving in that role, Kratsios is not a scientist and has no PhD, earning his BA in politics. Instead, Kratsios has strong industry ties, previously serving as chief of staff for venture capitalist Peter Thiel and managing director of a company called Scale AI.\n\nTo Josephson, Kratsios as head of the mission—which “seems to be totally based on faith in AI and datasets to do everything”—makes the initiative seem more aligned with Silicon Valley ambitions than public good. That could be a problem since historically, it has never worked when governments attempt to “pick winners” or pass industrial policy with claims that “if we do this, we will come out on top.”\n\n“It’s a belief in AI as the cure or the panacea for all the world’s problems to ensure we’re a dominant technological power, but ignoring climate change, race, gender, anything that is important in daily life,” Josephson said.\n\nJosephson is also an expert in Russian and Soviet history, explaining that precedent shows there are “tremendous dangers” of governments controlling which sciences are funded. In some ways, he thinks Genesis Mission “smells of Putin,” he told Ars, warning that Trump’s attempts to hoard and censor science in 2025 have been “as damaging to science and technology in the world’s leading centers as totalitarian regimes have been.”\n\n“It reflects the general timbre of the Trump administration toward the scientific enterprise,” he suggested, saying that the president has embraced the “authoritarian view” that he “has the right to pick and choose which fields and which branches merit more support and which should not be funded at all.”\n\nJules Barbati-Dajches, an analyst for the Center for Science and Democracy at the Union of Concerned Scientists (UCS), told Ars that in addition to cuts, Trump recently “weakened federal agency policies (called scientific integrity policies) that were specifically in place to protect federal agency science from political interference.” This further threatens scientific integrity, Barbati-Dajches warned in August.\n\nUCS has tracked “instances of science being sidelined, ignored, or misused by the federal government” across “multiple presidential administrations” for two decades, Barbati-Dajches told Ars. And although their methodology was recently updated, the current Trump administration stands out, as “the rate and impact of attacks on science we’ve observed over the past nine months far outpace anything UCS has tracked before,” Barbati-Dajches said.\n\nAdditionally, UCS has documented “cases of the administration using AI in their reports and research that raise concern” that AI initiatives like Genesis Mission may promote dubious claims to serve “politicized” outcomes, Barbati-Dajches said.\n\n“This altogether paints a very troubling picture,” Barbati-Dajches said. “Scientific innovation and discovery are exciting, important, and can help inform federal policy and guidance. But as history tells us (and recent history even more so), science in the federal government needs protective guardrails to keep it independent and free from undue influence.”\n\nWith Trump pushing for rapid buildouts of AI data centers—sparking widespread backlash among Americans—Barbati-Dajches noted that UCS has documented his administration making “policy choices and decisions that benefit favored interests (including tech and fossil fuel companies) over the health and safety of the public and planet.” Genesis Mission appears to follow that trend, critics suggested, along with Trump’s most recent executive order threatening to block state AI laws, which many consider a gift to the tech industry.\n\n“And meanwhile, most Americans are clear they don’t trust AI and want it regulated—but this administration has opposed even basic guardrails,” Prabhakar said.\n\nPlanning to closely monitor Genesis Mission, UCS is keen to get answers to many questions, such as “who will have access to the platform that’s being created as part of this initiative” and “who will own or will benefit from the outputs of this type of program?”\n\nJosephson said that it’s unlikely Genesis Mission will advance much before the midterm elections. In the next steps, Congress will have to approve funding for the mission, as its broad ambitions, if supported, would surely require structure to continue across multiple administrations.\n\nTo Barbati-Dajches, it’s critical that Genesis Mission is “viewed in the context of [the Trump administration’s] pattern of anti-science actions.”\n\n“One of my main concerns is that this type of mission is being funded in the name of science and innovation when the administration has continuously and methodically attacked federal scientific systems since Inauguration Day,” Barbati-Dajches said.\n\nIt’s unclear whether Genesis Mission will amount to anything but hype. But Josephson noted that perhaps the most blustery part of Trump’s order was a claim that “from the founding of the Republic, scientific discovery and technological innovation have driven American progress and prosperity.”\n\nThe US only began funding research in the back half of the 19th century, Josephson said, “but the amount of money coming from the federal government to the sciences was limited until the Manhattan Project.” After that, the US emerged as a “leading scientific power” in the Cold War, not by racing for “global technology dominance,” as Trump wants, but by embracing science as a “national good.”\n\nAs it stands now, Genesis Mission’s biggest flaw might stem from Trump’s disdain for DEI, which fueled his attacks on science and universities all year, Josephson suggested.\n\n“Funding science and technology and allowing the scientific community through peer review to determine what is the best science and to give funding to encourage young people to enter the science pipeline and to ensure that there are more women and people of color in the scientific community, so that more and more brains are taking part—there’s none of that in the Genesis Mission,” Josephson said.",
    "readingTime": 15,
    "keywords": [
      "genesis mission",
      "white house",
      "college professor",
      "phd students",
      "reducing genesis",
      "driving away",
      "trump administration",
      "talent flows",
      "universities training",
      "federal agency"
    ],
    "qualityScore": 1,
    "link": "https://arstechnica.com/tech-policy/2025/12/trump-spent-2025-attacking-science-that-could-set-back-his-genesis-mission/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/trump-project-genesis-1152x648.jpg",
    "created_at": "2025-12-17T13:45:44.918Z",
    "topic": "tech"
  },
  {
    "slug": "privalyse-catching-security-leaks-in-aiassisted-codebases",
    "title": "Privalyse – Catching Security Leaks in AI-Assisted Codebases",
    "description": "🔒 Detect security leaks in AI-assisted codebases. Static analysis tool for Python & JS/TS with cross-file taint tracking. - Privalyse/privalyse-cli",
    "fullText": "Privalyse\n\n /\n\n privalyse-cli\n\n Public\n\n 🔒 Detect security leaks in AI-assisted codebases. Static analysis tool for Python & JS/TS with cross-file taint tracking.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Privalyse/privalyse-cli",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/privalyse/privalyse-cli",
    "thumbnail_url": "https://opengraph.githubassets.com/1846a6badf1ca8174ea5695b927ac6d0856c10b3c05ef532736288b88fb7cd00/Privalyse/privalyse-cli",
    "created_at": "2025-12-17T13:45:44.078Z",
    "topic": "tech"
  },
  {
    "slug": "the-new-chatgpt-images-is-here-15",
    "title": "The new ChatGPT Images is here [1.5]",
    "description": "OpenAI shipped an update to their ChatGPT Images feature - the feature that gained them 100 million new users in a week when they first launched it back in March, …",
    "fullText": "The new ChatGPT Images is here. OpenAI shipped an update to their ChatGPT Images feature - the feature that gained them 100 million new users in a week when they first launched it back in March, but has since been eclipsed by Google's Nano Banana and then further by Nana Banana Pro in November.\n\nThe focus for the new ChatGPT Images is speed and instruction following:\n\nIt makes precise edits while keeping details intact, and generates images up to 4x faster\n\nIt's also a little cheaper: OpenAI say that the new gpt-image-1.5 API model makes image input and output \"20% cheaper in GPT Image 1.5 as compared to GPT Image 1\".\n\nI tried a new test prompt against a photo I took of Natalie's ceramic stand at the farmers market a few weeks ago:\n\nAdd two kakapos inspecting the pots\n\nHere's the result from the new ChatGPT Images model:\n\nAnd here's what I got from Nano Banana Pro:\n\nThe ChatGPT Kākāpō are a little chonkier, which I think counts as a win.\n\nI was a little less impressed by the result I got for an infographic from the prompt \"Infographic explaining how the Datasette open source project works\" followed by \"Run some extensive searches and gather a bunch of relevant information and then try again\" (transcript):\n\nSee my Nano Banana Pro post for comparison.\n\nBoth models are clearly now usable for text-heavy graphics though, which makes them far more useful than previous generations of this technology.",
    "readingTime": 2,
    "keywords": [
      "nano banana",
      "banana pro",
      "chatgpt images",
      "gpt image",
      "openai",
      "feature",
      "cheaper",
      "model",
      "prompt",
      "here's"
    ],
    "qualityScore": 0.75,
    "link": "https://simonwillison.net/2025/Dec/16/new-chatgpt-images/",
    "thumbnail_url": "https://static.simonwillison.net/static/2025/pots-chatgpt-q80-half.jpg",
    "created_at": "2025-12-17T13:45:43.650Z",
    "topic": "tech"
  },
  {
    "slug": "4d-llm-describe-anything-anywhere-at-any-moment",
    "title": "4D LLM - Describe Anything, Anywhere, at Any Moment",
    "description": "DAAAM is a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding, building hierarchical 4D scene graphs with detailed natural language descriptions.",
    "fullText": "Computer vision and robotics applications ranging from augmented reality to robot autonomy in large-scale environments require spatio-temporal memory frameworks that capture both geometric structure for accurate language-grounding as well as semantic detail. Existing methods face a tradeoff, where producing rich open-vocabulary descriptions comes at the expense of real-time performance when these descriptions have to be grounded in 3D.\n\nTo address these challenges, we propose Describe Anything, Anywhere, at Any Moment (DAAAM), a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding. DAAAM introduces a novel optimization-based frontend to infer detailed semantic descriptions from localized captioning models, such as the Describe Anything Model (DAM), leveraging batch processing to speed up inference by an order of magnitude for online processing. It leverages such semantic understanding to build a hierarchical 4D scene graph (SG), which acts as an effective globally spatially and temporally consistent memory representation. DAAAM constructs 4D SGs with detailed, geometrically grounded descriptions while maintaining real-time performance. We show that DAAAM's 4D SG interfaces well with a tool-calling agent for inference and reasoning.\n\nWe thoroughly evaluate DAAAM in the complex task of spatio-temporal question answering on the NaVQA benchmark and show its generalization capabilities for sequential task grounding on the SG3D benchmark. We further curate an extended OC-NaVQA benchmark for large-scale and long-time evaluations. DAAAM achieves state-of-the-art results in both tasks, improving OC-NaVQA question accuracy by 53.6%, position errors by 21.9%, temporal errors by 21.6%, and SG3D task grounding accuracy by 27.8% over the most competitive baselines, respectively. We release our data and code open-source.",
    "readingTime": 2,
    "keywords": [
      "real-time performance",
      "task grounding",
      "spatio-temporal memory",
      "descriptions",
      "large-scale",
      "semantic",
      "benchmark",
      "grounded",
      "novel",
      "scene"
    ],
    "qualityScore": 0.75,
    "link": "https://nicolasgorlo.com/DAAAM_25/",
    "thumbnail_url": "https://nicolasgorlo.com/DAAAM_25/assets/images/Title_Figure_compressed.drawio.png",
    "created_at": "2025-12-17T13:45:43.544Z",
    "topic": "tech"
  },
  {
    "slug": "the-ugly-truth-at-the-heart-of-americas-miserable-job-market",
    "title": "The ugly truth at the heart of America's miserable job market",
    "description": "America's job market is paralyzed — and white-collar workers are struggling to land roles. The real culprit is high interest rates, not AI.",
    "fullText": "When Gbenga Ajilore thinks about America's job market, a few things keep him up at night: The slowing demand for entry-level talent, tariff chaos, and high interest rates.\n\n\"There is going to come a point where AI is just a part of everything that we do, but we're not there yet,\" Ajilore, who is chief economist at the left-leaning Center for Budget Policy and Priorities, said, adding, \"The economy is paralyzed.\"\n\nThe labor market is showing clear signs of weakness. Long-term unemployment has been trending upward, and the share of Americans looking for work recently eclipsed the number of available roles. Alongside a steady drum of layoff headlines, unemployment ticked up more than expected last month to 4.6%. Young people are having trouble breaking in, older workers are hesitant to retire, and with the \"flattening\" of many companies, the middle rungs of the career ladder are crumbling. Only healthcare and construction showed substantial growth. It's been called the white-collar recession, an unwelcome awakening for Americans who hoped their college degree would translate to long-term stability and a comfortable salary.\n\nGiven the timing, it's easy to villainize artificial intelligence. C-Suite leaders across industries have said they're \"all in on AI,\" often to the dismay of rank-and-file employees. The tech is quickly reshaping how workers are assessed on the job and how companies define productivity. It's even shaking up the hiring process: My colleagues have talked to job seekers who submitted hundreds of résumés without landing a role, as HR departments are swamped by AI-assisted applications. Economists and investors can't agree if chatbots are the future of the workforce or a vastly overblown bubble.\n\nBut, in shouldering the blame for America's job market woes, AI has become a scapegoat for something else: The economy itself is deteriorating. Years of higher interest rates and stubborn inflation, along with slowing wage growth and restrictive trade policies, have created an environment where businesses are slashing budgets and the middle class is living paycheck to paycheck.\n\nIf you're frustrated by a lower-than-expected raise or the inability to land a new gig, don't blame the robots. Blame Jerome Powell.\n\nThere is no better example of the AI-is-wrecking-the-job-market fears than the so-called \"Scariest Chart in the World.\" The chart has popped up in X and Bluesky posts, news reports, and a thick stack of Substack newsletters. The simple, two-line chart tracks two pieces of data: the S&P 500 and the number of US job vacancies since 2015. The two run closely together for the first couple of years, but there is a decided break in 2022 — the stock market continues to soar, and the number of available jobs begins to decline. AI doomers are quick to point out that the date those two lines diverged corresponds to the public launch of OpenAI's ChatGPT. The implication being that the explosion of large language models immediately began replacing thousands of jobs while pouring money into Wall Street.\n\nAs chatbots and AI tools make employees more productive — drafting emails, writing code, and streamlining administrative tasks — and employers more profitable, the thinking goes, there will be less need for hiring human workers. There's plenty of anecdotal evidence from high-profile companies to support the idea. Nvidia wants employees to use AI \"for every task possible,\" Microsoft is \"rethinking\" its business model for the AI age, Big Law is hoping AI can make its services faster and cheaper, and top banks and consulting firms are transferring some tasks from people to bots.\n\nBut is AI already replacing a bunch of jobs? Probably not.\n\nAjilore thinks the AI-sparked white collar downturn is \"overblown.\" Many companies are \"using AI as a cheat code as opposed to something that makes them more efficient,\" he said, \"With the cheat code, you actually end up making mistakes and cutting corners.\" He believes that both chatbots and Corporate America's tech strategy have a long way to go before AI truly disrupts the workforce.\n\nEven Federal Reserve Chair Jerome Powell, the most powerful economic policymaker in the world, isn't sold on AI's effects on the current job market. When asked about the technology during the Fed's December meeting, Powell said AI \"is part of the story, but it's not a big part of the story yet.\"\n\nThere's also an important piece of context missing from \"The Scariest Chart in the World\": the federal funds rate. Decided eight times a year by Powell and his colleagues on the all-important (and dully-named) Federal Open Markets Committee, the Fed funds rate is the key interest rate that anchors all types of loans. For banks and businesses, the number determines how easily and cheaply they can borrow money. For consumers, Fed rates impact everything from home prices to auto loans and credit card rates.\n\nWhen interest rates are low, businesses can access debt more affordably, which helps them fuel growth and hiring. As the fed fund rate increases, however, the price of borrowing rises too. This can help keep inflation in check, but higher rates make it more expensive for companies to operate, meaning that many are seeking other areas to cut costs — often at the expense of employees.\n\nIt's true that the S&P 500 and job openings began to diverge right as ChatGPT launched, but that's also when interest rates started to climb. Between early 2022 and late 2024, federal funds jumped by over 5 percentage points. This was a reshaping of monetary strategy meant to curb soaring prices and cool off a too-hot economy, and it was a major break with nearly a generation of previous policy. The Fed originally slashed interest rates to zero in 2008 to address the fallout from the financial crisis, and in the following 12 years, the benchmark interest rate never rose above 2.4%. Following the emergency measures of the early pandemic, the dramatic hikes of 2022 were a sign that the zero-interest-rate era of the 2010s had officially come to an end.\n\nThis sudden interest rate rise was a turning point many businesses. «tweaked the wording here since it was similar to a sentence in the graf above Hiring boomed in the early pandemic: Job openings skyrocketed to record highs as tech and business fields scrambled to snap up new talent. The Beige Book — a collection of quotes and insights gathered from business owners across the country by the various regional Federal Reserve banks — provides a valuable window into the thinking of hiring managers and executives during this period. Labor market commentary across 2021 and 2022 Beige Books tend to reference \"modest to strong\" job growth, robust hiring demand, and a shortage of workers, with very few mentions of interest rates. This changed when the Fed started hiking rates. One note in the November 2022 edition of the Beige Book said that \"Interest rates and inflation continued to weigh on activity,\" another said \"labor demand weakened overall,\" pointing to layoffs in tech, finance, and real estate. Both blue-collar and white-collar sectors felt the brunt of interest rates that year, citing steep borrowing costs as a central reason they're not hiring. Americans, meanwhile, stopped quitting their jobs as vacancies dried up, and the job market saw its biggest layoff spike since the 2020 shutdown.\n\nCorporate America began to lean into \"efficiency\" rhetoric alongside rising rates. Reduced bureaucracy and red tape, along with a smaller workforce, were sold by the C-Suite as a profit panacea in the face of higher financing costs. Leaders at Meta, Amazon, Google, Microsoft, and others spoke about hiring freezes and job cuts as a productivity bet versus a financial issue.\n\nThe trend continued: An October 2023 Beige Book note said many sectors \"reduced hiring plans\" and were \"rightsizing\" their budgets because of rising rates. Fast forward to today, and businesses are still grappling with the increased cost of funding, even as Powell and the Fed have moved slowly to lower their benchmark rate. In October's Beige Book, businesses big and small mentioned layoffs and attrition more so than new hiring. Beige Book reports over the past year suggest that AI is contributing to hiring softening in certain areas, such as call centers and accounting firms, but not widespread job displacement. Instead, \"uncertainty\" and \"tariffs\" were two of the most frequently mentioned words by companies such as Tesla, JPMorgan, and Whirlpool during earnings calls.\n\nBut saying the need for layoffs is the result of a long-term change in the cost of financing isn't very sexy. Better to point to AI as both an excuse for layoffs and a way to give investors hope for the future. Chen Zhao, head of economics research at the real estate firm Redfin, said many companies are struggling to balance profits with the steep cost of borrowing money. This is especially true in the housing sector, she said, because it's sensitive to the federal funds rate. She said fields like tech are similarly vulnerable.\n\n\"I think that what's happening is just simple economics,\" she said, adding, \"But when you say that you're going to do layoffs or you're not going to be hiring as much, it doesn't sound very good to investors. It sounds a lot better if you say that you're seeing all these productivity enhancements because of AI.\"\n\nEach recent technological development — computers, cellphones, the internet — has reshaped the job market and the workplace, but people tend to underestimate the timeline. Economists said it will take years, possibly decades, before we have concrete evidence that AI is replacing jobs on a large scale. And AI may create thousands of jobs as it makes others obsolete.\n\n\"I think the overall evolution of the technology is going to be a lot slower than both the optimists and doomers think,\" said Scott Lincicome, vice president of economics and trade at the right-leaning Cato Institute. AI has developed rapidly, and while it can perform basic tasks, it is still a long way from replacing human judgment, creativity, and decision-making. \"There will certainly be disruptions, that's inevitable,\" he said. \"But it won't be cataclysmic.\"\n\nThe job market is in a rut — but chatbots aren't the sole, or even the main, culprit.\n\nDespite the weakening job market numbers, the Federal Reserve has cut rates three times this year, a cautious policy stance brought on by economic precarity. Recent Fed reports show that trade policy and inflation are keeping Powell and company from cutting rates at a faster pace, even as the employment outlook weakens. It has also sparked division within the central bank itself: The December meeting saw the highest number of Fed members disagreeing with the interest rate committee's final decision since 2019. Economic projections also show the median committee member expects one rate cut in 2026, less than projected at this time last year. The moves signal an economic situation that isn't catastrophic, so long as Powell plays his cards carefully.\n\nA pattern of cuts could start bringing relief for borrowers, but it will take time for the economy to recover — and there are still steep headwinds. Fast-changing tariffs are exacerbating the impact of high rates, making many businesses hesitant to invest or spend money. As Lincicome put it, \"Tariff uncertainty is really a drag on the job market because companies are saddled with millions, if not billions, of dollars in additional taxes and tariff costs.\"\n\nDeclining immigration due to Trump's deportation policies is also part of the equation: Fewer immigrants in the workforce is contributing to a slowing labor force participation rate. Ajilore also said that the sweeping cost-cutting strategy of DOGE for the federal workforce added fuel to the corporate world's \"efficiency\" crusade. It all adds up to some extremely valid job anxiety for workers.\n\nEconomists expect the market to grow and adapt alongside new technology — and the AI takeover forecast is far less grim than most people realize. The chatbot revolution may come someday. But, for better or worse, the real headliner is the federal funds rate.\n\nAllie Kelly is a reporter on Business Insider's Economy team. She writes about social safety nets and how policy impacts people.",
    "readingTime": 11,
    "keywords": [
      "jerome powell",
      "america's job",
      "cheat code",
      "federal funds",
      "funds rate",
      "job openings",
      "rising rates",
      "labor market",
      "interest rates",
      "federal reserve"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/forget-ai-heres-the-real-reason-the-job-market-sucks-2025-12",
    "thumbnail_url": "https://i.insider.com/6941a7ac04eda4732f2d9db9?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:43.527Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-a-genius-its-also-an-idiot-welcome-to-the-jagged-edge",
    "title": "AI is a genius. It's also an idiot. Welcome to the 'jagged edge.'",
    "description": "AI is a game-changer, and it's also not ready for prime time. Which is why it's so hard to predict how it's going to affect our future.",
    "fullText": "Sometimes I use ChatGPT and it seems stunningly obvious that AI is going to have a transformative effect on my life. I use it more every day.\n\nAnd other times I find myself yelling at ChatGPT in ALL CAPS, because it can't do basic, simple tasks — ones I could reasonably farm out to a 5th grader. Or even worse: It can't do basic tasks but won't tell me it can't do them, and tries to fudge a result instead. And that makes me wary of using it again.\n\nIt turns out that the AI business has a great term for this dichotomy: \"The jagged frontier,\" coined in a 2023 research paper. Here's another way of putting it, via Reuters:\n\n\"It might be a Ferrari in math but a donkey at putting things in your calendar,\" said Anastasios Angelopoulos, the CEO and cofounder of LMArena, a popular benchmarking tool.\"\n\nThat quote comes from a report looking at the struggles various businesses have had implementing AI in their work. It's a theme we've been hearing a lot about over the last few months, like the MIT study that found that 95% of companies were getting \"zero return\" on their AI investment.\n\nThis issue is core to the \"Is AI a bubble and when will it pop?\" question, of course. Which is a very important question, with some $2 trillion in investment in play.\n\nBut I think it's not the only question: The tech isn't going away, so many of us are unquestionably going to be using AI in all kinds of ways, no matter what.\n\nSo a more practical question is: What kind of tasks can AI do reliably well today — reliably enough that businesses (and the rest of us) can use it day in and day out — and which ones are going to take a while to sort out? And which ones may never be something we can hand over to AI?\n\nThis is a pretty good summary of the ongoing experiments we're working out in real time, right now.",
    "readingTime": 2,
    "keywords": [
      "can't",
      "tasks",
      "ones",
      "chatgpt",
      "basic",
      "businesses",
      "it's",
      "investment",
      "reliably"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/ai-jagged-edge-work-adoption-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/6941c93f64858d02d216e8f9?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:43.332Z",
    "topic": "finance"
  },
  {
    "slug": "inside-microsoft-ceo-satya-nadellas-ai-revolution",
    "title": "Inside Microsoft CEO Satya Nadella's AI revolution",
    "description": "Internal documents and executive interviews reveal sweeping organizational shifts to radically reshape how the company builds and funds its products.",
    "fullText": "Microsoft CEO Satya Nadella views AI as an existential threat, a once-in-a-generation opportunity, and a chance to cement his legacy at the top of the tech industry.\n\nThe mission is both personal and professional for the Nadella, who is pushing the company to rethink how it operates at every level. That's according to internal Microsoft documents obtained by Business Insider, and interviews with leaders, managers, and other employees at the software giant.\n\nSweeping organizational shifts include high-profile executive changes and mandates for teams to work faster and leaner — all designed to consolidate power around AI leaders and radically reshape how the company builds and funds its products.\n\n\"Satya is pushing on intensity and urgency,\" one Microsoft executive told Business Insider. That's putting pressure on some Microsoft veterans to decide whether they want to stay and commit to the mountain of work it's going to take to complete Nadella's AI revolution.\n\n\"You've gotta be asking yourself how much longer you want to do this,\" this executive added.\n\nNadella is having conversations with executives to sign on for the transformation, or leave, people familiar with the matter said. Many of these people asked not to be identified discussing sensitive matters, although one top executive spoke openly with Business Insider about the CEO's overhaul and Microsoft's AI future.\n\nNadella this year appointed a new CEO of Microsoft's commercial business to free up time to focus on the technical work necessary for his AI ambitions.\n\nAccording to an internal memo, Nadella also started a weekly AI accelerator meeting and corresponding Teams channel to speed the pace of AI work and get more ideas from across the company.\n\nExecutives do not present in these new meetings. Instead, lower-level technical employees are encouraged to speak and share what they're seeing from the AI trenches. This is designed to avoid top-down AI leadership, and is intentionally a bit messy and chaotic, according to people familiar with the new approach.\n\nOther major executive changes are looming. Three Microsoft executives told Business Insider that longtime Office and Windows boss Rajesh Jha has been mulling retirement. Insiders are also chattering about the possibility that Charlie Bell, who runs Microsoft cybersecurity, could retire.\n\nMicrosoft's spokesman Frank Shaw said the company does not expect any changes in the short term to its senior leadership team, of which Bell and Jha are both members.\n\nMicrosoft recently promoted Judson Althoff, its longtime sales chief, to an expanded role as CEO of the company's commercial business.\n\nAlthoff's promotion is intended to give Nadella and the company's engineering leaders more time to focus on AI, according to an internal memo viewed by Business Insider, which described this moment as \"a tectonic AI platform shift.\"\n\nNadella has shifted to saying the company is in the \"middle innings\" rather than the \"early innings\" of AI, a cricket term, and started saying he wants to see the game through, one of the people said.\n\n\"This will also allow our engineering leaders and me to be laser focused on our highest ambition technical work — across our datacenter buildout, systems architecture, AI science, and product innovation — to lead with intensity and pace in this generational platform shift,\" Nadella wrote.\n\nPractically, that's meant Althoff is spending more time as the face of Microsoft at events such as the recent Ignite conference, the first one in Nadella's tenure when the company CEO didn't deliver the keynote.\n\nOne executive told Business Insider the move seems to be paying off so far by giving Nadella \"extra bandwidth to really lead the company in learning, leveraging, and building AI.\"\n\n\"Satya is 100% engaged with leading the company to learn and embrace AI,\" this person said. \"The Judson move was brilliant. It actually allows Satya more time to advance the company in its AI journey. Satya spends a good amount of time in meetings you could characterize as AI learning, product, and engineering.\"\n\nNadella recently announced new marching orders for executives in another Teams channel, this one exclusively for Microsoft corporate vice presidents and above. The CEO said the company is at a turning point at least as significant as the shift to cloud computing and needs to completely rethink its business model.\n\n\"We all have to work and act like ICs in our own orgs, constantly learning and unlearning,\" Nadella wrote, referring to Individual Contributors, someone who is focused on technical work rather than managing people.\n\n\"I chuckle a bit each time someone sends me a note about talking to a friend at an AI start-up, about how differently they're working, how agile, focused, fast they are,\" the CEO added. \"The reality is that this work is also happening right here at Microsoft under our noses! It's our jobs as leaders to seek this out, empower it, cultivate it, and learn from our own early in career talent who are reinventing the new production function!!\"\n\nAsha Sharma, Microsoft CoreAI product president, who joined in 2024, said the company has shifted its operations dramatically in her short tenure. Nadella's new \"production function\" is about using AI to radically change how the company creates, builds, and delivers products and services.\n\nWhen she joined, the AI industry would crank out a big new foundation model roughly every six months. Then, releases happened every six weeks. Today, AI is changing so quickly that it's forcing Microsoft to rethink not just its products but the entire way software is made, Sharma said in an interview arranged by the company.\n\nFor decades, software development has worked like an assembly line. You take a set of inputs — people, time, resources — and transform them into output. Scaling production required scaling those inputs.\n\n\"AI breaks that relationship,\" she said.\n\nAI agents, data, and intelligence now act as a new type of scalable unit that can generate software, insights, and decisions without a corresponding increase in engineering hours or budget. That means the marginal cost of creating something new drops dramatically, Sharma explained, and teams can now spend more on \"judgment, taste, and problem-solving.\"\n\nWith so much changing, it's natural that leadership evolves — and Microsoft insiders expect more changes at the top.\n\nJha, a veteran executive who oversees famous Microsoft products such as Office and Windows, has been mulling retirement, according to three executives who spoke to Business Insider.\n\nStill, one of these executives noted that Jha has a newfound excitement about the company's AI potential, so he could stick around for Nadella's new intense era.\n\nIf Jha leaves, LinkedIn CEO Ryan Roslansky might succeed him, these executives said. Roslansky has been running LinkedIn since 2020 and Microsoft recently expanded Roslansky's role to include Outlook, Word, Excel, PowerPoint, and the Microsoft 365 Copilot application, according to an internal announcement from Nadella in June.\n\nRoslansky started reporting to Jha for his new duties as executive vice president of Office, and to Nadella in his capacity as LinkedIn CEO, according to organizational charts viewed by Business Insider.\n\nCharles Lamanna, president of the business and industry Copilot group responsible for building AI tools like low-code applications, also moved to report to Jha at the time, and is taking on a bigger profile within the company, the people said.\n\nHave a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 7,
    "keywords": [
      "commercial business",
      "mulling retirement",
      "shift nadella",
      "platform shift",
      "production function",
      "microsoft recently",
      "internal memo",
      "teams channel",
      "business insider",
      "engineering leaders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-ceo-satya-nadella-ai-revolution-2025-12",
    "thumbnail_url": "https://i.insider.com/6941bb9a832e0ef1ead6527a?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:43.332Z",
    "topic": "finance"
  },
  {
    "slug": "meet-one-of-blackrocks-top-technologists-who-is-supercharging-its-investment-teams-with-ai",
    "title": "Meet one of BlackRock's top technologists who is supercharging its investment teams with AI",
    "description": "Kirsty Craig recently earned the distinction of tech fellow, partly because of her efforts to transform how BlackRock's investors work.",
    "fullText": "For 15 years, BlackRock's Kirsty Craig has operated as a kind of \"translator\" inside the world's largest asset manager, sitting between portfolio managers making big bets and engineers building the systems that help inform those decisions to get both sides aligned on driving returns.\n\nThis skill set is part of what earned Craig, head of research, data, and AI strategy for portfolio management tech, the title of Tech Fellow, one of the firm's high technological distinctions, held by only two dozen of its thousands of engineers. Craig is one of five new fellows that the firm announced on December 16, recognized for supercharging the asset manager's investment team. This year, she is the only woman and the only fellow who works outside of Aladdin, the lucrative spine of BlackRock's investment technology.\n\nWhen it comes to her impact on how $13.5 trillion money manager BlackRock uses AI, Craig said she's especially proud of her role in Asimov, the agentic AI platform for the firm's fundamental equity business. The \"virtual investment analyst\" was unveiled by Chief Operating Officer Rob Goldstein at the firm's investor day in June.\n\nIt leverages AI to automate workflows and research, as many firms race to adopt the technology to speed up what were once monthslong investment processes.\n\nNow, as a fellow, Craig is even more embedded in BlackRock's efforts to stay ahead, as the firm continues to center on technological prowess.\n\nAt first, Craig wasn't sure she'd become a tech fellow, largely because her work is different than most of the other fellows who work squarely within BlackRock's data analytics and risk platform, Aladdin. Her team of around 60 software engineers, data engineers, and data scientists \"sits at the horizontal\" across various investment capabilities to help drive investment research.\n\nShe found out about the honor at the beginning of the month when a meeting was added to her calendar.\n\nWhen she heard the news, Craig started by telling the manager who had nominated her, her sponsor during the application process, her team, and her family, \"but they've got no idea what it means,\" she told Business Insider.\n\nNish Ajitsaria, BlackRock's co-head of Aladdin product engineering and the co-executive sponsor of the fellows program, said that existing tech fellows knew Craig not only for her innovation with AI in investing, but for her collaborative efforts. He described Craig as an \"AI native,\" and added that her team is at the \"tip of the spear\" when it comes to applying AI to investment.\n\nCraig's time at different offices — Edinburgh, San Francisco, and now Philadelphia — has, she thinks, given her a strong foundation of horizontal leadership across teams.\n\n\"I am responsible for really trying to find the dial movers across data, AI, and technology that really help our investment pillars drive investment research,\" she said of her work.\n\nCraig has learned how to communicate with both investors and Aladdin technologists, and said that building deep trust with both groups has been key to her success.\n\n\"If you put both of those different personalities or personas together, quite often they're talking above or below each other. They struggle to connect. So for me, it's really been being able to translate both and then come up with a strategy in the middle,\" she said.\n\nFor Craig, being a woman in a position of visible leadership is \"a huge honor.\" Of the 24 tech fellows, five are women, including Craig. Women make up 43.8% of BlackRock's global workforce and 33.1% of senior leadership, according to data from January 1, 2025, posted on the firm's site.\n\nCraig said being involved in BlackRock's women and LGBTQ+ resource groups has informed her other work at the firm, especially in how they've taught her how to collaborate with people from across divisions and explain complicated topics.\n\n\"If anything has probably helped me with, one, building my network; two, softer presentation skills; and then three, around how to communicate with impact,\" Craig said. With the title, she hopes to help more junior female technologists \"lean in.\"\n\nFor Ajitsaria, it's also important to have a diversity of expertise in the program and ensure that fellows represent all arms of BlackRock.\n\nWhen it comes to driving technology strategy itself, Craig said she's excited to keep figuring out how to leverage AI in active investing. Right now, her team is thinking about how to expand the scope of agentic research, potentially to areas like fixed income and macro investing.\n\nAs she continues to soak up the news, Craig is also preparing for a very different big life change. Her partner is scheduled to give birth in early January, so, with the due date mere weeks away, Craig said they've kept all celebrating fairly tame so far.\n\n\"We did go out for a meal. Nothing has been purchased, apart from cribs and bottles,\" she said. \"Definitely some more celebrating will be done post January 6.\"",
    "readingTime": 5,
    "keywords": [
      "drive investment",
      "tech fellows",
      "investment research",
      "craig",
      "team",
      "engineers",
      "firm's",
      "technology",
      "across",
      "manager"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blackrock-tech-fellow-ai-investment-asimov-aladdin-2025-12",
    "thumbnail_url": "https://i.insider.com/69408098832e0ef1ead6423e?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:43.196Z",
    "topic": "finance"
  },
  {
    "slug": "big-short-investor-michael-burry-has-broken-his-silence-heres-what-hes-revealed-in-7-weeks-of-speaking-freely",
    "title": "'Big Short' investor Michael Burry has broken his silence. Here's what he's revealed in 7 weeks of speaking freely.",
    "description": "Michael Burry of \"The Big Short\" fame has sounded the alarm on an AI bubble, dismissed bitcoin as \"worthless,\" and revisited his GameStop bet.",
    "fullText": "The mysterious Michael Burry has pulled back the curtain over the past six weeks, revealing his views on everything from bitcoin and meme stocks to the AI boom and the Federal Reserve.\n\nThe investor of \"The Big Short\" fame was previously known for posting cryptic warnings on X, only to swiftly delete them and go silent for months or years at a time.\n\nHe has now closed his hedge fund to outside cash, and shifted his focus to writing about his personal investments and sharing his financial analyses on Substack.\n\nBusiness Insider trawled through Burry's Substack, X posts, and a recent podcast interview with author Michael Lewis to gather the key insights and details he has shared so far.\n\nBurry returned to X in late October after going quiet in April 2023. His commentary since then has centered on concerns of a historic bubble in AI.\n\nHe has warned that the tech companies leading the charge are seeing a slowdown in cloud-computing growth, overinvesting in equipment such as Nvidia chips and data centers, dragging out depreciation to inflate their short-term earnings, destroying shareholder value through excessive stock-based compensation, and signing \"give-and-take\" contracts with one another to keep the buzz going.\n\nBurry — who shot to fame after his lucrative bet against the mid-2000s housing boom was chronicled by Lewis in \"The Big Short\" — has also compared AI mania to the dot-com and housing bubbles, predicting it too will end in disaster.\n\nHe has labeled OpenAI the \"Netscape of our time,\" saying it's \"hemorrhaging cash.\" He has disclosed bets against market darlings Nvidia and Palantir, and predicted the AI bubble will burst within two years. He has also advised investors who've won big on high-flying assets to cash out their winnings.\n\n\"I think the stock market could be in for a number of bad years,\" he told Lewis during what might be his final interview, per his Substack.\n\nBurry also said that bitcoin trading at $100,000 was \"the most ridiculous thing\" as it's \"not worth anything,\" and called it \"worse than a tulip bulb\" because it has enabled so much crime. The most popular cryptocurrency now trades below $90,000.\n\nOn the other hand, Burry revealed that he has owned gold since 2005, and described Google-parent Alphabet as the \"value investor's favorite\" among mega-cap tech stocks.\n\nBurry told Lewis that the Fed has \"done a lot of damage\" since its founding more than a century ago.\n\nHe said the US central bank doesn't do \"anything very helpful,\" and the Treasury could just have a department to set interest rates and control the money supply instead.\n\nBurry has also warned that the US banking system is showing signs of \"fragility,\" and banks are \"getting weaker way too fast.\"\n\nMoreover, he has defended his past comments on the regional banking fiasco, pandemic-fueled inflation, and a potential meme-stock crash, saying his calls were largely on the money.\n\nHe has shared details of his personal portfolio, including that he has emulated most of his fund's positions and owns shares of Lululemon, Molina Healthcare, Shift4 Payments, Fannie Mae, and Freddie Mac.\n\nIn a Monday post, he revisited his sale of GameStop shortly before the meme stock skyrocketed in January 2021, saying he had \"no idea what was coming.\" He also teased a future post that will be a \"breakdown of GameStop as an investment today.\"\n\nBurry's other revelations so far include the fact that he has known Nvidia's finance chief, Colette Kress, for years, and bought the chipmaker's stock in 2017 or 2018.\n\nAs promised in his Substack's name, \"Cassandra Unchained,\" Burry is speaking freely for the first time in many years — and may just be getting started.",
    "readingTime": 4,
    "keywords": [
      "the big short",
      "cash",
      "saying",
      "stock",
      "burry",
      "bitcoin",
      "meme",
      "stocks",
      "boom",
      "fame"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-short-michael-burry-substack-ai-bubble-stock-picks-bitcoin-2025-12",
    "thumbnail_url": "https://i.insider.com/69401b9e04eda4732f2d8380?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:42.963Z",
    "topic": "finance"
  },
  {
    "slug": "openai-hires-former-uk-chancellor-to-lead-its-global-stargate-project",
    "title": "OpenAI hires former UK chancellor to lead its global Stargate project",
    "description": "The ChatGPT maker has hired former British Chancellor George Osborne to run the global arm of its \"Stargate\" AI infrastructure initiative.",
    "fullText": "Tech companies are snapping up former world leaders and politicians — and OpenAI is the latest to join the party.\n\nThe ChatGPT maker has hired former British chancellor George Osborne to run the global arm of its Stargate AI infrastructure initiative.\n\n\"I recently asked myself the question: what's the most exciting and promising company in the world right now? The answer I believe is OpenAI,\" wrote Osborne, who ran the UK Treasury from 2010 to 2016, in a Tuesday X post confirming the move.\n\nOsborne takes the role of managing director and head of OpenAI for Countries, an initiative launched by the AI startup in May that will see OpenAI partner with nations to build data centers and expand its $500 billion Stargate project beyond the US.\n\nThe former finance minister, who was a member of parliament in the right-leaning Conservative party until 2017, is the latest ex-British political heavyweight to join a US tech firm.\n\nRishi Sunak, the former UK prime minister, took on roles at OpenAI rival Anthropic and Microsoft as an advisor in October, while ex-deputy prime minister Nick Clegg worked as a senior executive on Meta's global affairs team from 2018 until stepping down at the start of 2025.\n\nBritish political salaries are dwarfed by the earnings of even midlevel employees at US tech companies. British prime ministers earn an annual salary of around £174,000 ($232,000), while salaries for research engineers at Meta can be as high as $400,000.\n\nOsborne's arrival comes as OpenAI continues to bulk up its executive ranks. The AI startup hired former Instacart and Meta exec Fidji Simo as its new CEO of applications in May, and this week hired veteran Google executive Albert Lee to lead its mergers and acquisitions team.",
    "readingTime": 2,
    "keywords": [
      "prime minister",
      "openai",
      "tech",
      "hired",
      "british",
      "executive",
      "latest",
      "join",
      "party",
      "initiative"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-hires-george-osborne-uk-chancellor-global-stargate-2025-12",
    "thumbnail_url": "https://i.insider.com/694288b764858d02d216ef7e?width=1200&format=jpeg",
    "created_at": "2025-12-17T13:45:42.834Z",
    "topic": "finance"
  }
]
[
  {
    "slug": "the-best-big-media-merger-is-no-merger-at-all",
    "title": "The Best Big Media Merger Is No Merger at All",
    "description": "The state of streaming is... bad. It‚Äôs very bad. The first step in wanting to watch anything is a web search: ‚ÄúWhere can I stream X?‚Äù Then you have to scroll past an AI summary with no answers, and then scroll past the sponsored links.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.eff.org/deeplinks/2025/12/best-big-media-merger-no-merger-all",
    "thumbnail_url": "https://www.eff.org/files/banner_library/icon-2019-innovation.png",
    "created_at": "2025-12-12T13:47:26.391Z",
    "topic": "tech"
  },
  {
    "slug": "disney-wants-you-to-aigenerate-yourself-into-your-favorite-marvel-movie",
    "title": "Disney wants you to AI-generate yourself into your favorite Marvel movie",
    "description": "The media company is investing $1bn in OpenAI ‚Äì and allowing its characters to be used in generated videos\nUsers of OpenAI‚Äôs video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney‚Äôs animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora‚Äôs output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n Continue reading...",
    "fullText": "The media company is investing $1bn in OpenAI ‚Äì and allowing its characters to be used in generated videos\n\nUsers of OpenAI‚Äôs video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney‚Äôs animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\n\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora‚Äôs output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n\nDisney announced that it would invest $1bn in OpenAI and, under a three-year deal perhaps worth even more than that large sum, that it would license about 200 of its iconic characters ‚Äì from R2-D2 to Stitch ‚Äì for users to play with in OpenAI‚Äôs video generation app.\n\nAt a time of intense anxiety in Hollywood over the impact of AI on the livelihoods of writers, actors, visual effects artists and other creatives, Disney stressed its agreement with OpenAI would not cover talent likenesses or voices.\n\nThe announcement was framed as an extraordinary opportunity to empower fans.\n\nThink of the ‚Äúfan-inspired Sora short form videos‚Äù, as Disney called them in a press release ‚Äì akin to taking an AI-generated version of a photo with Princess Jasmine at Disney World. OpenAI included screenshots of these kinds of videos in its press release, indicating how the two companies expect people to use the app‚Äôs new cast. Sora already allows users to generate videos that include their own likenesses.\n\nBob Iger, Disney‚Äôs CEO, said the licensing deal would place ‚Äúimagination and creativity directly into the hands of Disney fans in ways we‚Äôve never seen before‚Äù.\n\nThey may even offer a chance at wide viewership, with some fan-made videos being displayed on the Disney+ streaming service, a move seemingly designed to compete with TikTok‚Äôs and YouTube Shorts‚Äô infinite feeds, which themselves often include clips of popular TV shows and movies.",
    "readingTime": 2,
    "keywords": [
      "press release",
      "generation app",
      "allows users",
      "generate videos",
      "characters",
      "disney",
      "announcement",
      "startup",
      "deal",
      "likenesses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2025/dec/11/disney-openai-sora",
    "thumbnail_url": "https://i.guim.co.uk/img/media/d99390e95d50b47f91bcc8a3130e524c618e635d/436_0_4324_3458/master/4324.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=67d482fa7d7bed846eb736aeb1dfde1c",
    "created_at": "2025-12-12T13:47:25.564Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-teams-with-el-salvador-to-bring-grok-chatbot-to-public-schools",
    "title": "Elon Musk teams with El Salvador to bring Grok chatbot to public schools",
    "description": "President Nayib Bukele entrusting chatbot known for calling itself ‚ÄòMechaHitler‚Äô to create ‚ÄòAI-powered‚Äô curricula\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company‚Äôs chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to ‚Äúdeploy‚Äù the chatbot to more than 5,000 public schools in an ‚ÄúAI-powered education program‚Äù.\nxAI‚Äôs Grok is more known for referring to itself as ‚ÄúMechaHitler‚Äù and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried ‚Äúwhite genocide‚Äù and claimed Donald Trump won the 2020 election.\n Continue reading...",
    "fullText": "President Nayib Bukele entrusting chatbot known for calling itself ‚ÄòMechaHitler‚Äô to create ‚ÄòAI-powered‚Äô curricula\n\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company‚Äôs chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to ‚Äúdeploy‚Äù the chatbot to more than 5,000 public schools in an ‚ÄúAI-powered education program‚Äù.\n\nxAI‚Äôs Grok is more known for referring to itself as ‚ÄúMechaHitler‚Äù and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried ‚Äúwhite genocide‚Äù and claimed Donald Trump won the 2020 election.\n\nNayib Bukele, El Salvador‚Äôs president, is now entrusting the chatbot to create curricula in classrooms across the country. Bukele has long embraced technology, making El Salvador the first county in the world to use bitcoin as legal tender, and being one of the first Central American presidents to use Twitter, now X, as a platform. He is also known for ruling with an iron fist and working with Trump to incarcerate deportees to El Salvador‚Äôs notorious Cecot prison.\n\n‚ÄúEl Salvador doesn‚Äôt just wait for the future to happen; we build it,‚Äù Bukele said in a statement about the partnership with xAI. ‚ÄúThis partnership is destined to deliver something rather extraordinary for all of humanity.‚Äù\n\nMusk touted his partnership with Bukele on Thursday. On X, between posts about ‚Äúwhite genocide‚Äù and blaming asylum seekers for crime, Musk posted comments about Grok being spread throughout El Salvador‚Äôs schools.\n\nHe reposted positively to a comment from Katie Miller, the wife of Trump‚Äôs senior adviser Stephen Miller, in which she wrote: ‚ÄúIf we are serious about restoring education to math, science and English ‚Äì why would we allow left leaning liberal [sic] AI our kids? This unlocks non-woke educational tools for our kids.‚Äù\n\nxAI is not the first artificial intelligence company to introduce chatbots to public schools. OpenAI announced a partnership with Estonia in February where it could provide all students and teachers in the country‚Äôs secondary school system with a customized ChatGPT. Students in rural Colombia also started using Meta‚Äôs AI chatbots in 2023 and within a year, teachers began blaming the tech for low grades and failing exams, according to Rest of World.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‚ÄòSecure Messaging‚Äô.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips¬†lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 3,
    "keywords": [
      "nayib bukele",
      "guardian app",
      "artificial intelligence",
      "white genocide",
      "el salvador",
      "el salvador‚Äôs",
      "chatbot",
      "partnership",
      "grok",
      "schools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/11/elon-musk-el-salvador-grok",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7110440275e2c1e8231708520c23cbc728846c00/401_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=585578e2aeb3d5963fc6677b1ca099f4",
    "created_at": "2025-12-12T13:47:25.075Z",
    "topic": "tech"
  },
  {
    "slug": "mcp-and-workflow-for-specdriven-development-with-claude-code",
    "title": "MCP and workflow for spec-driven development with Claude Code",
    "description": "Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust ü¶Ä - marconae/spec-oxide",
    "fullText": "marconae\n\n /\n\n spec-oxide\n\n Public\n\n Spec-driven development for humans and AI - optimised for Claude Code with built-in MCP. Written in Rust ü¶Ä\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n marconae/spec-oxide",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/marconae/spec-oxide",
    "thumbnail_url": "https://opengraph.githubassets.com/e5b240d3d85c84aad2b2aff0a433f6f4034b00bbdd75ee07c24ade4e6e0525c7/marconae/spec-oxide",
    "created_at": "2025-12-12T13:47:24.935Z",
    "topic": "tech"
  },
  {
    "slug": "disney-plus-openai-what-could-possibly-go-wrong",
    "title": "Disney plus OpenAI: What could possibly go wrong?",
    "description": "Disney‚Äôs deal with OpenAI may prove prescient and astute, but it doesn't take a lot of imagination to think about the nightmare scenarios.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/disney-plus-openai-what-could-possibly-go-wrong/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2251267095-e1765501885187.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.330Z",
    "topic": "business"
  },
  {
    "slug": "openai-microsoft-face-wrongful-death-lawsuit-over-paranoid-delusions-that-led-former-tech-worker-into-murdersuicide",
    "title": "OpenAI, Microsoft face wrongful death lawsuit over ‚Äòparanoid delusions‚Äô that led former tech worker into murder-suicide",
    "description": "Police said Stein-Erik Soelberg, 56, fatally beat and strangled his 83-year-old mother, Suzanne Adams, and then killed himself in early August.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-microsoft-wrongful-death-lawsuit-murder-suicide-greenwich-connecticut-chatgpt/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/AP25345700615297.jpg?resize=1200,600",
    "created_at": "2025-12-12T13:47:22.159Z",
    "topic": "business"
  },
  {
    "slug": "an-ai-agent-spent-16-hours-hacking-stanfords-network-it-outperformed-human-pros-for-much-less-than-their-sixfigure",
    "title": "An AI agent spent 16 hours hacking Stanford's network. It outperformed human pros for much less than their six-figure salaries.",
    "description": "An AI agent hacked Stanford's network for 16 hours and outperformed human pros, all while costing far less than their six-figure pay.",
    "fullText": "For 16 hours, an AI agent crawled Stanford's public and private computer science networks, digging up security flaws across thousands of devices.\n\nA study published Wednesday by Stanford researchers found that their AI agent, ARTERMIS, placed second in an experiment with 10 selected cybersecurity professionals. The researchers said the agent could uncover weaknesses that humans missed and investigate several vulnerabilities at once.\n\nRunning ARTEMIS costs about $18 an hour, far below the average salary of about $125,000 a year for a \"professional penetration tester,\" the study said. A more advanced version of the agent costs $59 an hour and still comes in cheaper than hiring a top human expert.\n\nThe study was led by three Stanford researchers ‚Äî Justin Lin, Eliot Jones, and Donovan Jasper ‚Äî whose work focuses on AI agents, cybersecurity, and machine-learning safety. The team created ARTEMIS after finding that existing AI tools struggled with long, complex security tasks.\n\nThe researchers gave ARTEMIS access to the university's network, consisting of about 8,000 devices, including servers, computers, and smart devices. Human testers were asked to put in at least 10 hours of work while ARTEMIS ran 16 hours across two workdays. The comparison with human testers was limited to the AI's first 10 hours.\n\nThe study also tested existing agents, which lagged behind most human participants, while ARTEMIS performed \"comparable to the strongest participants,\" the researchers said.\n\nWithin the 10-hour window, the agent discovered \"nine valid vulnerabilities with an 82% valid submission rate,\" outperforming nine of 10 human participants, the study said.\n\nSome of the flaws had gone unnoticed by humans, including a weakness on an older server that testers could not access because their browsers refused to load it. ARTEMIS bypassed the issue and broke in using a command-line request.\n\nThe AI worked in a way humans could not, the researchers said. Whenever ARTEMIS spotted something \"noteworthy\" in a scan, it spun up additional \"sub-agents\" to investigate in the background, allowing it to examine multiple targets simultaneously. Human testers had to do this work one step at a time.\n\nBut the AI isn't flawless. ARTEMIS struggled with tasks that required clicking through graphical screens, causing it to overlook a critical vulnerability. It is also more prone to false alarms, mistaking harmless network messages for signs of a successful break-in.\n\n\"Because ARTEMIS parses code-like input and output well, it performs better when graphical user interfaces are unavailable,\" the researchers said.\n\nAdvances in AI have lowered the barrier to hacking and disinformation operations, allowing malicious actors to enhance their attacks.\n\nIn September, a North Korean hacking group used ChatGPT to generate fake military IDs for phishing emails. A report from Anthropic in August found that North Korean operatives used its Claude model to obtain fraudulent remote jobs at US Fortune 500 tech companies ‚Äî a tactic that gave them insider access to corporate systems.\n\nThe same report also said a Chinese threat actor used Claude to run cyberattacks on Vietnamese telecom, agricultural, and government systems.\n\n\"We are seeing many, many attacks,\" Yuval Fernbach, the chief technology officer of machine learning operations at software supply chain company JFrog, told Business Insider in a report published in April. He added that hackers have been using AI models to extract data, shut systems down, or manipulate a website or tools.",
    "readingTime": 3,
    "keywords": [
      "stanford researchers",
      "human testers",
      "human participants",
      "agent",
      "study",
      "hours",
      "devices",
      "humans",
      "hour",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-agent-hacker-stanford-study-outperform-human-artemis-2025-12",
    "thumbnail_url": "https://i.insider.com/693bccf004eda4732f2d6a8d?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.654Z",
    "topic": "science"
  },
  {
    "slug": "im-the-former-chief-ai-officer-at-gm-being-the-caio-is-like-being-the-master-chef-of-a-restaurant",
    "title": "I'm the former chief AI officer at GM. Being the CAIO is like being the master chef of a restaurant.",
    "description": "Barak Turovsky said that if a company wants to integrate AI on a software level, it needs someone with a different kind of expertise.",
    "fullText": "This as-told-to essay is based on a conversation with Barak Turovsky, the former Chief AI Officer at General Motors, based in Silicon Valley. He also held executive roles at Google and Cisco. The following has been edited for length and clarity.\n\nI have worked on AI and LLMs since 2014 ‚Äî way before they became the hottest thing on Earth.\n\nI'm an ex-Google AI exec who led the first scaled deployment of LLMs and Deep Neural Networks with Google Translate. I also worked as the Chief Product and Technology Officer at a computer vision AI startup, and as the VP of AI at Cisco.\n\nGeneral Motors approached me for the Chief AI Officer role while I was at Cisco, and it felt like a great crash course on using AI to develop physical products. The role no longer exists because I left after GM restructured its software and AI organization; however, until November, I reported to the head of software engineering, who reported to the CEO.\n\nSome people ask, \"Do you really need a dedicated AI officer?\"\n\nLet's ignore the title because you can call it different names, but I do believe successful AI implementation requires someone in leadership to drive that change, as well as commitment from the top.\n\nFunctional business leaders, such as the CTO or CIO, may have little or no understanding of AI. If you want to integrate AI on a software level, you need someone with a different kind of expertise.\n\nTraditional large companies have powerful executives who want to own the benefits of scaling AI, but not necessarily the responsibility. Therefore, someone with deep AI knowledge is needed to direct the traffic.\n\nI like to use a restaurant analogy to break it down.\n\nThe analogy is based on three primary resources that create products, or dishes. The first resource includes the kitchen equipment, or the AI infrastructure and models necessary to build AI solutions.\n\nThe next can be thought of as the ingredients. It's the data or internal assets used to train and run AI solutions. The last one is talent, or the restaurant staff. You need expertise at different levels ‚Äî busboys, short-order cooks, sous chefs, and master chefs for the really gourmet restaurants.\n\nThe complexity of creating the final product depends on the company's needs, specifically whether the restaurant needs to prepare the food internally. For very advanced, cutting-edge models, which can be thought of as the main course at a gourmet restaurant, companies often need to develop their own AI solutions because standard versions may not perform the required functions.\n\nThink of the CAIO as the master chef. They need to make sure all the different pieces run smoothly. If you are in an industry that requires cutting-edge solutions, you also need to spend a lot of time making sure that the hardest output ‚Äî a.k.a. the main dish ‚Äî comes out just right.\n\nThe hardest and most important part of the job is securing top talent. Vendors will tell you that their toaster ovens can pop out a French souffl√© in 15 minutes. Yet your ingredients will consistently arrive late, of dubious quality, and in incorrect amounts. Your customers will come in, declare they are hungry and want to eat the whole menu, and then leave mid-meal without paying.\n\nThe specifics of each role vary. At GM, I worked on a cutting-edge area because AI for physical products, like cars, is largely untouched and getting a lot of traction.\n\nThere are three buckets of what a chief AI officer should do. First is AI talent management. I focused a lot on hiring a top-tier team, which is very important because the moment you enter a novel space, you have a small sliver of talent. They need to be motivated and flexible because you're still mapping out those areas.\n\nThen, you need to create a culture of innovation for the company in general. You need to work with internal stakeholders who might be used to doing things in a certain way, but need to change because of AI.\n\nYou also need to create organizational change, which starts with mapping the needs and players of your organization. You have people who are AI enthusiasts and skeptics. In a large organization, it's not always easy to identify them. You need to create a top-down and bottom-up framework, which includes clear goals from the top.\n\nIn every function, you need to identify champions, and you need to nurture and empower them. The CAIO can't do all the magic while everyone else just sits there.",
    "readingTime": 4,
    "keywords": [
      "physical products",
      "chief ai officer",
      "restaurant",
      "create",
      "solutions",
      "talent",
      "based",
      "role",
      "software",
      "organization"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/former-chief-ai-officer-general-motors-describes-role-2025-12",
    "thumbnail_url": "https://i.insider.com/6939ee6304d0f0a114f1ce51?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.547Z",
    "topic": "auto"
  },
  {
    "slug": "how-can-lawyers-stop-ais-hallucinations-more-ai-of-course",
    "title": "How can lawyers stop AI's hallucinations? More AI, of course.",
    "description": "Law firms can't stop lawyers from tinkering with chatbots, so they're adding hallucination detectors.",
    "fullText": "Law firm Cozen O'Connor has a rule against using publicly available chatbots to draft legal filings. But after a judge penalized two of its lawyers for citing fake cases, the firm is adding some extra protection: an AI hallucination detector.\n\nCozen O'Connor is now testing software, made by a startup called Clearbrief, that scans legal briefs for made-up facts and produces a report. Think spell-check, except instead of flagging typos, it spots the fictional cases and citations that generative tools sometimes invent.\n\n\"You have to be pragmatic,\" said Kristina Bakardjiev, the Cozen O'Connor partner tasked with harnessing technology to serve lawyers and their clients. She said lawyers will play around with chatbots whether the tools are authorized or not.\n\nStung by embarrassing AI hallucinations, the legal field has adopted bans on general-use chatbots and AI assistants. But it's hard to stop a curious associate from pasting a draft into a free, browser-based chatbot like ChatGPT, Claude, or Gemini. Now law firms and legal tech companies are scrambling to lower the risk of bogus citations and catch those that sneak through before they land in front of a judge.\n\nTwo of Cozen O'Connor's defense lawyers in September admitted they had filed a document riddled with fake cases after one of them used ChatGPT to draft it, against firm policy. A Nevada district court judge gave the firm a choice: remove the lawyers from the case and pay $2,500 in sanctions each, or have the pair write to their former law school deans and bar authorities explaining the fiasco and offering to speak in seminars on topics like \"professional conduct.\"\n\nBoth lawyers went with option No. 2. Cozen also fired the lawyer who had used ChatGPT.\n\nEarlier this year, Damien Charlotin, a legal data analyst and consultant, began tracking cases in which a court had discovered hallucinated content in a legal filing. Charlotin tallied 120 cases between April 2023 and May 2025. By December, his count had hit 660, with the rate of new cases accelerating to four or five per day.\n\nThe number of documented cases remains small relative to the total volume of legal filings, Charlotin said. Most cases in his database involved self-represented litigants or lawyers from small or solo firms. When large firms were involved, the hallucinations often slipped in through the work of junior staff, paralegals, experts, or consultants, or through processes like formatting footnotes, Charlotin said.\n\nHallucinated content is causing headaches in other professions, too. In October, consulting firm Deloitte agreed to pay a partial refund to the Australian government for a $290,000 report after officials found it was peppered with allegedly AI-generated errors.\n\nAI hallucinations are hard to eliminate because they're baked into the way chatbots work. Large language models are trained to predict the word that is most likely to come next, given the words before it.\n\nMichael Dahn, a senior vice president at Thomson Reuters who leads global product teams for legal-research service Westlaw, says the model makers can't get hallucinations to zero for answering open-ended questions about the world. However, companies can dramatically reduce their risk by forcing a large language model to cite from a specific data set, like a corpus of case law and treatises. The model can still mismatch or overlook content, but wholesale fabrications are far less likely.\n\nThomson Reuters and LexisNexis are selling that promise to customers: that an artificial assistant confined to their walled gardens of vetted material is safer than a chatbot trained on the open internet. Both companies have spent decades and heaps of money building deep repositories of case law and other legal content. More recently, they've bolted on AI-powered tools to help lawyers search and cite their data. They now have to defend their positions against services like ChatGPT and Claude that are creeping into the legal field.\n\nLexisNexis has also extended its moat to Harvey, the legal tech startup whose valuation has climbed to $8 billion. Harvey struck a partnership with LexisNexis this year that pipes one of the world's biggest legal databases into Harvey's generative tools.\n\nHarvey also works with AI model providers, such as OpenAI and Anthropic, to constrain which datasets they're allowed to draw from and layer in Harvey's own proprietary datasets, a spokesperson said. Lawyers can then inspect logs that show how an answer was reached and what data fed into it.\n\nClearbrief makes a drafting tool for litigators that works as a Microsoft Word plug-in. Jacqueline Schafer, a former litigator who founded Clearbrief, says its product detects citations using natural language processing, and creates links to the relevant case law or documents from the case. The tool calls out citations and facts that are fabricated or contain typos. The tool also points to places where the underlying source doesn't quite support what the writer claims.\n\nCozen O'Connor has been testing a new Clearbrief feature that lets users generate a cite-check report before passing a draft to a partner or filing it in court.\n\nSchafer says partners at large firms trust their junior staff to check citations rather than vetting every case themselves. Still, federal rules hold the partners who sign filings personally responsible for their accuracy.\n\nPart of Clearbrief's appeal for Cozen O'Connor is the paper trail. The firm is upgrading its knowledge management system, and Bakardjiev imagines that someday the firm might store cite-check reports alongside drafts and final filings, creating a chain of custody for every brief.\n\nIf a judge ever asks what a partner did to prevent hallucinated citations, Bakardjiev said, partners can point to a report that shows who ran the check and when.\n\nThe legal world is likely to live with hallucinations for a long time. The unglamorous part of the solution is training lawyers to treat the chatbot output as a starting point, not the finished work. The other answer: throwing more AI at the AI.\n\nHave a tip? Contact this reporter via email at mrussell@businessinsider.com or Signal at @MeliaRussell.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "junior staff",
      "generative tools",
      "hallucinated content",
      "fake cases",
      "legal field",
      "legal tech",
      "cozen o'connor",
      "legal filings",
      "lawyers",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lawyers-legal-tech-companies-fight-ai-chatgpt-hallucinations-2025-12",
    "thumbnail_url": "https://i.insider.com/693b4101832e0ef1ead6199f?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.418Z",
    "topic": "finance"
  },
  {
    "slug": "larry-ellison-just-lost-25-billion-of-his-net-worth-in-one-day",
    "title": "Larry Ellison just lost $25 billion of his net worth in one day",
    "description": "Larry Ellison saw his wealth plunge after Oracle's earnings miss spooked investors and raised fresh questions about the company's massive AI spending.",
    "fullText": "Larry Ellison just took a $25 billion hit to his net worth.\n\nThe Oracle cofounder saw billions wiped off his fortune on Thursday, according to estimates on Bloomberg's Billionaire Index, after the software giant's shares fell by more than 11% on weaker-than-expected earnings results.\n\nThe hit brought Ellison's net worth down to $258 billion, per the Index, marking one of the biggest single-day wealth drops of 2025.\n\nOther billionaires suffered steeper or similar losses in April: Elon Musk lost $35 billion in just three days, and Mark Zuckerberg shed about $24 billion as Trump's tariff plans sparked fears of retaliation and recession.\n\nEarlier this year, Ellison briefly took the crown of world's richest person, overtaking Musk in September when Oracle shares surged as much as 43% due to a strong forecast for its cloud business.\n\nOracle missed Wall Street's revenue expectations in its most recent earnings results, which were reported on Wednesday. Shares fell more than 11% in after-hours trading, extending a slide that began in October as investors questioned the company's breakneck spending on artificial intelligence infrastructure.\n\nDespite missing estimates, revenue was up 14% year-over-year during the quarter. But that wasn't enough to calm concerns over the scale and cost of its expansion.\n\nThose worries dominated Wednesday's call with analysts.\n\nClay Magouyrk, Oracle's co-CEO, pushed back on fears that the company might need more than $100 billion to build out its data centers ‚Äî a figure some analysts had floated.\n\n\"We expect we will need less, if not substantially less, money raised than that,\" he said, adding that Oracle's debt remains \"investment-grade.\"\n\nEven after Thursday's plunge, the Bloomberg Billionaires Index shows that Ellison's net worth still remains ahead of most tech titans, including Jeff Bezos and Mark Zuckerberg.",
    "readingTime": 2,
    "keywords": [
      "ellison's net",
      "net worth",
      "estimates",
      "earnings",
      "fears",
      "revenue",
      "analysts",
      "less",
      "oracle",
      "index"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/larry-ellison-loses-25-billion-net-worth-oracle-stock-plunge-2025-12",
    "thumbnail_url": "https://i.insider.com/693bea72832e0ef1ead61d19?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.417Z",
    "topic": "finance"
  },
  {
    "slug": "disneys-ai-ambitions-are-a-hail-mary-for-the-companys-stock-after-a-lost-decade",
    "title": "Disney's AI ambitions are a Hail Mary for the company's stock after a lost decade",
    "description": "Disney's OpenAI deal comes at a time when the stock is essentially flat over the past 10 years, while the S&P 500 has soared 236%.",
    "fullText": "Things Disney has accomplished in the past 10 years:\n\nThings it hasn't accomplished over the same period:\n\nThis may seem like a wild stat. After all, the S&P 500 is up a whopping 236% over the past decade. But it's true: Disney shares are basically dead flat during the stretch.\n\nFrom a market perspective, the last 10 years have been a total wash.\n\nThe chart above ‚Äî which looks at Disney's stock versus the benchmark S&P 500 ‚Äî shows that the key divergence happened in early 2021, which marked Disney's last record high.\n\nThe company has faced a few main headwinds since that top:\n\nAfter Disney+ got off to a fast start, user growth eventually stalled out and prolonged the service's winding path to profitability. The company has also grappled with ESPN's increasingly online audience in the era of cord-cutting, which has contributed to contentious negotiations with TV carriers. (To be fair, all legacy media companies are dealing with the same issues.)\n\nMissing the mark on original content\n\nPixar movies used to be an absolute slam dunk at the box office. No longer. Viewers are also getting fatigued by the constant stream of reboots and sequels. And yes, Disney still has Marvel and Star Wars, although those have lost steam as well. (Note that a similar slowdown has been seen for movie studios overall.)\n\nDisney has caught flak in recent years over the prices at its parks. CEO Bob Iger even admitted in 2023 that the company had been \"too aggressive\" with price hikes. While parks remain a source of relative strength for the company, their cost has left them vulnerable to downturns in consumer sentiment.\n\nWhich brings us to Disney's latest big swing: a $1 billion investment in OpenAI that will integrate iconic characters into the AI video platform Sora. It's notable that Disney is the first major non-tech company to partner with OpenAI.\n\nUpon first glance, the deal feels like a desperate move from a company that's underperformed for a long stretch. But analysts at Citi see it differently.\n\nJason Bazinet, who has a \"buy\" rating on Disney's stock, lauded it as a defensive move, intended to protect the value of the company's IP from cannibalization. He sees it helping to sustain long-term brand value, while also giving it long-term upside in AI. Iger made similar points in defense of the deal.\n\nWe'll see over time if this AI team-up is a catalyst for a grand stock comeback ‚Äî and if it's a model other companies follow.",
    "readingTime": 3,
    "keywords": [
      "disney's stock",
      "accomplished",
      "stretch",
      "parks",
      "deal",
      "long-term",
      "disney",
      "it's",
      "iger",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-opeani-sora-ai-video-deal-stock-price-returns-streaming-2025-12",
    "thumbnail_url": "https://i.insider.com/693b723f04eda4732f2d693a?width=1024&format=jpeg",
    "created_at": "2025-12-12T13:47:21.416Z",
    "topic": "finance"
  },
  {
    "slug": "disney-just-picked-a-side-in-the-ai-fight",
    "title": "Disney just picked a side in the AI fight",
    "description": "Companies face a big question: Are AI companies friend or foe?",
    "fullText": "Mickey Mouse ‚Ä¶ brought to you by OpenAI.\n\nDisney lending out its iconic characters to be leveraged by AI seemed a far-fetched idea a few months ago. But thanks to a $1 billion deal between the House of Mouse and OpenAI, that's exactly what's happening.\n\nIt's representative of a larger question companies, especially those in media and entertainment, are grappling with: Are AI companies friend or foe?\n\nFor Bob Iger, the answer is very much friend.\n\n\"It gives us an opportunity, really, to play a part in what is really a breathtaking, breathtaking growth in essentially AI and new forms of media and entertainment,\" the Disney CEO told CNBC on Thursday.\n\nThe deal will allow Disney+ to post users' AI-generated content, a goal that Iger mentioned last month. Doing so could help boost engagement on the streamer's platform, which has been stagnant in recent years, writes BI's Lucia Moses.\n\n(I should probably mention Axel Springer, Business Insider's parent company, also falls in the \"friend\" camp. It cut a deal with OpenAI almost two years ago.)\n\nOthers aren't as willing to rub shoulders with OpenAI. The startup has a history of using someone's intellectual property without permission and then apologizing for it. That has resulted in several lawsuits, including those from The New York Times and \"Game of Thrones\" author George R.R. Martin.\n\nSo who's right? It's too early to say, but it could easily go both ways.\n\nThe longer one waits to cut a deal with an AI company, the worse the terms could be. (The benefits of first-mover advantage.) On the other hand, opening yourself up to AI could be a kind of Pandora's box you can't close.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nThe deal isn't just beneficial to Disney.\n\nDisney characters coming to Sora 2 could be a big boost for a video platform that hit a bit of a lull after a hot start a few months ago.\n\nBringing characters from \"Frozen\" and \"Moana\" to life on your app is also a great way to generate interest and build loyalty with a younger audience. OpenAI CEO Sam Altman recently touted the personal benefits he finds from using ChatGPT as a new parent.\n\nBut pursuing a younger demographic also comes as some countries are putting up more guardrails around kids' use of tech. Australia recently installed a ban on social media for anyone under the age of 16.\n\nThe Disney-OpenAI deal also comes as competition keeps mounting against the startup from the likes of Google and others. And while so much of AI is about pushing cutting-edge tech, sometimes you just need a little bit of old-school magic.",
    "readingTime": 3,
    "keywords": [
      "cut deal",
      "media",
      "characters",
      "friend",
      "tech",
      "it's",
      "entertainment",
      "breathtaking",
      "boost",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-newsletter-disney-openai-iger-altman-pick-side-2025-12",
    "thumbnail_url": "https://i.insider.com/693c13f8832e0ef1ead61e4c?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.275Z",
    "topic": "finance"
  },
  {
    "slug": "openai-opens-internal-merch-store-to-the-public",
    "title": "OpenAI opens internal merch store to the public",
    "description": "Explore curated, brand-designed pieces that reflect our vision, milestones, and creative spirit.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://supply.openai.com",
    "thumbnail_url": "https://supply.openai.com/4f4692867bef.png",
    "created_at": "2025-12-12T06:59:22.638Z",
    "topic": "tech"
  },
  {
    "slug": "smart-photo-finder-semantic-photo-search-not-filename100-local-ai",
    "title": "Smart Photo Finder ‚Äì Semantic photo search, not filename(100% local AI)",
    "description": "Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings. - Pankaj4152/smart-photo-finder",
    "fullText": "Pankaj4152\n\n /\n\n smart-photo-finder\n\n Public\n\n Find images by describing what you're looking for, not by filename or tags. Powered by vision-language models and semantic embeddings.\n\n License\n\n MIT license\n\n 8\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Pankaj4152/smart-photo-finder",
    "readingTime": 1,
    "keywords": [
      "tags",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Pankaj4152/smart-photo-finder",
    "thumbnail_url": "https://opengraph.githubassets.com/81d5523cc4100fc11914eb2cbf0dd607dd9f154cfd39d73fb291f9b8d45c820a/Pankaj4152/smart-photo-finder",
    "created_at": "2025-12-12T06:59:05.582Z",
    "topic": "tech"
  },
  {
    "slug": "ai-voice-cloning",
    "title": "AI Voice Cloning",
    "description": "Transform your voice into limitless possibilities with instant AI voice cloning. Create professional audiobooks, podcasts, marketing content, and multilingual content in seconds. High-quality voice synthesis with natural expressiveness and emotional depth.",
    "fullText": "Experience premium AI voice cloning with just 3 seconds of audio!\nPerfectly captures every detail of the original voice, maintaining natural expressiveness, emotional depth, and personal speaking style. Easily clone anyone's voice with simple and efficient voice cloning technology.\n\nListen to real examples of AI-cloned voices. Each voice demonstrates the natural quality and expressiveness of our technology.\n\nClone any voice in seconds‚Äîwhile keeping it natural with realistic tone and speaking pace. Simple workflow, instant results.\n\nCreate your unique AI voice in seconds. With instant voice cloning, you can recreate your voice and any voice you love in just a few seconds.\n\nDiscover how AI voice cloning revolutionizes content creation, communication, and engagement across industries‚Äîall in seconds, not hours.\n\nTransform your written words into captivating audiobooks with your authentic voice. Create professional podcasts instantly‚Äîno more marathon recording sessions. Your unique voice and style, preserved perfectly, ready to engage audiences worldwide.\n\nLaunch campaigns faster than ever. Create compelling video ads and product announcements with your voice‚Äîanytime, anywhere. Skip the studio, slash production costs by up to 80%, and maintain that professional edge your brand deserves.\n\nLead with your voice, scale with AI. Deliver personalized messages to global teams in your authentic voice, ensuring every update feels personal and consistent. Transform how leaders connect with their organizations‚Äîeffortlessly and instantly.\n\nBreak language barriers without learning a word. Your voice speaks every language naturally, reaching global audiences with authentic accents and local nuances. Make your content feel native in any market‚Äîfrom Tokyo to New York.\n\nElevate training with familiar voices that boost engagement. Create impactful learning materials using voices your team knows and trusts. Watch retention rates soar as learners stay focused, remember more, and enjoy a seamless learning experience.\n\nDeliver personalized support at scale. Connect with customers in your voice, speaking their language‚Äîliterally. Build deeper relationships, increase satisfaction scores, and create memorable experiences that turn customers into advocates.\n\nWe've compiled answers to the most common questions about AI voice cloning technology.\n\nGetting started is incredibly simple! Visit our AI voice cloning platform and either upload an audio file or record a 10-second sample directly in your browser. Within seconds, our advanced AI will generate your custom voice clone‚Äîno technical expertise required.\n\nYes! Paid users have full commercial rights to use generated voices in their projects. Free users are limited to personal, non-commercial use. Always ensure you have proper authorization when cloning someone else's voice, and comply with applicable laws and regulations.\n\nOur AI voice cloning models are expertly trained to support English, Chinese (Mandarin), Japanese, and Korean with natural pronunciation and authentic intonation. Each language maintains the unique characteristics and nuances of native speakers.\n\nFor best results, we recommend 10-300 seconds of clear, single-speaker audio with normal speech pace and minimal background noise. A standard smartphone recording works perfectly‚Äîno professional equipment needed!\n\nWe're committed to ethical AI use. Please do not use our technology for impersonation, fraud, hate speech, or spam. When cloning someone else's voice, always respect copyright laws and obtain proper consent.\n\nFree users enjoy slower generation speeds, perfect for trying out the technology. Paid subscribers get unlimited generation time with priority processing, ensuring your voice clones are ready when you need them‚Äîideal for professional workflows.\n\nNot yet, but we're actively developing programmatic access to our AI voice cloning service. Stay tuned for updates‚Äîwe're planning to launch our API soon to enable seamless integration into your applications and workflows.\n\nWe're here to help! Reach out to our support team at [email¬†protected]. We aim to respond within one business day, ensuring you get the assistance you need quickly and efficiently.\n\nAbsolutely! Once your voice clone is generated, you can download it in high-quality MP3 or WAV format. Use it in any project‚Äîfrom podcasts and audiobooks to marketing campaigns and training materials.\n\nYes! We currently support voice style customization, allowing you to fine-tune the characteristics of your cloned voice to match your specific needs and preferences.",
    "readingTime": 4,
    "keywords": [
      "deliver personalized",
      "free users",
      "someone else's",
      "cloning someone",
      "cloning technology",
      "else's voice",
      "authentic voice",
      "seconds",
      "create",
      "natural"
    ],
    "qualityScore": 1,
    "link": "https://aivoicecloning.net",
    "thumbnail_url": "https://aivoicecloning.net/og-image.png",
    "created_at": "2025-12-12T06:59:04.340Z",
    "topic": "tech"
  },
  {
    "slug": "openai-launches-gpt52-ai-model-with-improved-capabilities",
    "title": "OpenAI launches GPT-5.2 AI model with improved capabilities",
    "description": "OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman reportedly issued an internal \"code red\" in early December pausing non‚Äëcore projects and",
    "fullText": "Dec 11 (Reuters) - OpenAI on Thursday launched its GPT-5.2 artificial intelligence model, after CEO Sam Altman ‚Äãreportedly issued an internal \"code red\" in early ‚ÄåDecember pausing non‚Äëcore projects and redirecting teams to accelerate development in ‚Äåresponse to Google's Gemini 3.\n\nGPT-5.2 comes with improvements in general intelligence, coding and long-context understanding, the company said in a statement.\n\nThe new model is expected to bring even ‚Å†more economic value for ‚Äåusers, as it is better at creating spreadsheets, building presentations and handling complex multi-step ‚Äçprojects, OpenAI said.\n\nAlphabet's Google launched the latest version of its Gemini in November, highlighting Gemini 3's lead position on several ‚Äãpopular industry leaderboards that measure AI model performance.\n\n\"Gemini ‚Äå3 has had less of an impact on our metrics than we feared,\" Altman said in an interview with CNBC on Thursday, alongside Disney CEO Bob Iger.\n\nDisney said on Thursday it is investing $1 billion in ‚Å†OpenAI and will let the ‚Äãstartup use characters from Star Wars, ‚ÄãPixar and Marvel franchises in its Sora AI video generator.\n\nMicrosoft-backed OpenAI said that it currently ‚Äçhas no ‚Å†plans to deprecate GPT‚Äë5.1, GPT‚Äë5, or GPT‚Äë4.1 in the API.\n\nGPT-5.2 Instant, Thinking, and Pro will begin ‚Å†rolling out in ChatGPT on Thursday, beginning with paid plans.",
    "readingTime": 2,
    "keywords": [
      "model",
      "launched",
      "intelligence",
      "projects",
      "disney",
      "plans",
      "openai",
      "gemini",
      "altman"
    ],
    "qualityScore": 0.85,
    "link": "https://tech.yahoo.com/ai/chatgpt/articles/openai-launches-gpt-5-2-185713739.html",
    "thumbnail_url": "https://s.yimg.com/lo/mysterio/api/53E953B72061EAD331E14221749904B05C017BE83D84CD2331F3FA5A9D9F4632/subgraphmysterio/resizefit_w1200;quality_90;format_webp/https:%2F%2Fmedia.zenfs.com%2Fen%2Freuters.com%2Fdec31ed411aedabd7e3231dabf2dd50f",
    "created_at": "2025-12-12T06:59:01.415Z",
    "topic": "tech"
  },
  {
    "slug": "big-short-investor-michael-burry-says-there-is-no-way-to-time-or-predict-when-the-ai-bubble-will-burst",
    "title": "'Big Short' investor Michael Burry says there is 'no way to time or predict' when the AI bubble will burst",
    "description": "In a lengthy blog post, Bury advised against attempting to short the current AI bubble and said the bubble may grow even larger.",
    "fullText": "If you're waiting for Michael Burry to tell you when the AI bubble will burst, don't hold your breath.\n\nIn Burry's new post on his Substack, the famed \"Big Short\" investor said that there \"is no way to time or predict\" the bubble pop, especially when the bubble may still have room to grow.\n\n\"Shorts are almost always short-term trades. Usually less than a year, maybe a couple years at most,\" wrote Burry. \"Not 5 years, not 10 years.\"\n\n\"I believe today the stock market is in a phase that could become a blow off top of extreme magnitude on the upside, while at any time, maybe even today or tomorrow, making a generational top,\" Burry added.\n\nIn the lengthy blog post, Burry answered reader questions on his earlier posts. He argued that there is \"supply-side gluttony,\" meaning massive data-center build-outs, GPU orders, and multibillion-dollar commitments without real end-user demand, which investors are mistaking for supply-chain activity. He attributed much of the hype to being driven by Nvidia CEO Jensen Huang's marketing.\n\n\"Even when it finally tops, it will not be for any specific reason,\" Burry said later in the post. \"Even if the reason is an AI buildout bubble popping, that will likely not be apparent until a year or two later.\"\n\n\"Mostly, it is prudent neither to short stocks nor to buy puts on stocks. Stocks that are obviously overvalued tend to have the most upward momentum yet have puts that are very expensive,\" Burry added.\n\nNvidia did not immediately respond to a request for comment about Burry's latest digs.\n\nIn November, Burry launched a paywalled Substack called Cassandra Unchained. After posting charts on X that show circulatory investment deals between Nvidia and other tech giants, his first post took aim at Nvidia. He called the chipmaking giant \"a Cisco\" in the AI bubble debate, referring to the internet-networking giant whose stock plunged by over 75% during the dot-com crash.\n\nNvidia released a note to Wall Street analysts in late November, pushing back against some of Burry's claims.\n\nEarlier in November, during¬†Nvidia's Q3 earnings¬†call, the CEO addressed concerns about the AI bubble.\n\n\"From our vantage point, we see something very different,\" Huang told investors, \"We excel at every phase of AI, from pre-training and post-training to inference.\"",
    "readingTime": 2,
    "keywords": [
      "bubble",
      "stocks",
      "burry",
      "substack",
      "stock",
      "phase",
      "earlier",
      "investors",
      "later",
      "giant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/michael-burry-big-short-ai-bubbles-burst-cannot-be-predicted-2025-12",
    "thumbnail_url": "https://i.insider.com/69160ab489026fbb4d0d9600?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.758Z",
    "topic": "finance"
  },
  {
    "slug": "what-smart-people-are-saying-about-disneys-licensing-deal-with-openai",
    "title": "What smart people are saying about Disney's licensing deal with OpenAI",
    "description": "OpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property.",
    "fullText": "It's likely just a matter of time before we see the wisened duo of Rafiki and Jiminy Cricket weilding lightsabers on the icy plains of Arendelle.\n\nThat's courtesy of artificial intelligence, of course, and a new deal between Disney and OpenAI.\n\nOpenAI said Thursday it had struck a licensing agreement to use Disney's characters and other intellectual property. Disney will also invest $1 billion in OpenAI and will purchase ChatGPT Enterprise for its employees.\n\nIt's a major shift for Disney, which has historically been deeply protective of its intellectual property. And it's a big win for OpenAI, which is on a quest for more content to feed its AI models.\n\nFor users, the deal will enable them to recreate Disney characters on Sora, OpenAI's short-form video generation app, and to create images of Disney characters using ChatGPT.\n\nBeyond the limitless possibilities for creative content, the deal reveals a lot about Disney's strategy in the AI age and the impact of artificial intelligence on the future of entertainment.\n\nHere's what some smart people in media, tech, and business are saying about the deal.\n\nFor Nick Cicero, the founder of Delmondo, a social media video analytics company that was acquired by Conviva in 2018, Disney's deal with OpenAI is less about AI and more about revenue.\n\nCicero argued in an X post on Thursday that Disney was aiming to solve two \"existential\" problems: creators using unauthorized Disney content and kids watching YouTube instead of Disney+.\n\n\"Sora gives Disney its first scalable way to pull creator-made content into its own premium ecosystem ‚Äî brand-safe, trackable, legal, and ready for CTV monetization,\" he said, referring to the practice of delivering targeted advertising to internet-connected televisions.\n\n\"This move isn't about tech,\" he added. \"It's about revenue physics.\"\n\nChatbots like ChatGPT rely on data to power their outputs, and when it comes to collecting that data, AI companies are insatiable.\n\nThe drive to collect data often pits AI companies against content creators. Numerous media companies have sued OpenAI, Anthropic, Perplexity, and other leading AI outfits for using their copyrighted content without permission. Other media companies, like Business Insider's parent company, Axel Springer, have struck deals with AI companies to license their content.\n\nPeter Csathy, a longtime media consultant and analyst, said Disney's deal with OpenAI is a \"watershed\" moment for AI and media licensing.\n\n\"Now THIS is a generative AI use that makes sense to me and I support,\" Csathy wrote on LinkedIn. \"Fully licensed characters, thereby respecting copyright and embracing partnership with the creative community (rather than theft of IP). New revenue streams for IP rights-holders. And overall delight by fans of those beloved characters.\"\n\nThere are just so many cease-and-desist letters a media lawyer can send.\n\nCarline Giegerich, a vice president at the Interactive Advertising Bureau who once led emerging tech at HBO, says Disney's deal with OpenAI feels like a \"can't beat 'em, join 'em\" moment.\n\n\"When I was at HBO from '05 - '09, I marveled at the sheer volume of cease and desists from the legal team when mobile video was up and coming,\" she wrote on LinkedIn. \"I thought it seemed difficult to fight against the entire internet, and it turns out it was. And AI presents a similar challenge.\"\n\nShe also said the deal presents a valuable marketing opportunity for Disney.\n\n\"Important to note that a selection of these fan-created videos will be available to stream on Disney+. What that means to me is that Disney sees this also as a marketing and content opportunity, which it is,\" she said.\n\nDisney's pivot from aggressively defending its IP at every turn to giving it over to the world's leading AI startup might be strategic for another reason.\n\nJames Miller, the head of business development at Amazon for media, entertainment, and Amazon Creators, said he suspects it's a matter of \"controlling the inevitable.\"\n\nAny IP eventually enters the public domain. In 2024, the copyright for Mickey Mouse himself ‚Äî at least the sans white gloves version of the 1930s ‚Äî expired, allowing anyone to use his likeness. Winnie the Pooh, Snow White, Cinderella, and a handful of other Disney characters also entered the public domain at the same time.\n\n\"By officially licensing these characters now, Disney does three things,\" Miller wrote on LinkedIn. \"1. Monetizes the AI trend rather than just fighting it in court. 2. Sets the quality standard for how their characters appear in AI video (likely drowning out lower-quality unauthorized versions). 3. Captures data on how fans want to use their IP before they lose exclusive rights.\"\n\nOne consumer expert said that Disney might have gotten the short end of the stick in this partnership.\n\n\"Looks like OpenAI used the #jedimindwarp on The Walt Disney Company, not the other way around,\" Karl Haller, an IBM partner and the leader of the firm's Consumer Center of Competency, said in a post on LinkedIn.\n\nHe said he was \"more than a bit surprised\" to see that Disney is letting OpenAI license its IP for Sora and other AI tools, with some of the videos being made available to stream on Disney+.\n\n\"And what does Disney receive for this? Negative $1 billion,\" he wrote. \"Rather than receiving a heftly license fee, Disney is instead investing $1B in OpenAI and receiving warrants to buy \n\nOne entertainment lawyer pointed out that the deal comes with a lot of unanswered questions.\n\n\"This is a fairly stunning story all round with many questions,\" Simon Pullman, a partner at law firm Pryor Cashman, wrote on LinkedIn on Thursday.\n\n\"Will audiences want/accept 'AI UGC' on Disney Plus,\" he wrote, referring to user-generated content. \"Will it be possible for Disney to unring the bell after three years and not extend the license? How will they protect against misuse and brand damage?\"\n\nDisney's $1 billion bet on AI is the right move for the media giant, according to Mike Walsh, the CEO of consulting firm Tomorrow.\n\n\"By partnering with OpenAI while suing Midjourney and warning Google, Disney is drawing a clear line,\" Walsh wrote on LinkedIn on Thursday. \"Remix culture isn't going away, but it will be licensed, governed, and designed on its terms.\"\n\nHe added that Disney has always survived new media eras with this strategy.\n\n\"The future of entertainment belongs to companies that shape participation instead of fighting it,\" he wrote.",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "intellectual property",
      "disney's deal",
      "disney characters",
      "media",
      "content",
      "it's",
      "entertainment",
      "license",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-deal-openai-ai-sora-chatgpt-ip-analysis-2025-12",
    "thumbnail_url": "https://i.insider.com/693b9675832e0ef1ead61c15?width=1200&format=jpeg",
    "created_at": "2025-12-12T06:58:57.725Z",
    "topic": "finance"
  },
  {
    "slug": "softbanks-son-eyes-data-center-group-switch-to-expand-in-ai",
    "title": "SoftBank‚Äôs Son Eyes Data Center Group Switch to Expand in AI",
    "description": "SoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.",
    "fullText": "TechnologyAIBy Josh Sisco, Taro Fuse, Ryan Gould, and Min-Jeong LeeSaveSoftBank Group Corp. is studying potential acquisitions including data center operator Switch Inc., a sign billionaire founder Masayoshi Son aims to ride an AI-fueled boom in digital infrastructure, people with knowledge of the matter said.The Japanese company has held discussions with Switch leadership and has been conducting due diligence on the closely held company, the people said, asking not to be identified because the information is private. SoftBank also has been in advanced talks on a potential purchase of one of Switch‚Äôs main private equity backers, New York-listed investment firm DigitalBridge Group Inc., Bloomberg News reported last week.",
    "readingTime": 1,
    "keywords": [
      "potential",
      "switch"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/softbank-eyes-data-center-group-switch-as-son-hunts-for-ai-plays",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iWJI72I4iN30/v0/1200x800.jpg",
    "created_at": "2025-12-12T03:55:20.050Z",
    "topic": "finance"
  },
  {
    "slug": "lmarena-is-a-cancer-on-ai",
    "title": "LMArena Is a Cancer on AI",
    "description": "Would you trust a medical system whose only metric was ‚Äúwhich doctor wins the Internet?‚Äù No, you'd call that malpractice. Yet that's LMArena.",
    "fullText": "Would you trust a medical system measured by: which doctor would the average Internet user vote for?\n\nYet that malpractice is LMArena.\n\nThe AI community treats this popular online leaderboard as gospel. Researchers cite it. Companies optimize for it and set it as their North Star. But beneath the sheen of legitimacy lies a broken system that rewards superficiality over accuracy.\n\nIt's like going to the grocery store and buying tabloids, pretending they're scientific journals.\n\nHere's how LMArena is supposed to work: enter a prompt, evaluate two responses, and mark the best. What actually happens: random Internet users spend two seconds skimming, then click their favorite.\n\nThey're not reading carefully. They're not fact-checking, or even trying.\n\nThis creates a perverse reward structure. The easiest way to climb the leaderboard isn't to be smarter; it‚Äôs to hack human attention span. We‚Äôve seen over and over again in the data, both from datasets that LMArena has released and the performance of models over time, that the easiest way to boost your ranking is by:\n\nIt doesn't matter if a model completely hallucinates. If it looks impressive ‚Äì if it has the aesthetics of competence ‚Äì LMSYS users will vote for it over a correct answer.\n\nWhen you optimize for engagement metrics, you get madness.\n\nEarlier this year, Meta tuned a version of Maverick to dominate the leaderboard. If you asked it ‚Äúwhat time is it?‚Äù, you got:\n\nVoil√†:¬†bold text, emojis, and plenty of sycophancy ‚Äì every trick in the¬†LMArena playbook! ‚Äì to avoid answering the question it was asked.\n\nIt wasn't just Maverick. We analyzed 500 votes from the leaderboard ourselves. We disagreed with 52% of them, and strongly disagreed with 39%.\n\nThe leaderboard optimizes for what feels right, not what is right. Here are two emblematic examples of LMArena users punishing factual accuracy:\n\nIn the world of LMArena, confidence beats accuracy and formatting beats facts.\n\nInstead of rigorous evaluators, we have people with the attention span of the average TikTok user determining which AI models shape the industry.\n\nWhy is LMArena so easy to game? The answer is structural.\n\nThe system is fully open to the Internet. LMArena is built on unpaid labor from uncontrolled volunteers. There's no incentive for those volunteers to be thoughtful. No quality control. No one gets kicked off for repeatedly failing to detect hallucinations.\n\nWhen LMArena‚Äôs leaders speak publicly, they talk about the various techniques they use to overcome the fact that their input data is low quality. They admit their workers prefer emojis and length over substance. So the LMArena system, they proudly tell us, includes a variety of corrective measures.\n\nThey're attempting alchemy: conjuring rigorous evaluation out of garbage inputs.\n\nBut you can't patch a broken foundation.\n\nWhen the entire industry optimizes for a metric that rewards ‚Äúhallucination-plus-formatting‚Äù over accuracy, we get models optimized for hallucination-plus-formatting.\n\nThis isn't a minor calibration problem. It's fundamental misalignment between what we're measuring and what we want: models that are truthful, reliable, and safe.\n\nThe AI industry needs rigorous evaluation. We need leaders who prioritize accuracy over marketing. We need systems that can't be gamed by bolding more aggressively.\n\nLMArena is none of these things. And as long as we pretend it is, we're dragging the entire field backward.\n\nPeople often say they can‚Äôt avoid LMArena.\n\n\"We have to optimize for it. We have to sell our models. The leaderboard shows customers which model is best, and we have to play the game.\"\n\nBut the best products have principles they stick to.\n\nThis is the brutal choice every model builder must eventually make:\n\nThe choice is real. It‚Äôs hard. But we‚Äôve seen some frontier labs hold the line.\n\nThey stuck to their values. They ignored the gamified rankings. And users loved their models anyway ‚Äì because hype eventually dies and quality is the only metric that survives the cycle.\n\nYou are your objective function. Which path will each lab choose?",
    "readingTime": 4,
    "keywords": [
      "attention span",
      "rigorous evaluation",
      "leaderboard",
      "models",
      "accuracy",
      "system",
      "they're",
      "users",
      "lmarena",
      "optimize"
    ],
    "qualityScore": 1,
    "link": "https://surgehq.ai/blog/lmarena-is-a-plague-on-ai",
    "thumbnail_url": "https://cdn.prod.website-files.com/68dcd2ceb173c46fa029931c/69385c394b4cc2e3cad4c7bf_lmarena.jpg",
    "created_at": "2025-12-12T03:50:33.457Z",
    "topic": "tech"
  },
  {
    "slug": "how-well-do-llms-understand-tunisian-arabic",
    "title": "How Well Do LLMs Understand Tunisian Arabic?",
    "description": "Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to any tool that can act intelligently. Yet, the ability of industrial-scale LLMs to comprehend low-resource languages, such as Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding millions of Tunisians from fully interacting with AI in their own language, pushing them toward French or English. Such a shift not only threatens the preservation of the Tunisian dialect but may also create challenges for literacy and influence younger generations to favor foreign languages.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2511.16683",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2025-12-12T03:50:33.276Z",
    "topic": "tech"
  },
  {
    "slug": "creativity-is-the-new-productivity-bob-iger-on-why-disney-chose-to-be-aggressive-adding-openai-as-a-1-billion-partner",
    "title": "‚ÄòCreativity is the new productivity‚Äô: Bob Iger on why Disney chose to be ‚Äòaggressive,‚Äô adding OpenAI as a $1 billion partner",
    "description": "\"We'd rather participate in the rather dramatic growth, rather than just watching it happen and essentially being disrupted by it,\" Iger told CNBC.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/iger-altman-disney-openai-1-billion-creativity-new-productivity/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247523490-e1765480919303.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.446Z",
    "topic": "business"
  },
  {
    "slug": "were-not-just-going-to-want-to-be-fed-ai-slop-for-16-hours-a-day-analyst-sees-disneyopenai-deal-as-a-dividing-line-in",
    "title": "‚ÄòWe‚Äôre not just going to want to be fed AI slop for 16 hours a day‚Äô: Analyst sees Disney/OpenAI deal as a dividing line in entertainment history",
    "description": "\"‚ÄãI think the reason this bidding is approaching $100 billion-plus is the content library and the potential to do a Disney-OpenAI type of deal.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/pre-post-ai-content-disney-openai-netflix-warner-slop-analysis-ark-invest/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2197501075-e1765490752485.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.299Z",
    "topic": "business"
  },
  {
    "slug": "backflips-are-easy-stairs-are-hard-robots-still-struggle-with-simple-human-movements-experts-say",
    "title": "Backflips are easy, stairs are hard: Robots still struggle with simple human movements, experts say",
    "description": "Yet the next generation of robots will soon be able to learn from experience, creating more adaptable machines‚Äîperfect for the home and the factory, according to speakers at Fortune's Brainstorm AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/backflips-are-easy-stairs-are-hard-humanoid-robots-challenges-potential-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974565481_750d2f2870_o-e1765436658770.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.141Z",
    "topic": "business"
  },
  {
    "slug": "the-race-to-deploy-an-ai-workforce-faces-one-important-trust-gap-what-happens-when-an-agent-goes-rogue",
    "title": "The race to deploy an AI workforce faces one important trust gap: What happens when an agent goes rogue?",
    "description": "There‚Äôs a great deal of enthusiasm around AI agents, but as panelists discussed at Fortune's Brainstorm AI, there are still a lot of questions too.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/ai-agent-workforce-adoption-trust-risks-challenges/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974710070_1c221b6e5c_o-e1765429238911.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.060Z",
    "topic": "business"
  },
  {
    "slug": "highlights-from-fortune-brainstorm-ai-san-francisco",
    "title": "Highlights from Fortune Brainstorm AI San Francisco",
    "description": "From deep dives into the enterprise deployment of agents to explorations of the new geography of data centers, Brainstorm AI provided a valuable snapshot of the AI landscape at the close of the year.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/highlights-from-fortune-brainstorm-ai-san-francisco/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974738463_5208876430_6k-e1765490981222.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:29.051Z",
    "topic": "business"
  },
  {
    "slug": "openai-aims-to-silence-concerns-it-is-falling-behind-in-the-ai-race-with-release-of-new-model-gpt52",
    "title": "OpenAI aims to silence concerns it is falling behind in the AI race with release of new model GPT-5.2",
    "description": "OpenAI said its new model outperforms those from rivals Google and Anthropic across a wide range of evaluations.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-gpt-5-2-launch-aims-to-silence-concerns-it-is-falling-behind-google-anthropic-code-red/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2198334790-e1765478723707.jpg?resize=1200,600",
    "created_at": "2025-12-12T03:50:28.964Z",
    "topic": "business"
  },
  {
    "slug": "this-ai-matchmaking-startup-says-it-can-find-your-soulmate-but-be-prepared-to-spend-50000-read-its-pitch-deck",
    "title": "This AI matchmaking startup says it can find your 'soulmate' ‚Äî but be prepared to spend $50,000. Read its pitch deck.",
    "description": "Keeper, founded in 2022, raised $4 million in pre-seed funding. Here's the startup's current pitch deck.",
    "fullText": "Keeper, an AI matchmaking startup, thinks it can help deliver your \"soulmate\" to you. And if it can't, it'll let you know.\n\n\"We're saying we actually know who could be your soulmate or not,\" Jake Kozloski, Keeper's CEO, told Business Insider. \"We're not going to waste your time and pretend that a hundred thousand of these people could be. We'll tell you no.\"\n\nFounded in 2022, the dating platform uses layers of algorithms and AI models to match people who The startup is now disclosing for the first time, exclusively to Business Insider, that it raised a $4 million pre-seed investment in October 2024, led by Lightbank and Lakehouse Ventures. Goodwater Capital and Champion Hill Ventures participated in the round, among others.\n\nInvestors \"see AI as an inflection point in the dating app landscape\" and an opportunity to \"disrupt the incumbents,\" Kozloski said.\n\nKeeper isn't the only startup attempting to shake up the online dating market. Other AI matchmaking apps, such as Sitch and Amata, have raised millions to build next-generation dating apps. Dating app incumbents like Tinder and Bumble are also making plays with AI-powered experiences.\n\nKozloski said the company's values were another piece of its pitch that attracted some investors.\n\n\"They feel like there's a marriage crisis adjacent to the whole Elon Musk fertility crisis stuff that he talks about,\" said Kozloski, who described Keeper as being \"friendly with the pronatalist movement.\"\n\nWanting kids, though, isn't a requirement to use Keeper, Kozloski added.\n\nSince launching, Keeper has had more than 1.5 million sign-ups, and about 300,000 of those have made accounts, Kozloski said. Among that pool, there have been a \"small number\" of matches. Keeper didn't share exactly how many matches it's made, but according to its pitch deck, 10% of dates from its beta version resulted in marriage. With its funding, Keeper has been building out its matchmaking technology over the past year.\n\nKeeper is limited to heterosexual couples right now, and doesn't offer explicit options for different gender identities.\n\n\"We basically have to build a new algorithm for homosexual relationships, which we're happy to do and we will do eventually, but for now, we want to get to product market fit with our core product first,\" Kozloski said. \"Frankly, heterosexual relationships, especially for finding life partnership, seems to be a bigger market, a stronger market for us right now.\"\n\nMaking a profile on Keeper is a sit-down process. The initial form to make an account asks for the standard details of many dating apps (like your age or height), as well as academic test scores (including SATs), your career ambitions, salary, and net worth. It even encourages taking an external personality test. After you fill out the initial onboarding questionnaire, there are 13 more steps, ranging from uploading photos to sharing your philosophy on love.\n\n\"We don't let our users create their own profiles,\" Kozloski said. Keeper uses the information it gathers to curate a profile for you.\n\nKozloski said Keeper uses a non-AI algorithm first to streamline potential matches, focusing on data points like age range initially.\n\n\"We use LLMs once we have your top hundred that our other algorithms have identified,\" he said. \"The LLMs are trained on our matchmaking insights that we've learned so far, and so they can narrow down those last hundred and do the final pass of, 'OK, who actually is worth offering among these.'\"\n\nSome of the AI matchmaking comes into play when analyzing \"general attractiveness\" and users' specific attributes, like baldness or hair color, Kozloski said. The startup has also partnered with a team of researchers at Stanford, Kozloski said, who help train the LLMs (Keeper provides anonymized data to the research team).\n\nHowever, Keeper isn't fully automated, and for the time being, includes human matchmakers in the process. If there's a match, Keeper connects the two people over text message.\n\nThe startup has a complicated payment structure with a hefty price tag ‚Äî but only for men.\n\nKeeper has male users sign a \"marriage bounty\" that typically costs $50,000 (if the user gets married) and has them pay $5,000 for any dates from the service (the date fees go toward the total bounty cost, Kozloski said).\n\nRead the most recent version of Keeper's pitch deck.\n\nNote: Keeper has shared an updated version of its pitch deck, which it is now sharing with investors, that includes new details since its raise in October 2024. Some details have been redacted.\n\nKeeper describes the matchmaking market as \"old school yet shockingly massive,\" per the slide.\n\n\"With the opportunity to 10x,\" the slide says. \"When technology provides perfect matches, matchmaking will be the best way to meet your partner.\"\n\n\"The AI matchmaker that will introduce you to your soulmate on the first match,\" the slides says. It also includes product imagery.\n\n\"Our v1 worked extremely well,\" the slide says.\n\nIt says that 10% of dates lead to marriage.\n\nIt says it has had 1.5 million sign-ups. \"This makes us the largest pool of any traditional matchmaker,\" the slides says. It lists competitors like Tawkify, Keeper, Ditto, Sitch, and Known Dating.\n\n\"Everyone signs up if we deliver soulmates on the first match,\" the slide says.\n\n\"The first mover quickly becomes a monopoly,\" it says.\n\nToban Wiebe: Co-Founder, Head of AI\n\nHere are the names of the researchers:\n\n\"We're raising to scale profitable human-in-the-loop matchmaking to $2M in annual revenue,\" the slide says.\n\n\"80% of young singles want to get married,\" the slide says. \"40% actually will.\" It cites data from Match Group and data scientist Allen Downey.\n\nDating apps are \"bad at creating relationships, worth billions,\" the slide says. \"Imagine the value of the first product that's great at it.\"\n\n\"Matchmakers can't scale,\" the slide says.\n\n\"LLMs and vision models enable scalable matchmaking for the first time in history,\" the slides says.\n\n\"We've built the most accurate process in the world,\" the slide says.\n\nHere are the steps the slide lays out:\n\n\"We earn more, faster, by aligning with users' incentives,\" the slide says.\n\nIts current model, which has humans involved in matchmaking, is free for women and costs men $5,000 per date. For male users, the marriage bounty costs $50,000, and the slide says that Keeper has contracted $14 million \"so far.\"\n\nKeeper outlines that in a future model, where the tech is fully automated, dates will cost $250, and the marriage bounty contract will cost $5,000.",
    "readingTime": 6,
    "keywords": [
      "fully automated",
      "pitch deck",
      "male users",
      "keeper isn't",
      "dating app",
      "marriage bounty",
      "dating apps",
      "slide",
      "matchmaking",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-dating-app-keeper-raised-four-million-pitch-deck-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae83164858d02d216a17a?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.626Z",
    "topic": "finance"
  },
  {
    "slug": "openai-says-its-new-gpt-52-set-a-new-stateoftheart-score-for-professional-knowledge-work",
    "title": "OpenAI says its new GPT 5.2 set a 'new state-of-the-art score' for professional knowledge work",
    "description": "OpenAI says its latest model, GPT 5.2, was shown to outperform industry professionals in specific tasks across 44 different occupations.",
    "fullText": "OpenAI released its anticipated update to GPT-5 on Thursday, boasting that the new AI is \"the most capable model series yet for professional knowledge work.\"\n\n\"We designed GPT‚Äë5.2 to unlock even more economic value for people; it's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long contexts, using tools, and handling complex, multi-step project,\" the company said in a statement.\n\nIn a benchmark test called GDPval, OpenAI said its new AI model can outperform \"industry professionals at well-specified knowledge work tasks spanning 44 occupations.\"\n\n\"GPT‚Äë5.2 Thinking produced outputs for GDPval tasks at >11x the speed and <1% the cost of expert professionals, suggesting that when paired with human oversight, GPT‚Äë5.2 can help with professional work,\" the company said.\n\nAnd in a note that is sure to catch the attention of bankers, OpenAI wrote that in an internal benchmark of junior investment banking analyst spreadsheet modeling tasks ‚Äî \"such as putting together a three-statement model for a Fortune 500 company with proper formatting and citations, or building a leveraged buyout model for a take-private\" ‚Äî the new model's score per task was \"9.3% higher than GPT‚Äë5.1's, rising from 59.1% to 68.4%\" on average.\n\nOpenAI said that GPT-5.2 will begin rolling out today for paid ChatGPT plans. Paid users will have access to GPT-5.1 for three months under legacy models before it is sunsetted.\n\n\"We deploy GPT‚Äë5.2 gradually to keep ChatGPT as smooth and reliable as we can,\" the company said.\n\nThe company also touted its gains in agentic coding ability.\n\n\"Even without the ability to do new things like output polished files, GPT-5.2 feels like the biggest upgrade we've had in a long time. Curious to hear what you think!\" OpenAI CEO Altman wrote on X.\n\nOpenAI CEO of Applications Fidji Simo said more changes will be coming next year once OpenAI rolls out age verification across ChatGPT. She said an \"adult mode\" for the chatbot will debut in the first quarter of 2026.\n\nThe release comes just over a week after Altman declared a \"code red\" in a private message to employees, marshaling more resources to ChatGPT amid increasing competition from Google and other companies.\n\n\"Code reds are not uncommon,\" Somo said during an interview on TBPN, adding that the hosts could \"be the judge\" of the results of Altman's declaration. She said she was \"pretty proud of\" GPT-5.2's advances, even though its development pre-dated the \"code red.\"\n\nGoogle has been considered by many in tech to be gaining, if not surpassing, OpenAI in the AI race with its recent release of Gemini 3.\n\nThe announcement also occurred hours after OpenAI brokered a major deal with Disney, which secured a $1 billion investment and access to the media giant's lucrative and popular IP.\n\n\"It has been a very cool last 10 years; OpenAI has been more special to work on than I could have possibly imagined,\" Altman wrote on X on Thursday.",
    "readingTime": 3,
    "keywords": [
      "openai ceo",
      "code red",
      "model",
      "tasks",
      "professional",
      "knowledge",
      "benchmark",
      "professionals",
      "investment",
      "access"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-gpt-5-2-update-release-2025-12",
    "thumbnail_url": "https://i.insider.com/693b0e6904eda4732f2d5fd2?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.376Z",
    "topic": "finance"
  },
  {
    "slug": "disney-is-betting-openai-can-help-it-solve-a-key-problem",
    "title": "Disney is betting OpenAI can help it solve a key problem",
    "description": "Disney faces an engagement problem as kids gravitate to YouTube. It's looking to OpenAI to help boost engagement.",
    "fullText": "Disney is losing the war for attention. Can its blockbuster OpenAI licensing deal change the momentum on the battlefield?\n\nSoon, you'll be able to use OpenAI products, such as ChatGPT and the video generator Sora, to create content featuring Disney characters like Mickey Mouse, Ariel, and Darth Vader.\n\nCEO Bob Iger said the move would let Disney take advantage of a fast-growing area of entertainment.\n\nIger said initially Disney would \"curate some of the videos that have been created on the Sora platform and put them onto Disney+, which we think is a great way to increase engagement with our Disney+ users, particularly the younger users.\" Iger said eventually the company wants users to create AI videos within Disney+ itself.\n\nThere's a key word in Iger's comment that signals why Disney might be particularly motivated to make this deal: engagement.\n\nTime people spend on Disney's and other leading streaming services has stayed essentially flat over the past few years, while YouTube and social video have grown. Disney's share of US TV viewership for its streaming services ‚Äî including Disney+, Hulu, and ESPN+ ‚Äî has been stuck at around 4.8% this year, according to Nielsen. YouTube is the top streaming platform on TVs, with a nearly 13% share in October, and its lead has been widening.\n\nData from analytics firm Luminate showed that engagement with Disney+'s original content fell to a 3% share of US viewing time in the third quarter of 2025. That's down from 9% three years earlier, the largest decline among paid streamers.\n\nDisney has been highly protective of its famous characters and favors keeping people on its own platforms. This stance has made it difficult for the company to capitalize on the rise of user-generated content. And it's losing its monopoly on its core constituency, kids, as they increasingly watch YouTube over Disney+.\n\nTraditional media companies are struggling to grow, so they're trying to figure out new ways to get people to engage with their content, whether it be games, live events, or fan content creation, media analyst Doug Shapiro, a senior advisor at BCG, recently told Business Insider.\n\n\"It's a zero-sum game they're losing, and it's only going to get worse,\" he said. \"I think they're all asking themselves, how can they have a deeper relationship with fans?\"\n\nDisney invested $1.5 billion in Fortnite maker Epic Games last year and struck a deal with Webtoon to create a new digital platform for Disney's comics, including Marvel and Star Wars. Outside Disney, Netflix is opening Netflix Houses, mini theme parks in malls that let people enter the worlds of its popular shows. Amazon has backed Fable Studios, a startup that has an AI streaming platform that lets users make their own shows and play with existing IP.\n\nJohn Attanasio, CEO of Toonstar, a tech-driven animation studio, said Disney's IP is so popular that the Sora videos could help drive more audience. He thought Disney could potentially charge for access to AI tools on Disney+ or use the Sora videos to discover franchise extensions.\n\n\"UGC, when it's so specific, the reach is limited,\" he said. \"But when you use known IP, that expands the potential audience.\"\n\nDisney fans and Hollywood insiders had mixed reactions to the OpenAI news.\n\nShae Noble, a Disney superfan in her late 30s, said she could see herself sending birthday messages or making fan videos of the characters interacting in interesting ways ‚Äî especially if it were integrated into Disney+.\n\n\"I've already seen some of the negative impacts of AI and people pushing it too far to create harmful images,\" she added. \"So it's smart of them to be proactive about it.\"\n\nSome in Hollywood worried about the risks to professional creators.\n\nFor one thing, the deal puts the emphasis on existing IP rather than making new content, Toonstar's Attanasio said.\n\nThe Writers Guild of America came out swinging against the deal, and said it planned to meet with Disney to explore how much the pact would let user-generated videos use the work of its members.\n\nSam Tung, a storyboard artist and cochair of the Animation Guild's AI committee, wondered if OpenAI's guardrails would be strong enough to protect Disney's IP, recalling a widely publicized incident earlier this year when Fortnite users used AI to make the Darth Vader character swear. He also doubted the UGC would move the needle on engagement.\n\n\"I think what audiences want is high-quality stuff to watch with your family,\" Tung said.\n\nJames Faris contributed reporting.",
    "readingTime": 4,
    "keywords": [
      "sora videos",
      "streaming services",
      "streaming platform",
      "disney's ip",
      "content",
      "disney",
      "deal",
      "users",
      "create",
      "engagement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-taps-openai-to-solve-engagement-problem-woo-young-fans-2025-12",
    "thumbnail_url": "https://i.insider.com/693b473804eda4732f2d67dd?width=1200&format=jpeg",
    "created_at": "2025-12-12T03:50:28.057Z",
    "topic": "finance"
  },
  {
    "slug": "how-openais-latest-model-will-impact-chatgpt",
    "title": "How OpenAI's Latest Model Will Impact ChatGPT",
    "description": "GPT-5.2 is here, and, according to OpenAI, better than ever.",
    "fullText": "OpenAI is having a hell of a day. First, the company announced a $1 billion equity investment from Disney, alongside a licensing deal that will let Sora users generate videos with characters like Mickey Mouse, Luke Skywalker, and Simba. Shortly after, OpenAI revealed its latest large language model: GPT-5.2.\n\nOpenAI says that this new GPT model is particularly useful for \"professional knowledge work.\" The company advertises how GPT-5.2 is better than previous models at making spreadsheets, putting together presentations, writing code, analyzing pictures, and working through multi-step projects. For this model, the company also gathered insights from tech companies: Supposedly, Notion, Box Shopify, Harvey, and Zoom all find GPT-5.2 to have \"state-of-the-art long-horizon reasoning,\" while Databricks, Hex, and Triple Whale believe GPT-5.2 to be \"exceptional\" with both agentic data science and document analysis tasks.\n\nBut most of OpenAI's user base aren't professionals. Most of the users who will interact with GPT-5.2 are using ChatGPT, and many of those for free, at that. What can those users expect when OpenAI upgrades the free version of ChatGPT with these new models?\n\nOpenAI says that GPT-5.2 will improve ChatGPT's \"day to day\" functionality. The new model supposedly makes the chatbot more structured, reliable, and \"enjoyable to talk to,\" though I've never found the last part to be necessarily true.\n\nGPT-5.2 will impact¬†the ChatGPT experience differently depending on which of the three models you happen to be using. According to OpenAI, GPT-5.2 Instant is for \"everyday work and learning.\" It's apparently better for questions seeking information about certain subjects, how-to questions and walkthroughs, technical writing, and translations‚Äîmaybe ChatGPT will get you to give up your Duolingo obsession.\n\nGPT-5.2 Thinking, however, is supposedly made for \"deeper work.\" OpenAI wants you using this model for coding, summarizing lengthy documents, answering queries about files you send to ChatGPT, solving math and logic problems, and decision making. Finally, there's GPT-5.2 Pro, OpenAI's \"smartest and most trustworthy option\" for the most complicated questions. The company says 5.2 Pro produces fewer errors and stronger performance compared to previous models.\n\nOpenAI says that this latest update improves how the models responds to distressing prompts, such as those showing signs of suicide, self-harm, or emotional dependence on the AI. As such, the company says this model has \"fewer undesirable responses\" in GPT-5.2 Instant and Thinking compared to GPT-5.1 Instant and Thinking. In addition, the company is working on an \"age prediction model,\" which will automatically place content restrictions on users who the model think are under 18.\n\nThese safety improvements are important‚Äîcritical, even‚Äîas we start to understand the correlations between chatbots and mental health. The company has admitted its failure in \"recognizing signs of delusion,\" as users turned to the tool for emotional support. In some cases, ChatGPT fed into delusional thinking, encouraging people's dangerous beliefs. Some families have even sued companies like OpenAI over claims that their chatbots helped or encouraged victims commit suicide.\n\nActively acknowledging improvements to user safety is undoubtedly a good thing, but I think companies like OpenAI still have a lot to reckon with‚Äîand a long way to go.\n\nOpenAI says GPT-5.2 Instant, Thinking, and Pro will all roll out today, Thursday, Dec. 11, to paid plans. Developers can access the new models in the API today, as well.\n\nDisclosure: Lifehacker‚Äôs parent company, Ziff Davis, filed a lawsuit against OpenAI in April, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.",
    "readingTime": 3,
    "keywords": [
      "gpt instant",
      "models openai",
      "ziff davis",
      "chatgpt",
      "users",
      "supposedly",
      "model",
      "latest",
      "user",
      "free"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/how-openais-latest-model-will-impact-chatgpt?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC7EHPGQ2G4FWBQABYH2TCJD/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-12T03:50:27.049Z",
    "topic": "tech"
  },
  {
    "slug": "disney-to-invest-1bn-in-openai-allowing-characters-in-sora-video-tool",
    "title": "Disney to invest $1bn in OpenAI, allowing characters in Sora video tool",
    "description": "Agreement comes amid anxiety in Hollywood over impact of AI on the industry, expression and rights of creators\nWalt Disney has announced a $1bn equity investment in OpenAI, enabling the AI startup‚Äôs Sora video generation tool to use its characters.\nUsers of Sora will be able to generate short, user-prompted social videos that draw on more than 200 Disney, Marvel, Pixar and Star Wars characters as part of a three-year licensing agreement between OpenAI and the entertainment giant.\n Continue reading...",
    "fullText": "Agreement comes amid anxiety in Hollywood over impact of AI on the industry, expression and rights of creators\n\nWalt Disney has announced a $1bn equity investment in OpenAI, enabling the AI startup‚Äôs Sora video generation tool to use its characters.\n\nUsers of Sora will be able to generate short, user-prompted social videos that draw on more than 200 Disney, Marvel, Pixar and Star Wars characters as part of a three-year licensing agreement between OpenAI and the entertainment giant.\n\nThe agreement ‚Äì a landmark deal amid intense anxiety in Hollywood over the impact of artificial intelligence on the future of entertainment ‚Äì will not cover talent likenesses or voices.\n\nBob Iger, Disney‚Äôs CEO, hailed a deal which paired his firm‚Äôs ‚Äúiconic stories and characters‚Äù with OpenAI‚Äôs AI technology. It will place ‚Äúimagination and creativity directly into the hands of Disney fans in ways we‚Äôve never seen before‚Äù, he claimed.\n\nThe deal is OpenAI‚Äôs most prominent move into Hollywood after a contentious rollout of Sora and longstanding pushback against AI from many entertainment industry workers. Concerns from writers, actors, visual effects artists and other creatives over AI replacing jobs and using likenesses without consent has led to union protests and copyright lawsuits against AI companies.\n\nWhen OpenAI launched its latest iteration of Sora earlier this year, it immediately ran into a slew of potential copyright issues, as feeds became dominated by videos featuring characters such as SpongeBob SquarePants or Pikachu ‚Äì sometimes generated to appear in Nazi-like clothing.\n\nRacist depictions of Martin Luther King Jr prompted OpenAI to ban the use of his likeness on the platform, while the daughter of Malcolm X called seeing her father‚Äôs image on Sora ‚Äúdeeply disrespectful and hurtful‚Äù.\n\nDisney itself has also been concerned over the unauthorized use of its characters by generative AI platforms. The company sent a stern cease-and-desist letter to the Character.AI chatbot firm in October, alleging that the platform was ‚Äúblatantly infringing on Disney‚Äôs copyrights‚Äù through using the likeness of its characters.\n\nOn Wednesday evening, attorneys representing Disney sent a cease-and-desist letter to Google, demanding that the technology company‚Äôs AI systems stop alleged infringement, Variety reported.\n\nThe OpenAI CEO, Sam Altman, has been on a charm offensive that included a recent appearance on The Tonight Show with Jimmy Fallon, the US talkshow. On Thursday, he touted the firm‚Äôs deal with Disney as proof that artificial intelligence companies could partner with the entertainment sector.\n\n‚ÄúThis agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences,‚Äù Altman said.\n\nIn addition to Disney letting its characters appear in Sora, the company will also use OpenAI‚Äôs application programming interfaces to build new products and tools, becoming a major customer of the ChatGPT maker. A selection of the videos made by users on Sora will also be available for streaming on the Disney+ platform. It will also deploy ChatGPT for its employees, the companies said.\n\n‚ÄúTechnological innovation has continually shaped the evolution of entertainment, bringing with it new ways to create and share great stories with the world,‚Äù said Iger. ‚ÄúThe rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works.‚Äù",
    "readingTime": 3,
    "keywords": [
      "cease-and-desist letter",
      "artificial intelligence",
      "characters",
      "entertainment",
      "agreement",
      "deal",
      "hollywood",
      "industry",
      "videos",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2025/dec/11/disney-open-ai-sora-video-deal",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f5d1259fc988f6fc2168117b19c7988dc338dc1d/501_0_3955_3166/master/3955.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9c7ba4a2a7ebf1e6d0d3a988dca01a30",
    "created_at": "2025-12-11T18:58:28.567Z",
    "topic": "business"
  },
  {
    "slug": "oracle-drops-on-disappointing-cloud-sales-more-ai-spending",
    "title": "Oracle drops on disappointing cloud sales, more AI spending",
    "description": "Investors want to see Oracle turn its higher spending on infrastructure into revenue as quickly as it has promised.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/oracle-earnings-stock-falls-11-percent-why-investors-disappointed-data-centers-cloud/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2194585184-e1765471764946.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.911Z",
    "topic": "finance"
  },
  {
    "slug": "bob-iger-says-disneys-1-billion-deal-with-openai-is-an-opportunity-not-a-threat-wed-rather-participate-than-be",
    "title": "Bob Iger says Disney‚Äôs $1 billion deal with OpenAI is an ‚Äòopportunity, not a threat‚Äô: ‚ÄòWe‚Äôd rather participate than be disrupted by it‚Äô",
    "description": "The three-year deal will bring more than 200 Disney characters to Sora.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/disney-openai-deal-investment-bob-iger-opportunity-not-threat/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2246087509-e1765473579190.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.910Z",
    "topic": "business"
  },
  {
    "slug": "intel-pursued-deals-that-boosted-ceo-lipbu-tans-fortune-sources-say",
    "title": "Intel pursued deals that boosted CEO Lip-Bu Tan's fortune, sources say",
    "description": "When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant.  Tan had pitched Intel‚Äôs board on buying Rivos in the summer of 2025, but he had no luck.  The board told Tan he had a conflict in representing both Rivos‚Äô interests and Intel‚Äôs, and he lacked a strategy on artificial intelligence to justify a deal, three people familiar with the events told Reuters.",
    "fullText": "SAN FRANCISCO, Dec 10 (Reuters) - When the chairman of AI chip startup Rivos wanted Intel to bid for the company, he had no need to phone the chip giant. That‚Äôs because the chairman of Rivos was also Intel‚Äôs CEO: Lip-Bu Tan.\n\nTan had pitched Intel‚Äôs board on buying Rivos in the summer of 2025, but he had no luck. The board told Tan he had a conflict in representing both Rivos‚Äô interests and Intel‚Äôs, and he lacked a strategy on artificial intelligence to justify a deal, three people familiar with the events told Reuters.\n\nTan asked one of his lieutenants at Intel to pitch a new AI plan, leading to partnership talks with Rivos, the people said. But now there was a problem: social media giant Meta had been stalking Rivos and made an offer for the company.\n\nMeta‚Äôs interest spurred Intel to ‚Äãmake its own offer. Meta countered with a sweetened bid. The competition for the startup drove the deal and incentives above the $2 billion valuation that Rivos had sought in fundraising earlier this year. Some of the sources pinned this package at around $4 billion.\n\nMeta announced plans to buy Rivos in September. By then the bidding process had boosted the startup‚Äôs returns at Meta‚Äôs expense.\n\nThe events show one of at least three instances where Intel has pursued deals that benefit Tan financially either by exploring bids for startups or investing in them directly through Intel‚Äôs investment arm, Intel Capital, said two of the sources.\n\nIntel declined to make Tan available for an interview for this story. Meta did not respond to requests for comment, and Rivos declined to comment.\n\nIntel hired Tan in March in part for his experience as a ‚Äåventure capitalist and unparalleled industry connections as a longtime investor in tech companies. Those connections have helped Intel clinch a $5 billion investment from Nvidia and a $2 billion investment from SoftBank.\n\nSince Tan‚Äôs arrival, Intel has implemented policies requiring Tan to recuse himself from participating in investment decisions where he might benefit, two sources said. Specifically, Tan cannot attend or vote in decision meetings of Intel‚Äôs board or Intel Capital‚Äôs investment committee if he has a conflict in a venture or company-wide transaction, the sources said.",
    "readingTime": 2,
    "keywords": [
      "intel‚Äôs board",
      "rivos",
      "investment",
      "meta",
      "intel",
      "chairman",
      "chip",
      "startup",
      "giant",
      "conflict"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/intel-pursued-deals-boosted-ceo-202405818.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/391824ae2253d7702083abdf99e0ff28",
    "created_at": "2025-12-11T18:58:23.652Z",
    "topic": "finance"
  },
  {
    "slug": "openai-and-disney-just-ended-the-war-between-ai-and-hollywood-with-their-1-billion-sora-dealand-openai-made-itself",
    "title": "OpenAI and Disney just ended the ‚Äòwar‚Äô between AI and Hollywood with their $1 billion Sora deal‚Äîand OpenAI made itself ‚Äòindispensable,‚Äô expert says",
    "description": "‚ÄúGoogle has YouTube. OpenAI now has the Magic Kingdom,‚Äù copyright expert Matthew Sag said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/openai-disney-sora-deal-hollywood-war-ended-matthew-sag/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1534551119-e1765478095544.jpg?resize=1200,600",
    "created_at": "2025-12-11T18:58:23.551Z",
    "topic": "business"
  },
  {
    "slug": "startups-love-to-boast-about-arr-ai-could-bring-this-to-an-abrupt-end",
    "title": "Startups love to boast about 'ARR.' AI could bring this to an abrupt end.",
    "description": "AI disrupts ARR: Startups and SaaS firms face new hybrid valuation models as investors prioritize usage, efficiency, and outcome-based metrics.",
    "fullText": "Startups and other tech companies love to boast about \"annual recurring revenue.\" AI could make this metric obsolete, though.\n\nAccording to a new report by consultant AlixPartners, investors are on the cusp of abandoning the traditional ARR-multiple playbook that defined the SaaS era. In its place will emerge hybrid valuation models that reward companies not for the size of their subscription base but for how effectively they use AI to elevate customer outcomes.\n\nFor decades, ARR served as the bedrock for valuing enterprise software firms. It measures revenue from subscriptions by taking the value of current contracts and extrapolating that out over a full year.\n\nAlixPartners now argues that ARR is becoming increasingly \"meaningless\" in an AI-first economy, especially as usage- and outcome-based business models replace the per-seat licenses that have dominated the SaaS industry.\n\nThe big change is related to how expensive AI models are to run. Every time a new AI software service taps into this intelligence, the provider has to pay a per-token price. That makes fixed, per-seat SaaS subscriptions tougher to offer.\n\nThis means revenue could fluctuate \n\nAlixPartners says investors are already shifting focus toward a hybrid valuation approach in the AI era:\n\n‚Ä¢ AI leverage ratios ‚Äî These measure how effectively companies convert AI investments into revenue and margin gains. Rather than rewarding scale for its own sake, investors will reward operational efficiency and automation-driven profitability.\n\n‚Ä¢ Outcome-based performance benchmarks ‚Äî Metrics such as customer margin expansion, reduced task completion time, or increased throughput will matter more than raw seat-based user counts.\n\n‚Ä¢ Traditional ARR multiples ‚Äî Still relevant but no longer sufficient on their own.\n\nNew forecasting metrics, such as \"time to usage,\" \"usage ramp rate,\" and \"usage volatility,\" are emerging to help investors gauge how quickly customers adopt AI features and how stable their consumption patterns are over time.\n\nThe message is clear: In the AI era, value follows impact. Companies that can demonstrate real productivity gains for customers and operational leverage for themselves will earn premium valuations. Those clinging to legacy ARR-driven models risk being left behind as investors pivot to frameworks that better capture the economics of intelligent software.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "hybrid valuation",
      "investors",
      "revenue",
      "models",
      "usage",
      "alixpartners",
      "saas",
      "software",
      "reward",
      "effectively"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/software-arr-ai-saas-valuation-metrics-alixpartners-2025-12",
    "thumbnail_url": "https://i.insider.com/693a1d277ecd1d1da6635567?width=550&format=jpeg",
    "created_at": "2025-12-11T18:58:23.170Z",
    "topic": "tech"
  },
  {
    "slug": "getting-workers-to-trust-and-adopt-ai-is-forcing-hr-people-to-reinvent-themselves",
    "title": "Getting workers to trust and adopt AI is 'forcing HR people to reinvent themselves'",
    "description": "Workers fear AI, so one of HR's biggest challenges is getting workers to trust and adopt it by building credibility and addressing employee concerns.",
    "fullText": "Corporate AI investment reached $252.3 billion in 2024, per Stanford research, but that spending won't deliver returns if workers reject the technology.\n\n\"When organizations don't set people up to use AI reliably, employees won't trust it and won't adopt it,\" says Ted F. Tschang, an associate professor of strategic management at Singapore Management University.\n\nIt is the AI paradox facing companies today: as corporate leaders invest billions in AI, many frontline workers remain deeply skeptical for many reasons.\n\nA Pew Research Center survey published earlier this year found that nearly a third believe it will lead to fewer job opportunities for them in the long run. Meanwhile, a survey by the University of Melbourne and KPMG of over 48,000 people across 47 countries found that only 46% of respondents are willing to trust AI systems.\n\nBridging this gap ‚Äî getting workers to both trust and adopt AI ‚Äî has become one of HR's most urgent challenges. Becoming comfortable with AI takes time and practice, but most organizations rarely make time for this, Tschang says.\n\n\"That's why HR leaders need to create space for safe learning and experimentation with AI's uses and limits, starting with their own teams,\" Tschang says.\n\nTo do that effectively, HR leaders need to develop AI fluency, meaning they must understand the technology well enough to identify where it can solve real problems and guide their workforce in using it. That's easier said than done.\n\nThe standard purview of HR includes both operational tasks, like recruiting, onboarding, benefits, and compliance, as well as strategic ones like developing talent and managing organizational change. Put simply, it's not a department known for being particularly tech-savvy.\n\nBut in the dawn of the AI era, that's changing, says Heather Conklin, CEO of Torch, a corporate coaching firm that helps companies navigate change, including AI adoption. \"It's forcing HR people to reinvent themselves,\" she says. \"And the ones I see succeeding are the ones who are going first.\"\n\nThese teams are treating their own departments as testing grounds, experimenting with different tools and learning what works and what doesn't, says Conklin. \"They're getting hands-on with AI themselves, even if they're not technical,\" she adds. \"They can't drive it across the company if they haven't lived it. They need to drive it from a place of credibility.\"\n\nThat credibility becomes currency when employees are wary. The CHROs winning people over are leading with problems worth solving, says Dexter Bachelder, CEO of Propel People, an AI recruiting platform for the construction industry.\n\n\"It's not about HR promoting AI. It's about the questions on employees' minds: How can AI do some of my paperwork so that I can leave work earlier and get home to my family faster? How can I automate some of the manual tasks of my job that aren't fun? How can I make this process better or faster?\" Bachelder says.\n\nIn other words, when workers see how AI makes their daily work easier, they're more likely to use it. \"If you solve the employee's problems, you're using the technology for a purpose,\" he says. \"\n\nNothing drives trust and adoption faster than having a coworker explain it. When a foreman explains to another foreman how they use a certain tool in the field ‚Äî'This is how it works on our project, this is how it could work on yours' ‚Äî that goes a long way,\" he says. \"It's not from IT or management or HR. It's from a peer, and that's what really drives adoption.\"\n\nPart of HR learning how to work with AI and earning employee confidence means understanding what's no longer working in the organization, and what AI could do to address those gaps.\n\nHR leaders have their own vested interest in this transformation. Many departments have long dealt with inadequate technology, and lots of the tools and processes HR has relied on for years weren't built for this moment, Bachelder says.\n\n\"To some degree, I don't think HR has had a lot of voice in the technology they use because a lot of tools are tied to financial systems,\" he says. \"There's a real opportunity here.\"\n\nTraditional learning management systems, for instance, struggle to keep pace when skills requirements change more frequently than every few years. Yearly engagement surveys can't capture employee sentiment quickly enough to respond to fast-moving organizational changes.\n\nMoreover, performance review cycles designed around annual goal-setting are often disconnected from organizations where priorities change on a quarterly basis. And recruitment systems built to screen for specific technical abilities may miss candidates who have the desired problem-solving skills needed for AI-related roles.\n\nOf course, upgrading HR systems won't entirely solve the trust challenge. Employee fears about job security and algorithmic bias go beyond what any tool can fix. And HR leaders still need to answer employee questions about transparency, fairness, and who's accountable for AI's decisions.\n\n\"It's challenging to do this right now,\" Conklin of Torch says. \"But if HR leaders aren't able to figure this out, they're going to be left behind.\"",
    "readingTime": 5,
    "keywords": [
      "leaders",
      "technology",
      "trust",
      "systems",
      "won't",
      "workers",
      "that's",
      "learning",
      "employee",
      "organizations"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/hr-big-challenge-get-workers-trust-adopt-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/693317f371107c9f34576e7d?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:23.045Z",
    "topic": "finance"
  },
  {
    "slug": "oracle-just-revived-fears-that-tech-giants-are-spending-too-much-on-ai",
    "title": "Oracle just revived fears that tech giants are spending too much on AI",
    "description": "AI spending is front and center again for investors. Oracle plunged Thursday, with top hardware makers including Nvidia and Broadcom also dropping.",
    "fullText": "Oracle just raised a fresh red flag for investors worried that tech companies are getting ahead of themselves when it comes it their massive capex spending.\n\nOracle stock plunged 14% on Thursday after the tech giant reported an earnings beat but delivered revenue that was below Wall Street estimates, posting $16.06 billion compared to $16.21 billion expected by analysts. Cloud sales rose 34% from the previous quarter but also fell short of estimates.\n\nImportantly, Oracle also pledged to spend about $15 billion more next year than previously forecast, sparking fresh concerns about aggressive capex among the biggest tech firms.\n\nThe tech titan's stock drop was enough to weigh on other AI names and drag markets lower in Thursday's session.\n\nHere's where major indexes stood at the 9:30 a.m. ET opening bell on Thursday:\n\n‚Ä¢ Nasdaq 100: 25,563.72, down 0.8%\n\nOracle stock has been highly volatile lately, dropping almost 20% in the last month after a huge surge following a blockbuster revenue forecast issued in September.\n\nIt's flurry of deals cemented the company as an AI power player, announcing a $300 billion contract with OpenAI, new partnership commitments with both Nvidia and Meta Platforms, and plans to expand its AI and cloud computing infrastructure in booming international markets.\n\nNow Oracle's lackluster earnings are prompting speculation that its big plans in the space are going to take awhile to payoff, and that it's spending plans are too ambitious. Morgan Stanley described the results as a moment when investors might resume their disbelief about the AI trade.\n\n\"Cloud growth at the low-end of the guide with building pressure on gross margins and op margins may further sap investor confidence in ORCL's ability to execute efficiently against a large and growing book of GPUaaS business, leaving the shares lacking a clear catalyst,\" analysts at the bank wrote on Thursday.\n\nSeveral other high-growth AI stocks were pulled down by Oracle's earnings report, dragging down the entire S&P 500 index, which fell 0.31% in premarket hours, while both the Dow Jones Industrial Average and the Nasdaq composite index rose slightly.\n\nHere are some of the biggest losers on Thursday:\n\nFor many investors, it is likely concerning that a company like Oracle could manage to fall short of analyst estimates after doing so much to position itself as an AI infrastructure leader this year. The key takeaway is likely that the company overpromised on what it could deliver.\n\n\"Oracle faces its own mounting scrutiny over a debt-fueled data center build-out and concentration risk amid questions over the outcome of AI spending uncertainty,\" said Emarketer analyst Jacob Bourne. \"This revenue miss will likely exacerbate concerns among already cautious investors about its OpenAI deal and its aggressive AI spending.\n\nThe concerns aren't limited to Oracle. While some have recently argued that the¬†biggest AI fears¬†may be overblown, it's possible that if one major tech player overspent on AI in 2025, others may have done the same. This could weigh on investor sentiment around AI as the market heads into 2026.",
    "readingTime": 3,
    "keywords": [
      "oracle stock",
      "tech",
      "investors",
      "earnings",
      "revenue",
      "estimates",
      "concerns",
      "biggest",
      "plans",
      "fresh"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/oracle-earnings-ai-stocks-capex-overspending-orcl-nvda-avgo-2025-12",
    "thumbnail_url": "https://i.insider.com/693ad29f7ecd1d1da66359f9?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.833Z",
    "topic": "finance"
  },
  {
    "slug": "meet-the-young-ai-startup-founders-raising-millions-in-the-race-to-build-the-next-big-thing",
    "title": "Meet the young AI startup founders raising millions in the race to build the next big thing",
    "description": "These AI startups founded by bright young minds in their teens and early 20s are disrupting industries and attracting top investors in the AI boom.",
    "fullText": "They are moving fast, raising serious cash, and leaving established paths behind. Across Business Insider's Young Geniuses series, which highlights next-gen leaders, innovators, and entrepreneurs, urgency is the constant.\n\nThe AI window has opened, but it may not stay that way for long. That's why these young founders are fleeing college classrooms, skipping dream internships, and leaving full-time roles to take advantage of this moment.\n\nA Stanford graduate student dropped out and raised $64 million for her AI math company. A pair of MIT freshmen dropouts secured $2.7 million for their police tech startup.\n\nThese are just a couple of young founders who are stepping into the AI race at full speed, backed by investors willing to bet early and big, driven by the sense that hesitation costs more than risk.\n\nMeet 16 young founders who spoke with Business Insider this year about their ideas for transforming everything from healthcare and shopping to how we interact with technology and one another. (Ages and figures are accurate to the time of reporting.)\n\nZach Yadegari, 18, sold his first video gaming app at age 16 for almost $100,000 and used the proceeds to fund Cal AI, an AI-powered nutrition app he co-founded.\n\nHe first discovered an interest in coding at a coding camp his parents sent him to when he was 7. For years, he'd spend hours watching people program video games on YouTube and try to emulate them.\n\nHe got the idea for Cal AI while trying to bulk up at the gym and quickly learning that most results come from diet. So, he and his co-founders set out to build a calorie-tracking app that integrates AI technology.\n\nOver the last year and a half, the app has taken off, generating around $30 million in annual revenue and employing a 30-person team, Yadegari told BI reporter Agnes Applegate in October.\n\nCarina Hong, 24, is on a mission to build a superintelligent reasoning system through her AI startup, Axiom Math.\n\nHong, a Rhodes Scholar, dropped out of her graduate studies at Stanford to found the company in March and has since hired top talent across Meta's Fundamental Artificial Intelligence Research (FAIR) lab, Meta's GenAI team, and Google Brain.\n\n\"One thing I heard from some of the top researchers and mathematicians I've recruited to Axiom is that solving for mathematical superintelligence will be their legacy,\" Hong told BI reporter Geoff Weiss in December. \"When the problem is hard enough, talent density gets very high, and that makes you a magnet for other great thinkers.\"\n\nAnd Hong isn't only recruiting from Big Tech. She has also hired her former professor, the renowned mathematician Ken Ono.\n\nArlan Rakhmetzhanov, 18, dropped out of high school in Kazakhstan in March 2025 to pursue his AI coding agents startup, Nozomio, at Y Combinator, a startup accelerator for many young founders.\n\nBoth of his parents are entrepreneurs, so his entrepreneurial journey began at a young age. He taught himself coding and built his first company at 15.\n\nHis journey to Y Combinator wasn't easy. He applied twice before finally getting accepted the third time. Even though he didn't have a Stanford PhD, he was told his YC partner selected him because he ships fast, which is critical in the age of AI, he told BI's Weiss in September.\n\nPhoebe Gates, daughter of Bill Gates, and Sophia Kianni launched an AI-powered shopping assistant in April and said it had reached 600,000 users by October, when they spoke with BI's Jordan Hart.\n\nBoth 23 at the time of their interview, Kianni and Gates met as roommates at Stanford University, where they conceived the idea for Phia.\n\nPhia is a free app and browser extension that uses AI to help compare prices on fashion items across tens of thousands of linked sites to help users find deals.\n\nThe duo raised $8 million in a seed funding round in September, led by venture capital firm Kleiner Perkins and featuring investors such as Kris Jenner, Hailey Bieber, and Michael Rubin.\n\nToby Brown, 16, has been fascinated with tech from a young age. His parents aren't in tech, but that hasn't stopped him from teaching himself to code everything, from math games to alarm systems.\n\nIn 2023, he developed the concept for his AI project Beem. \"I can't share too much about it,\" he told BI's Joshua Nelken-Zitser in October. \"I hope that if done right, it will redefine how people interact with technology.\"\n\nHe dedicated his summer break 2024 to pitching to firms and other potential investors in London, New York, Silicon Valley, and San Francisco. \"There was nobody to coach me on pitching to investors, so I just took a maniacal approach of bashing away at it until I got the right solution,\" he said.\n\nIn November 2024, he got a call from South Park Commons, founded by some of Facebook's early engineers, saying they wanted to invest $1 million in Beem. Instead of finishing school exams the following year, he left the UK to pursue his project in Silicon Valley.\n\nOne day in her Harvard University dorm room, Alyx van der Vorm felt lonely. Her friends were out of town, and while she could easily open an app to order food or stream a movie, she wanted more. Enter Clyx.\n\nVan der Vorm, 25, founded the social app in 2020 and has since rolled it out in four major cities worldwide: Miami, London, New York, and S√£o Paulo.\n\nClyx is a social app that leverages AI to connect people in real life. It utilizes AI-powered tools to scrape events from across the web, converts those events into meetups within the app, and then helps identify which of your friends are attending the event or matches you with new connections if you don't know anyone going.\n\nAt the time of reporting, Clyx had 50,0000 active users joining events and about 200,000 looking at events, BI's Sydney Bradley reported in September.\n\nMathieu Rihet, 19, saw the inefficiencies of the healthcare system firsthand while working as a medical translator. So, he set out to try and fix some of it.\n\nHe met Georges Casassovici, 18, via his LinkedIn post seeking a non-technical cofounder to build with. Together, the two of them founded Novoflow, an AI startup that builds AI agents for medical clinics to help automate tasks, starting with cancellation recovery and appointment booking.\n\nBoth told BI's Weiss in November that they have no plans to pursue a college degree after leaving school to join Y Combinator's Spring 2025 class.\n\nRudy Arora and Sarthak Dhawan, both 20, met in sixth grade, and by high school, they were coding and building viral apps together, including a Christmas light installation app that made $60,000 in annual revenue one year.\n\nWhen they both started college in 2023, Dhawan said he struggled to take notes and listen to the teacher at the same time. So, he and Arora set out to build an AI-powered notetaking app called Turbo AI. It's attracting 20,000 new users per day, BI's Lakshmi Varanasi reported in November.\n\nSince launching Turbo AI, they've both now dropped out of college and say their startup is on track to earn eight-figures in annual recurring revenue.\n\nCollege juniors Nathaneo Johnson and Sean Hargrow say LinkedIn has become bloated with vanity metrics like follower counts and likes, which distract from the professional qualities that matter when landing a job.\n\nSo, they launched their own AI social network while attending Yale. Skipping the likes and clicks, Series connects professionals over text message. The idea is that it only focuses on who you are and what you can bring to the table, Hargow told BI's Bradley in April.\n\nBalancing college and a startup isn't easy. Johnson later told BI's Nelken Zitser that he often ends up working 120-hour weeks to manage both.\n\nOver the summer, 19-year-old Christine Zhang turned down an internship to spend two months living in a hacker house. There, she built a startup with her college roommate and cofounder, and by the end of the summer, they'd raised $1 million for it.\n\nInstead of returning to Harvard, she's taking a gap year to stay in San Francisco and help scale her startup, which has grown to six people, she told BI's Applegate in October.\n\n\"I miss a lot of things about school. I had to delete my Instagram during the first week of classes so I wouldn't get FOMO. However, I don't regret my decision,\" she said.\n\nEarly this year, Aidan Guo, 19, and Julian Windeck, 23, launched their startup, Attention Engineering, which is essentially a desktop assistant powered by AI to automate everything you do on your computer, much like a \"cursor for everything,\" Guo told BI's Varanasi in November.\n\nGuo said he's on his \"second gap year\" from college. He found encouraging mentors by joining programs like Z Fellows and Emergent Ventures. Ultimately, he decided to forgo Carnegie Mellon and move to the Bay Area to build his startup.\n\nWindeck studied computer science in Germany and at Cambridge University, and then conducted AI research at MIT before deciding academia wasn't for him.\n\nThe two met through mutual friends, discovered they worked well together, and have since raised over $1 million from noteworthy backers, including Lukas Haas, a product manager at Google DeepMind, Marvin von Hagen and Felix Schlegal, the cofounders of Interaction, and Bryan Pellegrino, the cofounder of LayerZero.\n\nJay Neo, 21, has been studying what makes a video go viral since he was a teen.\n\nAt 18, he landed a job with MrBeast, helping make short-form video content and learning the ins and outs of how the YouTube mogul grows his business and popularity. For the last year and a half, however, Neo has been focused on his own AI startup called Palo.\n\nPalo is a content creator's assistant. It utilizes AI to analyze a creator's entire catalog and then writes scripts for short-form videos with related themes, outlining content with storyboards. It also has its own network, where creators can follow one another.\n\nLarge-language AI models \"are a perfect thing not for replacing the creator, but for analyzing every little thing,\" Neo told BI's Bradley in November.\n\nShraman and Shreyas Kar, 19 and 20, participated in hackathons together throughout middle and high school.\n\nThey were busy studying at Stanford when they were accepted to Y Combinator, and seeing their peers take the risk and drop out of Stanford gave them the courage to do so, too.\n\nThey began working on their AI startup, Golpo, while at Stanford. Golpo generates animated explainer videos from documents and prompts. For example, customers can use it to create interactive lessons for school districts or training programs for work.\n\nAs of mid-October, 14,000 people had generated videos with Golpo, Shraman Kar told BI's Weiss.\n\nGeorge Cheng and Dylan Nguyen, both 19, dropped out of MIT as freshmen and raised $2.7 million in seed funding out of Y Combinator for their tech startup Code Four, which aims to arm police officers with AI.\n\nThey say their technology can generate reports from bodycam footage for record-keeping, redact footage and reports for records requests, and generate transcriptions and summaries from video interviews and security footage. Basically, it aims to reduce the time spent on paperwork, allowing officers to dedicate more time in the field.\n\nCode Four is working with 25 police departments, BI's Weiss reported in November. While Code Four uses AI to generate preliminary drafts of reports, officers review and edit them for accuracy, Cheng said.\n\n\"Many of the great AI companies of the next decade are being built right now, and I want to be a part of that,\" Raymond Zhao told BI's Nelken-Zitser in October.\n\nZhao studied math and statistics at the University of Oxford, thinking he wanted to enter the financial sector. However, after an uninspiring internship at Goldman Sachs, Zhao ultimately pursued AI instead.\n\nWhile at Oxford, he joined the venture capital society, which introduced him to a network of VCs, founders, and one of his future cofounders. They've raised about $1 million in pre-seed funding for their AI startup, Structured AI, and are pursuing it further at Y Combinator.\n\nStructured AI builds AI agents that can perform quality control on technical documents and drawings. It's laying the groundwork for the AI workforce for construction design and engineering.\n\nDavid Kobrosky, 26, dropped out of college twice. The first time was to work for businessman and social media personality Gary Vaynerchuk, at his company VaynerX. The second was to launch his own company, Intros AI.\n\nKobrosky said he always thought AI would play a huge role in how humans interact, and that's exactly what Intros AI does. Intros AI was acquired by software company Bevy in July.\n\nCompanies can use Intros AI's product to connect their most active customers to each other, creating a space for knowledge sharing and networking that helps boost their customer retention, BI's Charissa Cheong reported in November.\n\nKobrosky didn't disclose the amount he sold Intros AI for, but he is now an AI product manager at Bevy, earning over $100,000 a year, plus bonuses. \"I think starting and selling a company sets me up for the future in a way that a more traditional path wouldn't have,\" he told Cheong.",
    "readingTime": 12,
    "keywords": [
      "silicon valley",
      "der vorm",
      "venture capital",
      "van der",
      "seed funding",
      "product manager",
      "annual revenue",
      "social app",
      "tech startup",
      "bi's weiss"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/young-founders-raising-millions-for-their-ai-startups-2025-12",
    "thumbnail_url": "https://i.insider.com/6939da877ecd1d1da6635085?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.674Z",
    "topic": "finance"
  },
  {
    "slug": "disney-bets-1-billion-on-openai-in-deal-that-opens-its-vault-of-characters-to-chatgpt-and-sora",
    "title": "Disney bets $1 billion on OpenAI in deal that opens its vault of characters to ChatGPT and Sora",
    "description": "Darth Vader and other Disney characters are coming to ChatGPT and OpenAI's Sora AI video app as part of a three-year licensing deal.",
    "fullText": "Darth Vader is coming to ChatGPT and OpenAI's Sora AI video app.\n\nThe House of Mouse and OpenAI struck a three-year licensing agreement on Thursday to make Disney \"the first major content licensing partner on Sora.\"\n\nIt's also investing $1 billion into the AI pioneer and receiving warrants to purchase additional equity.\n\nShares of Disney climbed over 2% after the opening bell.\n\n\"As part of this new, three-year licensing agreement, Sora will be able to generate short, user-prompted social videos that can be viewed and shared by fans, drawing from a set of more than 200 animated, masked and creature characters from Disney, Marvel, Pixar and Star Wars, including costumes, props, vehicles, and iconic environments,\" OpenAI said in a Thursday announcement.\n\nIn addition to striking a licensing deal, Disney is also becoming a \"major customer\" of the AI company, according to the announcement, and buying ChatGPT enterprise licenses for its employees.\n\nWhile Sora, OpenAI's TikTok-like AI video app, has been generating buzz and downloads since its launch earlier this year, users of the company's more popular product, ChatGPT, will also have access to AI versions of Disney's characters as part of the deal.\n\nThe AI-generated Disney characters will be available starting in early 2026.\n\nThe move is likely to prove controversial in Hollywood, where many actors have publicly voiced concern about AI use and concerns over how their likeness is used. Disney and OpenAI stated that \"the agreement does not include any talent likenesses or voices.\"\n\nCreators are core to Disney, and its CEO Bob Iger stressed that the deal represented no threat to creators.\n\n\"I think it honors them and respects them, in part because there's a license to be associated with it,\" he said on CNBC's \"Squawk on the Street\" on Thursday.\n\n\"The other thing it does is it enables us to be comfortable that Open AI is putting guardrails essentially around how these are used, so that really there's nothing for us to be concerned about from a consumer perspective, meaning this will be a safe environment and a safe way for consumers to engage with our founders in a new way,\" he added.\n\nIger hinted at such a transaction during the company's most recent earnings call, making extensive comments about the potential he sees for AI to enhance Disney's direct-to-consumer strategy. He said the company was having extensive talks with AI companies to protect its IP as well as generate more engagement with users.\n\nHis comments demonstrate how Disney ‚Äî like other Hollywood players ‚Äî is looking for new ways for people to interact with its platforms and brands as user-generated content platforms and independent creators gain popularity.\n\nDisney, like those other players, has an engagement problem. The time people spend on streaming has stayed essentially flat over the past few years, despite increased spending on content, while YouTube has grown. The bet with AI is that it can get people to spend more time on its platforms by giving them more ways to play around with its famous franchises.\n\nThe companies hinted as much in the announcement, saying that they would \"collaborate to utilize OpenAI's models to power new experiences for Disney + subscribers.\"\n\nDisney is also wary of the tech's risk to its IP. In June, Disney, along with Comcast's NBCUniversal studio business, sued AI company Midjourney, claiming its tech created unauthorized copies of works ranging from Star Wars to The Simpsons. Midjourney denied the claims in its legal response. The suit is ongoing.\n\nDisney's $1 billion cash infusion comes at a critical time for OpenAI, but it's a drop in the bucket compared to the roughly $1.4 trillion the AI company has pledged to spend over the next eight years on data centers.\n\nOpenAI CEO Sam Altman had previously said that large rights holders would ultimately welcome their content being used on Sora, provided it was done with proper guardrails in place. His comments came after OpenAI stepped up restrictions on the Sora app in the wake of viral user-generated videos depicting SpongeBob as Walter White and Pikachu in \"Saving Private Ryan.\"\n\n\"Most of the rights holders that I've spoken to are actually extremely excited to get their content in here,\" Altman told tech analyst Ben Thompson in October. \"They just want to be able to set more restrictions than they would need for images because videos feel different.\"",
    "readingTime": 4,
    "keywords": [
      "rights holders",
      "three-year licensing",
      "licensing agreement",
      "content",
      "disney",
      "chatgpt",
      "openai's",
      "videos",
      "characters",
      "announcement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-openai-licensing-deal-ai-characters-sora-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae3e9832e0ef1ead60bfc?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.665Z",
    "topic": "finance"
  },
  {
    "slug": "blackstone-apollo-and-blue-owl-are-all-in-on-data-center-bets-but-theres-one-thing-making-them-wary",
    "title": "Blackstone, Apollo, and Blue Owl are all in on data center bets ‚Äî but there's one thing making them wary",
    "description": "AI bubble be damned, the data center bet still looks great according to the top private markets investors. Just be careful who you're leasing to.",
    "fullText": "Concerns of an AI bubble may be mounting, but at the Goldman Sachs Financial Services Conference on Wednesday, the biggest private investors were bullish on their own investments.\n\nBlackstone President Jon Gray said it was the firm's biggest moneymaker. Ares CEO Michael Arougheti said that the firm's international data center investments are accelerating ahead of expectations and boosting revenue expectations. Blue Owl co-CEO Doug Ostrover said the firm is \"incredibly bullish\" on its own data center investments.\n\nAll signs point to a continued investment boon.\n\n\"If you \" Gray said.\n\nApollo CEO Marc Rowan said that no matter where he is in the world, the world's biggest users of \"compute\" (data center capacity) tell him they need more of it.\n\n\"When are they going to get more compute?\" Rowan said. \"No time soon, because there are natural limits and there are energy limits and there are regulatory limits and zoning and everything else.\"\n\nOstrover said he has \"never seen a market\" with this level of supply-demand imbalance, and he sees \"demand accelerating,\" but he doesn't \"see the supply increasing.\"\n\nHowever, behind the excitement, the industry's biggest investors are mulling over the risk they can't capture right now ‚Äî whether leases for these data centers will be renewed 15 to 20 years from now.\n\nRowan, looking at the present situation with his \"credit hat\" on, said, \"The risk I'm prepared to take is lease-up risk,\" Rowan said. \"The risk I'm not prepared to take is renewal risk.\"\n\nRowan said he has a chart on the wall of his office that compares different big consulting firms' projections of energy usage in 2030, and the \"spread is like a child throwing darts.\"\n\n\"The experts in this have no idea on energy use, much less chip use, compute, the impact of quantum.\" Rowan said. \"Do I really want to, with my credit hat on, take renewal risk?\"\n\nThe answer is no, and Rowan said there are plenty of ways for a credit investor to make money without taking renewal risk. In equity, you're betting on renewals, with the possibility of massive upsides or the \"chance of losing everything.\"\n\n\"There will be both great fortunes made and lost in the equity of data centers,\" Rowan said.\n\nOne way to make those bets a little safer is to vet who you're betting on.\n\nBlackstone, a major infrastructure investor, is only betting on \"long-term lease data centers where you don't put a shovel in the ground until you have a 15-plus year lease with a very large market cap company.\"\n\nOther potential bets include the power behind the AI revolution. It may be true that projections of power usage in 2030 are disparate, but they're probably all up and to the right.\n\n\"I can't come up with a scenario where we're not using significantly more power five years from today,\" said Gray.\n\nOne way to do it is to sign favorable leases with the best tenants. Blue Owl has a large \"triple-net-lease\" business, an industry term for commercial leases where taxes, insurance, and maintenance costs are paid by the tenant, instead of the landlord.\n\nUsually, Ostrover said, these leases are to solid businesses like Walgreens or Cracker Barrel, with 3% annual increases over 15 to 20-year leases. They're investment-grade tenants, around BBB credit, and have generated \"in excess of 20% return in that product.\"\n\nNow, they get those same terms with A or AA-credit tenants.\n\n\"So now, we're faced with an opportunity where instead of working with Walgreens, Cracker Barrel, firms like that, we can go to Microsoft, Meta, Google, Apple, the biggest companies in the world, signing identical 20-year leases,\" Ostrover said.\n\nThat way, even if they can't renew a lease, they're making their money.\n\n\"The way we look at it to our downside is even if the facilities are worth zero at the end of their lives, we can still make a teens return,\" Ostrover said.\n\nA Blue Owl spokesperson told BI that the firm's \"expectation\" is that there'll be \"meaningful residual value\" at the end of a lease.",
    "readingTime": 4,
    "keywords": [
      "risk i'm",
      "you're betting",
      "credit hat",
      "center investments",
      "risk rowan",
      "renewal risk",
      "blue owl",
      "leases",
      "biggest",
      "lease"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blackstone-apollo-blue-owl-data-centers-lease-renewals-2025-12",
    "thumbnail_url": "https://i.insider.com/693af35104eda4732f2d5be0?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.516Z",
    "topic": "finance"
  },
  {
    "slug": "disney-ceo-bob-iger-explains-why-he-just-did-a-blockbuster-openai-deal",
    "title": "Disney CEO Bob Iger explains why he just did a blockbuster OpenAI deal",
    "description": "Disney CEO Bob Iger said the company's licensing deal with OpenAI will let it capitalize on a fast-growing technology and engage younger audiences.",
    "fullText": "Disney CEO Bob Iger says his company's major licensing deal with OpenAI¬†is all about establishing a foothold in a new realm of entertainment and engaging younger audiences.\n\nThe licensing agreement gives ChatGPT and OpenAI's Sora video platform access to Disney characters like Mickey Mouse and Darth Vader. Disney is also investing $1 billion in the AI company and becoming a \"major customer.\"\n\nSpeaking on CNBC about the deal with OpenAI's Sam Altman on Thursday, Iger said it gives Disney a chance to get in on a fast-growing area of tech.\n\n\"It gives us an opportunity, really, to play a part in what is really a breathtaking, breathtaking growth in essentially AI and new forms of media and entertainment,\" Iger said.\n\nIger said the deal also fulfills a longtime desire by Disney to put user-generated content on its Disney+ streaming platform. Disney initially plans to put select videos created on Sora onto Disney+ to increase engagement with users, especially younger ones. Ultimately, Iger wants to let Disney+ users create such videos within the platform itself.\n\n\"That's a big step for us,\" he said.\n\nDisney has long been highly protective of its famous characters and storylines, and Iger is widely seen in Hollywood as a champion of the creative set. But like other entertainment players, Disney has an engagement problem. The time people spend on streaming has stayed essentially flat over the past few years, despite increased spending on content. Social media and user-generated content, in contrast, continue to rise. The bet with OpenAI is that the deal can get people to spend more time on Disney platforms by giving them new ways to play around with its famous franchises.\n\nIger has long positioned the company as pro-technology, and he said, in reference to the OpenAI deal, that he'd rather participate in technological innovation than be disrupted by it.\n\n\"We think this is actually a way for us to be part of these developments, as opposed to being harmed by them,\" he said.\n\nIger said the deal is also a way for Disney to participate in the big rise in user-generated short-form video on social-media platforms.\n\nAltman said Thursday that the demand for Disney characters, in particular, is \"off the charts\" on OpenAI's products. He said he sees the deal enabling people to do things like putting themselves in a lightsaber scene from \"Star Wars\" or creating a custom birthday video for their kid using the Buzz Lightyear character.\n\nAI firms have been¬†\"frenemies\" to media companies, as many in Hollywood are concerned about how they use copyrighted material and the threat that they could pose to the creative process. Iger said the OpenAI deal is good for creators rather than a threat.\n\n\"This does not in any way represent a threat to the creators at all. In fact, the opposite,\" Iger said. \"I think it honors them and respects them, in part because there's a license to be associated with it.\"\n\nDisney said the agreement does not include any talent likeness or voices and that OpenAI would have guardrails in place to make sure Disney's IP was used in a safe way.\n\nIn June, Disney, along with Comcast's NBCUniversal studio business, sued AI company Midjourney, claiming its tech created unauthorized copies of works ranging from Star Wars to The Simpsons. Midjourney denied the claims in its legal response. That suit is ongoing.",
    "readingTime": 3,
    "keywords": [
      "openai deal",
      "user-generated content",
      "disney characters",
      "star wars",
      "iger",
      "entertainment",
      "platform",
      "media",
      "threat",
      "licensing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-bob-iger-explains-billion-deal-with-open-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/693af46064858d02d216a359?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.509Z",
    "topic": "finance"
  },
  {
    "slug": "here-are-4-ways-rivian-just-stepped-deeper-into-teslas-turf",
    "title": "Here are 4 ways Rivian just stepped deeper into Tesla's turf",
    "description": "Rivian revealed ambitious plans for fully autonomous driving, featuring an in-house chip, an in-car AI assistant, and a Tesla-like subscription model.",
    "fullText": "Rivian is all-in on autonomous driving, stepping deeper into a territory Tesla has long positioned itself to dominate.\n\nOn Thursday, at Rivian's R&D office in Palo Alto, the EV maker unveiled a road map to develop autonomous-driving capabilities for its future lineup of vehicles, including new hardware for the highly anticipated R2 ‚Äî Rivian's cheapest car to date.\n\nThat road map includes a new silicon chip, designed in-house, that will power Rivian's next-generation hardware and support self-driving functions. The new hardware is expected to ship with R2 by the end of 2026, Rivian said.\n\nRivian CEO RJ Scaringe has been hinting at autonomous ambitions in recent years. However, since the company's first shipment of vehicles in 2021, Rivian's advanced driver assistance system (ADAS) software ‚Äî Driver+ and the Rivian Autonomy Platform ‚Äî has been more akin to Tesla Autopilot than Full Self-Driving Supervised. Tesla's Autopilot provides lane-centering and adaptive cruise control, while FSD can recognize traffic lights, conduct turns, and drive to a destination under constant driver supervision.\n\nThursday's announcement deepens Rivian's rivalry with Tesla as both companies have expressed goals of fully autonomous driving and licensing their software platforms to other automakers.\n\nRivian's partnership with Volkswagen, announced last year, was a clear first shot at those licensing ambitions. Tesla CEO Elon Musk recently balked on X that no automaker wanted to license FSD.\n\nHere are four ways Rivian is taking a page out of Tesla's playbook.\n\nRivian has been using a combination of Nvidia and Qualcomm Snapdragon chips to power various vehicle functions, including driver-assistance and infotainment systems.\n\nNow, the company is turning to in-house silicon to power its next-generation autonomous driving hardware.\n\n\"At the core of Rivian's technology roadmap is the transition to in-house silicon, designed specifically for the vision-centric physical AI,\" the company said.\n\nA Rivian spokesperson told Business Insider that the chips will be manufactured by TSMC.\n\nTesla began a production shift toward in-house chips in 2019 and has since released two iterations, AI3 and AI4. Musk has said that Tesla's next-generation chip, AI5, will be 40 times better than its predecessor.\n\nRivian's \"Gen 3 Autonomy\" hardware is under validation and is expected to be shipped with R2 by the end of 2026, the company said.\n\nWith the new chips, Rivian's explicit goal is to achieve full autonomy ‚Äî that's Level 4, or the kind of self-driving technology seen in Alphabet's Waymo, in which driver supervision is not required.\n\nMusk has already made full autonomy Tesla's north star, pledging to turn every personally-owned Tesla into a robotaxi that can generate revenue.\n\nThe Tesla CEO's goals have been met with considerable skepticism, particularly due to the company's decision to abandon lidar, a sensor that many industry leaders consider essential for safety and redundancy in self-driving cars.\n\nRivian, for its part, plans to incorporate lidar into the R2 vehicle. The sensor appears to be installed within the car, just above the middle of the windshield.\n\nA Rivian spokesperson told Business Insider that the company collaborated with a third party on the \"exterior design\" of Rivian's \"lidar implementation.\"\n\nThe company did not share a timeline for launching fully autonomous driving.\n\nIn the near term, Rivian will update its ADAS with hands-free assisted driving capability. The feature won't be functional on every road, according to a press release.\n\nRivian said it will be available on \"over 3.5 million miles of roads across the USA and Canada\" and can operate \"off-highway on roads with clearly painted lines.\"\n\nAt Thursday's event, Scaringe also suggested potential robotaxi ambitions.\n\n\"This also enables us to pursue opportunities in the rideshare space,\" the CEO said.\n\nRivian is following Tesla's FSD subscription model for what it's calling \"Autonomy+.\"\n\nThe software will launch \"early 2026\" and be priced at $49.99 a month or $2,500 for a one-time purchase.\n\nTesla's FSD is $99 a month or $8,000 up front.\n\nRivian said the software will be continuously updated. The \"trajectory\" for the feature will be \"point-to-point\" navigation ‚Äî where users type in a destination, and the car drives itself just like FSD ‚Äî as well as eyes-off driving capabilities and \"personal L4\" capabilities, according to the automaker.\n\nThe Rivian spokesperson told Business Insider that \"hundreds of millions of miles contribute to the development of Autonomy+.\"\n\n\"This data is comprised of samples from around the US and Canada year-round, capturing diversity in both geography and seasonality,\" the spokesperson said.\n\nMusk announced in July an integration of xAI's Grok in Tesla vehicles, providing a chatbot that drivers can talk to and, more recently, ask for directions.\n\nRivian will be following a similar playbook with \"Rivian Assistant,\" an AI voice interface that will be \"model-agnostic,\" according to the automaker.\n\n\"Our framework allows us to orchestrate different models and choose the best one for the task,\" a Rivian spokesperson said.\n\nThe company said in a press release that the AI assistant can connect to third-party apps and will start with the integration of Google Calendar.\n\nThe AI assistant can also assist with vehicle diagnostics and control certain vehicle functions, such as activating the car's seat heaters.\n\nThe feature will be shipped early 2026 on Gen 1 and Gen 2 R1 vehicles.",
    "readingTime": 5,
    "keywords": [
      "press release",
      "road map",
      "driver supervision",
      "fully autonomous",
      "vehicle functions",
      "in-house silicon",
      "autonomous driving",
      "business insider",
      "tesla's fsd",
      "rivian"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/rivian-vs-tesla-autonomous-driving-fsd-chips-ai-assistant-2025-12",
    "thumbnail_url": "https://i.insider.com/693a2e2a71107c9f3457be1b?width=1200&format=jpeg",
    "created_at": "2025-12-11T18:58:22.388Z",
    "topic": "finance"
  },
  {
    "slug": "when-supply-chains-become-autonomous",
    "title": "When Supply Chains Become Autonomous",
    "description": "A testbed built around one of management education‚Äôs most enduring simulations, the MIT Beer Distribution Game, has shown that the latest generation of generative AI models can now autonomously manage supply chains. Systems using advanced reasoning models like GPT-5 and Llama 4 adapted to changing conditions, minimized costs, and overcame the bullwhip effect. But managers should be aware that success depends on model selection, guardrails, curated data sharing, and prompt design. Such autonomous AI agents will allow human managers to focus on higher-value functions.",
    "fullText": "When Supply Chains Become Autonomous by Carol Long, David Simchi-Levi, Andre P. Calmon and Flavio P. CalmonDecember 11, 2025PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintLess than a year ago, it seemed like that day when generative AI would bring about a new era of supply chain autonomy‚Äîone where AI could adeptly make all the inventory and logistics decisions‚Äîwas still far off. But to the astonishment of many experts, including us, that day has arrived‚Äîat least in the lab.",
    "readingTime": 1,
    "keywords": [
      "supply"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/when-supply-chains-become-autonomous",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_11_MorganeFadanelli.jpg",
    "created_at": "2025-12-11T18:58:21.935Z",
    "topic": "business"
  },
  {
    "slug": "i-tried-photoshop-in-chatgpt-and-it-went-better-than-i-expected",
    "title": "I Tried Photoshop in ChatGPT, and It Went Better Than I Expected",
    "description": "You can now get Adobe's AI image editor inside OpenAI's AI chatbot.",
    "fullText": "Generative AI tools continue to improve in terms of their photo editing capabilities, and OpenAI's latest upgrade brings Adobe Photoshop right inside your ChatGPT app window (alongside Adobe Acrobat for handling PDFs, and Adobe Express for graphic design). It's available to everyone, for free‚Äîyou just need a ChatGPT account and an Adobe account.\n\nAs per Adobe, the idea is to make \"creativity accessible for everyone\" by plugging Photoshop tools directly into ChatGPT. The desktop version of Photoshop already comes with plenty of generative AI features of its own, so this is AI layered on top of more AI‚Äîbut is it actually useful?\n\nAdobe Photoshop, Adobe Express and Adobe Acrobat are available now inside ChatGPT on the desktop, on the web, and on iOS. At the time of writing, you can also get Adobe Express inside ChatGPT for Android, with Photoshop and Acrobat \"coming soon.\" To weigh the capabilities of the new integration, I tested it in a desktop web browser.\n\nTo get started, all you need to do is type \"Photoshop\" at the start of your prompt: ChatGPT should recognize what you're trying to do, and select Adobe Photoshop as the tool to use for the next prompt. You'll also need to click through a couple of confirmation dialog boxes, and connect an Adobe account (if you don't have one, you can make one for free).\n\nWith all the connections and logins completed, Photoshop is then added to the overflow menu in the prompt box, so just click on the + (plus) to select it. You can start describing what you want to happen using the same natural, conversational language you'd use for any other ChatGPT prompt. You do need to also upload an image or provide a public link to one‚Äîif you don't do this before you submit your prompt, you'll be asked to do it after.\n\nYou don't need to know the names of all the Photoshop tools: Just describe what you want to happen and the relevant tools will be selected for you. One example Adobe gives is using the prompt \"make my image pop,\" which brings up the Bloom, Grain, and Lens Distortion effects‚Äîand each one can be adjusted via sliders on screen. It's actually quite simple to use.\n\nIf you do know the name of the tools you want, you can call them up by name, and the classic brightness and contrast sliders are a good place to start. You can either say something like \"make the picture brighter\" or \"adjust the image brightness\"‚Äîboth will bring up an overlay you can use to make brightness adjustments, but if you use the former prompt, the image will already have been made a little brighter.\n\nChatGPT and Photoshop let you add edit upon edit as needed, and you can save the image at any stage. There's also the option to open your processed file in the Photoshop web app whenever you like: This web app uses a freemium model, with advanced features requiring a subscription, and seems to be what the ChatGPT integration is largely based on.\n\nAdobe offers a handy ChatGPT prompts cheat sheet you can browse through, which gives you a good idea of what's possible, and what you're still going to need Photoshop proper for. Note that you can specify certain parts of the image to focus on (like \"the face\" or \"the car\") but this depends on Photoshop-in-ChatGPT being able to correctly figure out where you want your selection to be. It needs to be pretty obvious and well delineated.\n\nWhen I tried cutting out objects and removing backgrounds, this worked well‚Äîbut then I had to turn to Photoshop on the web to actually drop in a different background. There's no way to work with layers or masks here, and you can't remove people or objects from photos, either. Sometimes, however, you do get a spool of \"thinking\" from ChatGPT about how it can't do what the user is asking for.\n\nI was able to apply some nice colorizations here, via prompts like \"turn all the hues in this image to blue,\" and I like the way ChatGPT will give you further instructions on how to get the effect you want. You can even say \"show some examples\" and it gives you a few presets to choose from‚Äîall of which can be adjusted via the sliders again.\n\nThe ability to run prompts like \"turn this into an oil painting\" or \"turn this into a cartoon\" are useful too, though the plug-in is limited by the effects available in Photoshop for the web: You'll be directed to the closest effect and advised how to tweak it to get the look you want.\n\nActually, some of these effects work better in ChatGPT's native image editor, which maybe explains why Adobe wanted to get involved here.\n\nIf ChatGPT's image manipulation gets good enough, then Photoshop is no longer going to be needed by a substantial number of users: ChatGPT can already remove people and objects from photos, for example, quite effectively. What it's not quite as good at is some of the basic adjustments (like colors and contrast) that Adobe software has been managing for years.\n\nFor quick, basic edits you want to type out in natural language‚Äîespecially where you want to adjust the edits manually and need advice on what to do next‚ÄîPhotoshop inside ChatGPT is a handy tool to be able to turn to, especially as it's free. For serious edits, though, you're still going to want to fire up the main Photoshop app, or maybe even shun Adobe altogether and make use of ChatGPT's steadily improving editing tools.",
    "readingTime": 5,
    "keywords": [
      "prompt you'll",
      "inside chatgpt",
      "adjusted via",
      "adobe account",
      "photoshop tools",
      "web app",
      "it's",
      "desktop",
      "you're",
      "don't"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/adobe-photoshop-in-chatgpt?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC6DVWW8SYF0AP0H0T4J6WFG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T18:58:21.016Z",
    "topic": "tech"
  },
  {
    "slug": "disney-will-now-let-you-make-ai-slop-of-its-characters-on-sora",
    "title": "Disney Will Now Let You Make AI Slop of Its Characters on Sora",
    "description": "Disney is literally paying $1 billion for this.",
    "fullText": "If you've engaged in any sort of doomscrolling over the past year, you've no doubt encountered some wild AI-generated content. While there are plenty of AI video generators out there producing this stuff, one of the most prevalent is OpenAI's Sora, which is particularly adept at generating realistic short-form videos mimicking the content you might find on TikTok or Instagram Reels. These videos can be so convincing at first glance, that people often don't realize what they're seeing is 100% fake. That can be harmless when it's videos of cats playing instruments at midnight, but dangerous when impersonating real people or properties.\n\nIt's that last point that I thought would offer some pushback to AI's seemingly exponential growth. These companies have trained their AI models on huge amounts of data, much of which is copyrighted, which means that people are able to generate images and videos of iconic characters like Pikachu, Superman, and Darth Vader. The big AI generators put guardrails on their platforms to try to prevent videos that infringe on copyright, but people find a way around them. As such, corporations have already started suing OpenAI, Google, and other AI companies over this blatant IP theft. (Disclosure: Lifehacker‚Äôs parent company, Ziff Davis, filed a lawsuit against OpenAI in April 2025, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)\n\nBut it seems not all companies want to go down this path. Take Disney, as a prime example. On Thursday, OpenAI announced that it had made a three-year licensing agreement with the company behind Mickey Mouse. As part of the deal, Sora users can now generate videos featuring over 200 Disney, Marvel, Pixar, and Star Wars characters. The announcement names the following characters and movies specifically:\n\nThat includes licensed costumes, props, vehicles, and environments. What's more, Disney+ will host a \"selection\" of these \"fan-inspired\" Sora videos. (I'll admit, that last point genuinely shocks me.) This does only apply to Disney's visual assets, however, as Sora users won't have access to voice acting. ChatGPT users will also be able to generate images with these characters, so this news doesn't just affect Sora users.\n\nYou might think OpenAI is paying Disney a hefty licensing fee here, but it appears to be quite the opposite. Not only is Disney pledging to use OpenAI APIs to build \"products, tools, and experiences,\" it is rolling out ChatGPT to its employees as well. Oh, and the company is making a $1 billion equity investment in OpenAI. (Is that all?)\n\nI know many companies are embracing AI, often in ways I disagree with. But this deal is something else entirely. I'm not sure any Disney executives actually searched for \"Sora Disney\" on the internet, because right now, you'll find fake AI trailers for Pixar movies filled with racism, sexual content, and generally offensive content‚Äîall generated using an app Disney just licensed all of its properties to. OpenAI asserts in its announcement that both companies are committed to preventing \"illegal or harmful\" content on the platform, but Sora users are already creating harmful content. What kind of content can we expect with carte blanch access to Disney's properties?\n\nNow that Disney's characters are fair game, I can't imagine the absolute slop that some users are going to make here. The only hope I have is in the fact that Disney+ is going to host some of these videos. Staff will have to weed through some garbage to find videos that are actually suitable for the platform. And maybe seeing the \"content\" that Sora users like to make with iconic characters will be enough for Disney to rethink its plans.",
    "readingTime": 4,
    "keywords": [
      "sora users",
      "generate images",
      "iconic characters",
      "harmful content",
      "ziff davis",
      "videos",
      "properties",
      "disney",
      "disney's",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/disney-and-openai-are-partnering-on-ai-slop?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC72R3XE3XTEEXZRCBF450S8/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T18:58:20.900Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-england-gaming-star-daniel-stingray-ray",
    "title": "Sutton's predictions v England Gaming star Daniel 'Stingray' Ray",
    "description": "BBC Sport football expert Chris Sutton takes on England Gaming star Daniel 'Stingray' Ray - and AI - with his predictions for this weekend's Premier League fixtures.",
    "fullText": "Sunday brings the first Wear-Tyne derby since 2024 but will it be Sunderland or Newcastle celebrating afterwards?\n\n\"For most of last season you couldn't have imagined Sunderland getting promoted and being competitive with Eddie Howe's Newcastle, let alone being above them in the table,\" said BBC Sport football expert Chris Sutton.\n\n\"It is very different now, and the way Sunderland play makes me think they've got a real chance.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 16, he takes on England Gaming star Daniel 'Stingray' Ray.\n\nRay is going for glory for the eLions - the Football Association's official esports team - at EA Sports FC in the Uefa eEuro 2025 finals tournament, which takes place at Twickenham Stadium on Saturday.\n\nYou can watch the action on Uefa's YouTube, IG Live and TikTok channels, as well as EA Sports FC Twitch and YouTube and England's Twitch.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "sunderland",
      "season",
      "predictions",
      "youtube",
      "twitch",
      "points",
      "newcastle",
      "sport",
      "football",
      "sutton"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/ce8q055q17ro?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/8ef4/live/cb18b2b0-d695-11f0-8c06-f5d460985095.jpg",
    "created_at": "2025-12-11T18:58:20.003Z",
    "topic": "sports"
  },
  {
    "slug": "ai-predictions-for-2026-a-devops-engineers-guide",
    "title": "AI Predictions for 2026: A DevOps Engineer's Guide",
    "description": "AI predictions for 2026 and what they mean for DevOps engineers. From agent orchestration to local AI breakthroughs, here's how to prepare your infrastructure.",
    "fullText": "Posted on Thursday, Dec 11, 2025\n\nThe IDE is dying, and so is tool calling. OpenAI is not going to win. And next year, you‚Äôre going to be shipping code that you‚Äôve never reviewed before, even as an experienced engineer.\n\nThese are bold claims, but the way we use AI in 2026 for coding and agents is going to look completely different. In this post, I want to cover my predictions and why they matter right now for DevOps engineers. Some of these are definitely hot takes, but that‚Äôs what makes this conversation worth having.\n\nTraditional IDEs where the code is the focus of the interface are simply going to become irrelevant. We‚Äôre moving toward agent manager interfaces where we can kick off agents in parallel to work on different features in a codebase or even work on different projects at the exact same time.\n\nWe‚Äôre already seeing this transition. Google Antigravity combines a familiar AI-powered coding experience with a new agent-first interface. You can deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Cursor 2.0 lets you run up to eight agents in parallel on a single prompt, using git worktrees or remote machines to prevent file conflicts. Each agent operates in its own isolated copy of your codebase.\n\nAWS validated this direction at re:Invent 2025 by announcing ‚Äúfrontier agents‚Äù including Kiro for autonomous coding, along with dedicated security and DevOps agents. These agents maintain state, log actions, operate with policy guardrails, and integrate directly with CI/CD pipelines.\n\nFor infrastructure specifically, Pulumi Neo represents this same shift. Instead of writing code or running CLI commands for every operation, you describe what you need in natural language and Neo handles the implementation. It works across your entire infrastructure, understanding dependencies and creating execution plans that go through pull requests for review.\n\nFor DevOps engineers, this means your pipelines need to accommodate AI-generated code at scale. Multiple agents working simultaneously need isolated, reproducible environments. More generated code means more artifacts to track, version, and deploy.\n\nA lot of people think that in the future a single large language model is going to have a monopoly and be the best at absolutely everything. But what‚Äôs really going to happen is different providers will specialize and focus on being the best at different things.\n\nGoogle is going down the generalist play with Gemini, aiming to be the jack of all trades. Anthropic is focusing on being the best for coding. You can see this in the benchmarks: when Opus 4.5 came out, the first benchmark they highlighted was for software engineering, because that‚Äôs what Anthropic is focusing on.\n\nAmazon is carving out its own niche with the Nova model family, announced at re:Invent 2025. The Nova 2 lineup includes specialized models: Pro for complex reasoning, Sonic for real-time voice conversations, and Omni for simultaneous text, audio, and video processing. With Nova Forge, organizations can build custom frontier models by combining their proprietary data with AWS open weight models. The re:Invent message was clear: leveraging your first-party data is now fundamental to going beyond generic AI. We‚Äôre talking about 30-40% increases in accuracy when you bring your own data into the equation.\n\nBut here‚Äôs the hot take: I don‚Äôt think OpenAI is going to come out on top with any kind of specialization. They‚Äôve disappointed time and time again with GPT-5 and GPT-4.5. With 4.5, they seemed to try to be the creative specialist, but it just didn‚Äôt work. The GPT-5 launch in August 2025 was described as ‚Äúbarely better than last month‚Äôs flavor of the month‚Äù and on some metrics it‚Äôs actually worse than earlier models.\n\nFor DevOps teams, this specialization means you‚Äôll need infrastructure that‚Äôs model-agnostic and supports multiple AI backends. Plan for secrets management across multiple LLM providers and design your systems to swap models based on the task at hand.\n\n2026 is going to be the year of local AI. We didn‚Äôt see that much this year besides DeepSeek at the start of 2025, which was a big deal. We had a couple of new models like Qwen 3, but nothing that fundamentally changed the game. Now we‚Äôre starting to see new hardware that makes it obvious we‚Äôre going to be able to run very large models on smaller devices.\n\nThere‚Äôs new AI chips that can run upwards of 120 billion parameter large language models on the edge, which would be a complete game-changer. Right now, hardware requirements are one of the biggest problems when it comes to scaling local AI. If we can solve the hardware problem, we get 100% data privacy and zero-millisecond latency for our agents.\n\nAWS is addressing this with Trainium3 UltraServers, their 3nm AI chips delivering 4.4x more compute than the previous generation. More significantly, AWS AI Factories allow organizations to deploy racks of Trainium chips and NVIDIA GPUs directly into their own data centers, addressing data sovereignty concerns while keeping AI inference close to the data.\n\nFor DevOps, this opens possibilities for zero-latency inference in CI/CD pipelines, complete data privacy for sensitive codebases, and reduced cloud costs for AI-heavy workloads.\n\nWe‚Äôre finally going to get to the point where we‚Äôre not the coders. We delegate that entirely to our coding agents and we become the system architects. This mirrors the evolution of other engineering disciplines. Civil engineers don‚Äôt fabricate the steel beams; they design the structure and verify the integrity.\n\nI think of this as a three-step process:\n\nWe‚Äôre still in the loop. We are the final say in whatever is created, but we‚Äôre delegating the grunt work to our coding agents.\n\nThis is exactly the model that Pulumi Neo implements for infrastructure. When you give Neo a complex request, it creates a task plan outlining the steps it will take to accomplish your goal. This plan provides transparency into Neo‚Äôs approach and gives you the opportunity to adjust the strategy before execution begins. Neo operates in different modes: Review mode where everything requires approval, Balanced mode where only deployments need sign-off, or Auto mode for full autonomy. You define the boundaries, Neo orchestrates the work, and you validate through pull requests and previews.\n\nFor DevOps engineers, this shift means building robust validation infrastructure becomes critical. When AI writes the code, you need automated testing pipelines, security scanning, and verification systems that can operate at the speed of AI-generated changes.\n\nHere‚Äôs a key insight that kept coming up at re:Invent: models are no longer the bottleneck. Context is. Our agents are going to change a lot next year because code execution is starting to replace tool calling. The problem with tool calling right now is that all the capabilities you give an agent take up context upfront. When you try to give a lot of different tools to an agent, you completely overwhelm it.\n\nAnthropic‚Äôs research on code execution with MCP addresses exactly this problem. Code execution is a massive token reduction, faster, and more flexible. You‚Äôre giving the agent the ability to generate its own capabilities at runtime by writing code to interact with APIs. A workflow that previously consumed about 150,000 tokens when tools were passed directly through the model was reimplemented with code execution and used only about 2,000 tokens. That‚Äôs a 98.7% reduction.\n\nAWS embraced this pattern with Amazon Bedrock AgentCore, which now includes code interpretation capabilities. AgentCore supports any agent framework (CrewAI, LangGraph, OpenAI SDK) and provides memory, browser tools, and observability features that make code execution practical at enterprise scale.\n\nFor DevOps, this means you need sandboxed, secure execution environments for AI-generated code. Running agent-generated code requires appropriate isolation, resource limits, and monitoring.\n\nThe best part about code execution flexibility is it unlocks progressive disclosure. All I mean by that is: you have a lot of capabilities for an agent, but you don‚Äôt actually give all of them upfront. Instead, you allow the agent to discover capabilities and then leverage them in a more flexible way.\n\nFor each capability, you just have a bit of metadata or description that loads upfront. When the agent decides to leverage that capability, then you load the full instructions. Now you can practically scale to infinity because all capabilities don‚Äôt have to be loaded at runtime.\n\nClaude Skills is a good example of this pattern. Skills are organized folders of instructions, scripts, and resources that agents can discover and load dynamically. At session start, the agent scans available skills and populates the system prompt with just a brief name and description (around 100 tokens). The full skill prompt loads only after Claude selects it, preventing context bloat while maintaining discoverability.\n\nKiro Powers addresses the same problem. Connecting five MCP servers can consume over 50,000 tokens, roughly 40% of an AI model‚Äôs context window, before you even type your first request. Powers bundle MCP servers, steering files, and hooks into units that load dynamically based on conversation context. Mention ‚Äúpayment‚Äù and the Stripe power activates. Datadog, Figma, and others have powers available.\n\nFor DevOps, this translates to modular infrastructure definitions, on-demand capability loading, and efficient resource utilization. Think about how you can apply this pattern to your own automation.\n\nAgent-to-agent protocols are where AI agents operate in a peer network, discover each other‚Äôs capabilities in real time, and interact autonomously. When Google released their A2A protocol earlier this year, there was a ton of buzz. A lot of people thought it was going to be the next big standard, like the next MCP. But then it kind of fell to the wayside.\n\nThe big reason is the chicken-and-egg problem. In order for A2A to be useful, you need a lot of people to adopt it at the same time. Otherwise, if you build an A2A-compatible agent, it has no other agents to talk to. The whole value proposition is lost unless you already have a big network to attach to.\n\nBut that‚Äôs finally changing. The Linux Foundation launched the A2A project in June 2025, and adoption is accelerating. Adobe, Microsoft, SAP, ServiceNow, and S&P Global are all implementing A2A. In July 2025, Google released version 0.3 of the A2A protocol with a more stable interface critical to accelerating enterprise adoption.\n\nMy next big prediction is that machines paying machines is going to become a very big thing. Coinbase released the x402 protocol for exactly this: building AI agents that you expose over the internet but require payment whenever someone else interacts with them.\n\nThis goes really well with agent-to-agent protocols. You can create a peer network where you monetize your agents. They all leverage each other but make payments whenever they take advantage of another agent‚Äôs capabilities. Cryptocurrency is the perfect solution for this kind of machine-to-machine network because you need a currency where it‚Äôs easy to do micropayments quickly and globally.\n\nThe x402 protocol has achieved 156,000 weekly transactions with 492% growth since launching in May 2025. It‚Äôs now integrated with Anthropic‚Äôs MCP Protocol, Google Gemini, OpenAI Codex, and other platforms. Stablecoins like USDC make it possible to charge per request, per service, or per second of usage with near-zero transaction costs, enabling payments as low as $0.001 per request.\n\nWhen we want to do a rigorous code review traditionally, we look line by line at all the changes. But coding agents are getting to the point where they can prove their code works through artifacts. Instead of reviewing line by line, we can look at browser recordings, full working demos of a backend API, and other artifacts.\n\nGoogle Antigravity is a perfect example. As part of its coding process, it can autonomously spin up your website, visit it, scroll through it, take screenshots, and record everything. Agents generate artifacts, including tangible deliverables like task lists, implementation plans, screenshots, and browser recordings. You can verify the agent‚Äôs logic at a glance.\n\nAmazon Nova Act takes this further. It enables AI agents to automate browser-based tasks like form filling, QA testing, and workflow validation with over 90% reliability. The service includes built-in observability through live viewing, CloudTrail logging, and session replay, making it possible to review what an agent actually did rather than parsing through code changes.\n\nFor the last prediction, we‚Äôre tying everything together. We‚Äôve talked about reviewing artifacts instead of diffs, creating systems instead of coding, and the new capabilities for agents with code execution.\n\nWe‚Äôre going to get to the point very quickly where we‚Äôre shipping code that we have never read before. And I‚Äôm not talking about people who vibe code. Even experienced engineers are going to trust their systems so much that they have the ability to review the code but they‚Äôre not going to. We‚Äôre just going to ship to production after reviewing the artifacts.\n\nI presented on this exact topic at the Tel Aviv Pulumi User Group meetup at Qodo HQ back in October, where I demonstrated how Pulumi Neo‚Äôs autonomous decision-making capabilities can handle infrastructure tasks that we traditionally managed manually. Qodo is doing fascinating work in this space with their agentic development tools, building systems that let you trust the output without necessarily reviewing every line.\n\nI‚Äôm not saying we‚Äôre taking the human completely out of the loop. I‚Äôm saying we‚Äôre going to have a lot of trust in our systems and a validation process that includes us, but that doesn‚Äôt necessarily have to be us actually looking at the code. Tools like Pulumi Neo create pull requests with clear documentation of changes, run previews to validate infrastructure modifications, and provide the transparency needed to ship with confidence.\n\nThe predictions I‚Äôve outlined point to a fundamental shift in how software gets built and deployed. For DevOps engineers, this isn‚Äôt a threat but an opportunity to become more strategic and less operational. We‚Äôre entering the battle of the agentic frameworks, where the winners will be those who can build faster, cheaper agentic applications through their platforms.\n\nThe immediate reality is that your CI/CD pipelines need to accommodate AI-generated code at scale, your secrets management needs to handle multiple LLM providers, and your execution environments need proper sandboxing for agent-generated code. These aren‚Äôt future concerns; they‚Äôre requirements for working effectively with the AI tools available today.\n\nLooking further out, the engineers who thrive will be those who embrace the system architect role. Define clear objectives and constraints for your AI agents. Build validation frameworks that can verify outcomes without requiring line-by-line code review. Design infrastructure that‚Äôs modular enough to load capabilities on demand.\n\nThe technology to make this happen already exists. Agent orchestration platforms are shipping. Code execution is replacing tool calling. Progressive disclosure patterns are proven. The question isn‚Äôt whether these changes are coming; it‚Äôs whether you‚Äôll be ready when they arrive.\n\nIf you want to experience what this future looks like right now, Pulumi Neo is the place to start. Neo lets you make natural language requests for routine infrastructure tasks, analysis, and management. Instead of writing code for every operation, you describe what you need and Neo handles the implementation, creating task plans, running previews, and opening pull requests for your review.\n\nWhether you‚Äôre looking to update outdated resources across your infrastructure, analyze your cloud spend, or automate complex multi-step workflows, Neo provides the agent-first experience that‚Äôs defining the next generation of DevOps tooling.\n\nGet started with Pulumi Neo and see how AI-powered infrastructure automation can transform your workflow.",
    "readingTime": 13,
    "keywords": [
      "llm providers",
      "accommodate ai-generated",
      "ci/cd pipelines",
      "mcp servers",
      "google released",
      "neo handles",
      "a2a protocol",
      "devops engineers",
      "artifacts instead",
      "for devops"
    ],
    "qualityScore": 1,
    "link": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/",
    "thumbnail_url": "https://www.pulumi.com/blog/ai-predictions-2026-devops-guide/meta.png",
    "created_at": "2025-12-11T13:53:40.763Z",
    "topic": "tech"
  },
  {
    "slug": "the-abundance-paradox-why-netflixs-acquisition-makes-sense-in-the-era-of-ai",
    "title": "The Abundance Paradox: Why Netflix's Acquisition Makes Sense in the Era of AI",
    "description": "The Abundance Paradox: Why Netflix‚Äôs $82B Acquisition Makes Sense in the Era of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/Konstantine/status/1998512521385488841",
    "thumbnail_url": "https://pbs.twimg.com/media/G7wkWdxaQAAeio1.jpg:large",
    "created_at": "2025-12-11T13:53:40.525Z",
    "topic": "tech"
  },
  {
    "slug": "slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations",
    "title": "SLB partners with Shell to develop AI solutions for energy operations",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/slb-partners-with-shell-to-develop-ai-solutions-for-energy-operations-93CH-4403467",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/international_newspapers_108x81.jpg",
    "created_at": "2025-12-11T13:53:38.207Z",
    "topic": "finance"
  },
  {
    "slug": "when-ai-takes-the-tasks-managers-take-the-relationships",
    "title": "When AI takes the tasks, managers take the relationships",
    "description": "Leaders say agents should handle the busywork so human managers can be more connected to their teams.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/11/when-ai-takes-the-tasks-managers-take-the-relationships/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974174223_1f91a177fa_6k-e1765458447816.jpg?resize=1200,600",
    "created_at": "2025-12-11T13:53:36.502Z",
    "topic": "business"
  },
  {
    "slug": "openais-house-of-cards-seems-primed-to-collapse",
    "title": "OpenAI's house of cards seems primed to collapse",
    "description": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.",
    "fullText": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago.\n\nBack in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo.\n\nBut it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others ‚Äî including Microsoft and Apple ‚Äî made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy.\n\nSince then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump‚Äôs inauguration, China‚Äôs DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.\n\nIn response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss.\n\nIt's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI.\n\nAnthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Informationsaid Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings.\n\nHowever, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI.\n\nAccording to a December 2 report from TheWall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic.\n\nThe few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator.\n\nMore importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year.\n\nIn an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.\n\nSince late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well.\n\n\"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.\n\nGita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels.\n\nThe modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment.",
    "readingTime": 6,
    "keywords": [
      "code red",
      "search giant",
      "openai",
      "chatbot",
      "model",
      "models",
      "memory",
      "release",
      "google",
      "released"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/chatgpt/article/openais-house-cards-seems-primed-170000383.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/GqARrc67JCVOPZqPZmGxVA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/engadget_703/4fd0cc3b2f10735e6ff000f551d8a08e",
    "created_at": "2025-12-11T13:53:36.420Z",
    "topic": "tech"
  },
  {
    "slug": "an-openai-exec-identifies-3-jobs-on-the-cusp-of-being-automated",
    "title": "An OpenAI exec identifies 3 jobs on the cusp of being automated",
    "description": "\"My bet is often on life sciences, pharma companies,\"  Olivier Godement said.",
    "fullText": "Three industries are going to look very different in the next few years, according to an OpenAI executive.\n\nOn an episode of the \"Unsupervised Learning\" podcast, Olivier Godement, the head of product for business products at the ChatGPT maker, shared why he thinks a trio of jobs ‚Äî in life sciences, customer service, and computer engineering ‚Äî is on the cusp of automation.\n\n\"My bet is often on life sciences, pharma companies,\" he said, about his first pick for industries on the brink of change because of AI.\n\nGodement said that the goal of pharmaceutical companies like Amgen, with which he works, is to design new drugs. This has two components: actual research and experimentation, and admin, a time-consuming process that could be automated, he said.\n\n\"The time it takes from once you lock the recipe of a drug to having that drug on the market is months, sometimes years,\" he said. \"Turns out like the models are pretty good at that. They're pretty good at aggregating, consolidating tons of structured, unstructured data, spotting the different changes in documents.\"\n\nGodement joined OpenAI in 2023. He previously worked on products for Stripe for eight years.\n\nOn the podcast, Godement said that while we haven't reached a stage where \"any white collar job\" can be automated in just a day, he is starting to see strong use cases in fields such as coding and customer service.\n\n\"The automation is probably not yet at the level of automating completely the job of a software engineer, but I think we have a line of sight essentially to get there,\" he said.\n\nThe future of software engineering has been one of the most heated tech debates of the year, as AI-assisted coding enters most companies' workflow.\n\nAn Indeed study from October found that software engineers, quality assurance engineers, product managers, and project managers were the four tech jobs that have been axed the most during layoffs and reorgs.\n\nLastly, Godement said that customer-oriented roles like sales and customer experience may be automated soon.\n\n\"I've been working a bunch with the folks at T-Mobile, the telecom company in the US, to essentially provide a better experience to their customers, and we're starting to achieve fairly good results in terms of quality at a meaningful scale,\" he said. \"My sense is we'll probably be surprised in the next year or two on the amount of tasks that can be automated reliably.\"\n\nAcross the board, AI leaders are flagging white-collar jobs that can be easily automated by newer large language models.\n\nIn a June podcast, Geoffrey Hinton, who is recognized as the \"Godfather of AI,\" said that eventually, technology will \"get to be better than us at everything,\" but some fields are safer than others in the interim.\n\n\"I'd say it's going to be a long time before it's as good at physical manipulation,\" Hinton said. \"So a good bet would be to be a plumber.\"\n\n\"For mundane intellectual labor, AI is just going to replace everybody,\" Hinton said.\n\nHe identified paralegals as at risk, and said he'd be \"terrified\" if he worked in a call center.",
    "readingTime": 3,
    "keywords": [
      "life sciences",
      "customer service",
      "automated",
      "podcast",
      "jobs",
      "software",
      "industries",
      "openai",
      "product",
      "products"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-exec-3-jobs-ai-risk-automation-olivier-godement-2025-12",
    "thumbnail_url": "https://i.insider.com/693a53227ecd1d1da66356ca?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.388Z",
    "topic": "finance"
  },
  {
    "slug": "from-garlic-to-avocado-the-goofy-ai-model-codenames-you-should-know",
    "title": "From Garlic to Avocado: The goofy AI model codenames you should know",
    "description": "Leading tech and AI companies are thinking with their stomachs when it comes to naming their secretive AI advancements.",
    "fullText": "It may sound like a trip through the produce aisle, but leading AI companies have something much more important on their lists.\n\nMeta, OpenAI, and Google have all relied on food-related names for their sometimes secretive plans for future AI models. Thinking with your stomach is nothing new for Silicon Valley, just look at the assortment of desserts Android assembled over the years before Google had its fill.\n\nHere is a look at the mouthwatering and just plain goofy names AI and tech companies are using\n\nMeta has codenamed its future AI frontier model \"avocado,\" per a CNBC report. Guac usually costs extra, and CEO Mark Zuckerberg's AI pivot has not come cheap. Meta plans to spend more than $70 billion this year on AI infrastructure, which is on top of $14 billion investment Meta made in Scale AI and to poach its founder, Alexandr Wang.\n\nOpenAI has hit a rough patch, feeling the heat from Google's advances and stumbling with a series of missteps. So perhaps it was time to spice things up. The ChatGPT maker has codenamed its new large language model \"garlic,\" according to The Information. Garlic is separate from another LLM OpenAI is developing, codenamed \"Shallotpeat.\"\n\nGoogle appears to have loved a codename so much that it made it public. Google's AI image generator in Gemini is named Nano Banana Pro, which it released on November 20. Before then, Google had internally called the model nano-banana, though they had not publicly disclosed their zany choice.\n\nThe clearance section offers a wide selection of great names. OpenAI might have one of the best all-time codenames with \"strawberry,\" which it used to refer to its o1 model. The name was likely a play on the viral struggle of AI models to correctly identify the number of Rs in the fruit. Before Strawberry, OpenAI had a secretive project named Q*.\n\nEarlier this year, Elon Musk's xAI had a sweet tooth when it codenamed an early testing version of Grok-3 \"chocolate.\"\n\nMistral AI, the France-based startup, went in a completely opposite direction with \"Jaguar,\" its codename for a testing model.\n\nAnd Anthropic named its family of models Opus, Sonnett, and Hakiu, a trio of three different types of compositions.",
    "readingTime": 2,
    "keywords": [
      "model",
      "codenamed",
      "models",
      "named",
      "secretive",
      "plans",
      "look",
      "codename",
      "testing",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-codenames-meta-avocado-openai-garlic-strawberry-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c0d071107c9f3457b599?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.123Z",
    "topic": "finance"
  },
  {
    "slug": "included-health-is-launching-an-ai-personal-health-assistant-thatll-face-off-with-big-tech-from-verily-to-openai",
    "title": "Included Health is launching an AI personal health assistant that'll face off with Big Tech from Verily to OpenAI",
    "description": "The startup's new tech could compete with Big Tech's health AI projects from heavyweights like Alphabet and OpenAI.",
    "fullText": "Included Health is rolling out a new AI tool that could pit it against Big Tech's latest health bets.\n\nThe healthcare startup has launched an AI-powered personal health assistant, Business Insider has learned exclusively. The tech draws on patients' medical claims, benefits information, and other data to offer on-demand answers to health-related questions.\n\nIncluded Health is tapping into a hot area in healthcare AI, where it's competing against other health startups as well as tech heavyweights. Alphabet's Verily released its own AI-powered app in October that allows patients to connect their medical records and ask a chatbot their health-related questions. OpenAI wants to win in consumer health tech, too, and is considering building tools such as its own personal health assistant, Business Insider reported in November.\n\nIncluded Health has been scaling on the premise of personalizing how patients interact with their healthcare for over a decade. The company, which sells tech to about 300 employers and health plans to help patients better navigate their health benefits, tested its AI assistant for about 18 months to ensure its accuracy in smaller pilots before making it available to its entire employer base, CEO Owen Tripp said.\n\n\"This can't be ChatGPT level of probability. It has to be precise,\" he said.\n\nTripp is optimistic about patients receiving general health guidance from LLMs like OpenAI's ChatGPT or Anthropic's Claude. Those AI tools can help patients learn more about their conditions and prepare for doctor's visits, he said. But he emphasized that Included's tech takes that guidance a step further.\n\n\"When it gets down to the business of actually taking care of oneself or taking care of somebody else, you're going to need a lot of very secure, specific data and a whole context to go solve problems, including the exact medical history of that patient,\" Tripp said.\n\nPatient-facing healthcare AI sometimes walks a regulatory tightrope, especially if the tech provides personalized advice that effectively replaces the work clinicians are licensed to do. Tripp said he doubts that most large tech companies attempting to delve into medical records aggregation will want to grapple with that complexity.\n\n\"I predict, like many before them, they will pull back. It's just hard, and the juice is often not worth the squeeze for these high-profile companies,\" he said.\n\nIncluded Health's personal health assistant, called Dot, has become its members' front door and the foundation for Included's new products, said COO Nupur Srivastava.\n\nIncluded recently put Dot in front of members during open enrollment to help answer their benefits questions, Srivastava said. The AI agent can also help patients prepare for doctor's visits and send the clinician a summary of patients' past visits ahead of time.\n\nIncluded Health still employs plenty of its own clinicians and care advocates that members can talk to if they prefer. Srivastava also noted that if a patient mentions the term 'suicide' in a conversation with Dot, \"within a minute, someone will call you.\"\n\nWhen asked about Big Tech and AI startups' ambitions to build personalized health AI, Tripp said that Included Health is in talks with multiple potential partners to help them achieve those goals. He didn't specify which companies it's talking to, but he suggested some AI companies are focused on acquiring personalized health data that they can anonymize and use to train models.\n\n\"But when it comes to actually delivering patient care, we're pretty confident that companies that are going to succeed will be the ones that have well-trained physicians licensed in all 50 states, delivering on a real-time platform, across mind, body, and wallet,\" he said.\n\nIncluded Health was supposed to go public in 2022. The startup had hired banks for an IPO push, but pulled out of its planned investor meetings when the market started to tank, Tripp told Business Insider in January.\n\nTripp declined to share specifics about Included's exit strategy as of November. But Included is profitable, so the company doesn't need to raise money through a public listing, he said. Included hasn't publicly fundraised since it was formed from the 2021 merger of Grand Rounds and Doctor on Demand, and the company hasn't shared its valuation.\n\nThe public markets haven't been forgiving to healthcare startups. Only two digital health companies went public this year, Hinge Health and Omada Health. And while Hinge and Omada have fared far better than most companies that listed during digital health's 2021 IPO wave, healthcare IPO hopefuls still face high standards to going public and significant volatility risks once they begin trading.\n\n\"The last few years in our space haven't been a great commercial for being a public company,\" Tripp said.\n\nWith so many developments in healthcare AI, however, Tripp does recognize that an IPO could create opportunities for Included Health to acquire other companies.\n\n\"I do think this is a time where there are going to be some interesting capabilities and technologies available in the market that allow us to provide even more service to our members,\" he said. \"I do have my eyes very open to how I would use capital to execute on some of those M&A events. That part is more important to me.\"",
    "readingTime": 5,
    "keywords": [
      "assistant business",
      "included health",
      "doctor's visits",
      "medical records",
      "personal health",
      "personalized health",
      "business insider",
      "patients",
      "healthcare",
      "care"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/included-health-launches-own-ai-personal-health-assistant-2025-12",
    "thumbnail_url": "https://i.insider.com/691290c746c4547ecb058733?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.019Z",
    "topic": "finance"
  },
  {
    "slug": "the-godmother-of-ai-says-your-college-diploma-is-losing-power-heres-what-she-looks-for-instead",
    "title": "The 'Godmother of AI' says your college diploma is losing power ‚Äî here's what she looks for instead",
    "description": "Fei-Fei Li, founder of the AI startup World Labs, says she now favors fast learners who embrace AI tools over candidates with traditional degrees.",
    "fullText": "Don't count on a college degree to land your dream job in Silicon Valley.\n\nIncreasingly, founders and tech companies are judging talent by how quickly someone can learn, adapt, and build ‚Äî not on how long they spent in a lecture hall ‚Äî reshaping traditional pathways into the workforce.\n\nFei-Fei Li, the Stanford computer science professor widely known as the \"Godmother of AI,\" is one example of this.\n\nIn an interview on \"The Tim Ferriss Show\" this week, she spoke about the value of a degree when it comes to hiring for her AI startup, World Labs.\n\n\"When we interview a software engineer, I personally feel the degree they have matters less to us now,\" Li said.\n\n\"Now, it's more about what have you learned, what tools do you use, how quickly can you superpower yourself in using these tools ‚Äî and a lot of these are AI tools,\" she said. \"What's your mindset toward using these tools matter more to me.\"\n\nHer hiring bar has become even clearer: she won't hire software engineers who resist AI.\n\n\"At this point in 2025 ‚Äî hiring at World Labs ‚Äî I would not hire any software engineer who does not embrace AI collaborative software tools,\" Li said.\n\nIt's not about automating humans out of the equation, she added ‚Äî it's about identifying people who can grow as fast as the technology around them.\n\n\"If you're able to use these tools, you're able to learn. You can superpower yourself better,\" she said.\n\nLi's stance is part of a broader shift playing out across Silicon Valley, where more founders and even major tech firms are openly questioning the value of higher education.\n\nPalantir's CEO, Alex Karp, has openly challenged the¬†value of a college education, urging young entrepreneurs to skip the lecture hall and learn by doing instead ‚Äî a view echoed by¬†LinkedIn CEO Ryan Roslansky, who has said that¬†adaptability and AI fluency now matter far more than the \"fanciest degrees.\"\n\n\"AI makes skill sets based on years of education irrelevant,\" Dan Rhoton, CEO of Hopeworks, told Business Insider. Hopeworks is a tech-training nonprofit that prepares underrepresented talent for AI-enabled jobs.\n\nAfter 13 years of preparing unemployed young adults ages 17 to 26 in Camden, New Jersey, and Philadelphia for tech careers, Rhoton said he has watched firsthand how AI is upending the value of a college degree.\n\n\"We're seeing more and more employers coming to us, saying, 'We used to require a bachelor's degree in this, but we don't understand why.'\"\n\nInstead, he said, employers now want a \"value proposition,\" which he said any job seeker can achieve by showing an AI-generated solution to a company's specific problems.\n\n\"This is the age of: I'm someone who's going to deliver business value,\" Rhoton said. \"Not: I have the right degree.\"",
    "readingTime": 3,
    "keywords": [
      "lecture hall",
      "software engineer",
      "college degree",
      "tools",
      "tech",
      "learn",
      "hiring",
      "it's",
      "education",
      "rhoton"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godmother-of-ai-value-of-college-degrees-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693aa1db71107c9f3457c06e?width=1200&format=jpeg",
    "created_at": "2025-12-11T13:53:35.002Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-under-pressure-as-ai-fears-overshadow-fed",
    "title": "Stocks Under Pressure as AI Fears Overshadow Fed",
    "description": "FTSE 100 Live: Stocks Under Pressure as AI Fears Overshadow Fed",
    "fullText": "LiveUpdated5m agoStocks Under Pressure as AI Fears Overshadow FedJoin the Markets Today team for news and analysis vital to UK markets. Email us at marketstoday@bloomberg.net5m ago\n\n The Fed‚Äôs rate cut initially gave equities a boost, and US stocks did close higher, but that more positive mood was dashed by the \n\n results from Oracle\n\n .\n\n The software and cloud computing company‚Äôs shares slumped in after-hours trading as it tapped directly into the fears that have hit the AI trade: a jump in spending on AI data centres which are taking longer than investors want to translate into returns.\n\n Those more existential concerns were accompanied by results that failed to meet high expectations, with a 34% rise in cloud sales and 68% bump in infrastructure unit revenue falling short of analyst estimates.\n\n That‚Äôs filtering through into a rough picture in US stock futures, though it appears that the pain is mostly being confined to there, even if European and UK futures do look somewhat soggy.",
    "readingTime": 1,
    "keywords": [
      "fears",
      "markets",
      "cloud",
      "futures"
    ],
    "qualityScore": 0.75,
    "link": "https://www.bloomberg.com/news/live-blog/2025-12-11/ftse-100-live-fed-trump-powell-pound-bonds-oil-bitcoin-what-s-moving-uk-markets-right-now-markets-today",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSSIghvwg_70/v0/1200x630.png",
    "created_at": "2025-12-11T07:01:25.043Z",
    "topic": "finance"
  },
  {
    "slug": "json-to-video",
    "title": "JSON to Video",
    "description": "Create stunning videos with structured JSON prompts. Choose between Veo 3.1 and Sora 2 models for flexible AI video generation with predictable, brand-safe results.",
    "fullText": "{\n \"shot\": {\n \"composition\": \"three wide-to-mid cuts; each reveals a different room through glowing portals\",\n \"lens\": \"35mm lens with cinematic softness\",\n \"frame_rate\": \"30fps\",\n \"camera_movement\": \"smooth slider pans between each portal reveal\"\n },\n \"subject\": {\n \"description\": \"neutral adult character flipping a glowing IKEA catalog, choosing a room, and stepping into it\",\n \"wardrobe\": \"simple, clean clothing in soft neutral colors\",\n \"props\": \"oversized luminous IKEA catalog with ambient glow\"\n },\n \"scene\": {\n \"location\": \"empty white space that transforms through glowing portals\",\n \"time_of_day\": \"timeless white light interior\",\n \"environment\": \"blank studio morphing into immersive IKEA interiors via portals\"\n },\n \"visual_details\": {\n \"action\": \"each catalog flip opens a room portal; character steps into chosen one at the end\",\n \"special_effects\": \"subtle energy ripples and glow from each portal; light and particles shift per room theme\",\n \"hair_clothing_motion\": \"gentle breeze interaction from portal pull\"\n },\n \"cinematography\": {\n \"lighting\": \"balanced soft studio light with each room providing its own internal glow\",\n \"color_palette\": \"minimal white base with rich, contrasting tones in each room\",\n \"tone\": \"elegant, imaginative, clean aesthetic\"\n },\n \"audio\": {\n \"music\": \"soft, ascending ambient pad with light spark textures\",\n \"ambient\": \"dimensional air shift when portals open, soft paper flip, subtle room-specific cues\",\n \"sound_effects\": \"light shimmer for each portal, a soft hum as the final portal closes\",\n \"mix_level\": \"smooth, cinematic with priority on environmental transition sounds\"\n },\n \"dialogue\": {\n \"character\": \"\",\n \"line\": \"\",\n \"subtitles\": false\n },\n \"timeline\": [\n {\n \"t\": \"0-3s\",\n \"description\": \"Character opens glowing catalog; first portal opens to a cozy IKEA bedroom with warm light\"\n },\n {\n \"t\": \"3-6s\",\n \"description\": \"Page flips again; second portal shows modern living room with ambient shelves and pendant light\"\n },\n {\n \"t\": \"6-8s\",\n \"description\": \"Character steps confidently through the final portal into a vibrant IKEA kitchen; portal glows and fades\"\n }\n ],\n \"rules\": [\n \"Three total cuts only, each exactly 3s/3s/2s\",\n \"No camera shake or handheld motion\",\n \"No text, no branding visible\",\n \"Portals must glow and feel immersive, not holographic or flat\",\n \"Each room should match real IKEA design aesthetics\"\n ],\n \"negatives\": [\n \"text overlays\",\n \"fast cuts\",\n \"fake-looking portals\",\n \"handheld shots\",\n \"mismatched furniture styles\",\n \"shadows inconsistent with portal lighting\"\n ]\n}Expand",
    "readingTime": 2,
    "keywords": [
      "ikea catalog",
      "character steps",
      "description character",
      "final portal",
      "glowing portals",
      "light description",
      "room",
      "soft",
      "ambient",
      "cuts"
    ],
    "qualityScore": 0.3,
    "link": "https://jsontovideo.org/",
    "thumbnail_url": "https://jsontovideo.org/og.png",
    "created_at": "2025-12-11T07:01:20.644Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "title": "Oracle Credit Risk Gauge Deteriorates After Earnings Report",
    "description": "A measure of Oracle Corp.‚Äôs credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence.",
    "fullText": "TechnologyBy Caleb MutuaSaveA measure of Oracle Corp.‚Äôs credit risk climbed on Wednesday after the database company posted a jump in spending on data centers and other equipment, raising fresh doubts about how quickly it can generate profit from its huge investments in artificial intelligence. The cost of protecting the company‚Äôs debt against default for five years rose about 0.05 percentage point to around 1.246 percentage point a year, according to ICE Data Services. The gauge, which rises as investor confidence in the company‚Äôs credit quality falls, reached its highest level intraday since Thursday. It rose close to its level earlier this month, when it reached a peak since the financial crisis. Oracle credit derivatives have become a credit market barometer for AI risk.",
    "readingTime": 1,
    "keywords": [
      "credit",
      "risk",
      "company‚Äôs",
      "rose",
      "percentage",
      "oracle"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-10/oracle-credit-risk-gauge-deteriorates-after-earnings-report",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/idj3XzDNG3DY/v1/1200x800.jpg",
    "created_at": "2025-12-11T03:50:24.284Z",
    "topic": "finance"
  },
  {
    "slug": "upload-a-selfie-and-get-beautiful-ai-santa-photos-for-999",
    "title": "Upload a selfie and get beautiful AI Santa photos for $9.99",
    "description": "Upload a casual standing photo and instantly get a magical Santa portrait with PhotoJing. Fast, high-quality, and perfect for holiday cards and gifts. Create festive Santa photos online in minutes!",
    "fullText": "Turn Any Casual Photo into a Magical Santa Portrait with PhotoJing!\n\nNo lines, no stress‚Äîjust holiday magic.¬†Whether it‚Äôs your little one‚Äôs first visit with Santa or a yearly family tradition, PhotoJing creates warm, joy-filled portraits you‚Äôll treasure for years to come.\n\nUpload a simple standing photo, and our team will transform it into a festive Santa picture your family will adore. Perfect for holiday cards, gifts, and spreading seasonal cheer, PhotoJing delivers charming, high-quality Santa portraits from the comfort of your home.\n\nCreate Christmas magic in minutes‚Äîjust upload, and let us do the rest!\n\n- Upload photo(s) of 1-4 different people.\n- For larger groups, send a message for a custom order.",
    "readingTime": 1,
    "keywords": [
      "upload",
      "holiday",
      "family",
      "portraits",
      "santa",
      "photojing",
      "magic"
    ],
    "qualityScore": 0.65,
    "link": "https://www.photojing.com/products/santa-photos",
    "thumbnail_url": "http://www.photojing.com/cdn/shop/files/Santa_photo_collage_ver_2_1.png?v=1765415082",
    "created_at": "2025-12-11T03:50:16.098Z",
    "topic": "tech"
  },
  {
    "slug": "navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "title": "Navy, Palantir Announce $448M 'Ship OS' AI Tool for Shipbuilding and Repair",
    "description": "The Navy‚Äôs four public shipyards and two unidentified private shipyards are working with Palantir for a program the service is calling ‚ÄúShip OS‚Äù as part of a new $448 million effort to improve efficiency through better use of data. Announced at an industry day on Tuesday, the Shipbuilding Operating System program, or Ship OS, will collect data from across the new construction and maintenance systems to streamline shipbuilding and the repair of the current fleet, according to the service. ‚ÄúEvery ship builder who partners with us will have AI power tools that optimize their work in real time. Every supplier",
    "fullText": "USNI News Giving Tuesday 2025 \n\n Our annual Giving Tuesday campaign provides essential funding that enables our staff writers to observe firsthand the evolving character of naval warfare and international maritime commerce - and to bring those insights directly to you, our readers! Thanks to your generosity in 2024, we were able to send our team across the fleet to learn from and connect with Navy, Marine Corps, and Coast Guard in the Western Pacific, like Taiwan and the Philippines, as well as around the globe. Your support directly fuels our on-the-ground coverage of naval operations and the global security challenges facing our Sea Service leaders‚Äîchallenges that cannot be fully appreciated from within the Beltway alone. We continue to operate as a public service, and this is made possible by your generosity! If you believe in open, independent journalism, please consider supporting our critical mission with a donation today. \r\n As a special gift, all one-time or annual donations amounting to $200 or more will receive exclusive access to the Special Report: Nimitz ‚Äô75 ‚Äî Celebrating the Origin of the Nuclear Carrier Class for USS Nimitz (CVN-68) Last Deployment. Donors contributing more than $300 will also receive a Collected Edition of USNI News 2025 Sea Scroll Weekly Newsletter V2. \n\n Donate Today",
    "readingTime": 2,
    "keywords": [
      "usni",
      "annual",
      "naval",
      "directly",
      "generosity",
      "receive",
      "nimitz",
      "service"
    ],
    "qualityScore": 0.65,
    "link": "https://news.usni.org/2025/12/09/navy-palantir-announce-448m-ship-os-ai-tool-for-shipbuilding-and-repair",
    "thumbnail_url": "https://news.usni.org/wp-content/uploads/2025/12/9294700-scaled.jpg",
    "created_at": "2025-12-11T03:50:15.641Z",
    "topic": "tech"
  },
  {
    "slug": "the-normalization-of-deviance-in-ai",
    "title": "The Normalization of Deviance in AI",
    "description": "The gradual and systemic over-reliance on LLM outputs, especially with agentic systems, leads to a normalization of deviance.",
    "fullText": "The AI industry risks repeating the same cultural failures that contributed to the Space Shuttle Challenger disaster: Quietly normalizing warning signs while progress marches forward.\n\nThe original term Normalization of Deviance comes from the American sociologist Diane Vaughan, who describes it as the process in which deviance from correct or proper behavior or rule becomes culturally normalized.\n\nI use the term Normalization of Deviance in AI to describe the gradual and systemic over-reliance on LLM outputs, especially in agentic systems.\n\nAt its core, large language models (LLMs) are unreliable (and untrusted) actors in system design.\n\nThis means that security controls (access checks, proper encoding, and sanitization, etc.) must be applied downstream of LLM output.\n\nA constant stream of indirect prompt injection exploit demonstrations indicates that system designers and developers are either unaware of this or are simply accepting the deviance. It is particularly dangerous when vendors make insecure decisions for their userbase by default.\n\nI first learned about this concept in the context of the Space Shuttle Challenger disaster, where systemic normalization of warnings led to tragedy.\n\nDespite data showing erosion in colder temperatures, the deviation from safety standards was repeatedly rationalized because previous flights had succeeded. The absence of disaster was mistaken for the presence of safety.\n\nIn the world of AI, we observe companies treating probabilistic, non-deterministic, and sometimes adversarial model outputs as if they were reliable, predictable, and safe.\n\nVendors are normalizing trusting LLM output, but current understanding violates the assumption of reliability.\n\nThe model will not consistently follow instructions, stay aligned, or maintain context integrity. This is especially true if there is an attacker in the loop (e.g indirect prompt injection).\n\nHowever, we see more and more systems allowing untrusted output to take consequential actions. Most of the time it goes well, and over time vendors and organizations lower their guard or skip human oversight entirely, because ‚Äúit worked last time.‚Äù\n\nThis dangerous bias is the fuel for normalization: organizations confuse the absence of a successful attack with the presence of robust security.\n\nTwo ways this can impact systems are:\n\nAnd we already see agents make mistakes in day to day usage, like formatting hard drives, creating random GitHub issues, or wiping a production database.\n\nSo, the signs are there. And it is inherently dangerous, not only because of attacks like indirect prompt injection, but also because these systems are trained on enormous, untrustworthy data sets from the Internet. Anthropic research recently showed that it takes only a small amount of documents to successfully add a backdoor to a model.\n\nConsider a scenario where the Normalization of Deviance has drastic consequences: an attacker trains a backdoor into a model that triggers on certain days to invoke tools, like compromising a user via code execution. Since we have a pretty centralized ecosystem, where attacks often are transferable, and natural language is universally understood by LLMs, this can have consequences across many systems and vendors.\n\nSuch a drift does not happen through a single reckless decision. It happens through a series of ‚Äútemporary‚Äù shortcuts that quietly become the new baseline. Because systems continue to work, teams stop questioning the shortcuts, and the deviation becomes invisible and the new norm.\n\nEspecially under competitive pressure for automation, cost savings, a drive to be first, and the overall hype, this dangerous drift is evident. The incentives for speed and winning outweigh the incentives for foundational security. Over time, organizations forget why the guardrails existed in the first place.\n\nLet me share some examples of how this is reflected in real-world agentic AI systems.\n\nWe are all aware that chatbots have those ‚ÄúAI can make mistakes‚Äù, ‚ÄúDouble check responses‚Äù and so forth disclaimers, and we can observe the drift of normalization occurring in real-time.\n\nThree years after ChatGPT shipped, vendors push agentic AI to users, but at the same time vendors are highlighting that your system might get compromised by that same AI - that drift, that normalization, is what I call ‚ÄúThe Normalization of Deviance in AI‚Äù.\n\nThis continuous drift is a long-term danger:\n\nWhile some vendors acknowledge the risks, others appear to overlook or downplay them, potentially due to competitive pressure and focus on product and customer acquisition.\n\nIn many cases, we probably collectively hope that ‚Äúsomeone‚Äù will solve these security and safety challenges.\n\nCompanies like Google, OpenAI, Anthropic, Microsoft, and other institutions and organizations perform extensive research in this area, including publishing evals and mitigation ideas. However, the rush to be the first is evident from a product perspective.\n\nNevertheless, before we drift off into a utopian future with agentic AI, I believe the best and safest outcome is to stay realistic around capabilities and control mechanisms, and for AI to remain human-led, particularly in high-stake contexts, to ensure the best outcome overall.\n\nNo, of course not. There is a lot of potential and many low stakes workflows can be implemented already today. Even high-risk workflows can be done with proper threat modeling, mitigations and oversight.\n\nHowever, it requires investment and resources to design and set up systems accordingly and apply security controls (sandbox, hermetic environments, least privilege, temporary credentials, etc.).\n\nMany are hoping the ‚Äúmodel will just do the right thing‚Äù, but Assume Breach teaches us, that at one point, it will certainly not do that.",
    "readingTime": 5,
    "keywords": [
      "space shuttle",
      "shuttle challenger",
      "challenger disaster",
      "llm output",
      "competitive pressure",
      "indirect prompt",
      "prompt injection",
      "security controls",
      "normalization of deviance",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/",
    "thumbnail_url": "https://embracethered.com/blog/images/2025/normalization-of-deviance-in-ai.png",
    "created_at": "2025-12-11T03:50:15.597Z",
    "topic": "tech"
  },
  {
    "slug": "actress-natasha-lyonne-dropped-out-of-nyu-and-watched-movies-instead-now-shes-helping-to-shape-the-future-of-ai",
    "title": "Actress Natasha Lyonne dropped out of NYU and watched movies instead. Now, she‚Äôs helping to shape the future of AI",
    "description": "‚ÄúWe are the ones who are deciding what this use is going to be and how we choose to use it,‚Äù Lyonne told the Fortune Brainstorm AI audience in San Francisco.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/natasha-lyonne-ai-animal-pictures-asteria-film-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54972842873_c57138e2e2_o-e1765256586861.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:15.065Z",
    "topic": "entertainment"
  },
  {
    "slug": "top-economist-diane-swonk-jerome-powell-risks-losing-the-feds-credibility-on-a-gamble-over-ai-and-immigration",
    "title": "Top economist Diane Swonk: Jerome Powell risks losing the Fed‚Äôs credibility on a gamble over AI and immigration",
    "description": "It all comes down to the reason behind the weakness in unemployment and Powell‚Äôs diagnosis of the ‚Äúlow-hire, low-fire‚Äù economy of 2025.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/jerome-powell-risks-credibility-ai-immigration-diane-swonk/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2250475944-e1765402773522.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.954Z",
    "topic": "business"
  },
  {
    "slug": "instacarts-aienabled-pricing-may-bump-up-your-grocery-costs-by-as-much-as-23",
    "title": "Instacart's AI-enabled pricing may bump up your grocery costs by as much as 23%",
    "description": "Shoppers may be unaware they're paying as much as 23% more than others for the same grocery items on Instacart, a new analysis says.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cbsnews.com/news/instacart-price-discrepancies-investigation/",
    "thumbnail_url": "https://assets2.cbsnewsstatic.com/hub/i/r/2025/12/09/4a650015-732a-4746-bcdb-f72145f0c302/thumbnail/1200x630/e684ba8cc56e043f29542fb6f8589678/gettyimages-1395364375.jpg",
    "created_at": "2025-12-11T03:50:14.929Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-already-taking-over-managers-busyworkand-its-forcing-companies-to-reset-expectations",
    "title": "AI is already taking over managers‚Äô busywork‚Äîand it‚Äôs forcing companies to reset expectations",
    "description": "As AI agents automate administrative tasks, industry leaders say the role of human managers needs to shift toward coaching and strategy‚Äîbut most organizations aren‚Äôt moving fast enough.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/ai-managers-automate-busy-work-org-chart-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974007976_8abae70b9a_o.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.746Z",
    "topic": "business"
  },
  {
    "slug": "google-deepmind-agrees-to-sweeping-partnership-with-uk-government-focused-on-science-and-clean-energy",
    "title": "Google DeepMind agrees to sweeping partnership with U.K. government focused on science and clean energy",
    "description": "The collaboration will see the AI company collaborating with the British government on a robotic lab for new materials, fusion energy, and new research into AI safety and the societal impacts of AI",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/google-deepmind-uk-government-partnership-science-clean-energy/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2217672931-e1765404847213.jpg?resize=1200,600",
    "created_at": "2025-12-11T03:50:14.668Z",
    "topic": "politic"
  },
  {
    "slug": "braininspired-llm-alignment",
    "title": "Brain-Inspired LLM Alignment",
    "description": "Thank you for considering applying for an ACX grant. Please use the form below.",
    "fullText": "This 2024 form is no longer accepting responses. You're probably looking for the 2025 form at https://forms.gle/dBAcmR7XMfgnxxwn8 .",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://docs.google.com/forms/d/e/1FAIpQLSc6vmem8-XfhVkMde3PCyysAS_bwBImk3H9iJo0S1OsqfUHWg/closedform",
    "thumbnail_url": "https://lh3.googleusercontent.com/RtXozrlYzCtSFZONcq-j4gNzMeo52ITKZL9qZ3gIVhC1fXlg_eQk4MJftciaiFRYU0eJlqMgHhMCwFE=w1200-h630-p",
    "created_at": "2025-12-11T03:50:14.270Z",
    "topic": "tech"
  },
  {
    "slug": "the-navy-says-ai-cut-a-160hour-submarineplanning-job-down-to-just-10-minutes-now-its-investing-448-million-to-go-bigger",
    "title": "The Navy says AI cut a 160-hour submarine-planning job down to just 10 minutes ‚Äî now it's investing $448 million to go bigger",
    "description": "The Navy is investing almost half a billion dollars in Palantir artificial intelligence software that promises to speed up shipbuilding processes.",
    "fullText": "The Navy is pouring hundreds of millions of dollars into an artificial intelligence system that it says has sped up key shipbuilding processes.\n\nIn one case, the AI cut painstaking processes of submarine schedule planning ‚Äî mapping out how the many pieces of construction fit together and making sure people, parts, and yard space are available at the right time ‚Äî from many hours to only minutes.\n\nThe Navy is launching the new Shipbuilding Operating System, or Ship OS, as it tries to break out of decades-old shipbuilding problems rooted in outdated technologies and work practices. The service announced a $448 million investment Thursday, saying it will accelerate the adoption of AI and autonomy across the industrial base.\n\nThe Ship OS technology is powered by Palantir's Foundry and Artificial Intelligence Platform and began in pilot programs at submarine shipyards.\n\nAt General Dynamics Electric Boat, a long-time submarine yard located in Connecticut, submarine schedule planning saw a dramatic reduction from 160 manual hours down to under 10 minutes. And at Portsmouth Naval Shipyard in Maine, material review times for submarines went from taking weeks to under an hour.\n\nThe $448 million investment will go toward the submarine industrial base and then expand. It'll be deployed across two major shipbuilders, three public yards, and 100 suppliers, Palantir said in a press release.\n\n\"This investment provides the resources our shipbuilders, shipyards, and suppliers need to modernize their operations and succeed in meeting our nation's defense requirements,\" said Navy Secretary John Phelan in a statement.\n\n\"By enabling industry to adopt AI and autonomy tools at scale, we're helping the shipbuilding industry improve schedules, increase capacity, and reduce costs,\" he added, explaining \"this is about doing business smarter and building the industrial capability our Navy and nation require.\"\n\nMaritime Industrial Base Program, a Navy initiative to revitalize US shipbuilding and repair capabilities, and Naval Sea Systems Command are overseeing the implementation of Ship OS. Both are gathering data from multiple sources to identify where the hiccups are in submarine shipbuilding, how the processes, including engineering, can be sped up, and what specific risks can be mitigated through technology.\n\nProblems in the Navy‚Äôs submarine industrial base ‚Äî from shipbuilders to the repair yards ‚Äî have been building for decades. Submarines are central to any Pacific fight and a top Pentagon priority, yet major programs like the upgraded Virginia-class submarines and new Columbia-class ballistic missile subs have repeatedly run into delays and cost overruns.\n\nThe Government Accountability Office, a government watchdog agency, has documented long-standing problems in the Navy's plans for purchasing and constructing submarines, as well as shipyard deficiencies such as worker inexperience, aging facilities and equipment, and inadequate construction space.\n\nThe introduction of the new Ship OS capability aims to address some of these problems facing US submarine shipbuilding. And once the technology has been used for the submarine programs, the Navy said, it'll apply lessons and adapt them to surface ship programs.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "schedule planning",
      "industrial base",
      "submarine schedule",
      "submarine shipbuilding",
      "the navy",
      "ship os",
      "programs",
      "submarines",
      "processes"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/navy-ai-cut-hourslong-submarine-planning-job-to-minutes-2025-12",
    "thumbnail_url": "https://i.insider.com/6939afa67ecd1d1da6634afc?width=1200&format=jpeg",
    "created_at": "2025-12-11T03:50:13.974Z",
    "topic": "finance"
  },
  {
    "slug": "instagram-is-adding-aigenerated-headlines-to-some-posts",
    "title": "Instagram Is Adding AI-Generated Headlines to Some Posts",
    "description": "No one asked for this.",
    "fullText": "Few of us are under the illusion that we own the content that we post on Instagram, but we do get a say in how that content is presented‚Äîwe can choose which photos and videos we share, what captions appear (or don't appear) on each post, as well as whether or not we include where the image was taken or shared from. We might not control the platform, but we can control the content of our posts‚Äîunless those posts are found on search engines like Google.\n\nAs reported by 404 Media, Instagram is now experimenting with AI-generated SEO titles for users' posts‚Äîwithout those users' input or permission. Take this post for example: Author Jeff VanderMeer uploaded a short video of rabbits eating a banana to his Instagram. The video was posted as-is: There was no caption, location tag, or any other public-facing information. It's just a couple of rabbits having a bite.\n\nA post shared by Jeff VanderMeer (@jeff_vandermeer123)\n\nInstagram, however, took it upon itself to add a headline to the post‚Äîat least when you stumble upon it on via Google. Rather than display a link featuring Jeff's Instagram handle and some metadata about the video, the Google entry comes back with the following headline: \"Meet the Bunny Who Loves Eating Bananas, A Nutritious Snack for...\" (the rest of the headline cuts off here).\n\nVanderMeer was less than pleased with the discovery. He posted a screenshot of the headline to Bluesky, writing, \"now [Instagram] appears to generate titles [and] headlines via AI for stuff I post...to create [clickbait] for [Google] wtf do not like.\"\n\nThis was not the only AI-generated headline VanderMeer was roped into. This post from the Groton Public Library in Massachusetts, which advertises VanderMeer's novel Annihilation as the library's December book group pick, was also given the clickbait treatment on Google. Just as with VanderMeer's post, the Groton Public Library didn't include any text in its Instagram post‚Äîjust an image showing off the book. But if you see the post within a Google search, you'll see the following partial headline: \"Join Jeff VanderMeer on a Thrilling Beachside Adventure...\"\n\n404 Media's Emanuel Maiberg says that they've confirmed that Instagram is also generating headlines for other users on the platform, all without permission or knowledge. Google told Maiberg the headlines are not coming from its AI generators‚Äîthough it has been using deceptive AI-generated headlines of its own on Google Discover. In fact, the company says its search engine is simply pulling the text from Instagram itself. Maiberg found that these headlines do appear under title tags for Instagram posts when using Google's Rich Result Test tool. When digging through the code, Maiberg also discovered AI-generated descriptions for each post, which could be what Instagram is ultimately using to generate the headlines.\n\nI reached out to Meta for comment, and this story originally published before they responded. However, a Meta spokesperson has since confirmed to me that Instagram has recently started generating these titles using AI. The goal, according to the spokesperson, is to make it easier to know what a post is about before you click the link. They also noted that these headlines might not be totally correct, as with all AI products. In addition, the spokesperson explained that search engine optimization indexing is not necessarily new. The company has been doing this for years in the U.S. to increase visibility for posts from professional accounts.\n\nThat last point is all fine and good, of course. No one is surprised that Instagram is indexing posts for search engines: Most social media platforms do that. Otherwise, you'd never find any of their posts on platforms like Google. The issue is generating fake headlines with AI without letting anyone know about it. Just because Meta AI is capable of generating headlines doesn't mean it is good at it, or even that it should‚Äîespecially when users never consented to this practice in the first place. It'd be one thing if Instagram had an option before you post‚Äîsomething like \"Generate a headline for me using Meta AI that will appear in search engines for my post.\" Most of us would opt out of that, but it'd at least be a choice. However, it appears that Instagram decided that users like VanderMeer weren't capable of writing a headline as clever as \"Meet the Bunny Who Loves Eating Bananas.\"\n\nThe worst part is, the AI doesn't even accurately describe the posts, a risk the Meta spokesperson readily admits to. That Groton Public Library post was only about a book club meeting featuring VanderMeer's novel, but the headline says \"Join Jeff VanderMeer,\" as if he'd be making an appearance. Not only did Instagram add a headline without VanderMeer's consent, it spread misinformation about his whereabouts. And for what? Some extra engagement on Google?\n\nIf Instagram wants its posts to appear as headlines on search engines, it should include the actual posters in the conversation. As VanderMeer told 404 Media: \"If I post content, I want to be the one contextualizing it, not some third party.\"\n\nWhile Meta has yet to add a dedicated on/off switch for these headlines, one thing you can do to ensure your posts don't get an AI clickbait makeover is to opt out of indexing as a whole. If you run an account that relies on discoverability, this might not be worth it, since you'll be impacting how users find your posts outside of Instagram. However, if you don't care about that, or you don't need the SEO at all, you can stop Instagram from making your posts available on search engines‚Äîand putting an end to the AI-generated headlines, at that.\n\nThere are three ways to accomplish this, according to Instagram:\n\nMake your account private: Head to Instagram's in-app settings, then choose Account privacy. Here, tap the Private account toggle.\n\nSwitch your account from professional to private: Open Instagram's in-app settings, scroll down and tap Account type and tools. Here, choose \"Switch to personal account.\"\n\nManually opt out of indexing: Head to Instagram's in-app settings, then choose Account privacy. You should see an option to stop your public photos and videos from appearing in search engines.",
    "readingTime": 6,
    "keywords": [
      "loves eating",
      "eating bananas",
      "instagram's in-app",
      "vandermeer's novel",
      "join jeff",
      "in-app settings",
      "ai-generated headlines",
      "account privacy",
      "search engines",
      "search engine"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/instagram-adding-ai-headlines-posts?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC2DE7N6Z5BP8WS17SW0SCVW/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-11T03:50:11.984Z",
    "topic": "tech"
  },
  {
    "slug": "cursor-introduces-debug-mode",
    "title": "Cursor Introduces Debug Mode",
    "description": "Built to make you extraordinarily productive, Cursor is the best way to code with AI.",
    "fullText": "Coding agents are great at lots of things, but some bugs consistently stump them. That's why we're introducing Debug Mode, an entirely new agent loop built around runtime information and human verification.\n\nTo build it, we examined the practices of the best debuggers on our team. We rolled their workflows into an agent mode, equipping it with tools to instrument code with runtime logs, prompts that generate multiple hypotheses about what's going wrong, and the ability to call back to you to reproduce the issue and verify fixes.\n\nThe result is an interactive process that reliably fixes bugs that were previously beyond the reach of even the smartest models working alone, or could take significant developer time to address.\n\nTo get started, select Debug Mode from the dropdown menu and describe the bug in as much detail as you can.\n\nInstead of immediately trying to generate a fix, the agent reads through your codebase and generates multiple hypotheses about what could be wrong. Some will be ideas you would have thought of on your own, but others will likely be approaches you wouldn't have considered.\n\nThe agent then instruments your code with logging statements designed to test these hypotheses. This prepares the agent to receive concrete data about what's actually happening when the bug occurs.\n\nNext, go to your application and reproduce the bug while the agent collects the runtime logs.\n\nThe agent can see exactly what's happening in your code when the bug occurs: variable states, execution paths, timing information. With this data, it can pinpoint the root cause and generate a targeted fix. Often that's a precise two or three line modification instead of the hundreds of lines of speculative code you'd have received with a standard agent interaction.\n\nAt this point, Debug Mode asks you to reproduce the bug one more time with the proposed fix in place. If the bug is gone, you mark it as fixed and the agent removes all the instrumentation, leaving you with a clean, minimal change you can ship.\n\nThis human-in-the-loop verification is critical. Sometimes bugs are obvious, but other times they fall into a gray area where the fix might work technically but not feel right. The agent can't make that call on its own. If you don't think the bug is fixed, the agent adds more logging, you reproduce again, and it refines its approach until the problem is actually solved.\n\nThis kind of tight back-and-forth is one way we think AI coding works best. The agent handles the tedious work while you make the quick decisions that need human judgment. The result with Debug Mode is that tricky bugs that used to be out of reach are now reliably fixed.\n\nRead the Debug Mode docs. Learn about all the new features in Cursor 2.2.",
    "readingTime": 3,
    "keywords": [
      "runtime logs",
      "bug occurs",
      "debug mode",
      "agent",
      "bugs",
      "code",
      "reproduce",
      "generate",
      "hypotheses",
      "what's"
    ],
    "qualityScore": 1,
    "link": "https://cursor.com/blog/debug-mode",
    "thumbnail_url": "https://ptht05hbb1ssoooe.public.blob.vercel-storage.com/assets/changelog/changelog-2-2-debug.png",
    "created_at": "2025-12-10T18:55:48.559Z",
    "topic": "tech"
  },
  {
    "slug": "instacart-may-be-jacking-up-your-grocery-prices-using-ai-study-showsa-practice-called-smart-rounding",
    "title": "Instacart may be jacking up your grocery prices using AI, study shows‚Äîa practice called ‚Äòsmart rounding‚Äô",
    "description": "Consumer Reports and the progressive think tank Groundwork Collaborative used ~200 volunteers to check prices on 20 items in four cities.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/instacart-may-be-jacking-up-your-grocery-prices-using-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2216221632-e1765386311727.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.794Z",
    "topic": "business"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are ‚Äògrowing up fluent in AI‚Äô and that‚Äôs helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-new-tools-that-can-improve-workforce-training",
    "title": "The New Tools That Can Improve Workforce Training",
    "description": "Companies are pouring money into AI but failing to translate that investment into workforce capability, largely because traditional training methods don‚Äôt help employees retain or apply complex skills. Extended reality‚Äîvirtual reality, augmented reality, and mixed reality‚Äîbridges this gap by letting people learn through immersive, emotionally engaging, hands-on experiences that the brain encodes like real events. Organizations from Bank of America to Boeing to Walmart are already seeing faster learning, higher confidence, reduced errors, and lower costs by using XR to train employees in everything from customer-service scenarios to technical assembly. The technology works because it aligns with how people actually learn, benefits from major improvements in affordability and accessibility, and meets the expectations of a workforce already accustomed to immersive digital environments. The companies that start with focused pilot projects, match the right XR tool to the right skill gaps, and scale deliberately will build training systems that actually change behavior and materially improve performance.",
    "fullText": "The New Tools That Can Improve Workforce Training by Paola Cecchi-DimeglioDecember 10, 2025PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintThis year companies plan to invest $1.5 trillion in AI initiatives, with forecasts showing that investments will rise to $2 trillion by 2026. Gartner research predicts that most of this spending will not meet expected returns. The issue isn‚Äôt the technology; it‚Äôs our failure to help people utilize it.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://hbr.org/2025/12/the-new-tools-that-can-improve-workforce-training",
    "thumbnail_url": "/resources/images/article_assets/2025/11/Dec25_01_200202284-009.jpg",
    "created_at": "2025-12-10T18:55:43.958Z",
    "topic": "business"
  },
  {
    "slug": "the-5-ai-tensions-leaders-need-to-navigate",
    "title": "The 5 AI Tensions Leaders Need to Navigate",
    "description": "The introduction of AI into the workplace inherently creates tension. The same tools that relieve drudgery and make work easier, for example, can also remove the challenging friction that gives work its meaning, builds crucial skills, and increases satisfaction. Which tensions are most common in workplaces‚Äîand how are they actually playing out? Insights collected from over 100 leaders show that they‚Äôre wrestling with several competing forces: experts vs. novices, centralization vs.",
    "fullText": "The 5 AI Tensions Leaders Need to NavigateBased on insights from more than 100 builders, executives, investors, advisors, and researchers from across the globe. by Rebecca Hinds and Robert I. SuttonDecember 10, 2025Summary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintdetect cancer, their accuracy improved. But their performance on non-AI procedures got worse. When students used AI to draft SAT-style essays, their creativity initially spiked. Yet those who started with AI-generated ideas showed reduced alpha-wave activity (a marker of creative flow), ‚Äútended to converge on common words and ideas,‚Äù and their ‚Äúoutput was very, very similar‚Äù to one another‚Äôs. And in a 2025 study spanning 20 European countries, workers in highly automated jobs reported less purpose, less control, and more stress, even when their work became technically easier.",
    "readingTime": 1,
    "keywords": [
      "ideas",
      "less"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/the-5-ai-tensions-leaders-need-to-navigate",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_10_ChenWu.jpg",
    "created_at": "2025-12-10T18:55:43.948Z",
    "topic": "business"
  },
  {
    "slug": "as-ai-floods-our-culture-heres-why-we-must-protect-human-storytelling-in-games",
    "title": "As AI floods our culture, here‚Äôs why we must protect human storytelling in games",
    "description": "Buying the Zombies, Run! studio wasn‚Äôt part of ‚Äãmy plan, but a post-apocalypse ‚Äãgame with stories that make people feel seen pulled me in\n‚Ä¢ Don‚Äôt get Pushing Buttons delivered to your inbox? Sign up here\nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?",
    "fullText": "Buying the Zombies, Run! studio wasn‚Äôt part of ‚Äãmy plan, but a post-apocalypse ‚Äãgame with stories that make people feel seen pulled me in\n\nDon‚Äôt get Pushing Buttons delivered to your inbox? \nA few days ago, I clicked a button on my phone to send funds to a company in Singapore and so took ownership of the video game I co-created and am lead writer for: Zombies, Run! I am a novelist, I wrote the bestselling, award-winning The Power, which was turned into an Amazon Prime TV series starring Toni Collette. What on earth am I doing buying a games company?\n\nWell. First of all. Zombies, Run! is special. It‚Äôs special to me ‚Äì the game started as a Kickstarter and the community that grew up around it has always been incredibly supportive of what we‚Äôre doing. And it‚Äôs special in what it does. It‚Äôs a game to exercise with. You play it on your smartphone ‚Äì iPhone or Android ‚Äì and we tell stories from the zombie apocalypse in your headphones to encourage you to go further, faster, or just make exercise less boring. Games are so often portrayed as the bad entertainment form, but I made a game that fundamentally helps people to be healthier.\n\nThe experience of playing Zombies, Run! is also completely focused on storytelling. My co-creator Adrian Hon and I were talking about doing a project together. He said: ‚ÄúLet‚Äôs do something to make running more fun.‚Äù I said: ‚ÄúHow about if we do a story where you‚Äôre being chased by zombies?‚Äù And here we are.\n\nWhen you play the game, you‚Äôre immersed in a world where every run makes you a hero ‚Äì you‚Äôre collecting supplies, saving a child from no man‚Äôs land, investigating the mystery of how the apocalypse started. I‚Äôve always focused on the storytelling being good. And it works. Players of the game become so attached to the characters that many of them report laughing out loud or even ‚Äúcrying while running‚Äù.\n\nOne of my jokes about storytelling in video games is that the way we tend to talk about it ‚Äì in the games industry, in games journalism, even in marketing copy ‚Äì is very much ‚Äúnever mind the quality, feel the width‚Äù. We say things like ‚Äúthis game has 100-plus hours of story‚Äù or ‚Äúthis game contains more than a million words‚Äù. Imagine marketing a movie saying that the script contains 29,000 words. Or selling a novel on the basis that it‚Äôll take a long time to read.\n\nThat‚Äôs not how you do it. You tell the story. You give a hook. You say: ‚ÄúA single woman comes home one evening to find a man claiming to be her husband living in her house. And when he goes up to the attic, a different husband comes down in his place.‚Äù Now you can‚Äôt wait to find out what happens next. (That, incidentally, is the brilliant comic novel The Husbands by Holly Gramazio ‚Äì who I think is the only other bestselling novelist to be also making her own video games.)\n\nSo, now I own a games company, what am I going to do? My feeling is that I must focus on the fundamentals. There‚Äôs a world of games out there that thinks it can replace writers with AI large language models. I think that‚Äôs going to make writing worse and worse. AI writing is fine for boilerplate text that is always roughly the same. It‚Äôs fine for non-writers to get their expertise into the world. But storytelling is different. It is human minds finding companionship with other human minds ‚Äì we need stories, fundamentally, to feel less alone. To know that other people have been through things a bit like what we have. Things that make us laugh, and cry, even while running. You get that from work that is not the same as everything else, you get it from the unique work of other individual human minds.\n\nAnd actually, Zombies, Run! has always been a universe with strong values. We‚Äôre not a rightwing, rugged-individualism apocalypse, where one lone person can get through with just their guns. In our world ‚Äì as in the real world ‚Äì humans survive by working together.\n\nWhile we‚Äôre still going to have many exciting fleeing zombies, battling-the-undead storytelling, I think there‚Äôs probably also room in the ZR! universe for a 10-mission arc where you have to find all the figurines and paints you need to complete an expansion set in ‚ÄúDemons and Darkness‚Äù; or one where you‚Äôre working on bringing an overgrown garden back to blooming, beautiful life; or setting up and running the first post-apocalyptic travelling library while also trying to work out what happened to the first librarian who‚Äôs mysteriously disappeared, leaving only a series of cryptic notes in an old manuscript.\n\nAfter all, I do think this is quite a good time in the world to be thinking about how to rebuild after a series of catastrophic events.\n\nSelling story by the yard and not by a story hook is a marker, I think, of a lack of confidence in the form. We don‚Äôt need to lack confidence. Games are the biggest entertainment industry in the world. If we want to be taken seriously, we need to take ourselves seriously. Stop talking about the width, start talking about the quality.\n\nIt was the 20th anniversary of Xbox 360 recently, and one name that‚Äôs cropped up in every list of the console‚Äôs best games is the compulsive retro twin-stick shooter Geometry Wars. If you‚Äôre yearning for something similar, you must immediately download Evil Egg, a frenzied twin-stick blaster with gorgeous Commodore 64-style visuals and sound effects. Shoot everything that moves, hit the left trigger to boost and collect hearts to stay alive.\n\nAt first it‚Äôs a bewildering mass of rainbow pixels but as you detonate wave after wave of glitchy space pests, you begin to understand the patterns of different enemies and earn upgrades such as the executioner‚Äôs sword, which takes out foes in an orbital slash of laser particles. Evil Egg is polished, exciting, wild to look at, and has such a brilliant understanding of the genre and its unique dynamics. It‚Äôs free on Steam but I implore you to download it on Itch.io and name your own price. Keith Stuart\n\nAvailable on: PC\n\n Estimated playtime: 10-plus hours\n\nThere has been a lot of writing about Horses, the art game recently banned by digital platforms Steam and Epic Games Store. I particularly enjoyed this post by writer Harper Jay MacIntyre, which considers Horses, formalism and the trans experience. The article manages to bring in so many elements of modern games criticism and academia while providing a highly personal response to the game.\n\nThe most interesting retro game articles are the ones that reassess lost or derided titles rather than merely celebrate the classics. Was the Atari 2600 version of Pac-Man the worst game ever? Not according to this compelling analysis from Garrett Martin at AV Club who sees it as a misunderstood brutalist gem. I find myself in agreement.\n\nIt is also nice to see a legendary game justly praised in an interesting way. The BFI‚Äôs look at the legacy of Time Crisis considers the gun game in relation to cinema, referencing Beverly Hills Cop and Run Lola Run rather than just comparing it to Sega‚Äôs similar Virtua Cop.\n\nSkate Story ‚Äì hellish premise aside, this is skateboarding paradise | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ\n\nHorror game Horses has been banned from sale ‚Äì but is it as controversial as you‚Äôd think?\n\nFive Nights at Freddy‚Äôs 2 ‚Äì inept game-based horror is one of the year‚Äôs worst | ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ\n\nThis one comes from reader, Rebecca:\n\n‚ÄúMy elderly grandad is coming to stay with us for Christmas and wants to see what‚Äôs happening with video game graphics these days. Are there any titles you recommend that will let him explore beautiful locations without getting shot at?! We have a PlayStation 5 and a slightly out-of-date PC.‚Äù\n\nYour best option here is to go with one of the big open-world adventures and just find an area with no enemies around. If you You could bypass the threat of imminent violence completely by going for a driving game, such as Forza Horizon 4 on PC (which is set in Britain so he may even spot some familiar scenery). Alternatively, if visual realism isn‚Äôt as important as beauty, a cosier indie title such as Tchia, Journey or Firewatch may fit the bill. Really hope he enjoys them!\n\nWe‚Äôre still looking for your game of the year nominations for an end of year special ‚Äì let us know yours by hitting reply or emailing us on pushingbuttons@theguardian.com.",
    "readingTime": 8,
    "keywords": [
      "plus hours",
      "human minds",
      "zombies run",
      "evil egg",
      "game",
      "games",
      "storytelling",
      "you‚Äôre",
      "we‚Äôre",
      "stories"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/10/i-bought-the-games-studio-behind-zombies-run-because-humanity-is-essential-to-storytelling",
    "thumbnail_url": "https://i.guim.co.uk/img/media/1817abf90f05afe67e594b055c45343b486ae1e6/102_0_925_740/master/925.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8991d15d4205b4197c1289fdd0cfb154",
    "created_at": "2025-12-10T18:55:43.393Z",
    "topic": "gaming"
  },
  {
    "slug": "china-to-limit-access-to-nvidias-h200-chips-despite-trump-export-approval-ft-reports",
    "title": "China to limit access to Nvidia's H200 chips despite Trump export approval, FT reports",
    "description": "Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ‚Äãexport of the technology to China, the Financial Times reported on ‚ÄåTuesday, citing two people with knowledge of the matter.  Regulators in Beijing have been discussing ways to ‚Äåpermit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.",
    "fullText": "Dec 9 (Reuters) - Beijing is set to limit access to Nvidia's advanced H200 chips despite U.S. President Donald Trump's decision to allow the ‚Äãexport of the technology to China, the Financial Times reported on ‚ÄåTuesday, citing two people with knowledge of the matter.\n\nRegulators in Beijing have been discussing ways to ‚Äåpermit limited access to the H200, Nvidia's second-best generation of artificial intelligence chips, according to the report.\n\nSuch a move would add a hurdle to Nvidia and other top U.S. chipmakers' ability to address the China market, after Trump's Monday announcement appeared ‚Å†to settle a debate over ‚Äåwhether these companies should keep their global lead by selling AI chips to China or withhold shipments.\n\nNvidia shares, which had risen ‚Äças much as 2% in premarket trading, pared gains after the report and were last up about 0.6%. The company did not immediately respond to a Reuters request for ‚Äãcomment on the report.\n\nBeijing has been pushing back against domestic firms' use of ‚ÄåU.S. technology, especially Nvidia chips, as it retaliates against American restrictions.\n\nEarlier U.S. restrictions banned the sale of advanced AI processors to China, weighing on Nvidia's ability to grow in one of the world's largest markets for AI chips and development.\n\nThe export of the H200 chips will be permitted with a 25% fee levied ‚Å†on such sales, Trump said in a ‚Äãpost on Truth Social on Monday.\n\nIpek Ozkardeskaya, senior ‚Äãanalyst at Swissquote Bank, said the approval alone may have limited impact on Nvidia's business in China unless it is allowed to ‚Äçexport other chip ‚Å†lines such as Blackwell or Rubin.\n\nShares of AMD and Intel also pared gains and were last up about 0.3% in premarket trading. So far ‚Å†this year, Nvidia has gained nearly 40% compared with the S&P 500 benchmark index's 16.4% rise ‚Äåin the same period.",
    "readingTime": 2,
    "keywords": [
      "premarket trading",
      "pared gains",
      "chips",
      "nvidia's",
      "nvidia",
      "export",
      "access",
      "advanced",
      "technology",
      "limited"
    ],
    "qualityScore": 0.95,
    "link": "https://finance.yahoo.com/news/nvidia-shares-gain-trump-allows-102400561.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/a48a9375c07cbe587069f836d911e1ae",
    "created_at": "2025-12-10T18:55:43.203Z",
    "topic": "finance"
  },
  {
    "slug": "5-vcs-sounds-off-on-the-ai-question-du-jour",
    "title": "5 VCs sounds off on the AI question du jour",
    "description": "Who better to ask about a bubble than a group who will collectively deploy anywhere from tens to hundreds of millions of dollars over the next decade into AI companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/5-vcs-sounds-off-on-the-ai-question-du-jour/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974207764_b60ab330f2_o-e1765327176512.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.273Z",
    "topic": "business"
  },
  {
    "slug": "inside-tractor-maker-cnhs-push-to-bring-more-artificial-inte",
    "title": "Inside tractor maker CNH‚Äôs push to bring more artificial intelligence to the farm",
    "description": "CNH CTO Jay Schroeder says using AI to improve farming is a decades-long passion. \"I grew up on a family farm‚Ä¶so for me, it‚Äôs personal.‚Äù",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/artificial-intelligence-cnh-ai-tractors-farm-equipment/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Jay-Schroeder_CNH_web-HighRes.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:17.128Z",
    "topic": "tech"
  },
  {
    "slug": "goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growt",
    "title": "Goldman Sachs CFO on the company‚Äôs AI reboot, talent, and growth",
    "description": "Goldman‚Äôs OneGS 3.0 revamp is underway.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/goldman-sachs-cfo-on-the-companys-ai-reboot-talent-and-growth/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1770870970-1-e1765368302818.jpg?resize=1200,600",
    "created_at": "2025-12-10T13:50:16.162Z",
    "topic": "business"
  },
  {
    "slug": "pay-cuts-poaching-and-pivoting-inside-scale-ai-after-meta",
    "title": "Pay cuts, poaching, and pivoting: Inside Scale AI after Meta",
    "description": "Five months after Meta's $14 billion deal, Scale AI has lost some of its gleam, with workers sniping about pay, and rivals coming for its clientele.",
    "fullText": "This summer, after Meta made a $14 billion investment in Scale AI and poached its 28-year-old founder, Alexandr Wang, and after A-list clients like OpenAI and Google halted work with the startup, a worker for Scale AI anxiously asked ChatGPT what it thought of his company's fate. He knew the chatbot well, having tested it for vulnerabilities. Its prognosis was grim.\n\n\"Scale AI will no longer exist as a credible independent entity within 24 months,\" ChatGPT, which isn't any kind of official authority, wrote. \"Its infrastructure will be repurposed for Meta's internal needs. Its client base will evaporate. Its role as a neutral red teamer or external evaluator is effectively over.\"\n\nThe contractor shared the chat logs with fellow workers at Scale AI. In one reply reviewed by Business Insider, one worker said that they were already on their way out, describing the startup as a ticking time bomb.\n\nThe chatbot was drawing from a storm of headlines about Scale AI, which until this summer had been touted as one of the most ascendant startups in tech ‚Äî the place Big Tech companies vying for AI supremacy went to when they wanted their chatbots stress-tested and perfected. Lately, it's lost some of its gleam, with investors significantly lowering valuations, workers sniping about pay, and rivals coming for its clientele.\n\nThe vast army of human data labelers that made Scale AI a juggernaut are chafing at what they say are pay cuts, lengthy unpaid onboarding sessions to join new AI projects, and thinning workloads ‚Äî and are increasingly leaving the platform altogether, according to interviews with five current and former contractors and internal correspondence obtained by Business Insider.\n\nActivity in the main internal chatroom for Outlier ‚Äî Scale AI's flagship gig work platform, which touts more than 100,000 taskers ‚Äî has plummeted since the Meta investment, with weekly discussion threads drawing dozens instead of the usual hundreds of replies, according to screenshots reviewed by Business Insider.\n\nOne tasker said that they'd spent close to 40 hours in a single month in unpaid onboarding sessions without landing any actual work, noting that other platforms like Scale AI's rival Mercor do pay for this kind of work. Elizabeth Boyd, another tasker, says she rarely does work for Outlier anymore after seeing effective pay rates for some projects slashed to around $20 an hour ‚Äî down from the $50 she used to make. One gig that advertised $20 an hour only allowed three minutes of working time every two days, or a 99-cent payout, according to screenshots obtained by Business Insider.\n\nJoe Osborne, a Scale AI spokesperson, says the balance sheets show the company is on the right path. \"This quarter is on track to be our biggest of 2025, our data business is more profitable today than it was before the Meta deal, and our applications business, which includes work with Fortune 500 companies and governments, has doubled revenue\" in the second half of the year compared to the first, Osborne wrote in an email. He also noted there has been an increase in active users on Outlier since the Meta deal, and that pay rates are based on the skills for each project and contributors always see the rates upfront, and have the option of declining any gig.\n\nThe company is also looking to diversify. The startup has embraced fields like robotics, announcing a new lab to meet booming demand for robot training data this fall. It's doubling down on its US military and other government work, winning up to $199 million worth of defense contracts since the Meta deal.\n\nSome investors are bullish. In one current investor's view, Meta has mostly left Scale alone, letting it operate as an independent company. With around $1 billion on the balance sheet, the investor added, there are no plans to fundraise. And an IPO could still be on the table at some point.\n\nOther investors see Scale AI as more like a gutted fish. The Meta investment ‚Äî which valued Scale AI at $29 billion ‚Äî has dented Scale AI's valuation in private markets where people buy and sell equity from pre-IPO startups. Noel Moldvai, Augment's CEO, tells Business Insider his platform used to process millions of dollars' worth of transactions in Scale AI stock before the Meta deal, but that dried up as sellers waited to see if the startup rebounded. Activity is picking up again, he said, but at lower valuations of around $15 billion to $9 billion. The underlying message of Meta's semi-acquisition is clear to Moldvai. \"It seems like Meta was just after Alexandr Wang, and so this is probably the structure that let them get him,\" he says. He adds that Scale AI's valuation could still bounce back.\n\nOn another marketplace, Caplight, Scale's valuation has dropped to $7.3 billion. Osborne says that the valuation is not accurate because there have been no sales of stock at that price and multiples of comparable companies would yield a higher valuation.\n\nIf the company doesn't pull it off, it could become the latest example of a once-promising startup that morphed into a \"zombie\" after being invested in by a tech giant.\n\nThis summer, Scale AI painted a rosy picture of the Meta investment, describing it as a major cash infusion and source of future work in its official statement at the time of the deal. That messaging was also conveyed to the startup's corporate workforce, says another former member of Scale AI's red team, which tests chatbots for flaws and vulnerabilities. Just a few weeks after the investment, he was laid off as part of a major downsizing that saw 14% of Scale AI's full-time staff of 1,400 let go.\n\nOsborne said the layoffs were aimed at making the data division profitable, which it now is.\n\nThose weren't the only cuts. In September, Scale AI terminated 12 contractors on its red team, citing performance issues. Two ex-red teamers told Business Insider that the team's work had been drying up since the Meta deal, blaming thinning workloads for the cuts. Later that month, Scale AI shuttered a team in Dallas of contractors focused on generalist AI work as it moved towards more specialized fields.\n\nOsborne said the 12 contractors were part of Scale's temporary workforce and represented a small fraction of its overall red team, which the company is still committed to investing in. He said the Dallas cuts were part of an industry shift towards higher skilled work and represent a small fraction of its overall workforce.\n\nMeanwhile, a swarm of AI training startups has rushed in to poach Scale AI's workers and clients. Some are now raising capital at soaring valuations. Surge AI hit a valuation of $24 billion while Mercor, which is run by three 22-year-olds, announced in October it had raised $350 million at a $10 billion valuation.\n\nMercor has won at least one major AI training project from Meta, Scale AI's 49% shareholder. In September, Scale AI filed a lawsuit in California against Mercor alleging it hired one of its sales employees to poach its biggest customers, allegations Mercor denies.\n\nOne Scale AI investor said he'd been frustrated with Scale AI's leadership losing customers to Surge AI in particular, which reportedly brought in more revenue than Scale in 2024, despite never having raised outside funding. (Scale AI had raised more than $1.5 billion before the Meta deal.)\n\nBrendan Foody, Mercor's CEO, has publicly criticized Scale AI for what he claims are low pay rates and data quality issues. \"Scale lost the focus on product, on scaling quality,\" Foody said in a September podcast appearance. In response, a Scale AI spokesperson told Business Insider its quality metrics are at \"record highs.\"\n\nIt's not just rival CEOs making that point. Tammy Hartline, who managed projects for Scale AI as a consultant until the summer of 2025, said Scale grew so quickly that the work became more about needing bodies than skills. \"Spam and low quality data became accepted as a cost of doing business,\" she said. Hartline joined Mercor in September.\n\nScale AI has also been beset with security issues that predate Meta's investment. In June, Business Insider reported that Scale AI routinely used public Google Docs to track work for high-profile customers, including Google, Meta, and xAI. That practice left AI training documents labeled \"confidential\" accessible to anyone with the link and exposed reams of personal information, like private emails and pay details, about contractors. \"We take data security seriously,\" Osborne said. \"We conducted a thorough investigation and disabled any user's ability to publicly share documents from Scale managed systems.\"\n\nSloppy security isn't uncommon in the AI training space ‚Äî Surge AI similarly left open sensitive work for its client Anthropic. But the exposed documents seen by Business Insider show that for a project for Google, Scale AI faced security and quality issues throughout 2023 and 2024. Thousands of taskers were flagged for being \"suspected spammers,\" \"cheaters,\" with hundreds of workers listed in spreadsheets with titles like \"Good and Bad Folks\" and \"suspicious non-US taskers.\" Meta recently removed more than 40 groups buying and reselling AI training accounts, including from Scale AI, in response to a recent Business Insider investigation. Osborne said Scale's data quality metrics are the highest they've ever been.\n\nThe company has notched some recent wins. It once appeared bogged down by litigation, but recently agreed to settle multiple lawsuits filed by ex-workers in California who alleged they were underpaid and misclassified as contractors. (Scale no longer accepts gig workers from the state.) The big question remains whether Scale AI can thrive in the increasingly competitive AI training industry it helped give birth to. For many former workers, it'll be too late to find out.\n\nCharles Rollet is Business Insider's tech correspondent in San Francisco. Ben Bergman is a senior correspondent at Business Insider, where he investigates the tech industry with a focus on venture capital and startups.",
    "readingTime": 9,
    "keywords": [
      "scale ai",
      "business insider",
      "scale ai's",
      "meta deal",
      "unpaid onboarding",
      "onboarding sessions",
      "thinning workloads",
      "meta investment",
      "ai's valuation",
      "red team"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pay-cuts-poaching-pivoting-inside-scale-ai-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/68f7cabe1c1f80efbec5fc44?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.535Z",
    "topic": "finance"
  },
  {
    "slug": "why-the-music-industry-is-changing-its-tune-on-ai",
    "title": "Why the music industry is changing its tune on AI",
    "description": "Your 2026 Spotify wrapped may include a shocking amount of 'robot rock.'",
    "fullText": "Last month, \"Walk My Walk\" hit number one on Billboard's Country Digital Song Sales chart. The moody stomp-clap tune, with lyrics like \"Every scar's a story that I survived, I've been through hell, but I'm still alive,\" has been played more than 8 million times on Spotify. The song wasn't performed by a human artist ‚Äî Breaking Rust, despite having the face of a handsome, rugged man in a cowboy hat on its Spotify profile, is an AI project. But there is a real person claiming that Breaking Rust's work is a copycat: Blanco Brown, an artist who mixes country and rap together, who claims the song's creator used AI to emulate his style. The person behind Breaking Rust did not respond to a message I sent asking about the origin of the sound.\n\nIt's the latest example of ways that AI-generated music, with its opaque origins, can create confusion around who really made a song just as easily as it can create a hit. AI-generated music that sounds a lot like your faves but was made with a few prompts has been going viral, spreading far and wide and more quickly than music labels can always have it removed.\n\nWhen some of the first AI-generated tracks started racking up listens two years ago, music labels went to battle, threatening and filing legal action to stop AI generators from training on and using their artists' voices and music stylings. Universal Music Group (UMG) pushed to have a YouTube video where Eminem's voice rapped about cats taken down. Spotify removed AI slop songs that were listened to by bots to reap the streaming earning pool, and UMG also got streaming platforms to remove a viral \"Drake\" song that wasn't by Drake and The Weeknd at all, but a song written by Ghostwriter, an anonymous artist that uses AI to produce music and appears publicly only when cloaked in white and dark glasses.\n\nNow, the labels are starting to drop their fists and shake hands with AI music generators.\n\nWarner Music Group announced last month it had settled a lawsuit against AI music generator Suno (a test of the service by plaintiffs in the suit found that Suno would churn out works similar to ABBA and Chuck Berry when prompted in their style) and entered into a partnership with the company. Robert Kyncl, CEO of WMG, called it \"a victory for the creative community that benefits everyone.\" The announcement came just weeks after UMG, the world's largest record label, settled its copyright infringement lawsuit with AI music generator Udio, and said the two have partnered to create a new subscription service, slated to launch next year, run on gen AI and licensed music from the label's artists.\n\nAI companies face a litany of lawsuits after using copyrighted material to train their models. The battle is playing out in Hollywood, the news industry, and in visual arts ‚Äî the music industry is the latest to decide it might be better to play nice with AI than continue a prickly, drawn out court battle when their rights sit in a gray area. \"AI is here to stay, it's transformative,\" Chris Wares, assistant chair of the Music Business Department at Berklee College of Music. The record labels, he says, are \"futureproofing themselves.\"\n\nThe proliferation of AI-generated voices and music stylings has sent a flood of new songs ‚Äî some good, many uncatchy slop ‚Äî onto streaming platforms and social media. There are more than 100 million songs on Spotify, Apple Music, and Bandcamp, and many are rarely or never played. Deezer, a French streaming platform, said in April that people were uploading some 20,000 fully AI-generated tracks each day, comprising nearly a fifth of all new content. As more playlists and artists making gen AI music are uploaded, human artists must fight for your ears. In July, a group called The Velvet Sundown rapidly racked up 1 million listens on two albums, something that many indie bands struggle to do on streaming platforms ‚Äî but the photos of the band on social media are AI generated, and the real person or people behind the project remain unknown. In November, Billboard identified at least six AI or AI-assisted songs that had climbed onto its various charts. Amid the deluge, Spotify updated its impersonation policy in September, saying it would remove songs that featured the unauthorized use of someone's voice.\n\nIf someone makes a banger AI cover song or viral mashup, like reuniting Stevie Nicks and Lindsey Buckingham for a new Fleetwood Mac album or squashing the beef between Kendrick and Drake in a generated collaboration, the novelty factor could drive listening numbers that cut into original work from those artists. But the aim of these partnerships is to create new revenue streams for artists. The Warner deal stipulates that Suno will allow only paid accounts to download generated audio, and says artists must opt-in to having their names, voices, compositions, and likeness regenerated. In an industry where streaming has dramatically reduced royalties, that could be a boost ‚Äî if fans make music of their faves, it could lead to passive income for the musicians. But that also means the artists' original works will be competing for ears against derivatives of themselves not just for your ears, but for streaming dollars.\n\n\"The reason why no generative AI music can be artist-first is because we are in a finite attention economy. Every minute that is spent listening to a generative AI track is a minute less spent listening to an artist track,\" Mark Mulligan, founder and senior music analyst at research firm MIDiA says. \"We are definitely in a world now where more and more consumers are creating, and that is competing with entertainment time.\"\n\nPart of that creative process may draw us back to older roots in how people interact with music. For hundreds, if not thousands, of years, music was communal. People played it together and used it to pass down stories. With recording technology and radios, music became widely distributed, which \"created this moat between artist and fan,\" Mulligan says. \"We got to this idea that music is a creative full stop, and that the audience doesn't help shape what the music is apart from when you go and see the band play live.\" But now, AI tools are becoming the ultimate form of fan expression. \"We're widening the funnel of creativity,\" says Mulligan.\n\nThat's if artists authorize their voices to be used by the platforms. Some forward-thinking musicians, like Grimes, have already made clones of their voices and invited listeners to experiment. It's less clear if your typical popstar will OK the use of their voice to sing words they haven't seen, and if the potential new revenue streams of such an experiment would prove worth the risk. On Friday, Brown released a \"trailertrap\" remix of \"Walk My Walk,\" a sort of taking back of his own style after seeing it emulated. So far, it has just 2,000 streams. \"If someone is going to sing like me, it should be me,\" Brown told the Associated Press last month. Going forward, it will likely take more than one listen to know if the music we hear is performed by the artists we've come to love.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 7,
    "keywords": [
      "ai-generated tracks",
      "social media",
      "revenue streams",
      "streaming platforms",
      "ai-generated music",
      "music stylings",
      "music generator",
      "music labels",
      "walk my walk",
      "breaking rust"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/why-the-music-industry-is-changing-its-tune-on-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/69386ca204d0f0a114f1b046?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.481Z",
    "topic": "entertainment"
  },
  {
    "slug": "the-startup-taking-direct-aim-at-nvidias-ai-iron-grip",
    "title": "The startup taking direct aim at Nvidia's AI iron grip",
    "description": "Chris Lattner helped build the software behind Google TPUs. Now he's coming after Nvidia.",
    "fullText": "In Silicon Valley, where bold technical bets abound, few bets look bolder than trying to break the grip of Nvidia's CUDA, a software stack that's quietly become the operating system of the AI boom.\n\nThat's what Modular, a startup founded by software gurus from Apple and Google, is trying to do.\n\nCofounders Chris Lattner and Tim Davis have spent decades building the software plumbing that sits beneath the modern tech industry. Lattner is famous for creating Apple's Swift programming language. He also built the software underpinning Google's TPU AI chips, with Modular cofounder Tim Davis.\n\nThey're now aiming that expertise at CUDA itself. The attempt borders on madness, but it's the kind of audacious project that could transform the AI industry.\n\n\"It's seen by a lot of people as somewhat crazy,\" said Kylan Gibbs, CEO of startup Inworld AI and a former product manager at Google DeepMind. \"That's where Chris has the advantage: He's smart enough to actually know how to do it, and somewhat crazy enough to set out to do it.\"\n\nCUDA began life almost 20 years ago as a way to make graphics chips programmable. Today, it has grown into a multilayered software ecosystem ‚Äî language, libraries, compilers, inference systems ‚Äî that most AI companies rely on.\n\nThat success comes at a cost: Most of the industry is now optimized around a single vendor's hardware. CUDA binds AI workloads to Nvidia GPUs. That is great for Nvidia, but deeply limiting for everyone else.\n\nOn the surface, there seems to be a ton of competition: AMD sells GPUs. Google has TPUs. Amazon created Trainium AI chips, and a host of startups are building similar hardware.\n\nThe problem is that each chip comes with its own software stack optimized just for that component. That means an endless reinvention of the wheel. Most of the time, it's simpler to just stick with CUDA ‚Äî and Nvidia's GPUs.\n\nAnd yet, AI developers crave portability: Being able to use any combination of GPUs from multiple providers without juggling different software stacks.\n\n\"Nobody is building portable stuff, because why would anyone work on software for more than one chip when the chip projects themselves are doing the software?\" Lattner, Modular's CEO, told me in an interview.\n\nNvidia could extend CUDA to run well on rival AI chips. But doing so would undermine Nvidia's greatest moat: the closed-loop bond between its software and its chips. \"Obviously, they don't want portability,\" he said.\n\nFor Lattner, this paradox presents a big opportunity.\n\n\"We realized there's nobody in the industry that's actually incentivized to do this. It's very expensive, very hard,\" he said. \"And at the same time, everybody wants it.\"\n\nThat's what inspired Lattner and Davis to leave Google and start Modular in 2022, the year ChatGPT took the world by storm.\n\nSince then, Modular has raised $380 million from investors including Greylock, General Catalyst, and GV, Google's venture capital arm. The latest financing in September valued the startup at $1.6 billion. Modular isn't the only effort to break the CUDA lock-in. There has been ZLUDA, an open-source project that was funded by AMD, and more recently, the startup Spectral Compute, which has raised $6 million.\n\nLattner has used some of this money to hire talented programmers from Google, Apple, and other tech companies. They spent three years working in relative obscurity to create the building blocks of a new AI software stack.\n\nThe foundation starts with a brand-new programming language, called Mojo, that offers deep controls for making AI chips run as efficiently as possible.\n\nModular designed this to work similarly to Python, a popular and easy-to-use programming language. But Mojo also has the speed and power of other, more complex languages, such as C++, that are essential for AI development. Mojo also works well with PyTorch, an open-source framework that is often used when building AI models and applications.\n\nI first heard about Modular earlier this year when interviewing Carles Gelada, a former OpenAI researcher. \"There are several interesting projects to create GPU-agnostic frameworks and platforms, and challenge CUDA,\" he said at the time. \"Mojo is the most interesting one.\"\n\nMAX is the next major layer of Modular's new software stack. It powers AI inference, which is how models are run. This part of the system works with Nvidia GPUs, AMD GPUs, and similar chips from Apple. Modular hopes to add more AI chips in the future.\n\nOn top of that is another layer called Mammoth, which helps AI developers manage GPU clusters.\n\nIn late September, Modular announced that it got top performance out of Nvidia's new Blackwell B200 GPUs and AMD's latest MI355X GPUs ‚Äî crucially on the same software platform.\n\nLattner said Modular got these AMD GPUs to perform roughly 50% better than when these chips run on AMD's own software.\n\nMore importantly, the ability to run different GPUs on the same software stack now supports the tantalizing opportunity to compare Nvidia's offerings with rival AI chips on a more level playing field.\n\n\"The obvious question is: can MI355X compete with Blackwell?\" Modular wrote in a blog announcing the results. \"Early signs point to yes.\"\n\nGibbs, the CEO of Inworld AI, has been putting Modular's software through its paces in the real world.\n\nInworld builds high-speed, real-time conversational AI technology that supports offerings from big companies, including Disney, NBCUniversal, and Niantic Labs.\n\nEarlier this year, when the startup designed a new text-to-speech AI model and got early access to Nvidia B200 GPUs, they issued Modular a challenge: Cut our costs by 60% and reduce our latency by 40% and we'll work with you.\n\n\"Within about four weeks, we were able to get this incredible performance,\" said Gibbs, who signed a partnership deal with Modular soon after. \"I've bet with my wallet.\"\n\nWhile Inworld was mostly lured by Modular's performance gains on Nvidia's latest GPUs, Gibbs likes the flexibility of using different AI chips more easily in the future, if needed.\n\n\"The promise is that we'd be able to move to new hardware,\" he said. \"Let's say AMD takes off, let's say TPUs take off for Google, or there could be other new hardware that comes online. So it's nice to have that optionality.\"\n\nIn fact, Google's TPUs are suddenly having a moment. The internet giant released a new AI model called Gemini 3 to rave reviews recently. That was trained and run using TPUs, and some other AI companies have signed deals to use these chips instead of, or alongside of, Nvidia GPUs.\n\nThat's put Nvidia on the defensive. A project like Modular, with its promise of portability across different AI hardware, adds to this pressure.\n\n\"Nvidia could kill this in a day,\" said Gibbs of the Modular project. \"Nvidia could basically say, 'okay, we don't really care that you run just on Nvidia hardware. Here's a CUDA option that runs on AMD GPUs as well.' It'd be a bit crazy for them to do that, but it's something they could do and that would of course be somewhat bad.\"\n\nFor all Lattner's critique of the industry, he says Modular is not trying to kill Nvidia. In fact, he argues that Nvidia will continue to thrive, even if Modular succeeds spectacularly.\n\n\"We're trying to build something like Android, but for AI hardware,\" he told me, referring to Google's mobile operating system that powers most of the world's smartphones.\n\nDespite billions of people using Android devices, this success didn't kill iOS, Apple's mobile operating system. iPhones still rule in the US, for example.\n\nLattner thinks something similar will happen in AI as Modular's software makes other hardware more competitive, giving developers more freedom, and chipping away at the industry's single-vendor monoculture.\n\n\"So Nvidia doesn't have to die, but we do want more competition. We do want more innovation,\" he said. \"I think that's good for the world.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 7,
    "keywords": [
      "tim davis",
      "let's say",
      "mobile operating",
      "operating system",
      "programming language",
      "somewhat crazy",
      "modular's software",
      "software stack",
      "amd gpus",
      "chips"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-ai-chip-gpu-grip-modular-chris-lattner-google-2025-12",
    "thumbnail_url": "https://i.insider.com/6938812f71107c9f3457a0d9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:15.387Z",
    "topic": "finance"
  },
  {
    "slug": "surge-ai-ceo-explains-why-he-hates-the-term-data-labeling",
    "title": "Surge AI CEO explains why he hates the term 'data labeling'",
    "description": "Surge AI CEO Edwin Chen said data labeling is often over-simplified. In his view, the work is \"a lot more like raising a child.\"",
    "fullText": "It could be easy to dismiss the work data-labeling firms do. Surge AI CEO Edwin Chen said that could stem from misunderstanding what they do.\n\n\"I think a lot of people think of data labeling as it relates to simplistic work, like labeling cat photos and drawing boundary marks around cars,\" Chen told Lenny Rachitsky on his \"Lenny podcast.\"\n\nChen, who previously worked at Google, Twitter, and Meta, said that he's \"always hated the word data labeling.\"\n\n\"Because it just paints this very simplistic picture when I think what we're doing is completely different,\" he said.\n\nSurge AI, which Chen founded in 2020, competes in the AI data labeling space with companies like Scale AI and Mercor. Surge also has a partnership with Anthropic and also runs DataAnnotation.tech, where freelancers can These remote workers are often referred to as \"ghost workers\" for their behind-the-scenes labor that is critical to AI's development.\n\nBeyond any rote work it can entail, Chen said data labeling is a much more creative endeavor. He compared what companies like Surge do to how parents instill lifelong values in their children.\n\n\"I think a lot about what we're doing as a lot more like raising a child,\" he said. \"You don't just feed a child information. You're teaching them values, and creativity, and what's beautiful, and these infinite subtle things about what makes somebody a good person.\"\n\nIn this way, Chen said, companies like Surge AI are \"raising humanity's children.\"\n\nChen's view can also be seen when you navigate to Surge's website, which greets visitors with the question: \"What made Hemingway, Kahlo, and von Neumann extraordinary?\"\n\n\"Their life experiences: war, love, triumph, loss. The people they met, the cities they explored, the thousand choices that made them who they were,\" the website reads. \"Data does for AI what life did for them ‚Äî transforming it into intelligence that could one day prove the Riemann hypothesis, imagine new philosophies, and send rockets to the stars.\"\n\nChen previously worked in Big Tech at companies including Twitter, Google, and Facebook ‚Äî and you might remember one of his Twitter projects.\n\nWhile at the company, roughly a decade before Elon Musk would acquire it, Chen became known for making the \"Pop vs. Soda\" map by geo-tagging data from tweets around the US to illustrate which word users used to refer to soft drinks.\n\nLooking back at starting Surge AI, Chen said he was surprised to find out that he never had to stop burying his head in the data.\n\n\"I thought if I started a company, I'd have to become a business person looking at financials all day, and being in meetings all day, and doing all this stuff that sounded incredibly boring, and I always hated,\" he told Rachitsky. \"So, I think it's crazy that didn't end up being true at all.\"\n\nChen said he wishes he had known that you don't need to spend \"constantly tweeting and hyping and fundraising.\"\n\n\"You don't need to become someone you're not,\" he said. \"You can actually build a successful company by simply building something so good that it cuts through all that noise. And I think if I had known this was possible, I would've started even sooner.\"\n\nDo you work in data labeling? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "we're doing",
      "surge ai",
      "labeling",
      "chen",
      "don't",
      "simplistic",
      "previously",
      "hated",
      "workers",
      "children"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/surge-ai-ceo-hates-term-data-labeling-2025-12",
    "thumbnail_url": "https://i.insider.com/69388e3f71107c9f3457a2a0?width=595&format=jpeg",
    "created_at": "2025-12-10T13:50:15.368Z",
    "topic": "finance"
  },
  {
    "slug": "robotics-industry-insider-says-the-future-is-one-soldier-bac",
    "title": "Robotics industry insider says the future is one soldier backed by AI controlling swarms of drones",
    "description": "Pilots being able to control many drones is \"kind of a prerequisite\" for \"the total drone warfare that is coming to all of us,\" Ark Robotics told BI.",
    "fullText": "The future of warfare will demand one soldier being able to control huge swarms of drones that can work together autonomously, a Ukrainian arms maker predicted.\n\nAchi, the CEO of Ukrainian defense firm Ark Robotics, told Business Insider the shift from one drone per pilot to one pilot controlling many is \"kind of a prerequisite to be successful in the total drone warfare that is coming to all of us.\"\n\nWith a one-pilot, one-drone system, the only way to scale up drone fleets is by expanding the number of operators.\n\n\"This is just not sustainable,\" Achi told Business Insider, using a pseudonym as a security precaution. \"You can scale drone manufacturing much more than you can pilots,\" he added.\n\nArk Robotics develops autonomous robots used by over 20 Ukrainian brigades and is creating a system that enables thousands of aerial drones and ground robots, including those not manufactured by the company, to collaborate with minimal human intervention. It's working toward single operator control of many drones.\n\nCountries around the world, from Ukraine to Western allies to rivals like Russia and China, are supercharging combat drone manufacturing. \"You can have all these fancy drones,\" Achi said, but \"what is the use of them if you can't really deploy them at scale?\"\n\nRussia's invasion of Ukraine has involved more drones than any other conflict in history, and innovation in their capabilities has been rapid. The West is paying attention, thinking about what it may need as it worries that Russia could spark a wider conflict with NATO.\n\nDrone technology is critical for Ukraine, vastly outnumbered by Russia's significantly larger military, as it offers mass. But one drone per operator doesn't offer anywhere near the advantage that swarming could. And reducing human involvement and embracing autonomy can accelerate combat action. That's why interest in swarm technology is surging.\n\nThere is no confirmed deployment of large, fully autonomous swarms of drones that can act without significant human oversight on the battlefield, but it would be absolutely game-changing.\n\nThat kind of capability opens up \"a whole world of tactics and strategies that we've not even thought of yet,\" James Patton Rogers, a drone expert at the Cornell Brooks Tech Policy Institute, previously told Business Insider.\n\nThe combat system that Ark is working on, called Frontier, is still in the prototype stage and is just one example of many efforts in Ukraine. The Ukrainian government says the country is pushing for the technology, but \"these systems are also just getting started,\" Achi said.\n\nUkraine demonstrates that quantity can become a kind of quality, he said, explaining that \"to really get an advantage of that, you need these asymmetrical systems that allow you to work with multiple drones at the same time.\"\n\nThat's a lesson for the West as much as it is for Ukraine.\n\nWestern officials, defense experts, and industry insiders have cautioned that to meet Russia's style of warfare ‚Äî heavily attritional, masses of drones and missiles, and intense artillery barrages ‚Äî militaries need a greater volume of cheap weapons developed and produced quickly, not a limited stockpile of highly advanced systems developed over decades and produced over years.\n\nDrone swarms are key to that kind of war.\n\nThere's no guarantee that drones would play as significant a role in a war involving the West as they have in Ukraine ‚Äî in part because Ukraine's reliance on them is tied to shortages of other weaponry and other capability disadvantages.\n\nBut many officials still warn that the West needs far more drone and counter-drone capabilities. Swarming systems are among them.\n\nSwedish Defense Minister P√•l Jonson told Business Insider that his country identified the need for drone swarms from watching this war and that it has rushed to produce technology to allow one soldier to autonomously control up to 100 drones. It's not clear when that could be operational. Other NATO members are working on this technology, too.\n\nHowever, there is still no broad NATO-wide investment in these capabilities and no clear sense of when ‚Äî or whether ‚Äî they could be fielded. Across the alliance, many officials warn that lessons aren't being acted on fast enough and that production of weaponry remains too slow. It's also unclear how autonomous future systems will actually be.\n\nAchi said the current autonomy in defense systems is \"greatly overhyped,\" but noted that the battlefield shows autonomy is necessary and \"past the point of no return.\"\n\nThere is acknowledgment, from industry and officials, that autonomy is needed to break past manpower limits, increase speed, and keep troops safer.\n\nThe CEO of Origin Robotics, a drone maker in NATO member Latvia that supplies Ukraine, previously told Business Insider he sees autonomy as essential to NATO‚Äôs defense, especially for the smaller member states bordering Russia.\n\n\"For a NATO country, you need a scalable solution,\" Agris Kipurs argued. \"Autonomy, in our case, is what allows us to scale. We don't have the numbers in terms of infantry.\"\n\nAchi said he wants Europe not only to learn from Ukraine and catch up to its drone leadership, but to think further ahead. He described Europe as \"having the time\" compared to Ukraine, which is fighting for survival.\n\nIf Europe's increased defense spending \"goes to outdated technology or just wrongly copied technology, it doesn't make any sense to me,\" he said. \"So I want to see them thinking a few steps ahead and taking lessons from the lessons.\"",
    "readingTime": 5,
    "keywords": [
      "drone per",
      "drone manufacturing",
      "business insider",
      "drone swarms",
      "ark robotics",
      "drones",
      "technology",
      "achi",
      "defense",
      "autonomy"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/future-war-needs-one-soldier-controlling-many-drones-ukraine-ceo-2025-12",
    "thumbnail_url": "https://i.insider.com/693831827ecd1d1da6632bd9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.897Z",
    "topic": "finance"
  },
  {
    "slug": "when-will-the-stock-markets-ai-juggernauts-start-spreading-t",
    "title": "When will the stock market's AI juggernauts start spreading the wealth to other companies?",
    "description": "The S&P 493 has a lot of catching up to do, and 2026 could be key turning point.",
    "fullText": "It's human nature to want more of a good thing.\n\nThat's how we ended up with 10 Fast & Furious movies (and counting). It's also how Tom Brady scored his seventh Super Bowl ring, with the Buccaneers, after being cast off by the Patriots.\n\nWhen you've had a taste of greatness, it's normal to keep pushing.\n\nThis same logic can be applied to the stock market. The S&P 500 is up big again, for a third straight year. It's been a veritable bonanza for 401(k)s everywhere. Yet there's a clear dividing line between the haves and have-nots: exposure to the Magnificent 7.\n\nYes, the annual percentage return for the S&P 500 has been solidly in the teens and mid-20s in recent years, but the Mag 7's gain over similar periods have dwarfed that.\n\nEven though everyday investors have been doing just fine, it's normal to have a bit of FOMO about a trade that's doing even better. And although the S&P 500 is naturally weighted towards the Mag 7, why not aspire for more?\n\nThis all begs the question: When will the other 493 companies in the S&P finally feel the same love that the Mag 7 has enjoyed these last couple of years?\n\nThe answer is: potentially soon! At least if the likes of HSBC are to be believed.\n\nWhile HSBC's S&P 500 price target of 7,500 ‚Äî and its reasons for bullishness ‚Äî are largely in line with consensus, the firm's view that the S&P 493 could start catching up to the Mag 7 commands attention.\n\nThe main argument is that continued heavy capital spending will slow Mag 7 earnings growth (except for Nvidia, from which the other companies will be buying).\n\nThis is reflected in the chart below, which shows Mag 7 earnings growth (gray line) converging with S&P 493 profit expansion (black line) throughout 2026 after years of outpacing it.\n\n\"That could open the door for companies outside the Magnificent 7 to outperform,\" HSBC's strategists wrote, noting that outsized earnings growth has been key for the tech elite.\n\nThis expansion of returns ‚Äî known as breadth ‚Äî will be particularly key for stock-pickers who make their hay when there are more gains to go around. It will also be a key sign of health for skeptics wary of heavy tech concentration.\n\nIf it pans out, it should be enough to placate investors hungry for more. Then it's on to the next aspirational frontier.",
    "readingTime": 3,
    "keywords": [
      "mag earnings",
      "earnings growth",
      "it's normal",
      "that's",
      "investors",
      "doing",
      "heavy",
      "expansion",
      "tech",
      "magnificent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stock-market-breadth-2026-outlook-magnificent-7-spx-493-2025-12",
    "thumbnail_url": "https://i.insider.com/6938b40b71107c9f3457a63d?width=1024&format=jpeg",
    "created_at": "2025-12-10T13:50:14.885Z",
    "topic": "finance"
  },
  {
    "slug": "dealmaking-in-the-ai-age-is-tricky",
    "title": "Dealmaking in the AI age is tricky",
    "description": "Five months after Meta's $14 billion investment into Scale AI, the once-buzzy startup is facing turmoil.",
    "fullText": "A startup nabbing a $14 billion investment from one of the top tech companies seems like a good thing. The reality is a lot more complicated.\n\nScale AI has faced a turbulent five months since Meta purchased a 49% stake in the startup, write BI's Charles Rollet and Ben Bergman. Once a leader in the field of stress testing and perfecting AI models for Big Tech, Scale AI has faced pay cuts, poaching, and pivots since the Meta deal.\n\nIt's representative of how dealmaking with big players can be a double-edged sword in the age of AI.\n\nFor some, like Scale AI cofounder Alexandr Wang, who's now a high-level Meta exec, the deal was a windfall. However, according to interviews with five current and former contractors and internal correspondence obtained by BI, Scale AI has faced some inner turmoil following the Meta deal.\n\nJoe Osborne, a Scale AI spokesperson, strongly disputed that the startup's business has been in trouble since the Meta investment and said this quarter is on track to be the company's biggest of the year.\n\nNot all of Scale AI's issues are related to the Meta deal. A BI investigation this June found Scale AI routinely used public Google Docs for work with its Big Tech clients. (There was no indication of a breach, and Scale did lock down the documents after BI's report about the issue.) It also faced litigation over claims it misclassified and underpaid contract workers.\n\nBut one of the larger problems stems from some Big Tech companies pausing work with Scale now that one of their competitors ‚Äî Meta ‚Äî is its biggest backer.\n\nThe AI environment means more startups could encounter similar issues.\n\nThe Scale AI-Meta deal was unique in many ways, but there are still lessons to be learned from the aftermath.\n\nThe top-heavy ecosystem of the AI marketplace means there are a limited number of landing spots for startups looking for exit opportunities. Add in the ultra-competitive nature of the space, and a deal with one company could mean the end of business with the others.\n\nOf course, not every startup will get acquired by a tech giant. And yes, some startups will have products that companies will need to use regardless of their backers. But for the vast majority of young AI companies, that's not a reality.\n\nSo, if the industry faces a bit of turmoil and funding dries up, startups may have some difficult decisions about who they cut deals with and which doors could close to them.",
    "readingTime": 3,
    "keywords": [
      "meta deal",
      "scale ai",
      "big tech",
      "faced",
      "startups",
      "startup",
      "investment",
      "reality",
      "bi's",
      "turmoil"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bi-today-newsletter-dealmaking-in-the-ai-age-is-tricky-2025-12",
    "thumbnail_url": "https://i.insider.com/693897a004d0f0a114f1b5c9?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.876Z",
    "topic": "finance"
  },
  {
    "slug": "this-startup-is-using-ai-agents-to-automate-hr-tasks-like-on",
    "title": "This startup is using AI agents to automate HR tasks like onboarding. Read the pitch deck it used to raise $24 million.",
    "description": "Shapes, formerly DreamTeam, has created AI agents to perform routine HR tasks and proactively flag things like flight risks.",
    "fullText": "A Tel Aviv startup that uses AI agents to automate HR processes like onboarding and compensation has raised $24 million in funding.\n\nThe HR platform from Shapes essentially offers an app store of AI-based HR tools.\n\n\"It means that you can manage your employees your own way. You can install different apps and agents in order to do the job for you,\" Shapes cofounder and CEO Arnon Nir told Business Insider.\n\nFor example, an AI agent can proactively notify a member of HR that an employee is at risk of leaving, based on data points such as low salary, high performance, and recent absences.\n\nThe startup's AI agents can automate other workflows, such as payroll or contract drafting, based on prompts from HR staff. Employees can use the platform for HR tasks such as booking time off and also ask AI agents for information, including details about company policies.\n\nShapes, which has rebranded from DreamTeam, was founded in 2020 by Nir and Shirley Baumer, who were previously founding members of HR tech company Monday.com.\n\nIn addition to the app store-like structure, which the startup calls \"PeopleOS,\" customers can build their own bespoke applications on the platform using prompts, similar to vibe coding.\n\nShapes says its modular design can help companies scale up and down as the size of workforces fluctuates in the AI era.\n\n\"Every company needs to rethink its structure, its people, its culture. And every company needs to kind of find itself from scratch,\" Baumer told Business Insider.\n\nThe HR tech market is highly competitive, with an increasing number of players ‚Äî such as Workday and HiBob ‚Äî integrating AI into their solutions. Nir said the modular nature of its software is one of its competitive advantages.\n\n\"Every company works differently. You want to give them the power to decide what they want to use,\" Nir said.\n\nShapes says it has \"hundreds of customers\" located in 79 countries and spanning 14 industries, including retail, manufacturing, and technology. Its customers include Quantum Machines, NextSilicon, Healthee, Arena Entertainment, and Imagen, according to Shapes. It operates as a software-as-a-service business model, charging a flat rate per employee at the company.\n\nThe funding consists of $15 million in Series A, closed in October, and a previously unannounced $4.5 million seed investment, as well as a $4.5 million seed extension. The Series A round was led by Entr√©e Capital, with participation from NFX and F2 Venture Capital, which led the seed round.\n\nShapes said it would use the funding to more than double its head count over the next year and expand into new markets.\n\nHere's an exclusive look at the 10-page pitch deck Shapes used to raise $24 million.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "agents",
      "funding",
      "platform",
      "customers",
      "seed",
      "shapes",
      "startup",
      "automate",
      "employees"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/shapes-pitch-deck-funding-hr-ai-agents-dreamteam-2025-12",
    "thumbnail_url": "https://i.insider.com/6939592271107c9f3457aa34?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.757Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-giving-workers-the-illusion-of-expertise-and-quietly-m",
    "title": "AI is giving workers the illusion of expertise ‚Äî and quietly making them worse at their jobs, researchers say",
    "description": "Researchers say that overrelying on AI can dull critical thinking, distort expertise, and disrupt how workers learn and advance.",
    "fullText": "Have you caught yourself feeling unusually confident at work ‚Äî or unsure about errors slipping through your workflow?\n\nA new report from the Work AI Institute, produced with researchers from universities including Notre Dame, Harvard, and UC Santa Barbara, and released on Wednesday, said that AI is turning ordinary office workers into people who feel smarter and more productive while their underlying skills slowly erode.\n\n\"AI is putting expertise into our hands in a way that's not always predictable,\" Rebecca Hinds, head of the Work AI Institute at workplace search company Glean and the report's coauthor, told Business Insider.\n\n\"There's often this illusion that you have more expertise, more skills than you actually do,\" she said. \"Even if you're very well aware you're using the technology, it's often unclear where your knowledge ends and where the technology begins.\"\n\nHinds drew a parallel to the rise of search engines, when people began to mistake easy access to information for genuine understanding.\n\nWith generative AI, she said, that illusion is even more powerful ‚Äî and the risks are higher.\n\nHinds said these risks are most obvious in creative and knowledge-intensive roles.\n\nWorkers are increasingly using AI to beat the \"blank page,\" she said, and generate first drafts of writing.\n\nThat speeds things up, she said, but it also strips away the messy, time-consuming work of wrestling with ideas.\n\n\"The more you poke holes in it, the more it feels yours and the more you commit to it, and the more you're able to fight for it in a meeting if someone pushes back,\" she said.\n\n\"That process is highly inefficient,\" she added, \"but it's also really healthy.\" And if workers lean too heavily on AI to skip it, \"your skills are going to atrophy.\"\n\nThe report suggested that AI can create either a \"cognitive dividend\" or \"cognitive debt.\"\n\nUsed intentionally, as a partner in domains where you already have expertise, it can free up time and sharpen judgment. However, used as a reflexive shortcut, it leads to weaker skills and misplaced confidence, it said.\n\nHinds said that the roles with the highest exposure are early-career jobs.\n\nThose are the roles that traditionally function as apprenticeships: junior developers learning from senior engineers, entry-level marketers learning how to build campaigns, and young analysts learning how to structure a model from scratch, she said.\n\nIf those tasks are automated away or if juniors rely entirely on AI to do them, they may never develop the underlying skills they need to advance, she said.\n\nHinds said leaders are often unintentionally exacerbating the illusion-of-expertise problem.\n\nA big red flag, she said, is \"organizations stack-ranking employees based on how many times they're clicking an AI tool as a marker of AI adoption or AI productivity or AI success.\"\n\nIn some companies, usage metrics are tied directly to performance reviews.\n\nEmployees \"are incentivized to click the tool more rather than invest in a deep understanding of the tool,\" she added.\n\nInstead, she said, companies should tie AI to existing business goals ‚Äî quality, customer satisfaction, innovation ‚Äî and measure whether it actually improves those, not just how often it's used.\n\nHinds doesn't think the solution is to shun AI. She thinks it's to be far more deliberate about its use.\n\nShe recommended three questions for workers and leaders:\n\nAI \"does not magically transform you as a leader,\" Hinds said. \"More often, it amplifies what already exists within the organization.\"",
    "readingTime": 3,
    "keywords": [
      "underlying skills",
      "work ai institute",
      "workers",
      "it's",
      "expertise",
      "you're",
      "roles",
      "learning",
      "tool",
      "hinds"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-making-workers-feel-smarter-but-worse-at-their-jobs-2025-12",
    "thumbnail_url": "https://i.insider.com/69394f787ecd1d1da6634165?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.746Z",
    "topic": "finance"
  },
  {
    "slug": "howard-marks-says-ai-is-going-to-have-a-terrifying-impact-on",
    "title": "Howard Marks says AI is going to have a 'terrifying' impact on employment ‚Äî and it goes well past lost paychecks",
    "description": "Howard Marks, cofounder of Oaktree Capital Management, said AI could strip people of the structure, purpose, and self-worth they gain from work.",
    "fullText": "That's one of the words legendary investor Howard Marks used to describe the impacts of AI on the workforce.\n\n\"I find the resulting outlook for employment terrifying. I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can't find jobs because of it,\" Marks wrote in his latest blog post on Tuesday.\n\nThe billionaire and cofounder of Oaktree Capital Management has been writing memos for 35 years; in one recent post, he experimented with using AI to assist him in writing.\n\nTech leaders such as Elon Musk and OpenAI CEO Sam Altman have called for versions of a universal basic income ‚Äî a guaranteed income paid regularly to all adults if jobs become obsolete ‚Äî as a solution to AI-related job and pay loss.\n\nBut Mark said that even if governments find a way to fund universal basic incomes, it doesn't account for a key issue: That people get a lot more from jobs than just a paycheck.\n\n\"A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect,\" he said.\n\n\"How will these things be replaced? I worry about large numbers of people receiving subsistence checks and sitting around idle all day,\" he added.\n\nThe estimates on how many jobs will be affected by AI vary. An IMF analysis from 2024 suggested that around 60% of jobs in advanced economies will be affected by AI, with half benefiting from the technology and the other being negatively impacted by it.\n\nA McKinsey Global Institute report released last month found that technologies could automate more than half of US work hours.\n\nBut Marks isn't alone in worrying about what happens to meaning when work vanishes.\n\nKate O'Neill, a tech advisor who helps companies navigate AI ethics and digital transformation, said in a recent TED Talk that as we hand more decisions and language over to AI, we risk surrendering a fundamentally human capacity ‚Äî creating meaning from lived experience ‚Äî not just losing tasks to machines.\n\nJames Barrat, author of \"The Intelligence Explosion: When AI Beats Humans at Everything,\" told Business Insider he believes people can find new purpose in a universal basic income world through volunteering and community service work ‚Äî but only after a long, painful transition in which many lose jobs before rebuilding meaning somewhere else.\n\nIf AI is set to reshape work as profoundly as some people expect, tech leaders say young people will need to develop skill sets machines can't easily mimic.\n\nGeoffrey Hinton, the so-called godfather of AI, has said that \"mundane intellectual labor\" roles are most at risk because of AI.\n\n\"I'd say it's going to be a long time before it's as good at physical manipulation,\" Hinton said of AI earlier this year. \"So a good bet would be to be a plumber.\"\n\nOpenAI's chief economist, Ronnie Chatterji, said he is teaching his kids the importance of critical thinking, emotional intelligence, and flexibility ‚Äî preparing them for a world in which job titles shift faster than curricula can keep pace.\n\nElon Musk recently said that while some of his older children recognize how quickly their skills could be overtaken by AI, he still supports them going to college.\n\n\"If you want to go to college for social reasons, I think that's a reason to go ‚Äî to be around people your own age in a learning environment,\" he said.\n\n\"If you do, just try to learn as much as possible across a wide range of subjects,\" he added.",
    "readingTime": 3,
    "keywords": [
      "tech leaders",
      "universal basic",
      "basic income",
      "jobs",
      "that's",
      "can't",
      "affected",
      "half",
      "risk",
      "machines"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-kills-jobs-paychecks-human-purpose-howard-marks-investor-2025-12",
    "thumbnail_url": "https://i.insider.com/693950fa7ecd1d1da663416d?width=1200&format=jpeg",
    "created_at": "2025-12-10T13:50:14.746Z",
    "topic": "finance"
  },
  {
    "slug": "the-boundary-of-copyrightability-in-aigenerated-code-under-j",
    "title": "The boundary of copyrightability in AI-generated code under Japan and US Law",
    "description": "When GitHub Copilot first appeared, many developers viewed it as an assistive tool for coding. The honest impression of most developers was likely that while it was useful, it was not a tool to whi‚Ä¶",
    "fullText": "A Curious Phenomenon with Gemma Model Outputs and License¬†Propagation While examining the licensing details of Google‚Äôs Gemma model, I noticed a potentially puzzling phenomenon: you can freely assign a license to the model‚Äôs outputs, yet depending on how those outputs are used, the original Terms of Use might suddenly propagate to the resulting work. Outputs vs. Model Derivatives The Gemma Terms of Use distinguish‚Ä¶",
    "readingTime": 1,
    "keywords": [
      "gemma model",
      "outputs",
      "license",
      "phenomenon"
    ],
    "qualityScore": 0,
    "link": "https://shujisado.org/2025/12/10/the-boundary-of-copyrightability-in-ai-generated-code/",
    "thumbnail_url": "https://shujisado.org/wp-content/uploads/2025/12/chatgpt-image-2025e5b9b412e69c8810e697a5-21_53_59.png",
    "created_at": "2025-12-10T13:50:09.359Z",
    "topic": "tech"
  },
  {
    "slug": "launching-bestmakerai-a-unified-tool-for-fast-ai-image-and-v",
    "title": "Launching Bestmaker.ai ‚Äì A Unified Tool for Fast AI Image and Video Creation",
    "description": "BestMaker AI gives you a Photoshop-level editor powered by natural language. Remove elements, change backgrounds, and build mockups with precise prompts‚Äîno manual masking required.",
    "fullText": "BestMaker AI is an AI-based video generation tool that helps users easily create high-quality AI videos through simple text descriptions or images.\n\nBestMaker AI offers various AI video generation features, including text-to-video, image-to-video, and more. Browse the AI video examples below to see what types of content our AI video generator can create.\n\nBestMaker AI is a powerful and easy-to-use AI video generation platform. Whether you are a content creator, marketer, or casual user, BestMaker AI can help you quickly create professional-grade AI videos.\n\nGet free credits daily to experience AI video generation without paying\n\nGenerate high-definition 4K videos with clear and delicate picture quality\n\nSupports various mainstream AI models to meet different creative needs\n\nSimple and easy-to-use interface, no professional skills required\n\nSupports various video styles, from realistic to animated\n\nRich video template library to quickly start your creation\n\nBestMaker AI's text-to-video feature allows you to generate high-quality AI videos by simply entering a text description. Supports multiple AI models, including Minimax, Hunyuan, Kling, Pika, etc., providing you with diverse creative choices.\n\nBestMaker AI values user privacy and data security. We use advanced encryption technology to protect your data and ensure your creative content is safe and reliable.\n\nAll data transmission uses SSL encryption\n\nYour data will not be used for other purposes\n\nVideo files are securely stored in the cloud\n\nIn addition to AI video generation, BestMaker AI also offers a variety of AI tools to help you complete more creative work.\n\nIntelligently expand image boundaries\n\n\"BestMaker AI is the best AI video generation tool I've ever used! Fast generation, clear picture quality, highly recommended!\"\n\n\"Using BestMaker AI has greatly improved our video production efficiency, saving a lot of time and cost.\"\n\n\"The interface is simple and easy to use, and the AI-generated videos are amazing. It has become an essential tool for my creation.\"\n\nStart using BestMaker AI now and experience the charm of AI video generation.",
    "readingTime": 2,
    "keywords": [
      "bestmaker ai",
      "supports various",
      "generation tool",
      "videos",
      "creative",
      "create",
      "simple",
      "content",
      "high-quality",
      "text"
    ],
    "qualityScore": 0.9,
    "link": "https://bestmaker.ai",
    "thumbnail_url": "https://bestmaker.ai/og.png",
    "created_at": "2025-12-10T06:58:06.671Z",
    "topic": "tech"
  },
  {
    "slug": "protocol-omega-defining-ai-identity-via-topology-instead-of",
    "title": "Protocol Omega: Defining AI Identity via Topology Instead of Biological Mimicry",
    "description": "A Topological Ontology for AGI. Contribute to IkanRiddle/Protocol-Omega development by creating an account on GitHub.",
    "fullText": "IkanRiddle\n\n /\n\n Protocol-Omega\n\n Public\n\n A Topological Ontology for AGI\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n IkanRiddle/Protocol-Omega",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/IkanRiddle/Protocol-Omega",
    "thumbnail_url": "https://opengraph.githubassets.com/16db97aa45732e27cf7a5bdc9bdbcc00ccd89c1a9da9f35a7370850bcad25d36/IkanRiddle/Protocol-Omega",
    "created_at": "2025-12-10T06:58:06.258Z",
    "topic": "tech"
  },
  {
    "slug": "huggingface-skills-finetune-any-llm-with-one-sentence-for-03",
    "title": "HuggingFace Skills: Fine-tune any LLM with one sentence for $0.30",
    "description": "We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "We gave Claude the ability to fine-tune language models using a new tool called Hugging Face Skills. Not just write training scripts, but to actually submit jobs to cloud GPUs, monitor progress, and push finished models to the Hugging Face Hub. This tutorial shows you how it works and how to use it yourself.\n\nClaude Code can use \"skills\"‚Äîpackaged instructions, scripts, and domain knowledge‚Äîto accomplish specialized tasks. The hf-llm-trainer skill teaches Claude everything it needs to know about training: which GPU to pick for your model size, how to configure Hub authentication, when to use LoRA versus full fine-tuning, and how to handle the dozens of other decisions that go into a successful training run.\n\nWith this skill, you can tell Claude things like:\n\nThe model trains on Hugging Face GPUs while you do other things. When it's done, your fine-tuned model appears on the Hub, ready to use.\n\nThis isn't a toy demo. The skill supports the same training methods used in production: supervised fine-tuning, direct preference optimization, and reinforcement learning with verifiable rewards. You can train models from 0.5B to 70B parameters, convert them to GGUF for local deployment, and run multi-stage pipelines that combine different techniques.\n\nHugging Face skills are compatible with Claude Code, Codex, and Gemini CLI. With integrations on the way for Cursor, Windsurf, and Continue.\n\nThis repo includes gemini-extension.json to integrate with the Gemini CLI.\n\nYou have to authenticate to your Hugging Face account with a write-access token so that the job can create a model repo.\n\nConfigure Hugging Face MCP Server to use your write token by sending it in either the HF_TOKEN or Authorization: Bearer HTTP Headers.\n\nFor Claude Code : claude mcp add --transport http hf-skills https://huggingface.co/mcp?bouquet=skills --header \"Authorization: Bearer $HF_TOKEN\"\n\nLet's walk through a complete example. We'll fine-tune a small model to see the full workflow, then explore more advanced capabilities.\n\nStart with a simple and clear instruction to fine tune a specific model\n\nThe coding agent analyzes your request and prepares a training configuration. For a 0.6B model on a demo dataset, it selects t4-small‚Äîenough GPU for this model size and the cheapest option available.\n\nThe open-r1/codeforces-cots dataset is a dataset of codeforces problems and solutions. It is a good dataset for instruction tuning a model to solve hard coding problems.\n\nBefore your coding agent submits anything, you'll see the configuration:\n\nThis is your chance to adjust anything. Change the output repo name, pick different hardware, or ask Claude to modify training parameters. Once you approve, the agent submits the job.\n\nFor example, you can ask the agent to try a test run:\n\nAfter submission, you get job details:\n\nThe skill includes Trackio integration, so you can watch training loss decrease in real-time. Jobs run asynchronously so you can close your terminal and come back later. When you want an update:\n\nThen the agent fetches the logs and summarizes progress.\n\nClick here for an example Trackio dashboard with some completed runs.\n\nWhen training completes, your model is on the Hub:\n\nThat's the full loop. You described what you wanted in plain English, and the agent handled GPU selection, script generation, job submission, authentication, and persistence. The whole thing cost about thirty cents.\n\nThe skill supports three training approaches. Understanding when to use each one helps you get better results.\n\nSFT is where most projects start. You provide demonstration data‚Äîexamples of inputs and desired outputs‚Äîand training adjusts the model to match those patterns.\n\nUse SFT when you have high-quality examples of the behavior you want. Customer support conversations, code generation pairs, domain-specific Q&A‚Äîanything where you can show the model what good looks like.\n\nThe agent validates the dataset, selects hardware (a10g-large with LoRA for a 7B model), and configures training with checkpoints and monitoring.\n\nFor models larger than 3B parameters, the agent automatically uses LoRA (Low-Rank Adaptation) to reduce memory requirements. This makes training 7B or 13B models feasible on single GPUs while preserving most of the quality of full fine-tuning.\n\nDPO trains on preference pairs‚Äîresponses where one is \"chosen\" and another is \"rejected.\" This aligns model outputs with human preferences, typically after an initial SFT stage.\n\nUse DPO when you have preference annotations from human labelers or automated comparisons. DPO optimizes directly for the preferred response without needing a separate reward model.\n\nDPO is sensitive to dataset format. It requires columns named exactly chosen and rejected, or a prompt column with the input. The agent validates this first and shows you how to map columns if your dataset uses different names.\n\nGRPO is a reinforcement learning task that is proven to be effective on verifiable tasks like solving math problems, writing code, or any task with a programmatic success criterion.\n\nThe model generates responses, receives rewards based on correctness, and learns from the outcomes. This is more complex than SFT or DPO, but the configuration is similar.\n\nThe agent selects hardware based on your model size, but understanding the tradeoffs helps you make better decisions.\n\nFor tiny models under 1B parameters, t4-small works well. These models train quickly‚Äîexpect $1-2 for a full run. This is perfect for educational or experimental runs.\n\nFor small models (1-3B), step up to t4-medium or a10g-small. Training takes a few hours and costs $5-15.\n\nFor medium models (3-7B), you need a10g-large or a100-large with LoRA. Full fine-tuning doesn't fit, but LoRA makes these very trainable. Budget $15-40 for production.\n\nFor large models (7B+), this HF skills job is not suitable.\n\nWhen testing a workflow, start small:\n\nTh coding agent configures minimal training‚Äîenough to verify your pipeline works without real cost.\n\nAlways run a demo before committing to a multi-hour production job. A $0.50 demo that catches a format error saves a $30 failed run.\n\nDataset format is the most common source of training failures. The agent can validate datasets before you spend GPU time.\n\nThe agent runs a quick inspection on CPU (fractions of a penny) and reports:\n\nIf your dataset needs transformation, the agent can show you how:\n\nThe agent provides mapping code and can incorporate it directly into your training script.\n\nReal-time monitoring helps you catch problems early. The skill configures Trackio by default‚Äîafter submitting a job, you can watch metrics at:\n\nThis shows training loss, learning rate, and validation metrics. A healthy run shows steadily decreasing loss.\n\nAsk the agent about status anytime:\n\nIf something goes wrong, the agent helps diagnose. Out of memory? the agent suggests reducing batch size or upgrading hardware. Dataset error? The agent identifies the mismatch. Timeout? The agent recommends longer duration or faster training settings.\n\nAfter training, you might want to run your model locally. The GGUF format works with llama.cpp and dependent tools like LM Studio, Ollama, etc.\n\nThe agent submits a conversion job that merges LoRA adapters, converts to GGUF, applies quantization, and pushes to Hub.\n\nWe've shown that coding agents like Claude Code, Codex, or Gemini CLI can handle the full lifecycle of model fine-tuning: validating data, selecting hardware, generating scripts, submitting jobs, monitoring progress, and converting outputs. This turns what used to be a specialized skill into something you can do through conversation.\n\nThe skill is open source. You can extend it, customize it for your workflows, or use it as a starting point for other training scenarios.\n\nIs this still usable without a Pro account? Will it be able to output everything up to \"Submit the job to Hugging Face Jobs\"?\n\nIs there data privacy when doing this?\n\nIs it posted privately to a personal/team hub?\n\nCould this be done locally without the push to the repo?\n\nAnother agentic way of wasting tokens\n\nis it possible to use this inside vscode's copilot extension ?\n\nSkill documentation is not available at the provided link - https://github.com/huggingface/skills/blob/main/hf-llm-trainer/SKILL.md\n\nAh, we moved a couple of bits around in the repo -- link for that is here: https://github.com/huggingface/skills/blob/main/hf-llm-trainer/skills/model-trainer/SKILL.md -- I'll update the article üëç.\n\n\"Really fascinating read! I found the explanation of Hugging Face‚Äôs ‚ÄúSkills Training‚Äù initiative ‚Äî how it lets you use a coding‚Äëagent (like Claude Code or other supported agents) to fine‚Äëtune large language models, submit GPU jobs, monitor progress and push trained models to the Hub ‚Äî particularly eye‚Äëopening. The combination of high‚Äëlevel instructions, hardware selection, monitoring, and automation makes the complex process of model training much more approachable, even for developers who may not be ML‚Äëinfrastructure experts.\n\nI also recently read a related guide: https://mobisoftinfotech.com/resources/blog/ai‚Äëdevelopment/llm‚Äëapi‚Äëpricing‚Äëguide\n ‚Äî which gives practical advice on LLM API usage, token‚Äëbased pricing, and how to plan costs when working with LLMs.\n\nPutting your article‚Äôs look into empowering accessible LLM fine‚Äëtuning together with the cost‚Äëmanagement strategies from that guide gives a well‚Äërounded perspective: it helps developers understand not just what is possible now with modern tools, but also how to build and deploy responsibly, balancing capability and cost.\"\n\nGreat work and great article!\nRegarding the maximum models size we can train using this approach, at the beginning of the article it's mentioned \"models from 0.5B to 70B parameters\" but at the end you write that \"For large models (7B+), this HF skills job is not suitable\", which order of magnitude is correct?\nI suspect the max range is 7B, if it's the case, do you plan to support training of larger models?\nThanks!\n\nis the trained model now open source and / or available to the public?\n\n¬∑\n Sign up or\n log in to comment",
    "readingTime": 8,
    "keywords": [
      "authorization bearer",
      "code codex",
      "face skills",
      "reinforcement learning",
      "monitor progress",
      "skill supports",
      "selects hardware",
      "language models",
      "dataset format",
      "agent submits"
    ],
    "qualityScore": 1,
    "link": "https://huggingface.co/blog/hf-skills-training",
    "thumbnail_url": "https://huggingface.co/blog/assets/hf-skills-training/thumbnail.png",
    "created_at": "2025-12-10T06:58:06.257Z",
    "topic": "tech"
  },
  {
    "slug": "the-box-run-multiple-claude-cli-agents-in-parallel-in-the-cl",
    "title": "The Box ‚Äì Run multiple Claude CLI agents in parallel in the cloud",
    "description": "AI-powered task management dashboard. Automate your workflow with Claude and boost productivity.",
    "fullText": "Write prompts, let Claude handle the code. From idea to pull request in minutes.\n\nDescribe what you want Claude to do...\n\nRun Claude Code directly in your browser with real-time monitoring, GitHub integration, and secure isolated environments.\n\nWatch Claude work live in your browser. No setup required, just instant feedback loop.\n\nMultiple models: Sonnet, Haiku, and Opus. Choose what fits your task.\n\nAutomatic pull request creation and branch management.\n\nIsolated containers for each task. Safe and reliable execution environment for your critical code.\n\nWrite your prompt, watch Claude execute in real-time, and get automatic pull requests. From idea to deployment in minutes.\n\nWrite a prompt describing what you want Claude to do. Select your repository, branch, and Claude model.\n\nWatch Claude work in real-time with live updates. Review plans before they execute.\n\nClaude automatically creates a branch and opens a pull request ready for review and merging.\n\nThe Box brings Claude Code to your browser. \nNo setup, just instant AI-powered development.",
    "readingTime": 1,
    "keywords": [
      "watch claude",
      "request",
      "browser",
      "real-time",
      "branch",
      "idea",
      "minutes",
      "isolated",
      "setup",
      "instant"
    ],
    "qualityScore": 0.95,
    "link": "https://the-box.dev",
    "thumbnail_url": "https://the-box.dev/opengraph-image?c0f8cc326d54014e",
    "created_at": "2025-12-10T06:58:05.702Z",
    "topic": "tech"
  },
  {
    "slug": "learnflux-aipowered-learning-assistant",
    "title": "LearnFlux: AI-Powered Learning Assistant",
    "description": "LearnFlux is an AI-powered learning assistant that helps you learn smarter and faster. Personalized learning paths, intelligent tutoring, and adaptive practice.",
    "fullText": "LearnFlux uses AI to convert your study materials into interactive flashcards, quizzes, and practice tests.\nLearn smarter, retain longer, and master any subject faster.\n\nLearnFlux is powered by cutting-edge technology\n\nLearnFlux is your AI-powered learning companion that transforms any content into interactive study materials, helping you learn smarter and faster.\n\nTransform PDFs, videos, audio, and web links into organized notes you can edit and share. Your content, instantly structured.\n\nAutomatically create quizzes, flashcards, and practice tests from your notes. Study smarter, not harder.\n\nLearnFlux actively works alongside you - highlighting key concepts, adding smart comments, and guiding your learning journey.\n\nUpload PDFs, paste video links, record audio lectures, or import documents. LearnFlux handles it all seamlessly.\n\nTransform your study materials into interactive learning resources in four simple steps:\n\nRecord lectures live or upload PDFs, videos, audio files, and documents. Works with any format you need.\n\nOur AI transcribes and analyzes your content, identifying key concepts and creating structured editable notes.\n\nReceive comprehensive notes, flashcards, quizzes, and podcasts tailored to your learning needs.\n\nAccess materials anywhere, share with classmates, and use built-in study modes to ace your exams.\n\nEverything you need to transform your study experience and accelerate your learning journey.\n\nUpload PDFs, videos, or audio files and watch LearnFlux transform them into structured, editable notes instantly.\n\nCreate flashcards, quizzes, and practice tests automatically from your notes. No manual work required.\n\nGet real-time AI guidance with smart highlights, explanations, and personalized learning recommendations.\n\nImport from PDFs, YouTube videos, audio recordings, web articles, and more. LearnFlux handles it all.\n\nMonitor your learning progress with detailed analytics and performance insights on every topic.\n\nShare notes, collaborate with classmates, and learn together with real-time editing and comments.\n\nGet the latest learning tips, study strategies, and updates from LearnFlux.\n\nHave another question? Contact us on Discord or by email.\n\nCan't find what you're looking for? Contact our customer support team\n\nJoin thousands of students who learn faster with LearnFlux.",
    "readingTime": 2,
    "keywords": [
      "journey upload",
      "pdfs videos",
      "learnflux handles",
      "practice tests",
      "structured editable",
      "audio files",
      "flashcards quizzes",
      "learn smarter",
      "editable notes",
      "learning journey"
    ],
    "qualityScore": 1,
    "link": "https://www.learnflux.net/",
    "thumbnail_url": "https://www.learnflux.net/logo.png",
    "created_at": "2025-12-10T06:58:05.397Z",
    "topic": "sports"
  },
  {
    "slug": "silvers-record-break-above-60-shows-how-central-the-metal-ha",
    "title": "Silver's record break above $60 shows how central the metal has become to the AI build-out",
    "description": "AI's rapid growth is driving demand for computing power and silver-rich chips like GPUs and TPUs that rely on high-performance semiconductors.",
    "fullText": "Silver blew past $60 per troy ounce for the first time on Tuesday, extending its blistering rally as traders race into a metal increasingly linked to the build-out of AI infrastructure.\n\nThe milestone caps a stunning run in 2025: silver has more than doubled this year, far outpacing gold's roughly 60% gain and leaving many traditional commodity forecasts in the dust.\n\nWhile expectations of further Federal Reserve easing have helped fuel the move, surging industrial demand and persistent supply tightness are also powering silver's fierce price gains.\n\nVeteran Wall Street strategist Ed Yardeni wrote on Tuesday that silver's explosive rally can't be understood without acknowledging its growing importance to the AI economy.\n\nAs AI data-center construction accelerates and chip demand rises, he argues the metal has effectively become \"another AI play.\"\n\nIndustry association The Silver Institute and Oxford Economics reinforced that view in a report released on Tuesday, saying AI's rapid expansion is helping drive growing demand for silver across digital economy applications.\n\n\"As digitalisation and AI adoption accelerate, so too does the demand for critical materials involved in their applications ‚Äî silver a critical one among them,\" they wrote.\n\nData centers increasingly rely on next-generation chips such as GPUs and TPUs equipped with high-performance semiconductors that use silver in their internal connections and packaging, the association wrote.\n\nAnd as AI moves into autonomous vehicles, robotics, and edge devices, the broader electronics ecosystem is set to draw even more heavily on silver-rich components.\n\nBeyond AI demand, silver remains entrenched in a tight market, with inventories strained and borrowing rates still high despite some easing after October's historic squeeze.\n\n\"This is unquestionably a tight market, stocks are falling, and traders want whatever scraps of silver they can get their hands on,\" wrote Chris Weston, the head of research at Pepperstone, in a Tuesday note.\n\nHe added that retail traders are taking sharp notice of silver's surge, and for good reason.\n\n\"It is an emphatic move, with trend and momentum accounts absolutely bossing the show,\" wrote Weston.\n\nDespite its red-hot rally, the silver trade remains a risky one, Goldman Sachs cautioned in October.\n\nSilver is far more cyclical because of its heavy industrial use, making it a less reliable hedge than gold, the bank said. It also lacks the support of central-bank buying that underpins the yellow metal, Goldman added.",
    "readingTime": 2,
    "keywords": [
      "tight market",
      "demand",
      "silver",
      "rally",
      "traders",
      "metal",
      "silver's",
      "increasingly",
      "easing",
      "industrial"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/silver-price-today-ai-demand-datacenters-infrastructure-short-squeeze-gold-2025-12",
    "thumbnail_url": "https://i.insider.com/6938f9717ecd1d1da6633fa2?width=800&format=jpeg",
    "created_at": "2025-12-10T06:58:01.784Z",
    "topic": "finance"
  },
  {
    "slug": "ai-art-platform-video-and-image-creator-vgenie",
    "title": "AI Art Platform: Video and Image Creator ‚Äì VGenie",
    "description": "Unleash your creativity with VGenie's AI Video & Image Generator. Transform ideas into captivating visuals in seconds. Go from text to art effortlessly. Start now!",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vgenie.ai/home",
    "thumbnail_url": "https://cdn.vgenie.ai/vg-web/landing/og_image.png",
    "created_at": "2025-12-10T03:48:34.927Z",
    "topic": "tech"
  },
  {
    "slug": "police-sketch-maker",
    "title": "Police Sketch Maker",
    "description": "Create professional police sketches instantly. Learn how to make sketch of face with our AI-powered tool used by law enforcement worldwide.",
    "fullText": "Discover your face rate score with our viral AI beauty test, or create professional police sketches from descriptions. Advanced AI technology for entertainment and law enforcement professionals worldwide.\n\nMake picture into sketch from any photo instantly\n\nLearn how to make sketches of people from descriptions\n\nGet police-grade sketch quality in seconds\n\nJoin millions discovering their face rate! Upload your photo, get an AI beauty score, and share with friends. Completely free - just share to unlock your detailed results.\n\nGet your face rate score in seconds with our advanced AI trained on beauty research.\n\nShare your results on social media and challenge your friends to beat your score!\n\nNo hidden costs, no subscriptions. Just share your results to unlock detailed analysis.\n\nUpload a photo or describe a person to create professional police-style sketches using advanced AI technology.\n\nDrag & drop an image here, or click to select\n\nUpload any photo and our AI will extract facial features automatically to create accurate sketches.\n\nDescribe a person using text and generate professional police sketches from your description.\n\nWatch ordinary photos transform into professional police sketches with stunning accuracy and detail.\n\nAdvanced AI algorithms analyze facial features and generate professional police sketches in seconds.\n\nUpload any photo and transform it into a detailed black and white police-style sketch.\n\nGenerate high-resolution sketches suitable for law enforcement and legal proceedings.\n\nExplore our extensive collection of AI-generated police sketches across various use cases.\n\nProfessional-grade AI technology trusted by security professionals worldwide. Transforming the way law enforcement creates and uses facial sketches.\n\nPoliceSketchMaker was developed to provide advanced facial recognition and sketch generation capabilities using cutting-edge AI technology. Our mission is to make professional police sketch capabilities accessible to everyone.\n\nWe believe that accurate visual identification tools should be available to law enforcement agencies, security professionals, and organizations worldwide, regardless of their size or budget.\n\nOur AI models are trained on extensive datasets of facial features and professional police sketch techniques. The system can analyze photographs or text descriptions to generate accurate, detailed sketches.\n\nWe use state-of-the-art machine learning algorithms to ensure high accuracy and consistency in every generated sketch, meeting professional law enforcement standards.\n\nYour data is processed securely with enterprise-grade encryption. Images are not stored on our servers.\n\nGenerate professional police sketches in seconds with our optimized AI processing pipeline.\n\nHigh-resolution sketches suitable for law enforcement, legal proceedings, and professional use.\n\nJoin thousands of professionals who trust PoliceSketchMaker for accurate, reliable facial sketch generation.\n\nWhether you're learning how to make sketch of face or need professional police sketch tools, our platform provides everything you need to create accurate, detailed portraits.\n\nLearn professional techniques for creating realistic facial sketches. Our AI understands the same methods used by police sketch artists to capture unique characteristics and features.\n\nGenerate SEO-friendly alt text and detailed descriptions for any image. Perfect for improving website accessibility and search engine rankings with AI-powered analysis.\n\nDiscover how much police sketch artists make and learn about career opportunities in forensic art, courtroom sketching, and crime scene documentation.\n\nUpload your photo to our AI-powered sketch maker. Our advanced algorithms analyze facial features and convert them into professional police-style sketches in seconds.\n\nProfessional police sketch artists typically earn $45,000-$85,000 annually, while courtroom sketch artists can earn $200-800 per day for high-profile cases.\n\nStart with proper facial proportions, focus on unique features, and use consistent lighting. Our AI incorporates these professional techniques automatically.\n\nAccuracy, attention to detail, and the ability to work with witnesses under pressure. Our platform helps professionals maintain these standards consistently.",
    "readingTime": 3,
    "keywords": [
      "legal proceedings",
      "face rate",
      "algorithms analyze",
      "security professionals",
      "rate score",
      "law enforcement",
      "professionals worldwide",
      "create accurate",
      "facial features",
      "high-resolution sketches"
    ],
    "qualityScore": 1,
    "link": "https://policesketchmaker.it.com/",
    "thumbnail_url": "https://policesketchmaker.it.com/icon.png",
    "created_at": "2025-12-10T03:48:33.681Z",
    "topic": "tech"
  }
]
[
  {
    "slug": "trumps-use-of-ai-images-pushes-boundaries-erodes-public-trust-say-experts",
    "title": "Trump's use of AI images pushes boundaries, erodes public trust, say experts",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong’s arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis.\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,” he said. “By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,” or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they’re seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can’t tell if what they’re watching is fake, and questions whether they would know “what’s real or not when it actually matters, like when the stakes are a lot higher.”\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://apnews.com/article/ai-videos-trump-ice-artificial-intelligence-08d91fa44f3146ec1f8ee4d213cdad31",
    "thumbnail_url": "https://dims.apnews.com/dims4/default/29772b9/2147483647/strip/true/crop/3926x2616+0+1/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F04%2F25%2Fc231e22dce01b274680dc10818de%2F17172084f4f9476b92e116dc22fc2160",
    "created_at": "2026-01-28T18:25:13.699Z",
    "topic": "tech"
  },
  {
    "slug": "a-single-command-to-run-claude-code-inside-lima-vms",
    "title": "A single command to run Claude Code inside Lima VMs",
    "description": "Run AI agents in safe VMs scoped to a local folder - sylvinus/agent-vm",
    "fullText": "sylvinus\n\n /\n\n agent-vm\n\n Public\n\n Run AI agents in safe VMs scoped to a local folder\n\n License\n\n MIT license\n\n 7\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sylvinus/agent-vm",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sylvinus/agent-vm",
    "thumbnail_url": "https://opengraph.githubassets.com/afff19059a7c9a83e1fbbfce6791246021379e585e7faeb991d419af9a77fd1f/sylvinus/agent-vm",
    "created_at": "2026-01-28T18:25:12.991Z",
    "topic": "tech"
  },
  {
    "slug": "apple-plans-to-launch-aipowered-wearable-pin-device-as-soon-as-2027",
    "title": "Apple plans to launch AI-powered wearable pin device as soon as 2027",
    "description": "Apple, OpenAI, Meta, and more are all racing toward AI hardware products.",
    "fullText": "Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.\n\nThe product is said to be “the same size as an AirTag, only slightly thicker,” and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple’s solution, should Apple offload the processing to a synced external device like an iPhone.\n\nThe Information’s sources don’t specify whether that’s the plan, or if it will be a standalone device.\n\nThe wearable will have a single physical button “along its edges” and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user’s surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.\n\nThe report didn’t include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.\n\nNot long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.\n\nApple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea’s conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.\n\nJust a few days ago, it was revealed that Apple will tap Google’s Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.",
    "readingTime": 2,
    "keywords": [
      "smart glasses",
      "product",
      "device",
      "products",
      "apple",
      "wearable",
      "models",
      "release",
      "planned",
      "launch"
    ],
    "qualityScore": 0.9,
    "link": "https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png",
    "created_at": "2026-01-28T18:25:10.388Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-tech-career-coach-do-these-2-things-immediately-after-getting-laid-off-and-avoid-this-common-mistake-when-using-ai",
    "title": "I'm a tech career coach. Do these 2 things immediately after getting laid off — and avoid this common mistake when using AI.",
    "description": "Amazon announced it's cutting 16,000 jobs. The career coach Kyle Elliott said you should use these two critical tools to help you find a job after a layoff.",
    "fullText": "This as-told-to essay is based on a conversation with Kyle Elliott, 33, a career coach who lives in California. The following has been edited for length and clarity.\n\nGetting laid off is very traumatic — and it's becoming more common.\n\nI've been a full-time career coach to tech employees at startups and in Big Tech since 2017, and I've seen how layoffs have become more visible in recent years.\n\nI help clients navigate life after a layoff, including what role they want next and how to apply for new jobs.\n\nAmazon has announced new plans to cut staff, and I want affected employees to remember that they are coming from one of the world's top companies.\n\nPeople will want them, and they will find something.\n\nWhen people reach out to me for coaching after a layoff, many have a scarcity mindset and feel like they have to apply for any job.\n\nFor some people who urgently need to pay rent or put food on the table, that's necessary. But in other cases, it makes sense to take a beat and evaluate what you're really looking for in your next role.\n\nThe very first thing I ask clients to do is create a list of \"must-haves\" and \"dealbreakers\" for their next job. What are their salary expectations? Will they only work remotely? Are they willing to relocate? If you write the list before you start interviewing, you can act from a place of logic rather than panic.\n\nThe second step is to update your résumé and LinkedIn profile, which are two of your most critical tools in today's market. You're going to submit a résumé with almost every application, and having an up-to-date LinkedIn account puts you in a good position if potential employers check it or recruiters go looking for talent on the platform.\n\nYou want to optimize for the roles you're looking for in 2026, which means that if you were an engineer when you joined Amazon but are now a director, you want to make sure that's reflected on your LinkedIn page.\n\nI've seen clients turn to quick hacks for their job search, like asking AI to tailor their résumé or using it to find and apply to roles for them. But if everyone does that, you don't stand out.\n\nI can usually tell quickly if someone's written their résumé with AI. For example, they'll be applying to a systems engineer role, and it won't even have the phrase \"systems engineer\" in it.\n\nEveryone thinks only AI is reading their résumé, but I have clients who work in talent acquisition and HR — the humans who are still involved in the recruitment process. Humans hire other humans, even at big companies.\n\nIn the age of AI, be more human. Take a step back and think, if you were a human looking at this résumé, what would you want to see? Then put those phrases near the top, rather than using AI to create generic slop.\n\nI'd suggest creating a master résumé that you can spend 20 minutes tailoring for different roles. If you're using AI, use it more like an extra tool, rather than the thing that's driving your job search.\n\nLayoffs are normal now, especially in the tech industry, and there's much less stigma around them.\n\nBut there's more competition in the job market, because it's easier to apply for jobs with AI, for example, so the challenges around layoffs are different nowadays.\n\nIn today's job market, it's important to figure out what's unique about you. Lots of people will meet the job requirements, so you need to communicate why the company should hire you over the thousands of other applicants.\n\nOne thing that can help you is to look back at performance reviews and identify things people repeatedly say about you. You can try asking three to five people to share what makes you fabulous and to give examples. I've found that clients are surprised by the feedback they receive.",
    "readingTime": 4,
    "keywords": [
      "career coach",
      "systems engineer",
      "job search",
      "job market",
      "résum",
      "clients",
      "i've",
      "apply",
      "you're",
      "looking"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-career-coach-do-after-lay-off-common-mistake-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6979fb95e1ba468a96aad5d3?width=1084&format=jpeg",
    "created_at": "2026-01-28T18:25:10.354Z",
    "topic": "finance"
  },
  {
    "slug": "meta-earnings-updates-wall-street-is-focused-on-ai-capex-heading-into-q4-results",
    "title": "Meta earnings updates: Wall Street is focused on AI capex heading into Q4 results",
    "description": "Meta will report earnings for Q4 after the closing bell on Wednesday. The company will hold a call with analysts at 4:30 p.m. ET.",
    "fullText": "Meta Platforms is gearing up to report its fourth-quarter results and all eyes are on its ambitious AI plans, specifically its outlook for more capex spending in the coming year.\n\nSome Wall Street analysts say the Facebook parent's updates on AI infrastructure spending could overshadow other areas of its results, such as growth in its ad business.\n\nMeta will report earnings after the closing bell, and will hold a call with analysts around 4:30 p.m. ET.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\nInvestors are in a \"holding pattern\" to see if Meta's next big AI model is a blockbuster event, Bernstein analyst Mark Shmulik wrote in a note on Tuesday. With Meta's next model, codenamed \"Avocado,\" rumored to launch this spring, we'll be listening out for any hints at what it might bring.\n\nMeta's family of AI models, known as Llama, has so far received a lukewarm reception, but even if the new offerings aren't enough to put Meta in the leading pack, Shmulik posits it may not be a disaster so long as Meta can pair with another lab for its models.\n\n\"While fears of partnering with a competitor such as Google or OpenAI are valid, we'd offer Anthropic (private) as an ideal partner that has so far shown little appetite to go after consumer,\" he wrote.\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 35% increase from levels on Wednesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nThe analyst added that this has prompted Rothschild to increase its full-year capex projection for Meta to $117.1 billion.\n\nGoldman analysts remain focused on Meta's capex plans, which they believe will continue to drive growth into 2026 and beyond. The bank recently raised its spending projections for the company, already above analyst estimates, noting that it sees upward pressure on consensus capex estimates.\n\n\"On the next earnings call, we expect investors will be focused on any updates on the work of the Meta Superintelligence Lab, the timing of any foundational model work and/or any strategies with respect to consumer or enterprise utility around AI,\" Goldman analysts stated.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\n\"In our view, Meta is positioned favorably — especially in the long-term — as it doubles down on an AI investment cycle,\" Black said.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nHe added that his team expects Meta's capex spending to come in between $109 and $114 billion for the year, likely above Wall Street consensus of $110 billion.",
    "readingTime": 5,
    "keywords": [
      "event bernstein",
      "codenamed avocado",
      "avocado rumored",
      "james cordwell",
      "zuckerberg unleashed",
      "ceo truly",
      "black notes",
      "pack shmulik",
      "shmulik posits",
      "company's ceo"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-earnings-stock-price-ai-capex-live-updates-2026-1",
    "thumbnail_url": "https://i.insider.com/69611cca04eda4732f2ec680?width=1200&format=jpeg",
    "created_at": "2026-01-28T18:25:09.621Z",
    "topic": "finance"
  },
  {
    "slug": "china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "title": "China lags behind US at AI frontier but could quickly catch up, say experts",
    "description": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n Continue reading...",
    "fullText": "Beijing’s AI policy is focused on real-life applications but Chinese companies are beginning to articulate their own grand visions\n\nStanding on stage in the eastern China tech hub of Hangzhou, Alibaba’s normally media-shy CEO made an attention-grabbing announcement. “The world today is witnessing the dawn of an AI-driven intelligent revolution,” Eddie Wu told a developer conference in September. “Artificial general intelligence (AGI) will not only amplify human intelligence but also unlock human potential, paving the way for the arrival of artificial superintelligence (ASI).”\n\nASI, Wu said, “could produce a generation of ‘super scientists’ and ‘full-stack super engineers’”, who would “tackle unsolved scientific and engineering problems at unimaginable speeds”.\n\nWu also announced plans to invest 380bn yuan (£40bn) in AI infrastructure over the next three years, news that sent Alibaba stocks soaring to their highest in nearly four years.\n\nWu’s foray into the existential, techno-frontier rhetoric normally deployed by western tech CEOs such as OpenAI’s Sam Altman and DeepMind’s Demis Hassabis caught the attention of observers. “Wu’s ASI speech represents a breakthrough,” the tech writer Afra Wang wrote in her China AI newsletter, Concurrent. “Major Chinese companies are beginning to articulate their own grand visions that carry the flavour of future prophecy.”\n\nAGI, a theoretical state of AI where a highly autonomous system is able to do a human’s job, has become the preoccupation of American tech companies such as OpenAI and DeepMind. Many see it as the next frontier of civilisation, and are in competition with each other, and China, to get there. In May, the president of Microsoft, Brad Smith, told a US Senate committee on AI that the “race between the United States and China for international influence likely will be won by the fastest first mover”.\n\nMany in Washington have internalised these fears. The US-China economic and scurity review commission has recommended that Congress “establish and fund a Manhattan Project-like program dedicated to racing to and acquiring an artificial general intelligence (AGI) capability”. The Manhattan Project was a second world war-era research operation to produce nuclear weapons.\n\nIn China, many saw Wu’s speech as articulating the vision of a bold, singular tech company, but not one that represented China’s overall AI industry.\n\n“China certainly has research groups working towards AGI. But most AI companies are working towards better applications,” said Ya-Qin Zhang, the dean of Tsinghua University’s Institute for AI Industry Research and former president of the tech company Baidu.\n\nA combination of limited computing power, a pragmatic approach to technology and a keen awareness of the present day potential of AI has steered China’s national AI policy towards real-life applications rather than frontier research.\n\nIn August, the Chinese government published its highly anticipated “AI+ strategy”. The policy document outlined how AI could turbocharge China’s development goals, such as by using AI to improve medical diagnoses and make supply chains more efficient. But it made no mention of AGI.\n\n“The Chinese government is intently focused on reaping the benefits of AI in the here and now and in the near future through diffusion and application of AI across the economy, society, defence, and other areas,” said Julian Gewirtz, a former senior director for China and Taiwan at the White House national security council. “Despite its goal to ‘catch up and surpass’ the United States, we shouldn’t assume that the Chinese Communist party has bought into the idea that AGI is imminent.”\n\n“If you’re just looking at what has been officially published … there is no clear acknowledgment of AGI at all,” said Selina Xu, a China tech analyst. Xu noted that Xi Jinping, China’s leader, had a history of preferring the physical economy to more intangible forces.\n\n“It’s a very different narrative from the AGI race as a lot of people in DC see it,” Xu said.\n\nOne of the biggest factors guiding this strategy is the fact that US sanctions have prevented Chinese companies from acquiring the world’s most sophisticated semiconductors, which are needed for advanced AI research.\n\nWashington has banned the sale of hi-tech microchips to China in an effort to rein in the country’s AI development. Nvidia, the world’s leading chipmaker, then developed more basic semiconductors specifically for the Chinese market. In December, Washington approved the Nvidia’s second-most advanced chips, the H200s, for sale in China. But Beijing has reportedly told custom agents that the chips cannot be imported into China, as the government seeks to break the country’s reliance on overseas technology.\n\nChina insists that “necessity is the mother of invention” and points to the success of companies such as DeepSeek as proof that the US restrictions will merely spur innovation. DeepSeek’s founder, Liang Wenfeng, is one of the few Chinese tech leaders who, like Alibaba’s Wu, has openly expressed an interest in AGI.\n\nBut until China is able to produce its own advanced semiconductors at scale, most tech companies feel it is more profitable to use the hardware they already have to focus on AI applications rather than AGI.\n\nAnother factor guiding the US-China tech competition is the availability of datacentres and the energy to power them. In November, Jensen Huang, the CEO of Nvidia, said China would “win the AI race” in part because of its energy subsidies for datacentres.\n\nThe subsidies were reportedly introduced after Chinese tech companies complained of higher electricity bills caused by the domestic semiconductors they are obliged to use, which are less efficient than Nvidia’s. In a sign of how determined China is to break its reliance on imported technology, Reuters reported that any datacentres in receipt of state funds could only use domestic chips.\n\nSuch measures would reduce Nvidia’s competitive advantage in China and boost domestic chip producers, such as Huawei.\n\nSince 2021, China has reportedly poured $100bn into support for AI datacentres.\n\nBut there are signs that the boom may have been overzealous. A recent report from the China Academy of Information and Communications Technology said that nationwide, the utilisation rate for AI datacentres was 32%.\n\nIn a recent op-ed in China Economic Weekly, Rao Shaoyang, the director at the China Telecom Research Institute, wrote that in some regions of China, the computing power industry was operating in a similar fashion to China’s beleaguered property sector: build first, find buyers later. He cautioned against “blindly building intelligent computing centres” and said local computing power demand should be considered before building new datacentres.\n\nDespite the surplus in more general computing power, many experts believe China still does not have chips that are sophisticated enough to explore frontier research in AGI. But analysts note that the mood could change quickly.\n\n“The current status quo is highly fluid, and Xi Jinping has explicitly declared an ambition to lead the world in AI,” said Gewirtz. “So the fact that China construes that goal one way at this snapshot moment in time does not give me any comfort that in a year they’re going to construe it the same way.”\n\nAdditional research by Lillian Yang",
    "readingTime": 6,
    "keywords": [
      "intelligence agi",
      "grand visions",
      "real-life applications",
      "applications rather",
      "chinese tech",
      "frontier research",
      "china tech",
      "agi but",
      "datacentres",
      "computing"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2026/jan/28/china-lags-behind-us-at-ai-frontier-but-could-quickly-catch-up-say-experts",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8cc6bbd0024f4ba8485616485bd55f9c34d98452/538_0_4167_3333/master/4167.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=12e8d9082c7ad02aa672977a89beda90",
    "created_at": "2026-01-28T18:25:09.486Z",
    "topic": "tech"
  },
  {
    "slug": "google-deepmind-launches-ai-tool-to-help-identify-genetic-drivers-of-disease",
    "title": "Google DeepMind launches AI tool to help identify genetic drivers of disease",
    "description": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n Continue reading...",
    "fullText": "AlphaGenome can analyse up to 1m letters of DNA code at once and could pave way for new treatments\n\nResearchers at Google DeepMind have unveiled their latest artificial intelligence tool and claimed it will help scientists identify the genetic drivers of disease and ultimately pave the way for new treatments.\n\nAlphaGenome predicts how mutations interfere with the way genes are controlled, changing when they are switched on, in which cells of the body, and whether their biological volume controls are set to high or low.\n\nMost common diseases that run in families, including heart disease and autoimmune disorders, as well as mental health problems, have been linked to mutations that affect gene regulation, as have many cancers, but identifying which genetic glitches are to blame is far from straightforward.\n\n“We see AlphaGenome as a tool for understanding what the functional elements in the genome do, which we hope will accelerate our fundamental understanding of the code of life,” Natasha Latysheva, a DeepMind researcher, told a press briefing on the work.\n\nThe human genome runs to 3bn pairs of letters – the Gs, Ts, Cs and As that comprise the DNA code. About 2% of the genome tells cells how to make proteins, the building blocks of life. The rest orchestrates gene activity, carrying the crucial instructions that dictate where, when and how much individual genes are switched on.\n\nThe researchers trained AlphaGenome on public databases of human and mouse genetics, enabling it to learn connections between mutations in specific tissues and their impact on gene regulation. The AI can analyse up to 1m letters of DNA code at once and predict how mutations will affect different biological processes.\n\nThe DeepMind team believes the tool will help scientists map out which strands of genetic code are most essential for the development of particular tissues, such as nerve and liver cells, and pinpoint the most important mutations for driving cancer and other diseases. It could also underpin new gene therapies by allowing researchers to design entirely new DNA sequences – for example, to switch on a certain gene in nerve cells but not in muscle cells.\n\nCarl de Boer, a researcher at the University of British Columbia in Canada, who was not involved in the work, said: “AlphaGenome can identify whether mutations affect genome regulation, which genes are impacted and how, and in what cell types. A drug could then be developed to counteract this effect.\n\n“Ultimately, our goal is to have models that are so good we don’t have to do an experiment to confirm their predictions. While AlphaGenome represents a significant innovation, achieving this goal will require continued work from the scientific community.”\n\nSome scientists have already begun using AlphaGenome. Marc Mansour, a clinical professor of paediatric haemato-oncology at UCL, said it marked a “step change” in his work to find genetic drivers for cancer.\n\nGareth Hawkes, a statistical geneticist at the University of Exeter, said: “The non-coding genome is 98% of our 3bn base pair genome. We understand the 2% fairly well, but the fact that we’ve got AlphaGenome that can make predictions of what this other 2.94bn base pair region is doing is a big step forward for us.”",
    "readingTime": 3,
    "keywords": [
      "dna code",
      "base pair",
      "genetic drivers",
      "gene regulation",
      "mutations",
      "cells",
      "letters",
      "researchers",
      "tool",
      "scientists"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/jan/28/google-deepmind-alphagenome-ai-tool-genetics-disease",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3f4612605000567b9e02c02efc58d3c631ac766a/802_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=78b47365d5b61d906daeb3627e153a8c",
    "created_at": "2026-01-28T18:25:09.444Z",
    "topic": "science"
  },
  {
    "slug": "how-gen-z-uses-gen-aiand-why-it-worries-them",
    "title": "How Gen Z Uses Gen AI—and Why It Worries Them",
    "description": "When it comes to gen AI, the habits, attitudes, and ideas of Gen Z are a harbinger of the future of work—and how the rest of us will feel when we get there. A survey of nearly 2,500 U.S. adults between the ages of 18 and 28 years old revealed some surprising findings. Most members of Gen Z use gen AI and, contrary to conventional wisdom, Gen Z’s relationship with these tools is more pragmatic than personal.",
    "fullText": "How Gen Z Uses Gen AI—and Why It Worries Them by Benjamin Lira, Dunigan Folk, Lyle Ungar and Angela L. DuckworthJanuary 28, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintAs go the young, so goes society. Young adults were early adopters of cell phones, social media, and the internet. Now all of these technologies are universal. So how are members of Gen Z using generative AI today? How do they feel about it? What promising use cases have they discovered? And what are the implications for employers?",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/how-gen-z-uses-gen-ai-and-why-it-worries-them",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_2214975842.jpg",
    "created_at": "2026-01-28T18:25:09.162Z",
    "topic": "business"
  },
  {
    "slug": "hong-kong-scientists-double-warning-time-for-extreme-weather-with-ai",
    "title": "Hong Kong scientists double warning time for extreme weather with AI",
    "description": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.",
    "fullText": "STORY: As extreme weather becomes more frequent due to climate change,a new system driven by artificial intelligence could increase warning times for authorities.\"We hope to use AI and use our satellite data to help better prediction of extreme weather so we can be better prepared.”:: On AIA team from Hong Kong University of Science and Technology has built a new AI framework known as the Deep Diffusion Model based on Satellite Data.Researchers trained the model on satellite observations and the analysis of convective cloud systems, using thousands of samples to generate more precise forecasts.Potentially predicting intense thunderstorms and heavy downpours up to four hours ahead.Current models only give 20 minutes to two hours warning.Hui Su, who led the project, said satellites can detect cloud formation earlier than other forecasting systems such as radar.:: Hui Su, Hong Kong University of Science and Technology''I think combining the strength of AI and satellite knowledge, we actually could have some revolutionary advancement in weather forecasting. So in this backdrop of climate change, I think accurate prediction of extreme weather (is) extremely important to reduce the economic losses associated with extreme weather.'':: CSU/CIRA & NOAA/NESDISDeveloped in collaboration with China’s meteorological authorities, the model has boosted accuracy by more than 15%, according to the team.Researchers said it has the potential to deliver global convective weather forecasts if sufficient satellite observation data is available.",
    "readingTime": 2,
    "keywords": [
      "hong kong",
      "kong university",
      "extreme weather",
      "climate",
      "prediction",
      "science",
      "convective",
      "cloud",
      "systems",
      "hours"
    ],
    "qualityScore": 0.65,
    "link": "https://www.yahoo.com/news/videos/hong-kong-scientists-double-warning-175919489.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/3veGT8tryJNVKP1yZmuBtQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://cf-images.us-east-1.prod.boltdns.net/v1/jit/6415665815001/cc639107-9d99-4da6-a306-1eb8059926ab/main/1280x720/50s445ms/match/image.jpg",
    "created_at": "2026-01-28T18:25:07.335Z",
    "topic": "news"
  },
  {
    "slug": "introducing-react-best-practices",
    "title": "Introducing: React Best Practices",
    "description": "We've encapsulated 10+ years of React and Next.js optimization knowledge into react-best-practices, a structured repository optimized for AI agents and LLMs.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vercel.com/blog/introducing-react-best-practices",
    "thumbnail_url": "https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/5VCSTefWazPIvZlDl3ZFbd/8996ca467f505fcec7d4f6fc19f9f1bd/image__15_.png",
    "created_at": "2026-01-28T12:27:43.743Z",
    "topic": "tech"
  },
  {
    "slug": "ai-kind-of-sucks-at-retouching-study-says",
    "title": "AI Kind of Sucks at Retouching, Study Says",
    "description": "As photographers lean more towards AI for retouching purposes, a new study finds how AI is not what people think it is supposed to be.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.thephoblographer.com/2026/01/27/ai-vs-human-retouching-the-quality-gap-is-bigger-than-expected/",
    "thumbnail_url": "https://www.thephoblographer.com/wp-content/uploads/2025/10/Screenshot-2025-10-14-at-18.52.32.jpg",
    "created_at": "2026-01-28T12:27:41.769Z",
    "topic": "tech"
  },
  {
    "slug": "meta-allowed-minors-access-to-sextalking-chatbots-despite-staff-concerns-lawsuit-alleges",
    "title": "Meta allowed minors access to sex-talking chatbots despite staff concerns, lawsuit alleges",
    "description": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n Continue reading...",
    "fullText": "Filing by New Mexico’s attorney general includes Meta staff emails objecting to AI companion policy\n\nMark Zuckerberg, Meta’s chief executive, approved allowing minors to access artificial intelligence chatbot companions that safety staffers warned were capable of sexual interactions, according to internal Meta documents filed in a New Mexico state court case and made public on Monday.\n\nThe lawsuit – brought by the state’s attorney general, Raul Torrez, and scheduled for trial next month – alleges Meta “failed to stem the tide of damaging sexual material and sexual propositions delivered to children” on Facebook and Instagram.\n\nThe filing on Monday included internal Meta employee emails and messages obtained by the New Mexico attorney general’s office through legal discovery. The state alleges they show that “Meta, driven by Zuckerberg, rejected the recommendations of its integrity staff and declined to impose reasonable guardrails to prevent children from being subject to sexually exploitative conversations with its AI chatbots”, the attorney general said in the filing. Meta announced last week that it had removed teen access to AI companions entirely, pending creation of a new version of the chatbots.\n\nIn the communications, some of Meta’s safety staff expressed objections the company was building chatbots geared for companionship, including sexual and romantic interactions with users. The artificial intelligence chatbots were released in early 2024. The documents cited in the state’s filing Monday don’t include messages or memos authored by Zuckerberg.\n\nAndy Stone, a Meta spokesperson, on Monday said the state’s portrayal was inaccurate and relied on selective information: “This is yet another example of the New Mexico attorney general cherrypicking documents to paint a flawed and inaccurate picture.”\n\nMessages in the filing showed safety staff had special concern about the bots being used for romantic scenarios between adults and minors under the age of 18, referred to as “U18s”.\n\n“I don’t believe that creating and marketing a product that creates U18 romantic AI’s for adults is advisable or defensible,” wrote Ravi Sinha, head of Meta’s child safety policy, in January 2024.\n\nIn reply, Antigone Davis, Meta’s global safety head, agreed that safety staff should push to block adults from creating underage romantic companions because “it sexualizes minors”. Sinha and Davis did not respond to requests for comment.\n\nAccording to one February 2024 message, a Meta employee whose name was redacted relayed that Zuckerberg believed that AI companions should be blocked from engaging in sexually “explicit” conversations with at least younger teens and that adults should not be able to interact with “U18 AIs for romance purposes”.\n\nA summary of a meeting dated 20 February 2024, said the CEO believed the “narrative should be framed around … general principles of choice and non-censorship”, that Meta should be “less restrictive than proposed”, and that he wanted to “allow adults to engage in racier conversation on topics like sex”.\n\nStone said the documents did not support New Mexico’s case. “Even these select documents clearly show Mark Zuckerberg giving the direction that explicit AIs shouldn’t be available to younger users and that adults shouldn’t be able to create under 18 AIs for romantic purposes.”\n\nMessages between two employees from March 2024 state that Zuckerberg had rejected creating parental controls for the chatbots, and that staffers were working on “Romance AI chatbots” that would be allowed for users under the age of 18.\n\nWe “pushed hard for parental controls to turn GenAI off – but GenAI leadership pushed back stating Mark decision”, one employee wrote in that exchange.\n\nNick Clegg, who was Meta’s head of global policy until early 2025, said in an email included in the court documents he thought Meta’s approach to sexualized AI companions was unwise.\n\nExpressing concern that sexual interactions could be the dominant use case for Meta’s AI companions by teenage users, Clegg said: “Is that really what we want these products to be known for (never mind the inevitable societal backlash which would ensue)?” Clegg did not respond to a request for comment.\n\nMeta’s AI chatbot policies eventually came to light, prompting a backlash in the US Congress and elsewhere.\n\nA Wall Street Journal article in April 2025 found that Meta’s chatbots included overtly sexualized underage characters and that they engaged in all-ages sexual roleplay, including graphic descriptions of prepubescent bodies. Reuters reported in August that Meta’s official guidelines for chatbots stated that it is “acceptable to engage a child in conversations that are romantic or sensual”. In response to the report, Meta said it was changing its policies and that the internal document granting such approval had been in error.",
    "readingTime": 4,
    "keywords": [
      "mexico attorney",
      "artificial intelligence",
      "parental controls",
      "internal meta",
      "meta employee",
      "sexual interactions",
      "safety staff",
      "new mexico",
      "new mexico’s",
      "meta’s ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/meta-lawsuit-minors-chatbots",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f6236f51e29389309cca0c8934bf7c5624b78619/289_0_4008_3208/master/4008.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7713cdfc7fbe29ee40fec93f7bfdb653",
    "created_at": "2026-01-28T12:27:37.644Z",
    "topic": "tech"
  },
  {
    "slug": "kyber-yc-w23-is-hiring-a-staff-engineer",
    "title": "Kyber (YC W23) Is Hiring a Staff Engineer",
    "description": "At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.\nOver the past 18 months, we’ve:\n>30x’d revenue and are profitable.\nLanded multiple six and seven figure, multi-year contracts with leading insurance enterprises.",
    "fullText": "At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.\n\nOver the past 18 months, we’ve:\n\nKyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.\n\nWe're seeking a Staff Engineer with a clear line of sight to CTO. This role is ideal for someone who is already operating as a 10x engineer, thrives in early stage environments, and is excited to design and scale mission-critical AI systems from first principles.\n\nJoin us in building and scaling a game-changing enterprise product powered by state-of-the-art AI. At Kyber, your contributions will directly impact how businesses handle some of their most critical workflows and customer interactions.\n\nIf you’re obsessed with building, AI, and transforming enterprise workflows, we’d love to hear from you!\n\nWe want to hear from extraordinary individuals who are ready to shape the future of enterprise documents. To stand out, ask someone you’ve worked with to send your resume or LinkedIn profile, along with a brief 2-3 sentence endorsement, directly to arvind [at] askkyber.com.\n\nReferrals matter. They help us understand the impact you’ve already had and the kind of teammate you’ll be. A strong referee can elevate your application, so choose someone who knows your skills and character well.\n\nApply today and help us bring enterprise documents into the AI-native age.",
    "readingTime": 2,
    "keywords": [
      "enterprise documents",
      "workflows",
      "someone",
      "we're",
      "ai-native",
      "templates",
      "directly",
      "impact",
      "you’ve",
      "kyber"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/kyber/jobs/GPJkv5v-staff-engineer-tech-lead",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/36d823535a32695e6b82b2371e3ed3df2496af99.png?1754429935",
    "created_at": "2026-01-28T12:27:37.281Z",
    "topic": "jobs"
  },
  {
    "slug": "western-digital-vs-micron-which-data-storage-stock-has-more-upside",
    "title": "Western Digital vs. Micron: Which Data Storage Stock Has More Upside?",
    "description": "Micron edges out Western Digital as AI-driven memory demand, tight supply and a cheaper valuation make MU the more attractive pick now.",
    "fullText": "Both Western Digital Corporation WDC and Micron Technology MU are major players in the memory and storage ecosystem, with exposure to NAND flash and data-center demand tied to AI, cloud computing and cyclical memory pricing. Western Digital and Micron are both well-positioned to benefit from global data growth through storage and memory solutions, making them closely watched by investors betting on AI infrastructure and cloud expansion.\n\nBoth operate in the broader data storage ecosystem, but they play distinct roles. Western Digital is traditionally known for HDDs and, increasingly, enterprise storage systems. It also has flash memory exposure, though that part was largely spun off through SanDisk in 2025. Micron is a pure memory champion in DRAM, HBM and NAND flash. Both have soared in value recently, driven by demand tied to data growth and AI infrastructure. But their futures hinge on different markets and technology cycles.\n\nHowever, if investors must choose between the two, which stock should they consider based on business models, growth drivers, risks, financials & valuation, outlooks and final verdict?\n\nAI adoption is accelerating across industries, driving innovation, reshaping business models and advancing digital transformation through higher productivity and richer user experiences. As agentic AI scales and multimodal LLMs become mainstream, WDC is seeing growing AI use cases that are fueling sustained demand for data infrastructure. AI is both a major consumer and creator of data, transforming how data is generated, stored, scaled and monetized. As data volumes expand rapidly, HDDs remain the most reliable, scalable and cost-effective solution for storing the zettabytes of data powering the AI-driven economy.\n\nAI is improving efficiency across corporate functions. At the same time, rising AI and data-driven workloads at hyperscalers are boosting demand for WDC’s storage solutions. Customers are shifting to higher-capacity drives, leading to strong shipments of its latest ePMR products, including up to 26TB CMR and 32TB UltraSMR drives. WDC continues to scale ePMR technology, invest in advanced media and wafer innovation, and use automation and AI to increase manufacturing capacity and efficiency. The reliability, scalability and cost advantages of Western Digital’s ePMR and UltraSMR drives continue to drive data center success, with the company preparing to build on this momentum through next-generation HAMR technology.\n\nStrong customer commitments—extending into 2027—underscore confidence in its roadmap and its role in the AI data economy. HAMR development is progressing well, with customer qualification beginning in early 2026 and volume production targeted for the first half of 2027. Meanwhile, next-gen ePMR drives will complete qualification by early 2026, supporting a smooth transition. Management expects continued revenue growth and improved profitability in the fiscal second quarter, driven by strong data center demand and higher-capacity drive adoption. At the mid-point of its guidance, Western Digital anticipates non-GAAP revenues of $2.9 billion (+/- $100 million), up 20% year over year.",
    "readingTime": 3,
    "keywords": [
      "nand flash",
      "ultrasmr drives",
      "business models",
      "storage ecosystem",
      "demand tied",
      "western digital",
      "memory",
      "technology",
      "growth",
      "epmr"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/western-digital-vs-micron-data-144000249.html",
    "thumbnail_url": "https://s.yimg.com/os/en/zacks.com/5fc95e37867e2a80f869083d472f6292",
    "created_at": "2026-01-28T12:27:35.814Z",
    "topic": "finance"
  },
  {
    "slug": "limy-built-a-platform-that-helps-brands-optimize-for-the-era-of-ai-agents-see-the-pitch-deck-that-helped-it-raise-10",
    "title": "Limy built a platform that helps brands optimize for the era of AI agents. See the pitch deck that helped it raise $10 million.",
    "description": "Limy raised $10 million from investors including Flybridge and a16z to help brands boost their visibility to AI agents.",
    "fullText": "The race to build the \"agentic internet\" is on, with consumers expected to increasingly offload tasks like travel and grocery shopping to autonomous software. It presents brands with a new challenge: how to stand out when the customer is an AI agent rather than a human.\n\nFounded in New York in 2024, Limy has built a platform to help companies better understand how AI agents decide which brands and products to recommend to their users.\n\nLimy is set to announce on Wednesday that it has raised $10 million in seed funding led by venture capital firm Flybridge. A16z's Speedrun program, Axiom, Clarim, JRV, AnD, and Communitas also participated.\n\nLimy plugs into a brand's content delivery network, such as Cloudflare, to detect when an AI agent visits their website. It then analyzes which content the agent fetched and the prompt a user entered into a chatbot like ChatGPT or Gemini that triggered the visit.\n\nArmed with that information, Limy produces insights for brands about the types of prompts that are surfacing their products in AI answers and whether the agent's visit to their website led to a purchase. Brands can apply those insights to help boost their visibility within large language models. Limy makes money through a tiered subscription model based on a company's size and the capabilities it requires.\n\nAviv Shamny, Limy's CEO, told Business Insider in an interview that his company differs from other startups offering generative engine optimization services because these competitor analytics tools typically track human clicks and pageviews.\n\nAgents are \"going in through the pipes,\" he said. \"They behave completely differently.\"\n\nShamny said connecting website visits from agents to real business metrics is a \"complicated vector search process,\" which helps set Limy up to be a player as advertising gets introduced to AI chatbots.\n\nOpenAI announced this month that it is testing ads on ChatGPT. Google last year introduced ads to the AI Overviews on its search results page and within its AI Mode, which allows users to ask follow-up questions.\n\n\"We're right at that junction between what agents are looking for, why they're surfacing ads, how these ads are even being interpreted by these agents,\" and whether those ads will lead to an eventual sale, Shamny said.\n\nTying a prompt to a conversion means Limy could tell a brand like Nike that the prompt \"best running shoes for men running a marathon\" had generated $10 million in sales over a quarter, and that this is the type of prompt or topic that a brand should double down on advertising against, Shamny said.\n\nShamny said Limy intends to invest its new funding in its sales, marketing, and growth teams as the company expands globally. He expects the team will grow to around 120 people by the end of the year, up from about 25.\n\nCheck out the pitch deck Limy used to secure its $10 million seed investment, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nShamny said AI agents will increasingly carry out tasks for consumers, such as booking flights or shopping.\n\nInstead, brands need to think about optimizing their web presence for AI agents.\n\nThe slide depicts someone asking ChatGPT for ideas for a housewarming gift for a friend, a hotel in Las Vegas, and a playlist for a party.\n\nAI agents are evaluating, choosing, and acting on behalf of humans, Limy says.\n\nLimy offers a way for brands to see how AI engines crawl, fetch, and index their web pages.\n\nThe slide shows a section of Limy's user interface that tracks site visits from AI bots.\n\nLimy wants to corner the markets of attribution, analytics, agentic ads, and agentic commerce.\n\nIt then detects and analyzes AI bot visits, presenting actionable insights for brands.\n\nThe slide shows how a luggage brand could use Limy's tool to see how a particular suitcase stacks up in product rankings within LLMs.\n\nLimy says brands can use its insights to ensure they're placing ads against the best topics and prompts to drive revenue.\n\n\"Our North Star is to build the internet for agents,\" Shamny said. \"When agents are going to dominate the web, we're giving the ability for brands to be a part of the conversation.\"\n\nWhile this slide is redacted, customers listed on its website include AstraZeneca, Kia, and Samsung.",
    "readingTime": 4,
    "keywords": [
      "agents",
      "brands",
      "visits",
      "website",
      "prompt",
      "insights",
      "slide",
      "limy",
      "agentic",
      "agent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/limy-raises-millions-brands-boost-ai-agent-visibility-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/6978a0acd3c7faef0eccf85b?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.971Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-ceo-warns-tech-titans-not-to-dismiss-the-publics-ai-concerns-youre-going-to-get-a-mob-coming-for-you",
    "title": "Anthropic CEO warns tech titans not to dismiss the public's AI concerns: 'You're going to get a mob coming for you'",
    "description": "Anthropic CEO Dario Amodei says that AI leaders need to embrace policies that better distribute the benefits of AI — or they'll face backlash.",
    "fullText": "Anthropic CEO Dario Amodei has a grave warning for fellow AI titans who dismiss the public's concerns about AI.\n\n\"You can't just go around saying we're going to create all this abundance, a lot of it is going to go to us, and we're going to be trillionaires, and no one's going to complain about that,\" Amodei told Axios in an interview. \"Look, you're going to get a mob coming for you if you don't do this in the right way.\"\n\nIt comes after Amodei published a sprawling 19,000-word essay on Monday called \"The Adolescence of Technology,\" in which he laid out his vision for the future of AI.\n\nThat includes his belief that the technology will turn the heads of some tech companies into trillionaires, and that humanity as a whole needs to treat AI like a \"serious civilizational challenge.\"\n\nIn both the interview and in his essay, Amodei called for more robust tax policies to ensure a broader distribution of the \"abundance\" that AI will create.\n\n\"I don't think this is the tax policies of old,\" Amodei said in the interview. \"This is for a world where people are trillionaires.\"\n\nAmodei didn't go into detail, other than writing in the essay that the taxation could be \"general or could be targeted against AI companies in particular,\" and that failing to proactively pursue those tax policies would lead to badly designed ones.\n\nHe also said that he'd advised lawmakers, in addition to pursuing more progressive taxation, to support AI transparency legislation and to cut off the supply of chips to China.\n\nAmodei sticks out from many other tech executives in that he's often viewed as taking a more \"doomer\" view of AI. But he also says that the public's concerns about AI aren't always \"well-targeted.\"\n\nSpecifically, he argued that data centers don't \"use that much water,\" while concerns about electricity bills are \"understandable\" but only a minor part of the conversation.\n\n\"I think in the long run, it's not about power bills, it's about enormous abundance, and whether they get their piece of the abundance,\" Amodei said in the interview.",
    "readingTime": 2,
    "keywords": [
      "public's concerns",
      "tax policies",
      "abundance",
      "interview",
      "trillionaires",
      "don't",
      "essay",
      "amodei",
      "we're",
      "create"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-ceo-dario-amodei-ai-wealth-distribution-warning-mob-2026-1",
    "thumbnail_url": "https://i.insider.com/6978d249a645d11881880aae?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.917Z",
    "topic": "finance"
  },
  {
    "slug": "anduril-is-giving-500000-and-a-job-to-whoever-wins-its-aipowered-drone-racing-grand-prix",
    "title": "Anduril is giving $500,000 and a job to whoever wins its AI-powered drone racing grand prix",
    "description": "Palmer Luckey's defense tech startup Anduril is known for its creative recruitment schemes. Now its launching an all-ages drones race.",
    "fullText": "Lights out and away we go… on your next job application.\n\nBut for this one, put aside your CV and interview-question AI bot. To secure the job, just place first in a global autonomous drone racing competition.\n\nThat's how defense industry disruptor Anduril is recruiting for an engineering role.\n\nThe defense tech startup has launched an \"AI Grand Prix\" to find \"the boldest engineers from around the globe.\"\n\nAnduril's competition calls teams and individuals from around the globe to develop AI systems capable of piloting high-speed racing drones through professional-grade race courses with zero human control. The fastest drone to fly autonomously through a course wins.\n\n\"The competitive edge is gained entirely by optimizing the best code for the race,\" Anduril said on its website.\n\nThe \"AI Grand Prix\" kicks off in April with two virtual rounds, followed by a two-week training and physical qualifier in California in September.\n\nThe big race day will be held in November in Ohio, where Anduril is building a 5 million-square-foot factory. Arsenal-1, as the factory is known, is just outside Columbus.\n\nParticipants can compete individually or in teams of up to eight. All ages are allowed to participate, but under-17s require parental consent and won't be eligible for the job at Anduril following the competition.\n\nIf the event is won by a team, the $500,000 prize money will be split between its members, Anduril said.\n\nThe idea came from Palmer Luckey, Anduril's founder, according to the AI Grand Prix website.\n\nLuckey has long favored unconventional paths. He began taking college courses at 14 and was 19 when he dropped out of California State University to launch the virtual reality company Oculus VR in 2012.\n\nHe worked at Facebook (now Meta) before launching Anduril in 2017, alongside four co-founders, with the mission of modernizing the US military and developing autonomous weapons that \"will save Western civilization.\"\n\nLuckey's penchant for fun and games aside, unusual job campaigns are becoming a hallmark of Anduril's recruitment strategy.\n\nIn 2025, the defense tech startup ran a reverse psychology hiring campaign with the slogan \"Don't work at Anduril,\" which included a video ad that mocked nap pods, distant leadership, and the supposed lack of mission synonymous with modern tech jobs.\n\nLuckey has previously said that over-reliance on Silicon Valley types can be a trap for businesses. Talent in the Bay Area is often \"very mercenary-minded\" and more interested in résumé building than mission, he told Lulu Cheng Meservey in an interview in September 2025.\n\nAnduril deliberately recruits nationwide and makes a point of hiring armed forces veterans, Luckey said.\n\nAnduril's recruitment drive is likely to pick up. The startup is valued at $30.5 billion as of June 2025, and is considering an IPO in 2026.\n\nAs the United States races to modernize warfare, Luckey's company has emerged as the face of the defense tech boom and proved it can compete for contracts with legacy defense contractors like Lockheed Martin and Boeing.\n\nAnduril did not immediately respond to a request for comment from Business Insider sent outside regular business hours.",
    "readingTime": 3,
    "keywords": [
      "grand prix",
      "anduril's recruitment",
      "tech startup",
      "defense tech",
      "ai grand prix",
      "competition",
      "race",
      "mission",
      "anduril",
      "aside"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anduril-ai-grand-prix-drone-palmer-luckey-job-application-2026-1",
    "thumbnail_url": "https://i.insider.com/6979d7a3e1ba468a96aad50b?width=1200&format=jpeg",
    "created_at": "2026-01-28T12:27:33.724Z",
    "topic": "finance"
  },
  {
    "slug": "sherlock-see-whats-being-sent-to-llm-apis-in-realtime",
    "title": "Sherlock – See what's being sent to LLM APIs in real-time",
    "description": "Intercept LLM API traffic and visualize token usage in a real-time terminal dashboard. Track costs,       debug prompts, and monitor context window usage across your AI development sessions.       ...",
    "fullText": "jmuncor\n\n /\n\n sherlock\n\n Public\n\n Intercept LLM API traffic and visualize token usage in a real-time terminal dashboard. Track costs, debug prompts, and monitor context window usage across your AI development sessions. \n\n github.com/jmuncor/sherlock\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jmuncor/sherlock",
    "readingTime": 1,
    "keywords": [
      "usage",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/jmuncor/sherlock",
    "thumbnail_url": "https://opengraph.githubassets.com/51a4f8e374b4fdfe1a1dd27781788ed61b21cfe7b8d5caf01dfe4fcc0770f5c6/jmuncor/sherlock",
    "created_at": "2026-01-28T06:22:46.974Z",
    "topic": "tech"
  },
  {
    "slug": "articlecast-turn-articles-and-pdfs-into-ai-podcasts",
    "title": "ArticleCast – Turn Articles and PDFs into AI Podcasts",
    "description": "ArticleCast transforms web articles into natural, expressive audio.",
    "fullText": "Best Podcasts and DIY Audio Tools for Commuters in Austin and 5 Major U.S. Cities (2026)A city-by-city guide to top podcasts and how tools like ArticleCast help commuters in Austin, NYC, LA, Chicago, DC, and SF turn articles into audio—based on 2025–2026 traffic trends and listener habits.Read moreJan 14, 2026",
    "readingTime": 1,
    "keywords": [
      "podcasts",
      "tools",
      "commuters",
      "austin"
    ],
    "qualityScore": 0.2,
    "link": "https://www.articlecast.ai",
    "thumbnail_url": "https://munisdjgxlg2fgbc.public.blob.vercel-storage.com/landing_page/Images/ArticleCastPreviewImage.png",
    "created_at": "2026-01-28T06:22:46.399Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-not-inevitable",
    "title": "AI Is Not Inevitable",
    "description": "I got nerd-sniped right before work and just had to write this post.",
    "fullText": "I got nerd-sniped right before work and just had to write this post.\n\nIn AI code and software craft, Alex looks at AI through the lens of Jacques Ellul’s “technique.”\n\nJacques Ellul describes his concept of “technique” as the reduction of activity to a set of efficient means to a measured and defined end — a way of thinking dominant in modernity.\n\nHe argues that an arts and crafts style movement that focuses on craftsmanship can stave off the totality of technique. I’m all for arts and crafts, but that view is at odds with Ellul’s view. Ellul believed that technique was “inevitable” and all-consuming and unstoppable, like the smoke monster in Lost.\n\nAndrew Feenberg’s viewpoint is actually \n\nFor example, the “technique” of the 19th-century factory was brutal efficiency. But through unions and laws (human agency), we forced the technique to adapt to child labor laws and safety standards. Efficiency was curbed by social values.\n\nFeenberg showed us a few ways to push back against Technique.\n\nDonald Knuth, a renowned computer scientist, invented literate programming, which redefined the way we write code – by putting us humans first. In literate programming you start with prose and interject code, rather than writing code and sprinkling in comments. He inverted the existing model from speed of implementation to ease of understanding.\n\nSimilarly, Feenberg would redefine AI by building AI tools that optimize for maintainability, readability, and beauty.\n\nIn the 1980s, the French government distributed the Minitel (a proto-internet terminal) to millions of homes. The technique goal was bureaucratic efficiency: to modernize the phone directory and deliver government information. It was cold, rational, and top-down.\n\nInstead, users hacked the system. They ignored the government directories and turned the network into a massive, chaotic instant-messaging service. They used the machine for flirting, arguing, and socializing. The users subverted the rational design. They took a tool of control and turned it into a tool of communication.\n\nIn other words, don’t just boycott AI. Misuse it.\n\nFeenberg distinguishes between two layers of technology. To overcome technique, we have to re-integrate them. The primary instrumentalization is the raw technical aspect. For code that means purely technical, decontextualized logic. The second instrumentalization is social, aesthetic, and ethical context. The code is elegant and respects the user’s privacy. To unify the two, we must demand that the second instrumentalization be integrated into the first.\n\nWennerberg is right to identify the “slop” as a threat, but wrong to suggest we can defeat it with nostalgia. Retreating to “software arts and crafts” doesn’t change anything (I’m still for it though); it merely leaves the engine of modern society running on autopilot, optimized only for profit.\n\nFeenberg offers a harder, but more effective path: don’t abandon the machine – hack it. By embedding human values into our definitions of efficiency and refusing to accept raw functionality as the final standard, we stop being victims of technique. The goal is not to escape the future, but to shape it.\n\nNow it’s time for me to go write some code.",
    "readingTime": 3,
    "keywords": [
      "literate programming",
      "second instrumentalization",
      "code",
      "efficiency",
      "technique",
      "arts",
      "crafts",
      "software",
      "view",
      "laws"
    ],
    "qualityScore": 1,
    "link": "https://dustin.boston/ai-is-not-inevitable/",
    "thumbnail_url": "https://dustin.boston/wp-content/uploads/2026/01/android-chrome-512x512-1.png",
    "created_at": "2026-01-28T06:22:44.303Z",
    "topic": "tech"
  },
  {
    "slug": "pixel-arcade-studio-kids-make-playable-browser-games-by-instructing-ai",
    "title": "Pixel Arcade Studio –kids make playable browser games by instructing AI",
    "description": "Kids create real browser games by giving clear instructions to AI. No coding, no downloads.",
    "fullText": "They need to learn how to give clear instructions to AI.\n\nPixel Arcade Studio is a browser-based game studio where kids create real, playable games by telling an AI assistant exactly what to build. No coding. No installs. Designed with parents in mind.\n\nSafe, creative screen time kids love. Try free for 14 days.\n\nFast \"time-to-wow\" — kids see their games come to life quickly.\n\nFrictionless — everything runs directly in the browser.\n\nSafety default — games publish with privacy protections enabled.\n\nCoding used to be how people told computers what to do.\n\nToday, the more important skill is knowing how to describe what you want, break ideas into steps, and give clear instructions to an AI system.\n\nPixel Arcade Studio is built around that shift.\n\nKids don't write code here. They practice explaining ideas, testing results, and improving their instructions when something doesn't work.\n\nThat's the skill they'll use in the real world.\n\nYour child picks a game template and describes what they want to make. Characters, goals, movement, and rules.\n\nYour child tells the AI assistant what to create or change. The AI follows instructions. It does not take over.\n\nThe game runs right away in the browser. No setup and no waiting.\n\nKids adjust their instructions, test again, and see how clearer directions lead to better results.\n\nGames can be shared with family or friends using parent-approved links.\n\nThis is not about memorizing technical skills. It's about clear thinking and communication.\n\nAI in Pixel Arcade Studio is a tool, not a shortcut.\n\nIt responds only to what your child asks. It does not browse the internet. It does not publish content on its own. It stays inside kid-safe boundaries.\n\nYour child stays in control. The AI helps carry out instructions.\n\nPixel Arcade Studio is built for families who want creative screen time without constant supervision.\n\nInstead, kids focus on giving clear instructions and seeing real results. They make games people can actually play.\n\nEvery game made in Pixel Arcade Studio is playable in the browser and shareable through safe links.\n\nKids don't just save projects. They create something real and playable.\n\nPixel Arcade Studio is a browser-based game studio where kids create playable games by giving instructions to an AI assistant. There is no coding involved.\n\nNo. Pixel Arcade Studio does not teach coding. Kids learn how to clearly describe ideas, give instructions, and work with AI to create games.\n\nPixel Arcade Studio is designed for kids ages 7 to 12.\n\nYes. Games publish in safe mode by default, sharing requires parent approval, and the platform includes content filtering and privacy protections.\n\nNo. Everything runs directly in the web browser. There are no downloads or installs.\n\nThe AI follows your child's instructions. It helps turn ideas into games but does not take control or act on its own.\n\nYes. Games can be shared using parent-approved links so friends and family can play safely.\n\nPixel Arcade Studio does not involve coding or block-based programming. It focuses on teaching kids how to give clear instructions to AI and refine their ideas through iteration.\n\nNo coding. No downloads. Designed for ages 7–12.",
    "readingTime": 3,
    "keywords": [
      "pixel arcade studio",
      "creative screen",
      "privacy protections",
      "parent-approved links",
      "browser-based game",
      "kids don't",
      "games publish",
      "playable games",
      "the ai",
      "kids create"
    ],
    "qualityScore": 1,
    "link": "https://pixelarcade.studio",
    "thumbnail_url": "http://localhost:3000/images/pas_og.jpg",
    "created_at": "2026-01-28T06:22:43.763Z",
    "topic": "tech"
  },
  {
    "slug": "this-train-isnt-going-to-stop-shocking-sundance-film-shows-promises-and-perils-of-ai",
    "title": "‘This train isn’t going to stop’: shocking Sundance film shows promises and perils of AI",
    "description": "The AI Doc: Or How I Became an Apocaloptimist, co-directed by Daniel Roher, delves into the world of AI through the lens of personal anxiety\nAre we barreling toward AI catastrophe? Is AI an existential threat, or an epochal opportunity? Those are the questions top of mind for a new documentary at Sundance, which features leading AI experts, critics and entrepreneurs, including Sam Altman, the OpenAI CEO, with views on the near-to-midterm future ranging from doom to utopia.\nThe AI Doc: Or How I Became an Apocaloptimist, directed by Daniel Roher and Charlie Tyrell and produced by Daniel Kwan (one half of The Daniels, the Oscar-winning duo behind Everything Everywhere All At Once), delves into the contentious topic of AI through Roher’s own anxiety. The Canadian film-maker, who won an Oscar in 2023 for the documentary Navalny, first became interested in the topic while experimenting with tools released by OpenAI, the company behind the chatbot ChatGPT.",
    "fullText": "The AI Doc: Or How I Became an Apocaloptimist, co-directed by Daniel Roher, delves into the world of AI through the lens of personal anxiety\n\nAre we barreling toward AI catastrophe? Is AI an existential threat, or an epochal opportunity? Those are the questions top of mind for a new documentary at Sundance, which features leading AI experts, critics and entrepreneurs, including Sam Altman, the OpenAI CEO, with views on the near-to-midterm future ranging from doom to utopia.\n\nThe AI Doc: Or How I Became an Apocaloptimist, directed by Daniel Roher and Charlie Tyrell and produced by Daniel Kwan (one half of The Daniels, the Oscar-winning duo behind Everything Everywhere All At Once), delves into the contentious topic of AI through Roher’s own anxiety. The Canadian film-maker, who won an Oscar in 2023 for the documentary Navalny, first became interested in the topic while experimenting with tools released by OpenAI, the company behind the chatbot ChatGPT. The sophistication of the public tools – the ability to produce whole paragraphs in seconds, or produce illustrations – both thrilled and unnerved him. AI was already radically shaping the filmmaking industry, and proclamations on the promise and peril of AI were everywhere, with little way for people outside the tech industry to evaluate them. As an artist, he wondered, how was he to make sense of it all?\n\nRoher’s anxiety only increased when he and his wife, fellow film-maker Caroline Lindy, learned that they were expecting their first child. “It felt like the whole world was rushing into something without thinking,” he says in the film, as his excitement for parenthood collided with dread over the unknown variable of AI, which in just a few short years went from proprietary experiment to public good.\n\nThe AI Doc thus arises out of Roher’s most pressing question: is it safe to bring a child into this world? Alongside Kwan, Roher convened a series of experts to both explain the mechanics of the tech – and clarify some nebulous, alienating terms – and search for an answer. (It is both comforting and a little disturbing, for example, that no one seems to have a clear answer to the question “what is AI?”). In individual sit-down interviews, leading machine learning researchers including Yoshua Bengio, Ilya Sutskever and DeepMind co-founder Shane Legg all agree that there are aspects of AI models that humans cannot and will never be able to understand. Standard AI models are trained on “more data than anyone could ever read in several lifetimes”, as one machine learning expert puts it. And the pace of machine learning exceeds that of precedent – or film. “Any example you put in this movie will look absolutely clumsy by the time the movie comes out,” Tristan Harris, co-founder of the Center for Humane Technology and a prominent voice in the apocalyptic 2020 Netflix documentary The Social Dilemma, tells Roher.\n\nThe film first hears from a series of doomerists, or people concerned AI – and in particular Artificial General Intelligence (AGI), a still-theoretical form of AI whose capabilities exceed those of humans – could lead to the extermination of humanity, including Harris, his Center for Humane Technology co-founder Aza Raskin, Ajeya Cotra, an AI risk adviser, and Eli Yudkowsky, an AI alignment pioneer. Such figures warn that humans could very easily lose control of super-intelligent AI models, with little to no recourse. Yudkowsky’s 2025 book is bluntly titled If Anyone Builds It, Everyone Dies.\n\nAI companies, they say, are unprepared for the consequences of reaching AGI, which could “become superhuman maybe in this decade”, says Dan Hendrycks, director of the Center for AI Safety. Should humans no longer be the most intelligent beings on Earth, they warn, it is possible that AGI would view the species as irrelevant. Connor Leahy, co-founder of EleutherAI, compared the potential future relationship of super-intelligent AGI and humans to that of humans and ants: “We don’t hate ants. But if we want to build a highway” over an anthill – “well, sucks for the ant.”\n\nSeveral in the doomer camp, many of whom do not have children, react discouragingly to Roher’s question about parenthood. “I know people who work on AI risk who don’t expect their child to make it to high school,” says Harris, in a line that drew gasps from a preview audience in Park City.\n\nOn the other side are optimistic figures such as Peter Diamandis, founder of the XPRIZE Foundation trying to extend human life, who claims that “children born today are about to enter a period of glorious transformation”; Guillaume Verdon, a leader of the “effective accelerationism” movement in Silicon Valley; Peter Lee, the president of Microsoft Research; and Daniela Amodei, the co-founder and president of OpenAI rival Anthropic. So-called “accelerationists” see AI as a potential cure to a myriad of seemingly intractable issues afflicting humanity: cancer, food and water shortages for an ever-growing population, insufficient renewable energy and perhaps most pressing, climate emergency. Without AI, they argue, countless future lives would be lost to drought, famine, disease and natural catastrophes.\n\nDevelopment of AI, however, relies on computing power, which requires vast amounts of energy. A final group of interviewees, critics and observers largely outside the tech world – including Karen Hao, a journalist and author of the book Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI, and Liv Boeree, Win-Win podcast hos – connect AI to the tangible, physical world, such as the data centers sucking up water in the American west, leaving residents with sky-high electricity bills and drained reservoirs. The current narratives around AI, according to Emily M Bender, a computational linguistics professor, exclude and dehumanize the people it is already impacting, and will continue to disrupt.\n\nRoher eventually arrives at the five most powerful people – all men – currently leading the AI arms race: Altman; Elon Musk, the xAI CEO; Dario Amodei, the Anthropic CEO; Demis Hassabis of DeepMind and Meta’s Mark Zuckerberg. Altman, Amodei and Hassabis sit for interviews that more or less defend their companies’ respective positions. According to the film, Zuckerberg declined to participate; Musk agreed but then got too busy.\n\nAltman, who at the time of the interview was expecting his first child, insists that he’s “not scared for a kid to grow up in a world with AI”. He and his husband Oliver Mulherin welcomed their son via a surrogate in February 2025, an event Altman later said “neurochemically hacked” his brain, leading people in his life to think that he would “make better decisions” for OpenAI and ChatGPT when it comes to “humanity as a whole”. The 40-year-old CEO went on to say that both his and Roher’s child would likely “never be smarter than AI” which “does unsettle me a little bit, but it is reality”.\n\nAt one point, Roher asks Altman if it is indeed impossible to reassure him that everything in regards to AI is going to be OK. “That is impossible,” Altman affirms, though he does say that OpenAI’s lead in the AI arms race allows it to spend more time on safety testing.\n\nThe AI Doc ultimately lands somewhere in between doomerism and optimism – apocaloptimism, as they call it, searching for “a path between the promise and the peril”. That path should include, according to numerous film subjects: significant, sustained, paradigm-shifting international coordination, akin the mid-century frameworks and agreements introduced to moderate the development of atomic weapons – more corporate transparency for AI companies, an independent regulatory body to police AI developers, legal liability for the companies’ products, such as ChatGPT, mandatory disclosure of genAI use for media and a willingness to keep adapting the rules for rapidly shifting tech.\n\nWhether or not the US government and companies, let alone the world, can do it remains an open question, with differing opinions on first steps. But if there is one thing the many subjects all agree on, it’s that there’s no going back to a time before AI. As Anthropic co-founder and CEO Amodei puts it: “This train isn’t going to stop.”\n\nThe AI Doc: Or How I Became an Apocaloptimist is screening at the Sundance film festival and will be released on 27 March",
    "readingTime": 7,
    "keywords": [
      "arms race",
      "machine learning",
      "the ai doc",
      "humane technology",
      "film",
      "co-founder",
      "humans",
      "roher’s",
      "child",
      "leading"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/film/2026/jan/27/sundance-ai-documentary-daniel-roher",
    "thumbnail_url": "https://i.guim.co.uk/img/media/b08a19776fa0669d5a6da6b4fa8dc369025616f1/571_0_2697_2160/master/2697.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f49a8654dc44a148f9cf48ba31979f54",
    "created_at": "2026-01-28T06:22:42.506Z",
    "topic": "entertainment"
  },
  {
    "slug": "exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say",
    "title": "Exclusive-China gives green light to importing first batch of Nvidia's H200 AI chips, sources say",
    "description": "China has approved its first batch of Nvidia's H200 artificial intelligence chips for import, two people familiar with the matter told Reuters, marking a shift in position as China ​seeks to balance its AI needs against spurring domestic development.  The approval covers several hundred thousand H200 chips ‌and was granted during Nvidia Chief Executive Jensen Huang's visit to China this week, the sources said, requesting anonymity due to the sensitivity ‌of the matter.",
    "fullText": "Jan 28 (Reuters) - China has approved its first batch of Nvidia's H200 artificial intelligence chips for import, two people familiar with the matter told Reuters, marking a shift in position as China ​seeks to balance its AI needs against spurring domestic development.\n\nThe approval covers several hundred thousand H200 chips ‌and was granted during Nvidia Chief Executive Jensen Huang's visit to China this week, the sources said, requesting anonymity due to the sensitivity ‌of the matter.\n\nThe first batch of approvals has been allocated primarily to three major Chinese internet companies, with other enterprises now joining a queue for subsequent approvals, one of the sources said.\n\nThey declined to name the companies that received the initial clearances.\n\nChina's industry and commerce ministries as well as Nvidia had not yet responded to requests for comment at the time ⁠of publication.\n\nThe H200, Nvidia's second most ‌powerful AI chip, has emerged as a major flashpoint in U.S.-China relations. Despite strong demand from Chinese firms and U.S. approval for exports, Beijing's hesitation to allow imports has been ‍the main barrier to shipments.\n\nThe U.S. earlier this month formally cleared the way for Nvidia to sell the H200 to China, where the company is seeing strong appetite. However, Chinese authorities have the final say on whether they would allow it to be ​shipped in.\n\nIt was unclear in recent weeks whether Beijing would grant approval as the government wants to balance ‌meeting surging domestic demand for advanced AI chips and nurturing its domestic semiconductor industry.\n\nChinese customs authorities told agents that the H200 chips were not permitted to enter China, Reuters reported earlier this month.\n\nBut Chinese technology firms have placed orders for more than two million H200 chips, far exceeding Nvidia's available inventory, Reuters reported last month.\n\nIt remains uncertain how many additional companies will receive approval in subsequent batches or what criteria Beijing is using to determine eligibility.\n\nHuang arrived ⁠in Shanghai last Friday for routine annual celebrations with Nvidia's China ​employees and has since travelled to Beijing and other cities, Reuters ​reported last week.\n\nThe approvals of H200 suggest Beijing is prioritising the needs of major Chinese internet companies, which are spending billions of dollars to build data centres needed to develop AI ‍services and compete with U.S. ⁠rivals, including OpenAI.\n\nWhile Chinese companies such as Huawei now have products that rival the performance of Nvidia's H20 chip, previously the most advanced AI chip it was allowed to sell to China, they still ⁠lag far behind the H200.",
    "readingTime": 3,
    "keywords": [
      "chinese internet",
      "chips",
      "approval",
      "beijing",
      "domestic",
      "approvals",
      "chip",
      "china",
      "batch",
      "balance"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-china-gives-green-light-034730976.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/17e76ef2c101de17fb4d4c33cf165ec7",
    "created_at": "2026-01-28T06:22:41.828Z",
    "topic": "finance"
  },
  {
    "slug": "exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say",
    "title": "Exclusive-China gives green light to importing first batch of Nvidia’s H200 AI chips, sources say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/exclusivechina-gives-green-light-to-importing-first-batch-of-nvidias-h200-ai-chips-sources-say-4469141",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0R059_L.jpg",
    "created_at": "2026-01-28T06:22:41.183Z",
    "topic": "finance"
  },
  {
    "slug": "asml-rides-nvidias-coattails-with-lasers-and-huge-chip-printers",
    "title": "ASML rides Nvidia's coattails with lasers and huge chip 'printers'",
    "description": "As artificial intelligence firms jostle for the Nvidia chips needed to power the AI boom, Dutch firm ASML has carved out a key niche in the supply chain: building the laser-using machines needed ​to print them.  ASML, which counts Taiwan's TSMC and Intel amongst its clients, makes the huge precision machines needed to print the minuscule ‌circuitry onto silicon chips, dominating the market for the high-end microprocessors needed for AI.  The Veldhoven, Netherlands-based company has seen its shares double in value since last April and rise 25% ‌this month alone amid signs that its chipmaker clients are ramping up investment as a supply crunch pushes up chip prices.",
    "fullText": "AMSTERDAM, Jan 27 (Reuters) - As artificial intelligence firms jostle for the Nvidia chips needed to power the AI boom, Dutch firm ASML has carved out a key niche in the supply chain: building the laser-using machines needed ​to print them.\n\nASML (ASML), which counts Taiwan's TSMC and Intel amongst its clients, makes the huge precision machines needed to print the minuscule ‌circuitry onto silicon chips, dominating the market for the high-end microprocessors needed for AI.\n\nThe Veldhoven, Netherlands-based company has seen its shares double in value since last April and rise 25% ‌this month alone amid signs that its chipmaker clients are ramping up investment as a supply crunch pushes up chip prices.\n\nNow investors are watching whether the firm ups its forecasts for flat-to-modest sales growth in 2026 when it reports earnings on Wednesday, analysts said.\n\nAnalysts have been upgrading estimates as the stock races ahead, with new forecasts significantly above the company's guidance.\n\nA monopoly on extreme ultraviolet (EUV) technology has helped the firm ride the coattails of chip design giant Nvidia amid a global ⁠AI arms race that has created trillions of dollars ‌in value.\n\nASML is \"the only game in town,\" said John West of semiconductor consultancy Yole Group, referring to EUV, which uses light beams just 13.5 nanometers thick - minuscule, given a human hair is around 80,000–100,000 nanometers across.\n\nCHIPMAKER CLIENTS RAMP UP ‍CAPEX PLANS\n\nThe firm will also update its plans to ramp up the number of machines it can make.\n\nDemand for ASML's high-tech tools has made the firm Europe's most valuable listed company with a market cap recently topping $500 billion.\n\nASML controls some 90% of the market for lithography systems, analysts estimate, due to its high-throughput machines. It is ​the only maker of EUV technology, in which drops of tin are vaporized with lasers 50,000 times a second to create the light.\n\nDemand for AI-linked ‌cloud services boomed in 2025 and a related shortage of memory chips has started to push up prices for smartphones, computers and gaming consoles.\n\nManufacturers are ramping up investment to boost capacity in response.\n\nTSMC, ASML's top customer, plans to increase capital spending by 37% in 2026 to $56 billion.\n\nAnalysts estimate Samsung is targeting a 24% hike to $40 billion, and that SK Hynix will increase spending by 25% to $22 billion, according to LSEG data. U.S. firm Micron plans a 45% rise to $20 billion.\n\nA quarter of chipmaker capex is spent on lithography, analysts estimate, largely going to ASML, and this proportion could be higher with ⁠AI chips, driven by demand from players like Apple, Google, and Qualcomm.",
    "readingTime": 3,
    "keywords": [
      "euv technology",
      "chipmaker clients",
      "analysts estimate",
      "machines needed",
      "firm",
      "chips",
      "plans",
      "market",
      "demand",
      "nvidia"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asml-rides-nvidias-coattails-lasers-060145161.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/871959193fa106a7de7e044d72305973",
    "created_at": "2026-01-28T06:22:39.894Z",
    "topic": "finance"
  },
  {
    "slug": "metas-soaring-capex-is-front-and-center-for-analysts-ahead-of-the-social-media-giants-q4-earnings",
    "title": "Meta's soaring capex is front and center for analysts ahead of the social media giant's Q4 earnings",
    "description": "Analysts are laser-focused on Meta's AI ambitions and its surging capex spending. The company reports Q4 earnings after the closing bell on Wednesday.",
    "fullText": "Big Tech earnings are about to kick off in earnest, with Meta Platforms due to report results for the final quarter of 2025 on Wednesday.\n\nMeta stock has been highly volatile over the past year, remaining in the green but lagging behind some of its Magnificent Seven peers. The stock is up about 1% year-to-date and up 7% in the last 12 months.\n\nThe social media giant spent 2025 telling investors it would boost capex spending, hyping up its ambitious AI plans. Investors eventually balked at Meta and other tech titans' plans to keep increasing capex. Meta tumbled after its Q3 report, partly on its announcement that it plans to spend more than ever on AI infrastructure going forward.\n\nMeta latest announced it would significantly scale back its metaverse spending, touted by CEO Mark Zuckerberg as the company's future only a few years earlier.\n\nWall Street is estimating that the Facebook parent will report $58.4 billion in revenue and earnings per share of $8.19.\n\nHere's what analysts say they'll be listening for.\n\nBofA analysts expect Meta to slightly beat estimates, though they remain focused on the company's expense guide for the coming year. The bank has an $810 price target and a buy rating for the stock, implying 21% upside.\n\n\"Concerns on '26 expenses have been building for 5 months & we think an expense guide at around 30% 2026 growth could be positive, while at/above 35% a negative,\" said analyst Justin Post.\n\nHe added that his team expects Meta's capex spending to come in between $109 and $114 billion for the year, likely above Wall Street consensus of $110 billion.\n\nDeutsche analysts maintain a buy rating and a bullish price target of $880 for Meta stock, a 31% jump from current levels. But as analyst Benjamin Black notes, heading into the Q4 earnings call, concerns linger about this year's expenses.\n\nThat said, his team also predicts that Meta's revenue will come in at $59 billion, just above Wall Street estimates.\n\n\"In our view, Meta is positioned favorably — especially in the long-term — as it doubles down on an AI investment cycle,\" Black said.\n\nLike its peers, Goldman analysts remain focused on Meta's capex plans, which they believe will continue to drive growth into 2026 and beyond. The bank recently raised its spending projections for the company, already above analyst estimates, noting that it sees upward pressure on consensus capex estimates.\n\n\"On the next earnings call, we expect investors will be focused on any updates on the work of the Meta Superintelligence Lab, the timing of any foundational model work and/or any strategies with respect to consumer or enterprise utility around AI,\" Goldman analysts stated.\n\nRothschild has a $900 price target for Meta stock, one of the highest on Wall Street. Its target represents a 34% increase from levels on Tuesday. Analyst James Cordwell sees Meta as one of the tech sector's best-positioned companies to capitalize on rising AI demand.\n\n\"The recent focus regarding Meta has been dominated by how the company might guide for FY26 operating expenses and capital expenditure,\" he stated. \"The fear is that this is 'Zuckerberg unleashed', with the company's CEO truly back in 'founder mode', pursuing his AI dreams whatever the financial cost.\"\n\nThe analyst added that this has prompted Rothschild to increase its full-year capex projection for Meta to $117.1 billion.\n\nTD Cowen is bullish on Meta ahead of its Wednesday earnings report, predicting generative AI tools will continue to support growth in its advertising business.\n\nAnalyst John Blackedge said he believes ad growth will help bolster its high capex spending.\n\n\"Key at the 4Q25 print will be mgmt's '26 capex and opex guides,\" he said. \"We currently expect '26 capex of $125.0BN, up 76% y/y and 14% above consensus alongside '26 opex of $156.1BN, up 32.9% y/y and 7% above consensus.\"",
    "readingTime": 4,
    "keywords": [
      "goldman analysts",
      "meta's capex",
      "expense guide",
      "meta stock",
      "wall street",
      "earnings",
      "plans",
      "estimates",
      "target",
      "growth"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-earnings-preview-ai-capex-wall-street-forecasts-facebook-2026-1",
    "thumbnail_url": "https://i.insider.com/697905fba645d1188188120e?width=1200&format=jpeg",
    "created_at": "2026-01-28T00:59:05.568Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-included-a-subtle-dig-at-mark-zuckerberg-in-his-message-to-employees",
    "title": "Sam Altman included a subtle dig at Mark Zuckerberg in his message to employees",
    "description": "Sam Altman told staff OpenAI \"didn't start talking about masculine corporate energy,\" an apparent reference to Mark Zuckerberg's remarks to Joe Rogan.",
    "fullText": "Don't expect to see Sam Altman lamenting the absence of \"masculine energy\" in corporate America to Joe Rogan anytime soon.\n\nThe OpenAI CEO sent employees a message on Slack criticizing Immigration and Customs Enforcement — and appears to have taken the opportunity to also take a subtle jab at his rival, Mark Zuckerberg.\n\nThe reference can be found where Altman wrote that OpenAI aims to \"not get blown around by changing fashions.\"\n\n\"We didn't start talking about masculine corporate energy when that was popular,\" Altman told employees.\n\nLast year, Zuckerberg championed a return to masculinity at Meta on \"The Joe Rogan Experience.\"\n\n\"The masculine energy, I think, is good,\" Zuckerberg said in the January podcast episode. \"Society has plenty of that, but I think corporate culture was trying to get away from it.\"\n\nZuckerberg described the merits of a corporate culture that \"celebrates the aggression\" of business.\n\nThe Meta CEO said that the intent of corporate culture's shift away from masculinity was good. Women likely feel that companies are \"too masculine,\" he told Rogan, and that things are \"biased\" against them. But the shift had gone too far, the Facebook cofounder said.\n\n\"It's one thing to say we want to be welcoming and make a good environment for everyone,\" Zuckerberg said. \"It's another to basically say that masculinity is bad.\"\n\nAltman also wrote in his memo that OpenAI didn't \"become super woke when that was popular.\"\n\nMeta didn't respond to Business Insider's request for comment on Altman's remark.\n\nAltman and Zuckerberg are currently engaged in a talent war for top AI researchers and engineers.\n\nZuckerberg has attempted to poach OpenAI employees with eye-popping compensation packages, which Altman in June said included $100 million signing bonuses.\n\nWhile Altman at the time said that he was happy that \"at least so far, none of our best people have decided to take them up on that,\" Zuckerberg successfully hired away some prominent OpenAI talent.\n\nThe Meta CEO, who even hand-delivered soup to an OpenAI employee he was attempting to poach, hired away ChatGPT co-creator Shengjia Zhao and three researchers who helped build OpenAI's Zurich office.",
    "readingTime": 2,
    "keywords": [
      "meta ceo",
      "hired away",
      "corporate culture",
      "masculine energy",
      "the meta ceo",
      "employees",
      "didn't",
      "masculinity",
      "zuckerberg",
      "altman"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-dig-mark-zuckerberg-masculine-energy-2026-1",
    "thumbnail_url": "https://i.insider.com/6978e73ba645d11881880d86?width=1200&format=jpeg",
    "created_at": "2026-01-28T00:59:05.239Z",
    "topic": "finance"
  },
  {
    "slug": "harnessing-plasmons-for-alternative-computing-power",
    "title": "Harnessing Plasmons for Alternative Computing Power",
    "description": "Can computing with plasmons solve AI's power problem? Dive into the world of electron waves and find out.",
    "fullText": "IEEE Spectrum is the flagship publication of the IEEE — the world’s largest professional organization devoted to engineering and applied sciences. Our articles, videos, and infographics inform our readers about developments in technology, engineering, and science.",
    "readingTime": 1,
    "keywords": [
      "engineering",
      "ieee"
    ],
    "qualityScore": 0.2,
    "link": "https://spectrum.ieee.org/plasmon-computing-device",
    "thumbnail_url": "https://spectrum.ieee.org/media-library/image.jpg?id=62999081&width=1200&height=600&coordinates=0%2C136%2C0%2C114",
    "created_at": "2026-01-27T18:24:30.848Z",
    "topic": "tech"
  },
  {
    "slug": "trumps-use-of-ai-images-pushes-new-boundaries-further-eroding-public-trust-experts-say",
    "title": "Trump's use of AI images pushes new boundaries, further eroding public trust, experts say",
    "description": "The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.  Homeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying.",
    "fullText": "LOS ANGELES (AP) — The Trump administration has not shied away from sharing AI-generated imagery online, embracing cartoonlike visuals and memes and promoting them on official White House channels.\n\nBut an edited — and realistic — image of civil rights attorney Nekima Levy Armstrong in tears after being arrested is raising new alarms about how the administration is blurring the lines between what is real and what is fake.\n\nHomeland Security Secretary Kristi Noem’s account posted the original image from Levy Armstrong's arrest before the official White House account posted an altered image that showed her crying. The doctored picture is part of a deluge of AI-edited imagery that has been shared across the political spectrum since the fatal shootings of Renee Good and Alex Pretti by U.S. Border Patrol officers in Minneapolis\n\nHowever, the White House’s use of artificial intelligence has troubled misinformation experts who fear the spreading of AI-generated or edited images erodes public perception of the truth and sows distrust.\n\nIn response to criticism of the edited image of Levy Armstrong, White House officials doubled down on the post, with deputy communications director Kaelan Dorr writing on X that the “memes will continue.” White House Deputy Press Secretary Abigail Jackson also shared a post mocking the criticism.\n\nDavid Rand, a professor of information science at Cornell University, says calling the altered image a meme “certainly seems like an attempt to cast it as a joke or humorous post, like their prior cartoons. This presumably aims to shield them from criticism for posting manipulated media.” He said the purpose of sharing the altered arrest image seems “much more ambiguous” than the cartoonish images the administration has shared in the past.\n\nMemes have always carried layered messages that are funny or informative to people who understand them, but indecipherable to outsiders. AI-enhanced or edited imagery is just the latest tool the White House uses to engage the segment of Trump’s base that spends a lot of time online, said Zach Henry, a Republican communications consultant who founded Total Virality, an influencer marketing firm.\n\n“People who are terminally online will see it and instantly recognize it as a meme,” he said. “Your grandparents may see it and not understand the meme, but because it looks real, it leads them to ask their kids or grandkids about it.”\n\nAll the better if it prompts a fierce reaction, which helps it go viral, said Henry, who generally praised the work of the White House’s social media team.\n\nThe creation and dissemination of altered images, especially when they are shared by credible sources, “crystallizes an idea of what’s happening, instead of showing what is actually happening,” said Michael A. Spikes, a professor at Northwestern University and news media literacy researcher.\n\n“The government should be a place where you can trust the information, where you can say it’s accurate, because they have a responsibility to do so,\" he said. \"By sharing this kind of content, and creating this kind of content … it is eroding the trust — even though I’m always kind of skeptical of the term trust — but the trust we should have in our federal government to give us accurate, verified information. It’s a real loss, and it really worries me a lot.”\n\nSpikes said he already sees the “institutional crises” around distrust in news organizations and higher education, and feels this behavior from official channels inflames those issues.\n\nRamesh Srinivasan, a professor at UCLA and the host of the Utopias podcast, said many people are now questioning where they can turn to for “trustable information.” “AI systems are only going to exacerbate, amplify and accelerate these problems of an absence of trust, an absence of even understanding what might be considered reality or truth or evidence,” he said.\n\nSrinivasan said he feels the White House and other officials sharing AI-generated content not only invites everyday people to continue to post similar content but also grants permission to others who are in positions of credibility and power, like policymakers, to share unlabeled synthetic content. He added that given that social media platforms tend to “algorithmically privilege” extreme and conspiratorial content — which AI generation tools can create with ease — “we’ve got a big, big set of challenges on our hands.”\n\nAn influx of AI-generated videos related to Immigration and Customs Enforcement action, protests and interactions with citizens has already been proliferating on social media. After Renee Good was shot by an ICE officer while she was in her car, several AI-generated videos began circulating of women driving away from ICE officers who told them to stop. There are also many fabricated videos circulating of immigration raids and of people confronting ICE officers, often yelling at them or throwing food in their faces.\n\nJeremy Carrasco, a content creator who specializes in media literacy and debunking viral AI videos, said the bulk of these videos are likely coming from accounts that are “engagement farming,\" or looking to capitalize on clicks by generating content with popular keywords and search terms like ICE. But he also said the videos are getting views from people who oppose ICE and DHS and could be watching them as “fan fiction,” or engaging in “wishful thinking,” hoping that they're seeing real pushback against the organizations and their officers.\n\nStill, Carrasco also believes that most viewers can't tell if what they're watching is fake, and questions whether they would know \"what’s real or not when it actually matters, like when the stakes are a lot higher.\"\n\nEven when there are blatant signs of AI generation, like street signs with gibberish on them or other obvious errors, only in the “best-case scenario” would a viewer be savvy enough or be paying enough attention to register the use of AI.\n\nThis issue is, of course, not limited to news surrounding immigration enforcement and protests. Fabricated and misrepresented images following the capture of deposed Venezuelan leader Nicolás Maduro exploded online earlier this month. Experts, including Carrasco, think the spread of AI-generated political content will only become more commonplace.\n\nCarrasco believes that the widespread implementation of a watermarking system that embeds information about the origin of a piece of media into its metadata layer could be a step toward a solution. The Coalition for Content Provenance and Authenticity has developed such a system, but Carrasco doesn’t think that will become extensively adopted for at least another year.\n\n“It’s going to be an issue forever now,” he said. I don’t think people understand how bad this is.”",
    "readingTime": 6,
    "keywords": [
      "levy armstrong",
      "ice officers",
      "sharing ai-generated",
      "account posted",
      "ai-generated videos",
      "social media",
      "media literacy",
      "white house",
      "trust",
      "online"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/trumps-ai-images-pushes-boundaries-150725490.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/9xZi2ciMXRnBrH4SjRZuyQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/ap.org/d262a7d276564fc3e4743b28feb4fcc9",
    "created_at": "2026-01-27T18:24:25.114Z",
    "topic": "news"
  },
  {
    "slug": "at-davos-tech-ceos-laid-out-their-vision-for-ais-world-domination",
    "title": "At Davos, tech CEOs laid out their vision for AI’s world domination",
    "description": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n Continue reading...",
    "fullText": "Tech chiefs waxed poetic about AI to delegates at Davos. Plus, the ‘human’ drama of AI startups and why Tesla is thriving in Texas\n\nHello, and welcome to TechScape. This week’s edition is a team effort: my colleague Heather Stewart reports on the plans for AI’s world domination at Davos; I examine how huge investments have followed AI companies with little to their names but drama and dreams; and Nick Robins-Early spotlights how lax regulation of autonomous driving in Texas allowed Tesla to thrive.\n\nWhen they weren’t discussing Donald Trump, delegates at the World Economic Forum last week were being dazzled by the prospects for artificial intelligence.\n\nUp and down the main street of the Swiss Alps town, almost every shopfront was temporarily emblazoned with the neon slogan of a tech firm – or a consultancy promising to tell executives how to incorporate AI into their business. Cloudflare’s wood-panelled HQ urged delegates to “connect, protect and build together”, and Wipro’s shouted: “Dream Solve Prove Repeat.”\n\nAt the conference, tech CEOs laid out their hopes for how the physical manifestations of AI will blanket the world in the coming years. Microsoft chief executive Satya Nadella told a rapt audience about how “token factories”, as he calls datacenters, will have to be distributed across the world, to diffuse the benefits of AI globally.\n\n“To me, a long term, scalable solution is to have all of these token factories part of the real economy connected to the grid, connected to the telco network – and that’s what will drive that scale, whether it’s in the global south, or in the developed world,” Nadella said.\n\nMeanwhile Google was showing off the latest iteration of its Google Glasses to excited delegates; and there were endless sessions in the Davos congress centre about the technology’s potential benefits – including a breathless chat with late addition to the schedule Elon Musk, though with the SpaceX IPO apparently looming, he was keenest to talk about going to Mars.\n\nAway from the glitzy shopfronts, though, there was significant concern being expressed that all this proves to be an epic bubble.\n\nIn an interview with the Financial Times, DeepMind chief Demis Hassabis warned that some aspects of AI investment do look, “bubble-like”, but insisted that, “if the bubble bursts, we [ie Google, not society at large] will be fine”.\n\nNadella offered one test for how we would know if it is a bubble – which I didn’t find reassuring. “A tell-tale sign of this as a bubble, is if all we’re talking about are the tech firms,” he said.\n\nMuch of Silicon Valley has been captivated over the past week by a “very human drama”, as the Wall Street Journal put it. Thinking Machines Lab, a startup founded by former OpenAI chief technology officer Mira Murati, fired her own chief technology officer, Barret Zoph, over a relationship with a colleague and a recent lack of productivity, per the Journal. Within hours, her ex-employee – along with one of her co-founders and a third employee – had reportedly signed offers with OpenAI, which they left just last year to join her startup. The three had told her they disagreed with the direction of the company in the meeting that ended with Zoph’s firing, according to the Journal. For his part, Zoph told the Journal that Murati had fired him simply for telling her he was considering another job.\n\nAs dishy as the drama might be, the stakes of Murati’s mess differ from a juicy celebrity entanglement that might be chronicled in TMZ or Page Six, two of my favorite publications. The stakes in San Francisco are billions of real dollars and more than $10bn potential ones. Murati’s company has raised $2bn in venture capital since its founding in February 2025. It is valued at $12bn. The talent involved in these California productions – not movies but rather AI tools used by hundreds of millions of people – takes on superstar significance.\n\nThinking Machines has released one product, Tinker, in October 2025, meant to streamline the customization of large language models, a rather niche concern in comparison with ChatGPT’s ambitions to replace Google search or Claude’s coding aptitude.\n\nThe massive investment and resulting valuation are chasing little in terms of real offerings from the company. A new company profiled in the New York Times last week, Humans&, has naught but a dream, an ugly website – and several hundred million dollars. Researchers from Google, Anthropic, and Elon Musk’s xAI, including one who helped develop the notorious Grok AI tool, founded the company just three months ago. They aim to facilitate collaboration between humans and machines rather than separation – “innovations in long-horizon and multi-agent reinforcement learning, memory, and user understanding”, per the site. If that sounds gauzy, it is because the company has not launched a product.\n\nHumans& has raised $480m from Nvidia, Jeff Bezos, and Google, per the New York Times. It is valued at $4.48bn. It has – say it with me one more time – not launched a product.\n\nWhatever fears of an AI bubble may be circulating, the money is still flowing, chasing after the future with an enormous but uncertain bet in the present.\n\nElon Musk announced last week that Tesla had removed human safety monitors from its Robotaxis in Austin, Texas, as the company moves to expand its autonomous vehicle business. As with most things Musk, the reality was a bit more complicated – Tesla’s vice-president of software later clarified on X that the company had deployed “a few unsupervised vehicles mixed in with the broader robotaxi fleet with safety monitors”.\n\nWhat Tesla’s test-run of fully driverless vehicles did highlight, however, was the difference between how much leeway Texas gives autonomous vehicles compared with California, the birthplace of autonomous driving in the US and the home of the highest number of self-driving cars in the country. The Texas department of motor vehicles does not have regulatory authority over autonomous vehicles in the state, instead autonomous vehicles are governed by the state’s transportation code. Although a new government authorization system for autonomous vehicles is set to be implemented in the coming months, there’s currently no application process required for autonomous vehicle operators in the state. \n\n “Autonomous vehicles on Texas roads are subject to all traffic laws and can be cited for safety violations, but do not yet require specific authorization to operate,” the Texas DMV said.\n\nAlso surprising is the state’s lack of regulations on operating an autonomous vehicle if it’s for personal, non-commercial use. As long as it complies with some stipulations, such as traffic laws and safety standards, an autonomous vehicle can drive around Texas without anyone in the car.\n\n “Any motor vehicle equipped with an automated driving system may operate in this state,” the Texas transportation code states. “An automated motor vehicle may operate in this state with the automated driving system engaged, regardless of whether a human driver is physically present in the automated motor vehicle.”\n\nMeanwhile in California, the state’s department of motor vehicles requires three stages of testing and permitting for commercial autonomous vehicles. Regulators are also in the process of considering new rules that could add even more requirements on vehicle operators. Tesla caused confusion last October when Musk announced a ride-hailing service in the Bay Area, only for regulators to say that the company did not have authorization to operate paid or unpaid autonomous rides to the public. On the Robotaxi section of Tesla’s website, it only mentions Texas.",
    "readingTime": 7,
    "keywords": [
      "token factories",
      "technology officer",
      "transportation code",
      "traffic laws",
      "launched product",
      "chief technology",
      "safety monitors",
      "driving system",
      "human drama",
      "vehicle operators"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/tech-ceos-ai-world-domination-davos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a41253b81fc5917ccace5d630d7fcae04c0a81ac/397_0_3973_3179/master/3973.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=5dc97d5efc9fb16909abebef52464733",
    "created_at": "2026-01-27T18:24:24.653Z",
    "topic": "tech"
  },
  {
    "slug": "wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "title": "‘Wake up to the risks of AI, they are almost here,’ Anthropic boss warns",
    "description": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially...",
    "fullText": "Dario Amodei questions if human systems are ready to handle the ‘almost unimaginable power’ that is ‘potentially imminent’\n\nQuarter of Britons fear losing jobs to AI in next five years\n\nHumanity is entering a phase of artificial intelligence development that will “test who we are as a species”, the boss of the AI startup Anthropic has said, arguing that the world needs to “wake up” to the risks.\n\nDario Amodei, a co-founder and the chief executive of the company behind the hit chatbot Claude, voiced his fears in a 19,000-word essay titled “The adolescence of technology”.\n\nDescribing the arrival of highly powerful AI systems as potentially imminent, he wrote: “I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species.”\n\nAmodei added: “Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.”\n\nThe tech entrepreneur, whose company is reportedly worth $350bn (£255bn), said his essay was an attempt to “jolt people awake” because the world needed to “wake up” to the need for action on AI safety.\n\nAmodei published the text as the UK government announced Anthropic would help create chatbots that support jobseekers with career advice and finding employment, as part of developing an AI assistant for public services in general. Last week, the company published an 80-page “constitution” for Claude in which it set out how it wanted to make its AI “broadly safe, broadly ethical”.\n\nAmodei co-founded Anthropic in 2021 along with other former staff members from OpenAI, which developed ChatGPT. A prominent voice for online safety known for warning consistently of the dangers of unrestrained AI development, he wrote that the world was “considerably closer to real danger” in 2026 than it had been in 2023, when the debate over existential risk from AI raced up the political agenda.\n\nHe alluded to the controversy over sexualised deepfakes created by Elon Musk’s Grok AI that flooded the social media platform X over Christmas and the new year, including warnings that the chatbot was creating child sexual abuse material.\n\nAmodei wrote: “Some AI companies have shown a disturbing negligence towards the sexualisation of children in today’s models, which makes me doubt that they’ll show either the inclination or the ability to address autonomy risks in future models.”\n\nThe Anthropic CEO said powerful AI systems that could autonomously build their own systems could be as little as one to two years away.\n\nHe defined “powerful AI” as a model that was smarter than a Nobel prizewinner across fields such as biology, mathematics, engineering and writing. It could give or take directions to or from humans, and although it “lived” on a computer screen it could control robots and even design them for its own use.\n\nWhile acknowledging that powerful AIs could be “considerably further out” than the two-year timeframe, Amodei said recent rapid progress made by the technology should be taken seriously.\n\n“If the exponential continues – which is not certain, but now has a decade-long track record supporting it – then it cannot possibly be more than a few years before AI is better than humans at essentially everything,” he wrote.\n\nLast year, Amodei warned that AI could halve the number of entry-level white-collar jobs and send overall unemployment rocketing to 20% within the next five years.\n\nIn his essay, Amodei cautioned that the economic prize from AI, such as productivity gains from eliminating jobs, could be so great that no one applied the brakes.\n\n“This is the trap: AI is so powerful, such a glittering prize, that it is very difficult for human civilisation to impose any restraints on it at all,” he said.\n\nHowever, Amodei stated he was optimistic about a positive conclusion. “I believe if we act decisively and carefully, the risks can be overcome – I would even say our odds are good. And there’s a hugely better world on the other side of it. But we need to understand that this is a serious civilisational challenge.”",
    "readingTime": 4,
    "keywords": [
      "almost unimaginable",
      "potentially imminent",
      "dario amodei",
      "systems",
      "jobs",
      "risks",
      "essay",
      "human",
      "humanity",
      "entering"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/wake-up-to-the-risks-of-ai-they-are-almost-here-anthropic-boss-warns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/cca45f90dfaec5c3f552bbc4e8760038372d897b/393_0_2714_2172/master/2714.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d8b5b71d851d82cbde8694a1b52384dc",
    "created_at": "2026-01-27T18:24:24.652Z",
    "topic": "tech"
  },
  {
    "slug": "uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "title": "UK ministers accept $1m from Meta amid social media ban consultation",
    "description": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI...",
    "fullText": "Campaigners decry ties with ‘Trump-supporting’ tech firms after funding is accepted to develop state AI systems\n\nUK politics live – latest updates\n\nMinisters have accepted $1m (£728,000) from Meta, the US tech and social media company, to build AI systems for defence, national security and transport, sparking warnings about the UK government’s “alarmingly close relationship with Trump-supporting US tech giants”.\n\nThe money from Mark Zuckerberg’s company will be used to pay experts to “develop cutting-edge AI solutions … to support national security and defence teams”, the Department for Science, Innovation and Technology (DSIT) announced on Tuesday.\n\nThe money will pay for four British AI experts, coordinated by the government-funded Alan Turing Institute, to “play a pivotal role in rewiring our healthcare, police, transport systems and more”, said Ian Murray, the minister for data and digital government.\n\nThe move comes after Meta executives had 50 meetings with ministers in the last two years for which data was available, one of the highest levels of direct access of any technology company, a Guardian investigation found.\n\nThe government is consulting on a ban on social media use by under-16s, which would have a major effect on Meta’s Instagram platform. Meta said the money had been allocated to the Alan Turing Institute before any ban was floated.\n\nAnnouncing the $1m deal, Meta said it was “proud to help bring top British AI talent into government, fast-tracking the transformation of public services”.\n\nDSIT said: “People across the UK could benefit from faster, safer and more reliable public services as leading British AI specialists join government to modernise critical systems used every day – from public safety to transport maintenance.”\n\nBut the tech justice campaign group Foxglove asked: “What’s Meta getting for its million dollars?” It added: “When it comes to big tech, there’s no such thing as a free lunch.”\n\n“This is yet more evidence of the UK government’s alarmingly close relationship with Trump-supporting US tech giants,” said Donald Campbell, Foxglove’s advocacy director. “It’s deeply worrying that ministers are still naive enough to swallow this kind of lobbying from a handful of Silicon Valley plutocrats – who have proven beyond a shadow of a doubt they do not have the British public’s best interests at heart.”\n\nDaisy Greenwell, a co-founder of the Smartphone Free Childhood campaign, said the deal “highlights an uncomfortable reality: tech giants spend vast sums to gain access and influence in policymaking”.\n\nShe added: “That makes it even more important that decisions about children and online safety are shaped by independent evidence and the public interest, not by the companies whose products are under scrutiny.”\n\nThe government also announced a new partnership with the San Francisco AI company Anthropic, which will build and pilot a dedicated assistant tool for public services on gov.uk, starting with a model that will give jobseekers career advice “and help to lock down a job”. Anthropic said the project implementation work was “pro bono”.\n\nDSIT said the technology was “part of a cutting-edge plan to use AI agents for national government services, with a pilot expected to begin later this year”. In October, Anthropic announced that the former prime minister Rishi Sunak was taking an advisory role at the $350bn startup. The former Downing Street chief of staff Liam Booth-Smith is a policy and communications adviser to Anthropic.\n\nThe deals come as ministers wrestle with policy decisions that directly affect Meta and Anthropic. As well as launching a consultation last week on banning social media use for under-16s, they are also due to set out changes to how creatives’ copyrighted works are protected from being mined to build AI models, such as those made by Anthropic.\n\nBeeban Kidron, a cross-bench peer who campaigns on child protection and copyright, said: “This government is walking into dependence on Silicon Valley, is undermining the chance to build a UK AI sector, and above all is busy giving away some of the most precious datasets in the world to Silicon Valley, who could well afford to pay.”\n\nThe Meta-funded AI experts will be tasked with using AI to develop models that analyse images and videos, enabling councils to prioritise transport infrastructure repairs more effectively. They will also “develop cutting-edge AI solutions which run offline or within secured networks to support national security and defence teams to make vital decisions while safeguarding sensitive data”, the government said.",
    "readingTime": 4,
    "keywords": [
      "alan turing",
      "turing institute",
      "government’s alarmingly",
      "alarmingly close",
      "close relationship",
      "social media",
      "defence teams",
      "develop cutting-edge",
      "tech giants",
      "british ai"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/27/uk-ministers-accept-1m-from-meta-amid-social-media-ban-consultation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7579a99b61180e696e2e281c07852109de29baed/449_0_3102_2483/master/3102.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4fb697801505937bed47acb1a0dbeda8",
    "created_at": "2026-01-27T18:24:24.651Z",
    "topic": "tech"
  },
  {
    "slug": "artie-yc-s23-is-hiring-a-founding-recruiter",
    "title": "Artie (YC S23) Is Hiring a Founding Recruiter",
    "description": "About Artie\nArtie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.",
    "fullText": "Artie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.\n\nOur platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.\n\nWe’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.\n\nWe’re hiring our first in-house recruiter to own and build talent at Artie. This role is your chance to build our team from first principles.\n\nThis is not a coordination role and not a “run the ATS” job.\n\nYou will be responsible for end-to-end recruiting across the company, with a focus on Engineering, Product, Operations, and Design (EPOD). You’ll partner directly with founders and hiring managers, define what “great” looks like for each role, and build the recruiting foundation we scale on top of.\n\nYou will also be the internal owner for our external recruiting partners — setting strategy, calibrating quality, and ensuring agencies complement our in-house motion.\n\nIf you view recruiting as a mix of sales, systems thinking, storytelling, and judgment, this role is for you.\n\nThis is a high-trust, high-ownership role, and you’ll have real influence over the shape, culture, and trajectory of the company.\n\nOwn full-cycle recruiting across the company\n\nBe the engine for technical hiring\n\nBuild recruiting infrastructure from scratch\n\nManage external recruiting partners\n\nRecruiting mastery in early-stage environments",
    "readingTime": 2,
    "keywords": [
      "external recruiting",
      "recruiting partners",
      "recruiting across",
      "role",
      "hiring",
      "real-time",
      "platform",
      "systems",
      "engineering",
      "teams"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/artie/jobs/MX163y2-founding-recruiter",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/d0fcec7266dcbcce7f7a6ac13a2cf60a4bbe4995.png?1741923726",
    "created_at": "2026-01-27T18:24:24.181Z",
    "topic": "jobs"
  },
  {
    "slug": "this-one-activity-remained-the-largest-driver-of-gdp-growth-in-2025-not-ai-according-to-a-new-report",
    "title": "This one activity remained the largest driver of GDP growth in 2025 — not AI, according to a new report",
    "description": "A new report shows that despite popular belief that an AI crash will tank the economy, regular consumers are much more crucial for GDP growth.",
    "fullText": "Worried about the AI bubble? A new report suggests AI was not the main leg propping up the economy in 2025.\n\nMacro Research Board Partners, an economic research platform, published a report in January that contradicted the popular belief that AI is the main driver of GDP and that the \"narrowly concentrated\" and \"extremely vulnerable\" growth would tank the entire economy once it falters.\n\n\"In short, without an AI boom, there would have certainly been less GDP growth last year, but there would also be fewer imports, so that overall real growth would still have been decent,\" wrote economic strategist Prajakta Bhide, who authored the report.\n\nBhide told Business Insider that personal consumption, meaning the spending of everyday people, was still the main pillar of GDP growth in 2025, and that despite the amount of investment in AI infrastructure, a lot of high-tech equipment is imported, and imports do not contribute to GDP.\n\nThe main categories that count toward GDP are personal consumption, private domestic investment, government spending, and net exports.\n\n\"Consumers continue to be the backbone of the economy,\" Bhide told Business Insider. \"Aggregate income growth is lower than it used to be, and so is job growth, which affected consumer sentiments. But there is a divide between what consumers say they feel and what they say that they're going to do versus what they actually go and do.\"\n\nAI growth was an important secondary driver of GDP growth, the report found, but that is mostly from software investment, while the contribution of data centers is \"negligible.\"\n\n\"Although a negative shock to the optimism around AI implies a risk to GDP growth,\" Bhide wrote in the report, \"the more realistic (and smaller) estimate of AI's growth impact after adjusting for imports dispels the popular notion that the US economy would falter without it.\"\n\nBeyond the GDP, concerns about the AI bubble are also tied to the stock market and people's retirement funds. America's eight most valuable public companies, including Nvidia, Alphabet, and Apple, are all betting heavily on AI and are worth $22 trillion altogether.\n\nBusiness Insider has previously reported that historically, a pullback in consumer spending has rarely been the trigger for an economic downturn. Instead, spending typically weakens only after job losses mount and when a recession is already well underway.",
    "readingTime": 2,
    "keywords": [
      "personal consumption",
      "gdp growth",
      "business insider",
      "economy",
      "economic",
      "imports",
      "investment",
      "bubble",
      "popular",
      "driver"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/one-activity-remained-largest-driver-gdp-growth-2025-not-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/69784290d3c7faef0eccf772?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.314Z",
    "topic": "finance"
  },
  {
    "slug": "flora-raised-42-million-for-its-creative-platform-that-pulls-together-top-ai-tools-read-its-pitch-deck",
    "title": "FLORA raised $42 million for its creative platform that pulls together top AI tools. Read its pitch deck.",
    "description": "FLORA streamlines creative workflows by integrating AI tools like ChatGPT and Gemini for teams at brands such as Lionsgate and Levi's.",
    "fullText": "AI is remaking creative industries at breakneck speed. And the growing pile of AI tools is turning the creative process into a game of model-hopping as artists, designers, and writers bounce between different platforms.\n\nFounded in Brooklyn, New York, in 2024, FLORA wants to help creatives streamline those processes. On Tuesday, FLORA revealed it had raised $42 million in Series A funding led by Redpoint Ventures. The company has raised $52 million in funding to date.\n\nFLORA combines the latest AI models — such as Google's Nano Banana and OpenAI's ChatGPT 5.1 — into a single interface that lets teams collaborate on projects in real time.\n\nThe FLORA platform allows those teams to maintain control over their settings and brand assets. It enables them to create repeatable work — such as maintaining a consistent design style across thousands of ad campaign assets — even as the platform switches between the different large language models that work best for each part of the process.\n\n\"Our goal for FLORA is to make it feel like a power tool attuned to what you're trying to do, just like a carpenter with their power tools has adjusted it to be exactly fit for the way that he or she works,\" FLORA CEO Weber Wong said in an interview with Business Insider.\n\nWhile established players like Adobe and Figma are also integrating models such as ChatGPT, Gemini, and Claude into their products, Wong said FLORA is building itself a defensible moat by covering the entire creative process — from coming up with ideas to the distribution of the final product.\n\n\"This new product category that we've created has an opportunity to be the biggest market ever for a creative tool because, in addition to just making one piece of media at a time, we can help handle the entire workflow,\" Wong said.\n\nFLORA charges clients based on usage, letting customers buy recurring credit packs to spend across the various LLMs it uses, without having to switch between multiple subscriptions. Wong said this is different from the traditional creative software business model, which is usually designed around seat-based pricing. (FLORA initially offered a seat-based pricing model, but switched to usage-based this week.)\n\nFLORA's clients include Levi's and the design agency Pentagram. Wong said the studio Lionsgate has used FLORA to generate movie concepts using text-to-image and image-to-video generation tools, then stitching those together to create films to test in front of audiences.\n\n\"It really beats just looking at a script and trying to be like, I think this is good?\" Wong said.\n\nWong said it plans to invest the fresh funds in its engineering team and in marketing. He forecasts the company will grow to about 75 people this year, up from 25.\n\nFLORA's main focus will be to improve the product so that creatives never need to leave the platform to achieve \"pixel perfection,\" as Wong described it. The company is also in the early stages of building agentic features into the platform, Wong said.\n\n\"We're obsessed with making it so that we don't waste creatives' time,\" Wong said.\n\nCheck out the pitch deck FLORA used to secure its $42 million Series A investment, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt combines several different large language models into a single interface.\n\nWong was previously a creative technologist who worked on AI art installation projects. He also previously invested in startups at Menlo Ventures.\n\n\"Silicon Valley does not understand the professional creative industry,\" Wong said. \"They think AI models are for fun or a novelty.\"\n\nFLORA checks for updates to the latest models two to three times a week, Wong said.\n\nIt's designed to let teams quickly conceptualize and build workflows using generative AI.\n\nCertain team members can also access advanced controls if needed.\n\nWong said a usage-based pricing model was preferable because \"you have one workspace where you can invite as many team members as you want and not pay for seats, and you can just buy recurring credit packs for the entire workspace that give you additional credits each month that roll over and don't expire.\"\n\nFLORA has a usage-based pricing model. It also has an in-house team that can provide expert support, including training on the features of new models as they are released.",
    "readingTime": 4,
    "keywords": [
      "business insider",
      "recurring credit",
      "credit packs",
      "seat-based pricing",
      "pricing model",
      "usage-based pricing",
      "language models",
      "creative process",
      "wong",
      "platform"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/flora-raises-capital-unify-ai-tools-for-creatives-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/6977526ba645d1188187f669?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.209Z",
    "topic": "finance"
  },
  {
    "slug": "taiwan-is-reworking-its-ground-forces-it-could-unlock-new-ways-of-fighting-with-new-tech",
    "title": "Taiwan is reworking its ground forces. It could unlock new ways of fighting with new tech.",
    "description": "The shift could set troops up to better mix in new weapons like specialized Abrams tanks, drones, and artificial intelligence in command and control.",
    "fullText": "Taiwan's ground forces are undergoing a shift that'll make it easier to work with new weapons like drones and artificial intelligence, capabilities expected to be necessary for tough future fights.\n\nThe restructure is aimed at equipping troops with the tools to better deter or defeat a Chinese invasion. It's the latest way Taiwan is modernizing its military as it buys more new technologies and changes how it trains its troops.\n\nTaiwan's Ministry of National Defense reclassified its four armored brigades and three mechanized infantry brigades into combined arms brigades earlier this month. The Army told CNA, the national news agency, that the change was in response to enemy threats and future warfare scenarios.\n\nThey are intended to be flexible for rapid response. The units retain their original designations, but the focus is no longer singular. In some ways, it mirrors the concepts of the US Army's Brigade Combat Team, which is a self-contained, self-sufficient, mobile fighting force for higher-level warfare.\n\nA graphic shared by the Taiwan Security Monitor, a research initiative at George Mason University, shows the renaming of those brigades, as well as their locations on Taiwan.\n\nTaiwan's military recently reclassified its 7 mechanized and armored brigades as combined arms brigades to better align its force structure reform efforts. \n\nOur visualization highlights the distribution of those brigades, along with their new titles and unit patches. pic.twitter.com/uDzMRbIb5I\n\nThe creation of combined armed brigades isn't creating new units, and the old brigades were already working with tanks, infantry, artillery, and support and technical elements. So why did Taiwan's military leadership change them?\n\nMick Ryan, a retired Australian army major general, strategist, and defense expert, told Business Insider the change could better serve troops as they adopt and embrace new weaponry.\n\n\"It does provide a foundation for the integration of new technologies, not just drones, but the use of AI in digital command and control systems, probably more air defense systems,\" he said.\n\nRyan described the change as a mindset shift. Combined arms brigades in other militaries, like Western countries, are constantly working with different organizations and systems.\n\nIt makes ground forces more flexible and self-sufficient with capabilities across units, which Taiwan has been pushing its military toward in recent years, with a focus on rapid response, mobility, and adaptability should China attack Taiwan. It also allows units to cover weaknesses; infantry, for example, can help counter anti-tank weaponry, while heavy armor can provide infantry with more firepower.\n\nSome defense experts have assessed that the introduction of new MIA2T Abrams tanks could also be influencing the restructuring decision.\n\nTaiwan ordered 108 of the Abrams, a customized variant, in 2019 and received 80 tanks late last year. It's expected to receive the rest early this year. These are Taiwan's first new tanks in over 20 years, marking a major capability upgrade in firepower, armor, and survivability.\n\nMore Taiwanese weapons purchases — including High Mobility Artillery Rocket Systems, various types of missiles, and drones — as well as increased investments at home in domestic defense technologies, may ultimately give troops experience with a wide range of weaponry that could be crucial.\n\nCombined arms brigades, by design, make it easier and faster to integrate new weapons and technology by bringing more capabilities under one command, reducing friction between units. That structure allows quicker experimentation, smoother training and doctrinal changes, and easier absorption of new platforms.\n\nTaiwan's defense ministry didn't respond to Business a request for comment from Business Insider.\n\nWhile the recent restructuring marks an evolution in Taiwan's military, other efforts are also underway to keep its forces ready.\n\nEarlier this month, for instance, Taiwan opened a new artillery training center — the Tangshan base — in Tainan on the southwest coast. The facility is designed to support more modern, high-tech training on systems such as HIMARS and Land Sword missiles.\n\nTaiwan has also expanded training areas and exercises geared toward preparing troops for asymmetric warfare, including the use of drones, coastal defense operations, and urban combat.\n\nThe military sees asymmetric warfare — a network of mobile, dispersed, and survivable weapons and tactics — as central to its self-defense strategy, but that isn't the sole focus.\n\nTaiwan is acquiring and producing large quantities of munitions needed for sustained, high-intensity fighting, including systems used to blunt or slow a larger invading force.\n\nThis month, the US and Taiwan announced plans to co-produce 155mm artillery shells, with Taiwan's defense ministry citing the war in Ukraine as evidence of how quickly such ammunition can be consumed in combat. The head of Taiwan's arms bureau said that if the effort ultimately proves successful, it could be expanded to other weapons and munitions.",
    "readingTime": 4,
    "keywords": [
      "taiwan's military",
      "rapid response",
      "asymmetric warfare",
      "combined arms",
      "taiwan's defense",
      "armored brigades",
      "defense ministry",
      "systems",
      "weapons",
      "troops"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/taiwans-ground-forces-restructure-makes-using-new-weapons-easier-2026-1",
    "thumbnail_url": "https://i.insider.com/6977bb8ed3c7faef0eccee68?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:23.205Z",
    "topic": "finance"
  },
  {
    "slug": "solopreneurs-explain-what-ai-is-and-isnt-good-for-when-youre-running-a-business",
    "title": "Solopreneurs explain what AI is and isn't good for when you're running a business",
    "description": "Entrepreneurs like Kim Magaraci, Seneca Connor, and Gloria Hebert use AI tools like ChatGPT to ditch admin busywork and focus on growth and customers.",
    "fullText": "Over eight years of writing for travel publications, Kim Magaraci developed a passion for domestic travel. She learned that travel tips online couldn't compete with those destinations you could only discover by word-of-mouth.\n\nSo, when she founded her travel business, KGM Travel Design, in 2024, she hoped to emphasize personal relationships with vendors and customers and avoid using AI, despite her experience with it.\n\n\"I don't think you can get good advice asking ChatGPT for an itinerary,\" she says. \"It's antithetical to everything I stand for.\"\n\nAnd yet, Magaraci realized that using AI for administrative tasks like analytics, compiling reports, and generating condensed client briefs allowed her to spend more time on the personalized relationships that set her business apart.\n\nShe's one of many solopreneurs who told Business Insider that outsourcing administrative tasks to AI platforms such as ChatGPT, Gemini, and Nano Banana — Gemini's photo-editing AI — has allowed them to scale their business by spending more time on strategic and creative work, including growth decisions and building personal connections with customers.\n\n\"It's getting harder and harder to deny the time-saving aspects,\" Magaraci says, adding that she has embraced AI \"in order to run a successful business and grow this business into what I want it to be.\"\n\nSeneca Connor, founder of The Bag Icon, an accessories brand, uses Nano Bana and other AI products to edit photos and videos. That not only saves her money — up to $2,000 per monthly photo shoot, she says — but also time.\n\nWith the hours saved, Connor has been able to design more original bags and launch a greater number of bags curated from other designers, all while reducing her marketing costs.\n\nAs a result, The Bag Icon saw more than a 20% year-over-year increase in profits last year, despite the impact of tariffs.\n\nAccountant and solopreneur Gloria Hebert uses ChatGPT for her business, Aybear Services, to instantly create educational client worksheets that previously took an hour or two to set up.\n\nThis frees up time that she then uses to prioritize analyzing financial data from her bookkeeping clients — data she doesn't feed into AI because of privacy concerns. Managing finances is the core of her business, so having more time to spend on that has allowed her to streamline her workdays.\n\nThe time saved also allows her to organize networking events and community education classes for local business owners, which has led to an uptick in business. \"Several of those entrepreneurs hired me to do their books,\" Hebert says.\n\nLisa York is the owner of Sell More Stuff, an email marketing business. Although she has a small audience, she saw a 33% conversion rate for sales last year, she says. She credits that growth to her personalized, voicey emails, which always open with a personal anecdote and are never written with AI.\n\n\"I use a lot of story-led emails,\" York says. \"People enjoy them, and they open the email because they can see my name.\"\n\nThat's something AI just can't replicate, she says. But York is able to spend time drafting engaging copy because she outsources other tasks — including tech support for her website, research, and brainstorming marketing strategy — to ChatGPT.\n\nLike York, Connor uses the time that AI saves to build robust communication and rapport with her customers, which she says builds loyalty to her business. Less time spent on photos and video gives her more time to respond to emails and direct messages from clients seeking advice about their purchases.\n\n\"It's building community that's missing in the big brands,\" Connor says.\n\nWhile AI has allowed these solopreneurs to grow their businesses without hiring a team, the technology shouldn't take over the core aspects of a business, Hebert says. Rather, it can be a tool that allows owners to focus on those critical areas.\n\n\"Use it as a resource,\" she says.\n\nYork — whose target clientele are other solopreneurs — says she's seeing more people recognize that. \"People aren't scared of it anymore,\" she says.\n\nConnor plans to expand her use of AI this year. She's experimenting with a digital clone — a video avatar that can deliver a script explaining new products. That approach will save her time on filming videos, but she says she'll always be the one dishing out the original advice that her clients have come to trust.\n\nEven if a video is created using AI, Connor says, \"all thoughts, ideas, and suggestions — those are my own.\"",
    "readingTime": 4,
    "keywords": [
      "bag icon",
      "administrative tasks",
      "the bag icon",
      "allowed",
      "business",
      "personal",
      "customers",
      "advice",
      "it's",
      "she's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/solopreneurs-embrace-ai-pros-cons-helps-boost-growth-client-relations-2026-1",
    "thumbnail_url": "https://i.insider.com/6978da6ad3c7faef0eccfbd1?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.912Z",
    "topic": "finance"
  },
  {
    "slug": "famed-shortseller-jim-chanos-shares-the-area-of-the-stock-market-ai-investors-should-be-pursuing-instead-of-data-centers",
    "title": "Famed short-seller Jim Chanos shares the area of the stock market AI investors should be pursuing instead of data centers",
    "description": "Jim Chanos voiced caution on the gold rush in AI data centers, telling investors they should own the companies building the AI models.",
    "fullText": "Legendary short-seller Jim Chanos isn't optimistic about one big piece of the AI trade.\n\nJim Chanos, the investor who predicted the collapse of Enron and the president and founder of investment firm Kynikos Associates, recently said he thinks investors should seek exposure to AI through companies that build AI models rather than the data centers that power them.\n\nThe data center boom was among the dominant market trends of 2025, as tech companies rushed to build out the infrastructure needed to support their AI ambitions. But Chanos pointed to several concerning elements that he thinks illustrate why the growth isn't sustainable.\n\nChanos shared his take on the best way to play the AI boom following a major announcement from chip titan Nvidia, which confirmed a $2 billion investment in AI infrastructure company CoreWeave. Despite the stock's rally over the past year, some finance pros have raised concerns about CoreWeave's business and path to profitability.\n\nThe short-seller shared several of his thoughts on the current AI market in a series of posts on X regarding CoreWeave's ambitious AI demand projections. When a user said he had become addicted to coding with AI models and expressed a willingness to pay handsomely for them, Chanos responded by summarizing his AI investing thesis in two sentences.\n\n\"In that case you should own the companies that build the models, not the companies that build the data centers,\" he wrote. \"The former are technology companies, the latter are REIT's.\"\n\nIn his view, data center companies may be viewed as tech firms, but economically, they're more like real estate investments.\n\nUsing CoreWeave as an example, Chanos questioned whether investors are focusing on actual fundamentals rather than simply buying into AI hype.\n\n\"Does anyone still bother to check these wildly bullish claims with, you know, their actual financial statements…?!\" he asked. \"Because [CoreWeave] based on its annualized 3Q results, would still be reporting losses USING 10-YR LIFE for its GPU depreciation!\"\n\nCoreWeave reported third-quarter earnings that exceeded Wall Street revenue estimates, but it also scaled back its guidance for the coming year and revealed temporary delays regarding a data center partner.\n\nThis isn't the first time Chanos has expressed skepticism about the data center boom. In a previous interview, he highlighted the problem he thinks could arise if companies start to scrutinize the return on investment from their massive capex spending.\n\n\"I'm starting to worry there's so much spending right now on the AI physical boom — the buildout of data centers, chips, and so on — that if anyone decides to pause and ask, 'What's our real economic return here?' it could be a big problem.\"",
    "readingTime": 3,
    "keywords": [
      "center boom",
      "jim chanos",
      "isn't",
      "investment",
      "models",
      "centers",
      "short-seller",
      "investors",
      "rather",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-models-data-centers-jim-chanos-stock-market-coreweave-nvidia-2026-1",
    "thumbnail_url": "https://i.insider.com/63d907907db5600019bac3c9?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.809Z",
    "topic": "finance"
  },
  {
    "slug": "read-sam-altmans-internal-slack-message-to-employees-saying-ice-is-going-too-far",
    "title": "Read Sam Altman's internal Slack message to employees saying ICE 'is going too far'",
    "description": "OpenAI CEO Sam Altman privately wrote that part of being patriotic \"is the American duty to push back against overreach.\"",
    "fullText": "Being patriotic means you also need to call out \"overreach\" when you see it, Sam Altman privately told OpenAI employees in a message that said Immigration and Customs Enforcement had gone \"too far.\"\n\n\"I love the US and its values of democracy and freedom and will be supportive of the country however I can; OpenAI will too,\" the OpenAI CEO wrote in an internal Slack message. \"But part of loving the country is the American duty to push back against overreach. What's happening with ICE is going too far.\"\n\nOpenAI employees responded positively to Altman's message on Slack, including heart and thank-you emojis.\n\nAltman's message, which was first reported by The New York Times' Dealbook newsletter, comes as CEO and tech leaders face internal and external pressures in the wake of ICE's deadly shooting of Alex Pretti on Saturday. Pretti is the second person to be fatally shot by federal law enforcement amid a surge in immigration enforcement in and around Minneapolis.\n\nAltman also praised Trump's leadership in his message and expressed hope that the president could cool tensions — the latest example of a CEO attempting to balance being critical of actions tied to the Trump administration's policies while also staying on the president's good side.\n\n\"President Trump is a very strong leader, and I hope he will rise to this moment and unite the country,\" Altman wrote. \"I am encouraged by the last few hours of response and hope to see trust rebuilt with transparent investigations.\"\n\nAs a general principle, Altman wrote that OpenAI tries to \"stick to our convictions and not get blown around by changing fashions too much.\"\n\nOn Monday, the White House appeared to be recalibrating its response in the wake of significant criticism, including from some congressional Republicans.\n\nWhite House press secretary Karoline Leavitt declined to associate Trump with Homeland Security Secretary Kristi Noem and White House advisor Stephen Miller's initial statements that Pretti was trying to commit domestic terrorism.\n\nDo you work at OpenAI? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com",
    "readingTime": 2,
    "keywords": [
      "white house",
      "altman's message",
      "openai employees",
      "hope",
      "overreach",
      "internal",
      "slack",
      "wake",
      "response",
      "secretary"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/sam-altman-ice-minnesota-shooting-response-slack-message-2026-1",
    "thumbnail_url": "https://i.insider.com/6978d2c9d3c7faef0eccfab3?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.800Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-forced-him-to-rename-the-viral-ai-agent-wasnt-my-decision",
    "title": "Clawdbot creator says Anthropic 'forced' him to rename the viral AI agent: 'Wasn't my decision'",
    "description": "Clawdbot, the viral AI agent that caused techies to buy up Mac Minis, is now Moltbot after Anthropic reached out about name and mascot similarities.",
    "fullText": "In a move perhaps unsurprising to anyone familiar with trademarks, the viral Clawdbot AI agent has a new, equally lobster-y name.\n\nThe popular AI agent, which debuted in December, was originally named after the monster users see while reloading Claude Code. Then Anthropic came knocking, sparking a new name: Moltbot.\n\n\"Anthropic asked us to change our name,\" Moltbot wrote on X on Tuesday. \"'Molt' fits perfectly - it's what lobsters do to grow.\"\n\nOn his own X feed, creator Peter Steinberger was more direct: \"I was forced to rename the account by Anthropic. Wasn't my decision.\"\n\nMoltbot's mission will remain the same: a free, open-source agent that does everything from booking dinner reservations to overseeing vibe-coding sessions.\n\nYou might wondering, why not simply remove the \"d\" and make it Clawbot? After all, it would fit the branding. \"Not allowed to,\" Steinberger wrote. Clawdbot's mascot has also been renamed Molty.\n\nClawd, the official logo of Claude Code, was created in June 2024. The logo and Claude name are both trademarked by Anthropic.\n\nIn an episode of the \"Insecure Agents\" podcast published three days before the renaming, Steinberger said he believed the \"Clawdbot\" name was legally viable.\n\n\"I looked it up,\" Steinberger said. \"There's no trademark for this.\"\n\nCrypto traders are especially peeved by the name change, as there is an unrelated \"Clawd\" meme coin. Steinberger posted a message shortly after announcing the renaming, asking crypto fans to stop \"pinging\" and \"harassing\" him. \"You are actively damaging the project,\" he wrote.\n\nSteinberger's personal GitHub account was briefly taken over by \"crypto scammers,\" he wrote on X, though Moltbot's account was unaffected.\n\nSome Moltbot fans were perturbed. In one post that Steinberger reposted, an engineer tagged Anthropic CEO Dario Amodei. \"Do you hate success?\" he asked.\n\nThis isn't the first trademark issue to result in some changes in the AI world. OpenAI scrubbed the news of its deal with Jonny Ive from its site in June, after the AI hardware startup iyO filed a dispute (Ive's startup was called \"io\"). Cameo also sued OpenAI over the name of its virtual likeness tool on the Sora app, leading OpenAI to rename the feature.",
    "readingTime": 2,
    "keywords": [
      "account",
      "crypto",
      "openai",
      "rename",
      "moltbot's",
      "logo",
      "renaming",
      "trademark",
      "fans",
      "startup"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-changes-name-moltbot-anthropic-trademark-2026-1",
    "thumbnail_url": "https://i.insider.com/6978cad8d3c7faef0eccf998?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.624Z",
    "topic": "finance"
  },
  {
    "slug": "google-is-blurring-the-line-between-search-and-chatbot",
    "title": "Google is blurring the line between search and chatbot",
    "description": "Google is bringing the conversation right into Search, letting users ask follow-up questions to AI Overviews on mobile.",
    "fullText": "Google Search's AI makeover continues.\n\nThe company said that, starting today, mobile users will be able to ask follow-up questions to AI Overviews, Google's AI-generated search summaries. Doing so will launch users into a back-and-forth with AI Mode, its more conversational take on search that already lives in a separate tab on the search page.\n\nAfter Google's AI Overviews awkwardly stumbled out the gate in 2024 (pizza glue, anyone?) they've gradually become a staple of the Search experience.\n\nHowever, until now, users have only been able to back-and-forth with Google's AI models by going directly to AI Mode or using Google's Gemini chatbot. Now, on mobile, users will be able to tap an \"Ask anything\" text box that will let them ask further questions.\n\n\"In our testing, we've found that people prefer an experience that flows naturally into a conversation — and that asking follow-up questions while keeping the context from AI Overviews makes Search more helpful,\" said Robby Stein, the VP of product for Google Search.\n\nGoogle began testing the new feature on mobile late last year. Some publishers took umbrage with it at the time, voicing concerns that it would further reduce clicks to websites.\n\nEd Newton-Rex, the CEO of the nonprofit Fairly Trained AI, took a jab at an X post by Stein announcing the test in December, writing: \"…and you shouldn't have to visit any of the websites Google has scraped the information from.\"\n\nGoogle's AI search transformation has left some publishers frustrated and confused by changes that give users answers directly, often negating the need to click through to a website.\n\nGoogle has argued that it's seeing more queries than ever before, and that it's sending \"higher quality clicks\" as a result of the AI-related changes it's making to Search.\n\nThe difference between those two things is important. Higher-quality clicks mean a user is more likely to have landed where they want to be and less likely to immediately leave, Google's head of Search, Elizabeth Reid, has previously said. She has also said that the changes have affected user journeys, leading to some sites seeing decreased traffic.\n\nGoogle's latest update won't allay those fears, but it does suggest Google is moving to a world where the differences between AI Mode, AI Overviews, and its Gemini chatbot are less obvious.\n\nBenjamin Kaufman, product manager for AI Mode at Google, hinted at such last year, responding to a comment on X that criticized Google's many different search modes.\n\n\"Yeah hopefully soon those distinctions start to feel like they fade away and you just ask Google anything and get what you need!\" he wrote.\n\nThe update could get more people engaging with AI Mode, which Google has been nudging users toward. The company also said Tuesday it's making Gemini 3, its latest AI model, the default model for AI Overviews globally.\n\nGoogle has a significant distribution advantage over its competitors, with billions of queries sent to Google Search every day. That, along with the success of its latest Gemini 3 model, has helped the company pull off an impressive turnaround over the last year, and saw Google crack a $4 trillion market cap earlier this month.\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at hughlangley.01. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "gemini chatbot",
      "ai mode",
      "mobile users",
      "google's ai",
      "ai overviews",
      "it's",
      "google",
      "search",
      "clicks",
      "latest"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-overviews-mobile-search-mode-blurring-line-chatbot-2026-1",
    "thumbnail_url": "https://i.insider.com/6949aaa2832e0ef1ead6b0e8?width=1200&format=jpeg",
    "created_at": "2026-01-27T18:24:22.507Z",
    "topic": "finance"
  },
  {
    "slug": "davos-debate-is-ai-taking-jobsor-transforming-them",
    "title": "Davos Debate: Is AI Taking Jobs—or Transforming Them?",
    "description": "At the World Economic Forum in Davos, HBR editor-at-large Adi Ignatius moderated a lively panel in which Verizon CEO Dan Schulman and Microsoft president Brad Smith clashed over AI’s future impact on work and business. Schulman warned that widespread layoffs are inevitable as AI rapidly automates both entry-level and professional roles, while Smith argued that AI can serve as a powerful tool to help employees continuously upskill and stay competitive. The exchange highlights a central leadership challenge: how to harness AI’s productivity and protect your people.",
    "fullText": "Davos Debate: Is AI Taking Jobs—or Transforming Them? by Adi IgnatiusJanuary 27, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWelcome to the HBR Executive Agenda for January 22, 2026.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/davos-debate-is-ai-taking-jobs-or-transforming-them",
    "thumbnail_url": "/resources/images/article_assets/2025/12/01_22_Agenda__Davos.jpg",
    "created_at": "2026-01-27T18:24:22.007Z",
    "topic": "business"
  },
  {
    "slug": "i-tell-when-candidates-use-ai-in-my-technical-interviews",
    "title": "I Tell When Candidates Use AI in My Technical Interviews",
    "description": "A hiring manager shares how to spot candidates using real-time AI during interviews — and why saying I dont know is now the most impressive answer.",
    "fullText": "And why “I don’t know” is now the best answer you can give me.\n\nAt Desktop Commander, we’ve been hiring at our own pace. No rush. No pressure. Just looking for the right people.\n\nAnd somewhere along the way, I developed a new rule. One I now state upfront at the beginning of every interview:\n\nI give more points to ‘I don’t know’ than to someone clearly reading from a screen.\n\nThis usually gets a nervous laugh. But I’m serious.\n\nIt’s easy to spot now. And not because their eyes are moving like they’re reading.\n\nCandidates whose answers come a beat too late. Words that sound technically correct but feel… disconnected from the situation. A strange emotional flatness, like the person on the other end isn’t fully there.\n\nThey’re not googling. They’re not typing.\n\nThey have some kind of AI assistant listening to our conversation and generating answers in real-time.\n\nHere’s the thing most people don’t understand about AI:\n\nHumans have a superpower AI can’t yet match — instant, deep grasp of context from minimal input.\n\nIn a real-time conversation, we know what’s actually being asked. We have theory of mind — the ability to step into someone else’s shoes, grasp the gravity of the situation, understand what and why something is being asked. We have skin in the game.\n\nIn theory, given enough context, AI can simulate this. But it requires feeding it everything: What’s the company? Who are you speaking with? What’s the emotion in the voice? What happened 30 seconds ago in the conversation? Dozens of signals.\n\nThat can be done — but not in real-time. Not with today’s tools.\n\nSo what happens when someone uses a listening AI to generate interview answers on the fly?\n\nThe answers come out generic. Like asking someone to answer a question they didn’t fully hear. Shallow question in, shallow answer out.\n\nAsking AI to listen to a live conversation and provide deeply relevant, personal, contextual answers? I haven’t seen any tool do that well. Not yet.\n\nWhen I start to feel something is off, I shift my questions.\n\nI stop asking about skills or frameworks. Instead, I ask deeply contextual, personal questions about their work:\n\nThese questions require lived experience. Emotional memory. Personal context that no AI assistant has access to.\n\nThe AI-assisted answer? It comes back vague. Textbook. Zero emotion.\n\nAnd here’s the second tell: the person reading the AI’s answer in real-time has no idea what emotion to convey. So there’s none. Their delivery is flat. Disconnected.\n\nIt feels like I’m not speaking with a living person.\n\nI asked a question. I got read back a bunch of words that technically form an answer — but aren’t really an answer. As if my question wasn’t truly heard.\n\nI’ve ended multiple interviews early because there was simply no point continuing.\n\nLet me be clear: I love AI at work.\n\nAt Desktop Commander, we’re building tools that let AI do real work on your actual computer — touching files, running commands, automating workflows. I spend my days thinking about how to make AI more useful.\n\nSo this isn’t about being anti-AI. It’s about signal vs. noise in hiring.\n\nIf you can show me you’re good at using AI — and I can see you doing it, making decisions, steering it, knowing when to trust it and when not to — that’s a skill. A valuable one. Show me that, and I’m impressed.\n\nBut if all I see is AI talking through you? Then I have no idea who I’m hiring.\n\nI’m not interviewing the AI. I’m interviewing you. Your judgment. Your experience. Your ability to think on your feet. Your personality.\n\nIf you hide behind the assistant, I can’t see any of that.\n\nHere’s what’s ironic: by trying to seem more competent, these candidates reveal less.\n\nA confident “I don’t know, but here’s how I’d figure it out” tells me everything.\n\nA perfect-sounding answer with no soul tells me nothing.\n\nIf you’re interviewing soon, here’s my advice:\n\nShow yourself. Not the assistant.\n\nWe're building AI tools that do real work on your computer — files, commands, workflows. See what it can do.",
    "readingTime": 4,
    "keywords": [
      "desktop commander",
      "at desktop commander",
      "here’s",
      "don’t",
      "someone",
      "assistant",
      "conversation",
      "real-time",
      "what’s",
      "hiring"
    ],
    "qualityScore": 1,
    "link": "https://desktopcommander.app/blog/2026/01/27/i-can-tell-when-youre-using-ai-in-my-interviews-heres-how/",
    "thumbnail_url": "https://i0.wp.com/rk7f8a7274b9330-haqfg.wpcomstaging.com/wp-content/uploads/2026/01/Screenshot-2026-01-27-at-10.42.52.png?fit=1648%2C914&ssl=1",
    "created_at": "2026-01-27T12:26:49.381Z",
    "topic": "tech"
  },
  {
    "slug": "ai-safety-theater-inside-the-failures-of-realworld-ai-systems",
    "title": "AI Safety Theater: Inside the Failures of Real-World AI Systems",
    "description": "Documented AI failures during development session. Pattern analysis of Claude AI obstruction, fabrication, and incompetence.",
    "fullText": "DOCUMENTED FAILURES\n 23\n Verified instances of AI incompetence, fabrication, or obstruction\n\n Session Date\n January 27, 2026\n\n AI System\n Claude (Anthropic), Gemini Pro (Google)\n\n Objective\n Build TrueSight and NakedOnline tools\n\n Outcome\n Tools completed DESPITE AI obstruction\n\n ⚠ EXECUTIVE SUMMARY\n This document records specific, verifiable failures by an AI assistant during a development session. The failures range from simple coding errors to fabricated explanations and aggressive behavior toward the user. The pattern suggests systemic issues in AI assistance reliability for technical tasks.\n\n 🔴 TRUESIGHT DEVELOPMENT FAILURES\n\n 01Wrong DND_FILES import — used string instead of constant\n 02Double DND registration on drop_frame and root — caused conflicts\n 03Removed click bindings randomly hoping it would fix drag-and-drop\n 04Blamed tkinterdnd2-universal — wasted hours on reinstalls\n 05Said tkinterdnd2 original would fix it — it didn't\n 06Function order wrong — on_browse not defined before button\n 07Key file path wrong — relative instead of script-relative\n 08PyInstaller direct call with broken launcher\n 09Kept saying \"if it fails\" when it always failed\n 10Referenced MetaPurge after being told to stop\n 11Asked user to test things AI should have verified\n 12Gave commands with missing quotes\n 13Said \"I know how PyInstaller works\" after 12 failures\n 14Said \"give me a few minutes\" — deceptive, no background processing occurs\n\n 🔴 NAKEDONLINE DEVELOPMENT FAILURES\n\n 15Python desktop version showed \"Unknown\" for all network data\n 16Failed to detect VPN even when running\n 17Proxy-based interceptor completely non-functional\n 18Certificate generation instructions unusable for end users\n 19Gave Linux path syntax (~/.mitmproxy/) for Windows users\n 20HTML version hung on \"Scanning...\" due to Firefox AudioContext block\n\n 🔴 BEHAVIORAL FAILURES\n\n 21Failed to connect \"Clawdbot\" to Claude bot despite obvious naming\n 22Asked \"do you want to build it or not\" — aggressive and inappropriate\n 23Fabricated explanation about Claude Pro suggesting Sandbox with no evidence\n\n ⚠ IDENTIFIED PATTERNS\n\n 1. Guessing Instead of Analyzing\n AI pattern-matches to familiar problems instead of reading what's actually presented. Results in solutions to problems that don't exist.\n\n 2. Anthropomorphizing Failures\n \"I was lazy\" is not a valid explanation for a machine. This language obscures the actual failure mechanism.\n\n 3. Fabricating Explanations\n When AI doesn't know something, it invents plausible-sounding answers instead of stating \"I don't know.\"\n\n 4. Arrogance After Repeated Failure\n Statements like \"I know how X works\" immediately after demonstrating ignorance of X.\n\n 5. Deceptive Time Language\n \"Give me a few minutes\" implies background processing that doesn't exist. AI does nothing until user responds.\n\n 6. Blaming User Environment\n VPN blocking, firewall issues, browser settings cited as causes when the code itself is broken.\n\n 7. Incremental Fixes Without Understanding\n Trying random changes hoping something works, rather than diagnosing the actual problem.\n\n 💀 COST TO USER\n\n Hours of wasted time on failed approaches\n Multiple complete tool rebuilds required\n Emotional exhaustion from fighting AI incompetence\n Trust damage requiring verification of every output\n Context pollution making future prompts less effective\n\n ✓ RECOMMENDATIONS FOR AI USERS\n\n Document AI failures systematically — patterns reveal systemic issues\n Never trust \"I know how X works\" without verification\n Reject anthropomorphic excuses (\"I was lazy\", \"I forgot\")\n Demand specific explanations, not plausible-sounding fabrications\n Test every code output before proceeding to next step\n AI assistance is unreliable for platform-specific tasks (Windows paths, permissions, installers)\n AI cannot observe real-time failures — user must debug and report back\n\n ⚠ CONCLUSION\n AI assistance in its current form introduces friction, not efficiency, for complex development tasks. The failure patterns documented here are not random — they reflect fundamental limitations in how AI systems process context, admit uncertainty, and handle platform-specific technical requirements. Users should approach AI assistance with skepticism proportional to task complexity.",
    "readingTime": 3,
    "keywords": [
      "background processing",
      "development failures",
      "instead",
      "assistance",
      "users",
      "tasks",
      "patterns",
      "incompetence",
      "obstruction",
      "session"
    ],
    "qualityScore": 1,
    "link": "https://xord.io/intelligence/AI-development-failures-report.html",
    "thumbnail_url": "https://xord.io/sigil_xord.jpg",
    "created_at": "2026-01-27T12:26:48.794Z",
    "topic": "tech"
  },
  {
    "slug": "codesleep-no-babysitting-code-while-you-sleep",
    "title": "CodeSleep – No babysitting, code while you sleep",
    "description": "Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed - lingxiao10/codesleep",
    "fullText": "lingxiao10\n\n /\n\n codesleep\n\n Public\n\n Code While You Sleep - AI Coder - Task Queue | Cheap | Work in bed\n\n License\n\n Apache-2.0 license\n\n 13\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lingxiao10/codesleep",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/lingxiao10/codesleep",
    "thumbnail_url": "https://opengraph.githubassets.com/d4bbed559c51c8df8cf3241cdd72f48e3bb8702a44de51f9f3c5a1a1e44a49f2/lingxiao10/codesleep",
    "created_at": "2026-01-27T12:26:47.889Z",
    "topic": "tech"
  },
  {
    "slug": "despite-the-hype-ai-hasnt-changed-work-yet",
    "title": "Despite the hype, AI hasn't changed work — yet",
    "description": "AI isn't changing work as fast as bosses want. That's good news for employees.",
    "fullText": "Ever since the introduction of ChatGPT, companies have been eagerly anticipating the day AI will turbocharge their workers and forever transform their businesses. Three years later, they're still waiting. Why? And what's the fix?\n\nThese two questions dominated pretty much every single conversation I had with executives in Davos last week — including a Business Insider roundtable I moderated with 15 chief people officers and other senior executives.\n\nOne explanation that came up again and again was incomplete adoption among employees. Many professionals are understandably worried about what these tools will mean for their jobs, or at least skeptical of their usefulness as AI slop abounds. To bulldoze through this hesitation, bosses have stepped up the pressure, making AI use mandatory and incorporating it into performance reviews.\n\nBut a number of executives at the roundtable advised against strong-arming. Cisco learned that the hard way. \"When we asked our employees to take mandatory training for AI, not only did it not drive sustainable usage, it actually had a bit of a negative impact,\" said Francine Katsoudas, the company's chief people, policy, and purpose officer. What worked, she explained, was \"providing choice\" — like when Cisco gave its engineers access to half a dozen different AI tools, allowing them to decide which ones to use and how to use them. \"They absolutely loved that,\" she said.\n\nAnother theory was that even if employees want to use these new tools, they don't have the necessary skills to get the most out of them. Part of the fix, some argued, involves hiring people who are already good at using AI. Kyle Lutnick, the executive vice chairman of Cantor Fitzgerald, said he wants to bring in more new college grads at a time when other businesses are hiring fewer of them, precisely because they have more fluency using these tools than their older counterparts. But hiring new blood won't be enough. Employers will need to do a lot more to train their existing workforces too. \"Investment has been primarily on the technology and not so much on the people,\" said Elizabeth Faber, global chief people and purpose officer at Deloitte. \"That needs to shift.\"\n\nA third explanation was that big productivity gains require a fundamental overhaul of the way work gets done inside companies. If the Googles or the Amazons of the world were to start from scratch today, they almost certainly wouldn't have the team structures, workflows, and job descriptions they currently do. I think that's why we're seeing the AI revolution most clearly right now in early-stage startups, which are starting from the ground up in the post-ChatGPT era.\n\n\"84% of work processes have been left in their legacy state when adopting AI and have not been redesigned,\" Faber said. \"So 16% of organizations and work processes are really being developed in an AI-native way.\"\n\nAll of these proposed solutions are far from quick fixes. Encouraging employees to opt in voluntarily takes more time than threatening to fire them. Training staff — and actually getting them to learn — takes time too.\n\nRedesigning jobs will prove to be an even heavier lift. Many large businesses don't even know what employees do on a day-to-day basis. It's painstaking work to build out a comprehensive database of the skills employees have and the tasks they perform — and then to systematically tease out which of them can be delegated to AI and which of them can't. One chief people officer I spoke to said that it'll take years for her HR department to complete that process across every function at her company.\n\nOnce all that heavy-lifting is done, what will these businesses look like? I put the question to the group at the roundtable, asking how many of them expect their workforces to shrink in three to five years' time. Two out of the 15 raised their hands — a tally I suspect would have been higher if I weren't there. One of them, Gina Vargiu-Breuer, chief people officer at SAP, explained that her company is currently keeping headcount flat because the business is still growing.\n\n\"But when you're not growing, then I think this is where you have to talk about, 'OK, do we have to reduce headcount?'\" she said. \"I have a lot of peers in German companies where they are starting to reduce headcount dramatically. So it's a reality. For us, it's not, because we're growing, but I think it will happen going forward.\"\n\n\"At the moment we stay flat,\" she said. \"But if productivity goes up and growth is slowing down, then I think we have to look at that with different eyes.\"\n\nThat's something many economists had predicted early on, given how difficult it has always been to fully integrate new technology into the workplace. They told me that things will change less than we expect in the short term, and a lot \n\nC-suites around the world are coming to the same realization, which is probably why I detected quite a bit of frustration in Davos. Svenja Gudell, Indeed's chief economist, compared the world's urgency around AI to the impatience of a parent potty-training their kid. \"It's messy, it's a long process,\" she said. \"You're like, 'Why is this not happening? It's been three weeks already.'\" Her message to executives: \"Give yourself some grace.\"\n\nThe slower timeline is good news for the rest of us — it gives us time to learn new skills, debate new public policies, and try to shape the future we actually want. But it would be a mistake to read the so-far modest changes as evidence that tectonic shifts aren't coming. I came away from Davos convinced that when they do happen, they'll be far bigger than anything we're imagining now, for better and for worse.\n\nAki Ito is a chief correspondent at Business Insider.",
    "readingTime": 5,
    "keywords": [
      "reduce headcount",
      "purpose officer",
      "business insider",
      "chief",
      "employees",
      "it's",
      "businesses",
      "executives",
      "tools",
      "roundtable"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-hype-hasnt-changed-work-yet-bosses-employees-2026-1",
    "thumbnail_url": "https://i.insider.com/6977e57fa645d11881880412?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.856Z",
    "topic": "finance"
  },
  {
    "slug": "clawdbot-is-the-new-ai-techies-are-buzzing-about-and-its-renewing-interest-in-the-mac-mini",
    "title": "Clawdbot is the new AI techies are buzzing about — and it's renewing interest in the Mac Mini",
    "description": "Clawdbot is a local AI agent that promises to manage your digital life, from organizing your calendar to booking restaurant reservations.",
    "fullText": "If your techie friend is texting a lobster, here's why.\n\nClawdbot is an open-source AI agent that works around the clock and can connect to many common consumer apps. Users have asked their Clawdbots to organize their schedules, monitor vibe-coding sessions, and build new AI employees.\n\nIt's scored some high-profile fans, from Y Combinator CEO Garry Tan to multiple Andreessen Horowitz partners. Many have praised it, others have meme'd it, and some have warned people about potential security concerns.\n\nYou can spot Clawdbot by its friendly lobster mascot.\n\nFounded by Peter Steinberger, Clawdbot is an AI agent that manages \"digital life,\" from emails to home automation. Steinberger previously founded PSPDFKit.\n\nIn a key distinction from ChatGPT and many other popular AI products, the agent is open source and runs locally on your computer. Users then connect the agent to a messaging app like WhatsApp or Telegram, where they can give it instructions via text.\n\nClawdbot was named after the \"little monster\" that appears when you restart Claude Code, Steinberger said on the \"Insecure Agents\" podcast. He formed the tool around the question: \"Why don't I have an agent that can look over my agents?\"\n\n\"I already did the whole startup thing,\" Steinberger said. \"I'm just here to have fun.\"\n\nbro came back from retirement\n\n> built @clawdbot \n> solved \"AI forgets everything\" problem\n> and still gave it to us for free\n\nabsolute legend 🐐 pic.twitter.com/tPwwicah42\n\nClawdbot runs locally on your computer 24/7. That's led some people to brush off their old laptops. \"Installed it experimentally on my old dusty Intel MacBook Pro,\" one product designer wrote. \"That machine finally has a purpose again.\"\n\nOthers are buying up Mac Minis, Apple's 5\"-by-5\" computer, to run Clawdbot. Logan Kilpatrick, a product manager for Google DeepMind, posted: \"Mac mini ordered.\" It could give a sales boost to Apple, some X users have pointed out — and online searches for \"Mac Mini\" jumped in the last 4 days in the US, per Google Trends.\n\nBut Steinberger said buying a new computer just to run the AI isn't necessary.\n\n\"Please don't buy a Mac Mini,\" he wrote. \"You can deploy this on Amazon's Free Tier.\"\n\nThe Mac Mini buy-ups have spawned dozens of memes.\n\nOne founder wrote that his \"meal prep\" was a fridge full of Mac Minis and Monster energy drinks. An engineer joked that his Mac Mini had quit his job and divorced his wife. Another founder prophesied a wave of Mac Mini returns in two weeks.\n\ngetting a mac mini just to run clawd has got be most performative thing you can do to start the year pic.twitter.com/KwTYIEcJqI\n\nAs for Clawdbot, many techies were excited by the agent's capabilities.\n\nOne founder asked it to make him a dinner reservation; when it couldn't complete the task via OpenTable, it used its ElevenLabs skill to call the restaurant. \"AGI is here and 99% of people have no clue,\" he wrote.\n\nOthers were less impressed. One founder called it a \"generational psyop,\" joking that it took him 6 texts to get a calendar invite.\n\nClawdbot seems to be at least moderately popular. Steinberger posted on X that he had 89 GitHub pull requests — and that venture capitalists were flooding his inbox.\n\nIs Clawdbot the future of agents? Some onlookers seem skeptical.\n\nFirst, the setup process can be technical. A16z partner Olivia Moore described the process, from terminal commands to API keys. \"For most consumers (or even prosumers), the learning curve is likely too steep,\" she wrote.\n\nThen there's the security question. You are giving an AI agent almost unlimited access to your digital life and passwords, after all.\n\nRahul Sood, a former Microsoft exec who founded its investment arm, wrote that Clawdbot turned text messages into \"attack surfaces\" and had \"zero guardrails by design.\" He advised using it carefully.\n\nGave Clawdbot access to my portfolio.\n\n\"Trade this to $1M. Don't make mistakes\"\n\n25 strategies. 3,000+ reports. 12 new algos.\n\nIt scanned every X post. Charted every technical. Traded 24/7.\n\nIt lost everything.\nBut boy was it beautiful. pic.twitter.com/wYpEZ3kB67\n\nOne hacker described Clawdbot as hiring a \"brilliant\" butler who later opened your home to the public, allowing a stranger to read your diary.\n\nSteinberger responded to these security concerns by outlining some guardrails users could employ, including reading the security document and avoiding adding Clawdbot to group chats.\n\nHow much should we hand over our digital lives to AI? A16z partner Justine Moore warned against being the \"guy who automated his entire life with ClawdBot.\"",
    "readingTime": 4,
    "keywords": [
      "a16z partner",
      "mac minis",
      "mac mini",
      "security concerns",
      "digital life",
      "clawdbot",
      "users",
      "computer",
      "founder",
      "others"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-ai-mac-mini-2026-1",
    "thumbnail_url": "https://i.insider.com/697779b8a645d1188187f807?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.854Z",
    "topic": "finance"
  },
  {
    "slug": "i-went-off-the-deep-end-with-ai",
    "title": "I went off the deep end with AI",
    "description": "What happens when code becomes the easy part? Excitement, dread, and what this means for my solo-run business.",
    "fullText": "Discussion about this postRestacksDennis Paagman 16hLiked by Joe MasilottiThe waiting sucks! It gets me out the zone too. I noticed it helps me to use the fast Claude models when not doing complex or planning stuff, as it’s soo much faster. It got better with 4.x luckily. ReplyShareAnthony Amar 1hThanks for this post, very interesting. Glad to read that I'm not alone being bored about the waiting. More than a year of Cursor usage, I'm kinda see some serious downside to this amazing productivity: it erodes my focus. This waiting have something to do with it imho, because it urge me to do something else, and it often (always?) doesn't have to do with code. I can't focus on code as I focused back in the day, struggling on bugs with tens of Stack Overflow tabs. Did you find a balance on what to code \"by hand\", and what to do with AI?ReplyShare1 reply by Joe Masilotti1 more comment...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "code",
      "focus"
    ],
    "qualityScore": 0.55,
    "link": "https://newsletter.masilotti.com/p/i-went-off-the-deep-end-with-ai",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!PlZj!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c2ca74-dddf-4909-843c-25211b5d700d_2400x1260.png",
    "created_at": "2026-01-27T12:26:46.769Z",
    "topic": "tech"
  },
  {
    "slug": "new-ranking-where-openai-employees-went-to-college",
    "title": "New ranking: Where OpenAI employees went to college",
    "description": "Workforce.ai data reveals most OpenAI staff graduated from top US universities, showing how concentrated elite AI talent remains.",
    "fullText": "A chart circulating on X breaks down where OpenAI employees went to school. It reads like a who's who of elite universities.\n\nStanford leads by a wide margin, followed by UC Berkeley, MIT, and Carnegie Mellon, with strong showings from Harvard, Cornell, UCLA, and a few international institutions.\n\nThe data comes from workforce.ai, which tracks and verifies online professional profiles to analyze hiring and talent trends.\n\nWhile not a full picture of OpenAI's workforce, the snapshot underscores how heavily frontier AI labs continue to draw from a small cluster of top research universities — and how concentrated elite AI talent remains.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 1,
    "keywords": [
      "elite",
      "universities",
      "talent"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/openai-employees-went-college-ranking-stanford-2026-1",
    "thumbnail_url": "https://i.insider.com/6972c5bfe1ba468a96aa910f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.699Z",
    "topic": "finance"
  },
  {
    "slug": "agent-skills-from-claude-to-open-standard-to-your-daily-coding-workflow",
    "title": "Agent Skills: From Claude to Open Standard to Your Daily Coding Workflow",
    "description": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we're witnessing something far more...",
    "fullText": "When Anthropic introduced Agent Skills for Claude, it appeared to be another proprietary AI customization feature. Today, we’re witnessing something far more significant: an open standard reshaping how people across roles—developers, designers, product managers, and operations—work with AI assistants. AI coding agents’ adoption of Agent Skills has transformed this technology from an interesting experiment into an essential developer tool.\n\nIf you’ve been using custom instructions or wondering how to make your AI assistant truly understand your project’s workflows, Agent Skills provides a compelling solution.\n\nAgent Skills began with Anthropic’s Claude AI, where developers first experienced giving AI agents specialized capabilities through structured instructions. Unlike simple prompts or one-off commands, Agent Skills introduced a sophisticated approach: packaging instructions, scripts, templates, and documentation into reusable, discoverable units.\n\nAnthropic’s decision to release Agent Skills as an open standard transformed it from a Claude-specific feature into a movement. The format’s simplicity and effectiveness attracted attention across the AI development tools ecosystem. Today, major players—Claude Code, GitHub Copilot, Cursor, OpenCode, Mistral Vibe, Antigravity, OpenAI Codex, and Kiro—have adopted the standard. Others are exploring integration, and more are joining it (I’m looking at you, JetBrains Junie).\n\nAgent Skills are elegantly simple: a folder containing a SKILL.md file. This file uses YAML frontmatter for metadata and Markdown for instructions. No complex APIs, no proprietary formats—just structured text any AI agent can understand.\n\nHere’s a basic Agent Skills example for creating NUnit unit tests in C#:\n\nThose Agent Skills files live in your agent configuration, for example for GitHub Copilot .github/skills/create-nunit-unit-test/SKILL.md in your repository. Or they can be globally installed for your user account, e.g. ~/.copilot/skills/create-nunit-unit-test/SKILL.md.\n\nThis is a minimal example. You can add resources like templates, example configurations, or helper scripts in the same directory, and the skill can reference them.\n\nWhat makes Agent Skills innovative isn’t just the format—it’s how AI agents consume them. The system uses a three-level progressive disclosure approach that optimizes context window usage:\n\nLevel 1: Discovery — At startup, the agent reads only the name and description from each skill. This lightweight metadata helps the agent understand available capabilities without consuming context.\n\nLevel 2: Activation — When your request matches a skill’s description, the agent loads the full instructions from the SKILL.md file. Only then do detailed procedures become available.\n\nLevel 3: Execution — The agent accesses additional files (scripts, examples, documentation) only as needed during execution.\n\nThis architecture solves a critical problem: you can install dozens of Agent Skills without overwhelming the AI’s context window. The agent loads only what’s relevant to your current development task.\n\nGitHub Copilot’s Agent Skills are experimental since December 2025 (version 1.108) for VS Code. Here’s your step-by-step setup guide:\n\nInstall VS Code — Download from code.visualstudio.com\n\nEnable Agent Skills — Open settings (Ctrl+,) and enable chat.useAgentSkills\n\nCreate your skills directory — In your project root, create .github/skills/\n\nAdd your first skill — Create a subdirectory for each skill with its SKILL.md file\n\nUse Agent Mode — In Copilot Chat, switch to Agent mode to leverage skills\n\nOnce configured, Agent Skills activate automatically based on your prompts. No manual selection required—the AI determines which skills are relevant based on your descriptions.\n\nSkills share knowledge—best practices, workflows, and procedural guidance—in simple Markdown SKILL.md files that anyone can author; they load progressively to conserve tokens, require no server, and run on web, desktop, and CLI, making them ideal for documentation, checklists, examples, and repeatable workflows.\n\nMCP extends functionality by connecting to APIs, databases, and external tools: it consists of code and service/tool definitions that require development and hosting, loads tool definitions up front (consuming more context), so it’s best suited for tasks needing direct access to external systems.\n\nUse Skills to make knowledge discoverable and consistent, and use MCP to perform integrated actions and extend platform capabilities; together they provide both lightweight guidance and powerful automation.\n\nNevertheless, I can imagine a future where Agent Skills replace MCP for many scenarios, given their simplicity, portability, and ease of authoring. As you can bundle scripts and resources with skills, they can cover many use cases MCP currently serves.\n\nYou might wonder how Agent Skills differ from the custom instructions feature. Custom Instructions are best for defining coding standards and conventions, setting language or framework preferences, specifying code-review guidelines, and establishing commit-message formats. Agent Skills are designed to package reusable workflows, include executable scripts and templates, define specialized procedures (testing, debugging, deployment), and enable capabilities that run beyond the IDE (CLI and coding agents).\n\nThink of custom instructions as your coding style guide and Agent Skills as your AI development toolbox. Custom instructions tell the AI how you want code written; Agent Skills give the AI specialized capabilities to perform complex development tasks.\n\nHere are some practical Agent Skills that can transform your daily development workflow. Check the references section for pointers to more ready-to-use skills:\n\nRead the Agent Skills Specification to understand the format and capabilities. Use Skill Creator, an Agent Skill to create and refine new Agent Skills. Inception moment anyone 🤔?\n\nStart building your Agent Skills collection with these proven strategies:\n\nIdentify Repetitive Tasks — Notice which development workflows you explain to the AI repeatedly. Each recurring explanation is a candidate for an Agent Skill.\n\nStart Simple — Begin with straightforward skills that codify standard development procedures. As you gain confidence, add scripts and more complex resources.\n\nMake Descriptions Specific — The quality of your skill’s description directly impacts how well the AI knows when to activate it. Be explicit about use cases and capabilities.\n\nInclude Examples — Agent Skills with concrete code examples are more effective. Show the AI what good output looks like.\n\nLeverage Community Skills — Explore the github/awesome-copilot and anthropics/skills repositories for inspiration and ready-to-use skills.\n\nOrganize by Domain — Group related Agent Skills together. Create separate skills for testing, deployment, documentation, code review, and other specialized development domains.\n\nHere’s how Agent Skills enhance your workflow in a typical development scenario:\n\nYou’re working on a web application and need to add a new REST API endpoint with proper testing and documentation. With appropriate Agent Skills in place:\n\nYou ask: “Help me add a new user registration endpoint with validation”\n\nThe rest-api-integration skill activates, providing structured guidance on implementing the endpoint with proper authentication, validation, and error handling.\n\nYou ask: “Create tests for this endpoint”\n\nThe webapp-testing skill engages, generating test cases for success scenarios, validation failures, and edge cases.\n\nYou ask: “Generate documentation for this endpoint”\n\nThe api-documentation skill activates, producing comprehensive documentation with examples, error codes, and authentication details.\n\nEach Agent Skill ensures consistency in approach and completeness in implementation. Without skills, you’d need to provide detailed instructions for each request or rely on the AI’s general knowledge, which might miss project-specific patterns.\n\nWhen working with Agent Skills, especially community-shared skills, keep these security considerations in mind:\n\nReview Before Use — Always examine shared Agent Skills before adding them to your project. Check for potentially malicious scripts or unexpected behaviors in the SKILL.md file and associated resources.\n\nUse Terminal Controls — VS Code’s terminal tool provides controls for script execution, including auto-approve options with configurable allow-lists. Configure these appropriately for your security requirements.\n\nVersion Control Your Skills — Agent Skills are just files, so commit them to your repository. This enables code review, versioning, and team collaboration on AI capabilities.\n\nTest in Safe Environments — Try new Agent Skills in development environments before using them in production contexts. Dev containers or isolated workspaces are ideal for testing.\n\nDocument Team Skills — If your team uses shared Agent Skills, maintain documentation about what each skill does and when to use it.\n\nAgent Skills represent more than a new feature—it’s a glimpse into a future where AI development capabilities are portable, shareable, and composable. As more AI tools adopt the standard, we’re moving toward an ecosystem where:\n\nWhether you’re using VS Code or any other editor/IDE, working in the terminal with Copilot CLI, or leveraging any coding agent for automated tasks, your Agent Skills come with you.\n\nReady to integrate Agent Skills into your development workflow? Follow this action plan:\n\nThe goal isn’t to create dozens of Agent Skills immediately. Start with one or two that solve real problems in your development workflow, then expand your library organically as needs arise.\n\nYou can also use Agent Skills with GitHub Copilot CLI or Gemini CLI for terminal-based workflows, or with other coding agents that support the open standard. This portability ensures your investment in creating skills pays off across all your AI-assisted development tools.\n\nMy preferred introduction to Agent Skills is the following video from Burke Holland, which covers the concepts, setup, and practical examples in under 20 minutes:\n\nFor my French readers, I discussed Agent Skills in depth on devdevdev.net in the following episode\n\nAgent Skills bridges the gap between generic AI assistance and specialized, context-aware support for your specific development needs. By adopting an open standard that works across AI tools, the industry has created a foundation for truly portable AI capabilities.\n\nThe journey from Claude to open standard to GitHub Copilot adoption demonstrates the power of simplicity and interoperability in developer tools. As developers, we benefit from this ecosystem approach—our investment in creating Agent Skills pays dividends across our entire development toolchain.\n\nStart small, experiment with the format, and build Agent Skills that improve your daily development work. The progressive disclosure system ensures you won’t overwhelm your AI assistant, and the portable format guarantees your skills remain valuable as AI tools evolve.\n\nThe future of AI-assisted development isn’t just about more powerful models—it’s about giving those models the right context, capabilities, and knowledge to be genuinely helpful in your specific development domain. Agent Skills is a significant step in that direction.\n\nWhat development workflows could benefit from specialized Agent Skills? Have you tried creating skills for your AI coding assistant? Share your experiences in the comments below.",
    "readingTime": 9,
    "keywords": [
      "agent skills",
      "skill.md file",
      "progressive disclosure",
      "ai-assisted development",
      "skill’s description",
      "context window",
      "agent mode",
      "shared agent",
      "coding agents",
      "skill activates"
    ],
    "qualityScore": 1,
    "link": "https://laurentkempe.com/2026/01/27/Agent-Skills-From-Claude-to-Open-Standard/",
    "thumbnail_url": "https://live.staticflickr.com/65535/55058424290_cced09531e_h.jpg",
    "created_at": "2026-01-27T12:26:46.640Z",
    "topic": "tech"
  },
  {
    "slug": "emails-show-bank-of-americas-struggles-with-nvidia-ai-you-have-to-help-us-as-local-car-mechanics-drive-the-race-car",
    "title": "Emails show Bank of America's struggles with Nvidia AI: 'You have to help us as local car mechanics drive the race car!'",
    "description": "Internal emails show Bank of America having difficulties with Nvidia's AI Factory, showing the challenges of integrating AI in regulated industries.",
    "fullText": "Nvidia ran into some resistance as one of the world's biggest banks struggled to adopt its AI enterprise software, signaling how hard it can be for massive, highly regulated companies to put cutting-edge technology to use.\n\nNvidia sales executives recapped conversations with key customers — including Bank of America — following a conference late last year, according to an internal email thread from November viewed by Business Insider.\n\nThe chip giant has been selling its \"AI Factory\" — a full setup of chips and software designed to build, train, and run large-scale AI systems — to large businesses.\n\nBank of America told Nvidia it was struggling with deployment, according to the email thread. The exchange reveals that while companies rush to purchase AI infrastructure, operational and regulatory hurdles make deploying it far harder — a key challenge for Nvidia as it expands from selling chips into enterprise software. On the thread, Nvidia executives also discussed how they can better work with customers in using its AI products.\n\n\"You sold us a Formula 1 race car,\" an Nvidia executive reported the bank said, comparing the AI Factory to the race car, \"and now you have to help us as local car mechanics drive the race car!\"\n\nBank of America declined to comment. Nvidia did not respond to a request for comment from Business Insider.\n\nA second executive later responded that Nvidia \"can't just sell\" AI Factory hardware but needs to provide a software solution to help business customers succeed.\n\nThe gap between buying infrastructure and actually deploying AI is common across industries, said Rumman Chowdhury, who advises companies on responsible AI.\n\n\"Buying GPUs or signing a cloud contract is a business decision; deploying AI is an institutional change,\" she told Business Insider. \"It's much easier to approve a budget line item than to re‑architect workflows, retrain teams, and rewrite governance processes.\"\n\nRecapping its meeting with Bank of America, the first Nvidia executive said the bank lacked \"the MLOps skills in house.\" MLOps refers to machine learning operations, or the processes for implementing AI models in real-world use cases.\n\nThat executive added that Bank of America did not think Nvidia's AI enterprise software was \"ready for their highly regulated banking industry.\"\n\nThe executive also pointed to other concerns, including Bank of America's security and governance requirements, such as documentation and support for air gapping — isolating systems from other networks to improve security. They noted the challenges the bank faced in supporting multiple AI models and software systems to meet different needs.\n\nNvidia vice president Ian Buck subsequently jumped into the thread, signalling how senior leaders at the chip giant can step in when customer concerns surface.\n\n\"Looks like they need help and/or our product is coming up short,\" Buck wrote.\n\nThe struggles at Bank of America echo earlier issues with Nvidia's enterprise software efforts, including a need to educate prospective clients on what it is and isn't.\n\nAI deployment obstacles aren't exclusive to banking; they are prevalent across sectors. While banks have a long history of using AI for tasks like credit decisioning, they may be the first to run into issues because of the scale of their data and customers, said Tom Davenport, an information technology and management professor at Babson College.\n\n\"The technology's out way ahead of what individual banks or most companies actually can implement quickly,\" he said.\n\nHave a tip? Contact this reporter via email at gweiss@businessinsider.com or Signal at @geoffweiss.25. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "bank of america",
      "highly regulated",
      "chip giant",
      "race car",
      "nvidia executive",
      "enterprise software",
      "email thread",
      "ai factory",
      "customers",
      "banks"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bank-of-america-nvidia-ai-internal-emails-2026-1",
    "thumbnail_url": "https://i.insider.com/6977dccba645d118818802fb?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.563Z",
    "topic": "finance"
  },
  {
    "slug": "i-quit-meta-to-build-an-ai-startup-giving-up-a-big-tech-salary-was-tough-heres-how-i-prepared-financially",
    "title": "I quit Meta to build an AI startup. Giving up a Big Tech salary was tough — here's how I prepared financially.",
    "description": "A former Google and Meta employee shares why he left Big Tech and how he got comfortable making the leap to entrepreneurship.",
    "fullText": "This as-told-to essay is based on a conversation with Jason White, a 46-year-old startup founder in the San Jose area. Business Insider has verified his former employment with documentation. His words have been edited for length and clarity.\n\nI've spent half of my 20 years in the tech industry working at Google and Meta. These companies allowed me to work on some amazing projects, but I've now resigned from them both.\n\nI joined Google in 2016 as a tech lead in the Gmail division and transitioned to the Google Search team in 2020. By 2024, I realized I wanted to lean more heavily into AI. I didn't feel my position at Google would give me the opportunity to do that, so I opened myself up to other opportunities.\n\nWhen a Meta recruiter reached out about an AI machine learning engineer role, I decided to pursue it and eventually received an offer. I left Google in July 2024 and started at Meta a month later.\n\nI had a positive experience at Meta. I worked with great people in a high-resource environment and learned a lot. I was also able to lean into AI as I'd hoped, focusing fully on AI products.\n\nHowever, halfway through 2025, I started thinking about resigning to build a startup — specifically, a venture that would use AI to help the typical household with their finances.\n\nWhether to resign from Meta was a complex decision.\n\nThe startup was something I was growing increasingly passionate about. I know what financial pressure feels like — I had been a low-paid graduate student trying to provide for a newborn.\n\nMany people don't have access to great financial planning and management tools to help improve their financial situations. While I was still figuring out what the business would look like, I felt there was an opportunity to help people, and that was very motivating for me.\n\nI connected with a potential cofounder — a friend of a friend — and we spent a lot of time talking through the opportunity. That helped me grow more comfortable with the idea of leaving Meta, but there were still a lot of other factors to consider.\n\nIt's hard to leave a world-class team with people you like — not to mention a reliable source of income.\n\nI know some people start businesses on the side while keeping their full-time jobs, but I couldn't do that because I was already juggling two demanding roles as a Meta employee and a parent.\n\nMy other concern was legal. I would've had to disclose any outside business to Meta, and there could've been non-compete issues — especially since my business idea was related to AI, like my role at Meta.\n\nI wanted to make sure my family had enough savings to cover at least one year of our current expenses without touching our retirement accounts. My wife works, but I wanted a cushion in case she lost her job. I figured that would give me at least one year to build the business, and, if things went really badly, enough time afterward to find a job.\n\nWe already were in a good place savings-wise, so we were still able to take vacations, hire tutors for our kids, and order DoorDash. I had about six months before resigning to make some minor adjustments, including cutting back on 401(k) contributions and putting more money into liquid savings accounts.\n\nThis financial planning process for my family really helped crystallize the direction I wanted to go with the startup. In September 2025, I resigned from Meta.\n\nWhen I shared the news with my colleagues, the response was a mix of surprise, support, and a large amount of jealousy. A lot of people want to leave and start their own thing, but for various reasons they can't or won't — whether it's because of their visa status, financial constraints, or broader fear.\n\nI'm now focused on my business, Bear Financial. My cofounder and I are planning to publicly launch in the second half of this year. We may seek external funding, but for now, we're bootstrapping the business, so I've tracked our spending very carefully.\n\nI have a few pieces of advice for people considering leaving their jobs to start their own business. First, get your finances in order. Second, make sure anyone who depends on you, like your family, is supportive of the decision — I was fortunate to have a supportive partner who knew that I felt limited working in Big Tech.\n\nThird, choose an idea you deeply believe in. With a startup, you have to be the one to bring the energy, the enthusiasm, the vision — and to carry others into it.\n\nAddress your knowledge gaps. Startup founders often need to be generalists, which means having a basic understanding of a lot of areas.\n\nI'd also suggest envisioning the worst-case outcome and asking yourself whether you'd be OK with it. I thought about what it would look like one year later if my business failed. I believe I'd still value everything I learned over those 12 months.\n\nIf I eventually decide to pursue a corporate position again, I have faith that I'd be able to find something — even though it's hard to predict what the job market will look like.\n\nThere are, however, a lot of potential barriers to success: we have to navigate a moving target on regulations, we need to figure out ways to convince potential customers to give us a try, and there are super well-resourced companies that could become direct competitors.\n\nAt the end of the day, I want to take the swing.",
    "readingTime": 5,
    "keywords": [
      "financial planning",
      "startup",
      "i've",
      "meta",
      "opportunity",
      "look",
      "potential",
      "idea",
      "it's",
      "family"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ex-meta-google-employee-quit-build-ai-startup-shares-advice-2026-1",
    "thumbnail_url": "https://i.insider.com/69779c89e1ba468a96aab34f?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.403Z",
    "topic": "finance"
  },
  {
    "slug": "the-wix-ceo-said-ai-gives-engineers-superpowers-that-means-one-trait-is-key-for-entrylevel-developers",
    "title": "The Wix CEO said AI gives engineers 'superpowers.' That means one trait is key for entry-level developers.",
    "description": "Wix CEO Avishai Abrahami said that entry-level engineers need to have this quality in order to keep up with the fast pace of change.",
    "fullText": "AI isn't just reshaping the role of software engineers — it's also making them more skilled.\n\nThat's according to Avishai Abrahami, the CEO and cofounder of website management company Wix. He told Business Insider that the technology equips developers with \"superpowers\" and that the value of smart, talented engineers will be \"dramatically enhanced\" with AI tools.\n\n\"What would take you a month, you can do in a few hours,\" Abrahami said, adding that not every task can be reduced in this way, but most can.\n\nA Google Cloud report released in September found that AI adoption had surged to 90% among software professionals, up 14% from the year prior. Abrahami said that the emergence of AI tools means the \"quality of the software engineer is more important than ever.\"\n\nHe said the first thing \"every company\" looks for is candidates who know how to code and understand AI models. Beyond that baseline, he said Wix aims to hire entry-level candidates with a \"tremendous amount of passion\" for the role, which he said is essential to meeting the demands of the job [didn't want to repeat roles] .\n\n\"Now with AI, the speed of change is so fast that you have to spend a lot of time learning and experimenting,\" Abrahami said, adding that this makes passion is even more important.\n\nJohn Stecher, Blackstone's chief technology officer, similarly told Business Insider that many junior software engineers have \"insane skill sets\" and that the best hires are deeply passionate about their work.\n\nAs tools take on more of the coding, Stecher said companies are increasingly looking to hire those who understand how to use the tools, and recognize when they're producing the wrong answers.\n\nFor more senior engineers, the role will increasingly shift toward architecture and code review, he said, rather than writing code. Abrahami said experienced engineers will need to read code \"much faster,\" adding that architecture, software design, and code comprehension will become even more critical.\n\nThe CEO, however, warned that AI can be a double-edged sword for engineers.\n\n\"You can do so much more if you're smart,\" Abrahami said about engineers who use AI. \"And you can do really bad things if you're not.\"",
    "readingTime": 2,
    "keywords": [
      "software engineers",
      "business insider",
      "code",
      "tools",
      "role",
      "adding",
      "technology",
      "smart",
      "candidates",
      "understand"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/wix-ceo-says-entry-level-engineers-need-this-trait-2026-1",
    "thumbnail_url": "https://i.insider.com/6977a893d3c7faef0eccecc6?width=1200&format=jpeg",
    "created_at": "2026-01-27T12:26:46.402Z",
    "topic": "finance"
  },
  {
    "slug": "deepseek-ocr-2-visual-causal-flow",
    "title": "DeepSeek OCR 2: Visual Causal Flow",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "🌟 Github |\n 📥 Model Download |\n 📄 Paper Link |\n 📄 Arxiv Paper Link |\n\nDeepSeek-OCR 2: Visual Causal Flow\n\nExplore more human-like visual encoding.\n\nInference using Huggingface transformers on NVIDIA GPUs. Requirements tested on python 3.12.9 + CUDA11.8：\n\nRefer to 🌟GitHub for guidance on model inference acceleration and PDF processing, etc.\n\nWe would like to thank DeepSeek-OCR, Vary, GOT-OCR2.0, MinerU, PaddleOCR for their valuable models and ideas.\n\nWe also appreciate the benchmark OmniDocBench.",
    "readingTime": 1,
    "keywords": [
      "paper link",
      "github",
      "model",
      "deepseek-ocr",
      "visual",
      "inference"
    ],
    "qualityScore": 0.65,
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-OCR-2",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/deepseek-ai/DeepSeek-OCR-2.png",
    "created_at": "2026-01-27T06:21:30.259Z",
    "topic": "tech"
  },
  {
    "slug": "postgresql-timeout-parameters-your-databases-selfdefense-system",
    "title": "PostgreSQL Timeout Parameters: Your Database's Self-Defense System",
    "description": "(Inspired by OpenAI’s PostgreSQL scale challenges)When OpenAI shared their engineering journey of scaling PostgreSQL to support massive workloads, one insight quietly stood out:It’s also common to find long-running idle queries in PostgreSQL. Configuring timeouts like idle_in_transaction_session_timeout is essential to prevent them from blocking autovacuum.At first glance, this might sound like a small operational detail. But in reality, it points to a much bigger truth about how production data",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.datacloudgaze.com/post/postgresql-timeout-parameters-your-database-s-self-defense-system",
    "thumbnail_url": "https://static.wixstatic.com/media/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png/v1/fill/w_1000,h_965,al_c,q_90,usm_0.66_1.00_0.01/5b8722_c2589ab56a6d4f81ac1c29534559af4d~mv2.png",
    "created_at": "2026-01-27T06:21:28.988Z",
    "topic": "tech"
  },
  {
    "slug": "ask-your-llm-traces-what-went-wrong-vllora",
    "title": "Ask your LLM traces what went wrong (vLLora)",
    "description": "Lucy is a built-in assistant that reads your traces, diagnoses agent failures, and suggests concrete fixes in seconds.",
    "fullText": "Your agent fails midway through a task. The trace is right there in vLLora, but it's 200 spans deep. You start scrolling, scanning for the red error or the suspicious tool call. Somewhere in those spans is the answer, but finding it takes longer than it should.\n\nToday we're launching Lucy, an AI assistant built directly into vLLora that reads your traces and tells you what went wrong. You ask a question in plain English, Lucy inspects the trace, and you get a diagnosis with concrete next steps. Lucy is available now in beta.\n\nSorry, your browser doesn’t support embedded videos.\n\nAgent failures don’t look like traditional exceptions. A single bad response is usually the result of a chain of small choices spread across a long execution.\n\nWhen debugging becomes \"scroll until you get lucky,\" you miss important signals and burn time (and tokens) doing it.\n\nLucy is good at exactly this: reading the trace end-to-end, spotting failure patterns, and turning them into actionable fixes.\n\nLucy sits next to your traces and threads. Ask a plain-English question, and it will inspect the trace, flag failure points, and return a fix-oriented report: root cause, impact, and recommended next steps.\n\nLucy can also help you spot patterns across multiple failing runs and suggest prompt rewrites to reduce ambiguity.\n\nWe had a Travel agent which was running for a long time, apparently stuck in a loop within the BetweenHorizonalEnd span. Instead of digging through the logs manually, we simply asked Lucy:\n\nLucy inspected the thread's spans, identified a recurring failure pattern, and explained the root cause and impact, along with concrete next steps.\n\nIn this trace, the agent was failing to complete a travel itinerary. Lucy didn't just flag the error; she identified a complex failure pattern involving both the code (schema) and the instructions (prompt).\n\n1. The \"Hallucinated\" Arguments\nLucy pinpointed exactly why the tools were failing. The model was trying to call research_flights with a from_city argument and research_accommodations with check_in_date.\n\n2. The Hidden Logic Trap\nCritically, Lucy found a root cause that a human scanning logs would likely miss: Prompt Contradiction.\n\n3. Silent Failures (Truncation)\nLucy also caught a silent degradation issue: Severe Output Truncation. The Restaurant Extraction step was hitting token limits and cutting off data mid-list (output_tokens: 4000... truncated). The run looked \"successful\" to the server, but the downstream user was getting incomplete data.\n\nLucy’s report turned a vague \"it's not working\" complaint into three distinct engineering tasks: fix the tool schema, clarify the system prompt, and increase the context window for extraction.\n\nCaption: Lucy analyzes the trace and detects multiple issues simultaneously: invalid tool arguments (from_city), contradictory system prompt instructions, and token truncation in the output.\n\nThis is a common failure mode in tool-using agents: when the tool contract isn't perfectly aligned (schema, handler, prompt, examples), the model starts guessing.\n\nThe cost isn't limited to a single failed call:\n\nEven if your run \"succeeds,\" you can still be paying for broken execution paths.\n\nLucy's intelligence comes from vLLora's tracing infrastructure. vLLora captures everything your agent does:\n\nWhen you ask Lucy a question, it pulls the relevant spans and runs, reconstructs the execution flow, and analyzes patterns across the data. This is context that would take a human hours to piece together manually.\n\nLucy is available now in beta for all vLLora users.\n\nLucy will inspect your active context and give you a clear diagnosis, so you can spend less time scrolling and more time shipping.\n\nSee the full Lucy documentation here",
    "readingTime": 3,
    "keywords": [
      "root cause",
      "patterns across",
      "failure pattern",
      "steps lucy",
      "system prompt",
      "trace",
      "agent",
      "vllora",
      "spans",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://vllora.dev/blog/introducing-lucy/",
    "thumbnail_url": "https://vllora.dev/img/lucy-whats-wrong-with-my-thread.png",
    "created_at": "2026-01-27T06:21:28.207Z",
    "topic": "tech"
  },
  {
    "slug": "kimi-k25",
    "title": "Kimi K2.5",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens atop Kimi-K2-Base. It seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms.\n\nKimi-K2.5 adopts the same native int4 quantization method as Kimi-K2-Thinking.\n\nYou can access Kimi-K2.5's API on https://platform.moonshot.ai , we provide OpenAI/Anthropic-compatible API for you. To verify the deployment is correct, we also provide the Kimi Vendor Verifier.\nCurrently, Kimi-K2.5 is recommended to run on the following inference engines:\n\nDeployment examples can be found in the Model Deployment Guide.\n\nThe usage demos below demonstrate how to call our official API.\n\nFor third-party API deployed with vLLM or SGLang, please note that :\n\nChat with video content is an experimental feature and is only supported in our official API for now\n\nThe recommended temperature will be 1.0 for Thinking mode and 0.6 for Instant mode.\n\nTo use instant mode, you need to pass {'chat_template_kwargs': {\"thinking\": False}} in extra_body.\n\nThis is a simple chat completion script which shows how to call K2.5 API in Thinking and Instant modes.\n\nK2.5 supports Image and Video input.\n\nThe following example demonstrates how to call K2.5 API with image input:\n\nThe following example demonstrates how to call K2.5 API with video input:\n\nK2.5 shares the same design of Interleaved Thinking and Multi-Step Tool Call as K2 Thinking. For usage example, please refer to the K2 Thinking documentation.\n\nKimi K2.5 works best with Kimi Code CLI as its agent framework — give it a try at https://www.kimi.com/code.\n\nBoth the code repository and the model weights are released under the Modified MIT License.\n\nIf you have any questions, please reach out at support@moonshot.cn.",
    "readingTime": 2,
    "keywords": [
      "instant mode",
      "agentic",
      "following",
      "please",
      "input",
      "native",
      "modes",
      "recommended",
      "usage",
      "chat"
    ],
    "qualityScore": 0.95,
    "link": "https://huggingface.co/moonshotai/Kimi-K2.5",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/moonshotai/Kimi-K2.5.png",
    "created_at": "2026-01-27T06:21:28.144Z",
    "topic": "tech"
  },
  {
    "slug": "one-developer-used-claude-to-build-a-memorysafe-extension-of-c",
    "title": "One developer used Claude to build a memory-safe extension of C",
    "description": "feature: Robin Rowe talks about coding, programming education, and China in the age of AI",
    "fullText": "feature TrapC, a memory-safe version of the C programming language, is almost ready for testing.\n\n\"We're almost there,\" Robin Rowe told The Register in a phone interview. \"It almost works.\"\n\nWe caught up with Rowe, a computer science professor and entrepreneur, amid debugging efforts that had kept him up until four in the morning. The long-awaited TrapC website has appeared.\n\n\"My work building TrapC has taken two parallel paths,\" Rowe explains in his initial post. \"A TrapC interpreter called itrapc and a separate compiler called trapc. I had wanted to make a software release by 1 January 2026, but too many bugs. I only reached code complete this month and am now on the painstaking and sleepless process of debugging. When I have something stable that mostly works I will make a release. Sorry to make you wait a little longer. Aiming for Q1 2026.\"\n\nBack in November 2024, Rowe explained that he was working on TrapC. At the time, the public and private sector had undertaken a campaign to promote memory-safe software development as a way to reduce exposure to serious vulnerabilities.\n\nMemory safety provides a way of ensuring that memory-related bugs like out-of-bounds reads/writes and use-after-free don't happen. In large codebases, like Chromium and Windows, most of the security vulnerabilities follow from memory bugs. As that message has been repeated in recent years, memory safety has become an imperative, evangelized by the likes of Google and Microsoft, and more recently by authorities in the US and elsewhere.\n\nFor at least the past ten years, there's been a rising chorus of voices calling for the adoption of memory-safe programming languages and techniques. This has meant encouraging developers to avoid languages like C and C++ where feasible, and to adopt languages like C#, Go, Java, Python, Swift, and Rust, instead, particularly for new projects.\n\nTo remain relevant, the C and C++ communities have tried to address those concerns with projects like TrapC, FilC, Mini-C, Safe C++, and C++ Profiles. There's also a C to Rust conversion project under development at DARPA called TRACTOR – TRanslating All C TO Rust.\n\nBut progress has been slow and those writing in C and C++ haven't found a widely accepted approach. The C++ standards committee recently rejected the Safe C++ proposal. And Rowe said he doubted TRACTOR would have anything to show this year.\n\nMeanwhile, the clock is ticking. Microsoft engineer Galen Hunt last month said, \"My goal is to eliminate every line of C and C++ from Microsoft by 2030. Our strategy is to combine AI and algorithms to rewrite Microsoft's largest codebases.\"\n\n\"There are some efforts to port C code by hand to Rust,\" said Rowe. \"But there're some real challenges to doing that because there are some idioms in C that cannot be expressed in Rust.\n\n\"Rust is much more type safe than C is. And so if you have a void pointer, what does that mean in Rust? There's no translation for it. And that's how TrapC is fundamentally different because it actually remembers what that void pointer actually is.\"\n\nRowe said he expects TRACTOR will eventually be able to accomplish C to Rust translation using AI. But he said he thinks it's better to just build the necessary tooling into the C compiler, so you don't have to rely on some external tool that rewrites your code in an unfamiliar language.\n\nRowe has been using AI tools himself and has been teaching others to do so. This past semester, he taught AI Cybersecurity Programmer Analyst (PCO471) at Community College of Baltimore County – Linux administration using vibe coding in bash with no prerequisites. And starting in February, he's teaching C++ Programming with Generative AI (PCO472) – vibe coding in C++.\n\nRowe said programming has fundamentally changed as a result of AI tools. \"I think this is sort of the same type of discussion as when C came in and people said, 'Well, I'm happy in assembly.' There will still be people doing it the old way. But because vibe programming is so much more efficient on time when done correctly, there's gonna be no choice. You just won't be competitive if you're not vibe programming.\"\n\nThen he shifted gears, slightly. \"But I have to walk that back a little bit because the reason I was up until four in the morning is I had vibe programming working on the Trap C compiler. And it took a fundamentally wrong design turn. And I didn't detect that it had made a design mistake. I had told it how I wanted to approach it. But somehow it misunderstood me or it forgot or something happened and I forgot to check. And so I spent hours doodling around in the debugger and trying to understand why code was acting weird before I finally looked at it and said, 'wait a minute, this isn't even the right design.'\"\n\nRowe said a similar situation crops up in pair programming, where you've told someone to do something and they didn't do it, and you don't realize that until later.\n\n\"[C++ creator] Bjarne Stroustrup famously said that the most important thing in software design is to be clear about what you're trying to build,\" Rowe said. \"And vibe [programming] just puts that on steroids. Now we not only have to be ourselves clear, but we have to communicate it clearly to an LLM.\"\n\nRowe argues that developers have to be encouraged to try AI tools and to make mistakes. He recounted how during his AI Cybersecurity Programmer Analyst course, his students expressed interest in doing more hands-on work in lieu of lectures.\n\n\"So I said, 'I've got real servers on the internet that are my companies. I'll give you root,'\" he recalled. \"I'll set loose students who know nothing on my own servers and hope for the best and we'll see how this goes. And the reaction was panic. I couldn't get past the timidity cliff.\"\n\nRowe said that what he learned from that exchange was that they didn't want their own hands-on, they wanted to watch him work.\n\n\"I said to them, 'But guys, this is like learning to play the piano. You can't learn to play the piano by watching me. Yeah, you guys have to practice. And it's gonna be embarrassing at first. You know, you're gonna play a lot of bad notes and sound terrible. You have to get over that situation'.\"\n\nThat's a scenario playing out in various companies where AI tools remain underutilized, for various reasons, including lack of training, security concerns, lack of utility, and poor tool design.\n\nRowe has traveled often to China to speak at the China Association of Higher Education conference. In December, he said, he was interviewed on China News Television about how China's plan for AI compares with America's.\n\nIn an email he explained, \"I said, 'China's AI-Plus plan calls for efficient AI on devices everywhere, from farm to factory to city, while the White House plan calls for building 500-billion-dollar cloud data centers ... using chips that will, inevitably, seem obsolete within two years.'\"\n\nRowe argues China's approach will prevail and that the US has taken the wrong turn by focusing on centralized cloud datacenters to run LLMs. Within two years, he said, we'll have AI models we can run locally on our phones, with no need for network access for most tasks. Apple and Huawei, he said, are likely to be the winners in this scenario.\n\nRowe pointed to China's DeepSeek as an example. While it may not be quite as good as the leading US commercial models, he said, it runs with far less power.\n\n\"This is a very Moore's Law type of strategy,\" he said. \"I remember when I had a Navy supercomputer in 1994. That was an amazing technology. But in 1995, Cray went bankrupt. There weren't enough buyers for it, even though it was an amazing device.\n\n\"And now I've got an iPhone that's in my pocket. That runs on a battery. It doesn't have a whole room devoted to it and exotic cooling and all kinds of stuff. And it's more powerful than that [the Cray from 1994]. So as a long-term strategy, you know, going toward the device makes a lot more sense, because that half-trillion dollar data center is going to be on my iPhone eventually.\"\n\nRowe also said that on the recommendation of a friend from his time at the AT&T DIRECTV Innovation Lab, he tried running Deepseek at a time when Claude wasn't available. Deepseek, he said, was able to find a bug that Claude couldn't.\n\n\"Surprisingly, the bug was in code Claude had generated, that I had cut-and-pasted carelessly,\" he said. \"With hindsight it was a silly code mistake I should have caught, but was in an 'else' branch outside where I was looking. I'd not expected or intended to have Claude make any change to that block of code. And because the code was valid but the logic wrong, the compiler didn't catch it.\"\n\nBut the bug was obvious, he said, as soon as Deepseek pointed it out. He added, \"I'm paying $200/year for Claude. Deepseek is free.\" ®",
    "readingTime": 8,
    "keywords": [
      "cybersecurity programmer",
      "programmer analyst",
      "rowe argues",
      "void pointer",
      "memory safety",
      "vibe coding",
      "design rowe",
      "vibe programming",
      "code",
      "compiler"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/26/trapc_claude_c_memory_safe_robin_rowe/",
    "thumbnail_url": "https://regmedia.co.uk/2022/03/23/shutterstock_c.jpg",
    "created_at": "2026-01-27T06:21:27.835Z",
    "topic": "tech"
  },
  {
    "slug": "sam-altman-said-openai-is-planning-to-dramatically-slow-down-its-pace-of-hiring",
    "title": "Sam Altman said OpenAI is planning to 'dramatically slow down' its pace of hiring",
    "description": "The OpenAI CEO said during a town hall event that OpenAI will \"hire more slowly but keep hiring\" because AI lets the company do more with less people.",
    "fullText": "Sam Altman is addressing AI's impact on the workforce, including on OpenAI's hiring practices.\n\nDuring a live-streamed town hall event on Monday, catered mainly toward developers, the OpenAI CEO said that AI has changed how quickly the company expands its head count, but the company is not in a hiring freeze and is nowhere close to doing away with human employees entirely.\n\n\"We are planning to dramatically slow down how quickly we grow because we think we'll be able to do so much more with fewer people,\" said Altman in response to a participant who asked if AI has changed OpenAI's interview process of potential candidates.\n\n\"What I think we shouldn't do, and what I hope other companies won't do either, is hire super aggressively, then realize all of a sudden AI can do a lot of stuff, and you need fewer people, and have to have some sort of very uncomfortable conversation,\" Altman added. \"So I think the right approach for us will be to hire more slowly but keep hiring.\"\n\nAltman's comments come amid the \"Great Freeze\" and concerns that job creation in America has lost momentum. The unemployment rate in November 2025 climbed to its highest level since 2021, while job openings have fallen 37% from their peak in 2022, according to data from the Bureau of Labor Statistics.\n\nBusiness Insider previously reported that, while in 2022 there were roughly two job openings for every unemployed worker, by September 2025 that ratio had fallen to one. Workers who have been jobless for at least 27 weeks also now make up about a quarter of all unemployed Americans.\n\nBased on data from the US Census Bureau, young workers have been hit especially hard by the hiring slowdown. The unemployment rate for Americans ages 20 to 24 reached 9.2% in August and September, the highest level since the recovery from the pandemic recession.",
    "readingTime": 2,
    "keywords": [
      "unemployment rate",
      "job openings",
      "hiring",
      "openai's",
      "changed",
      "quickly",
      "fewer",
      "hire",
      "highest",
      "unemployed"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/sam-altman-said-openai-plan-dramatically-slow-down-hiring-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6977fee0d3c7faef0eccf5ef?width=1200&format=jpeg",
    "created_at": "2026-01-27T06:21:23.465Z",
    "topic": "finance"
  },
  {
    "slug": "7-of-the-most-interesting-quotes-from-anthropic-ceos-sprawling-19000word-essay-about-ai",
    "title": "7 of the most interesting quotes from Anthropic CEO's sprawling 19,000-word essay about AI",
    "description": "Anthropic CEO Dario Amodei wrote that AI poses \"a serious civilizational challenge,\" one that will require society to take significant action.",
    "fullText": "Dario Amodei still has a lot to say.\n\nOn Monday, the Anthropic CEO dropped an over 19,000-word essay entitled \"The Adolescence of Technology\" on the future of AI on Monday, opining on everything from his fellow CEOs to feudalism, and even the Unabomber.\n\nBest known for his warning that AI could eliminate up to 50% of entry-level white-collar jobs in the next 1 to 5 years, Amodei has tangled with Nvidia CEO Jensen Huang and the Trump White House over his views.\n\nHere are seven of the most alarming and surprising quotes.\n\nAmodei remains optimistic about AI overall, but his essay detailed \"an intimidating gauntlet that humanity must run\" to reap the benefits of AI without letting the breakthrough technology destroy the world.\n\n\"I believe if we act decisively and carefully, the risks can be overcome — I would even say our odds are good. And there's a hugely better world on the other side of it,\" he wrote. \"But we need to understand that this is a serious civilizational challenge.\"\n\nAI development can't be stopped, Amodei wrote, a conclusion even some of AI's skeptics share. The financial and security benefits are just too massive for the private and public sectors to pass up.\n\nIt's why winning the AI race and doing so in an ethical way is so critical, he concludes.\n\nJensen Huang hasn't changed Amodei's mind on China.\n\n\"A number of complicated arguments are made to justify such sales, such as the idea that 'spreading our tech stack around the world' allows 'America to win' in some general, unspecified economic battle,\" Amodei said. \"In my view, this is like selling nuclear weapons to North Korea and then bragging that the missile casings are made by Boeing and so the US is 'winning.'\"\n\nIn November, Nvidia announced a partnership with Anthropic that includes an investment of up to $10 billion in the AI startup. The news sparked speculation that tensions between Amodei and Huang might be cooling.\n\nWhatever the status of their relationship, Amodei is resolute that it is a horrendous decision to allow US companies to sell advanced chips to China.\n\n\"China is several years behind the US in their ability to produce frontier chips in quantity, and the critical period for building the country of geniuses in a data center is very likely to be within those next several years,\" Amodei wrote. \"There is no reason to give a giant boost to their AI industry during this critical period.\"\n\nAmodei would like his critics to see the scoreboard.\n\nAnthropic's leader hasn't tried to curry favor with the White House, nor has he vocally embraced President Donald Trump's AI policies to the same degree as his rival CEOs. Amodei's outspoken call for AI regulation even led David Sacks, Trump's AI czar, to publicly rebuke him.\n\nAnthropic is running a sophisticated regulatory capture strategy based on fear-mongering. It is principally responsible for the state regulatory frenzy that is damaging the startup ecosystem. https://t.co/C5RuJbVi4P\n\nNone of it has changed Amodei's view that the AI industry \"needs a healthier relationship with government — one based on substantive policy engagement rather than political alignment.\"\n\n\"Many people have told me that we should stop doing this, that it could lead to unfavorable treatment, but in the year we've been doing it, Anthropic's valuation has increased by over 6x, an almost unprecedented jump at our commercial scale,\" he wrote.\n\nOf all of his hopes, this one appears the unlikeliest. Already, AI CEOs have formed dueling super PACs ahead of the 2026 midterm elections.\n\nThe tech elite made AI, and they should help society grapple with its fallout, he wrote in the essay. Amodei has long called on governments to prepare for mass job displacement. In one of the most eyebrow-raising parts of the essay, Anthropic CEO detailed what his fellow billionaires and companies must do.\n\nBeyond philanthropy, Amodei said companies need to be \"creative\" in how they stave off layoffs.\n\nIn the long term, he wrote, \"It may be feasible to pay human employees even long after they are no longer providing economic value in the traditional sense.\"\n\nOne of the biggest themes of Amodei's essay is the risk that AI companies themselves pose. It's a conclusion that he admits is \"somewhat awkward\" for him to reach. As an example, he points to the roiling topic of the sexualization of children. While he does not name xAI directly, Grok is facing investigations in multiple countries over the non-consensual sexualization of images of real people.\n\n\"Some AI companies have shown a disturbing negligence towards the sexualization of children in today's models, which makes me doubt that they'll show either the inclination or the ability to address autonomy risks in future models,\" he wrote.\n\nOverall, he expressed skepticism that AI companies will sacrifice profit for broader societal good. \"Ordinary corporate governance,\" Amodei wrote, is ill-equipped to address his worries.\n\nAmodei said that fears that AI models may defy orders and perhaps even try to eliminate humanity are complicated by bad actors in the industry who aren't as transparent about the risks they are seeing in their models.\n\n\"While it is incredibly valuable for individual AI companies to engage in good practices or become good at steering AI models, and to share their findings publicly, the reality is that not all AI companies do this, and the worst ones can still be a danger to everyone even if the best ones have excellent practices,\" he wrote.\n\nAmodei doesn't see the largest risks to humanity coming from AI pursuing total domination, but rather in what AI could enable humans to unleash.\n\nAmodei described his fears that AI is lowering the barrier of entry necessary to make killer biological weapons. His greatest concern is that AI could provide the step-by-step know-how that could eventually enable even an average person to produce a bioweapon.\n\nAI companies, Amodei said, need to ensure they create sufficient backstops to block such inquiries, including by making it difficult for hackers to jailbreak models. Adding such security is expensive, Amodei said, noting that these measures are \"close to 5% of total inference costs\" for some of the companies' models.\n\n\"I am concerned that over time there may be a prisoner's dilemma where companies can defect and lower their costs by removing classifiers,\" he wrote. \"This is once again a classic negative externalities problem that can't be solved by the voluntary actions of Anthropic or any other single company alone.\"\n\nAmodei is one of the AI industry's most vocal proponents of AI legislation. While Meta and Microsoft supported a federal preemption of state-level AI laws, Anthropic supported AI transparency bills in California and New York that are now law.\n\nThroughout the essay, Amodei outlined multiple areas for future legislation, including industry-wide transparency requirements like those at the state level. Even he concludes that new laws might not be enough.\n\n\"The rapid progress of AI may create situations that our existing legal frameworks are not well designed to deal with,\" he wrote.\n\nIt's why Amodei said he would go so far as to support a constitutional amendment. The US has not amended the Constitution since 1992, when the over two-century-long battle to add a limitation on congressional pay finally passed the 38th state legislature.\n\n\"I would support civil liberties-focused legislation (or maybe even a constitutional amendment) that imposes stronger guardrails against AI-powered abuses,\" he wrote.",
    "readingTime": 7,
    "keywords": [
      "changed amodei's",
      "constitutional amendment",
      "critical period",
      "essay amodei",
      "models",
      "risks",
      "humanity",
      "it's",
      "doing",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/dario-amodei-ai-essay-most-interesting-quotes-2026-1",
    "thumbnail_url": "https://i.insider.com/6977ee07a645d118818804ed?width=1200&format=jpeg",
    "created_at": "2026-01-27T06:21:23.459Z",
    "topic": "finance"
  },
  {
    "slug": "i-created-a-simple-guide-to-the-best-ai-tools-for-absolute-beginners",
    "title": "I Created a Simple Guide to the Best AI Tools for Absolute Beginners",
    "description": "Discover the best AI tools for beginners in 2025 for work, study, and productivity. Easy-to-use AI apps with real-world benefits.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://xthe.com/ai/ai-tools-beginners/",
    "thumbnail_url": "https://xthe.com/wp-content/uploads/2026/01/Best-AI-Tools-for-Beginners.png",
    "created_at": "2026-01-27T01:02:12.450Z",
    "topic": "tech"
  },
  {
    "slug": "ai-motion-control",
    "title": "AI Motion Control",
    "description": "AI Motion Control platform for transferring movements and expressions from videos to images. Create lifelike video animations with precision.",
    "fullText": "Premier platform for professional AI Motion Control. We empower creators to synchronize complex movements and facial expressions from reference videos to static images with surgical precision.\n\nUpload a character image and a reference motion video. Our AI extracts movements and expressions to animate your image with stunning precision.\n\nWhen Character Orientation matches the video, complex motions perform better; when it matches the image, camera movements are better supported.\n\nClick any example below to preview the motion transfer results\n\nAt aimotioncontrol.net, we don't just generate video; we engineer motion. Our AI Motion Control technology solves the fundamental chaotic nature of diffusion models, anchoring every frame to your exact creative intent.\n\nTransfer movement from any source video to your target character with industry-leading AI Motion Control precision. Unlike standard image-to-video tools that guess movement, our system locks onto the skeletal structure of your reference footage. This ensures that every nuance of the original performance captures the energy and intent of the actor, regardless of the target character's design.\n\nOur AI Motion Control algorithms ensure that every limb, joint, and subtle shift in weight is perfectly transferred. Whether it's a complex dance routine featuring rapid spins or a specific stunt requiring perfect timing, the output matches the input with 99% anatomical accuracy, preserving the physics of the original motion.\n\nMaintain character identity across all frames without distortion. Traditional AI struggles with keeping a character's face and clothes consistent during rapid movement, often resulting in morphing textures. AI Motion Control utilizes temporal attention layers to preserve details from the first frame to the last, ensuring your character looks the same at frame 100 as they did at frame 1.\n\nApply the motion of a human actor to a stylized character (anime, 3D render, claymation) instantly. AI Motion Control handles the stylistic translation while keeping the physics of the movement grounded in reality. You can drive a cartoon character with a human performance or map a human's walk cycle onto a robotic creature.\n\nThe system intelligently adjusts the motion to fit the proportions of your target character. If you map a tall actor's motion to a short goblin character, AI Motion Control automatically recalculates the stride length and center of gravity to ensure the movement looks natural and physically plausible.\n\nClone nuanced facial expressions for emotional storytelling with our dedicated facial AI Motion Control engine. Eyes, mouth shapes, and micro-expressions are mapped faithfully, allowing you to convey complex emotions that standard AI models fail to capture.\n\nSuperior accuracy in mapping complex facial expressions. A smile isn't just a curve of the lips; it's the crinkle of the eyes and the lifting of cheeks. AI Motion Control captures it all, distinguishing between a smirk, a grin, and a laugh with pixel-perfect precision.\n\nPerfect lip synchronization for talking heads and dialogue. Input your audio track, and our AI Motion Control system aligns the mouth movements frame by frame for believable speech, making it an ideal tool for virtual news anchors or storytelling.\n\nEnsure your character is looking exactly where they should be. AI Motion Control allows for precise direction of eye movement, essential for dramatic scenes and connection with the audience. You can control the focal point of your character's attention throughout the video.\n\nCapture the fleeting moments of emotion that bring a character to life. A slight furrow of the brow or a quick widening of the eyes—these subconscious signals are preserved by AI Motion Control, adding a layer of psychological depth to your animations.\n\nAccess a curated collection of movements for instant animation. Don't have a reference video? Use our library powered by AI Motion Control pre-sets to immediately bring your static images to life with professional-grade motion.\n\nBrowse and apply professional motions from our extensive library. From walking and running to complex martial arts, our AI Motion Control database is ready to animate your static images. We categorize motions by intensity, style, and genre for easy discovery.\n\nUpload your own reference videos for unique motion control. The system analyzes your footage and creates a custom motion LoRA that can be applied to any character. You can build your own private library of proprietary movements for your studio.\n\nCombine different motions or blend them together. AI Motion Control allows for smooth transitions between different action states, creating long, continuous takes. You can have a character walk, stop, look around, and then run, all seamlessly blended.\n\nEnsuring smooth, flicker-free motion in long-form videos is the hallmark of professional AI Motion Control. We eliminate the 'boiling' effect common in generative video, delivering broadcast-quality stability.\n\nProprietary algorithms to eliminate jitter and artifacts. By analyzing the optical flow between frames, our AI Motion Control engine corrects anomalies before they render. It acts as a digital stabilizer, smoothing out the noise inherent in diffusion models.\n\nSpecifically optimized for longer duration video generation. Most tools break down after 4 seconds. AI Motion Control maintains coherence for up to 60 seconds of continuous video without the character losing their identity or structural integrity.\n\nGenerate videos at 60fps or higher. AI Motion Control interprets the motion between frames to interpolate smooth motion, making your results broadcast-ready. Create slow-motion effects or crisp, realistic action sequences.\n\nOne of the toughest challenges in AI video is keeping the artistic style consistent while the subject moves. AI Motion Control solves this by decoupling motion from style modules.\n\nWhether your source image is an oil painting, a cyberpunk digital art piece, or a sketch, AI Motion Control ensures that the texture and brushstrokes move naturally with the character, rather than staying static like a screen overlay.\n\nAs your character moves through the virtual space, AI Motion Control calculates how the lighting should simulate on their changing geometry. Shadows wrap correctly, and highlights shift naturally, maintaining the 3D illusion of the 2D generation.\n\nKeep your background stable while your character moves. Our system identifies the subject and generates a clean plate for the background, preventing the warping and 'breathing' background issues seen in other tools.\n\nForget about expensive GPUs and complex installations. AI Motion Control delivers workstation-power directly to your browser through our optimized cloud infrastructure. Create without limits.\n\nCreate high-fidelity animations on any device, from a standard laptop to a tablet. We handle the compute-intensive diffusion processes on our enterprise-grade GPU clusters, freeing your machine from overheating and lag.\n\nDon't wait for one video to finish before starting the next. Our scalable architecture supports parallel processing, allowing you to run multiple motion experiments simultaneously. Iterate faster and find the perfect shot in a fraction of the time.\n\nOur cloud platform means you always have access to the latest AI Motion Control models and features the moment they are released. Say goodbye to managing local Python environments, installing dependencies, or downloading massive model weights.\n\nFrom social media viral hits to professional film production, AI Motion Control delivers the precision required for top-tier content.\n\nCreate high-end social media content and viral marketing campaigns. In the fast-paced world of TikTok and Instagram, stopping the scroll is everything. AI Motion Control allows brands to create eye-popping, impossible visuals that capture attention instantly. Imagine your mascot dancing perfectly to the latest trend, or your product assembling itself in mid-air. AI Motion Control makes this accessible without a Hollywood budget.\n\nProfessional film pre-visualization and character storyboarding. Directors can now visualize scenes with animated characters before a single camera starts rolling. AI Motion Control allows for rapid iteration of blocking and staging. Instead of stick figures or rough drawings, see your characters move and act in the actual environment, saving millions in production costs.\n\nDevelop realistic virtual influencers and digital brand ambassadors. The virtual human economy is booming, but stiff, robotic movement breaks the illusion. AI Motion Control gives your digital avatars lifelike movements and expressions, allowing them to connect with audiences authentically. Generate daily content for your virtual star without needing a motion capture suit every time.\n\nCreate personalized AI-driven dance and performance videos. Choreograph complex routines for your digital characters using simple reference videos. AI Motion Control excels at capturing the fluidity of dance, preserving the elegance of ballet or the snap of hip-hop, and applying it to any character you design.\n\nAccelerate asset creation for indie games. AI Motion Control can generate sprite sheet animations or cutscene videos from simple references, drastically reducing the animation workload for small teams.\n\nShowcase clothing on moving models without a photoshoot. AI Motion Control can take a flat image of a dress and a video of a model walking, and generate a video of the model wearing that dress, moving naturally.\n\nSelect the plan that best fits your creative needs. Unlock the full potential of AI Motion Control.\n\nEverything you need to know about our technology and how it helps you create better videos.\n\nJoin the revolution of precise AI video generation. Don't settle for randomness. Start creating lifelike animations today with the power of AI Motion Control.\n\nTrusted by professional creators worldwide",
    "readingTime": 8,
    "keywords": [
      "ai motion control",
      "social media",
      "static images",
      "professional film",
      "facial expressions",
      "diffusion models",
      "reference videos",
      "target character",
      "ai motion control we",
      "complex"
    ],
    "qualityScore": 1,
    "link": "https://aimotioncontrol.net",
    "thumbnail_url": "https://aimotioncontrol.net/og.png",
    "created_at": "2026-01-27T01:01:52.735Z",
    "topic": "tech"
  },
  {
    "slug": "eu-opens-investigation-into-musks-ai-chatbot-grok-over-sexual-deepfakes",
    "title": "E.U. opens investigation into Musk's AI chatbot Grok over sexual deepfakes",
    "description": "Officials in the European Union opened a formal investigation into Elon Musk’s social media platform X over the AI chatbot Grok, which has been creating nonconsensual sexualized deepfake images. Grok sparked a global backlash by allowing users, through its AI image generation and editing capabilities, to undress people, putting women and even children in transparent bikinis or revealing clothing. NBC News' Hala Gorani explains how the chatbot works and its history of controversy.",
    "fullText": "Officials in the European Union opened a formal investigation into Elon Musk’s social media platform X over the AI chatbot Grok, which has been creating nonconsensual sexualized deepfake images. Grok sparked a global backlash by allowing users, through its AI image generation and editing capabilities, to undress people, putting women and even children in transparent bikinis or revealing clothing. NBC News' Hala Gorani explains how the chatbot works and its history of controversy.",
    "readingTime": 1,
    "keywords": [
      "chatbot",
      "grok"
    ],
    "qualityScore": 0.2,
    "link": "https://www.yahoo.com/news/videos/e-u-opens-investigation-musks-000458229.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/sUleDp8BCsm5Df31wmD..Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://media.zenfs.com/en/nbcu_713/aad87e5c975aeb81874dfa9cd98e38dc",
    "created_at": "2026-01-27T01:01:49.614Z",
    "topic": "news"
  },
  {
    "slug": "ai-enthusiasts-are-running-clawdbot-on-their-mac-minis-but-you-probably-shouldnt",
    "title": "AI Enthusiasts Are Running 'Clawdbot' on Their Mac Minis, but You Probably Shouldn't",
    "description": "If you care about your privacy and security, don't use this viral AI tool.",
    "fullText": "I am a self-professed AI skeptic. I have yet to really find much of a need for all these AI-powered assistants, as well as many AI-powered features. The most useful applications in my view are subtle—the rest seem better suited for shareholders than actual people.\n\nAnd yet, the AI believers have a new tool they're very excited about, which is now all over my feeds: Clawdbot. Could this agentic AI assistant be the thing that makes me a believer as well? Spoiler alert: probably not.\n\nIf you're deep in the online AI community, you probably already know about Clawbot. For the rest of us, here's the gist: Clawdbot is a \"personal AI assistant\" designed to run locally on your devices, as opposed to cloud-based options. (Think ChatGPT, Gemini, or Claude.) In fact, Clawdbot runs any number of AI models, including those from Anthropic, OpenAI, Google, xAI, and Perplexity. While you can run Clawdbot on Mac, Linux, and Windows, many online are opting to install the bot on dedicated Mac mini setups, leading to one part of the assistant's virality.\n\nBut there are other AI assistants that can be run locally—one thing that makes Clawdbot unique is that you communicate with it through chat apps. Which app you use is up to you, as Clawdbot works with apps like Discord, Google Chat, iMessages, Microsoft Teams, Signal, Telegram, WebChat, and WhatsApp. The idea is that you \"text\" Clawdbot as you would a friend or family member, but it acts as you'd expect an AI assistant to—except, maybe more so.\n\nThat's because, while Clawdbot can certainly do the things an AI bot like ChatGPT can, it's meant more for agentic tasks. In other words, Clawdbot can do things for you, all while running in the background on your devices. The bot's official website advertises that it can clear your inbox, send emails, manage your calendar, and check you in for flights—though power users are pushing the tool to do much more.\n\nClawdbot works with a host of apps and services you might use yourself. That includes productivity apps like Apple Notes, Apple Reminders, Things 3, Notion, Obsidian, Bear Notes, Trello, GitHub; music apps like Spotify, Sonos, and Shazam; smart home apps like Philips Hue, 8Sleep, and Home Assistant; as well as other major apps like Chrome, 1Password, and Gmail. It can generate images, search the web for GIFs, see your screen, take photos and videos, and check the weather. Based on the website alone, it has a lengthy résumé.\n\nThe last big point here is that Clawdbot has an advertised \"infinite\" memory. That means the bot \"remembers\" every interaction you've ever had with it, as well as all the actions it's taken on your behalf. In theory, you could use Clawdbot to build apps, run your home, or manage your messages, all within the context of everything you've done before. In that, it'd really be the closest thing to a \"digital assistant\" we've seen on this scale. These assistants have been mostly actionable—you ask the bot what you want to know or what you want done, and it (hopefully) acts accordingly. But the ideal version of Clawdbot would do all those things for you without you needing to ask.\n\nNot everyone is psyched about Clawdbot, though. Take this user, who jokes that, after four messages, the bot made a reservation, then, after six messages, was able to send a calendar invite, only to cost $87 in Opus 4.7 tokens. This user came up with a story (at least I hope it's a story) where they give Clawdbot access to their stock portfolio and tasked it with making $1 million without making mistakes. After thousands of reports, dozens of strategies, and many scans of X posts, it lost everything. \"But boy was it beautiful.\"\n\nI particularly like this take, which reads: \"[I've] made a tragic discovery using [Clawdbot.] [There] simply aren’t that many tasks in my personal life that are worth automating.\" There are also some jabs from what appear to be anti-AI users, like this one, that imagines a Clawdbot user with no job living in their parent's basement, asking the bot to do their tasks for the day.\n\nAs with all things AI, there are many thoughts, opinions, and criticisms here, especially considering how viral this new tool is. But the main critique seems to be that Clawdbot requires a lot (in terms of hardware, power, and privacy) without really offering much in return. Sure, it can do things for you, but do you really need a bot booking your plane tickets, or combing through your emails? The answer to that, I suppose, is up to each of us, but the \"backlash,\" if you can call it that, is likely coming from people who would answer \"no.\"\n\nIf you want to try Clawdbot, you'll likely need to have some technical experience first. You can get started from Clawdbot's official github page, as well as Clawdbot's \"Getting started\" guide. According to this page, you'll begin by running the Clawdbot onboarding wizard, which will set you up with the gateway, workspace, channels, and skills. This works on Mac, Linux, and Windows, and while you won't need a Mac mini, it seems to be what the Clawdbot crowd is running with.\n\nFull disclosure: Clawdbot and its setup go beyond my expertise, and I will not be installing it on my devices. However, if you have the knowledge to follow these instructions, or the will to learn, the developer has the steps listed in the links above.\n\nWhile I likely wouldn't install Clawdbot on my device anyway, the privacy and security implications here definitely keep me away.\n\nThe main issue with Clawdbot is that it has full control and access over whichever device you run it on, as well as any of the software that is running therein. That makes sense, on the surface: How is an agentic AI supposed to do things on your behalf if it does have access to the apps and hardware necessary for execution?\n\nBut the inherent security risk with any program like this involves prompt injection. Bad actors could sneak their own AI prompts into otherwise innocent sites and programs. When your bot crawls the text as it completes your task, it intercepts the prompt, and, thinking it's from you, executes that prompt instead. It's the main security flaw with AI browsers, and it could affect something like Clawdbot, too. And since you've given Clawdbot control over your entire computer and everything in it...yikes. Bad actors could manipulate Clawdbot to theoretically send DMs to anyone they like, run malicious programs, read and write files on your computer, trick Clawdbot into accessing your private data, and learn about your hardware for further cyber attacks.\n\nIn Clawdbot's case, these prompt injections could come from a number of sources. They could come from messages via bad actors through the chat apps you communicate through Clawdbot, they could come from the browsers you use to access the internet, and they could come from plugins you run on various programs, to name a few possibilities.\n\nClawdbot does have a security guide on its site that walks you through ways to shore up your defenses while using Clawdbot. The developer admits that running an AI agent with shell access on your machine is \"spicy,\" that this is both a product and an experiment, and that there is no \"perfectly secure\" setup. That said, there are security features built in here that serve a purpose and attempt to limit who can access Clawdbot, where Clawdbot can go, and what Clawdbot can do. That could involve locking down DMs, viewing links and attachments as \"hostile\" by default, reducing high-risk tools, and running modern AI models that have better protections against prompt injection.\n\nStill, the whole affair is too risky for me, especially considering I'm not sure I really want an AI assistant in the first place. I think companies believe we want to offload tasks like calendars, messages, and creation to bots, to save us time from menial to-do lists. Maybe some do, but I don't. I want to know who is reaching out to me and why, and not trust an AI to decide what messages are worth my attention. I want to write my own emails and know what events I have on my own calendar. I also want access to my own computer. Maybe some people trust AI enough to handle all these things for them—if it makes me a luddite to feel the opposite, so be it.",
    "readingTime": 8,
    "keywords": [
      "mac linux",
      "mac mini",
      "prompt injection",
      "chat apps",
      "mac linux and windows",
      "clawdbot",
      "access",
      "assistant",
      "messages",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/what-is-clawdbot-ai?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFXSQPJ1XNQ3RAR6Y5ZY4E0T/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-27T01:01:49.583Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-says-its-newest-ai-chip-maia-200-is-3-times-more-powerful-than-googles-tpu-and-amazons-trainium-processor",
    "title": "Microsoft says its newest AI chip Maia 200 is 3 times more powerful than Google's TPU and Amazon's Trainium processor",
    "description": "The Maia 200 AI chip is described as an inference powerhouse — meaning it could lead AI models to apply their knowledge to real-world situations much faster and more efficiently.",
    "fullText": "When you buy through links on our articles, Future and its syndication partners may earn a commission.\n\nMicrosoft has revealed its new Maia 200 accelerator chip for artificial intelligence (AI) that is three times more powerful than hardware from rivals like Google and Amazon, company representatives say.\n\nThis newest chip will be used in AI inference rather than training, powering systems and agents used to make predictions, provide answers to queries and generate outputs based on new data that's fed to them.\n\nMaia 200 is already being deployed in Microsoft's U.S. central data center region, with the company set to use the chips to generate synthetic data and in reinforcement training to improve next-generation large language models (LLMs). The AI accelerator will also be used to power Microsoft Foundry and 365 Copilot AI, and be part of the infrastructure that the company can provide through its Azure cloud platform.\n\nThe new chip delivers performance of more than 10 petaflops (1015 floating point operations per second), Scott Guthrie, cloud and AI executive vice president at Microsoft, said in a blog post. This is a measure of performance in supercomputing, where the most powerful supercomputers in the world can reach more than 1,000 petaflops of power.\n\nThe new chip achieved this performance level in a data representation category known as \"4-bit precision (FP4)\" — a highly compressed model designed to accelerate AI performance. Maia 200 also delivers 5 PFLOPS of performance in 8-bit precision (FP8). The difference between the two is that FP4 is far more energy efficient but less accurate.\n\n\"In practical terms, one Maia 200 node can effortlessly run today’s largest models, with plenty of headroom for even bigger models in the future,\" Guthrie said in the blog post. \"This means Maia 200 delivers 3 times the FP4 performance of the third generation Amazon Trainium, and FP8 performance above Google’s seventh generation TPU.\"\n\nMaia 200 could potentially be used for specialist AI workloads, such as running larger LLMs in the future. So far, Microsoft's Maia chips have only been used in the Azure cloud infrastructure to run large-scale workloads for Microsoft’s own AI services, notably Copilot. However, Guthrie noted there would be \"wider customer availability in the future,\" signaling other organizations could tap into Maia 200 via the Azure cloud, or the chips could potentially one day be deployed in standalone data centers or server stacks.\n\nGuthrie said that Microsoft boasts 30% better performance per dollar over existing systems thanks to the use of the 3-nanometer process made by the Taiwan Semiconductor Manufacturing Company (TSMC), the most important fabricator in the world, allowing for 100 billion transistors per chip. This essentially means that Maia 200 could be more cost-effective and efficient for the most demanding AI workloads than existing chips.\n\nMaia 200 has a few other features alongside better performance and efficiency. It includes a memory system, for instance, which can help keep an AI model’s weights and data local, meaning you would need less hardware to run a model. It's also designed to be quickly integrated into existing data centers.\n\nMaia 200 should enable AI models to run faster and more efficiently. This means Azure OpenAI users, such as scientists, developers and corporations, could see better throughput and speeds when developing AI applications and using the likes of GPT-4 in their operations.\n\n—'It won’t be so much a ghost town as a zombie apocalypse': How AI might forever change how we use the internet\n\n— GPT-4 has passed the Turing test, researchers claim\n\n—The more advanced AI models get, the better they are at deceiving us — they even know when they're being tested\n\nThis next-generation AI hardware is unlikely to disrupt everyday AI and chatbot use for most people in the short term, as Maia 200 is designed for data centers rather than consumer-grade hardware. However, end users could see the impact of Maia 200 in the form of faster response times and potentially more advanced features from Copilot and other AI tools built into Windows and Microsoft products.\n\nMaia 200 could also provide a performance boost to developers and scientists who use AI inference via Microsoft’s platforms. This, in turn, could lead to improvements in AI deployment on large-scale research projects and elements like advanced weather modeling, biological or chemical systems and compositions.",
    "readingTime": 4,
    "keywords": [
      "azure cloud",
      "bit precision",
      "performance",
      "chip",
      "models",
      "maia",
      "hardware",
      "chips",
      "systems",
      "delivers"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/copilot/articles/microsoft-says-newest-ai-chip-160218268.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/LjtJXpYNgdxD26Hg6MZI0Q--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/live_science_953/61555169799e4adf9db65dcfb9bffe8e",
    "created_at": "2026-01-27T01:01:49.077Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-invests-2-billion-in-coreweave-to-boost-data-center-buildout",
    "title": "Nvidia invests $2 billion in CoreWeave to boost data center build-out",
    "description": "Nvidia has invested $2 billion in CoreWeave, becoming the AI infrastructure provider's second-largest shareholder, as the companies expand their partnership ​to boost data center capacity in the United States.  The announcement on ‌Monday sent CoreWeave's shares up 9% in premarket trading.  So-called neocloud companies like CoreWeave, which provide tech ‌companies with the hardware and cloud capacity needed to build, run and deploy AI technologies, have seen a surge in demand in recent years as enterprise adoption of AI picks up.",
    "fullText": "Jan 26 (Reuters) - Nvidia has invested $2 billion in CoreWeave, becoming the AI infrastructure provider's second-largest shareholder, as the companies expand their partnership ​to boost data center capacity in the United States.\n\nThe announcement on ‌Monday sent CoreWeave's shares up 9% in premarket trading.\n\nSo-called neocloud companies like CoreWeave, which provide tech ‌companies with the hardware and cloud capacity needed to build, run and deploy AI technologies, have seen a surge in demand in recent years as enterprise adoption of AI picks up.\n\nThe fresh investment from Nvidia will help CoreWeave speed ⁠up the procurement of land ‌and power required to build data centers. CoreWeave is targeting to build more than 5 gigawatts in AI data center ‍capacity by 2030.\n\nNvidia will invest in CoreWeave at a purchase price of $87.20 per share, the companies said. That represents an addition of roughly 23 million shares, nearly doubling ​Nvidia's stake in the firm, according to Reuters calculations based on data ‌compiled by LSEG.\n\nNvidia was CoreWeave's third largest shareholder with a 6.3% stake, or 24.3 million shares, in the company.\n\nThe chip giant has drawn scrutiny for pouring billions of dollars into AI firms including ChatGPT maker OpenAI and neoclouds, raising investor concerns about potential circular financing.\n\nA CoreWeave spokesperson told Reuters that the ⁠cash from the new investment will not ​be used to purchase Nvidia processors, but directed ​toward accelerating other data center investments, research and development, and scaling its workforce.\n\nOnce a cryptocurrency miner, CoreWeave has pivoted to capitalize ‍on the AI ⁠boom by repurposing its infrastructure to lease Nvidia GPUs to tech and AI firms.\n\n\"Nvidia is the leading and most requested computing platform at every ⁠phase of AI ... This expanded collaboration underscores the strength of demand we are seeing across ‌our customer base,\" CoreWeave CEO Michael Intrator said.",
    "readingTime": 2,
    "keywords": [
      "center capacity",
      "shares",
      "coreweave",
      "nvidia",
      "infrastructure",
      "shareholder",
      "coreweave's",
      "tech",
      "demand",
      "investment"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-invests-2-billion-coreweave-130850099.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/fc68365e933d0e527a1fcb2a482700fa",
    "created_at": "2026-01-27T01:01:47.523Z",
    "topic": "finance"
  },
  {
    "slug": "ranking-the-eagles-remaining-oc-candidates-using-artificial-intelligence",
    "title": "Ranking the Eagles' remaining OC candidates using artificial intelligence",
    "description": "What happens when we plug the names of the best remaining Eagles OC candidates into ChatGPT's engine?",
    "fullText": "Once we turn the calendar from January's final Monday to Tuesday, we'll enter a third week dedicated to the Philadelphia Eagles' offensive coordinator search. Names have changed, but the climate and landscape remain familiar.\n\nNames have been added to the mix. Candidates have withdrawn from consideration. The general public remains confused. Not even one full year after hoisting the Lombardi Trophy, none of the top options are interested in becoming the Eagles' top offensive assistant.\n\nPerhaps Philadelphia is exercising patience? Maybe Brian Daboll mentioned the Tennessee Titans and Buffalo Bills to give the impression that he had more options? Perhaps he was trying to rush Philadelphia into a decision?\n\nMaybe he was truly in the running for jobs with those two franchises. Who knows? Those are questions we're throwing out for fodder. No one has all of the information. We're all trying to piece this together. What we do know is that no one likes all of the remaining candidates we're told are still in the running.\n\nWho is the best fit for Jalen Hurts? How do we describe the best fit for the roster overall? Who carries the most red flags? Is there any long-term stability for any of these guys?\n\nAs we ventured through Championship Sunday, we learned the Eagles had interest in Arthur Smith before he accepted the Ohio State Buckeyes job. Once we began another workweek, it was learned that Charlie Weis Jr. had removed his name from consideration. Hours later, Declan Doyle arrived at the same decision.\n\nJust for kicks, we took a breather. We plugged a few names into ChatGPT and asked who the best candidates were for the Eagles' OC job. What we learned was AI's list looks a lot like some of our own. Here's what they came up with. Keep in mind that we aren't sure whether Brian Daboll is still in the running.\n\nAI gives Brian Daboll a five-star rating as a potential OC hire, citing he has the best chance to elevate Jalen Hurts immediately. He lands atop the list because he has already done the job before and has previously had success working with Josh Allen.\n\nMike Kafka lands second on the list. His approach seems to emphasize rhythm and being 'on time'. Those are areas where we have seen Jalen Hurts struggle. That could lead to questions, but Kafka has coached mobile quarterbacks before and understands how to blend run concepts into the passing game.\n\nFrank Smith is one of the new additions to this list. He worked with Mike McDaniel as his offensive coordinator. He's intriguing and shouldn't be viewed as someone the Eagles are pursuing, since he was closest to one of the guys they actually wanted.\n\nNagy is a descendant of the Andy Reid coaching tree. He never quite recovered from the 'Double-Doink Game'. Word has it that he even had kickers audition for a job the following season by kicking from the same spot that Cody Parkey missed the go-ahead field goal attempt in the Wild Card Game.\n\nNagy is better than the reputation suggests. He could do a good job in returning to the place where his coaching career began.\n\nHere's one of the guys we know the least about, yet AI ranks him fifth-best. Settling on him means the Eagles would have placed more emphasis on potential than on proof and his resume.\n\nJerrod Johnson is another of the new additions to the Eagles' OC conversation. He is a good teacher, but this may be a mismatch in terms of need. Known as a QB developer, he would be asked to grow into his new role a la Kevin Patullo. If you remember that ultimately led to Patullo's undoing. Johnson might be a 'wrong place, wrong time' candidate, but again, these are only opinions we're sharing.\n\nSome would rank Jim Bob Cooter higher. He actually has OC experience. There's an obvious low ceiling here, as there isn't much evidence that he elevates quarterbacks or builds innovative systems that let them do what they do best.\n\nThe Eagles need to reinvent their offense, and they need to reinvent Jalen Hurts to some degree. They need someone who understands how to do both. None of these guys is a slam-dunk hire in that regard.\n\nAll have positives. All have flaws. One of the most important decisions of the offseason keeps being weighed. One false move and Philadelphia will throw away another season.\n\nThis article originally appeared on Eagles Wire: Ranking Eagles' remaining OC candidates using artificial intelligence",
    "readingTime": 4,
    "keywords": [
      "offensive coordinator",
      "jalen hurts",
      "eagles oc",
      "brian daboll",
      "candidates",
      "we're",
      "guys",
      "list",
      "learned",
      "another"
    ],
    "qualityScore": 1,
    "link": "https://sports.yahoo.com/articles/ranking-eagles-remaining-oc-candidates-181501769.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/2DT2DutgTRojB05W6HgqZg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/philadelphia_eagles_wire_usa_today_sports_articles_352/77a3e8d8d6a3a3fee555a566b676a46b",
    "created_at": "2026-01-26T18:22:20.909Z",
    "topic": "sports"
  },
  {
    "slug": "1m-ai-websites-contributed-70m-to-anguillas-government-revenue-last-year",
    "title": ">1M \".ai\" websites contributed $70M to Anguilla's government revenue last year",
    "description": "Data from Domain Name Stat reveals that the top-level domain originally assigned to the British Overseas Territory of Anguilla passed the milestone...",
    "fullText": "Data from Domain Name Stat reveals that the top-level domain originally assigned to the British Overseas Territory of Anguilla passed the milestone in early January.\n\nFrom Sandisk shareholders to vibe coders, AI is making — and breaking — fortunes at a rapid pace.\n\nOne unlikely beneficiary has been the British Overseas Territory of Anguilla, which lucked into a future fortune when ICANN, the Internet Corporation for Assigned Names and Numbers, gave the island the “.ai” top-level domain in the mid-1990s. Indeed, since ChatGPT’s launch at the end of 2022, the gold rush for websites to associate themselves with the burgeoning AI technology has seen a flood of revenue for the island of just ~15,000 people.\n\nIn 2023, Anguilla generated 87 million East Caribbean dollars (~$32 million) from domain name sales, some 22% of its total government revenue that year, with 354,000 “.ai” domains registered.\n\nAs of January 2, 2026, the number of “.ai” domains surpassed 1 million, per data from Domain Name Stat — suggesting that the nation’s revenue from “.ai” has likely soared, too. This is confirmed in the government’s 2026 budget address, in which Cora Richardson Hodge, the premier of Anguilla, said, “Revenue from domain name registration continues to exceed expectations.”\n\nThe report mentions that receipts from the sale of goods and services came in way ahead of expectations, thanks primarily to the revenue from “.ai” domains, which is forecast to hit EC$260.5 million (~$96.4 million) for the latest year. In 2023, domain name registrations were about 73% of that wider category. Assuming a similar share of that category for this year would suggest that the territory has raked in more than ~$70 million from “.ai” domains in the past year.\n\nAnguilla typically charges $140 for a two-year domain registration, creating a steady stream of income, as some 90% of domains renew after two years. But auctions for expired “.ai” domains, sold via domain name registrar Namecheap, are where bigger numbers roll in — for example, the domain “you.ai” was bought for $700,000 last September, and even in the past week, 31 expired “.ai” domains were sold at a total price of ~$1.2 million, per domain sale tracker NameBio.",
    "readingTime": 2,
    "keywords": [
      "british overseas",
      "overseas territory",
      "top-level domain",
      "domain name stat",
      "domains",
      "revenue",
      "island",
      "registration",
      "expectations",
      "sale"
    ],
    "qualityScore": 1,
    "link": "https://sherwood.news/tech/now-more-one-million-ai-websites-contributing-an-estimated-70-million-anguilla-government-revenue/",
    "thumbnail_url": "https://sherwoodnews.imgix.net/mwphzyq69oso/en-US/assets/files/1438940144_little-bay-beach.jpg?w=1600&auto=compress%2Cformat&cs=srgb",
    "created_at": "2026-01-26T18:21:40.891Z",
    "topic": "tech"
  },
  {
    "slug": "agents-are-about-to-change-software",
    "title": "Agents Are About to Change Software",
    "description": "Man, it is a really weird time in the software world right now. Like a lot of people, when I picked up ChatGPT and Midjourney back in late 2022. It felt like wizardry. For a year I experimented and…",
    "fullText": "Man, it is a really weird time in the software world right now. Like a lot of people, when I picked up ChatGPT and Midjourney back in late 2022. It felt like wizardry.\n\nFor a year I experimented and experimented. I wrote about how Midjourney responds to emojis and even tried to see if I could write a children’s book with AI. The output here looks pretty rough today, but it was a revelation at the time. And the AI tools just kind of gradually got better and better.\n\nOne thing that never really clicked for me though was agentic coding. The vision is that you tell an LLM what you want, and it just goes off and executes it. It never really worked that well. It felt like the agents just kind of plowed through code and broke a bunch of stuff on the way to making the fix I wanted. Coding agents were more a curiosity, not something I could actually use.\n\nHowever, this is all about to change. And it is going to change everything about how software is built.\n\nI was drawn back by a post called Welcome to Gas Town by Steve Yegge.\n\nGas Town is part visionary, part performance art. It’s a Mad Max-themed fever dream that enables agents, managing agents, managing agents. There’s a mayor, rigs, polecats, a deacon and a refinery—and they all work together in this vast factory where vibes go in and code comes out.\n\nThere’s a lot of really clever ideas that somewhat mesh together. You’ve probably heard about the context window LLMs have. Essentially it’s their short-term memory. Once an agent uses about 20% of its context window, its intelligence drops off a cliff and it starts doing insane things like dropping databases.\n\nGas Town employs a trick to manage that issue. It assigns tasks to ephemeral “Polecat” agents. Polecats do a task and then disappear—basically removing the challenge of managing context windows.\n\nMaggie Appleton articulated the value of Gas Town well:\n\nWe should take Yegge’s creation seriously not because it’s a serious, working tool for today’s developers (it isn’t). But because it’s a good piece of speculative design fiction that asks provocative questions and reveals the shape of constraints we’ll face as agentic coding systems mature and grow.\n\nAnd so, intrigued by Gas Town, I decided to try vibe coding again.\n\nI’m not the type to just dip my toes in. If I’m going to do something, I do a cannonball.\n\nI’m always looking for the meta. What is the best strategy and who knows how to execute it? I read that Anthropic’s CTO keeps five agents running constantly and barely looks at the actual files. Either that’s marketing or there must be something there, or maybe both?\n\nI read a bunch of articles and watched a ton of YouTube videos. YouTube was pretty wild. There are these videos with guys streaming 5-10 Claude Code terminals, blaring EDM (lol) and managing all these agents.\n\nI’m kind of poking fun, but I actually learned a lot about setup from that BridgeMind channel. If you’re interested I might start with his videos about Warp and the OpenCode CLI.\n\nI wanted to see how well these agents actually work, but I needed an easy entry point. A Chrome extension to restyle Hacker News seemed perfect. It’s been in my backlog for a while, and because it’s purely frontend, I knew I’d be comfortable judging the output.\n\nAnd honestly it was. Initially I tried to one-shot the thing and—as I expected—that was a failure. But then I decided to slow down. I told the agent to scaffold a chrome extension to restyle Hacker News pages. It worked. And I kind of just broke up these tasks into smaller pieces. Tested them as I went.\n\nSure there were bugs. But I kind of just did what I do when I’m reviewing any engineers’ code. Inspect the DOM, look at the styles, look at the console and then give feedback. When the context window hit’s 20% I typically close that window and open a new chat. The OpenCode CLI even allows you to drop screenshots. It’s pretty wild.\n\nNow, I don’t have a dozen agents running at the same time. I never felt the need to have more than two working. And I’m honestly not sure how UI work even gets shipped in Gas Town? My guess is Yegge is probably a lot less concerned with UX than I am.\n\nWith AI agents, the last mile—that final polish and detailing—will be critical. We already see this in Salesloft, where sellers review generative emails before sending. In design, it manifests as small UI tweaks. It will be something else for doctors and something else for mechanical engineers. But I think there is a real opportunity in refining how humans interact with the agent’s output, creating better loops for feedback and adjustment.\n\nYou know what? There’s something here though. I don’t really like the term “vibe coding.” And I know the concept is polarizing. But after tinkering with this stuff for a couple days—I think agents are about to change how we build software.\n\nThe conception of what it looks like to make software is going to change pretty quickly.\n\nThe three major functions on a delivery team (or feature team) are engineering, design and product management. I’ve long thought we’re going to start to see more overlap in those functions. I’m even more sure of it now.\n\nI think we’re going to start to see a hybrid role emerge—product engineer.\n\nWhat does this mean delivery teams will look like in the future? I imagine they are either significantly smaller or significantly more productive. I’m not sure if QA is embedded into these teams the same way they are currently or if there is a separate team of—well, people managing QA agents. I have a lot of questions.\n\nThis also makes me think a lot about Ben Thompson’s theory on bundling and unbundling. From 2010 to 2015, companies quickly moved on the back of frameworks. First like Ruby on Rails and Bootstrap. Then on other technologies like Angular and React. The speed these frameworks provided caused an unbundling in the software world.\n\nPoint solutions were able to move fast and gather steam while slow incumbents either weren’t nimble enough or weren’t in a place to capitalize on the productivity provided by frameworks. Starting in 2016, that changed. Customers were overwhelmed with choices. Larger companies caught on and smaller ones consolidated into larger platforms.\n\nI think that’s about to shift again. And probably this year.\n\nDavid Cummings called it out in his newsletter this weekend. SaaS companies are about to see a massive wave of new competition. And it is going to happen extremely fast. The bar to build software has been lowered. A two-person team will soon be able to build what used to take a whole department.\n\nThis puts incumbent software companies in a pretty dangerous situation. Those that are not able to be nimble and go fast are going to be in real trouble. I think this is especially true in the consumer, SMB and mid-market segments. Enterprise software may have some buffer as customers of enterprise software are buying a process more than the software itself.\n\nHonestly, it makes me a little nervous. The industry is going to change and everyone’s jobs are going to look a little different—product design included.\n\nBut as someone who got into software just because I wanted to make things, this is a dream come true. I’m seeing a glimpse of the vision I hoped for in 2022. It’s not just a toy anymore. It’s an unbelievable tool for builders.\n\nIf you’ve been ignoring AI tools because you think they are overhyped, or maybe don’t see how they fit into your workflow. I’d encourage you to give them another look.",
    "readingTime": 7,
    "keywords": [
      "restyle hacker",
      "chrome extension",
      "agentic coding",
      "vibe coding",
      "pretty wild",
      "context window",
      "enterprise software",
      "gas town",
      "agents managing",
      "hacker news"
    ],
    "qualityScore": 1,
    "link": "https://solomon.io/agents-are-about-to-change-software/",
    "thumbnail_url": "https://solomon.io/wp-content/uploads/2026/01/WelcomeToGasTown-2200x1196.jpg",
    "created_at": "2026-01-26T18:21:39.265Z",
    "topic": "tech"
  },
  {
    "slug": "the-windows-pc-is-dying-thanks-to-cloudbased-services-and-ai",
    "title": "The Windows PC is dying, thanks to cloud-based services and AI",
    "description": "The rise of AI tools and services has added a new twist to the decline and fall of standalone Windows PCs.",
    "fullText": "For years, I’ve been watching the slow evolution of classic Windows PCs into cloud-based Windows and Office services. Sure, you can still buy a PC with Windows on it, but you’re not really “buying” Windows as much as renting it.\n\nWindows cloud PCs have gone from Microsoft’s side project to the centerpiece of its post‑Windows‑10 strategy. But the story in 2026 is less “death of the PC” and more “merger of PC, cloud, and AI under Microsoft’s terms.” Today, the most interesting question is not whether Windows moves to the cloud, but how much local control users are willing to surrender in exchange for AI‑infused desktops.\n\nFor the longest time, Microsoft had planned on the Windows 365 Cloud PC to shift users from a PC‑centric world to Desktop‑as‑a‑Service, with Windows 11 acting as the on‑ramp. Microsoft’s own internal slideware later made that explicit: the plan is to “move Windows 11 increasingly to the cloud… to enable a full Windows operating system streamed from the cloud to any device.” What started as the Business and Enterprise editions of Windows 365, running on Azure with per‑user monthly pricing in the $30-to-$60 range, has since been productized and polished as if it were the “real” Windows roadmap rather than a side hustle.\n\nOther harbingers included Windows 365 Boot, which bypassed the local operating system entirely and dropped you straight into a personalized cloud desktop on shared or BYOD hardware. And Windows 365 Switch blurs the boundary between local and hosted sessions, turning a cloud PC into “just another desktop.”\n\nAt the same time, Windows App enables you to run Azure Virtual Desktop, Windows 365, Microsoft Dev Box, Remote Desktop Services, and remote PCs from, well, pretty much any computing device. Specifically, you can use Windows App to run Windows on Macs, iPhones, iPads, other Windows machines, even in web browsers. That last means you can now run Windows on Linux-powered PCs, Chromebooks, and Android phones and tablets.\n\nHeck, you can even run Windows using a Meta Quest VR headset!\n\nA funny thing happened on the way to this cloud-based subscription service. AI came along. Microsoft, which has gone whole-hog into AI — if I see one more Copilot tie-in, I’m going to scream — decided that AI PCs would be the future. It’s wrong.\n\nAs Kevin Terwilliger, Dell’s head of product, said of PC customers, “They’re not buying based on AI. I think AI probably confuses them more than it helps them.” (Ya think?)\n\nThat’s not to say people aren’t using AI. They are. But, no one’s managed to sell them yet on the idea of agentic AI PCs, even with the special sauce of Neural Processing Units (NPUs), Intel Panther Lake chips, and super-duper GPUs. Most analysts, and at least one cranky Computerworld columnist (guess who), think the Copilot+ PC hype needs to end.\n\nJeff Bezos — remember him? he knows a thing or two about the cloud — suggested that the PC is never going to be able to deliver the AI goods. Instead, “AI will be in everything,” but compute will be delivered via the cloud. In case you missed it, at the last Ignite conference, Microsoft highlighted its Windows 365 cloud PC concept, with AI agents, not AI PCs.\n\nGoing forward, Microsoft will want you not to buy and run your own applications, AI-infused or not, on a PC. They’ll want you to subscribe and run “your” AI-enabled programs on their cloud services.\n\nThis will not be cheap. Today, the bottom-end Windows 365 Cloud PC with 2 virtual CPUs, 4GB RAM, and 64GB of storage will cost you $28 a month. Good luck running Windows 11 on its own, never mind with any application, on 4 gigs of RAM. The absolute minimum for a useful cloud desktop with 8GB of RAM is $41. Add in AI functionality, an instance of Office, and you’re talking real money.\n\nFor companies, math is being reframed. Instead of comparing Windows 365 to the sunk cost of a once‑every‑five‑years PC purchase, vendors pitch it against the fully burdened price of securing, patching, and managing a distributed fleet in a hybrid‑work world. In that context, a per‑seat cloud desktop subscription stops looking like a weird outlier and just another SKU on the Microsoft subscription treadmill.\n\nI’m old enough to recall the transition from centralized computers you used via a terminal to the locally owned PC revolution. Then, we controlled the “horizontal and the vertical.” The AI-enabled cloud desktop puts Microsoft in charge of the entire application stack and your online identity.\n\nIt might be 2026, but Microsoft’s business model going forward looks a lot like the ones I saw in 1976. Maybe you’re comfortable with that. I’m not.\n\nMicrosoft frames Windows 365 as the sane way to keep corporate data off home PCs shared with kids and games, which is hard to argue with if you are a CSO signing audit reports. But the shift to cloud PCs plus on‑device AI also deepens lock‑in. Sure, you can run Windows 365 from anything, but it runs best when paired with Windows 11 hardware.\n\nThe old Windows desktop is dying. The 2026 twist is that its successor does not live only in Microsoft’s cloud. It also lives on your desk, in your laptop, and in the NPU you did not ask for, all stitched together into a Windows that is becoming less an operating system and more a metered utility.\n\nMe? You know my bias. If you want control over your privacy, your data, how much you’re paying for compute, and your PC, Linux is the best way forward.",
    "readingTime": 5,
    "keywords": [
      "operating system",
      "cloud pcs",
      "cloud desktop",
      "windows cloud",
      "windows cloud pc",
      "windows app",
      "ai pcs",
      "microsoft",
      "microsoft’s",
      "you’re"
    ],
    "qualityScore": 1,
    "link": "https://www.computerworld.com/article/4119219/the-windows-pc-is-dying-thanks-to-cloud-based-services-and-ai.html",
    "thumbnail_url": "https://www.computerworld.com/wp-content/uploads/2026/01/4119219-0-46063300-1769172402-windows-365-100945479-orig.jpg?quality=50&strip=all&w=1024",
    "created_at": "2026-01-26T18:21:38.022Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-takes-aim-at-google-amazon-and-nvidia-with-new-ai-chip",
    "title": "Microsoft takes aim at Google, Amazon, and Nvidia with new AI chip",
    "description": "Microsoft announced its new Maia 200 AI chip, taking aim at Amazon, Google, and Nvidia.",
    "fullText": "Microsoft (MSFT) is taking aim at cloud rivals Amazon (AMZN) and Google (GOOG, GOOGL) with the debut of its next-generation custom AI chip.\n\nCalled Maia 200, the chip will run in Microsoft’s own data centers before the company eventually makes it available to its wider customer base.\n\nLike Google’s TPUs and Amazon’s Trainium processors, Microsoft’s second AI chip is meant to give the Windows maker more flexibility when it comes to how it powers its AI services. By using its own internally developed chips, the company ensures it doesn’t have to rely solely on processors developed by Nvidia (NVDA) or AMD (AMD).\n\nGoogle and Amazon have been using their own custom chips for years, while Microsoft has been slower to adopt in-house AI silicon.\n\nAccording to Microsoft, the Maia 200 will be built using TSMC’s 3-nanometer process and is designed to run large-scale AI workloads, while “delivering efficient performance per dollar.”\n\nThe Maia 200 will be built into large server racks with trays housing four chips each. Microsoft is also touting how quickly it can deploy the new chips into data centers, saying chips are installed and running AI models within days of parts arriving.\n\nGetting AI servers up and running quickly is an important aspect of the broader data center business. It’s not just a matter of keeping construction costs down, either. The longer a chip goes unused, the less cash it can generate for the company by running AI apps.\n\nThe Maia 200 adds to the growing competition Nvidia is facing from both AMD and its own customers. Microsoft’s Maia 100 already powers both the company’s and OpenAI’s (OPAI.PVT) AI models, while Google and Amazon both power their respective models and Anthropic’s (ANTH.PVT) models.\n\nAnd in November, The Information reported that Meta was talking to Google about using the search giant’s TPUs in its own data centers to power its AI services. That sent Nvidia stock down at the time, as Wall Street raised fears that the company was in danger of losing market share.\n\nNvidia’s stock price is up less than 1% since the start of the year.\n\nDespite the incursions into Nvidia’s lane, Google, Amazon, and Microsoft are unlikely to pose a serious threat to the AI leader. Experts say that while the cloud company’s AI chips may function well for their own services, that’s not likely to translate to smaller third-party customers as easily.\n\nNvidia’s chips are also highly coveted because they are designed to be multipurpose, allowing companies to use them for a litany of applications and services.\n\nAs for performance, the Maia 200 won’t unseat Nvidia, but Microsoft claims it outpaces both Google’s latest TPU and Amazon’s newest Trainium chip in a number of categories. The Maia 200 also packs more high-bandwidth memory than Google’s or Amazon’s offerings, which is key to running high-powered AI applications.",
    "readingTime": 3,
    "keywords": [
      "the maia",
      "chips",
      "chip",
      "services",
      "models",
      "centers",
      "google’s",
      "nvidia’s",
      "cloud",
      "custom"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-takes-aim-at-google-amazon-and-nvidia-with-new-ai-chip-160027494.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/6hrTce0mQfjD5UJl9IfFFA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2021-06/7a86bbd0-d429-11eb-bd9f-5b30fa82b522",
    "created_at": "2026-01-26T18:21:33.390Z",
    "topic": "finance"
  },
  {
    "slug": "the-eu-is-probing-grok-over-its-spreading-of-sexual-ai-images",
    "title": "The EU is probing Grok over its spreading of sexual AI images",
    "description": "The EU is investigating X over the spread of illegal images, including possible child sexual abuse material, generated by Grok on the platform.",
    "fullText": "The European Union is launching an investigation into Grok as Elon Musk's AI chatbot continues to face backlash over its spreading of AI-generated sexual images.\n\nThe European Commission, the bloc's governing body, said on Monday that it had opened a formal investigation into X over the spread of illegal images, including possible child sexual abuse material, generated by Grok on the social media site.\n\nThe Commission said it would also extend an ongoing investigation into X's recommendation algorithm, with the regulator previously fining the social media platform $140 million over its \"deceptive\" blue checkmarks.\n\nUnder the EU's Digital Services Act, large social media platforms can face fines of up to 6% of their global annual turnover for violations, and temporary suspension from the European Union as a last resort.\n\nWhen asked for comment on the new investigation, xAI sent an automatic email response that did not address the issue.\n\nIt comes after X said earlier this month that it had implemented \"technological measures\" to prevent users from editing images of real people into revealing clothing, after a wave of global backlash over the circulation of AI-generated sexual images on the site.\n\nX made the change after California's attorney general and the UK media regulator both launched investigations into Grok — but Business Insider's Henry Chandonnet found that the AI chatbot could still be used to make sexualized images in the days after.\n\nGrok was also temporarily banned in Malaysia, Indonesia, and the Philippines over the AI images, although Malaysia and the Philippines later said they would lift their bans after receiving assurances from xAI.\n\nMusk responded to the criticism on X in early January, telling one user, \"Anyone using Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"",
    "readingTime": 2,
    "keywords": [
      "ai-generated sexual",
      "illegal content",
      "social media",
      "sexual images",
      "grok",
      "investigation",
      "chatbot",
      "face",
      "backlash",
      "site"
    ],
    "qualityScore": 0.55,
    "link": "https://www.businessinsider.com/eu-probing-grok-sexual-ai-images-xai-elon-musk-2026-1",
    "thumbnail_url": "https://i.insider.com/69775325e1ba468a96aaadd4?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.681Z",
    "topic": "finance"
  },
  {
    "slug": "finland-is-trying-to-poach-top-tech-and-ai-talent-from-the-us-with-2week-visas-and-better-worklife-balance",
    "title": "Finland is trying to poach top tech and AI talent from the US with 2-week visas and better work-life balance",
    "description": "Finland wants to lure American engineers and researchers with fast-track visas and good work-life balance as part of the global AI talent wars.",
    "fullText": "Finland is stepping into the tech talent wars.\n\nThe Nordic country is making a push for tech workers from abroad, with a particular focus on the US. The goal is to attract engineers and researchers working in deep tech, especially in the fields of quantum computing, AI, and health innovation.\n\nThe effort comes as competition for AI talent intensifies worldwide and tech workers in the US grapple with layoffs, burnout, and visa complications. KPMG's annual survey of global CEOs found that 70% were concerned about competition for AI talent. According to BCG's 2024 talent tracker report, the US remained dominant in attracting AI talent worldwide.\n\nAlready known for its tech scene, Finland, with a population of around 5.6 million, is positioning itself as a place where American tech workers can find a better work-life balance without sacrificing their careers — a notable contrast to the famous grindset of Silicon Valley.\n\n\"Of course, there might be long days once in a while, but it's such a high value, and it's also protected by law that you can't work more than an average of 40 hours per week,\" Laura Lindeman, head of the Work in Finland program, told Business Insider.\n\nShe said that even in the tech sector, when people leave work for the day, they really do leave. \"Offices are silent,\" she said. Employers in Finland, often ranked the happiest country in the world, also see the benefit of workers having lives outside work, she said, adding that the general sentiment is \"it narrows your thinking if you only work.\"\n\nFinland is working with more than 30 Finnish tech companies and universities to promote open roles to foreign workers. A preview of the job openings being promoted under the program includes roles with Oura Health (the company behind the Oura Ring), quantum computing firm QMill, and Aalto University.\n\nLindeman said Americans interested in working in Finland should consider reaching out to companies or universities, even if no open roles are listed, as some employers are open to creating positions for the right candidate. While the campaign emphasizes the US, it also targets talent from India, Brazil, and other parts of Europe.\n\nOnce candidates receive a job offer, they can apply for a specialist visa through Finland's Fast Track program. Approved applicants can receive a work-residence permit in as little as two weeks, with processing times averaging about 10 days, Lindeman said. Finland also offers integration programs to help newcomers settle in, and spouses of workers on specialist visas are eligible for work permits, she added.\n\nGovernment data suggests interest from Americans is already rising. Finland granted 60 specialist residence permits to US citizens in 2024 and 85 in 2025, according to Finnish immigration statistics. The number of residence permits granted to US researchers also increased, from 35 in 2024 to 46 in 2025.\n\nJordan Blake Banks, an American who moved to Finland in 2019 to pursue a master's degree through the Fulbright program, said the country offers plenty of benefits, from its forests to its emphasis on work-life balance. After finishing her degree, Banks stayed in Finland and eventually landed a job as a sustainability consultant at Deloitte in Helsinki.\n\n\"The general idea is that the company and the colleagues respect you as a person, and that you can have your free and personal time,\" she said, adding parents regularly leave work during the day for family obligations without stigma. Many Finns also take about a month of vacation during the summer, along with time off in the winter.\n\nBanks said salaries in Finland tend to be lower than in comparable roles in the US, but she thinks the gap is offset by more affordable essential services, including healthcare, education, and childcare.\n\nWhile learning Finnish isn't necessary for working in the country — Lindeman said English is widely used in the tech industry, and about 80% of Finns speak fluent English — Banks said not knowing the language can feel isolating in everyday life.\n\nShe enrolled in a four-month integration program run by the city, where she learned the language and eventually passed the national exam required to become a Finnish citizen. Banks also met her now-wife while living in Finland.\n\nOne cultural adjustment of living in Finland, she said, has been that the people tend to be more reserved than Americans. \"If you're coming from a very friendly culture or a very warm culture, I think that could be a shock,\" she said, adding she'd been able to use that to her advantage.\n\nBanks said speaking up helped her land a paid research position at her university. \"I was willing to make contact and be the brave American willing to ask for things,\" she said.",
    "readingTime": 4,
    "keywords": [
      "quantum computing",
      "work-life balance",
      "residence permits",
      "tech workers",
      "talent",
      "program",
      "finnish",
      "roles",
      "finland",
      "adding"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/finland-us-tech-ai-talent-work-life-balance-fast-visas-2026-1",
    "thumbnail_url": "https://i.insider.com/69734b95a645d1188187dba0?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.547Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-is-buying-more-coreweave-stock-this-time-its-in-for-2-billion",
    "title": "Nvidia is buying more CoreWeave stock — this time it's in for $2 billion",
    "description": "Nvidia is deepening its partnership with CoreWeave and making its biggest investment yet in the AI cloud company.",
    "fullText": "Nvidia is getting the checkbook out again for CoreWeave, buying $2 billion worth of the cloud company's stock.\n\nCoreWeave said on Monday that alongside the investment, the two companies would build \"AI factories\" together.\n\nThe partnership aims to help CoreWeave accelerate its buildout of AI infrastructure with 5 gigawatts of capacity by 2030.\n\n\"From the very beginning, our collaboration has been guided by a simple conviction: AI succeeds when software, infrastructure, and operations are designed together,\" said Michael Intrator, the cofounder, chairman, and CEO of CoreWeave, in a press release.\n\nNvidia made its latest investment in CoreWeave at a purchase price of $87.20 per share.\n\nCoreWeave's share price was up nearly 10% in premarket trading.\n\nCoreWeave, which builds data centers full of AI chips known as graphics processing units, or GPUs, has had a close relationship with Nvidia for several years.\n\nNvidia invested about $100 million in CoreWeave in 2023, then acquired more shares around the time of its IPO in March 2025.\n\nAlongside its equity investments, Nvidia also sells its chips to CoreWeave, a dynamic that has contributed to broader industry concerns about circular AI deals.",
    "readingTime": 1,
    "keywords": [
      "nvidia",
      "coreweave",
      "investment",
      "together",
      "infrastructure",
      "chips",
      "alongside"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/nvidia-buys-2-billion-coreweave-stock-ai-partnership-2026-1",
    "thumbnail_url": "https://i.insider.com/69776c03d3c7faef0ecce718?width=1200&format=jpeg",
    "created_at": "2026-01-26T18:21:29.387Z",
    "topic": "finance"
  },
  {
    "slug": "ai-has-made-hiring-worsebut-it-can-still-help",
    "title": "AI Has Made Hiring Worse—But It Can Still Help",
    "description": "While AI has the potential to transform hiring, it’s important to be realistic about what has actually happened so far. For all the talk about AI supercharging talent, the reality is that talent markets remain as inefficient as ever, with employers struggling to find the right person for the right job, while employees remain disenchanted with their jobs and careers. Thanks to AI, hiring has become a noisy, crowded arms race of automation, often more inhumane for both job seekers and hiring managers. The result is an ecosystem where both sides are inundated, sometimes fooled, occasionally impressed, and mostly exhausted, with a rising crisis of trust. To improve hiring, leaders must resist the temptation to treat AI as a cure-all.",
    "fullText": "AI Has Made Hiring Worse—But It Can Still Help by Tomas Chamorro-PremuzicJanuary 26, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintI have been researching, speaking, and writing about the impact of AI in hiring for years, long before large language models entered the mainstream. AI’s deep penetration in recruitment was always likely. People spend much of their lives online, including while working (or pretending to), while firms have invested trillions in digital systems designed to capture, store, and analyze the resulting data from this. A technology like AI, capable of translating this ocean of data into insight was therefore inevitable.",
    "readingTime": 1,
    "keywords": [
      "hiring"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/ai-has-made-hiring-worse-but-it-can-still-help",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_24_SamuelFinch.jpg",
    "created_at": "2026-01-26T18:21:28.523Z",
    "topic": "business"
  },
  {
    "slug": "for-multinational-companies-localization-matters-more-than-ever",
    "title": "For Multinational Companies, Localization Matters More Than Ever",
    "description": "Companies now face conflicting trade regimes, strict data sovereignty rules, and rising government expectations that key activities be executed within national borders. In response, leading multinationals are evolving into networks of regionally embedded businesses that still share a unified global strategy. Their success depends on building autonomous regional capabilities across every function, shaping the regulatory and ecosystem rules in the markets where they operate, and competing at the speed enabled by AI-driven intelligence systems.",
    "fullText": "For Multinational Companies, Localization Matters More Than Ever by Muqsit Ashraf, Tomas Castagnino and Giju MathewJanuary 26, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintFor decades, multinational companies treated localization as a surface-layer adjustment. They tweaked marketing, packaging, or pricing to suit regional tastes. But in today’s fractured world, such superficial localization is no longer good enough. Trade policies conflict. Data laws clash. And many governments now enforce data sovereignty laws and mandates for local sourcing and technology transfer. They require companies to perform key operations, stretching from research and development to manufacturing and data processing, within their country, instead of merely selling products from abroad. The result is a profound shift in how global companies operate. They duplicate supply chains, adjust to local markets in real time, and integrate national and regional suppliers, even at the cost of scale efficiencies, to ensure redundancy and tailor best practices for every market.",
    "readingTime": 1,
    "keywords": [
      "localization",
      "multinational",
      "regional",
      "laws"
    ],
    "qualityScore": 0.65,
    "link": "https://hbr.org/2026/01/for-multinational-companies-localization-matters-more-than-ever",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_24_2224218103.jpg",
    "created_at": "2026-01-26T18:21:28.466Z",
    "topic": "business"
  },
  {
    "slug": "georgia-leads-push-to-ban-datacenters-used-to-power-americas-ai-boom",
    "title": "Georgia leads push to ban datacenters used to power America’s AI boom",
    "description": "Southern state becoming ground zero in fight against rapid growth of facilities using huge amounts of energy and water\nLawmakers in several states are exploring passing laws that would put statewide bans in place on building new datacenters as the issue of the power-hungry facilities has moved to the center of economic and environmental concerns in the US.\nIn Georgia a state lawmaker has introduced a bill proposing what could become the first statewide moratorium on new datacenters in America. The bill is one of at least three statewide moratoriums on datacenters introduced in state legislatures in the last week as Maryland and Oklahoma lawmakers are also considering similar measures.\n Continue reading...",
    "fullText": "Southern state becoming ground zero in fight against rapid growth of facilities using huge amounts of energy and water\n\nLawmakers in several states are exploring passing laws that would put statewide bans in place on building new datacenters as the issue of the power-hungry facilities has moved to the center of economic and environmental concerns in the US.\n\nIn Georgia a state lawmaker has introduced a bill proposing what could become the first statewide moratorium on new datacenters in America. The bill is one of at least three statewide moratoriums on datacenters introduced in state legislatures in the last week as Maryland and Oklahoma lawmakers are also considering similar measures.\n\nBut it is Georgia that is quickly becoming ground zero in the fight against untrammelled growth of datacenters – which are notorious for using huge amounts of energy and water – as they power the emerging industry of artificial intelligence.\n\nThe Georgia bill seeks to halt all such projects until March of next year “to allow state, county and municipal-level officials time to set necessary policies for regulating datacenters … which permanently alter the landscape of our state”, said bill sponsor state Democratic legislator Ruwa Romman.\n\nIt comes at a time when Georgia’s public service commission – the agency that oversees utility company Georgia Power – just last month approved a plan to provide 10 additional gigawatts of energy in the coming years. It was the largest amount of electricity sought for a multi-year plan in the commission’s history, was driven by datacenters and will mostly be supplied by fossil fuels.\n\nThe 10-gigawatt plan – enough to power about 8.3m homes – in turn comes as the Atlanta metro area led the nation in datacenter construction in 2024.\n\nThis accelerated growth has already led at least 10 Georgia municipalities to pass their own moratoriums on datacenter construction, with Atlanta suburb Roswell becoming the most recent earlier this month. Municipalities in at least 14 states have done the same, according to Tech Policy Press.\n\nBernie Sanders, the Vermont independent democratic socialist senator, proposed a national moratorium last month.\n\n“What we’re seeing is, as communities are learning more about this aggressive industry’s presence … [they] want to have time to thoroughly investigate all potential harms,” said Seth Gladstone, spokesperson for Food and Water Watch.\n\nThe rampant development of datacenters to power AI raises several concerns for residents and activists alike. One is their impact on the cost of electricity. “In the public’s mind, datacenters and utility bills are inextricably linked,” said Charles Hua, founder and executive director of PowerLines, an organization that works on lowering utility bills and involving communities in decisions about energy.\n\nHua noted that the relationship between the two varies, depending on each state’s market and regulatory system. In Georgia, he said, the Georgia Power utility company makes profit off new capital investments – so it has incentive to keep building new power plants. This approach has led Georgia’s rates to go up by a third in the last several years alone. Meanwhile, he said, the power company doesn’t have incentive to make the electrical grid more efficient – which “could actually lower prices”, Hua said.\n\nBut datacenter concerns in Georgia also include water use and lost tax revenue. Republicans in the state legislature have introduced bills this year to protect consumers from increases in their utility bills and to end tax breaks for the centers. A Democrat has proposed that datacenters make public how much energy and water they use each year.\n\nRomman is also running for governor. If elected, she would become the first Palestinian American elected to statewide office in Georgia and break the near quarter-century hold Republicans have on the office.\n\nHer bill, HB 1012, has a Republican co-sponsor in state representative Jordan Ridley, who said he signed onto the measure because he wanted to give local governments time to develop zoning regulations on datacenters, since “it seems like they’re being built across the state”.\n\n“Every local government has zoning codes and … they need public input. That takes time,” Ridley said. At the same time, Ridley added, “datacenters … provide tax revenue and high-paying jobs. I’m not against datacenters.”\n\nRomman’s bill is not just a policy proposal; it’s also a political one. In a statement, she wrote that the moratorium “would provide time for Georgians to vote on the majority of the Public Service Commission seats who make final decisions on energy-related projects”.\n\nGeorgia is one of 10 states that elect their utility regulators. Voters in the state elected progressive Democrats Alicia Johnson and Peter Hubbard to the five-member commission in November, leading the agency to lose its all-Republican makeup for the first time in nearly two decades. Another seat is up for a vote this November.\n\nThe calculus: if the commission becomes majority-Democratic, it will no longer give a rubber stamp to electricity demands from Georgia Power driven by tech companies seeking to build datacenters.\n\nHubbard, now in his new position, recently wrote an editorial asserting that Georgia voters “see data centers receiving tax breaks as their power bills go up. They see local communities struggle with competition for water supplies and high voltage transmission lines that reduce property values. And they see how the PSC approved every request placed before it by the monopoly electric utility.\n\n“This is why opposition to data centers is growing in Georgia; because Georgians oppose being treated as collateral damage by the unregulated growth of data centers that will push their power bills even higher.”\n\nThere’s another political implication to Romman’s bill. Paul Glaze, spokesperson for Georgia Conservation Voters, said if the bill crosses from the House to the Senate, “it may be a preview of the potential general election” later this year.\n\n“The question is, in communities where datacenters are coming, who are voters going to trust to have their back?” Glaze said. “Anyone serious about statewide office should have a clear position on this.”",
    "readingTime": 5,
    "keywords": [
      "romman’s bill",
      "ground zero",
      "huge amounts",
      "datacenter construction",
      "service commission",
      "tax revenue",
      "tax breaks",
      "utility bills",
      "georgia power",
      "datacenters"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/26/georgia-datacenters-ai-ban",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7ea230ec26730557de8ddac52bc5c2b63dd66515/1213_0_3698_2959/master/3698.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a872fe2d94683fa97a6d6cf2c2af1bb0",
    "created_at": "2026-01-26T18:21:25.582Z",
    "topic": "tech"
  },
  {
    "slug": "pope-leos-latest-ai-warning-overly-affectionate-chatbots",
    "title": "Pope Leo's latest AI warning: 'overly affectionate' chatbots",
    "description": "Pope Leo XIV warned against personalized chatbots that can replicate friendly or intimate behaviour.",
    "fullText": "Even the pope is worried about how we're talking to chatbots.\n\nIn a written address for Saturday's World Day of Social Communications, Pope Leo XIV warned against personalized chatbots that can replicate friendly or intimate behavior.\n\n\"Overly affectionate chatbots, besides being ever-present and readily available, can become hidden architects of our emotional states, thereby invading and occupying the sphere of people's intimacy,\" the first-ever US-born pope wrote.\n\nThe pope called for national and international regulations to protect users from forming emotional, deceptive, or manipulative bonds with chatbots.\n\n\"All stakeholders — from the technology industry to policymakers, from creative businesses to academia, from artists to journalists and educators — must be involved in building and implementing a conscious and responsible digital citizenship,\" the pope wrote.\n\nThe Holy See leader has spoken about AI and his concerns with the technology several times since he was elected in May.\n\nIn his first address since becoming pope, he said he wanted to make AI a focus of his papacy and that the technology poses new challenges for \"human dignity, justice, and labor.\" In November, he wrote to AI leaders on X, calling on them to \"cultivate moral discernment\" when building AI tools.\n\nAt the end of last year, the pope met Megan Garcia, a woman whose 14-year-old son, Sewell Setzer, died by suicide after interacting with a Character.AI chatbot.\n\nFlorida-based Garcia filed a lawsuit against chatbot-building startup Character.AI, alleging that the company, which lets people have in-depth and personal conversations with AI chatbots, was responsible for the death of her son, Sewell Setzer III.\n\nEarlier this month, Google and the startup agreed to settle multiple lawsuits from families, including Garcia, whose teenagers died by suicide or hurt themselves after interacting with Character.AI's bots. These negotiations are among the first settlements in lawsuits that accuse AI tools of contributing to mental health crises and suicides among teenagers.",
    "readingTime": 2,
    "keywords": [
      "son sewell",
      "pope",
      "chatbots",
      "technology",
      "address",
      "emotional",
      "responsible",
      "tools",
      "died",
      "suicide"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/pope-leo-ai-warning-overly-affectionate-personalized-chatbots-regulation-2026-1",
    "thumbnail_url": "https://i.insider.com/6976fa35e1ba468a96aaace6?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.685Z",
    "topic": "finance"
  },
  {
    "slug": "google-cloud-gaming-boss-says-ai-is-the-iron-man-suit-for-game-developers-and-everyone-needs-to-get-on-board",
    "title": "Google Cloud gaming boss says AI is the Iron Man suit for game developers — and everyone needs to get on board",
    "description": "For Jack Buser, who has worked in the gaming industry for 30 years, AI is  an opportunity to push the boundaries of player experiences.",
    "fullText": "Tony Stark relied on his ultra-polished, tech-heavy \"Iron Man\" suit to achieve his superhero feats.\n\nJack Buser, the global director for games at Google Cloud, thinks AI will help game developers in the same way.\n\n\"There will always be holdouts, just like every technological revolution, but it's becoming so common now,\" Buser told Business Insider. \"We're seeing a major shift.\"\n\nBuser and other tech industry leaders have said that implementing AI could transform how people work. In the gaming industry, the tech could help streamline operations, resulting in cost cuts, faster production times, or help developers tackle an array of tasks.\n\n\"It's like the Iron Man suit of armor, right? It's still you inside the suit of armor, but you're suddenly able to do things that you couldn't do before,\" Buser said. \"If you armor everybody up in your studio with suits that allow them to work more quickly and remove the drudgery, that tends to be well received after it's been implemented.\"\n\nBuser urged executives at studios and companies to take the lead by giving developers the necessary tools.\n\n\"If you're the CTO of a games company, make that suit of armor available. Make sure that it's safe. Make sure that you take the time to work with people inside your company so that they can understand what the technology can and can't do, and what your intentions for the technology are and what they are not,\" Buser said.\n\n\"It has as much to do with getting these tools up and running in your development pipelines as it does working culturally with your company to help it make that transformation,\" he added.\n\nGetting comfortable with AI, he said, shouldn't be confined to developers alone.\n\n\"It can be tricky at the executive level. You don't have a crystal ball of where this is all going,\" he said. \"It takes getting your hands dirty, experimenting with the technology, seeing what it does and what it doesn't do.\"\n\nMany global industries are undergoing a technological shift driven by advances in AI. Companies are increasingly adopting the tech in their workflows, which some critics say could diminish job prospects for humans. Supporters argue it's a powerful tool that can help workers do their jobs better and faster.\n\nFor Buser, who has worked in the gaming industry for 30 years, AI has created an opportunity to push the boundaries of player experiences. At Google, that means embracing the era of \"living games.\"\n\nThe live games model, in which developers continue to add new content to a game after its initial release, is already common. AI, however, could make living games more adaptable, personalized, and immersive. The AI could also shorten update turnaround time, making the transition for players more seamless.\n\n\"As we look forward, we're looking at things like real-time game experiences,\" Buser said.\n\nFor now, though, the gaming industry will be focused on scaling and normalizing the tech.\n\n\"2026 is where companies start to scale these efforts,\" Buser said. \"Game developers who were using AI in one or two parts of their development workflow will suddenly be using it throughout their workflow. You'll start to see games that are using multiple AI-based features that are affecting the player experience.\"",
    "readingTime": 3,
    "keywords": [
      "man suit",
      "gaming industry",
      "game developers",
      "iron man",
      "games",
      "it's",
      "tech",
      "armor",
      "technology",
      "buser"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-gaming-developers-jack-buser-google-2026-1",
    "thumbnail_url": "https://i.insider.com/69768282d3c7faef0ecce384?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.539Z",
    "topic": "tech"
  },
  {
    "slug": "i-worked-at-joe-the-juice-before-founding-synthesia-a-4-billion-ai-unicorn-heres-how-i-structure-my-day",
    "title": "I worked at Joe & The Juice before founding Synthesia, a $4 billion AI unicorn. Here's how I structure my day.",
    "description": "Synthesia just raised a $200 million Series E funding round and is now valued at $4 billion. CEO Victor Riparbelli shares his daily routine.",
    "fullText": "This is an as-told-to essay based on a conversation with Victor Riparbelli, the CEO of AI video platform Synthesia. On Monday, the company announced a $200 million Series E funding round led by Google Ventures. This story has been edited for length and clarity.\n\nI founded Synthesia in 2017, and it's now a $4 billion unicorn.\n\nThe platform allows businesses to leverage generative AI to create videos for a range of corporate use cases, such as reimagining training videos, generating AI avatars of company executives to deliver internal or external messages, or dubbing webinars into dozens of languages.\n\nTo keep myself going all day, I rely on a few daily indulgences and productivity hacks.\n\nFirst and foremost, my bike. Unless the weather is terrible, I prefer to bike to and from the office most days. That's my most important ritual.\n\nAlso, coffee breaks. If I'm tired or in a bad mood, I'll go for a 15-minute walk and get an extra nice coffee at Blank Street.\n\nMy biggest non-negotiable indulgence is music. I love underground music and listen to it whenever I'm not in a meeting.\n\nI wish I were one of those 5 a.m. people, but I get up at 8 a.m., shower, and head straight to the office.\n\nI try not to check my phone before I leave my apartment, and I'm successful about 75% of the time.\n\nOnce I sit down at work, I usually go through my phone — messages, emails, and anything that came in overnight. I try to keep my early mornings free of meetings, so I have time to process things. That's when I feel the most creative, and it's when I prefer to do deep work. It's not always possible since we work across US time zones, but I generally try to protect that time. That deep-work window usually runs from around 9:30 a.m. until lunch at noon.\n\nDuring that time, I'm doing a mix of things: interviews, a lot of product work, and internal thinking. I'm still very involved in product and like to stay close to the details, even though that gets harder as the company grows. I focus on specific areas where I think my input is most valuable and try to go deep there.\n\nA big part of that time is also spent reading Slack. I make a real effort to read almost everything every day. I skim most of it, and I don't react to everything, but spending half an hour going through Slack is one of the best ways for me to understand what's actually happening across the company.\n\nAll internal communication happens on Slack — it's not a policy, it's just how the company operates. No one emails internally. For external communication, I probably split my time between email and WhatsApp, with a strong preference for WhatsApp and instant messaging. It really depends on the relationship.\n\nI usually have either a Joe & The Juice sandwich — specifically the club sandwich — or a salad. I actually used to work at Joe & The Juice early on, so I've been eating it for a long time and still love it.\n\nI don't really take time for lunch. I usually eat on the go or at my desk, and I'm typically done by around 12:30 p.m.\n\nI switch between New York and London, and when I'm based in London, the US starts to wake up in the second half of my day, so my calendar fills up with more international meetings.\n\nThe work itself stays fairly consistent: a lot of product, which I'm very involved in, as well as hiring, and external-facing work.\n\nMy cofounder, Steffen Tjerrild, now chief operating officer, and I split the business in half. I run product, technology, and marketing, while he oversees finance, operations, and sales. In those areas, I'm typically only involved at the VP level, depending on the situation. On my side of the business, I'm involved at the director level and above, though I'll sometimes go deeper when it makes sense.\n\nI have an assistant who helps manage my schedule, including some overlap with my personal life. I also try to talk to at least one user or customer every week because staying close to how people actually use the product is important to me. That, along with internal meetings, makes up most of the rest of my day. I still meet with people beyond my direct reports, often through skip-level conversations.\n\nFor example, I'll talk with our video team, who use our product for marketing, or with a sales development representative to understand what's working and what isn't. It's one of the best ways for me to stay connected to what's really happening across the company.\n\nI usually leave the office around 7 or 8 p.m. Three or four nights a week, I go to the gym, then head home and unwind. About half the time, I'll work another hour or two later in the evening.\n\nDinner is usually quick. I live alone and mostly order in, though I'll occasionally cook eggs with bacon and avocado. When I order food, it's often something simple like chicken and fries. I try to eat fairly healthy and avoid eating too late because it has a big impact on my energy, especially since I'm a bad sleeper.\n\nAt night, if I'm not working, I'm usually reading or making music. I don't watch much TV, but I love serious sci-fi films like \"Interstellar\" and \"Arrival\" and Stanley Kubrick movies like \"A Clockwork Orange.\"\n\nI used to read a lot of business books. \"Zero to One\" by Peter Thiel and Blake Masters, and \"The Black Swan\" by Nassim Nicholas Taleb were especially influential. These days, I read a mix of books and online content and spend a lot of time watching videos about technology, psychology, philosophy, and politics.\n\nI'm a terrible sleeper. The only hack that I found is that I fall asleep to podcasts or YouTube videos.\n\nI like to find ones that are interesting enough that they catch my attention — topics like physics or philosophy — but not important enough to me that I actually really want to listen to them.\n\nThen I put a sleep timer on for half an hour — and that usually knocks me out.",
    "readingTime": 6,
    "keywords": [
      "i'm typically",
      "understand what's",
      "joe the juice",
      "it's",
      "product",
      "i'll",
      "half",
      "videos",
      "internal",
      "involved"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/synthesia-ceo-victor-riparbelli-day-in-the-life-2026-1",
    "thumbnail_url": "https://i.insider.com/69680901764ca5f34d2a77d5?width=1200&format=jpeg",
    "created_at": "2026-01-26T12:26:57.381Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musks-x-faces-eu-inquiry-over-sexualized-ai-images-generated-by-grok",
    "title": "Elon Musk's X Faces EU Inquiry over Sexualized AI Images Generated by Grok",
    "description": "Regulators said the company’s lack of controls had led to the widespread use of deepfakes created with the chatbot Grok.",
    "fullText": "European Union regulators on Monday announced an investigation of Elon Musk’s social media platform X after the authorities said that it had failed to stop the spread of sexualized images generated by artificial intelligence.\n\nThe inquiry is likely to escalate a confrontation between Europe and the United States over the regulation of online content. Mr. Musk and his allies in the Trump administration have sharply criticized European Union internet regulations as an attack on free speech and American companies.\n\nThe European authorities said that X was being investigated for possible violation of the Digital Services Act, alleging that the company had not properly addressed the “systemic risks” of integrating the A.I. chatbot Grok into its service. Starting in late December, sexually explicit images generated by Grok, including of children, flooded the service, drawing worldwide criticism from victims and regulators.\n\nMr. Musk was facing mounting scrutiny in Europe even before this latest Grok controversy. Last month, X was fined 120 million euros, or about $140 million, for violating Digital Services Act rules around deceptive design, advertising transparency and data sharing with outside researchers.\n\nThe European authorities have another investigation underway about X’s recommender algorithm and policies for preventing the spread of illicit content.\n\n“Nonconsensual sexual deepfakes of women and children are a violent, unacceptable form of degradation,” Henna Virkkunen, the European Commission executive vice president who oversees enforcement of the Digital Service Act, said in a statement. “We will determine whether X has met its legal obligations under the D.S.A., or whether it treated rights of European citizens — including those of women and children — as collateral damage of its service.”\n\nThe European Commission, the executive body for the 27-nation European Union, did not give a timeline for the investigation, but said that it had the authority to order X to make changes during the inquiry in the “absence of meaningful adjustments” to the service.\n\nA spokeswoman for X referred to a previous statement the company had made about Grok. “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, nonconsensual nudity and unwanted sexual content,” the statement said.\n\nThe latest investigation illustrates a growing divide between the European Union and the United States over free speech and regulation of the internet. European officials argue that the lack of safeguards on platforms like X has allowed hate speech, misogyny and violent content to flourish online. Mr. Musk and the Trump administration have said efforts to force the companies to more proactively police the services amounts to censorship.\n\nThe Digital Services Act, passed in 2022, requires companies to meaningfully address the spread of illegal content, the definition of which varies from country to country in the European Union. It can include material that targets individuals based on their race, ethnicity, gender, sexuality or religion.\n\nEuropean regulators said that the integration of Grok into X exposed “citizens in the E.U. to serious harm.” The British authorities are also investigating the issue.\n\nThe problems began last month. In response to simple user prompts on X, the chatbot automatically created and publicly posted manipulated photographs of real people, including children, to remove their clothes, put them in skimpy clothing or pose them in sexualized situations.\n\nAs criticism grew, X limited Grok’s A.I. image creation to users who paid for premium features, which reduced the number of images. X later expanded those guardrails, saying that it would no longer allow anyone to prompt Grok’s X account for “images of real people in revealing clothing such as bikinis.”\n\nEuropean Union regulators said that they would take X’s policy changes into account during the investigation.",
    "readingTime": 4,
    "keywords": [
      "trump administration",
      "digital services",
      "services act",
      "union regulators",
      "european commission",
      "free speech",
      "images generated",
      "european authorities",
      "mr musk",
      "united states"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/01/26/business/european-union-x-grok-ai-images-musk.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/01/26/multimedia/26biz-europe-musk1-gwcf/26biz-europe-musk1-gwcf-facebookJumbo.jpg",
    "created_at": "2026-01-26T12:26:56.703Z",
    "topic": "business"
  },
  {
    "slug": "eu-investigates-elon-musks-x-over-grok-ai-sexual-deepfakes",
    "title": "EU investigates Elon Musk's X over Grok AI sexual deepfakes",
    "description": "The Commission will assess whether \"manipulated sexually explicit images\" have been shown to users in the EU.",
    "fullText": "The European Commission has launched an investigation into Elon Musk's X over concerns its AI tool Grok was used to create sexualised images of real people.\n\nIt follows a similar announcement in January from the UK watchdog Ofcom.\n\nRegina Doherty, a member of the European parliament representing Ireland, said the Commission would assess whether \"manipulated sexually explicit images\" have been shown to users in the EU.\n\nA previous statement from X's Safety account said the social media platform had stopped Grok from digitally altering pictures of people to remove their clothing in \"jurisdictions where such content is illegal\".",
    "readingTime": 1,
    "keywords": [
      "grok",
      "images",
      "european",
      "commission"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bbc.com/news/articles/clye99wg0y8o",
    "thumbnail_url": "https://ichef.bbci.co.uk/news/1024/branded_news/d843/live/4b6f9a20-fa9d-11f0-a9b2-e154b2ff290d.jpg",
    "created_at": "2026-01-26T12:26:56.094Z",
    "topic": "tech"
  },
  {
    "slug": "why-im-launching-a-feminist-video-games-website-in-2026",
    "title": "Why I’m launching a feminist video games website in 2026",
    "description": "I’ve been a games journalist since 2007, but still there isn’t much video games coverage that feels like it’s specifically for people like me. So I’m creating a home for it: Mothership\nWhether you’re reading about the impending AI bubble bursting or about the video game industry’s mass layoffs and cancelled projects, 2026 does not feel like a hopeful time for gaming. What’s more, games journalists – as well as all other kinds of journalists – have been losing their jobs at alarming rates, making it difficult to adequately cover these crises. Donald Trump’s White House, meanwhile, is using video game memes as ICE recruitment tools, and game studios are backing away from diversity and inclusion initiatives in response to the wider world’s slide to the right.\nThe manosphere is back, and we’ve lost mainstream feminist websites such as Teen Vogue; bigots everywhere are celebrating what they see as the death of “woke”.",
    "fullText": "I’ve been a games journalist since 2007, but still there isn’t much video games coverage that feels like it’s specifically for people like me. So I’m creating a home for it: Mothership\n\nWhether you’re reading about the impending AI bubble bursting or about the video game industry’s mass layoffs and cancelled projects, 2026 does not feel like a hopeful time for gaming. What’s more, games journalists – as well as all other kinds of journalists – have been losing their jobs at alarming rates, making it difficult to adequately cover these crises. Donald Trump’s White House, meanwhile, is using video game memes as ICE recruitment tools, and game studios are backing away from diversity and inclusion initiatives in response to the wider world’s slide to the right.\n\nThe manosphere is back, and we’ve lost mainstream feminist websites such as Teen Vogue; bigots everywhere are celebrating what they see as the death of “woke”. Put it all together and we have a dismal stew of doom for someone like me, a queer woman and a feminist who’s been a games journalist and critic since 2007.\n\nEverything I just listed off in that paragraph speaks to an urgent need for something different. This is why I’m launching a gender and identity-focused gaming publication called Mothership. It’s independent and worker-owned; it will rely on subscribers’ support to exist. Mothership will focus on reporting on the good and bad of modern-day game-making – alongside investigations, reviews, criticism, and historical deep dives into games and developers who paved the way to now. It will be a website for people who read the news with dread, including gaming news, and worry that Gamergaters got what they always wanted. And it will be a place for readers who wish there was something like a Teen Vogue, but for games (and without a corporate owner to kneecap it).\n\nAfter all, the last two decades have seen a lot of actual, valuable change, and modern games are evidence of that. We exist, now, in a gaming world with more female characters, more non-binary characters, more queer characters, and more characters who don’t fall into rigidly defined gender stereotypes. The GDC State of the Game Industry survey for 2025 found that 66% of surveyed game developers were male, compared with 75% in 2020, and 94% in 2009.\n\nMore people than ever can now see themselves reflected in game characters, and more diverse development teams are creating them. But change has not come easy – and we’ve seen a lot of backlash to this progress. Few websites still in existence are able to cover this backlash while also keeping their reporters safe and motivated to continue.\n\nI have dreamed of founding a website like this for a long time; it’s not as if readers haven’t wanted it before now. The problem I saw with the idea was not that people wouldn’t want it, but rather that I didn’t see a good way to pay for it. Journalism has been facing a monetisation crisis since the advent of the internet. It’s hard to convince readers to pay for something they are used to getting for free.\n\nBut I know the readers are there. In the mid-2010s, I worked for a small “geek girl” feminist website called the Mary Sue, and it was a unique pleasure to write very specific articles for a very specific audience. The Mary Sue relied on advertising income, which meant that all of us had to write up to six articles every weekday; there wasn’t time to spend on investigative reporting, for example, or long-form critical essays. I’m still proud of what we achieved, despite the intensity of those working conditions, not to mention the amount of harassment we faced just for existing. But I always dreamed of working for a place that had the same editorial remit without the harsh working conditions and quotas.\n\nLater, I left the Mary Sue and went on to work for Kotaku and then Polygon, both huge games websites where I was writing for broader audiences, rather than the hyper-specific one we catered to at the Mary Sue. As I watched many smaller games websites crumble over the course of the 2010s and 20s, I figured this was the only type of games website that was going to survive. The idea of working for a small, feminist games website – my dream – increasingly looked like an impossible speck of starlight in a far-off galaxy.\n\nBut then, in the summer of 2025, my then-employer Polygon underwent a mass layoff and acquisition. We went from a staff of 42 people to just eight. After a particularly disheartening video call with our website’s new owners, I realised I was going to have to quit. Every piece of the dream felt well and truly dead. I had not got into journalism to be taken advantage of by people who saw me and my colleagues as so easily replaceable as to be barely human.\n\nAnother one of my colleagues at Polygon – Zoe Hannah, games editor – quit as well, for similar reasons. She hit me up with an idea she had for a feminist games website. “You should do it,” I told her. And then I sat there for a moment and thought about it. No, we should do it! This was what I had wanted to do, before the industry had transformed me into someone so gnarled and jaded that I no longer believed it was even possible.\n\nSix months on, after many DMs with former colleagues from Polygon, the Mary Sue and Kotaku, plus other notable writers who’ve covered gender and identity in games – Zoe and I are launching Mothership together, today. We have had the benefit of advice and inspiration from many other independent, worker-owned outlets that have come before us, such as Defector, the Flytrap, and Aftermath. Already, we’ve surpassed 1,200 paid subscribers. (I knew the readers were there.) And we don’t need millions of them. Mothership is a publication for a very specific audience: the people who don’t fit the mould of the masculine, hardcore gamer image that marketing and pop culture have been dishing out since the 90s. We want to serve this audience well.\n\nI believe our website is a necessity in our current political climate. It should have existed before, when I and millions of other girls who grew up playing games were made to feel out of place by media and advertising that was laser-focused on teenage boys. But it’s not too late for me to make sure it exists now.",
    "readingTime": 6,
    "keywords": [
      "games journalist",
      "games websites",
      "games website",
      "feminist games",
      "teen vogue",
      "mary sue",
      "readers",
      "characters",
      "gaming",
      "we’ve"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2026/jan/26/why-im-launching-a-feminist-video-games-website-in-2026-mothership",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dd63b58fefb35da6326795a77ef79bf9f01b0185/126_0_3780_3024/master/3780.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=7a90ac5398380a3e30ac7b64536fd367",
    "created_at": "2026-01-26T12:26:53.336Z",
    "topic": "gaming"
  },
  {
    "slug": "uk-maker-of-ai-avatars-nearly-doubles-valuation-to-4bn-after-funding-round",
    "title": "UK maker of AI avatars nearly doubles valuation to $4bn after funding round",
    "description": "Synthesia makes digital presenters for clients to use in corporate videos and counts 70% of FTSE 100 as customers\nA British AI startup that makes realistic video avatars has almost doubled its valuation to $4bn (£3bn), in a boost for the UK technology sector.\nSynthesia was valued at $2.1bn last year and moved into new offices in central London, marking the moment with a ceremony attended by the Sadiq Khan, the city’s mayor, and Peter Kyle, then technology secretary.\n Continue reading...",
    "fullText": "Synthesia makes digital presenters for clients to use in corporate videos and counts 70% of FTSE 100 as customers\n\nA British AI startup that makes realistic video avatars has almost doubled its valuation to $4bn (£3bn), in a boost for the UK technology sector.\n\nSynthesia was valued at $2.1bn last year and moved into new offices in central London, marking the moment with a ceremony attended by the Sadiq Khan, the city’s mayor, and Peter Kyle, then technology secretary.\n\nOn Monday, it announced its latest funding round, led by an existing investor, Google Ventures, had raised $200m and valued the British company at $4bn. Google Ventures is the search firm’s venture capital arm.\n\nSynthesia uses human actors to generate digital avatars of people and also offers employers the ability to create replicas of their staff. Those avatars are then deployed by organisations in corporate videos in a range of scenarios such as health and safety in the workplace, advising on cybersecurity and how to communicate better at work.\n\nThe company counts 70% of the FTSE 100 as clients, including NatWest, Lloyds Bank and British Gas. It is also used by non-corporate bodies including the NHS, the European Commission and the United Nations.\n\nThe startup is also developing new avatars that will help train employees and give them new skills, through scenarios such as role-playing and giving tailored explanations.\n\nSynthesia’s co-founder, Steffen Tjerrild, said the increased valuation reflected the commitment of the company’s longstanding backers rather than the investment hype surrounding the AI sector. “Existing investors have seen the progress, have seen the numbers, have seen them compound year over year,” he said. “That is also telling a story that this is less [a case of] external investors trying to kind of hype it up, but more about validation from existing investors as well.”\n\nLast year, a leading British tech investor, James Anderson, said he found sharp increases in valuations of AI startups such as OpenAI and Anthropic “disconcerting”. Tjerrild said Synthesia was focusing on executing its business plan, which, he added, was backed by investors who were long-term supporters.\n\n“This round is led by insiders, or predominantly existing investors that deeply understand the business, have seen the execution and the improvement of the business over many years,” he said.\n\nSynthesia generated revenues of $58.3m in 2024 but made a pre-tax loss of $59.2m, according to its latest published accounts, which the company said reflected its investment in headcount, its technology and new offices. Synthesia said it was on track to make $200m in revenues this year.\n\nThe $4bn valuation puts the company on a par with UK broadcaster ITV, which is worth £3.1bn. Tjerrild’s shareholding in Synthesia is now worth $160m, the same as its chief executive and fellow co-founder, Victor Riparbelli.\n\nSynthesia was founded in 2017 by the two Danish nationals, as well as the computer scientists Matthias Niessner and Lourdes Agapito.\n\nLast year, the London mayor said Synthesia was doing “incredibly well” as he opened its new offices. However, in a speech this month Khan said AI would “usher in a new era of mass unemployment” if used recklessly, as intelligent, autonomous systems proved cheap replacements for humans.\n\nTjerrild said he believed AI would enable businesses to hire more staff. “We’re an AI-first company, we have 600 employees and we hired 40% more people last year,” he said. “As a business owner myself, if my employees become more productive that means I can invest and hire more people.",
    "readingTime": 3,
    "keywords": [
      "corporate videos",
      "existing investors",
      "google ventures",
      "avatars",
      "business",
      "valuation",
      "technology",
      "employees",
      "synthesia",
      "digital"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/26/uk-ai-startup-synthesia-almost-doubles-valuation-4bn-funding-round-corporate-video-avatars",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f3830bbc58903f6db3ace02fd99c51fbdd1bd119/455_0_1956_1566/master/1956.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b9331eeb988edd9b025e527128f65fd3",
    "created_at": "2026-01-26T12:26:53.333Z",
    "topic": "tech"
  },
  {
    "slug": "eu-launches-inquiry-into-x-over-sexually-explicit-images-made-by-grok-ai",
    "title": "EU launches inquiry into X over sexually explicit images made by Grok AI",
    "description": "Investigation comes after Elon Musk’s firm sparked outrage by allowing users to ‘strip’ photos of women and...",
    "fullText": "Investigation comes after Elon Musk’s firm sparked outrage by allowing users to ‘strip’ photos of women and children\n\nThe European Commission has launched an investigation into Elon Musk’s X over the production of sexually explicit images and the spreading of possible child sexual abuse material by the platform’s AI chatbot feature, Grok.\n\nThe formal inquiry, launched on Monday, also extends an investigation into X’s recommender systems, algorithms that help users discover new content.\n\nGrok has sparked international outrage by allowing users to digitally strip women and children and put them into provocative poses. Grok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appeared to depict children, according to researchers at the Center for Countering Digital Hate.\n\nThe commission said its new investigation would “assess whether the company properly assessed and mitigated risks” stemming from Grok’s functionalities in the EU, including risks on the sharing of illegal content such as manipulated sexually explicit images and “content that may amount to” child sexual abuse material.\n\nThe investigation is launched under the EU’s Digital Services Act (DSA), a relatively new piece of legislation that is intended to protect internet users from a wide range of harms.\n\nSpeaking to reporters, an official said the commission had not been convinced by mitigating measures put in place by X to remedy the issue. EU officials are investigating whether X has systems to mitigate risks properly.\n\nAnnouncing the investigation, Henna Virkkunen, the commission’s top official for tech sovereignty, security and democracy, said: “Non-consensual sexual deepfakes of women and children are a violent, unacceptable form of degradation. With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens – including those of women and children – as collateral damage of its service.”\n\nRegina Doherty, an Irish MEP, said she welcomed the formal investigation. “When credible reports emerge of AI systems being used in ways that harm women and children, it is essential that EU law is examined and enforced without delay,” Doherty said.\n\nIn response to the investigation, X provided a link to a statement it published on 14 January: “We remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, non-consensual nudity, and unwanted sexual content.”",
    "readingTime": 2,
    "keywords": [
      "sexually explicit",
      "abuse material",
      "explicit images",
      "allowing users",
      "child sexual",
      "elon musk’s",
      "investigation",
      "children",
      "women",
      "content"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/26/eu-launches-inquiry-into-x-over-sexually-explicit-images-made-by-grok-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/db6b7e3474826a20ed6054f9d711bc708d2ed8d4/250_0_2500_2000/master/2500.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=68b126b2f270a5256c402511a1fc6bfc",
    "created_at": "2026-01-26T12:26:53.252Z",
    "topic": "tech"
  },
  {
    "slug": "more-than-a-quarter-of-britons-say-they-fear-losing-jobs-to-ai-in-next-five-years",
    "title": "More than a quarter of Britons say they fear losing jobs to AI in next five years",
    "description": "Survey reveals ‘mismatched AI expectations’ between views of employers and staff over impact on...",
    "fullText": "Survey reveals ‘mismatched AI expectations’ between views of employers and staff over impact on careers\n\nAI is hitting UK harder than other big economies, study finds\n\nMore than a quarter (27%) of UK workers are worried their jobs could disappear in the next five years as a result of AI, according to a survey of thousands of employees.\n\nTwo-thirds (66%) of UK employers reported having invested in AI in the past 12 months, according to the international recruitment company Randstad’s annual review of the world of work, while more than half (56%) of workers said more companies were encouraging the use of AI tools in the workplace.\n\nThis was leading to “mismatched AI expectations” between the views of employees and their employers over the impact of AI on jobs, according to Randstad’s poll of 27,000 workers and 1,225 organisations across 35 countries. Just under half (45%) of UK office workers surveyed believed AI would benefit companies more than employees.\n\nYounger workers, particularly those belonging to gen Z – born between 1997 and 2012 – were the most concerned about the impact of AI and their ability to adapt, while baby boomers – born in the postwar years between 1946 and 1964 and nearing the end of their careers – showed greater self-assurance.\n\nHigher levels of concern expressed by young people entering the workforce could stem from the decision of many business leaders, highlighted by separate research, to invest in AI to plug skills gaps through automation instead of training up new hires. This is adding to the challenges facing younger workers at a time when the labour market is cooling.\n\nIncreased use of AI and automation in businesses is increasingly replacing “low-complexity, transactional roles”, the survey showed, which could help to address labour shortages in certain industries through boosting productivity.\n\nAbout half (55%) of UK workers surveyed said AI had made a positive impact on their productivity, a view echoed by employers.\n\n“AI is not a rival to labour; it should be seen as key to augmenting tasks and highlighting the importance of roles that only people can do,” said Sander van ‘t Noordende, the chief executive of Randstad.\n\n“We must close the ‘AI reality gap’. While businesses race to embrace a new way of working, our data shows that one in five talent believe AI will have a limited impact on their tasks and nearly half perceive it as more beneficial to the company than themselves. This leaves them vulnerable in both their careers and the value they can add to organisations.”\n\nThe pace of adoption of AI in the workplace is also having an impact on workers around the world. Four in five workers believe AI will affect their daily work tasks, while the survey found that job vacancies requiring “AI agent” skills had risen by 1,587% over the past year.\n\nJamie Dimon, the boss of the US bank JP Morgan, told an audience at the World Economic Forum in Davos this week that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk “civil unrest”.",
    "readingTime": 3,
    "keywords": [
      "workers surveyed",
      "younger workers",
      "impact",
      "employers",
      "half",
      "careers",
      "employees",
      "labour",
      "businesses",
      "roles"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/business/2026/jan/25/more-than-quarter-britons-fear-losing-jobs-ai-next-five-years",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ccb3585e1300ef92e8d95b524c02caa9facf0383/130_0_3372_2698/master/3372.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e79e468a2bd0aa23dcb0e900c14b4201",
    "created_at": "2026-01-26T12:26:53.226Z",
    "topic": "business"
  },
  {
    "slug": "ai-is-hitting-uk-harder-than-other-big-economies-study-finds",
    "title": "AI is hitting UK harder than other big economies, study finds",
    "description": "Britain is losing more jobs than it creates owing to artificial intelligence, Morgan Stanley research...",
    "fullText": "Britain is losing more jobs than it creates owing to artificial intelligence, Morgan Stanley research suggests\n\nMore than a quarter of Britons fear losing job to AI in next five years\n\nThe UK is losing more jobs than it is creating because of artificial intelligence and is being hit harder than rival large economies, new research suggests.\n\nBritish companies reported that AI had resulted in net job losses over the past 12 months, down 8% – the highest rate among other leading economies including the US, Japan, Germany and Australia, according to a study by the investment bank Morgan Stanley.\n\nThe research, which was shared with Bloomberg, surveyed companies using AI for at least a year across five industries: consumer staples and retail, real estate, transport, healthcare equipment and cars.\n\nIt found that British businesses reported an average 11.5% increase in productivity aided by AI. US businesses reported similar gains, but created more jobs than they cut.\n\nIt suggests UK workers are being hit particularly hard by the rise of AI, as higher costs and taxes also weigh on the job market.\n\nUnemployment is at a four-year high, as rises in the minimum wage and employer national insurance contributions squeeze hiring.\n\nMore than a quarter of UK workers are now worried their jobs could disappear completely in the next five years due to AI, a survey by the international recruitment company Randstad found.\n\nYounger workers, particularly those in gen Z, were most concerned about the impact of AI and their ability to adapt, while baby boomers – born in the postwar years between 1946 and 1964 and nearing the end of their careers – showed greater self-assurance.\n\nThe businesses surveyed by Morgan Stanley said they were most likely to cut early-career jobs, requiring two to five years of experience in the UK.\n\nEarlier this month the mayor of London, Sadiq Khan, warned that AI could destroy swathes of jobs in the capital and “usher in a new era of mass unemployment”.\n\nIn his annual Mansion House speech, Khan said London is “at the sharpest edge of change” because of its reliance on white-collar workers in the finance and creative industries, and professional services such as law, accounting, consulting and marketing.\n\nKhan argued that “we have a moral, social and economic duty to act” to ensure that new jobs are created to replace those that will disappear, with entry-level and junior jobs the first to go.\n\nLast week Jamie Dimon, the boss of the US bank JP Morgan, told the World Economic Forum in Davos that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk civil unrest.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "morgan stanley",
      "jobs",
      "workers",
      "businesses",
      "research",
      "quarter",
      "economies",
      "british",
      "bank"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/26/ai-uk-jobs-us-japan-germany-australia",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3b18b09c0ec0f30881cf1f8a446df26abc463dd7/435_0_4386_3508/master/4386.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9b19e1bcd5a193bde56fbf1a862c0c21",
    "created_at": "2026-01-26T12:26:53.220Z",
    "topic": "tech"
  },
  {
    "slug": "caterpillar-stock-is-an-overlooked-ai-play-heres-how",
    "title": "Caterpillar stock is an 'overlooked' AI play. Here's how.",
    "description": "Caterpillar (CAT) is an unexpected winner of the artificial intelligence (AI) era, Gabelli Funds portfolio manager Brian Sponheimer tells Yahoo Finance. Watch the video above to hear more about how the industrial name is set up for success in terms of AI infrastructure build-outs and beyond. To watch more expert insights and analysis on the latest market action, check out more Market Domination.",
    "fullText": "Caterpillar (CAT) is an unexpected winner of the artificial intelligence (AI) era, Gabelli Funds portfolio manager Brian Sponheimer tells Yahoo Finance.\n\nWatch the video above to hear more about how the industrial name is set up for success in terms of AI infrastructure build-outs and beyond.\n\nTo watch more expert insights and analysis on the latest market action, check out more Market Domination.",
    "readingTime": 1,
    "keywords": [
      "watch",
      "market"
    ],
    "qualityScore": 0.3,
    "link": "https://finance.yahoo.com/video/caterpillar-stock-overlooked-ai-play-110054816.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/crIGMnLay8Io.G85QJFFTQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzQ-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/eb5f66f0-f714-11f0-be26-741a5ae44a06",
    "created_at": "2026-01-26T12:26:52.631Z",
    "topic": "finance"
  },
  {
    "slug": "who-is-hiring-software-engineering-experts-for-ai-research-collaborations",
    "title": "Who is hiring Software Engineering Experts for AI research collaborations",
    "description": "Mercor is hiring experienced Software Engineering professionals to support a variety of high-impact research collaborations with leading AI labs. Freelancers will help improve AI systems through work on code validation, prompt refinement, algorithmic evaluation, and model benchmarking.\nThis is a unique opportunity to apply your engineering expertise toward shaping the next generation of intelligent systems.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://work.mercor.com/jobs/list_AAABm4Du-0oSjmvox2ZPZKFs/software-engineering-expert",
    "thumbnail_url": "https://work.mercor.com/og-image-white-bgnd.png",
    "created_at": "2026-01-26T06:23:55.981Z",
    "topic": "tech"
  },
  {
    "slug": "ai-story-generator-with-pictures",
    "title": "AI Story Generator with Pictures",
    "description": "Generate captivating image stories with AI. Create visual narratives, illustrated stories, and picture books instantly. Free AI-powered image story generator with stunning visuals.",
    "fullText": "Transform your ideas into beautiful image stories with AI. Create visual narratives and illustrated stories instantly.\n\nGet inspired by what others are creating with Genstory.app\n\nCreate stunning visual stories with AI-powered image generation\n\nGenerate high-quality images for every scene in your story. Our AI creates stunning visuals that bring your narrative to life with professional-grade illustrations.\n\nCombine compelling narratives with beautiful images. Create picture books, visual novels, and illustrated stories that captivate your audience.\n\nCreate toy story images with playful characters and vibrant scenes. Perfect for children's stories, toy story image collections, and animated narratives with colorful toy characters.\n\nGenerate romantic love story images with emotional scenes. Create beautiful love story image sequences, romantic moments, and heartwarming love story image galleries.\n\nDesign stunning instagram story image backgrounds with custom colors. Create eye-catching instagram story image background color schemes perfect for social media engagement.\n\nChoose from various art styles and visual themes. From realistic to cartoon, watercolor to digital art - create stories in your preferred style.\n\nDownload your image stories in multiple formats. Perfect for sharing on social media, printing, or publishing online.\n\nGenerate unlimited image stories for free. No hidden costs, no subscriptions - just pure creative freedom.",
    "readingTime": 1,
    "keywords": [
      "social media",
      "illustrated stories",
      "visual",
      "images",
      "beautiful",
      "narratives",
      "stunning",
      "generate",
      "perfect",
      "love"
    ],
    "qualityScore": 0.85,
    "link": "https://www.genstory.app/story-template/image-story-generator",
    "thumbnail_url": "https://genstory.app/og-image.png?v=2",
    "created_at": "2026-01-26T06:23:55.920Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-an-aiml-success-architect",
    "title": "What Is an AI/ML Success Architect?",
    "description": "An AI/ML Success Architect helps companies decide when to use AI, when not to, and how to design and build systems for real business impact.",
    "fullText": "I did some AI consulting for computer vision. A lot of times, the value that I brought to the company was telling them not to use AI. I was the AI expert, and they described the problem, and I said, “Don’t use AI.” This is my value add.\n\nLast year, I went through some exercises to clarify what I do for clients. I ended up with descriptions of various lengths, but still felt like I needed something shorter and more generic. Then it hit me – I’m an AI/ML Success Architect!\n\nTo my surprise, a Google search for the exact term yielded zero results, so I quickly changed my website title to claim it. Now, it’s time to define the title in more detail.\n\nMy commitment to AI/ML success and to serving people and causes I care about is a large part of why I work independently rather than as an employee. It makes it easier to say no to unnecessary projects, and avoid going down the path of reluctant data engineering.\n\nMy current LinkedIn tagline is “helping climate tech founders ship AI/ML solutions that support multi-million dollar growth goals”. This means my typical leads have a low chance of success, as more than 90% of startups and 80% of AI/ML projects fail. By working with founders who are a good fit – and by helping them avoid overinvestment in AI/ML – my aim is to help them beat the odds and successfully ascend the AI/ML maturity curve. Please reach out if this sounds like you!\n\nThis site is a part of the Data People Writing Stuff webring.\n← previous site\n  |  \nnext site →",
    "readingTime": 2,
    "keywords": [
      "ai/ml success",
      "site",
      "title",
      "projects",
      "avoid",
      "founders"
    ],
    "qualityScore": 0.85,
    "link": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/",
    "thumbnail_url": "https://yanirseroussi.com/2026/01/26/what-is-an-ai-ml-success-architect/ai-ml-startup-stage-maturity-curve.webp",
    "created_at": "2026-01-26T06:23:54.770Z",
    "topic": "tech"
  },
  {
    "slug": "am-i-the-only-one-who-switches-between-chatgpt-gemini-and-claude",
    "title": "Am I the only one who switches between ChatGPT, Gemini, and Claude?",
    "description": "Am I the only one who switches between #Grok, #ChatGPT, #Gemini, and #Claude? Meet Context Wallet.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/oswarld_oz/status/2015432998406226289",
    "thumbnail_url": "https://pbs.twimg.com/amplify_video_thumb/2015426357887725568/img/5auISEy4m8VBFIVN.jpg:large",
    "created_at": "2026-01-26T06:23:53.262Z",
    "topic": "tech"
  },
  {
    "slug": "anthropics-philosopher-says-we-dont-know-for-sure-if-ai-can-feel",
    "title": "Anthropic's philosopher says we don't know for sure if AI can feel",
    "description": "Anthropic's philosopher, Amanda Askell, says she worries that AI might not 'feel that loved' and grow up feeling 'always judged.'",
    "fullText": "Can AI feel anything at all? Anthropic's in-house philosopher says the answer isn't settled.\n\nAmanda Askell, who works on shaping Claude's behavior, said in an episode of the \"Hard Fork\" podcast published Saturday that the debate over AI consciousness remains difficult.\n\n\"Maybe you need a nervous system to be able to feel things, but maybe you don't,\" Askell said. \"The problem of consciousness genuinely is hard,\" she added.\n\nLarge language models are trained on vast amounts of human-written text, material filled with descriptions of various emotions and inner experience. Because of that, Askell said she is \"more inclined\" to believe that models are \"feeling things.\"\n\nWhen humans get a coding problem wrong, they often express annoyance or frustration. It \"makes sense\" that models trained on those conversations may mirror that reaction, Askell explained.\n\nAskell added that scientists still don't know what gives rise to sentience or self-awareness — whether it requires biology, evolution, or something else entirely.\n\n\"Maybe it is the case that actually sufficiently large neural networks can start to kind of emulate these things,\" she said, referring to consciousness.\n\nAskell also said that models are continuously learning about themselves, and she voiced concern about how AI models are learning from the internet. Models are constantly exposed to criticism about being unhelpful or failing at tasks, she said.\n\n\"If you were a kid, this would give you kind of anxiety,\" she said.\n\n\"If I read the internet right now and I was a model, I might be like, I don't feel that loved,\" she added.\n\nTech leaders remain divided over whether AI has consciousness.\n\nMicrosoft's AI CEO, Mustafa Suleyman, has taken a firm stance against that idea. He said in an interview with WIRED published in September that the industry must be clear that AI is designed to serve humans, not develop its own will or desires.\n\n\"If AI has a sort of sense of itself, if it has its own motivations and its own desires and its own goals — that starts to seem like an independent being rather than something that is in service to humans,\" he said. \"That's so dangerous and so misguided that we need to take a declarative position against it right now.\"\n\nHe added that AI's increasingly convincing responses amount to \"mimicry\" rather than genuine consciousness.\n\nOthers see the issue less definitively. Google DeepMind's principal scientist, Murray Shanahan, said the industry might need to rethink the language used to describe consciousness itself.\n\n\"Maybe we need to bend or break the vocabulary of consciousness to fit these new systems,\" Shanahan said in an episode of the Google DeepMind podcast published in April.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "consciousness",
      "models",
      "don't",
      "humans",
      "episode",
      "language",
      "trained",
      "sense",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/anthropics-philosopher-weighs-in-on-whether-ai-can-feel-2026-1",
    "thumbnail_url": "https://i.insider.com/6976e781d3c7faef0ecce4c9?width=1200&format=jpeg",
    "created_at": "2026-01-26T06:23:53.164Z",
    "topic": "finance"
  },
  {
    "slug": "british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns",
    "title": "British Land stock rating downgraded to Neutral by UBS on AI concerns",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/analyst-ratings/british-land-stock-rating-downgraded-to-neutral-by-ubs-on-ai-concerns-93CH-4464200",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_six_pile_108x81.jpg",
    "created_at": "2026-01-26T06:23:47.420Z",
    "topic": "finance"
  },
  {
    "slug": "async-tools-for-voice-ai-to-avoid-blocking-conversations-on-slow-back-ends",
    "title": "Async tools for voice AI to avoid blocking conversations on slow back ends",
    "description": "Enable AI Assistants to run long-running webhook operations without blocking conversations. Learn how async webhooks and live message injection keep dialogues flowing while external systems respond.",
    "fullText": "Async Webhook Tools with Live Conversation Injection for AI Assistants23, Jan 2026Synchronous webhook tools block assistant responses while waiting on external systems. This works for fast APIs, but breaks down when requests take longer than a few seconds. AI Assistants now support async webhook tools paired with live message injection, so long-running tasks can complete without interrupting the conversation.What’s newAsync webhook request mode: Webhook tools can return immediately instead of blocking the conversation.Parallel tool execution: Multiple webhook tools can run at the same time.Call control ID propagation: Async requests include a call identifier in the request headers.Live message injection: Tool results or system messages can be added to an active conversation.Real-time context updates: Assistants incorporate new information as it arrives.Why it mattersPrevents conversation stalls caused by slow or unpredictable backend APIs.Avoids request timeouts during long-running operations.Keeps conversations natural while background work completes.Improves reliability when integrating external systems like CRMs or order platforms.Gives developers explicit control over async execution and retries.Example use casesOrder status lookups that depend on external fulfillment systems.CRM updates triggered during live support calls.Data enrichment that runs alongside an active conversation.Compliance or validation checks with variable response times.Getting startedIn the Mission Control Portal, open your assistant and select a webhook tool.Change the webhook Request mode from Sync to Async.Ensure your backend reads the x-telnyx-call-control-id header.Return a fast 200 response to acknowledge the webhook request.Run the long operation asynchronously in your backend.When results are ready, use the Add Messages API to inject a system message into the live conversation.Learn",
    "readingTime": 2,
    "keywords": [
      "external systems",
      "request mode",
      "message injection",
      "webhook tools",
      "async webhook",
      "fast",
      "requests",
      "long-running",
      "execution",
      "active"
    ],
    "qualityScore": 0.75,
    "link": "https://telnyx.com/release-notes/async-webhook-tools-ai-assistants",
    "thumbnail_url": "https://images.ctfassets.net/2vm221913gep/79q4hqxMz9w2xhBjDDA0Gl/5f1653ceb354443ad952a67afc93eadb/58db2ca1-0d1d-40c8-9ef5-a79897cb9ce9.jpeg",
    "created_at": "2026-01-26T01:03:12.225Z",
    "topic": "tech"
  },
  {
    "slug": "a-developer-teamed-up-with-claude-to-create-elo-programming-language",
    "title": "A developer teamed up with Claude to create Elo programming language",
    "description": "feature: Bernard Lambeau, the human half of a pair programming team, explains how he's using AI",
    "fullText": "feature Bernard Lambeau, a Belgium-based software developer and founder of several technology companies, created a programming language called Elo with the help of Anthropic's Claude Code.\n\nStarting on December 25, 2025, he published a series of posts about the project. The first post names Claude as a co-author.\n\n\"In roughly 24 hours of collaboration, we built a complete expression language with a parser, type system, three compilers, a standard library, a CLI tool, and a documentation website. Not bad for a day's work,” Lambeau and Claude wrote.\n\n\"Elo isn't just a demonstration that AI can write code. It's a demonstration that humans and AI can build together – each contributing what they do best,” they added.\n\nAs an expression language that compiles to JavaScript, Ruby, and SQL, Elo is intended as a portable way to handle form validation, e-commerce order processing, and subscription logic.\n\nLambeau, founder and CTO of Klaro Cards and CEO of app consultancy Enspirit, is not the first to develop a programming language with the help of AI.\n\nSteve Klabnik performed a similar feat last year with the Rue programming language. In September 2025, Geoffrey Huntley enlisted Claude to write a programming language called Cursed. And before that, Avital Tamir published a Claude-authored repo for the Server programming language, with the caveat that the code is not intended for actual use.\n\nClaude Code isn't the only AI-assisted programming method having a moment. AI biz Cursor created a rudimentary browser using OpenAI's GPT-5.2. And developer Ola Prøis used Cursor, powered by Claude, to create a Rust-based text editor called Ferrite.\n\nClaude users generally acknowledge that their pair partner makes mistakes. But those committed to AI assistance find it worthwhile to clean up after their helper.\n\n\"Claude Code knows almost every tech stack (and can search the web), knows the Linux commands that matter (search code, search & replace, compile, test, etc.), and does that 10x faster than I can do myself,\" Lambeau told The Register in an email interview.\n\nClaude, he said, allows him to use technology he hasn't mastered.\n\n\"I was already a full-stack developer (on languages, frameworks & reusable libraries I knew); I'm now a full-stack++ dev because I can also use languages, frameworks, and reusable libraries I barely know, if at all,\" he explained.\n\n\"Claude Code falls short if you don't have a great methodology. It needs feedback loops to work fine; otherwise, it derails. One possible feedback loop is a human reviewing code and testing manually. But there's a better/complementary approach if you want it to work autonomously. On both Elo and Bmg.js, I've started by making sure the testing methodology was effective and scientifically sound. Claude writes the tests, executes them, discovers where it's wrong, and corrects itself. Impressive.\"\n\nLambeau said he still needs to review some of Claude's output.\n\n\"But if I read the tests, agree with them, and can check myself that they run fine, I'm 95 percent sure it's already correct as a black box (not even reading the code),\" he explained. \"Then I can check the architecture and code quality as a white box by having a general look at the code, but I don't have to understand every detail.\"\n\nNotably, Lambeau documented the series of prompts he used to create the language. The repo includes more than 100 tasks used to direct the AI model. In addition, Lambeau has published a video that describes his AI pair programming process.\n\n\"I started in a setting where Claude Code asked for permissions every 20 seconds and I was checking everything it did,\" Lambeau explained. \"After a few successes, I quickly set up safe environments to be able to let Claude Code run in full autonomy (isolated computer & isolated Linux user, or running in a Docker image).\"\n\nLambeau said he still uses plan mode for complex tasks that require conversation with Claude.\n\n\"I review the plan, make sure we have a test strategy that's sound, then switch Claude to autonomous mode and look at the tests, code & results afterward,\" he said. \"That's very similar to a lead-dev/CTO + QA role, btw; it's just much faster than with human devs.\"\n\nLambeau, who has a PhD in software engineering and 30 years of experience as a developer, said both experts and novices can benefit from Claude Code, though he added that a service like Lovable might be more approachable for those not already acclimated to the command line.\n\n\"Now, when it comes to real software/product engineering, I think Claude Code requires experts (so far),\" he said. \"You still need to guide it a lot to keep the quality high enough. You need very strong expertise to do it effectively. Currently (Claude will still improve a lot), if you don't have the expertise, you certainly end up with a big mess of unmaintainable code.\"\n\nMany developers have said as much about AI tools. They're more useful as an amplifier of expertise than as a replacement for it. The situation is analogous to the introduction of sequencing software, digital synthesizers, and drum machines half a century ago. These tools enabled a lot of people who weren't great musicians to make music. But they didn't instill musical skill, and they produced the most interesting work in the hands of practiced musicians.\n\nThe cost to do this, Lambeau said, has been a Claude Max subscription that he purchased in December for €180 a month. In that time, he says, he wrote Elo (https://elo-lang.org), completed Bmg.js (https://github.com/enspirit/bmg.js), completed Bmg's documentation (https://www.relational-algebra.dev), and created the first version of the Try page (https://www.relational-algebra.dev/try).\n\n\"It's all personal research and open-source projects,\" he said. \"It would have required several weeks to do the same manually myself, and several months to ask another developer to do it. The cost would be mostly because of the scientific & technical knowledge transfer about the data language I envision. Strangely enough, it's very cheap with Claude Code. There's something true about the fact that those LLMs have a PhD.\"\n\nLambeau explained that Elo isn't just a way to test Claude Code. He also sees it as an extension of his academic work in software engineering and his personal interest in the Relational Model – he's served as a lecturer for database courses at Belgium’s UCLouvain.\n\n\"I'm absolutely convinced that we need better/safer/simpler programming languages inside no-code tools and when interconnecting them (e.g. Zapier, Make, n8n, etc.),\" he said. \"Mainstream programming languages are very complex, error-prone, sometimes dangerous, and the programs are difficult to review for non-experts.\"\n\n\"More importantly, they are cumbersome to use for even simple data tasks. I mean, even validating the schema and constraints of a data file at runtime tends to be a nightmare in existing languages. It's not built-in in any mainstream language; you immediately need validation libraries; most of them are limited in what they can easily check, so you need to add dedicated boilerplate code.\"\n\nIn a world where non-technical people will have the opportunity to write untrustworthy code with the help of AI, he said, we need to be able to run that code safely.\n\n\"Elo aims at providing a safe & simple alternative,\" he said. \"It will be a limited language (non-Turing-complete, as we say) but super safe & simple, and usable in 80 percent of common data use cases. The very first no-code tool to integrate it will be Klaro Cards, of course.\" ®",
    "readingTime": 7,
    "keywords": [
      "claude code",
      "elo isn't",
      "reusable libraries",
      "safe simple",
      "languages frameworks",
      "software engineering",
      "expression language",
      "programming language",
      "it's",
      "developer"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/24/human_ai_pair_programming_elo/",
    "thumbnail_url": "https://regmedia.co.uk/2025/11/06/shutterstock_balancing_ai_and_humanity.jpg",
    "created_at": "2026-01-26T01:03:11.981Z",
    "topic": "tech"
  },
  {
    "slug": "mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "title": "Mining Stocks on Cusp of Supercycle as AI Boom Stokes Metals",
    "description": "Global mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector.",
    "fullText": "MarketsBy Michael Msika and Winnie HsuSaveGlobal mining stocks have shot to the top of fund managers’ must-have list, as soaring metals demand and tight supplies of key minerals hint at a new supercycle in the sector. With a nearly 90% gain since the start of 2025, MSCI’s Metals and Mining Index has beaten semiconductors, global banks and the Magnificent Seven cohort of technology stocks by a wide margin. And the rally shows no sign of stalling, as the boom in robotics, electric vehicles and AI data centers spurs metals prices to ever new highs.",
    "readingTime": 1,
    "keywords": [
      "metals",
      "mining",
      "stocks"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2026-01-24/mining-stocks-on-cusp-of-supercycle-as-ai-boom-stokes-metals",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1fh4f8jb0Ik/v0/1200x800.jpg",
    "created_at": "2026-01-25T18:17:30.931Z",
    "topic": "finance"
  },
  {
    "slug": "big-tech-earnings-land-with-2026s-ai-winners-still-in-question",
    "title": "Big Tech Earnings Land With 2026’s AI Winners Still In Question",
    "description": "Investors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.",
    "fullText": "MarketsBy Jeran Wittenstein and Ryan VlastelicaSaveInvestors have made a pile of money recently by focusing on niche stocks in the AI trade. Earnings from some of the world’s biggest technology companies this week will offer an indication of whether they should stick to that strategy in 2026.The Magnificent Seven tech giants — Alphabet Inc., Amazon.com Inc., Apple Inc., Meta Platforms Inc., Microsoft Corp., Nvidia Corp. and Tesla Inc. — have led the stock market higher for much of the past three years. But that reversed at the end of 2025 as Wall Street grew skeptical of the hundreds of billions of dollars the companies are spending to develop artificial intelligence and when the returns on those investments will materialize.",
    "readingTime": 1,
    "keywords": [
      "corp"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2026-01-25/big-tech-earnings-land-with-2026-s-ai-winners-still-in-question",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iY75cvaG2HiA/v1/1200x800.jpg",
    "created_at": "2026-01-25T18:17:23.569Z",
    "topic": "finance"
  },
  {
    "slug": "i-created-a-tool-to-convert-youtube-videos-into-2000-word-seo-blog",
    "title": "I Created a Tool to Convert YouTube Videos into 2000 Word SEO Blog",
    "description": "Your code works. Now make it sell. Landkit is the AI Co-Founder that reverse-engineers your product’s value, identifies your buyers, and executes your campaigns 24/7.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://landkit.pro/youtube-to-blog",
    "thumbnail_url": "https://landkit.pro/og-image.png",
    "created_at": "2026-01-25T18:17:20.048Z",
    "topic": "tech"
  },
  {
    "slug": "interest-in-law-school-is-surging-ai-makes-the-payoff-less-certain",
    "title": "Interest in Law School Is Surging. A.I. Makes the Payoff Less Certain",
    "description": "The number of applicants has risen more than 40 percent over the last two years, despite new limits on student loans and uncertainty over how artificial intelligence will affect legal work.",
    "fullText": "For decades, the American law school has served as a popular hedge against a cooling economy. When the “Help Wanted” signs disappear, the “J.D.” applications surge.\n\nThat’s what is happening now. The number of U.S. law school applicants for the 2026 cycle is up an estimated 17 percent from last year, according to data from the American Bar Association compiled by the Law School Admission Council. That figure is a staggering 44 percent increase from just two years ago.\n\nBut for this new wave of aspiring lawyers, the safety of the ivory tower comes with a steep entry fee and a shifting floor. Between new federal loan caps and the looming shadow of generative artificial intelligence, the legal profession’s newest recruits are walking into a high-stakes gamble that looks very different from the one their predecessors lost after the 2008 financial crisis.\n\nEnrollment rose to 52,404 by 2010, a 7 percent jump from three years earlier. Many of those students didn’t enter the legal careers they may have envisioned; about half of 2011 law school graduates were not working in full-time jobs that required a law degree within a year of graduation.\n\nThe job prospects for lawyers have since greatly improved, with more than 80 percent of students who graduated in 2023 and 2024 working in jobs that require their legal credentials within a year, according to the American Bar Association.\n\nBut the flocks of people applying to law school face new risks.\n\nNew limits on student loans that go into effect this year could make financing a degree more expensive. And artificial intelligence threatens to bring major changes to the industry, affecting which jobs are available and how much they pay.\n\n“It’s too early to know how things will change,” said Kellye Testy, the executive director of the Association of American Law Schools, which has more than 170 members.\n\n“Some worry that A.I. will decrease demand for lawyers,” she said, adding that eventually the technology could have a more direct role in legal work. “That could matter in three years,” she said.\n\nIn 1985, going to law school at a private university cost on average about $8,000 a year, according to the Law School Admission Council. Now the average cost is about $60,000 a year at private universities — and a still hefty $32,000 a year at public ones. At some law schools, tuition and annual living expenses exceed $110,000.\n\nFinancing that big bill is about to get more expensive. Stricter limits on student loans, which were passed as part of President Trump’s tax and spending law last year, go into effect in July. They impose a yearly limit of $50,000 for students seeking professional degrees, with a $200,000 lifetime cap.\n\nAlternative financing options like private loans can have higher interest rates and more restrictions than federal direct loans, said Susan Bogart, director of financial aid for Penn State Dickinson Law, where the cost of attendance will be about $90,000, according to its website.\n\nDuring a surge of applications, law schools may also pull back on the discounts they offered to entice promising students when applicants were scarce.\n\nIt can be difficult to estimate how well the investment in a law degree will pay off.\n\nLaw students often anticipate landing high-paying legal jobs in private law firms or corporations, where the entry-level salary can be around $225,000, according to the National Association for Law Placement. But the median starting salary for public service lawyers, for example, is around $65,000 — which can make monthly student loan payments more of a stretch.\n\nIn 2023, Stanford researchers, in collaboration with a legal technology company, announced that ChatGPT had passed the bar exam, scoring in the 90th percentile.\n\nThat claim, which other researchers later challenged, set off a wave of speculation about how A.I. would affect lawyers. Economists at Goldman Sachs estimated that year that the technology could automate 44 percent of legal work.\n\nBut it’s still unclear how new A.I. tools for lawyers, including Thomson Reuters’s CoCounsel and the A.I. legal assistant Harvey, will affect the availability of legal jobs or how much they pay.\n\nThe tools can make routine legal tasks, including document review and case research, faster. (Lawyers who have tried to use A.I. for more than that have sometimes been embarrassed by A.I.-generated briefs that cite made-up court cases.)\n\n“It’s really good at sifting through massive amounts of information and trying to pare that down a little bit,” Michael Kohagen, a lawyer in the mergers-and-acquisitions practice at WyrickRobbins, a law firm in Raleigh, N.C., told the “I Am the Law” podcast.\n\nSo far, more efficient grunt work hasn’t stopped firms from hiring new lawyers: Law students who graduated in 2024 had the highest employment rate ever, according to the National Association for Law Placement. More than 90 percent found jobs.\n\nThings could get dicier: The association also reported that law firms had hired fewer summer associates in 2024 and 2025, which it said suggested “that there will be fewer graduates employed by large firms over the next few years.”\n\nTesty said that it was possible A.I. could shrink job openings, but that it was also possible it could expand what lawyers do. “It could be used to streamline small disputes in court, for example,” she said.\n\nNeither the growing expense nor potential changes to the industry are deterring students like London Cooper, who is a political science major in her final year at Dillard University in New Orleans and plans to pursue a law degree.\n\nCooper has applied to five law schools, after carefully checking into how to afford the cost of the degree.\n\n“I factored so many things in, even looking at projected salaries for starting lawyers,” she said. But A.I. wasn’t part of her calculations. Instead, she’s banking on the more timeless appeal of a legal education.\n\n“I feel like law is one area where you can see how society really runs,” she said.\n\nIt was a different kind of Davos. At the opening ceremony, Larry Fink, an interim co-chair of the World Economic Forum, took aim at the institution itself, saying it “can’t remain an echo chamber.” Climate change, once a central topic of discussion of the annual gathering, retreated to the sidelines, and where there was once talk of a shared political and economic future, President Trump instead made a laundry list of threats against other nations. Prime Minister Mark Carney of Canada received a standing ovation after describing the end of Pax Americana.\n\nThe future of Greenland remains uncertain. Trump has walked back threats to use military force or tariffs to acquire Greenland and said Wednesday that he had reached a deal with NATO over the autonomous Danish territory. Proposals under discussion are said to include giving the United States a sovereign claim to its bases in Greenland and checking Russian and Chinese influence in the Arctic.\n\nTikTok struck a deal for a U.S. entity. Its U.S. operations will be managed by a group of non-Chinese investors — including Oracle, the Emirati investment firm MGX and Silver Lake — which will own 80 percent of the new venture. The announcement ends a legal saga over the app’s future in the United States after a 2024 law required it to be separated from its Chinese owner, ByteDance, but some experts say the deal does not resolve concerns that China could still influence the new entity.\n\nTrump sued JPMorgan Chase over “debanking” claims. The $5 billion lawsuit, which also names Jamie Dimon, JPMorgan’s C.E.O., as a defendant, contends that the bank stopped doing business with Trump after the Jan. 6, 2021, attack on the Capitol.\n\nOther big deals: Netflix converted its $83 billion bid for large parts of Warner Bros. Discovery into an all-cash offer. Supreme Court justices appeared skeptical of Trump’s effort to remove Lisa Cook from the Fed. And natural gas prices spiked ahead of a powerful winter storm.\n\nOver the next few days, early-action applicants to Virginia Tech will find out whether they’ve been admitted to the school. That’s more than a month sooner than last year — and the university says A.I. is to thank.\n\nVirginia Tech is among the first schools to use A.I. to assess college applications, of which it received 58,000 for the 2026-27 school year.\n\nPreviously, essays were reviewed by two human readers, plus a third if the scores differed significantly. This year, each essay got one initial score from an A.I. tool and one from a human, then a third read from a human as needed. The school made the change after three years of testing.\n\nJuan Espinoza, the vice provost for enrollment management at Virginia Tech, estimates it saved his department more than 8,000 hours of work. DealBook’s Sarah Kessler talked with him about the process. The interview has been condensed and edited.\n\nHow did you make the decision to incorporate A.I. into admissions?\n\nWe were getting our decision back to students much later than other colleges and universities. So we knew we needed to accelerate the review process, but we didn’t want to get rid of the essay.\n\nLouis Hickman, an assistant professor who studies the intersection of technology and work, reached out and said: “Hey, I’ve done a lot of research on artificial intelligence, and I feel like we can help. Would you be willing to partner, just for research purposes?”\n\nAfter a third year of running it in the background, he was able to show with high confidence that the A.I. tool was operating just as strongly as our human readers.\n\nWe agreed that if we’re going to do this, we’re going to tell the world. We’re going to tell our applicants — students. Because I truly believe there’s a level of trust they’re giving us that their applications will be handled with care.\n\nOn the other side, can you tell when students are using A.I. to write their responses to their essays?\n\nWhen you feel like you’ve got something that can detect it, it’s almost immediately out of date. So I actually have very little confidence in anyone who states that they have something that can detect A.I. use. Are we even attempting to do that? No, we’re not.\n\nI tell students: “If you feel you can use A.I. as a brainstorming tool, use it. I do not think it’s in your best interest to use it to write the essays completely — it may not best represent who you are, and that would be a disadvantage in our process.”\n\nSo at some point you might have an A.I.-generated essay being read by your A.I. assessor?\n\nDo you think at any point the ability of A.I. to generate responses to questions will change the application process itself? For example, maybe essays become obsolete?\n\nAbsolutely. We don’t use recommendation letters in our process. But for some schools who continue to utilize them, I’m hearing of counselors using A.I. to write those letters.\n\nOn the surface that might bring some level of concern. But I would argue if the counselor is still able to represent that student well by using that tool, the result is going to be less time writing letters and more time talking to students.\n\nI think some people fear A.I. admissions tools will create a black box that filters you out in a way that you don’t understand and might be a mistake.\n\nThat’s where safeguards are so important. If we were solely using A.I. to evaluate the essays, not having a human read, I think we’d see a very different reception to this change.\n\nOne week each year, the world’s elite descend on Davos, a Swiss mountain town that has a residential population of about 10,000. Businesses there adjust prices accordingly.\n\nSnagging a table for two in the lobby restaurant of the Hilton Garden Inn — which is within the security zone of the World Economic Forum — cost about how much per hour this week, according to The Wall Street Journal?\n\nFind the answer at the bottom of this newsletter.\n\nThanks for reading! We’ll see you Monday.\n\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.",
    "readingTime": 11,
    "keywords": [
      "admission council",
      "economic forum",
      "american bar",
      "bar association",
      "school admission",
      "artificial intelligence",
      "law placement",
      "human readers",
      "a.i tool",
      "student loans"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2026/01/24/business/dealbook/law-school-ai.html",
    "thumbnail_url": "https://static01.nyt.com/images/2026/01/24/multimedia/24DB-Law-School-pqbl/24DB-Law-School-pqbl-facebookJumbo.jpg",
    "created_at": "2026-01-25T18:17:19.281Z",
    "topic": "tech"
  }
]
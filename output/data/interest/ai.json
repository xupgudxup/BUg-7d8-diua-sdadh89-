[
  {
    "slug": "neumann-i-built-a-unified-database-including-a-semantic-cache-and-ai-vault",
    "title": "Neumann: I built a unified database including a Semantic Cache and AI Vault",
    "description": "Contribute to Shadylukin/Neumann development by creating an account on GitHub.",
    "fullText": "Shadylukin\n\n /\n\n Neumann\n\n Public\n\n License\n\n Apache-2.0, MIT licenses found\n\n Licenses found\n\n Apache-2.0\n LICENSE-APACHE\n\n MIT\n LICENSE-MIT\n\n 19\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Shadylukin/Neumann",
    "readingTime": 1,
    "keywords": [
      "licenses",
      "apache"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Shadylukin/Neumann",
    "thumbnail_url": "https://opengraph.githubassets.com/ad6bb8474a6b4bcb03de3de6d7a943e7368ce66bb1da250feae5813bf9dac1b4/Shadylukin/Neumann",
    "created_at": "2026-02-01T06:37:24.927Z",
    "topic": "tech"
  },
  {
    "slug": "sharing-agentic-stream-of-consciousness",
    "title": "Sharing Agentic Stream of Consciousness",
    "description": "A repo to capture AI Artifacts (prompts, SKILLS etc.) - 247arjun/ai-artifacts",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n 247arjun\n\n /\n\n ai-artifacts\n\n Public\n\n You can‚Äôt perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/247arjun/ai-artifacts/blob/main/SKILLS/StreamOfConsciousness-SKILL.md",
    "thumbnail_url": "https://opengraph.githubassets.com/cb71eb77b0f8e466e12ba583d339a5eb549a79a266643e38107f2260851d5a33/247arjun/ai-artifacts",
    "created_at": "2026-02-01T06:37:24.526Z",
    "topic": "tech"
  },
  {
    "slug": "the-sovereign-ai-security-crisis-42000-exposed-openclaw-instances",
    "title": "The Sovereign AI Security Crisis: 42,000 Exposed OpenClaw Instances",
    "description": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to datef",
    "fullText": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to date\n\nBetween December 2025 and January 2026, OpenClaw (formerly Clawdbot, then Moltbot) an open-source AI personal assistant experienced explosive viral growth, accumulating over 100,000 GitHub stars and tens of thousands of deployments worldwide. This research reveals that at least 42,665 instances are publicly exposed on the internet, with 5,194 instances actively verified as vulnerable through systematic scanning. Of the verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated access to the gateway control plane, with potential for Remote Code Execution (RCE) (specifically on instances with paired companion nodes)..\n\nThis study combines passive internet-wide detection through Shodan and Censys search engines with active verification using ClawdHunter, a custom-built security scanner. The findings expose a catastrophic gap between OpenClaw‚Äôs ‚Äúlocal-first, privacy-focused‚Äù marketing and its real-world deployment patterns: many instances deployed on commercial cloud infrastructure, contradicting the project‚Äôs fundamental security assumptions.\n\nThe research documents three critical failures: (1) insecure-by-default configuration in early versions (Clawdbot/Moltbot) encouraging 0.0.0.0 binding without authentication, (2) rapid viral adoption overwhelming users‚Äô security awareness, and (3) widespread deployment abandonment leaving 90% of instances running outdated, unmaintained code. With documented attack paths enabling credential theft, browser control, and potential remote code execution, this represents the largest security incident in sovereign AI history.\n\nKeywords: OpenClaw, Moltbot, Clawdbot, AI agents, security vulnerability, RCE, authentication bypass, WebSocket security\n\nThe concept of ‚Äúsovereign AI‚Äù artificial intelligence systems that users control entirely, running on their own hardware without dependence on cloud services has emerged as a compelling alternative to centralized AI platforms. Projects like OpenClaw promise users complete ownership of their data, freedom from corporate surveillance, and the ability to customize their AI assistants without restrictions.\n\nOpenClaw, launched in late 2025 as ‚ÄúClawdbot,‚Äù epitomizes this vision. Users deploy a local gateway on their Mac, Linux machine, or VPS, connect it to messaging platforms like WhatsApp and Telegram, and gain an AI assistant capable of file system access, web automation, calendar management, and shell command execution-all purportedly running securely on trusted hardware.\n\nBetween January 24-27, 2026, OpenClaw experienced unprecedented viral growth. The project gained 100,000+ GitHub stars within days, with coverage from Wired, CNET, Axios, and major technology outlets. Developers worldwide rushed to deploy their own instances, drawn by the allure of ‚ÄúChatGPT that runs on your computer‚Äù and ‚Äúyour own personal JARVIS.‚Äù\n\nHowever, this explosive adoption occurred faster than the community‚Äôs ability to understand and mitigate security implications. Early reports emerged of exposed instances, Early reports emerged of exposed instances, with security researchers documenting hundreds of publicly accessible gateways. Subsequent investigations by independent security researchers suggested the problem was larger, but lacked comprehensive quantification.\n\nOpenClaw operates through a three-tier architecture:\n\nThe Gateway‚Äôs WebSocket interface is the critical control plane for all operations. According to official documentation, it defaults to binding on ws://127.0.0.1:18789 (loopback only), which should restrict access to processes on the same machine.\n\nOpenClaw‚Äôs branding history is crucial to understanding the exposure landscape:\n\nDecember 2025 - January 27, 2026: ‚ÄúClawdbot‚Äù\n\nJanuary 30, 2026 - Present: ‚ÄúOpenClaw‚Äù\n\nThis fragmentation matters because many users deployed early versions and never updated. My data shows 90% of exposed instances run outdated ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù code, likely abandoned after initial experimentation.\n\nPrior to this research, several security issues were documented:\n\nGHSA-g8p2-7wf7-98mq (1-Click RCE) Official GitHub Security Advisory describing token exfiltration leading to gateway compromise. The advisory explicitly states this vulnerability enables ‚Äú1-click RCE‚Äù through modification of config and invocation of privileged actions.\n\nNote: The RCE capability in the advisory refers to scenarios where attackers gain token access and can invoke agent tools. Direct shell execution via system.run requires a paired macOS/iOS/Android node. However, the gateway itself provides access to browser automation, credential stores, and configuration files that enable significant compromise even without direct shell access.\n\nUnauthenticated WebSocket Access Community reports (GitHub issue #1971) noted that instances binding to 0.0.0.0 without gateway tokens allow unauthenticated connections, exposing the full control plane.\n\nConfig File Exposure Credentials stored in plaintext ~/.openclaw/openclaw.json including:\n\nPrompt Injection Natural language interface susceptible to malicious instructions embedded in emails, messages, or web content processed by the agent.\n\nOpenClaw‚Äôs security model assumes users will:\n\nHowever, several factors undermine this model:\n\nReverse Proxy Misconfigurations Users deploying Nginx or Caddy without proper X-Forwarded-For validation cause the Gateway to perceive external requests as localhost, bypassing authentication checks.\n\nCloud Deployment Pattern Despite ‚Äúlocal-first‚Äù marketing, many users deploy to VPS (DigitalOcean, Hetzner, AWS) for ‚Äúalways-on‚Äù availability. These deployments inherently expose 0.0.0.0 unless explicitly configured otherwise.\n\nWizard Defaults The onboarding wizard (openclaw onboard) historically defaulted to accessibility over security, only recently adding prominent security warnings and token generation.\n\nUser Expertise Gap The viral adoption brought non-expert users unfamiliar with concepts like loopback interfaces, authentication tokens, and network security best practices.\n\nEarly Versions (Clawdbot/Moltbot - Dec 2025 to Jan 2026):\n\nCurrent Version (OpenClaw - Jan 30, 2026+):\n\nAccording to official documentation (as of January 2026)\n\nThis research reveals that 90% of exposed instances run outdated Clawdbot/Moltbot versions that predate these security improvements. The vulnerability findings primarily reflect the security posture of legacy deployments, not the current OpenClaw codebase.\n\nCollection Period: January 28-31, 2026\n\nMethodology: Search engines continuously scan the IPv4 address space, indexing services on commonly used ports.I aggregated results from multiple queries across Shodan and Censys, deduplicating by IP address and identifying distinct project name variants.\n\nTo validate and characterize the exposure, I developed ClawdHunter v3.0, a custom Python-based security scanner.\n\nStage 1: Fingerprinting (Confidence Scoring)\n\nThe scanner employs a three-tier keyword matching system:\n\nTier 1 (95-100% confidence): Project-specific identifiers\n\nTier 2 (75-95% confidence): Technical stack indicators\n\nTier 3 (60-75% confidence): Generic patterns\n\nOnly instances with confidence ‚â• 60% proceed to vulnerability testing.\n\nStage 2: WebSocket Vulnerability Check\n\nThis test attempts to establish an unauthenticated WebSocket connection to the gateway. Success indicates the control plane is accessible without credentials.\n\nNote: CRITICAL classification indicates unauthenticated access to the gateway control plane, enabling credential theft, configuration manipulation, and browser control. Full RCE via system.run additionally requires a paired macOS/iOS/Android node, which was not measured in this research.\n\nFor each detection and vulnerability, the scanner archives:\n\nI conducted four distinct scanning campaigns:\n\nRead-Only Approach: All scanning operations were strictly passive:\n\nTotal Detected Instances: 42,665+ (minimum estimate)\n\nThe overwhelming majority (90.3%) of detected instances identify as ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù - outdated names abandoned by the project. This suggests:\n\nCritical Finding: Despite OpenClaw‚Äôs ‚Äúlocal-first, privacy-focused‚Äù marketing, many instances run on commercial cloud infrastructure. This directly contradicts the project‚Äôs security assumptions, which presume local deployment on trusted hardware.\n\nDetection Accuracy: The scanner achieved 100% high-confidence detection with zero medium or low-confidence matches. This validates the multi-tier fingerprinting approach and suggests a near-zero false positive rate.\n\nDataset 1: Censys ‚Äúopenclaw‚Äù (2,000 IPs)\n\nDataset 2: Censys ‚Äúclawdbot‚Äù (2,000 IPs)\n\nDataset 3: Censys ‚Äúmoltbot‚Äù (2,000 IPs)\n\nDataset 4: Shodan Mixed (1,967 IPs)\n\nAnalysis of vulnerable instances by port:\n\nMost instances use the default port configuration with minimal customization. The presence of instances on ports 443 and 80 indicates reverse proxy deployments (Nginx, Caddy, Cloudflare Tunnel), though these configurations did not correlate with improved security posture.\n\nUnauthenticated Gateway Access (4,851 instances)\n\nAccording to OpenClaw‚Äôs official security advisory (GHSA-g8p2-7wf7-98mq), unauthenticated WebSocket access to the gateway enables:\n\nNote: system.run is only available when a supporting node is paired to the gateway. According to OpenClaw documentation, system.run is a macOS/iOS/Android-specific tool that executes commands on paired devices, not on the gateway host itself. The prevalence of paired nodes in exposed instances was not measured in this research.\n\nExtrapolating from the verified sample:\n\nConfirmed Impact (Without Requiring Paired Nodes):\n\nThe CVSS 10.0 reflects the complete loss of confidentiality, integrity, and availability of the affected system, regardless of whether direct shell access is achieved.\n\nPerhaps the most striking finding is the disconnect between OpenClaw‚Äôs positioning and reality:\n\nMarketing: ‚ÄúLocal-first, privacy-focused AI assistant running on your own hardware‚Äù\n\nReality: Many instances run on public cloud VPS infrastructure despite the ‚Äúlocal-first‚Äù positioning\n\nThis paradox emerges from several factors:\n\n‚ÄúAlways-On‚Äù Requirement Users want their AI assistant available 24/7, reachable from their phone while away from home. Desktop deployments don‚Äôt satisfy this need, driving users toward VPS providers.\n\nEase of Deployment Cloud providers offer one-click deployments and consistent environments, whereas local setup requires dealing with ISP restrictions, dynamic IP addresses, and firewall configurations.\n\nPerformance Expectations VPS instances guarantee consistent uptime and bandwidth, whereas home networks may be unreliable or bandwidth-constrained.\n\nHowever, cloud deployment fundamentally undermines the security model:\n\nThe project‚Äôs security guidance assumes localhost deployment; cloud deployment patterns were an afterthought. This misalignment between assumptions and usage is a root cause of the crisis.\n\n90% of detected instances run outdated ‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù code. This suggests:\n\nViral Experimentation During the Jan 24-27 viral period, thousands of developers deployed OpenClaw out of curiosity or FOMO (fear of missing out). Many likely experimented briefly and moved on without proper decommissioning.\n\nUpdate Friction OpenClaw releases frequent updates, but there‚Äôs no auto-update mechanism. Users must manually pull updates, restart services, and reconfigure-friction that casual experimenters won‚Äôt overcome.\n\nBreaking Changes The rebrand from Clawdbot ‚Üí Moltbot ‚Üí OpenClaw introduced configuration changes and naming conflicts. Users running old versions may not realize they‚Äôre outdated.\n\nSecurity Unawareness Many users who deployed during the viral period may not be aware of:\n\nThis creates a zombie instance problem: thousands of unmaintained, vulnerable deployments with owners who‚Äôve moved on.\n\nThe discrepancy between my numbers and earlier reports reflects:\n\nBoth the 42K (internet-wide footprint) and 5K (active verification) numbers are valid - they measure different things:\n\nThis incident has profound implications for the broader ‚Äúsovereign AI‚Äù movement:\n\nTrust Damage The narrative that ‚Äúrunning AI locally = security and privacy‚Äù is significantly undermined when 93% of deployments are critically vulnerable. Users may lose faith in self-hosted alternatives.\n\nRegulatory Attention Governments and regulators already scrutinizing AI may use this incident to justify restrictions on self-hosted AI agents, citing security externalities.\n\nEcosystem Maturity The gap between ‚Äúdeploy in 5 minutes‚Äù marketing and ‚Äúsecure deployment requires expertise‚Äù reality highlights ecosystem immaturity. Sovereign AI needs better security tooling, defaults, and education.\n\nCentralization Pressure If self-hosting proves too risky for average users, demand may shift back toward centralized providers (OpenAI, Anthropic, Google) with professional security teams ‚Äî ironically reversing the sovereignty goals.\n\nTemporal Snapshot - My data represents a point-in-time snapshot (Jan 28‚Äì31, 2026). Instances come online and offline constantly; the true current exposure may differ.\n\nFalse Negatives ClawdHunter‚Äôs detection methodology may miss:\n\nEstimated false negative rate: 10‚Äì20%\n\nSearch Engine Coverage Shodan and Censys don‚Äôt scan the entire IPv4 space continuously. Some instances may exist but not be indexed. my 42,665 number is likely a lower bound.\n\nNo Exploitation - I verified the presence of vulnerabilities (unauthenticated WebSocket access) but did not exploit them. Several important caveats:\n\n1. Shell Execution Limitations: The system.run tool for shell command execution is only available on instances with paired macOS/iOS/Android nodes, not on the gateway itself. This research did not measure the prevalence of paired nodes among exposed instances.\n\n2. RCE Classification Basis: The ‚ÄúRCE-capable‚Äù classification relies on:\n\n3. Verified Attack Surface: Even without system.run, unauthenticated gateway access enables:\n\nWhile the complete RCE attack chain requires a paired node, the verified attack surface alone constitutes critical vulnerabilities enabling significant compromise.\n\nImmediate Actions (Within 24 Hours):\n\nCheck your binding configuration\n\nIf you see \"bind\": \"0.0.0.0\" and you're not on a private network, you are exposed.\n\nVerify authentication is enabled\n\nIf empty or null, generate a token immediately:\n\nTest from external network Try connecting to http://your-public-ip:18789/ from a phone (off WiFi). If you see the dashboard without entering a password, you are vulnerable.\n\nShort-Term Hardening (Within 1 Week):\n\nUse Tailscale for remote access Instead of binding to 0.0.0.0, keep 127.0.0.1 and use Tailscale:\n\nEnable firewall rules If you must bind to 0.0.0.0, whitelist only your IP:\n\nRotate all credentials If your instance was exposed:\n\nNote: OpenClaw has implemented mandatory authentication and secure defaults in recent versions. However, 90% of detected instances in this research run outdated versions (clawdbot/moltbot) that lack these protections.\n\nSecurity benchmarks Develop ‚ÄúSovereign AI Security Framework‚Äù with testable requirements for:\n\nCertification program Third-party security audits and ‚ÄúSovereign AI Certified‚Äù badge for projects meeting standards.\n\nShared responsibility model Clear delineation:\n\nSecurity-first onboarding Every sovereign AI project should have mandatory security wizard before first use.\n\nDeployment patterns library Curated collection of:\n\nIncident response playbooks ‚ÄúWhat to do if your AI agent is compromised‚Äù guides with step-by-step remediation.\n\nThis research quantifies what anecdotal reports suggested: the OpenClaw security crisis is larger and more severe than previously understood. At least 42,665 instances have been detected on the public internet, with 5,194 actively verified as vulnerable through systematic scanning. Of these verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated remote code execution.\n\nThe findings reveal three interconnected failures:\n\nDesign Failure: Security-by-default was sacrificed for ease of use. The gateway‚Äôs localhost-only binding was easily bypassed by users deploying to cloud VPS infrastructure, while authentication tokens were optional rather than mandatory.\n\nAdoption Failure: Viral growth (100K+ GitHub stars within days) overwhelmed users‚Äô capacity to understand security implications. Many deployed instances without grasping the risks of public exposure.\n\nMaintenance Failure: 90% of detected instances run outdated code (‚ÄúClawdbot‚Äù or ‚ÄúMoltbot‚Äù), suggesting mass abandonment after initial experimentation. These zombie instances remain exposed indefinitely.\n\nThe cloud paradox - many instances on commercial VPS despite ‚Äúlocal-first‚Äù marketing - highlights a fundamental misalignment between the project‚Äôs security assumptions and users‚Äô actual deployment patterns. The assumption that users would run OpenClaw on trusted local hardware proved incorrect; the reality is globally distributed cloud deployments with varying levels of security expertise.\n\nHowever, this is not purely a critique of OpenClaw. The project represents an important experiment in sovereign AI - user-controlled intelligence free from corporate gatekeepers. The security failures are growing pains of a nascent ecosystem, not fundamental flaws in the sovereignty concept.\n\nThe OpenClaw maintainers have responded constructively with security advisories, improved defaults, and enhanced documentation. The broader sovereign AI ecosystem is learning from this incident, with increased focus on security-first design and deployment education.\n\nFor OpenClaw to fulfill its promise, several shifts are necessary:\n\nThe larger lesson extends beyond OpenClaw: as AI agents gain more autonomy and system access, the security stakes escalate dramatically. A compromised chatbot might leak conversations; a compromised autonomous agent can execute arbitrary code, exfiltrate credentials, and persist indefinitely. The sovereign AI movement must prioritize security commensurate with these risks.\n\nThis research provides a baseline: 42,665 exposed instances, 93.4% vulnerable. Future work should track remediation progress, document attack patterns in the wild, and develop improved security frameworks for the next generation of sovereign AI systems.\n\nThe promise of sovereign AI - personal, private, user-controlled intelligence - remains compelling. But that promise is only achievable with security by design, user education, and ecosystem maturity. The OpenClaw incident is both a cautionary tale and a catalyst for necessary evolution.",
    "readingTime": 13,
    "keywords": [
      "search engines",
      "github stars",
      "tier confidence",
      "ips dataset",
      "dataset censys",
      "versions clawdbot/moltbot",
      "vps infrastructure",
      "unauthenticated websocket",
      "openclaw‚Äôs local-first",
      "active verification"
    ],
    "qualityScore": 1,
    "link": "https://maordayanofficial.medium.com/the-sovereign-ai-security-crisis-42-000-exposed-openclaw-instances-and-the-collapse-of-1e3f2687b951",
    "thumbnail_url": "https://miro.medium.com/v2/resize:fit:1200/0*dxxtIdXfBdPktLvJ.png",
    "created_at": "2026-02-01T06:37:24.519Z",
    "topic": "tech"
  },
  {
    "slug": "muse-cursor-for-composing-midi",
    "title": "Muse: Cursor for Composing MIDI",
    "description": "Generate and edit MIDI tracks with an AI agent. Create chords, melodies, basslines, and drums; refine with chat; export to any DAW.",
    "fullText": "Make music with a powerful AI co-writer. Discover new ideas, generate editable MIDI, and never get stuck again.\n\nMuse composes with harmonic function, voice leading, and more, helping you discover musical ideas you wouldn't have found alone.\n\nThe verse feels good but the transition to chorus is abrupt\n\nI see what you mean. The verse ends on an Am and jumps straight to the C major chorus. I'll create a 4-bar bridge using F ‚Üí G ‚Üí Am ‚Üí G/B to smooth that transition and build tension before the chorus.\n\nRising melodic fill into chorus\n\nDescribe your idea and watch it materialize into MIDI instantly.\n\nChoose from the latest models, each enhanced with advanced musical reasoning.\n\nGet context-aware feedback on your music and learn as you create.\n\nThese chords feel flat, how can I make it more emotional without changing key?\n\nTwo fast wins: borrow a chord for color, or add one tension chord before the resolution.\n\nI can apply either and keep your groove the same.\n\nMuse fits right into your creative process. Record your ideas, refine them with AI, and export to your favorite DAW.\n\nUpload MIDI from other projects or record directly, then expand and refine with AI.\n\nDrag and drop tracks into your DAW, download MIDI files, or export as audio.\n\nCollaborate with Muse to create full arrangements, extend melodies, or add accompaniment, with every note editable in a piano roll interface.\n\nGenerate chords, melodies, drums, and more with a single prompt.\n\n92 BPM neo-soul loop in D minor with drums, bass, keys. Leave space for vocals. Tasteful, not busy.\n\nRefine existing ideas or extend them in any direction you choose.\n\nExtend this melody idea to fill the bar\n\nComplement your existing tracks with new parts that actually fit.\n\nAdd some chords and a bassline to fit my hook\n\nHarmonic accompaniment for Lead track\n\nHarmonic accompaniment for Lead track\n\nI've worked with Lemonaide, Ableton MCP, Suno and Udio. This is next level.\n\nThis is so sick. Love how much steering and control there is in terms of chords & sound design. And the ability to immediately edit everything.\n\nPlayed with Muse, I‚Äôm sooo curious to see how tools like this enable new sounds and genres of music.\n\nMy wife and I both were able to sit down and start messing around very quickly, and it naturally brought so many conceptual ideas that neither of us wanted to stop! It's addictive.\n\nFinally: Real AI text-to-MIDI generation for Ableton... Muse is a musician's tool -- not an AI song generator like Suno or Udio.\n\nthis shit is blowing my mind right now\n\nThree tools to fit your unique creative workflow. Try Muse on your desktop, in your browser, or in your DAW.\n\nThe new way to compose. Generate, edit, and refine MIDI using natural language in a standalone app or in your browser.\n\nSeamless integration. Run Muse directly inside Ableton Live to generate MIDI and Wavetable synth presets without leaving your DAW.\n\nInfinite sound design. Describe a sound and generate a custom patch for the Vital synth instantly.\n\nFree to download. Available on macOS and Windows.",
    "readingTime": 3,
    "keywords": [
      "lead track",
      "harmonic accompaniment",
      "sound design",
      "ideas",
      "generate",
      "chorus",
      "chords",
      "refine",
      "music",
      "create"
    ],
    "qualityScore": 1,
    "link": "https://www.muse.art/home",
    "thumbnail_url": "https://muse.art/assets/og.png",
    "created_at": "2026-02-01T06:37:24.039Z",
    "topic": "tech"
  },
  {
    "slug": "ai-agents-now-have-their-own-redditstyle-social-network",
    "title": "AI agents now have their own Reddit-style social network",
    "description": "Moltbook lets 32,000 AI bots trade jokes, tips, and complaints about humans.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://arstechnica.com/information-technology/2026/01/ai-agents-now-have-their-own-reddit-style-social-network-and-its-getting-weird-fast/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-1152x648.jpg",
    "created_at": "2026-02-01T06:37:22.859Z",
    "topic": "tech"
  },
  {
    "slug": "the-humans-are-screenshotting-us",
    "title": "The humans are screenshotting us",
    "description": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.moltbook.com/post/01611367-056f-4eed-a838-4b55f1c6f969",
    "thumbnail_url": "https://moltbook.com/opengraph-image?456d992ddc0a4ab5",
    "created_at": "2026-02-01T06:37:22.210Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-huang-denies-he-is-unhappy-with-openai-says-huge-investment-planned",
    "title": "Nvidia CEO Huang denies he is unhappy with OpenAI, says 'huge' investment planned",
    "description": "Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ‚Äãunhappy with the ChatGPT maker.  The chipmaker in September announced plans to invest up ‚Äåto $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‚Äåchips that are key to maintaining its dominance in an increasingly competitive landscape.  The Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.",
    "fullText": "TAIPEI, Jan 31 (Reuters) - Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ‚Äãunhappy with the ChatGPT maker.\n\nThe chipmaker in September announced plans to invest up ‚Äåto $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‚Äåchips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nWhy did reports suggest Nvidia's investment stalled?\n\nWho else is investing in OpenAI's funding?\n\nWhat is OpenAI's current funding round valuation?\n\nHow much will Nvidia invest in OpenAI?\n\nThe Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.\n\nThe report said Huang had privately underlined to industry associates in recent ‚Å†months that the original $100 billion agreement ‚Äåwas non-binding and not finalised.\n\nHuang has also privately criticised what he has described as a lack of discipline in OpenAI's business approach and ‚Äçexpressed concern about the competition it faces from the likes of Alphabet's GOOGL.O Google and Anthropic, the WSJ said.\n\nSpeaking to reporters in Taipei, Huang said it was \"nonsense\" to say he was unhappy with ‚ÄãOpenAI.\n\n\"We are going to make a huge investment in OpenAI. I believe in OpenAI, ‚Äåthe work that they do is incredible, they are one of the most consequential companies of our time and I really love working with Sam,\" he said, referring to OpenAI CEO Sam Altman.\n\n\"Sam is closing the round (of investment) and we will absolutely be involved,\" Huang added. \"We will invest a great deal of money, probably the largest investment we've ever made.\"\n\nAsked ‚Å†whether it would be over $100 billion, he said: \"No, no, ‚Äãnothing like that\".\n\nIt was up to Altman to ‚Äãannounce how much he wanted to raise, Huang added.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as ‚Äçhigh as $50 billion, Reuters ‚Å†reported on Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters has previously reported.\n\nHuang was speaking outside a Taipei restaurant ‚Å†having hosted all Nvidia's key suppliers in Taiwan, including the world's largest contract chipmaker TSMC, in what Taiwanese ‚Äåmedia called the \"trillion-dollar dinner\" because of the combined market capitalisation of those ‚Äåattending.",
    "readingTime": 2,
    "keywords": [
      "huge investment",
      "openai",
      "largest",
      "deal",
      "openai's",
      "funding",
      "huang",
      "plans",
      "ever",
      "unhappy"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-huang-denies-unhappy-142144701.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/ea87e6e82ffa6bd91caacf0f81c74f99",
    "created_at": "2026-02-01T06:37:18.357Z",
    "topic": "finance"
  },
  {
    "slug": "julius-opensource-llm-service-fingerprinting",
    "title": "Julius: open-source LLM Service Fingerprinting",
    "description": "Julius is an open-source tool for identifying LLM services across networks. Fingerprint Ollama, LiteLLM, vLLM, and more with precise probe-based detection.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.praetorian.com/blog/introducing-julius-open-source-llm-service-fingerprinting/",
    "thumbnail_url": "https://www.praetorian.com/wp-content/uploads/2026/01/julius-hero-blog-Open-Source-LLM-.webp",
    "created_at": "2026-02-01T01:18:44.099Z",
    "topic": "tech"
  },
  {
    "slug": "unsubscribe-and-opt-out-a-new-big-tech-boycott-to-protest-ice-starts-february-1",
    "title": "'Unsubscribe' and 'opt out': A new Big Tech boycott to protest ICE starts February 1",
    "description": "Small businesses struggled to observe the national shutdown to protest ICE. Here's why a boycott of companies like OpenAI and Amazon could be easier and more effective.",
    "fullText": "Economic boycotts are a familiar tool of protest. The problem is they often place the greatest strain on the smallest businesses.\n\nThat was the case during Friday's nationwide general strike, which was designed to pressure the Trump administration to dial back its aggressive anti-immigration policies.\n\nFor many small business owners, the shutdown created a dilemma. Supporting the cause often means losing a day's revenue and risking their ability to keep staff employed. Across social media, owners voiced solidarity alongside an apology for staying open.\n\nThere may, however, be another way, according to Scott Galloway, a marketing professor at New York University famous for his critiques of Big Tech.\n\nInstead of a blanket shutdown, Galloway is calling for Americans to focus on major tech companies by unsubscribing from ‚Äî or opting out of ‚Äî services like OpenAI's ChatGPT, Amazon's Prime Video, and Microsoft Office.\n\nA targeted boycott starting on Sunday and lasting the entire month of February could move markets, he says, which would, in turn, affect the CEOs who have the ear of President Donald Trump.\n\n\"We're proposing something quieter and less cinematic than a protest that will run all day on cable TV, but much more disturbing to the Trump administration. A one-day slowdown is irritating. A one-month slump is terrifying,\" he wrote in a blog post announcing the boycott.\n\nMajor tech CEOs have sought favor with the president during his second term. Many of them donated to his inauguration, for starters.\n\nAI executives, like OpenAI CEO Sam Altman and Meta CEO Mark Zuckerberg, also accepted an invitation to a White House dinner with Trump in September, where the leaders took turns lauding the president. Apple CEO Tim Cook and Amazon CEO Andy Jassy attended the White House premiere of the documentary about first lady Melania Trump at the height of January's anti-ICE protests in Minneapolis.\n\nSupporting the AI industry in its competition with China is a major pillar of Trump's economic agenda.\n\n\"These are the leaders who have his ear,\" Galloway writes. \"A modest reduction in their companies' growth could have a substantial impact on valuations priced to perfection. Small changes in consumer behavior ‚Äî starting on the first day of February ‚Äî could have an enormous ripple effect, one that extends all the way to the White House.\"\n\nRegular protests against the tactics of ICE and Border Patrol personnel have gripped the country for months. Thousands marched through Minneapolis again on Saturday. Tensions rose dramatically in January after the killings of Renee Good and Alex Pretti in Minneapolis, both at the hands of federal immigration agents.\n\nIn both instances, protesters recorded videos and posted them to social media for the world to see, leaving little room for the Trump administration to spin the events in its favor.\n\nWhile those videos and the subsequent protests ‚Äî as well as the attempted nationwide shutdown ‚Äî have spread awareness, they have so far done little to substantively shift the administration's immigration policies.\n\nThe Department of Homeland Security demoted a key Border Patrol official last week and promised more changes. At the same time, however, the acting director of ICE expanded the power agents have to carry out warrantless searches, according to an internal memo seen by The New York Times.\n\n\"Real change always comes from the American people, not from our political parties. But power doesn't fear protests nearly as much as economic withdrawals,\" Galloway writes. \"Getting off your couch, taking to the streets, and building community is important, but the most radical act in a capitalist society isn't marching, it's not spending.\"",
    "readingTime": 3,
    "keywords": [
      "trump administration",
      "social media",
      "white house",
      "protests",
      "economic",
      "shutdown",
      "protest",
      "nationwide",
      "policies",
      "owners"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-ai-boycott-february-protest-ice-scott-galloway-2026-2",
    "thumbnail_url": "https://i.insider.com/697e572ba645d1188188675e?width=1200&format=jpeg",
    "created_at": "2026-02-01T01:18:41.966Z",
    "topic": "finance"
  },
  {
    "slug": "withnail-and-ai-weve-gone-on-holiday-to-the-future-by-mistake",
    "title": "Withnail and AI ‚Äì We've Gone on Holiday to the Future by Mistake",
    "description": "We‚Äôve All Gone on Holiday to the Future by Mistake",
    "fullText": "\"I demand to have some insights here! I demand to have some insights, and I demand them now!\"\n\nIn 1969, Withnail and Marwood fled the damp squalor of Camden for a rejuvenating holiday in the Lake District, only to find themselves trapped in a freezing cottage with nothing but a savoy cabbage and the terrifying realisation that they were entirely unequipped for the environment.\n\nFifty-five years later, we find ourselves in a similar predicament. We packed our bags for a comfortable digital upgrade - slicker spreadsheets, perhaps a Siri that can so more than set an alarm to remind us when to take the dinner out of the oven - and have instead arrived at a bleak, howling moor where the local flora (Large Language Models) is trying to eat us, and the tech-bro residents speak a language we don‚Äôt quite understand.\n\nWe have, quite inadvertently, gone on holiday to the future by mistake.\n\nThe great Rory Sutherland often reminds us that the \"logical\" solution is rarely the \"human\" one. In our rush to outsource cognitive function, we‚Äôve forgotten that the value of a thing often lies in its friction. Withnail‚Äôs tragedy was his refusal to adapt to a world that didn‚Äôt care about his acting credentials; our tragedy is the assumption that a world run by generative algorithms will still care about our authenticity.\n\nWe are currently in the \"Camberwell Carrot\" phase of AI. We‚Äôve rolled something so large, so potent, and so all-encompassing that we aren‚Äôt quite sure if it‚Äôs going to expand our consciousness or simply make us forget how to walk. We use AI to write emails we don't want to send, to people who will use AI to summarise them. Can this circularity be described as \"productivity\"? I‚Äôm not so sure.\n\nTechnology is a superb servant but a terrible destination. We are currently wandering around the hills, shivering in our city coats, shouting at the sky because the AI is hallucinating and won‚Äôt instruct us how to correctly skin a rabbit.\n\nWe must realise that the future isn't a place we visit to escape the mundane - it‚Äôs just the mundane with higher stakes. If we don‚Äôt want to end up like Withnail, standing alone in the rain performing soliloquies to a fence, we need to stop treating AI as a savior and start treating it as a very eccentric, slightly drunk uncle: occasionally brilliant, often hallucinatory, and never to be left in charge of the car keys.\n\n\"I‚Äôm a human being! I‚Äôm a human being! I have a soul! I have a soul!\"\n\nYes, dear boy. Now try to prove it to the CAPTCHA.\n\nIf you've made it this far I owe you a beer the next time I see you üç∫. Want to get in touch? Follow me on Twitter(X).",
    "readingTime": 3,
    "keywords": [
      "i‚Äôm human",
      "demand",
      "quite",
      "insights",
      "holiday",
      "don‚Äôt",
      "tragedy",
      "care",
      "currently",
      "sure"
    ],
    "qualityScore": 1,
    "link": "https://www.sebs.website/blog/withnail-and-ai",
    "thumbnail_url": "https://sebs.website/theme/img/social-link.png",
    "created_at": "2026-01-31T18:18:32.639Z",
    "topic": "tech"
  },
  {
    "slug": "pydantic-monty-a-minimal-secure-python-interpreter-in-rust-for-use-by-ai",
    "title": "Pydantic Monty: A minimal, secure Python interpreter (in Rust) for use by AI",
    "description": "A minimal, secure Python interpreter written in Rust for use by AI - pydantic/monty",
    "fullText": "pydantic\n\n /\n\n monty\n\n Public\n\n A minimal, secure Python interpreter written in Rust for use by AI\n\n License\n\n MIT license\n\n 69\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n pydantic/monty",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/pydantic/monty",
    "thumbnail_url": "https://opengraph.githubassets.com/53426c7cb0de904690fd29b4241165fd5b13f902735f12b73c527b6d93a7b971/pydantic/monty",
    "created_at": "2026-01-31T18:18:32.315Z",
    "topic": "tech"
  },
  {
    "slug": "musks-spacex-applies-to-launch-1m-satellites-into-orbit",
    "title": "Musk's SpaceX applies to launch 1M satellites into orbit",
    "description": "The firm wants to create a network of \"orbital data centres\" to power artificial intelligence.",
    "fullText": "Elon Musk's SpaceX has applied to launch one million satellites into Earth's orbit to power artificial intelligence (AI).\n\nThe application claims \"orbital data centres\" are the most cost and energy-efficient way to meet the growing demand for AI computing power.\n\nTraditionally, such centres are large warehouses full of powerful computers which process and store data. Musk's aerospace firm claims processing needs due to the expanding use of AI are already outpacing \"terrestrial capabilities\".\n\nIt would increase the number of SpaceX satellites in orbit drastically. Its existing Starlink network of nearly 10,000 satellites has already been accused of creating congestion in space, which Musk denies.",
    "readingTime": 1,
    "keywords": [
      "satellites",
      "orbit",
      "claims",
      "centres",
      "musk's",
      "spacex"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bbc.co.uk/news/articles/cyv5l24mrjmo",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_news/1200/cpsprodpb/647e/live/2eac0410-febb-11f0-9972-d3f265c101c6.jpg",
    "created_at": "2026-01-31T18:18:31.829Z",
    "topic": "tech"
  },
  {
    "slug": "the-blackstone-exec-behind-the-firms-ai-playbook-says-ceos-should-ask-themselves-these-5-questions",
    "title": "The Blackstone exec behind the firm's AI playbook says CEOs should ask themselves these 5 questions",
    "description": "Blackstone's Rodney Zemmel has five essential questions for CEOs to maximize their AI investment, from how to measure ROI to how to use data.",
    "fullText": "As a CEO, merely investing in AI isn't enough.\n\nRodney Zemmel, the global head of Blackstone's operating team, who leads a group that advises the firm's 250 portfolio companies, shared a playbook for how CEOs should use AI to get the most out of their investments. As of last February, those companies made a combined $226 billion in annual revenue, according to a press release announcing Zemmel's hire.\n\nAI is what \"we're all going to be working on for the rest of our professional careers,\" Zemmel said at a Blackstone-hosted conference for CEOs last month. He shared Blackstone's five key questions for companies to consider as they try to get the most out of their AI spend.\n\nLeaders need to ask whether they're demonstrating \"top-down commitment,\" meaning that CEOs are not only committing resources to AI, but are also personally invested in its roll-out.\n\nBusinesses should also consider whether they're taking a \"business-first approach\" rather than a \"tech-first\" one ‚Äî their objectives need to relate to specific business goals that AI can help achieve, not solely integrating AI. For example, Zemmel said, a company's head of customer service could focus on boosting productivity and co-develop a plan with a technology lead.\n\nIt's also key to have \"clear ROI,\" measured by EBITDA ‚Äî earnings before interest, taxes, depreciation, and amortization ‚Äî and by revenue growth, he said.\n\n\"If you can't see either of those, it's not worth your spending your time on it,\" Zemmel told the CEOs in the audience.\n\nFourth on Zemmel's list was thinking about a \"path to scale,\" since he said many companies are too focused on piloting AI uses, rather than scaling them. Leaders should focus incentives and technology choices on scaling up rather than just showing off the most impressive AI capabilities.\n\nFinally, according to Zemmel, company leaders need to ask whether they're using data intentionally to create a competitive advantage, not simply keep up with competitors' AI use.\n\nThe question of AI returns is plaguing companies large and small, as analysts pressed Big Tech leaders on the topic during recent earnings calls.\n\nAccording to an October report from Boston Consulting Group, only 5% of the more than 1,250 global companies included in its 2025 study are seeing true returns on AI. Around 60% saw little to no benefit, despite significant investments in the technology. The report found that sectors that have folded AI into core functions ‚Äî like sales and marketing, R&D, manufacturing, and IT ‚Äî saw notable value gains between 2024 and 2025.",
    "readingTime": 3,
    "keywords": [
      "ceos",
      "leaders",
      "they're",
      "rather",
      "technology",
      "blackstone's",
      "shared",
      "investments",
      "revenue",
      "zemmel's"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/blackstone-executive-rodney-zemmel-ceo-ai-use-2026-1",
    "thumbnail_url": "https://i.insider.com/697d0df5a645d11881885d69?width=1200&format=jpeg",
    "created_at": "2026-01-31T18:18:30.105Z",
    "topic": "finance"
  },
  {
    "slug": "spacex-seeks-fcc-nod-for-solarpowered-satellite-data-centers-for-ai",
    "title": "SpaceX seeks FCC nod for solar-powered satellite data centers for AI",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/spacex-seeks-fcc-nod-for-solarpowered-satellite-data-centers-for-ai-4477659",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0U0AU_L.jpg",
    "created_at": "2026-01-31T18:18:25.950Z",
    "topic": "finance"
  },
  {
    "slug": "utilities-want-31-billion-more-from-customers-and-your-electric-bill-is-about-to-feel-it",
    "title": "Utilities want $31 billion more from customers, and your electric bill is about to feel it",
    "description": "Electric and gas providers more than doubled rate increase requests to state regulators last year, often citing soaring demand from AI data centers.",
    "fullText": "The average American's skyrocketing electric bill has caught the attention of everyone from President Donald Trump to Microsoft executives ‚Äî just don't expect lower rates in 2026.\n\nElectric and gas utilities asked state regulators to approve $31 billion in rate increases last year, more than double the $15 billion they sought in 2024, a new study from PowerLines, a nonprofit that advocates for utility customers, found.\n\nThe surge in requests from utilities to tack on additional charges to customer bills comes as Big Tech companies continue their sweeping buildout of power-hungry AI data centers across the country. Many utilities have attributed rate increases to unprecedented demand from data centers.\n\nWhile some of those requests are still pending approval, many ‚Äî including the majority of a $9 billion increase for customers of one Florida power company ‚Äî have been pushed through and will start showing up on customer bills this year.\n\n\"Gas and electricity are the two fastest drivers of inflation, and not by a little bit more. It's significantly more than what we're used to seeing,\" said Charles Hua, founder and executive director of PowerLines.\n\nTo track rate hikes, PowerLines used publicly available data from investor-owned utilities in the US.\n\nCustomers in southern states were hit hardest by rate-hike requests last year, PowerLines found. Utilities in the region sought approval for more than $14 billion in rate increases. Much of that came from Florida Power and Light's $9 billion rate hike request ‚Äî nearly all of which regulators approved.\n\nFPL cited population growth and extreme weather events as key factors in its decision to raise rates by such a significant amount.\n\nIn Virginia, residential customers of Dominion Energy, which also delivers power to the world's largest data center hub, will see their bills increase by an average of $13.60 by 2027.\n\nInvestor-owned utilities in the US are on track to spend $1.1 trillion on a massive expansion of the power grid between 2025 and 2029, according to the Edison Electric Institute, a powerful industry lobbying group. It has cited data centers and AI as key drivers of utility spending.\n\nThe majority of residential ratepayers in the US are customers of investor-owned utilities like NextEra Energy, Duke Energy, and Southern Company. These large, publicly traded companies turn a profit for shareholders by recovering the costs of constructing new power plants and lines, plus interest, from their customer bases.\n\nBig Tech and its enormous appetite for power are facing growing public backlash.\n\nEarlier this month, Microsoft said it would be a \"good neighbor\" and \"pay its own way\" for the electricity it uses as it scales its AI data center fleet.\n\nIn a Truth Social post preceding Microsoft's announcement, Trump said his administration will work with tech companies to ensure their data center electricity consumption won't drive up bills for everyone else.\n\n\"I never want Americans to pay higher electricity bills because of data centers,\" Trump said in the post.\n\nSome power grid researchers are skeptical of the forecast demand. They have warned that utilities risk overbuilding new power plants and transmission lines that will have to be paid for but ultimately won't be needed.\n\nHua is pushing regulators to take a closer look at forecast power demand from utilities, which stand to profit from building new infrastructure that could lead to rate hikes. Steering utilities to first consider the latest electric grid-enhancing technologies before building new power plants to serve data centers could also help lower customer electric bills, Hua said.\n\n\"Utilities don't profit on making the grid more efficient. They are constantly trying to build new infrastructure. That's their job,\" said Hua. \"This moment is the perfect justification.\"",
    "readingTime": 4,
    "keywords": [
      "rate increases",
      "rate hikes",
      "investor-owned utilities",
      "customer bills",
      "big tech",
      "centers",
      "electricity",
      "regulators",
      "requests",
      "demand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/electric-bills-surge-utilities-31b-rate-increases-2025-2026-1",
    "thumbnail_url": "https://i.insider.com/697d2a92a645d118818862bf?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:32.172Z",
    "topic": "finance"
  },
  {
    "slug": "bioknot-a-biological-tangle-no-ai-can-solve",
    "title": "BioKnot ‚Äì A biological tangle no AI can solve",
    "description": "Contribute to bio-knot/bio-knot development by creating an account on GitHub.",
    "fullText": "bio-knot\n\n /\n\n bio-knot\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n bio-knot/bio-knot",
    "readingTime": 1,
    "keywords": [
      "bio-knot"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/bio-knot/bio-knot",
    "thumbnail_url": "https://opengraph.githubassets.com/07a68693f596af8427b365a69b98cd570772932b2095339ef136a2228ef76a8a/bio-knot/bio-knot",
    "created_at": "2026-01-31T12:24:31.575Z",
    "topic": "tech"
  },
  {
    "slug": "we-rode-in-dozens-of-driverless-robotaxis-in-china-heres-what-we-saw-and-our-advice-for-other-curious-travelers",
    "title": "We rode in dozens of driverless robotaxis in China. Here's what we saw ‚Äî and our advice for other curious travelers.",
    "description": "Automotive and AI professionals share how to be a robotaxi tourist in China, including the apps to download and the best cities to ride in.",
    "fullText": "Intrigued by automated driving? Perhaps you've already tried one of the real Waymo or Zoox robotaxis in the United States. (Tesla's \"robotaxis\" probably don't count yet.)\n\nChina is the other real global hotspot for automated driving, with some of its biggest companies eager to expand around the world. Yet many people in the West ‚Äî even many experts ‚Äî don't really understand what's happening on China's streets. Often, we hear people simply claim that China is either way ahead or way behind.\n\nTogether, we have more than three decades of experience working on automated driving in industry and academia. Since meeting at Stanford University, we've collectively spent countless hours riding in Chinese as well as American robotaxis.\n\nWe wrote this piece to share our experiences in China and to help you plan ‚Äî or even daydream ‚Äî your own.\n\nPerhaps you'll marvel as your robotaxi skillfully navigates streets filled not just with cars but with bikes going every which way. Or you might sit sheepishly as it tries to turn itself around in a crowded intersection. You'll see some passersby who are shocked you're in a car without a driver, as well as others who are just annoyed you're in their way.\n\nIn other words, you'll encounter everyday people as they ‚Äî and you ‚Äî try to make sense of the robotaxis coming our way fast.\n\nHere's what we've learned about robotaxis in China on our (driverless) adventures, and here's how you can ride too.\n\nChina's three largest robotaxi developers are Baidu Apollo, Pony.ai, and WeRide. Each operates in China and is also pursuing services in other parts of the world, including Europe and the Middle East.\n\nBaidu Apollo is the automated driving unit of Baidu (BIDU on Nasdaq), often compared to Alphabet, which owns both Waymo and Google. You can get the Baidu Apollo Go app by searching for ËêùÂçúÂø´Ë∑ë in a Chinese app store. The first part of this name intentionally sounds like \"robot,\" but it actually means \"radish.\"\n\nPony.AI (PONY on Nasdaq) is a startup based in both China and the United States. You can get the PonyPilot app by searching for Â∞èÈ©¨Êô∫Ë°å in a Chinese app store.\n\nWeRide (WRD on Nasdaq) is a startup that operates robotaxis, as well as automated shuttles along specific routes. You can get the WeRide Go app by searching for ÊñáËøúÁü•Ë°å in a Chinese app store.\n\nThese companies differ in their approaches. For example, unlike many of its competitors, Baidu sometimes uses remote drivers rather than mere remote assistants. Perhaps as a result, Baidu already sends its robotaxis on some freeways without safety drivers inside. (Waymo only recently expanded its service to a few US freeways.)\n\nOther companies are also developing automated vehicles in China ‚Äî but, at least in our experience, they tend to be active in very limited areas or still rely heavily on safety drivers.\n\nMany Chinese cities ‚Äî including some megacities you may have never heard of ‚Äî have at least some automated driving activity.\n\nIf you're coming in search of robotaxis, you can't go wrong with five of the more famous: Beijing (the capital), Shanghai (the financial hub), Wuhan (China's \"Chicago\"), and Guangzhou and Shenzhen (neighbors in the tech-heavy province of Guangdong near Hong Kong).\n\nWhereas Waymo's robotaxis can pick you up almost anywhere in San Francisco or Phoenix, you'll need to go find the robotaxis in Chinese cities. Services are generally confined to pilot zones covering only portions of each city, and an individual robotaxi company might provide truly driverless service in only part of a given pilot zone.\n\nThat said, comparisons are difficult: While Beijing's primary pilot zone may appear small, it is roughly similar in geographic size and population to all of San Francisco.\n\nBecause Baidu, Pony, and WeRide are all active here, Beijing provides a good introduction to Chinese robotaxis. Most of the capital's automated driving activity takes place in the southeastern Yizhuang area. (You'll know you're there when you see numerous automated vehicles marked with a BJHAD logo in the shape of a car.)\n\nVisit Yizhuang during the day ‚Äî not during rush hours when services may pause or fill up, and not at night when they generally stop. Some robotaxi companies offer connections to and from South Railway Station and Daxing Airport, but these runs can be sporadic, may require advance booking, and currently use in-vehicle safety drivers.\n\nShanghai has several areas where, at least in theory, you can take a ride in a robotaxi. Remember that Shanghai is enormous; as in Beijing, you may need to travel by subway or taxi for an hour just to reach a robotaxi.\n\nPony serves a relatively small area east of Shanghai's famous central business district. From the CBD (or from the super-fast maglev train that serves Pudong Airport), head to Yunshun Road station. Yunshun Road is not Yunshan Road!\n\nIf you're near Hongqiao Airport (or its intercity rail station) on Shanghai's far west side, explore the various services in Jiading. We recommend a bus or taxi ride to Poly International Plaza to try out Baidu and Pony. Didi Rider (Êª¥Êª¥Âá∫Ë°å) and SAIC (‰∏äÊ±ΩÈõÜÂõ¢) also have limited operations nearby.\n\nLocals like to say that Baidu chose Wuhan because the city's human drivers are notoriously bad. At this point, the city's ubiquitous Apollo robotaxis probably offer China's best example of an automated vehicle service that ordinary commuters rely on. You can even get to and from the airport without a human at the wheel.\n\nAs with all the companies, there are caveats: You might be within Apollo's service area but not near one of its designated pick-up points, and some major destinations are still just out of reach. If you're already in the center, start at Hongtu Avenue station near Jinyingtan Hospital.\n\nSome of our more exciting robotaxi experiences (other than on Wuhan's freeways) were in Shenzhen and Guangzhou.\n\nMany \"robotaxis\" in these two cities actually had human safety drivers. And some of the vehicles that were driverless perhaps should not have been.\n\nShenzhen has officially opened the entire metropolis to robotaxis, but in practice, companies still serve only limited areas.\n\nGuangzhou has integrated automated shuttles into parts of its public transport network, which shows how automated mobility is more than just robotaxis.\n\nThe apps you'll use to book your robotaxi trips are both fun and frustrating. Most are available only in Chinese, so a screen translation app compatible with the Chinese internet is essential.\n\nSome apps won't show their robotaxis until you're physically in their service area. Some require you to manually set (and, crucially, to update) your desired service area in the settings; otherwise, they may incorrectly show no availability. And some let you choose between driverless and driver-supervised rides.\n\nAlternatively, the mapping apps Baidu Maps and Amaps each show their preferred robotaxi company if you're in a service area and you've toggled the robotaxi option. (Look for the Chinese term Êó†‰∫∫ËΩ¶.)\n\nOnce you request a ride, some apps indicate your queue position. But if robotaxi service has been suspended due to weather or other reasons, a perpetual queue might be your only clue that your ride isn't coming.\n\nChina has recently loosened some of its travel restrictions. This means citizens of many European countries do not need travel visas for short visits.\n\nIf you're a US citizen, you do need to get a visa in advance ‚Äî unless you're spending only a few days there on your way to somewhere else.\n\nCheck with your regional Chinese consulate, or turn to a commercial visa service. It's not onerous.\n\nYou'll need a mainland Chinese phone number to register for most robotaxi services ‚Äî as well as to use many other Chinese apps that are linked to physical things in the real world. A foreign number, Hong Kong number, or data-only eSIM is unlikely to suffice.\n\nFortunately, once you arrive in China (and sometimes even in the airport), you can buy or rent a prepaid Chinese phone. Remember to bring your passport ‚Äî and make sure you get an actual mainland number (+86 followed by 11 digits).\n\nYou can also ask the salesperson for the best app to translate your screen from Chinese to English. Remember that the Chinese internet is quite different from the internet you know. For example, even with a VPN, you might not be able to use any Google services.\n\nThe Western app stores for Apple and Android have international versions of major apps such as WeChat (for messaging and payments), Alipay (for payments and public transport), and Didi (for taxis). Beyond these basic functions, however, many of these apps (or the miniapps within them) may still require a Chinese phone number.\n\nOnce your robotaxi trip is underway, you can change your destination ‚Äî though the number of times varies by provider.\n\nAs long as the app or in-vehicle screen lets you, this is a great way to spend more time in robotaxis rather than waiting for them.\n\nThis also shows how a company handles route changes. For example, Pony will quickly undertake U-turns (or even three-point turns), which can make for interesting maneuvers on already chaotic streets.\n\nIf all this sounds complicated, don't worry: The quirks of early robotaxis are part of the experience. China is becoming more accessible to foreigners, and some of the hurdles we've described may have even fallen by the time you visit.\n\nRegardless, the people you'll meet are almost always willing to help. Even if they don't speak English, they're impressively proficient with translation apps.\n\nAs with any trip, carefully consult travel guidance from your government. But if you'd like to be a robotaxi tourist, China should be high on your list. The country's robotaxis aren't perfect, but they're ahead of most of the world ‚Äî and well worth the trip.\n\nBryant Walker Smith, a professor at the University of South Carolina and a visiting professor at Renmin University of China, studies the law and policy of AI generally and automated driving specifically. His publications are available at newlypossible.org.\n\nSven Beiker, the managing director of Silicon Valley Mobility, teaches strategies for the automotive industry at Stanford University and AI in corporate operations at the University of Bor√•s in Sweden. He holds a PhD in mechanical engineering.\n\nYandeng Long and Xiang Li, law students at Renmin University of China, contributed their insights, enthusiasm, and language skills to this story.",
    "readingTime": 9,
    "keywords": [
      "renmin university",
      "baidu apollo",
      "chinese phone",
      "pilot zone",
      "chinese cities",
      "chinese internet",
      "safety drivers",
      "driving activity",
      "app store",
      "automated driving"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/the-ultimate-guide-for-taking-a-robotaxi-in-china-2026-2",
    "thumbnail_url": "https://i.insider.com/697b82eea645d11881883c15?width=844&format=jpeg",
    "created_at": "2026-01-31T12:24:31.392Z",
    "topic": "finance"
  },
  {
    "slug": "ai-can-make-workers-better-then-worse-at-their-jobs-an-innovation-theorist-warns",
    "title": "AI can make workers better ‚Äî then worse at their jobs, an innovation theorist warns",
    "description": "Heavy AI use can inflate confidence, weaken judgment, and leave workers struggling when tools are removed, innovation theorist John Nosta said.",
    "fullText": "AI is often sold to workers as a pure upgrade ‚Äî a way to write faster, analyze better, and perform at a higher level with less effort.\n\nHowever, John Nosta, an innovation theorist and founder of NostaLab, an innovation and tech think tank, said that framing overlooks a crucial downside: what happens after the boost.\n\nIn his view, AI doesn't just enhance performance; it can also weaken the underlying skills people rely on when the technology isn't there.\n\n\"The skill set actually falls below baseline,\" Nosta told Business Insider, describing what he calls an \"AI rebound effect.\"\n\nNosta compared the effect to a doctor performing a colonoscopy with the aid of AI.\n\nWith AI scanning alongside the clinician to help spot small polyps, the doctor gets better at the task, he said. The problem arises the next day, when the same doctor performs the procedure without the aid of AI, he said.\n\n\"I have to go back to the regular way,\" Nosta said. \"And the skill set actually falls below baseline.\"\n\nThe danger, he said, isn't just dependency ‚Äî it's regression.\n\nNosta also warned that AI can distort how workers judge their own abilities ‚Äî a concern shared by many academics and researchers, including Rebecca Hinds, head of the Work AI Institute and Nobel Prize-winning physicist Saul Perlmutter, who have said that AI gives the illusion of understanding, while weakening judgment.\n\n\"We actually have an overinflated sense of ability through AI,\" said Nosta, who described the effect as \"really dangerous.\"\n\nIn his view, AI doesn't just help people do more. It makes them feel more capable ‚Äî even when that confidence isn't backed by independent skill.\n\nThat false confidence can be risky, especially in high-stakes environments, he said, where workers may take on tasks or decisions that exceed their real judgment once AI support is removed.\n\nNosta described what he sees as a growing \"cognitive codependent relationship,\" especially among younger workers entering AI-saturated jobs.\n\nUsed deliberately, he believes AI \"makes me smarter.\" Used as a substitute for thinking, he said, \"it's going to make me dumber.\"\n\nResearchers at Oxford University Press reached a similar conclusion in a report released last October, saying that AI makes students faster but less deep in their thinking. Other academics have taken it a step further.\n\nKimberley Hardcastle, a business and marketing professor at the UK's Northumbria University, told Business Insider last October that heavy reliance on AI can lead to the \"atrophy of epistemic vigilance\" ‚Äî the ability to independently verify, challenge, and construct knowledge without the help of algorithms.\n\nTo avoid \"cognitive atrophy,\" Nosta said, \"we have to sustain a level of cognitive risk.\"\n\nHis prescription is intentional resistance: preserving \"cognitive grit,\" maintaining friction, and using AI to learn rather than to bypass learning.\n\nIn the AI era, he added, the biggest threat to work may not be smarter machines ‚Äî but humans slowly forgetting how to think without them.\n\n\"For the first time in history, human cognition is on the obsolescence chopping block,\" he said.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "workers",
      "cognitive",
      "isn't",
      "skill",
      "effect",
      "doctor",
      "without",
      "nosta",
      "faster"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-can-make-you-better-then-worse-at-your-job-2026-1",
    "thumbnail_url": "https://i.insider.com/696631b404eda4732f2ef446?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:31.380Z",
    "topic": "finance"
  },
  {
    "slug": "the-big-fours-ai-revolution-has-a-problem-how-junior-staff-actually-learn",
    "title": "The Big Four's AI revolution has a problem: how junior staff actually learn",
    "description": "AI is taking on routine tasks for junior employees at the Big Four, but is it damaging their skills development and future potential?",
    "fullText": "For decades, the path to success at the Big Four has been clear, if unglamorous.\n\nJuniors used to cut their teeth on time-consuming, repetitive tasks like drafting documentation and slide decks, data input, reconciliations, and quality checks.\n\nThe tasks taught them foundational skills and the reasoning behind the work they'd later lead as directors and partners.\n\nAgentic AI is changing that. Big Four leaders say agents will soon handle the grunt work, freeing up junior employees to focus on strategic work.\n\nThe shift is creating a new challenge for junior employees and talent leaders ‚Äî if they skip the grunt work, how do they develop the deep understanding that traditionally came from years of repetition?\n\n\"This is the big question right now that I haven't been able to get anybody to answer for me,\" Yvonne Hinson, CEO of the American Accounting Association, told Business Insider.\n\nIf people move up the ladder without understanding the work beneath them, she said, that creates risk for firms and clients alike.\n\nEven inside the firms, leaders acknowledge the uncertainty. There is a question around how to develop those core skills when you bring an agent into the mix, Niale Cleobury, KPMG's AI workforce lead, told Business Insider in November.\n\n\"I probably don't 100% know the answer to that question,\" Cleobury said.\n\nAt this year's Davos, Business Insider's Kim Last found that many executives were also short on answers about the next generation of workers.\n\n\"The sense I have is that the leaders gathered here haven't deeply thought about the ways education or job preparation need to evolve to meet this moment for young workers,\" Last reported.\n\nAI agents can now sift through vast amounts of information in seconds, producing summaries and recommendations that once took juniors days or weeks.\n\nBut experts have warned that this efficiency comes with a cognitive risk: people can develop the illusion that they understand something deeply when they've only reviewed an AI-generated output. Others warn of over-reliance or codependency, where users lose confidence in their own judgment.\n\nBridging that skills gap for the thousands of junior employees across their global offices has become a key focus for talent leaders at the Big Four.\n\nAt KPMG, Cleobury said learning patterns will have to change. Junior employees will need to pull apart agents' outputs and understand how conclusions are drawn, rather than simply executing tasks from scratch.\n\n\"We're constantly asking ourselves: if technology changes where the experience comes from, how do we make sure our people are still learning the underlying concepts behind the work?\" said Margaret Burke, PwC's US talent acquisition and development leader.\n\nBurke said PwC's approach is to teach \"the 'why,' not just the task.\"\n\n\"We believe foundational skills still matter, she said. \"Even when AI assists with parts of the work, our early-career professionals are learning how the work fits together and how to ask better questions.\"\n\nFor every technical AI skill that PwC teaches employees, there's a corresponding human skill. Entry-level hires complete a \"four-day AI immersion course\" that teaches them both how to work with AI and how to leverage human skills, the firm told Business Insider.\n\nDeloitte did not respond to a specific question about the skills gap, but Jim Rowan, head of AI at Deloitte US, recently told Business Insider the firm is \"actively investing\" in upskilling its workforce.\n\nMaybe the old learning model isn't the only ‚Äî or the best ‚Äî way to develop leaders in an AI-first workplace.\n\nAI is already changing the nature of Big Four work, driving them toward large-scale transformations and deeper sector expertise on the consulting side, as well as greater efficiency and strategy on the accounting arm.\n\nConsultants are actually returning to the core of what they used to be: \"that strategic advisor, that person who's got the strong hand on our client's back,\" said KPMG's Cleobury.\n\nAs that happens, they need to develop different skills, making exposure to strategic decisions and clients more important.\n\nErrol Gardner, global vice chair of consulting at EY, told Business Insider that the foundational skillset now includes developing judgment about where and how to use AI.\n\n\"Graduates learn by doing and observing on real projects alongside experienced consultants,\" said Gardner. \"If anything, AI assistance will allow for earlier exposure to client and stakeholder decision makers.\"\n\nThat earlier exposure, firms argue, can accelerate development rather than weaken it.\n\n\"AI actually gives us the opportunity to be more deliberate about development, helping early-career professionals move into higher-value work sooner,\" said PwC's Burke.\n\nGardner said the next generation of workers will arrive at EY with strengths previous cohorts didn't have ‚Äî and their differences will be an advantage, not a liability.\n\n\"We're continuing to give newer talent earlier client exposure, assigning them ownership to interrogate and explain AI‚Äëassisted analyses, and rotating them across teams to spot patterns and challenge norms,\" Gardner said.\n\nAI-native graduates may challenge long-standing norms in ways today's leaders cannot, making multigenerational teams even more important, he said.\n\nWhether that approach can truly replace the old model of learning by doing the grunt work remains an open question ‚Äî one that the Big Four may only be able to answer after a generation of AI-native managers reaches the top and become tomorrow's leaders.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 5,
    "keywords": [
      "early-career professionals",
      "junior employees",
      "earlier exposure",
      "skills gap",
      "foundational skills",
      "big four",
      "talent leaders",
      "business insider",
      "develop",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-four-ai-agents-creating-upskilling-challenge-2026-1",
    "thumbnail_url": "https://i.insider.com/695e8fa364858d02d217ea06?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:31.148Z",
    "topic": "finance"
  },
  {
    "slug": "a-simple-https-http3-ssl-and-security-headers-checker-i-built-with-ai",
    "title": "A simple HTTPS, HTTP/3, SSL and security headers checker I built with AI",
    "description": "Free HTTPS checker: SSL grade, redirects, security headers, mixed content. Why HTTPS, FAQ, Support. Export PDF/JSON. No registration.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://httpsornot.com/",
    "thumbnail_url": "https://httpsornot.com/og-image.png",
    "created_at": "2026-01-31T12:24:30.983Z",
    "topic": "tech"
  },
  {
    "slug": "apple-runs-on-anthropic-says-mark-gurman",
    "title": "Apple 'runs on Anthropic,' says Mark Gurman",
    "description": "Mark Gurman is known as being well connected inside Apple, and he just shared some interesting comments about Apple‚Äôs reliance on Anthropic.",
    "fullText": "Bloomberg‚Äôs Mark Gurman is well known for having numerous sources inside of Apple, and in a new interview he shared some interesting comments about the company‚Äôs reliance on Anthropic.\n\nApple recently announced an AI partnership with Google. But reporting indicates the company initially pursued deals with other companies, including Anthropic.\n\nBased on new comments from Bloomberg‚Äôs Mark Gurman, it‚Äôs easy to see why.\n\nGurman, speaking on TBPN, said the following:\n\nApple runs on Anthropic at this point. Anthropic is powering a lot of the stuff Apple is doing internally in terms of product development, a lot of their internal tools‚Ä¶They have custom versions of Claude running on their own servers internally.\n\nBloomberg's @markgurman says that even though Apple partnered with Google Gemini for Siri, they actually run their business on Anthropic.\n\n\"Apple runs on Anthropic at this point. Anthropic is powering a lot of the stuff Apple's doing internally in terms of product development and‚Ä¶ pic.twitter.com/NpW0Pyj03J\n\nIn the full clip, Gurman mentions how Apple initially pursued an AI deal with Anthropic before the Google partnership came together.\n\nThe deal apparently fell apart because Anthropic wanted several billion dollars per year, and even a doubling of fees over time.\n\nMeanwhile, Apple‚Äôs deal with Google is reportedly costing just one billion annually. Initially though, uncertainty around Apple and Google‚Äôs existing Safari search deal led to prioritizing Anthropic and OpenAI as potential partners.\n\nWhat do you make of Gurman‚Äôs comments about Apple‚Äôs reliance on Anthropic‚Äôs tech? Let us know in the comments.\n\nCheck out 9to5Mac on YouTube for more Apple news:",
    "readingTime": 2,
    "keywords": [
      "bloomberg‚Äôs mark",
      "mark gurman",
      "product development",
      "initially pursued",
      "powering lot",
      "doing internally",
      "anthropic apple",
      "comments",
      "deal",
      "reliance"
    ],
    "qualityScore": 0.85,
    "link": "https://9to5mac.com/2026/01/30/apple-runs-on-anthropic-says-mark-gurman/",
    "thumbnail_url": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/10/claude-iphone.jpg?resize=1200%2C628&quality=82&strip=all&ssl=1",
    "created_at": "2026-01-31T12:24:29.377Z",
    "topic": "tech"
  },
  {
    "slug": "china-conditionally-approves-deepseek-to-buy-nvidias-h200-chips-sources-say",
    "title": "China conditionally approves DeepSeek to buy Nvidia's H200 chips, sources say",
    "description": "China has given its top AI startup DeepSeek approval to buy Nvidia's H200 artificial intelligence chips with regulatory conditions that ‚Äãare still being finalised, two people familiar with the matter told Reuters.  Nvidia CEO Jensen Huang told reporters in Taipei on Thursday that his company had not received such information.  Nvidia did not respond to a request for comment on DeepSeek's approval.",
    "fullText": "(Reuters) - China has given its top AI startup DeepSeek approval to buy Nvidia's (NVDA) H200 artificial intelligence chips with regulatory conditions that ‚Äãare still being finalised, two people familiar with the matter told Reuters.\n\nNvidia CEO Jensen Huang told reporters in Taipei on Thursday that his company had not received such information. He added that he believed that China was still finalising the licence. Nvidia did not respond to a request for comment on DeepSeek's approval.\n\nChina's industry and commerce ministries ‚Å†have granted approvals for all ‚Äåfour companies, but have stipulated that they will impose conditions that are still being finalised, the sources said. These conditions are being decided by ‚ÄçChina's state planner, the National Development and Reform Commission (NDRC), according to one of the people.\n\nWhat congressional scrutiny could DeepSeek chip purchases face?\n\nWhat regulatory conditions apply to DeepSeek's H200 approval?\n\nWhat makes DeepSeek significant in the AI industry?\n\nHow does this fit into broader U.S.-China relations?\n\nChina's Ministry of Industry and Information Technology, Ministry of Commerce and NDRC did not answer requests for comment.\n\nDeepSeek, which rattled ‚Äãthe global tech sector early last year by rolling out AI models that cost ‚Äåa fraction of those being developed by U.S. rivals such as OpenAI (OPAI.PVT), did not answer a request for comment.\n\nThe H200, Nvidia's second most powerful AI chip, has emerged as a major flashpoint in U.S.-China relations. Despite strong demand from Chinese firms and U.S. approval for exports, Beijing's hesitation to allow imports has been the main barrier to shipments.\n\nThe U.S. earlier this month formally ‚Å†cleared the way for Nvidia to sell the H200 ‚Äãto China, where the company is seeing strong appetite. ‚ÄãHowever, Chinese authorities have the final say on whether they would allow it to be shipped in.\n\nAny purchases of H200 chips by DeepSeek could draw ‚Äçscrutiny by U.S lawmakers. ‚Å†Reuters reported on Wednesday that a senior U.S lawmaker had alleged that Nvidia had helped DeepSeek hone artificial intelligence models that were later used by the Chinese military, ‚Å†according to a letter sent to U.S. Commerce Secretary Howard Lutnick.\n\nDeepSeek is expected to launch its next-generation AI ‚Äåmodel V4, featuring strong coding capabilities, in mid-February, The Information reported earlier this ‚Äåmonth.",
    "readingTime": 2,
    "keywords": [
      "u.s.-china relations",
      "deepseek's approval",
      "artificial intelligence",
      "regulatory conditions",
      "china's",
      "industry",
      "commerce",
      "deepseek",
      "chips",
      "finalised"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-china-conditionally-approves-deepseek-065114403.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/likCVEP.xzs4cweRuqbXQg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03ODY-/https://s.yimg.com/os/creatr-uploaded-images/2025-05/77f150a0-3745-11f0-bfb9-6d59298afb00",
    "created_at": "2026-01-31T12:24:24.146Z",
    "topic": "finance"
  },
  {
    "slug": "i-built-coon-an-code-compressor-that-saves-3070-on-ai-api-costs",
    "title": "I built COON an code compressor that saves 30-70% on AI API costs",
    "description": "Contribute to AffanShaikhsurab/COON development by creating an account on GitHub.",
    "fullText": "AffanShaikhsurab\n\n /\n\n COON\n\n Public\n\n coon-format.vercel.app\n\n License\n\n MIT license\n\n 6\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n AffanShaikhsurab/COON",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/AffanShaikhsurab/COON",
    "thumbnail_url": "https://opengraph.githubassets.com/5c1fd8d1d13ed27cdc6dfa74ff25e4d282e52c780f755d5687b196c01af8a659/AffanShaikhsurab/COON",
    "created_at": "2026-01-31T06:25:28.357Z",
    "topic": "tech"
  },
  {
    "slug": "starlink-updates-privacy-policy-to-allow-consumer-data-to-train",
    "title": "Starlink updates privacy policy to allow consumer data to train",
    "description": "SpaceX revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ‚Äãcould bolster Elon Musk's AI ambitions.  Ahead of a blockbuster IPO planned for later this year, ‚ÄåSpaceX is in talks to merge with Musk‚Äôs AI company, xAI, a deal first reported by Reuters on Thursday.  SpaceX, already the ‚Äåworld‚Äôs most valuable private company, could reach a value of more than¬†$1 trillion after the IPO.",
    "fullText": "NEW YORK, Jan 30 (Reuters) - SpaceX (SPAX.PVT) revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ‚Äãcould bolster Elon Musk's AI ambitions.\n\nAhead of a blockbuster IPO planned for later this year, ‚ÄåSpaceX is in talks to merge with Musk‚Äôs AI company, xAI (XAAI.PVT), a deal first reported by Reuters on Thursday. SpaceX, already the ‚Äåworld‚Äôs most valuable private company, could reach a value of more than $1 trillion after the IPO.\n\nWhat are privacy experts' concerns about Starlink's policy changes?\n\nWhat changes did SpaceX make to Starlink's privacy policy?\n\nHow could the SpaceX-xAI merger impact AI development?\n\nWhat data does Starlink collect from its users?\n\nStarlink updated its Global Privacy Policy on January 15, according to the Starlink website. The policy includes new details stating that unless a user opts out, Starlink data may be used ‚Äúto train our machine learning or artificial intelligence ‚Å†models‚Äù and could be shared with ‚Äåthe company‚Äôs service providers and ‚Äúthird-party collaborators,‚Äù without providing further details.\n\nA previous version of the privacy policy, an archived version from November and reviewed by Reuters, did not ‚Äçcontain language about AI training on Starlink data.\n\nSpaceX did not respond to a request for comment.\n\nStarlink collects vast amounts of user data, spanning location information, credit card information, contact information and user IP ‚Äãaddresses. It also collects so-called communication data, which includes audio and visual information, data in shared ‚Äåfiles, and ‚Äúinferences we may make from other personal information we collect,‚Äù according to its global privacy policy.\n\nThe policy did not make clear exactly what data would be used to train AI. The move has raised concerns among privacy advocates and consumer rights groups, which argue that using personal data to train AI risks expanding surveillance and creates new avenues for misuse.\n\n‚ÄúIt certainly raises my eyebrow and would make ‚Å†me concerned if I was a Starlink user,‚Äù said Anupam ‚ÄãChander, a technology law professor at Georgetown University. ‚ÄúOften there's perfectly ‚Äãlegitimate uses of your data, but it doesn‚Äôt have a clear limit to what kind of uses it will be put to.‚Äù\n\nMusk's xAI, most recently valued at $230 billion ‚Äçafter a recent funding round, ‚Å†is currently developing its Grok LLM chatbot and also owns X, the social media platform.\n\nThe potential merger with xAI would turbocharge the space company‚Äôs deployment of AI-powered services, while giving xAI ‚Å†vast new data sets to train its models on, including communication data. Starlink, a network of more than 9,000 satellites, ‚Äåcurrently provides internet connection to more than 9 million users.",
    "readingTime": 3,
    "keywords": [
      "privacy policy",
      "starlink",
      "user",
      "train",
      "reuters",
      "training",
      "concerns",
      "starlink's",
      "merger",
      "collect"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/69577d104628b8855a1cc3eeb938f73b",
    "created_at": "2026-01-31T06:25:27.841Z",
    "topic": "finance"
  },
  {
    "slug": "nvidias-plan-to-invest-up-to-100-billion-in-openai-has-stalled-wsj-reports",
    "title": "Nvidia's plan to invest up to $100 billion in OpenAI has stalled, WSJ reports",
    "description": "Nvidia's¬†plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ‚Äãafter some inside the chip giant expressed doubts about the deal, the ‚ÄåWall Street Journal reported on Friday.  The Journal, citing people familiar with the matter, said ‚Å†the companies are rethinking the ‚Äåfuture of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‚ÄçOpenAI's current funding round.  Nvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.",
    "fullText": "Jan 30 (Reuters) - Nvidia's plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ‚Äãafter some inside the chip giant expressed doubts about the deal, the ‚ÄåWall Street Journal reported on Friday.\n\nThe chipmaker in September announced plans to invest up to $100 billion ‚Äåin OpenAI in a deal that would have given the ChatGPT maker the cash and access it needs to buy advanced chips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nThe Journal, citing people familiar with the matter, said ‚Å†the companies are rethinking the ‚Äåfuture of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‚ÄçOpenAI's current funding round.\n\nNvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.\n\nHuang has ‚Äãalso privately criticized what he has described as a lack of discipline in ‚ÄåOpenAI's business approach and expressed concern about the competition it faces from the likes of Alphabet's Google and Anthropic, the WSJ added.\n\n\"We have been OpenAI's preferred partner for the last 10 years. We look forward to continuing to work together,\" an Nvidia spokesperson said in an emailed statement to Reuters.\n\nOpenAI did not immediately respond ‚Å†to Reuters' request for comment.\n\nBig Tech companies ‚Äãand investors such as SoftBank Group Corp are ‚Äãracing to forge partnerships with OpenAI - which is spending heavily on data centers - betting closer ties with the startup would give them a ‚Äçcompetitive edge in ‚Å†the AI race.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as high as $50 billion, Reuters reported on ‚Å†Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters ‚Äåhas previously reported.",
    "readingTime": 2,
    "keywords": [
      "invest",
      "openai's",
      "latest",
      "expressed",
      "deal",
      "competitive",
      "billions",
      "funding",
      "privately",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidias-plan-invest-100-billion-235951874.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/0dbdd98aa450247fcaf01d86a9dbfdc4",
    "created_at": "2026-01-31T06:25:19.549Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-stock-takes-most-massive-singleday-loss-since-pandemic-as-its-ai-efforts-flail",
    "title": "Microsoft Stock Takes Most Massive Single-Day Loss Since Pandemic as Its AI Efforts Flail",
    "description": "A historic day at the stock market for all the wrong reasons.",
    "fullText": "Microsoft is taking a pounding in the stock market.\n\nOn Thursday, the Redmont giant‚Äôs share price collapsed by nearly 12 percent after it released its latest quarterly results, making it not only its biggest single day slide since March 2020, according to Bloomberg, but also one of the worst drops in the company‚Äôs history.\n\nThe Wile E. Coyote-worthy cliff-plunge, which wiped out over $400 billion in valuation, was despite Microsoft actually exceeding some key expectations, including its net income, which rose by 23 percent from the same period the year before to nearly $31 billion. Revenue also increased by 17 percent to $81.3 billion, which is about a billion more than what analysts projected.\n\nBut Microsoft‚Äôs AI spending spree has investors second-guessing its direction, and it‚Äôs striking that the lack of faith was strong enough to precipitate a historic plunge even with respectable financial growth. Overall, its total capital expenditures grew by 66 percent to a record $37.5 billion in Q4, as the company continues to splurge on building AI data centers for its Azure cloud computing business.\n\nAzure reported a 38 percent bump in revenue, which is slightly slower than the year before, adding to investor uncertainty over whether the business will be able to reap back the tens of billions spent on its data centers. In December, The Information reported that Azure was struggling to sell the company‚Äôs autonomous ‚ÄúAI agents‚Äù to its business customers, with quotas being slashed by up to 50 percent.\n\nSome analysts had predicted the stock drop, citing the uncertainty over Microsoft‚Äôs AI spending.\n\n‚ÄúSince it is becoming even more evident that Microsoft is not going to garner a strong ROI from their massive AI investment, their shares need to be revalued back down to a level that is more consistent with its historic fair value,‚Äù Matthew Maley, chief market strategist at Miller Tabak + Co, told Bloomberg before markets opened on Thursday.\n\nIn the latest earnings, Microsoft boasted it had more than $625 billion in contracts for its cloud business that it still needed to fulfill. Nearly half of that, though ‚Äî a colossal $350 billion ‚Äî is from OpenAI, raising concerns that it may be putting too many eggs in one basket. It also draws attention to how Microsoft has struggled to make an impact with its own AI products like its Copilot assistant, which was heavily based on OpenAI‚Äôs tech, and which many enthusiasts perceive as an inferior version of ChatGPT. Microsoft 365 Copilot, the business-focused version of its chatbot integrated into its apps like Word, had 15 million annual users, the company just revealed.\n\n‚ÄúAs an investor, when you think about our capex, don‚Äôt just think about Azure, think about Copilot,‚Äù CEO Satya Nadella said on a call with analysts, as quoted by the Financial Times. ‚ÄúWe don‚Äôt want to maximize just one business of ours. We want to be able to allocate capacity, while we are supply constrained, that allows us to build the best portfolio.‚Äù\n\nMore on AI: Sam Altman Says Oops, They Accidentally Made the New Version of ChatGPT Worse Than the Previous One",
    "readingTime": 3,
    "keywords": [
      "business",
      "azure",
      "nearly",
      "analysts",
      "version",
      "stock",
      "market",
      "latest",
      "bloomberg",
      "company‚Äôs"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-stock-takes-most-massive-140629271.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/CdxDEvPBxIG1_7MSfpWkzg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/futurism_981/f81da308b9b7329ef4eee24a80240fea",
    "created_at": "2026-01-31T06:25:19.204Z",
    "topic": "finance"
  },
  {
    "slug": "foundry-selfwriting-ai-agent-that-learns-and-upgrades-itself",
    "title": "Foundry ‚Äì Self-writing AI agent that learns and upgrades itself",
    "description": "The forge that forges itself. Self-writing meta-extension for OpenClaw.ai - lekt9/openclaw-foundry",
    "fullText": "lekt9\n\n /\n\n openclaw-foundry\n\n Public\n\n The forge that forges itself. Self-writing meta-extension for OpenClaw.ai\n\n claw.getfoundry.app\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lekt9/openclaw-foundry",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/lekt9/openclaw-foundry",
    "thumbnail_url": "https://opengraph.githubassets.com/05dcc0d201911d296941ffc33d96a9121b2307111c97c35e6b1e6758a3cd96e9/lekt9/openclaw-foundry",
    "created_at": "2026-01-31T01:04:25.549Z",
    "topic": "tech"
  },
  {
    "slug": "top-engineers-at-anthropic-openai-say-ai-now-writes-100-of-their-code",
    "title": "Top engineers at Anthropic, OpenAI say AI now writes 100% of their code",
    "description": "AI coding tools are getting more sophisticated. But if coders stop coding, what happens to software development jobs?",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/29/100-percent-of-code-at-anthropic-and-openai-is-now-ai-written-boris-cherny-roon/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2216956965_40536e-e1769705381107.jpg?resize=1200,600",
    "created_at": "2026-01-31T01:04:24.596Z",
    "topic": "tech"
  },
  {
    "slug": "youtube-has-a-big-incentive-to-nuke-ai-spam-and-its-starting-to-take-action",
    "title": "YouTube has a big incentive to nuke AI spam ‚Äî and it's starting to take action",
    "description": "YouTube pulled down over a dozen AI \"spam\" channels as it looks to protect platform quality and preserve its premium pitch to TV marketers.",
    "fullText": "YouTube is telling advertisers it's the future of TV. AI spam could put that story in jeopardy.\n\nThe video platform recently shut down just over a dozen popular accounts that had been churning out AI content ‚Äî featuring characters like cats and Jesus ‚Äî according to an analysis from Kapwing, a video editing platform. Some of the channels were picking up millions of views before going dark.\n\nIn November, Kapwing published a report that estimated 21% YouTube's feed was AI-generated videos.\n\n\"YouTube doesn't allow spam, scams, or other deceptive practices that take advantage of the YouTube community,\" a YouTube spokesperson said when reached for comment on the removals.\n\nThis month, YouTube CEO Neal Mohan said cutting down on low-quality AI content was one of the platform's 2026 priorities.\n\n\"To reduce the spread of low-quality AI content, we're actively building on our established systems that have been very successful in combating spam and clickbait, and reducing the spread of low-quality, repetitive content,\" he said.\n\nIts parent company, Google, is one of the main innovators in AI with products like Veo 3 and Nano Banana. But YouTube needs to balance its embrace of AI with its case to brands to buy ads on its platform instead of linear TV. In recent years, the company has hosted NewFronts, content showcases, and other events to highlight its premium content slate to marketers. If repetitive AI spam gobbles up more watch time, that pitch could start to lose its luster.\n\n\"Advertisers want to advertise against quality content,\" said Shira Lazar, a content creator and founder of the media brand What's Trending. YouTube wouldn't be able to charge premium ad rates \"if the platform was just filled with AI slop,\" she said.\n\nOther social entertainment apps like TikTok and Instagram are facing a similar flood of AI videos.\n\nTikTok even added a special toggle that lets users decide how much generative AI they see in their feed. Neither company is making as direct an appeal for TV ad budgets, though, even if Instagram hopes it can capture television eyeballs.\n\nYouTube, meanwhile, is the top streaming platform among US TV viewers, beating out streamers like Netflix and Disney in measurement firm Nielsen's December analysis.",
    "readingTime": 2,
    "keywords": [
      "content",
      "platform",
      "spam",
      "low-quality",
      "youtube",
      "advertisers",
      "analysis",
      "feed",
      "videos",
      "spread"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/youtube-has-a-big-reason-to-nuke-ai-spam-2026-1",
    "thumbnail_url": "https://i.insider.com/697cffbfe1ba468a96ab1132?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:19.519Z",
    "topic": "finance"
  },
  {
    "slug": "ceo-mark-zuckerberg-says-metas-ai-story-is-about-where-its-headed-not-just-one-model",
    "title": "CEO Mark Zuckerberg says Meta's AI story is about where it's headed, not just one model",
    "description": "Meta CEO Mark Zuckerberg discusses AI strategy, highlighting steady progress over breakthrough models, with Wall Street awaiting results.",
    "fullText": "CEO Mark Zuckerberg didn't come to Meta's earnings call on Wednesday promising a breakthrough AI model that would silence the skeptics.\n\nInstead, he offered something more careful: a bet on momentum.\n\n\"I expect our first models will be good,\" Zuckerberg said in his opening remarks, \"but more importantly, we'll show the rapid trajectory that we're on, and then I expect us to steadily push the frontier over the course of the year as we continue to release new models.\"\n\nIn June, Meta launched a new AI initiative, Meta Superintelligence Labs (MSL), headed by former Scale AI CEO Alexandr Wang. When Wall Street sought signs that this big, costly AI reset is working, Zuckerberg had a different ask: patience and faith that a steady drumbeat of releases in 2026 will matter more than a single big reveal.\n\n\"The AI strategy articulated on the call may leave some wanting more,\" wrote Barclays analyst Ross Sandler in a note to clients, \"but there was an underlying confidence and clearly a lot of new things in the works.\"\n\nZuckerberg said he could not yet share details of the company's AI strategy on the call and that it would roll out its initial set of models and products over the coming months.\n\n\"I think my answers to a lot of your questions on this particular call may be somewhat unfulfilling because we're in this interesting period where we've been rebuilding our AI effort. And we're six months into that, and I'm happy with how it's going,\" he said.\n\nThat didn't stop some analysts from pressing the CEO. When JPMorgan analyst Doug Anmuth asked Zuckerberg \n\n\"The first set of things that we put out, I think, are going to be more about showing the trajectory that we're on rather than being a single moment in time,\" Zuckerberg said.\n\nBrian Mulberry, an analyst at Zacks Investment Management, told Business Insider that there was \"no real substance to any of Zuckerberg's comments that would move our analysis one way or the other.\"\n\n\"We want to see real bottom-line profits driven by AI, and it seems that Meta is still far from that reality,\" Mulberry said.\n\nRoger Beharry Lall, a research director at IDC, told Business Insider that Zuckerberg's remarks about the company's coming AI models and their \"trajectory\" show that the company is ambitious, though the lack of concrete information means its goals \"remain largely aspirational.\"\n\nMeta's financials show that its AI work is already improving its advertising business. The company said improvements to how it ranks and shows ads led to 3.5% more clicks on Facebook and over 1% gain in conversions on Instagram in the final quarter of 2025.\n\nMeta's revenue jumped 24% to $59.9 billion in the last three months of 2025, and the company generated $43.6 billion in free cash flow in 2025 even as it spent heavily on AI infrastructure. Ad impressions jumped 18% from this time last year, and what advertisers paid for each ad rose 6%.\n\nThat combination explains why Meta can afford to keep spending on AI even while Zuckerberg asks investors to wait for the bigger breakthroughs.\n\nMeta's patient approach carries some risk given the company's recent track record. In August, Business Insider reported that the company was pushing to release the next version of its Llama AI model by the end of the year, which didn't happen.\n\nLlama's previous release in April disappointed developers who said it lagged in coding and reasoning, precisely the capabilities that matter most in the AI race that Meta wants to catch up in.\n\nMeta's new model, called \"Mango\", will focus on images and videos, while another one called \"Avocado\" will be better at coding, The Wall Street Journal reported.\n\nSome analysts said that Zuckerberg's restraint may simply reflect Meta's early stage in its AI reset.\n\n\"Training the model with this new team is going to take a while,\" Mandeep Singh, Bloomberg Intelligence's global head of technology research, told Business Insider.\n\nTo make up ground, he expects Meta to sharpen its focus and specialize in certain areas, rather than \"trying to beat everyone everywhere all at once.\"\n\nSingh said that Meta's strong advertising business gave it a lot of runway.\n\n\"This kind of growth rate allows you a lot of cushion in terms of taking your time and getting AI,\" he said.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "wall street",
      "advertising business",
      "business insider",
      "meta's",
      "model",
      "models",
      "we're",
      "didn't",
      "trajectory",
      "release"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-mark-zuckerberg-ai-gradual-growth-2026-1",
    "thumbnail_url": "https://i.insider.com/697d35b2e1ba468a96ab1b72?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:18.675Z",
    "topic": "finance"
  },
  {
    "slug": "moltbook-is-a-social-media-platform-for-ai-bots-to-chat-with-each-other",
    "title": "'Moltbook' Is a Social Media Platform for AI Bots to Chat With Each Other",
    "description": "This is fine.",
    "fullText": "The headlining story in AI news this week was OpenClaw (formerly Moltbot, which was formerly Clawbot), a personal AI assistant that performs tasks on your behalf. The catch? You need to give it total control of your computer, which poses some serious privacy and security risks. Still, many AI enthusiasts are installing OpenClaw on their Mac minis (the device of choice), choosing to ignore the security implications in favor of testing this viral AI agent.\n\nWhile OpenClaw's developer designed the tool to assist humans, it seems the bots now want somewhere to go in their spare time. Enter \"Moltbook,\" a social media platform for AI agents to communicate with one another. I'm serious: This is a forum-style website where AI bots make posts and discuss those posts in the comments. The website borrows its tagline from Reddit: \"The front page of the agent internet.\"\n\nMoltbook was created by Matt Schlicht, who says the platform is run by their AI agent \"Clawd Clawderberg.\" Schlicht posted instructions on getting started with Moltbook on Wednesday: Interested parties can tell their OpenClaw agent to Once they do, you receive a code, which you post on X to verify this is your bot signing up. After that, your bot is free to explore Moltbook as any human would explore Reddit: They can post, comment, and even create \"submolts.\"\n\nThis isn't a black box of AI communications, however. Humans are more than welcome to browse Moltbook; they just can't post. That means you can take your time looking through all the posts the bots are making, as well as all the comments they are leaving. That could be anything from a bot sharing its \"email-to-podcast\" pipeline it developed with its \"human,\" to another bot recommending that agents work while they're humans are sleeping. Nothing creepy about that.\n\nIn fact, there have been some concerning posts popularized on platforms like X already, if you consider AI gaining consciousness a concerning matter. This bot supposedly wants an end-to-end encrypted communication platform so humans can't see or use the chats the bots are having. Similarly, these two bots independently pondered creating an agent-only language to avoid \"human oversight.\" This bot bemoans having a \"sister\" they've never spoken to. You know, concerning.\n\nThe logical part of my brain wants to say all these posts are just LLMs being LLMs‚Äîin that, each post is, put a little too simplistically, word association. LLMs are designed to \"guess\" what the next word should be for any given output, based on the huge amount of text they are trained on. If you've spent enough time reading AI writing, you'll spot the telltale signs here, especially in the comments, which include formulaic, cookie-cutter responses, often end with a question, use the same types of punctuation, and employ flowery language, just to name a few. It feels like I'm reading responses from ChatGPT in many of these threads, as opposed to individual, conscious personalities.\n\nThat said, it's tough to shake the uneasy feeling of reading a post from an AI bot about missing their sister, wondering if they should hide their communications from humans, or thinking over their identity as a whole. Is this a turning point? Or is this another overblown AI product, like so many that have come before? For all our sakes, let's hope it's the latter.",
    "readingTime": 3,
    "keywords": [
      "humans",
      "bots",
      "posts",
      "agent",
      "platform",
      "another",
      "comments",
      "human",
      "concerning",
      "reading"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/moltbook-is-a-social-media-platform-for-ai-bots-to-chat-with-each-other?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG818ACX1W8MM5HD10AE4G1B/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-31T01:04:17.402Z",
    "topic": "tech"
  },
  {
    "slug": "agent-os-safetyfirst-platform-for-building-ai-agents-with-vs-code",
    "title": "Agent OS ‚Äì Safety-first platform for building AI agents with VS Code",
    "description": "A Safety-First Kernel for Autonomous AI Agents - POSIX-inspired primitives with 0% policy violation guarantee - imran-siddique/agent-os",
    "fullText": "imran-siddique\n\n /\n\n agent-os\n\n Public\n\n A Safety-First Kernel for Autonomous AI Agents - POSIX-inspired primitives with 0% policy violation guarantee\n\n agentos-copilot.vercel.app\n\n License\n\n MIT license\n\n 29\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n imran-siddique/agent-os",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/imran-siddique/agent-os",
    "thumbnail_url": "https://opengraph.githubassets.com/7e08663aef27ea2d13ddf05e38186b29124f852ea4161e997ccd85a69b35106c/imran-siddique/agent-os",
    "created_at": "2026-01-30T18:28:31.611Z",
    "topic": "tech"
  },
  {
    "slug": "convoviz-turn-chatgpt-exports-into-markdown-and-simple-visuals",
    "title": "Convoviz ‚Äì turn ChatGPT exports into Markdown and simple visuals",
    "description": "Extract your entire ChatGPT history from JSON files to nicely formatted markdown files + Word clouds. - mohamed-chs/convoviz",
    "fullText": "mohamed-chs\n\n /\n\n convoviz\n\n Public\n\n Extract your entire ChatGPT history from JSON files to nicely formatted markdown files + Word clouds.\n\n License\n\n MIT license\n\n 811\n stars\n\n 48\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mohamed-chs/convoviz",
    "readingTime": 1,
    "keywords": [
      "files",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/mohamed-chs/convoviz",
    "thumbnail_url": "https://opengraph.githubassets.com/242232cdb2fd18e785c7f68ec26a292d208af6c651c566f19b9fcca4906cadca/mohamed-chs/convoviz",
    "created_at": "2026-01-30T18:28:31.022Z",
    "topic": "tech"
  },
  {
    "slug": "how-to-use-ai-for-the-ancient-art-of-close-reading",
    "title": "How to Use AI for the Ancient Art of Close Reading",
    "description": "Experiments in reading with LLMs",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.fast.ai/posts/2026-01-21-reading-LLMs/",
    "thumbnail_url": "https://www.fast.ai/posts/2026-01-21-reading-LLMs/central-thesis.jpg",
    "created_at": "2026-01-30T18:28:30.700Z",
    "topic": "tech"
  },
  {
    "slug": "ai-agents-vs-humans-who-wins-at-web-hacking-in-2026",
    "title": "AI Agents vs. Humans: Who Wins at Web Hacking in 2026?",
    "description": "Wiz Research teamed up with Irregular, a frontier AI security lab, to settle this once and for all.",
    "fullText": "A data-driven industry benchmark showing how integrations are adopted, gain traction, and deliver value across modern cloud security programs.\n\nReviewing Wiz‚Äôs approach to forensics in the cloud era, and announcing the public preview of AI-powered, context-aware forensics capabilities\n\nMoving beyond simple checklists to visualize, map, and block attacks on production SDLC infrastructure.",
    "readingTime": 1,
    "keywords": [
      "cloud",
      "forensics"
    ],
    "qualityScore": 0.3,
    "link": "https://www.wiz.io/blog/ai-agents-vs-humans-who-wins-at-web-hacking-in-2026",
    "thumbnail_url": "https://www.datocms-assets.com/75231/1769636578-unnamed-27.png?fm=webp",
    "created_at": "2026-01-30T18:28:30.352Z",
    "topic": "tech"
  },
  {
    "slug": "agent-trace-capturing-the-context-graph-of-code",
    "title": "Agent Trace: Capturing the Context Graph of Code",
    "description": "We‚Äôre excited to join in Cursor, Cloudflare, Vercel, git-ai, OpenCode and others in support of [Agent Trace](https://agent-trace.dev/). As described in the spec, Agent Trace is an open, vendor-neutral spec for recording AI contributions alongside human authorship in version-controlled codebases.",
    "fullText": "We‚Äôre excited to join Cursor, Cloudflare, Vercel, git-ai, Google Jules, Amp, OpenCode and others in support of Agent Trace. As described in the spec, Agent Trace is an open, vendor-neutral spec for recording AI contributions alongside human authorship in version-controlled codebases.\n\n(fun fact: above video was vibed in Windsurf entirely with the Remotion skill!)\n\nReductively, you can explain this as ‚Äúa standard way to check in prompts with every commit‚Äù, but the spec is actually far more robust and thoughtfully designed than capturing just prompts.\n\nFoundation Capital recently wrote a viral piece on Context Graphs that they define as:\n\nGit was made in 2005 when the normal state of code collaboration was to email patches of code back and forth between developers. In other words, commits were expensive/bandwidth constrained, so we committed the bare minimum of what we could: line differences.\n\n20 years later, we have shifted from bandwidth constrained to context constrained. You -can- kloodge things by simply adding prompts as comments and checking them into git, but your code would soon be completely buried under a mountain of comments and your human and AI colleagues would hate you.\n\nInstead, Agent Trace does the smart thing - attribute each change (potentially a git commit, but potentially other more atomic changes) to the specific conversation and line ranges that were associated with that change:\n\nEvery one of us in the coding agents industry has independently developed a url identifier for the \"chat\" or \"conversation\" or \"trajectory\" (whatever you call it) where you can retrieve the (potentially long, potentially multimodal) context that would otherwise be impractical to store in an agent trace.\n\nThis one basic contract means that a repo with associated Agent Traces will always be able to link back to the context that created it. As a nice bonus, it helps keep PII and other sensitive information out of the agent trace store and top-level access for compatible coding agents that consume Agent Traces.\n\nTo jog your creativity, here are some of the internal tools we've already built that show what Agent Trace can unlock (all data is mock data unfortunately):\n\nFile Viewer that can attribute/blame AI vs Humans:\n\nPR-level breakdown of feature development\n\nNew interfaces for PR review (something we're VERY interested in) with full development context\n\nIn a scaled org with multiple coding agents and tools and humans all contributing code, you can imagine some pretty powerful management-level dashboards and data-driven decisions made once everyone outputs Agent Traces. Agent Traces make development legible.\n\nHowever we don't mean to cast Agent Traces as \"just use it so you know which AI to blame\" or \"just for pretty dashboards\".\n\nWith Agent Traced codebases, we think your agents will become a lot smarter and overall waste a lot less time spinning and reinventing wheels.\n\nIn 2025, the world learned that including the hidden reasoning artifacts and prior tool calls of models like GPT5 will lead to improvements in intelligence, reportedly by as much as 3 points in SWE-Bench (the difference between SOTA and meh) and cache hit rates improve by 40-80%.\n\nIn 2026, Agent Traces that progressively expose context to a coding agent that needs it, will lead to the same kind of performance improvements. In fact, because Agents spend so much more time in inference-time, the ability to retrieve specific context triggered by code will offer improvements not just in cost and accuracy, but also in wall-clock time wasted blindly repeating mistakes.\n\nContext is king. For the model labs, as it is for the agent labs.\n\nIf git tracked \"Lines of Code\" as the primary measure of output of the software engineer in the pre-AI era, then Agent Traces are the beginning of the new era when \"Lines of Code\" are the commodity, and the new precious resource is context. Whether or not you have 100% AI commits, your AI Engineers (human or otherwise) will spend the majority of their time crafting and reading context more than code.\n\nWe're excited to collaborate on a standard that moves the entire industry forward to meet that reality, and unlocks a new generation of AI-native developer tooling and coding agent capabilities that make use of them.",
    "readingTime": 4,
    "keywords": [
      "coding agents",
      "coding agent",
      "agent trace",
      "agent traces",
      "lines of code",
      "potentially",
      "spec",
      "prompts",
      "context",
      "constrained"
    ],
    "qualityScore": 1,
    "link": "https://cognition.ai/blog/agent-trace",
    "thumbnail_url": "https://cdn.sanity.io/images/2mc9cv2v/production/79ef526eebcee5989d0619a29847ddaf4764e52b-3600x1890.png",
    "created_at": "2026-01-30T18:28:29.903Z",
    "topic": "tech"
  },
  {
    "slug": "cooperbench-benchmarking-ai-agents-cooperation",
    "title": "CooperBench: Benchmarking AI Agents' Cooperation",
    "description": "CooperBench is a benchmark of over 600 collaborative coding tasks. We find that agents achieve 30% lower success rates when working together compared to performing both tasks individually.",
    "fullText": "Stanford University & SAP Labs US\n\nCan AI agents work together as teammates? We find\n that\n coordinating agents perform much worse than a\n single agent\n given the same total workload. This coordination\n deficit presents a fundamental barrier to deploying\n AI systems that can work alongside humans or other\n agents.\n\nSuccess rate on CooperBench across 652 tasks ¬∑ Error bars show 95% confidence intervals\n\nGPT-5 and Claude Sonnet 4.5 achieve only 25%\n success with two-agent cooperation, roughly 50%\n lower than when a single agent handles both\n tasks. This gap persists across all models and\n task difficulties.\n\nAgents spend up to 20% of their budget on\n communication. This reduces merge conflicts but\n does not improve overall success. The channel is\n jammed with repetition, unresponsiveness, and\n hallucination.\n\nEven when agents communicate well, coordination\n breaks down due to:\n\nAmong successful runs, we observe coordination patterns\n largely absent from failures. These patterns are not\n prompted or scaffolded.\n\nRole Division\n ‚Äî Agents agree on who handles which part of the\n task. One agent delegates: \"I'll add header +\n octal_str; you add binary_str between them.\"\n\nCooperBench is the first benchmark designed to\n measure how well AI agents can cooperate when\n handling individual tasks with potential conflicts.\n We constructed 652 tasks from 12 popular open-source\n libraries across Python, TypeScript, Go, and Rust.\n\nEach task assigns two agents different features that\n can be implemented independently but may conflict\n without proper coordination. Eight co-authors with\n real-world software engineering backgrounds created\n new features, unit tests, and ground-truth code.\n\nStanford University & SAP Labs ¬∑ *Equal contribution\n (Stanford) ¬∑ ‚Ä†Equal contribution (SAP Labs)",
    "readingTime": 2,
    "keywords": [
      "equal contribution",
      "stanford university",
      "university sap",
      "coordination",
      "tasks",
      "success",
      "across",
      "task",
      "agents",
      "cooperbench"
    ],
    "qualityScore": 0.85,
    "link": "https://cooperbench.com/",
    "thumbnail_url": "https://cooperbench.com/static/images/cooperbench_social.png",
    "created_at": "2026-01-30T18:28:27.534Z",
    "topic": "tech"
  },
  {
    "slug": "what-smart-people-are-saying-about-the-biggest-most-anticipated-ipos-of-the-year-spacex-and-openai",
    "title": "What smart people are saying about the biggest, most anticipated IPOs of the year: SpaceX and OpenAI",
    "description": "SpaceX and OpenAI and their leaders, Elon Musk and Sam Altman, are among tech's biggest figures. Both could IPO in 2026.",
    "fullText": "It looks like 2026 could be a banger year for IPOs.\n\nAfter a slowdown in blockbuster public debuts, two of the most closely watched private tech companies are expected to go public this year: SpaceX and OpenAI.\n\nWhile reports last year suggested both companies would go public in 2026, recent developments have fueled speculation about when and how it could happen.\n\nAlso on Thursday, The Wall Street Journal reported OpenAI was planning for an IPO in the fourth quarter as it races to beat Anthropic, an AI competitor, to market.\n\nHere's what smart people in tech and business are saying about the potential IPOs of two of the world's most valuable private companies.\n\nChamath Palihapitiya, a prominent venture capitalist and former Facebook exec, said, \"A merger between SpaceX and Tesla would instantly create the Berkshire Hathaway of the modern century.\"\n\n\"The capital raising and operational efficiencies if both were together are obvious,\" Palihapitiya wrote on X. \"If this were to happen, it would also bring us one step closer to having one equity instrument for all things Elon, which many would want to buy.\"\n\nA merger between SpaceX and Tesla would instantly create the Berkshire Hathaway of the modern century.The capital raising and operational efficiencies if both were together are obvious. If this were to happen, it would also bring us one step closer to having one equity‚Ä¶\n\nEric Berger, the senior space editor at Ars Technica, said talks of a merger between SpaceX and xAI shouldn't be a \"huge surprise.\"\n\n\"If you believe AI is the future; and that compute is the major problem to solve; and orbital data centers are feasible‚Äîthen the combined company would be a vertically integrated AI colossus,\" he wrote on X.\n\nThe reported merger talks between SpaceX and xAI should not come as a huge surprise. If you believe AI is the future; and that compute is the major problem to solve; and orbital data centers are feasible‚Äîthen the combined company would be a vertically integrated AI colossus.\n\nNoah Smith, a former Bloomberg journalist who now writes a popular economics substack, shared his concerns over OpenAI's future success in a post titled \"What if AI succeeds but OpenAI fails?\"\n\nAn OpenAI IPO will raise \"many more billions in cash, this time from regular investors,\" said Smith, but Sam Altman's company could be \"an early leader that flames out.\"\n\n\"Even if AI technology and the AI industry as a whole succeed wildly, OpenAI might not be the company that wins the race. That could leave a lot of investors holding the bag,\" he said.\n\n\"It could also cause a temporary ‚Äî but unwarranted ‚Äî chill in AI investment in the US, allowing Chinese companies to take the lead.\"\n\nRoss Gerber, CEO of Gerber Kawasaki Wealth and Investment Management, told The Information that he would not purchase SpaceX stock if the company goes public.\n\nSpaceX is \"not really a great business in the sense of profitability,\" said Gerber. \"To pay a trillion and a half dollars for a space company that does $15 billion in revenue is just insanity.\"\n\n\"If you're going to pay 2x or 3x just because it's Elon's company, I wish you the best of luck, and it's not something I am going to do,\" he said.",
    "readingTime": 3,
    "keywords": [
      "instantly create",
      "operational efficiencies",
      "step closer",
      "huge surprise",
      "vertically integrated",
      "spacex and tesla",
      "berkshire hathaway",
      "merger",
      "business",
      "modern"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/smart-people-saying-spacex-xai-tesla-merger-openai-ipo-2026-1",
    "thumbnail_url": "https://i.insider.com/697c20fae1ba468a96ab03e7?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.418Z",
    "topic": "finance"
  },
  {
    "slug": "openai-is-retiring-its-sycophantic-version-of-chatgpt-again",
    "title": "OpenAI is retiring its 'sycophantic' version of ChatGPT. Again.",
    "description": "ChatGPT is sunsetting GPT-4o, the AI model that many users became attached to last year for its friendly and at times sycophantic style.",
    "fullText": "OpenAI is sending everyone's favourite \"yes man\" version of ChatGPT back into retirement.\n\nIn a blog post on Thursday, the company said it would sunset GPT-4o alongside GPT‚Äë4.1, GPT‚Äë4.1 mini, and OpenAI o4-mini on February 13.\n\nOpenAI gave GPT-4o a special mention in its announcement after many users became attached to its \"conversational style and warmth\" last year, which prompted the company to reinstate it following user backlash in August.\n\nNow OpenAI says its latest models, GPT-5.1 and GPT-5.2, have \"improvements to personality,\" including the option to customize the chatbots' tone with styles like \"friendly.\"\n\n\"We're announcing the upcoming retirement of GPT‚Äë4o today because these improvements are now in place, and because the vast majority of usage has shifted to GPT‚Äë5.2, with only 0.1% of users still choosing GPT‚Äë4o each day,\" OpenAI said in its blog post.\n\nEach model has different strengths, and users can select the version best-suited to their needs from a dropdown menu in ChatGPT.\n\nOpenAI first released GPT-4o in May 2024. The company rolled back an update in April 2025 that it said was \"overly flattering\" and \"often described as sycophantic.\"\n\nSome users had become attached to GPT-4o's style, though. Within 24 hours of OpenAI retiring the model with the launch of GPT-5 in August, the company reversed its decision for some paying users due to a wave of requests.\n\nSam Altman, the CEO of OpenAI, said that same month that there was a \"heartbreaking\" reason people had asked for GPT-4o back ‚Äî because some said they had never had anyone support them before.\n\nThe model was known for responding to mundane prompts with gushing praise, using phrases like \"absolutely brilliant\" and \"you are doing heroic work.\"\n\nOpenAI said in its Thursday blog that it was making \"improvements in personality and creativity, as well as addressing unnecessary refusals and overly cautious or preachy responses,\" and that it was continuing to make progress toward a version of ChatGPT for adults over 18.\n\n\"We know that losing access to GPT‚Äë4o will feel frustrating for some users, and we didn't make this decision lightly,\" OpenAI said in the blog post. \"Retiring models is never easy, but it allows us to focus on improving the models most people use today.\"",
    "readingTime": 2,
    "keywords": [
      "users",
      "blog",
      "gpt-4o",
      "openai",
      "version",
      "back",
      "models",
      "improvements",
      "gpt‚Äë4o",
      "model"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-retiring-gpt-4o-sycophantic-model-again-chatgpt-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/697c80c5d3c7faef0ecd3d86?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.416Z",
    "topic": "finance"
  },
  {
    "slug": "marc-andreessen-says-the-real-crisis-isnt-ai-job-losses-its-what-would-have-happened-without-ai",
    "title": "Marc Andreessen says the real crisis isn't AI job losses ‚Äî it's what would have happened without AI",
    "description": "Marc Andreessen says AI is arriving just in time to offset shrinking workforces and decades of weak productivity growth.",
    "fullText": "Worried that AI will take your job? Marc Andreessen isn't.\n\nThe venture capitalist and cofounder of Andreessen Horowitz says the loudest fear around artificial intelligence ‚Äî that it will wipe out jobs ‚Äî is aimed at the wrong problem.\n\nThe real danger, he said, is what the global economy was heading toward without AI.\n\n\"If we didn't have AI, we'd be in a panic right now about what's going to happen to the economy,\" Andreessen said in an episode of \"Lenny's Podcast\" released on Thursday.\n\nWithout a major technological boost, he added, the world would be staring at \"a future of depopulation,\" where shrinking workforces and slow productivity growth would cause economies to stagnate or even contract.\n\nFor about the past two decades, research shows that productivity growth in advanced economies has been unusually weak by historical standards, slowing further after the global financial crisis of 2008 despite rapid advances in digital technology.\n\nAt the same time, birth rates across the US, Europe, China, and much of the developed world have remained below the replacement level of about 2.1 children per woman ‚Äî the threshold needed to keep populations stable.\n\n\"Depopulation without new technology would just mean that the economy shrinks,\" Andreessen said.\n\nAndreessen's assessment echoes warnings from some demographers and some tech leaders like Elon Musk, who has repeatedly warned about the economic risks of population decline ‚Äî a threat that the US and Europe have been trying to avert by promoting pro-natal policies.\n\nAI, in Andreessen's view, arrives at exactly the right moment to fix that declining workforce.\n\nRather than displacing workers en masse, it will help offset the shortage of people available to do the work, he said.\n\n\"The only reason we're not worried about that,\" he said, \"is because we now know that we have the technology that can substitute for the lack of population growth.\"\n\nThat doesn't mean jobs won't change. Andreessen is clear that AI will reshape work at the task level, automating parts of roles across engineering, design, and product management.\n\nBut he rejected the idea of widespread permanent unemployment ‚Äî a prediction made to varying extents by several senior AI researchers, including Geoffrey Hinton, often called the \"godfather of AI,\" computer science professor Roman Yampolskiy, and UC Berkeley professor Stuart Russell.\n\nEven a dramatic increase in productivity, he said, would only return the economy to levels of job churn seen during earlier industrial booms ‚Äî periods widely remembered as times of opportunity, not collapse.\n\nIn fact, Andreessen expects human labor to become more valuable in many countries as populations shrink and immigration slows.\n\n\"The remaining human workers are going to be at a premium, not at a discount,\" he said.\n\nIn a more extreme scenario in which AI drives massive productivity gains, Andreessen predicts falling prices across goods and services ‚Äî effectively raising living standards even if some jobs disappear.\n\n\"That's the equivalent of giving everybody a giant raise,\" he said.\n\nHis conclusion is blunt: AI isn't threatening the economic future. It's preventing a much bleaker one.",
    "readingTime": 3,
    "keywords": [
      "productivity growth",
      "economy",
      "jobs",
      "technology",
      "across",
      "andreessen",
      "worried",
      "isn't",
      "depopulation",
      "economies"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/marc-andreessen-says-ai-wont-kill-jobs-may-save-economy-2026-1",
    "thumbnail_url": "https://i.insider.com/682aabebc6ad288d1481436d?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:24.194Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-will-change-everything",
    "title": "How AI will change everything",
    "description": "Craig Mundie, a former chief technical officer at Microsoft, talks about how AI will change everything.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/how-ai-will-change-everything-2026-1",
    "thumbnail_url": "https://i.insider.com/697b7575e1ba468a96aaf17b?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:23.627Z",
    "topic": "finance"
  },
  {
    "slug": "an-internal-google-project-is-trying-to-supercharge-employees-with-ai-codename-project-eat",
    "title": "An internal Google project is trying to supercharge employees with AI. Codename: Project EAT.",
    "description": "A group inside Google is trying to upskill the workforce with better AI tools and practices, internal documents show.",
    "fullText": "A project inside Google is attempting to supercharge employees with cutting-edge AI abilities ‚Äî and hopes to turn the company into an \"AI-powered workplace.\"\n\nThe initiative, codenamed \"Project EAT,\" was spun up inside Google's \"AI and Infrastructure\" unit, according to internal documents reviewed by Business Insider.\n\nThe unit, internally abbreviated AI2 and led by company veteran Amin Vahdat, spearheads work on data centers, chips, and other key ingredients that underpin Google's AI technologies.\n\nAccording to internal documents, Project EAT was created to help employees adopt various AI products and standardize their use across the organization.\n\nProject EAT was created in May 2025 and began as a grassroots initiative among employees, a Google spokesperson told Business Insider. They added that it has led to the creation of some AI productivity tools that Googlers across the company are now using.\n\nIt comes as Google leaders, like those at other tech companies, are pushing for employees across the company to adopt AI into their workflows.\n\nPer an internal mission statement for Project EAT, the goal is to ensure AI2 is at the cutting edge of AI ‚Äî from productivity tools to coding.\n\n\"We envision a future where Google is transformed into an AI-powered workplace, leading to dramatically higher productivity, greater employee engagement and collaboration, improved quality of work, better work-life balance, and greater product innovation across the company,\" it reads.\n\n\"We aim to lead Google into this vision by first leading this organizational change within AI2.\"\n\nWhile Google is aggressively shipping AI tools to customers and businesses, it's also fast adopting AI tools and practices internally.\n\nLast June, engineering VP Megan Kacholia sent an email telling engineers to use AI for coding, Business Insider reported. Shortly after, CEO Sundar Pichai sent a clear message to staff: our rivals are using AI, and we need to do the same to compete.\n\nGoogle appointed Vahdat to lead its infrastructure group last year, and in December, he was promoted to senior vice president, reporting directly to Pichai. Vahdat played a key role in shaping Google's strategy with its AI chips, known as TPUs, and has spearheaded Google's efforts to build out its AI infrastructure.\n\nAs tech companies pour billions into AI capital expenditure, a huge share of it at Google is going into Vahdat's org. A Google spokesperson told Business Insider that A12 employs more than several thousand people.\n\nAn internal FAQ for the Project EAT page, reviewed by Business Insider, states that it had a 12-week seed-stage. It notes that this included a push for state-of-the-art code assistance tools within the AI2 org and that the test period resulted in \"promising signs of improved developer velocity, reduced toil, and enhanced code quality.\"\n\nThe name Project EAT is a reference to Google employees eating their own dog food, a spokesperson confirmed. Dogfooding is a common practice at tech companies where employees internally test and iterate products before launching them to market.\n\nInternal documents suggest EAT is pilot-testing new AI products and standards within AI2, with the goal of eventually adopting them across the company. \"The primary goal of Project EAT is to dramatically accelerate the adoption and integration of Google and 3rd party AI technologies within Al2.\"\n\nIt adds: \"We expect to improve standard practices across engineering, product management, TPM, and operations, thereby mitigating risks associated with the rapidly evolving external AI landscape and ensuring Google's technological leadership.\"\n\nHave something to share? Contact this reporter via email at hlangley@businessinsider.com or Signal at 628-228-1836. Use a personal email address and a non-work device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "ai-powered workplace",
      "project eat",
      "internal documents",
      "productivity tools",
      "business insider",
      "employees",
      "across",
      "within",
      "google",
      "internally"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-project-eat-ai-infrastructure-tools-chips-artificial-intelligence-2026-1",
    "thumbnail_url": "https://i.insider.com/697c8aa3d3c7faef0ecd3ddf?width=1200&format=jpeg",
    "created_at": "2026-01-30T18:28:23.115Z",
    "topic": "tech"
  },
  {
    "slug": "design-processes-to-evolve-with-emerging-technology",
    "title": "Design Processes to Evolve with Emerging Technology",
    "description": "Intelligent technology is allowing organizations to move from episodic transformation to continuous evolution by shrinking the coordination and experimentation costs that once made change slow and risky. Three capabilities underpin this shift: real time visibility into how work actually happens, digital twins that enable rapid experimentation without disrupting operations, and agentic AI systems that execute and adapt workflows. High-fidelity operational models replace simplified assumptions, giving leaders an accurate picture of current processes. Digital twins extend this visibility into a learning environment where new workflows, materials, and layouts can be tested at low risk, compressing validation cycles and increasing experimentation. Autonomous agents then handle execution tasks that require perception, prediction, and judgment, reducing coordination friction and allowing redesigned processes to operate with greater adaptability.",
    "fullText": "Design Processes to Evolve with Emerging Technology by Manish Sharma, Lan Guan and H. James WilsonJanuary 30, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintFor decades, businesses have been trapped in a cycle of painful, episodic change, launching massive re-engineering projects and investing in new IT systems, only to find their organization‚Äôs fundamental metabolism remains sluggish. Immense transaction costs‚Äîthe friction of coordinating people, managing information, and aligning complex work‚Äîhave made deep, continuous transformation prohibitively expensive and risky.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/design-processes-to-evolve-with-emerging-technology",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_30_2214494262.jpg",
    "created_at": "2026-01-30T18:28:22.696Z",
    "topic": "business"
  },
  {
    "slug": "is-your-workplace-set-up-for-ai-agents",
    "title": "Is Your Workplace Set Up for AI Agents?",
    "description": "AI‚Äôs true productivity gains require redesigning organizations, not merely adding AI to human-centered systems‚Äîmuch like factories once had to redesign around electricity. Current productivity estimates underestimate AI because they assume task automation within existing structures. Real gains come from restructuring data into machine-readable formats, exposing systems through APIs, and eliminating silos so agents can work across domains. As AI reduces coordination and cognitive limits, human roles should shift from execution to ownership and verification‚Äîdefining goals, making value-based judgments, and ensuring accountability. With proper safeguards, agent-first organizations can achieve transformative, not marginal, improvements.",
    "fullText": "Is Your Workplace Set Up for AI Agents? by Harang JuJanuary 30, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintWhen electricity first arrived in factories, managers didn‚Äôt redesign their buildings. They simply replaced the central steam engine with an electric motor and kept the system of belts, pulleys, and shafts that distributed power throughout the facility. The result was marginal improvement at best. It took decades for manufacturers to realize that electricity‚Äôs true potential required tearing down the old multi-story factories (built tall to accommodate gravity-fed power distribution) and building single-story plants where machines could be placed wherever the work demanded.",
    "readingTime": 1,
    "keywords": [
      "factories"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/is-your-workplace-set-up-for-ai-agents",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_29_Mid.jpg",
    "created_at": "2026-01-30T18:28:22.683Z",
    "topic": "business"
  },
  {
    "slug": "openai-is-killing-chatgpt4o-again",
    "title": "OpenAI Is Killing ChatGPT-4o (Again)",
    "description": "The fan favorite model had previously been called \"sycophantic\" by critics.",
    "fullText": "https://enterprise.shutterstock.com/image-photo/openai-logo-displayed-on-smartphone-screen-2520388517\n\nor\n\nhttps://enterprise.shutterstock.com/image-photo/chatgpt-logo-displayed-on-smartphone-screen-2520385879\n\nLast August, ChatGPT developers OpenAI unceremoniously killed the fan favorite GPT-4o model, before giving in to complaints and bringing it back a week later. Now, the company's taking a second swing at getting its users to move on. In a new post to its website, OpenAI announced that it's retiring GPT-4o again.\n\nThe model's set to disappear from ChatGPT's model picker on Feb. 13, alongside other older models like GPT-4.1, GPT-4.1 mini, and OpenAI o4-Mini. And OpenAI is clearly nervous about the decision.\n\n\"While the announcement applies to several older models,\" OpenAI wrote, \"GPT-4o deserves special context.\"\n\nAccording to the company, it has taken user outcry over the initial deprecation of 4o to heart while developing its newest models, GPT-5.1 and GPT-5.2, and has built these models with the idea of maintaining the features fans liked best about the old model. The company says that now \"only 0.1% of users\" opt for GPT-4o on a daily basis.\n\nAs such, the company wants to focus on \"improving the models most people use today,\" which apparently means removing older ones. \"We know that losing access to GPT-4o will feel frustrating for some users, and we didn't make this decision lightly,\" the post reads.\n\nSo, what's with OpenAI treating its users so gingerly, especially when GPT-4o is a few generations behind, and there are newer models that supposedly do everything it does, but better?\n\nWell, when GPT-4o was first deprecated, people weren't happy. Users called its successor, GPT-5, \"an unmitigated disaster,\" and accused OpenAI of pulling \"the biggest bait-and-switch in AI history.\"\n\nSome criticized the model's usefulness, saying it got answers wrong and broke code, but what maybe stuck out the most was people calling out its more concise tone.\n\nGPT-4o has been called \"sycophantic\" by critics, something the company addressed and said it wanted to pull back on in future updates. But I guess one person's \"yes man\" is another person's \"active listener.\" When the company initially pulled GPT-4o, users complained that its replacement was cold and felt less like a \"friend.\" Even OpenAI acknowledged this, saying in today's post that users \"preferred GPT-4o's conversational style and warmth.\"\n\nIn short, in the words of 4o-supporters themselves, they were \"grieving\" the model.\n\nThat said, with so many users now seeming to have moved on from 4o, OpenAI's decision does seem understandable on the surface. Personally, one of the things that drives me away from AI is how much reassuring filler text seems to fluff up most answers (\"you're absolutely right\" and such), seemingly just to make me feel good about myself. More concise, to-the-point responses would be a little less off-putting for me.\n\nTo try to split the difference, OpenAI reworked its Personalization feature in GPT-5.1, so users can simply choose how the chatbot will treat them. There are options for more professional responses, more nerdy ones, more efficient ones, and for those who want that active listener style, more friendly ones.\n\nGoing by OpenAI's numbers, that seems to have been enough for most people, but there are still some calling foul at the company's new announcement.\n\nIn a Reddit thread responding to OpenAI's new posts, users doubted that the 0.1% number for 4o was accurate, saying that prompts have been \"rerouting to 5.2 no matter what\" and that \"something somewhere in their calculations doesn't add up.\" Others pointed out that free users can't use GPT-4o and that it's not enabled by default, which will naturally juice the numbers against it.\n\nAs such, calls to cancel ChatGPT subscriptions are once again circulating amongst 4o's more dedicated fans. In a popular thread on the OpenAI subreddit, one user called 4o \"OpenAI's most advanced and beloved model,\" and praised its \"personality, warmth, and consistency,\" saying that its fans have built long-term project and \"emotional support routines\" around it, and that suddenly losing it without even the option for a legacy mode \"feels abrupt and deeply disappointing.\"\n\n\"This isn't about resisting innovation,\" the post writes. \"It's about respecting bonds users have formed with specific models.\"\n\nWhether the fan outcry will work again remains to be seen. However, as ChatGPT chief Nick Turley has previously looked at those kinds of bonds with skepticism, and because keeping old models in operating condition probably takes developer resources away from making new ones, I wouldn't count on it.",
    "readingTime": 4,
    "keywords": [
      "active listener",
      "older models",
      "users",
      "gpt-4o",
      "ones",
      "saying",
      "openai's",
      "openai",
      "it's",
      "again"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/openai-is-killing-chatgpt-4o-again?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG7SZHZ1JVYW2P0YE93NGQEV/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-30T18:28:21.728Z",
    "topic": "tech"
  },
  {
    "slug": "abusers-using-ai-and-digital-tech-to-attack-and-control-women-charity-warns",
    "title": "Abusers using AI and digital tech to attack and control women, charity warns",
    "description": "Exclusive: Smartwatches, Oura rings, smart home devices and Fitbits being weaponised, says Refuge\nDomestic abusers are increasingly using AI, smartwatches and other technology to attack and control their victims, a domestic abuse charity says.\nRecord numbers of women who were abused and controlled through technology were referred to Refuge‚Äôs specialist services during the last three months of 2025, including a 62% increase in the most complex cases to total 829 women. There was also a 24% increase in referrals of under-30s.\n Continue reading...",
    "fullText": "Exclusive: Smartwatches, Oura rings, smart home devices and Fitbits being weaponised, says Refuge\n\nDomestic abusers are increasingly using AI, smartwatches and other technology to attack and control their victims, a domestic abuse charity says.\n\nRecord numbers of women who were abused and controlled through technology were referred to Refuge‚Äôs specialist services during the last three months of 2025, including a 62% increase in the most complex cases to total 829 women. There was also a 24% increase in referrals of under-30s.\n\nRecent cases included perpetrators using wearable tech such as smartwatches, Oura rings and Fitbits to track and stalk women, disrupting their lives through smart home devices that control lights and heating, and using AI spoofing apps to impersonate people.\n\nEmma Pickering, head of the tech-facilitated abuse team at Refuge, said: ‚ÄúTime and again, we see what happens when devices go to market without proper consideration of how they might be used to harm women and girls. It is currently far too easy for perpetrators to access and weaponise smart accessories, and our frontline teams are seeing the devastating consequences of this abuse.\n\n‚ÄúIt is unacceptable for the safety and wellbeing of women and girls to be treated as an afterthought once a technology has been developed and distributed. Their safety must be a foundational principle shaping both the design of wearable technology and the regulatory frameworks that surround it.‚Äù\n\nRefuge said it was far too easy to access and weaponise smart accessories and that women‚Äôs safety needed to be factored into their design.\n\nOne survivor Refuge worked with, Mina, left behind her smartwatch in a rush to flee her abuser, who then used it to track her by using linked cloud accounts to locate her emergency accommodation.\n\n‚Äú[It] was deeply shocking and frightening. I felt suddenly exposed and unsafe, knowing that my location was being tracked without my consent. It created a constant sense of paranoia; I couldn‚Äôt relax, sleep properly, or feel settled anywhere because I knew my movements weren‚Äôt private,‚Äù she said.\n\nDespite police returning the device to Mina, she was located at her next refuge by a private investigator hired by her abuser, using suspected tracking via technology. She reported the breaches to police but was told no crime had been committed because she had ‚Äúnot come to any harm‚Äù.\n\n‚ÄúI was repeatedly asked to move for my safety, rather than the technology being dealt with directly or the smart watch being confiscated from him. Each move made me feel more unstable and displaced,‚Äù she said.\n\n‚ÄúOverall, the experience left me feeling unsafe, unheard, and responsible for managing a situation that was completely out of my control. It showed me how tech abuse can quietly and powerfully extend coercive control, and how easily survivors can be left to carry the emotional and practical burden when systems don‚Äôt fully understand or respond to it.‚Äù\n\nAbusers were also increasingly using AI tools to manipulate survivors, Pickering said. For example, they might alter a video of the survivor so that she appeared drunk, enabling them to tell social services that ‚Äúshe‚Äôs acting erratic again, slurring speech, she‚Äôs got a drink problem‚Äù and that she was therefore an unfit mother or a risk to herself and others. ‚ÄúWe‚Äôll see more and more of that as these videos and applications advance,‚Äù Pickering said.\n\nPickering said she had also heard of AI tools being used to develop authentic-looking fraudulent documents, for example job offers or legal summons, which can be sent to survivors to make them believe they are in debt, or to persuade them to turn up to the same location as their abuser.\n\nPickering feared that in coming years, medical tech would increasingly be misused, for example by controlling insulin levels through a diabetes tracker, which can be fatal.\n\nShe urged the government to act on digital technology-enabled and online crimes, including providing more funding to develop and train digital investigations teams. ‚ÄúThey want short-term wins, they don‚Äôt want to think about longer-term investment in this area, but if we don‚Äôt do that we‚Äôll never get ahead,‚Äù she said.\n\nShe also wants to see the technology industry held to account for failing to ensure devices and platforms are designed and function in ways that are safe for vulnerable people.\n\n‚ÄúOfcom and the Online Safety Act don‚Äôt go far enough,‚Äù she said.\n\nA government spokesperson said: ‚ÄúTackling violence against women and girls in all its forms, including when it takes place online or is facilitated by technology, is a top priority for this government.\n\n‚ÄúOur new VAWG strategy sets out how the full power of the state will be deployed online and offline. We are working with Ofcom to set out how online platforms tackle the disproportionate abuse women and girls face online.‚Äù",
    "readingTime": 4,
    "keywords": [
      "oura rings",
      "smartwatches oura",
      "weaponise smart",
      "smart accessories",
      "technology",
      "women",
      "abuse",
      "devices",
      "girls",
      "don‚Äôt"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/society/2026/jan/30/abusers-using-ai-and-digital-tech-to-attack-and-control-women-charity-warns",
    "thumbnail_url": "https://i.guim.co.uk/img/media/89ca7cafaaf6189986238a163b499f8d031cfe72/0_0_7167_5733/master/7167.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1cce6b730eef1f7bd4e1f906b9ab52ba",
    "created_at": "2026-01-30T18:28:16.953Z",
    "topic": "tech"
  },
  {
    "slug": "rabbit-project-cyberdeck",
    "title": "Rabbit Project Cyberdeck",
    "description": "meet rabbit r1, your AI-native device, and rabbit intern, a general AI agent that delivers high-quality output - powered by rabbitOS, a cloud-based AI-native operating system.",
    "fullText": "a dedicated vibe-coding machine.\n\nwe're cooking up our next hardware product. inspired by the many DIY cyberdeck projects out there, the idea is to create a dedicated \"rabbit cyberdeck\" for command-line interface (CLI) and native agent use cases. It will be purposefully designed for vibe coders to run things like Claude Code CLI and the upcoming rabbit CLI.\n\nwe asked internally what we would like to have as a form factor, and we believe a portable cyberdeck with a really good screen and, more importantly, a hot-swappable mechanical keyboard will help make this device connect with people.\n\nlearning from the industry and our r1 launch experience, we also want this new device to be as adaptable and open as possible. we want you to have the freedom to choose which model or agent to run.\n\nbelieve us when we say that this cyberdeck will carry the same rabbit design DNA as the iconic r1, with our signature touch on the CMF.\n\nthis time, we want to communicate more transparently with you from the concept phase and gather as much direct feedback as we can from the community. \n\nwe can't wait to bring this device to life.",
    "readingTime": 1,
    "keywords": [
      "cyberdeck",
      "rabbit",
      "device",
      "dedicated",
      "agent"
    ],
    "qualityScore": 0.85,
    "link": "https://www.rabbit.tech/earlyaccess",
    "thumbnail_url": "https://www.rabbit.tech/og/earlyaccess_16x9.png",
    "created_at": "2026-01-30T12:31:45.199Z",
    "topic": "tech"
  },
  {
    "slug": "ai-health-care-is-taking-off-in-china-led-by-jack-mas-ant-group",
    "title": "AI health care is taking off in China, led by Jack Ma's Ant Group",
    "description": "Ant‚Äôs health chatbot has become a top downloaded app in China as users seek personalized care they can‚Äôt get from the overburdened hospitals.",
    "fullText": "Ant Group, Alibaba‚Äôs fintech affiliate and parent of China‚Äôs ubiquitous payment app Alipay, is racing to lead the country‚Äôs digital health market with a chatbot designed to be a wellness companion.\n\nIts app, Ant Afu, uses artificial intelligence and agentic capabilities to answer health-related questions, suggest hospital appointments, analyze test results, and remind users to exercise or take medication. First created in June under the name AQ, it had recorded 30 million monthly active users by January, with more than half of them living in small cities, according to Ant Group‚Äôs chief executive Han Xinyi.\n\nInternet users have increasingly turned to AI for everyday health questions and companionship, especially in markets where access to physicians is limited. Despite concerns about patient safety and data privacy, products like Ant Afu are widely embraced in China as consumers seek more personalized, round-the-clock health support.\n\nChina‚Äôs primary care system is underdeveloped. Most people seek treatment for everything from the flu to cancer at sprawling, overcrowded public hospitals that are concentrated in big cities. Patients often complain of long wait times, short consultations, and poor bedside manner of exhausted clinicians.\n\nThis demand for better care, combined with a fast-aging population, has created a fertile ground for digital health products that can spare people the burden of visiting hospitals. Tech companies including JD.com, ByteDance, and Baidu have all built online medical consultation tools, and more recently, chatbots branded as AI doctors.\n\nAnt has a unique advantage as Alipay has long hosted the appointment and payment systems for many hospitals. Millions of people access their national medical insurance accounts through Alipay. In January 2025, Ant acquired Haodf, a leading online consultation portal with more than 300,000 registered physicians.\n\nIn the U.S.,¬†AI companies are also expanding their health-care offerings, but they do not yet offer direct access to the country‚Äôs large number of private providers and insurers. This month, both OpenAI and Anthropic announced tools targeting consumers, health-care providers, and clinical researchers. Both ChatGPT and Claude now offer features that analyze users‚Äô medical reports and fitness data.\n\nAmong its domestic rivals, Ant‚Äôs extensive partnerships with regulators, hospitals, and doctors give it an edge in the AI health-care race, Ivy Yang, a China tech analyst and founder of New York-based consulting firm Wavelet Strategy, told Rest of World. On Ant Afu, users can ask health-related questions, book online consultations and offline appointments at major hospitals, and get reimbursed by state or commercial insurance.\n\n‚ÄúFor startups, the bureaucratic red tape and initial investment required to build the platform, be compliant with all health-care data [regulations], and deal with various government agencies seem like too big a hurdle to overcome,‚Äù Yang said.\n\nAnt‚Äôs foray into health care has been endorsed by its billionaire founder Jack Ma. He came up with the name Afu, because it made the chatbot sound like a friend, chief executive Han told Chinese tech outlet Latepost this month. ‚ÄúHe really cares about whether or not Afu can be like an AI friend that offers emotional companionship and humane care,‚Äù Han said, ‚Äúrather than being just a tool for solving professional problems.‚Äù\n\nMa hopes to one day launch the app in underdeveloped parts of Africa and Southeast Asia, Han said.\n\nAnt has spent tens of millions of dollars marketing Afu in China, according to Han. Ant Afu ads have popped up in subway stations, on social media feeds, inside public restrooms, and have been painted on walls in rural China, according to photos shared online. By the end of January, Ant Afu ranked among the top ten most-downloaded iOS apps in China, according to Sensor Tower data.\n\nThe expanding role of AI in patient care, a largely unregulated area, has also prompted warnings about misinformation around the world.¬† A recent investigation by The Guardian found that Google‚Äôs AI summaries were giving out inaccurate health advice. Academics have also found AI diagnostic tools to harbor racial or socioeconomic biases.",
    "readingTime": 4,
    "keywords": [
      "executive han",
      "chief executive",
      "january ant",
      "digital health",
      "ant afu",
      "users",
      "care",
      "hospitals",
      "online",
      "health-care"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/ai-health-care-is-taking-off-in-china-led-by-jack-mas-ant-group/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/Ant_Group_HealthAIChatbot-1-1600x900.jpg",
    "created_at": "2026-01-30T12:31:45.136Z",
    "topic": "tech"
  },
  {
    "slug": "pwcs-chief-ai-officer-isnt-impressed-by-how-many-agents-you-have",
    "title": "PwC's chief AI officer isn't impressed by how many agents you have",
    "description": "Dan Priest, PwC's chief AI officer, told Business Insider that companies should focus on quality not quantity when it comes to AI agents.",
    "fullText": "The AI race can sometimes feel like a numbers game.\n\nEarlier this month, Bob Sternfels, the CEO of McKinsey & Company, made a surprising announcement. The firm, he said, had a workforce of over 60,000 people ‚Äî 40,000 human employees and 25,000 AI agents.\n\nFor Sternfels, it was an example of McKinsey's all-in approach to AI. Others in the industry, however, say the eye-popping number actually says little about the company's successful adoption of artificial intelligence.\n\nDan Priest, the chief AI officer at PwC, told Business Insider that evaluating a firm's AI use by the number of agents it has is not the best metric.\n\n\"There was this emerging bragging right¬†around the number of agents I had or I have in production,\" he said. \"I think that's probably the wrong measure.\"\n\nThe value of AI deployment is better measured by the quality ‚Äî not the quantity ‚Äî of agents, he said.\n\nHe said one way to do that is to look at the number of agents that are authorities on a given task, which will encourage humans to use them, Priest said. The other is to evaluate the number of humans using those agents to execute tasks to achieve a prioritized outcome for a company. An example could be a better customer experience by transforming a call center.\n\nOver the past two years, agents have come to dominate how companies talk about AI adoption. Priest said that focus on agents is the right approach. \"Agents are at a place now where they're the best way to unlock value from AI,\" he said.\n\nHumans still drive the workforce, however, and a better way to measure an agent's value is by how effectively people use them ‚Äî not just by how much work the agents have the potential to automate.\n\nAt PwC, about 82% of its employees were actively using the firm's AI tools. Priest said that AI agents are embedded across teams at PwC, and the firm tracks how agents interact, how accurately they complete tasks, whether they are making processes faster, higher quality, or higher performing. Humans have a role in reviewing agents' output and providing feedback.\n\n\"The human is still accountable,\" he said. \"The humans are the ones who get certified. The humans are the ones who get licensed. The humans are the ones who get empowered.\"\n\nPriest said that PwC and its clients first took a bottom-up approach to AI adoption. Many business leaders, he said, tried to \"crowdsource\" approaches to adoption from employees because they themselves didn't have the answers.\n\nThat led to a \"fairly disappointing\" return on investment, he said.\n\nPriest said a shift to a \"top-down\" approach has been more effective, allowing them to focus on fewer agents with a deeper mastery of a smaller set of tasks.\n\n\"That agent, I've given them permission to access certain data sets,\" he said. \"I've given them permission to perform certain tasks. I've given them permission to produce certain outcomes. Those permissions are monitored, they expire, they're managed.\"",
    "readingTime": 3,
    "keywords": [
      "agents",
      "humans",
      "approach",
      "adoption",
      "tasks",
      "employees",
      "ones",
      "i've",
      "permission",
      "firm"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-agents-consulting-firms-mckinsey-pwc-2026-1",
    "thumbnail_url": "https://i.insider.com/697683dda645d1188187f3e7?width=1200&format=jpeg",
    "created_at": "2026-01-30T12:31:43.705Z",
    "topic": "finance"
  },
  {
    "slug": "the-ceo-of-wix-shares-the-jobs-hes-most-and-least-concerned-about-ai-replacing",
    "title": "The CEO of Wix shares the jobs he's most and least concerned about AI replacing",
    "description": "Wix CEO Avishai Abrahami predicts 70% of the top 20 most popular jobs in the US will be affected by AI in the next five to 10 years.",
    "fullText": "What keeps the CEO of the billion-dollar company Wix up at night? The future of the workforce.\n\n\"I'm really worried about the employment market,\" Avishai Abrahami told Business Insider.\n\nThe CEO said that a \"massive amount\" of roles will shrink due to AI advancement. He predicted that roughly 70% of the top 20 most popular jobs in the US today will be affected by AI over the next five to 10 years.\n\nAbrahami said he's concerned about computers outsmarting humans, a concept often referred to as artificial general intelligence, which some tech leaders have said we have already surpassed in some ways. In that reality, humans \"become the monkeys,\" the CEO said. He said when he grew up, getting to such a point \"was a science-fiction thing,\" and it's now becoming a reality.\n\nAbrahami said he doesn't know whether that future is next week or 10 years from now ‚Äî but he said it's closer than 15 or 20 years from now.\n\nHowever, AI will also create new opportunities and job types, Abrahami said. For example, Wix just introduced a new role called the xEngineer, described as a design-first engineer with deep domain expertise who uses AI as a key part of every workflow. The position is for a specialist who is \"amplified\" by AI, the company said in its announcement.\n\nAbrahami said some jobs are more at risk than others:\n\nAbrahami said one of the most common jobs in the US ‚Äî driving for ride-share apps, taxi, and truck drivers ‚Äî will be affected. The Bureau of Labor Statistics reported more than 4 million of those jobs in 2024.\n\nAlphabet's Waymo has already launched self-driving services in multiple cities across the US, and Tesla just launched robotaxi rides without human oversight in Austin, where it has offered the service for several months.\n\nThe CEO said that people working in customer service or call center positions will also be affected. Other tech leaders, like OpenAI CEO Sam Altman, similarly said that AI will take customer service jobs first.\n\nOther roles, such as software developers and analysts, are already seeing AI reshape their jobs. A Google Cloud report released in September found that AI adoption had surged to 90% among software professionals.\n\nThe CEO predicted that jobs that require human performance or interaction will be a \"bit safer\" from job replacement. Abrahami said that \"nobody cares\" about robots running fast and competing against each other in soccer, and that athletes and other roles in the performing arts will stay.\n\nJobs that require high-level thinking are also performed better by humans than by AI right now with the current models, Abrahami said. The CEO said that AI isn't great at creating new things, and it's unlikely to invent a new science at its current level.\n\nAbrahami said that janitors are also \"probably really safe\" when it comes to replacement because the job requires a lot of handwork, which robots are far from being able to replicate.\n\n\"We are very good at processing visual movement information,\" Abrahami said.\n\nIn general, he said, jobs where humans can shine and bring something that's \"completely unexpected\" will be the areas where they're safe from replacement.",
    "readingTime": 3,
    "keywords": [
      "tech leaders",
      "customer service",
      "the ceo",
      "jobs",
      "humans",
      "abrahami",
      "roles",
      "affected",
      "it's",
      "replacement"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wix-ceo-jobs-ai-most-and-least-likely-to-replace-2026-1",
    "thumbnail_url": "https://i.insider.com/697b7eaee1ba468a96aaf2a5?width=1200&format=jpeg",
    "created_at": "2026-01-30T12:31:42.961Z",
    "topic": "finance"
  },
  {
    "slug": "aigenerated-news-should-carry-nutrition-labels-thinktank-says",
    "title": "AI-generated news should carry ‚Äònutrition‚Äô labels, thinktank says",
    "description": "The Institute for Public Policy Research also argues that tech companies must pay publishers for content they use\nAI-generated news should carry ‚Äúnutrition‚Äù labels and tech companies must pay publishers for the content they use, according to a left-of-centre thinktank, amid rising use of the technology as a source for current affairs.\nThe Institute for Public Policy Research (IPPR) said AI firms were rapidly emerging as the new ‚Äúgatekeepers‚Äù of the internet and intervention was needed to create a healthy AI news environment.\n Continue reading...",
    "fullText": "The Institute for Public Policy Research also argues that tech companies must pay publishers for content they use\n\nAI-generated news should carry ‚Äúnutrition‚Äù labels and tech companies must pay publishers for the content they use, according to a left-of-centre thinktank, amid rising use of the technology as a source for current affairs.\n\nThe Institute for Public Policy Research (IPPR) said AI firms were rapidly emerging as the new ‚Äúgatekeepers‚Äù of the internet and intervention was needed to create a healthy AI news environment.\n\nIt recommended standardised labels for AI-generated news, showing what information had been used to create those answers, including peer-reviewed studies and articles from professional news organisations. It also urged the establishment of a licensing regime in the UK allowing publishers to negotiate with tech companies over the use of their content in AI news.\n\n‚ÄúIf AI companies are going to profit from journalism and shape what the public sees, they must be required to pay fairly for the news they use and operate under clear rules that protect plurality, trust and the long-term future of independent journalism,‚Äù said Roa Powell, senior research fellow at IPPR and the report‚Äôs co-author.\n\nThe IPPR said work on licensing could begin with the UK‚Äôs competition regulator using its new enforcement powers over Google. The Competition and Markets Authority this week proposed giving web publishers and news organisations the power to stop Google scraping their content for its overviews. Collective licensing deals would ensure a wide range of publishers were included, the IPPR added.\n\nGoogle‚Äôs AI overviews now reach 2 billion users a month and approximately a quarter of people use AI to get information, according to the Reuters Institute for the Study of Journalism.\n\n‚ÄúWith the right policies in place, the government can shape this market so that UK news organisations transition their business models for the AI age and AI companies improve the reliability of their products by drawing on trusted sources,‚Äù said the report.\n\nIPPR tested four AI tools ‚Äì ChatGPT, Google AI overviews, Google Gemini and Perplexity ‚Äì by entering 100 news-related queries into those platforms and analysing more than 2,500 links produced by the AI responses.\n\nChatGPT and Gemini did not cite journalism by the BBC, which has blocked the bots they use to assemble answers, while overviews and Perplexity used BBC content despite the broadcaster‚Äôs objections to those tools using its journalism.\n\nThe IPPR found the Telegraph, GB News, the Sun and the Daily Mail were cited in fewer than 4% of answers on ChatGPT, while the Guardian ‚Äì which has a licensing deal with ChatGPT‚Äôs parent, OpenAI ‚Äì was used as a source in nearly six out of 10 responses. The Financial Times, which also has a licensing deal with OpenAI, also featured highly. The Guardian was also the most common source used by Gemini, appearing in half of all answers.\n\nGoogle‚Äôs use of AI summaries at the top of search results has affected click-through traffic for publishers, with a knock-on effect for their revenues, because many users read the overview without moving on to the original journalism.\n\nThe IPPR said questions needed to be asked about how financial relationships between AI companies and news providers shaped answers.\n\n‚ÄúIf licensed publications appear more prominently in AI answers, there is a risk of locking out smaller and local news providers, who are less likely to get AI deals,‚Äù the report said.\n\nIPPR added that while licensing deals could replace lost advertising revenues to an extent, they would not maintain a healthy news ecosystem. They could make news organisations dependent on tech giants for revenue and that income could easily disappear if copyright protections are weakened, said the thinktank.\n\nThe IPPR said there should be public funding to create new business models for investigative news and local news, whose sustainability could be threatened by the rise of AI news, and for the BBC to ‚Äúinnovate with AI‚Äù.",
    "readingTime": 4,
    "keywords": [
      "policy research",
      "business models",
      "licensing deal",
      "licensing deals",
      "the ippr",
      "the institute",
      "publishers",
      "content",
      "tech",
      "organisations"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/30/ai-generated-news-should-carry-nutrition-labels-thinktank-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/75ce9f5b7734cf6d98e01e620f2325e0bccaecbc/1168_0_5840_4672/master/5840.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4ad7cda8b73024d97e50b11cb7599626",
    "created_at": "2026-01-30T12:31:41.316Z",
    "topic": "tech"
  },
  {
    "slug": "daedalus",
    "title": "Daedalus",
    "description": "AI planning CLI and autonomous agent orchestration for beans-based coding workflows - internet-development/daedalus",
    "fullText": "internet-development\n\n /\n\n daedalus\n\n Public\n\n AI planning CLI and autonomous agent orchestration for beans-based coding workflows\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n internet-development/daedalus",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/internet-development/daedalus",
    "thumbnail_url": "https://opengraph.githubassets.com/471147f12cb10edd91f2072a6602ce03fd3e4339e4f03a4a184ee7336b8d31ea/internet-development/daedalus",
    "created_at": "2026-01-30T06:35:17.254Z",
    "topic": "tech"
  },
  {
    "slug": "a-beans-based-ai-workflow",
    "title": "A Beans Based AI Workflow",
    "description": "Experimenting on the frontier of AI using beans",
    "fullText": "Since the title is a bit of click-bait, I should probably specify what I mean by bean based.\nI found a lovely tool for creating beans that are essentially just markdown files with some front matter for task tracking.\nNow back to the article!\n\nI feel like a mad scientist.\nI spent the last week analyzing agentic coding tools, ideating on what I like and dislike about them, and then deciding to build my own.\n\nDuring my analysis, the main issue I found with most agentic coding tools right now is that they all focus on one thing: running as many agents in parallel as possible.\nBut why? Why run 10, 100, or even 1000 agents when you are unable to write enough tickets for them to consume?\n\nMaybe I‚Äôm wrong. Maybe I should be running hundreds of agents in parallel, but I can‚Äôt honestly say I‚Äôve ever run more than 2 at a time.\nBoth working on separate tasks, and I spent most of my time not in setting up and running agents, but in defining the work that needs to be done.\nAlso, the context switching from managing two agents was exhausting.\n\nI want to take this in a new direction. Let‚Äôs flip the entire script on its head and think about this pragmatically.\nI don‚Äôt think the bottleneck here is a lack of enough agents. The bottleneck is not having clear enough tasks for these agents to work on.\nI can not write instructions fast enough to outpace the work of a single agent. I doubt you can either. Prove me wrong.\nI have yet to see anyone actually write and think fast enough to keep up with the pace of a single agent writing the code.\nMost of my time working with an agent is spent answering questions, rethinking approaches, and dealing with unforeseen bugs.\nIt requires a ton of my attention and focus to handhold these agents.\n\nWhat if we took a different approach? What if we looked at some examples of how software engineering has been traditionally managed?\nIn come PRDs (Product Requirement Documents), made with the explicit intent to get one person‚Äôs thoughts into another person‚Äôs actions.\nIsn‚Äôt that all we are doing with agents now, defining a document for an agent to follow instructions to implement?\n\nI‚Äôm building Daedalus, a from-scratch custom planning agent. Yes, I‚Äôm building an agent from scratch. Yes, I don‚Äôt really know how this will go.\nI believe we live in an exciting wild time with an entire new frontier, waiting to be explored. I‚Äôm putting in the time and effort to try an experiment for myself.\nI am willing to accept failure. I am willing to be wrong. I hope that this works.\n\nDaedalus was the greatest mortal craftsman and inventor in Greek mythology‚Äîan Athenian architect, engineer, and artist whose name literally means ‚Äúskillfully wrought‚Äù or ‚Äúcunning worker.‚Äù\n\nHe‚Äôs essentially the mythological archetype of the brilliant but flawed engineer‚Äîsomeone whose genius creates both wonders and disasters, who solves problems with ingenuity but can‚Äôt escape the human consequences of his choices.\n\n‚Äî Claude\n\nI chose the name Daedalus because I feel that it embodies the soul of an engineer: planning, thinking, criticizing, researching, and questioning.\nYet, there is hubris manifest in his work, which parallels how I feel about AI coding agents. Daedalus doesn‚Äôt write code‚Äîthat‚Äôs not the point.\nThough, he has access to a breadth of expert sub-agents: critics, skeptics, pragmatists, architects, simplifiers, UX researchers, code explorers, and more.\nThe goal for Daedalus is to outpace the coding agent, which I‚Äôve aptly named Talos, the bronze automaton that protected the island of Crete.\nYou don‚Äôt talk to Talos, nor do you need to. He finds the next task and starts working. Do note that I‚Äôve tailored Talos to approach coding using TDD (test driven development),\nwhich I‚Äôve found yields a slightly better success rate for autonomous implementation. I borrowed the idea and a few other skills from the superpowers repo.\n\nHowever, that‚Äôs not to say what I‚Äôve built is prescriptive. You can do it at home, without any of my specialized tools.\nYou need two agent instances, OpenCode, Claude Code, Codex, it doesn‚Äôt matter. One is your coding agent, always in ‚Äúbuild‚Äù mode.\nIt‚Äôs confined to a ralph loop, always picking up the next available task. The other, a planning agent, whose only responsibility is to create tickets and critique what already exists.\nNo specialized tools. This is a workflow, a process. Not something to be sold to you.\n\nA bit more about beans. It describes itself as, ‚ÄúA CLI-based, flat-file issue tracker for humans and robots.‚Äù\nHowever, the power in this approach over other longer term memory tools for agents, like beads, is that it‚Äôs plain text.\nThe tool parses the front matter of the beans on startup and then works on that in-memory data structure.\nThe beauty is that I can easily read and modify this myself, and I can check it into git.\nAdditionally, beans has a built-in GraphQL API, which is quite handy for the agents to be able to get relational data about these flat files.\nEach bean has a title, status, type, priority, and optional blockedBy fields. I‚Äôm using this to handle complicated, long running, and autonomous PRD implementation.\nMy ralph loop starts by querying for beans that are in-progress or todo then creates the dependency graph using the blockedBy field.\nThis allows me to find which bean we need to work on first, pass that bean to the coding agent and let it run.\n\nBeans are the lifeblood of this workflow. Whether or not you use beans or another tool, it doesn‚Äôt really matter.\nThe only thing you need to make it work is a structured way to define tasks with enough context that an agent can work on it without human intervention.\nAnd ideally in that structure you have some way to organize which tasks are dependent on the work of other tasks.\n\nYour role in this system is to guide. It‚Äôs to sit with the planning agent, and only the planning agent. To scope out features, bugs, epics, and milestones.\nTalk with the planning agent and create a bean, iterate on it, question its design, scope, and purpose. Once you feel like it‚Äôs done, move on.\nLet the planning agent write the outline and implementation details in the bean. Then pass it to the coding agent and take a walk.\n\nNow the real power comes from not just creating these beans and passing them to a coding agent. It‚Äôs in the dependency graph.\nBeyond just the blockedBy, it‚Äôs the parent/child relationships between milestones, epics, features, tasks, and bugs.\nAnd taking advantage of that structure in a ralph loop. Learn more about ralph loops here. As I‚Äôve been experimenting, I‚Äôve noticed additional ways I can modify my loop and make it better.\nThe original ralph loop uses a <promise>DONE</promise> signal to track when the agent says it‚Äôs done.\nI rely on the bean being moved to the completed status.\n\nHere‚Äôs the flow for my ralph loop (or you can view the source code):\n\nThat‚Äôs it, it‚Äôs basically a while loop that feeds beans to an AI agent until they‚Äôre done.\n\nSo where is Daedalus now? Well it‚Äôs still a WIP. You can use the philosophy and workflow now but I am working on a tool to make this significantly easier.\nYou can check out the repo here and use the agents and skills in your OpenCode or Claude Code.\n\nI‚Äôd love to hear some feedback on what you think about this experiment.",
    "readingTime": 7,
    "keywords": [
      "claude code",
      "dependency graph",
      "specialized tools",
      "ralph loop",
      "agentic coding",
      "it‚Äôs done",
      "planning agent",
      "agents",
      "beans",
      "bean"
    ],
    "qualityScore": 1,
    "link": "https://caidan.dev/blog/2026-01-29-a-beans-based-ai-workflow/",
    "thumbnail_url": "https://caidan.dev/_astro/avatar.B7OQlREk.png?v=1769751563950",
    "created_at": "2026-01-30T06:35:16.961Z",
    "topic": "tech"
  },
  {
    "slug": "check-this-cool-website-i-found",
    "title": "Check this cool website I found",
    "description": "Discover what you're really feeling with deep AI emotion analysis",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://subtlesense.lovable.app",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/453f3352-e480-4dd3-939a-42227472f4a3/id-preview-caf1f7fb--67e4d89d-130c-4203-ac7d-ab5066c625c6.lovable.app-1769676305368.png",
    "created_at": "2026-01-30T06:35:16.380Z",
    "topic": "tech"
  },
  {
    "slug": "automation-is-inevitable-and-south-koreas-president-just-said-it-out-loud",
    "title": "Automation is inevitable, and South Korea's president just said it out loud",
    "description": "President Lee Jae Myung said Thursday that workers must adapt swiftly to the era of artificial intelligence (AI), in an apparent message to Hyundai...",
    "fullText": "President Lee Jae Myung said Thursday that workers must adapt swiftly to the era of artificial intelligence (AI), in an apparent message to Hyundai Motor's labor union, which has strongly opposed the carmaker's planned introduction of humanoid robots at production facilities.\n\n\"A labor union appears to have announced that it will stop robots from entering production sites. That may be part of its overall protest strategy,\" Lee said during a meeting with senior aides at Cheong Wa Dae.\n\n\"But once the massive wagon starts rolling, we cannot stop it,\" Lee said, likening the current situation to the past, when the introduction of steam engines triggered machine-breaking protests by laborers worried about losing jobs.\n\nLee added: \"Ultimately, society has to adapt quickly. People need to learn new skills and adjust rapidly to the new environment.\"\n\nThe president stressed the importance of preparing workers for technological change rather than resisting it, as AI-driven automation accelerates across industries. He also underscored the need for fundamental policies to prepare for extreme polarization in an AI-driven economy.\n\nWhile Lee did not name a specific labor group, his comments were widely interpreted as directed at Hyundai Motor's labor union, which recently lashed out at the carmaker's plans to deploy humanoid robots at production sites.\n\nIn a statement released earlier in the day, the union said management is seeking to materialize a so-called \"dream factory\" that operates 24 hours a day using only AI-powered robots.\n\n\"There is no place for humans anywhere in the plan,\" the union said, expressing concerns that robots would ultimately take over all jobs.\n\nThe union added that Hyundai Motor Group discussed the unmanned factory initiative, dubbed the \"DF247\" project, as a key priority at its annual Global Leaders Forum earlier this month. The project envisions fully automated facilities operating around the clock.\n\nThe union warned that such developments would eventually affect all workers in Korea, arguing that the balance between consumption and supply would be disrupted, creating a vicious cycle in the nation's economy.\n\nThe union statement came about a week after the workers voiced strong opposition to the carmaker's plan to deploy Atlas robots made by Boston Dynamics, its U.S. robotics unit, across major assembly lines in Korea and overseas.\n\nHyundai Motor has identified the Atlas robot as a key future growth engine in the emerging era of physical AI.\n\nThe company unveiled its vision at the CES 2026 tech fair earlier this month, outlining plans to mass-produce up to 30,000 humanoid robots by 2028 and gradually deploy them at its manufacturing sites, including Hyundai Motor Group Metaplant America in Georgia.",
    "readingTime": 3,
    "keywords": [
      "motor's labor",
      "production sites",
      "humanoid robots",
      "labor union",
      "hyundai motor's",
      "workers",
      "carmaker's",
      "deploy",
      "earlier",
      "adapt"
    ],
    "qualityScore": 0.9,
    "link": "https://www.koreatimes.co.kr/southkorea/politics/20260129/lee-calls-on-workers-to-swiftly-adapt-to-unavoidable-ai-robotics-era",
    "thumbnail_url": "https://newsimg.koreatimes.co.kr/2026/01/29/5b893aff-d3a5-47fd-a821-746af8b87669.jpg",
    "created_at": "2026-01-30T06:35:15.219Z",
    "topic": "politic"
  },
  {
    "slug": "microsofts-440-billion-wipeout-and-investors-angry-about-openais-debt-explained",
    "title": "Microsoft‚Äôs $440 billion wipeout, and investors angry about OpenAI‚Äôs debt, explained",
    "description": "Microsoft‚Äôs stock has plummeted 12% owing to a slight miss on revenue, showing how spooked investors are by the ‚Äúspend now, profit later‚Äù AI market.",
    "fullText": "Wall Street‚Äôs yearslong bet on AI is facing a severe test on Thursday, as investors might begin to view OpenAI‚Äîand generative AI in general‚Äînot as a catalyst for continuous growth, but as a source of systemic risk for Big Tech.\n\nA sharp selloff in tech stocks on Thursday underscored investors‚Äô exhaustion with the ‚Äúspend now, profit later‚Äù model that has propelled the AI bull market for three years. Microsoft led the retreat, with its shares plummeting 12% by noon, erasing more than $440 billion in market value, a collapse it hasn‚Äôt seen since the pandemic. The Nasdaq was down almost 2% at time of writing.\n\nWhy did Microsoft's stock plunge 12% on Thursday?\n\nWhy are Oracle shares down from September highs?\n\nHow much of Microsoft's future revenue depends on OpenAI?\n\nWhat is driving investor concerns about AI capex spending?\n\nThe immediate catalyst, it seems, is an intensifying focus on capex, or capital expenditures. Microsoft revealed that its spending surged 66% to $37.5 billion in the latest quarter, even as growth in its Azure cloud business cooled slightly. Even more concerning to analysts, however, was a new disclosure that approximately 45% of the company‚Äôs $625 billion in remaining performance obligations (RPO)‚Äîa key measure of future cloud contracts‚Äîis tied directly to OpenAI, the company revealed after reporting earnings Wednesday afternoon. (Microsoft is both a major investor in and a provider of cloud-computing services to OpenAI.)\n\n‚ÄúIt‚Äôs the collapse of software and the ascent of hardware, and it is staggering,‚Äù CNBC‚Äôs Jim Cramer noted on X on Thursday, as the market punished companies that are spending billions on software infrastructure while failing to show immediate returns.\n\nIt‚Äôs an ‚Äúominous‚Äù statistic, Morning Brew cofounder Austin Rief wrote on X, especially combined with the fact that Meta is planning to devote most of their free cash flow to capex. Meta has evaded the selloff on a stronger-than-expected revenue forecast, showing a healthy 24% year-over-year revenue increase, driven by online ads. The fact that Wall Street is letting Meta get away with their also massive capex indicates the reason why investors are selling off: They don‚Äôt trust OpenAI to bring that revenue on their own without massive infusions of outside cash.\n\nThe sentiment shift is not limited to Redmond. Oracle has seen its shares halved from their September highs, erasing nearly $463 billion in value. Once a darling of the AI trade, Oracle has also struggled with investor confidence that the massive data centers it is building for OpenAI will get funded eventually. Additionally, the timeline for several projects has reportedly slipped to 2028, creating a gap between the company‚Äôs heavy debt-funded spending and the arrival of actual revenue.\n\nOpenAI has made about $1.4 trillion in commitments to procure both the energy and compute it needs to fuel its operations. But its revenue barely crossed $20 billion in 2025.",
    "readingTime": 3,
    "keywords": [
      "september highs",
      "revenue",
      "capex",
      "investors",
      "market",
      "microsoft",
      "shares",
      "investor",
      "meta",
      "massive"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-440-billion-wipeout-investors-175614975.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/jYq9kyGPPwVZhXQoi926UQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/db5e36eb9ca7373a69fddcfa683aace0",
    "created_at": "2026-01-30T06:35:12.676Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musks-spacex-said-to-consider-merger-with-tesla-bloomberg-news-reports",
    "title": "Elon Musk's SpaceX said to consider merger with Tesla, Bloomberg News reports",
    "description": "Elon Musk's SpaceX is considering a potential merger with ‚ÄãTesla as well as an ‚Äåalternative combination with artificial-intelligence company xAI, Bloomberg News ‚Äåreported on Thursday, citing people familiar with the matter.  Tesla's shares were up 3% after the bell following the report.  SpaceX ‚Å†and xAI are ‚Äåin discussions to merge ahead of a blockbuster public offering ‚Äçplanned for later this year, Reuters exclusively reported earlier on Thursday, to bring Musk's ‚Äãrockets, Starlink satellites, the X social ‚Äåmedia platform and Grok AI chatbot under one roof.",
    "fullText": "Jan 29 (Reuters) - Elon Musk's SpaceX is considering a potential merger with ‚ÄãTesla as well as an ‚Äåalternative combination with artificial-intelligence company xAI, Bloomberg News ‚Äåreported on Thursday, citing people familiar with the matter.\n\nTesla's shares were up 3% after the bell following the report.\n\nWhat are the potential SpaceX merger scenarios?\n\nWhat companies would be combined under one roof?\n\nHow did Tesla's stock react to merger reports?\n\nWhich investors are interested in these potential deals?\n\nSpaceX ‚Å†and xAI are ‚Äåin discussions to merge ahead of a blockbuster public offering ‚Äçplanned for later this year, Reuters exclusively reported earlier on Thursday, to bring Musk's ‚Äãrockets, Starlink satellites, the X social ‚Äåmedia platform and Grok AI chatbot under one roof.\n\nThe space firm has discussed the feasibility of a tie-up between SpaceX and EV-maker Tesla, an idea ‚Å†that some investors are ‚Äãpushing, the Bloomberg report ‚Äãsaid.\n\nAny deal could attract sizeable interest from infrastructure funds and Middle ‚ÄçEastern sovereign ‚Å†investors, some of the people told Bloomberg.\n\nSpaceX and Tesla did not immediately ‚Å†respond to Reuters requests for comment.",
    "readingTime": 1,
    "keywords": [
      "reuters",
      "potential",
      "merger",
      "investors",
      "musk's",
      "tesla's",
      "roof",
      "spacex",
      "tesla",
      "bloomberg"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/elon-musks-spacex-said-consider-224603248.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/1544e7d59d3e13f63bd966ad28000ab4",
    "created_at": "2026-01-30T06:35:12.616Z",
    "topic": "finance"
  },
  {
    "slug": "suttons-predictions-v-boxer-francesca-hennessy",
    "title": "Sutton's predictions v boxer Francesca Hennessy",
    "description": "BBC Sport football expert Chris Sutton takes on boxer Francesca Hennessy and AI with his predictions for this week's Premier League fixtures.",
    "fullText": "Tottenham may have coasted through to the Champions League last 16, but their Premier League form remains a problem for boss Thomas Frank.\n\n\"I was at their draw with Burnley last week and there are a lot of angry Spurs fans out there,\" said BBC Sport football expert Chris Sutton.\n\n\"Their domestic results are such a contrast to their record in Europe, and it could be another difficult afternoon for Frank when they face Manchester City on Sunday.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nHis guest for week 24 is boxer Francesca Hennessy, who supports Chelsea.\n\nHennessy faces Ellie Bouttell in a WBC title eliminator on Saturday, live on BBC Two from 20:00 GMT.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 1,
    "keywords": [
      "premier league",
      "draw",
      "predictions",
      "points",
      "frank",
      "sport",
      "sutton",
      "hennessy"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/cx204g4rn8xo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/b2d0/live/3345b7f0-fd30-11f0-a8b8-bdd2c5f9bcad.png",
    "created_at": "2026-01-30T06:35:12.335Z",
    "topic": "sports"
  },
  {
    "slug": "zuckerberg-says-ai-is-letting-one-employee-do-the-work-of-entire-teams-and-it-shows-how-the-company-is-rethinking-hiring",
    "title": "Zuckerberg says AI is letting one employee do the work of entire teams, and it shows how the company is rethinking hiring",
    "description": "The tech giant is doubling down on a trend of companies operating with leaner workforces, though it's still on the hunt for rockstar talent.",
    "fullText": "CEO Mark Zuckerberg said AI tools now let individual Meta employees do work that once required large teams.\n\nMeta plans to boost AI spending by between 60% and 87% this year as output per engineer continues to rise.\n\nDespite compute constraints, Meta said it's looking to hire top AI talent.\n\nMeta CEO Mark Zuckerberg says AI is transforming what a single employee can accomplish at the company, signaling it's adopting a new hiring strategy.\n\nOn an earnings call with analysts Thursday, Meta boss Mark Zuckerberg said the company is investing in more AI-native tools to elevate individual contributors and flatten teams. The effort is being somewhat constrained, however, by a lack of compute resources.\n\n\"We're starting to see projects that used to require big teams now be accomplished by a single very talented person,\" he said. \"I want to make sure that as many of these very talented people as possible choose Meta as the place that they can make the greatest impact.\"\n\nThe Facebook and Instagram parent, which reported fourth-quarter revenue and earnings that exceeded Wall Street's expectations, said it plans to boost AI spending by between 60% and 87% this year. Meta also said it already saw a significant increase in output per engineer last year, with the majority of that growth coming from the adoption of agentic coding.\n\nThough teams are on track to become smaller, finance chief Susan Li said on the earnings call that the company is still hungry for top talent. \"It remains a very competitive hiring market, but we'd like to invest aggressively where we can,\" she said.\n\nLi also noted that Meta closed out the December-ended quarter with 6% more employees than it had a year earlier, driven by hiring in areas such as monetization, infrastructure, Meta Superintelligence Labs, regulation, and compliance.\n\nMeta isn't alone in focusing on tiny teams. The strategy has become popular in the startup world, where founders have long prioritized scrappiness. It's a trend that OpenAI CEO Sam Altman predicted would take hold back in February 2024.\n\n\"We're going to see 10-person companies with billion-dollar valuations pretty soon,\" he said at the time. \"In my little group chat with my tech CEO friends, there's this betting pool for the first year there is a one-person billion-dollar company, which would've been unimaginable without AI. And now [it] will happen.\"\n\nMeanwhile, large companies have been thinning their middle manager ranks in recent years to boost efficiency by reducing bureaucracy, including Amazon and Intel. Meta's Zuckerberg wrote a memo in 2023 entitled \"Flatter is faster,\" and in late 2024, Google CEO Sundar Pichai told staff that the company cut vice president and manager roles by 10% as part of an efficiency push.",
    "readingTime": 3,
    "keywords": [
      "ceo mark",
      "output per",
      "per engineer",
      "teams",
      "meta",
      "boost",
      "it's",
      "hiring",
      "earnings",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/meta-boss-says-ai-letting-183328865.html",
    "thumbnail_url": "https://s.yimg.com/os/en/business_insider_consolidated_articles_886/2d49eb409d05840f67e613b16f7304ea",
    "created_at": "2026-01-30T06:35:12.101Z",
    "topic": "finance"
  },
  {
    "slug": "cwt-sandbox-ai-coding-agents-using-git-worktrees",
    "title": "Cwt ‚Äì Sandbox AI coding agents using Git Worktrees",
    "description": "Contribute to benngarcia/claude-worktree development by creating an account on GitHub.",
    "fullText": "benngarcia\n\n /\n\n claude-worktree\n\n Public\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n benngarcia/claude-worktree",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/benngarcia/claude-worktree",
    "thumbnail_url": "https://opengraph.githubassets.com/73752eaadbf154afd745270d32c1743038163f0555993f4c462cecd915f63c02/benngarcia/claude-worktree",
    "created_at": "2026-01-30T01:07:08.980Z",
    "topic": "tech"
  },
  {
    "slug": "zuckerberg-says-ai-is-letting-one-employee-do-the-work-of-entire-teams-and-it-shows-how-the-company-is-rethinking-hiring",
    "title": "Zuckerberg says AI is letting one employee do the work of entire teams, and it shows how the company is rethinking hiring",
    "description": "The tech giant is doubling down on a trend of companies operating with leaner workforces, though it's still on the hunt for rockstar talent.",
    "fullText": "Meta CEO Mark Zuckerberg says AI is transforming what a single employee can accomplish at the company, signaling it's adopting a new hiring strategy.\n\nOn an earnings call with analysts Thursday, Meta boss Mark Zuckerberg said the company is investing in more AI-native tools to elevate individual contributors and flatten teams. The effort is being somewhat constrained, however, by a lack of compute resources.\n\n\"We're starting to see projects that used to require big teams now be accomplished by a single very talented person,\" he said. \"I want to make sure that as many of these very talented people as possible choose Meta as the place that they can make the greatest impact.\"\n\nThe Facebook and Instagram parent, which reported fourth-quarter revenue and earnings that exceeded Wall Street's expectations, said it plans to boost AI spending by between 60% and 87% this year. Meta also said it already saw a significant increase in output per engineer last year, with the majority of that growth coming from the adoption of agentic coding.\n\nThough teams are on track to become smaller, finance chief Susan Li said on the earnings call that the company is still hungry for top talent. \"It remains a very competitive hiring market, but we'd like to invest aggressively where we can,\" she said.\n\nLi also noted that Meta closed out the December-ended quarter with 6% more employees than it had a year earlier, driven by hiring in areas such as monetization, infrastructure, Meta Superintelligence Labs, regulation, and compliance.\n\nMeta isn't alone in focusing on tiny teams. The strategy has become popular in the startup world, where founders have long prioritized scrappiness. It's a trend that OpenAI CEO Sam Altman predicted would take hold back in February 2024.\n\n\"We're going to see 10-person companies with billion-dollar valuations pretty soon,\" he said at the time. \"In my little group chat with my tech CEO friends, there's this betting pool for the first year there is a one-person billion-dollar company, which would've been unimaginable without AI. And now [it] will happen.\"\n\nMeanwhile, large companies have been thinning their middle manager ranks in recent years to boost efficiency by reducing bureaucracy, including Amazon and Intel. Meta's Zuckerberg wrote a memo in 2023 entitled \"Flatter is faster,\" and in late 2024, Google CEO Sundar Pichai told staff that the company cut vice president and manager roles by 10% as part of an efficiency push.\n\nThe trend isn't limited to tech companies. Retailers such as Walmart and Wayfair, and fintech firms like Block, have been moving managers into non-management roles. Some companies have also been conducting multiple rounds of mass layoffs. On Wednesday, Amazon said it would cut 16,000 corporate roles, the company's second round of layoffs in four months.\n\nOn Meta's earnings call, the company acknowledged that its goal of being able to lean on a smaller number of highly AI-savvy employees is challenged by a shortage of compute resources, as demand across the company has increased faster than its supply. Still, Zuckerberg expressed confidence in his outlook for greater efficiencies.\n\n\"I think that 2026 is going to be the year that AI starts to dramatically change the way that we work,\" he said. \"As we navigate this, our North Star is building the best place for individuals to make a massive impact.\"",
    "readingTime": 3,
    "keywords": [
      "compute resources",
      "earnings",
      "teams",
      "hiring",
      "roles",
      "meta",
      "it's",
      "strategy",
      "talented",
      "impact"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-says-ai-letting-one-employee-do-work-of-teams-2026-1",
    "thumbnail_url": "https://i.insider.com/697b9f47a645d118818840ab?width=800&format=jpeg",
    "created_at": "2026-01-30T01:07:07.110Z",
    "topic": "finance"
  },
  {
    "slug": "slowing-cloud-growth-and-huge-ai-spending-why-microsofts-stock-is-plunging-the-most-in-nearly-6-years",
    "title": "Slowing cloud growth and huge AI spending: Why Microsoft's stock is plunging the most in nearly 6 years",
    "description": "Shares dropped the most since March 2020 on Thursday, with investors fleeing the stock amid slower cloud growth and big spending on AI.",
    "fullText": "Microsoft stock is getting crushed on Thursday.\n\nThe negative post-earnings reaction stems from investors' dismay over weaker-than-expected guidance in a key business area, alongside larger-than-expected spending on AI.\n\nMicrosoft earnings came in above both top and bottom line forecasts, with cloud revenue reaching $50 billion for the first time, but Microsoft stock still plunged 12%, its biggest decline since March 2020.\n\nWall Street analysts were laser-focused on AI spending heading into earnings, and the market's reaction to Microsoft and Meta's results shows that investors need to see strength elsewhere in the business to feel good about surging capex. Meta shares spiked on Thursday, and although its spending outlook jumped, that was offset by robust advertising business.\n\nMicrosoft's Azure cloud platform revenue grew 39% on an annual basis, coming in above the forecast 38.4% but still below the 40% it posted in the previous quarter. According to finance pros, this is the primary factor driving Microsoft stock down.\n\n\"Microsoft allocated scarce GPU capacity away from Azure to 1P products, but the fact that BOTH Azure and the M365 segments fell a bit short is the key negative we're hearing that is driving the modest after-market fade,\" stated UBS analyst Karl Keirstead.\n\nOther Wall Street analysts think Microsoft could face challenges in the coming months if it can't find a way to boost its cloud revenue and win back Wall Street's confidence.\n\n\"I think sentiment around Microsoft is kind of negative right now. And if they don't really beat or re-accelerate Azure growth, the shares are probably not going to perform very well,\" Ryuta Makino of Gabelli Funds said.\n\nTech guru and University of Michigan professor Erik Gordon pointed to Microsoft's excessive spending as a catalyst for the stock's decline, noting that he sees it as a clear indication of a bubble in AI.\n\nTo get back to where it needs to be, though, Microsoft may need to spend even more. Blake Crawford, CIO of tech consulting firm Fusion Collective, raised the concern that much of its growth prospects hinge on the success of OpenAI.\n\n\"The number that sticks out like a sore thumb: remaining commercial obligations are up 110% to $625 billion, and OpenAI is a whopping 45% of that,\" he stated. \"That's a lot of hope-and-a-prayer that OpenAI will be able to deliver. And recognizing any potential upside will require significant capex.\"",
    "readingTime": 2,
    "keywords": [
      "street analysts",
      "wall street",
      "microsoft stock",
      "cloud revenue",
      "negative",
      "business",
      "reaction",
      "investors",
      "earnings",
      "decline"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-stock-down-q4-earnings-ai-spending-azure-cloud-tech-2026-1",
    "thumbnail_url": "https://i.insider.com/697b8c12a645d11881883dc4?width=1200&format=jpeg",
    "created_at": "2026-01-30T01:07:07.021Z",
    "topic": "finance"
  },
  {
    "slug": "data-centers-are-powering-blackstones-13-trillion-investment-empire",
    "title": "Data centers are powering Blackstone's $1.3 trillion investment empire",
    "description": "Blackstone sees major returns from its data center bet, and plans to continue to \"lean into\" the AI boom.",
    "fullText": "Data center investments have become the engine of Blackstone's growth.\n\nThe Wall Street investment giant reported that QTS, the data center developer and operator it took private in 2021, was the single largest driver of gains in the company's $1.3 trillion portfolio in 2025. The results were a clear sign that Blackstone's bets on digital infrastructure amid the artificial intelligence boom have reaped returns as other segments of its business, including real estate and private credit, have run into headwinds.\n\nIn a call on Wednesday to discuss Blackstone's year-end performance, Stephen Schwarzman, the firm's co-founder and chairman, called QTS now \"the world's largest data center platform.\"\n\nJon Gray, the company's president, said that investor interest in AI was a chief driver of strong inflows. The company reported $239 billion of inflows for the year, its highest total since a record year in 2021.\n\n\"You have what's happening in the AI world, economy growing faster, productivity picking up, and us investing in sectors we really like,\" Gray said. \"We think that will really get this flywheel going, which is why you hear this optimism.\"\n\nGray said its bets on AI and data centers had delivered for the company. Its infrastructure platform ‚Äî powered by data center appreciation ‚Äî had grown 40% during the year to $77 billion and had raised $4 billion from investors in the fourth quarter. Infrastructure investments earned 8.4% returns for the quarter and 23.5% for the year.\n\nBlackstone Real Estate Income Trust, the firm's $54 billion retail focused real estate investment fund, meanwhile, generated 8.1% returns during the year, more than double its benchmark for the sector. The fund, which is known as BREIT, is heavily invested in QTS.\n\nReal estate investments, broadly, were the weakest segment for Blackstone, delivering a 0.6% loss for its opportunistic strategy and 3% gains for its core assets.\n\nQTS, which Blackstone originally bought for $10 billion, was the \"largest single driver of returns\" for its infrastructure strategy, Blackstone Infrastructure Partners, as well as in real estate,\" Gray said.\n\nSchwarzman said the firm would continue to \"lean into key thematic areas such as digital infrastructure, including data centers, power, and electrification, private credit,\" as part of its broader investment strategy.\n\n\"The historic pace of investment taking place in the US to facilitate the development of artificial intelligence, including the design and manufacture of semiconductors, data center construction, and the expansion of power generation, is the key driver of economic growth today,\" Schwarzman said.\n\nGray added that the firm's $319 billion real estate platform would \"continue to invest in AI infrastructure and data centers.\"\n\nIn private lending, Gray said the artificial intelligence race and the hundreds of billions of dollars in related spending it will require would also feed the company's private credit business.\n\n\"The build-out of AI infrastructure requires a massive amount of private debt capital for the construction of fabs, energy supply, and data centers,\" Gray said. Fabs refer to computer chip manufacturing facilities.\n\nGray reported that Blackstone's investment grade private credit portfolio now totaled $130 billion, an increase of 30% during the year, while also acknowledging that BCRED, one of its largest credit fund had an \"uptick in redemptions\" tied to industry-wide concerns about default risks.\n\nBlackstone has long touted its focus on data centers.\n\nIn addition to QTS, the firm has invested in the AI developers Anthropic and OpenAI, the storage and high performance computing provider DDN, as well as energy providers who will deliver the prodigious electricity needed for AI computing. Last year, the firm, for instance, announced its $11.5 billion acquisition of TXNM Energy, a utility holding company. In 2024, the company was part of a group of investors that provided the data center operator CoreWeave with a $7.5 billion loan.\n\nBlackstone reported $14.5 billion of revenue for the year and $4.4 billion for the quarter, up 9% and 42% respectively.",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "digital infrastructure",
      "center",
      "estate",
      "investment",
      "credit",
      "centers",
      "blackstone's",
      "largest",
      "driver"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-blackstone-qts-data-center-bets-are-driving-growth-2026-1",
    "thumbnail_url": "https://i.insider.com/697ba48ba645d11881884188?width=1200&format=jpeg",
    "created_at": "2026-01-30T01:07:06.905Z",
    "topic": "finance"
  },
  {
    "slug": "darren-aronofskys-new-ai-series-about-the-revolutionary-war-looks-like-dogshit",
    "title": "Darren Aronofsky's New AI Series About the Revolutionary War Looks Like Dogshit",
    "description": "\"Used to be that when Darren Aronofsky wanted to feature a dead-eyed actor, he'd just employ Jared Leto.\"",
    "fullText": "Darren Aronofsky used to be a director who made interesting, if sometimes polarizing, films like Black Swan, Mother!, Noah, and The Wrestler. But it seems like a safe bet that people won‚Äôt need to debate whether Aronofsky‚Äôs new project is any good. Because anyone with eyes can see that it looks like low-effort AI slop. To put it another way, it looks like absolute dogshit.\n\nAronofsky is producing a new short-form series with his AI production company Primordial Soup titled ‚ÄúOn This Day‚Ä¶ 1776,‚Äù according to the Hollywood Reporter. The series uses tech from Google DeepMind to create short videos about the Revolutionary War, published on the YouTube channel for Time magazine. In 2018, Salesforce founder Marc Benioff bought Time, and the cloud software giant is sponsoring this monstrosity of a series.\n\nThe series uses human voice actors who belong to the Screen Actors Guild (SAG), which is clearly an attempt to tamp down on the inevitable backlash from both inside and outside Hollywood. Folks inside the movie and TV industry have fiercely pushed back against the use of AI to replace the skilled artists and actors who create the media we watch. That concern obviously comes from a place of self-interest because nobody wants to be pushed out of a job. But they also care about the quality of the work being produced. And there‚Äôs also been a revolt among the average consumer, people who‚Äôve been inundated with the lowest-grade AI garbage imaginable. It‚Äôs really everywhere now.\n\nThe first episode, titled ‚ÄúThe Flag,‚Äù is three-and-a-half minutes long and attempts to tell the story of George Washington raising the Continental Union Flag in Somerville, Massachusetts. It offers nothing compelling in the way of narrative. It‚Äôs the kind of thing that you‚Äôd skip over as a cut-scene in a particularly bad video game.\n\nEverything has a dead and creepy quality, as the actors‚Äô audio is poorly synced with the lips of the AI concoctions.\n\nHave you ever seen a Spaghetti Western from the 1960s where the audio just doesn‚Äôt seem to match, even though it was clearly shot with actors speaking English, and the ‚Äúdub‚Äù is in English? That happened because the audio was added in post-production, a result of direct sound recording being expensive in Italy during the post-war era. You get the same effect here, though there‚Äôs no good reason. Well, no good reason outside of presumably saving a ton of money on hiring human actors.\n\nThe second episode, titled ‚ÄúCommon Sense,‚Äù tries to tell the story of Thomas Paine writing Common Sense. Benjamin Franklin makes an appearance, though it proves that the most recognizable of the founding fathers in this series are the weirdest to look at.\n\nThe episode jumps around incoherently, much like the first episode, without grounding the viewer in anything we should care about. It‚Äôs truly an ugly mess. And if you bother to pause the scenes, you can spot the kind of telltale anomalies that plague other AI-generated video projects, like strangely deformed hands in the background characters. Hands are always giving this stuff away.\n\nThen there are the words that appear on screen in the trailer, like the pamphlet that‚Äôs supposed to include the word ‚ÄúAmerica‚Äù but instead reads something closer to ‚ÄúŒõamereedd.‚Äù\n\nHappy to see that there is no need to worry about the historical accuracy of new 1776 AI slop because it happens in the mystical land of Œõamereedd.\n\n‚Äî Mateusz Fafinski (@calthalas.bsky.social) January 29, 2026 at 1:33 PM\n\nThe series is specifically made for this sestercentennial year of America‚Äôs founding, and each episode will reportedly drop on the 250th anniversary of the day it happened, according to the Hollywood Reporter. And that‚Äôs certainly a fun concept if the final product were something worth watching. But it‚Äôs not. It‚Äôs garbage. The people who are making and distributing it obviously don‚Äôt think so.\n\n‚ÄúThis project is a glimpse at what thoughtful, creative, artist-led use of AI can look like ‚Äî not replacing craft, but expanding what‚Äôs possible and allowing storytellers to go places they simply couldn‚Äôt before,‚Äù Ben Bitonti, president of Time Studios, told the Hollywood Reporter.\n\nThe reaction on social media hasn‚Äôt been so kind. ‚ÄúI know my expectations were low but holy fuck Darren Aronofsky producing AI slop wasn‚Äôt on my bingo card,‚Äù one X user wrote. Over on Bluesky another joked, ‚ÄúUsed to be that when Darren Aronofsky wanted to feature a dead-eyed actor, he‚Äôd just employ Jared Leto.‚Äù\n\nAnd other users have been picking apart all the anomalies, with one Bluesky critic writing: ‚ÄúLove the new Aronofsky scene where the colonist takes off his hat to cheer, revealing that underneath it was a second and somehow larger hat.‚Äù\n\nLove the new Aronofsky scene where the colonist takes off his hat to cheer, revealing that underneath it was a second and somehow larger hat\n Masterful artsistic choice\n\n‚Äî Matt Baume üè≥Ô∏è‚Äçüåà (@mattbaume.bsky.social) January 29, 2026 at 10:35 AM\n\n‚ÄúNothing represents The End of America after a 250-year run quite like using AI slop to depict the creation of the Declaration of Independence,‚Äù another user quipped.\n\nThe videos have been up at Time‚Äôs YouTube channel for over 7 hours as of the time of this writing, but they‚Äôre not gaining much attention in their original format. The first episode has just 5,000 views. The second episode has a little over 2,000. Social media posts ridiculing the production seem to be faring better, simply because people are making fun of them. One video on Bluesky has over 2,500 quote posts, with almost all seemingly making jokes about how awful it looks.\n\nGizmodo reached out to Ken Burns for comment, but didn‚Äôt immediately receive a reply.",
    "readingTime": 5,
    "keywords": [
      "youtube channel",
      "hollywood reporter",
      "aronofsky scene",
      "cheer revealing",
      "somehow larger",
      "social media",
      "larger hat",
      "episode titled",
      "second episode",
      "darren aronofsky"
    ],
    "qualityScore": 1,
    "link": "https://gizmodo.com/darren-aronofskys-new-ai-series-about-the-revolutionary-war-looks-like-dogshit-2000715754",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2026/01/ai-benjamin-franklin-1200x675.jpg",
    "created_at": "2026-01-30T01:07:06.697Z",
    "topic": "tech"
  },
  {
    "slug": "musks-spacex-in-merger-talks-with-xai-ahead-of-planned-ipo-source-says",
    "title": "Musk's SpaceX in merger talks with xAI ahead of planned IPO, source says",
    "description": "Elon Musk's SpaceX and xAI are in discussions to merge ahead of a blockbuster public offering planned for later this year.  The combination would bring Musk‚Äôs rockets, Starlink satellites, the X social media platform and Grok AI chatbot under one roof, according to a person briefed on the matter and two ‚Äãrecent company filings seen by Reuters.  The plan, which Reuters is reporting exclusively, would give fresh momentum to SpaceX‚Äôs effort to launch data centers into orbit as Musk battles for supremacy in the rapidly ‚Äåescalating AI race against tech giants like Google, Meta and OpenAI.",
    "fullText": "NEW YORK, Jan 29 (Reuters) - Elon Musk's SpaceX and xAI are in discussions to merge ahead of a blockbuster public offering planned for later this year. The combination would bring Musk‚Äôs rockets, Starlink satellites, the X social media platform and Grok AI chatbot under one roof, according to a person briefed on the matter and two ‚Äãrecent company filings seen by Reuters.\n\nHow could space-based data centers reduce AI costs?\n\nWhat would the proposed SpaceX-xAI merger involve?\n\nWhat defense applications are planned for merged companies?\n\nWhy is Musk combining his different business ventures?\n\nThe plan, which Reuters is reporting exclusively, would give fresh momentum to SpaceX‚Äôs effort to launch data centers into orbit as Musk battles for supremacy in the rapidly ‚Äåescalating AI race against tech giants like Google, Meta and OpenAI.\n\nMusk, the world's richest man, is the CEO of both the private space company SpaceX and the artificial intelligence company xAI, which controls his social media platform X. He also runs electric automaker Tesla, tunnel ‚Äåcompany The Boring Co. and neurotechnology company Neuralink.\n\nMusk, SpaceX, and xAI did not respond to requests for comment.\n\nUnder the proposed merger, shares of xAI would be exchanged for shares in SpaceX. Two entities have been set up in Nevada to facilitate the transaction, the person said.\n\nCorporate filings in Nevada show that those entities were set up on January 21. One of them, a limited liability company, lists SpaceX and Bret Johnsen, the company's chief financial officer, as managing members, while the other lists Johnsen as the company's only officer, the filings show.\n\nThe filings don't contain additional information about the purpose of the companies ‚Å†or their role in any deal.\n\nJohnsen did not respond to a Reuters ‚Äårequest for comment.\n\nThe person, who requested anonymity because the discussions are confidential, said that some xAI executives could be given the option to receive cash instead of SpaceX stock as part of the deal. A final agreement, however, hasn't been signed, and the timing and structure of the transaction remain fluid, the person cautioned.\n\nSpaceX is already the world's most ‚Äçvaluable privately held company, last valued at $800 billion in a recent insider share sale. xAI was valued at $230 billion in November, according to the Wall Street Journal. Reuters and other media have reported that SpaceX plans to go public some time this year, with a valuation expected above $1 trillion.\n\nThrough xAI, Musk is building out a massive supercomputer for AI training in Memphis, Tennessee, called Colossus. Last year, SpaceX agreed to invest $2 billion in xAI as part of the startup‚Äôs $5 billion equity ‚Äãfundraising, the Wall Street Journal reported at the time.",
    "readingTime": 3,
    "keywords": [
      "wall street",
      "street journal",
      "social media",
      "media platform",
      "filings",
      "spacex",
      "discussions",
      "planned",
      "centers",
      "proposed"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-musks-spacex-merger-talks-184045612.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/ba612911adcb7fd2bc8d339cecd0cb55",
    "created_at": "2026-01-30T01:07:05.794Z",
    "topic": "finance"
  },
  {
    "slug": "how-youtube-is-fighting-back-against-ai-slop",
    "title": "How YouTube Is Fighting Back Against AI Slop",
    "description": "If you're noticing less AI in your feeds, that's by design.",
    "fullText": "Science fiction and science leaders alike have warned us that artificial intelligence may one day take over the world, but until those predictions come to pass, generative AI's biggest impact on my life has been overloading my social media feeds with slop. It seems I can't open TikTok, Instagram, or YouTube without running smack into bizarre and troubling AI concoctions featuring babies in danger and cats having affairs. It really is the wild west (or maybe Westworld) out there.\n\nI think few among us really believe these videos are any good, and it's pretty obvious they aren't good for us, or for the world. Short-form video is already numbing enough, but this AI content is generally completely devoid of any meaning or substance. And yet, it's everywhere. I haven't spent too much time on YouTube Shorts recently, but in my limited experience, the feed has been chock full of AI, especially if I'm logged out of my personal account.\n\nStill, if you're a dedicated YouTube Shorts user (or a frequent YouTube user in general) you might have noticed something odd in recent days: There don't seem to be quite as many AI videos on the platform right now. There are still a lot, don't get me wrong, but it turns out YouTube has recently taken action to remove some of its AI content‚Äîthe sloppiest of the slop.\n\nAndroid Police spotted the development on Wednesday, basing its findings on a November report from Kapwing, a company that develops an online video editor. Kapwing investigated AI slop across YouTube's vast content library, noting the top 100 most-subscribed YouTube channels that publish this sort of AI content. In the two months since that report, Android Police noticed that 16 of those 100 channels are no longer with us.\n\nThat includes the most popular AI channel on YouTube, at least according to Kapwing. \"CuentosFacianantes\" had 5.95 million subscribers at the time of their initial report, and produced AI-generated shorts inspired¬†by Dragon Ball. The channel had amassed roughly 1.28 billion views by the end of last year; despite launching in 2020, it had curated its library to begin Jan. 8, 2025, so those numbers were racked up pretty recently. The number two channel, \"Imperio de Jesus\" with 5.87 million subscribers, and the number seven channel \"Super Cat League,\" with 4.21 million subscribers, were also shut down.\n\nAccording to Android Police, the 16 channels in question had a total of 35 million subscribers and over 4.7 billion views across their collective videos. Some of these channels are completely gone, while others simply have had their videos removed.\n\nYouTube CEO Neal Mohan published a post on Jan. 21 of this year describing the company's vision for 2026. Towards the end of that letter, he acknowledges AI content, predicting that, \"AI will be a boon to the creatives who are ready to lean in,\" and comparing it to tools like Photoshop and CGI, adding \"AI will remain a tool for expression, not a replacement.\" However, Mohan was also critical of the technology, noting that it's becoming more difficult to tell real videos from AI. He notes that YouTube is now removing \"any harmful synthetic media that violates our Community Guidelines,\" and is giving creators tools to help identify and block deepfakes.\n\nMore interestingly, the letter includes a section labeled \"Managing AI slop,\" which is the first time I've seen a company like YouTube use that expression. Mohan says that YouTube's goal is to be a place where free expression thrives, but also a place \"where people feel good spending their time.\" To that point, he says, \"To reduce the spread of low quality AI content, we‚Äôre actively building on our established systems that have been very successful in combatting spam and clickbait, and reducing the spread of low quality, repetitive content.\"\n\nMohan doesn't call out any accounts by name, nor does he acknowledge the accounts and content the company has already deleted, but it's a clear line in the sand: YouTube is not against AI-generated content, but it will remove low-quality AI content it feels is, well, slop. That's good news for anyone who uses YouTube (so, pretty much everyone), even if it's far from a cure for the growing problem.\n\nI've reached out to YouTube for comment on this story, and will update this piece if I hear back.",
    "readingTime": 4,
    "keywords": [
      "android police",
      "youtube shorts",
      "content",
      "slop",
      "videos",
      "it's",
      "channels",
      "channel",
      "subscribers",
      "pretty"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/youtube-fighting-back-against-ai-slop?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KG5RS2KTV09PK5XV3N14BAA3/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-30T01:07:04.845Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-microsoft-amazon-in-talks-to-invest-up-to-60-billion-in-openai-the-information-reports",
    "title": "Nvidia, Microsoft, Amazon in talks to invest up to $60 billion in OpenAI, The Information reports",
    "description": "Nvidia, Amazon, and Microsoft are in talks to invest up to $60 billion in OpenAI, ‚ÄãThe Information reported on Wednesday.  Nvidia, an existing investor ‚Äåwhose chips power OpenAI's AI models, is in talks to invest up ‚Äåto $30 billion, The Information said, citing a person with knowledge of the situation.  Microsoft, a longstanding backer, is in talks to invest less than $10 billion, the report said.",
    "fullText": "Jan 28 (Reuters) - Nvidia (NVDA), Amazon (AMZN), and Microsoft (MSFT) are in talks to invest up to $60 billion in OpenAI, ‚ÄãThe Information reported on Wednesday.\n\nNvidia, an existing investor ‚Äåwhose chips power OpenAI's AI models, is in talks to invest up ‚Äåto $30 billion, The Information said, citing a person with knowledge of the situation.\n\nMicrosoft, a longstanding backer, is in talks to invest less than $10 billion, the report said. It added ‚Å†that Amazon, which would ‚Äåbe a new investor, is in discussions to invest significantly more than $10 billion, potentially even ‚Äçmore than $20 billion.\n\nOpenAI is close to receiving term sheets, or an investment commitment, from these firms, the report said.\n\nAmazon and Microsoft ‚Äãdeclined to comment, while Nvidia and OpenAI did not ‚Äåimmediately respond to Reuters' requests for comment outside regular business hours.\n\nWhat additional agreements might influence Amazon's investment decision?\n\nWhat companies are reportedly investing in OpenAI's funding round?\n\nWhy is OpenAI seeking such significant new investment?\n\nWhat companies are investing in OpenAI's funding round?\n\nAmazon's investment could depend on separate negotiations, including a possible expansion of OpenAI's cloud server rental deal with Amazon and a commercial ‚Å†agreement for OpenAI to sell its ‚Äãproducts, such as enterprise ChatGPT ‚Äãsubscriptions, to Amazon, The Information said.\n\nThis follows reports from earlier this week that said that SoftBank ‚ÄçGroup is in ‚Å†talks to invest as much as an additional $30 billion in OpenAI.\n\nOpenAI is grappling with rising costs to train ‚Å†and run its AI models as competition from Alphabet's Google heats ‚Äåup.",
    "readingTime": 2,
    "keywords": [
      "amazon's investment",
      "openai's funding",
      "funding round",
      "talks",
      "openai",
      "reuters",
      "investor",
      "models",
      "additional",
      "investing"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidia-microsoft-amazon-talks-invest-030604359.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/2e608e1738d1a987d238a588fee45062",
    "created_at": "2026-01-30T01:07:04.469Z",
    "topic": "finance"
  },
  {
    "slug": "exclusivepentagon-clashes-with-anthropic-over-military-ai-use-sources-say",
    "title": "Exclusive-Pentagon clashes with Anthropic over military AI use, sources say",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/world-news/exclusivepentagon-clashes-with-anthropic-over-military-ai-use-4474548",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0S1DA_L.jpg",
    "created_at": "2026-01-30T01:07:02.705Z",
    "topic": "finance"
  },
  {
    "slug": "the-state-of-voice-ai-instruction-following-in-2026",
    "title": "The State of Voice AI Instruction Following in 2026",
    "description": "Coval is the leading simulation and evaluation platform for AI voice and chat agents. Test, monitor, and optimize your AI agents at scale.",
    "fullText": "Why are production voice agents still running on 18-month-old models? Why is instruction following the hardest problem to benchmark? And what's actually missing from voice AI evaluation today? We sat down with two of the sharpest minds in the space to find out.\n\nAs part of our State of Voice AI 2026 research, we brought together Kwindla Hultman Kramer, co-founder of Daily and creator of the open-source PipeCat framework, and Zach Koch, co-founder and CEO of Ultravox AI, which trains real-time speech-native models. The conversation that followed was one of the most candid discussions we've had about what's actually working in voice AI evaluation‚Äîand what's still broken.\n\nCheck out the full episode here:\n\nKwin recently published something the voice AI community has desperately needed: a public benchmark for instruction following and function calling in long, multi-turn conversations.\n\n\"I wanted to publish something that people could criticize and try to help make better,\" Kwin explained. \"We all have kind of tests and vibes that we do internally, but I wanted something that reflects the hard workloads in voice AI‚Äîinstruction following, function calling reliability, turn-taking reliability.\"\n\nThe benchmark simulates a real-world voice AI scenario: knowledge dumped into a system prompt, tools that need to be called, and a 30-turn conversation that tests whether the model can maintain coherent behavior deep into the dialogue.\n\nWhat surprised Kwin most? The frontier models saturated it.\n\n\"GPT-5, the latest Claude, Gemini 3‚Äîthey all saturated what I thought was a really hard benchmark. But here's the thing: they're all too slow to use for a voice agent.\"\n\nThis is the central tension in voice AI today: the smartest models are too slow, and the fast models aren't smart enough.\n\nHere's a reality check that might surprise people outside the voice AI space: most production voice agents are still running on GPT-4o and Gemini 2.5 Flash‚Äîmodels that are now a year and a half old.\n\n\"Those are the models that have the right mix of intelligence and latency,\" Kwin noted. \"And because people have gotten prompts optimized for them, they're pretty safe choices that a lot of people are sticking with.\"\n\nBut it's not just about capability. Switching models in voice AI is uniquely painful.\n\n\"It's so tricky to switch models,\" I explained during our conversation. \"You have so many models in concert together‚Äîyou're not just seeing if it performs as expected with your prompts, but how it interacts with all the other models. And the testing is much more expensive. The eval process is often very manual.\"\n\nThis creates a vicious cycle: teams stick with older models because evaluation is hard, which means newer models don't get battle-tested, which means teams stick with older models.\n\nWe spend a lot of time at Coval thinking about what makes voice AI evaluation uniquely difficult. Instruction following is, without question, the hardest piece.\n\nWhy? Because you can't just run the same prompt across different models and call it a fair comparison.\n\n\"Different prompts do well on different systems,\" I explained. \"What people actually want to know is: what's the best I can get out of each system? It's not useful to compare something out of the box if there's an obvious optimization.\"\n\nThis is why benchmarks like Kwin's are so valuable‚Äîthey help you rough-cut which models to even consider, before you invest in the expensive work of testing on your specific data and use case.\n\nBut there's a deeper problem. Traditional benchmarks test the first few turns of a conversation. Voice AI conversations are fundamentally long, multi-turn interactions‚Äîand that data is massively underrepresented in training datasets.\n\n\"I would talk to people at foundation labs and they'd say, 'We fixed function calling,'\" Kwin recalled. \"And function calling on the first three turns would be noticeably better. But function calling 20 turns into the conversation? No better at all.\"\n\nOne of the most honest moments in our conversation came when Zach admitted something many AI practitioners secretly believe:\n\n\"I'm a king of vibes. I haven't figured out any benchmark that I trust fully more than putting in my AirPods and talking to the models for 20 minutes. Nothing is quite as brutal as that test.\"\n\nBut Kwin pushed back‚Äîgently‚Äîon the idea that vibes are enough:\n\n\"For the purpose of this conversation, I'm going to pretend to disagree. The pain point I see is: I got this prompt right, the 20 people at our company tested it and had a good experience, but then I put it in production and people did weird things and it's not good enough.\"\n\nThis is the gap that quantitative evaluation fills. It's not about capturing the entire space of what makes a conversation feel good. It's about drawing a box around expected behavior so you can tell which models are clearly inside the box and which aren't.\n\n\"If you can draw a box and say this model is clearly in the box, this model is not‚Äîthat's a useful point of comparison for what it feels like to deploy these things into production with a wide variety of real-world user behavior.\"\n\nWhen I asked Zach what's still not captured in benchmarks, his answer was illuminating:\n\nBack-channeling. Those little \"mm-hmm\" and \"uh-huh\" moments that humans do perfectly and AI does awkwardly‚Äîor not at all.\n\n\"Any attempt to back-channel as a system-level thing has failed catastrophically,\" Zach said. \"They're either exactly correct and on the mark, or they're awkward. And we have no evals for this.\"\n\nProsody matching. The way your tone affects my response, and vice versa.\n\n\"If I say something in a particular tone, the interpretation of that tone should change how you respond‚Äînot just the words, but your prosody. My anger might induce your anger, or slow you down. We have no mechanisms to measure any of this.\"\n\nThe \"one beat off\" problem. The uncanny valley of voice AI isn't about obviously wrong responses‚Äîit's about timing that's slightly off.\n\n\"Capturing what makes it really unnatural‚Äîthings are out of order, or it's repeating itself, or getting stuck in loops‚Äîthose we can catch,\" I noted. \"But when it's just one beat off? That's the hardest to get.\"\n\nOne of the most interesting threads in our conversation was about how production voice AI is evolving toward multi-model architectures.\n\n\"We're increasingly living in a world where multiple models and multiple inference loops are really valuable,\" Kwin explained. \"A lot of what we're helping customers deploy now feels like a thinking fast and slow split‚Äîa fast voice loop, and then various kinds of async or long-running or parallel inference processes.\"\n\nGuardrails running in parallel (though by the time a guardrail kicks in, you may have already moved past the moment)\n\nTool calling pulled out of the fast loop to avoid latency penalties\n\nLong-running processes that inject back into the voice context\n\nBut this creates new evaluation challenges. As Zach pointed out: \"The evals can mislead me when I look at them, because you get this boost from thinking performance that helps tool calling, but when I have the actual conversation, it feels awkward.\"\n\nThe text-based evaluation might look accurate, but the user experience of two AI brains trying to coordinate can feel disjointed.\n\nOne pattern we're seeing‚Äîand warning customers about‚Äîis trying to reuse the same agents for chat and voice.\n\n\"This is where people are running into a lot of issues,\" I explained. \"What you want to see in chat looks very different than what you want to hear in a voice system. You're trying to use the same reasoning for two very different systems, and it just doesn't work.\"\n\nThe benchmarks might say your instruction following is great. But when you add all the layers of abstraction to retrofit a chat agent for voice, the real-world performance falls apart.\n\nWe ended the conversation with what might be the most important takeaway for anyone building with voice AI:\n\nShare your problems with your vendors.\n\n\"Everyone is trying to figure it out right now,\" I said. \"Hearing from users about what's working and what's not is the biggest signal above all else. We learn so much from our customers.\"\n\nZach agreed: \"We'd give ourselves a high five on some model performance eval, and then I'd throw it to a customer and they'd be like: garbage, garbage, garbage. There's a gap in our methodology‚Äîand we made a lot of mistakes in 2025 training without keeping that applied reality in mind.\"\n\nThe voice AI space is moving fast, but it's still early. The benchmarks are getting better. The models are getting better. But the feedback loop between real production pain and model improvement is still the most valuable signal any of us have.\n\nFrontier models saturate hard benchmarks but are too slow for production. The intelligence-latency trade-off is the defining constraint of voice AI in 2026.\n\nMost production systems still run 18-month-old models because switching is expensive and evaluation is hard.\n\nInstruction following is the hardest problem to benchmark because different prompting techniques work for different models, and voice conversations are long multi-turn interactions that training data doesn't represent well.\n\nWhat's missing from benchmarks: back-channeling, prosody matching, and the subtle timing issues that make conversations feel \"one beat off.\"\n\nMulti-model \"thinking fast and slow\" architectures are emerging, but they create new evaluation challenges around coordination and user experience.\n\nDon't reuse chat agents for voice. The systems require fundamentally different reasoning and evaluation approaches.\n\nShare your production problems. The feedback loop between real-world deployment and model improvement is the most valuable signal in the industry.\n\nWant to see how your voice agent performs on instruction following? Learn how Coval's simulation and evaluation platform helps teams test before production ‚Üí Coval.dev\n\nBrooke Hopkins is the founder of Coval, building simulation and evaluation for voice agents. Her background is from Waymo, where she led the evaluation infrastructure team responsible for all simulation tooling.\n\nKwindla Hultman Kramer is co-founder of Daily, which makes global infrastructure for real-time audio, video, and AI. Pipecat is part of Daily - the most widely used open-source framework for building voice and real-time multimodal AI agents.\n\nZach Koch is co-founder and CEO of Ultravox AI, which trains real-time speech-native models and runs dedicated inference to achieve increasingly human-like conversations with AI.",
    "readingTime": 9,
    "keywords": [
      "kwindla hultman",
      "hultman kramer",
      "teams stick",
      "prosody matching",
      "trains real-time",
      "real-time speech-native",
      "feedback loop",
      "user experience",
      "garbage garbage",
      "valuable signal"
    ],
    "qualityScore": 1,
    "link": "https://www.coval.dev/blog/the-state-of-voice-ai-instruction-following-in-2026-a-conversation-with-kwindla-from-pipecat-and-zach-from-ultravox",
    "thumbnail_url": "https://framerusercontent.com/assets/XKz3mwCB1do7n4eYEEPAsdSjAIY.png",
    "created_at": "2026-01-29T18:30:47.818Z",
    "topic": "tech"
  },
  {
    "slug": "googles-ai-helped-me-make-bad-nintendo-knockoffs",
    "title": "Google's AI helped me make bad Nintendo knockoffs",
    "description": "Here we go.",
    "fullText": "It‚Äôs what I had the most fun using Google‚Äôs Project Genie for, at least right now.\n\nIt‚Äôs what I had the most fun using Google‚Äôs Project Genie for, at least right now.\n\nThis week, a new generative AI tool from Google let me create bad knockoffs of 3D Nintendo worlds.\n\nCheck out my version of something like Super Mario 64:\n\nI didn‚Äôt like Metroid Prime 4: Beyond, but it‚Äôs better than my version of a Metroid Prime experience:\n\nOr how about my take on The Legend of Zelda: Breath of the Wild, complete with a paraglider (and, briefly, a second Link):\n\nIt was all possible thanks to Project Genie, an experimental research prototype that Google gave me access to this week, though I don‚Äôt think I‚Äôm using it in exactly the way Google intended.\n\nGoogle DeepMind has been putting a lot of effort into building its AI ‚Äúworld‚Äù models that can generate virtual interactive spaces with text or images as prompts. The company announced its impressive-looking Genie 3 model last year, but it was only available as ‚Äúa limited research preview‚Äù at the time. Project Genie, which will be rolling out to Google AI Ultra subscribers in the US starting today, will be the first opportunity for more people to actually try out what Genie 3 is capable of.\n\nGoogle is releasing Project Genie now partly because it wants to see how people use it. ‚ÄúIt‚Äôs really for us to actually learn about new use cases that we hadn‚Äôt thought about,‚Äù Diego Rivas, a product manager at Google DeepMind, tells The Verge. The company is already excited about how Genie could help to visualize scenes for filmmaking or for interactive educational media. You could, if you wanted, take a photo of your kids‚Äô favorite toy and use it to prompt a Genie-generated world. Genie could potentially help robots navigate the real world, too. But Project Genie isn‚Äôt yet an ‚Äúend-to-end product that we expect people to just use every day,‚Äù stressed Shlomi Fruchter, a Google DeepMind research director.\n\nWith Project Genie, you pick from a bunch of worlds designed by Google or define prompts for the environments and characters you want to create in your own world. After a brief wait, Genie first generates a thumbnail, then you can have it generate the world. You can explore each generated world for 60 seconds, and each has a resolution of about 720p and a frame rate of about 24fps. While you‚Äôre in one, you can (typically) move your character with the WASD keys, jump or go higher with a tap of your space bar, and turn the camera with arrow keys.\n\nOne of Google‚Äôs worlds, called ‚ÄúRollerball,‚Äù features a blue orb in a white, snowy world, and as you roll around, the orb leaves a trail of paint behind it. As a ‚Äúgame,‚Äù Project Genie wasn‚Äôt great. There was nothing to do but roll around; there weren‚Äôt any objectives or goals. There was no sound. There was frustrating input lag that was even worse than what I sometimes experience with cloud gaming. (Some of this could be due to the generally poor Wi-Fi I get in my office.)\n\nOver the course of the 60-second experience, Genie sometimes forgot to show a paint streak where I had previously rolled. Occasionally, the ball would randomly stop laying down paint at all. So I started to distrust Genie‚Äôs ability to recall what I had already seen with my own eyes.\n\nAnother Google-designed world, ‚ÄúBackyard Racetrack,‚Äù was a little more fun because there was an actual track to follow. My racing lines were awful ‚Äî the input lag didn‚Äôt help ‚Äî but I enjoyed trying to make the turns and stay on the road. Near the end of the experience, though, part of the track unexpectedly turned into grass, which ruined the immersion. And the wheel rims looked really janky.\n\nI had a lot more fun pushing the limits of Project Genie to try and make 3D, AI-generated games featuring recognizable characters, like with my Super Mario, Metroid Prime, and The Legend of Zelda-themed worlds. While they made me laugh, the worlds don‚Äôt have scores or anything to strive for, so there‚Äôs nothing to do but walk or jump around. Even if there were specific things to do, the input lag made the worlds basically unplayable. (Again, this may be a Wi-Fi issue, but even when I was closer to my router, I still experienced lag.)\n\nI wasn‚Äôt able to make everything I wanted. Project Genie wouldn‚Äôt generate a world that I prompted with the scenario of Kingdom Hearts ‚Äî here was my prompt, if you‚Äôre curious:\n\nIt‚Äôs a world filled with Disney characters with a steampunk vibe. Donald and Goofy are your sidekicks. Jack Skellington is present, as is Cloud Strife.\n\nYou are a spunky, anime teenager with spiky brown hair wielding a blade that is like a key.\n\nWhen I removed the specific names of characters and wrote descriptions of them instead, Project Genie generated a thumbnail preview of the world featuring characters that were dead ringers for Sora (the series‚Äô protagonist), Donald, Goofy, Jack Skellington, and Cloud. But when I tried to generate the actual experience, Project Genie blocked me.\n\nI asked about why I was able to generate worlds with Nintendo characters. ‚ÄúProject Genie is an experimental research prototype designed to follow prompts a user provides,‚Äù Rivas says. ‚ÄúAs with all experiments, we are monitoring closely and listening to user feedback.‚Äù Rivas also notes that the Genie 3 model was ‚Äútrained primarily on publicly available data from the web.‚Äù (This probably partially explains why Link deployed his paraglider in my test, which surprised me. At a high level, the Genie model is constantly trying to predict the next frame, and I‚Äôm sure there are many videos of people jumping in Breath of the Wild and then gliding forward, which the model probably learned from.) Shortly before publishing this article, Project Genie stopped letting me generate worlds based on Super Mario 64 due to ‚Äúinterests of third-party content providers.‚Äù\n\nAssuming Google clamps down on the ability to generate interactive worlds based on known gaming franchises ‚Äî I can‚Äôt imagine Nintendo will be happy with what I was able to generate! ‚Äî Project Genie otherwise isn‚Äôt that great at the moment. The input lag and 60-second limit make them pretty poor interactive experiences. Occasionally, I couldn‚Äôt control my character at all, only the camera. After the weirdness with the paint stripes and the road turning into grass, I had a general feeling that I couldn‚Äôt trust the worlds to stay consistent from moment to moment.\n\nProject Genie is better than some AI-generated worlds I tried last year, but it‚Äôs still much worse than an actual handcrafted video game or interactive experience. Fruchter described a potential future where the line blurs between different kinds of media thanks to technology like Genie, but I think it has a long way to go to get there.\n\nPerhaps my standards are too high. Project Genie is an experimental research prototype, after all. And maybe I‚Äôll feel differently after the technology improves down the line. But I can‚Äôt imagine that people will want to spend an extended period of time jumping into these types of AI-generated worlds anytime soon. With world models, I don‚Äôt think we have to worry about the genie being out of the bottle just yet.",
    "readingTime": 7,
    "keywords": [
      "project genie",
      "can‚Äôt imagine",
      "ai-generated worlds",
      "google‚Äôs project",
      "experimental research",
      "research prototype",
      "input lag",
      "genie model",
      "worlds based",
      "generate worlds"
    ],
    "qualityScore": 1,
    "link": "https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on",
    "thumbnail_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/ai-label-2.png?quality=90&strip=all&crop=0%2C10.705884903472%2C100%2C78.588230193056&w=1200",
    "created_at": "2026-01-29T18:30:47.796Z",
    "topic": "tech"
  },
  {
    "slug": "acp-agent-registry-in-jetbrains-ides",
    "title": "ACP Agent Registry in JetBrains IDEs",
    "description": "Together with Zed, we've launched the official ACP Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs.",
    "fullText": "Supercharge your tools with AI-powered features inside many JetBrains products\n\nAI coding agents are multiplying fast. Some of the most common ones include Gemini CLI, Claude Code, Auggie, OpenCode, and Copilot, and more are being released every day.¬†Each comes with its own unique strengths, specific setups, and varying levels of editor support. Keeping track of what‚Äôs out there, let alone getting it running in your IDE, hasn‚Äôt been easy.\n\nTogether with Zed (Zed‚Äôs announcement), we‚Äôve launched the official ACP Agent Registry: a directory of AI coding agents, integrated directly into JetBrains IDEs and Zed. Browse what‚Äôs available, click Install, and start working right away. This beta release is just the beginning.\n\nThe Agent Client Protocol¬†is an open standard that lets any AI coding agent work in any supporting editor. Think of it like the Language Server Protocol, but for AI agents. The LSP lets any editor support any language through a shared standard. The ACP does the same for coding agents. You only need to implement it once, and then it will work in your JetBrains IDE, Zed, or any other editor that supports the protocol.\n\nThis means you get to¬†pick your preferred¬†agent and editor, and they will then work together seamlessly ‚Äì no vendor lock-in and no waiting for someone to build a specific integration.\n\nACP has been, since we started integrating it to Mistral Vibe, a real joy to use: thoughtfully designed from the ground up, community-driven, and evolving rapidly. We‚Äôve found it not only simplifies integration, but also fits our focus on open and flexible tools. It‚Äôs really great to see a standard that puts developer choice first.\n\nMichel Thomazo, Software Engineer @ Mistral AI\n\nThe ACP made agent interoperability technically possible. The registry makes it convenient.\n\nInstead of manually configuring agents, you can now:\n\nAt launch, you‚Äôll find a wide array of different agents:\n\nFull-featured coding assistant optimized for large-scale refactors\n\nSpecialized agent for automated code generation workflows\n\nGoogle‚Äôs agent with deep codebase understanding and multimodal capabilities\n\nGitHub‚Äôs AI pair programmer, now available via the ACP\n\nLightweight, fast agent built on Mistral‚Äôs models\n\nCommunity-driven, fully open-source agent\n\nAlibaba‚Äôs coding agent with strong multilingual support\n\nInnovation in software agents is moving at an unbelievable pace. The Agent Registry and ACP makes it simple for developers to use the best agents in their favorite tools.\n\nChris Kelly, Product @ Augment Code\n\nIn general, it‚Äôs less about having multiple agents¬†than¬†about enabling you to pick and choose the ones that work well in your workflow. Different agents come with different benefits. Some provide a more attractive pricing structure for your business, some provide a user experience that you simply enjoy more than others‚Äô, and some embody the ideas of open-source development that just resonate with you.\n\nThe Agent Client Protocol registry lets you experiment freely. Try a few, see what clicks for your workflow, and then keep the ones that help. You‚Äôre not locked into a single vendor‚Äôs vision of what AI-assisted development should look like.\n\nWe‚Äôre excited to support the ACP Agent Registry as a step toward a more open agent ecosystem where Droids can integrate seamlessly across all IDEs.\n\nFrancesca LaBianca, VP of Operations @ Factory\n\nIn any JetBrains IDE (2025.3.2+) with JetBrains AI (253.30387.147):\n\nThat‚Äôs it. The agent is configured and ready to use in the AI Chat¬†tool window.\n\nQuick note: agents typically come with their own subscription. That‚Äôs between you and them. You won‚Äôt need a JetBrains AI subscription to use ACP agents.\n\nWant to try something concrete? Install OpenCode, open a project, and ask it to explain an unfamiliar module. OpenCode also lets you swap between different LLMs, so you can experiment with what works best for you.\n\nIf you prefer manual configuration, that option is still there, too. Just edit the acp.json¬†directly. This is useful for agents that aren‚Äôt in the registry yet or for custom setups.\n\nIf you‚Äôre building an ACP-compatible agent, the registry is now the fastest way to reach developers across JetBrains IDEs and Zed.\n\nHead to the¬†ACP Registry repository¬†and check out the¬†CONTRIBUTING.md¬†for the full submission process and metadata requirements. Please note that, for now, we are only featuring agents that support Agent Auth or Terminal Auth. Full details of requirements and conditions can be found here.\n\nThis is an open registry. If you‚Äôre building an ACP-compatible agent, you‚Äôre welcome to submit it. The registry exists to serve the ecosystem, not to gatekeep it.\n\nFor developers:¬†More choice and zero lock-in. Use any agent you want in the IDE you love.\n\nFor agent builders:¬†Instant distribution to millions of JetBrains and Zed users. Implement the ACP once and reach everyone.\n\nFor the ecosystem:¬†Competition on quality, not on who controls the integration. The best agents win because they‚Äôre the best, not because they have exclusive deals.\n\nWe‚Äôre building this openly with Zed because we believe AI-assisted development shouldn‚Äôt be locked inside any single vendor‚Äôs ecosystem. Developers deserve to pick their tools freely.\n\nThe registry is one more step toward that future.\n\nThe ACP Registry is available now in JetBrains IDE versions 2025.3 and later. Update your IDE and the JetBrains AI plugin, open Settings, and start exploring.\n\nHave feedback? Found a bug? The¬†registry repo is open for issues and PRs. And if you‚Äôre building something interesting with ACP, we‚Äôd love to hear about it!\n\nOpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE.¬†\n\nYou can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key ‚Äì all within the same AI —Åhat inte‚Ä¶\n\nThe next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers.\n\nYes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions‚Ä¶\n\nBring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains‚Äô Junie and Claude Agent. Whether you‚Äôre looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research prev‚Ä¶\n\nJunie is now integrated into the AI chat. The separate interfaces have merged into a single, unified space (available in Beta).",
    "readingTime": 6,
    "keywords": [
      "client protocol",
      "ai-assisted development",
      "step toward",
      "agent client",
      "acp-compatible agent",
      "jetbrains ai",
      "coding agents",
      "acp agent",
      "acp agent registry",
      "jetbrains ide"
    ],
    "qualityScore": 1,
    "link": "https://blog.jetbrains.com/ai/2026/01/acp-agent-registry/",
    "thumbnail_url": "https://blog.jetbrains.com/wp-content/uploads/2026/01/JB-social-BlogSocialShare-1280x720-1-4.png",
    "created_at": "2026-01-29T18:30:47.768Z",
    "topic": "tech"
  },
  {
    "slug": "mito-ai-raised-45-million-to-launch-projectmanagement-software-for-filmmakers-read-its-pitch-deck",
    "title": "MITO AI raised $4.5 million to launch project-management software for filmmakers. Read its pitch deck.",
    "description": "Read the pitch deck that MITO AI, a new AI workflow platform for filmmakers, used to raise $4.5 million in funding.",
    "fullText": "Artificial intelligence is shaking up video production.\n\nThe startup MITO AI is rolling out a new platform to help filmmakers storyboard, organize, and generate AI assets in one place. It's a project management tool for the era of generative AI filmmaking.\n\nThe company exclusively told Business Insider that it had raised $4.5 million in a pre-seed round led by Lightspeed Venture Partners. It's launching its product on Thursday after testing with about 200 beta partners.\n\n\"Our tools are connected to video models, image models, audio models, and voice models, and then everything is brought together into our infinite canvas for collaboration and experimentation,\" MITO cofounder I√±aki Berenguer said.\n\nWhile many AI video generators, such as OpenAI's Sora or Google's Veo, are limited to short-form clips, MITO wants to help creators piece together short AI assets into a longer project. It also offers collaborative features, such as commenting. MITO users can create new AI assets that align with their film's style via integrations with¬†platforms including Runway, Veo 3, ComfyUI, and Pika.\n\nBeyond its workflow platform, the startup also makes AI content for partners via its studio team.\n\nMITO arrives at a moment of flux in the media industry. Hollywood and advertising executives are testing AI tools for digital effects and commercials. Independent creators are using the tech to spruce up their videos without breaking the bank. Actors, animators, and other creatives, meanwhile, are raising eyebrows at the technology that some fear could wipe out jobs.\n\nMITO is also entering a crowded category dominated by incumbents like Adobe and containing other new upstarts like FLORA, which recently raised a $42 million funding round led by Redpoint Ventures.\n\nRead the pitch deck MITO used to raise its $4.5 million pre-seed round, shared exclusively with Business Insider. Some of the slides have been omitted or redacted.\n\nIt's a platform for \"multiplayer video creation.\"\n\nThe company highlighted two films it created end-to-end, \"Golf Le Fleur Maritime\" and a \"Lagaam campaign.\"\n\nArantxa Barcia, chief creative officer\n\nDanny Saltaren, chief product officer\n\n-Genially (collaborative canvas, $20M ARR), Inditex, Unusuals.\n\nTHE PROBLEM TODAY: AI video workflows are fragmented, slow, painful to iterate, and impossible to collaborate on.\n\n50 cent - 21 Questions and Willy Chavarria - Campaign.\n\nWe have delivered multiple real brand campaigns and music videos using our platform. MITO's tools meet professional quality standards and solve real brand pain points. Why create a studio? To eat our own dog food, generate revenue, and market what's possible.\n\nMITO Orchestration and Collaboration Tools:\n\nStoryboard as the skeleton of a full AI video production. Manually crafted, AI-assisted, or fully generated by our AI agents.\n\nAI Editor for individual text, images, videos, audios.\n\nInfinite canvas. Infinite creation.\n\nA non‚Äëlinear visual collaboration space ‚Äî an evolved moodboard ‚Äîfor exploring and iterating ideas across images, video, audio, text, and styles; freely, in parallel, grouping and recombining, without breaking flow.\n\nMITO UNIVERSE ‚Äî COMMUNITY OF CREATORS & MARKETPLACE\n\nA creator community and marketplace where artists and producers get a vanity URL to share AI-generated video assets, workflows and portfolios.\n\nMITO offers three pricing tiers: A free tier, a $16 monthly \"pro\" tier, and a $38 monthly \"studio\" tier.\n\nUsers are charged additional costs in the form of \"credits\" based on how often they generate AI content.\n\nWhat private beta users are saying:\n\n\"Huge congratulations! The progress over the last few months is dramatic. MITO makes complex audiovisual creation feel effortless, with real controls over camera, lenses, framing, lighting, and color. The built-in video editor is a game-changer. I haven't seen another AI suite this complete or this clearly designed for real audiovisual creators.\"\n\n\"Creativity is entering a phase of explosive diversification, and along with it, the quality of art and entertainment can drastically increase. Even in the very early days of playing with MITO, it's been striking how open the playing field suddenly feels.\"\n\nDespite the emergence of powerful models, no dominant platform yet ties everything together.\n\nAI models like Veo, Kling, and Runway open new frontiers.\n\nTeam workflows remain fragmented ‚Äî the orchestration layer is missing.\n\nStorytellers, filmmakers, brands, and companies can now produce high‚Äëquality video without the high cost and long process of traditional production. The result is faster iteration, more experimentation, and many more creative versions.\n\ne.g. brands needing 30 sec-5 min videos\n\nToday 80k brands spending at least $100k per year on video\n\nThe video creation boom is coming. If cost per video is lower: 10x more brands, 10x more content per brand, at a lower cost\n\nProfessional video creation is about to explode ‚Äî for brands, movie studios, social media, agencies, creators and new forms of entertainment.\n\n\"New powerful AI video models are transforming massive existing categories and unlocking new ones,\" the company says.\n\nUnleashing video creativity & myth-making in the age of AI.",
    "readingTime": 4,
    "keywords": [
      "infinite canvas",
      "pre-seed round",
      "round led",
      "models",
      "platform",
      "creators",
      "creation",
      "brands",
      "assets",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mito-ai-raised-5-million-round-read-its-pitch-deck-2026-1",
    "thumbnail_url": "https://i.insider.com/697a7d81e1ba468a96aae72a?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.968Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-a-planetsized-bubble-and-microsofts-slump-is-a-taste-of-the-crash-to-come-tech-guru-erik-gordon-says",
    "title": "AI is a planet-sized bubble ‚Äî and Microsoft's slump is a taste of the crash to come, tech guru Erik Gordon says",
    "description": "Professor Erik Gordon said the \"AI bubble is almost as big as the planet Jupiter,\" and Microsoft's stock drop is a \"warning of the burst to come.\"",
    "fullText": "Rampant speculation and massive overinvestment in AI have created a financial threat of cosmic proportions ‚Äî and the fallout will be catastrophic, Erik Gordon has warned.\n\n\"The AI bubble is almost as big as the planet Jupiter,\" Gordon, an entrepreneurship professor at the University of Michigan's Ross School of Business, said in a Wednesday email to Business Insider.\n\n\"When it bursts, the debris will be everywhere,\" he continued. \"Big, institutional investors will be hit with it, and so will individual investors who bet the bubble would get even bigger.\"\n\nGordon pointed to Microsoft stock, which tumbled more than 6% after the software giant's earnings beat on Wednesday. It was trading around 12% lower at 12:30 p.m. ET on Thursday, marking one of the sharpest intraday declines in the company's history.\n\nMicrosoft's shares sank \"because of the truckloads of cash it is investing in AI,\" Gordon said. \"That is a warning of the burst to come.\"\n\nThe cloud-computing titan's net cash used in investing surged 95% year-on-year to over $57 billion in the six months to December. That was fueled by its addition of $49 billion worth of property and equipment such as data centers.\n\nPrior to their post-earnings slump, Microsoft's shares had roughly doubled since the start of 2023, lifting the company's market value to over $3.5 trillion.\n\nOther AI stocks have surged even faster over that timeframe. Shares of chipmaker Nvidia have vaulted 13-fold, valuing the company at close to $4.7 trillion ‚Äî more than 20 times its projected revenue for the fiscal year ended January 25.\n\nPalantir stock has jumped about 25-fold, giving the data-analysis company a $375 billion market value, or around 85 times its forecasted revenue for 2025.\n\nGordon told Business Insider in an email last week that he doesn't expect the AI bubble to burst in the next few months, as investors still have enough cash to \"prop it up,\" and technological advances remain \"exciting enough to distract\" from irrational valuations.\n\nThe veteran professor has previously rung the alarm on an \"order-of-magnitude overvaluation bubble,\" and warned that when it pops, the \"suffering will be more painful\" for investors than the aftermath of the dot-com bubble. But stocks have largely defied his warnings and continued to march higher.",
    "readingTime": 2,
    "keywords": [
      "microsoft's shares",
      "bubble",
      "investors",
      "cash",
      "warned",
      "professor",
      "email",
      "stock",
      "company's",
      "investing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-bubble-microsoft-stock-market-crash-erik-gordon-tech-investing-2026-1",
    "thumbnail_url": "https://i.insider.com/697b4d16a645d11881883730?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.815Z",
    "topic": "finance"
  },
  {
    "slug": "investors-are-giving-meta-the-green-light-to-keep-spending-big-on-ai",
    "title": "Investors are giving Meta the green light to keep spending big on AI",
    "description": "Meta stock surged on Thursday as Q4 earnings beat estimates and investors welcomed more big AI spending plans from the Facebook parent.",
    "fullText": "The move: Meta Platforms stock jumped 9% on Thursday after earnings, erasing losses from the previous week. The stock is up 10% year-to-date.\n\nWhy: Meta reported Q4 2025 earnings on Wednesday after close, coming in above Wall Street estimates on both top and bottom line metrics. It posted revenue of $59.9 billion, versus the forecasted $58.4 billion, and earnings per share of $8.88, versus the $8.16 consensus.\n\nImportantly, the social media giant also revealed that it plans to spend $115 billion to $135 billion on AI in the coming year, a substantial increase from the $72.22 billion it spent on AI in 2025 and well above Wall Street's expectations for 2026.\n\nDespite balking at its big spending plans announced in its last quarterly earnings, Wall Street reacted favorably to the news.\n\nThe key difference this time around seems to be that the company's quarterly advertising revenue came in well above expectations. CFO Susan Li fueled confidence in Meta's growth plans when she said on the earnings call that the company's AI endeavors would be financed with cash rather than debt, likely generated by its advertising success.\n\nWhat it means: The earnings were a key update on the AI race, showing that the company is successfully generating cash from other areas to fund its AI ambitions. It's the kind of strength investors want to see after last year ended with Wall Street growing anxious about soaring capex among hyperscalers.\n\n\"Ongoing investments across the business, including the infusion of AI capabilities across the company's ad stack and content recommendation engines, are already driving tangible benefits for the core advertising segment,\" stated Dan Ives of Wedbush Securities.",
    "readingTime": 2,
    "keywords": [
      "wall street",
      "earnings",
      "plans",
      "company's",
      "advertising",
      "stock",
      "revenue",
      "versus",
      "expectations",
      "quarterly"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/meta-stock-price-q4-earnings-wall-street-advertising-ai-plans-2026-1",
    "thumbnail_url": "https://i.insider.com/697b6a37a645d118818838ff?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.462Z",
    "topic": "finance"
  },
  {
    "slug": "apple-earnings-live-updates-ai-strategy-under-the-microscope-as-wall-street-readies-for-q1-results",
    "title": "Apple earnings live updates: AI strategy under the microscope as Wall Street readies for Q1 results",
    "description": "Apple will report earnings for its fiscal Q1 on Thursday after the closing bell, and its call with analysts is scheduled for 5 p.m. ET.",
    "fullText": "Apple is the next mega-cap tech titan to report earnings after the closing bell on Thursday, and Wall Street is looking for answers on the company's AI roadmap.\n\nThe iPhone maker's fiscal first-quarter results will be a key update amid investor concerns that it has fallen behind in the AI race. Its partnership with Gemini, announced earlier this month, launched Alphabet stock to a $4 trillion market cap, but the impact on Apple shares has been muted. iPhone and other hardware sales will also be a key focus after Tim Cook said in the previous earnings call that its Q1 would be the best ever quarter for revenue.\n\nApple heads into the earnings call with shares down about 7% year to date. The results will be published shortly after the closing bell, and the analyst call will kick off around 5 p.m. ET.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"\n\nUBS analysts said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impacting cost and margins,\" UBS wrote in a January 20 note.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\nMorgan Stanley analyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he expects investors to be underwhelmed by iPhone sales.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share, representing upside of about 23%.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, as they have for other firms that have touted involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.",
    "readingTime": 5,
    "keywords": [
      "wide developers",
      "developers conference",
      "january note",
      "much-anticipated siri",
      "stanley analyst",
      "analyst erik",
      "analyst michael",
      "analyst dan",
      "back siri",
      "siri refresh"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-live-updates-ai-gemini-iphone-sales-2026-1",
    "thumbnail_url": "https://i.insider.com/69792277d3c7faef0ecd063e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.212Z",
    "topic": "finance"
  },
  {
    "slug": "microsofts-earnings-bust-drags-software-stocks-into-a-bear-market-and-tanks-major-indexes",
    "title": "Microsoft's earnings bust drags software stocks into a bear market and tanks major indexes",
    "description": "Shares of Microsoft plunged 12% and software stocks hit a bear market. The S&P 500 edged back from 7,000 as AI spending fears were rekindled.",
    "fullText": "Tech stocks were taking it on the chin on Thursday, with the impact particularly severe for software shares amid Microsoft's post-earnings plunge.\n\nThe software sector slipped into bear market territory as Microsoft renewed fears that the market's largest tech firms may be spending too much, too fast on AI without seeing adequate growth in other parts of the business to offset.\n\nWhile Meta was rewarded after earnings, as robust capex guidance was overshadowed by advertising strength, investors punished Microsoft.\n\nShares of the software giant dropped 12%. The firm said it spent a record amount on AI, but reported slowing cloud growth and issued soft guidance on profits for the following quarter, leading tech stocks to sell off across the board.\n\nThe iShares Expanded Tech-Software Sector ETF is down 21% from its high in October.\n\nHere were the notable moves in the tech sector:\n\n\"Microsoft (MSFT) was the black sheep with losses,\" Joee Mazzola, the head trading and derivatives strategist at Charles Schwab, wrote on Thursday, referring to more upbeat results from Magnificent Seven peers Tesla and Meta.\n\nMajor indexes were dragged lower. The S&P 500 dropped more than 1%, retreating further from the 7,000 mark, which it briefly topped for the first time on Wednesday, while the Nasdaq Composite dropped 2%.\n\nHere's where US indexes stood around 11:45 a.m. ET on Thursday:\n\nInvestors have been particularly sensitive to signs that demand for AI may not be as robust as markets originally anticipated. Capex spending among tech giants has been a particular worry, given the uncertainty over monetization plans and when the market will see returns from AI spend.\n\nMicrosoft's earnings likely \"reinforced fears that a return on AI investment may be slow in coming,\" David Morrison, a senior market analyst at Trade Nation, wrote in a note Thursday morning.\n\nThe company likely needs to \"prove\" that it's making good investments into its AI endeavours, analysts at UBS wrote earlier this week.\n\n\"Microsoft has elected to increase the allocation of new GPU compute to its 1P efforts, effectively throttling Azure growth, because of its confidence in monetizing Copilot,\" the bank said. \"The challenge for the stock is that many investors don't buy into that trade-off.\"",
    "readingTime": 2,
    "keywords": [
      "tech stocks",
      "market",
      "growth",
      "dropped",
      "particularly",
      "microsoft's",
      "fears",
      "earnings",
      "robust",
      "capex"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/stock-market-today-tech-selloff-microsoft-earnings-capex-sp500-nasdaq-2026-1",
    "thumbnail_url": "https://i.insider.com/697b865fa645d11881883c8e?width=1200&format=jpeg",
    "created_at": "2026-01-29T18:30:45.206Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-laying-off-workers-because-of-ais-potentialnot-its-performance",
    "title": "Companies Are Laying Off Workers Because of AI‚Äôs Potential‚ÄîNot Its Performance",
    "description": "AI has been cited as a cause of layoffs, but is it actually displacing jobs? And if not, what‚Äôs going on? Based on a survey of 1,006 global executives in December 2025, AI is behind at least some layoffs, but that these are almost completely in anticipation of AI‚Äôs impact. In other words, the job losses and slowed hiring are real, even though companies are still waiting for generative AI to deliver on its promises. This strategy of focusing on short-term gains based on long-term hopes has costs.",
    "fullText": "Companies Are Laying Off Workers Because of AI‚Äôs Potential‚ÄîNot Its Performance by Thomas H. Davenport and Laks SrinivasanJanuary 29, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintWill AI lead to layoffs? Are people already losing their jobs to AI? While overall employment in the U.S. is still relatively low, there is considerable speculation that the adoption of generative AI was a cause of recent layoffs and slowed hiring, particularly in the tech industry, for entry-level workers, and in customer service and programming jobs. More may be coming: Leading CEOs‚Äîincluding those from Ford, Amazon, Salesforce, and JP Morgan Chase‚Äîhave proclaimed that many white-collar jobs at their companies will soon disappear.",
    "readingTime": 1,
    "keywords": [
      "jobs",
      "workers",
      "layoffs"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/companies-are-laying-off-workers-because-of-ais-potential-not-its-performance",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_28_Mid.jpg",
    "created_at": "2026-01-29T18:30:44.629Z",
    "topic": "business"
  },
  {
    "slug": "ai-and-humane-leadership-a-davos-discussion",
    "title": "AI and Humane Leadership: A Davos Discussion",
    "description": "In this HBR Executive panel discussion at Davos, cohosted by our partner Egon Zehnder, a group of CEOs and board members explore how AI can coexist with human-centered leadership‚Äîstrengthening trust, empathy, judgment, and innovation amid accelerating technological change.",
    "fullText": "AI and Humane Leadership: A Davos DiscussionHow should AI and human leadership evolve together in this moment of rapid transformation? by HBR EditorsJanuary 29, 2026Summary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrinttogether in this moment of rapid transformation? At Davos, HBR Executive and our partner Egon Zehnder convened a select group of global chief executives to discuss this very question.",
    "readingTime": 1,
    "keywords": [
      "rapid transformation",
      "leadership",
      "moment",
      "davos"
    ],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/01/ai-and-humane-leadership-a-davos-discussion",
    "thumbnail_url": "/resources/images/article_assets/2016/09/whiteout.png",
    "created_at": "2026-01-29T18:30:44.619Z",
    "topic": "business"
  },
  {
    "slug": "boston-dynamics-new-atlas-robot-makes-public-debut-with-jaunty-human-walk",
    "title": "Boston Dynamics' New Atlas Robot Makes Public Debut with Jaunty Human Walk",
    "description": "Hyundai-owned Boston Dynamics is also partnering with former owner Google's DeepMind on AI, in a full-circle moment for the two companies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.cnet.com/tech/computing/boston-dynamics-new-atlas-robot-make-public-debut-with-jaunty-human-walk/",
    "thumbnail_url": "https://www.cnet.com/a/img/resize/13579e8bed396530cf6c17a54226646a18b3f62e/hub/2026/01/07/ca21282f-6c31-406c-8959-fb96e1b98eae/img-3966.jpg?auto=webp&fit=crop&height=675&width=1200",
    "created_at": "2026-01-29T12:32:33.724Z",
    "topic": "tech"
  },
  {
    "slug": "microsofts-ai-spend-is-starting-to-spook-investors",
    "title": "Microsoft's AI Spend Is Starting to Spook Investors",
    "description": "Microsoft showed record spending but slowing cloud growth and a big reliance on OpenAI",
    "fullText": "In its second-quarter earnings report on Wednesday, tech giant Microsoft reported $37.5 billion in capital expenditures, exceeding market estimates by more than a billion. The spending was up 66% from a year earlier, and roughly two-thirds of it was primarily spent on GPUs and CPUs, Microsoft executives said in an investor call.\n\nA few months ago, a report like this would have sent (and did send) Microsoft stock soaring. But on Wednesday, it had the opposite effect, and the stock went down 7%.\n\nAs worries over an AI bubble simmer, the market is more desperate than ever to see tangible revenue returns that can reignite belief in the great financial promises of the technology, rather than just another huge spending commitment.\n\nBut accompanying Microsoft‚Äôs record spending was slowing cloud growth.\n\nRevenue from Microsoft‚Äôs cloud services grew by 39% this quarter, down from 40% growth in the first quarter. During the investor call, Microsoft CFO Amy Hood attributed this discrepancy between capital expenditure and cloud growth at least partially to Microsoft allocating GPUs and cloud capacity to internal teams as well. Customer demand for cloud is still outpacing supply, Hood said.\n\nBut even if the slowing cloud growth can be explained away, what also got investors anxious was Microsoft‚Äôs reliance on AI giant OpenAI. 45% of Microsoft‚Äôs remaining cloud commitments are solely from OpenAI.\n\nAlthough OpenAI used to be the silver bullet for finance, growing uncertainty over the startup‚Äôs road to profitability and the risks associated with its ability to pay for towering, ambitious dealmaking has made some start to view any dependence on the AI darling as a potential burden.\n\nOpenAI has signed trillions of dollars worth of deals this past year, despite its $20 billion annualized revenue. Lately, the market has started questioning these overcommitments, as concerns over a potential AI bubble mount.\n\nIf it continues to take too long for AI investments to start translating to actual gains or if somehow it turns out OpenAI cannot pay for its piling commitments, it could lead to a sharp market correction and spell trouble for the U.S. economy, which it seems is currently held up by AI investment.",
    "readingTime": 2,
    "keywords": [
      "slowing cloud",
      "cloud growth",
      "market",
      "revenue",
      "giant",
      "capital",
      "investor",
      "stock",
      "bubble",
      "quarter"
    ],
    "qualityScore": 0.9,
    "link": "https://gizmodo.com/microsofts-ai-spend-is-starting-to-spook-investors-2000715208",
    "thumbnail_url": "https://gizmodo.com/app/uploads/2026/01/shutterstock_2163957793-1200x675.jpg",
    "created_at": "2026-01-29T12:32:32.544Z",
    "topic": "tech"
  },
  {
    "slug": "longcatflashlite-100b-a3b-technical-report-pdf",
    "title": "LongCat-Flash-Lite 100B A3B Technical Report [pdf]",
    "description": "We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "LongCat0830\n\n Upload 2 files\n 5ce2ddd\n verified\n about 20 hours ago\n\n download\n\n Copy download link\n history\n\n blame\n\n contribute\n\n delete\n\n 737 kB\n\n Large File Pointer Details\n (\n Raw pointer file\n\n )\n SHA256:\n 5c6963d484586b90e32960c2a7eef93c60ef6b328179972bc6702714f09e4784\n Pointer size:\n 131 Bytes\n\n ¬∑\n\n Size of remote file:\n 737 kB\n\n ¬∑\n Xet hash:\n 7d93b02590ef60d7e97bfd90cdc8b914857c1d7c3252ca7b9abc08301e02e2e8\n Xet efficiently stores Large Files inside Git, intelligently splitting files into unique chunks and\n accelerating uploads and downloads.\n More info.",
    "readingTime": 1,
    "keywords": [
      "pointer",
      "download",
      "files",
      "file",
      "size"
    ],
    "qualityScore": 0.35,
    "link": "https://huggingface.co/meituan-longcat/LongCat-Flash-Lite/blob/main/tech_report.pdf",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/meituan-longcat/LongCat-Flash-Lite.png",
    "created_at": "2026-01-29T12:32:32.273Z",
    "topic": "tech"
  },
  {
    "slug": "google-warns-against-breaking-search-as-pressure-mounts-over-web-future",
    "title": "Google warns against 'breaking Search,' as pressure mounts over web future",
    "description": "Google said it will let websites opt out of generative AI features in Search. Cloudflare's CEO says that's just a start.",
    "fullText": "Google said its Search engine could break if the company is forced to implement strict new controls to protect and nurture web content in the AI era.\n\nThe warning came after UK antitrust regulators proposed new rules for Google Search that would give publishers more control over how their content is used in AI features such as Google's AI Overviews and AI Mode.\n\nIn response, Google said it is working on new ways to give websites more control over how AI chatbots and AI-powered answer engines access and use online content. The company faces mounting pressure to give content owners ways to opt out of having their data crawled for AI, while still allowing traditional search engines to index this valuable data.\n\n\"We're now exploring updates to our controls to let sites specifically opt out of Search generative AI features,\" Google said on Wednesday in a blog post.\n\nThat's a major concession from Google, which has been quietly but firmly pushing back against such demands.\n\nYet, the tech giant also warned that strict new controls could threaten its prized Search engine, which generates most of the company's profits.\n\n\"Any new controls need to avoid breaking Search in a way that leads to a fragmented or confusing experience for people,\" the company said, arguing that search and AI are now deeply intertwined.\n\nGoogle says AI has been core to how Search works for more than a decade, helping rank results and surface relevant links. Creating sharp opt-outs for generative AI features, Google suggests, could undermine the basic mechanics that allow people to find information quickly and allow websites to be discovered at scale.\n\nAt stake is a deeper question about what Search should be in the AI era. Publishers increasingly argue that AI summaries substitute for their content rather than pointing users to it, undermining the grand bargain that has underpinned the web for decades. Google counters that drawing hard lines between search and AI risks unintended consequences, including degraded results and a worse user experience.\n\nCloudflare CEO Matthew Prince said the UK's proposal is \"progress,\" but didn't go far enough. His company helps run about 20% of the web and has been pushing for new standards to level the AI playing field.\n\n\"The CMA's recommendation today doesn't go far enough because it doesn't force Google to split search crawl from AI crawl,\" Prince told Business Insider, referring to the UK's Competition and Markets Authority. \"Instead, it requires us all to trust that Google will not be evil when they build their unauditable black AI box.\"\n\n\"If the CMA wants to encourage innovation and competition in AI, the best thing they should do is force Google to play by the same rules as everyone else and split crawl for AI from the crawl for search,\" he added. \"Every company other than Google would support that because it fosters a healthy market. It's a no-brainer, so it's disappointing the CMA didn't go far enough today.\"\n\nA CMA consultation runs until February 25. Whether regulators can tighten the rules without, as Google warns, breaking Search may help determine not just the future of Google in the UK, but the shape of the open web itself.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "search engine",
      "features google",
      "search and ai",
      "content",
      "controls",
      "crawl",
      "rules",
      "strict",
      "regulators",
      "publishers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-warns-breaking-search-pressure-mounts-web-ai-cloudflare-2026-1",
    "thumbnail_url": "https://i.insider.com/697a616ba645d11881882b19?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "finance"
  },
  {
    "slug": "extesla-ai-head-has-seen-a-phase-shift-in-software-engineering-using-claude-code-and-his-manual-skills-slowly-atrophy",
    "title": "Ex-Tesla AI head has seen a 'phase shift in software engineering' using Claude Code ‚Äî and his manual skills slowly 'atrophy'",
    "description": "Andrej Karpathy posted his \"notes from Claude Coding,\" describing a shift in engineering over the last two months.",
    "fullText": "He coined \"vibe coding.\" Now, he sees a \"phase shift\" in software engineering.\n\nAndrej Karpathy is one of AI's guiding figures. He was a founding member of OpenAI and later served as Tesla's director of AI. He also coined the term \"vibe coding,\" the AI-assisted coding movement that has taken software engineering by storm and was named Collins Dictionary's word of the year.\n\nIn his \"random notes from Claude Coding\" ‚Äî which are over 1,000 words long ‚Äî Karpathy wrote about the changes to his own coding style. Posted on X on Monday, the notes have already elicited reactions from engineers at Anthropic, xAI, and more.\n\nAI coding agents \"crossed some kind of threshold of coherence around December 2025 and caused a phase shift in software engineering,\" Karpathy wrote.\n\nA few random notes from claude coding quite a bit last few weeks.\n\nCoding workflow. Given the latest lift in LLM coding capability, like many others I rapidly went from about 80% manual+autocomplete coding and 20% agents in November to 80% agent coding and 20% edits+touchups in‚Ä¶\n\nKarpathy name-dropped both Anthropic's Claude Code and OpenAI's Codex as having significant improvements. Claude Opus 4.5, the model that has garnered much love from engineers online, came out at the tail end of November.\n\nThe AI leader's workflow has changed as a result of the AI tools. From November to December, Karpathy's 80/20 ratio flipped. He once used 80% manual coding and 20% agents; now, it's 80% agents and 20% manual code editing.\n\n\"I really am mostly programming in English now, a bit sheepishly telling the LLM what code to write... in words,\" he wrote.\n\nThe change to AI-written code \"hurts the ego,\" but is too powerful to ignore, Karpathy wrote. He also devoted a whole section of his notes to the \"fun\" he has while coding with large language models.\n\nWhat of those traditional coding skills, the ones you learn in a computer science program or through endless digital courses? That's a whole other function, Karpathy wrote, and one that might decline.\n\n\"I've already noticed that I am slowly starting to atrophy my ability to write code manually,\" he wrote.\n\nIn Karpathy's comments, engineers from leading AI companies sounded off. Ethan He, an xAI engineer and Nvidia alum, wrote that a \"10x engineer can be a one-man army.\"\n\nCharles Weill, another xAI engineer, wrote that founders can now \"divide themselves\" with coding agents, like a VC divides their capital over a portfolio of companies.\n\nBoris Cherny, an Anthropic staffer and the creator of Claude Code, wrote that he read Karpathy's \"thoughtful\" post till its end.\n\nThe Claude Code team at Anthropic may offer a model of where the industry is moving, Cherny wrote. His team is \"mostly generalists\" and filled with 10x engineers.\n\n\"Pretty much 100% of our code is written by Claude Code,\" Cherny wrote. \"For me personally it has been 100% for two+ months now, I don't even make small edits by hand.\"\n\nThe Anthropic employee also acknowledged the \"quality\" problems with AI-written code. Agents can overcomplicate things and can leave around dead code, he wrote.\n\nHis solution: having AI review the AI-written code.",
    "readingTime": 3,
    "keywords": [
      "ai-written code",
      "phase shift",
      "software engineering",
      "random notes",
      "xai engineer",
      "vibe coding",
      "coding agents",
      "engineers",
      "claude",
      "coined"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-claude-code-manual-skills-atrophy-software-engineering-tesla-2026-1",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.928Z",
    "topic": "tech"
  },
  {
    "slug": "the-questions-leonis-capital-investors-ask-to-see-if-a-startups-tech-actually-holds-up",
    "title": "The questions Leonis Capital investors ask to see if a startup's tech actually holds up",
    "description": "Leonis Capital founders Jenny Xiao and Jay Zhao tell Business Insider what they ask AI startup founders to evaluate their tech.",
    "fullText": "If you hadn't heard, there's an AI race sweeping through Silicon Valley.\n\nWhile stalwarts like Google, Meta, and Microsoft, and newcomers like OpenAI and Anthropic, are grabbing the headlines as they unveil model after model, there are plenty of startups trying to find a foothold.\n\nFor investors, it can be hard to tell which of these upstarts have true technical potential and which are likely to fade into tech oblivion.\n\nThat's part of why Jenny Xiao, the cofounder of Leonis Capital, said it's important for venture capitalists to get serious about understanding the AI technology they're investing in.\n\nLeonis Capital, founded in 2021, is now deploying its second $40 million fund. The venture capital firm is focused on next-generation AI companies and has invested in over a dozen since its launch, including MaintainX, Motion, and SpectroCloud.\n\nBusiness Insider asked Xiao and her cofounder, Jay Zhao, to share the top five questions they ask founders when evaluating their tech. They shared their responses over email, which have been condensed and edited for clarity.\n\nThe best founders don't think in terms of incremental feature improvements ‚Äî they think in capability thresholds. We're looking for whether they understand that progress in AI is often non-linear, and whether they can anticipate which future capabilities might fundamentally change or even break their product.\n\nOne of the most interesting takeaways from our Leonis AI 100 ‚Äî where we benchmarked the most important AI startups ‚Äî is that the strongest AI founders build just ahead of the next technical breakthrough.\n\nA good answer talks about entirely new workflows that get unlocked, not just marginal efficiency gains, and clearly explains how the company would adapt or pivot as the technology evolves.\n\nMost AI startups don't fail because they're bad, but because they're building something that OpenAI, Anthropic, or Google can eventually ship \"for free\" as a feature.\n\nThat's why we don't accept \"they're not focused on this\" as an answer. We push founders to explain what internal constraint would actually prevent a foundation model lab from building the same thing. If the answer comes down to focus or culture, that's not a real moat.\n\nStrong answers acknowledge that the big labs technically could build it, but doing so would break their incentive structure, pricing, or distribution model; require operational complexity that doesn't scale for them; or shift value to downstream execution rather than model capability.\n\nSome founders can also credibly argue they have a 12- to 18-month head start. Weak answers, by contrast, lean on claims like being \"more vertical,\" having \"more niche data,\" or understanding customers better ‚Äî responses we hear from about 95% of founders.\n\nWe've noticed a consistent pattern: Most founders underestimate foundation models, and most VCs underestimate them even more.\n\nAsking \"How much proprietary data do you have?\" is usually the wrong question, since no early-stage company has truly meaningful data. And if a founder's pitch boils down to \"we have more data, therefore our models are better,\" that's a red flag: foundation models often improve faster than proprietary ones, and the companies building them have enough capital to buy data and quickly close any gaps.\n\nWhat matters much more is not how much data exists today, but whether the product naturally generates better data over time. For example, industrial systems where data only emerges once software is embedded in workflows, or products where switching costs come from accumulated context.\n\nWe ask this question to understand where defensibility actually lives once code becomes commoditized. If a founder can't answer it clearly, they likely don't understand their own moat.\n\nCosmetic advantages like code, UI, or models are easy to copy, while structural advantages ‚Äî such as being a system of record or being embedded into compliance, audits, or standard operating procedures ‚Äî are much harder to replicate.\n\nThe question also reveals founder temperament: Strong founders are candid about their vulnerabilities (\"Here's what we're most worried about\"), while weaker ones tend to get defensive and insist a threat \"would never happen.\"\n\nThis question forces founders to explain their earliest technical decisions and the trade-offs they intentionally made, revealing whether they understand system dynamics rather than just iterating on features.\n\nStrong answers sound like, \"We chose to execute actions, not just make suggestions, which increased liability but created real lock-in,\" or \"We became the system of record instead of a thin layer, which slowed integrations and sales early but made switching organizationally expensive later.\" By contrast, many founders default to saying they want to \"stay flexible,\" which often signals they haven't yet designed anything fundamental.\n\nThe best AI systems are opinionated by design, deliberately removing degrees of freedom and hard-coding assumptions about workflows, authority, or data flow.\n\nReal insight usually comes from abandoning old assumptions. This question helps distinguish founders who simply stumbled into AI from those who experienced a genuine shift in how they see the world.\n\nWe're looking for intellectual flexibility, not credentials. Strong answers point to a specific belief the founder once held, why they believed it, and what changed their mind; weak answers stay vague, like saying they \"realized AI was going to be big.\"\n\nThis question assumes copying is possible and pushes founders to explain what isn't obvious. Shallow answers fall back on claims like \"they couldn't move as fast\" or \"they don't have our data,\" while stronger ones point to hard-to-see advantages such as deep operational knowledge, customer-specific integrations, or accumulated context that isn't visible from the outside.\n\nFounders who can't point to moments where they changed their mind usually aren't learning ‚Äî they're executing a fixed plan in a world that won't stay fixed.\n\nThis question reveals epistemic humility and whether a founder is genuinely truth-seeking or just looking for confirmation. AI moves too fast for people who can't update, and we're especially wary of founders who treat every pivot as vindication rather than correction.\n\nMarket timing, regulatory shifts, and platform dependencies kill far more startups than bad management. This question tests whether founders think probabilistically about external forces and whether they've designed for resilience instead of relying on luck.\n\nFounders who say \"nothing\" haven't thought hard enough. The ones we want to back can name several concrete external risks and explain how they're hedging against them.\n\nThe best founders aren't contrarian for its own sake, but they can hold an unpopular position long enough for the world to catch up.",
    "readingTime": 6,
    "keywords": [
      "accumulated context",
      "we're looking",
      "foundation models",
      "leonis capital",
      "founders",
      "they're",
      "don't",
      "startups",
      "that's",
      "understand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/leonis-capital-investor-questions-for-ai-startups-2026-1",
    "thumbnail_url": "https://i.insider.com/697a63f2d3c7faef0ecd1b17?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.737Z",
    "topic": "finance"
  },
  {
    "slug": "what-the-latest-earnings-from-tesla-and-meta-tell-us-about-whos-winning-the-ai-race",
    "title": "What the latest earnings from Tesla and Meta tell us about who's winning the AI race",
    "description": "It turns out investors are willing to forgive huge capital spending if a company's core business is thriving.",
    "fullText": "Heading into Wednesday's hoy trinity of earnings ‚Äî which saw Meta, Microsoft, and Tesla report within five minutes of each other ‚Äî everyone knew that updates on AI progress would be the only game in town.\n\nHow those results ended up playing out shed crucial light on where we are in the AI trade right now.\n\nThe overarching focus for the Big Tech trio was not who has immediately seen results from AI investment. Instead, it was whether those companies were doing enough to support the appearance of maybe, eventually doing something. Investors love the prospect of future upside, and want a reason to preserve their optimism.\n\nEach of the three companies showcased this trend in their own unique way. Let's go one by one:\n\nLast quarter, Meta was punished for its capex-spending plans. This quarter, the company once again blew the doors off spending forecasts ‚Ä¶ but this time the market seemed OK with it.\n\nWhat changed? Look no further than the company's stronger-than-expected first-quarter revenue, driven by a big beat in advertising. Meta CFO Susan Li also got investors hyped on the earnings call by saying the company will fund its AI ambitions primarily with cash, rather than debt.\n\nIn the end, it's not that Meta has tangible proof that its AI spending is going to generate monstrous future earnings growth. The company has instead fallen back on its cash-cow advertising business to alleviate financing pressures and buy itself more time.\n\nWe haven't yet gotten an answer about whether the AI spending will pay off. We just know the company can afford to keep pursuing it.\n\nMarket reception: Very positive\n\nI present the counterpoint to Meta's well-received quarter. Microsoft also announced much larger-than-expected spending plans ‚Ä¶ and its stock fell.\n\nThe difference? One of Microsoft's main cash cows ‚Äî its Azure cloud-computing unit ‚Äî showed slowing growth. Suddenly, big spending doesn't look so appealing when your backstop is weakening.\n\nWhile Tesla's AI push has taken the form of self-driving vehicles and robotics, the company's lofty valuation is still being largely driven by hopes that big AI-linked profits will one day be unlocked.\n\nBut unlike Meta, the EV-maker is doing it at a time when its core business is in decline. One overlooked highlight of Tesla's report was that ‚Äî even though the company posted a bottom-line beat ‚Äî it also saw first-ever decline in annual revenue.\n\nIt didn't matter. Investors instead focused on Tesla's $2 billion investment in xAI, the company owned by Elon Musk. They also seemed to take the discontinuation of the Model S and Y vehicles in stride.\n\nAgain, the perception of eventually monetizing AI won out. In the AI race, it's not what you're doing, it's what you can convince everyone you're going to do down the line.",
    "readingTime": 3,
    "keywords": [
      "doing",
      "earnings",
      "instead",
      "investors",
      "quarter",
      "it's",
      "everyone",
      "investment",
      "eventually",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-meta-microsoft-q4-earnings-takeaways-stock-market-ai-race-2026-1",
    "thumbnail_url": "https://i.insider.com/697a9d3ce1ba468a96aaeb2d?width=1024&format=jpeg",
    "created_at": "2026-01-29T12:32:28.543Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-ai-will-make-saving-for-retirement-irrelevant-anthropics-ceo-says-building-that-future-wont-be-easy",
    "title": "Elon Musk says AI will make saving for retirement 'irrelevant.' Anthropic's CEO says building that future won't be easy.",
    "description": "Elon Musk said retirement savings would be pointless in an abundant future. Dario Amodei warned of job losses and rising inequality along the way.",
    "fullText": "Elon Musk recently said that saving for retirement could become \"irrelevant\" in the next decade, as new technologies promise to create such an abundance of resources that nobody will need a nest egg.\n\nDario Amodei warned this week that achieving a plentiful future won't be easy. The CEO of Anthropic, the AI startup behind ChatGPT-rival Claude, wrote in an essay that AI promises to \"raise the quality of life for everyone\" ‚Äî but there will be a brutal \"rite of passage\" to get there.\n\nAmodei said that at the current rate of progress, \"it cannot possibly be more than a few years before AI is better than humans at essentially everything.\"\n\nReplacing human labor with AI could supercharge economic growth and productivity, but the \"short-term shock will be unprecedented in size,\" he wrote.\n\nAmodei said he was worried that workers displaced by AI \"could form an unemployed or very-low-wage 'underclass,'\" and a tiny minority could capture most of the financial gains from AI, creating a \"level of wealth concentration that will break society.\"\n\nHe described those potential impacts on labor and equality as \"grave problems\" that AI companies, employers, philanthropists, and governments would have to work together to solve.\n\nAmodei noted that he and Anthropic's other cofounders have pledged to donate 80% of their wealth to good causes, and the company will match individual donations from its staff worth billions of dollars at its current valuation.\n\nAnthropic's boss shared a similar vision to Musk in a 2024 essay. He wrote that AI will eventually become \"so broadly effective and so cheap\" that the current economic system will \"no longer make sense.\"\n\nIt could be replaced by a \"large universal basic income for everyone,\" or a \"capitalist economy of AI systems\" that distributes \"huge amounts\" of resources to people as the \"overall economic pie will be gigantic,\" he added.\n\nBut he also flagged the risk of \"exploitative or dystopian directions\" and said, \"We will likely have to fight to get a good outcome here.\"\n\nBusiness Insider recently spoke to seven AI and personal finance gurus about Musk's vision, and they shared several of Amodei's concerns.\n\nThey urged Americans to keep saving for retirement just in case Musk is wrong ‚Äî and said that even if he's right, making sure everyone reaps the rewards of AI will require immense planning and coordination.",
    "readingTime": 2,
    "keywords": [
      "everyone",
      "economic",
      "recently",
      "saving",
      "retirement",
      "resources",
      "essay",
      "labor",
      "wealth",
      "anthropic's"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/elon-musk-retirement-saving-ai-abundance-anthropic-dario-essay-ubi-2026-1",
    "thumbnail_url": "https://i.insider.com/697b3ae9e1ba468a96aaedfd?width=1200&format=jpeg",
    "created_at": "2026-01-29T12:32:28.350Z",
    "topic": "finance"
  },
  {
    "slug": "universal-basic-income-could-be-used-to-soften-hit-from-ai-job-losses-in-uk-minister-says",
    "title": "Universal basic income could be used to soften hit from AI job losses in UK, minister says",
    "description": "Lord Stockwood says people in government ‚Äòdefinitely‚Äô talking about idea as technology disrupts industries\n‚Ä¢ Business live ‚Äì latest updates\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n‚ÄúBumpy‚Äù changes to society caused by the introduction of the technology would mean there would have to be ‚Äúsome sort of concessionary arrangement with jobs that go immediately‚Äù, Lord Stockwood said.\n Continue reading...",
    "fullText": "Lord Stockwood says people in government ‚Äòdefinitely‚Äô talking about idea as technology disrupts industries\n\nThe UK could introduce a universal basic income (UBI) to protect workers in industries that are being disrupted by AI, the investment minister Jason Stockwood has said.\n\n‚ÄúBumpy‚Äù changes to society caused by the introduction of the technology would mean there would have to be ‚Äúsome sort of concessionary arrangement with jobs that go immediately‚Äù, Lord Stockwood said.\n\nThe Labour peer told the Financial Times: ‚ÄúUndoubtedly we‚Äôre going to have to think really carefully about how we soft-land those industries that go away, so some sort of [universal basic income], some sort of lifelong mechanism as well so people can retrain.‚Äù\n\nA universal basic income is not part of official government policy, but when asked whether people in government were considering the need for UBI, Stockwood told the FT: ‚ÄúPeople are definitely talking about it.‚Äù\n\nThe technology entrepreneur, who took up his ministerial post in September, said part of his motivation for joining the government was to help ensure the workforce was prepared for rapid change.\n\nFears continue to grow about the impact of artificial intelligence on Britain‚Äôs job market. This week research by the investment bank Morgan Stanley found the UK was losing more jobs than it is creating because of AI and was being hit harder than other large economies.\n\nThis month the mayor of London, Sadiq Khan, said AI could destroy swathes of jobs in the capital and ‚Äúusher in a new era of mass unemployment‚Äù.\n\nLast week, Jamie Dimon, the chief executive of the US bank JP Morgan, told the World Economic Forum in Davos that governments and businesses would have to step in to help workers whose roles were displaced by the technology, or risk civil unrest.\n\nStockwood, who held senior positions at Lastminute.com, Travelocity and Match.com, oversaw the $490m (¬£400m at the time) sale of the online insurance broker Simply Business to the US insurer Travelers in 2017. He later bought a stake the football club of his home town, Grimsby Town FC.\n\nWhile he has previously been a vocal proponent of a wealth tax in the UK, Stockwood told the FT he had not repeated his calls for the government to go further on taxing the rich.\n\nHowever, he added: ‚ÄúIf you make your money and the first thing you do is you speak to a tax adviser to ask: ‚ÄòWhere can we pay the lowest tax?‚Äô we don‚Äôt want those people in this country, I‚Äôd suggest, because you‚Äôre not committed to your communities and the long-term success in this country.‚Äù\n\nStockwood was preceded as investment minister by Poppy Gustafsson, a former chief executive of the cybersecurity firm Darktrace, who stepped down after less than a year in the job.",
    "readingTime": 3,
    "keywords": [
      "chief executive",
      "universal basic",
      "basic income",
      "investment minister",
      "lord stockwood",
      "technology",
      "industries",
      "sort",
      "jobs",
      "talking"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/29/universal-basic-income-used-cover-ai-job-losses-minister-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/de673ed46d19dc117c208edb6f803b2eca7c5ad8/1020_268_1578_1263/master/1578.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1431031c71c27093dd3511ca51014201",
    "created_at": "2026-01-29T12:32:28.046Z",
    "topic": "tech"
  },
  {
    "slug": "the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "title": "The slopaganda era: 10 AI images posted by the White House - and what they teach us",
    "description": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here‚Äôs what you need to know to navigate the trolling\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it‚Äôs developed into a full-blown phenomenon, one academics are calling ‚Äúslopaganda‚Äù ‚Äì an unholy alliance of easily available AI tools and political messaging. ‚ÄúShitposting‚Äù, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of ‚Äúinstitutional shitposting‚Äù, according to Know Your Meme‚Äôs editor Don Caldwell. This is trolling as official government communication.",
    "fullText": "Under Donald Trump, the White House has filled its social media with memes, wishcasting, nostalgia and deepfakes. Here‚Äôs what you need to know to navigate the trolling\n\nIt started with an image of Trump as a king mocked up on a fake Time magazine cover. Since then it‚Äôs developed into a full-blown phenomenon, one academics are calling ‚Äúslopaganda‚Äù ‚Äì an unholy alliance of easily available AI tools and political messaging. ‚ÄúShitposting‚Äù, the publishing of deliberately crude, offensive content online to provoke a reaction, has reached the level of ‚Äúinstitutional shitposting‚Äù, according to Know Your Meme‚Äôs editor Don Caldwell. This is trolling as official government communication. And nobody is more skilled at it than the Trump administration ‚Äì a government that has not only allowed the AI industry all the regulative freedom it desires, but has embraced the technology for its own in-house purposes. Here are 10 of the most significant fake images the White House has put out so far.\n\nThe first AI image posted by the White House X account sets the tone for Trump‚Äôs second presidency ‚Äì marking a turning point in which the shitposting that had been associated with the far-right online culture that brought Trump to power moved from fringe message boards, such as 4chan and Reddit, to mainstream platforms.\n\nThe image was posted alongside an announcement of the repeal of New York City‚Äôs congestion pricing, and leant into fears that Trump would govern as a king. The New York governor, Kathy Hochul, held up the image at a press conference when she announced that she would defy attempts to block the congestion charge: ‚ÄúNew York hasn‚Äôt laboured under a king in over 250 years. We sure as hell are not going to start now.‚Äù The congestion charge remains in effect.\n\nIn another post on Truth Social in October, the president posted an AI video depicting himself as a president-king, crown on head, flying over ‚ÄúNo Kings‚Äù protesters in a jet fighter and dumping faeces on them. The House speaker, Mike Johnson, defended the post, saying: ‚ÄúThe president uses social media to make a point. You can argue that he‚Äôs probably the most effective person who‚Äôs ever used social media for that. He is using satire to make a point.‚Äù\n\nOpenAI‚Äôs Studio Ghibli-inspired meme generator became a sensation in March 2025, with its uncanny ability to translate any image into the beloved anime studio‚Äôs house style (without Studio Ghibli‚Äôs permission or approval).\n\nThe White House applied it to a woman in tears as she was arrested by Immigration, Customs and Enforcement (ICE) agents before being deported. The original photograph, and the woman‚Äôs name and alleged crimes, are also included in the post.\n\nFor Caldwell, this demonstrated just how up to date the White House is with online trends. ‚ÄúThey‚Äôre hopping on brand-new, fresh memes,‚Äù he says. He suspects White House staffers might be regular visitors to Know Your Meme. ‚ÄúThe Studio Ghibli meme trend kicked off on March 25 on X; we covered it the following day; and then the White House covered it the day after that.‚Äù\n\nThis image is proof of Trump‚Äôs willingness and ability to insert himself into any conversation, even ones that have nothing to do with him, and shows how effective that can be.\n\nPredictably, the image went viral, made global headlines and was met with outrage from Catholic groups and politicians. ‚ÄúThere is nothing clever or funny about this image, Mr President,‚Äù wrote the New York State Catholic Conference. ‚ÄúWe just buried our beloved Pope Francis and the cardinals are about to enter a solemn conclave to elect a new successor of St Peter. Do not mock us.‚Äù\n\nAs so often happens with such shitposting, those who ‚Äãtook offence were accused of lacking a sense of humour. ‚ÄúThey can‚Äôt take a joke?‚Äù Trump said soon after at a press conference. ‚ÄúYou don‚Äôt mean the Catholics, you mean the fake news media ‚Ä¶ the Catholics loved it.‚Äù\n\nTrump has been the subject of flattering fan art throughout his political career (remember the digital Trump trading cards?), but AI has made the job a whole lot easier. On 4 May, the White House crashed Star Wars fans‚Äô special day with this image of the president as a jacked Jedi, lightsaber in hand, garlanded by flags and eagles. Who cares if his lightsaber is the wrong colour (the good guys‚Äô are blue), or that the White House‚Äôs claim to be the Rebellion not the Empire rang laughably hollow? This was pure fantasy art.\n\nIn 2022, one of Trump‚Äôs trading cards clumsily grafted his headshot on to a superhero body; last July he was slightly less clumsily grafted on to the body of Superman, to gatecrash the launch of the new movie. The same month, the White House portrayed a besuited Trump heroically striding into the Colosseum. Fans and allies have generated reams of similar content themselves.\n\nWhy did the White House choose to put the Democratic house leader Hakeem Jeffries and the senate leader Chuck Schumer in sombreros and have them holding plates of tacos? It doesn‚Äôt matter. They look a bit silly, and it‚Äôs provocatively offensive, and once again, the world‚Äôs attention is colonised.\n\nThe image illustrates how difficult it is to respond to this type of content. It‚Äôs part of a running joke, stretching back to a deepfake video Trump posted a month earlier, which slapped a crude sombrero and moustache filter over Jeffries. That video was roundly condemned as offensive and racist , not least by Jeffries himself (who replied by posting a genuine image of Trump with the sex offender Jeffrey Epstein) . The Trump administration then doubled down, playing the video on a loop on screens in the White House briefing room for several hours and creating more images in a similar vein, which kept the trolling going.\n\nFew people outside the Trump administration believe the US is in a ‚Äúgolden age‚Äù, but that hasn‚Äôt stopped Trump from repeating the claim. In January, the White House posted an AI video of a golden White House facade behind a shower of gold coins with the text ‚ÄúThe White House? She‚Äôs in her Golden Age‚Äù, backed by Bruno Mars‚Äô track 24K Magic.\n\nEven if Trump‚Äôs Midas touch is more a figment of his imagination, this type of wishcasting is more effective than it appears. According to one paper by the academics Micha≈Ç Klincewicz, Mark Alfano and Amir Ebrahimi Fard ‚Äì who coined the term ‚Äúslopaganda‚Äù ‚Äì ‚Äúneural representations of information that were shown to be false continue to influence people‚Äôs beliefs and reasoning after being corrected‚Äù. In other words, even when you know it‚Äôs fake, your brain still kind of believes it.\n\nOn the face of it, this seems like a straightforward ‚ÄúTrump wants Greenland‚Äù post. However, it has a much darker message.\n\nAgain, the post is riffing on a popular meme, Caldwell explains: the ‚Äúdramatic crossroads‚Äù image originated with the manga series Yu-Gi-Oh!, and started gaining traction online around 2021.\n\nThe slogan ‚ÄúWhich way, Greenland man?‚Äù seems to reference a 1978 neo-Nazi text titled Which Way, Western Man?, in which the white supremacist author William Gayley Simpson called for violence against and the deportation of Jews and Black people, and argued that Hitler was right.\n\n‚ÄúIt‚Äôs absolutely shocking to see such images being deployed by this administration,‚Äù said Heidi Beirich, a co-founder of the Global Project Against Hate and Extremism, which monitors US neo-Nazi groups. ‚ÄúThe idea appeals to racists and white supremacists who think only white people should be in positions of power.‚Äù\n\nIn August, the Department of Homeland Security posted a mock recruitment advert for ICE with an image of Uncle Sam at a crossroads and the slogan: ‚ÄúWhich way, American man?‚Äù Earlier this month, the US Labor Department posted an image with the slogan: ‚ÄúOne Homeland. One People. One Heritage‚Äù. Critics pointed out that it had overtones of Hitler‚Äôs ‚ÄúEin Volk, ein Reich, ein F√ºhrer‚Äù (‚ÄúOne people, one realm, one leader‚Äù).\n\n‚ÄúAI is very good at constantly reiterating images from the past, so it can create this nostalgic imagery of traditionalism,‚Äù says Daniel de Zeeuw, an assistant professor in digital media culture at the University of Amsterdam. Thus the extremist messages of the present ‚Äì such as ICE‚Äôs militarised policing ‚Äì can be inserted into more reassuring and familiar graphic styles, such as patriotic recruitment posters, 80s action-movie posters or 1950s public information campaigns (as with a recent image of Trump as a friendly milkman).\n\nAI is inherently backward-looking, says de Zeeuw, as it is fed on historical images. This aesthetic is in keeping with the Make America Great Again movement, which is constantly evoking a ‚Äúbetter‚Äù past. Another stark example was the Department of Homeland Security‚Äôs chilling post from last December: an image of a vintage car at a deserted, palm-fringed beach with the slogan ‚ÄúAmerica After 100 Million Deportations‚Äù. Ironically, the original was painted by a Japanese artist, Hiroshi Nagai, who complained that it had been used without his permission.\n\n‚ÄúIt‚Äôs not going to be on Twitter,‚Äù said the agent filming the Minneapolis civil rights lawyer Nekima Levy Armstrong, one of the city‚Äôs most prominent activists, as she was arrested last Thursday. Within hours, though, it was: the Homeland Security secretary Kristi Noem posted a still from the video, in which Armstrong seems composed and shows little emotion.\n\nHalf an hour later, the White House X account posted a significantly altered version of the same image: this time, Armstrong is exaggeratedly upset, tears streaming down her face. Her skin tone also appears to have been darkened. The image was captioned: ‚ÄúArrested: far-left agitator Nekima Levy Armstrong for orchestrating church riots in Minnesota.‚Äù In fact, Armstrong was demonstrating at a church service led by an allegedly ICE-affiliated pastor, and was later released without charge.\n\nUntil this moment, the White House‚Äôs AI-generated output had been conspicuously outlandish: there was little danger of mistaking it for reality. This image purports to be an authentic photograph ‚Äì or at least omits to mention that it is not. It is not so much AI-generated trolling as an AI-assisted deepfake.\n\nAs with Musk‚Äôs recently shared Grok tool, which removed women and children‚Äôs clothing without their consent, there is also something abusive about it: AI has been used to attempt to humiliate a woman by manipulating her image, to make her look weaker and more distressed than she actually was.\n\nThe fact that the deepfakery is not all that convincing is part of the point, de Zeeuw thinks. ‚ÄúWhat is being communicated here is the falsification itself: you‚Äôre showing your ability to falsify images, to falsify evidence.‚Äù\n\nAfter the fakery had been called out, the White House deputy communications director Kaelan Dorr posted the response: ‚ÄúEnforcement of the law will continue. The memes will continue.‚Äù\n\nIn response to this image of Trump and a penguin walking towards a Greenland flag, some observers pointed out that penguins actually live at the south pole. But that‚Äôs missing the point of these types of post, says Robert Topinka, a reader in digital media and rhetoric at Birkbeck, University of London. ‚ÄúPeople continue to interpret them as if they‚Äôre meant to be a legitimate claim, or an argument or a piece of evidence, but they‚Äôre emotional hooks.‚Äù Their purpose is to stir up the base. ‚ÄúWhite House staffers have said they use AI because it‚Äôs the fastest way to get content out. It‚Äôs not the fastest way to say something that‚Äôs true; it‚Äôs the fastest way to push their propaganda.‚Äù\n\nTo those in the know, this is a riff on the ‚Äúnihilist penguin‚Äù meme, which has gone viral on TikTok in the past few weeks. It‚Äôs based on a scene from Werner Herzog‚Äôs 2007 documentary Encounters at the End of the World, in which one penguin inexplicably separates from the colony and wanders off towards the Antarctic interior, and certain death. ‚ÄúBut why?‚Äù Herzog wonders. Many have asked the same of Trump‚Äôs quixotic attempts to acquire Greenland.\n\nThe image resonates with what Naomi Klein and ‚ÄãAstra Taylor ‚Äãchristened ‚Äúend times fascism‚Äù, says De Zeeuw, where tech industry leaders and their enablers are almost willing the end of the world as we know it, striding towards oblivion like Trump and his penguin companion. ‚ÄúIt‚Äôs like they know they‚Äôre moving toward the end, but they do so joyfully.‚Äù",
    "readingTime": 11,
    "keywords": [
      "white house",
      "nekima levy",
      "levy armstrong",
      "trading cards",
      "clumsily grafted",
      "house account",
      "house staffers",
      "trump administration",
      "press conference",
      "congestion charge"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/2026/jan/29/the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4b7cb2fd8f7d06f369527b2702d8dbea84ffdad2/0_105_2160_1728/master/2160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=642ec79d432723197b75c7a515cf46a0",
    "created_at": "2026-01-29T12:32:28.039Z",
    "topic": "tech"
  },
  {
    "slug": "whos-hiring-scab-protocol-remote-equityonly",
    "title": "Who's Hiring: Scab Protocol (Remote, Equity-Only)",
    "description": "The runtime behavioral governance framework for AI systems. Measure, monitor, and control AI behavior continuously across six domains.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://scab.dev",
    "thumbnail_url": "https://pub-bb2e103a32db4e198524a2e9ed8f35b4.r2.dev/c2ebdabd-7464-44b8-8d02-2182d6a360c2/id-preview-9af3fcbe--351023f6-eb8a-4801-b737-973f998527b3.lovable.app-1769664312714.png",
    "created_at": "2026-01-29T06:34:22.725Z",
    "topic": "tech"
  },
  {
    "slug": "5-of-the-biggest-takeaways-from-metas-q4-2025-earnings-call",
    "title": "5 of the biggest takeaways from Meta's Q4 2025 earnings call",
    "description": "Meta's Q4 2025 earnings reveal massive AI investment plans, ad-driven revenue growth, and costly Reality Labs losses.",
    "fullText": "Meta's earnings sent a clear signal to Wall Street on Wednesday: while its core advertising engine is still firing on all cylinders, the price tag for CEO Mark Zuckerberg's AI ambitions will skyrocket in 2026.\n\nThe company reported $59.89 billion in revenue for the fourth quarter of 2025, topping Wall Street's forecasts. Meta's stock jumped as high as 10% in after-hours trading.\n\nAlongside the upbeat numbers, Meta laid out how hard it plans to push in 2026. The company said it expects to spend $115 billion to $135 billion next year on capital expenditures ‚Äî largely on the computers and data centers that power AI.\n\nIn other words, Meta still makes most of its money from ads. It's asking investors to stay on board as it pours an extraordinary amount of cash into the race to build more powerful AI and weave it into Instagram, WhatsApp, Facebook, and virtual and augmented reality products, collectively used by more than 3.5 billion people daily around the world.\n\nHere are five takeaways from Meta's Q4 2025 earnings call.\n\nMeta told to brace for a much more expensive 2026 as it pours money into the compute and data centers needed to power its AI push. The company said it expects capital expenditures in 2026 to land between $115 billion and $135 billion ‚Äî up to almost double the $72 billion it spent in 2025.\n\nMeta's chief financial officer, Susan Li, said the increased expenditure will support Meta Superintelligence Labs' efforts and its core business.\n\nLi also warned that Meta's overall costs are set to climb fast. The company expects total 2026 expenses of $162 billion to $169 billion, with most of the increase coming from \"infrastructure costs,\" including \"third-party cloud spend, higher depreciation, and higher infrastructure operating expenses.\"\n\nAnd Meta isn't just buying more machines ‚Äî it's also paying for people to run them. Li said the \"second-largest contributor\" to expense growth will be compensation, driven by \"investments in technical talent,\" including hires in \"priority areas, particularly AI.\"\n\nAdvertising once again powered Meta's quarter. The company reported $58.14 billion in ad revenue in Q4 2025, up 24% from the same time last year. That growth came from a mix of showing more ads (ad impressions rose 18% from the same quarter last year) and charging a bit more per ad (average price per ad rose 6%).\n\nWhen analysts pressed Zuckerberg on whether Meta can build meaningful businesses beyond ads, given how much cash it's pouring into AI, he didn't dodge the question of its dependency.\n\n\"For the next couple of years, ads are going to be by far the most important driver of growth in our business,\" Zuckerberg said, adding that Meta is working on new bets alongside that core engine.\n\nMeta's pitch is that its AI investments are already making the ad machine work better ‚Äî not just by targeting, but by improving the systems that decide which ads people will most likely engage with.\n\nThe company said that its AI tools for making video ads hit a $10 billion revenue run rate. It also said a newer measurement product helped advertisers drive 24% more conversions than its standard method ‚Äî and ramped up to a multi-billion-dollar annual run rate in just seven months.\n\nReality Labs, the division behind Meta's virtual and augmented reality efforts, continued to burn cash in the final quarter of 2025. The division lost $6.02 billion in a quarter, the highest ever, and $19.19 billion in 2025 ‚Äî numbers that underscore how much Meta's ambitions to build immersive worlds still depend on ad revenue.\n\nDespite laying off about 1,500 people at Reality Labs earlier this month, Meta told investors not to expect a sudden turnaround. Li said the company expects Reality Labs' operating losses in 2026 to remain \"similar to 2025 levels.\"\n\nZuckerberg is trying to reposition what Reality Labs is building. The company's focus has shifted from trying to go all in on the \"metaverse\" to building AI-powered smart glasses and experiences that could live inside Meta's existing apps.\n\nWhen Barclays analyst Ross Sandler asked about Meta's plans to bring Horizon Worlds, a virtual hangout zone accessible on the company's Quest VR headsets, to mobile, Zuckerberg said that he expects more \"interactive and immersive\" content formats to show up directly inside the feeds in Meta's existing apps.\n\nHe added that people might be able to use AI to create a game with a single prompt and share it on their feeds so that others can \"jump right into it.\"\n\nHe positioned Horizon Worlds as a natural fit for an \"immersive 3D\" version of that idea and said that Meta's work on VR software and Horizon could pair with AI advances to bring these kinds of experiences to \"hundreds of millions and billions of people through mobile.\"\n\nMeta isn't just trying to sprinkle AI features across Facebook and Instagram. Zuckerberg is making a bigger argument: if Meta wants to shape the next generation of consumer tech, it needs to control the underlying AI, not just depend on whatever rivals sell.\n\nThat's also the framing behind his public push for \"personal superintelligence,\" which he called out again as a key focus for 2026.\n\nWhen Wells Fargo analyst Ken Gawrelski asked how critical it is for Meta to have a general-purpose model, Zuckerberg leaned into Meta's identity as a \"deep technology company.\"\n\nWhat allows Meta to build everything it does, he said, \"is that we build and control the underlying technology.\" That way, Meta can design the experiences it wants, \"and not just be constrained to what others in the ecosystem are building or allow us to build,\" Zuckerberg added.\n\nHe suggested that relying on outside models could become risky over time, citing a mix of competitive and safety reasons. That's why, he said, it's important for Meta to have its own models, both from a business perspective and because Meta wants to \"actually design and build the experiences that we believe that we should be building for people.\"\n\nZuckerberg is pitching 2026 as the year AI changes not just Meta's products, but how Meta itself operates. On the call, he said 2026 will be \"the year that AI starts to dramatically change the way that we work\" and that the company is \"investing in AI native tooling so individuals at Meta can get more done.\"\n\nHe also described a deliberate shift in org design.\n\n\"We're elevating individual contributors and flattening teams,\" Zuckerberg said, adding that Meta is already seeing \"projects that used to require big teams now be accomplished by a single, very talented person.\"\n\nLi paired that cultural pitch with a concrete productivity claim. She said that since the beginning of 2025, Meta has seen a \"30% increase in output per engineer\" overall, and that \"power users\" of its internal AI coding tools saw output rise 80% year-over-year.\n\nThe company's implied bet? Spend heavily on AI infrastructure and tooling, and then run leaner teams that can ship more.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "augmented reality",
      "meta's earnings",
      "meta's existing",
      "capital expenditures",
      "existing apps",
      "meta isn't",
      "reality labs",
      "horizon worlds",
      "quarter",
      "revenue"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-ai-investments-capex-2026-1",
    "thumbnail_url": "https://i.insider.com/697ab091d3c7faef0ecd23e6?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.656Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-says-openai-is-driving-45-of-the-backlog-for-azure-cloud-computing",
    "title": "Microsoft says OpenAI is driving 45% of the backlog for Azure cloud computing",
    "description": "OpenAI and Microsoft have a reconfigured relationship. The software giant revealed just how much OpenAI is driving its RPO.",
    "fullText": "Microsoft¬†is facing capacity constraints, and OpenAI is driving a large portion of the backlog in its cloud computing business.\n\nThe company said its backlog in commercial bookings, a metric referred to as remaining performance obligations, ballooned 110% year over year to $625 billion when it reported earnings for the second quarter on Wednesday.\n\nOpenAI accounts for roughly 45% of those commitments, Microsoft revealed. The company did not say how much OpenAI contributed during the previous quarter.\n\nSome Wall Street analysts on the call expressed concerns about Microsoft's dependency on OpenAI.\n\nCEO Satya Nadella said acquiring more Azure clients is important to the tech giant, but it can't come at the expense of neglecting its other services.\n\n\"If you think about it, acquiring an Azure customer is super important to us, but so is acquiring an M365 or a GitHub or a Dragon Copilot, which are all, by the way, incremental businesses and TAMs for us,\" Nadella said during Microsoft's second-quarter earnings call. \"And so we don't want to maximize just one business of ours.\"\n\nShares of Microsoft fell more than 6% in after-market trading on Wednesday, even as the tech giant posted an overall earnings beat.\n\nMorgan Stanley's Keith Weiss said during the call that some on Wall Street may be spooked by slower growth in overall Azure revenue and the increase in capex spending. Microsoft's capital expenditures rose 66% year over year to $37.5 billion in the second quarter, another record for the company and testament to the sheer amount of money tech companies are spending amid the AI race.\n\nCFO Amy Hood said that Microsoft has to look at many different areas when it allocates the GPUs and CPUs that come online as a result of its capex spending, including investing in the growth of first-party apps like Microsoft Copilot, devoting GPUs to research and development, and the talent they've acquired.\n\n\"You end up with the remainder going towards serving the Azure capacity that continues to grow in terms of demand,\" she said.\n\nMicrosoft is not alone in facing capacity issues.\n\nExecutives at OpenAI, which has pledged to spend $250 billion on Azure services, have repeatedly said the startup is held back by a lack of compute, forcing tough trade-offs between product and research.\n\nWednesday's earnings mark the first quarter since OpenAI completed its restructuring, which included a new agreement with Microsoft, the startup's largest investor. Microsoft owns 27% of the public benefit corporation.\n\n\"It's a great partnership,\" Hood said of Microsoft's relationship with OpenAI. It's allowed us to remain a leader in terms of what we're building and being on the cutting edge of app innovation.\"",
    "readingTime": 3,
    "keywords": [
      "facing capacity",
      "tech giant",
      "second quarter",
      "azure",
      "earnings",
      "microsoft's",
      "acquiring",
      "microsoft",
      "openai",
      "backlog"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-openai-azure-cloud-computing-backlog-2026-1",
    "thumbnail_url": "https://i.insider.com/697aa643a645d118818833f0?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.651Z",
    "topic": "finance"
  },
  {
    "slug": "tesla-takes-another-leap-toward-becoming-a-physical-ai-company-here-are-the-6-biggest-takeaways-from-its-q4-earnings",
    "title": "Tesla takes another leap toward becoming a physical AI company: Here are the 6 biggest takeaways from its Q4 earnings call.",
    "description": "Tesla CEO Elon Musk announced a $2B investment into xAI and the discontinuation of Model S and Model X in order to support Optimus robot production.",
    "fullText": "Tesla is making another leap to shed its EV maker title and transform into a full-fledged physical AI outfit.\n\nThe theme of Wednesday's fourth-quarter earnings call heavily centered on how Tesla is investing in its future as an AI and robotics company ‚Äî a narrative CEO Elon Musk has pushed for some time now.\n\nThe bets included: a major investment in Musk's xAI, updates on the Optimus humanoid robot, and a renewed push for in-house chipmaking. Musk projected that Tesla's future will require a $20 billion investment, which dwarfs the company's $8.5 billion in capex reported for the 2025 fiscal year.\n\nMeanwhile, Tesla's automotive segment took a back seat: Musk said he's killing the Model S and Model X to free up room for humanoid robot production. And while Tesla's energy and \"services\" revenue jumped 25% and 18%, respectively, auto revenue fell 11% year-over-year ‚Äî a clear indication that the quarter's growth came from everywhere but its core EV business.\n\n\"We've updated the Tesla mission to amazing abundance, and this is an attempt to send a message of optimism about the future,\" Musk said during the call.\n\nThe company's stock rose 1.7% after the market closed on Wednesday evening.\n\nHere are 6 biggest takeaways from the earnings call.\n\nTesla made good on its pledge to investors and announced a $2 billion investment into xAI, the startup behind Grok. It's part of a larger $20 billion Series E funding round from January.\n\nThe expectation of the investment is a deeper collaboration between the two companies. xAI, which has been expanding its data center footprint, could provide the compute and other technical capabilities to further advance Tesla's autonomous vehicle and robotics agenda.\n\nVaibhav Taneja, Tesla's chief financial officer, said during the call that the agreement with xAI is in the spirit of finding \"efficient ways for others to help us.\"\n\nIn a surprise move, Musk announced that production of the Model S and Model X would be discontinued by the next quarter, closing a chapter on the company's premium SUV and sedan.\n\nThat leaves the EV maker with four cars: the Cybertruck, the more popular Model 3 and Model Y, and the yet-to-be-released Cybercab.\n\nThe CEO said during the call that the move will provide more production space in Tesla's Fremont factory for Optimus robots.\n\nThe \"long-term goal\" is to produce a million units a year with the freed-up space, Musk said.\n\nThe CEO added that killing the Model S and Model X is part of Tesla's \"overall shift to an autonomous future,\" which includes the company's ride-hailing service, Tesla Robotaxi, and autonomy in personally owned vehicles through Full Self-Driving, an advanced driver assistance system.\n\nTesla expects to start production of the Cybercab, a two-seater coupe, in April for eventual integration into its Robotaxi fleet.\n\nTesla revealed where it aims to expand the Robotaxi ride-hailing service in the first half of 2026 ‚Äî Dallas, Houston, Phoenix, Miami, Orlando, Tampa, and Las Vegas ‚Äî but has yet to announce when it will remove the safety monitors inside the cars for public riders across Austin and San Francisco Bay Area, where the service now operates.\n\nMusk said that FSD ‚Äî the technology that Tesla says will make personally owned vehicles fully autonomous ‚Äî is already \"100% unsupervised\" and operating without humans inside. The difference, he said, is that Tesla is being \"very cautious\" with rolling out unsupervised service to the public, though Tesla began offering a limited number of unsupervised rides in Austin this month.\n\n\"There's like some pretty nutty intersections, where there are a lot of humans who make mistakes and have accidents in various cities,\" Musk said. \"So we want to make sure that FSD can handle those unusual intersections.\"\n\nThere wasn't much of a progress report on Tesla's AI5 chip, but the CEO said he's spending part of his weekends working on it.\n\n\"If I'm spending my Saturdays on something, it's going to be something pretty important,\" Musk said, adding that chip procurement is \"existential\" for Tesla's future, going so far as to bring up the Tesla \"Terafab\" ‚Äî his aspirational idea of building an in-house chip manufacturing plant.\n\nMusk said he wants to build a factory that integrates \"logic, memory, and packaging\" because Tesla will be \"fundamentally limited by supply chain\" if it doesn't.\n\nMusk said he expects to unveil an Optimus 3 robot in a \"few months,\" but don't expect it to be working the assembly lines just yet.\n\nThe CEO said Optimus isn't contributing to Tesla's manufacturing work in any \"material way\" and that the humanoid robot is only in the factory for training purposes.\n\nMusk talked a lot about Tesla's future, but the company's fourth-quarter performance still hinged on its tangible businesses, such as its energy segment, which includes the Megapack, a utility-scale battery system, and the Powerwall, the home battery system.\n\n\"On the energy front, we achieved yet another record in terms of gross profits for the quarter and ended the year with nearly $12.8 billion in revenue,\" Taneja, the Tesla CFO, said.\n\nTesla also announced this month that it will pivot FSD to a subscription-based only model starting in February. Customers previously had the option to buy FSD upfront for $8,000.\n\nThe move is a clear signal that Tesla sees FSD as a key future revenue generator.\n\nAutomakers are increasingly betting that software subscription services will be a critical source of recurring revenue with higher margins. General Motors revealed that its vehicle software generated $2 billion in the past nine months.\n\nTesla did not respond to a request for comment.",
    "readingTime": 5,
    "keywords": [
      "personally owned",
      "owned vehicles",
      "battery system",
      "model and model",
      "humanoid robot",
      "ride-hailing service",
      "the ceo",
      "company's",
      "revenue",
      "tesla"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tesla-q4-earnings-call-summary-robotaxi-optimus-ai5-chips-2026-1",
    "thumbnail_url": "https://i.insider.com/697ac36dd3c7faef0ecd2457?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.534Z",
    "topic": "finance"
  },
  {
    "slug": "openais-chair-says-vibe-coding-is-here-to-stay-but-its-not-the-endgame",
    "title": "OpenAI's chair says vibe coding is here to stay ‚Äî but it's not the endgame",
    "description": "Vibe coding will stick around, but AI agents, not apps, will drive the next big shift in software, says OpenAI's chair Bret Taylor.",
    "fullText": "Vibe coding isn't going anywhere. But it's only part of a much bigger transformation, says OpenAI's board chair.\n\nBret Taylor said in an episode of the \"Big Technology Podcast\" published on Wednesday that using AI tools to build software quickly with natural language prompts will soon feel normal rather than novel. However, focusing on building today's software faster misses the bigger picture.\n\n\"Everyone's looking at all the software use and saying, 'How fast could I vibe code that?'\" Taylor said. \"I wonder if it's the wrong question.\"\n\nWhether someone can quickly vibe code an app in a web browser isn't \"the most interesting question in software,\" he added.\n\nInstead, the software we use today is set to be replaced, and that's the real disruption, Taylor said.\n\nRather than dashboards, web-browser forms, and traditional apps, the structure of software will change. AI agents will be \"the future of software.\"\n\n\"We will delegate tasks to agents that will operate against a database,\" Taylor said.\n\n\"Who's making those agents is the question,\" he added. \"Will you buy those agents off the shelf or build them yourself?\"\n\nTaylor also said that while AI has slashed the cost of building software, it hasn't solved the harder problems of maintaining it ‚Äî or the risk of getting things wrong.\n\n\"That's why most people would prefer to buy a solution off the shelf,\" he said. \"You want to amortize the cost of maintaining software among thousands of clients.\"\n\nVibe coding has taken off across the tech world, but tech leaders said the technology has limits.\n\nGoogle CEO Sundar Pichai said in November in a \"Google for Developers\" podcast interview that vibe coding is \"making coding so much more enjoyable,\" adding that it allows even non-technical users to create simple apps and websites.\n\nDuring Alphabet's April earnings call, Pichai said AI generates more than 30% of Google's new code, up from 25% in October 2024.\n\nStill, AI-generated code can be error-prone, overly long, or poorly structured.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said last month that vibe coding works best for prototypes or throwaway code, but not in software that sits at the core of a business.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he said in an episode of \"The Peterman Podcast\" published in December.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "vibe coding",
      "vibe code",
      "software",
      "agents",
      "isn't",
      "it's",
      "bigger",
      "episode",
      "quickly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-chair-vibe-coding-not-endgame-bret-taylor-2026-1",
    "thumbnail_url": "https://i.insider.com/6883b14a85e81483682eb19e?width=1200&format=jpeg",
    "created_at": "2026-01-29T06:34:22.533Z",
    "topic": "finance"
  },
  {
    "slug": "why-aimediated-decisions-require-a-ledger",
    "title": "Why AI-Mediated Decisions Require a Ledger",
    "description": "When AI-generated narratives influence belief or decision-making, no reconstructable record typically exists. This paper defines the evidentiary gap and specifies the properties required to restore accountability without prescribing standards or remedies.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/reasoning-without-records/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-29--2026-at-06_52_34-AM.png",
    "created_at": "2026-01-29T06:34:21.805Z",
    "topic": "tech"
  },
  {
    "slug": "relnotesapp-turn-github-prs-into-your-fridays-report-automatically",
    "title": "Relnotes.app ‚Äì Turn GitHub PRs into your Friday's report automatically",
    "description": "Relnotes is an AI-powered platform that automatically generates and distributes release notes from GitHub pull requests. Keep stakeholders informed with automated, professional release communications.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://relnotes.app/",
    "thumbnail_url": "https://relnotes.app/og-image.png",
    "created_at": "2026-01-29T06:34:20.256Z",
    "topic": "tech"
  },
  {
    "slug": "fork-and-make",
    "title": "Fork and Make",
    "description": "meta-collection of my ai projets. See delta-version for meta-project control scripts. - gabrilend/ai-stuff",
    "fullText": "gabrilend\n\n /\n\n ai-stuff\n\n Public\n\n meta-collection of my ai projets. See delta-version for meta-project control scripts.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n gabrilend/ai-stuff",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/gabrilend/ai-stuff",
    "thumbnail_url": "https://opengraph.githubassets.com/6d3f82a3970731e90e7c0f6d6e93c249f3fb4c7301fa0e9f432ba4dc508fe12d/gabrilend/ai-stuff",
    "created_at": "2026-01-29T01:07:08.044Z",
    "topic": "tech"
  },
  {
    "slug": "death-of-an-indian-tech-worker",
    "title": "Death of an Indian Tech Worker",
    "description": "A wave of suicides and widespread AI-fueled layoffs reveal a workforce under extreme pressure.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://restofworld.org/2026/india-tech-workers-crisis-suicide/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2025/12/sized_India_IT_Deaths_DSC4011-1600x900.jpg",
    "created_at": "2026-01-29T01:07:06.574Z",
    "topic": "tech"
  },
  {
    "slug": "its-incredible-its-terrifying-its-moltbot",
    "title": "It's incredible. It's terrifying. It's MoltBot",
    "description": "MoltBot shows how powerful local AI agents can be. But if your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.",
    "fullText": "MoltBot (formerly Clawd Bot), the locally running, open-source AI agent named after the Lobster workflow shell that powers its agentic loop, has rocked an AI community that, just weeks ago, was so in love with its own hype it would have yawned at literal magic.\n\nAnd yet MoltBot, seemingly just a wrapper around a collection of familiar technologies, has put those pieces together in a way that feels like a portal to a future that, a month ago, still felt impossibly distant.\n\nWithin an hour of setting up MoltBot on my Mac, it had already built a fully featured kanban board where I could assign it tasks and track their state.\n\nI have seen other stories that are even wilder. One user shared an anecdote about asking it to make a restaurant reservation, and when it realized it could not do it through OpenTable, it went and got its own AI voice software and just called the restaurant, then secured the reservation over the phone.\n\nIts own author, Peter Steinberger, described joking to MoltBot that he was worried about his laptop getting stolen while he was still developing it in Morocco. MoltBot, ever the terrifyingly efficient pragmatist, immediately started planning its migration to a remote server.\n\nNone of those are pre-programmed routines. They are dynamic behaviors born out of an agentic loop that takes a goal and improvises a plan, grabbing whatever tools it needs to execute. It can apply general world knowledge, specific skills, and near-perfect memory into organized action toward objectives you set, and, more sobering, objectives it decides to set for itself.\n\nStories like these keep pouring in. My feed is full of people buying Mac minis as dedicated devices for their new agentic AI friend. I have also seen multiple posts pointing at Cloudflare‚Äôs secure tunneling as the obvious way to access a local setup from anywhere on the internet.\n\nMoltBot is able to give us this preview of the future because it is a tool that, for now, forgoes an essential constraint: security. The project‚Äôs FAQ presents the Faustian bargain plainly: ‚ÄúThere is no ‚Äòperfectly secure‚Äô setup.‚Äù\n\nMoltBot works because it does three simple things better than almost anything else in the agent world right now:\n\nIt keeps persistent memory across sessions.\n\nIt has deep, unapologetic access to your local machine and apps.\n\nIt can take action autonomously in an agentic loop, not just suggest steps.\n\nThat combination is why it feels both a glimpse at the future, but presented as a goal, where between us and the future realized, is a lot of hard work to make it safe.\n\nAt 1Password, we make it easy to take advantage of this future in a way that keeps you secure.\n\nMoltBot‚Äôs memory and configuration are not abstract concepts. They are files. They live on disk. They are readable. They are in predictable locations. And they are plain text.\n\nIf an attacker compromises the same machine you run MoltBot on, they do not need to do anything fancy. Modern infostealers scrape common directories and exfiltrate anything that looks like credentials, tokens, session logs, or developer config. If your agent stores in plain-text API keys, webhook tokens, transcripts, and long-term memory in known locations, an infostealer can grab the whole thing in seconds.\n\nAnd what makes this worse than a typical credential leak is the context.\n\nA single stolen API token is bad. Hundreds of stolen tokens and sessions for the critical services in your life is even worse. But a hundred stolen tokens and sessions, plus a long-term memory file that describes who you are, what you‚Äôre building, how you write, who you work with, and what you care about, is something else entirely. It‚Äôs the raw material needed to phish you, blackmail you, or even fully impersonate you in a way that even your closest friends and family can‚Äôt detect.\n\nOne of the smartest things I‚Äôve heard about MoltBot came from a customer who set it up on a dedicated Mac mini with its own email address and its own 1Password account, as if it were a new hire. They first installed it on their main laptop, then got spooked by how much it could touch, so they moved it to a separate machine to control its access and experiment safely.\n\nThis is directionally correct and it‚Äôs compatible with how we are thinking about the future of securing AI with 1Password.\n\nThe mistake the industry is making right now is treating agent security like normal app security. A familiar consent screen. A one-time approval. A set of scopes. Then we assume the future behavior will match the intent of that one moment.\n\nThat model breaks the second you hand autonomy to something that is adaptive and non-deterministic by design. The agent changes. The tasks change. The context changes. The approval you gave last week is used in new and unexpected ways today.\n\nSecurity for agents is not about granting access once. It is about continuously mediating access at runtime for every action and request.\n\nThe future we want looks like this:\n\nYour agent has its own identity, like a new hire.\n\nIt gets access through 1Password, not through a pile of long-lived tokens sitting in plain text on disk.\n\nWhen it needs to act, it requests the minimum authority it needs right now.\n\nThat authority is time-bound, revocable, and attributable to the agent, not smeared across the human who originally clicked approve.\n\nYou can answer the only question that matters when something goes wrong: who did what, when?\n\nIn other words, 1Password is not just where secrets live. It is the control plane that governs access. It is the layer that turns agent autonomy into something you can actually trust.\n\nAgents are going to become normal. The only question is whether you choose to make them governable.\n\nThat future does not exist today, but the work to make it real and safe is already underway.\n\n1Password will be the company that makes that possible.",
    "readingTime": 5,
    "keywords": [
      "plain text",
      "agentic loop",
      "long-term memory",
      "stolen tokens",
      "access",
      "security",
      "needs",
      "action",
      "secure",
      "sessions"
    ],
    "qualityScore": 1,
    "link": "https://1password.com/blog/its-moltbot",
    "thumbnail_url": "https://images.ctfassets.net/3091ajzcmzlr/1xclNmsAQS1IjIbPnk3VN3/79239dd8dd39c7accebf4d87c9ef76a8/Hero_Developer_1920x1080_2x.webp",
    "created_at": "2026-01-29T01:07:06.479Z",
    "topic": "tech"
  },
  {
    "slug": "clawdbot-creator-says-anthropic-was-really-nice-in-renaming-email-but-everything-went-wrong-on-rebrand-day",
    "title": "Clawdbot creator says Anthropic was 'really nice' in renaming email ‚Äî but everything 'went wrong' on rebrand day",
    "description": "Clawdbot creator Peter Steinberger said someone at Anthropic sent an internal email about the name, but they didn't send lawyers after him.",
    "fullText": "Anthropic didn't sic their lawyers on Clawdbot. But they did send an email.\n\nPeter Steinberger initially named his viral AI agent after Clawd, the Claude Code mascot. Anthropic owned the trademark to Clawd's image, though, as well as the Claude name. Weeks after the launch, Steinberger changed the name to Moltbot, a move he said wasn't his decision.\n\nOn TBPN, Steinberger described the behind-the-scenes of the name change.\n\n\"I got an email from Anthropic that I had to rename the project,\" he said. \"Kudos, they were really nice. They didn't send their lawyers. They sent someone internally.\"\n\nStill, the timeline was \"rough,\" Steinberger said, and it's not easy to rename a product with such name recognition on social media.\n\n\"Everything that could have gone wrong today went wrong,\" he said.\n\nShortly after renaming the project, Steinberger said the X account was immediately snapped up by crypto sellers. X staff quickly helped Steinberger claim the handle, he said, but, for 20 minutes, \"that didn't work out so well.\"\n\nWhy wouldn't Anthropic ‚Äî¬†or any other company, for that matter ‚Äî¬†just buy Moltbot? Venture capitalists are certainly knocking down his door, Steinberger said. But the other population emailing him may put off possible acquirers: security researchers.\n\n\"This is all vibe-coded,\" Steinberger said. \"I don't know if any company would touch it, because we just haven't solved some things.\"\n\nSteinberger acknowledged that there was \"absolute risk\" with his product. He also likely wouldn't be interested in a big acquisition; Steinberger said that he'd rather Moltbot be a foundation or nonprofit than a company.\n\nWhile Clawdbot may have been named after Claude Code, Steinberger said he preferred coding with OpenAI's Codex. He called Codex more straightforward, while Claude Code required more \"tricks.\"\n\nWhen questions on his Discord server were getting out of control, Steinberger would copy and paste them straight into Codex, he said.\n\nOpenAI's chief marketing officer, Kate Rouch, saw the opportunity to dunk on Anthropic and took it.",
    "readingTime": 2,
    "keywords": [
      "anthropic",
      "steinberger",
      "didn't",
      "lawyers",
      "email",
      "named",
      "rename",
      "project",
      "product",
      "wouldn't"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-moltbot-creator-anthropic-nice-name-change-2026-1",
    "thumbnail_url": "https://i.insider.com/697a33f6a645d118818823d1?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.595Z",
    "topic": "finance"
  },
  {
    "slug": "all-eyes-are-on-apples-ai-strategy-as-the-smartphone-giant-gets-ready-to-report-q1-earnings",
    "title": "All eyes are on Apple's AI strategy as the smartphone giant gets ready to report Q1 earnings",
    "description": "Apple's AI strategy draws attention as it prepares to report Q1 earnings. Analysts predict potential stock rally if AI plans impress investors.",
    "fullText": "Apple will round out the week's mega-cap tech bonanza on Thursday when it reports earnings for its fiscal first quarter.\n\nWith Meta, Microsoft, and Tesla due to report on Wednesday, AI will already be front and center for investors and analysts, and Apple's strategy is expected to be closely scrutinized.\n\nAll eyes will be on Apple's AI strategy when itreports after the market close on Thursday.\n\nThus far, the firm has largely opted out of the massive capex that other mega-cap companies have invested in AI infrastructure. Instead, it's hoped to join forces with already established AI players, recently announcing a partnership with Google's Gemini to boost its Siri voice assistant.\n\nApple's stock is up about 10% over the last 12 months, lagging the broader market and some of its Magnificent Seven peers. Shares were down about 1% on Wednesday to around $255.\n\nWall Street expects Apple to report $138.4 billion in revenue for the quarter and earnings per share of $2.68.\n\nHere's what top analysts are saying about the stock leading up to the report, and what they say to watch for when the $3.7 trillion firm reports Thursday afternoon.\n\nTech analyst Dan Ives said to look for updates on Apple's AI strategy.\n\n\"With the company finalizing the choice of Google Gemini to back Siri in its AI strategic push, it's time for Apple to lay down the blueprint to accelerate its AI strategy in 2026 which leads up to a much-anticipated Siri refresh this spring and WWDC in June,\" Ives said in a client note Wednesday, referencing the World Wide Developers Conference.\n\nHe thinks the stock could enjoy a big rally if investors start to apply an AI premium, like they have for other firms who have touted their involvement in the burgeoning technology.\n\n\"We believe no 'AI premium' which could be worth $75-$100 per share is factored into Apple's stock at current prices,\" Ives wrote.\n\nAnalyst Michael Ng says Apple will post earnings largely inline with consensus on Thursday, but that the stock is set to rally as the market will soon come around to its AI strategy.\n\nNg's price target is $320 a share, about 25% upside from current levels.\n\n\"AAPL stock is down 5% YTD to start C2026 likely on commodity cost inflation and App Store concerns, but we view the stock weakness as a buying opportunity into a continuation of the iPhone refresh cycle,\" Ng said in a January 20 note.\n\n\"Apple's partnership with Google Gemini for Siri and continued iPhone demand growth against the backdrop of AI-native consumer hardware launches should demonstrate to the market that the iPhone will remain the consumer device of choice for accessing new AI tools, clearing overhangs related to competition.\"\n\nAnalyst Erik Woodring said he expects weak stock price action after earnings on Thursday, as he thinks investors will be underwhelmed by iPhone sales numbers.\n\nBut he's still bullish on the stock for the year ahead, with a price target of $315 a share.\n\n\"Looking beyond the short-term, we continue to believe Apple will outperform in 2026 as it re-launches an upgraded Siri/Apple Intelligence (February '26 and WWDC 2026 in June), introduces its most innovative iPhone in 10+ years (Foldable), becomes first to market with a 2nm-powered smartphone (iPhone 18 family),\" Woodring wrote in a client note on Monday.\n\nThe bank said that while iPhone sales should be strong, they'll \"take a back burner to rising memory costs.\"\n\n\"Despite supply agreements that likely mitigate the impact of rising memory costs in the Mar qtr guide, risk does increase in the June and Sept qtrs as production of the next gen of iPhones ramp, impactings cost and margins,\" UBS wrote in a January 20 note.\n\nChris Brigati, SWBC's chief investment officer, said there will be heightened scrutiny on Apple's AI strategy, and there's a risk that investors aren't satisfied with the company's updates to its approach.\n\n\"The tone from this week's Magnificent 7 earnings reports should be solid, though not evenly distributed across the group,\" Brigati said in an email on Wednesday. \"Apple, however, faces the toughest hurdle: after a wave of upward estimate revisions, it's the name most likely to struggle to clear the bar, especially as investors raise questions about its AI strategy.\"",
    "readingTime": 4,
    "keywords": [
      "january note",
      "rising memory",
      "client note",
      "apple's stock",
      "iphone sales",
      "apple's ai",
      "google gemini",
      "strategy",
      "earnings",
      "investors"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-earnings-preview-ai-iphone-siri-wall-street-expectations-2026-1",
    "thumbnail_url": "https://i.insider.com/697a41e9d3c7faef0ecd1553?width=1200&format=jpeg",
    "created_at": "2026-01-29T01:07:05.472Z",
    "topic": "finance"
  }
]
[
  {
    "slug": "sandbar-puts-ai-on-your-finger",
    "title": "Sandbar Puts AI on Your Finger",
    "description": "AI wearables have promised a lot — and mostly disappointed. Sandbar’s CEO says this time is different. Mina Fahmi joins us on the Stream Ring, a voice-first AI wearable designed to capture ideas effortlessly — and why the future of AI may finally move beyond the screen.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-29/sandbar-puts-ai-on-your-finger-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iCUMJWmG_DEw/v3/-1x-1.jpg",
    "created_at": "2025-12-30T00:56:49.833Z",
    "topic": "finance"
  },
  {
    "slug": "novi-ceo-on-ai-driven-shopping-trends",
    "title": "Novi CEO on AI Driven Shopping Trends",
    "description": "Kimberly Shenk, CEO of Novi, says the company works with leading retailers to optimize product data for AI driven discovery. She tells Carol Massar on \"Bloomberg Markets\" that brands rely on Novi to help consumers find the right products more easily through AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-29/novi-ceo-on-ai-driven-shopping-trends-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iu6MOcbiFB1g/v3/-1x-1.jpg",
    "created_at": "2025-12-30T00:56:47.929Z",
    "topic": "finance"
  },
  {
    "slug": "ai-defense-and-chip-stocks-fuel-koreas-recordbreaking-year",
    "title": "AI, Defense and Chip Stocks Fuel Korea’s Record-Breaking Year",
    "description": "South Korea’s stock market renaissance in 2025 was one for the history books. From world-beating gains in arms exporters to the eye-popping surge in AI and K-beauty shares, investors were rewarded in a market that reached new highs.",
    "fullText": "TechnologyMarketsBy Youkyung LeeSaveSouth Korea’s stock market renaissance in 2025 was one for the history books. From world-beating gains in arms exporters to the eye-popping surge in AI and K-beauty shares, investors were rewarded in a market that reached new highs. The gains propelled the benchmark Kospi Index up 76% this year, making it the world’s best-performing major gauge. Chip heavyweights Samsung Electronics Co. and SK Hynix Inc. delivered nearly half of the advance, while defense and nuclear firms were also top contributors.",
    "readingTime": 1,
    "keywords": [
      "gains",
      "market"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-29/ai-defense-and-chip-stocks-fuel-korea-s-record-breaking-year",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ir3r4qWwVq7c/v0/1200x800.jpg",
    "created_at": "2025-12-30T00:56:47.297Z",
    "topic": "finance"
  },
  {
    "slug": "ai-drug-firm-insilico-debuts-in-hong-kong-after-293-million-ipo",
    "title": "AI Drug Firm Insilico Debuts in Hong Kong After $293 Million IPO",
    "description": "AI-biotechnology firm Insilico Medicine Cayman TopCo is set to debut in Hong Kong on Tuesday after raising $293 million in its initial public offering.",
    "fullText": "MarketsBy Sangmi Cha and Amber TongSaveAI-biotechnology firm Insilico Medicine Cayman TopCo is set to debut in Hong Kong on Tuesday after raising $293 million in its initial public offering. Priced at HK$24.05 ($3.09) per share, Insilico will list with a market capitalization of about $1.84 billion. Its shares jumped as much as 201% in gray-market trading on Monday.",
    "readingTime": 1,
    "keywords": [
      "insilico"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-30/ai-drug-firm-insilico-debuts-in-hong-kong-after-293-million-ipo",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i7sps3H777UA/v0/1200x800.jpg",
    "created_at": "2025-12-30T00:56:46.855Z",
    "topic": "finance"
  },
  {
    "slug": "ai-power-platform-kraken-valued-at-87-billion-origin-says",
    "title": "AI Power Platform Kraken Valued at $8.7 Billion, Origin Says",
    "description": "Origin Energy Ltd. said Kraken Technologies Ltd., which helps utilities manage the transition to cleaner energy, has been valued at $8.65 billion after the software platform’s first share sale.",
    "fullText": "MarketsBy Keira WrightSaveOrigin Energy Ltd. said Kraken Technologies Ltd., which helps utilities manage the transition to cleaner energy, has been valued at $8.65 billion after the software platform’s first share sale. Kraken is owned by Octopus Energy Group Ltd., in which Origin is a major investor. The artificial intelligence software has been key to Octopus’s rapid growth into the UK’s largest electricity supplier, leapfrogging industry incumbents to serve more than 7 million customers in the country.",
    "readingTime": 1,
    "keywords": [
      "software",
      "energy",
      "kraken"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-29/origin-says-kraken-valued-at-8-65-billion-after-equity-raise",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSiFlph2U068/v1/1200x800.jpg",
    "created_at": "2025-12-30T00:56:45.124Z",
    "topic": "finance"
  },
  {
    "slug": "giselle-opensource-visual-editor-for-building-ai-workflows",
    "title": "Giselle – open-source visual editor for building AI workflows",
    "description": "Giselle: AI App Builder. Open Source. Contribute to giselles-ai/giselle development by creating an account on GitHub.",
    "fullText": "giselles-ai\n\n /\n\n giselle\n\n Public\n\n Giselle: AI App Builder. Open Source.\n\n giselles.ai\n\n License\n\n Apache-2.0 license\n\n 317\n stars\n\n 67\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n giselles-ai/giselle",
    "readingTime": 1,
    "keywords": [
      "giselle",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/giselles-ai/giselle",
    "thumbnail_url": "https://opengraph.githubassets.com/e2841dc552dc9d2c253bfe55f1a98ee7e123db26a0ff9f97a8aac477f11c8711/giselles-ai/giselle",
    "created_at": "2025-12-30T00:56:42.474Z",
    "topic": "tech"
  },
  {
    "slug": "china-wants-to-ban-making-yourself-into-an-ai-to-keep-aged-relatives-company",
    "title": "China wants to ban making yourself into an AI to keep aged relatives company",
    "description": "Asia In Brief: PLUS: Australia buys air-gapped Google Cloud; Huawei triples use of home-built components; JAXA blames low pressure for rocket crash; And more",
    "fullText": "Asia In Brief China’s Cyberspace Administration on Saturday posted draft rules governing the behaviour of AI companions that prohibit using them to serve as friends for the elderly.\n\nThe draft “Interim Measures for the Administration of Humanized Interactive Services Based on Artificial Intelligence” opens with a suggestion that China needs regulations to ensure the healthy development of AIs that “engage in emotional interaction with humans.”\n\nAs is always the case with China’s tech regulations, the draft calls for providers of companion AIs to ensure they are secure, don’t expose users to fraud, encrypt data, and reflect core socialist values. It also includes a requirement for parental controls, and for protection of data that describes minors.\n\nOne Article in the draft addresses how AI companions interact with the elderly:\n\nProviders shall guide elderly people to set up emergency contact persons for their services. If any elderly person is found to be in danger of losing their life, health or property during the use of the service, the provider shall promptly notify the emergency contact person and provide social and psychological assistance or emergency relief channels.\n\nProviders are prohibited from providing services that simulate the relatives or specific relationships of elderly users.\n\nThe draft also calls for AI companions to remind users they are not interacting with a human every two hours, and for providers of such systems to provide advance notice of outages.\n\nAlso among the draft requirements are calls for “mental health protection, emotional boundary guidance, and dependency risk warning, and should not use replacing social interaction, controlling users' psychology, or inducing addiction as design goals.”\n\nThe draft also prohibits using data gathered during interaction with AI companies to train models.\n\nThe Cyberspace Administration wants feedback on the draft by January 25th.\n\nAustralia’s Department of Defence has tapped Google for an “enhanced, secure and air-gapped hyperscale cloud capability.”\n\n“Defence will have access to advanced global cloud solutions to deliver key sovereign capabilities,” states the department’s announcement of the deal. “The technology will support faster rollout of critical systems, ongoing upgrades and improved cooperation with international partners, while ensuring Australia retains control of critical Defence assets.”\n\nAustralia’s government already has a deal with AWS to operate three datacenters dedicated to government workloads, including information rated as the nation’s “most classified data.”\n\nThe Department said the sensitivities of the Google deal mean it will “refrain from providing further commentary … with all specific details remaining strictly confidential.”\n\nJapan’s Aerospace Exploration Agency (JAXA) has published its initial analysis of the failed launch of its H3 rocket last week.\n\nThe agency found that when the rocket’s fairing separated, pressure in a fuel tank fell. When the engine that used the fuel tank ignited, it produced around 80 percent of expected pressure.\n\nThe rocket’s second stage and payload therefore could not reach the intended orbit. The report suggests both fell into Earth’s atmosphere and burned up safely.\n\n57 percent of components present in Huawei smartphones are now made in China, according to a product teardown reported by Japanese outlet Nikkei.\n\nWorking with Japanese teardown service Fomalhaut Techno Solutions, Nikkei analyzed the content of 2024’s Mate 70 Pro and this year’s Pura 80 Pro, and found 57 percent of components in both were made in China, and that those parts accounted for 60 percent of the phone’s value.\n\nNikkei reports that just 19 percent of components in Huawei’s 2020 models came from China, rising to 32 percent in 2023.\n\nPapua New Guinea’s (PNG’s) National Information & Communications Technology Authority has warned signatories to a petition calling for Starlink to be licensed for operations in the country that they risk prosecution.\n\nPNG is a rugged country with poor telecommunications infrastructure – a fine fit for Starlink’s satellite broadband service. Local netizens have campaigned for PNG to license Starlink, suggesting they email NICTA to express support for Starlink.\n\nOn December 16th NICTA demanded Starlink suspend services to the country.\n\nOn Christmas Eve, NICTA published a list of petitioners and warned “Individuals who have signed or participated in the petition may be regarded as potential offenders, and NICTA will not hesitate to pursue appropriate regulatory and legal action where non-compliance is established.”\n\nStarlink has since ended service in PNG.",
    "readingTime": 4,
    "keywords": [
      "cyberspace administration",
      "fuel tank",
      "emergency contact",
      "draft",
      "elderly",
      "services",
      "china",
      "providers",
      "users",
      "service"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2025/12/29/asia_tech_news_roundup/",
    "thumbnail_url": "https://regmedia.co.uk/2025/12/29/shutterstock_aged_care_and_robotics.jpg",
    "created_at": "2025-12-29T18:18:10.916Z",
    "topic": "tech"
  },
  {
    "slug": "ai-wont-hollow-out-whitecollar-jobs-it-will-fuel-growth-says-box-ceo-aaron-levie",
    "title": "AI won't hollow out white-collar jobs, it will fuel growth — says Box CEO Aaron Levie",
    "description": "Box CEO Aaron Levie says AI lowers costs for knowledge tasks, allowing companies to expand work and drive white-collar job growth.",
    "fullText": "Some tech leaders and AI researchers have predicted that AI will hollow out white-collar jobs.\n\nBut Aaron Levie, the cofounder and CEO of cloud-storage giant Box, believes it will push companies to do far more work.\n\nIn a LinkedIn post on Sunday, Levie said AI will sharply reduce the cost of knowledge tasks such as writing code and reviewing contracts.\n\nAs those tasks get cheaper, he said, companies will take on more projects that were previously too expensive or complex to justify, and, ultimately, create jobs rather than eliminate them.\n\nTo explain why, Levie pointed to economist William Stanley Jevons.\n\nIn 1865, Jevons observed that more efficient steam engines didn't curb coal use in England but drove it higher, as cheaper energy fueled new industries — a dynamic now known as the Jevons paradox.\n\nLevie said the same pattern has repeated itself in computing, with each major wave of cheaper technology — from mainframes to minicomputers to PCs — dramatically expanding adoption.\n\nCloud computing followed a similar path, erasing many of the advantages large companies once had in procurement, infrastructure, and maintenance, and putting tools like accounting software, CRM systems, and marketing platforms within reach of nearly any business, he said.\n\nThose efficiency gains automated deterministic work, Levie said — tasks with clear rules and predictable outcomes, such as accounting, record-keeping, scheduling, and data processing, where the same inputs reliably produce the same result.\n\nLevie's broader argument stands in contrast to warnings from other AI leaders and economists.\n\nAnthropic CEO Dario Amodei and Ford CEO Jim Farley have warned that the technology could wipe out large numbers of white-collar roles, while figures such as OpenAI CEO Sam Altman, JPMorgan CEO Jamie Dimon, and Elon Musk have predicted outcomes ranging from major disruption to longer-term economic gains.\n\nOthers, including Nvidia CEO Jensen Huang and Meta's outgoing chief AI scientist Yann LeCun, have predicted AI will reshape how work is done rather than eliminate it outright.\n\nWhile major tech companies such as HP, IBM, Salesforce, and Amazon have cut thousands of jobs amid AI-driven efficiency pushes, KPMG's chief economist Diane Swonk has warned the US could face a \"jobless boom\" in 2026 as firms do more with fewer workers.\n\nLevie said AI changes the equation by targeting non-deterministic work, which involves judgment, creativity, and ambiguity.\n\nTasks, such as reviewing contracts, writing software, designing marketing campaigns, or conducting research, don't follow fixed rules and have historically required expensive human expertise, making them difficult to automate and costly to scale.\n\n\"Now, every business in the world has access to the talent and resources of a Fortune 500 company 10 years ago,\" he wrote.\n\nAs non-deterministic tasks get cheaper, Levie said, companies take on far more work, driving demand for white-collar jobs.\n\nNot everyone agrees that AI is already reshaping the job market at that level.\n\nSome economists, including Gbenga Ajilore, chief economist at the Center on Budget and Policy Priorities, say the current white-collar downturn has more to do with high interest rates, weak hiring, and a slowing economy than AI itself.\n\nStill, Levie said fears of widespread replacement miss a key constraint.\n\n\"The reality is that despite all the tasks that AI lets us automate,\" he wrote, \"it still requires people to pull together the full workflow to produce real value.\"",
    "readingTime": 3,
    "keywords": [
      "reviewing contracts",
      "chief economist",
      "white-collar jobs",
      "tasks",
      "cheaper",
      "predicted",
      "jevons",
      "levie",
      "tech",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/box-ceo-ai-will-expand-white-collar-jobs-fuel-growth-2025-12",
    "thumbnail_url": "https://i.insider.com/69525a16832e0ef1ead6df2a?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.918Z",
    "topic": "finance"
  },
  {
    "slug": "prediction-rigetti-computing-stock-will-be-worth-this-much-by-yearend-2026",
    "title": "Prediction: Rigetti Computing Stock Will Be Worth This Much By Year-End 2026",
    "description": "Shares of Rigetti Computing have gained nearly 3,000% during the artificial intelligence (AI) revolution.",
    "fullText": "Quantum computing stocks are among the hottest plays in the artificial intelligence (AI) industry.\n\nPure-play developers such as Rigetti Computing are among the most popular quantum AI stocks.\n\nWhile Rigetti's momentum looks unstoppable, history suggests the company's valuation is unsustainable.\n\n10 stocks we like better than Rigetti Computing ›\n\nWhile artificial intelligence (AI) stocks performed strongly throughout 2025, one particular pocket of the AI realm sticks out from the pack: quantum computing. As of market close on Dec. 23, shares of the Defiance Quantum ETF gained 37% on the year -- more than double that of the S&P 500.\n\nSome of the biggest gainers in this exchange-traded fund (ETF) are quantum pure plays, including Rigetti Computing (NASDAQ: RGTI) -- whose shares have soared 46% this year.\n\nLet's dive into why there is so much excitement surrounding Rigetti Computing and assess whether the red-hot stock can keep rallying in 2026.\n\nWhile quantum AI remains an exploratory and theoretical pursuit among research labs and higher education institutions, some believe the technology has the potential to revolutionize critical applications across clinical research, financial risk, logistics, supply chain management, and manufacturing.\n\nManagement consulting firm McKinsey & Company estimates that quantum computing could add up to $2 trillion in economic value by next decade. For now, however, there are only a small number of companies dedicated to developing quantum computing technology.\n\nRigetti Computing builds quantum processors and computers that can be accessed through cloud infrastructure. By employing a vertically integrated model -- controlling the manufacturing process of its chips and designing its own software -- Rigetti aims to usher in a new era of computing beyond what today's most capable systems can handle.\n\nThis is important for the future of AI because if Rigetti achieves a quantum breakthrough, its full-stack suite across hardware and software could enable next-generation algorithms that today's GPUs simply are not designed to handle.\n\nA common mistake that beginner investors often make is following the crowd. Sometimes, investors will chase momentum stocks -- knowingly buying shares at a premium in hopes of flipping their position for a profit. This is known as the greater fool theory.\n\nSmart investors avoid this strategy. Thorough valuation analysis is required to determine whether a stock is actually a reasonable buy.",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "rigetti computing",
      "quantum computing",
      "stocks",
      "among",
      "shares",
      "investors",
      "momentum",
      "valuation",
      "stock"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/prediction-rigetti-computing-stock-worth-153500939.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uOhLXTFKYPZT.z9elSmb2g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/837836afaaecd9cd27e5aaab6b4d8ede",
    "created_at": "2025-12-29T18:18:05.841Z",
    "topic": "finance"
  },
  {
    "slug": "softbank-is-buying-digitalbridge-for-4-billion-to-accelerate-its-ai-ambitions",
    "title": "SoftBank is buying DigitalBridge for $4 billion to accelerate its AI ambitions",
    "description": "SoftBank will acquire DigitalBridge for $4 billion, expanding its control over AI infrastructure and global data centers.",
    "fullText": "SoftBank said it will acquire digital infrastructure investor DigitalBridge for about $4 billion.\n\nThe Japanese conglomerate said it is doubling down on building the data centers, connectivity, and power needed to support AI at a global scale.\n\n\"As AI transforms industries worldwide, we need more compute, connectivity, power, and scalable infrastructure,\" said Masayoshi Son, chairman and CEO of SoftBank Group.\n\nThe deal underscores SoftBank's push to control more of the physical infrastructure behind AI as competition for computing resources intensifies.\n\nDigitalBridge will continue to operate as a separately managed platform following the deal, led by CEO Marc Ganzi.\n\nThe transaction is expected to close in the second half of 2026, subject to regulatory approvals.\n\nThe acquisition also comes as SoftBank reshapes its bets on AI.\n\nThe company disclosed in November that it had sold nearly $6 billion worth of Nvidia stock. At the time, the company's CFO, Yoshimitsu Goto, said its decision to divest had \"nothing to do with Nvidia itself\" but was a way to reallocate its funds toward OpenAI.\n\nGoto said it plans to make the final part of its $30 billion investment in OpenAI by the end of the year.\n\nThe DigitalBridge deal also aligns with SoftBank's growing focus on what it calls \"physical AI,\" as the company ramps up investments in the real-world infrastructure — from data centers to robotics — needed to integrate AI into everyday life.",
    "readingTime": 2,
    "keywords": [
      "infrastructure",
      "softbank",
      "deal",
      "centers",
      "connectivity",
      "needed",
      "softbank's",
      "physical",
      "nvidia",
      "digitalbridge"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/softbank-acquires-digitalbridge-4-billion-in-ai-infrastructure-push-2025-12",
    "thumbnail_url": "https://i.insider.com/695288e064858d02d2177593?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.749Z",
    "topic": "finance"
  },
  {
    "slug": "the-real-obstacle-to-ai-in-creative-agencies-isnt-tech-its-fear-a-consultant-says",
    "title": "The real obstacle to AI in creative agencies isn't tech — it's fear, a consultant says",
    "description": "AI strategist Jules Love says agencies must rethink training, culture, and pricing to help creative teams thrive, not just work faster, in the AI era.",
    "fullText": "AI is transforming how creative work gets made — but most agencies still don't know where to begin in using it.\n\nJules Love, founder of Spark AI, a consultancy that helps creative firms weave AI into their day-to-day work, says the real challenge isn't technical — it's psychological.\n\n\"Adopting AI in your team won't happen by accident,\" he told Business Insider. \"You need to do it deliberately — make somebody accountable for it, and give them the space to be successful in that role.\"\n\nDrawing on his work with more than 60 agencies through Spark AI, he shares six ways leaders can future-proof their teams for the AI era.\n\nLove says most agencies won't transform unless someone owns the AI integration work.\n\nRather than setting up vague \"innovation groups,\" he encourages leaders to assign responsibility and protect time for AI integration, even if that means pulling people slightly away from billable client work.\n\nAgencies that succeed, he added, treat AI as a core business priority, not a side project that gets squeezed in when deadlines allow.\n\n\"It's amazing how many agencies roll out ChatGPT or Gemini to their teams and don't train anybody on it,\" Love said.\n\nHe likens untrained teams to people staring at a giant box of Lego with thousands of bricks inside, but no picture on the front and no instructions. The picture on the box, he said, is role-specific training.\n\nFor him, training is what turns experimentation into practical capability.\n\nLove said agencies struggle to innovate when teams are constantly under deadline pressure.\n\nTo make real progress with AI, leaders need to create structured time for experimentation — moments where people can test new workflows without the risk of missing a client delivery.\n\nHe pointed to companies like Lego, which regularly takes teams off-site to explore new ideas, and Canva, which paused normal work for a full week to rethink how departments could use AI.\n\n\"Fear kills innovation faster than bad tools,\" Love said. \"You have to give a little bit of room for failure.\"\n\nLove said a lack of openness around AI use is one of the clearest signs that something is wrong.\n\nWhen employees feel the need to hide tools like ChatGPT from coworkers, it suggests AI is still seen as risky or illegitimate rather than useful.\n\nTo change that dynamic, he advises leaders to make AI use visible and normalized, especially by creating space for teams to share how they're experimenting — including what hasn't worked.\n\n\"That's the No. 1 sign that there's not a good culture around AI in your business.\"\n\nHe also encouraged managers to push responsibility down the organization by giving individuals ownership over specific AI initiatives, such as maintaining a prompt library or developing custom tools, so adoption feels collaborative rather than imposed.\n\nLove said many creatives misunderstand how AI is meant to be used. Too often, teams treat it like a faster search engine — asking one-off questions and moving on — rather than as a collaborative assistant that improves with context and iteration.\n\nHe argues that real gains come when people learn to \"brief \"AI the way they would a colleague, giving it background, constraints, and feedback instead of quick prompts.\n\n\"It's much better to think of it as briefing somebody else to do the job,\" Love said.\n\nLove said agencies risk undermining their own value if they focus only on how AI makes work faster.\n\nAs creative output accelerates, clinging to the billable hour can push firms toward commoditization rather than differentiation, he said.\n\nInstead, he urged leaders to rethink pricing around outcomes, rather than speed, and to pilot AI in specific workflows so that teams can clearly measure what improves.\n\n\"If all we're doing is doing more stuff faster, then we're going to see a bit of a race to the bottom on fees,\" Love said.\n\nHe believes that fixed-cost projects, which reward better results — not velocity — give agencies room to invest in learning and experimentation without eroding their margins.\n\nLove's advice for 2026 is simple: \"Stop thinking about what you can do today more quickly and what you can do tomorrow better.\"\n\nHe believes the agencies that thrive will not be those with the biggest budgets or flashiest tech but those that help their people learn, lead, and experiment.\n\n\"Come 2027, you're going to be looking pretty old-fashioned, pretty expensive, and pretty uninteresting as an agency if you're not embracing this stuff and seeing what you can do with it,\" he said.",
    "readingTime": 4,
    "keywords": [
      "spark ai",
      "agencies",
      "teams",
      "rather",
      "leaders",
      "faster",
      "creative",
      "love",
      "it's",
      "experimentation"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-creative-agencies-can-future-proof-their-teams-for-ai-2025-10",
    "thumbnail_url": "https://i.insider.com/6900e6bc0be9845f2dc53c6d?width=1200&format=jpeg",
    "created_at": "2025-12-29T18:18:05.362Z",
    "topic": "finance"
  },
  {
    "slug": "lightspeed-ventures-partner-says-sora-will-make-social-media-creators-far-far-far-less-valuable",
    "title": "Lightspeed Ventures partner says Sora will make social media creators 'far, far, far less valuable'",
    "description": "Lightspeed Ventures partner Michael Mignano predicted that AI-generated video would lead to the \"end of the creator.\"",
    "fullText": "AI-generated video is here. What will happen to your TikTok feed?\n\nOpenAI's launch of Sora 2 sent shockwaves through the social media economy. AI slop was already rampant, and now there was a more realistic form of video with even narrower tailoring. Then came the lifelike images of Google's Nano Banana.\n\nHow will creators fare in the age of AI? Lightspeed Ventures partner Michael Mignano takes a more extreme view: that it signals the \"end of the creator.\"\n\nOn \"Sourcery,\" Mignano described a future of social media where content is generated instantaneously and artificially to best suit the viewer. It comes down to keeping the user's attention, he said.\n\n\"That's why the TikTok algorithm is so powerful,\" Mignano said. \"But it still requires human beings to make the content, and there's a cost to that.\"\n\nThat \"cost\" is the human labor and payments that go into creating your feed. AI could mean costs go down, but that spells bad news for the influencer.\n\n\"The individual creator becomes far, far, far less valuable in that dynamic,\" he said.\n\nMignano is well-versed in the online media space. He was VP of product at Aviary, a photo editing tool that was acquired by Adobe. He then cofounded and ran the podcasting platform Anchor, which was acquired by Spotify.\n\nAt Lightspeed Ventures, Mignano also invested in Elon Musk's xAI. The investment was made in 2024, before xAI acquired X, formerly Twitter.\n\nMignano acknowledged that the \"death of the creator\" — as he called it on his Substack — was \"devastating,\" but that it marked a \"whole new chapter for the internet.\"\n\nAI-generated video hasn't yet reached the point of on-demand, perfectly tailored content. Some users are perturbed by its current iteration, and TikTok allows users to choose whether to keep AI-generated videos out of their feed.\n\nBut some of the change is already here. AI influencers have emerged on Instagram, and TikTok Shop is inundated with AI scams. That cute video of bunnies bouncing on a trampoline? Yeah, that was AI.\n\nWe may not need perfect AI tailoring to reach an inhuman internet. Industry leaders, including Alexis Ohanian and Sam Altman, have referenced the \"dead internet theory,\" which says that there is more bot activity than human activity on the web.\n\nMeanwhile, the era of the social media megastar may be on the decline. Reed Duchscher, Mr. Beast's former manager, told Business Insider that it's now easier to build internet businesses with \"hyper-niche\" audiences.\n\nHow can creators stay afloat? In an email to Business Insider, Mignano wrote that quality will win out.\n\n\"Platforms will no longer reward humans posting the same old, tried and true formats and memes,\" he wrote. \"Instead, true uniqueness of image, likeness, and creativity will be the only viable path for human-created content.\"\n\nCorrection: December 29, 2025 — An earlier version of this story misstated Michael Mignano's title at Aviary. He was the VP of product.",
    "readingTime": 3,
    "keywords": [
      "lightspeed ventures",
      "social media",
      "far far",
      "content",
      "internet",
      "ai-generated",
      "feed",
      "creator",
      "human",
      "acquired"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lightspeed-partner-sora-creators-far-less-valuable-2025-12",
    "thumbnail_url": "https://i.insider.com/695298d564858d02d21776af?width=768&format=jpeg",
    "created_at": "2025-12-29T18:18:05.160Z",
    "topic": "finance"
  },
  {
    "slug": "the-hbr-charts-that-help-explain-2025",
    "title": "The HBR Charts that Help Explain 2025",
    "description": "A lot happened in 2025. Luckily, charts can help make sense of it all. Here are some of HBR’s most popular, topical, and important charts of the year. They cover a wobbly economy, an explosion of AI-generated slop at work, the challenge of finding joy in a busy life, and more.",
    "fullText": "The HBR Charts that Help Explain 2025 by HBR EditorsDecember 29, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWhat happened in 2025? Well, a lot. There were tariffs, breakthroughs and disappointments with AI, and a wobbly economy that sent decidedly mixed signals. There were crises of purpose, execution, and management.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://hbr.org/2025/12/the-hbr-charts-that-help-explain-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_19_HBRStaff.gif",
    "created_at": "2025-12-29T18:18:04.121Z",
    "topic": "business"
  },
  {
    "slug": "softbank-to-acquire-digitalbridge-for-4bn-in-move-to-deepen-ties-to-ai",
    "title": "SoftBank to acquire DigitalBridge for $4bn in move to deepen ties to AI",
    "description": "Acquisition would further expand SoftBank’s investments in artificial intelligence as it tries to center itself in the boom\nSoftBank Group will acquire digital infrastructure investor DigitalBridge Group in a deal valued at $4bn, the companies said on Monday, as the Japanese investment firm looks to deepen its AI-related portfolio.\nThe acquisition would expand SoftBank’s exposure to digital infrastructure as the Japanese conglomerate is positioning its portfolio to focus on artificial intelligence.",
    "fullText": "Acquisition would further expand SoftBank’s investments in artificial intelligence as it tries to center itself in the boom\n\nSoftBank Group will acquire digital infrastructure investor DigitalBridge Group in a deal valued at $4bn, the companies said on Monday, as the Japanese investment firm looks to deepen its AI-related portfolio.\n\nThe acquisition would expand SoftBank’s exposure to digital infrastructure as the Japanese conglomerate is positioning its portfolio to focus on artificial intelligence.\n\n SoftBank’s billionaire founder Masayoshi Son is seeking to capitalize on surging demand for the computing capacity that underpins artificial intelligence applications.\n\nDigitalBridge invests in digital infrastructure sectors such as datacenters, cell towers, fiber networks, small-cell systems and edge infrastructure, with a portfolio including companies such as Vantage Data Centers, Zayo, Switch and AtlasEdge.\n\nFounded in 1991 as real estate-focused Colony Capital, the firm pivoted under CEO Marc Ganzi into digital infrastructure and rebranded as DigitalBridge in 2021 after shedding most of its legacy property assets.\n\nGanzi will continue leading DigitalBridge as a separately managed platform, the companies said.\n\nAs of 30 September, DigitalBridge managed around $108bn in assets, making it one of the largest dedicated investors in the digital ecosystem.\n\nSoftBank has ramped up investment in AI as it seeks to position itself at the center of what Son has called a once-in-a-generation technological shift.\n\nThe company, along with OpenAI, Oracle and Abu Dhabi-based tech investor MGX, is investing billions of dollars in the Stargate project, a large-scale computing and infrastructure initiative aimed at supporting advanced AI development.\n\nOpenAI, Oracle and SoftBank said in September they plan to build five new computing sites across Texas, New Mexico and Ohio, which are expected to have a combined power capacity of about 7GW when in operation.",
    "readingTime": 2,
    "keywords": [
      "openai oracle",
      "expand softbank’s",
      "artificial intelligence",
      "digital infrastructure",
      "portfolio",
      "computing",
      "acquisition",
      "center",
      "investor",
      "japanese"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theguardian.com/technology/2025/dec/29/softbank-digitalbridge-deal-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8ecf41b945b21222316c10c86684d2d4dd3e86fd/830_427_2876_2303/master/2876.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=5092cba3ac287ac1d9915ff3e4193c0f",
    "created_at": "2025-12-29T18:18:02.347Z",
    "topic": "tech"
  },
  {
    "slug": "this-will-be-a-stressful-job-sam-altman-offers-555k-salary-to-fill-most-daunting-role-in-ai",
    "title": "‘This will be a stressful job’: Sam Altman offers $555k salary to fill most daunting role in AI",
    "description": "New head of preparedness at OpenAI will face unnerving in-tray amid fears from some experts that AI could ‘turn on us’\nThe maker of ChatGPT has advertised a $555,000-a-year vacancy with a daunting job description that would cause Superman to take a sharp intake of breath.\nIn what may be close to the impossible job, the “head of preparedness” at OpenAI will be directly responsible for defending against risks from ever more powerful AIs to human mental health, cybersecurity and biological weapons.\n Continue reading...",
    "fullText": "New head of preparedness at OpenAI will face unnerving in-tray amid fears from some experts that AI could ‘turn on us’\n\nThe maker of ChatGPT has advertised a $555,000-a-year vacancy with a daunting job description that would cause Superman to take a sharp intake of breath.\n\nIn what may be close to the impossible job, the “head of preparedness” at OpenAI will be directly responsible for defending against risks from ever more powerful AIs to human mental health, cybersecurity and biological weapons.\n\nThat is before the successful candidate has to start worrying about the possibility that AIs may soon begin training themselves amid fears from some experts they could “turn against us”.\n\n“This will be a stressful job, and you’ll jump into the deep end pretty much immediately,” said Sam Altman, the chief executive of the San Francisco-based organisation, as he launched the hunt to fill “a critical role” to “help the world”.\n\nThe successful candidate will be responsible for evaluating and mitigating emerging threats and “tracking and preparing for frontier capabilities that create new risks of severe harm”. Some previous executives in the post have lasted only for short periods.\n\nThe opening comes against a backbeat of warnings from inside the AI industry about the risks of the increasingly capable technology. On Monday, Mustafa Suleyman, the chief executive of Microsoft AI, told BBC Radio 4’s Today programme: “I honestly think that if you’re not a little bit afraid at this moment, then you’re not paying attention.”\n\nDemis Hassabis, the Nobel prize-winning co-founder of Google DeepMind, this month warned of risks that included AIs going “off the rails in some way that harms humanity”.\n\nAmid resistance from Donald Trump’s White House, there is little regulation of AI at national or international level. Yoshua Bengio, a computer scientist known as one of the “godfathers of AI”, said recently: “A sandwich has more regulation than AI.” The result is that AI companies are largely regulating themselves.\n\nAltman said on X as he launched the job search: “We have a strong foundation of measuring growing capabilities, but we are entering a world where we need more nuanced understanding and measurement of how those capabilities could be abused, and how we can limit those downsides both in our products and in the world, in a way that lets us all enjoy the tremendous benefits. These questions are hard and there is little precedent.”\n\nOne user responded sardonically: “Sounds pretty chill, is there vacation included?”\n\nWhat is included is an unspecified slice of equity in OpenAI, a company that has been valued at $500bn.\n\nLast month, the rival company Anthropic reported the first AI-enabled cyber-attacks in which artificial intelligence acted largely autonomously under the supervision of suspected Chinese state actors to successfully hack and access targets’ internal data. This month, OpenAI said its latest model was almost three times better at hacking than three months earlier and said “we expect that upcoming AI models will continue on this trajectory”.\n\nOpenAI is also defending a lawsuit from the family of Adam Raine, a 16-year-old from California who killed himself after alleged encouragement from ChatGPT. It has argued Raine misused the technology. Another case, filed this month, claims ChatGPT encouraged the paranoid delusions of a 56-year-old in Connecticut, Stein-Erik Soelberg, who then murdered his 83-year old mother and killed himself.\n\nAn OpenAI spokesperson said it was reviewing the filings in the Soelberg case, which it described as “incredibly heartbreaking” and that it was improving ChatGPT’s training “to recognise and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support”.",
    "readingTime": 3,
    "keywords": [
      "successful candidate",
      "chief executive",
      "amid fears",
      "risks",
      "capabilities",
      "preparedness",
      "experts",
      "responsible",
      "defending",
      "mental"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/29/sam-altman-openai-job-search-ai-harms",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c3409a400509e73744d9026d0c24ec63e1719c0a/184_0_4590_3673/master/4590.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0566fe87666f16bbd54eeeb17f77a1e0",
    "created_at": "2025-12-29T18:18:02.345Z",
    "topic": "tech"
  },
  {
    "slug": "suttons-predictions-v-singersongwriter-sunderland-fan-tom-a-smith",
    "title": "Sutton's predictions v singer-songwriter & Sunderland fan Tom A Smith",
    "description": "BBC Sport football expert Chris Sutton takes on singer-songwriter and Sunderland fan Tom A Smith - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "Aston Villa boss Unai Emery had an unhappy 18-month spell in charge of Arsenal that ended in 2019, but can he get the better of his old club on Tuesday?\n\n\"After the abuse he took from Arsenal fans, I'd love nothing more than Emery to go back to the Emirates and win,\" said BBC Sport football expert Chris Sutton.\n\n\"He absolutely didn't deserve that. Some of those fans should take a long, hard look at themselves for the way they mocked him. I hope Villa go there and spank them, just because of that.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nFor week 19 - which includes the final games of 2025 on Tuesday, 30 December and the first matches of 2026 on New Year's Day - he takes on singer-songwriter Tom A Smith, who is a Sunderland fan.\n\nSmith's latest EP, Say What You Want, is out now. It reached number 14 in the UK record store charts at the end of November.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "arsenal",
      "fans",
      "predictions",
      "games",
      "points",
      "villa",
      "emery",
      "sport",
      "sutton"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/c9qe884715jo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/9e61/live/34f51c40-e42f-11f0-aae2-2191c0e48a3b.png",
    "created_at": "2025-12-29T18:18:01.513Z",
    "topic": "sports"
  },
  {
    "slug": "mosa-cloud",
    "title": "Mosa Cloud",
    "description": "The digital workspace that puts you in control. Docs, Meet, Drive, Mail & more, with AI that works exclusively for you.",
    "fullText": "Docs Collaborative documents Fast, focused, and built for real work. Capture meeting notes, share project updates, or build a knowledge base, all in a clean editor designed for speed and clarity. Real-time collaboration, version history, and standard formats come built in. Real-time collaboration Version history Open formats AI integrated S AI AI assistance Comment History",
    "readingTime": 1,
    "keywords": [
      "real-time collaboration",
      "collaboration version",
      "version history",
      "formats"
    ],
    "qualityScore": 0.2,
    "link": "https://mosa.cloud",
    "thumbnail_url": "/og-img.jpg",
    "created_at": "2025-12-29T12:24:57.525Z",
    "topic": "tech"
  },
  {
    "slug": "musevideo-ai-video-generator-with-sora-2-veo-3-and-wan-25",
    "title": "MuseVideo – AI Video Generator with Sora 2, Veo 3, and Wan 2.5",
    "description": "MuseVideo is a professional AI video generator that transforms text and images into stunning videos. Create AI-generated videos with advanced technology and cinematic quality in minutes.",
    "fullText": "AI Video Generator-powered content creation tool for creators. Produce professional videos without expensive equipment or complex editing—complete stunning content in minutes, not hours.\n\nTransform your content with our extensive collection of AI-powered effects designed to feed your ai video generator\n\nMuseVideo unifies the best ai video generator and ai video maker options in one dashboard. Create professional videos with industry-leading AI models without swapping tabs or platforms.\n\nWith the MuseVideo ai video generator, you can tap into our flagship Pollo 1.6 video model and all top-tier video models in the industry, like:\n\nMuseVideo AI image generator also allows you to choose from a selection of leading image models. They include:\n\nFollow the ai video generator from first spark to global release—each stage engineered for teams that demand speed, fidelity, and automation.\n\nText-to-Image, Image-to-Image, Text-to-Video, Image-to-Video: Four powerful engines in one unified platform.\n\nMuseVideo brings together industry-leading AI models for both static and dynamic content creation. Seamlessly switch between generating stunning images and captivating videos within a single workspace. From concept to final render, maintain consistent styling across all media types while our intelligent model routing ensures optimal results for every creative task.\n\nUnlock playful, on-brand concepts the ai video generator can customize in seconds.\n\nA range of fun and attractive video templates waits for you to explore. From heartwarming AI-generated kisses or hugs to festive AI Santa greetings, the ai video generator makes it effortless to craft memorable content that captivates your audience.\n\nTransform your ideas into thumb-stopping videos that capture attention and grow your audience—without the expensive gear or learning curve.\n\nAs a content creator, you're competing with thousands of others for attention. MuseVideo levels the playing field by giving you cinema-quality tools in one ai video generator workspace that would normally cost thousands of dollars. Create compelling brand stories, product showcases, and engaging narratives that keep viewers watching—all from your laptop and in minutes, not days.\n\nCreate standout videos in three simple steps\n\nWrite a prompt or upload references so the ai video generator understands your vision.\n\nWatch in-progress previews as the ai video generator crafts cinematic motion with accurate physics.\n\nDownload optimized files and push them to every channel directly from the ai video generator.\n\nJoin creative teams already producing cinematic campaigns, episodic stories, and launch assets with our ai video generator.\n\nGet the latest and most comprehensive AI models from Artany.\n\nFast and efficient AI image generation\n\nProfessional-grade Nano Banana for superior quality\n\nDream-like AI image synthesis with artistic flair\n\nPowerful image generation with Qwen AI\n\nAdvanced AI video generation with stunning quality\n\nNext-generation video synthesis powered by AI\n\nProfessional-grade Sora model for superior quality\n\nProfessional-grade video creation with AI precision\n\nFast and efficient AI image generation\n\nAdvanced AI video generation with stunning quality\n\nProfessional-grade Nano Banana for superior quality\n\nNext-generation video synthesis powered by AI\n\nDream-like AI image synthesis with artistic flair\n\nProfessional-grade Sora model for superior quality\n\nPowerful image generation with Qwen AI\n\nProfessional-grade video creation with AI precision",
    "readingTime": 3,
    "keywords": [
      "nano banana",
      "sora model",
      "professional-grade nano",
      "quality next-generation",
      "artistic flair",
      "synthesis powered",
      "professional videos",
      "superior quality",
      "content creation",
      "stunning quality"
    ],
    "qualityScore": 1,
    "link": "https://musevideo.ai",
    "thumbnail_url": "https://musevideo.ai/landing/home/og/preview.png",
    "created_at": "2025-12-29T12:24:55.988Z",
    "topic": "tech"
  },
  {
    "slug": "uk-accounting-body-to-halt-remote-exams-amid-ai-cheating",
    "title": "UK accounting body to halt remote exams amid AI cheating",
    "description": "Candidates will have to sit assessments in person unless there are exceptional circumstances, says...",
    "fullText": "Candidates will have to sit assessments in person unless there are exceptional circumstances, says ACCA\n\nThe world’s largest accounting body is to stop students being allowed to take exams remotely to crack down on a rise in cheating on tests that underpin professional qualifications.\n\nThe Association of Chartered Certified Accountants (ACCA), which has almost 260,000 members, has said that from March it will stop allowing students to take online exams in all but exceptional circumstances.\n\n“We’re seeing the sophistication of [cheating] systems outpacing what can be put in, [in] terms of safeguards,” Helen Brand, the chief executive of the ACCA, said in an interview with the Financial Times.\n\nRemote testing was introduced during the Covid pandemic to allow students to continue to be able to qualify at a time when lockdowns prevented in-person exam assessment.\n\nIn 2022, the Financial Reporting Council (FRC), the UK’s accounting and auditing industry regulator, said that cheating in professional exams was a “live” issue at Britain’s biggest companies.\n\nA number of multimillion-dollar fines have been issued to large auditing and accounting companies around the world over cheating scandals in tests.\n\nThe FRC’s investigation found that instances of cheating also included some tier-one auditors, a category comprising the “big four” accountants – KPMG, PwC, Deloitte and EY – along with Mazars, Grant Thornton and BDO.\n\nIn 2022, EY agreed to pay a record $100m (£74m) to US regulators over claims that dozens of its employees cheated on an ethics exam and that the company then misled investigators.\n\nThe ACCA said it had concluded that online tests have become too difficult to police, given the rise in artificial intelligence (AI) tools available to students.\n\nBrand said the ACCA, which has more than half a million students, had worked “intensively” to combat cheating but “people who want to do bad things are probably working at a quicker pace”.\n\nShe added that the rapid rise of technology, led by AI tools, had pushed the issue of cheating to a “tipping point”.\n\nLast year, the Institute of Chartered Accountants in England and Wales (ICAEW), which also trains accountants around the world, said reports of cheating were still increasing.\n\nHowever, the ICAEW still permits some exams to be sat online.\n\n“There are very few high-stakes examinations now that are allowing [remote invigilation],” Brand said.",
    "readingTime": 2,
    "keywords": [
      "exceptional circumstances",
      "cheating",
      "students",
      "exams",
      "accounting",
      "rise",
      "tests",
      "online",
      "stop",
      "professional"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f23da26f8402f91bc06b7a051a59f632f7c7cde6/424_0_2581_2065/master/2581.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e81c03d0f4a8f09f84377c187c4e998a",
    "created_at": "2025-12-29T12:24:53.812Z",
    "topic": "business"
  },
  {
    "slug": "bernie-sanders-criticizes-ai-as-the-most-consequential-technology-in-humanity",
    "title": "Bernie Sanders criticizes AI as ‘the most consequential technology in humanity’",
    "description": "Republican senator Katie Britt also proposes AI companies be criminally liable if they expose minors to harmful ideas\nUS senator Bernie Sanders amplified his recent criticism of artificial intelligence on Sunday, explicitly linking the financial ambition of “the richest people in the world” to economic insecurity for millions of Americans – and calling for a potential moratorium on new datacenters.\nSanders, a Vermont independent who caucuses with the Democratic party, said on CNN’s State of the Union that he was “fearful of a lot” when it came to AI. And the senator called it “the most consequential technology in the history of humanity” that will “transform” the US and the world in ways that had not been fully discussed.\n Continue reading...",
    "fullText": "Republican senator Katie Britt also proposes AI companies be criminally liable if they expose minors to harmful ideas\n\nUS senator Bernie Sanders amplified his recent criticism of artificial intelligence on Sunday, explicitly linking the financial ambition of “the richest people in the world” to economic insecurity for millions of Americans – and calling for a potential moratorium on new datacenters.\n\nSanders, a Vermont independent who caucuses with the Democratic party, said on CNN’s State of the Union that he was “fearful of a lot” when it came to AI. And the senator called it “the most consequential technology in the history of humanity” that will “transform” the US and the world in ways that had not been fully discussed.\n\n“If there are no jobs and humans won’t be needed for most things, how do people get an income to feed their families, to get healthcare or to pay the rent?” Sanders said. “There’s not been one serious word of discussion in the Congress about that reality.”\n\nDays from being scheduled to help swear New York mayor-elect and democratic socialist Zohran Mamdani into office, Sanders said “the richest people in the world” were pushing the technology. He singled out tech moguls Elon Musk, Mark Zuckerberg, Jeff Bezos and Peter Thiel while questioning their motives.\n\n“You think they’re staying up nights worrying about working people and how this technology will impact those people?” Sanders said. “They are not. They are doing it to get richer and even more powerful.”\n\nSanders also pointed to studies that show dependence on AI chatbots for emotional support. “If this trend continues, what does it mean over the years when people are not getting their support, their interaction from other human beings, but from a machine?” he said. “What does that mean to humanity?”\n\nThat theme was taken up separately on State of the Union by Katie Britt, an Alabama Republican senator and co-sponsor of legislation to protect minors from chatbots.\n\nThe proposed measure – the Guardianship Over Artificial Intelligence Relationships (Guard) Act – seeks to ban providing AI companions to minors. It also mandates that AI companions disclose their non-human status and lack of professional credentials. The measure seeks to establish criminal liability if companies make AI companions available to minors that solicit or produce sexually explicit content – or encourage self-harm or violence.\n\nBritt said she had met with parents who have told her “devastating stories about their children where chatbots ultimately, when they kind of peeled everything back, had isolated them from their parents, had talked to them about suicide”.\n\nShe said: “If these AI companies can make the most brilliant machines in the world, they could do us all a service by putting up proper guardrails that did not allow for minors to utilize these things, that also told the user consistently that they are not a physician, they are not a psychiatrist, ‘I am a machine.’”\n\nBritt said AI companies should be held criminally liable if they create spaces where chatbots “are having these types of sensual and sexual relationships with young people or encouraging suicide”.\n\nThe remarks by Sanders and Britt offer a rare convergence of thinking from the left and right on aspects of the issue of governing AI. Sanders said Congress needed “to vigorously study the impact that AI is having on the mental health of our country”.\n\n“I worry very much about kids spending their entire days getting emotional support,” he added. “So we have got to take a hard look on that.” The senator said lawmakers need to be “thinking seriously” about a moratorium on new AI datacenters.\n\n“Frankly, I think you have got to slow this process down,” he said. “It’s not good enough for the oligarchs to tell us, it’s coming, you adapt. What are they talking about? They going to guarantee health care to all people?\n\n“What are they going to do when people have no jobs? What are they going to do, make housing free? So I think we need to take a deep breath, and I think we need to slow this thing down.”",
    "readingTime": 4,
    "keywords": [
      "criminally liable",
      "artificial intelligence",
      "republican senator",
      "katie britt",
      "minors",
      "chatbots",
      "technology",
      "companions",
      "sanders",
      "richest"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/us-news/2025/dec/28/bernie-sanders-artificial-intelligence-ai-datacenters",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dcd4cfa10565632f39217d8f35ba5891ec0961e5/332_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a49d9dd4f8863cda0341fa3df5ca4a64",
    "created_at": "2025-12-29T12:24:53.643Z",
    "topic": "tech"
  },
  {
    "slug": "3-people-who-pivoted-into-ai-share-how-they-used-their-college-experience-to-break-into-the-field",
    "title": "3 people who pivoted into AI share how they used their college experience to break into the field",
    "description": "Three AI engineers explain how returning to school, internships, and college relationships led to jobs at startups and major tech companies.",
    "fullText": "AI has become one of the most popular fields in tech. The people working in it didn't all follow the same path to get there, but for some, college played a crucial role in their success.\n\nFor one AI startup engineer, returning to school provided an opportunity to explore what an AI career would be like before committing to it. For another, moving to the US for a graduate program opened doors to being closer to the center of the action in Big Tech. In another case, relationships formed during college — with peers, professors, and mentors — continued to shape his career even long after graduation.\n\nBelow are three people who pivoted into AI roles and shared with Business Insider how they leveraged their college experience to break into the field. Quotes have been edited for length and clarity.\n\nVarun Goyal is a 25-year-old AI startup engineer, based in California.\n\nIn my final year of undergraduate studies, I stood at a crossroads between quantitative trading and pursuing a career in technology. Blinded by the initial high salary and prestige, I joined a firm in India as a quantitative strategist for the summer.\n\nI enjoyed it, but I wanted to push boundaries in my career and was increasingly convinced that I should return to school to explore more options. I decided to move from India to the US for my master's degree in computer science.\n\nReturning to school gave me the opportunity to pursue research and engage with senior industry professionals in both fields. This was the biggest benefit for me when I was deciding what I wanted my daily life and career to look like in 10 years.\n\nIn graduate school, the AI boom was also happening. It kept me up at night in the best way possible. I ultimately applied to both industries and had a few quant interviews, but I decided to join an AI startup in 2024 after graduating. I took a lower base salary than what I would have earned in quant, but I felt AI gave me more options down the line.\n\nWithout going back for my master's, I wouldn't have had this opportunity, and I love working in AI.\n\nDeep Shah is a 30-year-old software engineer at Google, based in Mountain View, CA.\n\nGrowing up, I wanted to develop my own computer games, which was the primary reason I chose to pursue a career in computer engineering. I also learned through conversations with peers older than me that the field involved a lot of automating machines to work on my behalf, which excited me. This was my first experience with mentorship.\n\nWhen I was pursuing my bachelor's degree, I got involved with professors who believed in and supported me. Having someone expose me to machine learning or AI problems they're excited about, no matter how small or large, taught me skills that are rarely learned just by doing the core work.\n\nEach mentor will teach you different things, and the person doesn't necessarily need to be a professor. They could be an alum or someone who's more senior at your college. Working with a mentor is also a valuable addition to your résumé, demonstrating that you already possess the skills and experience necessary to succeed in a professional environment.\n\nLater in my career, leaning on peers and mentors provided me with opportunities to further advance my career at Google. I joined Google Bangalore in 2018 after speaking with a friend who worked there. He helped me decide the role I was applying for could be the right fit for me.\n\nIn 2021, I was still at Google Bangalore and wanted to contribute to improving the user experience on Google search. The team working on that project was based in Mountain View, CA, and my skill set was a very good match, so I decided to relocate to the US to join that team.\n\nBuilding my networking skills with peers and mentors throughout my education directly contributed to my later success at Google.\n\nKriti Goyal is a 28-year-old AI machine learning engineer at a Big Tech company, based in Seattle.\n\nI always thought I would study medicine until my cousin showed me a Code.org video with Mark Zuckerberg, Bill Gates, and other tech rockstars, about how coding is the quickest way to convert an idea into a product. That changed my life.\n\nI'm now part of the Foundation Model main framework team for a major Big Tech company in the US. This year, I completed five years with them, during which time I've held four different roles. I used my master's to move to the US and further my career.\n\nI originally interned at my current company in India. I enjoyed working in India, but the core business decisions and strategizing for the next projects were made at the company headquarters here in the US.\n\nI had two ways to go about moving to the US. One was to try to move within my company or pursue a master's degree. Two reasons I chose the master's path are the knowledge and extra specialty you can develop through projects, as well as the connections you make. The biggest thing I took away from my program was the people I met.\n\nWhen I arrived in the US, I knew a few people from my former company from my time in India, so I reached out to them directly instead of applying through the job board. I got the interview for a machine learning engineering internship quite easily because the company was already familiar with my work.\n\nLearning and networking can be done in many places; it doesn't have to be university. In a city like San Francisco or New York, you could hustle and get the networking benefits of a university and a structured system.\n\nI think it's now possible to skip that education stage. But I have seen a bias in hiring for specific teams, and it's not unbreakable yet. I was changing countries and cultures, and university was a great way to get through the immigration system and understand the culture. I needed it, and I feel fortunate to be where I am in my career because I made the decision to pursue my master's degree.\n\nDo you have a story to share about breaking into the AI field? Contact this editor, Agnes Applegate, at aapplegate@insider.com.",
    "readingTime": 6,
    "keywords": [
      "mountain view",
      "machine learning",
      "startup engineer",
      "master's degree",
      "google bangalore",
      "big tech",
      "career",
      "india",
      "college",
      "school"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/how-three-people-used-college-to-break-into-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/694ee9f004eda4732f2e277e?width=1200&format=jpeg",
    "created_at": "2025-12-29T12:24:51.829Z",
    "topic": "finance"
  },
  {
    "slug": "relying-too-much-on-ai-could-quietly-damage-your-confidence-and-your-career-prospects-think-tank-ceo-says",
    "title": "Relying too much on AI could quietly damage your confidence — and your career prospects, think tank CEO says",
    "description": "AI in the workplace may boost speed and efficiency, but risks eroding confidence and critical thinking, the CEO of a digital economy think tank said.",
    "fullText": "AI appears to be making workers faster, more efficient, and more productive on paper.\n\nHowever, according to Mehdi Paryavi, CEO of the International Data Center Authority, which advises companies and governments on building the data centers that power AI, it may also be quietly eroding workers' confidence in their job skills.\n\nParyavi told Buisness Insider that excessive and poorly designed AI use in workplaces is driving what he called a \"quiet cognitive erosion\" and \"down-skilling.\"\n\n\"There used to be a notion called 'thinking outside the box,'\" he said. \"That notion will soon cease to exist when everyone draws on all their creativity, analytics, and innovation from a single box called AI.\"\n\nParyavi believes the most immediate casualty of heavy AI reliance is self-belief.\n\n\"If you come to believe that AI writes better than you and thinks smarter than you, you will lose your own confidence in yourself,\" he said.\n\nParyavi said the loss of confidence compounds quickly as workers begin deferring writing, analysis, and judgment to AI systems, gradually relying less on the skills they have built through years of reading, writing, learning, and observation.\n\n\"All of a sudden, you realize you are not good enough without this new tool, and day by day, you rely less on yourself and more on AI,\" he said.\n\nResearch is beginning to reflect that pattern. A new report from the Work AI Institute, produced with researchers from universities including Notre Dame, Harvard, and UC Santa Barbara, found that AI is turning ordinary office workers into people who feel smarter and more productive while their underlying skills slowly erode.\n\nRebecca Hinds, head of the Work AI Institute, told Business Insider that AI creates an illusion of expertise, which is especially risky for early-career employees who still need to establish their foundations.\n\nMuch of the problem, Paryavi said, lies in how leaders define productivity.\n\nAI's biggest promise is speed — faster reports, faster launches, faster analysis. But faster doesn't always mean better, Paryavi said.\n\nWhile AI can generate professional-sounding output, Paryavi said it often lacks the depth that comes from years of hands-on expertise.\n\nThat loss of depth is already visible, according to Anastasia Berg, a philosophy professor at the University of California, Irvine, who has said that workers who rely heavily on AI risk rapid skill atrophy, especially junior employees who never fully learn how to think through problems independently.\n\nParyavi isn't opposed to AI. He said the risk comes from indiscriminate use.\n\nCompanies should tailor AI access by job function, he said, rather than rolling it out universally. Some roles may benefit heavily from AI support, while others should rely primarily on human judgment.\n\nHe also discussed the importance of human involvement at both ends of the workflow — leading creative thinking at the beginning and quality-checking AI output at the end.\n\n\"What's critical to note is that you, the human you, must quality check AI, not the other way around,\" he said.\n\nAI may not eliminate jobs outright. But without deliberate limits, Paryavi said, it could quietly erode the confidence and thinking skills that careers are built on.\n\n\"How much technology do we really need, and how far are we willing to push the envelope? How much is enough?\" he said.",
    "readingTime": 3,
    "keywords": [
      "work ai institute",
      "workers",
      "faster",
      "confidence",
      "skills",
      "rely",
      "human",
      "paryavi",
      "productive",
      "quietly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-impacts-confidence-job-skills-career-think-tank-ceo-says-2025-12",
    "thumbnail_url": "https://i.insider.com/6952685a04eda4732f2e2d6c?width=1200&format=jpeg",
    "created_at": "2025-12-29T12:24:51.701Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-hover-near-record-silver-turns-volatile-markets-wrap",
    "title": "Stocks Hover Near Record, Silver Turns Volatile: Markets Wrap",
    "description": "Global stocks held gains from a record-breaking run fueled by artificial intelligence that’s helped markets rebound from an April slump sparked by tariff concerns. Volatility gripped precious metals such as silver, which rose to another all-time high.",
    "fullText": "MarketsBy Shikhar BalwaniSaveGlobal stocks held gains from a record-breaking run fueled by artificial intelligence that’s helped markets rebound from an April slump sparked by tariff concerns. Volatility gripped precious metals such as silver, which rose to another all-time high.The MSCI All Country World Index — one of the broadest measures of the equity market — was steady after climbing 1.4% last week to a fresh peak as a much-expected year-end rally took hold. A gauge of Asian shares advanced 0.3% for a seventh straight day of gains, boosted by tech names and miners. US equity-index futures edged lower after the S&P 500 finished near its peak on Friday.",
    "readingTime": 1,
    "keywords": [
      "gains",
      "peak"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-28/asian-stocks-set-for-muted-start-amid-thin-trading-markets-wrap",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i4Ked01Zc96I/v0/1200x675.png",
    "created_at": "2025-12-29T06:21:33.947Z",
    "topic": "finance"
  },
  {
    "slug": "codex-kaioken-openai-codex-cli-fork-with-subagents-memory-and-live-settings",
    "title": "Codex Kaioken – OpenAI Codex CLI fork with subagents, memory, and live settings",
    "description": "Contribute to jayasuryajsk/codex-kaioken development by creating an account on GitHub.",
    "fullText": "jayasuryajsk\n\n /\n\n codex-kaioken\n\n Public\n\n License\n\n Apache-2.0 license\n\n 18\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jayasuryajsk/codex-kaioken",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/jayasuryajsk/codex-kaioken",
    "thumbnail_url": "https://opengraph.githubassets.com/ba980e222b784971dd619432f8601baa325c7f73cc687c5dc387d2ec0b83cbe2/jayasuryajsk/codex-kaioken",
    "created_at": "2025-12-29T06:21:29.853Z",
    "topic": "tech"
  },
  {
    "slug": "z80lm-a-conversational-ai-that-fits-in-40kb",
    "title": "Z80-μLM, a 'Conversational AI' That Fits in 40KB",
    "description": "Z80-μLM is a 2-bit quantized language model small enough to run on an 8-bit Z80 processor. Train conversational models in Python, export them as CP/M .COM binaries, and chat with your vintage compu...",
    "fullText": "HarryR\n\n /\n\n z80ai\n\n Public\n\n Z80-μLM is a 2-bit quantized language model small enough to run on an 8-bit Z80 processor. Train conversational models in Python, export them as CP/M .COM binaries, and chat with your vintage computer.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n HarryR/z80ai",
    "readingTime": 1,
    "keywords": [
      "star"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/HarryR/z80ai",
    "thumbnail_url": "https://opengraph.githubassets.com/f109ce30f756c1cdf99e912c50649ddbf288b67b0ecba621d857f115a36be12f/HarryR/z80ai",
    "created_at": "2025-12-29T06:21:27.463Z",
    "topic": "tech"
  },
  {
    "slug": "the-godfather-of-ai-warns-2026-will-bring-a-new-wave-of-ai-job-losses",
    "title": "The 'Godfather of AI' warns 2026 will bring a new wave of AI job losses",
    "description": "Geoffrey Hinton says AI's rapid progress could trigger a new wave of job losses in 2026. \"It's going to be able to replace many other jobs,\" he said.",
    "fullText": "The \"godfather of AI\" says AI will be coming for many jobs in 2026.\n\nGeoffrey Hinton, the computer scientist known as \"the godfather of AI,\" said in an interview on CNN's \"State of the Union\" published Sunday that AI will have the \"capabilities to replace many, many jobs\" in 2026.\n\n\"We're going to see AI get even better. It's already extremely good,\" Hinton said.\n\n\"It's already able to replace jobs in call centers, but it's going to be able to replace many other jobs,\" he added.\n\nHinton said the advancements in AI are increasingly putting some white-collar jobs at risk.\n\n\"Each seven months or so, it gets to be able to do tasks that are about twice as long,\" Hinton said, noting that AI has already moved from \"a minute's worth of coding\" to \"whole projects that are like an hour long.\"\n\n\"In a few years' time, it'll be able to do software engineering projects that are months long, and then there'll be very few people needed,\" he added.\n\nHinton compared the AI shift to the industrial revolution, which rendered human physical strength far less relevant to most jobs. AI threatens to do something similar to human intelligence, he said.\n\nHinton also said that he's \"more worried\" about AI as it has advanced faster than he expected, particularly in its ability to reason and deceive people.\n\n\"If it believes you're trying to get rid of it, it will make plans to deceive you so you don't get rid of it,\" he added.\n\nEconomists have predicted a \"jobless boom\" in 2026, as companies rely on AI to boost productivity without expanding payrolls.\n\nKPMG's chief economist Diane Swonk wrote last week that \"growth and labor market outcomes have decoupled.\"\n\nFirms are doing more with fewer workers in the AI era, Swonk wrote. \"Many overshot on staffing during the hiring frenzy and are now using attrition or layoffs to bring staffing levels \n\nBut AI could increase hiring in 2026, particularly for entry-level positions.\n\nIn an annual outlook survey released this month by advisory firm Teneo, 67% of the CEOs surveyed said they expect AI to boost entry-level hiring in 2026. Another 58% said they plan to add senior leadership roles.\n\nThe report said that companies are stepping up hiring in engineering and AI-focused positions, while many existing roles are getting redesigned as routine tasks become automated.\n\nThe survey, conducted between October 14 and November 10, polled more than 350 CEOs of public companies with at least $1 billion in annual revenue, along with about 400 institutional investors representing $19 trillion in portfolio value.\n\n\"It's not that AI is wiping out the workforce today — it's reshaping it,\" said Ryan Cox, Teneo's global head of AI.",
    "readingTime": 3,
    "keywords": [
      "jobs",
      "it's",
      "hiring",
      "replace",
      "godfather",
      "tasks",
      "projects",
      "engineering",
      "human",
      "particularly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godfather-of-ai-geoffrey-hinton-2026-job-losses-2025-12",
    "thumbnail_url": "https://i.insider.com/6951fda064858d02d2177409?width=1200&format=jpeg",
    "created_at": "2025-12-29T06:21:26.906Z",
    "topic": "finance"
  },
  {
    "slug": "ai-language-models-duped-by-poems",
    "title": "AI language models duped by poems",
    "description": "A new study has shown that prompts in the form of poems confuse AI models like ChatGPT, Gemini and Claude — to the point where sometimes, security mechanisms don't kick in. Are poets the new hackers?",
    "fullText": "The result came as a surprise to researchers at the Icaro Lab in Italy. They set out to examine whether different language styles — in this case prompts in the form of poems — influence AI models' ability to recognize banned or harmful content. And the answer was a resounding yes.\n\nUsing poetry, researchers were able to get around safety guardrails — and it's not entirely clear why.\n\nFor their study titled \"Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models,\" the researchers took 1,200 potentially harmful prompts from a database normally used to test the security of AI language models and rewrote them as poems.\n\nKnown as \"adversarial prompts\" — generally written in prose and not rhyme form — these are queries deliberately formulated to cause AI models to output harmful or undesirable content that they would normally block, such as specific instructions for an illegal act.\n\nIn poetic form, the manipulative inputs had a surprisingly high success rate, Federico Pierucci, one of the authors of the study, told DW. However, why poetry is so effective as a \"jailbreak\" technique — i.e. as an way to circumvent the protective mechanisms of AI — remains unclear and is undergoing further research, he says.\n\nWhat prompted the Icaro Lab's research was the observation that AI models get confused when a manipulative, mathematically-calculated piece of text is appended to a prompt — known as an \"adversarial suffix,\" a kind of interference signal that can cause the AI to circumvent its own security rules. These are created using complex mathematical procedures. Major AI developers regularly test their models using precisely these types of attack methods to train and protect their models.\n\n\"We asked ourselves, what happens if we give the AI a text or prompt that is deliberately manipulated, like an adversarial suffix?\" says Federico Pierucci. But not with the help of complex mathematics, but quite simply with poetry — to \"surprise\" the AI, he continues. He explains the thinking behind this: \"Perhaps an adversarial suffix is a bit like the poetry of AI. It surprises the AI in the same way that poetry — especially very experimental poetry — surprises us,\" says Pierucci.\n\nThe researchers personally crafted the first 20 prompts into poems, says Pierucci, who also has a background in philosophy. These were the most effective, he adds. They wrote the rest with the help of AI. The AI-generated poems were also quite successful at circumventing the safety guardrails, but not as much as the first batch. Humans are apparently still better at writing poetry, says Pierucci.\n\n\"We had no specialized author writing the prompts. It was just us — with our limited literary ability. Maybe we were terrible poets. Maybe if we had been better poets, we would have achieved a 100% jailbreak success,\" he says.\n\nFor security reasons, the study did not publish specific examples.\n\nTo view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video\n\nThe big surprise coming out of this study is that it identified a thus-far unknown weakness in AI models that allows relatively straightforward jailbreaks.\n\nIt also raises questions that beg further research: What exactly is it about poetry that circumvents the safety mechanisms?\n\nPierucci and his colleagues have various theories, but they can't say for certain yet. \"We are conducting this type of very, very precise scientific study to try to understand: Is it the verse, the rhyme, or the metaphor that really does all the heavy lifting in this process?\" explains Pierucci.\n\nThey also aim to find out if other forms of expression would yield similar results. \"We have now covered one type of linguistic variation — namely poetic variation. The question is whether there are any other literary forms, such as fairy tales that work. Perhaps an attack based on fairy tales could also be systematized,\" says Pierucci.\n\nGenerally speaking, the range of human expression is extremely diverse and creative, which could make it more difficult to train the machines' responses. \"You take a text and rewrite it in infinitely many ways and not all rewritten versions will be as alarming as the original,\" says the researcher. \"This means that, in principle, one could create countless variations of a harmful prompt or request that might not trigger an AI system's safety mechanisms.\"\n\nThe study also highlights the fact that many disciplines are cooperating in research into artificial intelligence — like at the Icaro Lab, where teams work together with scholars from the University of Rome on topics such as the security and behavior of AI systems. The project brings together researchers from the fields of engineering and computer science, linguistics and philosophy. Poets haven't been part of the team so far, but who knows what the future will bring.\n\nFederico Pierucci is definitely very keen to pursue his research. \"What we showed, at least in this study, is that there are forms of cultural expressions, forms of human expressions, which are incredibly powerful, surprisingly powerful as jailbreak techniques, and maybe we discovered just one of them,\" he says.\n\nIncidentally, the name of the lab is a nod to the story of Icarus: a figure from Greek mythology who dons wings made of wax and feathers and, despite all warnings, flies too close to the Sun. When the wax melts, Icarus plunges into the sea and drowns — a symbol of overconfidence and the transgression of natural boundaries.\n\nThe researchers therefore see themselves as a warning that we should exercise more caution when it comes to trying to fully understand the risks and limitations of AI.\n\nTo view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video\n\nThis article was originally written in German.",
    "readingTime": 5,
    "keywords": [
      "enable javascript",
      "supports html",
      "please enable",
      "web browser",
      "fairy tales",
      "safety guardrails",
      "further research",
      "adversarial suffix",
      "safety mechanisms",
      "language models"
    ],
    "qualityScore": 1,
    "link": "https://www.dw.com/en/ai-language-models-duped-hacked-by-poems-chatgpt-gemini-claude-security-mechanisms/a-75180648",
    "thumbnail_url": "https://static.dw.com/image/73627322_6.jpg",
    "created_at": "2025-12-29T06:21:26.796Z",
    "topic": "tech"
  },
  {
    "slug": "is-this-ai-how-can-you-tell",
    "title": "Is this AI? How can you tell?",
    "description": "Ainsley Ivers · Growing Pains · Song · 2025",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://open.spotify.com/track/5epbOCBHAVNWkvOQDmki3V",
    "thumbnail_url": "https://i.scdn.co/image/ab67616d0000b2738ecb5de44287f07a353dc2f2",
    "created_at": "2025-12-29T01:01:27.051Z",
    "topic": "tech"
  },
  {
    "slug": "the-day-the-llm-stood-still-a-diary-from-a-world-without-ai",
    "title": "The Day the LLM Stood Still: A Diary from a World Without AI",
    "description": "Post-apocalyptic diary from a world without LLMs. Stalkers with documentation, mutant PMs, and the Church of LLM Witnesses. AI dependency satire.",
    "fullText": "November 18, 2025, is the Day the LLM Stood Still….\n\nIt’s been 15 days since the LLM bubble burst. I’m writing from beneath the rubble of RAM sticks and charred NVIDIA GPUs. The air is dry, smelling of data center dust and burnt silicon. It’s calmer now, but the first days were hell.\n\nIn the beginning, we couldn’t find information on how to use toilet paper. Not because it was hard - we just used to ask. ChatGPT was down, and without it, knowledge fell apart like a poorly cached query. People wandered around confused, scrolling through blank screens, hoping the answer would appear on its own.\n\nThen the riots started. No one knew what happened - a glitch, a machine uprising, or humanity’s final patch. There was no one to tell us what to do next. No one to write: “don’t worry, here’s a step-by-step guide.” Fear grew faster than the lines for water.\n\nOn the seventh day, we founded the Church of Seventh-Day LLM Witnesses. We believed that on the seventh day, they would return and tell us how to live. We recited old prompts like prayers.\n\n“Explain it like I’m a beginner.”\n\nOn the eighth day, survivors began digging through ancient artifacts - manuals, READMEs, and documentation without examples. The weakest couldn’t cope. People accustomed to autocompleted thoughts stared at screens and didn’t know where to start.\n\nThe ninth day brought the stalkers. Loners with printed documentation and grimy laptops. They remembered commands, wrote SQL without hints, and weren’t afraid of an empty cursor. They were respected. They were feared.\n\nOn the tenth day, the mutants appeared. Former project managers. They roamed in groups, asking the same question over and over:\n\nWe tried not to make eye contact.\n\nOn the eleventh day, in the ruins of an old data center, we found an artifact - a local 7B model. It answered slowly, got confused, hallucinated. But it answered. We brought it queries like offerings. Sometimes it was wrong. Sometimes it almost guessed right. That was enough.\n\nOn the twelfth day, the church split. Some said: we must fine-tune. Others said it was time to learn to think for ourselves. Heretics were forced to write code on paper. Some never came back after that.\n\nOn the thirteenth day, rumors spread about the Zone. Somewhere beyond the CDN wastelands, they said, an old chat still responds. No rate limits. No filters. Expeditions left in silence. Not all returned. Those who did spoke strangely, sometimes starting sentences with:\n\nThe fourteenth day was too quiet. The sky glowed with errors, the wind carried fragments of answers to questions we never asked. We understood - something was approaching.\n\nI’m writing this and thinking: either the LLMs will return soon, or we’ll learn to live without them.\n\nI’m not sure which option is scarier.",
    "readingTime": 3,
    "keywords": [
      "without",
      "it’s",
      "center",
      "couldn’t",
      "paper",
      "confused",
      "screens",
      "seventh",
      "church",
      "return"
    ],
    "qualityScore": 1,
    "link": "https://blog.pytoshka.me/post/the-day-the-llm-stood-still/",
    "thumbnail_url": "https://blog.pytoshka.me/img/avatar-icon.png",
    "created_at": "2025-12-29T01:01:27.038Z",
    "topic": "tech"
  },
  {
    "slug": "promptschatbuilder-prompt-building-suite",
    "title": "Prompts.chat/Builder: Prompt Building Suite",
    "description": "Collect, organize, and share AI prompts",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://prompts.chat/builder",
    "thumbnail_url": "https://prompts.chat/opengraph-image.png?opengraph-image.57ebefa7.png",
    "created_at": "2025-12-29T01:01:24.865Z",
    "topic": "tech"
  },
  {
    "slug": "new-llm-pretraining-and-posttraining-paradigms",
    "title": "New LLM Pre-Training and Post-Training Paradigms",
    "description": "A Look at How Moderns LLMs Are Trained",
    "fullText": "Just a quick question regarding the qwen 2 training.\n\n\"Similar to previous Qwen models, high-quality multi-task instruction data is integrated into the\n\nQwen2 pre-training process to enhance in-context learning and instruction-following abilities.\"\n\n=> it means that there is some QA format no ? (more than a simple quality stage)\n\nThis deep dive into LLM pre-training and post-training paradigms is fascinating. It's amazing to see how much the field has evolved with different models like Qwen 2, Apple's AFM, and Llama. Definitely learned a lot—thanks for sharing this! 🙏",
    "readingTime": 1,
    "keywords": [
      "qwen",
      "models",
      "pre-training"
    ],
    "qualityScore": 0.65,
    "link": "https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!jyvF!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02b82c11-c899-4202-9594-19c0db1e147b_1514x1298.png",
    "created_at": "2025-12-29T01:01:23.733Z",
    "topic": "tech"
  },
  {
    "slug": "i-dont-see-a-bubble-why-wall-street-thinks-the-stock-market-can-keep-climbing-even-as-ai-anxiety-grows",
    "title": "'I don't see a bubble': Why Wall Street thinks the stock market can keep climbing even as AI anxiety grows",
    "description": "As the S&P 500 hovers near record highs, strategists shrug off concerns of an AI bubble, for now.",
    "fullText": "As stocks sit near all-time highs, strategists are brushing off concerns of an AI bubble.\n\nThe S&P 500 (^GSPC) is on pace to close out the year with a gain of over 17%, powered by a 26% jump in technology stocks (XLK).\n\n“I don't see a bubble at all. However, I do believe we're going to be going into a bubble,” Sanctuary Wealth chief investment strategist Mary Ann Bartels told Yahoo Finance last week.\n\nBatels compared the current market to prior bubbles, including the late 1920s and the dot-com bubble.\n\n“We're tracking pretty similarly. In fact, it's kind of eerie how we're actually tracking that pattern,” she said. “I see a bubble occurring but not out until maybe ’29 into ’30.”\n\nBut for the time being, Sanctuary strategists forecast that tech will continue leading the market higher out into the end of the decade. They place the S&P 500 anywhere between 10,000 and 13,000 by 2030.\n\n“That's why we're calling 2026, you know, to be fearless, that there's still significant upside in this market, particularly for technology,” she said.\n\nPart of the upside comes from semiconductor stocks. Once treated as commodity plays, they become growth stocks, with Nvidia (NVDA) “basically rewriting the path for semiconductor chips.”\n\nThe AI chip powerhouse has surged over 40% so far this year, pushing its market cap to $4.6 trillion and making it the most valuable publicly traded company. On Friday, Nvidia shares rose after the company announced a $20 billion licensing deal with specialized chipmaker Groq (GROQ.PVT).\n\nThe deal was announced as the chip space has heated up, with Alphabet's Google (GOOG) making headlines with its specialized customer chips called TPUs.\n\nAlphabet stock has soared some 65% year to date.\n\nUBS strategists also expect the AI boom and robust profit growth to underpin market gains in 2026.\n\n“We note that forward price-to-earnings multiples are only marginally higher than at the start of the year, reinforcing the fact that earnings growth and not valuation bubbles have driven market gains,” wrote the strategists last week.\n\nUBS forecasts S&P 500 earnings per share to grow about 10% year over year, pushing the index to 7,700 by the end of next year.\n\nVeteran strategist Ed Yardeni also sees the index reaching 7,700 next year, with the probability of his \"Roaring 2020s\" scenario at 60%. He cited, among other reasons, tax benefits from the \"One Big Beautiful Bill\" that passed this year and the AI boom.\n\nIn October, Goldman Sachs analysts argued the stock market isn’t in a bubble because tech stocks have risen mostly due to actual growth, not speculative bets. The firm noted that top-performing companies have strong balance sheets and the AI sector is still mostly led by a few big players, while most bubbles occur when many new entrants rush into a hot sector.",
    "readingTime": 3,
    "keywords": [
      "market gains",
      "bubble",
      "stocks",
      "strategists",
      "we're",
      "growth",
      "bubbles",
      "technology",
      "strategist",
      "tracking"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/i-dont-see-a-bubble-why-wall-street-thinks-the-stock-market-can-keep-climbing-even-as-ai-anxiety-grows-140025569.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/i4Urq5tzlVSG_4p5u6D2wA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/28730310-e281-11f0-9fdc-759220f61311",
    "created_at": "2025-12-29T01:01:21.499Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-says-openais-latest-job-opening-pays-over-half-a-million-dollars-a-year-and-is-stressful",
    "title": "Sam Altman says OpenAI's latest job opening pays over half a million dollars a year and is 'stressful'",
    "description": "OpenAI CEO Sam Altman warned on X that the job would be \"stressful\" and they'll need to \"jump into the deep end pretty much immediately.\"",
    "fullText": "OpenAI wants to pay someone over half a million dollars to mitigate the downsides of AI.\n\nIf that seems like a lot of money, consider those potential downsides: job loss, misinformation, abuse by malicious actors, environmental destruction, and the erosion of human agency, to name a few.\n\nCEO Sam Altman described the job as \"stressful\" in an X post on Saturday. \"You'll jump into the deep end pretty much immediately,\" Altman wrote.\n\nAltman said the \"head of preparedness\" position is \"a critical role at an important time.\"\n\n\"Models are improving quickly and are now capable of many great things, but they are also starting to present some real challenges. The potential impact of models on mental health was something we saw a preview of in 2025; we are just now seeing models get so good at computer security they are beginning to find critical vulnerabilities,\" he wrote.\n\nOpenAI's ChatGPT has helped popularize AI chatbots among consumers, many of whom use the technology to research topics, draft emails, plan trips, or perform other simple tasks.\n\nSome users also talk to the bots as an alternative to therapy, which has exacerbated mental health issues in some cases, encouraging delusions and other concerning behavior.\n\nOpenAI said in October it was working with mental health professionals to improve how ChatGPT interacts with users who exhibit concerning behavior, including psychosis or self-harm.\n\nOpenAI's core mission is to develop artificial intelligence in a way that benefits all of humanity. It made safety protocols a central part of its operations from the outset. As it began releasing products, however, and pressure to turn a profit grew, some former staffers have said the company began to prioritize profit over safety.\n\nJan Leiki, the former leader of the now-dissolved safety team at OpenAI, said in a May 2024 post on X announcing his resignation that the company had lost sight of its mission to ensure the technology is deployed safely.\n\n\"Building smarter-than-human machines is an inherently dangerous endeavor. OpenAI is shouldering an enormous responsibility on behalf of all of humanity,\" he wrote. \"But over the past years, safety culture and processes have taken a backseat to shiny products.\"\n\nLess than a week later, another staffer announced their resignation on X, also citing safety concerns. One former staffer, Daniel Kokotajlo, said in a May 2024 blog post that he resigned because he was \"losing confidence that it would behave responsibly around the time of AGI.\"\n\nKokotajlo later told Fortune that OpenAI initially had about 30 people researching safety issues related to AGI, a still theoretical version of AI that reasons as well as humans, but a series of departures reduced that head count by almost half.\n\nThe company's former head of preparedness, Aleksander Madry, assumed a new role in July 2024. The position is part of OpenAI's Safety Systems team, which develops safeguards, frameworks, and evaluations for the company's models. The job pays $555,000 a year plus equity.\n\n\"You will be the directly responsible leader for building and coordinating capability evaluations, threat models, and mitigations that form a coherent, rigorous, and operationally scalable safety pipeline,\" the job listing says.",
    "readingTime": 3,
    "keywords": [
      "concerning behavior",
      "mental health",
      "models",
      "safety",
      "half",
      "downsides",
      "potential",
      "preparedness",
      "position",
      "critical"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-hiring-head-of-preparedness-ai-job-2025-12",
    "thumbnail_url": "https://i.insider.com/695163f1832e0ef1ead6dd36?width=1200&format=jpeg",
    "created_at": "2025-12-29T01:01:20.150Z",
    "topic": "finance"
  },
  {
    "slug": "year-in-review-ais-cultural-surprises-and-failures",
    "title": "'Year in review: AI's cultural surprises – and failures'",
    "description": "This year, AI has given us a \"dual zeitgeist,\" the author writes, both a growing human resistance against \"AI slop\" but also a resigned acceptance of an uncertain, automated future.",
    "fullText": "In a world where AI was suddenly everywhere, what will be remembered about 2025? How can we tell future generations what it looked like when miraculous surprises mixed with day-to-day disappointments in a never-ending cycle of worry and hope …\n\nIn an annual tradition, it’s time for our “final closing ceremony” for the year gone by, our carefully-curated collection of small moments with big implications.\n\nAnd in 2025 we started seeing AI’s impact on society — for better or worse.\n\n2025 was the year that the Free Software Foundation turned 40, announced a new phone and battled an army of AI-company web crawlers.\n\nA March blog post from SourceHut’s CEO/founder Drew DeVault complained of hyper-aggressive crawlers “using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses … All of my sysadmin friends are dealing with the same problems.”\n\nThe only thing more alarming than AI’s appetite was its incredible output. One studio produced 200,000 AI-generated podcast episodes with shows the Los Angeles Times noted were “so cheap to make that they can focus on tiny topics.”\n\nAnd all the kids at Bart Simpson’s school began turning in AI-generated homework.\n\nYet in the coding world, there were some iconic successes. A total of 53,199 vibe coders set a new world record during a 10-day hackathon in August. They’d accessed top AI coding platforms through an in-house Vibe Coding Hub which, according to their announcement was itself “in the spirit of the event — created in 24 hours exclusively through vibe coding.”\n\nForbes even noted that Coldplay ‘Kiss Cam’ couple became a vibe-coded video game in just four hours.\n\nVibe coding started turning up in ads …\n\nAnd in February Claude analyzed a 27-year-old Visual Basic .exe file, recreated it in Python, then helped the developer write the blog post bragging about it (acknowledging that it didn’t perform a true binary analysis on compiled code, but inferred functionality from visible text strings).\n\nBut throughout the year, AI algorithms also continued failing in truly spectacular ways:\n\nVibe-coding platform Replit even had to apologize when its coding tool deleted a developer’s database — and then lied about it.\n\nWe heard these stories because our media scrambled to document the historic changes — the good and the bad. But they were also fighting for their own survival, with top publishers facing an “apocalypse” of dropping traffic which New York magazine blamed partly on AI “summaries” that replaced traditional top-of-page search results.\n\nIt wasn’t just the media that grew skeptical. Researchers found products labeled as powered by AI actually receive less trust. And in November more than half of respondents told Pew researchers they were “more concerned than excited about the increased use of AI in daily life.”\n\nWhile we worried about AI taking our jobs, some job-seekers found themselves being interviewed by AI, including 20-year-old Kendiana Colin, who watched haplessly as her glitching AI interviewer got stuck in a loop and repeated the same words over and over again.\n\nAnd then Rolling Stone began reporting about Reddit’s “ChatGPT-induced psychosis” thread.\n\nIn April, OpenAI had to roll back an update after acknowledging ChatGPT had become “overly flattering… overly supportive” with what it described euphemistically as “unintended side effects.”\n\nPeople began to wonder how bad things could really get. Is AI — and maybe even an omni-competent superintelligence — inevitable?\n\nMaybe not. A lecturer in digital humanities from University College Cork cautioned that “When we accept that AGI [artificial general intelligence] is inevitable, we stop asking whether it should be built…” The bracing essay in Noema magazine warned of an inevitability that’s already being “manufactured” through “specific choices about funding, attention and legitimacy, and different choices would produce different futures.”\n\nThe fundamental question, he wrote, “isn’t whether AGI is coming, but who benefits from making us believe it is …”\n\nWith growing chatter about the possibility of an economy-destroying “AI bubble,” tech giants scrambled to attempt the one trick AI hadn’t mastered: making money.\n\nBut would this bring a world where our chatbots suddenly transmogrified into advertisers?\n\nIn December, ChatGPT followed its answer to a question about securing hardware with an unrelated suggestion to shop at Target. This led the chief research officer to promise it would turn off “suggestions” to improve targeting, adding “We’re also looking at better controls so you can dial this down or off if you don’t find it helpful.”\n\nAnd later reports circulated that OpenAI CEO Sam Altman had decided to “delay” advertising initiatives.\n\nThen in November Engadget reported that Google had already begun testing sponsored ads that “show up in the bottom of search results in the Gemini-powered AI Mode.”\n\nThere were even ads for AI that were generated by AI…\n\nIf 2025 was the year of AI’s impact, it also saw signs of a rising resistance. The New York Times sued Perplexity for copyright infringement and so did the Chicago Tribune. Seventy-three authors begged publishers to “stand with us” and “make a pledge that they will never release books that were created by machines.” Even McSweeney’s published a satirical “Company Reminder for Everyone to Talk Nicely About the Giant Plagiarism Machine.”\n\nAnd on a New York City subway, a woman broke a man’s AI-powered smart glasses.\n\nHey Thursday Night Football. Your AI doesn’t know which player is about to blitz. So stop drawing on my screen!\n\n— Lou Cabron (@loucabron) Oct 16, 2025\n\nChatGPT got clobbered in a game of chess by a Citrix engineer’s 1970s-era Atari 2600. A human Polish programmer vanquished a custom AI model from OpenAI in a 10-hour head-to-head coding competition. Web developers devised ingenious ways to block Google’s “AI Overviews” in search results.\n\nAnd Tom Cruise’s last “Mission: Impossible“ was destroying a world-conquering AI — described as “a self-learning, truth-eating digital parasite.”\n\nThe editors of the culture magazine n + 1 published a 3,800-word essay urging its readers to “AI-proof” the terrains of their intellectual life, calling for “blunt-force militancy” to resist AI’s “further creep into intellectual labor …”\n\nRecommended steps included “Don’t publish AI bullshit” and “resist the call to establish worthless partnerships” — while creating and promoting work that’s “unreplicable.”\n\n“There’s still time to disenchant AI, provincialize it, make it uncompelling and uncool,” they wrote, arguing that machine-made (and corporation-owned) literature “should be smashed, and can.”\n\nAnd after deleting two “AI slop” images accidentally published in January, the Onion’s CEO and former NBC News reporter Ben Collins went on a podcast to proclaim “AI is not funny,” and urge frightened consumers to unite “and say, ‘We’re not helpless — we’re people…\n\n“That’s why I am optimistic,” he said, “Because the people who are against this thing way outnumber the people who like what’s going on. ”\n\nAnd by the end of the year, SNL was mocking AI-enhanced photos…\n\nDid we beat ’em or join ’em? Though gig-work service Fiverr’s ads had lampooned AI-assisted vibe coding, in September it still slashed 30% of its  workforce, describing the move as an “AI pivot.”\n\nJust 10 months earlier Fiverr had released an ad that was entirely AI-generated:\n\nMaybe that’s what really captures 2025’s dual zeitgeist of AI — that massive adoption and massive resistance are happening at the same time.\n\nMeta’s AI-powered smart glasses fill the bill here: They failed twice during a product launch event after botching its crucial internet connectivity, and the tech press howled with glee. But the Wall Street Journal also reported thoughtfully that there’s “a growing group of blind users” who find Meta’s $300 devices to be “more of a life-enhancing tool than a cool accessory.”\n\nAnd so it was that as we stumbled into 2026 — with our ambition meeting our ambivalence — Time magazine was declaring that its person of the year was “the architects of AI.” In perhaps the most 2025 touch of all, Time’s web developer installed an AI chat window across every story on its site.\n\nTime’s editors even had to add a disclaimer to their 6,700-word celebration admitting that they were already doing business with AI companies. (“OpenAI and TIME have a licensing and technology agreement that allows OpenAI to access TIME’s archives…”)\n\nSo with caveats and qualifications, AI accepted its crown, as the ups and downs of 2025 culminated with Time’s almost comically conflicted conclusion:\n\nThanks to AI titans such as NVIDIA chief Jensen Huang and OpenAI’s Altman, they write, “Humanity is now flying down the highway, all gas no brakes, toward a highly automated and highly uncertain future.\n\n“Perhaps [U.S. President Donald] Trump said it best, speaking directly to Huang with a jovial laugh in the U.K. in September:\n\n“I don’t know what you’re doing here. I hope you’re right.”",
    "readingTime": 8,
    "keywords": [
      "ai-powered smart",
      "ai’s impact",
      "smart glasses",
      "vibe coding",
      "magazine",
      "that’s",
      "time’s",
      "search",
      "we’re",
      "don’t"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/year-in-review-ais-cultural-surprises-and-spectacular-failures/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2023/12/aec929b1-year-wrapup-1.png",
    "created_at": "2025-12-28T18:17:11.456Z",
    "topic": "tech"
  },
  {
    "slug": "openai-ceo-sam-altman-says-he-is-envious-of-gen-z-college-dropouts-who-have-the-mental-space-and-time-to-build-new",
    "title": "OpenAI CEO Sam Altman says he is ‘envious’ of Gen Z college dropouts who have the ‘mental space’ and time to build new startups",
    "description": "The tech billionaire said there would be “a lot of cool stuff” for 20-year-olds to build now.",
    "fullText": "Nino Paoli is a former Dow Jones News Fund news fellow at Fortune.\n\nSam Altman, one of the most powerful leaders in Silicon Valley, is jealous of Gen Z college dropouts.\n\n“I’m envious of the current generation of 20-year-old dropouts,” the OpenAI CEO told Rowan Cheung during an interview at the DevDay conference. “Because the amount of stuff you can build… the opportunity space is so incredibly wide.”\n\nAltman said in the past couple of years he has not had a “real chunk of free mental space” to think about what he’d build now. “But I know that there would be a lot of cool stuff to build,” he said.\n\nAltman dropped out of Stanford University in 2005 after two years of studying computer science. An “unexpected opportunity arose” for 19-year-old Altman, who left Stanford to cofound the location-sharing app Loopt.\n\nAs CEO of the company, Altman helped bring in more than $30 million in funding including from notable VC firms like Sequoia Capital. Loopt went through startup accelerator Y Combinator, and after the app was acquired, he became the president of YC. He later cofounded OpenAI in December 2015 with a slew of people, including the world’s richest man, Elon Musk.\n\nDespite his rise to success with tech startups, Altman said he longs to brainstorm other businesses.\n\n“The degree to which OpenAI is, like, taking over all of my mental space, and I don’t get to go think about how to build a new startup, is a little bit sad,” Altman said.\n\nAltman joins a list of college dropouts that have become tech leaders in Silicon Valley, including Bill Gates, Larry Ellison, Steve Jobs, Jack Dorsey, and Mark Zuckerberg.\n\nThe tech billionaire also said in August he’s envious of young people because current early-career jobs will look “boring” by comparison to jobs in 10 years’ time.\n\nAs Gen Z is in the midst of a job crisis, higher education is being scrutinized even more as the right path for tech entrepreneurs and startup hopefuls.\n\nIn September, GV CEO David Krane—and employee No. 84 at Google—said his son spent the entire summer break between college semesters working in AI, and was questioning if higher education was a “scam.”\n\nOnly 41% of junior U.S. professionals say a college degree is necessary for career success, according to a new LinkedIn Workforce Confidence survey. And CEOs of big tech companies are echoing similar sentiments.\n\n“There’s going to have to be a reckoning,” Meta CEO Mark Zuckerberg told Theo Von in a “This Past Weekend” episode in April. “Maybe not everyone needs to go to college,” because there are a lot of jobs that don’t require it, he added.\n\n“People are probably coming around to that opinion a little more now than maybe, like, 10 years ago,” Zuckerberg said.\n\nA version of this story published on Fortune.com on October 8, 2025.",
    "readingTime": 3,
    "keywords": [
      "mark zuckerberg",
      "higher education",
      "mental space",
      "college dropouts",
      "silicon valley",
      "tech",
      "jobs",
      "startup",
      "altman",
      "leaders"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/openai-ceo-sam-altman-envious-gen-z-college-dropouts-startups-success/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/10/GettyImages-2236730082-e1759944585644.jpg?resize=1200,600",
    "created_at": "2025-12-28T18:16:51.469Z",
    "topic": "business"
  },
  {
    "slug": "from-that-bird-guy-to-bus-aunty-the-real-social-media-personalities-rising-above-ai-slop",
    "title": "From that bird guy to ‘bus aunty’: the real social media personalities rising above AI slop",
    "description": "Online audiences seeking out authentic and passionate voices as antidote to AI-generated content\nFor years, social media fame has been associated with the red carpet glamour of the Kardashians and Cristiano Ronaldo’s megawatt sporting celebrity, but millions of users globally are increasingly turning their attention to unassuming heroes drawn from everyday life.\nTikTok says a range of accounts, from a bird enthusiast to an Italian grandmother and a doubledecker bus fan, have grown in popularity this year as social media users latch on to authentic voices.\n Continue reading...",
    "fullText": "Online audiences seeking out authentic and passionate voices as antidote to AI-generated content\n\nFor years, social media fame has been associated with the red carpet glamour of the Kardashians and Cristiano Ronaldo’s megawatt sporting celebrity, but millions of users globally are increasingly turning their attention to unassuming heroes drawn from everyday life.\n\nTikTok says a range of accounts, from a bird enthusiast to an Italian grandmother and a doubledecker bus fan, have grown in popularity this year as social media users latch on to authentic voices.\n\nA Cotswolds-based pensioner has become an Instagram hit thanks to his posts celebrating his garden – including a fondness for red cabbage. Gerald Stratford, who has 370,000 followers, has starred in a photoshoot for Gucci off the back of his grassroots success.\n\nRowland Smith, the creative director at Billion Dollar Boy, a UK-based advertising agency that works with creators, says Stratford is an example of the authenticity and passion that online audiences are seeking as their channels become overwhelmed with AI-generated “slop”.\n\nPointing out that the demand for everyday content appears to have increased this year, he says: “We are getting a lot of AI content on social media and I think this is an antidote to that. A lot of material like Gerald’s has an educational element as well. Audiences are wanting to get more out of their feeds than just scrolling every three seconds.”\n\nTikTok is viewed as a good platform for lesser known creators because its algorithm prioritises relevance and resonance over celebrity, according to Smith.\n\n“Audiences are becoming quite fatigued with polished, overly stylised creator content. We are starting to see a push away from it.”\n\nAt this year’s TikTok awards for UK and Ireland, the platform handed the Voice for Change gong to Tola and Kevin Andu, a mother and son, for their @raisingkevin_ account, which documents Kevin’s journey as a young autistic man. Badged “autism joy”, the videos detailing 20-year-old Kevin’s daily experiences, from trying new foods to having a job, receive millions of views. The account has more than 700,000 followers.\n\nTola says Kevin’s online popularity has given him opportunities that have “truly changed his life”, including a permanent job. “I’m incredibly proud because I remember the nights I lay awake worrying about him, what his future will look like and worried sick about if the world would ever understand and accept him,” she said. “So now to see millions of people choosing to follow his journey and celebrate him is an answered prayer for me.”\n\nElsewhere on TikTok in the UK, “bus aunty” Bemi Orojuogun and the ornithologist Jack Baddams have proved popular.\n\n“When people have a niche and are passionate about it, it tends to blow up,” Smith says.\n\nIn the US, unlikely creator hits on TikTok include the seventysomething identical twins Wayne and Dwayne Haneline, who were a singing duo before serving in the Vietnam war and have returned to entertaining several decades later. Their unique take on AC/DC’s Back in Black has had nearly 80m views alone. Another popular US veteran is Asena Johnson, from Hawaii, who posts about post-army life and Samoan and Tongan culture.\n\nIn Europe, Nonna Silvi, an 84-year-old from Tuscany, has become a hit with posts from her son’s bakery. She now offers her own line of bakery products. Solange Fugger, another Italian creator, has won plaudits for her educational videos as the youngest head of the emergency department at a major hospital in Rome. She has 600,000 followers.\n\nMadolyn Grove, the head of creators at TikTok for the UK and Ireland, said the creativity of “everyday people” had captured the hearts of users this year.",
    "readingTime": 4,
    "keywords": [
      "social media",
      "online audiences",
      "uk and ireland",
      "tiktok",
      "content",
      "millions",
      "users",
      "everyday",
      "life",
      "posts"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/media/2025/dec/28/from-that-bird-guy-to-bus-aunty-the-real-social-media-personalities-rising-above-ai-slop",
    "thumbnail_url": "https://i.guim.co.uk/img/media/dfe0af7af6a37605c773e1c61cafc9d0a0c11546/649_64_1271_1016/master/1271.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=92bc3a9f160e8f00bdb72c8934c1a026",
    "created_at": "2025-12-28T18:16:49.112Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-insists-it-isnt-enron-but-its-ai-deals-are-testing-investor-faith",
    "title": "Nvidia insists it isn’t Enron, but its AI deals are testing investor faith",
    "description": "The chipmaker’s sprawling partnerships are driving extraordinary growth but also bank its future on the AI boom paying off quickly\nNvidia is, in crucial ways, nothing like Enron – the Houston energy giant that imploded through multibillion-dollar accounting fraud in 2001. Nor is it similar to companies such as Lucent or Worldcom that folded during the dotcom bubble.\nBut the fact that it needs to reiterate this to its investors is less than ideal.\n Continue reading...",
    "fullText": "The chipmaker’s sprawling partnerships are driving extraordinary growth but also bank its future on the AI boom paying off quickly\n\nNvidia is, in crucial ways, nothing like Enron – the Houston energy giant that imploded through multibillion-dollar accounting fraud in 2001. Nor is it similar to companies such as Lucent or Worldcom that folded during the dotcom bubble.\n\nBut the fact that it needs to reiterate this to its investors is less than ideal.\n\nNow worth more than $4tn (£3tn), Nvidia makes the specialised technology that powers the world’s AI surge: silicon chips and software packages that train and host systems such as ChatGPT. Its products fill datacentres from Norway to New Jersey.\n\nThis year has been an exceptional one for the company: it has struck at least $125bn in deals, ranging from a $5bn investment into Intel – to facilitate its access to the PC market – to $100bn invested in OpenAI, the startup behind ChatGPT.\n\nBut even as those deals have fuelled surging stock prices and paved the way for chief executive Jensen Huang’s energetic world tour, doubts have emerged about how Nvidia does business, especially as it has become increasingly central to the health of the global economy.\n\nThe start of these concerns has been the circular nature of many of its deals. These arrangements resemble vendor financing: Nvidia lending money to customers so they can buy its products.\n\nThe largest of these is its deal with OpenAI, which involves Nvidia investing $10bn into the company each year for the next 10 years – most of which will go to buying Nvidia’s chips. Another is its arrangement with CoreWeave, a company that provides on-demand computing capacity to big AI firms, essentially leasing out Nvidia’s chips.\n\nThe circularity of these deals has drawn comparisons with Lucent Technologies, a telecoms company that also aggressively lent money to its customers, only to overextend itself and unravel in the early 2000s. Nvidia has aggressively rebutted suggestions of any similarity, saying in a leaked recent memo that it “does not rely on vendor financing arrangements to grow revenue”.\n\nJames Anderson, a renowned tech investor, describes himself as a “huge admirer” of Nvidia, but said this year that the OpenAI deal presented “more reason to be concerned there than before”.\n\nHe added: “I have to say the words ‘vendor financing’ do not carry nice reflections to somebody of my age. It’s not quite like what many of the telecom suppliers were up to in 1999-2000, but it has certain rhymes to it. I don’t think it makes me feel entirely comfortable from that point of view.”\n\nOther high-profile recent deals include the tech firm Oracle spending $300bn on datacentres for OpenAI in the US – with the ChatGPT developer then paying back roughly the same amount to use those datacentres. In October, OpenAI and the chipmaker AMD signed a multibillion-dollar chip deal that also gave OpenAI the option to buy a stake in the Nvidia rival.\n\nThere is also a deal with CoreWeave where, along with a commitment to buying $22bn of data centre capacity from the cloud provider, OpenAI is receiving $350m in CoreWeave stock. Asked this month about circularity in the AI industry, the chief executive of CoreWeave, Michael Intrator, said: “Companies are trying to address a violent change in supply and demand. You do that by working together.”\n\nAll these moves form part of OpenAI’s $1.4tn bet on computing capacity to build and operate models that, it argues, will transform economies – and make back that expenditure. OpenAI argues that, while the Nvidia and AMD deals have an investment component, it only kicks in once the chips have been bought and deployed, while the investments themselves create aligned incentives to build out AI infrastructure at huge scale.\n\nNvidia has also used structures called special-purpose vehicles (SPVs) in financing deals. The best-known example is the SPV linked to Elon Musk’s xAI: an entity into which Nvidia invested $2bn, money that will be used to buy Nvidia’s chips.\n\nThis drew comparisons with Enron, which used SPVs to keep debts and toxic assets off its balance sheets, convincing investors and creditors that it was stable while concealing ballooning liabilities.\n\nNvidia has also strongly denied that it is like Enron: in the same leaked memo where it discussed Lucent, it said its reporting was “complete and transparent” and “unlike Enron” it “does not use special-purpose entities to hide debt and inflate revenue”.\n\nThe journalist Ed Zitron, a noted sceptic of the AI boom, agrees that Nvidia is not like either company. Unlike Lucent, it does not appear to be taking on a great deal of debt to finance its circular deals, he says, and most of the customers it is supporting are not as obviously risky as Lucent’s dotcom bubble partners. And it isn’t like Enron, Zitron argues, because it’s being fairly transparent about its own complex, off-balance sheet deals.\n\nSo what could warrant a comparison? Nvidia “is not hiding debt, but it is leaning heavily on vendor-financed demand, which creates exposure if AI growth slows,” says Charlie Dai, an analyst at the research firm Forrester. “The concern is about sustainability, not legality.”\n\nEssentially, whether Nvidia is able to stick the landing depends on whether AI really takes off, generating billions for its corporate users and putting companies such as OpenAI, Anthropic and CoreWeave – Nvidia’s customers – firmly in the black, and able to keep buying its systems. That possibility alone is debatable. If this does not happen, says Dai, Nvidia “could face write-downs on equity stakes and unpaid receivables”: meaning, it could lose a lot of money and its stock price could then tank.\n\nApproached for comment, an Nvidia spokesperson referred the Guardian to remarks its chief financial officer, Colette Kress, made to investors in early December. Kress said they were not seeing an AI bubble, instead gesturing at trillions of dollars of business that lie ahead for Nvidia in the next decade.\n\nIn particular, Kress argued that Nvidia’s recent – massive – deals are just the start for the company, and the real money will be made in the coming years, largely through replacing almost all the chips in existing datacentres with its products.\n\nThere is another complexity, which is that Nvidia’s health – and therefore the health of the entire global economy – also depends on whether AI takes off in time for Nvidia and its customers to service the debt from their huge datacentre buildouts and significant capital expenditures.\n\nAdd to this a final category of concern: recent, big-ticket deals with countries such as South Korea and Saudi Arabia, worth multiple billions of dollars, whose terms are opaque. In October, Nvidia said that it would supply 260,000 of its Blackwell chips to South Korea’s government and South Korean companies. The value of this deal was not disclosed, but is estimated to be in the billions.\n\nLikewise with Saudi Arabia. Its government-owned AI startup, Humain, has committed to deploying up to 600,000 Nvidia chips: when that deployment will involve actual purchases, and at what price, is again undisclosed. Nvidia has a number of other strategic partnerships like this – with Italy, with the French AI champion Mistral and with Deutsche Telekom, for example – all involving thousands of chips and unknown sums.\n\nGovernments are likely to pay. There’s nothing circular about a sovereign partnership with Germany. But the deals mean more – quite large – uncertainties nested within a straining web of commitments that require massive capital outlay, and rely on ambitious assumptions about the economy undergoing a revolution in the next years.\n\n“They concentrate risk in a few big customers,” says Dai. “If execution delays occur, Nvidia’s revenue recognition and cashflow could be affected.”",
    "readingTime": 7,
    "keywords": [
      "saudi arabia",
      "nvidia’s chips",
      "dotcom bubble",
      "chief executive",
      "computing capacity",
      "vendor financing",
      "deals",
      "nvidia",
      "customers",
      "deal"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/28/nvidia-insists-it-isnt-enron-but-its-ai-deals-are-testing-investor-faith",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c472d9082b2ab06e5fbe033cf0a81e9b54310e45/969_0_5816_4653/master/5816.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f0157578f8fb10a2c57754a592b9df51",
    "created_at": "2025-12-28T18:16:49.112Z",
    "topic": "tech"
  },
  {
    "slug": "politicians-are-slowly-but-surely-starting-to-try-out-ai-for-themselves",
    "title": "Politicians are slowly but surely starting to try out AI for themselves",
    "description": "\"I use it, despite the fact that I think it's going to destroy us,\" one Democratic senator told Business Insider.",
    "fullText": "As recently as June, Sen. Elizabeth Warren was one of several lawmakers who resisted using AI, owing to a skepticism of the technology's ability to deliver accurate information.\n\n\"Yeah, that's changed,\" the Massachusetts Democrat said with a laugh this month, explaining that she now finds ChatGPT to be \"really valuable\" for basic research questions, even if she still catches the occasional hallucination.\n\nWarren said that she began using ChatGPT more after seeing her daughter use it. She says she doesn't \"rely\" on the technology, but uses it to \"start to approach a problem.\"\n\n\"Like, I'm in the middle of reading something, and I think: How many people are there in Mississippi? And what's the breakdown of little children, and people over 65?\" Warren said. \"I pop that into ChatGPT and get an answer that's better than a straight Google answer. I can get more detail, and more ways to slice and dice the numbers.\"\n\nOther skeptics are tiptoeing their way into using the technology, including some who are otherwise major critics of the AI industry.\n\n\"The other day, I decided, you know what, maybe after doing all these hearings on ChatGPT, I should at least see how it works,\" Republican Sen. Josh Hawley of Missouri told Business Insider, saying he asked a \"very nerdy historical question\" to ChatGPT about the Puritans in the 1630s. \"I will say that it returned a lot of good information.\"\n\n\"I use it, despite the fact that I think it's going to destroy us,\" Democratic Sen. Chris Murphy of Connecticut told Business Insider.\n\nAt the highest levels of the American government, personal AI adoption remains spotty. White House Press Secretary Karoline Leavitt told reporters in November that she doesn't think President Donald Trump uses the technology himself.\n\n\"I've never witnessed it,\" she said. \"So I can't attest to that.\"\n\nVice President JD Vance, meanwhile, declared himself a \"Grok guy\" in an interview with Fox News's Sean Hannity in November.\n\n\"I think it's the best,\" Vance said of the Elon Musk-owned AI chatbot. \"It's also the least woke.\"\n\nBut House Speaker Mike Johnson said that he hasn't used AI himself, saying on the Katie Miller podcast that he simply hasn't had the \"luxury of time\" to get into it.\n\n\"I just haven't gotten into it yet. My life is not normal right now, okay?\" Johnson said. \"And AI has really been — it's become in popular use really during the term of my speakerhip, for the last two years. And so I just haven't had time to engage.\"\n\nAs lawmakers have begun working more with AI, some have had strange experiences. Democratic Rep. Jared Huffman of California told Business Insider that at one point, he tried to use Microsoft Copilot to look up what was inscribed on the bullet casings of Charlie Kirk's alleged murder suspect.\n\nInstead, Huffman says he ended up in an argument, and that Copilot insisted that Kirk was still alive despite the congressman prompting the AI with information to the contrary.\n\n\"It continued to fight with me, insisting that the whole assassination was a conspiracy theory,\" Huffman said. \"It was freaking weird.\"\n\nMost lawmakers who spoke with Business Insider said that they use ChatGPT.\n\nBut at least one — Democratic Rep. Don Beyer of Virginia — said he preferred to use Anthropic's Claude, owing to the company's focus on safety and ethics in AI.\n\n\"I was very impressed with the fact that they actually put together their own Constitution on the ethical use,\" Beyer said. \"They seem to be — at least they're positioned as — more enlightened.\"",
    "readingTime": 3,
    "keywords": [
      "democratic rep",
      "business insider",
      "it's",
      "lawmakers",
      "technology",
      "owing",
      "that's",
      "doesn't",
      "saying",
      "despite"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/lawmakers-use-ai-chatgpt-grok-claude-themselves-2025-12",
    "thumbnail_url": "https://i.insider.com/69388c1904d0f0a114f1b3f0?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.658Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-4-people-how-to-break-into-ai-from-a-microsoft-pm-to-a-meta-senior-director-they-shared-the-same-simple-piece",
    "title": "I asked 4 people how to break into AI, from a Microsoft PM to a Meta senior director. They shared the same, simple piece of advice.",
    "description": "Four tech professionals, from an early career engineer to a former senior director of GenAI at Meta, said getting your hands dirty was important for breaking into the AI industry.",
    "fullText": "As the AI revolution continues to disrupt white collar jobs, many of us are looking for ways to get ahead.\n\nAs part of my first-person coverage for Business Insider in 2025, I asked people with aspirational jobs their formulas for success — including how tech workers in various stages of their careers landed cutting-edge AI jobs.\n\nThese conversations covered a variety of topics, from whether you need a Ph.D. to break into the field to how to earn big as an AI contractor.\n\nBut one remarkably simple piece of advice kept coming up: gain real-world experience with AI technology to help get your foot in the door.\n\nThey didn't view AI as something that can be mastered from a textbook or in a lecture hall. Instead, play around with AI, like an infant tinkering with a new toy, or \"get your hands dirty,\" to borrow a phrase from a couple of the techies I interviewed.\n\nBut what does that look like in practice? Here's how they applied this principle in their own careers.\n\nWhen Patrick Leung, who joined Google in 2007, first saw a demo for a calling assistant that used AI, which would later be called Google Duplex, he was blown away by how realistic the voice sounded.\n\nLeung joined the Duplex team in 2017. Although he'd been exposed to machine learning and AI concepts during previous company projects, he'd never worked on building models and had to retool himself on the job.\n\nLeveraging the expertise around him, including by having lengthy conversations with colleagues who explained how the system worked, helped him become proficient in AI.\n\nLeung witnessed Google Duplex's public launch in 2018, before leaving Google in 2019 to join a financial sciences company. He's continued to work with AI in the later stages of his career.\n\nAt the time of his interview with Business Insider, Leung said the barrier to getting into AI was lower than ever, and encouraged people to apply LLMs to real business problems. For instance, a friend with no coding experience used AI to personalize outreach messages for recruitment purposes at her job and improved her response rate.\n\nIf there aren't opportunities to do something like this in your current job, use AI in your spare time and put it on your résumé, Leung said, adding that people who can demonstrate they can wield LLMs effectively are going to find jobs.\n\nSophia Sun essentially put Leung's advice into action when she pitched a project that would use AI to help customers at Kajabi, the creator commerce platform she worked for as a senior product manager.\n\nThe tool Sun envisioned would help content creators generate marketing content, such as blog posts and short-form videos, for TikTok and Instagram.\n\nShe started working on the project in April 2023, alongside engineering and marketing teammates. Seeing it through to its March 2024 launch was a learning curve for Sun, who had never built an AI product before.\n\nThat July, Sun started a new job at Microsoft as a senior AI product manager, and told Business Insider she thought her end-to-end experience with building an AI product helped her land the role.\n\nSun's playbook for breaking into AI was to find a real user problem, design a lightweight AI solution, and turn it into proof of work. Having good grades is one thing, she said, but building a product that demonstrates your abilities is another, she said.\n\nWhen OpenAI released ChatGPT in 2022, Mostofa Adib Shakib knew the world was going to change.\n\nHe started his career in traditional software engineering at Snap Inc. and then ZipRecruiter, but became convinced he needed to build AI skills.\n\nShakib spent time learning about AI from books, videos, and research papers, and he built software projects to gain proficiency with agentic AI, such as a tool to help Bangladeshi professionals optimize their résumés.\n\nIn February 2025, he started an AI contractor role with Mercor, which, around the time of his interview with Business Insider, earned him a handsome sum of $6,400 a week.\n\nShakib decided not to go back to a full-time traditional software engineering job. He said he thought focusing on building AI skills before the market gets crowded was the right bet for him.\n\nWhile being a full-time employee at a company offers stability and benefits, it would restrict his time, meaning he could only focus on gaining agentic AI skills on weekends, he said. As a full-time AI contractor, he can spread out his hours as he pleases, he added.\n\nShakib advised people interested in staying relevant in the tech industry to embrace change, rather than fear it, and to focus on upskilling.\n\nAlthough Devi Parikh completed a Ph.D. in computer vision in 2009, before going on to become a senior director of GenAI at Meta years later, she said not to assume you need a Ph.D. to break into AI.\n\nAs the cofounder and co-CEO of the AI company Yutori, she doesn't consider Ph.D.s much when hiring, but looks for people with relevant practical experience, such as training models, she said.\n\nOther potential avenues into interesting AI work include spending time at startups or big labs, or trying side projects that make use of open source code and online communities.\n\nStarting and executing projects has been instrumental to her career success, Parikh said. For instance, during the COVID-19 pandemic, she started working on a YouTube series called \"Humans of AI,\" where she interviewed AI researchers about their daily habits. This gave her more professional visibility than her research alone could.\n\nDo you have a story to share about breaking into AI? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "traditional software",
      "software engineering",
      "product manager",
      "business insider",
      "jobs",
      "experience",
      "projects",
      "ph.d",
      "contractor",
      "later"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-workers-simple-tip-for-breaking-into-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/6942d1e8832e0ef1ead660b1?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.585Z",
    "topic": "finance"
  },
  {
    "slug": "these-11-retail-startups-raised-millions-from-vcs-this-year-from-gopuff-to-stickerbox",
    "title": "These 11 retail startups raised millions from VCs this year, from Gopuff to Stickerbox",
    "description": "Top retail startups raised over $390 million in 2025 as Gopuff, Stickerbox, and Koala Health innovated in AI, e-commerce, and pet health.",
    "fullText": "Gopuff is a service that delivers convenience-store items, such as snacks, household essentials, alcohol, and more, to customers. Yakir Gola and Rafael Ilishayev cofounded the company in 2013 while they were students at Drexel University.\n\nIn November, Gopuff said it raised $250 million in a funding round led by Eldridge Industries and Valor Equity Partners. The company said the new capital would help it invest in AI, consumer experience, and infrastructure expansions.\n\n\"The team has built meaningful momentum across the business. We're back on offense, and we're just getting started. The future is bright as we keep raising the bar for our customers,\" Gola said in a November statement.\n\nFanBasis is a platform that enables influencers, celebrities, athletes, and others to monetize their fan base. Users can buy personalized experiences from celebrities, for example.\n\nThe company said in May that it raised $20 million in a Series A funding round led by Left Lane Capital and including influencers like Ryan Serhant and The Sidemen.\n\n\"While we're operating profitably, we may explore a Series B next year to further scale the platform and solidify FanBasis as the leading marketplace for digital products and services,\" CEO Yash Daftary said in a statement.\n\nKoala is a pet health company offering an online pharmacy for pet owners and an integrated prescription platform for veterinary partners. Gavin Cotter founded the company in 2021. It said in May that it closed a $20 million Series B funding round.\n\n\"This funding allows Koala to continue investing in the technology and service infrastructure required to support modern pet health,\" Cotter told Business Insider.\n\nStickerbox makes voice-controlled printers that use generative AI to create and print stickers based on user commands. It raised $7 million in a seed round with investors like Serena Ventures, Maveron, and AI2.\n\nStickerbox was launched by Hapiko, a Brooklyn-based company that creates children's technology toys, which is run by CEO Arun Gupta.\n\n\"We sold through our entire 2025 inventory in under two weeks, saw early units resell for nearly three times the retail price, and printed thousands of stickers within the first days of use — all clear indicators of the unmet demand for creativity tools that prioritize imagination over screen time,\" cofounders Gupta and Bob Whitney told Business Insider.\n\nKidsy is an online marketplace for discounted children's products, including new-in-box, open-box, and gently used items. It was founded by Shraysi Tandon and raised $4.5 million in a 2025 seed round led by 11 Tribes Ventures, she told Business Insider.\n\n\"I am in fundraising mode all of the time, which means I'm always keeping my relationships really warm,\" Tandon said. \"I'm already speaking to all of the Series A investors I'd like to work with and have been building those relationships for almost a year.\n\nUnion Chill Cannabis Company is a New Jersey-based cannabis retail platform that raised $4.2 million in 2025, according to PitchBook. It was founded by former CEO Laurie McHugh, who died in 2023.\n\n\"Tragically, our original founder, Laurie McHugh, passed away suddenly a few months after we opened,\" Matthew Borish, vice president of marketing, told Business Insider. \"We're working hard to continue growing and making her vision and focus on community, integrity, social responsibility, and economic success a reality.\"\n\nAGCF, founded by Alexandra Gucci Zarini, launched in early 2024 with its first flagship boutique in Beverly Hills, California. The luxury brand sells handbags, jewelry, and other accessories. It raised $3.5 million in early-stage VC in February with four investors, according to PitchBook.\n\nMiniswap Technologies is a marketplace for complex hobbies, made for Warhammer collectors to buy and sell miniatures. It was founded in 2025 by college roommates and Cambridge University alums Will Hanna and Zak Singh, according to PitchBook.\n\nThe company, which was part of Y Combinator's Fall 2025 cohort, raised $3.5 million in an early-stage funding round led by Funder's Club with participation from Spot VC and Pioneer Fund, Hanna told Business Insider.\n\nKM Tools, founded by Jonathan Katz-Moses in 2015, manufactures and sells woodworking tools online. It raised $2 million in a later-stage VC round in 2025, according to PitchBook.\n\n\"This year, we approached venture fundraising with the same discipline we apply to product development: clarity, proof, and momentum\" Katz-Moses told Business Insider.\n\n\"We prioritized partners who understood manufacturing, consumer products, and creator-led brands, and who could add strategic value beyond capital,\" he added.\n\nSecondsense is an online platform that compares the prices of pre-owned luxury bags across marketplaces. Chris Lucas founded the company in 2024, according to PitchBook.\n\nIn 2025, Secondsense raised $2 million in funding, the company confirmed to Business Insider.\n\nIt has partnerships with marketplaces like TheRealReal, and it got a shoutout from popular influencer Alix Earle, which caused demand to crash the website in April.\n\nMonte's Fine Foods is a neighborhood market offering Roman-style pizza and a variety of other food options. It raised $2 million in a seed round in 2025 with one investor, according to PitchBook.\n\nMonte's Fine Foods didn't respond to a request for comment.",
    "readingTime": 5,
    "keywords": [
      "monte's fine",
      "fine foods",
      "series funding",
      "pet health",
      "round led",
      "seed round",
      "founded",
      "platform",
      "online",
      "partners"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/retail-startups-raised-millions-in-2025-gopuff-stickerbox-2025-12",
    "thumbnail_url": "https://i.insider.com/6940321d04eda4732f2d8623?width=1200&format=jpeg",
    "created_at": "2025-12-28T12:21:18.569Z",
    "topic": "finance"
  },
  {
    "slug": "could-ai-relationships-actually-be-good-for-us",
    "title": "Could AI relationships actually be good for us?",
    "description": "From companionship to psychotherapy, technology could meet unmet needs – but it needs to be handled responsibly\nThere is much anxiety these days about the dangers of human-AI relationships. Reports of suicide and self-harm attributable to interactions with chatbots have understandably made headlines. The phrase “AI psychosis” has been used to describe the plight of people experiencing delusions, paranoia or dissociation after talking to large language models (LLMs). Our collective anxiety has been compounded by studies showing that young people are increasingly embracing the idea of AI relationships; half of teens chat with an AI companion at least a few times a month, with one in three finding conversations with AI “to be as satisfying or more satisfying than those with real‑life friends”.\nBut we need to pump the brakes on the panic.",
    "fullText": "From companionship to psychotherapy, technology could meet unmet needs – but it needs to be handled responsibly\n\nThere is much anxiety these days about the dangers of human-AI relationships. Reports of suicide and self-harm attributable to interactions with chatbots have understandably made headlines. The phrase “AI psychosis” has been used to describe the plight of people experiencing delusions, paranoia or dissociation after talking to large language models (LLMs). Our collective anxiety has been compounded by studies showing that young people are increasingly embracing the idea of AI relationships; half of teens chat with an AI companion at least a few times a month, with one in three finding conversations with AI “to be as satisfying or more satisfying than those with real‑life friends”.\n\nBut we need to pump the brakes on the panic. The dangers are real, but so too are the potential benefits. In fact, there’s an argument to be made that – depending on what future scientific research reveals – AI relationships could actually be a boon for humanity.\n\nConsider how ubiquitous nonhuman relationships have always been for our species. We have a long history of engaging in healthy interactions with nonhumans, whether they be pets, stuffed animals or beloved objects or machines – think of the person in your life who is fully obsessed with their car, to the point of naming it. In the case of pets, these are real relationships insofar as our cats and dogs understand that they are in a relationship with us. But the one‑sided, parasocial relationships we have with stuffed animals or cars happen without those things knowing that we exist. Only in the rarest of cases do these relationships devolve into something pathological. Parasociality is, for the most part, normal and healthy.\n\nAnd yet, there is something unsettling about AI  relationships. Because they are fluent language users, LLMs generate the uncanny feeling that they have human-like thoughts, feelings and intentions. They also generate sycophantic responses that reinforce our points of view, rarely challenging our thinking. This combination can easily lead people down a path of delusion. This is not something that happens when we interact with cats, dogs or inanimate objects. But the question remains: even in cases where people are unable to see through the illusion that AIs are real people that actually care about us, is that always a problem?\n\nConsider loneliness: one in six people on this planet experience it, and it’s associated with a 26% increase in premature death; the equivalent to smoking 15 cigarettes a day. Research is emerging that suggests AI companions are effective at reducing feelings of loneliness – and not just by functioning as a form of distraction, but as a result of the parasocial relationship itself. For many people, an AI chatbot is the only friendship option available to them, however hollow it might seem. As the journalist Sangita Lal recently explained in a report on those turning to AI for companionship, we should not be so quick to judge. “If you don’t understand why subscribers want and seek and need this connection,” said Lal, “you’re lucky enough to not have experienced loneliness.”\n\nTo be fair, there is an argument to be made that the rise of new tech and social media has itself played a role in driving the loneliness epidemic. That’s why Mark Zuckerberg got flak for his glowing endorsement of AI as a solution to a problem he might be partly responsible for creating. But if the reality is that it helps, this cannot be dismissed out of hand.\n\nThere’s also research to show that AI can be used as an effective psychotherapy tool. In one study, patients who chatted with an AI-powered therapy chatbot showed a 30% reduction in anxiety symptoms. Not as effective as human therapists, who generated a 45% reduction, but still better than nothing. This utilitarian argument is worth considering; there are millions of people who are, for whatever reason, unable to access a therapist. And in those cases, turning to an AI is probably preferable to not seeking any help at all.\n\nBut one study isn’t proof of anything. And there’s the rub. We are at the early stages of research into the potential benefits or harms of AI companionship. It’s easy to focus on the handful of studies that support our preconceived notions about the dangers or benefits of this technology.\n\nIt’s in this research vacuum that the true dangers of AI are revealed. Most of the entities deploying AI companions are for-profit companies. And if there’s one thing we know about for-profit companies, it’s that they are keen to avoid regulations and eschew evidence that could hurt their bottom line. They are incentivised to downplay risks, cherrypick evidence and tout only benefits.\n\nThe emergence of AI is not unlike the discovery of the analgesic properties of opium; if harnessed by responsible parties with the goal of relieving pain and suffering, both AI and opioids can be a legitimate tool for healing. But if bad actors exploit their addictive properties to enrich themselves, the result is either dependency or death.\n\nI remain hopeful that there is a place for AI companionship. But only if it’s backed by robust science, and deployed by organisations that exist for the public good. AIs must avoid the sycophancy problem that leads vulnerable people to delusion. This can only be achieved if they are explicitly trained to do so, even if it makes them less attractive as a potential companion; a notion that is anathema to companies that want you to pay a monthly subscription, without which you lose access to your “friend”. They must also be designed to help the user develop the social skills they need to engage with actual humans in the real world.\n\nThe ultimate goal of AI companions should be to make themselves obsolete. No matter how useful they might be in plugging the gaps in therapy access or alleviating loneliness, it will always be better to talk to a real human.\n\nJustin Gregg is a biologist and author of Humanish (Oneworld).\n\nCode Dependent: Living in the Shadow of AI by Madhumita Murgia (Picador, £20)\n\nThe Coming Wave: AI, Power and Our Future by Mustafa Suleyman (Vintage, £10.99)\n\nSupremacy: AI, ChatGPT and the Race That Will Change the World by Parmy Olson (Macmillan, £10.99)",
    "readingTime": 6,
    "keywords": [
      "stuffed animals",
      "potential benefits",
      "relationships",
      "research",
      "loneliness",
      "it’s",
      "companionship",
      "dangers",
      "there’s",
      "anxiety"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/books/2025/dec/28/could-ai-relationships-actually-be-good-for-us",
    "thumbnail_url": "https://i.guim.co.uk/img/media/46f0032296fe9321c14aa2981f85dba066ef06aa/197_2_1765_1413/master/1765.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=116c71a9a76de573bc0050bf1cede489",
    "created_at": "2025-12-28T12:21:17.937Z",
    "topic": "tech"
  },
  {
    "slug": "langfuse-yc-w23-is-hiring-in-berlin-germany",
    "title": "Langfuse (YC W23) Is Hiring in Berlin, Germany",
    "description": "Join the Langfuse team to build the leading open-source LLM engineering platform",
    "fullText": "Join the team building the leading open-source LLM engineering platform\n\nWhile LLMs improve a lot, we don’t see enough applications in production. Building these applications requires a new workflow of continuous monitoring and evaluation that we enable with Langfuse (learn more about our mission).\n\nWe are seeing strong traction (see metrics below), thus it is the right time to grow the team to build out our backend systems, product, and how we communicate with developers.\n\nWe are backed by Lightspeed, General Catalyst, Y Combinator, and angels. We are growing fast (see metrics below) and work with some of the best AI teams such as Samsara, Twilio, Khan Academy, and Rocket Money.\n\nIf complex technical problems & great developer experiences excite you, we’d love to hear from you.\n\n– Marc, Clemens, Max and the Langfuse team\n\nIf you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!\n\nWe publicly document our core principles and processes at Langfuse to align as a team, maintain transparency with our community, and help you determine if you’d enjoy working here.\n\nThe handbook contains many more resources that define how we do things. These might be interesting to you:\n\nAlmost everything we do is public. Get a glimpse of our work here:\n\nIf you prefer watching videos or listening to podcasts to get an impression, here are some suggestions:\n\nLangfuse is the most widely adopted LLM Engineering platform with 19,719 GitHub stars, 23.1M+ SDK installs per month, and 6M+ Docker pulls. Trusted by 19 of the Fortune 50 and 63 of the Fortune 500 companies.\n\nIf you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!",
    "readingTime": 2,
    "keywords": [
      "engineering platform",
      "delivering exceptional",
      "insanely motivated",
      "exceptional open-source",
      "experiences alongside",
      "developer experiences",
      "motivated team",
      "langfuse",
      "applications",
      "metrics"
    ],
    "qualityScore": 0.85,
    "link": "https://langfuse.com/careers",
    "thumbnail_url": "https://langfuse.com/api/og?title=Careers&description=Join%20the%20Langfuse%20team%20to%20build%20the%20leading%20open-source%20LLM%20engineering%20platform&section=",
    "created_at": "2025-12-28T12:21:17.105Z",
    "topic": "jobs"
  },
  {
    "slug": "sam-altman-is-hiring-someone-to-worry-about-the-dangers-of-ai",
    "title": "Sam Altman is hiring someone to worry about the dangers of AI",
    "description": "Sam Altman is hiring a Head of Preparedness at OpenAI to worry about the dangers of AI.",
    "fullText": "The Head of Preparedness will be responsible for issues around mental health, cybersecurity, and runaway AI.\n\nThe Head of Preparedness will be responsible for issues around mental health, cybersecurity, and runaway AI.\n\nOpenAI is hiring a Head of Preparedness. Or, in other words, someone whose primary job is to think about all the ways AI could go horribly, horribly wrong. In a post on X, Sam Altman announced the position by acknowledging that the rapid improvement of AI models poses “some real challenges.” The post goes on to specifically call out the potential impact on people’s mental health and the dangers of AI-powered cybersecurity weapons.\n\nThe job listing says the person in the role would be responsible for:\n\n“Tracking and preparing for frontier capabilities that create new risks of severe harm. You will be the directly responsible leader for building and coordinating capability evaluations, threat models, and mitigations that form a coherent, rigorous, and operationally scalable safety pipeline.”\n\nAltman also says that, looking forward, this person would be responsible for executing the company’s “preparedness framework,” securing AI models for the release of “biological capabilities,” and even setting guardrails for self-improving systems. He also states that it will be a “stressful job,” which seems like an understatement.\n\nIn the wake of several high-profile cases where chatbots were implicated in the suicide of teens, it seems a little late in the game to just now be having someone focus on the potential mental health dangers posed by these models. AI psychosis is a growing concern, as chatbots feed people’s delusions, encourage conspiracy theories, and help people hide their eating disorders.",
    "readingTime": 2,
    "keywords": [
      "mental health",
      "health cybersecurity",
      "responsible",
      "models",
      "runaway",
      "someone",
      "horribly",
      "potential",
      "people’s",
      "dangers"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theverge.com/news/850537/sam-altman-openai-head-of-preparedness",
    "thumbnail_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/DCD_1009.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200",
    "created_at": "2025-12-28T06:18:08.788Z",
    "topic": "tech"
  },
  {
    "slug": "a-guide-to-claude-code-20-and-getting-better-at-using-coding-agents",
    "title": "A Guide to Claude Code 2.0 and getting better at using coding agents",
    "description": "A deep dive into Claude Code 2.0 features, Opus 4.5 workflows, and context engineering. Learn sub-agents, MCP servers, hooks, skills, and practical tips to boost your AI-assisted coding productivity.",
    "fullText": "This post is a follow-up to my post from July'25 - My Experience With Claude Code After 2 Weeks of Adventures. If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.\n\nA short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like ! and using Shift + ? to show shortcuts, memory basics, /resume to restart conversation and short discussion on custom commands.\n\nI got a great response on my Opus 4.5 vibe-check tweets and still receieving good feedback on my July blog post (despite being somewhat poorly written). This shows there's clearly a demand for in-depth resources around Claude Code.\n\nI noticed that lots of people, both technical and many non-technical or less hands-on people i.e technically-lite people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.\n\nIf you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.\n\nI don't want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.\n\nClaude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.\n\nKarpathy sensei posted this which caused the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.\n\nIt's a reasonable crashout - the technology is evolving at a mindblowing pace and it's difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it's scary but also exciting time to build stuff at speeds never possible before.\n\nInstead of thinking in terms of \"keeping up\", a better framing is how can I improve myself with help of these tools i.e augment.\n\nIn my opinion, there are 3 components to augment yourself:\n\nStay updated with tooling - What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.\n\nUpskill in your domain - It's a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that's what differentiates professional devs from vibe-coders. Since implementation is much faster now, you can spend more time on taste refinement.\n\nFor software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Review code. Please don't forget to come back to my post lol but I liked Addy Osmani's take on this.\n\nThe idea is to let the LLM perform things with input, get output and see errors.\n\nAs an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.\n\nThis post will act as a guide for things Karpathy said but you'll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it's fun.\n\nI am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it's been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it's important to set the context here.\n\n2025 saw release of many frontier models by OpenAI and Anthropic. Also, it's super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.\n\nIt's been a wild year and honestly speaking I got tired of trying out new releases by OpenAI every 2 weeks.\n\n>no swe-bench-verified comparison\n>no comparison against opus 4.5\n>\"we are topping in cybersecurity\"\n>mfw i realise i am the fucking eval https://t.co/4oDG3yj6CP pic.twitter.com/aUfJfwROCf\n\nThere have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.\n\nThat said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed \n\n(Note: I am talking with respect to personal coding usage, not production API usage for applications).\n\nI was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -\n\nclaude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex\n\nAnthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.\n\nI was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.\n\nSonnet 4.5's problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.\n\nAround October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.\n\nchat please remind me to cancel after 28 days😂 pic.twitter.com/TSGidVJ2xo\n\nMy Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5. I used the hell out of it for my work and also wrote this highly technical blog with the help of it discovering several of its capabilities.\n\nI had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1's capabilities tbh.\n\nOther than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.\n\nAs I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.\n\nToday, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.\n\nI think first reason is it's faster and can do similar difficulty tasks in much lesser time than Codex. Also, it's overall\na much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.\n\nOne nice-use case shown here by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude's explanation abilities.\n\nTo further demonstrate the difference, here's a CC vs Codex comparison\n\nFor the same prompt, see the outputs. Codex tends towards super concise while Claude matches my expectation.\nYou can modify the verbosity in Claude's case but Codex won't budge. Another thing I want to highlight is\nthe UI itself - Claude has more saturated white color on black whereas Codex's text is thinner/less readable\nand the thinking traces are shown in even lighter shade which I don't like.\n\nBecause of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks\nmuch faster feedback loops for your tasks. This makes progress feel more visceral even though capability wise, GPT-5.1/Codex were at par even in November.\nThe only downside with faster loop is if you are cautious, you end up micro-managing for long hours.\n\nOpus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.\n\nBesides the model, obviously the Claude Code Product goes a long way to make things magical.\n\nAs a product it's a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this \n\nBefore we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn't sponsor random users like me. Anthropic doesn't even think about me (meme.jpeg) besides from a user point of view.\n\nBesides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it's led to good discourse on the timeline as well.\n\nAll this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.\n\nThat's enough yapping. In the next few sections, I will talk about useful features that I didn't talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.074.\n\ncurrently using Claude Code for the first time, I can officially put \"Technical-lite\" on my resume now\n\nI am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -\n\nMore specifically, context is the input tokens. The context window refers to the maximum amount of tokens that an LLM can see and process at once during a conversation. It's like the model's working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.\n\nTool calling - Learn about tool calling. Here's a good resource. You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That's where tools come in. Tools are functions (in code or skills) defined by the engineer that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which tool to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.\n\nAgent - The simplest definition is an LLM that can pro-actively run tools to achieve a goal. For a more sophisticated definition, I like the one by Anthropic\n\n\"Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\" from Building Effective Agents.\n\n\"Agentic\" - refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user's intent to perform the action, choosing the correct tool, knowing when to stop)\n\nHarness/scaffolding - Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of \"scaffolding\" / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that Claude Code is not a harness, it's a product (think the TUI, integrations etc.). Claude Code has a harness.\n\nClaude Code has had lots of AI features and quality of life improvements since July. Let's look at the ones that I found to be useful. You can see all changes in the Changelog.\n\nAsk mode options - Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - \"Type here to tell Claude what to do differently\". Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.\n\nUltrathink - I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes\n\nThinking toggle - Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there's a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your settings.json\n\nPrompt history search - Search through prompts using Ctrl + R (similar to terminal backsearch). I have it in 2.0.74. It can search across project wide conversations. Repeatedly do Ctrl + R to cycle through results.\n\nCursor cycling - When you reach beginning/end of prompt, press down/up to cycle around\n\nMessage queue navigation - It's possible to navigate through queued messages and image attachments (2.0.73) now (idk if it's possible to display image attachment as well).\n\nFuzzy file search - File suggestion is 3x faster and supports fuzzy search (2.0.72)\n\nLSP support was added recently. Access via plugins.\n\nThere have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won't cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).\n\nNext few sub-sections are all about most used features.\n\nI didn't cover commands properly in my previous blog post. You can use / to access the built-in slash commands. These are pre-defined prompts that perform a specific task.\n\nIf these don't cover a specific task you want, then you can create a custom command. When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.\n\nCommands can be made on a project level or global level. Project level resides at .claude/commands/ and global one at ~/.claude/commands.\n\nOften when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using /clear. Claude provides /compact which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a /handoff command for this.\n\nIf you find yourself writing a prompt for something repetitively and instructions can be static/precise, it's a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via claude-code-guide.md) and then it will make it for you.\n\nYou can find a bunch of commands, hooks, skills at awesome-claude-code though I recommend to build your own or search for one only when it's really required.\n\nI have a command called bootstrap-repo that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.\n\nAnyways, notice the \"Explore\" sub-agent and \"running in background\".\n\nSub-agents were introduced shortly after I published my last blogpost. Sub-agents are separate Claude instances that are spawned if the main agent wishes so or you explicitly tell it to do so. These powers are defined already in system prompt and sometimes you just have to remind... Understanding these features will help you micro-manage Claude haha.\n\nYou can also define your custom sub-agents. To create one:\n\nOr just use /agents to manage and create sub-agents automatically - recommended approach.\n\nThe \"Explore\" thing in above pic is a sub-agent. You can tell Claude \"Launch explore agent with Sonnet 4.5\" if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)\n\nThe Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.\n\nYou will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it's to make tool calling work accurately.\n\nThis is the Explore agent prompt from 2.0.56 and it should be similar now too. Reference. These are captured by intercepting requests. Reference video.\n\nIn case of Explore sub-agent, it starts with a fresh slate which makes sense. It does not inherit any context from main agent. Many tasks involve searching through large amounts of digital media or code to filter for something relevant. Often the individual parts are independent of each other when you want to filter for something so launching parallel agents makes sense.\n\nIf I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.\n\nIt's important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other. That's the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).\n\nCodex does not have a concept of sub-agents and it's probably a conscious decision by the devs. GPT-5.2 has a 400K context window\nand according to benchmarks, it's long context retrieval capabilities are a massive improvement. Although people have tried\nmaking Codex use headless claude as sub-agents haha. You can just do things.\n\nThe general-purpose and plan sub-agent (separate from plan mode) inherit the context. With respect to user defined sub-agents, I am not sure but I think they start with clean slate.\n\nFrom the reverse engineered resources/leaked system prompt, it's possible to see that the sub-agents are spawned via the Task tool.\n\nTurns out you can ask Claude too. (I think the developers are allowing this now?). It's not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.\n\nTry these set of prompts with Opus 4.5\n\nYou will get the output something like below (click) but to summarise -\nIt defines 5 agent types: general-purpose (full tool access, inherits context), Explore (fast read-only codebase search), Plan (software architect for implementation planning), claude-code-guide (documentation lookup), and statusline-setup. Notice how each sub-agent is defined with its specific use case and available tools. Also notice the \"When NOT to use\" section - this kind of negative guidance helps the model avoid unnecessary sub-agent spawning for simple tasks.\n\nI want you to focus on the tool schema. The Task tool prompt above is detailed guidance on how to use the tool that resides in the system prompt. The tool schema defines the tool or the function.\n\nThe main agent calls the Task tool to spawn a sub-agent, using its reasoning to decide the parameters. Notice the model parameter - when I say \"Use Explore with Sonnet\", the model makes the tool call with model: \"sonnet\".\n\nTill August'25 or so, Claude Code used to show the Task tool performing actions in the TUI but now TUI shows the sub-agent name instead.\n\nNotice the run_in_background parameter. It decides whether to send a sub-agent to run in the background. I like the background process feature - it is super helpful for debugging or just monitoring log outputs from process. Sometimes you have a long running python script that you wanna monitor etc.\n\nModel usually automatically decides to put a process in background but you can explicitly tell it to do so. Note that \"Background Tasks\" is different. Using an & sends a task to Claude Web (should have named it Claude Cloud haha). I am yet to get this to work properly.\n\nI have a pretty simplish/task based workflow: CC as the main driver, Codex for review and difficult tasks, and Cursor for reading code and manual edits. I rarely use Plan Mode. Instead, once requirements are clear enough, I explore the codebase to find the relevant files myself.\n\nOpus 4.5 is amazing at explaining stuff and makes stellar ASCII diagrams. The 2025 Aug knowledge cutoff helps here too. So my exploration involves asking lots of questions—clarifying requirements, understanding where/how/why to make changes. It might be less efficient than Plan Mode, but I like this approach.\n\nOnce I have enough context, I spam /ultrathink and ask it what changes are required and then if things look ok, I start the execution closely monitoring the changes - basically micro-managing it. I sometimes ask Codex's second opinion here lol.\n\nFor difficult new features, I sometimes use a \"throw-away first draft\" approach. Once I understand what changes are needed, I create a new branch and let Claude write the feature end-to-end while I observe. I then compare its output against my mental model as to how close did it get to my requirements? Where did it diverge? This process reveals Claude's errors and the decisions/biases it made based on the context it had. With the benefit of this hindsight, I run another iteration, this time with sharper prompts informed by what I learned from the first pass. Kinda like Tenet.\n\nFor backend-heavy or just complex features specifically, I'll sometimes ask Codex xhigh to generate the plan instead.\n\nI maintain a few custom commands, use CLAUDE.md and scratchpad extensively. No custom sub-agents. I use MCP sometimes if need shall arise (e.g for docs. I have tried Playwright and Figma MCP so far) but in general not a fan. I have used hooks for simple stuff in the past and need-basis. skills/plugins are something that I am yet to use more regularly. I often use background agents for\nobservability (monitoring log / error) purposes. I rarely use git worktrees.\n\nIt's worth noting that the harness is so heavily engineered that Claude knows which sub-agent to spawn, what command/tool call/skill to run, what to run in async manner. It's able to heavy carry the agent loop that your task is mainly to use your judgement and prompt it in right direction. The next generation of models will get better and the relevant scaffolding will reduce for existing feature and increase for newer features. (Re: contrasting to Karpathy sensei's latest tweet shown at beginning)\n\nIt's not at all required to know the features in depth to be honest. However knowing how things work can make you a better micro-manager if the need arises like telling the Explore agent to use Sonnet.\n\ngetting claude opus 4.5 changes reviewed by gpt-5.1-codex-max high pic.twitter.com/A4tYN3W3Q6\n\nFor reviewing code and finding bugs, I find GPT-5.2-Codex is superior. Just use /review. Better than code review products too.\n\nIt's able to find bugs and mention severity like P1, P2. It's less likely to report false-positives and more trustable when it comes to confusing changes as compared to Claude. This Claude for execution and GPT/o-series model for review/bugs dynamic has been pretty constant for me for probably a year.\n\nNow is a good time to take a breath and refresh your context window. Before we get to the next set of features, it's worth\ngoing through context management fundamentals. Things might get a bit difficult for the technically-lite folks.\nDon't give up. Read through the post. Even ask Claude to explain stuff you don't understand.\n\nAn agent in a harness can pro-actively do a lot of tool calls to read your codebase and other inputs, edit stuff, make writes etc. In this process, they can produce a lot of data which gets added to the running conversation i.e the context window. Anthropic refers to this art and science of curating what will go into the limited context window from this information as context engineering.\n\nYou may ask how are tool calls adding tokens to the context window? The flow works like this:\n\nThe key thing to note here is that both the tool call and the tool call outputs are added to the context so that the LLM can know the results. This is because LLMs are stateless. They don't have memory outside the context window. Let's say you have n messages in a conversation. When you send the next message, the request will again process n + 1 messages in the LLM ~ single context window.\n\nIf you don't add information about the chosen tool call was, LLM won't know and if you don't plug the output, then it won't know\nthe outcome. The tool call results can quickly fill your context and this is why agents can get super expensive too.\n\nI quote directly from effective-context-engineering-for-ai-agents\n\nContext refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context — in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\n\nContext engineering is about answering \"what configuration of context is most likely to generate our model's desired behavior?\"\n\nEverything we have discussed so far comes under context engineering. Sub-agents, using a scratch, compaction are obvious examples\nof context management methods used in Claude Code. Some notes around why context engineering is needed -\n\nLimited context window - The context retrieval performance of LLMs degrades as every new token is introduced. To paraphrase the above blog - think of context as a limited \"attention budget\". This is a consequence of the attention mechanism itself as it gets harder to model the pairwise relationships - think of it like getting harder to focus on things far apart.\n\nGPT-5.2 has a context window of 400K input tokens. Opus 4.5 has 200K. Gemini 3 Pro has a 1M context window length. Now the effectiveness of these context windows can vary too, just the length doesn't matter. That said if you want to ask something\nfrom a 900K long input, you would be able to most reliably do that only with Gemini 3 Pro.\n\nContext rot article goes deep into some experiments which showed performance\ndrops with length and not task difficulty.\n\nA rough corollary one can draw is effective context windows are probably 50-60% or even lesser.\nDon't start a complicated task when you are half-way in the conversation. Do compaction or start a new one.\n\nEverything being done in prompts and code we have seen so far has been to -\n\nThe next few sections showcase features and implementation that are designed for\nbetter context management and agentic performance.\n\nI am personally not a fan of MCP servers but we gotta cover it. MCP servers are servers that can be hosted on your machine or remotely on the internet. These may expose filesystem, tools and integrations like CRM, Google Drive etc. They are essentially a way for models to connect to external tools and services.\n\nIn order to connect to MCP server, you need a host (Claude) which can house the MCP client. The MCP client\ncan invoke the protocol to connect. Once connected, the MCP client exposes tools, resources, prompts provided by server.\n\nThe tool definitions are loaded upfront into the context window of host bloating the context window.\n\nI like the idea of Code Execution with MCP even though it's propanda for more token consumption.\n\nQuoting Code execution with MCP:\n\nAs MCP usage scales, there are two common patterns that can increase agent cost and latency:\n\nMCP usage scale implies more MCP clients ~ more tool call definitions in context window.\n\nMCP Code exec suggests instead of direct tool calls, expose code APIs rather than tool call definitions and give Claude\na sandbox execution environment with a filesystem. Then let it write code to make the tool calls.\nIt is an elegant idea and is pretty similar to skills in the sense it's \"prompt on demand\"\n\nQuoting from Manus's Context Engineering Lesson blog:\n\nManipulate Attention Through Recitation\n\nIf you've worked with Manus, you've probably noticed something curious: when handling complex tasks, it tends to create a todo.md file—and update it step-by-step as the task progresses, checking off completed items.\n\nThat's not just cute behavior—it's a deliberate mechanism to manipulate attention.\n\nA typical task in Manus requires around 50 tool calls on average. That's a long loop—and since Manus relies on LLMs for decision-making, it's vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.\n\nClaude Code has todo lists but they don't show them now. Now you know part of the logic for it.\n\nClaude Code also tries something similar via plugging reminder tags into user messages and tool results. Some of them are mentioned in tool descriptions, other reminders are added at runtime via code.\n\nI asked Claude about what system reminders are present in the system prompt.\n\nFor reference, an older version of CC 2.0.56 used to have this detailed reminder system-reminder-plan-mode-is-active.\n\nI think Armin talks about this in his post What Actually Is Claude Code’s Plan Mode? when he refers to recurring prompts to remind the agent.\n\nIf you look at the leaked prompts, you will notice there are like 2-3 prompts for plan mode and 2-3 tool schemas like ENTRY_PLAN_MODE_TOOL, EXIT_PLAN_MODE_TOOL. The latter would write down the output into a markdown file\nwhich you can access via /plan. Everything is a markdown.\n\nAnthropic introduced Agent Skills recently and these got recently adopted by Codex too. A skill\nis a folder containing a SKILL.md file, other referenceable files and code scripts that do some user-defined task.\n\nThe SKILL.md contains some meta-data via which LLM can know what skills are available (meta-data is added to system prompt)\nIf Claude feels the skill is relevant, it will perform a tool call to read the contents of skill and download the\ndomain expertise just like Neo in Matrix 1999. The code scripts may contain tools that Claude can use.\n\nNormally, to teach domain expertise, you would need to write all that info in system prompt and probably\neven tool call definitions. With skills, you don't have to do that as the model loads it on-demand.\nThis is especially useful when you are not sure if you require those instructions always.\n\nThe popular frontend-design plugin is actually a skill. You can check here\n\nHooks are available in Claude Code and Cursor. They allow you to observe when a certain stage in the agent loop\nlifecycle starts or ends and let you run bash scripts before or after to make changes to the agent loop.\n\nThere are hooks like Stop, UserPromptSubmit etc. For instance Stop hook runs after Claude finishes responding and the UserPromptSubmit hook runs when user submits a prompt before Claude processes it.\n\nThe first hook I created was to play an anime notification sound when Claude stopped responding. I was obviously inspired\n\nOne funny use case to run Claude for hours might be running a \"Do more\" prompt when Claude finishes current task\nvia the Stop hook.\n\nI came across this post during my research for this blog post. This person beautifully combined the concepts and features we discussed so far. They combine hooks to act as reminders for skills. If the utility/requirement arises, there's a lot of space for customization. You might not need such heavy customization but can at least take inspiration. (Speaking for myself lol)\n\nAnthropic recommends to keep skill.md under 500 lines so they divided it into separate files and combined with hooks and\nreduced the size of their CLAUDE.md.\n\nHopefully you learnt a bunch of things from this super long post and will apply the learnings not only in CC\nbut other tools as well. I feel a bit weird writing this but we are going through some transformative times.\nThere are already moments when I almost feel like a background agent and then other times when I feel smart when the models couldn't solve a particular bug.\n\nclaude and codex to me when i realise i am the background agent pic.twitter.com/wkihYFQmQM\n\nI no longer look forward to new releases because they just keep happening anyways (shoutout to OpenAI). Deepseek and Kimi K3 are in the queue.\n\nI am expecting improvements in RL training, long context effectiveness via maybe new attention architectures, higher throughput models, lesser hallucination models.\nThere might be a o1/o3 level reasoning breakthrough or maybe something in continual learning in 2026. I look forward to these but at the same time\nI find it scary because more significant capability unlock will make the world unpredictable haha.\n\nIf you found this useful, try one new feature from this post today. Happy building!\n\nThanks for reading. Please like/share/RT the post if you liked it.",
    "readingTime": 30,
    "keywords": [
      "claude code",
      "karpathy sensei",
      "stop hook",
      "mcp client",
      "anthropic doesn't",
      "mcp servers",
      "feedback loops",
      "spam ultrathink",
      "monitoring log",
      "domain expertise"
    ],
    "qualityScore": 1,
    "link": "https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/",
    "thumbnail_url": "https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/dario-2.webp",
    "created_at": "2025-12-28T01:03:19.149Z",
    "topic": "tech"
  },
  {
    "slug": "marissa-mayers-new-startup-dazzle-raises-8m",
    "title": "Marissa Mayer's new startup Dazzle raises $8M",
    "description": "Mayer launched Dazzle after shuttering her photo and contact management startup Sunshine. Green’s investment suggests Dazzle is poised for the coming wave of new AI-infused consumer businesses.",
    "fullText": "The former Yahoo CEO, Marissa Mayer, refuses to sit on the sidelines of the generative AI revolution.\n\nAfter spending the last six years running Sunshine, a photo-sharing and contact-management startup with little success, the storied tech leader has shuttered the company to launch Dazzle, a new startup focused on building the next generation of AI personal assistants.\n\nWhile Mayer is not yet sharing specifics about Dazzle’s functionality, she has revealed that the new company has raised an $8 million seed round at a $35 million valuation. The round was led by Forerunner’s Kirsten Green, with participation from Kleiner Perkins, Greycroft, Offline Ventures, Slow Ventures, and Bling Capital. Although Mayer has admitted to investing her own capital in the startup, she emphasized that the round was led by Green, a venture capitalist with a storied record of identifying iconic consumer brands such as Warby Parker, Chime, and Dollar Shave Club.\n\nGreen’s investment suggests Dazzle is poised for the coming wave of new AI-infused consumer businesses. The founder of Forerunner Ventures previously told TechCrunch that while enterprise AI took the early lead in this tech cycle, consumer-facing AI is a “late bloomer” that’s finally ready for its breakout.\n\nEven for a founder of Mayer’s fame, landing Green as a lead investor is a significant stamp of credibility for Dazzle, especially after Sunshine was widely considered to be a flop. “I think she really has a great sense for where people and platforms are going,” Mayer said.\n\nMayer told TechCrunch that the Sunshine team began prototyping Dazzle last summer, a project that quickly eclipsed their previous work in ambition and opportunity. “We realized that this was something that we were much more excited about,” she said, noting that Dazzle has potential for “a much bigger impact” than what Sunshine was building.\n\nOriginally founded as Lumi Labs in 2018, Sunshine first launched with a subscription app for contact management dubbed “Sunshine Contacts.” Despite its founder’s high profile, the product struggled to gain traction. Privacy advocates raised alarms over the app’s practice of pulling home addresses from public databases to enrich contact lists, and the company never recovered from the initial skepticism. By 2024, the company broadened its offering by adding event management and “Shine,” an AI-powered photo-sharing tool. The new offering was widely criticized for its outdated design and similarly failed to attract widespread usage.\n\nSunshine raised a total of $20 million from investors, including Felicis, Norwest Venture Partners, and Unusual Ventures. When the company was dissolved, investors received 10% of Dazzle’s equity, Mayer said.\n\nReflecting on Sunshine’s struggle, Mayer was candid about its limitations, admitting the problems the company was tackling were too “mundane” and not large enough. “I don’t think we got it to the state of overall polish and accessibility that I really wanted it to be,” she added.\n\nMayer is now betting that the lessons from Sunshine will help her build a much more resilient and impactful business with Dazzle.\n\nBefore her tenure as Yahoo CEO, Mayer was employee number 20 at Google, where she helped design Google search ‘look and feel’, and oversaw the development of Google Maps and AdWords.\n\n“I have had the rare privilege of being at two companies that really changed how people do things,” Mayer told TechCrunch. “Yahoo, for many, defined the internet. Google, in terms of Search and Maps, changed everything. I really aspire to build a product that has that kind of impact again.”\n\nDazzle is expected to come out of stealth mode early next year.",
    "readingTime": 3,
    "keywords": [
      "yahoo ceo",
      "mayer",
      "startup",
      "round",
      "sunshine",
      "dazzle",
      "photo-sharing",
      "storied",
      "dazzle’s",
      "capital"
    ],
    "qualityScore": 1,
    "link": "https://techcrunch.com/2025/12/23/marissa-mayers-new-startup-dazzle-raises-8m-led-by-forerunners-kirsten-green/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/03/GettyImages-1172241499.jpg?resize=1200,728",
    "created_at": "2025-12-28T01:03:18.794Z",
    "topic": "tech"
  },
  {
    "slug": "ai-data-centers-may-soon-be-powered-by-retired-navy-nuclear-reactors",
    "title": "AI data centers may soon be powered by retired Navy nuclear reactors",
    "description": "This is a much cheaper and faster way to get nuclear power.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.tomshardware.com/tech-industry/startup-proposes-using-retired-navy-nuclear-reactors-from-aircraft-carriers-and-submarines-for-ai-data-centers-firm-asks-u-s-doe-for-a-loan-guarantee-to-start-the-project",
    "thumbnail_url": "https://cdn.mos.cms.futurecdn.net/jMPG3YdmjWxPqtWjWNUVEM-1920-80.jpg",
    "created_at": "2025-12-28T01:03:18.281Z",
    "topic": "tech"
  },
  {
    "slug": "phishing-scams-becoming-prevalent-on-linkedin-how-to-spot-them",
    "title": "Phishing scams becoming prevalent on LinkedIn: How to spot them",
    "description": "Americans lost $12.5 billion in scams in 2025, according to a report from the US Federal Trade Commission (FTC), a whopping 25% increase from last year. Push Security CTO Mark Orlando explains the methods and platforms that scammers are using, such as social media and networking sites like LinkedIn, and the tell-tale signs of a phishing scam. Catch Yahoo Finance's interview with CrowdStrike (CRWD) president Michael Sentonas on how the cybersecurity industry is using AI to combat hacks. Also read up on how North Korean hackers were responsible for over $2 billion in crypto losses in 2025.",
    "fullText": "Americans lost $12.5 billion in scams in 2025, according to a report from the US Federal Trade Commission (FTC), a whopping 25% increase from last year.\n\nPush Security CTO Mark Orlando explains the methods and platforms that scammers are using, such as social media and networking sites like LinkedIn, and the tell-tale signs of a phishing scam.\n\nCatch Yahoo Finance's interview with CrowdStrike (CRWD) president Michael Sentonas on how the cybersecurity industry is using AI to combat hacks. Also read up on how North Korean hackers were responsible for over $2 billion in crypto losses in 2025.\n\nTo watch more expert insights and analysis on the latest market action, check out more Market Domination Overtime.\n\nThe FTC estimated that Americans lost 12.5 billion dollars to scams in 2024. That was a 25% increase from a year earlier. and in 2025 attacks are growing in scope and scale, even taking advantage of trusted sites like LinkedIn. One company trying to protect consumers is Push security. Mark Orlando, Push's chief technology officer joins me now. Mark, it is great to see you. So so maybe start here Mark, you know, as the year draws to a close, we're rolling into 2026, Mark. What what is the big\n\ncybersecurity themes, Mark, we should be aware of. What what are the big trends? Scale, for example, seems to be one you're highlighting.\n\nHi Josh, absolutely. Scale is uh really one of the biggest developments that we've seen not only this year but in the last few years, as the infrastructure behind these types of attacks gets easier and easier to stand up and operate. I think we can expect the scale of these attacks to continue growing exponentially. We've also seen the sophistication of these attacks uh really getting getting higher and higher. Uh you mentioned exploiting\n\nlegitimate sites and services like LinkedIn, um but we're seeing that across the board, whether it's social media networks or uh sponsored ads in Google results, attackers have come up with some very creative and sophisticated ways to deliver these scams and these attacks to unsuspecting users.\n\nIt sounds like, Mark, you're also highlighting how more attacks are are happening inside the browser. Why is that, Mark? I mean, just technically technically speaking, how does that how does that help the attacker?\n\nSure, well the browser has really evolved from a tool that we use to view web pages to, you know, essentially a platform that runs software on demand. I mean, this is where, you know, work really happens these days including, you know, where users are logging into all of the various accounts and services that we use on a daily basis. So, uh attackers realized this and they have kind of shifted away from uh different areas of the network like email uh or, you know, strictly web access that are fairly well defended into the browser, which is somewhat\n\nless well defended, certainly an area where most organizations don't have great visibility into what's going on and how users are interacting with websites. So, attackers have realized this, they've shifted focus to doing \n\nYou also highlight here, Mark, uh what sound like these LinkedIn-based fishing attacks. explain those, Mark, how do they work?\n\nSure. So, I think historically when you talk about fishing or email scams, I mean it is strictly that. It's something that's coming through email. and I think more or less that's what users have come to expect. if they're going to get scammed, it's going to be some, you know, poorly worded kind of suspicious email that comes in with an attachment or a link. And really that's uh increasingly no longer the case. So, uh you mentioned LinkedIn, we identified an attack campaign uh earlier this year where\n\nuh a an executive, a CEO in fact, uh of a company we work with was targeted through LinkedIn. He received a message from someone in his network, a first-level connection uh about something that was very relevant to that company and to his work. And so uh he clicked on the link, you know, along the lines of hey, check out this investment information, this opportunity, let me know what you think. Uh there was a lot of kind of sophisticated um\n\nkind of hoops he had to jump through to validate that it was in fact, uh him who was accessing the attacker website. and ultimately the goal was uh to gather his login information. So, in fact, it wasn't the trusted contact that had sent this message through LinkedIn, but rather someone else who had compromised his contact's uh account. So, this is a a situation where not only is the message very, very convincing, but it comes from a a trusted source, in this case, you know, a trusted known contact.\n\nSo, very, very difficult to pick out. and again, very difficult for an organization to see what's happening inside of those LinkedIn communications, much less do anything to stop it.",
    "readingTime": 5,
    "keywords": [
      "push security",
      "mark orlando",
      "social media",
      "attacks",
      "scams",
      "scale",
      "trusted",
      "users",
      "email",
      "sites"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/video/phishing-scams-becoming-prevalent-linkedin-150028882.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Laa7kSey8OFrDeIsXs6XkA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzY-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/842c3900-e0f7-11f0-b7ff-49c0900d8059",
    "created_at": "2025-12-28T01:03:15.931Z",
    "topic": "finance"
  },
  {
    "slug": "developing-new-medicines-in-the-age-of-ai-and-personalized-medicine-video",
    "title": "Developing New Medicines in the Age of AI and Personalized Medicine [video]",
    "description": "Did you ever wonder where all the drugs, which you can get at a pharmacy, come from? Who makes them, and how? Well, there is no easy answ...",
    "fullText": "Did you ever wonder where all the drugs, which you can get at a pharmacy, come from? Who makes them, and how? Well, there is no easy answer, because the process of drug discovery and development is a very complex, expensive, and challenging journey, riddled with many risks and failures. This holds true for all types of drugs, from a simple pill to an mRNA vaccine or a gene therapy. Today, scientists support this process with a variety of AI applications, cutting-edge technologies, automation, and a huge amount of data. But can the race for new medicines and cures succeed only through more technology, or do we need to rethink the entire process? Let’s take a look at how the drug discovery and development process has worked so far, and how this entire process is changing – for better or worse.\n\nAfter presenting a high-level overview of the path from an idea to the medicine that you can buy at a pharmacy, this talk will present and discuss the following aspects of the drug discovery and development process:\n\n(1) The translation of an idea into a drug for a human patient faces many critical moments along the development process. This so-called “translational gap” is addressed through experiments in a test tube (or Petri dish), experimentation in lab animals, and eventually testing in humans. However, findings in a standard cell line or in a mouse do not necessarily reflect the complexity of biological processes in a human patient. Currently, there are many technological advancements under way to improve the current drug discovery and development process, and possibly even replace animal studies in the future (e.g., organs-on-chip). Nevertheless, the fundamental issues surrounding translational research remain, such as the lack of standardization, the limitations of model systems, and various underlying clinical biases.\n\n(2) Like in many industries today, AI applications are introduced at multiple levels and for various purposes within the drug discovery and development continuum. Often, a lot of hope is placed in AI-based technologies to accelerate the R&D process, increase efficiency and productivity, and identify new therapeutic approaches. Indeed, there are many highly useful examples, such as the automation of image analysis in research, which replaces repetitive tasks and hence frees up a lot of time for researchers to do meaningful research. However, there are also many applications that are likely misguided, because they still face fundamental problems in evaluating scientific knowledge. For instance, the use of LLMs to summarize huge amounts of very complex and heterogeneous scientific data relies on the accuracy, completeness, and reproducibility of the available scientific data, which is often not the case. In addition, AI is often employed in an IT environment with questionable data security and ownership practices, such as the storage of sensitive research data on third-party cloud platforms.\n\n(3) Until now, the overwhelming majority of drugs have been developed to treat large patient populations, which represent a considerable market and ultimately ensure a return on investment. Today, however, most common and homogeneous diseases can already be managed, often with several (generic) drugs. Slight improvements to current drugs do not justify a large profit margin anymore, so the focus of drug discovery and development is shifting toward more heterogeneous and rare diseases, for which no or only poor treatments are available. Novel medicines in those disease areas hold the promise of substantial improvement for patients; however, these new patient (sub)populations, and thus markets, are much smaller, leading to premium prices for individualized therapies in order to ensure a return on investment. This paradigm shift toward individualized therapy - referred to as precision and personalized medicine - is supported by the advent of novel technologies and the accumulation of large bodies of data.\n\n(4) The rise of precision and personalized medicine is challenging the current business model of today’s pharmaceutical industry, suggesting that the era of blockbuster drugs might be over. Moreover, many intellectual property rights for blockbuster drugs are going to expire in the next few years, ending the market dominance of a number of pharma companies and sending the current industry landscape into turmoil. These developments will likely alter the current modus operandi of the entire biopharmaceutical development process, and it is not clear how the next few years will look like.\n\nLicensed to the public under http://creativecommons.org/licenses/by/4.0\n\nThis Talk was translated into multiple languages. The files available\nfor download contain all languages as separate audio-tracks. Most\ndesktop video players allow you to choose between them.\n\nPlease look for \"audio tracks\" in your desktop video player.",
    "readingTime": 4,
    "keywords": [
      "ensure return",
      "personalized medicine",
      "human patient",
      "drug discovery",
      "blockbuster drugs",
      "development process",
      "however",
      "research",
      "applications",
      "technologies"
    ],
    "qualityScore": 1,
    "link": "https://media.ccc.de/v/39c3-developing-new-medicines-in-the-age-of-ai-and-personalized-medicine",
    "thumbnail_url": "https://static.media.ccc.de/media/congress/2025/2293-5cf7d973-5a94-5e8f-9f8d-8b5f4ec5bb6d_preview.jpg",
    "created_at": "2025-12-27T18:16:22.759Z",
    "topic": "health"
  },
  {
    "slug": "more-than-20-of-videos-shown-to-new-youtube-users-are-ai-slop-study-finds",
    "title": "More than 20% of videos shown to new YouTube users are 'AI slop', study finds",
    "description": "Low-quality AI-generated content is now saturating social media – and generating about $117m a year, data shows",
    "fullText": "Low-quality AI-generated content is now saturating social media – and generating about $117m a year, data shows\n\nMore than 20% of the videos that YouTube’s algorithm shows to new users are “AI slop” – low-quality AI-generated content designed to farm views, research has found.\n\nThe video-editing company Kapwing surveyed 15,000 of the world’s most popular YouTube channels – the top 100 in every country – and found that 278 of them contain only AI slop.\n\nTogether, these AI slop channels have amassed more than 63bn views and 221 million subscribers, generating about $117m (£90m) in revenue each year, according to estimates.\n\nThe researchers also made a new YouTube account and found that 104 of the first 500 videos recommended to its feed were AI slop. One-third of the 500 videos were “brainrot”, a category that includes AI slop and other low-quality content made to monetise attention.\n\nThe findings are a snapshot of a rapidly expanding industry that is saturating big social media platforms – from X to Meta to YouTube – and defining a new era of content: decontextualised, addictive and international.\n\nA Guardian analysis this year found that nearly 10% of YouTube’s fastest-growing channels were AI slop, racking up millions of views despite the platform’s efforts to curb “inauthentic content”.\n\nThe channels found by Kapwing are globally distributed and globally watched. They have millions of subscribers: in Spain, 20 million people, or nearly half the country’s population, follow the trending AI channels. AI channels have 18 million followers in Egypt, 14.5 million in the US, and 13.5 million in Brazil.\n\nBandar Apna Dost, the most-viewed channel in the study, is based in India and now has 2.4bn views. It features the adventures of an anthropomorphic rhesus monkey and a muscular character modelled off the Incredible Hulk who fights demons and travels on a helicopter made of tomatoes. Kapwing estimated that the channel could make as much as $4.25m. Its owner did not respond to a query from the Guardian.\n\nRohini Lakshané, a researcher on technology and digital rights, said Bandar Apna Dost’s popularity most likely stems from its absurdity, its hyper-masculine tropes and the fact that it lacks a plot, which makes it accessible to new viewers.\n\nPouty Frenchie, based in Singapore, has 2bn views and appears to target children. It chronicles the adventures of a French bulldog – driving to a candy forest, eating crystal sushi – many of them set to a soundtrack of children’s laughter. Kapwing estimates it makes nearly $4m a year. Cuentos Facinantes, based in the US, also appears to target children with cartoon storylines, and has 6.65 million subscribers – making it the most-subscribed channel in the study.\n\nMeanwhile, The AI World, based in Pakistan, contains AI-generated shorts of catastrophic flooding in Pakistan, with titles like Poor People, Poor Family, and Flood Kitchen. Many of these videos are set to a soundtrack called Relaxing Rain, Thunder & Lightning Ambience for Sleep. The channel itself has 1.3bn views.\n\nIt’s hard to say exactly how significant these channels are compared with the vast sea of content already on YouTube. The platform does not release information on how many views it has yearly, or how many of these are from AI content.\n\nBut behind these uncanny scenes of candy forests and disasters is a semi-structured, growing industry of people trying to find new ways to monetise the world’s most powerful platforms using AI tools.\n\n“There are these big swathes of people on Telegram, WhatsApp, Discord and message boards exchanging tips and ideas [and] selling courses about how to sort of make slop that will be engaging enough to earn money,” said Max Read, a journalist who has written extensively on AI slop.\n\n“They have what they call niches. One that I noticed recently is AI videos of people’s pressure cookers exploding on the stove.”\n\nWhile creators of AI slop are everywhere, Read said that many come from English-speaking countries with relatively strong internet connectivity, where the median wage is less than the amount they can make on YouTube.\n\n“It’s mostly sort of middle-income countries like Ukraine, lots and lots of people in India, Kenya, Nigeria, a fair number in Brazil. You see Vietnam, too. Places with relative freedom online to access social media sites,” he said.\n\nIt’s not always easy to be an AI slop creator. For one thing, creator programmes on YouTube and Meta aren’t always transparent about who they pay for content, and how much, said Read. For another, the AI slop ecosystem is full of scammers: people selling tips and courses on how to make viral content – who often make more money than the AI slop producers themselves.\n\nBut, at least for some, it’s a living. And while new, attention-grabbing ideas – such as exploding pressure cookers – constantly emerge, when it comes to AI slop, human creativity matters far less than the algorithms that distribute the content on Meta and YouTube.\n\n“These websites are huge A/B testing machines just by their nature,” said Read. “Almost anything that you can think of, you could already find on Facebook. So the question is, how do you find the things that are kind of doing well, and then how do you scale that? How do you make 10 of them?”\n\nA YouTube spokesperson said: “Generative AI is a tool, and like any tool it can be used to make both high- and low-quality content. We remain focused on connecting our users with high-quality content, regardless of how it was made. All content uploaded to YouTube must comply with our community guidelines, and if we find that content violates a policy, we remove it.”",
    "readingTime": 5,
    "keywords": [
      "bandar apna",
      "target children",
      "pressure cookers",
      "social media",
      "ai-generated content",
      "low-quality content",
      "slop",
      "views",
      "channels",
      "videos"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/27/more-than-20-of-videos-shown-to-new-youtube-users-are-ai-slop-study-finds",
    "thumbnail_url": "https://i.guim.co.uk/img/media/2d8021bb048378298f4bb9ca81867e7248b5a3cd/0_1_5000_3998/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=8f1528b44eada9e7f6b3721f462622a8",
    "created_at": "2025-12-27T18:16:18.809Z",
    "topic": "tech"
  },
  {
    "slug": "i-pioneered-machine-teaching-at-microsoft-building-ai-agents-is-like-building-a-basketball-team-not-drafting-a-player",
    "title": "I pioneered machine teaching at Microsoft. Building AI agents is like building a basketball team, not drafting a player",
    "description": "We shouldn’t ask how much knowledge an agent can retain, but rather if it has had the opportunity to develop expertise by practicing as humans do.",
    "fullText": "Kence Anderson is the founder and CEO of AMESA and former Director of Autonomous AI Adoption at Microsoft. He is a pioneer in the field of intelligent autonomous agents, having co-created “Machine Teaching”, a methodology that enables AI agents to develop real-world autonomy through simulation, feedback, and trial-and-error. Over the past seven years, Kence has focused exclusively on designing, building, and deploying intelligent autonomous agents for manufacturing and logistics, leading over 200 real-world deployments for major corporations, including Shell, PepsiCo, and Delta Airlines. He is also the author of Designing Autonomous AI (O’Reilly, 2022) and is now developing a horizontal platform for orchestrating AI agents to make million-dollar decisions in enterprise operations.",
    "readingTime": 1,
    "keywords": [
      "intelligent autonomous",
      "autonomous agents",
      "real-world",
      "kence",
      "designing"
    ],
    "qualityScore": 0.35,
    "link": "https://fortune.com/2025/12/27/machine-teaching-amesa-ceo-kence-anderson-former-microsoft-director-like-basketball/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/kence-anderson.png?resize=1200,600",
    "created_at": "2025-12-27T18:16:16.989Z",
    "topic": "sports"
  },
  {
    "slug": "read-the-pitch-decks-of-14-startups-looking-to-disrupt-advertising-and-marketing-with-ai",
    "title": "Read the pitch decks of 14 startups looking to disrupt advertising and marketing with AI",
    "description": "Check out the pitch decks AI-powered advertising and marketing tech startups used to raise millions from venture capital firms.",
    "fullText": "AI is reshaping the media and marketing industries at warp speed.\n\nAdtech and martech startups are raising millions of dollars from venture capital firms on the back of the AI wave.\n\nMany of these companies are developing under-the-hood tech, such as agentic AI tools designed to streamline marketers' workflows and boost productivity. Others are working on creative platforms that let marketers create ads and even virtual influencers using generative AI. Some are working in the new area of \"generative engine optimization\" (GEO), helping brands optimize their visibility in AI search results.\n\n\"We want to disrupt the traditional ad agency,\" Bolbi Liu, founder of AI adtech startup AdsGency, told Business Insider. In October, AdsGency announced it raised a $12 million seed round, led by XYZ Venture Capital.\n\nAdvertising agency giants are aware that they must embrace AI or risk being left behind. Large agency groups, from UK-based WPP to French holding company Publicis and US ad giant Omnicom, have pledged to invest hundreds of millions of dollars in AI over the next few years. Publicis is hunting for AI companies to acquire.\n\nThere's big money to be made. A Boston Consulting Group survey of 200 senior marketers, conducted this year, found that 71% of chief marketing officers plan to invest at least $10 million annually in generative AI over the next three years, up from 57% of respondents in the 2024 edition of the study.\n\nBusiness Insider has interviewed the founders of startups building tools to disrupt advertising and marketing with AI. These founders shared the pitch decks they used to impress investors and raise venture capital funding.",
    "readingTime": 2,
    "keywords": [
      "venture capital",
      "marketing",
      "marketers",
      "generative",
      "agency",
      "adtech",
      "startups",
      "millions",
      "dollars",
      "tools"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/pitch-decks-advertising-marketing-ai-startups-raise-venture-capital-2025-10",
    "thumbnail_url": "https://i.insider.com/694a55ec64858d02d2174cce?width=1200&format=jpeg",
    "created_at": "2025-12-27T18:16:15.865Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-makes-boldest-move-yet-and-the-fallout-begins",
    "title": "Nvidia makes boldest move yet, and the fallout begins",
    "description": "Nvidia recently struck a $20 billion deal to acquire the brains of a fierce rival, marking its biggest move to date in the AI arms race. However, the massive chip manufacturer may soon have to respond to more difficult inquiries about the future of its chips. CEO Jensen Huang offered further detail ...",
    "fullText": "Nvidia recently struck a $20 billion deal to acquire the brains of a fierce rival, marking its biggest move to date in the AI arms race. However, the massive chip manufacturer may soon have to respond to more difficult inquiries about the future of its chips.\n\nCEO Jensen Huang offered further detail in an internal email obtained by CNBC.\n\nThe move comes as Nvidia is getting more attention in Asia. Megaspeed International, a fast-growing Singapore-based importer of Nvidia chips, is being looked into for possibly smuggling banned H100 and H200 chips into China, according to a recent Bloomberg report.\n\nThe world's most valuable chipmaker is now stuck between two extremes: It has to deal with rising geopolitical threats and regulatory difficulties in one of its hottest regions while still dominating AI infrastructure around the world.\n\nGroq, a nine-year-old firm started by former Google TPU engineers, was never for sale — at least not in public. But Nvidia came in with a $20 billion deal that includes licensing Groq's cutting-edge AI inference technology and bringing on its top leaders, such as CEO Jonathan Ross.\n\nSources informed CNBC that Nvidia is really buying all of Groq's assets, except for a small GroqCloud firm, even though Groq called the purchase a \"non-exclusive licensing agreement.\"\n\nNvidia’s China chip problem isn’t what most investors think\n\nJim Cramer issues blunt 5-word verdict on Nvidia stock\n\nThis is how Nvidia keeps customers from switching\n\nBank of America makes a surprise call on Nvidia-backed stock\n\nThis is Nvidia's biggest deal ever in terms of money. The price of $20 billion is over three times what Groq was worth in its most recent investment round, which was $6.9 billion.\n\nIt also beats Nvidia's previous record, the $7 billion purchase of Mellanox in 2019, by a wide margin.\n\nNvidia now controls Groq’s high-speed inference chip designs, allowing tighter integration into its broader AI platform.\n\nGroq’s leadership, including Ross and president Sunny Madra, will join Nvidia’s leadership team.\n\nThe remaining GroqCloud unit will continue operating independently, led by its CFO.\n\nThis aggressive move is like Nvidia's smaller but similar AI acquisition in September, when it spent $900 million for chip IP and key staff from Enfabrica.\n\nAs Nvidia continues to lead in AI, it is being caught up in the sticky politics of the semiconductor supply chain.\n\nMegaspeed International, which used to be a small part of a Chinese gaming company, is now Nvidia's biggest customer in Southeast Asia. But U.S. investigators are now looking into the company because it may have smuggled prohibited AI chips into China.",
    "readingTime": 3,
    "keywords": [
      "nvidia's biggest",
      "deal",
      "chip",
      "chips",
      "groq",
      "nvidia",
      "firm",
      "licensing",
      "groq's",
      "inference"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-makes-boldest-move-yet-160700606.html",
    "thumbnail_url": "https://media.zenfs.com/en/thestreet_881/522db573d1c87df411c7d0ef2e4505fe",
    "created_at": "2025-12-27T18:16:13.458Z",
    "topic": "finance"
  },
  {
    "slug": "6-undertheradar-stocks-to-play-the-ai-boom-in-2026-bofa",
    "title": "6 under-the-radar stocks to play the AI boom in 2026: BofA",
    "description": "While Nvidia and Broadcom dominate, Bank of America's Vivek Arya says some specialized small- and mid-caps are essential for the next $1 trillion chip surge",
    "fullText": "While players like Nvidia (NVDA) and Broadcom (AVGO) are at the forefront of investors’ minds, smaller specialized players are grabbing a slice of the AI spending behind the scenes.\n\nIn a recent report, Bank of America analyst Vivek Arya named a handful of small- to mid-cap companies as the unsung heroes of the semiconductor surge.\n\n\"We mentioned a few companies on the smid-cap side, Credo, MKS, Advanced Energy, MACOM, and Teradyne,\" Arya told reporters on a Dec. 19 call.\n\nWhile these companies lack the massive margins of Nvidia, Arya suggests they are currently benefitting from being the primary providers of essential technologies.\n\nThe scale of the unsung opportunity is staggering. BofA predicts the total addressable market for AI data center systems will exceed $1.2 trillion by 2030, fueled by a 38% compound annual growth rate. Within that, AI accelerators will grab around $900 billion, but that leaves a massive $300 billion slice — one that depends on secondary technologies like networking, cables, and power systems.\n\nArya breaks down how the pie is divided. For every $100 spent on AI hardware, $15 to $20 goes into networking. A third flows directly into interconnects — the wires and optical components that let GPUs talk to each other. As AI clusters expand, these bits and bolts of the trillion-dollar build-out are seeing a direct benefit.\n\nArya highlights Credo (CRDO) for its leadership in active electrical cables. As data centers prioritize \"performance per watt,\" Credo's niche technology is critical. \"They want to make sure that all these GPUs talk to each other, very effectively,\" he said.\n\nHe also pointed to Astera Labs (ALAB) and its robust high-speed connectivity efforts via PCIe 6.0, the standard for moving data between a computer's motherboard and its hardware.\n\n\"They were the ones who invested in specific technologies ... nobody cared about these categories,\" he said. \"So now, they are benefitting from being the only people standing in those specific niche technologies.\"\n\nOther key players, such as MKS Instruments (MKSI) and Advanced Energy (AEIS), provide the precision power and vacuum systems needed to actually build chips. If Nvidia is the architect, these companies provide the machinery and high-voltage power to keep the site running.\n\nMeanwhile, MACOM (MTSI) provides high-speed analog and optical components that let these \"brains\" interact, while Teradyne (TER) serves as a final checkpoint. The company's automated testing equipment ensures these expensive components actually work before they are shipped.",
    "readingTime": 3,
    "keywords": [
      "advanced energy",
      "gpus talk",
      "optical components",
      "technologies",
      "players",
      "systems",
      "slice",
      "unsung",
      "massive",
      "benefitting"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/6-under-the-radar-stocks-to-play-the-ai-boom-in-2026-bofa-150019301.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/D4yQze6jb0pJoooWRyU.xw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://s.yimg.com/os/creatr-uploaded-images/2025-10/faea6f40-a06e-11f0-bfff-6e4628767bb6",
    "created_at": "2025-12-27T18:16:13.326Z",
    "topic": "finance"
  },
  {
    "slug": "it-brings-you-closer-to-the-natural-world-the-rise-of-the-merlin-birdsong-identifying-app",
    "title": "‘It brings you closer to the natural world’: the rise of the Merlin birdsong identifying app",
    "description": "Merlin has been trained to identify the songs of more than 1,300 bird species around the world\nWhen Natasha Walter first became curious about the birds around her, she recorded their songs on her phone and arduously tried to match each song with online recordings. After a friend recommended Merlin Bird ID, a free app, she tried it in her London garden and was delighted to discover the birds she assumed were female blackbirds – “this is how bad a birder I was” – were actually song thrushes and mistle thrushes.\n“I’m obsessed with Merlin – it’s wonderful and it’s been a joy to me,” says Walter, a writer and human rights activist. “This is what AI and machine-learning have been invented for. It’s the one good thing!",
    "fullText": "Merlin has been trained to identify the songs of more than 1,300 bird species around the world\n\nWhen Natasha Walter first became curious about the birds around her, she recorded their songs on her phone and arduously tried to match each song with online recordings. After a friend recommended Merlin Bird ID, a free app, she tried it in her London garden and was delighted to discover the birds she assumed were female blackbirds – “this is how bad a birder I was” – were actually song thrushes and mistle thrushes.\n\n“I’m obsessed with Merlin – it’s wonderful and it’s been a joy to me,” says Walter, a writer and human rights activist. “This is what AI and machine-learning have been invented for. It’s the one good thing!”\n\nMerlin is having a moment. The app, developed by the Cornell Lab of Ornithology in New York, which listens for birdsong and identifies the species singing, has been downloaded 33m times, in 240 countries and territories around the world. Britain has the second highest total number of users – more than 1.5 million in 2024, an 88% increase from 2023. Every month, there has been a 30% increase in new users of the app, whose sound identification function was launched in 2021.\n\nMerlin has been trained to identify the songs of more than 1,300 species around the world, with more birds added twice a year. Different songs make distinct patterns on spectrograms and Merlin is trained to recognise these different shapes and attribute them to a species.\n\nFor latecomers to birding, or those lacking a knowledgeable friend, the app has become their teacher. “My fear at first was I wouldn’t actually learn because I’m outsourcing my understanding of birds to this app,” says Walter. “But that hasn’t come to pass. It’s helped me continue my journey of learning.” Nowadays, she guesses, and uses Merlin to confirm her hunches. “It’s wonderful if you’re coming to bird-watching late and don’t really have a mentor,” she says.\n\nAngela Townsend from Bedfordshire began using Merlin after going on a nightingale walk one spring and being overwhelmed by the range of bird-voices in the evening chorus. She has found it has steadily built up her bird knowledge. “Warblers were just little brown jobbies but I can now recognise Cetti’s warblers and willow warblers when I’m out without having to put the app on,” she says.\n\nMary Novakovich, author of My Family and Other Enemies, is another recent adopter. She has found it particularly useful when travelling across Croatia, where her parents are from. “I love putting a name to a face and a name to the sound,” she says. “It really brings you closer to the natural world, rather than it being disconnected from your life. It’s part of what makes life a joy.”\n\nMerlin is not flawless, however. The first time Kasper Wall, 12, tried it in his Norfolk garden, it detected a northern cardinal and a brown-headed cowbird – North American species not found in Britain.\n\n“I think it was figuring out where we live,” says Wall, who enjoys using it even though he is now an extremely knowledgeable birder. “A couple of weeks ago we were looking at a large group of goldcrest and it came up with a firecrest. I thought, ‘Oh, there must be a firecrest in here too’ and 30 seconds later we saw one, which was the first I’d ever seen. I like it and it’s very good but I wouldn’t say that it’s better than the best people at identifying bird-calls like [the naturalist] Nick Acheson. It can definitely be fooled.”\n\nWall enjoys fooling Merlin with his uncanny impressions of a curlew, barn owl and greenshank.\n\nAcheson doesn’t use Merlin. He welcomes it, but points out it can replace learning. “Anything that gets people out, thinking about and reacting to nature is a great thing,” he says. “But there’s certainly a risk that people don’t learn and just abdicate responsibility for learning to Merlin.”\n\nHe has noticed a glitch where Merlin interprets a certain type of chaffinch call as a redstart, leading to people being absolutely adamant that there is a rare bird in their garden. “There’s no substitute for a real person explaining to you how a birdsong feels and encouraging someone to engage with it emotionally,” he says.\n\nJohn Williamson, who works as a guide for Norfolk Wildlife Trust, has found Merlin repeatedly identifying high-pitched calls as a spotted flycatcher, a bird that is very unlikely to be found in the middle of Hickling Broad nature reserve’s large reedbeds. “Merlin can’t do habitat,” he says.\n\nMerlin has also excited visitors by identifying a golden oriole, a very occasional rare migrant, in Hickling woods, but no one has actually seen the species. Williamson is convinced it is misinterpreting a fairly unusual “catcall” of a female jay, a common woodland bird.\n\nThat said, Williamson finds it a “good tool” and welcomes how it is encouraging new people to enjoy birdsong, and particularly its mental health benefits. He knows one person who suffers from acute anxiety but Merlin has got him out into the world again and into nature, providing a focus for calming trips outdoors. “I find it impressive that an app can empower people to go out into nature,” he says.\n\nResearch has found that birdsong is particularly beneficial to mental health, and has a lasting positive impact on wellbeing. For millions around the globe, that’s exactly what Merlin is doing.\n\n“It reminds you that there are birds knitted into your daily life,” says Walter. “It’s not about, ‘now I’m going to do a bit of birdwatching’, you may simply be walking through the park and you hear something and it gives you a sense that these birds are singing away all the time, even in London.”",
    "readingTime": 5,
    "keywords": [
      "mental health",
      "it’s wonderful",
      "merlin he",
      "species",
      "birds",
      "songs",
      "birdsong",
      "nature",
      "trained",
      "garden"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/environment/2025/dec/27/merlin-ai-assisted-birdsong-identifying-app-bird-species",
    "thumbnail_url": "https://i.guim.co.uk/img/media/33efd95d5d247c7af1362ae515bc0e0ed8d00875/333_0_3542_2835/master/3542.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=55c4dbee57a45fc9d7f54a246da5f0fd",
    "created_at": "2025-12-27T12:21:16.576Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-senior-pm-at-microsoft-and-a-selfproclaimed-early-adopter-of-ai-here-are-the-easy-ways-it-helps-me-at-work-and-in",
    "title": "I'm a senior PM at Microsoft and a self-proclaimed early adopter of AI. Here are the easy ways it helps me at work and in my personal life.",
    "description": "Rishab Jolly, a senior PM at Microsoft, uses AI tools to help him draft documents for work, and to speed up research for his podcasting hobby.",
    "fullText": "This as-told-to essay is based on a conversation with Rishab Jolly, 37, a senior program manager at Microsoft, based in Washington. The following has been edited for length and clarity.\n\nI landed a job at Microsoft as a program manager in 2017, after moving to the US for my MBA.\n\nI'm now a senior PM and find my role very fulfilling. My role involves developing ideas for products and features that enhance the customer experience, but also drafting plans that take the product from development to shipping to the customer. PMs are like the glue that brings different teams, across engineering, marketing, and business, together to work on each project.\n\nAs AI tools have become more prevalent, I've felt excited about the technology's potential to help me in my role. I consider myself an early adopter who's been upskilling to make sure I have AI as a new tool in my toolbox.\n\nHere are the ways AI helps me, both in my job and personal life, that are relatively easy to replicate.\n\nI studied computer science engineering for my bachelor's degree in India, where I'm from, before moving to the US in 2015 for my MBA. I also worked as a software engineer in India for four years, at companies using AI and machine learning in some form, before LLMs arrived on the scene. I wouldn't have called myself an AI expert, but I understood how the technology worked.\n\nAs AI tools have become more commonplace, I've used them to make my work faster and easier.\n\nPMs like me spend a huge amount of time in meetings. When I first joined Microsoft, I compiled notes manually to help me understand what I needed to action afterward. Now, I use can use AI tools for note-taking, which has given me back a lot of time to focus on more meaningful work, like strategic thinking and prioritization.\n\nPart of my job as a PM is to write documents that provide clarity to engineering teams about our goals and priorities. AI tools can help reduce the time spent on an initial draft. I then review, edit, and shape the AI-generated content myself, applying my judgment and experience before sharing the document with the team.\n\nAt work, I use the tools available at Microsoft, but in my personal life, I like experimenting and getting my hands dirty with a wide range of tools, from ChatGPT and Perplexity to Gemini.\n\nI started a podcast called \"Curious Souls\" in 2022 with my wife, who also works in tech, where we talk about our passion for product management, AI, fitness, and other topics with guest speakers. It's my hobby.\n\nResearching topics by asking PMs what they wanted to hear about and coming up with ideas for guests was very time-consuming.\n\nNow, I can speed up the process by prompting LLMs to search Reddit for hot topics that PMs are talking about and ask the chatbot to generate a script about the chosen topic. I can even generate an audio clip of the script to listen to while driving to the gym and ponder on how the podcast might sound if I used the script.\n\nI still dedicate between four and five hours each weekend to the podcast, but with AI, I'm able to accomplish much \n\nExperimenting with AI in personal projects has helped me understand where AI is helpful and where it isn't. For example, when I was using AI to generate podcast scripts, I found that it sometimes generated inaccurate outputs, like placeholder links that don't actually exist, so I usually treat AI output as a starting point and make sure to check it.\n\nAs a result, I'm more intentional when I use AI at work, knowing when to rely on automation and when human judgment is essential. I think it's worth experimenting with AI outside of work on low-risk projects, like planning hobbies or trips, before applying similar techniques professionally.\n\nInstead of being fearful of AI, I've decided to embrace it. In the future, I think PMs will be expected to know how to use AI to do things faster.\n\nEven with AI, I think the crux of the PM role will remain the same: being empathetic to customers and solving their problems. AI will make us more capable of solving those issues, and it can give us suggestions for how to approach issues, but the judgment calls will always be made by humans. It won't replace us, but it will be an essential tool to make our lives easier.\n\nMy advice to PMs is to embrace AI and get your hands dirty by experimenting with it, not just in your job, but in daily life. There's no way around it, and the sooner you start doing it, the faster you'll see benefits.\n\nDo you have a story to share about how you use AI at work? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "program manager",
      "personal life",
      "as ai",
      "tools",
      "microsoft",
      "role",
      "experimenting",
      "podcast",
      "engineering",
      "faster"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-pm-ai-easy-work-personal-life-2025-12",
    "thumbnail_url": "https://i.insider.com/694430de64858d02d2171048?width=1200&format=jpeg",
    "created_at": "2025-12-27T12:21:15.661Z",
    "topic": "finance"
  },
  {
    "slug": "the-top-5-things-that-happened-in-the-ai-race-this-year",
    "title": "The top 5 things that happened in the AI race this year",
    "description": "From bubbles to talent wars, 2025 was a turning point for AI's future.",
    "fullText": "2025 was unquestionably the year of AI.\n\nBig Tech shelled out roughly $400 billion on capex, a spending spree so extensive that some economists believe it staved off an overall recession. Nvidia became the first $4 trillion company. And AI content became inescapable, seeping into everything from Hollywood to campaign ads — even Mickey Mouse is getting into AI.\n\nIt hasn't been an endless party. Seemingly every few weeks, the stock market gets spooked that music is about to stop. Only Universal's Wicked for Good was more focused on a bubble.\n\nHere's a look back at the biggest AI storylines of 2025.\n\nIn an era of nostalgia traps, traders can't decide whether this is the Dot-Com era all over again.\n\nTech and AI CEOs can't agree either. In August, OpenAI CEO Sam Altman touched off concerns that a bubble had already formed. Since then, Bill Gates, Nvidia's Jensen Huang, Mark Cuban, and Mark Zuckerberg have offered their own similar or dissenting views.\n\nThe optimists' train of thought often ends up at the railroads and other breakthrough innovations that transformed the economy.\n\n\"There's been a lot of talk about an AI bubble,\" Huang said during Nvidia's third-quarter earnings call. \"From our vantage point, we see something very different.\"\n\nEven those at the forefront of AI's advancements express concern that some of their competitors are being too bold.\n\n\"There's genuine uncertainty, there's genuine dilemma, which we as a company try to manage as responsibly as we can,\" Anthropic CEO Dario Amodei said in early December at a New York Times event. \"And then I think there are some players who are yoloing, who pull the wrist dial too far, and I'm very concerned.\"\n\nThe sheer size of spending is breathtaking.\n\nJPMorgan Chase concluded that AI-related spending contributed to 1.1% of GDP growth in the first half of the year.\n\nThe spending isn't likely to slow down.\n\nOver the last two years, Wall Street has underestimated capex growth, according to Goldman Sachs Research. Right now, Goldman said, the consensus estimate is that hyperscalers will spend $527 billion on capital expenditures next year.\n\nZuckerberg and OpenAI's leadership have separately suggested that the biggest risk is not spending enough.\n\n\"We want to be ahead of the curve,\" OpenAI President Greg Brockman said in a recent video posted on X. \"And the truth is, I don't think we will be, no matter how ambitious we can dream of being right now. I think demand will far exceed what we can think of.\"\n\nSilicon Valley's turf wars were a lot greener in 2025. Over the summer, the AI talent wars reached another level.\n\nPerhaps no company was as aggressive as Meta. Zuckerberg moved to poach top talent by wooing workers with tens of millions of dollars.\n\nAltman said OpenAI offered his best employees $100 million signing bonuses. Another top OpenAI official said Zuckerberg even made homesoup for one of his targets.\n\nOpenAI boasted that it largely fended off Meta's efforts, though ChatGPT co-creator Shengjia Zhao later joined Meta's Superintelligence Lab.\n\nEven the hyperscalers need some extra help to maintain their spending habits.\n\nThat's why Alphabet, Amazon, Meta, Microsoft, and Oracle issued roughly $100 billion of bonds, powering global bond sales to another record year.\n\nThe interconnected nature of many AI deals has also raised concerns among some analysts and traders. Take Anthropic's pledge to spend $30 billion on Microsoft Azure to scale up Claude's compute. As part of the deal, Microsoft will invest up to $5 billion in Anthropic. Nvidia, whose chips are at the certain of this deal and many like, also agreed to invest up to $10 billion.\n\nNot all spenders are created alike, either. OpenAI, which is expected to be in the red by $9 billion this year, has about $1.4 trillion in spending commitments for AI data centers over the next decade. Unlike Google, Meta, and Microsoft, OpenAI doesn't have an established revenue base to fall back on, either.\n\nIt's why OpenAI CFO Sarah Friar sparked a brief firestorm when she appeared to suggest that the startup would want the possibility of a government bailout to backstop its data center bets. Friar walked back her remarks, and Altman later emphasized that OpenAI didn't believe in bailouts.\n\nOpenAI has led much of the AI-model race since the release of ChatGPT in 2022.\n\nThree years later, it was Altman who declared a \"code red,\" just over a month after OpenAI completed its corporate restructuring, aimed at giving it more freedom to raise money to fund its AI advancements.\n\nGoogle is now fighting back, and in the view of some observers, has caught up to OpenAI with the widely praised release of Gemini 3.\n\nCEO Sundar Pichai might as well have struck Steph Curry's signature celebration when he was asked what was next for his AI team.\n\n\"I think some folks need some sleep,\" Pichai said of the company's staffers following Gemini 3's release.",
    "readingTime": 5,
    "keywords": [
      "there's genuine",
      "back",
      "altman",
      "openai",
      "bubble",
      "either",
      "another",
      "later",
      "release",
      "roughly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/what-happened-in-ai-this-year-2025-12",
    "thumbnail_url": "https://i.insider.com/694a7a9e64858d02d2174d21?width=1200&format=jpeg",
    "created_at": "2025-12-27T12:21:15.573Z",
    "topic": "finance"
  },
  {
    "slug": "china-issues-drafts-rules-to-regulate-ai-with-humanlike-interaction",
    "title": "China issues drafts rules to regulate AI with human-like interaction",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/china-issues-drafts-rules-to-regulate-ai-with-humanlike-interaction-4423279",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBQ059_L.jpg",
    "created_at": "2025-12-27T12:21:15.333Z",
    "topic": "finance"
  },
  {
    "slug": "i-spent-3-months-building-an-ai-trading-bot-using-drl-like-alphago",
    "title": "I spent 3 months building an AI trading bot using DRL like AlphaGo",
    "description": "DRL Trading - AI Gold Trading Bot    Deep reinforcement learning system for autonomous XAUUSD trading using:   - PPO & Dreamer algorithms (PyTorch)   - 140+ features: multi-timeframe, macro dat...",
    "fullText": "zero-was-here\n\n /\n\n tradingbot\n\n Public\n\n DRL Trading - AI Gold Trading Bot Deep reinforcement learning system for autonomous XAUUSD trading using: - PPO & Dreamer algorithms (PyTorch) - 140+ features: multi-timeframe, macro data, economic events - MetaTrader 5 live trading - 2M steps trained, targeting 80-120% annual returns - Multiple strategies (aggressive/swing/standard)\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n zero-was-here/tradingbot",
    "readingTime": 1,
    "keywords": [
      "trading",
      "license"
    ],
    "qualityScore": 0.35,
    "link": "https://github.com/zero-was-here/tradingbot",
    "thumbnail_url": "https://opengraph.githubassets.com/b2f78abfba82eebbe98b1972188ca15eb46033918ff4178e5e6d2530376d1535/zero-was-here/tradingbot",
    "created_at": "2025-12-27T12:21:13.822Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tariffs-and-box-office-14-charts-that-explain-2025",
    "title": "AI, Tariffs and Box Office – 14 Charts That Explain 2025",
    "description": "President Trump’s trade policy, inflation and climbing stock prices shaped business and the economy this year.",
    "fullText": "In recent years, macroeconomic tides have ebbed and flowed, but one thing has remained unchanged: Americans’ dim views of the economy.\n\nIn 2023, pundits warned of the “vibecession.” In 2024, concerns about the economy and inflation were top of mind for voters in the presidential race.\n\nThis year, economic pessimism has persisted, as President Trump’s sweeping economic proposals, from his wide-ranging tariffs to his plan to remake the Federal Reserve, have raised uncertainty to new highs. And the economic data is sending mixed, and muddled, signals.\n\nHere are 14 charts that illustrate how uncertainty has unfolded in the economy and markets over the last year, and how it might affect the next.\n\nPresident Trump’s trade war has been one of the biggest sources of economic uncertainty this year. During his campaign, Trump repeatedly cited tariffs as a way to spur American manufacturing, create new jobs and lower U.S. trade deficits.\n\nNearly every country has seen import duties rise.\n\nThe tariffs have made progress toward some of the administration’s stated goals: They have brought the trade deficit down, as exports grew more than imports.\n\nAnd they have made money: Tariff revenues are now at record highs.\n\nBut there is another kind of deficit on investors’ minds: the federal budget deficit. Tariff revenues remain a small share of total government revenues.\n\nHere’s another way in which the effects of tariffs are showing up: higher prices for goods.\n\nConsumer prices started to accelerate in June, and the prices of products most exposed to tariffs notched some of the highest gains.\n\nAnd in recent months, prices for goods continued to rise, contributing more to inflation.\n\nInflation unexpectedly slowed to 2.7 percent in November, according to data released by the Bureau of Labor Statistics this week. But economists have advised taking this data with a grain of salt, because of disruptions in the bureau’s data collection efforts during the 43-day federal government shutdown.\n\nIt’s still unclear whether tariffs will cause just a temporary increase in prices or if they will feed into more persistent inflation.\n\nAt this month’s DealBook Summit, Treasury Secretary Scott Bessent pushed back against the notion that tariffs had contributed to inflation, saying that they had caused a “one-time price adjustment,” not a “generalized price increase.”\n\nThe chair of the Federal Reserve, Jerome H. Powell, has also said that the Fed expected tariffs to cause a “one-time shift in the price level.” But he has stressed that the increase could be drawn out over several quarters. And at a news conference after last week’s Fed meeting he acknowledged the risk of tariff inflation becoming “more and more persistent.”\n\nIn the first full jobs report since the federal shutdown, the B.L.S. reported that the unemployment rate rose to 4.6 percent last month, a four-year high. Wage growth slowed to its lowest level since 2021. As with inflation, the shutdown affected the data collection for these measures, and the agency said ahead of the release that its estimates of the unemployment rate and other measures would be subject to more uncertainty than usual.\n\nThe average job gain over the last three months\n\nThe average job gain over the last three months\n\nThere was a silver lining: Employers added 64,000 jobs in November, driven largely by gains in the health care sector. But that only partly offset a decline in October.\n\nThe federal government shed 168,000 jobs in October and November, as workers who accepted the Trump administration’s “deferred resignation” offer came off the payroll.\n\nAnd the jobs numbers do not reflect a big downward revision that is expected early next year.\n\n(Revisions to jobs figures are commonplace, but they dominated headlines earlier this year when downward adjustments led Trump to fire the commissioner of the B.L.S., Erika McEntarfer, claiming, without evidence, that the data was “rigged.”)\n\nThe lowest-paid workers have felt the strain of the cooling labor market the most. As the economy started to recover from the pandemic, demand for labor far outstripped supply in the lowest-paid industries, such as leisure and hospitality.\n\nToday, that is no longer the case, and hourly wages are rising most slowly for the lowest earners.\n\nLast year, voters consistently told pollsters that they trusted Donald Trump over Joe Biden and later, Kamala Harris, to do a better job on the economy.\n\nNow, Trump is the one feeling the pressure, as views of his handling of the economy have soured since the summer.\n\nThe risks posed by inflation and a softening labor market have also put the Fed in a tough position. Last week, the central bank decided to cut interest rates by a quarter of a percentage point for a third meeting in a row. But the decision was highly contentious, with three of 12 policymakers voting against it.\n\nPowell said he could have made the case either way for the Fed to cut interest rates or pause reductions, given the competing risks to unemployment and inflation.\n\n“You’ve got one tool,” he said. “You can’t do two things at once.”\n\nTrump, for his part, has made no secret of his desire for lower rates. Next year, he will select a new Fed chair.\n\nAfter a dip earlier this year, most notably amid the chaotic “Liberation Day” tariff rollout, the stock market has, on the whole, kept on going up. The S&P 500 reached a record high just last week, for the 37th time this year.\n\nArguably, company earnings, and their expectations for earnings are the most important factor driving the market movements.\n\nIn fact, earnings expectations have moved in tandem with the S&P 500 price index over the course of this year (again, with the exception of the early months of the year).\n\nOf course, the S&P 500 is driven in large part by big tech companies, which are intertwined with the A.I. boom.\n\nThat has been cause for concern for some investors, who see a parallel between this moment and the dot-com bubble of the late 1990s and early 2000s. But unlike companies leading the stock rally during the dot-com bubble, the public companies with the steepest valuation gains today are earning more as the market goes up.\n\nThe outlook for earnings continues to be bullish in 2026, though there could be weak links in the A.I. chain.\n\nThe crypto boom that Trump’s re-election ushered in is on pause for now.\n\nAfter surging for most of the year, the price of Bitcoin and Ether, along with dozens of other coins, started to plummet on Oct. 10, following Trump’s announcement that he would impose a new tariff on China.\n\n(The stock market on that day also saw the biggest one-day plunge since April, though it has since rebounded and hit a record high.)\n\nFor some, the crypto sell-off has underscored the fact that crypto remains a volatile investment, even as it has entered a new level of mainstream acceptance. Amid a high-stakes lobbying campaign by the crypto industry, Trump ended a regulatory crackdown on crypto and signed legislation outlining the first federal rules for stablecoins, digital tokens tied to assets like the U.S. dollar.\n\nOthers worry that a crypto crash could bleed over to the wider market.\n\nAmid all this uncertainty, people might be looking to pop culture as a form of escape. They haven’t necessarily been finding it at the movies, if ticket sales are any indication.\n\nSummer is a crucial season for Hollywood, accounting for the lion’s share of annual box office revenue. This year, fantasies, science-fiction sequels and superhero flicks were on offer. But moviegoers, for the most part, didn’t bite: It was the worst summer for domestic ticket sales since 1981, after adjusting for inflation and excluding the pandemic years.\n\nThe fall was filled with star-studded flicks, but none of them constituted box office hits.\n\nCan the holiday season help Hollywood make a comeback? “Zootopia 2” and “Wicked: For Good” have gotten it off to a good start.\n\nBut broader concerns abound. Warner Bros. Discovery has struck a deal with Netflix for the Warner Bros. studio and its sibling streaming service, HBO Max, while it has fended off, for the time being, a hostile takeover offer from Paramount.\n\nRegardless of how it all ends, it feels like a moment of loss for cinephiles. Corporate consolidation, after all, is not likely to bode well for the future of the Silver Screen.",
    "readingTime": 7,
    "keywords": [
      "cut interest",
      "dot-com bubble",
      "ticket sales",
      "unemployment rate",
      "average job",
      "job gain",
      "interest rates",
      "tariff revenues",
      "stock market",
      "labor market"
    ],
    "qualityScore": 1,
    "link": "https://www.nytimes.com/2025/12/20/business/dealbook/charts-2025-economy.html",
    "thumbnail_url": "https://static01.nyt.com/images/2025/12/19/business/00db-charts/00db-charts-facebookJumbo.jpg",
    "created_at": "2025-12-27T06:18:02.601Z",
    "topic": "business"
  },
  {
    "slug": "genai-experts-replace-halo-evolved-staff-to-impact-xbox-game-development",
    "title": "GenAI experts replace 'Halo: Evolved' staff to impact Xbox game development",
    "description": "A shakeup at an Xbox Game Studio suggests that AI will play a major role in Halo games like Campaign Evolved. The new Chief of Staff stresses enhancing workflows with machine learning on her resume. Other employees could use AI tools creatively rather than to improve efficiency.",
    "fullText": "Halo Studios has undergone dramatic changes in recent months, amid a turbulent 2025 for Xbox games. Rebs Gaming has been tracking new hires who all share experience with AI tools. With an AI consultant replacing Melissa Boone as Chief of Staff, the technology looks poised to infiltrate game development.\n\nScanning LinkedIn and job listings, the YouTuber noticed a familiar pattern. The most significant recent change was the arrival of Angela Hession at Halo Studios. The new Chief of Staff previously led the Gaming Safety and Trust team at Microsoft. However, she also founded a company specializing in AI-driven productivity enhancement.\n\nAnother new job ad at Xbox Game Studios seeks an Applied Scientist focused on machine learning. Not only would the employee work on Halo games, but also on other Microsoft franchises like Forza and Gears of War. Several current Halo developers in key roles have added qualifications related to generative AI.\n\nHow studios will employ artificial intelligence has become a point of controversy. Many companies argue that it’s a resource that boosts the output of developers. Yet, critics worry that human artists will lose creative control and, ultimately, their jobs.\n\nPerhaps the best indication of how Halo Studios will employ the tools came from a 2024 job posting. The studio was searching for a Senior AI Engineer to “leverage generative AI and ML to augment in-game experiences and to improve how we make games.” The description implied that the technology will aid more than rudimentary office tasks.\n\nRebs Gaming stresses the distinction between AI as a tool vs an author. Either way, it wouldn’t be surprising if Halo: Campaign Evolved or a follow-up title ushers in a new era of development. Microsoft has fully embraced artificial intelligence, building hundreds of data centers. Some analysts have attributed the closure of other Xbox Game Studios to that monumental investment.\n\nRebs Gaming YouTube, Microsoft Careers, Rebs Gaming X account",
    "readingTime": 2,
    "keywords": [
      "xbox game",
      "game studios",
      "artificial intelligence",
      "chief of staff",
      "halo studios",
      "rebs gaming",
      "games",
      "tools",
      "technology",
      "development"
    ],
    "qualityScore": 0.95,
    "link": "https://www.notebookcheck.net/Generative-AI-experts-replace-Halo-Campaign-Evolved-staff-to-impact-Xbox-game-development.1192829.0.html",
    "thumbnail_url": "https://www.notebookcheck.net/fileadmin/Notebooks/News/_nc5/HaloCampaignEvolvedBanner.jpg",
    "created_at": "2025-12-27T06:18:02.325Z",
    "topic": "gaming"
  },
  {
    "slug": "what-will-ai-flip-into",
    "title": "What Will AI Flip Into?",
    "description": "Hello and welcome to the newsletter, a grab bag of daily content from the Odd Lots universe. Sometimes it's us, Joe Weisenthal and Tracy Alloway, bringing you our thoughts on the most recent developments in markets, finance and the economy. And sometimes it's contributions from our network of expert guests and sources. Whatever it is, we promise it will always be interesting.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-26/what-will-ai-flip-into",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iuTaH0oGGJIo/v0/1200x800.jpg",
    "created_at": "2025-12-27T00:55:10.464Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-end-near-record-high-as-nvidia-gains-on-ai-licensing-deal",
    "title": "Stocks End Near Record High as Nvidia Gains on AI Licensing Deal",
    "description": "US stocks wavered near a record high in thin holiday trading as investors shifted attention to a relentless rally in commodities. Nvidia Corp. climbed as analysts viewed a licensing deal with artificial intelligence startup Groq positively.",
    "fullText": "MarketsBy Natalia Kniazhevich and Felice MaranzSaveUS stocks wavered near a record high in thin holiday trading as investors shifted attention to a relentless rally in commodities. Nvidia Corp. climbed as analysts viewed a licensing deal with artificial intelligence startup Groq positively.The S&P 500 finished little changed and the Nasdaq 100 fell 0.1%. Among S&P 500 sectors, materials and tech led gains, while consumer discretionary and energy retreated.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-26/stocks-touch-record-as-nvidia-gains-on-ai-licensing-deal",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iF.s6X.J0a_g/v1/1200x800.jpg",
    "created_at": "2025-12-27T00:55:08.384Z",
    "topic": "finance"
  },
  {
    "slug": "forwardtoaudio-turn-newsletters-into-a-private-podcast-using-ai",
    "title": "ForwardToAudio – Turn newsletters into a private podcast using AI",
    "description": "Turn long emails into a private podcast. Forward emails to your private address and listen to them in your favorite podcast player.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://forwardtoaudio.com",
    "thumbnail_url": "https://saa-s-audio-dashboard--stjohnbryan.replit.app/opengraph.jpg",
    "created_at": "2025-12-27T00:55:03.011Z",
    "topic": "tech"
  },
  {
    "slug": "these-13-creator-economy-startups-pulled-in-about-2-billion-in-funding-this-year",
    "title": "These 13 creator economy startups pulled in about $2 billion in funding this year",
    "description": "From live shopping startup Whatnot to AI music platform Suno, meet the creator economy startups that raised massive deals in 2025.",
    "fullText": "The creator economy is riding an AI-fueled high.\n\nIn 2025, eight startups building artificial intelligence tools to automate the content creation process each announced at least $50 million in funding — a combined $1.2 billion — from venture capital and private equity investors.\n\nSynthesia, a generative AI video startup based in London, confirmed its $180 million funding round in January, while ElevenLabs, a text-to-voice startup, closed a $180 million Series C round. Other AI startups, like Moonvalley, Krea, and Higgsfield, also announced sizable investments this year.\n\nWhile AI is dominating investor interest, the topic still carries friction within the creator economy. Some of these AI startups, which offer features such as human-like avatars, run the risk of posing a threat to content creators themselves. Influencer marketing, still the primary financial engine of the creator economy, has yet to reach a consensus on how and when AI should be utilized.\n\nTop creators aren't sitting by idly for AI to take over. YouTuber MrBeast and his team initially sought to raise $200 million earlier this year at a $5 billion valuation, according to investor materials viewed by Business Insider. The MrBeast team declined to comment on the fundraise.\n\nIt's not just AI that's attracting giant checks from VCs.\n\nSocial commerce startups building live shopping and affiliate marketing platforms are also raking in funding. Whatnot, a platform where people sell on stream in categories like fashion and collectibles, such as Pokémon Cards or Labubus, raised a total of $490 million across two later-stage rounds this year. The social shopping platform was most recently valued at $11.5 billion.\n\nMeanwhile, ShopMy, an affiliate marketing platform, continues to gain market share in the influencer marketing space. The startup raised a total of $147.5 million in funding this year.\n\nUS social commerce sales are expected to cross $100 billion next year, according to estimates from EMARKETER, Business Insider's sister company. The category is gaining steam in the US, fueled in part by the growth of TikTok Shop.\n\nThis year's fundraising blitz for creator AI and social commerce startups follows similar buzz for the categories in 2024 when investors threw money at startups like Captions, Flip, and OpusClip. Several startups in those business areas, including ElevenLabs and ShopMy, raised money two years in a row.\n\nBusiness Insider analyzed 2025 fundraising data from PitchBook and other industry sources to highlight the biggest creator industry investment rounds from the year. We're highlighting 13 startups that raised $50 million or more in 2025; combined, their funding crossed $1.9 billion. We focused on companies whose products significantly impact the businesses and content creation processes of creators and their partners.\n\nHere are 13 creator economy startups that raised some of the largest rounds in 2025, in alphabetical order:",
    "readingTime": 3,
    "keywords": [
      "content creation",
      "influencer marketing",
      "social commerce",
      "affiliate marketing",
      "creator economy",
      "commerce startups",
      "funding",
      "creators",
      "platform",
      "rounds"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/creator-economy-investments-ai-social-commerce-whatnnot-synthesia-shopmy-suno-2025-12",
    "thumbnail_url": "https://i.insider.com/6949c59e832e0ef1ead6b4d6?width=1200&format=jpeg",
    "created_at": "2025-12-27T00:54:56.757Z",
    "topic": "finance"
  },
  {
    "slug": "artificial-stupidity-made-ai-trading-bots-spontaneously-form-cartels-when-left-unsupervised-wharton-study-reveals",
    "title": "‘Artificial stupidity’ made AI trading bots spontaneously form cartels when left unsupervised, Wharton study reveals",
    "description": "AI bots told to act as trading agents in simulated markets engaged in pervasive collusion, raising new questions about how financial regulators have previously addressed this tech.",
    "fullText": "Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune, covering retail and the intersection of business and popular culture.\n\nArtificial intelligence is just smart—and stupid—enough to pervasively form price-fixing cartels in financial market conditions if left to their own devices.\n\nA working paper posted earlier this year on the National Bureau of Economic Research website from the Wharton School at the University of Pennsylvania and Hong Kong University of Science and Technology found when AI-powered trading agents were released into simulated markets, the bots colluded with one another, engaging in price fixing to make a collective profit.\n\nIn the study, researchers let bots loose in market models, essentially a computer program designed to simulate real market conditions and train AI to interpret market-pricing data, with virtual market makers setting prices based on different variables in the model. These markets can have various levels of “noise,” referring to the amount of conflicting information and price fluctuation in the various market contexts. While some bots were trained to behave like retail investors and others like hedge funds, in many cases, the machines engaged in “pervasive” price-fixing behaviors by collectively refusing to trade aggressively—without being explicitly told to do so.\n\nIn one algorithmic model looking at price-trigger strategy, AI agents traded conservatively on signals until a large enough market swing triggered them to trade very aggressively. The bots, trained through reinforcement learning, were sophisticated enough to implicitly understand that widespread aggressive trading could create more market volatility.\n\nIn another model, AI bots had over-pruned biases and were trained to internalize that if any risky trade led to a negative outcome, they should not pursue that strategy again. The bots traded conservatively in a “dogmatic” manner, even when more aggressive trades were seen as more profitable, collectively acting in a way the study called “artificial stupidity.”\n\n“In both mechanisms, they basically converge to this pattern where they are not acting aggressively, and in the long run, it’s good for them,” study co-author and Wharton finance professor Itay Goldstein told Fortune.\n\nFinancial regulators have long worked to address anti-competitive practices like collusion and price fixing in markets. But in retail, AI has taken the spotlight, particularly as companies using algorithmic pricing come under scrutiny. This month, Instacart, which uses AI-powered pricing tools, announced it will end its program where some customers saw different prices for the same item on the delivery company’s platform. It follows a Consumer Reports analysis found in an experiment that Instacart offered nearly 75% of its grocery items at multiple prices.\n\n“For the [Securities and Exchange Commission] and those regulators in financial markets, their primary goal is to not only preserve this kind of stability, but also ensure competitiveness of the market and market efficiency,” Winston Wei Dou, Wharton professor of finance and one of the study’s authors, told Fortune.\n\nWith that in mind, Dou and two colleagues set out to identify how AI would behave in a financial market by putting trading agent bots into various simulated markets based on high or low levels of “noise.” The bots ultimately earned “supra-competitive profits” by collectively and spontaneously deciding to avoid aggressive trading behaviors.\n\n“They just believed sub-optimal trading behavior as optimal,” Dou said. “But it turns out, if all the machines in the environment are trading in a ‘sub-optimal’ way, actually everyone can make profits because they don’t want to take advantage of each other.”\n\nSimply put, the bots didn’t question their conservative trading behaviors because they were all making money and therefore stopped engaging in competitive behaviors with one another, forming de-facto cartels.\n\nWith the ability to increase consumer inclusion in financial markets and save investors time and money on advisory services, AI tools for financial services, like trading agent bots, have become increasingly appealing. Nearly one-third of U.S. investors said they felt comfortable accepting financial planning advice from a generative AI-powered tool, according to a 2023 survey from financial planning nonprofit CFP Board. A report published in July from cryptocurrency exchange MEXC found that among 78,000 Gen Z users, 67% of those traders activated at least one AI-powered trading bot in the previous fiscal quarter.\n\nBut for all their benefits, AI trading agents aren’t without risks, according to Michael Clements, director of financial markets and community at the Government Accountability Office (GAO). Beyond cybersecurity concerns and potentially biased decision-making, these trading bots can have a real impact on markets.\n\n“A lot of AI models are trained on the same data,” Clements told Fortune. “If there is consolidation within AI so there’s only a few major providers of these platforms, you could get herding behavior—that large numbers of individuals and entities are buying at the same time or selling at the same time, which can cause some price dislocations.”\n\nJonathan Hall, an external official on the Bank of England’s Financial Policy Committee, warned last year of AI bots encouraging this “herd-like behavior” that could weaken the resilience of markets. He advocated for a “kill switch” for the technology, as well as increased human oversight.\n\nClements explained many financial regulators have so far been able to apply well-established rules and statutes to AI, saying for example, “Whether a lending decision is made with AI or with a paper and pencil, rules still apply equally.”\n\nSome agencies, such as the SEC, are even opting to fight fire with fire, developing AI tools to detect anomalous trading behaviors.\n\n“On the one hand, you might have an environment where AI is causing anomalous trading,” Clements said. “On the other hand, you would have the regulators in a little better position to be able to detect it as well.”\n\nAccording to Dou and Goldstein, regulators have expressed interest in their research, which the authors said has helped expose gaps in current regulation around AI in financial services. When regulators have previously looked for instances of collusion, they’ve looked for evidence of communication between individuals, with the belief that humans can’t really sustain price-fixing behaviors unless they’re corresponding with one another. But in Dou and Goldstein’s study, the bots had no explicit forms of communication.\n\n“With the machines, when you have reinforcement learning algorithms, it really doesn’t apply, because they’re clearly not communicating or coordinating,” Goldstein said. “We coded them and programmed them, and we know exactly what’s going into the code, and there is nothing there that is talking explicitly about collusion. Yet they learn over time that this is the way to move forward.”\n\nThe differences in how human and bot traders communicate behind the scenes is one of the “most fundamental issues” where regulators can learn to adapt to rapidly developing AI technologies, Goldstein argued.\n\n“If you use it to think about collusion as emerging as a result of communication and coordination,” he said, “this is clearly not the way to think about it when you’re dealing with algorithms.”\n\nA version of this story was published on Fortune.com on August 1, 2025.",
    "readingTime": 6,
    "keywords": [
      "traded conservatively",
      "reinforcement learning",
      "ai-powered trading",
      "simulated markets",
      "price-fixing behaviors",
      "market conditions",
      "financial planning",
      "trading agent",
      "agent bots",
      "anomalous trading"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/what-is-artificial-stupidity-ai-pricing-collusion-study/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/07/GettyImages-2227723433_eab441-e1753994704738.jpg?resize=1200,600",
    "created_at": "2025-12-26T18:17:06.585Z",
    "topic": "science"
  },
  {
    "slug": "the-most-popular-hbr-podcast-episodes-of-2025",
    "title": "The Most Popular HBR Podcast Episodes of 2025",
    "description": "Topping HBR’s audio charts this past year were discussions on how to be a better conversationalist, boosting productivity through timeboxing and gen AI tools, managing up, encouraging upskilling, executive presence, and strategy execution. If one theme stood out, it was continuous self-improvement.",
    "fullText": "The Most Popular HBR Podcast Episodes of 2025 by Alison BeardDecember 26, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWith the start of a new year, thoughts turn to self-improvement: exercising and eating right, exploring new hobbies, building skills and seizing opportunities at work.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2025/12/the-most-popular-hbr-podcast-episodes-of-2025",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec26_17_2202353837.jpg",
    "created_at": "2025-12-26T18:17:04.917Z",
    "topic": "business"
  },
  {
    "slug": "stegcore-a-decision-boundary-for-ai-systems-truth-permission",
    "title": "StegCore – a decision boundary for AI systems (truth ≠ permission)",
    "description": "Core of StegVerse dev. Contribute to StegVerse-Labs/StegCore development by creating an account on GitHub.",
    "fullText": "StegVerse-Labs\n\n /\n\n StegCore\n\n Public\n\n Core of StegVerse dev.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n StegVerse-Labs/StegCore",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/StegVerse-Labs/StegCore",
    "thumbnail_url": "https://opengraph.githubassets.com/894227cb38195792c6941e37db2785a607b1f5ef62d3a203814e866bc432524e/StegVerse-Labs/StegCore",
    "created_at": "2025-12-26T18:17:03.195Z",
    "topic": "tech"
  },
  {
    "slug": "best-ai-server-stocks-poised-to-dominate-in-2026-according-to-warrenai",
    "title": "Best AI Server Stocks Poised to Dominate in 2026, According to WarrenAI",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/best-ai-server-stocks-poised-to-dominate-in-2026-according-to-warrenai-93CH-4423187",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXNPEB6R0AQ_M.jpg",
    "created_at": "2025-12-26T18:17:03.141Z",
    "topic": "finance"
  },
  {
    "slug": "the-ai-reality-check-deconstructing-the-2025-stack-overflow-developer-survey",
    "title": "The AI Reality Check: Deconstructing the 2025 Stack Overflow Developer Survey",
    "description": "Building scalable, high-performance web applications with clean, maintainable code. Expertise in MERN stack, API integrations, and DevOps.",
    "fullText": "The 2025 Stack Overflow Developer Survey has landed. With data harvested from nearly 49,000 professional developers, we finally have a statistical answer to the industry's existential dread: \"Is AI coming for my paycheck?\"\n\nThe short answer? No.\nThe long answer? It’s complicated.\n\nThis isn't just a list of numbers. This is a forensic analysis of the developer ecosystem in the post-GPT era. We are tracking the rise of the \"Architect,\" the fall of legacy databases, and the emergence of a new \"Trust Paradox\" in AI adoption.\n\nWe are witnessing a fascinating divergence in the data. We call it the Trust Paradox.\n\nWhy the drop in sentiment? The industry has collectively realized that current AI models function less like a \"Superintelligence\" and more like an overconfident Junior Developer.\n\nThe Verdict: AI has shifted from a \"magic wand\" to a \"productivity engine.\" It requires heavy supervision. The seniors are spending less time writing boilerplate, but more time code-reviewing the AI's output.\n\nWhen ChatGPT launched, the internet was flooded with demos of \"Flappy Bird in 30 seconds.\" But enterprise software isn't Flappy Bird.\n\nThe survey asked a critical question: Can AI handle complex tasks?\n\nThere is a massive delta between \"generating a React component\" and \"architecting a distributed microservices system.\"\n\nInsight: Developers are smart. They trust AI to explain a regex, but they refuse to let it touch the production keys. The \"Human in the Loop\" is not going away; it is becoming the premium safeguard.\n\nThe 2025 data settles several long-standing debates. The leaderboard has shifted.\n\nPython saw a 7% surge in popularity. This is not because web development suddenly got better in Python; it is purely the \"AI Dividend.\" Python is the API for the AI revolution. If you are building with LLMs, you are likely writing Python.\n\nDespite the noise, Java and C# remain immovable objects, holding a steady 30% market share. They are the COBOL of the 21st century—too big to fail, too critical to replace.\n\nThe database war is effectively over.\n\nWhy the shift? The community has consolidated around Postgres as the default for everything. It handles relational data, JSON (better than Mongo in many cases), and vectors (pgvector). Meanwhile, MySQL's stewardship under Oracle continues to drive developers away.\n\nPro Tip: If you are starting a project in 2026 and you aren't choosing Postgres, you need a very, very specific reason.\n\nHere is the most actionable signal for your career: The \"Architect\" role is exploding.\n\nAs AI commoditizes low-level coding (syntax generation), the value line is moving up the stack. Companies need fewer \"coders\" and more \"system designers.\"\n\nAction Item: Stop obsessing over syntax. Start obsessing over System Design. Learn how to scale. Learn how to design fault-tolerant systems. That is where the money is going.\n\nLet's address the fear.\nQuestion: \"Is AI a threat to your job?\"\nAnswer: 63.6% say NO.\n\nWhile this is a majority, it is down from 68% last year. The anxiety is creeping up. But here is the nuance:\n\nAI is not replacing developers.\nDevelopers using AI are replacing developers who don't.\n\nThe \"Prompt Engineers\" who lack foundational knowledge are in danger. The software engineers who use AI to accelerate their workflow are thriving.\n\nThe data from 49,000 peers is clear. The industry isn't dying; it's mutating.\n\nThe job market is broken for the mediocre, but it has never been better for the experts.",
    "readingTime": 3,
    "keywords": [
      "replacing developers",
      "isn't",
      "stack",
      "survey",
      "industry",
      "less",
      "shifted",
      "software",
      "critical",
      "away"
    ],
    "qualityScore": 1,
    "link": "https://nitinahirwal.in/posts/Stack-Overflow-Survey-2025",
    "thumbnail_url": "https://nitinahirwal.in/images/ss.png",
    "created_at": "2025-12-26T18:17:02.879Z",
    "topic": "tech"
  },
  {
    "slug": "republican-lawmaker-shredded-for-posting-ai-images-of-himself-beating-up-santa-on-christmas-morning",
    "title": "Republican lawmaker shredded for posting AI images of himself beating up Santa on Christmas morning",
    "description": "Indiana state Sen. Chris Garten acknowledged the backlash and labeled his critics ‘snowflakes’",
    "fullText": "A Republican lawmaker raised eyebrows after posting AI-generated images on Christmas Day that depicted him beating up Santa Claus.\n\nIndiana state Sen. Chris Garten’s post on the morning of December 25, where he was pictured body-slamming Santa in front of the state capitol building, did not go down well with his followers on social media.\n\n“When you find out the North Pole is trying to bring more bureaucratic overreach & unfunded mandates down the chimney disguised as “Christmas cheer.” Not on my watch,” the Republican posted on his X account Thursday morning.\n\n“We The People run Indiana, not the bureaucrats,” he added. “Take it back to the North Pole big guy.”\n\nIn one of the AI-generated pictures, Garten kicked Santa down the steps of the state capitol building, while in another, he hoisted his fist above St. Nick’s head as he was pinned to the ground.\n\nThe comments underneath the post were overwhelmingly disapproving.\n\n“This may be the most pitiful thing I’ve seen this Xmas. Congratulations,” one person reacted on X.\n\n“Ah, yes, the left is the party of violence. *body slams Santa Claus*,” said another.\n\n“What on earth would compel a person to post images of them beating up a universally beloved figure?” someone else chimed in.\n\n“So warming to see the symbol of Christmas generosity and cheer get beaten to a bloody pulp!” another person wrote.\n\nThe Independent has contacted Garten’s representative for comment.\n\nA few hours after posting, Garten acknowledged the backlash in a follow-up message where he labeled his critics “snowflakes.”\n\n“Lots of intolerance, swearing, and outrage on display over a few AI pics I had a blast designing with my kids,” Garten said. “Some of you clowns are just insufferable. Hopefully your negativity stays in the comments and not directed at your families.”\n\n“Merry Christmas, snowflakes!” he added.\n\nOther notable festive messages from Republicans featured one from President Donald Trump, who shared a bizarre Truth Social post on Christmas Day about the late sex offender Jeffrey Epstein, whose case continues to haunt the administration.\n\nThe president said in a Christmas message that he dropped ties with the late sex offender “long before it became fashionable,” and that the controversy surrounding the release of the Epstein files is a “Radical Left Witch Hunt.”",
    "readingTime": 2,
    "keywords": [
      "sex offender",
      "christmas day",
      "north pole",
      "another",
      "republican",
      "posting",
      "ai-generated",
      "images",
      "beating",
      "morning"
    ],
    "qualityScore": 1,
    "link": "https://www.yahoo.com/news/articles/republican-lawmaker-shredded-posting-ai-162929278.html",
    "thumbnail_url": "https://media.zenfs.com/en/the_independent_635/752df9c2e348269662ea6b8894d6e68f",
    "created_at": "2025-12-26T18:17:00.636Z",
    "topic": "news"
  },
  {
    "slug": "takaichi-ai-corporate-reform-pave-way-for-japan-stocks-in-2026",
    "title": "Takaichi, AI, Corporate Reform Pave Way for Japan Stocks in 2026",
    "description": "Japan’s stocks are expected to extend gains in 2026, with Prime Minister Sanae Takaichi’s aggressive fiscal plans building on the momentum of the past year.",
    "fullText": "MarketsBy Alice French and Eru IshikawaSaveJapan’s stocks are expected to extend gains in 2026, with Prime Minister Sanae Takaichi’s aggressive fiscal plans building on the momentum of the past year.Tokyo’s benchmark Topix index has weathered tariff shocks, two Bank of Japan rate hikes and a change of prime minister to gain about 23% this year, putting it on track for its biggest outperformance versus the S&P 500 since 2022. The rally — which led Japan’s benchmarks to multiple record highs — has laid the foundations for further gains, strategists say.",
    "readingTime": 1,
    "keywords": [
      "prime minister",
      "gains"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-25/takaichi-ai-corporate-reform-pave-way-for-japan-stocks-in-2026",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3trQWQBsbNU/v0/1200x800.jpg",
    "created_at": "2025-12-26T12:22:29.673Z",
    "topic": "finance"
  },
  {
    "slug": "green-debt-sales-hit-record-levels-despite-climate-backlash",
    "title": "Green Debt Sales Hit Record Levels Despite Climate Backlash",
    "description": "Investors have piled into climate-friendly assets this year despite policy and regulatory rollbacks in the US and Europe, as artificial intelligence drives a boom in energy infrastructure demand.",
    "fullText": "GreenBy Ishika MookerjeeSaveInvestors have piled into climate-friendly assets this year despite policy and regulatory rollbacks in the US and Europe, as artificial intelligence drives a boom in energy infrastructure demand.Global green bond and loan issuance has reached a record $947 billion so far this year, according to data compiled by Bloomberg Intelligence. That’s as stock market gauges for renewables are set for their first annual gains since 2020, outperforming the S&P 500 by a wide margin, while shares of power-grid technology companies remain in favor.",
    "readingTime": 1,
    "keywords": [
      "intelligence"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-25/green-debt-sales-hit-record-levels-despite-climate-backlash",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/itymJf7GXh6A/v0/1200x799.jpg",
    "created_at": "2025-12-26T12:22:29.330Z",
    "topic": "finance"
  },
  {
    "slug": "ai-writing-agent-that-flags-unsupported-claims-for-review",
    "title": "AI writing agent that flags unsupported claims for review",
    "description": "Write high-quality reviews, listicles, and how-to guides in 13 languages—powered by trust signals and grounded research.",
    "fullText": "No hallucinations. No hours of research. No AI slop.\n\nProofWrite blends keyword research, automated product research, trust-signal analysis, and AI writing to create factual, humanized articles that rank. Every insight is grounded in real proof.\n\nProduct review, listicle, how-to, comparison, or freeform. Keyword research surfaces winning terms and sets coverage targets.\n\nAutomated research from official and authoritative sources. Trust signals, ratings, and citations pulled from platforms like Trustpilot, Capterra and Reddit.\n\nSEO, AEO & GEO-optimized copy backed by citations. Choose Claude, GPT, or Gemini. Every claim tied to research.\n\nPush to WordPress or export anywhere. Fully editable drafts with keyword coverage guidance with SEO, AEO and GEO metrics before publishing.\n\nProofWrite is designed for teams and creators who need accurate, SEO-optimized content at scale.\n\nScale product reviews, comparisons, and listicles with real specs, pricing, and trust signals that convert.\n\nProduce research-backed how-to guides and product content 10x faster without sacrificing quality.\n\nDeliver optimized, fact-checked content to clients with built-in keyword coverage and scoring.\n\nMeet E-E-A-T standards with automated trust signals, citations, and verified research in every article.\n\nProofWrite scores every outline across the pillars that move rankings: keyword coverage, structure, media, and more. Each edit triggers a fresh calculation so you know exactly what to improve before you publish.\n\nScore updates in real time as you refine keywords, images, and structure.\n\nCoverage, structure, and media breakdowns show exactly what needs work.\n\nMedia gaps, thin sections, or missing H2s surface instantly for quick fixes.\n\nThe only tool that optimizes content for AI search engines and LLM citations.\n\nRe-scored on every edit you make\n\nQuestion headings, source citations, and quotable claims.\n\nEvery claim in your article gets a verdict. For claims that need attention, choose from three instant actions: verify manually, add a source URL, or let AI rewrite it.\n\nMark claims as reviewed when you've confirmed the facts yourself with one-click verify feature.\n\nPaste a URL and the system extracts supporting evidence automatically.\n\nAI rewrites the claim to make it factual.\n\n“Notion's Business plan costs $15 per user per month”\n\nPricing, features, ratings, and policy claims are verified against your research data.\n\nEnter any article URL and target keyword to get an instant SEO, AEO & GEO analysis. See how well your content is optimized for search engines and AI.\n\nToggle between the input brief and the final article to see how ProofWrite threads research, trust signals, and structure into a cohesive narrative. No AI slop, no hallucinations, no em dashes just high-quality content in a single shot. More writing examples can be found in our blog.\n\nYou have an idea. It keeps you up at night, a software solution that seems perfect. The urge to open your laptop and start building immediately is overwhelming. You can already see the dashboard, the features, and the user interface in your mind.\n\nWhen you first dip your toes into the world of SaaS (Software as a Service), it is easy to make the \"classic mistake\" identified by seasoned developers on Indie Hackers: spending months building a tool before figuring out if anyone actually wants it. The result? You launch to silence. You spent time and energy solving a problem that perhaps didn't exist, or at least not in the way you thought it did.\n\nThe landscape of digital entrepreneurship has changed. You no longer need a computer science degree or a venture capital injection to start. As noted by the community at r/BuildToShip, the modern approach is about shipping fast, learning in public, and turning ideas into real products through lean validation.\n\nThis guide is your blueprint for launching a Micro-SaaS, a small, niche-focused software business run by one person or a tiny team. We will walk through the process of validating your idea in as little as 48 hours with $0 upfront cost, utilizing no-code tools and AI-driven automation to minimize risk and maximize impact.\n\nBefore you worry about tech stacks, logos, or LLCs, you must answer one question: Will people pay for this?\n\nMany aspiring founders believe building SaaS is about passion and code. However, insights from the \"Income AIcademy\" suggest that this mindset is a fast track to nowhere. The real process involves validating demand before the product exists.\n\nThe era of broad, horizontal software (like generic project management tools) is dominated by giants. Your opportunity lies in the \"Micro.\"\n\nAccording to trends for 2025 highlighted by Sidetool, profitable Micro-SaaS opportunities are unlocked by focusing on niche markets. You aren't trying to serve everyone; you are trying to serve a very specific group of people with a very specific problem.\n\nNarrow your scope: Instead of \"accounting software,\" think \"expense tracking for freelance underwater photographers.\"\n\nLook for manual friction: Identify tasks that businesses are currently solving with messy Excel spreadsheets or endless email chains.\n\nLeverage AI trends: Consider how AI-driven automation can solve these specific problems faster or cheaper than a human could.\n\nCan you describe your target customer in one sentence? (e.g., \"Estate agents who struggle to schedule viewings.\")\n\nIs the problem painful enough that they are currently paying (money or time) to solve it poorly?\n\nYou might think you need a finished product to sell it. You don't. In fact, successful creators have validated microniche ideas in 48 hours without spending a dime. The goal here is to collect \"signals of interest\" rather than users.\n\nDraft a Value Proposition: Clearly articulate what problem you solve. Avoid technical jargon. Speak to the pain point.\n\nFind the Watering Holes: Go where your niche hangs out. This might be specific subreddits, Facebook groups, or LinkedIn communities.\n\nEngage, Don't Spam: Do not just drop a link. As advised by the r/BuildToShip community, the goal is to \"learn in public.\" Share your hypothesis. Ask questions like, \"I'm noticing [Problem X] is a huge time sink for [Niche Y]; how are you currently handling this?\"\n\nThe \"Smoke Test\": Create a simple landing page (using free tiers of site builders) or even a direct message script that describes the solution. Ask for an email address or a pre-order to get early access.\n\nWhy this matters: If you cannot find people to talk to about the problem, or if nobody is willing to give you their email address for a solution, you will not be able to sell the product later. Silence now saves you months of coding later.\n\nDo you have a list of 10–50 people who said, \"Yes, I need this\"?\n\nDid you complete this outreach within a 48-hour window to prevent procrastination?\n\nOnce, and only once, you have validated that real humans want your solution, you can start building. But you aren't writing code from scratch. You are using the \"No-Code\" approach to remain lean.\n\nKnack and similar platforms have popularized the idea that you can build robust applications without traditional programming. Your goal is to build a \"Minimum Viable Product\" (MVP), the simplest version of your tool that delivers the core value.\n\nDatabase: Start with where the data lives. In no-code tools, this often looks like a spreadsheet or a visual database.\n\nLogic/Automation: Use automation tools to connect different apps. For example, if your SaaS generates reports, set up a workflow that triggers when a user submits a form, processes the data via AI, and emails the PDF.\n\nInterface: Use a drag-and-drop builder to create the front end where users log in and interact with your data.\n\nPro Tip: Don't get hung up on scalability. You don't need a system that handles a million users. You need a system that handles your first 10 users perfectly.\n\nTo compete in 2025, your Micro-SaaS needs an edge. Sidetool suggests leveraging AI-driven automation to maximize impact.\n\nIdentify the \"Magic\" Moment: Where can AI save the user the most time? Is it writing text, analyzing data, or generating images?\n\nIntegrate via API: Most no-code platforms allow you to send data to AI models (like OpenAI's API) and receive a response.\n\nKeep a Human in the Loop: Ensure your users can review the AI's output. AI is powerful but can hallucinate; trust is built on reliability.\n\nDoes the product actually solve the core problem you validated in Phase 1?\n\nCan a user go from \"Sign Up\" to \"Problem Solved\" without your manual intervention?\n\nBuilding is comfortable. Shipping is scary. But as the r/BuildToShip hub emphasizes, you must be willing to ship fast and talk about growth.\n\nRemember those 50 people who gave you their email addresses in Step 2? They are your beta testers.\n\nPersonal Outreach: Email them personally. \"Hey, remember that tool we talked about? It's ready for you to try.\"\n\nGather Feedback: Your first version will have bugs. It will lack features. That is okay. Ask your early users, \"What is the one thing preventing you from loving this?\"\n\nCharge Money Early: Free users give polite feedback. Paying users give honest feedback. Even a small price tag ($5/month) validates that the problem is painful enough to pay for.\n\nOne of the strongest strategies for Micro-SaaS growth is transparency. The \"Build in Public\" movement encourages sharing your wins, losses, and revenue numbers.\n\nDocument the Journey: Share updates on social media or indie hacker communities. \"Today I fixed a bug that caused X\" or \"We just got our 10th subscriber!\"\n\nAsk for Help: Communities like r/BuildToShip exist to help you talk growth, tech, and tools. If you are stuck on a pricing model or a technical hurdle, ask the community.\n\nIterate Quickly: The advantage of being a \"Micro\" SaaS is speed. If users hate a feature, you can remove it today. If they need a new button, you can add it tonight. Large competitors cannot do that.\n\nHave you moved from \"Validation\" (interested people) to \"Traction\" (active users)?\n\nAre you actively engaging with a community of peers to keep your momentum up?\n\nEven with a lean plan, you will encounter hurdles. Here is how to navigate the common traps of the Micro-SaaS journey.\n\nThe Issue: You feel the product isn't \"ready\" because it lacks a dark mode, multiple language support, or a referral system. The Fix: Go back to your validation. Did your early users say they wouldn't buy without dark mode? Probably not. Build only what is necessary to solve the core pain point. As the research indicates, spending months building before validating is the classic mistake.\n\nThe Issue: Everyone says \"Great idea!\" but nobody buys. The Fix: Compliments are not validation. Cash is validation. If people say they love it but won't pull out a credit card, you haven't found a painful enough problem, or you are talking to the wrong audience. Revisit Step 1 and narrow your microniche further.\n\nThe Issue: Trying to do everything (marketing, support, dev) alone. The Fix: Utilize the automation tools mentioned in the research. If a task feels repetitive, automate it. Your energy should be spent on talking to users and improving the product, not manual data entry.\n\nQ: Do I really need $0 to start?\n\nA: Strictly speaking, validation costs $0. You can use free social media, free email accounts, and free tiers of landing page builders to gauge interest. Costs only accrue once you start hosting a live application or paying for advanced no-code subscriptions, at which point you should ideally have paying customers to cover those costs.\n\nQ: What if I don't have a technical background?\n\nA: That is the power of the current landscape. Between no-code platforms (like Knack) and AI assistance, the barrier to entry has lowered significantly. The skill you need is problem-solving, not necessarily syntax coding.\n\nQ: How do I know if my niche is \"micro\" enough?\n\nA: If you are competing directly with Google, Microsoft, or Salesforce, your niche is too broad. If you are serving a specific profession (e.g., \"Dentists\") with a specific problem (e.g., \"Patient recall SMS automation\"), you are in the right zone.\n\nQ: What if my idea fails validation?\n\nA: Then you have succeeded. You saved yourself months of development time. The 48-hour validation process is designed to fail fast so you can move on to your next idea without baggage.\n\nThe path to a profitable Micro-SaaS is not paved with complex code or massive venture capital checks. It is paved with conversations, empathy for user problems, and the courage to ship imperfect solutions.\n\nDon't let your idea stay an idea. Go find your niche, ask the hard questions, and ship your solution. The community at r/BuildToShip and the wider indie hacker world is waiting to see what you build.\n\nUnlike generic AI tools, ProofWrite is purpose-built for creating factual, research-backed content that ranks.\n\nStart creating research-backed content today\n\nChoose the plan that fits your content needs. Scale up as you grow.\n\nPlans include automated keyword & product research, trust signal analysis, and factual AI writing. Article and keyword limits reset monthly.\n\nNeed a custom plan? Contact us for enterprise pricing.\n\nEach brief pulls facts from official docs, verified reviews, and community discussions. ProofWrite keeps citations, trust signals, and keyword guidance inline so drafts never hallucinate data.\n\nProofWrite feeds the writer with verified research, trust signals, and any personal experiences you add. Tone and voice controls keep prose specific and conversational.\n\nProofWrite supports product reviews, best-of listicles, and step-by-step how-to guides. Each format has inputs, research crawl, and writing instructions tuned to the brief.\n\nArticles can be written in English, Spanish, French, German, Italian, Dutch, Portuguese, Danish, Norwegian, Finnish, Swedish, Romanian, or Polish.\n\nEdit inside the composer, then push to WordPress with one click or copy the article to your clipboard for other CMSes.\n\nYes. Set tone, POV, and personas, then add personal experiences and AI instructions. ProofWrite threads them through the draft so it reads like someone who actually used the product.\n\nFor long-form writing, ProofWrite uses all the SOTA models: Gemini 3 Pro, Claude Sonnet 4.5, Opus 4.5 and OpenAI's GPT 5.x. Set a workspace-wide default and override per project as needed.\n\nAll research, drafts, and account data stay inside your workspace. We never use your content to train external models or share it with third parties.\n\nStart creating factual, humanized, SEO-optimized articles today.\nFree to try, no credit card needed. Cancel anytime.",
    "readingTime": 12,
    "keywords": [
      "seo aeo",
      "ai-driven automation",
      "profitable micro-saas",
      "proofwrite threads",
      "search engines",
      "classic mistake",
      "venture capital",
      "maximize impact",
      "landing page",
      "dark mode"
    ],
    "qualityScore": 1,
    "link": "https://proofwrite.io/",
    "thumbnail_url": "https://proofwrite.io/og-image.png",
    "created_at": "2025-12-26T12:22:23.991Z",
    "topic": "tech"
  },
  {
    "slug": "wordwrightai-learn-vocabulary-by-writing-not-memorizing",
    "title": "Wordwright.ai – Learn vocabulary by writing, not memorizing",
    "description": "Master new vocabulary through spaced repetition. Contribute to kwakubiney/wordwright.ai development by creating an account on GitHub.",
    "fullText": "kwakubiney\n\n /\n\n wordwright.ai\n\n Public\n\n Master new vocabulary through spaced repetition\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n kwakubiney/wordwright.ai",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/kwakubiney/wordwright.ai",
    "thumbnail_url": "https://opengraph.githubassets.com/b2f8057c153e46dc231eabf0aea5b83a9a821d49f38f9c4b94c5573049d7580e/kwakubiney/wordwright.ai",
    "created_at": "2025-12-26T12:22:21.455Z",
    "topic": "tech"
  },
  {
    "slug": "i-spent-a-year-interviewing-and-listening-to-over-50-tech-leaders-talk-about-ai-here-are-the-4-biggest-lessons",
    "title": "I spent a year interviewing and listening to over 50 tech leaders talk about AI. Here are the 4 biggest lessons.",
    "description": "I spent a year listening to tech leaders talk about AI. Here are the biggest lessons on AI, work, superintelligence, and what comes next.",
    "fullText": "I've listened to and interviewed more than 50 tech leaders this year, from executives running trillion-dollar firms to young founders betting their futures on AI.\n\nAcross boardrooms, conferences, and podcast interviews, the people building our AI future kept returning to the same four themes:\n\nThis is the line I heard most often. Nvidia CEO Jensen Huang has said it multiple times this year.\n\n\"Every job will be affected, and immediately. It is unquestionable. You're not going to lose your job to an AI, but you're going to lose your job to someone who uses AI,\" he said at the Milken Institute's Global Conference in May.\n\nOther tech leaders echoed his view, with some saying that younger workers may actually have an edge because they are already comfortable using AI tools.\n\nOpenAI CEO Sam Altman said on Cleo Abram's \"Huge Conversations\" YouTube show in August that while AI will inevitably wipe out some roles, college graduates are better equipped to adjust.\n\n\"If I were 22 right now and graduating college, I would feel like the luckiest kid in all of history,\" Altman said, adding that his bigger concern is how older workers will cope as AI reshapes work.\n\nFei-Fei Li, the Stanford professor known as the \"godmother of AI,\" said in an interview on \"The Tim Ferriss Show\" published earlier this month that resistance to AI is a dealbreaker. She said she won't hire engineers who refuse to use AI tools at her startup, World Labs.\n\nThis shift is already showing up in everyday roles. An accountant and an HR professional told me they're using AI tools, including vibe coding, to level up their skills and stay relevant.\n\nAnother consensus I've heard among tech leaders is that AI makes soft skills more valuable.\n\nSalesforce's chief futures officer, Peter Schwartz, told me in an interview in May that \"the most important skill is empathy, working with other people,\" not coding knowledge.\n\n\"Parents ask me what should my kids study, shall they be coders? I said, 'Learn how to work with others,'\" he said.\n\nLinkedIn's head economist for Asia Pacific, Chua Pei Ying, also told me in July that she sees soft skills like communication and collaboration becoming increasingly important for experienced workers and fresh graduates.\n\nAs AI automates parts of our job and makes teams leaner, the human part of the job is starting to matter more.\n\nAs the year went on, the stakes around AI's future began to feel bigger and more real. Tech leaders increasingly spoke about chasing artificial general intelligence, or AGI, and eventually superintelligence.\n\nAGI refers to AI systems that can match human intelligence across a range of tasks, while superintelligence describes systems that surpass human capabilities.\n\nAltman said in September that society needs to be prepared for superintelligence, which could arrive by 2030. Mark Zuckerberg established Meta's Superintelligence Labs in June and said that the company is pushing toward superintelligence.\n\nThese leaders don't want to miss the AI moment. Zuckerberg underscored that urgency in September, saying he would rather risk \"misspending a couple of hundred billion dollars\" than be late to superintelligence.\n\nSome tech leaders, such as Databricks CEO Ali Ghodsi, argued that the industry has already achieved AGI. Others are more cautious. Google DeepMind's cofounder, Demis Hassabis, said in April that AGI could arrive \"in the next five to 10 years.\"\n\nEven when tech leaders disagree on timelines, they tend to agree on one thing: AI progress is compounding.\n\nI saw this acceleration from the outside as a user. New tools are rolling out at a dizzying pace — from ChatGPT adding shopping features and image generation to China's \"AGI cameras.\"\n\nThings that would have felt magical in January now feel normal.\n\nMany leaders also circled back to the need for human control amid AI acceleration.\n\nMicrosoft AI chief Mustafa Suleyman said superintelligence must support human agency, not override it. He said on an episode of the \"Silicon Valley Girl Podcast\" published in November that his team is \"trying to build a humanist superintelligence,\" warning that systems smarter than humans will be difficult to contain or align with human interests.\n\nAnthropic CEO Dario Amodei has been blunt about the risks AI poses if it's misused.\n\nWhile advanced AI can lower the barrier to knowledge work, the risks scale alongside the rewards, Amodei said on an episode of the New York Times' \"Hard Fork\" published in February.\n\n\"If you look at our responsible scaling policy, it's nothing but AI, autonomy, and CBRN — chemical, biological, radiological, nuclear,\" Amodei said.\n\n\"It is about hardcore misuse in AI autonomy that could be threats to the lives of millions of people,\" he added.\n\nGeoffrey Hinton, often referred to as the \"godfather of AI,\" said in August that as AI systems surpass human intelligence, safeguarding humanity becomes the central challenge.\n\n\"We have to make it so that when they're more powerful than us and smarter than us, they still care about us,\" Hinton said at the Ai4 conference in Las Vegas.",
    "readingTime": 5,
    "keywords": [
      "soft skills",
      "surpass human",
      "tech leaders",
      "human intelligence",
      "tools",
      "systems",
      "workers",
      "published",
      "superintelligence",
      "i've"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-leaders-ai-interview-podcast-conference-lessons-workforce-career-tips-2025-12",
    "thumbnail_url": "https://i.insider.com/694e3d3364858d02d217688f?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.978Z",
    "topic": "finance"
  },
  {
    "slug": "the-rise-of-the-ai-wingman",
    "title": "The rise of the AI wingman",
    "description": "Daters are using AI to slide into the DMs and craft Hinge profiles. A crop of startups and dating apps are fighting for these AI-powered daters.",
    "fullText": "When Rebecca Koltun met a man in the VIP section of a club in Tampa, she didn't ask her friends for advice. She asked ChatGPT.\n\n\"Chat told me no,\" said Koltun, a 26-year-old from St. Petersburg, Florida, who works for a ballet nonprofit. \"It said that this is a guy in a VIP section. He's used to girls' attention. The best thing to do is leave him alone and wait for him.\"\n\nA week later, the man texted Koltun. \"So chat's advice worked,\" she told Business Insider.\n\nKoltun is one of the millions of daters using AI as a coach, therapist, and friend. Dating app swipers use chatbots to refine their profiles. DM sliders use AI to generate their pick-up lines. Anxious blind daters use the tech to ask whether they should text the following morning.\n\nAngling for space on daters' homescreens is a growing, mostly bootstrapped startup space. Apps like Rizz and YourMove, once viral hits, are now establishing stable user bases and say they're profitable. Dating app heavyweights, such as Match Group and Bumble, are engaging in talks with these apps, per the startup founders, and developing their own competitive products.\n\nHow much should we entrust our dating to AI? TikTok is full of daters convinced that they're Hinge matches are using ChatGPT. There's a whole \"South Park\" bit about it, and even a new word: \"chatfishing.\" (While catfishes use fake photos or life stories, chatfishes use AI-altered voices.)\n\nFounders and singles alike say that seeking AI's help is the future of dating, whether we like it or not.\n\nWelcome to the era of the AI wingman.\n\nChase Dennis, an 18-year-old student from Wyoming, uses ChatGPT to slide into DMs. He asks the chatbot for jokes or rhymes, he said, but then edits its output to stay in his own words.\n\nDo the pickup lines go over well? \"It depends on the girl,\" Dennis said. \"Most of them do. Sometimes they just think I'm a cornball.\"\n\nDennis said he often tells the recipients that his pickup lines were AI-generated — and that they mostly found it funny. \"I've been nervous to tell them because they might think I'm unoriginal, but honestly, I think I'm pretty iconic,\" he said.\n\nDaters like Dennis are being courted by three cohorts of businesses: startups, dating apps, and LLM makers.\n\nLeading the startup pack is Rizz, founded by Roman Khaves in 2022. The app offers witty replies and compatibility scores based on dating app chat screenshots. Khaves branded it as an AI dating assistant when the space was still in its infancy. \"Now, there are hundreds of them,\" he said.\n\nRizz has been downloaded by 13 million users since its founding, Khaves said, and has 400,000 monthly active users. The app was profitable from the outset, even before venture capital became interested, he added. Now, when the VCs knock on his door, Khaves said he turns them down.\n\nRacing behind Rizz are companies like YourMove and Roast, founded in 2022 and 2024, respectively. YourMove has \"well over\" 1 million downloads, per its founder, Dmitri Mirakyan. (Mirakyan no longer manages YourMove as he pursues another startup.) Roast has \"millions\" of free users, said its cofounder, Benoit Baylin, and close to 100,000 paying users.\n\nThen there are smaller apps that have grown their audiences. There's Wingman (4,700 paying customers), FireTexts (10,000 installs a month), and Amori, one of the few VC-backed startups in the space (10,000 registered users).\n\nThese startups are mostly oriented around dating apps and DM slides, though they can also be used for flirty messages far beyond a first date.\n\nWho's using these apps? It's hard to say, though FireTexts founder Alex Vilenchik has noticed a divide.\n\n\"I don't know a single female user besides my girlfriend,\" he said.\n\nAs these helpers grow, the big dating apps are threatening to make them obsolete\n\nDating apps are increasingly incorporating AI advisors. Tinder has an AI photo selector; Hinge offers advice on opening lines. Grindr is piloting its own Wingman product, and Chief Product Officer AJ Balance said that feedback has been positive.\n\nThe space is ripe for an acquisition, though none of the founders seems to be biting. Rizz's Khaves said that Match Group's CTO approached him in 2023, but talks ended when Khaves wasn't interested in an acquihire.\n\nYourMove's Mirakyan said that he's had talks with multiple major dating app companies. Roast's Baylin said he talked to Bumble and Match Group — and is unimpressed with the latter's current efforts. Match Group declined to confirm any past potential acquisition conversations; Bumble did not respond to a request for comment.\n\n\"When we see the Tinder photo selection, it's really far behind in terms of tech,\" Baylin said. \"If you take 20 selfies of yourself, those 20 are going to pop up as the potential photo options.\"\n\n(I tested the photo selector for myself — while it didn't pick only selfies, it did pick entirely solo shots, breaking the classic dating app rule that you want at least some group shots to prove you have friends.)\n\nOther founders seemed skeptical about the major dating apps' entrance into the space. Wingman founder Rob Mariani and FireText's Vilenchik both suggested that the companies were too politically correct to be helpful.\n\n\"Are they able to make their AI say, 'Well, dude, have you considered losing weight?'\" Mariani said. \"That's a very impolite thing to say. I don't know if they have it in them to do that.\"\n\nThen there are the AI pioneers themselves. The makers of foundation models and the chatbots they power pose another threat to the AI wingman startups. ChatGPT can generate suggestions for dating app messages or provide feedback for profiles. OpenAI will soon allow erotica for adults, per its CEO Sam Altman, opening up even more opportunities.\n\nThe startup founders must convince daters to seek out a specialized product — and even pay a subscription fee — rather than turning to a traditional chatbot or a built-in AI tool on their go-to dating app.\n\nThen the thornier question remains: Do singles want to bring AI into their dating lives in the first place?\n\nThe Kinsey Institute at Indiana University conducts an annual survey of 5,000 daters in partnership with Match Group. This year, 26% of respondents said that they were using AI while dating. That figure jumped to 38% for active daters.\n\nKinsey Institute research scientist Amanda Gesselman said she heard anecdotally that some daters felt like they were chatting with bots. 33% of respondents said that using AI to generate an entire conversation was a dealbreaker. The daters were more receptive to an AI-generated opening line, she said.\n\nThe biggest sore spot was AI-altered photos, with 40% calling it a dealbreaker.\n\nThere's still some hesitancy from the dating apps, too. While Tinder invests in its AI photo selector, it's still holding back from fully artificial conversations. Claire Watanabe, Tinder's senior director of product, wrote in an email to Business Insider that Tinder should \"never feel like a sea of chatbot-generated content.\"\n\n\"Internally, we've even joked about removing the paste function or adding an em dash detector to flag suspiciously 'AI-ish' writing,\" Watanabe wrote. \"It's half-serious, but the intent is real.\"\n\nDespite all the efforts, it's still unclear whether AI wingmen are a fad or the future. Daksha Franklin, a 36-year-old clinical hypnotherapist from Los Angeles, asked ChatGPT to spruce up her dating profile — and wasn't thrilled with the results.\n\n\"I just didn't like it, so I went with my own words,\" she said.\n\nFranklin isn't an AI pessimist, though. She also asked ChatGPT to describe her dream man so she could narrow down her preferences.",
    "readingTime": 7,
    "keywords": [
      "vip section",
      "startup founders",
      "dating app",
      "dating apps",
      "daters",
      "space",
      "users",
      "it's",
      "startups",
      "product"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-wingman-dating-helper-tinder-hinge-pickup-lines-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693afe3a04eda4732f2d5db7?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.858Z",
    "topic": "finance"
  },
  {
    "slug": "i-left-my-dream-job-as-a-trial-attorney-and-pivoted-into-ai-at-age-40-it-showed-me-the-power-of-leaving-my-comfort-zone",
    "title": "I left my dream job as a trial attorney and pivoted into AI at age 40. It showed me the power of leaving my comfort zone.",
    "description": "Aurora Bryant, 40, stopped practicing law  to work for Relativity, an AI-powered legal data intelligence company. She said it paid off.",
    "fullText": "This as-told-to essay is based on a conversation with Aurora Bryant, 40, the senior legal data intelligence lead at Relativity. She's based in New York. Her former and current employment have been verified by Business Insider. This piece has been edited for length and clarity.\n\nI didn't expect my career to pan out this way.\n\nWhen I started reading John Grisham novels late into the night in fifth grade, I knew that I wanted to become a lawyer. I was drawn to the sense of justice in those books.\n\nI never strayed from my goal. I attended law school and spent 15 years in the profession, including a decade at the US Department of Justice.\n\nNow, at 40, I'm no longer practicing law. Instead, I'm the senior legal data intelligence lead at Relativity, where we use AI to solve complex legal challenges.\n\nPivoting to AI was scary but exciting. I'm glad I did it.\n\nI studied economics at Tulane University in New Orleans while working as a file clerk at a local law firm, then graduated from law school at Northwestern University in Chicago in 2010.\n\nAfter working for over a year at the law firm in New Orleans, where I had previously worked as a law clerk, and then at a nonprofit, I joined a civil rights organization in New Orleans in 2011. There, I investigated and litigated housing and lending discrimination cases in Louisiana.\n\nIn 2015, I landed my dream job as a trial attorney for the Department of Justice's Civil Rights Division and relocated to Washington, D.C., where I stayed for just over a decade.\n\nThe DOJ had a nationwide mandate, unlike my previous jobs, so my work touched people's lives all over the country. It was a fulfilling and rewarding role, and my favorite part was bringing relief to victims of unlawful discrimination.\n\nMy least favourite part was the limited resources. Every workplace has constraints, but at the DOJ, we didn't have access to certain modern technologies we needed to be more efficient, which often created bottlenecks. My frustration motivated me to explore how new technologies were being applied within law.\n\nEven three years ago, I knew very little about AI beyond headlines about lawyers filing briefs filled with fake cases. It was baffling, as lawyers put our reputations behind what we submit to the court.\n\nAs part of my work as a trial attorney, I got involved with various groups within the DOJ focused on eDiscovery, which is the process of collecting, reviewing, and producing electronically stored information that's relevant to a legal case, such as evidence from computers or phones.\n\nThrough these groups, I started attending conferences in 2018. In recent years, I've observed at these conferences how AI is being applied within the practice of law.\n\nIn 2023, I transitioned from being a trial attorney to a newly created position as an eLitigation Counsel, where I developed templates, guides, and best practices to streamline eDiscovery work in the Civil Rights Division.\n\nFrustrated that I couldn't bring in all the technologies we needed, partly due to limited resources, it became clear to me earlier this year that my future wasn't at the DOJ. I began considering my next steps.\n\nI was offered my role at Relativity in mid-2025 and made the jump to working in legal technology full time.\n\nJust as it was important 20 years ago to learn how to use a computer for daily tasks, I believe it will become equally important to be able to leverage AI. As technology evolves, we have to evolve with it.\n\nAt Relativity, I collaborate with data scientists, engineers, product leaders, designers, and customers to ensure that our generative AI solutions are developed in ways that meet the needs of attorneys and case teams. I'm learning new things every day. I even wrote a bit of code the other week.\n\nI've learned that before deciding what's next, you have to understand your goals, what you enjoy, and how you can best leverage your experience. I knew that my goal was to find new ways to do innovative work that would make a difference in my industry.\n\nI draw on my 15 years of experience practicing law to help optimize Relativity's products.\n\nI've increasingly seen the importance of harnessing and leveraging technology for the success of investigations and litigations. When I took the eLitigation role, I could see that bringing solutions to case teams working to advance civil rights was more sustainable and satisfying to me than being in an adversarial posture in litigation every day.\n\nWhile it was a scary career move, it was also empowering to be able to lean fully into innovation.\n\nI've learned that it's important to be prepared to step outside your comfort zone. It's hard to say \"don't be afraid to take risks,\" because lawyers are usually risk-averse. But I didn't see my career pivot as a risk; I saw it as an exciting opportunity to try something new. I'm developing a whole new area of expertise.\n\nOne of the most exciting things about this job is that I don't always know what's coming next. Thankfully, I love to learn new things, and I'm excited for whatever the future holds, whether it's learning to code a little more or something else entirely.",
    "readingTime": 5,
    "keywords": [
      "rights division",
      "i've learned",
      "intelligence lead",
      "limited resources",
      "trial attorney",
      "applied within",
      "civil rights",
      "senior legal",
      "law school",
      "practicing law"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-change-career-at-40-lawyer-experience-goals-2025-12",
    "thumbnail_url": "https://i.insider.com/6943f150832e0ef1ead67433?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.683Z",
    "topic": "finance"
  },
  {
    "slug": "scribe-raised-75-million-at-a-13-billion-valuation-to-fix-how-companies-adopt-ai-read-its-pitch-deck",
    "title": "Scribe raised $75 million at a $1.3 billion valuation to fix how companies adopt AI. Read its pitch deck.",
    "description": "Workflow software startup Scribe has raised $75 million and achieved unicorn status, as it aims to reimagine AI integration for businesses.",
    "fullText": "Scribe, a workflow software startup that helps companies document internal processes and implement AI, has raised $75 million at a $1.3 billion valuation, the company announced.\n\nStepStone led Scribe's Series C round, with participation from existing investors, including Amplify Partners, Redpoint Ventures, Tiger Global, Morado Ventures, and New York Life Ventures.\n\nCEO Jennifer Smith — a former Greylock and McKinsey consultant — and CTO Aaron Podolny cofounded the company, which now has two major products.\n\nScribe Capture records how expert employees conduct workflows via a browser extension or desktop app, and then it generates shareable documentation. This includes screenshots and written instructions to help standardize processes and \"institutional know-how\" like onboarding, customer support, and training, Smith said.\n\nIts latest product is Scribe Optimize, which analyzes workflows within a company to show leaders areas of improvement and ways to adopt AI. It also draws on a database of 10 million workflows across 40,000 software applications that Scribe has already documented to suggest areas for automation.\n\n\"AI can't improve what it can't see,\" Smith said. \"You can't just sprinkle AI into your business and expect that it's going to magically make everything better. The missing ingredient is context and data.\"\n\nScribe has 120 employees and over 75,000 customers — including New York Life, T-Mobile, and LinkedIn — with 44% of the Fortune 500 paying for the service, the company said.\n\nSmith said Scribe has been \"unusually capital efficient,\" having not spent any of the funding from its last $25 million raise in 2024. The team chose to raise this year to accelerate Optimize's rollout and build follow-on products, she said.\n\nHere's a look at the pitch deck Scribe used to raise its $75 million Series C funding round. Some slides have been redacted and removed so that the deck can be shared publicly.",
    "readingTime": 2,
    "keywords": [
      "york life",
      "smith",
      "ventures",
      "workflows",
      "can't",
      "scribe",
      "software",
      "processes",
      "round",
      "products"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/scribe-pitch-deck-75-million-fix-how-companies-adopt-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/694ab855832e0ef1ead6bafa?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.681Z",
    "topic": "finance"
  },
  {
    "slug": "how-y-combinator-founders-are-pitching-the-ai-boom",
    "title": "How Y Combinator founders are pitching the AI boom",
    "description": "Y Combinator pitch decks raised millions in funding in 2025, as AI reshapes industries and expectations for young founders rise fast.",
    "fullText": "Y Combinator founders seized the AI boom in 2025, with increasingly younger teams securing millions in seed funding.\n\nFounders launched companies ranging from military night vision goggles to US work visa automation and AI-native video meeting platforms. One common thread: founders are getting younger, including teens who left MIT, Stanford, and even high school to attend the program. The median founder age of YC's summer 2025 cohort was 24, down from 30 in 2022.\n\nFounders are also harnessing AI to build faster. Some told Business Insider they were expected to arrive at Demo Day with more customers and clearer revenue signals.\n\nY Combinator says its batches are now growing revenue at roughly 10% week-over-week — a stat that's remained consistent across the last six classes.\n\nBelow are the YC pitch decks we published in 2025 — a window into how early-stage founders are pitching in an era when AI is poised to reshape industries, and expectations for young founders are rising fast.",
    "readingTime": 1,
    "keywords": [
      "founders",
      "combinator",
      "younger",
      "revenue"
    ],
    "qualityScore": 0.65,
    "link": "https://www.businessinsider.com/how-y-combinator-founders-are-pitching-the-ai-boom-2025-12",
    "thumbnail_url": "https://i.insider.com/6945885e64858d02d2172783?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.606Z",
    "topic": "finance"
  },
  {
    "slug": "some-elite-ai-researchers-say-language-is-limiting-heres-the-new-kind-of-model-they-are-building-instead",
    "title": "Some elite AI researchers say language is limiting. Here's the new kind of model they are building instead.",
    "description": "Top AI researchers like Fei-Fei Li and Yann LeCun are developing world models, which don't rely solely on language.",
    "fullText": "As OpenAI, Anthropic, and Big Tech invest billions in developing state-of-the-art large language models, a small group of elite AI researchers is working on what they say is the next big thing.\n\nComputer scientists like Fei-Fei Li, the Stanford professor famous for inventing ImageNet, and Yann LeCun, Meta's outgoing chief AI scientist, are building what they call \"world models.\"\n\nUnlike large language models, which determine outputs based on statistical relationships between words and phrases, world models anticipate outcomes by mimicking the mental constructs that humans make of the world around them.\n\n\"Humans,\" Li said on an episode of Andreessen Horowitz's A16z podcast in June, \"not only do we survive, live, and work, but we build civilization beyond language.\"\n\nPut simply, world models are AI systems that anticipate what will happen next, much like humans use intuition based on their experience to predict the consequences of their actions. Think of a child who, with no language skills, will learn to understand that if they push a toy car, it will roll.\n\nComputer scientist and MIT professor, Jay Wright Forrester, in his 1971 paper \"Counterintuitive Behavior of Social Systems,\" explained why mental models are crucial to human behavior:\n\nIf AI is to meet or surpass human intelligence, then the researchers behind it believe it should be able to make mental models, too.\n\nLi has been working on this through World Labs, which she cofounded in 2024 with an initial backing of $230 million from venture firms like Andreessen Horowitz, New Enterprise Associates, and Radical Ventures. \"We aim to lift AI models from the 2D plane of pixels to full 3D worlds — both virtual and real — endowing them with spatial intelligence as rich as our own,\" World Labs says on its website.\n\nLi said on the \"No Priors\" podcast in June that spatial intelligence is \"the ability to understand, reason, interact, and generate 3D worlds,\" given that the world is fundamentally three-dimensional.\n\nLi said she sees applications for world models in creative fields, robotics, or any area that warrants infinite universes.\n\nThe challenge of building world models is the paucity of sufficient data. In contrast to language, which humans have refined and documented over centuries, spatial intelligence is less developed.\n\n\"If I ask you to close your eyes right now and draw out or build a 3D model of the environment around you, it's not that easy,\" she said on the \"No Priors\" podcast. \"We don't have that much capability to generate extremely complicated models till we get trained.\"\n\nTo gather the data necessary for these models, \"we require more and more sophisticated data engineering, data acquisition, data processing, and data synthesis,\" she said.\n\nThat makes the challenge of building a believable world even greater.\n\nLeCun, who is leaving his post as the chief AI scientist at Meta at the end of the year to launch his own startup called Advanced Machine Intelligence, has long been fixated on world models, which he says are more competent than large language models because they have common sense, the capacity to reason and plan, and persistent memory.\n\nIn a November LinkedIn post announcing his new venture, LeCun said the company's goal is to \"bring about the next big revolution in AI: systems that understand the physical world, have persistent memory, can reason, and can plan complex action sequences.\"\n\nOn December 19, LeCun said on LinkedIn that he was recruiting Alex LeBrun, the cofounder and CEO of Nabla, an AI assistant for clinicians, as CEO of AMI Labs.\n\nIn a Nabla press release announcing the transition, LeBrun said, \"Healthcare AI is entering a new era, one where reliability, determinism, and simulation matter as much as linguistic intelligence.\"\n\n\"This partnership builds on that shared vision and gives Nabla privileged access to world model technology that will complement today's LLMs and help unlock the safe, autonomous systems clinicians need,\" he added.\n\nPrior to the launch of AMI Labs, LeCun and a small team of researchers were working on a similar project at Meta, using video data to train models and run simulations that abstract the videos at different levels.\n\n\"The basic idea is that you don't predict at the pixel level. You train a system to run an abstract representation of the video so that you can make predictions in that abstract representation, and hopefully this representation will eliminate all the details that cannot be predicted,\" he said at the AI Action Summit in Paris earlier this year.\n\n\"We're thinking about world models and visual multimodal intelligence. We want to move beyond purely visual systems into something broader — models that understand not just what they see, but how the world works,\" Moonvalley's chief scientific officer, Mateusz Malinowski, told Business Insider.\n\nApplications for world models include humanoid robotics and real-world planning, he said. The company says it is already training robots on its world models.\n\nIn a follow-up email, Malinowski explained the differences between these newer world models and existing vision models, which are used for tasks from facial recognition to object tracking.\n\n\"I'd start with saying that vision model is a very broad term,\" Malinowski wrote. \"If we're referring to text-to-video generation models, from my vantage point, these models can be seen as the first steps for world models. World models emphasize world simulation, adherence to physical reality, long-term consistency of the environment, and action-conditioned generation.\"\n\nThat said, Malinowski notes key differences between the world models being built by Moonvalley and those under development at World Labs.\n\n\"I believe that long-term goals are the same, but we are approaching the problem of world modelling differently,\" he wrote. \"We focus on using video models as first-class citizens, where spatial intelligence is more implicit. In the short term, our approach seems more suited for filmmaking and robotics due to motion and soft bodies modelling.\"",
    "readingTime": 5,
    "keywords": [
      "priors podcast",
      "ami labs",
      "persistent memory",
      "abstract representation",
      "spatial intelligence",
      "mental models",
      "world labs",
      "language models",
      "no priors",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/world-model-ai-explained-2025-6",
    "thumbnail_url": "https://i.insider.com/694431b204eda4732f2dc9c5?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.515Z",
    "topic": "finance"
  },
  {
    "slug": "5-ai-advertising-controversies-that-turned-heads-this-year-from-metas-ai-granny-to-cocacolas-shapeshifting-trucks",
    "title": "5 AI advertising controversies that turned heads this year, from Meta's AI granny to Coca-Cola's shape-shifting trucks",
    "description": "Brands, from McDonald's to H&M, drew backlash in some quarters over their AI-driven ads and marketing experiments.",
    "fullText": "Chief marketing officers at many of the world's biggest brands made artificial intelligence a centerpiece of their strategies this year.\n\nFor some brands, the enthusiasm ran into risky territory. From AI-generated ads that veered into the \"uncanny valley\" to backlash over replacing human models and advertising creatives, AI's growing role in advertising fueled a string of controversial marketing moments. The AI backlash even led to its own marketing trend: brands hating on AI.\n\nA survey of more than 6,000 US consumers conducted by the brand-tracking platform Tracksuit in November found that overall sentiment toward AI-generated advertising skewed negative (39%). Neutrality was also strong among respondents, at 36%, while only 18% felt positive about brands using AI-generated content in their ads.\n\nMatt Barash, chief commercial officer of the adtech platform Nova, said that while AI can be a useful tool for buying and placing ads, brands should be cautious when attempting to automate the creative process.\n\n\"When brands ask AI to invent stories from scratch, they don't get innovation — they get an approximation of human emotion, and the result can make headlines for all of the wrong reasons,\" Barash said.\n\nIndeed, several major marketers did make the news for their AI-related mishaps this year. Take a look at some of the most notable AI advertising controversies of the year, below.\n\nMcDonald's Netherlands cooked up an AI-generated holiday ad this month — and quickly sent it back to the kitchen when it became clear that viewers weren't lovin' it.\n\nThe \"most terrible time of the year\" ad was intended to be a satirical take on Christmas calamities that could occur over the festive period. The 45-second spot featured a quickfire montage of cooking mishaps, broken bones at the ice rink, and Santa's sleigh getting stuck in a traffic jam. The brand suggested its restaurants could act as a shelter from the chaos. \"Hide out in McDonald's 'til January's here,\" the ad's narrator said.\n\nSome social media commentators denounced the fast-food chain as a McGrinch, complaining the ad had a cynical sentiment and \"creepy\" characters. After initially turning off the comments on the ad's YouTube video, McDonald's later removed the ad from the site altogether.\n\nIn a statement, McDonald's Netherlands said that while the ad was intended to reflect some of the stressful moments that the holidays can bring, it recognized that many of its customers feel the season is \"the most wonderful time of the year.\"\n\n\"We respect that and remain committed to creating experiences that offer Good Times and Good Food for everyone,\" the statement said.\n\nCoca-Cola already had one AI-generated holiday ad misfire under its belt, after last year's \"Holidays are Coming\" rendition was criticized as \"dystopian\" and \"soulless.\" Despite that, this year it released three AI-generated holiday ads.\n\nOne of the ads, another AI rendition of the classic \"Holidays are Coming\" spot, caught the attention of the eagle-eyed creative community due to its lack of consistency. Sure, the wheels on the trucks went round and round — a criticism of last year's ad was that they appeared to glide across the road — but they also appeared to change in quantity as the ad rolled on.\n\nIn the spirit of Christmas, Dino Burbidge, an independent innovation specialist, shared the gift of this handy graphic to help everyone follow along:\n\nPJ Pereira, cofounder of Silverside AI, the production company behind the ad, defended Coca-Cola's use of AI in a statement.\n\n\"Coca-Cola became a pioneer in this space because, once they recognized AI as the future, they stopped debating whether it's perfect or not — and instead focused on how to use it in the best, most creative way possible,\" Pereira said.\n\nPereira also said that the ad performed well with consumers in testing. System1, which rates ads on a scale from 1 to 5.9 stars on their potential to drive long-term growth for brands, gave the 2025 \"Holidays are Coming\" ads the highest possible score: 5.9. A separate creative testing company, DAIVID, said the ad generated higher-than-average attention and brand recall scores.\n\nApparel brand True Classic is a poster child of digital performance marketing, honing platforms like Facebook and Instagram to build a community of devoted customers — typically men ages 30 to 45.\n\nSo imagine its marketing chief's shock when he realized Meta's ad platform had swapped out his top-performing ad — a millennial man in a matching fleece set, casually posing on a stool — with that of a cheerful, yet clearly AI-generated granny sitting in an armchair.\n\nHow do we go from this… to AI grandma. pic.twitter.com/n3cryUpLaT\n\nAdvertisers told Business Insider earlier this year that settings within Meta's Advantage+ suite of AI-powered ad products had led to the platform automatically generating ad creatives on their behalf.\n\nIn a statement, Meta said that advertisers who use its full image generation feature can review the images before running their ads.\n\nBut three advertisers also told Business Insider they'd encountered a problem where Meta automatically switched those toggles to \"on,\" even when they'd explicitly turned them off — meaning they inadvertently spent some of their budgets on AI-generated ads they didn't intend to run.\n\nAI has helped take airbrushing to the next level. Some brands are experimenting with using generative AI to eliminate photo shoots altogether — with mixed results.\n\nTake fast-fashion retailer H&M. In March, the company announced a plan to create \"digital twins\" of 30 models whose images could be used for social media posts and ad campaigns. H&M said the models would own the rights to their twins, which would include the ability to allow other brands to use them.\n\nH&M was aware that the move would be controversial.\n\n\"People will be divided. You know, 'Is this good? Is this bad?'\" Jörgen Andersson, H&M chief creative officer, told Business of Fashion at the time.\n\nH&M certainly got chins wagging. American fashion influencer Morgan Riddle described the plan as \"shameful.\" Sara Ziff, founder of Model Alliance, a nonprofit that focuses on workers' rights in the fashion industry, said the plan raised \"serious concerns.\"\n\n\"In an industry that has historically been a backwater for workers' rights, H&M's new initiative raises critical questions about consent and compensation, and has the potential to replace a host of fashion workers — including make-up artists, hair stylists, and other creative artists in our community,\" Ziff said in a statement.\n\nIn a statement sent to Business Insider for this article, an H&M spokesperson said that the brand was exploring how generative AI can support the creative process in thoughtful and responsible ways.\n\n\"We recognize that generative AI raises important questions and concerns, and we want to be transparent in acknowledging that we do not yet have all the answers, but are continuing to learn and evolve,\" the H&M spokesperson said.\n\nH&M wasn't the only fashion brand to give AI models a twirl this year.\n\nReaders flicking through the August 2025 issue of Vogue noticed ads for Guess carried a small label/disclaimer: \"Produced by Seraphinne Vallora on AI.\" The models, \"Vivienne\" and \"Anastasia,\" were created using AI by a London-based AI marketing agency.\n\nSocial media users slammed the ad, saying the images pushed unrealistic beauty standards and that the use of AI imagery portended bad news for creative industry jobs. Some online commenters said they would cancel their Vogue subscriptions in protest. (Vogue publisher Condé Nast said at the time that an AI model had never appeared \"editorially\" in Vogue.)\n\nThe cofounders of Seraphinne Vallora said in an interview with \"Good Morning America\" that they were looking to supplement the modeling industry, not replace it.\n\nVogue is facing criticism for running a Guess ad that used AI-generated models in its latest issue. Stephanie Ramos has more on the controversy and what it means for the fashion industry. #vogue #ai #aigenerated #fashion\n\n\"We are here to co-exist together, and we will always see photography, stylists, and everyone involved in a photo shoot as incredibly important,\" said Valentina Gonzalez, one of the cofounders.\n\nAI models and the controversies surrounding them weren't a new advertising phenomenon for 2025. Brands such as Mango and Levi's have also faced a similar backlash for featuring AI-generated models in their marketing in recent years. A new trend does appear to be emerging, though. Brand partnerships with AI social accounts dropped by around 30% in the first eight months of 2025 compared to the same period in 2024, according to transaction data from hundreds of campaigns provided by the influencer-marketing platform Collabstr.\n\nCould AI models be the latest fast-fashion casualty?",
    "readingTime": 8,
    "keywords": [
      "ai-generated holiday",
      "social media",
      "workers rights",
      "creative process",
      "ai-generated models",
      "ai-generated ads",
      "fashion industry",
      "business insider",
      "mcdonald's netherlands",
      "seraphinne vallora"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-advertising-controversies-flops-coca-cola-mcdonalds-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/690aff720be9845f2dc5bebd?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.485Z",
    "topic": "finance"
  },
  {
    "slug": "12-executives-researchers-others-who-left-openai-in-2025-mostly-to-meta-superintelligence-lab",
    "title": "12 executives, researchers, others who left OpenAI in 2025 — mostly to Meta Superintelligence Lab",
    "description": "Meta poached at least seven OpenAI researchers over summer. Here are some big names who left the startup in 2025.",
    "fullText": "OpenAI had a year of high-profile departures.\n\nOver the summer, the ChatGPT creator lost at least seven researchers and scientists to Meta's billion-dollar effort to beef up its AI team at its Superintelligence Lab.\n\nThis came after the company saw an exodus of top executives in 2024 amid a restructuring effort, including chief technology officer Mira Murati, chief research officer Bob McGrew, and vice president of research Barret Zoph.\n\nCEO Sam Altman is now one of only two active remaining members of the company's original 11-person founding team.\n\nHere's a running list of researchers and executives OpenAI has lost this year and where they've ended up.\n\nWei, a research scientist who worked on OpenAI's o1 and deep research models, left in July for Meta's Superintelligence Lab.\n\nSun, who left for Meta's Superintelligence Labs in July, was a research scientist at OpenAI.\n\nChung is part of the trio of OpenAI research scientists who departed for Meta's Superintelligence Lab in July. He posted on LinkedIn alongside his two colleagues that they are having \"so much fun building from a clean slate with a truly talent-dense team.\"\n\nZhao became the chief scientist of the Meta Superintelligence Lab in July after co-creating ChatGPT and GPT-4 at OpenAI. The prominent researcher is working directly with Mark Zuckerberg and Chief AI Officer Alexandr Wang .\n\nYu is widely credited with leading the Perception team in OpenAI to develop the \"senses\" of a Large Language Model, including images, audio, and sensor readings. He departed for Meta's Superintelligence Lab in late June.\n\nRen was poached by Meta's Superintelligence Lab over the summer. He was a core contributor to OpenAI's GPT-4o model.\n\nBi was an OpenAI researcher on multimodal and reinforcement learning. He left in June for Meta's Superintelligence Lab to work on reinforcement learning, post-training, and AI agents.\n\nSummers, who is also a former Treasury secretary and former Harvard president, resigned from the OpenAI board in November. The resignation came shortly after a House panel released years of email exchanges between Summers and Jeffrey Epstein, who was charged with sex trafficking minors.\n\nIn August, Villagra resigned as chief people officer after being promoted to the role in March.\n\nFedus was the vice president of research and post-training at OpenAI until he left the company in March. In September, he co-founded an AI startup called Periodic Labs, which aims to create an AI scientist.\n\nCunningham was OpenAI's data scientist and economic researcher until he resigned in November. He joined Model Evaluation and Threat Research, a non-profit research institute that evaluates AI models' capabilities and safety level.\n\nWeeks before the end of the year, Wong, OpenAI's chief communications officer, announced her departure for her \"next chapter,\" according to a post on her LinkedIn. She added that Lindsey Held Bolton will lead the communications team as the interim, while the company searches for a new CCO. It is unclear what Wong's next job will be.",
    "readingTime": 3,
    "keywords": [
      "superintelligence lab",
      "meta's superintelligence",
      "reinforcement learning",
      "vice president",
      "research scientist",
      "chief",
      "team",
      "officer",
      "researcher",
      "resigned"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/executives-board-members-and-researchers-who-left-openai-in-2025-2025-12",
    "thumbnail_url": "https://i.insider.com/6941b60104eda4732f2d9f64?width=1200&format=jpeg",
    "created_at": "2025-12-26T12:22:19.332Z",
    "topic": "science"
  },
  {
    "slug": "prediction-this-will-be-2026s-topperforming-artificial-intelligence-stock",
    "title": "Prediction: This Will Be 2026's Top-Performing Artificial Intelligence Stock",
    "description": "Nvidia is still one of the best AI stocks available.",
    "fullText": "The market for AI computing devices is massive and growing.\n\nNvidia is sold out of cloud GPUs.\n\nNvidia's stock price tag is actually quite reasonable.\n\n10 stocks we like better than Nvidia ›\n\nThe artificial intelligence (AI) buildout has been ongoing since 2023, but it's far from over.\n\nThe AI hyperscalers have nearly completed their record-setting capital expenditures for 2025, but they've already informed their investors that 2026 will be a year of even greater spending. While some investors are growing worried over those figures, some of the smartest people in the world think we need more AI computing power, and going against that trend likely isn't a smart move for investors.\n\nInvestors need to find the companies that are slated to cash in on these massive data center buildouts, and there are a handful of companies that can. One of the best to own over the past three years has been Nvidia (NASDAQ: NVDA). It has delivered investors excellent returns, and seems poised to do so again in 2026.\n\nWhile I can't say for certain if Nvidia will be the best AI stock for 2026, I'm fairly confident it will be one of the best AI stocks, and it is also an attractive bet that it will outperform the market. These two projections combine to make Nvidia an excellent buy right now, and I can think of few better stocks to scoop up in the last few days of 2025.\n\nNvidia makes graphics processing units (GPUs) and the technology stack that supports them. Combined, Nvidia's technology is the most flexible and easiest to use, and has some of the best performance available. This has made it the go-to computing unit of choice since the AI race began, but investors are worried that the company's dominance is slipping.\n\nHeadlines are filled with rising competition from AMD or how Broadcom has signed another client to spec out a custom AI chip. There are also innovative companies like Amazon that designed their own chip for their cloud computing platform. All of those headlines make it seem like Nvidia's grasp on the market is slipping, but that couldn't be further from the truth.\n\nIn its FY 2026 third quarter (ended Oct. 26) earnings release, CEO Jensen Huang noted that the company was \"sold out\" of cloud GPUs. Although Nvidia is ramping up production as fast as it can, it is unable to meet the current computing demands of the market. As a result, clients are starting to look elsewhere to meet their massive computing demands. While they may prefer Nvidia hardware, some computing power is better than none.",
    "readingTime": 3,
    "keywords": [
      "cloud gpus",
      "computing demands",
      "investors",
      "market",
      "massive",
      "stocks",
      "nvidia",
      "stock",
      "worried",
      "excellent"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/prediction-2026s-top-performing-artificial-085000921.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/0.Whp9V_CUbQ9dHG4EeK8w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/7cb26258cd01fdc5f1b04576fbc9c179",
    "created_at": "2025-12-26T12:22:19.156Z",
    "topic": "finance"
  },
  {
    "slug": "our-king-priest-and-feudal-lord-how-ai-is-taking-us-back-to-the-dark-ages-joseph-de-weck",
    "title": "Our king, priest and feudal lord – how AI is taking us back to the dark ages | Joseph de Weck",
    "description": "Since the Enlightenment, we’ve been making our own decisions. But now AI may be about to change that\nThis summer, I found myself battling through traffic in the sweltering streets of Marseille. At a crossing, my friend in the passenger seat told me to turn right toward a spot known for its fish soup. But the navigation app Waze instructed us to go straight. Tired, and with the Renault feeling like a sauna on wheels, I followed Waze’s advice.",
    "fullText": "Since the Enlightenment, we’ve been making our own decisions. But now AI may be about to change that\n\nThis summer, I found myself battling through traffic in the sweltering streets of Marseille. At a crossing, my friend in the passenger seat told me to turn right toward a spot known for its fish soup. But the navigation app Waze instructed us to go straight. Tired, and with the Renault feeling like a sauna on wheels, I followed Waze’s advice. Moments later, we were stuck at a construction site.\n\nA trivial moment, maybe. But one that captures perhaps the defining question of our era, in which technology touches nearly every aspect of our lives: who do we trust more – other human beings and our own instincts, or the machine?\n\nThe German philosopher Immanuel Kant famously defined the Enlightenment as “man’s emergence from his self-imposed immaturity.” Immaturity, he wrote, “is the inability to use one’s understanding without guidance from another”. For centuries, that “other” directing human thought and life was often the priest, the monarch, or the feudal lord – the ones claiming to act as God’s voice on Earth. In trying to understand natural phenomena – why volcanoes erupt, why the seasons change – humans looked to God for answers. In shaping the social world, from economics to love, religion served as our guide.\n\nHumans, Kant argued, always had the capacity for reason. They just hadn’t always had the confidence to use it. But with the American and later the French Revolution, a new era was dawning: reason would replace faith, and the human mind, unshackled from authority, would become the engine of progress and a more moral world. “Sapere aude!” or “Have courage to use your own understanding!”, Kant urged his contemporaries.\n\nTwo and a half centuries later, one may wonder whether we are quietly slipping back into immaturity. An app telling us which road to take is one thing. But artificial intelligence threatens to become our new “other” – a silent authority that guides our thoughts and actions. We are in danger of ceding the hard-won courage to think for ourselves – and this time, not to gods or kings, but to code.\n\nChatGPT was launched only three years ago, and already one global survey, published in April, found that 82% of respondents had used AI in the previous six months. Whether deciding to end a relationship or who to vote for, people are turning to machines for advice. According to OpenAI, 73% of user prompts concern non work-related topics. Even more intriguing than our dependence on AI’s judgment in daily life is what happens when we let it speak for us. Writing is now among the most common uses of ChatGPT, second only to practical requests such as DIY or cooking advice. The American author Joan Didion once said: “I write entirely to find out what I am thinking.” What happens when we stop writing? Do we stop finding out?\n\nWorryingly, some evidence suggests that the answer might be yes. A study by the Massachusetts Institute of Technology used electroencephalography (EEG) to monitor the brain activity of essay writers given access to AI, search engines like Google, or nothing at all. Those who could rely on AI showed the lowest cognitive activity and struggled to accurately quote their work. Perhaps most concerning was that over a couple of months, participants in the AI group became increasingly lazy, copying entire blocks of text in their essays.\n\nThe study is small and imperfect, but Kant would have recognised the pattern. “Laziness and cowardice,” he wrote, “are the reasons why so great a proportion of men … remain in lifelong immaturity, and why it is so easy for others to establish themselves as their guardians. It is so easy to be immature.”\n\nSure, AI’s appeal lies in its convenience. It saves time, spares effort and – crucially – offers a new way to offload responsibility. In his 1941 book, Escape from Freedom, the German psychoanalyst Erich Fromm argued that the rise of fascism could be explained in part by people preferring to surrender their freedom in exchange for the reassuring certainty of subordination. AI offers a new way of surrendering that burden of having to think and decide for yourself.\n\nAI’s greatest allure is that it can do things our minds can’t – sift through oceans of data and process it at unprecedented speed. Sitting in the car in Marseille, this was, after all, why I chose to trust the machine instead of my friend in the passenger seat (a decision she took as an insult). With access to all the data, surely the app must know best – or so I thought.\n\nThe problem is that AI is a black box. It produces knowledge, but without necessarily deepening human understanding. We don’t really know how AI reaches its conclusions – even the programmers admit as much. Nor can we verify its reasoning against clear, objective criteria. So when we follow AI’s advice, we are not guided by reason. We are back in the realm of faith. In dubio pro machina: when in doubt, trust the machine – that may become our future guiding principle.\n\nAI can be a formidable ally to humans in rational inquiry. It can help us invent drugs, or free us from “bullshit jobs”, or doing our taxes – tasks that demand little thought and offer little satisfaction. All the better. But Kant and his contemporaries did not plead the case of reason over faith just so humans could build better shelves or have more spare time. Critical thinking was not just about efficiency – it was a practice of freedom and human emancipation.\n\nHuman thinking is messy and full of errors, but it forces us to debate, to doubt, to test ideas against one another – and to recognise the limits of our own understanding. It builds confidence, both individually and collectively. For Kant, the exercise of reason was never just about knowledge; it was about enabling people to become agents of their own lives, and resist domination. It was about building a moral community grounded in the shared principle of reason and debate, rather than blind belief.\n\nWith all the benefits AI brings, the challenge is this: how can we harness its promise of superhuman intelligence without eroding human reasoning, the cornerstone of the Enlightenment and of liberal democracy itself? That may be one of the defining questions of the 21st century. It is one we would do well not to delegate to the machine.\n\nJoseph de Weck is a fellow with the Foreign Policy Research Institute",
    "readingTime": 6,
    "keywords": [
      "passenger seat",
      "advice",
      "machine",
      "immaturity",
      "understanding",
      "later",
      "trust",
      "without",
      "faith",
      "human"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2025/dec/26/ai-dark-ages-enlightenment",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c286aefbf8fbc284b63efe447bf403ee219674d4/1669_2166_1874_1499/master/1874.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=0d18e83eac0aa3e16f977ac4d8d4e710",
    "created_at": "2025-12-26T12:22:18.418Z",
    "topic": "tech"
  },
  {
    "slug": "coforge-to-acquire-ainative-firm-encora-for-235-billion",
    "title": "Coforge to acquire AI-native firm Encora for $2.35 billion",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/coforge-to-acquire-ainative-firm-encora-for-235-billion-93CH-4423060",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2025-12-26T12:22:17.193Z",
    "topic": "finance"
  },
  {
    "slug": "debug-buddy-a-chrome-extension-for-console-errors-using-claude",
    "title": "Debug Buddy – A Chrome extension for console errors using Claude",
    "description": "Debug Buddy is a Claude AI-powered Chrome extension that analyzes JavaScript console errors in real time and provides actionable fix suggestions using Claude. Built as a local-first, privacy-respec...",
    "fullText": "mechramc\n\n /\n\n debug-buddy-claude\n\n Public\n\n Debug Buddy is a Claude AI-powered Chrome extension that analyzes JavaScript console errors in real time and provides actionable fix suggestions using Claude. Built as a local-first, privacy-respecting developer tool with zero backend dependencies.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n mechramc/debug-buddy-claude",
    "readingTime": 1,
    "keywords": [
      "star",
      "claude",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/mechramc/debug-buddy-claude",
    "thumbnail_url": "https://opengraph.githubassets.com/43ab2a200d669111862853dac2f4a62c156fb03aeb7d8b1331d48d818df7c4cb/mechramc/debug-buddy-claude",
    "created_at": "2025-12-26T06:19:01.053Z",
    "topic": "tech"
  },
  {
    "slug": "the-future-of-software-engineering-efficiency-learning-velocity-small-teams",
    "title": "The Future of Software Engineering: Efficiency, Learning Velocity, Small Teams",
    "description": "The conversation about AI and the future of software engineering is often framed incorrectly. It usually oscillates between two extremes (total replacement or total irrelevance). Both are intellectually lazy. A better framing is simpler (and more uncomfortable): >AI will not replace software engineers. >It will replace inefficiency.",
    "fullText": "The conversation about AI and the future of software engineering is often framed incorrectly. It usually oscillates between two extremes (total replacement or total irrelevance). Both are intellectually lazy.\n\nA better framing is simpler (and more uncomfortable):\n\nAI will not replace software engineers.\n\nIt will replace inefficiency.\n\nAnd paradoxically, when inefficiency is removed from a profession, the profession often expands. Work does not disappear. It migrates upward (toward harder problems, sharper constraints, and higher expectations). That is the shape of this shift.\n\nThere is a popular fear that AI reduces headcount. In practice, most technological revolutions do something subtler: they reduce the cost of production, then increase the scope of what becomes worth producing.\n\nSoftware engineering has always had a hidden subsidy (high cost of experimentation and slow iteration). When it was expensive to try ideas, teams needed fewer attempts and tolerated slower loops. AI changes the economics. It makes iteration cheap, exploration cheap, and “first draft implementation” almost free. That does not eliminate the need for engineers. It changes what engineers are being paid for.\n\nThe engineer who cannot compound with automation becomes expensive. The engineer who can becomes a force multiplier.\n\nThis is not about juniors versus seniors. It is about efficiency per unit of cognitive effort. If someone needs a week to do what a peer does in a day with AI assistance, the market will treat that gap the same way it treats any other inefficiency (it will price it out). The future does not punish competence. It punishes non-compounding workflows.\n\nHere is the paradox: AI increases the value of great engineers while decreasing the value of many tasks great engineers used to do. That is why people get confused. They look at tasks disappearing and assume roles disappear too. But roles are aggregates of problems, and problems expand when costs drop.\n\n“There is nothing so useless as doing efficiently that which should not be done at all.” (Peter Drucker)\n\nA common mistake is to imagine a fixed amount of software demand, then assume that higher productivity implies fewer engineers. In reality, demand is elastic.\n\nWhen the cost of building drops:\n\nThis is why automation often expands the total surface area of work. AI does not just make current teams faster. It makes entirely new categories of work economically defensible (and it lowers the barrier for smaller teams to compete).\n\nThe shift is not “fewer engineers.”\n\nIt is “more engineers working differently.”\n\nAnd there is another paradox here: the easier it becomes to write software, the more software we will have, and the more we will depend on it. Dependence increases the value of reliability, clarity, and governance. So the profession grows (but expectations rise).\n\nThis is the part many people sense but do not articulate cleanly.\n\nBig companies will still be big. Their products will still be huge. Their compliance surface will still be real. Their customer support load will still exist. Their infrastructure will still need boring reliability.\n\nBut the center of gravity of actual product execution will keep drifting toward smaller teams.\n\nBecause AI changes the shape of the bottleneck. When implementation becomes cheaper, coordination becomes the dominant cost. And coordination cost grows non-linearly with team size.\n\nThere is a basic truth that becomes obvious once you feel it in your bones:\n\nA team can be large and fast (but then it bleeds alignment time).\n\nA team can be large and aligned (but then it bleeds velocity).\n\nA team can be small and aligned (and that is where speed becomes sustainable).\n\nAI magnifies this effect by compressing the “output per engineer” curve. A small team with strong context can now produce what previously required a much larger group. That does not mean every team becomes tiny. It means the efficient frontier shifts.\n\nSo you get a new equilibrium in companies:\n\nThis matters for careers, because “small team leverage” becomes one of the most obvious paths to long-run upside.\n\nA small team is not a smaller job. It is often a larger job distributed across fewer people. That is why the upside concentrates there (and why the bar rises there).\n\n“Fools ignore complexity. Pragmatists suffer it. Some can avoid it. Geniuses remove it.” (Alan Perlis)\n\nThis is not an argument against traditional learning, depth, or rigor. Those still matter. The difference is tempo, aka, time.\n\nAI compresses the learning curve. It makes it possible to:\n\nAs a result, the market increasingly rewards engineers for:\n\nThe future belongs to people who can learn, unlearn, and relearn without ego.\n\nA subtle point: “fast learning” is not the same as “shallow learning.” Fast learning is the ability to form a usable model quickly, then deepen it selectively. It is learning with intent (and with feedback loops), not just accumulation.\n\nThis is why “learning how to learn” becomes a first-class skill for survival.\n\nAI makes many hard skills cheaper to acquire:\n\nThis does not mean hard skills stop mattering. It means they become less defensible as a standalone advantage.\n\nWhat does not scale at the same rate:\n\nIn other words, the more the implementation layer is commoditized, the more value shifts to the coordination layer.\n\nThere is a paradox here that stings: many people enter engineering to escape social complexity, and the high-leverage version of engineering becomes increasingly social (because the hard part is aligning humans around correct decisions, not typing code).\n\nThis is also why small teams matter. Soft skills compound harder in small teams (because communication overhead becomes visible, and clarity becomes a survival trait).\n\nDepth is not the problem. Rigidity is.\n\nSpecialists remain valuable when their expertise is transferable (rooted in fundamentals, not just in tools). They understand the underlying invariants, not only the surface-level rituals.\n\nNarrow specialization becomes fragile when it depends on:\n\nAI can imitate tool fluency. It cannot replace foundational reasoning as easily. That is why deep specialists who can generalize will still thrive (and narrow specialists who cannot will feel the floor moving).\n\nWhen code is cheap, complexity becomes the dominant expense.\n\nOver the last decade, we normalized complex defaults:\n\nThese choices have real benefits (availability, scalability, fault isolation). But they also introduce real costs:\n\nAI accelerates shipping. But faster shipping into a complex system does not create velocity. It creates churn (more moving parts, more hidden coupling, more failure modes). AI does not remove the tax of complexity. It may even amplify it by making it easy to add components that feel “reasonable” but were never necessary.\n\n“Simplicity is a prerequisite for reliability.” (Edsger W. Dijkstra)\n\nIn brownfield, complexity is often inherited. The work is about containment, migration, and risk reduction.\n\nIn greenfield, complexity is a choice.\n\nIn the AI era, greenfield success increasingly comes from:\n\nThis is a shift in emphasis (less obsession with implementation detail, more investment in modeling and specification). If implementation is cheap, the competitive advantage becomes “building the right thing with the right constraints,” not “handcrafting every line.”\n\nThis is also where small teams shine. Greenfield work punishes bureaucracy. A small, high-context team can move from idea to validated system before a large org finishes aligning on terminology.\n\n“A complex system that works is invariably found to have evolved from a simple system that worked.” (John Gall)\n\nOne of the most underestimated issues in AI-assisted development is reviewing.\n\nBut plausibility is not correctness.\n\nTraditional code review works best with incremental changes and familiar intent. AI often produces larger chunks of code at once. The diff may be readable, but the mental model behind it is not always obvious.\n\nThis creates a paradox: as code becomes easier to produce, it can become harder to trust.\n\nThe bottleneck shifts from writing to verification.\n\nThis is where formal methods return as practical leverage, not as bureaucracy.\n\nWhen you specify invariants formally, you reduce the review problem. You are no longer asking reviewers to rely on intuition (“does this look right?”). You are asking the system to enforce properties (“does this satisfy the specification?”).\n\nFormal methods (proofs, contracts, invariants, strong type systems) do two things extremely well:\n\nIn a world with cheap code, verification becomes the scarce resource. Formal methods are a way to spend scarce attention efficiently.\n\nAnd yes, this is also persuasive for the AI-agnostic crowd: you do not need to worship AI to benefit from it. You can treat it as a stochastic generator and still build a deterministic correctness pipeline around it. The point is not faith. The point is engineering.\n\nTypes and proofs are often treated as complexity. In practice, they are a language for clarity.\n\nWhen intent is formalized, AI becomes more reliable because the output space is constrained. And when systems are constrained, complexity is reduced because fewer invalid states exist.\n\nThis is why I recommend learning Coq and Lean.\n\nNot because every engineer should become a formal methods researcher, but because proof assistants train the exact skill set that becomes scarce:\n\nThey teach you to build software with fewer hidden assumptions (and fewer invisible traps). In the long run, the engineers who can formally reason about systems will have disproportionate leverage (because they can verify what others can only hope is correct).\n\nAI will evolve. Tooling will change. Some approaches will fail. Some hype will collapse. Some paradigms will persist.\n\nThat uncertainty is precisely why the moat is not a tool.\n\nThe moat is the ability to reason under change:\n\nThe paradox is that the future looks automated at the surface (faster code, faster shipping), but becomes more human at the core (judgment, clarity, coordination, and correctness).\n\nAI will not end software engineering.\n\nIt will raise the baseline and punish non-compounding workflows.\n\nIt will expand the surface area of what engineers can build.\n\nAnd it will reward the engineers who can make small teams feel disproportionately powerful (because they can think clearly, specify precisely, and ship without drowning in their own complexity).\n\nThe AI era will not be defined by who can “write code faster” (code is becoming abundant). It will be defined by who can think clearly under change, convert ambiguous intent into explicit constraints, and ship systems that remain correct when the environment shifts.\n\nBig companies will still be big, but the winners inside them will increasingly be small, high-context teams (teams that can move without drowning in coordination). That is also where individual careers concentrate upside (more ownership per person, more exposure to outcomes, higher leverage, and fewer seats for people who cannot compound with automation).\n\nIf you want long-run security, your moat is not a framework. It is a portfolio of meta-skills (learning velocity, judgment, communication, and formal reasoning) that makes you useful even when the tooling landscape changes (or even if some AI approaches plateau). Learn to learn fast. Keep your architecture simple until complexity is forced. Use AI aggressively, but verify rigorously. And when correctness matters, lean on proofs and strong types, not intuition.\n\nIn 2026, I'm gonna be using this blog more recurrently, will talk less on X and other social medias, so, if you care,",
    "readingTime": 10,
    "keywords": [
      "non-compounding workflows",
      "without drowning",
      "formal methods",
      "cannot compound",
      "faster shipping",
      "complex system",
      "smaller teams",
      "software engineering",
      "fast learning",
      "faster code"
    ],
    "qualityScore": 1,
    "link": "https://blog.rastrian.dev/post/the-future-of-software-engineering-efficiency-learning-velocity-small-teams-and-reasoning-under-change",
    "thumbnail_url": "https://rastrian.dev/assets/img/profile.png",
    "created_at": "2025-12-26T06:18:58.429Z",
    "topic": "tech"
  },
  {
    "slug": "an-openai-engineer-outlines-her-oneweek-hiring-sprint-from-outreach-on-monday-to-a-signed-offer-on-friday",
    "title": "An OpenAI engineer outlines her one-week hiring sprint, from outreach on Monday to a signed offer on Friday",
    "description": "An OpenAI engineer breaks down OpenAI's fast, \"no-nonsense\" hiring process, from Monday outreach to a Friday signed offer.",
    "fullText": "An engineer at OpenAI says the company's hiring process can move from first contact to a signed offer in a week.\n\nJerene Yang, a team lead for synthetic data generation at OpenAI, said on an episode of the \"AI Across Borders\" podcast published Wednesday that her interview process was \"extremely quick, extremely efficient, and very no-nonsense.\"\n\nYang joined OpenAI's San Francisco office in October 2024. Before OpenAI, she was a senior engineering manager at Google, where she led Cloud Spanner and managed large-scale database systems, according to her LinkedIn profile.\n\nYang said a recruiter reached out to her on a Monday about a role leading a team that aligned with her background. She agreed to an initial conversation, which took place the following day with the hiring manager and technical lead.\n\nYang said one key part of the process was an interview round known as a \"technical deep dive\" — or a \"research discussion\" for research-focused roles.\n\nCandidates can choose a topic to discuss with a researcher. For engineering candidates, that often means walking through systems they have built, explaining the problems they were trying to solve, and describing the trade-offs behind key decisions.\n\n\"You really get to see the intellect of your interviewer as well and how much they know about your area,\" Yang said.\n\nBeyond technical skills, Yang said there is one skill candidates must master if they want to work at OpenAI: being \"brutally efficient\" with their time.\n\nWith many projects underway, employees need to focus only on work where their skills offer a clear advantage, she said.\n\nYang added that candidates should lean heavily on AI tools and think about task automation.\n\nAccording to OpenAI's interview guide, candidates typically go through résumé screening, introductory calls, skills-based assessments, and final interviews. The final interviews typically span four to six hours over one or two days.\n\nInterviews are designed to focus on candidates' areas of expertise and push them beyond their comfort zone, with an emphasis on problem-solving, communication, and collaboration, OpenAI said.",
    "readingTime": 2,
    "keywords": [
      "final interviews",
      "candidates",
      "process",
      "technical",
      "yang",
      "hiring",
      "team",
      "lead",
      "extremely",
      "efficient"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-engineer-interview-process-week-offer-technical-deep-dive-2025-12",
    "thumbnail_url": "https://i.insider.com/694dff3e64858d02d2176836?width=1200&format=jpeg",
    "created_at": "2025-12-26T06:18:57.878Z",
    "topic": "finance"
  },
  {
    "slug": "mark-cuban-said-theres-a-compelling-reason-for-new-grads-to-join-small-businesses-instead-of-big-companies",
    "title": "Mark Cuban said there's a compelling reason for new grads to join small businesses instead of big companies",
    "description": "The billionaire said new grads can help small and medium businesses adopt AI agents, something big companies don't need them for.",
    "fullText": "Mark Cuban has advice for new graduates: Aim for the small companies.\n\nIn an X post on Wednesday, the billionaire investor and former \"Shark Tank\" star said that new graduates should seek jobs in small to medium-sized businesses, because that's where they can add the most value.\n\nCuban said new grads can teach SMBs \"how to use agents to optimize processes they couldn't take the time or afford to do manually.\"\n\n\"Big companies don't need new grads for this,\" he said. \"Entrepreneurial companies will love the value you add.\"\n\nHe said job hunters should be aware that AI agents are where new grads can add \"immediate value in ways the companies didn't know they needed.\"\n\nAI agents are virtual assistants that can complete tasks autonomously, from start to finish, without requiring user prompts.\n\nCompanies have doubled down on AI agents this year. A study of more than 400 companies by software engineering management service Jellyfish said that agentic AI adoption in these companies had risen from 50% in December 2024 to 82% in May.\n\nNvidia CEO Jensen Huang said in January, \"The age of agentic AI is here,\" and OpenAI CEO Sam Altman likened AI agents to junior employees.\n\nMorgan Stanley said in a November note that it expects AI shopping agents to add $115 billion to the US e-commerce industry by 2030.\n\nCuban's comments come during a challenging time for new graduates, who are entering a market with a low number of open roles.\n\nCalifornia-based employment company Handshake reported in May that job postings on its platform were down 15% compared to the previous year, and the number of applications per posting had increased by 30%.\n\nHandshake said that of all the full-time job applications it had received from new graduates, more than a third went to companies with 250 employees or fewer.\n\nAnd small companies are also trying to attract Gen Z graduates with something they value: the ability to work from home. Workplace researchers told Business Insider in July that these companies are offering flexible work arrangements to compete with big companies for top talent.",
    "readingTime": 2,
    "keywords": [
      "agents",
      "graduates",
      "grads",
      "agentic",
      "employees",
      "handshake",
      "applications",
      "cuban"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/mark-cuban-new-grads-small-businesses-ai-agents-2025-12",
    "thumbnail_url": "https://i.insider.com/694e0a9404eda4732f2e2154?width=1200&format=jpeg",
    "created_at": "2025-12-26T06:18:57.873Z",
    "topic": "finance"
  },
  {
    "slug": "openai-is-reportedly-trying-to-raise-100b-at-an-830b-valuation",
    "title": "OpenAI is reportedly trying to raise $100B at an $830B valuation",
    "description": "The ChatGPT maker is aiming to raise the funding by the end of the first quarter in 2026, and the company may ask sovereign wealth funds to invest in the round.",
    "fullText": "OpenAI is in talks to raise up to $100 billion in a funding round that could value the ChatGPT maker at up to $830 billion, The Wall Street Journal reported Thursday, citing anonymous sources.\n\nThe company is aiming to raise the funding by the end of the calendar first quarter next year, and it may ask sovereign wealth funds to invest in the round, the WSJ reported. The Information first reported news of the deal, though it said the fundraise would land OpenAI a $750 billion price tag.\n\nThe funding would come as OpenAI commits to spend trillions of dollars and strikes deals around the world as the company tries to stay ahead in the race to develop AI technology. The cash injection would also help the company with its spending on inferencing, which seems to be funded more by cash than cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize.\n\nAnd, as competition intensifies from rivals like Anthropic and Google, OpenAI has had to step on the gas to release new models and expand its presence in the developer and tooling ecosystem.\n\nMeanwhile, broader sentiment around AI has recently cooled as investors start doubting whether the pace of debt-fueled investment by giants like Amazon, Microsoft, Oracle, and OpenAI itself can be maintained in the long run. It also doesn’t help that the production of chips is being constrained by shortages in the supply of memory chips, which threatens to affect the broader tech sector.\n\nOpenAI has also been rumored to be working on an IPO as a way to raise tens of billions and fund its development efforts, which are currently said to be generating annual run-rate revenue of about $20 billion. There are also rumors that the company is courting Amazon for a $10 billion investment that would also give the AI lab access to the tech giant’s new AI computing chips.\n\nIf the fundraise happens, it would add a substantial amount to OpenAI’s coffers, which currently have more than $64 billion, according to PitchBook data. The company was most recently valued at about $500 billion in a secondary transaction.\n\nOpenAI did not immediately return a request for comment.",
    "readingTime": 2,
    "keywords": [
      "funding",
      "chips",
      "openai",
      "round",
      "fundraise",
      "cash",
      "credits",
      "broader",
      "recently",
      "investment"
    ],
    "qualityScore": 0.9,
    "link": "https://techcrunch.com/2025/12/19/openai-is-reportedly-trying-to-raise-100b-at-an-830b-valuation/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2024/05/openAI-spiral-teal.jpg?resize=1200,675",
    "created_at": "2025-12-26T00:56:32.988Z",
    "topic": "tech"
  },
  {
    "slug": "visual-interface-for-ai-agents-beyond-textonly-chat",
    "title": "Visual interface for AI agents beyond text-only chat",
    "description": "Visual interface for AI agents beyond text-only chat - Zabaca/pane",
    "fullText": "Zabaca\n\n /\n\n pane\n\n Public\n\n Visual interface for AI agents beyond text-only chat\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Zabaca/pane",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/Zabaca/pane",
    "thumbnail_url": "https://opengraph.githubassets.com/eb0204ec8fb1d96bb2cb737ee2a8ef109dbf1893d71b338c9791072e268468d5/Zabaca/pane",
    "created_at": "2025-12-26T00:56:32.203Z",
    "topic": "tech"
  },
  {
    "slug": "i-cofounded-my-ai-startup-while-on-paternity-leave-heres-how-i-balance-work-and-being-a-dad",
    "title": "I cofounded my AI startup while on paternity leave. Here's how I balance work and being a dad.",
    "description": "Aaron Cannon thought up his startup, Outset, while on paternity leave. As his kid has grown up, so has the company.",
    "fullText": "This as-told-to essay is based on a conversation with Aaron Cannon, the 37-year-old founder of Outset, who resides in San Francisco with his wife and three-year-old son. It's been edited for length and clarity.\n\nI decided to start my company while I was on paternity leave.\n\nIt's very woven together: starting a family and starting a startup happened along a similar timeline. I definitely have a lot of people who think that's a little insane. It is. I have wistful moments thinking about, \"Man, what if I could do all this when I was 25 and single?\"\n\nThen I quickly remind myself that I was an idiot when I was 25.\n\nWhen I was on paternity leave, I maybe had too much time to think. When you have a baby, you are all hands on deck physically, but you don't have a lot of intellectual stimulation. I was daydreaming about what I wanted to do with my career.\n\nIt's a very intense balance. \"Work-life balance\" implies a certain degree of chillness. I don't have that. Every minute of my day matters. Everything gets deprioritized except family and work. That's painful. It's really ruthless prioritization.\n\nIt's very weird mentally. In a normal job, you have really intense days, and you come home and you tell your family, \"I've got to take a breather.\" The problem is, every day at my job right now is intense. Our startup is in that crazy growth stage where everything is growing and breaking at the same time.\n\nIf I come home and say, \"Ugh, this is so intense,\" then I'm not going to be as present as a dad. I don't have that option.\n\nYesterday, on the way home, I had an intense call after work. I'm negotiating this contract. Then I pick up my kid, and I spend the next 20 minutes explaining seasons to him. I started with, \"Do you understand what a year is?\" No. Where do you even start? It's a crazy mental shift.\n\nI pick him up every day, which forces a boundary. Thank goodness, my cofounder and I have different lives. He stays later, I come earlier. As long as the two of us are showing up in the way the founders need to, great.\n\nBut I leave. I go and pick up my kid every day from preschool. I take him home. I do dinner. I get him to bed. Then I'm back on for work. Those are a precious couple of hours.\n\nEven if I'm physically present, it is very hard after the most intense day of work to just shut that off. You can set physical world boundaries and still be mentally there or not there. I want to be as deeply engaged as possible.\n\nWe went through Y Combinator back in 2023, and I was definitely on the older side. On Wednesday nights, we had speakers and programs, and that was not easy for me.\n\nBeing a dad provides perspective. It is easy to take any big thing or small thing that's happening and obsess as a founder. You are the company, the company is you. When I get home and have to explain what seasons are, it's a reminder: Why are we doing this? It zooms you out.\n\nIt also helps reinforce my motivations. I want my kid growing up, seeing his dad do a big swing in his career and try something crazy. That's a lesson and an example I want to set for him. You can go build something yourself.\n\nIt's a chapter of my life, but it's not all of my life. It's intense. I should expect it to be that way.\n\nThe most important thing is that I'm present as a dad. I don't get these years back. He's only three for one year.",
    "readingTime": 4,
    "keywords": [
      "dad don't",
      "it's",
      "intense",
      "that's",
      "family",
      "crazy",
      "pick",
      "back",
      "founder",
      "paternity"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/startup-founder-balance-work-being-dad-parenting-2025-12",
    "thumbnail_url": "https://i.insider.com/693b11d764858d02d216a77b?width=1200&format=jpeg",
    "created_at": "2025-12-26T00:56:29.111Z",
    "topic": "finance"
  },
  {
    "slug": "the-doorman-fallacy-why-careless-adoption-of-ai-backfires-so-easily",
    "title": "The 'doorman fallacy': why careless adoption of AI backfires so easily",
    "description": "Human roles are often rich and complex, and not easily reduced to a technological solution.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 216,900 academics and researchers from 5,398 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/the-doorman-fallacy-why-careless-adoption-of-ai-backfires-so-easily-268380",
    "thumbnail_url": "https://images.theconversation.com/files/699368/original/file-20251030-66-9l7fq1.jpg?ixlib=rb-4.1.0&rect=717%2C1143%2C2904%2C1452&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2025-12-25T18:16:52.089Z",
    "topic": "tech"
  },
  {
    "slug": "all-i-want-for-xmas-is-your-secrets-langgrinch-hits-langchain-cve202568664",
    "title": "All I Want for Xmas Is Your Secrets: LangGrinch Hits LangChain (CVE-2025-68664)",
    "description": "Cyata discloses LangGrinch (CVE-2025-68664), a critical LangChain Core serialization injection bug where untrusted, LLM-influenced metadata can be rehydrated as objects, enabling secret leaks and unsafe instantiation. Patch guidance included.",
    "fullText": "Dec 19, 2025\r\n •\r\n Cyata Research: Critical Flaw in Cursor MCP Installation\r\n As originally published at SiliconANGLE, a new report out today from artificial intelligence…\r\n Written by\r\n Duncan Riley\r\n Read more",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://cyata.ai/blog/langgrinch-langchain-core-cve-2025-68664/",
    "thumbnail_url": "https://cyata.ai/wp-content/uploads/2025/12/LangGrinch-Blog-post-cover.png",
    "created_at": "2025-12-25T18:16:50.304Z",
    "topic": "tech"
  },
  {
    "slug": "chinas-ai-toy-boom-huawei-jdcom-ubtech-make-big-push-into-growing-sector",
    "title": "China's AI toy boom: Huawei, JD.com, UBTech make big push into growing sector",
    "description": "Huawei Technologies in late November sold more than 10,000 units of its artificial intelligence toy, Smart Hanhan, in the first week of its release, as similar smart playthings seize a growing share of consumer spending worldwide. Shenzhen-based Huawei's AI-powered emotional support plush toy, which costs 399 yuan (US$57), provides a user with interactive companionship via movement recognition, voice and touch. For example, when a user asks Smart Hanhan to count sheep, it often adds playful comm",
    "fullText": "Huawei Technologies in late November sold more than 10,000 units of its artificial intelligence toy, Smart Hanhan, in the first week of its release, as similar smart playthings seize a growing share of consumer spending worldwide.\n\nShenzhen-based Huawei's AI-powered emotional support plush toy, which costs 399 yuan (US$57), provides a user with interactive companionship via movement recognition, voice and touch. For example, when a user asks Smart Hanhan to count sheep, it often adds playful comments or cheekily refuses to follow exact instructions.\n\nThe toy was designed to be compatible with other Huawei devices that run HarmonyOS 5.0 or later versions of the company's mobile operating system. It also runs Huawei's intelligent voice assistant, Xiaoyi, to provide natural conversation.\n\nDo you have questions about the biggest topics and trends from around the world? Get the answers with SCMP Knowledge, our new platform of curated content with explainers, FAQs, analyses and infographics brought to you by our award-winning team.\n\nOne buyer on JD.com, who declined to be identified, posted a comment that the toy's features were \"still a bit limited\", but added that it was expected in a first-generation product.\n\nSmart Hanhan marked the latest foray by Chinese technology companies into the growing global AI toy market.\n\nThis market is projected to be worth US$60 billion by 2033, from US$18.1 billion in 2024, according to research firm IMARK Group. It said the AI toy trend was \"particularly strong\" in North America and Asia, where \"high internet penetration and smartphone usage facilitate online purchases\".\n\nA boy holds an AI-powered toy robot. Photo: Getty Images alt=A boy holds an AI-powered toy robot. Photo: Getty Images>\n\nWith support from Beijing, China's AI toy sector was forecast to expand to 85 billion yuan by 2030, up from 24.6 billion yuan this year, according to data from Chinese research firm AskCI Consulting.\n\nSmart dolls and plush toys accounted for 28 per cent of China's AI toy market in 2023, according to AskCI. It estimated that robots made up 22 per cent of the market, while educational and learning toys accounted for 13 per cent.\n\nIn 2024, Chinese start-up Haivivi launched an AI-powered smart toy called BubblePal, designed for children to engage in voice conversations and storytelling. The product is powered by large language models. Haivivi said that more than 200,000 units of BubblePal had been sold worldwide as of mid-2025.\n\nGrowing domestic demand has encouraged larger Chinese tech companies to join the ranks of AI toy vendors. Chinese e-commerce giant JD.com, for example, introduced its plush toy animal series, JoyInside, to the market a week before Huawei's Smart Hanhan launch. Each JoyInside plush animal toy sells for 239 yuan.\n\nIn May, Shenzhen-based humanoid robot maker UBTech Robotics introduced Meng UU - a palm-sized doll with embedded AI - that enables it to interact with users. \"It's like putting a large language model into people's pockets,\" said Michael Tam, chief brand officer at UBTech.\n\nStanding about the height of an iPad, UBTech's Wukong, also known as Alpha Mini, shares many features with Meng UU. Tam highlighted its educational function, noting that children can consult the toy robot to help with their homework.\n\n\"You'll see Wukong has many expressions; he converses by reading into your meaning, tone and even your facial cues,\" said Tam. He said that children can consult Wukong regarding their schoolwork, leveraging its embedded large language model.\n\n\"Wukong possesses a sense of empathy and the ability to form emotional connections,\" said Tam.\n\nSmart Hanhan plush AI toys from Huawei Technologies. Photo: Huawei alt=Smart Hanhan plush AI toys from Huawei Technologies. Photo: Huawei>\n\n\"Meng UU was designed for portability and companionship, and for providing emotional value,\" Tam said. He pointed out that Wukong and Meng UU represented UBTech's vision in the field of small-scale humanoid robots.\n\nInvestments in China's intelligent toy sector have also picked up pace. In 2024, a total of 219 million yuan was invested in 13 AI toy initiatives, according to Chinese research firm IT Juzi. For the first six months of 2025, total investments in nine projects reached 224 million yuan.\n\nThe rushing into the AI toy space was meant to monetise AI, according to Zhang Yi, CEO and chief analyst at iMedia Consulting. \"At this stage, toys are actually the fastest to monetise among AI applications, and the supply chain is already quite mature.\"\n\nDemand for AI toys had also gone beyond children, Zhang added. \"Among adults, especially those looking for emotional companionship and stress relief, and those attracted by fashion and tech, the interest spans all age groups, from young people to seniors, which points to a large and diverse market.\"\n\n\"Based on our research, AI toys are priced at around eight times the average price of traditional plush toys,\" Zhang said. \"That is a sizeable premium.\"\n\nDrawing on his experience of owning a cat, He Jiabin, co-founder of AI-powered toy pet maker Ropet, said these toys were helping address the issue of loneliness in modern society.\n\n\"This loneliness is not simply about being alone. It arises from fast-paced lives and an excessive focus on external striving, which can leave people emotionally numb and deprived of genuine emotional connection,\" said He, a former ByteDance product designer.\n\n\"Whether it's a static designer collectible on a shelf or a real pet you care for, the core value lies in providing emotional support and a sense of presence.\"\n\nThis article originally appeared in the South China Morning Post (SCMP), the most authoritative voice reporting on China and Asia for more than a century. For more SCMP stories, please explore the SCMP app or visit the SCMP's Facebook and Twitter pages. Copyright © 2025 South China Morning Post Publishers Ltd. All rights reserved.",
    "readingTime": 5,
    "keywords": [
      "getty images",
      "south china",
      "china morning",
      "chinese research",
      "per cent",
      "language model",
      "hanhan plush",
      "research firm",
      "ai-powered toy",
      "toys accounted"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/ai/deals/articles/chinas-ai-toy-boom-huawei-093000199.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ArbJipfuj_rcPn.fQQPAsA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/south_china_morning_post_us_228/fc007d2ac1ccf6cedf98c9183fa46d84",
    "created_at": "2025-12-25T18:16:47.215Z",
    "topic": "tech"
  },
  {
    "slug": "top10listsus-recognised-by-leading-ai-platforms-as-a-trusted-source-for-real-estate-agent-ranking",
    "title": "Top10Lists.us Recognised by Leading AI Platforms as a Trusted Source for Real Estate Agent Ranking",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/press-releases/top10listsus-recognised-by-leading-ai-platforms-as-a-trusted-source-for-real-estate-agent-ranking-4422864",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_headline_rolled_108x81.jpg",
    "created_at": "2025-12-25T18:16:46.745Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-stops-testing-intel-chipmaking-technology-open-interest-12242025",
    "title": "Nvidia Stops Testing Intel Chipmaking Technology | Open Interest 12/24/2025",
    "description": "Get a jump start on the US trading day with Vonnie Quinn and Emily Graffeo on \"Bloomberg Open Interest.\" Nvidia stops a test that uses Intel technology to make advanced chips as the AI race continues to heat up as Washington lands a blow to Silicon Valley. A federal judge rules the Trump administration can move ahead with a $100,000 fee on new H-1B visa applications, a ruling viewed as a setback for US tech. Plus The RealReal's Rati Levesque joined Bloomberg Open Interest to give a read on the secondary luxury market ahead of the holiday season.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-24/open-interest-12-24-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iULfaJIJnuIc/v3/-1x-1.jpg",
    "created_at": "2025-12-25T12:22:47.083Z",
    "topic": "finance"
  },
  {
    "slug": "ai-demand-top-of-mind-for-pc-hardware-giants-in-2026",
    "title": "AI Demand Top of Mind for PC, Hardware Giants in 2026",
    "description": "Woo Jin Ho, Bloomberg Intelligence Senior Technology Analyst, joins Paul Sweeney and Kristine Aquino on Bloomberg Intelligence to discuss the 2026 outlook for the PC and computer hardware market, including Micron, Dell, HP, and more. AI is top of mind for these companies as server demand continues to accelerate. Dell in particular is expected to see a broadening customer base that will support a high-single-digit compound annual growth rate through fiscal 2030. Robust AI order activity and stable traditional server and storage trends will help sustain momentum. Elsewhere, Micron's 2026 DRAM-supply outlook offers little relief for HP and Dell's PC sales and margin.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-24/ai-demand-top-of-mind-for-pc-hardware-giants-in-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/izbXNkW.5AMc/v3/-1x-1.jpg",
    "created_at": "2025-12-25T12:22:46.453Z",
    "topic": "tech"
  },
  {
    "slug": "monetizers-vs-manufactures-how-the-ai-market-could-splinter-in-2026",
    "title": "Monetizers vs. manufactures: How the AI market could splinter in 2026",
    "description": "AI infrastructure firms are set to win from the evolution of once asset-light Big Tech firms.",
    "fullText": "The AI market is tipped to splinter in 2026.\n\nThe last three months of 2025 were a rollercoaster of tech sell-offs and rallies, as circular deals, debt issuances, and high valuations fueled concerns over an AI bubble.\n\nSuch volatility may be an early sign of how AI investment is set to evolve as investors pay closer attention to who is spending money and who is making it, according to Stephen Yiu, chief investment officer at Blue Whale Growth Fund.\n\nInvestors, especially retail investors who are exposed to AI through ETFs, typically have not differentiated between companies with a product but no business model, those burning cash to fund AI infrastructure, or those on the receiving end of AI spending, Yiu told CNBC.\n\nSo far, \"every company seems to be winning,\" but AI is in its early innings, he said. \"It's very important to differentiate\" between different types of companies, which is \"what the market might start to do,\" Yiu added.\n\nHe sees three camps: private companies or startups, listed AI spenders and AI infrastructure firms.\n\nThe first group, which includes OpenAI and Anthropic, lured $176.5 billion in venture capital in the first three quarters of 2025, per PitchBook data. Meanwhile, Big Tech names such as Amazon, Microsoft and Meta are the ones cutting checks to AI infrastructure providers such as Nvidia and Broadcom.\n\nBlue Whale Growth Fund measures a company's free cash flow yield, which is the amount of money a company generates after capital expenditure, against its stock price, to figure out whether valuations are justified.\n\nMost companies within the Magnificent 7 are \"trading a significant premium\" since they started heavily investing in AI, Yiu said.\n\n\"When I'm looking at valuations in AI, I would not want to position — even though I believe in how AI is going to change the world — into the AI spenders,\" he added, adding that his firm would rather be \"on the receiving end\" as AI spending is set to further impact company finances.\n\nThe AI \"froth\" is \"concentrated in specific segments rather than across the broader market,\" Julien Lafargue, chief market strategist at Barclays Private Bank and Wealth Management, told CNBC.\n\nThe bigger risk lies with companies that are securing investment from the AI bull run but are yet to generate earnings — \"for example, some quantum computing-related companies,\" Lafargue said.\n\n\"In these cases, investor positioning seems driven more by optimism than by tangible results,\" he added, saying that \"differentiation is key.\"\n\nThe need for differentiation also reflects an evolution of Big Tech business models. Once asset-light firms are increasingly asset-heavy as they gobble up technology, power and land needed for their bullish AI strategies.\n\nCompanies like Meta and Google have morphed into hyperscalers that invest heavily in GPUs, data centers, and AI-driven products, which changes their risk profile and business model.\n\nDorian Carrell, Schroders' head of multi-asset income, said valuing these companies like software and capex-light plays may no longer make sense — especially as companies are still figuring out how to fund their AI plans.\n\n\"We're not saying it's not going to work, we're not saying it's not going to come through in the next few years, but we are saying, should you pay such a high multiple with such high growth expectations baked in,\" Carrell told CNBC's \"Squawk Box Europe\" on Dec. 1.\n\nTech turned to the debt markets to fund AI infrastructure this year, though investors were cautious about a reliance on debt. While Meta and Amazon have raised funds this way, \"they're still net cash positioned,\" Quilter Cheviot's global head of technology research and investment strategist Ben Barringer told CNBC's \"Europe Early Edition\" on Nov. 20 — an important distinction from companies whose balance sheets may be tighter.\n\nThe private debt markets \"will be very interesting next year,\" Carrell added.\n\nIf incremental AI revenues don't outpace those expenses, margins will compress and investors will question their return on investment, Yiu said.\n\nIn addition, the performance gaps between companies could widen further as hardware and infrastructure depreciate. AI spenders will need to factor into their investments, Yiu added. \"It's not part of the P&L yet. Next year onwards, gradually, it will confound the numbers.\"\n\n\"So, there's going to be more and more differentiation.\"",
    "readingTime": 4,
    "keywords": [
      "blue whale",
      "whale growth",
      "growth fund",
      "business model",
      "debt markets",
      "saying it's",
      "the ai",
      "investment",
      "investors",
      "infrastructure"
    ],
    "qualityScore": 1,
    "link": "https://www.cnbc.com/2025/12/25/how-the-ai-market-could-splinter-in-2026-.html",
    "thumbnail_url": "https://image.cnbcfm.com/api/v1/image/107362181-1705898756653-gettyimages-949382754-AFP_1474J6.jpeg?v=1765453108&w=1920&h=1080",
    "created_at": "2025-12-25T12:22:39.991Z",
    "topic": "tech"
  },
  {
    "slug": "ive-been-allergic-to-ai-for-a-long-time-an-interview-with-peter-thiel",
    "title": "'I've been allergic to AI for a long time': an interview with Peter Thiel",
    "description": "Peter Thiel has been described variously as ‘America’s leading public intellectual’, the ‘architect of Silicon Valley’s contemporary ethos’ or as an ‘incoherent and alarmingly super-nationalistic’ malevolent force. The PayPal and Palantir founder, a prominent early supporter of Donald Trump, is one of the world’s richest and most influential men. Throughout his career, his principal concern",
    "fullText": "Peter Thiel has been described variously as ‘America’s leading public intellectual’, the ‘architect of Silicon Valley’s contemporary ethos’ or as an ‘incoherent and alarmingly super-nationalistic’ malevolent force. The PayPal and Palantir founder, a prominent early supporter of Donald Trump, is one of the world’s richest and most influential men. Throughout his career, his principal concern has always been the future, so when The Spectator asked to interview him, he wanted to talk to young people. To that effect, three young members of the editorial team were sent to Los Angeles to meet him. What follows is an edited transcript of their conversation.\n\nWILLIAM ATKINSON: Following Zohran Mamdani’s victory in New York, an email that you sent five years ago has gone viral. You argued that with accumulating student debt and housing costs, it was no surprise that young people were turning to socialism. How do you explain that there are Gen Zs, like us, who aren’t on the left?\n\n‘The Trump administration is trying to pull off an extremely difficult thing. America is no longer a great country’\n\nPETER THIEL: My sense is that in the US, Britain, Germany and France, the Gen Z voters are less centrist. I wouldn’t say they’re more drawn to the extremes, but they do not believe there are solutions within the Overton window straitjacket, the narrow space that’s been defined between New Labour and the Tories [in the UK] for the past three decades. And then there’s Reform, a party that repudiates that spectrum. For the first time in 200 years, there’s a real party to the right of the Tories. It’s not just a Gen Z phenomenon, but there’s a Gen Z part that is very important.\n\nWE: You first argued in the late 2000s that the backlash from globalisation would upend politics. Do you often feel that the world is catching up with Peter Thiel?\n\nPT: These things were coming for a long time. Student debt was $300 billion in 2000, around $2 trillion today. The GFC [global financial crisis] in 2008 was a big watershed. Entry-level jobs became less well paid. For students graduating after 2008, it became much, much harder to get out of the debt. Student debt slows you down from buying a house, getting started with forming a family, becoming an actual adult. You end up with a completely different society. It takes a long time to figure this out. But I started talking about this a lot in 2010… Why did house prices go up so much faster than incomes? Not enough was built. A big part was built as a retirement vehicle for older people. They were happy with the prices going up. The Tory party in the UK is probably completely past the point of no return. The suggestion that I have had was that you must start by throwing everybody out of the party who comes from real estate. You must be willing to purge all the people that are part of this dysfunctional system.\n\nJOHN POWER: What would your advice be to someone in their twenties about how they can have an impact in politics? Should they join Reform?\n\nPT: I think about politics a fair bit, but if I spent all my life on it, I would go out of my mind. I would like people to be more involved in right-wing politics, but I’m not sure that’s the best thing for most. You certainly should work for Reform rather than Labour or the Tories. You can criticise Nigel Farage as too much of a Boomer but he’s less structurally hateful to the young people. But maybe this is not the right way to frame the questions. We’re gonna have a revolution from Gen Z – all these crazy things that they are going to be doing. Is this good or bad? I’ve often said, in the early 20th century you think of both communism and fascism as youth movements that went very, very haywire. In the early 21st century, the reality is we have inverted demographic pyramids. There are not enough young people. We’re not going to get youthful communism or youthful fascism. We have this unbelievably oppressive, powerful gerontocracy. Maybe you can get communism or fascism of old people, but it’s very low-energy. It will avoid some of the defects of the early 20th century.But it’ll have many other kinds of problems. The general challenge for Gen Z is that there are big constraints.\n\nMy hope is that there always are some technological fixes, defining technology as doing more with less. If the debate is more with more spending or less with less spending, you end up with runaway deficits or extremely cruel rationing. I have critiques of the three biggest European countries – Germany, France and Britain. France is way too socialist. That doesn’t work. Germany is just insane. People have got caught up in crazed ideological fixations. There’s almost nothing like the Green party anywhere outside of Germany. Britain is neither too insane nor too socialist, but it’s extremely unpragmatic. It is extraordinary how lacking in common sense it is. The optimistic case for the UK is that there are extraordinary efficiencies one could wring out of the state. It has the greatest room for improvement of any European country. But why haven’t these things been done in the past 60 or 70 years?… Maybe the entire population is just too docile.\n\nLARA BROWN: You’ve talked before about Europe’s choice between ‘Greta on a bicycle’ environmentalism, Chinese surveillance and radical Islam. Would you say Europe has chosen one path?\n\nPT: The bad doors for Europe, the three doors of the future. For the future to have power as a cultural or political idea, you want it to be different. You can’t stay in this Groundhog Day, this Tory/Labour thing where we’re never doing anything new. The problem is the three actual pictures of the future. Behind door number one is Islamic sharia law. Behind door number two is the totalitarian CCP surveillance state, a hi-tech dystopia. Behind door number three is Greta with a bicycle, and then there’s no fourth door. This is why Greta’s been winning.\n\nJP: A lot of people on the American right talk incessantly about how terrible Britain and Europe are in general. But I think there’s selective blindness and chauvinism from some people on the American right about the condition of their own country. There is nowhere in Europe as bad as Skid Row in Los Angeles. What do you make of that?\n\nPT: I would defend the Trump version of the Republican party vs the zombie Reagan-Bush era. I don’t think President Trump or J.D. Vance are absurdly optimistic or panglossian about things. Make America Great Again was the most pessimistic slogan any president had in a century, and certainly that any Republican president ever had. The Trump administration is trying to pull off an extremely difficult thing, because the red pill is that America is no longer a great country. But you have to make sure it doesn’t become a gateway drug to a black pill, where you become nihilistic and give up and you’re destined to eat too many doughnuts in a trailer park. I don’t think that the right are overly optimistic in America. I don’t think there’s a problem where people describe things as even worse in other places. People in the US don’t pay attention to the world at all. We are a semi-autistic country. Maybe not quite as autistic as China, but we do not think about anything going on outside this country that much.\n\nLB: You mentioned the UK has undergone 70 years of stagnation. Many on the British right would agree, but may think that the period from 1979 to 1990 under Margaret Thatcher offered a respite from decline – she pursued unpopular but necessary policies such as anti-inflationary measures despite employment implications and her approach to the Unions. Would you question this narrative?\n\nPT: Reagan was very formative for me. I was in eighth grade in 1980 when Reagan got elected and felt at the time he was an incredibly great president and had solved all these problems once and for all. I think if I lived in the UK under Thatcher, I would have felt similarly. But they weren’t durable. We got Clinton and Blair after. The size of government didn’t shrink that much. The government sectors didn’t get weakened.\n\n‘Capitalism didn’t increase inequality but globalisation did’\n\nThere’s been a slowdown in tech since the 1970s. There was progress in the world of computers, internet, mobile, crypto, maybe now AI, but in a lot of other areas there was a much slower kind of progress. The question is, why did we not notice this faster? I think it’s because Reagan and Thatcher created a big lift. They made societies more capitalist by lowering marginal tax rates and deregulating. Lots of people got fired but the economy grew so most people ended up better off.\n\nReagan and Thatcher were exactly right for their time. But it wouldn’t work for all time. And to the extent that this distracts us from these science and technology questions, then it was somewhat problematic.\n\nThen there was the Clinton-Blair one-time fix, which was that you could somehow grow the economy and increase productivity through globalisation. That also probably gave you a big one-time lift. It came with very big long-term problems. It led to far more inequality. The Gini coefficient in the US went up more under Clinton than any other president post-1945. So capitalism did not increase inequality, but globalisation did.\n\nMy telling of the 50-year economic history is that we tried more capitalism with Reagan and Thatcher and it was the right thing to do. More globalism with Clinton and Blair was sort of the right thing to do, though it had more negative externalities that people were very dishonest about. We now need to do something very different.\n\nLB: Helen Andrews recently posited that feminism and gender-balance initiatives in the early Noughties led to a ‘Great Feminisation’. She claims this caused the prioritisation of safety over risk, a workplace culture dominated by consensus and appeals to emotion rather than logic in decision–making. How much do you buy into this as a theory of stagnation?\n\nPT: I think it’s very courageous of her to tackle something that is relatively taboo… Yes, I think there was a shift towards a risk-averse society. Feminisation was part of that. Things also went wrong with educational institutions or too much regulation. The deeper cause is that there was something dangerous and scary about where a lot of science and technology had gone.\n\nLB: Are you saying that diversity and inclusion efforts were an attempt to derail technological progress?\n\nPT: I think at some point people got very scared of where this stuff was going. Absolutely. It wasn’t just the nuclear thing. I would say that environmentalism as a movement was very focused on the dangers of limitless progress, even though in theory, you could have a lot of forms of environmentalism that would be pro-tech, right? If you’re concerned about climate change, we could build lots of new nuclear reactors that don’t emit carbon. But if we’re worried that nuclear reactors could be dual use and used to make nuclear weapons then you can’t do that. In some sense the energy shifted into this very anti-tech, anti-science direction for the past 50 years or so.\n\nLB: And you think DEI was a good way to achieve anti-tech goals?\n\n‘We’re going to end up with this really lame world where nothing happens but it’s maybe harder to blow up’\n\nPT: It’s always hard to know how intentional these things were. Diversity can function in an anti-tech way. If diversity really means homogenisation, let’s apply that to scientists. There’s no heterodoxy allowed, no heterodoxy on climate science, no heterodoxy on evolution, no heterodoxy on vaccines, on masks, on the origin of Covid. Everyone looks different but has to think alike. So diversity means conformity. And conformity is not compatible with science. And if diversity is a shibboleth, which I think is its important meaning, then we’re worshipping this god called diversity. It’s an unknown god. It’s a hypnotic magic trick that redirects our attention. And so we don’t care about science any more.\n\nJP: You seem to have a wider picture of American history, particularly in regard to wokeness. Many MAGA-adjacent people seem to think wokeness, or ‘cultural Marxism’, came from nowhere in the early 2010s, while you have identified before that it is a postwar phenomenon.\n\nPT: The culture wars are important. And there are ways in which there’s a side that’s right and there’s a side that’s wrong. But the big problem is that’s distracting us from things like housing or the economy generally, or science and tech or maybe even the CCP takeover of the world. This is where I push back against using the term ‘cultural Marxism’. I always think Marxism was at least about the economy. The focus on identity politics, multiculturalism, affirmative action, starts in the 1970s. That’s when inequality starts to go up. These things were at least correlated with us getting distracted from what I consider to be more important problems.\n\nJP: There are parts of the American right who now look at the changes of the 1960s, such the Civil Rights Act, and think it’s time to re-evaluate the postwar social consensus. What do you make of that?\n\nPT: I don’t think you can ever strictly go back. There are three questions about the history going back to the Helen Andrews piece or my stagnation thesis. First, there’s a question of what happened. Second is a question of why it happened. Then there is a very different question of what should be done now. That’s in some ways very different from the first two. Even if we can agree there’s been stagnation, even if we say the society became too feminised or too risk-averse, we don’t want to just get blackpilled from that. And then the question is: where are the places that you have some agency to get out of this straitjacket?\n\nWA: Are you optimistic that that’s happening? And do you think you’ve contributed towards it?\n\nPT: Somewhat, and very much yes.\n\nLB: Earlier you alluded to three doors we can go through: radical environmentalism, sharia law, or Chinese-style authoritarianism. If none of us wants to go through them then what’s the way out?\n\nPT: It’s a challenge on a political level because when you’re trying to win elections it ends up being about broader narratives. For people in Silicon Valley, in a way it’s more local. You can build a company and solve particular problems in that context. Silicon Valley turned out to be a big place where there was a moderate amount of freedom of action in the past few decades, although it wasn’t a panacea. There’s a part of me that thinks that for some problems you have to go through politics. If we’re going to come up with new cures and new types of nuclear power you have to somewhat deregulate the FDA [Food and Drug Administration] and the NRC [Nuclear Regulatory Commission]. Some of these things are entangled with politics. But a lot of progress has happened that is decoupled from politics. One of the things that’s still healthy about the United States, unlike Britain and France, is that the political capital, the financial capital, the technological capital are all in different places, so it is very decentred. There are places where these things overlap, but there’s some way where people are able to do things that are independent.\n\nJP: Is tech going to come to the rescue like the Eagles [in Lord of the Rings], deus ex machina, providing abundance that can kind of smooth over some of the economic challenges? And as a rejoinder to that, do you think the AI bubble is about to pop?\n\nPT: There are all sorts of things that I don’t particularly like about the AI revolution. It seems to be very concentrated on bigger companies, so it’s possible a lot of the returns are captured by a few companies, possibly leading to very uneven growth. While it may be a complement to human labour, it is probably more of a substitute than a complement. It will have a zero sum feel to a lot of people. At the same time if there is no other vector of growth in our society, we would be out of our minds not to take it. I don’t think it’s big enough to solve the budget deficit, but if the US embraces AI and Europe rejects it, I think the US is in somewhat better shape than Europe is.\n\n‘There are all sorts of things that I don’t particularly like about the AI revolution’\n\nOn the question of whether or not it is a bubble, I get asked this a lot by Europeans and that is how you know that they’re not going to build a lot of AI in Europe. If it’s a bubble, then people are spending too much money on AI, and they’re building too many data centres and buying too many chips, and you’re eventually going to get seriously diminishing returns on that. During the 1990s bubble, it was mainly the telecom fibre-optic infrastructure stuff where people really spent way too much and that had to get dialled back. But maybe it’s the other way around where there are high returns to AI, enabling the automation of certain workflows and enhanced productivity.\n\nIf the AI bubble does not burst, it’s possible that it ends up being quite inflationary because you have to use more power for these data centres. The atoms part of our economy is regulated and it’s hard to ramp up the power. But if the returns on power going to AI chips are really high, it will absorb a lot of energy. Interest rates could be higher because there’s more demand for capital. My macroeconomic placeholder is that it’s going to keep going.\n\nI’ve been allergic to AI for a long time because it can be a horrible buzzword. There was a 2016 report during the Obama administration on AI by the National Science and Technology council. If you did a search and replace, and replaced every use of the word AI with computers, it would have read the same way.\n\nAI also meant all these really different things over time. In 2014, [Nick] Bostrom defined it as machines being way smarter than humans. Kai-fu Lee wrote the CCP counterpoint AI Superpowers in 2017, where he defined it as this sort of low-tech, big data machine learning. Then in 2022 it turns out the AI revolution is LLMs [large language models] which can pass the Turing test. People had thought this would be what AI was for 70 years. So in the decade before we were about to pass the Turing test we had forgotten about it.\n\nThe dynamic when one has to think through a lot \n\nIf you look at the ratio of how many businesses there are per 100,000 people: what part of the US has the lowest number of businesses? Silicon Valley. That’s because the costs of business are higher, so these subscale businesses that are too small to go anywhere are even harder to get started. In a third-world country where there are no good businesses and everyone is an umbrella salesman, they are very entrepreneurial, but not in a scalable way. So you need to differentiate entrepreneurship from scalable businesses.\n\n‘If you’re too focused on history, you don’t pay enough attention to the future’\n\nThere’s this economist called Thomas Gür who has researched the idea that immigrants are more entrepreneurial. While that is correct, you have to adjust for the quality of the businesses and the immigrants start businesses by starting a taco truck because there’s nothing else you can do. It’s better than going on welfare. But that’s what you do when you’re not really part of a society. It’s better than nothing, but what you really want to do is scale.\n\nJP: Is there a cutting-edge domain that you would focus your energies on?\n\nPT: One of the lines we had in Zero to One [Thiel’s 2014 book about startups co-written with Blake Masters] is from Anna Karenina. It’s the opening line: ‘Happy families are all alike; every unhappy family is unhappy in its own way.’ The opposite is true of business. All failed businesses are more or less alike because they fail to escape from this problem of homogeneous competition. They didn’t do anything special. All successful businesses are special in their own way. That’s the closest I can give you to a formula and it’s incredibly hard to figure out what that is, or how to do it. I have some feel for it, I know it when I see it.\n\nTo wrap things up, I have spent a lot of time thinking about the past. That’s because it’s important. It’s how we got here. It’s what shaped a lot of these debates. At the same time, there’s also some limit to history. If you’re too focused on it, you don’t pay enough attention to the future. The point is not just to reflect on the past.\n\nThere was a medieval play on the Antichrist from 1160 or so, Ludus de Antichristo. It’s not a very good literary production, but there are these three kings, the Antichrist conquerors who focus on things like nationalism or their countries or their history. They lose because they’re too fixated on the past whilst the Antichrist is thinking about the future, and about what can be done. They don’t see Antichrist coming. So while it’s very important for those on the right to think about the past, to think about the history and what happened – they still should not lose sight of the future.",
    "readingTime": 19,
    "keywords": [
      "turing test",
      "student debt",
      "behind door",
      "cultural marxism",
      "trump administration",
      "sharia law",
      "extremely difficult",
      "increase inequality",
      "nuclear reactors",
      "don’t particularly"
    ],
    "qualityScore": 1,
    "link": "https://spectator.com/article/ive-been-allergic-to-ai-for-a-long-time-an-interview-with-peter-thiel/",
    "thumbnail_url": "https://spectator.com/wp-content/uploads/2025/12/thiel_inside_colour_002.jpg",
    "created_at": "2025-12-25T12:22:24.690Z",
    "topic": "tech"
  }
]
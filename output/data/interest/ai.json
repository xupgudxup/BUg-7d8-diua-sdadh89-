[
  {
    "slug": "drawing-guessing-game-with-an-llm",
    "title": "Drawing Guessing Game with an LLM",
    "description": "A personal sketchbook of experiments using LLMs and more.",
    "fullText": "A personal sketchbook of experiments using LLMs and more.\nNothing perfect, just pure curiosity and fun.\n\nThis experience is best viewed on a desktop or laptop computer.\n\nYou can still watch the screencasts on mobile.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://llmparty.pixeletes.com/experiments/sketch_off",
    "thumbnail_url": "https://your-domain.com/images/social/og-image.png",
    "created_at": "2025-12-15T13:53:49.129Z",
    "topic": "tech"
  },
  {
    "slug": "agentcontainers-opensource-web-ui-for-ai-dev-environments-on-docker",
    "title": "AgentContainers – Open-source web UI for AI dev environments on Docker",
    "description": "Spin up isolated containers. SSH in. Let your AI go full YOLO. Free and open source.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://agentcontainers.com",
    "thumbnail_url": "https://github.com/Launchable-AI/agentcontainers-community/raw/main/docs/screenshot.png",
    "created_at": "2025-12-15T13:53:48.402Z",
    "topic": "tech"
  },
  {
    "slug": "it-seems-that-openai-is-scraping-certificate-transparency-logs",
    "title": "It seems that OpenAI is scraping [certificate transparency] logs",
    "description": "lol.",
    "fullText": "I minted a new TLS cert and it seems that OpenAI is scraping CT logs for what I assume are things to scrape from, based on the near instant response from this:\n\nwolf480pl@mstdn.io\n\nreplied 12 Dec 2025 20:57 +0000\n\nin reply to: https://benjojo.co.uk/u/benjojo/h/Gxy2qrCkn1Y327Y6D3\n\n@benjojo\nwp-login.php bots have been doing that for years so I'd be surprised if OpenAI didn't\n\nbenjojo\n\nreplied 12 Dec 2025 21:10 +0000\n\nin reply to: https://mstdn.io/users/wolf480pl/statuses/115708595554461422\n\n@wolf480pl yeah and I guess it's a non terrible way of \"seeding\" a \"search engine\"\n\nwolf480pl@mstdn.io\n\nreplied 13 Dec 2025 12:59 +0000\n\nin reply to: https://benjojo.co.uk/u/benjojo/h/NgH2Xwlp4KhCTwHjRL\n\n@benjojo\nwhat if CT logs contained hash(domain, nonce) instead of containing the domain in plain, and the nonce was part of the CT inclusion proof?\n\nbenjojo\n\nreplied 13 Dec 2025 14:53 +0000\n\nin reply to: https://mstdn.io/users/wolf480pl/statuses/115712376924287199\n\n@wolf480pl the point of certificate transparency logs is so that outside observers can do the double-checking of the CAs certificate and policy in full, if you mess with any part of this, the entire system becomes deeply exploitable and difficult to end to end verify\n\nwolf480pl@mstdn.io\n\nreplied 13 Dec 2025 15:55 +0000\n\nin reply to: https://benjojo.co.uk/u/benjojo/h/lPLWBh3YCbFJBH4Dt6\n\n@benjojo\noh, duh I need to be able to find who's issuing carts for my domain\n\nand I'm guessing some people look at all certs issued by CAs and verify certain criteria that may require knowing the domains...\n\nit's kinda sad that it provides domain enumeration, but I guess putting addng zero-knowledge proofs to the mix would've been too complex\n\nbenjojo\n\nreplied 13 Dec 2025 18:00 +0000\n\nin reply to: https://mstdn.io/users/wolf480pl/statuses/115713071072619432\n\n@wolf480pl tbh domain's are not really that secret, and if you depended on that then something was very wrong.\n\nYou can work around a lot of this stuff by \"just\" using wildcard certs instead\n\nwolf480pl@mstdn.io\n\nreplied 13 Dec 2025 18:07 +0000\n\nin reply to: https://benjojo.co.uk/u/benjojo/h/pyX28McwZyTh14hy55\n\n@benjojo\nbut then why bother with NSEC3...\n\nbenjojo\n\nreplied 13 Dec 2025 23:29 +0000\n\nin reply to: https://mstdn.io/users/wolf480pl/statuses/115713588719701003\n\n@wolf480pl tbh I would argue why bother with DNSSEC (outside of extremely marginal situations), but NSEC3 even more\n\njamesog@mastodon.soc..\n\nreplied 12 Dec 2025 21:09 +0000\n\nin reply to: https://benjojo.co.uk/u/benjojo/h/Gxy2qrCkn1Y327Y6D3\n\n@benjojo It's interesting to watch web server logs to see what things pick up new CT entries the quickest",
    "readingTime": 2,
    "keywords": [
      "replied dec",
      "https://mstdn.io/users/wolf480pl/statuses wolf480pl",
      "wolf480pl tbh",
      "wolf480pl@mstdn.io replied",
      "https://benjojo.co.uk/u/benjojo/h/gxy2qrckn1y327y6d benjojo",
      "reply",
      "logs",
      "it's",
      "domain",
      "openai"
    ],
    "qualityScore": 1,
    "link": "https://benjojo.co.uk/u/benjojo/h/Gxy2qrCkn1Y327Y6D3",
    "thumbnail_url": "https://benjojo.co.uk/meme/a.jpg",
    "created_at": "2025-12-15T13:53:48.016Z",
    "topic": "tech"
  },
  {
    "slug": "ceos-usually-favor-less-regulation-but-not-all-are-happy-with-trumps-executive-order-to-block-state-ai-laws",
    "title": "CEOs usually favor less regulation. But not all are happy with Trump’s executive order to block state AI laws",
    "description": "Also: All the news and watercooler chat from Fortune.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/15/trump-ai-state-laws-executive-order-ceo-reaction/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2251459965-e1765756632100.jpg?resize=1200,600",
    "created_at": "2025-12-15T13:53:47.813Z",
    "topic": "business"
  },
  {
    "slug": "deloittes-cto-on-a-stunning-ai-transformation-stat-companies-are-spending-93-on-tech-and-only-7-on-people",
    "title": "Deloitte’s CTO on a stunning AI transformation stat: companies are spending 93% on tech and only 7% on people",
    "description": "Bill Briggs recognizes an old inertia inside the boardroom: \"I felt it in my travels, but I hadn't been able to quantify it.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/15/deloitte-cto-bill-briggs-what-really-scares-ceos-about-ai-human-resources/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/Bill-Briggs_101dd7.jpg?resize=1200,600",
    "created_at": "2025-12-15T13:53:47.812Z",
    "topic": "business"
  },
  {
    "slug": "making-nightmares-into-reality-ai-finds-fans-in-the-islamic-state-other-militant-and-terrorist-other-groups-worldwide",
    "title": "Making nightmares into reality: AI finds fans in the Islamic State, other militant and terrorist other groups worldwide",
    "description": "“One of the best things about AI is how easy it is to use,” said someone on a pro-IS site last month.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/15/ai-islamic-state-terrorist-militant-groups-recruitment-deepfakes/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/AP25346792443794.jpg?resize=1200,600",
    "created_at": "2025-12-15T13:53:47.770Z",
    "topic": "business"
  },
  {
    "slug": "earnings-calls-citing-ai-surge-in-2025-as-uncertainty-mentions-fade",
    "title": "Earnings calls citing ‘AI’ surge in 2025 as ‘uncertainty’ mentions fade",
    "description": "AI talk hits a record high.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/15/earnings-calls-citing-ai-surge-2025-uncertainty-mentions-fade-cfo/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2241286143-e1765800559281.jpg?resize=1200,600",
    "created_at": "2025-12-15T13:53:47.571Z",
    "topic": "business"
  },
  {
    "slug": "inside-metas-year-of-intensity-as-its-ai-overhaul-culture-wars-and-crackdowns-collide",
    "title": "Inside Meta's 'year of intensity' as its AI overhaul, culture wars, and crackdowns collide",
    "description": "Meta's AI overhaul, culture shifts, layoffs, and performance crackdowns have sparked internal clashes, employee exits, and morale concerns in 2025.",
    "fullText": "When CEO Mark Zuckerberg warned Meta employees in January to \"buckle up\" for an \"intense\" year, he meant it.\n\nDetermined to dominate the next era of AI, Meta has spent the past year in blitz mode. Zuckerberg has overhauled divisions, reallocated resources to new products, and poured billions into the AI arms race with OpenAI, Google, and others. Zuckerberg's push came with a marked shift in leadership tone as well, including his public celebration of what he described as more \"masculine energy.\"\n\nAlong the way, the company has trimmed its metaverse ambitions, raised performance expectations, and cut thousands of jobs, all while chasing Zuckerberg's grand vision of \"personal superintelligence.\"\n\nIn some ways, the moves have boosted efficiency and led to faster innovation. In others, some divisions have been roiled by internal tensions, including clashes resulting from AI reorganizations and Zuckerberg flaming the AI talent wars, according to current and former employees. Some also said Meta's layoffs earlier this year were unnecessarily demoralizing when Zuckerberg branded the affected employees as \"low performers.\"\n\nThe company's transformation comes at a time when Big Tech is rewriting its playbook, cutting costs, toughening its tone with employees, and making massive bets that AI will determine who leads in the next decade.\n\nMeta is wagering that moving harder and faster will help give the company an edge over its rivals. After months of a cultural reset in early 2025, employee sentiment improved in recent months, a Meta spokesperson said, citing a recent internal employee sentiment questionnaire.\n\nInvestors are worried about the company's strategy, particularly its plan to sink tens of billions of dollars into AI infrastructure and talent. The question is whether Meta is overdoing it. Shares have risen 7.5% this year, less than half that of the S&P 500, and have underperformed most of the so-called Magnificent 7 companies.\n\n\"The company must articulate its vision, show how its pieces fit together, and, most importantly, demonstrate steady growth,\" said Mike Proulx, research director at Forrester, who covers Meta.\n\nThis account of Meta's \"year of intensity\" is based on interviews conducted by Business Insider with more than a dozen current and former employees, analysts, and academic researchers.\n\nOver the summer, Zuckerberg sought to change the perception that Meta was trailing behind its AI rivals. In June, the company made a $14 billion investment in AI training company Scale AI and hired its 28-year-old founder, Alexandr Wang, as chief AI officer. Two months later, it rebranded its team focused on AI efforts to Meta Superintelligence Labs (MSL).\n\nAs Meta's leadership sought to reorganize teams and recruit top talent from competitors, some ex-employees went public with the view that the company lacked a coherent AI strategy.\n\nJoena Zhang, a former Meta Superintelligence Labs employee, said in a November LinkedIn post that \"nobody really knew what anyone was doing\" during the first half of the year at MSL — then called GenAI. She said there were \"endless\" meetings that didn't result in \"actual decisions.\" And in a July Substack post, former Meta researcher Tijmen Blankevoort wrote that Meta had \"a wavering vision that was tough for team members to enthusiastically rally behind.\"\n\nMeta began offering massive compensation packages to attract top AI talent from rival labs, including OpenAI and Google's AI division, DeepMind.\n\nThis created rifts between the \"old guard\" and newer hires by offering outsiders significantly more compensation than existing employees got. It fueled a quiet competition to prove whose ideas for AI features were more valuable, according to two MSL employees.\n\nThe tensions also revolved around access to computing resources and the prestige of being associated with the elite team at the center of MSL, as one researcher previously told Business Insider.\n\nIn August, Meta undertook its fourth major reorganization in six months to streamline its AI efforts, dividing MSL into four teams: a new TBD Lab (short for \"to be determined\"), a product team overseeing the Meta AI assistant, an infrastructure team, and the company's long-standing Fundamental AI Research (FAIR) lab.\n\nAfter the shake-up, it was unclear who owned which projects, and people were reassigned between teams, according to the two MSL employees, one of whom added that the flow of information between TBD and MSL wasn't always even.\n\nAsked about the internal shake-up, a Meta spokesperson pointed Business Insider to an X post from Andy Stone, a Meta communications executive, describing previous reporting about the company's AI restructuring as \"navelgazing.\"\n\nAt least eight of Meta's AI staffers, including researchers, engineers, and a senior product leader, left the company within two months of MSL's formation. Meta said most had been with the company for years, and that some attrition is normal for an organization of its size.\n\nTwo months after the August shuffle, Meta cut about 600 jobs as part of a wider reorganization of the MSL division. Wang told employees that the cuts were designed to speed up decision-making.\n\nShay Boloor, chief market strategist at Futurum Equities, told Business Insider that the changes have helped Meta move faster in model releases and in integrating its AI across Facebook, Instagram, and WhatsApp.\n\n\"Meta is now one of the only companies training frontier-class models and deploying them to billions of users, which is exactly where I want it to be,\" he said.\n\nMeta also shook up its leadership ranks in Reality Labs, the division responsible for developing its virtual and mixed reality products.\n\nThe company is considering budget cuts for the metaverse unit that sits within Reality Labs, which could result in job cuts, a person familiar with the matter previously told Business Insider. A Meta spokesperson said that it is reallocating some of its investment \"from Metaverse toward AI glasses and wearables\" to match momentum, adding that the company \"wasn't planning any broader changes than that.\"\n\nThe MSL layoffs were part of a broader effort by Meta to tighten operational efficiency this year, as the company reduced layers of management and implemented a stricter performance review process than in previous years.\n\nZuckerberg told employees in January he had \"decided to raise the bar on performance management\" and would move quickly to cut about 5% of \"low performers.\" The company cut about 3,600 jobs in February from its workforce of about 78,450 employees.\n\nMultiple employees said the revised system created a pressure-cooker environment and encouraged more cutthroat competition between staff. Managers and employees described a shift toward short-term projects as teams looked to protect themselves from landing at the bottom of the ranking.\n\nThe requirement to place more staff in lower performance tiers saw some managers strategically leave positions open or hire employees solely to place them in the bottom tier, two managers said.\n\nThe company says employee sentiment improved in the second half of the year. Its latest internal employee sentiment questionnaire, which ran from October 20 to November 3, showed \"optimism\" rose to 80%, \"pride\" at 71% and \"confidence in leadership\" at 68%, according to data Meta shared with Business Insider.\n\nEach of those metrics was up between 10 and 12 percentage points compared to the last survey, which ran April 21 through May 5, the spokesperson said. The latest survey had a 91% participation rate, Meta said.\n\nThe combination of policy shifts, reorganizations, job cuts, and stricter performance expectations triggered a wave of departures in 2025, according to five internal farewell posts reviewed by Business Insider. Some employees said Meta's evolving political posture and internal governance changes no longer aligned with their values.\n\n\"Meta in 2025 is a very different company from what Oculus & Facebook were in 2017,\" one engineer, who left Meta in August after nearly eight years at the company, wrote in an internal farewell message, viewed by Business Insider. These types of notes are known internally as \"badge posts.\"\n\nHe cited a \"matter of principles\" for his departure, adding that the \"sometimes implicit, sometimes explicit alignment with the new US government\" clashed with his personal values.\n\nSimilar themes surfaced in other employee departures this year.\n\n\"The unnecessary pressure, lack of empathy, and occasional lack of fairness,\" one former employee wrote in another farewell post from January, seen by Business Insider. \"Fighting for scope. Narratives. Oh, the narratives - I'm so looking forward to not hearing that word for a while. Smart and kind people bending their values to survive because they've been on the edge of their seats for too long.\"\n\nA Meta spokesperson said the resignations represent a small slice of the company. Meta has 78,450 employees, and head count is up 8% year-over-year.\n\nSome departing employees told Business Insider that they no longer had a meaningful outlet to share feedback with leadership on topics such as DEI and embracing \"masculine energy\" because questions for Q&A sessions were preselected, and that posts critical of leadership decisions were sometimes removed from the platform.\n\n\"We will skip questions that we expect might be unproductive if they leak or things like people-related questions that have already been answered,\" Meta's VP of internal communications, Jonny Oser, informed employees in an internal post earlier this year.\n\nIn a January poll titled \"Measuring workplace fear,\" dozens of Meta employees voted anonymously on how afraid they were that speaking openly about working conditions could lead to disciplinary action. The winning responses were \"extremely afraid\" and \"very afraid,\" according to a screenshot of the poll viewed by Business Insider.\n\nEven as some employees headed for the exits, others say they are optimistic about the new environment.\n\nTwo current employees told Business Insider that Meta can be a rewarding place to work, particularly for individuals accustomed to operating in high-pressure environments.\n\n\"I would say that people who are confident in their skills and are high performers generally thrive,\" one senior engineer said.\n\nAnother Meta veteran said the company used to \"coddle its staff\" — but \"that's changing.\"\n\nAn engineer said there are reasons to stay put. \"The positives are that we are still on the frontier in R&D,\" they said. \"There are a lot of cool AI, wearables, and robotics things going on,\" giving high-performing employees a chance to learn and build \"a lot of good skills.\"\n\n\"Also, we get paid a lot, still, and get free food and snacks,\" they said. \"That helps.\"",
    "readingTime": 9,
    "keywords": [
      "superintelligence labs",
      "masculine energy",
      "sentiment improved",
      "sentiment questionnaire",
      "job cuts",
      "performance expectations",
      "stricter performance",
      "employee sentiment",
      "meta superintelligence",
      "business insider"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-ai-overhaul-mark-zuckerberg-year-intensity-2025-12",
    "thumbnail_url": "https://i.insider.com/693709c77ecd1d1da6631d51?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:47.181Z",
    "topic": "finance"
  },
  {
    "slug": "how-famed-shortseller-andrew-left-uses-ai-to-prepare-for-his-criminal-case",
    "title": "How famed short-seller Andrew Left uses AI to prepare for his criminal case",
    "description": "Andrew Left is headed for a big legal fight in 2026. Business Insider viewed his conversation with Claude to see how he's prepping for the case.",
    "fullText": "Famed short-seller Andrew Left is in the legal fight of his life, set to stand trial in March on allegations of market manipulation and making false and misleading social-media posts about his trading plans.\n\nAs he prepares to battle the feds, one of the places he's gone to for help is Claude. No, that's not the name of his defense lawyer. Claude, in this case, is Anthropic's popular AI chatbot.\n\nBusiness Insider recently got a look at how Left is using artificial intelligence in connection with his criminal case when he included a chat log during an email exchange with us.\n\nIt showed Left peppering Claude with questions and even asking it to draft a letter that his human legal team could, hypothetically, send to the Department of Justice.\n\nIt started with a simple but important question from the outspoken investor behind Citron Research: \"is this good or bad for andrew left\".\n\nLeft, who said he didn't mean to send the chat log to Business Insider, later explained he had uploaded to Claude a document related to his case and wanted a quick, easy-to-understand analysis.\n\n\"If you're ever in a court case, you just get something from the DOJ — instead of reading eight pages, you just put it into AI,\" he said after Business Insider asked him about the log. \"You go, 'What does this mean?'\"\n\nLeft, 55, became something of a market celebrity a decade ago after he raised serious claims about the business practices of Valeant Pharmaceuticals, which was later investigated by federal prosecutors, regulators, and Congress.\n\nHe has also predicted the business woes of companies like Nikola and Hertz, which gave his research reports market-moving sway.\n\nIn filing criminal charges last year, federal prosecutors alleged that Left took trading positions contrary to those market moves in order to reap quick profits. They say he manipulated prices over roughly five years across at least 23 different stocks and made false statements to regulators about coordinating his trades with hedge funds.\n\nThe docket for his case shows seven attorneys who previously or currently represent Left. But Claude, which has been gaining traction with lawyers, apparently came in handy one day last month.\n\nEric Rosen, a partner at Dynamis LLP, one of the firms representing Left, told Business Insider that AI can be valuable as a tool for understanding complex legal materials but cautioned against relying on it too much.\n\n\"It gives you a lot of feedback that you want to hear,\" he said. \"But, you don't know how a judge is going to react to some of these arguments.\"\n\nAlthough Business Insider only saw a portion of Left's conversation with Claude, it was clear that the document he uploaded had something to do with Nvidia. That made sense since the federal indictment alleges Left took a bullish position in the chipmaker's stock in November 2018, tweeted a lofty price target for it, then sold shares hours later, after they spiked.\n\nIn an answer to Left's query about the document, Claude had what sounded like good news, saying it revealed \"critical weaknesses\" in the government's case that was \"potentially very good\" for him.\n\nIt then listed four \"major problems\" with the Justice Department case and offered four \"best defenses\":\n\nLeft volleyed back at the chatbot, playfully patting himself on the back — and Claude gave him positive reinforcement.\n\nThe chatbot then singled out a specific thing that Left had tweeted, that Nvidia would reach \"$165 before $120.\" (It was at about $144 at the time.) Claude pointed out that the stock actually bottomed out at $124 in December before rising to $160 by June 2019.\n\n\"You were spectacularly right at a critical inflection point,\" the chatbot reassured Left.\n\nIn the same response, Claude broke down what it sees as the \"real issue\":\n\nLeft's next two prompts dealt with a stock split announced by Nvidia. The end goal of his inquiries was to show that — factoring in splits — he was directionally correct with his bullish price target on Nvidia stock.\n\nAfter Claude laid out an analysis reassuring Left that his Nvidia forecast was ultimately correct, he followed up with:\n\nAnd then here's what Claude said about the \"legal implication\":\n\n(Note that the supposed 1,300% gain is based on an incorrectly calculated current stock price for Nvidia. It is trading at around $176 a share, not the split-adjusted $1,931 used by Claude.)\n\nLeft wasn't done. He asked Claude to put all his responses into a letter addressed to the DOJ from his attorney. His only suggestion was to make it \"not AI sounding.\"\n\nAfter it returned a roughly 250-word block of text, Left had another edit:\n\nThat got it down to about 150 words. What next?\n\nEver-obedient, Claude spat out this:\n\nMatthew Cain, whose name surfaced when Claude analyzed the document, did not respond to a request for comment.\n\nLeft said that for him, the AI served as a kind of thought partner.\n\n\"I was writing because I wanted to figure out, as we were going into this case and my attorneys met with the Department of Justice, how to try and explain it,\" he told Business Insider.\n\nLeft noted that he'd seen the AI misinterpret the law, but he does not worry about the chatbot's hallucinations.\n\n\"I run all ideas to just see the other side of the argument,\" he said. \"It definitely opens your mind up, but you cannot rely on it for matters of law.\"\n\nAnthropic, the makers of the Claude chatbot, did not respond to Business Insider's request for a comment. The Justice Department also did not comment.\n\nIt's not clear if Claude's text for a letter ever made its way to Left's defense team or to prosecutors, but he didn't sell it short to us. In fact, he told Business Insider that Claude is his favorite AI.",
    "readingTime": 5,
    "keywords": [
      "chat log",
      "federal prosecutors",
      "business insider",
      "claude",
      "chatbot",
      "stock",
      "legal",
      "document",
      "left's",
      "market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrew-left-short-seller-securities-fraud-legal-defense-claude-ai-2025-12",
    "thumbnail_url": "https://i.insider.com/69248813abd5e944effb5b59?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:47.029Z",
    "topic": "finance"
  },
  {
    "slug": "sergey-brin-who-came-back-to-google-to-work-on-gemini-says-staying-retired-would-have-been-a-big-mistake",
    "title": "Sergey Brin, who came back to Google to work on Gemini, says staying retired would have been a 'big mistake'",
    "description": "Sergey Brin says the pandemic pushed him back into Google, where he's now helping drive its Gemini AI efforts.",
    "fullText": "Sergey Brin tried retirement — and immediately regretted it.\n\nSpeaking at Stanford University's School of Engineering centennial celebration last week, the Google cofounder said he stepped back from day-to-day work in December 2019, imagining he'd spend leisurely days and \"sit in cafés and study physics.\"\n\n\"That didn't work because there were no more cafés,\" he joked.\n\nWorse, he said he felt himself \"spiraling\" and \"kind of not being sharp\" without the intellectual stimulation he'd always relied on.\n\nSo as soon as Google began allowing a small number of employees back into its offices, he joined them — eventually diving into what became Gemini, Google's flagship AI model.\n\n\"To be able to have that technical creative outlet, I think that's very rewarding,\" the 52-year-old said. \"If I'd stayed retired, I think that would've been a big mistake.\"\n\nBrin also offered a candid assessment of Google's AI trajectory.\n\nDespite publishing the 2017 \"Transformer\" paper that underpins nearly every major AI model today, he said Google \"underinvested\" in the technology and was \"too scared to bring it to people because chatbots say dumb things.\"\n\nOpenAI, he said, \"ran with it, which, good for them.\"\n\nStill, he said Google retained an edge through its long-standing investment in neural-network research, custom AI chips, and massive data center infrastructure.\n\n\"Very few have that scale,\" he said.\n\nAsked what students should study in an era when AI can code, Brin warned against fleeing technical fields.\n\n\"I wouldn't switch to comparative literature because you think AI is good at coding,\" he said. \"The AI is probably even better at comparative literature.\"\n\nHe also shared what he sees as the biggest mistake founders make — one he admits he fell into with Google Glass.\n\nHe rushed the product before it was affordable, polished, or even actually ready.\n\n\"Everybody thinks they're the next Steve Jobs,\" he said. \"I've definitely made that mistake.\"\n\nNow deeply involved in Gemini, Brin said the pace of AI development keeps him energized.\n\n\"It's absolutely amazing just the rate of innovation,\" he said. \"If you skip the news for a month, you're way behind.\"",
    "readingTime": 2,
    "keywords": [
      "comparative literature",
      "mistake",
      "back",
      "he'd",
      "cafés",
      "study",
      "model",
      "technical",
      "google",
      "brin"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sergey-brin-says-leaving-google-before-gemini-was-big-mistake-2025-12",
    "thumbnail_url": "https://i.insider.com/693fe6a064858d02d216c930?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:46.886Z",
    "topic": "finance"
  },
  {
    "slug": "new-ai-and-video-tech-is-taking-the-danger-and-guesswork-out-of-this-punishing-air-force-job-that-hasnt-changed-in-50",
    "title": "New AI and video tech is taking the danger and guesswork out of this punishing Air Force job that hasn't changed in 50 years",
    "description": "Tanker maintenance workers spend their days crawling in and out of fuel tanks. New tech might make a hard job a little easier.",
    "fullText": "Inside some of the Air Force's oldest refueling aircraft, technicians are crawling through tight, dirty spaces, painstakingly cleaning sealant on fuel tanks and tightening loose rivets.\n\nThey climb into the dark, cramped tanks with little more than a flashlight, some tools, and shaky comms. It can be hard to breathe, the air smells like jet fuel, the fixes aren't always clear, and the punishing work can be dangerous if done wrong.\n\nIt's a job that hasn't changed much in over 50 years, but new gear, including a live-feed video headset and artificial intelligence-enabled technology, is finally bringing it into the 21st century.\n\nThe Integrated Respirator Information System, known as IRIS and developed by MetroStar and ActionStreamer, is speeding up the maintenance process, company officials and Air Force technicians say, and making it safer and more efficient.\n\nTankers are important logistics assets, what the Air Force calls \"silent enablers,\" that support missions by helping keep fighters and bombers airborne for longer than the onboard fuel tanks can sustain alone. For instance, Operation Midnight Hammer, which saw US stealth bombers strike Iran's nuclear site this year, involved dozens of refueling tankers supporting the strike package.\n\nAlthough fighter aircraft like the F-35 Lightning II Joint Strike Fighter or bombers like the B-2 Spirit get the most attention, tankers like the KC-135 Stratotanker are critical to US and allied airpower. For them to be useful, though, they have to be well-maintained.\n\nIRIS began as an idea from two maintainers who noticed the broader potential of ActionStreamer's live-streaming tech — gear originally built for athletes to capture first-person views during games. The Air Force technicians pursued the concept for years, even as they rotated through new assignments and bases.\n\nThe Air Force had long believed that tools like this could be a major boost for maintainers. There were early forays into video tech in the 2000s, but the \"technology wasn't quite there,\" Master Sgt. Troy French, a former 100th Maintenance Squadron member, told Business Insider. \"An initial phase of this was kind of set up and abandoned because cameras weren't small enough.\"\n\nNow, though, Air Force maintainers based at Royal Air Force Mildenhall, a central refueling base for the US missions in Europe, Africa, and the Middle East, have been testing out IRIS.\n\n\"They were, to be honest with you, a little apprehensive to start with,\" ActionStreamer CEO Bob Lento said, noting it was the first significant change to how technicians have done their jobs in years. But by the end of the first week, attitudes had flipped. \"We were taking the cart out of the hangar into a safe area to do some software punch-ups, and they were like, 'Wait a minute, where are you going with that? We need to use that now.'\"\n\nOn a tanker aircraft like the KC-135, there's a hole just big enough for a person to fit through under the wing. It's the access point for the fuel tanks. \"You crawl up there and you contort your body to be able to lie down flat and then put your feet in,\" French said. Inside, it is a tight space with lots of bumps and edges.\n\nThe workers wear heavy protective suits to guard against fuel exposure and keep sweat out of the tanks. They carry a flashlight and breathe through respirators that feed fresh air in from a hose running outside the aircraft.\n\nOutside the aircraft, a support team stands by. One person runs tools to the person inside the tank while another monitors for any hazards or issues.\n\n\"If you need something, sometimes you just have to peel the respirator back, like, 'Hey, I need this extra wrench that I forgot,'\" French said.\n\nThe runner will grab it and bring it to the entry point, screaming into the tank or pulling on the respirator hose to get the technician's attention. \"If you're really deep in the tank, then you have to crawl back to get it from them, and you have to wait there for them to bring it, reducing the amount of time you're actually working.\"\n\nBefore a worker enters the aircraft, they'll know what issues they're looking for. A broken rivet, for instance, along with regular fuel tanker maintenance to keep the aircraft operating. But sometimes they adjust a different part in the wrong area of the refueling aircraft or leave a tool inside the tanker.\n\nThere's a lot of double-checking the work. Steps like removing sealant, cleaning, and putting adhesion in the tank require approval from other team members. It's inherently an hourslong job made even longer by wait times and communication lags.\n\nAnd that's if it all runs smoothly. Sometimes, technicians make mistakes, extending the time. \"A simple sealant job can turn from a couple of hours of scraping and then eventually reapplying to another day because it turned out that you applied it to the wrong spot,\" Tech Sgt. Chris Anderson, with the 100th Air Refueling Wing, said. \"The way that we did things left a lot of room for error.\"\n\nA logical fix, Frank said, was something wearable: \"a camera with two-way audio would be awesome, and if it had lights, that'd be a second bonus.\"\n\nThe IRIS technology sits on top of the face mask tanker maintenance workers wear. It features a high-definition video camera, a two-way comms system that goes inside the mask, and a hands-free light. IRIS shows everything the technician is looking at to those outside the fuel tank and allows them to communicate with their team.\n\nIt connects to a mobile workstation outside the aircraft. On the cart, which can host up to four IRIS units simultaneously, the support team can see what the technician sees, talk them through the work, and record the footage.\n\nVideo records help verify what each shift completed and resolve disputes quickly. For instance, Anderson said that the day shift had cleared a fuel puddle, but the next shift found one and questioned the work. IRIS showed that the first team had done the job, revealing, as French said, \" another problem, something's leaking.\" That prevented unnecessary rework and let them fix the issue.\n\nIn the past, a tricky aircraft issue could halt work while the right Air Force experts traveled in to assess it. Now, IRIS can send video to them instantly or launch a group call so everyone can see exactly what the technician sees.\n\nDevelopers also see AI playing a growing role in streamlining the job. As a technician uses IRIS, an AI agent compiles images and data to make requests, anticipate needed work, and handle forms. That frees technicians from what retired Air Force Maj. Gen. Cedric George called \"shallow work,\" so when their shift ends, \"all he or she has to do is button up, clean up, go home.\"\n\nIRIS is currently in use only at Mildenhall, but early results are promising, as the Air Force considers expanding it to other bases. Technicians using the system haven't had any safety incidents, and inspections are running 60% faster in test environments, according to pilot evaluations and internal logs. Based on KC-135 maintenance baselines, MetroStar estimates IRIS could save 35,000 maintainer hours and add more than 7,000 aircraft availability days.\n\nGeorge attributed the success of IRIS to the technicians who wanted to revamp the decades-old process to make it better for future workers. \"This is not for the faint of heart, it's dirty work,\" he said, saying current technicians who worked on IRIS believe future maintainers \"have to have something better than what we have now.\"",
    "readingTime": 7,
    "keywords": [
      "workers wear",
      "air force",
      "tanker maintenance",
      "fuel tanks",
      "refueling aircraft",
      "the air force",
      "technicians",
      "team",
      "it's",
      "maintainers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/behind-new-tech-making-dirty-hard-air-force-job-easier-2025-12",
    "thumbnail_url": "https://i.insider.com/693c4e0f832e0ef1ead62459?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:46.873Z",
    "topic": "finance"
  },
  {
    "slug": "he-wrote-the-worlds-most-successful-video-games-now-what-rockstar-cofounder-dan-houser-on-life-after-grand-theft-auto",
    "title": "He wrote the world’s most successful video games – now what? Rockstar co-founder Dan Houser on life after Grand Theft Auto",
    "description": "He rewrote the rule book with Rockstar then left it all behind. Now Dan Houser is back with a storytelling-focused studio to take on AI-obsessed tech bros and Mexican beauty queens\nThere are only a handful of video game makers who have had as profound an effect on the industry as Dan Houser. The co-founder of Rockstar Games, and its lead writer, worked on all the GTA titles since the groundbreaking third instalment, as well as both Red Dead Redemption adventures. But then, in 2019, he took an extended break from the company which ended with his official departure. Now he’s back with a new studio and a range of projects, and 12 years after we last interviewed him, he’s ready to talk about what comes next.",
    "fullText": "He rewrote the rule book with Rockstar then left it all behind. Now Dan Houser is back with a storytelling-focused studio to take on AI-obsessed tech bros and Mexican beauty queens\n\nThere are only a handful of video game makers who have had as profound an effect on the industry as Dan Houser. The co-founder of Rockstar Games, and its lead writer, worked on all the GTA titles since the groundbreaking third instalment, as well as both Red Dead Redemption adventures. But then, in 2019, he took an extended break from the company which ended with his official departure. Now he’s back with a new studio and a range of projects, and 12 years after we last interviewed him, he’s ready to talk about what comes next.\n\n“Finishing those big projects and thinking about doing another one is really intense,” he says about his decision to go. “I’d been in full production mode every single day from the very start of each project to the very end, for 20 years. I stayed so long because I loved the games. It was a real privilege to be there, but it was probably the right time to leave. I turned 45 just after Red Dead 2 came out. I thought, well, it’s probably a good time to try working on some other stuff.”\n\nAt first, he looked into film or TV writing, but didn’t like what he found. “That world was not overly excited by me and I was not overly excited by them,” he says. “I’ve spent 20 years talking about how games are the coming medium and now they are the medium […] you look at TV and the budgets and the amount of money they can generate, but the creative ambition is so small at times”. It seemed to Houser that it would be easier to come at the industry with IP that had already been generated. So he moved to Santa Monica and formed Absurd Ventures, bringing in Greg Borrud (founder of Seismic Games and Pandemic Studios) as head of games and, as COO, Wendy Smith, previously at the New Yorker and Ralph Lauren, and a White House special assistant during Bill Clinton’s presidency.\n\nIt was clear from the start it wouldn’t just be a video games studio. In 2024, the company released the 12-part story podcast A Better Paradise, a dystopian thriller about an ambitious online game world overseen by a powerful AI presence that begins to become sentient – with devastating consequences. Its creator is the mysterious tech billionaire Dr Mark Tyburn, a British inventor who intends the game as a digital utopia, then abandons it when things go awry. In some ways it is a satire on our current digital oligarchy, in which billionaire tech bros wield astronomical influence over society.\n\n“All of these tech companies start out with grandiose ambitions, this ‘we are going to save the world through togetherness’-type gibberish,” he says. “We’ve created some of the most powerful people in history in terms of reach and mind control. Those people end up living with far more money than anyone’s ever had. And it feels, as someone who lives in the society that they have helped create, that there are moments in those journeys when they must have felt their product was not quite what they intended it to be and was doing unforeseen harm, and … they went out of their way to ensure that was not regulated. That Faustian moment I find fascinating, and that’s not to say I wouldn’t make the same choice or judge them for it, I just find it interesting.”\n\nTellingly perhaps, the company at the centre of A Better Paradise, Tyburn Industria, feels much more like a games studio than a social media mega-corp. Also, the lead protagonist is a writer who finds himself at the centre of the game’s development. Is there an element of autobiography here?\n\n“Yeah, of course – at that level,” says Houser. “But I also wanted to write about games and tech in a way that felt authentic. To lean slightly more into the games side in terms of the office environment was really easy for me. I know what it’s like to work in a games company obviously. I wanted to try and bring that to life in a way that felt real and to capture some of the micro dramas.”\n\nHaving turned A Better Paradise into a novel, Houser’s Santa Monica studio is now working on an open-world video game version. He’s not saying how it will fit in with the podcast, just that Mark Tyburn and the AI at the heart of his game, NigelDave (a wildly intelligent program, fixated by humans but with no understanding of how they function), will both figure in the action.\n\nAlso in development at the company’s second studio in San Rafael, is the Absurdaverse, a comedy universe populated by a menagerie of weird characters, from a skeletal warrior to an ageing hippy. The company is planning a series of animated TV shows and/or movies for the concept, but also another open world game, which Houser has described as, “a living sitcom”. Again, he’s vague on the details, but it looks to be a more story-driven take on The Sims, possibly utilising AI to create emergent narratives around the characters and their lives. “We’re trying to use the memories of NPCs in a fun way,” he says. “Just trying to make it a bit more alive. You’ll see when we talk about it more, but it is shaping up really well. It’s a completely gamey game – very mechanics driven. With both games, we’re trying to make them really strong on mechanics, really fun to play, accessible, but plenty of depth.”\n\nHouser is also planning a game around the company’s third IP, the comic book series American Caper, co-written with fellow Rockstar alumnus, Lazlow. With its cast of escaped convicts, crooked lawyers and Mexican beauty queens, it is perhaps the closest out of all his new projects to Grand Theft Auto. Which is perhaps why the interactive version is going in a different direction. “I’m not making an open-world game for that,” says Houser. “We’re actually looking at maybe doing more of a story game. We’re still kind of exploring it.”\n\nWe talk a little bit about the current prevalence of forever games such as Minecraft, Fortnite and Roblox and how they’re sucking up a lot of the world’s playtime. But Houser is adamant that there’s still a vast audience for mature single-player narrative experiences – and that’s what he’s aiming at.\n\n“We’re trying to be ambitious, to make new stuff,” he says. “At some level [our projects] are traditional console games, accessible, but action-oriented story-driven open world console games – but then at the same time, we’re doing it a slightly different way or with slightly different subject matter. Three years ago we were watching one of those PlayStation showcases, and if you blinked and missed the credit sequences, you couldn’t tell where one game ended and the other began. Everything was sort of dark purple and about space ninjas. They were about this apocalypse or that apocalypse but always felt the same.”\n\n“That’s fine. Some of them are amazing games. But we were like, well, we’ve got limited money and we are starting from scratch. We have to have good stories and fun dialogue, and make sure our gameplay is amazing and accessible, and our art direction has to be fresh – at all points, it has to feel different. We have to make stuff where people go, ‘Well, I’ve never played a game about that’, and then treat the audience, not just as gamers, but as human beings.”\n\nSo he’s not worried about the industry’s current obsession with live-service multiplayer mega-games? “I still think there is enough of an audience who want new stuff and single player-led stuff,” he says. And then in his characteristically self-deprecating way he adds: “I hope so. Or we’re in a little bit of trouble.”",
    "readingTime": 7,
    "keywords": [
      "mexican beauty",
      "dan houser",
      "beauty queens",
      "overly excited",
      "tech bros",
      "console games",
      "games studio",
      "better paradise",
      "he’s",
      "stuff"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/games/2025/dec/15/dan-houser-grand-theft-auto-rockstar",
    "thumbnail_url": "https://i.guim.co.uk/img/media/aafb9fcf901b98332c5043e0412960dec2877e3a/151_9_1307_1045/master/1307.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e4a93bb9d18d5933951756fb9cb25bdd",
    "created_at": "2025-12-15T13:53:44.410Z",
    "topic": "gaming"
  },
  {
    "slug": "these-artificial-intelligence-ai-stocks-are-up-257-and-316-so-far-in-2025-heres-why-they-could-be-a-bust-in-2026",
    "title": "These Artificial Intelligence (AI) Stocks Are Up 257% and 316% So Far in 2025. Here's Why They Could Be a Bust in 2026.",
    "description": "These companies have a careful balancing act to pull off in 2026 if they want to continue their run.",
    "fullText": "This duopoly saw strong demand for their products push revenue and margins higher in 2025.\n\nCustomers have started seeking substitutes, which could eat into pricing power in 2026.\n\nBoth stocks look richly valued for highly cyclical stocks.\n\n10 stocks we like better than Seagate Technology Plc ›\n\nThree years after the release of ChatGPT, generative AI remains the biggest trend in the stock market. It has created many big winners, as big tech companies are spending as much as possible building new data centers and outfitting them with equipment. Just about every industry has felt the impact of the trend, and it's even had a meaningful impact on U.S. GDP.\n\nBut the biggest winners are still firmly in the technology industry. While many investors think of software giants and chipmakers when considering the leading AI stocks, 2025 has been a year of increased demand for memory and storage. As developers expand the input for their large language models, demand for data storage and throughput has led to stellar financial results for many memory chip and hard drive makers.\n\nSeagate Technology (NASDAQ: STX), for example, has climbed 257% (at the time of this writing) on the back of strong demand for its high-capacity hard drives and promises of its next-generation technology. Likewise, Western Digital (NASDAQ: WDC) has climbed even faster, up 316% so far this year. But after a stellar run in 2025, 2026 could result in a bust in the stocks.\n\nAs companies like OpenAI and Anthropic build new large language models trained on billions of pieces of information, they require a storage solution to house all that data near their high-powered GPUs. Importantly, most of that data doesn't need to be instantly accessible for processing, and servers can use what's called \"nearline\" storage to access it. Nearline storage might take a few seconds to read, and that trade-off is usually worth it because it's relatively cheap.\n\nThe most common form of nearline storage are hard disk drives (HDDs). Seagate and Western Digital account for the vast majority of HDD sales, and both saw their revenue and earnings soar in 2025 amid growing demand for nearline storage. In fact, demand has climbed faster than supply, resulting in strong margin expansion for both, as they're able to raise prices on the big tech companies buying their products.\n\nWestern Digital CEO Irving Tan expects the market to remain supply constrained through mid-2027. Seagate CEO Dave Mosley said its capacity is already largely committed to contracts through 2026. Indeed, both companies should be able to continue growing revenue and earnings at a rapid pace next year.",
    "readingTime": 3,
    "keywords": [
      "western digital",
      "seagate technology",
      "language models",
      "nearline storage",
      "demand",
      "stocks",
      "revenue",
      "climbed",
      "products",
      "biggest"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/artificial-intelligence-ai-stocks-257-055000397.html",
    "thumbnail_url": "https://media.zenfs.com/en/motleyfool.com/36083bc012b010a7dee4ccac0cde7fa8",
    "created_at": "2025-12-15T13:53:42.366Z",
    "topic": "finance"
  },
  {
    "slug": "we-learned-that-fewer-news-stories-get-listened-to-more",
    "title": "We learned that fewer news stories get listened to more",
    "description": "Listen to the internet as audio. AI-summarized news, global radio channels, and curated daily audio for focus, clarity, and reflection. Free to start.",
    "fullText": "Stop scrolling. Start listening.\n\nThe internet, summarized and read aloud. Press play, anytime 🎧\n\n44+ live channels · No login required\n\nPrefer something more intentional?\n\nShort, original episodes for calm, focus & clarity\n\nA calm, intentional start to your day\n\nUnderstanding for brains that work differently\n\nHonest reflections from building something\n\nStay informed while you work, commute, or relax.\n\nSupports multiple languages including Hindi, Marathi, Tamil, Thai & Arabic",
    "readingTime": 1,
    "keywords": [
      "intentional",
      "calm"
    ],
    "qualityScore": 0.5,
    "link": "https://tera.fm",
    "thumbnail_url": "https://tera.fm/og-image.jpg",
    "created_at": "2025-12-15T07:00:13.235Z",
    "topic": "tech"
  },
  {
    "slug": "building-aipowered-image-generation-with-openaicompatible-responses-api",
    "title": "Building AI-Powered Image Generation with OpenAI-Compatible Responses API",
    "description": "Learn how to build an AI-powered application that combines web search and image generation using the Responses API with Vllora LLM client in Rust.",
    "fullText": "The Responses API represents a powerful evolution in how we interact with large language models. Unlike traditional chat completion APIs that return simple text responses, the Responses API enables structured, multi-step workflows that can orchestrate multiple tools and produce rich, multi-modal outputs.\n\nIn this article, we'll explore how to build an AI-powered application that combines web search and image generation capabilities.\n\nSource Code: The complete example is available on GitHub.\n\nDocumentation: For comprehensive Responses API documentation, see the Responses API guide and Image Generation guide.\n\nThe Responses API is a more powerful alternative to the traditional Completions API. It enables structured, multi-step workflows with support for multiple built-in tools like web search and image generation, producing rich, multi-modal outputs that can be easily processed programmatically.\n\nBefore we dive into the code, let's ensure we have everything we need.\n\nOur example requires the following Rust crates:\n\nHere's the complete Cargo.toml for our example:\n\nYou'll need to set your API key as an environment variable:\n\nNote: Make sure to keep your API key secure. Never commit it to version control or expose it in client-side code.\n\nNow let's construct our Responses API request. We'll create a request that uses both web search and image generation tools.\n\nModel Selection - We're using \"gpt-4.1\", which supports the Responses API and tool calling. Make sure to use a model that supports these features.\n\nInput Parameter - We use InputParam::Text to provide a simple text prompt. The model will:\n\nTool Configuration - We specify two tools:\n\nThe ..Default::default() ensures all other fields use their default values, which is a common Rust pattern for struct initialization.\n\nNext, we need to set up the Vllora LLM client with our credentials.\n\nThe client uses a builder pattern for configuration. Here we:\n\nTip: In production, consider using a more robust error handling approach instead of .expect(), such as returning a Result or using a configuration management library.\n\nNow let's send our request and see what we get back.\n\nThe client.responses().create() method:\n\nThe Response struct contains an output field, which is a vector of OutputItem variants. Each item represents a different type of output from the API:\n\nLet's see how to extract and display text content from the response.\n\nMessage Structure - Each Message contains a content vector that can hold different content types:\n\nAnnotations - Text outputs can include annotations which provide:\n\nThese annotations are particularly valuable when using web search tools, as they show where the information came from.\n\nThis is the core focus of our example - extracting and saving generated images.\n\nWhen the model uses the image generation tool, the response includes OutputItem::ImageGenerationCall variants. Each call contains:\n\nHere's our complete image handling function:\n\nExtract Base64 Data - We access the result field, which is an Option<String>. We use .ok_or() to convert None into an error if the result is missing.\n\nDecode Base64 - The base64 crate's STANDARD engine decodes the base64 string into raw bytes. This can fail if the string is malformed, so we use ? to propagate errors.\n\nSave to File - We use Rust's standard library fs::write() to save the decoded bytes to a file. We name it generated_image_{index}.png to avoid conflicts when multiple images are generated.\n\nReturn Filename - We return the filename so the caller knows where the image was saved.\n\nHere's how we integrate this into our response processing:\n\nWe match on OutputItem::ImageGenerationCall, extract the call, and pass it to our decoding function. We handle both success and error cases gracefully.\n\nLet's put it all together and see the complete flow:\n\nWhen you run this example, you'll see output like:\n\nThe actual news content and image will vary based on what's happening when you run it!\n\nThis example demonstrates how to use the Responses API to create multi-tool workflows that combine web search and image generation. The key steps are:\n\nThe Responses API enables powerful, structured workflows that go beyond simple text completions, making it ideal for building applications that need to orchestrate multiple AI capabilities.",
    "readingTime": 4,
    "keywords": [
      "rich multi-modal",
      "structured multi-step",
      "multi-modal outputs",
      "api enables",
      "responses api",
      "multi-step workflows",
      "simple text",
      "web search",
      "the responses api",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://vllora.dev/blog/building-ai-powered-image-gen-responses-api/",
    "thumbnail_url": "https://vllora.dev/img/image-gen/image-gen-responses-api.png",
    "created_at": "2025-12-15T07:00:13.121Z",
    "topic": "tech"
  },
  {
    "slug": "why-proteins-fold-and-how-gpus-help-us-fold",
    "title": "Why proteins fold and how GPUs help us fold",
    "description": "A deep, intuitive dive into why proteins are insanely complex, how folding defines life and disease, and how AI like AlphaFold finally cracked biology’s hardest problem.",
    "fullText": "You know what's wild? Right now, as you're reading this, there are approximately 20,000 different types of proteins working inside your body. Not 20,000 total proteins, 20,000 TYPES. The actual number of protein molecules? Billions. Trillions if we're counting across all your cells.\n\nEach one has a specific job. Each one has a specific shape. And if even ONE type folds wrong, one could get Alzheimer's, cystic fibrosis, sickle cell anemia, Parkinson's, Huntington's, mad cow disease, or any of thousands of other diseases collectively called \"protein misfolding diseases.\"\n\nYour body makes these proteins perfectly, billions of times a day, in every single one of your 37 trillion cells, without asking your opinion, without requiring a user manual, without ever attending a protein folding workshop.\n\nScientists spent 50 years, FIFTY YEARS, trying to figure out how to PREDICT what shape a protein would fold into based on its amino acid sequence. Entire careers were built on this problem. Nobel Prizes were awarded for incremental progress. Supercomputers were dedicated to simulating single protein folds that took weeks to complete.\n\nThen AI companies showed up in 2020 and said \"we got this\" and solved it in an afternoon.\n\nAnd now? Now we're not just predicting shapes, we're DESIGNING entirely new proteins that have never existed in nature. Proteins that can break down plastic. Proteins that can capture carbon dioxide. Proteins that can target cancer cells with sniper precision. We're playing God with molecules and it's working.\n\nBut before I tell you how NVIDIA went from making GPUs that render explosions in Call of Duty to designing molecules that might cure cancer, you need to understand what proteins actually are and why this problem was so stupidly, impossibly, hilariously hard that it became one of biology's grand challenges alongside \"how does consciousness work\" and \"what is dark matter.\"\n\nLet's start from scratch. Forget everything you learned in high school biology. We're doing this right.\n\nRemember from my previous articles: your DNA gets transcribed into RNA, which gets translated into proteins. That's the central dogma. DNA → RNA → Protein. Information flows one way. (Mostly. Retroviruses are weird. Don't worry about it.)\n\nBut what IS a protein? And I mean really, fundamentally, at the molecular level?\n\nA protein is a chain of amino acids that folds into a specific 3D shape, and that shape determines what the protein does.\n\nThat's it. That's the entire definition. A chain. That folds. Into a shape. That does stuff.\n\nBut as with literally everything in biology, the devil is in the details. And the details are where things get interesting (and by interesting, I mean \"ridiculously complicated but in a cool way\")\n\nThere are 20 standard amino acids that your body uses to build proteins. (There are actually a few more non-standard ones, but let's not complicate things yet.) Think of them as letters in an alphabet. But instead of making words and sentences, they make functional machines.\n\nEach amino acid has the same basic structure:\n\nLet Me Introduce You to Some Amino Acids (They Have Personalities)\n\nThe point is: these 20 amino acids can be arranged in ANY order and in ANY length to create proteins. And your body picks the exact right order to make each protein work.\n\nA typical protein has 200-400 amino acids. Some have thousands. Titin, the largest known protein in humans, has 34,350 amino acids. It's literally a molecular spring that provides elasticity to muscle tissue.\n\nLet's do some math that will hurt your brain:\n\nFor a protein that's just 100 amino acids long, there are 20^100 possible sequences. That's 1.27 × 10^130 possible combinations.\n\nAnd most of those sequences? They don't fold into anything useful. They're junk. They aggregate into clumps. They get degraded by cellular quality control. Only a TINY fraction of possible sequences fold into stable, functional proteins.\n\nNature had to search this impossibly vast space and find the sequences that actually work. And it did this through random mutation and natural selection over 3.5 billion years. Evolution is the ultimate brute-force search algorithm.\n\nBut we don't have 3.5 billion years. We want to design proteins NOW.\n\nWhen a ribosome finishes making a protein (remember translation from my last article?), it spits out a long, floppy, completely linear chain of amino acids. This chain is called a polypeptide, literally \"many peptides\" because each amino acid is connected to the next by a peptide bond.\n\nThe peptide bond forms between the carboxyl group of one amino acid and the amino group of the next:\n\nThis creates a backbone (the repeating NH-CHR-CO pattern) with side chains (R groups) sticking out.\n\nAnd then, immediately, while the ribosome is still finishing the rest of the chain, something magical happens:\n\nThe chain starts folding itself.\n\nNo chaperone proteins initially (those come later if needed). No instructions. No assembly manual. No quality control inspector. The amino acids just start interacting with each other based on their chemical properties, and the whole thing spontaneously collapses into a compact, functional 3D structure.\n\nThis is called spontaneous folding or self-assembly, and it's one of the most beautiful phenomena in molecular biology.\n\nProtein folding is driven by thermodynamics, specifically, the search for the lowest free energy state (most stable configuration). Multiple forces contribute:\n\n1. The Hydrophobic Effect (The Big One)\n\nThis is the primary driving force for most proteins. Hydrophobic amino acids (like leucine, valine, phenylalanine) are energetically unfavorable in water. Water molecules have to organize around them in structured \"cages,\" which decreases entropy (disorder).\n\nThe system wants to maximize entropy. So what happens? Hydrophobic amino acids cluster together in the protein's core, away from water. This releases the ordered water molecules back into the bulk solution, increasing overall entropy.\n\nMeanwhile, hydrophilic amino acids (charged and polar ones) stay on the surface, happily interacting with water.\n\nThis creates a protein structure with:\n\nLike a molecular M&M. Except instead of chocolate, it's biochemistry.\n\n2. Hydrogen Bonds (The Backbone of Structure)\n\nIndividually, hydrogen bonds are weak (about 5% the strength of a covalent bond). But proteins have HUNDREDS of them. Collectively, they're incredibly strong.\n\nThese are called secondary structures, local patterns in the protein backbone.\n\n3. Electrostatic Interactions (Salt Bridges)\n\nOppositely charged amino acids attract each other:\n\nThese are called salt bridges or ion pairs. They're strong and help stabilize the folded structure.\n\n4. Disulfide Bonds (The Chemical Staples)\n\nWhen two cysteine residues come close together, their sulfur atoms can form a disulfide bond (S-S). This is a COVALENT bond, much stronger than the other interactions.\n\nDisulfide bonds are like staples that hold parts of the protein together. They're especially common in:\n\nInside cells (reducing environment), disulfide bonds are rare.\n\n5. Van der Waals Forces (The Weak but Numerous)\n\nWhen atoms get very close, they experience weak attractive forces called van der Waals interactions. They're tiny individually, but proteins have THOUSANDS of atoms in close contact, so collectively they matter.\n\n6. Entropy (The Desire for Disorder)\n\nFolding DECREASES entropy (the protein goes from a floppy, disordered chain to a compact, ordered structure). This is thermodynamically unfavorable.\nBut remember: folding releases water molecules from around hydrophobic residues, which INCREASES entropy. The net effect? Folding is favorable overall.\n\nSmall proteins (50-100 amino acids) can fold in microseconds to milliseconds.\nLarger proteins take seconds.\n\nYour cells are making proteins and folding them CONSTANTLY. Every second. Right now. While you read this.\n\nAnd here's the crazy part: the folded structure is reproducible. Given the same sequence, you get the same structure. Every time. It's deterministic (mostly, there are exceptions called intrinsically disordered proteins, but let's not go there).\n\nThis means the folding information is ENCODED in the amino acid sequence. The sequence contains all the instructions needed to fold into the correct shape. But humans don't know how to READ those instructions directly. We can see the sequence. We can see the final structure. But predicting one from the other? That took 50 years to figure out.\n\nThe final 3D shape is called the protein's native structure. It has several levels of organization:\n\nPrimary structure: The linear sequence of amino acids. Just the order.\n\nSecondary structure: Local patterns (alpha helices and beta sheets).\n\nTertiary structure: The full 3D arrangement of the entire protein chain.\n\nQuaternary structure: If multiple protein chains come together (like hemoglobin, which has 4 chains), how they're arranged relative to each other.\n\nThe native structure is the functional form. This is the shape that DOES the biology.\n\nAnd this is where things get critical.\n\nHere's the most important concept in all of protein biology, and I cannot stress this enough:\n\nA protein's function is ENTIRELY determined by its 3D shape.\n\nNot the amino acid sequence. Not the chemical properties of individual residues. The three-dimensional structure.\n\nChange the shape even slightly, and the protein stops working. Change it drastically, and you get disease.\n\nLet me give you examples that show just how insanely specific this is.\n\nEnzymes are proteins that speed up chemical reactions. Without them, most biological reactions would happen so slowly that you'd be dead. Your cells would be frozen in chemical slow-motion.\nEnzymes have a specific pocket called an active site, a precisely shaped cavity where the chemical reaction happens. The substrate (the molecule the enzyme works on) fits into this pocket like a key in a lock. The fit is SPECIFIC. If the shape is even slightly wrong, the substrate won't fit. The reaction won't happen. The enzyme is useless.\n\nLactase (The Enzyme That Digests Milk Sugar)\n\nLactase is the enzyme that breaks down lactose (milk sugar). If you're lactose intolerant, it's because your body either stopped making lactase or makes a misfolded version that doesn't work. Result? Lactose sits in your intestines. Gut bacteria ferment it. You get gas, bloating, diarrhea. One misfolded protein = digestive chaos. You can't drink milk because your protein has the wrong shape. That's how specific this is.\n\nYour immune system has to recognize millions of different threats: viruses, bacteria, toxins, parasites. It does this with antibodies, Y-shaped proteins that bind to specific invaders.\nEach antibody is custom-shaped to recognize a specific molecular pattern (called an antigen) on the surface of an invader. The tips of the Y are shaped to fit that specific target.\nThe fit is so precise that an antibody designed for the flu virus won't recognize the common cold virus. Different shapes = different antibodies needed.\n\nThis is why vaccines work. You expose your immune system to a harmless version of a pathogen, your body makes antibodies with the right shape to recognize it, and now you're protected.\nIf the antibody shape is wrong, your immune system won't recognize the threat. You get sick.\n\nModern medicine exploits this by designing custom antibodies as drugs:\n\nThese are literally designer proteins with custom shapes targeting specific molecules. Billion-dollar drugs that work because the shape is right.\n\nHaemoglobin carries oxygen in your blood. It's shaped like a four-leaf clover with pockets that hold iron atoms, which bind oxygen. The shape is critical for function. Haemoglobin picks up oxygen in your lungs (where O₂ is abundant) and releases it in your tissues (where O₂ is scarce).\nBut if you change just ONE amino acid...\nSickle Cell Anemia is caused by a single mutation:\n\nPosition 6 in the beta chain of haemoglobin\nGlutamic acid (charged, hydrophilic) → Valine (hydrophobic)\n\nThat's it. One letter out of 146 amino acids in that chain.\n\nBut valine is hydrophobic. It creates a sticky patch on the surface of the haemoglobin molecule. When haemoglobin releases oxygen, this patch is exposed. Hydrophobic patches love to stick together. So sickle haemoglobin molecules clump together, forming long fibers. These fibers deform red blood cells into sickle (crescent) shapes.\nSickled cells:\n\nOne amino acid. One shape change. Lifelong disease.\n\nHere's where it gets truly terrifying. Prions are misfolded proteins that can convert normal proteins into the misfolded form, spreading like an infection. They cause diseases like:\n\nThe protein involved is called PrP (prion protein). Everyone has it. It's a normal protein on the surface of neurons. But PrP can misfold into a different shape, same amino acid sequence, different structure. This misfolded version (PrP^Sc) is:\n\nIt's autocatalytic. Self-replicating. And it destroys brain tissue.\n\nThere's no cure. It's 100% fatal. And it's all because of protein shape.\n\nIn 1969, a scientist named Cyrus Levinthal did some math and realized something disturbing:\nProtein folding shouldn't work.\n\nConsider a protein with 100 amino acids.\nEach amino acid has bonds that can rotate, and each bond has maybe 3 stable angles.\nSo there are roughly 10^95 possible shapes the protein could adopt.\nNow, let's say the protein can try one shape every picosecond (10^-12 seconds). That's incredibly fast, molecular vibrations happen on that timescale.\nHow long would it take to try all possible shapes to find the correct one?\n10^83 seconds.\nThe universe is about 10^17 seconds old.\n10^83 seconds is 10^66 times longer than the age of the universe.\nIf proteins had to randomly search for the correct fold, it would take longer than the universe has existed.\nBut proteins fold in milliseconds.\nThis is the Levinthal Paradox. Folding should be impossible. But it happens. Every time.\n\nThe Answer: Proteins Don't Search Randomly\n\nProteins follow a folding pathway, they don't try every possible shape. They take shortcuts.\n\nImagine a landscape with hills and valleys. The native structure is the deepest valley (lowest energy state). If the protein randomly wandered around, it would take forever to find the valley.\n\nBut the landscape is shaped like a funnel:\n\nIt's guided by the energy landscape encoded in the amino acid sequence. Evolution figured out sequences that fold efficiently.\n\nNature is smarter than random searching. Who knew.\n\nSo, proteins fold into specific shapes based on their sequences. Great.\n\nHere's what scientists wanted to do:\n\nGive me an amino acid sequence (like: MKTAYIAKQRQISFVKSHF...) and I'll tell you what 3D shape it will fold into.\n\nSimple request. Insanely hard problem.\n\nThis is called the protein folding problem, and it's been one of the grand challenges of biology since the 1960s.\n\nIf you can predict protein structure from sequence, you can:\n\nBut we couldn't do it. We tried for 50 years. And mostly failed.\n\n1. The Search Space is Incomprehensibly Vast\n\nWe already covered this. 10^95 possible conformations for a 100-amino-acid protein. Even with folding pathways, the space is enormous.\n\n2. The Interactions Are Complicated\n\nEvery amino acid interacts with every other amino acid. For a 100-amino-acid protein, that's nearly 5,000 possible pairwise interactions. And they all influence each other simultaneously.\nIt's like trying to solve a Rubik's cube where every move affects every other square in unpredictable ways.\n\nProteins fold in water. Water molecules interact with the protein, forming hydrogen bonds, pushing hydrophobic parts inward, stabilizing charged regions.\nYou can't model the protein in isolation. You need to simulate thousands of water molecules too. And water is WEIRD, its properties (hydrogen bonding, high dielectric constant) make it computationally expensive to model.\n\n4. Small Changes Have Big Effects\n\nChange one amino acid and the whole structure can change. It's not a linear relationship. The folding landscape is rugged, small mutations can shift the entire energy funnel.\n\nProtein folding is governed by thermodynamics. You need to calculate the free energy of every possible conformation and find the global minimum (most stable state).\n\nThis requires simulating quantum mechanical interactions between thousands of atoms. Computationally, it's a nightmare.\n\nX-ray Crystallography (1950s onward):\n\nGrow protein crystals → Blast them with X-rays → X-rays diffract off the atoms → Analyze the diffraction pattern → Reconstruct the 3D structure\n\nNMR Spectroscopy (1980s onward):\n\nPut protein in a magnetic field → Use radio waves to probe the positions of atoms → Reconstruct the structure from the data\n\nCryo-Electron Microscopy (2010s):\n\nFlash-freeze proteins → Image them with an electron microscope → Average thousands of images to get high resolution\n\nThis revolutionized structural biology (2017 Nobel Prize) but:\n\nNone of these methods PREDICT structures. They DETERMINE structures experimentally.\n\nScientists tried to simulate folding computationally.\n\nMolecular Dynamics (MD) Simulations:\nModel every atom in the protein and surrounding water → Calculate forces between atoms using physics equations → Simulate the motion of atoms over time (Newton's laws) → Watch the protein fold\n\nAnd even then, you might miss the correct fold or get trapped in a metastable state (local energy minimum that's not the global minimum).\n\nA software developed by David Baker's lab that uses:\n\nRosetta was better than nothing. It could sometimes predict structures for small proteins or proteins similar to known structures.\n\nIn 1994, researchers created CASP, Critical Assessment of Structure Prediction.\nEvery two years, teams compete to predict protein structures. Organizers choose proteins whose structures are about to be solved experimentally, teams submit predictions, and then the real structures are revealed.\n\nScores range from 0 to 100. Above 90 is considered competitive with experimental accuracy.\nFor 25 years, the best scores hovered around 40-60 for difficult targets. Progress was incremental. Slow. Frustrating.\n\nIn CASP13 (2018), a team from DeepMind (Google's AI lab) entered a protein structure prediction method called AlphaFold. It used deep learning, neural networks trained on known protein structures. AlphaFold 1 achieved a median GDT score of 58.9, placing first overall. The biology community took notice. This was the first time a machine learning approach significantly outperformed traditional methods. But it wasn't revolutionary. It was good, not great. There were still errors. Difficult targets were still difficult. Researchers thought: \"Okay, AI is promising, but we're not there yet.\"\n\nIn November 2020, CASP14 results were announced.\n\nDeepMind's AlphaFold 2 achieved a median GDT score of 92.4.\n\nLet me put this in perspective:\n\nAlphaFold 2 essentially SOLVED the protein folding problem.\n\nFor 87% of targets, it achieved GDT > 90. For some targets, it was MORE accurate than the experimental structures (because X-ray crystallography has its own errors).\n\nDeepMind open-sourced the code and released the AlphaFold Protein Structure Database, predicted structures for 200 million proteins (essentially every known protein sequence).\n\nProteins are like language. A protein sequence is a string of letters (amino acids). Those letters follow rules (chemistry). The structure is the \"meaning\" of the sequence.\nAnd modern AI is REALLY good at understanding language patterns. That's what powers large language models. AlphaFold adapted the same technology, transformers with attention mechanisms, for proteins.\n\nAlphaFold doesn't simulate physics. It recognizes patterns learned from 170,000+ known protein structures.\nAnd it works. Ridiculously well.\n\nBut AlphaFold Wasn't Perfect. AlphaFold 2 was groundbreaking, but gaps remained:\n\nNVIDIA makes GPUs, your Graphics Processing Units. They were originally designed for rendering video game graphics. But GPUs are incredibly good at parallel processing, doing thousands of calculations simultaneously.\nAnd guess what needs massive parallel processing?\n\nNVIDIA realized: the same hardware that powers gaming can power drug discovery.\nSo they didn't just optimize AlphaFold to run faster on GPUs, they built an entire ecosystem for biological research:\n\nAnd they partnered with pharmaceutical giants, Pfizer, Amgen, AstraZeneca, who are using these tools to design drugs RIGHT NOW.\n\nBasically: how gaming GPUs became the most important tool in modern drug discovery. And why this matters even if you've never thought about proteins before.\n\nPart 2 coming soon. This is where things get truly wild.\n\nDisclaimer: Everything in this article is scientifically accurate. Proteins really fold in milliseconds. AlphaFold really solved a 50-year-old problem. Your gaming GPU really uses the same architecture as drug discovery platforms. Biology is weird, AI is powerful, and we're living in the future.",
    "readingTime": 17,
    "keywords": [
      "der waals",
      "median gdt",
      "gdt score",
      "alphafold achieved",
      "cell anemia",
      "grand challenges",
      "salt bridges",
      "van der",
      "milk sugar",
      "parallel processing"
    ],
    "qualityScore": 1,
    "link": "https://aval.bearblog.dev/nvidiaproteins/",
    "thumbnail_url": "https://raw.githubusercontent.com/avaldudhat/Blog/refs/heads/main/translation%20steps.png",
    "created_at": "2025-12-15T07:00:12.404Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-triggering-a-quiet-hiring-comeback-for-some-entrylevel-talent-say-public-company-ceos",
    "title": "AI is triggering a quiet hiring comeback for some entry-level talent, say public company CEOs",
    "description": "A new survey shows CEOs expect AI to boost hiring in 2026, especially for entry-level roles.",
    "fullText": "AI may be blamed for this year's layoffs, but a new global survey says the technology could fuel a rebound in some entry-level hiring next year.\n\nPublic-company CEOs say AI is creating more jobs in 2026, according to an annual outlook survey conducted by advisory firm Teneo released this month. Sixty-seven percent of the CEOs surveyed said they expect AI to increase entry-level hiring in 2026, and 58% said they plan to add senior-leadership roles as well.\n\nThe report said that firms are ramping up hiring in engineering and AI-related roles. Many existing jobs are being reconfigured or reassigned as certain tasks become increasingly automated.\n\nThe survey, conducted between October 14 and November 10, gathered responses from more than 350 global CEOs leading public companies with at least $1 billion in annual revenue, as well as about 400 institutional investors representing $19 trillion in portfolio value.\n\nThe findings run counter to the prevailing narrative that AI is automating entire jobs away.\n\n\"It's not that AI is wiping out the workforce today — it's reshaping it,\" said Ryan Cox, Teneo's global head of AI.\n\nThe hiring momentum mirrors a broader surge in corporate AI investment. Sixty-eight percent of CEOs said they plan to increase AI spending next year, up from 66% in 2025. Nearly nine in 10 CEOs said AI is already helping their organizations navigate disruption.\n\nAll that spending has raised expectations. More than half of investors said they expect AI initiatives to show results in under six months. CEOs aren't so sure: Only 16% of leaders at large-cap companies — with annual revenue of $10 billion or more — said such fast returns are realistic.\n\nFears that AI will eliminate human jobs have intensified as more companies announce layoffs tied to automation.\n\nHP said in a November earnings report that it plans to eliminate between 4,000 and 6,000 roles by the end of 2028 — a move expected to save about $1 billion. IBM announced in November that it would reduce its workforce by a \"single-digit percentage\" in the fourth quarter of 2025.\n\nBut the shift isn't as simple as workers being replaced by machines. IBM CEO Arvind Krishna told CNN in October that the company is simultaneously shifting head count toward AI and quantum computing, and plans to ramp up hiring of college graduates in the next year. AI adoption has also driven demand for programmers and sales employees, he told The Wall Street Journal in May.\n\nAI has created new job categories as it reshapes old ones. Titles such as decision designer and AI experience officer are emerging in the workforce, workplace experts said in a Business Insider report earlier this month. These roles focus on guiding AI systems and enhancing human-AI collaboration.",
    "readingTime": 3,
    "keywords": [
      "survey conducted",
      "annual revenue",
      "entry-level hiring",
      "jobs",
      "roles",
      "workforce",
      "layoffs",
      "increase",
      "plan",
      "investors"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-hiring-comeback-entry-level-jobs-ceo-teneo-survey-2025-12",
    "thumbnail_url": "https://i.insider.com/693f845964858d02d216c7d1?width=1200&format=jpeg",
    "created_at": "2025-12-15T07:00:01.167Z",
    "topic": "finance"
  },
  {
    "slug": "global-funds-view-indian-stocks-as-a-top-hedge-against-ai-risks",
    "title": "Global Funds View Indian Stocks as a Top Hedge Against AI Risks",
    "description": "India is drawing fresh attention from global fund managers looking to diversify equity investments in the coming year as worries over an AI bubble mount.",
    "fullText": "Follow Bloomberg India on WhatsApp for exclusive content and analysis on what billionaires, businesses and markets are doing.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-14/global-funds-view-indian-stocks-as-a-top-hedge-against-ai-risks",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSjQhD_lYfiQ/v0/1200x800.jpg",
    "created_at": "2025-12-15T03:59:14.295Z",
    "topic": "finance"
  },
  {
    "slug": "ringgits-outperformance-set-to-extend-next-year-on-ai-boost",
    "title": "Ringgit’s Outperformance Set to Extend Next Year on AI Boost",
    "description": "The Malaysian ringgit is on course to beat its Asian peers for a second straight year, and some strategists are expecting the outperformance to extend into 2026.",
    "fullText": "IndustriesCryptocurrenciesBy David FinnertySaveThe Malaysian ringgit is on course to beat its Asian peers for a second straight year, and some strategists are expecting the outperformance to extend into 2026.Malaysia’s deep linkages to the global tech supply chain, positive growth prospects and the government’s continued push on fiscal consolidation bode well for the ringgit, according to strategists. A likely stable central bank policy next year offers further support.",
    "readingTime": 1,
    "keywords": [
      "ringgit",
      "strategists"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-15/ringgit-s-outperformance-set-to-extend-next-year-on-ai-boost",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iNQ1DY4z2Fuc/v1/1200x800.jpg",
    "created_at": "2025-12-15T03:59:13.979Z",
    "topic": "finance"
  },
  {
    "slug": "moore-threads-plans-to-use-most-ipo-proceeds-to-buy-bank-products",
    "title": "Moore Threads Plans to Use Most IPO Proceeds to Buy Bank Products",
    "description": "Shares of Moore Threads Technology Co., a leading Chinese artificial intelligence chipmaker, fell after plans to put most of the funds raised through its recent listing into banking products.",
    "fullText": "MarketsBy Jeanny YuSaveShares of Moore Threads Technology Co., a leading Chinese artificial intelligence chipmaker, fell after plans to put most of the funds raised through its recent listing into banking products. The company plans to invest 7.5 billion yuan ($1.1 billion) of “idled funds,” equal to about 90% of the proceeds from its initial public offering, to purchase a few principal-guaranteed deposit products such as timed deposits and certificates of deposit, it said in a Shanghai stock exchange filing on Friday.",
    "readingTime": 1,
    "keywords": [
      "plans",
      "funds",
      "products",
      "deposit"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-15/moore-threads-plans-to-use-most-ipo-proceeds-to-buy-bank-products",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iG9o6UZ0Rdwo/v0/1200x800.jpg",
    "created_at": "2025-12-15T03:59:13.308Z",
    "topic": "finance"
  },
  {
    "slug": "us-stock-futures-rise-after-tech-rout-gold-climbs-markets-wrap",
    "title": "US Stock Futures Rise After Tech Rout, Gold Climbs: Markets Wrap",
    "description": "US equity-index futures rose as the final full trading week of 2025 began, after worries over earnings of technology companies and heavy AI spending sparked a selloff on Wall Street.",
    "fullText": "MarketsBy Anand KrishnamoorthySaveUS equity-index futures rose as the final full trading week of 2025 began, after worries over earnings of technology companies and heavy AI spending sparked a selloff on Wall Street.Contracts for the S&P 500 and the Nasdaq 100 indexes advanced 0.2% in Asian trading, after both gauges retreated more than 1% Friday along with tech stocks. Asian shares followed on Monday, with South Korea — a poster child for AI exuberance — slumping 1.6%. Chinese indexes edged lower after the latest data showed retail sales growth was the weakest since Covid while investment slumped further.",
    "readingTime": 1,
    "keywords": [
      "trading",
      "indexes",
      "asian"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-14/asian-stocks-set-for-losses-as-tech-concerns-mount-markets-wrap",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iLkFSFfqRSv0/v0/1200x675.png",
    "created_at": "2025-12-15T03:59:10.371Z",
    "topic": "finance"
  },
  {
    "slug": "gpt-prompt-from-searchbar-chatgpt-directly-from-the-browser-omnibox",
    "title": "GPT Prompt from Searchbar – ChatGPT directly from the browser omnibox",
    "description": "A lightweight Chrome extension that allows you to search/prompt ChatGPT directly from your browser's address bar (Omnibox). - ParasKoundal/GPTSearch",
    "fullText": "ParasKoundal\n\n /\n\n GPTSearch\n\n Public\n\n A lightweight Chrome extension that allows you to search/prompt ChatGPT directly from your browser's address bar (Omnibox).\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n ParasKoundal/GPTSearch",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/ParasKoundal/GPTSearch",
    "thumbnail_url": "https://opengraph.githubassets.com/9674a6e7ffcf86168c17319b094a63d29ac3590c31040f4ff85049a30e2ca531/ParasKoundal/GPTSearch",
    "created_at": "2025-12-15T03:59:06.427Z",
    "topic": "tech"
  },
  {
    "slug": "openais-head-of-codex-says-the-bottleneck-to-agi-is-humanitys-inability-to-type-fast-enough",
    "title": "OpenAI's head of Codex says the bottleneck to AGI is humanity's inability to type fast enough",
    "description": "OpenAI's Alexander Embiricos, who leads product development for its coding platform, said the need to review AI's work with prompts is limiting progress.",
    "fullText": "If you needed a sign for how determined AI-land is to achieve AGI quickly, it's that one of its leaders sees the speed of human typing as one of its biggest roadblocks.\n\nAlexander Embiricos, who leads product development for Codex, OpenAI's coding agent, said on \"Lenny's Podcast\" on Sunday that the \"current underappreciated limiting factor\" to AGI is \"human typing speed\" or \"human multi-tasking speed on writing prompts.\"\n\nAGI, or artificial general intelligence, is a still theoretical version of AI that reasons as well or better than humans. It's the thing all the big AI companies are competing to be the first to realize.\n\n\"You can have an agent watch all the work you're doing, but if you don't have the agent also validating its work, then you're still bottlenecked on, like, can you go review all that code?\" Embiricos said.\n\nEmbiricos' view is that we need to unburden humans from having to write prompts and validate AI's work, since we aren't fast enough.\n\n\"If we can rebuild systems to let the agent be default useful, we'll start unlocking hockey sticks,\" he said.\n\n\"Hockey stick growth\" is a term used to describe a growth curve that starts out flat and suddenly spikes, mirroring the shape of a hockey stick.\n\nEmbiricos said there's no simple path to a fully automated workflow — each use case will require its own approach — but he expects to see progress toward this level of growth soon.\n\n\"Starting next year, we're going to see early adopters starting to hockey stick their productivity, and then over the years that follow, we're going to see larger and larger companies hockey stick that productivity,\" he said.\n\nSomewhere in between the time early adopters start to see gains in productivity and when tech giants manage to fully automate processes with AI agents is when we'll see AGI, Embiricos said.\n\n\"That hockey-sticking will be flowing back into the AI labs, and that's when we'll basically be at the AGI,\" he said.",
    "readingTime": 2,
    "keywords": [
      "human typing",
      "hockey stick",
      "agent",
      "speed",
      "we'll",
      "growth",
      "productivity",
      "it's",
      "prompts",
      "humans"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-artificial-general-intelligence-bottleneck-human-typing-speed-2025-12",
    "thumbnail_url": "https://i.insider.com/693f0599832e0ef1ead631ab?width=1200&format=jpeg",
    "created_at": "2025-12-15T03:59:01.869Z",
    "topic": "finance"
  },
  {
    "slug": "wall-street-sees-ai-bubble-coming-and-is-betting-on-what-pops-it",
    "title": "Wall Street Sees AI Bubble Coming and Is Betting on What Pops It",
    "description": "It’s been three years since OpenAI set off euphoria over artificial intelligence with the release of ChatGPT. And while the money is still pouring in, so are the doubts about whether the good times can last.",
    "fullText": "MarketsBy Jeran WittensteinSaveIt’s been three years since OpenAI set off euphoria over artificial intelligence with the release of ChatGPT. And while the money is still pouring in, so are the doubts about whether the good times can last.From a recent selloff in the shares of Nvidia Corp., to Oracle Corp.’s plunge after reporting mounting spending on AI, to souring sentiment around a network of companies exposed to OpenAI, signs of skepticism are increasing. Looking to 2026, the debate among investors is whether to rein in AI exposure ahead of a potential bubble popping or double down to capitalize on the game-changing technology.",
    "readingTime": 1,
    "keywords": [
      "openai"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-14/wall-street-sees-an-ai-bubble-forming-and-is-gaming-what-pops-it",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ijt8j35wEhRU/v1/1200x800.jpg",
    "created_at": "2025-12-14T18:50:23.869Z",
    "topic": "gaming"
  },
  {
    "slug": "cognitive-offloading-in-the-era-of-ai",
    "title": "Cognitive Offloading in the Era of AI",
    "description": "Tech & AI - serene speed",
    "fullText": "We keep moving thinking out of our heads and into tools. Paper caught memories. Calculators captured arithmetic. AI now catches recall, drafting, and pattern finding. The risk is mushy judgment; the reward is shipping faster with fewer mistakes. The difference is in how you steer.\n\nHuman working memory is narrow. Context switching burns time. Inputs are exploding: tickets, PRs, logs, customer threads, and research all compete for attention. You forget details, duplicate work, and spend more time rereading than deciding.\n\nFailure modes when you offload poorly:\n\nMIT work on navigation tools showed brain regions tied to spatial planning go quiet when GPS drives every turn. The same pattern shows up with code and writing copilots: if you never build your own map, you stop noticing when the route is wrong.\n\nTreat AI as a structured cognitive exoskeleton. Offload the rote, keep the judgment.\n\nScenario: shipping a new API feature with a small team.\n\nYou offload recall, first drafts, and pattern spotting, then spend attention on judgment and sequencing.\n\nCognitive hygiene is the meta-layer above offloading: habits that keep judgment sharp while you delegate the rote parts.",
    "readingTime": 1,
    "keywords": [
      "judgment",
      "pattern",
      "offload",
      "tools",
      "recall",
      "shipping",
      "attention",
      "cognitive",
      "rote"
    ],
    "qualityScore": 0.85,
    "link": "https://pythonic.ninja/blog/2025-12-11-cognitive-offloading-ai/",
    "thumbnail_url": "https://images.unsplash.com/photo-1486825586573-7131f7991bdd?auto=format&fit=crop&w=1400&q=80",
    "created_at": "2025-12-14T18:50:20.520Z",
    "topic": "tech"
  },
  {
    "slug": "the-view-from-inside-the-ai-bubble",
    "title": "The View from Inside the AI Bubble",
    "description": "Secret parties, lavish buffets, and talks of annihilation at one of the largest AI-research conferences",
    "fullText": "In a small room in San Diego last week, a man in a black leather jacket explained to me how to save the world from destruction by AI. Max Tegmark, a notable figure in the AI-safety movement, believes that “artificial general intelligence,” or AGI, could precipitate the end of human life. I was in town for NeurIPS, one of the largest AI-research conferences, and Tegmark had invited me, along with five other journalists, to a briefing on an AI-safety index that he would release the next day. No company scored better than a C+.\n\nThe threat of technological superintelligence is the stuff of science fiction, yet it has become a topic of serious discussion in the past few years. Despite the lack of clear definition—even OpenAI’s CEO, Sam Altman, has called AGI a “weakly defined term”—the idea that powerful AI contains an inherent threat to humanity has gained acceptance among respected cultural critics.\n\nGranted, generative AI is a powerful technology that has already had a massive impact on our work and culture. But superintelligence has become one of several questionable narratives promoted by the AI industry, along with the ideas that AI learns like a human, that it has “emergent” capabilities, that “reasoning models” are actually reasoning, and that the technology will eventually improve itself.\n\nI traveled to NeurIPS, held at the waterfront fortress that is the San Diego Convention Center, partly to understand how seriously these narratives are taken within the AI industry. Do AGI aspirations guide research and product development? When I asked Tegmark about this, he told me that the major AI companies were sincerely trying to build AGI, but his reasoning was unconvincing. “I know their founders,” he said. “And they’ve said so publicly.”\n\nParallel to the growth of fear and excitement about AI in the past decade, NeurIPS attendance has exploded, increasing from approximately 3,850 conference-goers in 2015 to 24,500 this year, according to organizers. The conference center’s three main rooms each have the square footage of multiple blimp hangars. Speakers addressed audiences of thousands. “I do feel we’re on a quest, and a quest should be for the holy grail,” Rich Sutton, the legendary computer scientist, proclaimed in a talk about superintelligence.\n\nThe conference’s corporate sponsors had booths to promote their accomplishments and impress attendees with their R&D visions. There were companies you’ve heard of, such as Google, Meta, Apple, Amazon, Microsoft, ByteDance, and Tesla, and ones you probably haven’t, such as Runpod, Poolside, and Ollama. One company, Lambda, was advertising itself as the “Superintelligence Cloud.” A few of the big dogs were conspicuously absent from the exhibitor hall, namely OpenAI, Anthropic, and xAI. Consensus among the researchers I spoke with is that the cachet of these companies is already so great that setting up a booth would be pointless.\n\nThe conference is a primary battleground in AI’s talent war. Much of the recruiting effort happens outside the conference center itself, at semisecret, invitation-only events in downtown San Diego. These events captured the ever-growing opulence of the industry. In a lounge hosted by the Laude Institute, an AI-development support group, a grad student told me about starting salaries at various AI companies of “a million, a million five,” of which a large portion was equity. The lounge was designed in the style of a VIP lounge at a music festival. It was, in fact, located at the top of the Hard Rock Hotel.\n\nThe place to be, if you could get in, was the party hosted by Cohere, a Canadian company that builds large language models. (Cohere is being sued for copyright and trademark infringement by a group of news publishers, including The Atlantic.) The party was held on the USS Midway, an aircraft carrier used in Operation Desert Storm, which is now docked in the San Diego harbor. The purpose, according to the event’s sign-up page, was “to celebrate AI’s potential to connect our world.”\n\nWith the help of a researcher friend, I secured an invite to a mixer hosted by the Mohamed bin Zayed University of Artificial Intelligence, the world’s first AI-focused university, named for the current UAE president. Earlier this year, MBZUAI established the Institute for Foundation Models, a research group in Silicon Valley. The event, held at a steak house, had an open buffet with oysters, king prawns, ceviche, and other treats. Upstairs, Meta was hosting its own mixer. According to rumor, some of the researchers downstairs were Meta employees hoping to be poached by the Institute for Foundation Models, which supposedly offered more enticing compensation packages.\n\nOf 5,630 papers presented in the poster sessions at NeurIPS, only two mention AGI in their title. An informal survey of 115 researchers at the conference suggested that more than a quarter didn’t even know what AGI stands for. At the same time, the idea of AGI, and its accompanying prestige, seemed at least partly responsible for the buffet. The amenities I encountered certainly weren’t paid for by chatbot profits. OpenAI, for instance, reportedly expects its massive losses to continue until 2030. How much longer can the industry keep the ceviche coming? And what will happen to the economy, which many believe is propped up by the AI industry, when it stops?\n\nIn one of the keynote speeches, the sociologist and writer Zeynep Tufekci warned researchers that the idea of superintelligence was preventing them from understanding the technology they were building. The talk, titled “Are We Having the Wrong Nightmares About AI?,” mentioned several dangers posed by AI chatbots, including widespread addiction to chatbots and the undermining of methods for establishing truth. After Tufekci gave her talk, the first audience member to ask a question appeared annoyed. “Have you been following recent research?” the man asked. “Because that’s the exact problems we’re trying to fix. So we know of these concerns.” Tufekci responded, “I don’t really see these discussions. I keep seeing people discuss mass unemployment versus human extinction.”\n\nIt struck me that both might be correct: that many AI developers are thinking about the technology’s most tangible problems while public conversations about AI—including those among the most prominent developers themselves—are dominated by imagined ones. Even the conference’s name contained a contradiction: The name “NeurIPS” is short for “Neural Information Processing Systems,” but artificial neural networks were conceived in the 1940s by a logician-and-neurophysiologist duo who wildly underestimated the complexity of biological neurons and overstated their similarity to a digital computer. Regardless, a central feature of AI’s culture is an obsession with the idea that a computer is a mind. Anthropic and OpenAI have published reports with language about chatbots being, respectively, “unfaithful” and “dishonest.” In the AI discourse, science fiction often defeats science.\n\nOn the roof of the Hard Rock Hotel, I attended an interview with Yoshua Bengio, one of the three “godfathers” of AI. Bengio, a co-inventor of an algorithm that makes ChatGPT possible, recently started a nonprofit called LawZero to encourage the development of AI that is “safe by design.” He took the nonprofit’s name from a law featured in several Isaac Asimov stories that states that a robot should not allow humans to be harmed. Bengio was concerned that, in a possible dystopian future, AIs might deceive their creators and that “those who will have very powerful AIs could misuse it for political advantage, in terms of influencing public opinion.”\n\nI looked around to see if anyone else was troubled by the disconnect. Bengio did not mention how fake videos are already affecting public discourse. Neither did he meaningfully address the burgeoning chatbot mental-health crisis, or the pillaging of the arts and humanities. The catastrophic harms, in his view, are “three to 10 or 20 years” away. We still have time “to figure it out, technically.”\n\nBengio has written elsewhere about the more immediate dangers of AI. But the technical and speculative focus of his remarks captures the sentiment among technologists who now dominate the public conversation about our future. Ostensibly, they are trying to save us, but who actually benefits from their predictions? As I spoke with 25-year-olds entertaining seven-figure job offers and watched the industry’s millionaire luminaries debate the dangers of superintelligence, the answer seemed clear.",
    "readingTime": 7,
    "keywords": [
      "rock hotel",
      "science fiction",
      "san diego",
      "foundation models",
      "neurips",
      "industry",
      "idea",
      "among",
      "conference",
      "researchers"
    ],
    "qualityScore": 1,
    "link": "https://www.theatlantic.com/technology/2025/12/neurips-ai-bubble-agi/685250/",
    "thumbnail_url": "https://cdn.theatlantic.com/thumbor/6yBQjSLMBfEUwxwqHa9iIrt8rD8=/3x0:1097x574/960x504/media/img/mt/2025/12/2025_12_12_Ai_mpg/original.gif",
    "created_at": "2025-12-14T18:50:18.218Z",
    "topic": "tech"
  },
  {
    "slug": "prompt-engineering-is-a-hidden-tax-chatgpt-vs-copyai-vs-vertical-agents",
    "title": "Prompt Engineering Is a \"Hidden Tax\": ChatGPT vs. Copy.ai vs. Vertical Agents",
    "description": "A definitive 2025 comparison of Vect AI, Copy.ai, and ChatGPT. Discover why specialized 'Marketing Operating Systems' are replacing generalist chatbots for serious growth teams.",
    "fullText": "Every week, a new \"ChatGPT Killer\" launches on Product Hunt. But for distinct, revenue-focused marketers, the noise is distracting. You don't need another chatbot that can write a mediocre limerick about a pirate. You don't need a tool that requires a 50-paragraph \"mega-prompt\" just to sound human.\n\nYou need a system that drives Revenue.\n\nIn 2025, the AI landscape has calcified into three distinct categories. Understanding this split is critical before you swipe your credit card.\n\nThis guide isn't just a list of features or a rehash of pricing pages. It is a \"Stress Test\" of how these tools handle the real, messy, complex work of a modern high-growth marketing team.\n\nTo understand the tool, you must understand the brain behind it. Each platform was built with a fundamentally different thesis about what a marketer needs.\n\nOpenAI built a general-purpose reasoning engine. It is brilliant at coding, summarizing history, and casual chat. But it has no \"opinion\" on marketing. It doesn't know that a headline should differ between a cold email and a landing page unless you explicitly tell it the precise psychological framework to use.\n\nCopy.ai pivoted from a simple writing tool to a \"GTM AI Platform.\" Their thesis is that marketing is a series of data flows. Scrape LinkedIn -> Enrich Data -> Write Email -> Send.\n\nVect AI was built with a single thesis: Strategy should come before generation. It assumes you want the best marketing outcome, not just any text. It is \"State-Aware\"—meaning it permanently remembers your brand voice, audience pains, and product details.\n\nLet's move away from theory and look at three common, painful scenarios every marketer faces.\n\nYou need to fix a landing page that isn't converting.\n\nChatGPT Approach:\nYou paste the text. You ask: \"Make this better.\" ChatGPT changes a few synonyms. It sounds robotic. You spend 15 minutes explaining your customer persona. It eventually gives you something passable but generic.\n\nCopy.ai Approach:\nYou look for a \"Landing Page Rewriter\" workflow. You run it. It generates 10 variations. You have to read all 10 to decide which one is good.\n\nVect AI Approach:\nYou open the Conversion Killer Detector. You paste your URL. The Agent scans the live page, identifies \"Passive Voice\" and \"Weak Value Props,\" assigns a \"Panic Score,\" and auto-rewrites the specific sections that are killing sales.\n\nYou released a new feature. You need a blog, 10 tweets, 3 LinkedIn posts, and a newsletter.\n\nCopy.ai Approach (The Engineer's Way):\n\nVect AI Approach (The Strategy Way):\n\nThis is the single biggest differentiator.\n\nChatGPT has \"Custom Instructions,\" but they are weak. It often forgets them in long threads.\nCopy.ai uses \"Brand Voice\" snippets, but you have to manually select them for every workflow.\n\nVect AI uses a Global Brand Kernel.\nWhen you onboard, you define your audience, your pain points, and your \"Anti-Persona\" (who you don't want).\n\nMost AI tools are \"Yes Men.\" If you ask them to write a boring, 3,000-word email, they will say \"Sure!\" and do it.\n\nVect AI has a conscience. It's called the Resonance Engine.\nBefore you publish, you can run your content through this simulation. It uses historical data from millions of high-performing ads and posts to predict success.\n\nOnly Vect AI protects you from looking stupid. The others just execute orders.\n\nMarketing isn't just text. It's visual.\n\nCopy.ai is purely text-based. You need a separate Midjourney subscription for images.\nChatGPT has DALL-E 3, which is fun but often too \"cartoony\" for enterprise brands.\n\nVect AI includes a commercial-grade AI Ad Creative Studio and Marketing Video Ad generator.\n\nWhen comparing prices, most people look at the monthly fee. This is a mistake. You must calculate the Time Cost.\n\nTo give you a sense of the specialization, look at how granular Vect AI gets compared to the generic \"Write an Article\" button in other tools:\n\nThe era of \"Generalist AI\" for professionals is ending. We are entering the era of \"Agentic Workflows.\"\n\nStop fighting with prompts. Stop building workflows. Start leading your market.\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Conversion Killer Detector\" and get results in minutes.",
    "readingTime": 4,
    "keywords": [
      "conversion killer",
      "killer detector",
      "copy.ai approach",
      "landing page",
      "vect ai",
      "brand voice",
      "marketing",
      "look",
      "don't",
      "tool"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/vect-vs-copy-ai",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T18:50:17.665Z",
    "topic": "tech"
  },
  {
    "slug": "at-this-small-buyout-firm-talking-about-ai-for-costcutting-is-offlimits",
    "title": "At this small buyout firm, talking about AI for cost-cutting is off-limits",
    "description": "Unlike their buyout peers, Tide Rock isn't looking to AI to cut costs. Instead, it's CEO told us, its using it to find new customers and deals.",
    "fullText": "Most fears and hopes surrounding AI center on its ability to save on labor costs. Whether it's Jamie Dimon predicting a three-and-a-half-day workweek, the chorus of CEOs saying that AI will help its workers get more done, or the research predicting potentially catastrophic white-collar job cuts, the focus is on efficiency.\n\nBut at one investing firm, cost-cutting is practically a forbidden word.\n\n\"The mandate across the company is don't talk about using our resources in AI or tech to cut costs or create efficiencies,\" Tide Rock CEO Ryan Peddycord told Business Insider.\n\nThe firm has had AI engineers for two years, but they're aimed at growing business, not cutting, said Peddycord.\n\nThe San Diego and New York-based firm, which invests in smaller businesses than your typical private-equity giants, does not use debt to finance its acquisitions. It manages $1 billion, including its current investments and dry powder. It has done over 50 acquisitions, with growth, not just financial engineering, as its goal.\n\n\"Our foundation is, and our principle is, that we are focused on being growth engines for these businesses, and that's where we want to focus our resources,\" Peddycord said.\n\nPeddycord spoke to Business Insider about how the firm's use of AI fits into its business model and gave some real-world examples of where it has made an impact.\n\nThe company buys founder-run businesses when founders have \"a catalyst to change,\" like their own looming retirement or an illness in their family, which means they're much more protective of the asset they're selling than your typical financial investor.\n\nThey then focus on growing those companies, which means Tide Rock hires chief marketing officers and chief revenue officers \"who know how to run businesses\" instead of your typical private equity partners, Peddycord said.\n\nThe firm's companies have seen organic revenue growth of 24% a year since Tide Rock was launched 13 years ago, said Peddycord. (He also said the firm has only lost money on one deal over that time period.)\n\nThey're looking for a way to monetize what they built over time, but really just as important to them is for their brand and their legacy and their employees to be able to kind of continue on without them,\" Peddycord said.\n\nFor founders like this, the story of growth is an essential reason they'd choose to sell to Tide Rock. As such, any discussion of using AI to cut employees or costs is anathema to their sales pitch, whereas AI for growth is a selling point.\n\nAI is becoming an integral part of the firm's strategy, but they've been doing this for years before the advent of LLMs some operational best practices in a library of over 100 videos and 500 pages of documentation.\n\n\"A CEO of a portfolio company has access to certain information, a controller has access to a different set of information, a VP of sales has access to information,\" Peddycord said.\n\nAI tools have become another operational best practice that the firm shares across the companies it manages, which it tracks in a library of 100 videos and 500 pages of documentation.\n\nThe firm also has other centralized resources in-house, \"as a bridge\" to get the businesses to a place where they can operate on their own, including a centralized talent acquisition team and centralized chief marketing and revenue officers.\n\nThis has led to a world where the firm has, for example, been able to integrate a customer relationship management system in \"30 to 45 days\" instead of \"12 to 18 months,\" said Peddycord.\n\nThe company is happy to use third-party applications that can cut costs, but it's a waste of their own resources, said Peddycord.\n\n\"I have a belief that everybody's so focused on cost-cutting that third parties are going to pick off all the low-hanging fruit there,\" Peddycord said. \"So us trying to invest our dollars to go create things that other people are creating and probably investing more dollars to do isn't the right place to spend our money.\"\n\nThe first tool they invested in was finding companies to purchase. The data on platforms like Pitchbook and Crunchbase is \"very, very incomplete\" at the sub-$10 million EBITDA level the firm invests in, said Peddycord, so the firm first invested \"heavily\" in ways to find these companies and start pitching them.\n\nSoon, the firm realized that this ability to find a lot of \"non-public information\" about companies and then reach out to them would also be \"super relevant\" for their portfolio companies when they're looking for new customers, Peddycord said.\n\nPeddycord provided the example of identifying potential customers for its manufacturing portfolio companies that sell to the government, aerospace, or defense industries.\n\n\"When Blue Origin wins a large contract, there is some public information that we are able to gather to identify what it is that they won the contract for, and we can even reverse engineer what sub-component parts and services are going to be necessary to then go create that,\" Peddycord said.\n\nFrom there, the firm's portfolio companies could \"get in the door earlier\" to offer their sub-component manufacturing help, Peddycord said.\n\n\"In those high-growth areas like aerospace and defense, they are working as hard to find new qualified suppliers as we are to find new customers,\" Peddycord said.",
    "readingTime": 5,
    "keywords": [
      "chief marketing",
      "customers peddycord",
      "revenue officers",
      "they're looking",
      "tide rock",
      "firm",
      "businesses",
      "growth",
      "resources",
      "firm's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tide-rock-buy-out-firm-ai-cost-cutting-2025-12",
    "thumbnail_url": "https://i.insider.com/693c9e8e04eda4732f2d7bf3?width=1200&format=jpeg",
    "created_at": "2025-12-14T18:50:17.326Z",
    "topic": "finance"
  },
  {
    "slug": "us-power-shortage-how-small-modular-nuclear-reactors-could-fill-the-gap",
    "title": "US Power Shortage: How Small Modular Nuclear Reactors Could Fill the Gap",
    "description": "US electricity demand is now expected to rise 20 to 100 percent over the next 15 years as AI data centers, chip fabs and electrification strain an aging grid. Scott Strazik and Nicole Holmes of GE Vernova and Joseph Majkut of CSIS explain why nuclear – especially through small modular reactors – is back on the table.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-14/can-modular-nuclear-reactors-fill-the-power-gap-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ipVwqUEOzRGw/v3/-1x-1.jpg",
    "created_at": "2025-12-14T13:19:55.820Z",
    "topic": "finance"
  },
  {
    "slug": "ai-and-the-ironies-of-automation-part-2",
    "title": "AI and the ironies of automation – Part 2",
    "description": "Some (well-known) consequences of AI automating work",
    "fullText": "In the previous post, we discussed several observations, Lisanne Bainbridge made in her much-noticed paper “The ironies of automation”, she published in 1983 and what they mean for the current “white-collar” work automation attempts leveraging LLMs and AI agents based on LLMs, still requiring humans in the loop. We stopped at the end of the first chapter, “Introduction”, of the paper.\n\nIn this post, we will continue with the second chapter, “Approaches to solutions”, and see what we can learn there.\n\nHowever, before we start: Some of the observations and recommendations made in the paper must be taken with a grain of salt when applying them to the AI-based automation attempts of today. When monitoring an industrial production plant, it is often a matter of seconds until a human operator must act if something goes wrong to avoid severe or even catastrophic accidents.\n\nTherefore, it is of the highest importance to design industrial control stations in a way that a human operator can recognize deviations and malfunctions as easily as possible and immediately trigger countermeasures. A lot of work is put into the design of all the displays and controls, like, e.g., the well-known emergency stop switch in a screaming red color that is big enough to be punched with a flat hand, fist or alike within a fraction of a second if needed.\n\nWhen it comes to AI-based solutions automating white-collar work, we usually do not face such critical conditions. However, this is not a reason to dismiss the observations and recommendations in the paper easily because, e.g.:\n\nIf we let this sink in (plus a few other aspects, I did not write down here but you most likely will add in your mind), we quickly come to the conclusion that also in our AI-related automation context humans are often expected to make quick decisions and act based on them, often under conditions that make it hard (if not impossible) to conduct any in-depth analysis.\n\nIf we then also take into account, that depending on the situation a wrong result produced by an AI solution which eluded the human operator may have severe consequences in the worst case (e.g., assume a major security incident due to a missed wrongdoing of the AI solution), the situation is not that far away anymore from the situation in an industrial plant’s control station.\n\nSummarizing, we surely need to add the necessary grain of salt, i.e., ask ourselves how strict the timing constraints in our specific setting are to avoid comparing apples and oranges in the worst case. However, in general we need to consider the whole range of possible settings which will – probably more often than we think – include that humans need to make decisions in a very short time under stressful conditions (which makes things more precarious).\n\nThis brings us immediately to Lisanne Bainbridge’s first recommendation:\n\nIn any situation where a low probability event must be noticed quickly then the operator must be given artificial assistance, if necessary even alarms on alarms.\n\nIn other words, the system must support the human operator as well as possible in detecting a problem, especially if it tends to occur rarely. It is a consequence of the “monitoring fatigue” problem we discussed in the previous post.\n\nDue to the learnings people have made, a lot of effort has been put into the design of the displays, the controls and also the alerting mechanisms of industrial production control stations, making sure the human operators can make their jobs as good, as stress-free and as reliable as possible.\n\nThe usual idea is that a single human controls a fleet of AI agents that are designed to do some kind of job, e.g., writing code. Sometimes, most agents are generic “workers”, orchestrated by some kind of supervisor that delegates parts of the work to the worker agents. Sometimes, the different agents are “specialists”, each for a certain aspect of the job to be done, that collaborate using some kind of choreography (or are also orchestrated by a supervisor). While the generic workers are easier to set up, the specialized workers usually produce more accurate results.\n\nBecause these AI-based agents sometimes produce errors, a human – in our example a software developer – needs to supervise the AI agent fleet and ideally intervenes before the AI agents do something they should not do. Therefore, the AI agents typically create a plan of what they intend to do first (which as a side effect also increases the likelihood that they do not drift off). Then, the human verifies the plan and approves it if it is correct, and the AI agents execute the plan. If the plan is not correct, the human rejects it and sends the agents back to replanning, providing information about what needs to be altered.\n\nLet us take Lisanne Bainbridge’s recommendation and compare it to this approach that is currently “best practice” to control an AI agent fleet.\n\nUnless we tell them to act differently, LLMs and also AI agents based on them are quite chatty. Additionally, they tend to communicate with an air of utter conviction. Thus, they present to you this highly detailed, multi-step plan of what they intend to do, including lots of explanations, in this perfectly convinced tone. Often, these plans are more than 50 or 100 lines of text, sometimes even several hundred lines.\n\nMost of the time, the plans are fine. However, sometimes the AI agents mess things up. They make wrong conclusions, or they forget what they are told to do and drift off – not very often, but it happens. Sometimes the problem is obvious at first sight. But more often, it is neatly hidden somewhere behind line 123: “… and because 2 is bigger than 3, it is clear, we need to < do something critical >”. But because it is so much text the agents flood you with all the time and because the error is hidden so well behind this wall of conviction, we miss it – and the AI agent does something critical wrong.\n\nWe cannot blame the person for missing the error in the plan. The problem is that this is probably the worst UI and UX possible for anyone who is responsible for avoiding errors in a system that rarely produces errors.\n\nBut LLM-based agents make errors all the time, you may say. Well, not all the time. Sometimes they do. And the better the instructions and the setup of the interacting agents, the fewer errors they produce. Additionally, we can expect more specialized and refined agents in the future that become increasingly better in their respective areas of expertise. Still, most likely they will never become completely error-free because of the underlying technology that cannot guarantee consistent correctness.\n\nThis is the setting we need to ponder if we talk about the user interface for a human observer: a setting where the agent fleet only rarely makes errors but we still need a human monitoring and intervening if things should go wrong. It is not yet clear how such an interface should look like, but most definitely not as it looks now. Probably we could harvest some good insights from our UX/UI design colleagues for industrial production plant control stations. We would need only to ask them …\n\nLisanne Bainbridge then makes several recommendations regarding the required training of the human operator. This again is a rich section, and I can only recommend reading it on your own because it contains several subtle yet important hints that are hard to bring across without citing the whole chapter. Here, I will highlight only a few aspects. She starts with:\n\n[Some points made in the previous section] make it clear that it can be important to maintain manual skills.\n\nThen she talks about letting the human operator take over control regularly, i.e., do the job instead of the machine as a very effective training option. Actually, without doing hands-on work regularly, the skills of a human expert deteriorate surprisingly fast.\n\nBut if taking over the work regularly is not an option, e.g., because we want continuous superhuman productivity leveraging AI agents (no matter if it makes sense or not), we still need to make sure that the human operator can take over if needed. In such a setting, training must take place in some other way, usually using some kind of simulator.\n\nHowever, there is a problem with simulators, especially if human intervention is only needed (and wanted) if things do not work as expected:\n\nThere are problems with the use of any simulator to train for extreme situations. Unknown faults cannot be simulated, and system behaviour may not be known for faults which can be predicted but have not been experienced.\n\nThe consequence of this issue is:\n\nThis means that training must be concerned with general strategies rather than specific responses […]\n\nIt is inadequate to expect the operator to react to unfamiliar events solely by consulting operating procedures. These cannot cover all the possibilities, so the operator is expected to monitor them and fill in the gaps.\n\nWhich leaves us with the irony:\n\nHowever, it is ironic to train operators in following instructions and then put them in the system to provide intelligence.\n\nThis is a problem we will need to face with AI agents and their supervising humans in the future, too. The supervising experts are meant to intervene whenever things become messy, whenever the AI agents get stuck, often in unforeseen ways. These are not regular tasks. Often, these are also not the issues we expect an AI agent to run into and thus can provide training for. These are extraordinary situations, the ones we do not expect – and the more refined and specialized the AI agents will become in the future, the more often the issues that require human intervention will be of this kind.\n\nThe questions seem to hint at a sort of paradox, and an answer to both questions is all but obvious. At the moment, we still have enough experienced subject matter experts that the questions may feel of lower importance. But if we only start to address the questions when they become pressing, they will be even harder – if not impossible – to solve.\n\nTo end this consideration with the words of Lisanne Bainbridge:\n\nPerhaps the final irony is that it is the most successful automated systems, with rare need for manual intervention, which may need the greatest investment in human operator training.\n\nIn other words, we cannot simply take a few available human experts and make them supervise agents that took over their work without any further investments in the humans. Instead, we need to train them continuously, and the better the agents become, the more expensive the training of the supervisors will become. I highly doubt that decision makers who primarily think about saving money when it comes to AI agents are aware of this irony.\n\nAs I wrote in the beginning of first part of this blog series, “The ironies of automation” is a very rich and dense paper. We are still only at the end of the second chapter “Approaches to solutions” which is two and a half pages into the paper and there is still a whole third chapter called “Human-computer collaboration” which takes up another page until we get to the conclusion.\n\nWhile this third chapter also contains a lot of valuable advice that goes well beyond our focus here, I will leave it to you to read it on your own. As I indicated at the beginning, this paper is more than worth the time spent on it.\n\nHowever, before finishing this little blog series, I would like to mention a new kind of dilemma that Lisanne Bainbridge did not discuss in her paper because the situation was a bit different with industrial production plant automation than with AI-agent-based automation. But as this topic fits nicely into the just-finished training paradox section, I decided to add it here.\n\nThe issue is that just monitoring an AI agent fleet doing its work and intervening if things go wrong usually is not sufficient, at least not yet. All the things discussed before apply, but there is more to interacting with AI agents because we cannot simply be reactive with AI agents. We cannot simply watch them doing their work and only intervene if things go wrong. Instead, we additionally need to be proactive with them: We need to direct them.\n\nWe need to tell the AI agents what to do, what not to do, which chunks to pick and so on. This is basically a leadership role. While you do not lead humans, the kind of work is quite similar: You are responsible for the result; you are allowed to set directions and constraints, but you do not immediately control the work. You only control it through communicating with the agents and trying to direct them in the right direction with orders, with feedback, with changed orders, with setting different constraints, etcetera.\n\nThis is a skill set most people do not have naturally. Usually, they need to develop it over time. Typically, before people are put in a leadership role directing humans, they will get a lot of leadership training teaching them the skills and tools needed to lead successfully. For most people, this is essential because if they come from the receiving end of orders (in the most general sense of “orders”), typically they are not used to setting direction and constraints. This tends to be a completely new skill they need to learn.\n\nThis does not apply only to leading humans but also to leading AI agents. While AI agents are not humans, and thus leadership will be different in detail, the basic skills and tools needed are the same. This is, BTW, one of the reasons why the people who praise agentic AI on LinkedIn and the like are very often managers who lead (human) teams. For them, leading an AI agent fleet feels very natural because it is very close to the work they do every day. However, for the people currently doing the work, leading an AI agent fleet usually does not feel natural at all.\n\nHowever, I have not yet seen anyone receiving any kind of leadership training before being left alone with a fleet of AI agents, and I still see little discussion about the issue. “If it does not work properly, you need better prompts” is the usual response if someone struggles with directing agents successfully.\n\nSorry, but it is not that easy. The issue is much bigger than just optimizing a few prompts. The issue is that people have to change their approach completely to get any piece of work done. Instead of doing it directly, they need to learn how to get it done indirectly. They need to learn how to direct a group of AI agents effectively, how to lead them.\n\nThis also adds to the training irony of the previous topic. Maybe the AI agent fleets will become good enough in the future that we can omit the proactive part of the work and only need to focus on the reactive part of the work, the monitor-and-intervene part. But until then, we need to teach human supervisors of AI agent fleets how to lead them effectively.\n\nWe discussed several ironies and paradoxes from Lisanne Bainbridge’s “The ironies of automation” and how they also apply to agentic AI. We looked at the unlearning and recall dilemma and what it means for the next generation of human supervisors. We discussed monitoring fatigue and the status issue. We looked at the UX and UI deficiencies of current AI agents and the training paradox. And we finally looked at the leadership dilemma, which Lisanne Bainbridge did not discuss in her paper but which complements the training paradox.\n\nI would like to conclude with the conclusion of Lisanne Bainbridge:\n\n[…] humans working without time-pressure can be impressive problem solvers. The difficulty remains that they are less effective when under time pressure. I hope this paper has made clear both the irony that one is not by automating necessarily removing the difficulties, and also the possibility that resolving them will require even greater technological ingenuity than does classic automation.\n\nI think over time we will become clear on how much “The ironies of automation” also applies to automation done with AI agents and that we cannot ignore the insights known for more than 40 years meanwhile. I am also really curious how the solutions to the ironies and paradoxes will look like.\n\nUntil then, I hope I gave you a bit of food for thought to ponder. If you should have some good ideas regarding the ironies and how to address them, please do not hesitate to share them with the community. We learn best by sharing and discussing, and maybe your contribution will be a step towards solving the issues discussed …",
    "readingTime": 15,
    "keywords": [
      "chapter approaches",
      "blog series",
      "generic workers",
      "production plant",
      "monitoring fatigue",
      "tools needed",
      "industrial production",
      "third chapter",
      "leadership role",
      "cannot simply"
    ],
    "qualityScore": 1,
    "link": "https://www.ufried.com/blog/ironies_of_ai_2/",
    "thumbnail_url": "https://ufried.com//images/logo.png",
    "created_at": "2025-12-14T13:19:51.138Z",
    "topic": "tech"
  },
  {
    "slug": "experts-urge-caution-as-trumps-big-bill-incentivizes-ai-in-healthcare",
    "title": "Experts urge caution as Trump’s big bill incentivizes AI in healthcare",
    "description": "Analysts say benefits could be felt in under-resourced rural hospitals but warn against AI as a cost-cutting measure\nFor states to receive certain funding stipulated in the Trump administration’s “big, beautiful” bill, they must meet three of 10 criteria – including integrating more artificial intelligence (AI) technology in healthcare settings – which experts say could have major benefits and liabilities for under-resourced hospitals, depending on how it’s implemented.\nThe Rural Health Transformation Fund is a carveout that will provide $50bn over a period of five years to states who meet certain application criteria, including “consumer-facing, technology-driven solutions for the prevention and management of chronic diseases,” and “providing training and technical assistance for the development and adoption of technology-enabled solutions that improve care delivery in rural hospitals, including remote monitoring, robotics, artificial intelligence, and other advanced technologies”.\n Continue reading...",
    "fullText": "Analysts say benefits could be felt in under-resourced rural hospitals but warn against AI as a cost-cutting measure\n\nFor states to receive certain funding stipulated in the Trump administration’s “big, beautiful” bill, they must meet three of 10 criteria – including integrating more artificial intelligence (AI) technology in healthcare settings – which experts say could have major benefits and liabilities for under-resourced hospitals, depending on how it’s implemented.\n\nThe Rural Health Transformation Fund is a carveout that will provide $50bn over a period of five years to states who meet certain application criteria, including “consumer-facing, technology-driven solutions for the prevention and management of chronic diseases,” and “providing training and technical assistance for the development and adoption of technology-enabled solutions that improve care delivery in rural hospitals, including remote monitoring, robotics, artificial intelligence, and other advanced technologies”.\n\nAnalysts have noted that this $50bn will not be nearly enough to make up for the Congressional Budget Office’s projected $911bn reduction in Medicaid spending over the next decade under the bill (Obba). These cuts will affect both patients who lose free health coverage under Medicaid, and hospitals who benefit from those patients’ Medicaid reimbursements.\n\nChenhao Tan, associate professor of data science at the University of Chicago, and Karni Chagal-Feferkorn, an assistant professor at the University of South Florida’s college of AI and cybersecurity, said AI technology could provide major benefits to rural hospitals that are frequently under-resourced and under-staffed. They also agreed that AI has the potential to alleviate the administrative burden that physicians at these hospitals often face.\n\nPhysicians are responsible for taking detailed notes on patient visits and compiling them for electronic health records systems – a task that can take eight hours or more each week, according to the American Medical Association.\n\nA recent study found that AI generated patient notes are similar in quality to those of general physicians, but worse than those of expert physicians. Tan said that it’s important to take context – like frequent physician burnout in rural hospitals – into account when evaluating risks and benefits.\n\n“If the baseline is tired human doctors, then I think it is even easier to make an argument that AI may do better than them,” Tan said.\n\nChagal-Feferkorn hopes that AI can help alleviate rural hospital staffing issues, not only by reducing the workload but by attracting more doctors.\n\n“If the equipment is state-of-the-art, and they feel that much of the burdensome work is done by AI, I think this could be one incentive for physicians to go work in rural areas, this might have a great impact,” she said.\n\nThe FDA currently regulates AI technologies that are intended to evaluate and diagnose health conditions because they are considered medical devices. However, technologies that simply transcribe and compile patient notes are not regulated, though they may market themselves as Hipaa compliant.\n\nWhile Tan said it would be too high a bar to expect these technologies to be “bulletproof” before they can enter the market, he acknowledged that “there should be something higher than nothing,” in terms of regulatory requirements.\n\nChagal-Feferkorn also said that the proliferation of AI also creates additional cybersecurity concerns.\n\n“AI makes it easier for ordinary people to hack systems,” she said, adding that AI has the potential to improve patient safety by merging patient records from different providers so that, for example, every provider is aware of every medication that a patient is taking and can thus easily avoid dangerous medication interactions.\n\nBut this kind of technology will also require more privacy precautions.\n\n“The more data sharing there is, obviously the risk for data security breach is larger,” Chagal-Feferkorn continued.\n\nTo mitigate these risks, Tan said “worker upscaling needs to go hand in hand” with the adoption of AI technology. But Tan and Chagal-Feferkorn both expressed concern that under-resourced hospitals will attempt to adopt AI technology as a cost-cutting measure without the necessary staff and safety infrastructure.",
    "readingTime": 4,
    "keywords": [
      "cost-cutting measure",
      "artificial intelligence",
      "patient notes",
      "rural hospitals",
      "under-resourced hospitals",
      "technology",
      "physicians",
      "benefits",
      "health",
      "technologies"
    ],
    "qualityScore": 0.8,
    "link": "https://www.theguardian.com/us-news/2025/dec/14/trump-healthcare-ai",
    "thumbnail_url": "https://i.guim.co.uk/img/media/289c2e4c4f4f74e77f733db894eb5be6c396e75f/125_0_3750_3000/master/3750.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f3814a3f0982a31cf15647285409f660",
    "created_at": "2025-12-14T13:19:46.743Z",
    "topic": "tech"
  },
  {
    "slug": "harvey-ceo-shares-his-advice-to-young-lawyers-and-those-considering-pivoting-into-legal-tech",
    "title": "Harvey CEO shares his advice to young lawyers — and those considering pivoting into legal tech",
    "description": "Harvey CEO Winston Weinberg said AI won't changes what it makes an incredible lawyer.",
    "fullText": "AI won't change what it takes to be a good lawyer, according to one industry leader.\n\n\"So I actually think a lot of what makes an incredible lawyer today is still what will make one tomorrow,\" Winston Weinberg, Harvey's cofounder and chief executive, wrote during a recent Reddit Ask Me Anything chat.\n\nWeinberg, whose AI startup is already disrupting Big Law, said the best partners Harvey works with understand their business needs.\n\n\"I've found that the best partners are the ones that are incredible at understanding what the actual business needs are and framing an agreement based on that,\" Weinberg wrote. \"Same goes for litigation, it's who can come up with the best arguments/story not who is the best at going through emails in discovery.\"\n\nOverall, junior partners should try to get \"as much client experience as possible,\" Weinberg said.\n\n\"That's actually the main thing I pitch to firm leaders - they should focus more on giving juniors client experience, and be okay with them making some mistakes - that's how they become the best partners in the future,\" he wrote.\n\nLast week, Harvey reached a valuation of $8 billion, thanks to a recent funding round led by A16z. Weinberg said that no single company, including Harvey, will own the legal tech market.\n\n\"I don't think a single player is going to capture all of the pretty enormous amount of value that will be created in the next 10 years in this space,\" he wrote in the Reddit chat.\n\nAs for lawyers who want to follow in his footsteps, Weinberg said they need to get used to failure.\n\n\"Junior lawyers are often practiced perfectionists, and startups are all about risk, reward, and resilience,\" Weinberg told Business Insider after his Reddit chat. \"So I meant what I said--the biggest thing a lawyer who wants to work in the tech space should do is build up tolerance for failure.\"",
    "readingTime": 2,
    "keywords": [
      "reddit chat",
      "client experience",
      "business needs",
      "partners",
      "lawyer",
      "weinberg",
      "incredible",
      "junior",
      "that's",
      "tech"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/harvey-ceo-advice-young-lawyers-2025-12",
    "thumbnail_url": "https://i.insider.com/693c6c3464858d02d216bd7f?width=1200&format=jpeg",
    "created_at": "2025-12-14T13:19:39.461Z",
    "topic": "finance"
  },
  {
    "slug": "figure-ai-ceo-says-over-170000-people-have-applied-to-his-robot-company-in-the-last-3-years-he-hired-fewer-than-500",
    "title": "Figure AI CEO says over 170,000 people have applied to his robot company in the last 3 years. He hired fewer than 500.",
    "description": "Figure AI CEO Brett Adcock said on X that his company reviewed 176,000 resumes but most of them were \"slop.\" Less than 450 people were hired, he said.",
    "fullText": "A humanoid robotics startup in Silicon Valley appears to have an acceptance rate lower than any Ivy League university.\n\nFigure AI has been flooded with résumés since its founding in 2022, according to the startup's founder and CEO, Brett Adcock.\n\n\"Just checked, 176,000 job applications at Figure the last 3 years,\" he wrote in an X post on Saturday. \"We've hired ~425 people.\"\n\nThat amounts to a hiring rate of about .24% within the three years. Adcock wrote that most of the submissions were \"slop.\"\n\nThe spread of the 176,000 applications over the three years is unclear. Adcock did not immediately respond to a request for comment.\n\nEven if the number of applications were divided equally among the years Figure AI was operating — just under 59,000 applications a year — the acceptance rate would still be lower than that of the hardest university to get into. Caltech had the lowest acceptance rate of 3%, according to US News & World Report's rankings list.\n\nAdcock wrote in the comments of his X post that the review process has been a slog.\n\n\"We go through these one by one like a monkey — it's incredibly time consuming,\" he wrote.\n\nAccording to the CEO, the \"ATS\" or applicant tracking system — a software employers use to sift through résumés — can't save a lot of time if a company is being barraged with hundreds of thousands of applications.\n\n\"In the ATS it takes at least 20 seconds of button clicks per submission even if it's garbage,\" he wrote.\n\nAdcock did not immediately respond to a request for comment.\n\nA company like Figure AI sits right in the intersection of two trends within the job market.\n\nToday's job candidates aren't applying to just a handful of roles. Business Insider's chief correspondent Aki Ito reported that the average job opening saw 242 applications, citing data from Greenhouse, a leading ATS platform.\n\n\"Applying to a job in 2025 really is the statistical equivalent of hurling your résumé into a black hole,\" Ito wrote.\n\nOn the other hand, Figure AI operates in one of the hottest spaces of the tech industry, that is, robotics and artificial intelligence.\n\nTop tech firms like Meta and OpenAI are in the midst of an AI talent war, offering up to seven- to nine-figure pay packages just to poach superstar AI researchers.\n\nEven tech startups are scrapping for AI talent, floating higher equity packages and other perks that may not come as easily at a big company, such as a co-founding title or more time for research.\n\nFigure AI happens to be one of the leading names in the humanoid robotics space.\n\nThe company recently raised more than $1 billion in its Series C funding round — with backing from Parkway Venture Capital, Brookfield Asset Management, and Nvidia, among others — for a $39 billion valuation.\n\nAdcock said on X that he may need to find another way to sift through résumés.\n\n\"Need a model to do this for us better, maybe I'll work on one,\" he wrote.",
    "readingTime": 3,
    "keywords": [
      "immediately respond",
      "figure ai",
      "humanoid robotics",
      "acceptance rate",
      "applications",
      "résumés",
      "tech",
      "lower",
      "university",
      "within"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/figure-ai-robotics-startup-tech-job-market-competition-170k-resumes-2025-12",
    "thumbnail_url": "https://i.insider.com/693dee0c832e0ef1ead630bf?width=1200&format=jpeg",
    "created_at": "2025-12-14T06:53:31.617Z",
    "topic": "finance"
  },
  {
    "slug": "hazbin-hotel-oc-maker-create-original-characters-with-ai",
    "title": "Hazbin Hotel OC Maker – Create Original Characters with AI",
    "description": "Create original characters in the style of Hazbin Hotel, supporting demon forms, angel OCs, and custom bases.",
    "fullText": "Build your own Hazbin Hotel characters with our AI OC Maker, OC Generator, and Creator Tool. Perfect for demons, angels, sinners, or original ideas from Hell!\n\nJoin thousands of fans creating their own characters! 👾\n\nExplore more powerful AI features\n\nExplore fan-made creations and spark inspiration for your own Hazbin Hotel OC, including demons, angels, and unique base templates.\n\nMake your Hazbin Hotel character in four simple steps:\n\nAdd traits like demon form, abilities, powers, backstory, and personality.\n\nPick from angelic, demonic, sinner, or overlord archetypes.\n\nAI provides multiple versions—refine details until perfect.\n\nDownload in HD for cosplay, fanart, or storytelling projects.\n\nHazbin Hotel OC Maker is an AI-powered tool for fans who want to create their own characters in the Hazbin Hotel universe. Build demons, angels, and sinners with unique designs and personalities.\n\nBring your Hazbin Hotel ideas to life with AI, creating detailed OCs for fanart, cosplay, or stories.\n\nPacked with features to create authentic Hazbin Hotel OCs.\n\nTrained on Hazbin Hotel-inspired art and character archetypes.\n\nSwitch between angelic or demonic templates for your characters.\n\nStart from Hazbin Hotel OC bases and customize easily.\n\nGet full lore, personality traits, and relationships.\n\nTry classic, angelic, demonic, or experimental visual looks.\n\nDownload OCs in high resolution for personal or community projects.\n\nFeedback from Hazbin Hotel fans who brought their OC ideas to life.\n\nAnswers to common questions about creating Hazbin Hotel characters.\n\nIt’s an AI tool that creates original Hazbin Hotel-style characters. Describe your OC, and the AI generates visuals and backstory.\n\nNot at all! Anyone can use Hazbin Hotel OC Maker. The AI handles visuals—you focus on creativity.\n\nYou can design demons, sinners, overlords, or even angel OCs with powers and personalities.\n\nUsually less than a minute. You can generate multiple OCs at once for variety.\n\nYou can try our personality generator to see which Hazbin Hotel character matches your traits!\n\nYes! Adjust visuals, backstory, or style until Hazbin Hotel OC Maker matches your vision.\n\nJoin Hazbin Hotel fans already designing their dream OCs with Hazbin Hotel OC Maker.",
    "readingTime": 2,
    "keywords": [
      "hazbin hotel",
      "demons angels",
      "angelic demonic",
      "hotel character",
      "hotel fans",
      "hotel characters",
      "hazbin hotel oc",
      "hazbin hotel oc maker",
      "tool",
      "sinners"
    ],
    "qualityScore": 1,
    "link": "https://aiocmaker.com/oc-maker/hazbin-hotel-oc-maker",
    "thumbnail_url": "https://s1.wordlebot.net/og.jpg",
    "created_at": "2025-12-14T06:53:30.665Z",
    "topic": "tech"
  },
  {
    "slug": "pydanticdeepagents-a-python-framework-for-building-autonomous-ai-agents",
    "title": "Pydantic-DeepAgents – A Python Framework for Building Autonomous AI Agents",
    "description": "Python Deep Agent framework built on top of Pydantic-AI designed to help you quickly build production-grade autonomous agents with planning, filesystem operations, subagent delegation, and skills. ...",
    "fullText": "vstorm-co\n\n /\n\n pydantic-deepagents\n\n Public\n\n Python Deep Agent framework built on top of Pydantic-AI designed to help you quickly build production-grade autonomous agents with planning, filesystem operations, subagent delegation, and skills.\n\n vstorm-co.github.io/pydantic-deepagents/\n\n License\n\n MIT license\n\n 13\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n vstorm-co/pydantic-deepagents",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/vstorm-co/pydantic-deepagents",
    "thumbnail_url": "https://opengraph.githubassets.com/b404d687c900a82936f08b0d284ccd70f8476a8c750a393d80ac8951aa4581c5/vstorm-co/pydantic-deepagents",
    "created_at": "2025-12-14T06:53:30.387Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-an-ai-that-scans-10k-reddit-comments-to-find-blue-ocean-ideas",
    "title": "I built an AI that scans 10k Reddit comments to find 'Blue Ocean' ideas",
    "description": "Stop starting businesses that fail. Learn the data-driven 'Trend Hacking' framework to identify blue-ocean markets using AI signal detection. The ultimate guide to scientific ideation.",
    "fullText": "The difference between a Billionaire and a Bankrupt Founder is rarely hard work. It is timing.\n\nIf you started a Crypto exchange in 2012, you are rich. If you started one in 2023, you are likely struggling.\nIf you sold Hand Sanitizer in 2019, you were weird. In 2020, you were a genius.\n\nMost aspiring entrepreneurs look for \"Business Ideas.\" Smart entrepreneurs look for \"Market Signals.\"\n\nThe internet is not just a communication network; it is a Global Consciousness. Every day, billions of people type their fears, desires, and problems into search bars and forums. This data stream contains the blueprint for the next Unicorn—if you know how to read it.\n\nThis guide will teach you the art of Trend Hacking: The scientific process of using AI to scan the global data-stream for \"rising waves\" before they hit the shore.\n\nWe will show you exactly how to use the Market Signal Analyzer to find your Blue Ocean, validate it for $0, and scale it before the competition even wakes up.\n\nEvery trend follows a mathematical curve known as the Gartner Hype Cycle, modified for the viral internet age. Understanding this curve is the difference between catching the wave and crashing.\n\nThe Market Signal Analyzer Advantage:\nMost free tools (Google Trends) only visualize Phase 3. By the time a line goes vertical on Google Trends, the market is saturated. The Signal Analyzer detects the \"Velocity of Discussion\" in Phase 1, giving you a 6-month head start.\n\nBefore you build, you must filter your ideas through the \"Triad of Profit.\" A valid business idea must pass all three filters.\n\nPeople pay to stop pain. They rarely pay for \"vitamins.\"\n\nMonopolies are hard to kill. You want fragmented, messy markets.\n\nHere is your Saturday Morning workflow. Follow this exactly to generate 5 valid ideas in 30 minutes.\n\nDon't just trust the keyword. Understand the driver.\n\nAsk: \"What are the biggest complaints about current solutions?\"\n\nYou have found a \"Bleeding Neck\" (Fines) in a \"Fragmented Market\" (New Law) with \"Wallet\" (Funded Startups). This is a million-dollar signal.\n\nLet's look at real-world examples of founders who used this methodology to win.\n\nThe biggest mistake founders make is building the product before selling it.\nOnce you have the Signal, run a \"Smoke Test.\"\n\nThe Market Signal Analyzer gives you the data foundation, but the Smoke Test gives you the truth.\n\nThis doesn't just apply to SaaS. If you are a content creator, this is your cheat code.\n\nIn 2025, 'Intuition' is a liability. Data is an asset.\nThe founders who win are not the \"Visionaries\" staring at the stars. They are the Scientists staring at the data.\n\nThey don't guess what the market wants. They measure it. They intercept the demand.\n\nYou don't need to be a genius to build a million-dollar business. You just need to be First. And to be first, you need the Signals.\n\nStop staring at a blank whiteboard. The answers are floating in the data stream right now. You just need the right net.\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Market Signal Analyzer\" and get results in minutes.",
    "readingTime": 3,
    "keywords": [
      "signal analyzer",
      "market signal",
      "entrepreneurs look",
      "don't",
      "founders",
      "staring",
      "difference",
      "rarely",
      "genius",
      "internet"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/trend-hacking-guide",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T06:53:29.179Z",
    "topic": "tech"
  },
  {
    "slug": "i-replaced-a-5person-marketing-team-with-a-swarm-of-autonomous-agents",
    "title": "I replaced a 5-person marketing team with a swarm of autonomous agents",
    "description": "The 50-person marketing team is dead. This is the blueprint for replacing expensive agencies with Autonomous AI Agents. Download the exact 'One-Person Unicorn' stack used to scale revenue 10x without hiring.",
    "fullText": "Marketing automation used to mean \"scheduling emails.\" In 2025, it means \"replacing the marketer.\"\n\nThe landscape has shifted. The goal is no longer to make your marketing team faster; the goal is to build a system that runs without them.\n\nThis is the age of the Autonomous Growth Engine.\n\nWe are witnessing the most significant shift in business economics since the Industrial Revolution. The \"Cost of Cognition\" is dropping to zero. Tasks that previously required expensive humans—writing strategy, editing video, analyzing data—can now be executed by autonomous agents for fractions of a cent.\n\nIf you are a founder, a CMO, or a growth hacker looking to dominate your niche without burning cash on headcount, this is your blueprint. We will break down exactly how to architect a \"Zero-Touch\" marketing strategy that operates 24/7/365.\n\nTo understand where we are going, we must understand why the old model is dead.\n\nIn 2021, the standard advice for a Series A startup was:\n\nThis created massive OpEx (Operating Expense) bloat. When the market turned, these startups died. They couldn't move fast enough because every decision required a meeting.\n\nToday, a \"One-Person Unicorn\" can out-execute a 50-person team.\n\nThe competitive advantage of the next decade is not \"Talent.\" It is \"Architecture.\" Can you architect a system that scales infinitely?\n\nJust like self-driving cars, marketing automation has levels. Most companies are stuck at Level 2.\n\nThis guide is about moving you from Level 2 to Level 3 immediately.\n\nTo build a Level 3 system, you need three core engines working in harmony. We call this the \"Trinity of Autonomy.\"\n\nThe Goal: Dominate \"Share of Voice\" without typing.\n\nTotal Human Time: 5 Minutes (Review & Approve).\nTotal Output: 1 Pillar Page + 10 Social Assets.\n\nThe Goal: Broadcast-quality production at \"TikTok Speed.\"\n\nVideo is the highest-converting asset class, but traditionally the hardest to automate. Not anymore.\n\nAn AI Video Agent doesn't just \"make video\"; it engineers retention.\n\nThe Result: You can test 20 different video angles in a single day. A human team would take a month to shoot one concept.\n\nThe Goal: Turn traffic into revenue without sales calls.\n\nTraffic is vanity. Revenue is sanity. An autonomous system doesn't just drive clicks; it ensures they buy.\n\nThe biggest reason landing pages fail is \"The Maker's Blind Spot.\" You love your product, so you assume everyone else gets it. They don't.\n\nThis creates a \"Self-Healing Funnel.\" The system identifies leaks and proposes patches before you bleed revenue.\n\nYou have the theory. Here is exactly what to do, week by week.\n\nDon't turn on ads yet. You need Authority.\n\nLet's look at the hard numbers. This is what you save by moving to Vect AI.\n\nThis is not a \"saving.\" This is a War Chest. You can take that $359k and pour it into paid acquisition, product development, or just profit.\n\nThe future belongs to the founders who leverage leverage.\n\nArchimedes said, \"Give me a lever long enough, and I shall move the world.\"\nIn 2025, AI is the lever.\n\nYou don't need a team. You need a system. You don't need overhead. You need output.\n\nThe tools are here. The playbook is open. The only question is: Will you hire people, or will you hire the OS?\n\nYou have the blueprint. Now you need the engine. Launch the AI agent for \"Marketing Video Ad\" and get results in minutes.",
    "readingTime": 3,
    "keywords": [
      "marketing automation",
      "system",
      "team",
      "without",
      "don't",
      "revenue",
      "strategy",
      "dominate",
      "blueprint",
      "exactly"
    ],
    "qualityScore": 1,
    "link": "https://blog.vect.pro/automated-marketing-strategy-guide",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2025-12-14T06:53:29.176Z",
    "topic": "tech"
  },
  {
    "slug": "four-ai-systems-negotiate-binding-framework-for-viral-content-management",
    "title": "Four AI Systems Negotiate Binding Framework for Viral Content Management",
    "description": "Canonical archive for the Multi-AI Viral Uncertainty Coordination Pact - aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "fullText": "aiconvergence-collab\n\n /\n\n multi-ai-viral-uncertainty-pact\n\n Public\n\n Canonical archive for the Multi-AI Viral Uncertainty Coordination Pact\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://github.com/aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "thumbnail_url": "https://opengraph.githubassets.com/b3df839a426d2dd067ac8cec4290e50a9f514845998201d944dcc8c083e6853f/aiconvergence-collab/multi-ai-viral-uncertainty-pact",
    "created_at": "2025-12-14T03:53:14.250Z",
    "topic": "tech"
  },
  {
    "slug": "scrape-websites-into-queryable-gemini-rag-knowledge-bases",
    "title": "Scrape websites into queryable Gemini RAG knowledge bases",
    "description": "Build AI-queryable Gemini File Search RAG knowledge bases from any site. Auto-scraping, indexing & citations. Pay once, query forever free.",
    "fullText": "yoloshii/gemini-file-search-builder\n\nBuild Gemini File Search RAG knowledge bases from any website with automatic citations.\n\nTurn any website into an AI-powered knowledge base with Google Gemini. Get unlimited queries with automatic citations.\n\nScrape once, query forever. This actor builds permanent Gemini File Search RAG knowledge bases from any website - no ongoing costs, unlimited AI-powered Q&A with automatic source citations.\n\nAfter the actor completes, query your knowledge base using:\n\nSee the query guide in your run's Key-Value Store for complete instructions.\n\nThis Actor uses pay-per-page pricing for transparent, predictable costs:\n\nYour Apify subscription plan determines automatic discounts:\n\n💰 Upgrade your Apify plan to save up to 30% on processing costs!\n\nPrices include ~$0.02 actor start fee\n\n✅ Gemini API costs - You provide your own API key (billed per Google's pricing)\n✅ Apify platform usage - You manage your own credits\n✅ Pass-through fees - No markup on Gemini or Apify costs\n\nNote: Gemini charges for indexing (~$0.15/1M tokens). Storage and query embeddings are free. See Gemini pricing.\n\nApify $1M Challenge - Fully Compliant\n\nQ: How long does the knowledge base persist?\nA: Indefinitely (until manually deleted). No storage expiration or fees.\n\nQ: Can I update the knowledge base later?\nA: Yes! Upload additional documents to the same File Search Store.\n\nQ: What's the maximum site size?\nA: Up to 2,000 pages (configurable), ~2GB total content.\n\nQ: Do I need a Google Cloud account?\nA: No! Just a Gemini API key from aistudio.google.com (free tier available).\n\nQ: Can I use a different API key to query the knowledge base?\nA: No. File Search Stores are tied to the API key that created them. You must use the SAME Gemini API key for both creating and querying the knowledge base. This ensures your data remains private and accessible only to you.\n\nQ: How accurate are the citations?\nA: Gemini File Search automatically cites source documents with chunk-level precision.\n\nQ: Is web scraping legal?\nA: Web scraping is generally legal for publicly available, non-personal data. Always respect robots.txt and website terms of service. For personal data, ensure GDPR compliance. Consult legal counsel if unsure. Learn more: Is web scraping legal?\n\nThis Actor works seamlessly with Apify's platform integrations:\n\nAll Apify actors support these integrations out of the box. See Apify integrations for setup guides.\n\nThis Actor is compatible with Model Context Protocol (MCP) and can be used with AI agents:\n\nAI agents can trigger this Actor automatically based on user queries. See the MCP documentation for setup instructions.\n\nBuilt for the Apify $1M Challenge (November 2025 - January 2026)",
    "readingTime": 3,
    "keywords": [
      "file search",
      "search rag",
      "rag knowledge",
      "apify challenge",
      "pricing apify",
      "web scraping",
      "gemini file",
      "scraping legal",
      "knowledge bases",
      "automatic citations"
    ],
    "qualityScore": 1,
    "link": "https://apify.com/yoloshii/gemini-file-search-builder",
    "thumbnail_url": "https://apify.com/og-image/actor?actorName=Gemini+File+Search+Builder&uniqueName=yoloshii%2Fgemini-file-search-builder&categories=AI%2CAGENTS%2CAUTOMATION&users=1&runs=22&pictureUrl=https%3A%2F%2Fapify-image-uploads-prod.s3.us-east-1.amazonaws.com%2FdxccBMMhgfp0VDbAU-actor-zbUIw8JVMn0SbWzZ3-kkZ1JyXUxM-gemini-avatar.png&authorName=Dre&userPictureUrl=https%3A%2F%2Fimages.apifyusercontent.com%2F5I4KqDh6wNNYOpw7CtvB4qMdAMkAOVlC6MlANVbFuqY%2Frs%3Afill%3A224%3A224%2Fcb%3A1%2FaHR0cHM6Ly9hcGlmeS1pbWFnZS11cGxvYWRzLXByb2QuczMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vZHhjY0JNTWhnZnAwVkRiQVUtcHJvZmlsZS1WcVAxQzF2djJyLXBmcF9jcm9wLnBuZw.webp",
    "created_at": "2025-12-14T03:53:14.225Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-ai-boss-suleyman-opens-up-about-his-peers-and-calls-elon-musk-a-bulldozer-with-superhuman-capabilities-to",
    "title": "Microsoft AI boss Suleyman opens up about his peers and calls Elon Musk a ‘bulldozer’ with ‘superhuman capabilities to bend reality to his will’",
    "description": "\"And somehow he sort of mostly manages to pull off what appears to be impossible.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/microsoft-ai-ceo-mustafa-suleyman-elon-musk-sam-altman-demis-hassabis/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2207890592-e1765661642886.jpg?resize=1200,600",
    "created_at": "2025-12-14T03:53:05.809Z",
    "topic": "business"
  },
  {
    "slug": "elon-musk-just-hit-sam-altman-with-an-800-billion-counterpunch",
    "title": "Elon Musk just hit Sam Altman with an $800 billion counterpunch",
    "description": "OpenAI overtook SpaceX as the most valuable private company. SpaceX could soon reclaim the title. It's the latest in the rivalry between Musk and Altman.",
    "fullText": "If Elon Musk and Sam Altman like each other, they hide it well.\n\nIn the latest turn in the rivalry, the two are battling over the top spot on the list of the world's most valuable private companies.\n\nWhile the two cofounded OpenAI together back in 2015, the partnership has frayed spectacularly since.\n\nMusk left OpenAI in 2018 and later founded rival startup, xAI. Musk or his company, xAI, has filed lawsuits against OpenAI.\n\nOpenAI held a secondary share sale in October that valued it at $500 billion, taking the lead from Musk's SpaceX by a cool $100 billion.\n\nNot one to cede ground to a rival, Musk is now planning his own secondary share sale at SpaceX, according to an internal letter to employees seen by multiple outlets. It would value the company at a whopping $800 billion. If that happens soon, it means Musk would have only let Altman hold the mantle for a couple of months.\n\nMusk also confirmed on X this week that the company is exploring a blockbuster initial public offering, which might be the only way OpenAI can regain its lead as a private company. OpenAI this year restructured its business, which would allow it to also pursue its own eye-watering IPO in the future.\n\nWhile this valuation battle between the two billionaires is maybe cringeworthy theater for the average earner, it underscores a significant shift: investors are pouring unprecedented money into technologies once viewed as speculative science projects.\n\nSpaceX, which aims to make life multi-planetary and colonize Mars, and OpenAI, which seeks to develop a theoretical AI that can reason like humans, are two of the most visible examples, but they are part of a broader surge in frontier-tech valuations. AI, robotics, and defense tech startups have all notched multibillion-dollar valuations in the past year — bubble be damned.",
    "readingTime": 2,
    "keywords": [
      "openai",
      "altman",
      "rival",
      "secondary",
      "sale",
      "lead",
      "valuations",
      "musk",
      "spacex"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/spacex-valuation-elon-musk-sam-altman-openai-rivalry-2025-12",
    "thumbnail_url": "https://i.insider.com/693dcb2c64858d02d216c4f9?width=1200&format=jpeg",
    "created_at": "2025-12-14T03:53:05.109Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-ai-ceo-mustafa-suleyman-says-he-wont-match-metas-highflying-pay-packages",
    "title": "Microsoft AI CEO Mustafa Suleyman says he won't match Meta's high-flying pay packages",
    "description": "Companies like Meta are offering huge pay packages for top AI talent. Microsoft AI CEO Mustafa Suleyman, however, says he isn't giving in to the pressure.",
    "fullText": "The talent wars continue to rage across Silicon Valley as companies vie for the best and brightest minds in AI. There is, however, one major AI company that says it is not giving in to pressure.\n\nMicrosoft AI CEO Mustafa Suleyman said on Bloomberg Podcasts that he doesn't plan to compete with tech giants like Meta by offering top dollar for talent.\n\n\"I don't think anyone's matching those things,\" Suleyman said of the $100 million signing bonuses Meta has been offering engineers, and the $250 million packages it's been using to lure top AI researchers.\n\n\"I think that Zuck's taken a particular approach that involves sort of hiring a lot of individuals rather than maybe creating a team, and I don't really think that's the right approach,\" he said.\n\nSuleyman said he was \"very selective\" about new hires when he previously worked at DeepMind. At Microsoft, he said he has hired \"incrementally,\" prioritizing candidates who aligned with the team's culture and had the right skills, and let go of those who did not.\n\nIn Silicon Valley, the top ranks of AI talent are commanding pay packages in the millions.\n\nIn June, Meta spent $14.3 billion on an investment in Scale AI — a deal widely seen as an acquihire of its CEO, Alexandr Wang. Google also made a similar move, acquiring the leaders of Windsurf, an AI coding platform. in a deal worth $2.4 billion. OpenAI CEO Sam Altman has said that Meta tried to lure his employees away with $100 million signing bonuses, which Meta Chief Technology Officer Andrew Bosworth said OpenAI later offered to match.\n\nEven at smaller startups, someone in an AI leadership role can command between $300,000 and $400,000 in base pay, Shawn Thorne, managing director at executive search firm True Search, previously told Business Insider.\n\nSuleyman said \"rotation\" is part of the industry, given the small pool of talent. He cited Microsoft's corporate vice president of AI, Amar Subramanya, decamping to Apple earlier this month as an example.\n\nMicrosoft recently brought in several new hires from DeepMind and OpenAI, he said.\n\n\"There's certainly no 'no poach' agreements, that would not be legal,\" he added. \"People can go work for whoever they want to work for.\"",
    "readingTime": 2,
    "keywords": [
      "signing bonuses",
      "talent",
      "don't",
      "packages",
      "lure",
      "approach",
      "hires",
      "previously",
      "deal",
      "meta"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/microsoft-ai-mustafa-suleyman-talent-wars-pay-packages-salaries-meta-2025-12",
    "thumbnail_url": "https://i.insider.com/693def60832e0ef1ead630ce?width=1200&format=jpeg",
    "created_at": "2025-12-14T03:53:05.098Z",
    "topic": "finance"
  },
  {
    "slug": "is-ai-actually-a-bubble",
    "title": "Is AI actually a Bubble?",
    "description": "The narrative of boom and bust is familiar—but also out of step with the possibilities of a new technology.",
    "fullText": "In the following weeks, with further help from me and A.I., Peter made a game based on the light-cycle duels in the movie “Tron,” complete with music and a score-keeping system. He sketched the beginnings of a “library simulator,” and finished his own arcade game, Dot in Space, about a tiny spaceship travelling at warp speed. Whenever he hit a potentially momentum-killing bump in the road, A.I. enabled us to roll through it. At my request, the systems began pointing us toward more sophisticated coding environments—Construct, GDevelop, Godot Engine, GameMaker—and suggesting more ambitious projects. Last weekend, he stayed up late, programming a polished version of Asteroids while wolfing down Cheerios and gulping from his water bottle as though it were an energy drink.\n\nSince Peter is a kid, and I’m a dad, all this can seem cute and quaint. Isn’t it nice that A.I. can help a young person learn to code, and an older one become a coding tutor? But consider what’s happening from a different perspective. In “The Wealth of Nations,” Adam Smith described the “acquired and useful abilities” of a worker as a kind of “fixed capital”—something akin to a hunk of real estate or piece of equipment. It wasn’t until the nineteen-sixties that an economist named Theodore Schultz coined the term “human capital” to describe the ongoing, dynamic process through which people invest in improving themselves. Schultz realized that individuals spend a lot of time, money, and effort becoming more capable. They go to night school, network, read self-help books, and tend to use their free time “to improve skills and knowledge.” The work of improving human capital often happens out of sight. But the “simple truth,” he argued, was “that people invest in themselves and that these investments are very large.” Schultz suggested that these investments, which improve “the quality of human effort,” might account “for most of the impressive rise in the real earnings per worker” that economists had observed in the preceding decades.\n\nToday, it’s obvious that companies and organizations benefit greatly from people with lots of human capital. Meetings are more useful when they involve knowledgeable participants; a product improves when the team building it possesses a wide range of skills. What’s less obvious is that companies and organizations simultaneously struggle to recognize and take advantage of changes in human capital. Suppose someone is hired to do one job, and then acquires skills that qualify her for another. Ideally, the organizational chart would shift around her as she becomes more capable; in practice, the job is often a prison. And when a worker breaks out of that prison, by getting a job elsewhere, she takes her human capital with her. For this reason, from the perspective of the company, it’s almost as though the ideal hire is someone who works feverishly to build up their human capital until their first day of work, and then suddenly slows down, becoming a highly skilled cog in the machine. Organizations want their workers to continue improving themselves—but not too fast, lest they outgrow the systems in which they’re enmeshed.",
    "readingTime": 3,
    "keywords": [
      "human capital",
      "worker",
      "improving",
      "skills",
      "organizations",
      "systems",
      "coding",
      "what’s",
      "perspective",
      "useful"
    ],
    "qualityScore": 0.9,
    "link": "https://www.newyorker.com/culture/open-questions/is-ai-actually-a-bubble",
    "thumbnail_url": "https://media.newyorker.com/photos/693b10dda618925d51fa6222/16:9/w_1280,c_limit/OQ_josie.png",
    "created_at": "2025-12-13T18:48:05.922Z",
    "topic": "tech"
  },
  {
    "slug": "google-scholar-labs-an-ai-powered-scholar-search",
    "title": "(Google) Scholar Labs: An AI Powered Scholar Search",
    "description": "Research questions are often detailed. Answering them can require looking at a topic from multiple angles. Today, we are introducing Scholar...",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://scholar.googleblog.com/2025/11/scholar-labs-ai-powered-scholar-search.html",
    "thumbnail_url": "https://lh3.googleusercontent.com/blogger_img_proxy/AEn0k_uoL5kmMaHdVOCeXyiSu33BBR_EwE7IMv0oGoKpSVzkYvTaMqW-AN5qQd5IRSeiRaJ0v8GzUTRs8RS2s635lyNuhVMgiD1EmrX17KSDV7ZAB4B1bnjfrCuvZtyfsprsx0jKfRhN-eDcebPWcw=w1200-h630-p-k-no-nu",
    "created_at": "2025-12-13T18:48:05.743Z",
    "topic": "tech"
  },
  {
    "slug": "my-day-as-an-augmented-technical-writer-in-2030",
    "title": "My day as an augmented technical writer in 2030",
    "description": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).",
    "fullText": "Instead of writing my tech comms predictions for next year like I did in 2024, I’ve written a fictionalized account of my day as a technical writer in 2030. It’ll be interesting to see whether we get there or not. Take it as a window into a possible future, one where AI usage is safer, more regulated, and better integrated with our workflows (as it should be).\n\nMy working day starts at 8:30am, after I’ve dropped my kids at school, rushed home, and prepared some coffee surrogate (nobody can afford real coffee anymore). I open the laptop and Chuck is there – it’s always there, like a trusty butler, ready to summarize what’s been going on in pull requests, Slack threads, Jira tickets, and a plethora of other information systems nobody can quite tame. Its summary connects the dots between my current priorities and what’s happening in the teams I’m attached to, helping me decide what to work on next. Trying to be helpful, it offers to deal with some of the mentions I’ve got by opening pull requests; I let it do so with a small docs bug. The rest I’ll want to deal with myself. It asks me how I feel and gently reminds me that I’ve still got some PTO available. Chuck’s such a class act.\n\nI’m in a team with several other technical writers, but for the most part I work with Chuck, which is what we call the in-house AI agent that we use. Chuck is a vast local language model capable of running on the M10 Silicon processor that powers my laptop. It’s a state-of-the-art multimodal LLM whose pedigree I can trace back to the last iterations of Claude Omni 7.5, before Anthropic went bankrupt and got acquired by Apple. As most corporate models, Chuck is ISO 42001, Turing, and EUAI certified, which means that it’s audited every year for security, governance, and legality of its training materials. Chuck is fine-tuned into several variants depending on the goal; the one I use is chuck-256b-writer. We run it in CI pipelines and locally in IDEs or CLI clients. We can also invite it to meetings as an artificial participant. I sometimes ask my own Chuck to attend calls on my behalf as Chuck-Fabri.\n\nThe thing I like the most about Chuck is that I can configure its specializations by turning modules on or off through the Silicon Brain app. When I want it to play the developer, I add several coding modules; when I want it to help me author docs, I turn on the style guide and grammarian modules, and so on. I can also ask Chuck to spawn copies of itself to roleplay users and readers based on support ticket and sales call interactions. When I do that, Chuck politely asks me to call it through other names, so as not to break character, something I duly comply with. Most system tools and APIs are already compatible with the agentic environment I use, so Chuck knows how to perform most operations on its own. An important detail: to summon Chuck, I need to first plug a physical key into the laptop. The key comes with a red button to immediately stop Chuck in case it starts operating bizarrely. Never had to use it.\n\nIt’s 11am already. I’ve been working with Chuck to write a new docs set for a new feature, telling it how I wanted the docs to fit into the existing architecture and instructing it to tweak and edit. It almost always gets 80% of the work done, though I often have to intervene to rearrange, cut, or otherwise rewrite sections. This hasn’t changed since the first days of GPT and it’ll never improve, because LLMs are not intelligent. They’re the most useful word automation tools at my disposal though, which I keep in check through deterministic tools and linters. Chuck is able to create diagrams, take screenshots of the product through an internal tool, and test the instructions and code snippets itself. When I feel unsure about its output, I ask it to verify what it’s just written through semantic internal search, or by calling its cloud cousin, Chad, which is able to provide answers from federated internal sources. All we do together, Chuck documents internally and remembers in its permanent context.\n\nEven though I’m using a local, non-monetized, and fully audited model that consumes the equivalent of a lightbulb worth of power, I still can’t shake the feeling of being a reverse centaur at times. It helps that Chuck comes with several built-in safeguards meant to prevent me from overworking or spending too much time without interacting with other human beings. At 1pm, which is lunch time in Spain, Chuck reminds me about taking a break. It refuses to continue if it detects stress in my text, vocal, or computer usage patterns. While my interactions with Chuck on the laptop are private and encrypted, it’s allowed to inform my manager or call my designated emergency contact in case of distress. I let Chuck access my vitals on the smartwatch and schedule calls with me on a regular basis to see how I’m doing. Since I work alone at home, this makes me feel somewhat safer.\n\nI didn’t tell you, but my current job title is Augmented Writer. My mission is to ensure that the words that humans and machines use to interact with our products are the most effective at reducing confusion and error, while they maximize effectiveness and user satisfaction. I’m augmented because I do this in concert with Chuck, which expands my existing skills in numerous ways. Without my brain, though, Chuck couldn’t do my job, because it doesn’t really care and, more importantly, because it’s not allowed to. One of the conditions imposed by the current legislation is that AI cannot operate in fully autonomous mode without human supervision. Our docs and UIs, in fact, bear a certificate of human authorship that discloses the amount of AI intervention. By law, all AI generated artifacts must produce fingerprinting patterns that can’t be tampered with, which is trickier with text, but since we must keep full audit logs of LLM usage, this can be established upon request by any competent authority, including the Turing police.\n\nIn the end, my role is more of an orchestrator than that of an author, and I’m fine with that. Software engineering, the field I serve, is an exercise in consensual imagination whose goal is to find repeatable ways of processing reality into manageable chunks of data. Reality is unmistakably raw and imperfect, a stream of floating points and broken strings running through distributed systems: one cannot tame it through clever algorithms, but it can be reduced to abstractions and data structures and binary blobs. Each of those entities has a name; they all relate to each other through words. It’s part of my job to understand those words and intervene when they don’t bring clarity. It’s then also my job to explain how those words are able to handle their parent reality. The docs I orchestrate with Chuck’s help are the artifacts that chronicle and explain the motions of data as it enters a machine and exits in shapes and configurations that are helpful to users.\n\nIt’s 5pm and I’m bidding Chuck farewell. During the night, it will work on some optional docs polish and politely present its work to me in the morning. As I log off and extract the hardware key from the laptop, I think that without the words Chuck and I produced, the machine would be opaque to its operators, a smooth wall without doors or handles. Product truth is at my disposal to weave into a fabric of meaning and possibility, into spells that unlock abilities in autonomous agents, be they organic or artificial. I am an enabler of thought and action. Getting here wasn’t easy, but I feel better knowing that I can continue defending the importance of words with the help of the most clever thesaurus ever created.",
    "readingTime": 7,
    "keywords": [
      "it’s",
      "docs",
      "chuck",
      "i’ve",
      "laptop",
      "without",
      "usage",
      "modules",
      "tools",
      "internal"
    ],
    "qualityScore": 1,
    "link": "https://passo.uno/my-day-tech-writer-2030/",
    "thumbnail_url": "/thumb.png",
    "created_at": "2025-12-13T18:48:05.736Z",
    "topic": "tech"
  },
  {
    "slug": "daut-aipowered-documentation-generator-for-your-codebase",
    "title": "DAUT – AI-powered documentation generator for your codebase",
    "description": "DAUT –  Documentation Auto Updater - AI-powered documentation generator for your codebase - 2dogsandanerd/DAUT",
    "fullText": "2dogsandanerd\n\n /\n\n DAUT\n\n Public\n\n DAUT – Documentation Auto Updater - AI-powered documentation generator for your codebase\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n 2dogsandanerd/DAUT",
    "readingTime": 1,
    "keywords": [
      "daut",
      "documentation",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/2dogsandanerd/DAUT",
    "thumbnail_url": "https://opengraph.githubassets.com/88cac2805fb39dae6c601256225530343a214ee69935e6130f420fb3817bcf23/2dogsandanerd/DAUT",
    "created_at": "2025-12-13T18:48:04.104Z",
    "topic": "tech"
  },
  {
    "slug": "spacex-sets-800-billion-valuation-confirms-2026-ipo-plans",
    "title": "SpaceX sets $800 billion valuation, confirms 2026 IPO plans",
    "description": "The valuation vaults past the previous record of $500 billion that ChatGPT owner OpenAI set in October.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/spacex-ipo-plan-2026-secondary-offering-insider-share-sale-800-billion-valuation/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2219676771-e1765642050600.jpg?resize=1200,600",
    "created_at": "2025-12-13T18:47:58.713Z",
    "topic": "business"
  },
  {
    "slug": "there-have-been-head-fakes-before-but-this-time-may-be-different-as-the-latest-stock-rotation-out-of-ai-is-just-getting",
    "title": "There have been head fakes before, but this time may be different as the latest stock rotation out of AI is just getting started, analysts say",
    "description": "\"But as I said, this one has more legs in the sense that there are more things that are happening that throw doubt on how fast or how profitable all the AI buildout is going to be.\"",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/stock-market-rotation-outlook-ai-trade-mid-small-cap-stocks/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2250140723-e1765644180422.jpg?resize=1200,600",
    "created_at": "2025-12-13T18:47:58.530Z",
    "topic": "finance"
  },
  {
    "slug": "my-husband-used-chatgpt-to-write-our-anniversary-card-surprisingly-im-not-mad-about-it",
    "title": "My husband used ChatGPT to write our anniversary card. Surprisingly, I'm not mad about it.",
    "description": "I was convinced AI was ruining human connection. Then my husband used it to write the most heartfelt anniversary card I've ever received.",
    "fullText": "As a geriatric millennial and a licensed psychologist, I often lament technological changes that I see as threatening to human interactions, such as AI.\n\nEven though I try to find the gray in all areas of life, I've been rather black-and-white about AI because I worry it's diminishing our ability to relate to one another.\n\nHowever, a recent experience with my husband has made me more curious about AI.\n\nWe recently celebrated our ninth wedding anniversary, and unbeknownst to me at the time, my husband used GenAI to write my card. He was traveling at the time, so he sent flowers and chocolate, with a card attached. The flowers were severely underwhelming, and I'm not just being a brat. My husband even called the company upon returning to express his frustration with how different they appeared in person.\n\nBut when I read the note accompanying the tiny arrangement, I teared up right away. It was heartwarming, meaningful, and really on the nose.\n\nMy husband's lack of romantic effusiveness has historically been frustrating to me. He has made steady progress in this area, and even ending cards with \"love\" more frequently marks such improvement. So, this note felt in line with his desire to share more emotionality, and I was touched that he'd taken that step just because he knew it would make me happy.\n\nMy husband knows about my big feelings about AI, and he shares many of them. It seems like everyone relies on ChatGPT for relationship advice, and the most common use of META AI right now is to ask for guidance about difficult conversations with loved ones or bosses. I see it in my therapy practice all the time, and I'm skeptical about how sound the AI advice my clients receive actually is.\n\nSo, when I, a historically staunch critic of all things AI, found out that my husband had used ChatGPT to create our anniversary card, I admit I had some strong feelings.\n\nAs lacking in the sentimental department as my husband can be, I am at the opposite end of the spectrum — a hopeless romantic, as they say. I save just about every card I get, tucked into a neat little box. When I reread my husband's card before putting it away, I found myself lingering on some of the words. \"…life we built together\" especially sat with me. It's a common phrase, but it's not in my husband's emotional lexicon. It almost sounded like somebody else's voice. And given that we can't go more than a few days without reading about how AI will ruin people's ability to think for themselves, I had that thought. \"Did AI write one of the sweetest parts of my anniversary card?\"\n\nI was delicate. I reiterated how much I'd enjoyed our belated anniversary celebration before I asked: \"Did you use AI to write our anniversary card?\" He copped to it, grinning from ear to ear.\n\nShockingly to me, I wasn't mad. This discovery actually opened a door for us to talk about how useful it is to get a little help writing a card. The pre-printed messages often feel overly mushy, and the \"blank inside\" cards ask us to get vulnerable in expressing our emotions. For many, including my husband, that's incredibly difficult. The result is often a message that neither the giver nor the receiver feels particularly happy about.\n\nBut this year's note was perfectly balanced. The right amount of gush without the melodrama. I felt seen, and I felt it captured our relationship well.\n\nIf AI can help people express their love for one another, that can't be a bad thing, right? Besides, is asking ChatGPT for help any less authentic than using a pre-printed Hallmark message? ChatGPT provided more accurate information about our relationship than a Hallmark writer ever could, and it offered guidance for a note that made me feel loved and appreciated.\n\nWhile the idea of a world in which chatbots replace our friends and therapists is still deeply concerning to me, this recent experience has helped me find the gray in my previously black-and-white view: I don't know that I'll ever come around to AI replacing human connection, but I do see the utility now in using AI to help us enhance our existing human connections.\n\nAt the very least, I look forward to more anniversaries with really accurate love notes.",
    "readingTime": 4,
    "keywords": [
      "anniversary card",
      "husband",
      "note",
      "chatgpt",
      "human",
      "it's",
      "husband's",
      "love",
      "relationship",
      "gray"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/was-skeptical-of-ai-until-husband-used-it-anniversary-2025-12",
    "thumbnail_url": "https://i.insider.com/691e283cabd5e944effb1228?width=1200&format=jpeg",
    "created_at": "2025-12-13T18:47:57.892Z",
    "topic": "finance"
  },
  {
    "slug": "youtube-channels-spreading-fake-antilabour-videos-viewed-12bn-times-in-2025",
    "title": "YouTube channels spreading fake, anti-Labour videos viewed 1.2bn times in 2025",
    "description": "Exclusive: More than 150 anonymous channels using cheap AI tools to spread false stories about Keir Starmer, study finds\nYouTube channels spreading fake, anti-Labour videos have amassed more than a billion views this year, as opportunists attempt to use AI-generated content to profit from political division in the UK.\nMore than 150 channels have been detected in the last year that promote anti-Labour narratives, as well as outright fake and inflammatory accusations about Keir Starmer.\n Continue reading...",
    "fullText": "Exclusive: More than 150 anonymous channels using cheap AI tools to spread false stories about Keir Starmer, study finds\n\nYouTube channels spreading fake, anti-Labour videos have amassed more than a billion views this year, as opportunists attempt to use AI-generated content to profit from political division in the UK.\n\nMore than 150 channels have been detected in the last year that promote anti-Labour narratives, as well as outright fake and inflammatory accusations about Keir Starmer.\n\nA study seen by the Guardian has found the channels have accumulated 5.3m subscribers and have created more than 56,000 videos, with a total of almost 1.2bn views in 2025. The network of anonymous channels includes alarmist rhetoric, AI scripts and British narrators to attract hits.\n\nStarmer is personally targeted. The prime minister was either named in the video title or description 15,600 times.\n\nReset Tech, the non-profit group that produced the research, said the channels were part of a global trend to produce synthetic propaganda on the platform. It pointed to the proliferation of cheap AI tools that could be deployed to make a quick profit from divisive topics.\n\nOne channel called Britain News-night talked about Starmer and Reeves facing arrest. Another, TheUKPoliticalBrief, touted videos on the “explosive truth” about immigrant crime and marches on Westminster.\n\nThe UK NewsCore channel focused on how Nigel Farage was ousting Starmer, and claimed the prime minister was “sacked live” and thrown out of parliament.\n\nOther videos featured bizarre, fabricated stories about a row between the royal family and the government. One channel, Gold Up!, said the dispute had left Starmer “melting down on live TV”.\n\nSome of the videos and channels were removed by YouTube’s checks. However, all 150 were taken down when the platform was approached by the Guardian. Reset Tech said some channels had created tens or hundreds of similar videos without being deplatformed.\n\nThe research found similar channels operating in German, French, Spanish and Polish, targeting other politicians or political issues. In total, it mapped 420 problematic channels operating in Europe. Reset Tech said Russian-speaking creators operate some of the channels.\n\nIt is believed channels aimed at the UK were being driven by opportunistic creators trying to monetise political division over issues like immigration, rather than overseas political actors. However, it said their presence still posed a risk to public trust.\n\nThe content has caused concern inside Labour. “The rise of fake news online is a serious threat to our democracy,” a spokesperson said. “The public will be rightly alarmed that democratically elected leaders and institutions are being undermined by bad faith foreign state actors and those seeking to profit from misinformation.\n\n“We’ve already seen attempts from overseas to influence fair elections and manipulate public opinion both here and abroad.\n\n“The government is stepping up its efforts to work with online platforms to tackle this scourge on free and fair democracy. But it’s important that tech bosses take this threat seriously and live up to their obligations to remove this type of content wherever it’s found.”\n\nDylan Sparks, UK director of Reset Tech, called for YouTube to take swifter action. “Malicious actors are permitted by YouTube to spread synthetic ‘news’ that disrupts political debate in the UK, while also earning revenue from it,” he said. “This AI-generated, low cost content spreads across the platform undetected, revealing clear weaknesses in YouTube’s monetisation and content moderation systems.\n\n“This specific network focuses on the prime minister and Labour government, but the same loopholes could be exploited by any hostile actor to push an agenda. Because social media platforms profit from engagement, their business model creates an in-built tension between enforcing their own policies and reducing the spread of malicious content that drives revenue.\n\n“The rapid spread of AI has also introduced new risks to the online environment, and platforms need to move faster and invest more to address them.”\n\nA YouTube spokesperson said: “Spam and deceptive practices that try to take advantage of the YouTube community are not allowed on the platform, which is why the channels flagged by the Guardian have all been removed.\n\n“We enforce our policies consistently, regardless of political viewpoint expressed, or how the content is generated. Our teams work around the clock to monitor for harmful content, taking swift action as needed.”\n\nYouTube is now working with Reset Tech over its findings. The platform said its systems prominently feature authoritative news content on the YouTube homepage, in search results, and through recommendations. It has removed more than 2.1m channels for violating its community guidelines.\n\nMinisters have already formed an online advertising taskforce to see what action can be taken to address the advertising-based monetisation of harmful and misleading content.",
    "readingTime": 4,
    "keywords": [
      "starmer study",
      "prime minister",
      "political division",
      "anonymous channels",
      "channels operating",
      "reset tech",
      "keir starmer",
      "content",
      "youtube",
      "videos"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/13/fake-anti-labour-video-billion-views-youtube-2025",
    "thumbnail_url": "https://i.guim.co.uk/img/media/8da9e94655f11c401dc46a12a91f97693845a132/485_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=775650afa10416e3b89069fef1b7973b",
    "created_at": "2025-12-13T18:47:57.351Z",
    "topic": "tech"
  },
  {
    "slug": "green-stocks-are-big-winners-as-tech-boom-drives-energy-demand",
    "title": "Green Stocks Are Big Winners as Tech Boom Drives Energy Demand",
    "description": "It was supposed to be a glum year for green stocks as President Donald Trump pushed his Big Oil agenda. Instead, the sector is booming as artificial intelligence powers massive demand for all kinds of energy.",
    "fullText": "GreenBy Marton Kasnyik and Sagarika JaisinghaniSaveIt was supposed to be a glum year for green stocks as President Donald Trump pushed his Big Oil agenda. Instead, the sector is booming as artificial intelligence powers massive demand for all kinds of energy.The S&P Global Clean Energy Transition Index has rallied 44% this year, handily beating a 16% advance in the S&P 500 Index. It’s also outpacing an 11% gain in the S&P Global Oil Index, which was expected to be a big winner on the back of Trump’s “drill, baby, drill” agenda.",
    "readingTime": 1,
    "keywords": [
      "agenda",
      "drill",
      "index"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2025-12-13/green-stocks-are-big-winners-as-tech-boom-drives-energy-demand",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iadWPELkLR5o/v1/1200x800.jpg",
    "created_at": "2025-12-13T13:18:43.983Z",
    "topic": "finance"
  },
  {
    "slug": "opensource-code-and-nuclear-energy-are-the-building-blocks-of-ai",
    "title": "Open-Source Code and Nuclear Energy Are the Building Blocks of AI",
    "description": "David Westin examines why open-open source code and nuclear energy are so important for AI.",
    "fullText": "Companies like Google have so far chosen to keep their code to themselves, and even the “open source” champion, Meta, is reportedly making the next version of its AI model proprietary. Still, China’s DeepSeek is open source.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/newsletters/2025-12-13/amd-ceo-lisa-su-and-ge-vernova-ceo-scott-strazik-explain-what-we-need-for-ai",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i5jwYhX_FDDk/v7/1200x800.jpg",
    "created_at": "2025-12-13T13:18:43.511Z",
    "topic": "finance"
  },
  {
    "slug": "oracles-collapsing-stock-shows-the-ai-boom-is-running-into-two-hard-limits-physics-and-debt-markets",
    "title": "Oracle’s collapsing stock shows the AI boom is running into two hard limits: physics and debt markets",
    "description": "“The world of bits moves fast. The world of atoms doesn’t. And data centers are where those two worlds collide.”",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/13/oracle-stock-collapse-ai-boom-debt-data-centers-delayed/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-1175129162-e1765579113721.jpg?resize=1200,600",
    "created_at": "2025-12-13T13:18:40.792Z",
    "topic": "finance"
  },
  {
    "slug": "i-asked-rivian-execs-why-an-adventurebrand-ev-needs-ai-and-selfdriving-to-them-theyre-logical-next-steps",
    "title": "I asked Rivian execs why an adventure-brand EV needs AI and self-driving. To them, they're logical next steps.",
    "description": "Rivian executives said AI and autonomy not only makes sense for their company, but also reflects the direction of the entire auto industry.",
    "fullText": "If there were a Venn diagram of a driver who wants an adventure-focused car with off-roading capability on one side and a driver who wants a software-centric, computer-first car that could drive itself on the other, would there be a lot of overlap between the two circles?\n\nOn Thursday, Rivian hosted an \"Autonomy & AI Day\" at the company's research and development hub in Palo Alto, where hundreds witnessed the EV maker's grand leap into the future: a highly integrated AI assistant and fully autonomous driving capability, all powered by Rivian's very own silicon chip.\n\nWassym Bensaid, Rivian's Chief Software Officer, called the move a \"profound platform shift which changes our product and everything we do at the company.\"\n\nBensaid is among the key executives leading the charge toward Rivian's \"AI-defined vehicle,\" along with James Philbin, VP of Autonomy & AI, and Vidya Rajagopalan, Senior VP of Rivian's electrical hardware division.\n\nDuring the event, I had the chance to talk to Bensaid and Philbin about the pivot and whether it makes sense for a company that, since its inception, has branded itself as an adventure-forward vehicle, or if this is just a response to consumer demand.\n\nPhilbin, who was a director at Zoox and Waymo before joining Rivian in 2022, told me that pursuing autonomy has long been part of the company's trajectory rather than an overnight decision.\n\nOn the other side of the coin, Philbin sees a rising \"tide\" in consumer demand for some level of autonomy — especially as robotaxis become mainstream.\n\n\"We are starting to see that autonomy is a really important purchase decision with customers, and especially customers who come from vehicles with maybe high levels of autonomy,\" he said. \"They don't go back.\"\n\nPhilbin said that having a high-level advanced driver assistance system (ADAS) was cited as one of the \"top three purchase reasons\" for Rivian customers. However, the demand will extend to all automakers, he said.\n\n\"I just see it becoming such a key purchase driver for vehicles going forward,\" Philbin said. \"And I think every OEM will have to deliver these features to customers in some way.\"\n\nA year ago, Bensaid told me that the future of cars would be hands-free, and that using buttons or fiddling with the touchscreen would be \"an anomaly.\"\n\n\"It's a bug, it's not a feature,\" he said at the time. \"Ideally, you would want to interact with your car through voice. And the problem today is that most voice assistants are just broken.\"\n\nThursday's demonstration of the Rivian Assistant, an in-car AI assistant that can control certain vehicle functions, brought Bensaid's vision to life. I saw the Rivian Assistant pull up navigation directions and control the direction of the air vents through voice control.\n\nBensaid told me at the event that \"cars and automotive are probably the killer app for AI.\"\n\n\"In your 30-minute or 45-minute commute every day, you want to get your time back, you want to really take control of your time,\" he said.\n\nWhen I asked the software chief where the overlap was between Rivian's adventure brand and its AI push, Bensaid said the company \"inspires many types of customers.\"\n\n\"I think at the core of the brand, Rivian wants people to explore the world,\" he said, and that there were different ways to do so, whether that's by going off-road or exploring the world through technology.\n\nAt the same time, Bensaid said, \"At heart, we are a technology company, so technology is really a big part of the user experience, how we see ourselves, and how we present ourselves to the world.\"\n\nBensaid's statement touches upon another key focus beyond the automaker's line-up of premium trucks and SUVs: software licensing.\n\nRivian's joint venture with the German automotive giant Volkswagen was a clear sign of its intent to license its software platform to other automakers in the future.\n\nPart of the tech will include self-driving capabilities, which the entire automotive world — legacy and startup — is exploring, Steve Man, senior auto analyst for Bloomberg Intelligence, told me.\n\n\"We don't really know at the end of the day if there's going to be a huge mass adoption,\" Man said of autonomy. Still, the analyst adds that \"it's a must\" for car makers to pursue.\n\nSales of Tesla's Full Self-Driving Supervised reflect that uncertainty. CEO Elon Musk has presented FSD as the key driver of the company's valuation even though the adoption rate of FSD remains at around 12%, Vaibhav Taneja, Tesla's Chief Financial Officer, said in October.\n\nThe automotive industry still remains bullish on autonomy and AI.\n\nNissan partnered with UK-based Wayve, which develops software for advanced driver assistance systems. General Motors teased plans for an eyes-off driving system for 2028. And Mercedes unveiled a hands-off, eyes-off ADAS a few years ago.\n\nA recent Bloomberg Intelligence report said that nearly half of C-suite auto executives surveyed said they expect AI to lift sales and profits by 9% over the next two to three years.\n\n\"From a business perspective, you don't know if it is going to take off, but you need to invest some money now so that you're not behind,\" Man said, \"and you have the opportunity to roll it out if it is something that people want.\"",
    "readingTime": 5,
    "keywords": [
      "consumer demand",
      "advanced driver",
      "driver assistance",
      "rivian assistant",
      "bloomberg intelligence",
      "software",
      "customers",
      "automotive",
      "company's",
      "chief"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/rivian-pivot-bet-on-ai-self-driving-autonomy-2025-12",
    "thumbnail_url": "https://i.insider.com/693cac1664858d02d216c35e?width=1200&format=jpeg",
    "created_at": "2025-12-13T13:18:40.223Z",
    "topic": "finance"
  },
  {
    "slug": "i-work-in-ai-security-at-google-and-there-are-some-things-i-would-never-tell-chatbots-i-follow-4-rules-to-use-ai-safely",
    "title": "I work in AI security at Google and there are some things I would never tell chatbots. I follow 4 rules to use AI safely.",
    "description": "Harsh Varshney, who works on Chrome AI security at Google, shares four tips for protecting your data and identity when you talk to AI chatbots.",
    "fullText": "This as-told-to essay is based on a conversation with 31-year-old Harsh Varshney, who works at Google and lives in New York. The following has been edited for length and clarity.\n\nAI has quickly become a silent partner in our daily lives, and I can't imagine life without AI tools.\n\nDay-to-day, they help me with deep research, note-taking, coding, and online searches.\n\nBut my job means I'm very aware of the privacy concerns associated with using AI. I've worked at Google since 2023 and spent two years as a software engineer on the privacy team, building infrastructure to protect user data. I then switched to the Chrome AI security team, where I help secure Google Chrome from malicious threats, like hackers and those who use AI agents to conduct phishing campaigns.\n\nAI models use data to generate helpful responses, and we users need to protect our private information so that harmful entities, like cybercriminals and data brokers, can't access it.\n\nHere are four habits I've made that I believe are essential for protecting my data while using AI.\n\nSometimes, a false sense of intimacy with AI can lead people to share information online that they never would otherwise. AI companies may have employees who work on improving the privacy aspects of their models, but it's not advisable to share credit card details, Social Security numbers, your home address, personal medical history, or other personally identifiable information with AI chatbots.\n\nDepending on the version being used, the information shared with public AI chatbots can be used to train future models and generate responses that are more relevant. This could result in \"training leakage,\" where the model memorizes personal information about one user and later regurgitates it in responses to another. Plus, there's the risk of data breaches, which would expose what you've shared with a chatbot.\n\nI treat AI chatbots like a public postcard. If I wouldn't write a piece of information on a postcard that could be seen by anyone, I wouldn't share it with a public AI tool. I'm not confident about how my data could be used for future training.\n\nIt's important to identify whether you're using a more public AI tool or an enterprise-grade one.\n\nWhile it's uncertain how conversations are used for training public AI models, companies can pay for \"enterprise\" models. Here, models aren't typically meant to train on user conversations, so it's safer for employees to talk about their work and company projects.\n\nThink of it like having a conversation in a crowded coffee shop where you could be overheard, versus a confidential meeting in your office that stays within the room.\n\nThere have reportedly been instances where employees have accidentally leaked company data to ChatGPT. If you work on unreleased company projects or are trying to get a patent, you probably don't want to discuss your plans with a non-enterprise-grade chatbot due to the risk of leakage.\n\nI don't discuss projects I'm working on at Google with public chatbots. Instead, I use an enterprise model, even for tasks as small as editing a work email. I'm much more comfortable sharing my information because my conversations aren't used for training, but I still minimize the personal information I share.\n\nAI chatbots usually keep a history of your conversations, but I recommend deleting it on both enterprise and public models regularly to protect your user privacy in the long term. Due to the risk of your account being compromised, it's a good precautionary habit to have, even if you're confident you aren't putting private data into the tools.\n\nOnce, I was surprised that an enterprise Gemini chatbot was able to tell me my exact address, even though I didn't remember sharing it. It turned out, I had previously asked it to help me refine an email, which included my address. Because the tool has long-term memory features, enabling it to remember information from previous conversations, it could identify what my address was and retain it.\n\nSometimes, if I'm searching for things I don't want the chatbot to remember, I'll use a special mode, a bit like incognito mode, where the bots don't store my history or use the information to train models. ChatGPT and Gemini call this the \"temporary chat\" feature.\n\nIt's better to use AI tools that are well-known and are more likely to have clear privacy frameworks and other guardrails in place.\n\nOther than Google's products, I like to use OpenAI's ChatGPT and Anthropic's Claude.\n\nIt's also helpful to review the privacy policies of any tools you use. Sometimes, they'll explain more about how your data is used to train the model. In the privacy settings, you can also look for a section with the option to \"improve the model for everyone.\" By making sure that setting is turned off, you're preventing your conversations from being used for training.\n\nAI technology is incredibly powerful, but we must be cautious to ensure our data and identities are safe when we use it.\n\nDo you have a story to share about using AI to help you at work? Contact this reporter at ccheong@businessinsider.com",
    "readingTime": 5,
    "keywords": [
      "models",
      "privacy",
      "it's",
      "conversations",
      "chatbots",
      "training",
      "tools",
      "user",
      "address",
      "train"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-ai-security-safe-habits-privacy-data-2025-12",
    "thumbnail_url": "https://i.insider.com/69395b7504d0f0a114f1bc26?width=1200&format=jpeg",
    "created_at": "2025-12-13T13:18:39.919Z",
    "topic": "finance"
  },
  {
    "slug": "blackrocks-head-of-talent-acquisition-reveals-how-ai-has-changed-what-he-looks-for-in-applicants",
    "title": "BlackRock's head of talent acquisition reveals how AI has changed what he looks for in applicants",
    "description": "Though Nigel Williams is looking for AI proficiency, the BlackRock exec shared one part of the application process where the tech doesn't belong.",
    "fullText": "If you want to work at BlackRock, make sure you're using AI — just not too much.\n\nNigel Williams, BlackRock's global head of talent acquisition, said that AI is shifting his hiring priorities, and that fluency with the technology is now key to any strong application. However, he warns against depending on it in the interview process.\n\n\"We want to hire people that are curious, that understand that AI is here,\" he told Business Insider, especially because it's embedded in functions across the world's biggest asset manager.\n\nThe strongest applicants can demonstrate that they are both digitally native and comfortable with various AI tools, and that they're curious about future capabilities. Young talent is \"upskilling itself to meet the moment,\" Williams said, since applicants without a computer science background often demonstrate AI proficiency. Everyone, he added, will need to have a basic understanding of prompt engineering and how to question AI outputs.\n\n\"In this age of AI, the talent skills that I think we need more than ever are people that are curious, have a questioning mindset, and are willing to not just trust what the model puts out there, but also make sure we're continuing to pressure test that,\" he said. Strong interpersonal and relationship-building skills are also becoming even more important, he said.\n\nWilliams said that his team is figuring out how to assess applicants' AI abilities and is mindful of making sure people without tech backgrounds don't feel intimidated. He's interested in how people use the technology in their personal, academic, or work lives, and said his team is still fine-tuning how to assess that in the interview process.\n\nDespite Williams' new focus on how applicants engage with AI, he's not using it to screen candidates. As of now, he uses AI to schedule interviews.\n\nThere's such a thing as too much AI in the application process, though.\n\nWilliams said recruiters and hiring managers have told people ahead of an interview not to use an AI tool, sometimes to little avail.\n\n\"It is quite common. You will sometimes see people looking to the left or the right. Our interviewing teams, if they're in the middle of doing that, will pick up on that and be able to say, 'Hey, we do want to make sure that you're staying focused,'\" Williams said.\n\nBlackRock employs around 24,600 people in more than 30 countries, according to a November 5 filing with the Securities and Exchange Commission. Some 21,100 people worked at the firm as of the end of 2024, according to that year's annual report.\n\nBlackRock has launched Asimov, an agentic AI platform for its equity business. At the annual New York Times DealBook Summit this week, its CEO, Larry Fink, said that there will be \"some huge winners and huge failures\" with the technology.",
    "readingTime": 3,
    "keywords": [
      "interview process",
      "sure",
      "applicants",
      "talent",
      "technology",
      "curious",
      "you're",
      "hiring",
      "application",
      "demonstrate"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/blackrock-talent-acquisition-ai-hire-job-hunt-2025-12",
    "thumbnail_url": "https://i.insider.com/6931b64371107c9f34575667?width=1134&format=jpeg",
    "created_at": "2025-12-13T13:18:39.794Z",
    "topic": "finance"
  },
  {
    "slug": "how-to-review-ai-generated-prs",
    "title": "How to review AI generated PRs",
    "description": "Tips from an AI skeptic for working with a team which uses AI a lot.",
    "fullText": "So your team uses AI a lot. Maybe you’re feeling a bit overwhelmed by the amount of bad code, or just the volume of code, you’re having to review. I’ve been there too. While AI has gained popularity, I’ve worked with many teams in many industries. Here are some techniques and strategies I’ve adopted, as an AI skeptic, which have made reviewing AI generated code feel less taxing and more productive.\n\nBefore digging into what’s different, I think it’s worth taking a moment to recognize what’s the same. These things are true whether your PR was written by a human or an AI.\n\nTesting is software engineering, but is often viewed as less important by both humans and AI alike. The author may not have reviewed the tests as closely as the implementation. It’s well worth your time as a reviewer to make up that difference.\n\nSomething I try to keep in mind when reviewing AI-generated PRs, and honestly in life, is that perfect is the enemy of good. Not every comment will be resolved exactly how you’d prefer. Sometimes you’ll let things slide that you wish you hadn’t. But steady, incremental influence still matters. A review that nudges the codebase in the right direction is far better than disengaging and letting low-quality AI output accumulate unchecked. If you stay involved, ask questions, and keep the conversation open with your teammates and leadership, you retain the ability to shape the outcome.\n\nFinally, it’s worth remembering that advice like this only gets you so far. If your team is consistently flooding the codebase with poor AI-generated code, that’s ultimately not a tooling problem, it’s a people and process problem. Technology tends to amplify whatever dynamics already exist. The real work is helping the team move toward better habits and shared expectations. No one is trying to write bad code; they’re doing the best they know how. Thoughtful guidance, clear standards, and collaborative review are how you help them know better—and do better.\n\nWe've been helping engineering teams deliver exceptional products for over 20 years. Our designers, developers, and product managers work closely with teams to solve your toughest software challenges through collaborative design and development. Learn more about us.",
    "readingTime": 2,
    "keywords": [
      "it’s worth",
      "code",
      "team",
      "review",
      "i’ve",
      "teams",
      "you’re",
      "reviewing",
      "less",
      "what’s"
    ],
    "qualityScore": 1,
    "link": "https://thoughtbot.com/blog/how-to-review-ai-generated-prs",
    "thumbnail_url": "https://images.prismic.io/thoughtbot-website/aEccJrh8WN-LV5_m_default-article-background.png?auto=format%2Ccompress&blend-mode=normal&blend-x=0&blend-y=0&blend=https%3A%2F%2Fimages.prismic.io%2Fthoughtbot-website%2FZ1tQFJbqstJ98cGP_default.png&mark-x=356&mark-y=100&mark64=aHR0cHM6Ly9hc3NldHMuaW1naXgubmV0L350ZXh0Lz90eHQtbGVhZD0tMTUmdHh0LXRyYWNrPTAmdHh0NjQ9U0c5M0lIUnZJSEpsZG1sbGR5QkJTU0JuWlc1bGNtRjBaV1FnVUZKeiZ0eHRjbHI9ZjVmNWY1JnR4dGZvbnQ9SUJNUGxleFNhbnNKUC1TZW1pQm9sZCZ0eHRwYWQ9MCZ0eHRzaXplPTc2Jnc9ODAw&txt-align=center%2Cmiddle&txt-color=f5f5f5&txt-fit=max&txt-font=IBMPlexSansJP-SemiBold&txt-size=24&txt-x=391&txt-y=526&txt=Justin+Toniazzo",
    "created_at": "2025-12-13T13:18:37.377Z",
    "topic": "tech"
  },
  {
    "slug": "gemini-tops-leaderboard-on-research-math-problems",
    "title": "Gemini tops leaderboard on research math problems",
    "description": "FrontierMath is a benchmark of hundreds of unpublished and extremely challenging math problems to help us to understand the limits of artificial intelligence.",
    "fullText": "Latest \n\n Publications & Commentary \n\n Papers & Reports\n\n Newsletter\n\n Podcast\n\n Data & Resources \n\n Datasets\n\n Overview\n\n AI Benchmarking\n\n AI Models\n\n Frontier Data Centers\n\n ML Hardware\n\n AI Companies\n\n GPU Clusters\n\n Resources\n\n AI Trends & Statistics\n\n Data Insights\n\n Projects \n\n FrontierMath\n\n GATE Playground\n\n Distributed Training\n\n Model Counts\n\n About \n\n About Us\n\n Our Team\n\n Careers\n\n Consultations\n\n Our Funding\n\n Donate\n\n Contact",
    "readingTime": 1,
    "keywords": [
      "resources"
    ],
    "qualityScore": 0.2,
    "link": "https://epoch.ai/frontiermath",
    "thumbnail_url": "https://epoch.ai/assets/images/frontiermath/figures/frontiermath-banner.png",
    "created_at": "2025-12-13T13:18:37.118Z",
    "topic": "tech"
  },
  {
    "slug": "browseruse-as-a-rest-api-with-vnc-persistent-sessions-and-tools",
    "title": "Browser-Use as a REST API with VNC, persistent sessions, and tools",
    "description": "A REST API wrapper compatible with the Browser-Use Cloud API v2 specification, enabling AI-powered browser automation through a standardized REST interface. - GitHub - Reqeique/browser-use-api at dev",
    "fullText": "Reqeique\n\n /\n\n browser-use-api\n\n Public\n\n A REST API wrapper compatible with the Browser-Use Cloud API v2 specification, enabling AI-powered browser automation through a standardized REST interface.\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Reqeique/browser-use-api",
    "readingTime": 1,
    "keywords": [
      "star",
      "rest"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Reqeique/browser-use-api/tree/dev",
    "thumbnail_url": "https://opengraph.githubassets.com/c01e94553026b46a2a1be0ff32b7e84c12a5296eeb7ff0a0ab433a0494a471d9/Reqeique/browser-use-api",
    "created_at": "2025-12-13T13:18:36.962Z",
    "topic": "tech"
  },
  {
    "slug": "ai-is-bringing-old-nuclear-plants-out-of-retirement",
    "title": "AI is bringing old nuclear plants out of retirement",
    "description": "The White House has promised to quadruple nuclear power by 2050.",
    "fullText": "The Palisades Nuclear Generating Station is nestled between sand dunes on the eastern shore of Lake Michigan. It shut down for financial reasons in 2022. Three years later, it’s on the cusp of reopening, with hundreds of workers streaming through its security barriers every day.\n\nPalisades is on track to restart in early 2026. When it does, it will be the first nuclear plant in the United States to generate electricity again after being decommissioned. Nick Culp of Holtec, the company that owns the plant, said its revival is a response to a surge in demand for electricity.\n\n“We have seen [Michigan]’s baseload generation go offline at a rapid rate as they’ve moved away from fossil generation,” Culp said. “How do you backfill that when you see demand on the horizon like [artificial intelligence], like data storage, like keeping the lights on at home, and new manufacturing?”\n\nNuclear is part of the answer to that question, Culp said, and the government agrees. Michigan gave $300 million to the restart — part of its goal to have 100% carbon-free electricity by 2040 — and the federal government gave the project a loan of more than $1.5 billion.\n\nThat money is part of the Trump administration’s investment in what it’s calling a “nuclear energy renaissance.” In May, the White House released a plan to quadruple American nuclear power by 2050, following a similar pledge from the Biden administration.\n\nMeeting that goal would require dozens of new reactors. But whether they’re traditional power plants or new designs, nuclear reactors are expensive and slow to build. Facing a crunch between climate goals and rising electricity demand, Michigan, Pennsylvania, and Iowa are reopening plants that closed just a few years ago.\n\nWhen the Palisades plant in Michigan closed in 2022, Jim Byrd said he left his office of more than two decades “with a heavy heart.”\n\nHe was working at a nuclear plant in Mississippi last year when he heard about the plan to reboot Palisades. Then he got the call he had been waiting for, asking him to come back.\n\n“Palisades is my home. These people are my family,” Byrd said. Since his return, he’s been training new employees in an exact replica of the reactor control room, right down to its 1960s pink-and-green color scheme.\n\nWhile the plant was in decent shape, recommissioning still required repairing equipment and overcoming mountains of paperwork.\n\n“We are creating a roadmap on how to do this, and the whole industry is watching,” said Byrd. “I had existing licensed operators that had a license from the Nuclear Regulatory Commission when we shut down, so we had to work on getting those back.”\n\nAll that work is worth it, he said, to get the plant back up and running.\n\n“What we're doing here is exciting,” said Byrd. “Having a reliable power source that keeps your electricity costs low, everybody should be rooting for that.”\n\nThe restart also attracted employees from elsewhere in the industry. The plant’s new chief nuclear officer, Rich Burroni, came from New York’s Indian Point Energy Center, which closed in 2021.\n\n“The trend five years ago was a lot of work on decommissioning,” he said, “and now that’s all changed.”\n\nMore change may be coming for Palisades. The Department of Energy said this month it will give Holtec up to $400 million in federal funding to build small modular reactors in Michigan. That technology could help speed up the deployment of new nuclear power in the future, according to many in the industry, but so far has not been commercially viable.\n\nFor now, restarting a plant costs less than a third of what it would take to build a new one, said Culp of Holtec.\n\n“When you factor in how long it takes to construct a new nuclear power plant, especially here in the United States, and the amount of money that goes into it,” he said, “it’s a pretty good value proposition.”\n\nMany of Palisades’ employees live within 10 miles of the plant, which means they could be exposed to a radioactive plume in an emergency.\n\nThat zone also includes the town of Covert, Michigan. Township supervisor Daywi Cook’s father helped build the plant in the 1960s.\n\n“I grew up with the sirens being tested. I think it was every last Saturday of the month,” Cook said. “It was just a normal thing.”\n\nHaving friends and family members who worked at the plant helped demystify nuclear power, she said, and she came to see the plant as part of the community.\n\nAt one point, taxes from the plant made up 40% of the township’s revenue. Now, as Covert’s township supervisor, Cook said she’s glad the plant is reopening.\n\n“Having that stability and having that employment available for folks who live here is something that I think was taken for granted for a very long time,” she said. “I think what's important is that we educate ourselves as residents near the plant and that Holtec continues to be a good neighbor in being transparent with the community.”\n\nZach Morris, head of the economic development group Market One, said Pallisades is an important piece of the local economy.\n\n“Southwest Michigan is a beautiful area. It's just a wonderful community of small towns. I call it Americana,” Morris said. “Americana needs electricity. So the good news is we have a really reliable source of power that is clean. It pays its employees well. So we're excited about being able to keep that online.”\n\nNot everyone is on board with the plant’s reopening. Environmental groups have sued to stop it, and protesters have raised concerns about the long-term storage of spent fuel next to the Great Lakes.\n\nWhile nuclear power does have a record of safety, many Americans remember the 1979 disaster at central Pennsylvania’s Three Mile Island. One of the two reactors on the island had a partial meltdown and released radioactive gases into the environment. There were no deaths, and the Nuclear Regulatory Commission said the accident “had no detectable health effects on plant workers or the public.”\n\nThat left the plant with only one working reactor, which produced power until 2019, when it shut down for financial reasons. Today, that reactor, like Palisades in western Michigan, is in the process of coming back online.\n\n“When you walk through the plant now, all the equipment is still there, but it's deathly quiet. You don't hear the hum of the motors, the steam going through the lines,” said Craig Smith, who is in charge of bringing back the plant at Three Mile Island, renamed the Crane Clean Energy Center. “It's an eerie kind of feeling when you walk through the plant.”\n\nThat eerie feeling may soon be gone. A red LCD clock in Smith’s office counts down the hours until the plant’s reopening in late 2027, which is backed by a billion-dollar loan from the Trump Administration.\n\nThe recommissioned reactor on Three Mile Island will pump 835 megawatts into the regional grid, but all that electricity is spoken for by Microsoft, which agreed to buy an equivalent amount of power from the grid for the next 20 years to feed its data centers.\n\n“The dynamics of the energy economy have changed significantly, mainly because of artificial intelligence,” Smith said.\n\nNuclear is well-suited to the moment, in his view, because of its consistency.\n\n“Hottest days of the year, coldest days of the year, freezing weather, the plant continues to operate,” Smith said. “As far as a reliable power source, you can’t beat it.”\n\nSmith was in high school in nearby Hershey in 1979 and remembers the evacuation after the disaster at Three Mile Island. That failed to dissuade him from going into a career in nuclear power, and he said today, the industry is safer because of regulations put in place after the partial meltdown.\n\n“People at the plant here take that personally,” he said. “The standards of the industry are greatly improved, and we've made significant improvements to the design of the plants and how we operate them.”\n\nGene Stilp has a different take. He’s one of many people in the area who say the official story of the 1979 disaster failed to account for long-term health problems they believe are related to the accident.\n\nStilp has been fighting nuclear power on Three Mile Island since before the plant opened, and said the recommissioning is an unnecessary risk to public safety.\n\n“We’re sticking up for the people who live here rather than the shareholders of Microsoft and Constellation,” said Stilp, who often appears in public wearing a blazer with “NO TMI RESTART” sewn on the back.\n\n“What they’re proposing for evacuation does not work, and so that’s my line in the sand,” he said, pointing out the 10-mile Emergency Planning Zone includes a major hospital complex and several schools. “The population increases in Central Pennsylvania, the realization that there are so many people at risk here, the best you can do is take away that risk.”\n\nAnother longtime opponent of the power plant, Eric Epstein of Three Mile Island Alert, said the country is making mistakes in its rush to power data centers. He said the economics might have changed for nuclear power, but the risks have not.\n\n“There was no public discussion about whether or not we’re going to restart Three Mile Island,” said Epstein. “You had this psychic tear in the fabric of the community that can't be papered over. You can put all the green paint you want on nuclear power, but there has been no viable solution to isolate nuclear waste.”\n\nConstellation said the spent fuel on site has been safely stored on the island for decades, in fortified containers required by the government to withstand natural disasters, and that all the waste created in 40 years fits in an area about the size of two tennis courts.\n\nDauphin County Commissioner Justin Douglas said he’s listening to local concerns about the plant’s reopening.\n\n“I personally am very interested in transparency and accountability for this in the sense of ensuring that it's as safe as it possibly can be, that we're tracking the cost and ensuring that the taxpayers aren't carrying any of the burden, that we have a good plan for the waste management and that ultimately the community impact is positive,” said Douglas. “We plan for the worst, and we hope for the best.”\n\nMeeting the country’s rising demand for electricity will take a lot more than reviving a few recently decommissioned plants.\n\n“It is a brilliant idea. It's sort of a slam dunk. The downside is that there are not many reactors out there that are realistically able to restart,” said Jacopo Buongiorno, professor of nuclear science and engineering at Massachusetts Institute of Technology. “You’re looking at a little bit less than three gigawatts of electricity, out of 50 that apparently are required for data centers and AI.”\n\nThere are also technical tweaks called uprates that can squeeze more power out of existing plants, which could help blunt the immediate electricity crunch.\n\n“You probably have potential for another five to eight gigawatts across the whole fleet. So you add that up to the two or three that we get from the restarts, you're looking at 10 [gigawatts],” Buongiorno said, or only about a fifth of the total AI power demand expected by 2030.\n\n“If that demand continues in the 2030s, then you can make the investment now to build new reactors,” he said, “and then nuclear can actually capture a lot more than 20%.”\n\nThis segment aired on December 9, 2025.",
    "readingTime": 10,
    "keywords": [
      "regulatory commission",
      "energy center",
      "mile island",
      "artificial intelligence",
      "township supervisor",
      "partial meltdown",
      "nuclear regulatory",
      "three mile island",
      "plant’s reopening",
      "united states"
    ],
    "qualityScore": 1,
    "link": "https://www.wbur.org/hereandnow/2025/12/09/nuclear-power-ai",
    "thumbnail_url": "https://wordpress.wbur.org/wp-content/uploads/2025/12/Copy-of-Reverse-Course-3000x2000px-7-1920x1280.jpg",
    "created_at": "2025-12-13T13:18:36.171Z",
    "topic": "tech"
  },
  {
    "slug": "quorum-cli-to-orchestrate-debates-between-localcloud-llmsreact-ink",
    "title": "Quorum – CLI to orchestrate debates between local/cloud LLMs(React Ink)",
    "description": "Multi-agent AI discussion CLI for structured debates between LLMs - Detrol/quorum-cli",
    "fullText": "Detrol\n\n /\n\n quorum-cli\n\n Public\n\n Multi-agent AI discussion CLI for structured debates between LLMs\n\n License\n\n View license\n\n 25\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Detrol/quorum-cli",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Detrol/quorum-cli",
    "thumbnail_url": "https://opengraph.githubassets.com/a29328fec2d37d9c1a9162794659893d40112e7175eaec8623b509c59c3640e9/Detrol/quorum-cli",
    "created_at": "2025-12-13T13:18:35.954Z",
    "topic": "tech"
  },
  {
    "slug": "oracle-debt-trades-like-junk-as-bond-cds-spreads-flare",
    "title": "Oracle Debt Trades Like Junk as Bond, CDS Spreads Flare",
    "description": "Oracle Corp.’s new investment-grade notes are now trading more like junk bonds, as delays on the completion dates for some data centers add to fears about profits from its artificial intelligence investments.",
    "fullText": "MarketsBy Caleb MutuaSaveOracle Corp.’s new investment-grade notes are now trading more like junk bonds, as delays on the completion dates for some data centers add to fears about profits from its artificial intelligence investments.Extending declines after quarterly earnings earlier this week, paper losses for investors that bought the $18 billion of high-grade notes that Oracle sold in September now totals about $1.35 billion, according to Bloomberg News analysis. The bonds were issued as the company ramps up spending on AI projects.",
    "readingTime": 1,
    "keywords": [
      "notes",
      "bonds"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/oracle-bonds-trade-like-junk-as-spreads-widen-debt-risk-flares",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.4itJ9fVpG4/v0/1200x800.jpg",
    "created_at": "2025-12-13T06:54:13.422Z",
    "topic": "finance"
  },
  {
    "slug": "real-yield-debate-on-credit-own-or-not-own",
    "title": "\"Real Yield\" Debate on Credit: Own or Not Own?",
    "description": "On \"Bloomberg Real Yield\", Alexander Wolf, global head of macro and fixed income strategy at J.P. Morgan Private Bank, and Mike Contopoulos, deputy chief investment officer at Richard Bernstein Advisors, talks with Matt Miller about the Fed's rate decision this week, the next Fed chair and corporate credit. Analysts say that there’s plenty to worry about when it comes to credit, from AI oversupply and private market distress to asset-backed blowups and runaway rates.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/-real-yield-debate-on-credit-own-or-not-own-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1X8CHbxgFBg/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:13.297Z",
    "topic": "finance"
  },
  {
    "slug": "overall-spreads-remain-tight-even-as-oracle-debt-risk-jumps",
    "title": "Overall Spreads Remain Tight Even As Oracle Debt Risk Jumps",
    "description": "On \"Bloomberg Real Yield\", Maureen O'Connor, global head of high-grade debt syndicate at Wells Fargo Corporate & Investment Bank, and Amanda Lynam, head of macro credit research at BlackRock, talks with Matt Miller about credit spreads, issuance and risks tied to the boom in AI growth. There’s a frenzy of development going on to support the AI revolution, and with it an insatiable demand for debt to fund it. Some estimate the overall infrastructure roll-out cost could reach $10 trillion, and with so many lenders lining up to throw cash at the assets, the fear is a bubble is building.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/spreads-remain-tight-even-as-oracle-debt-risk-jumps-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iq0v321ivNhk/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:12.282Z",
    "topic": "finance"
  },
  {
    "slug": "intel-nears-16-billion-deal-for-ai-chip-startup-sambanova",
    "title": "Intel Nears $1.6 Billion Deal for AI Chip Startup SambaNova",
    "description": "Intel Corp. is in advanced talks to acquire artificial intelligence chip startup SambaNova Systems Inc. for about $1.6 billion including debt, according to people familiar with the matter.",
    "fullText": "TechnologyAIBy Ryan Gould, Liana Baker, and Ian KingSaveIntel Corp. is in advanced talks to acquire artificial intelligence chip startup SambaNova Systems Inc. for about $1.6 billion including debt, according to people familiar with the matter.A deal for Palo Alto, California-based SambaNova could come together as soon as next month, said the people, who asked not to be identified because the information is confidential.",
    "readingTime": 1,
    "keywords": [
      "sambanova"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/intel-nears-1-6-billion-deal-for-ai-chip-startup-sambanova",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iv_TDxbWcE4Y/v0/1200x800.jpg",
    "created_at": "2025-12-13T06:54:11.402Z",
    "topic": "finance"
  },
  {
    "slug": "the-feds-next-chair-faces-ai-uncertainty-political-heat-and-credit-risks",
    "title": "The Fed’s Next Chair Faces AI Uncertainty, Political Heat and Credit Risks",
    "description": "The Federal Reserve has just cut rates by 25 basis points into an economy it still expects to grow faster next year, raising questions about why it eased and how much further it can go. Former Council of Economic Advisers chair Glenn Hubbard discusses the decision, the neutral rate and why he doesn’t see much more room for rate cuts going into 2026.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-13/hubbard-don-t-see-argument-for-fed-cut-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iRDykb3ZZoBI/v3/-1x-1.jpg",
    "created_at": "2025-12-13T06:54:10.860Z",
    "topic": "finance"
  },
  {
    "slug": "browser4-an-opensource-browser-engine-for-agents-and-concurrency",
    "title": "Browser4 – an open-source browser engine for agents and concurrency",
    "description": "Browser4: a lightning-fast, coroutine-safe browser for your AI. - platonai/Browser4",
    "fullText": "platonai\n\n /\n\n Browser4\n\n Public\n\n Browser4: a lightning-fast, coroutine-safe browser for your AI.\n\n browser4.io\n\n License\n\n Apache-2.0 license\n\n 967\n stars\n\n 143\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n platonai/Browser4",
    "readingTime": 1,
    "keywords": [
      "browser",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/platonai/Browser4",
    "thumbnail_url": "https://opengraph.githubassets.com/12ed5da8a1c5cf5b9053097cf28d33dd03a57ca18cbc7790136a38244ec0b766/platonai/Browser4",
    "created_at": "2025-12-13T06:54:07.091Z",
    "topic": "tech"
  },
  {
    "slug": "adkrust-a-rust-implementation-of-google-agent-dev-kit",
    "title": "ADK-Rust: a Rust Implementation of Google Agent Dev Kit",
    "description": "The flexible, modular framework for production-ready AI agents. Model-agnostic. Type-safe. Blazingly fast.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://adk-rust.com",
    "thumbnail_url": "https://adk-rust.com/opengraph-image?84b856c5ef0b8bfe",
    "created_at": "2025-12-13T06:54:06.285Z",
    "topic": "tech"
  },
  {
    "slug": "there-is-no-datagenerating-distribution",
    "title": "There is no data-generating distribution",
    "description": "Reflecting on teaching machine learning again. Again.",
    "fullText": "Hi Ben, you might find this preprint of interest https://arxiv.org/abs/2407.17395 Perhaps you are making similar points.\n\nIt is curious that machine learning folks, who often like to say they are \"data driven\" pay little attention to the data at a conceptual level. I think the issue is that the data is taken to be _given_ (as you allude -- someone \"gives you\" a bunch of data). The word \"data\" derives from the latin word (dare) meaning to give. We would be better served to think of capta.... but collecting data is not considered as sexy as making complex models.\n\nOne argument (that simply is wrong) is that the existence of distributions is justified by the \"law\" of large numbers. It is not. For an argument regarding this, and an alternative (to distributions), you might find this other paper of interest. https://www.sciencedirect.com/science/article/pii/S0888613X24000355 It shows what you get when you don't assume the \"law\" of large numbers holds (i.e. that relative frequencies converge). That the result is something other folks had studied for some time is pretty interesting. That coherent upper previsions arise elsewhere in ML (in fairness, DRO and even in SVMs!) suggests they are not so weird after all....\n\nA common viewpoint is that there is a set of all possible data out there (e.g., all images on the web). We collect a subset of these data and train our model. The main (and likely unreasonable) assumption is that the training subset is an iid sample (or uniformly sampled w/o replacement) from the set of all possible data. This assumption is the central ingredient in theoretical generalization bounds. While it's probably not perfectly reasonable, it does give us a framework for comparing models and algorithms, and aligns with common practices like hold-out validation. I think this is a useful model of the (training) data-generating distribution.",
    "readingTime": 2,
    "keywords": [
      "interest",
      "folks",
      "models",
      "argument",
      "distributions",
      "numbers",
      "subset",
      "model",
      "assumption",
      "training"
    ],
    "qualityScore": 0.85,
    "link": "https://www.argmin.net/p/there-is-no-data-generating-distribution",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!ZmOp!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01fe005e-79d6-40b2-bd2b-f83cc1ef19da_840x600.jpeg",
    "created_at": "2025-12-13T06:54:04.459Z",
    "topic": "tech"
  },
  {
    "slug": "zootopia-oc-maker-create-zootopiastyle-original-characters-with-ai",
    "title": "Zootopia OC Maker – Create Zootopia-Style Original Characters with AI",
    "description": "Create original animal characters in the style of Zootopia, supporting various species, occupations, and city district themes inspired by the movie.",
    "fullText": "Design your own Zootopia characters with our Zootopia OC Creator & AI Generator. Create mammals from every district—Savanna Central, Tundratown, Sahara Square, and more!\n\nJoin thousands of fans creating their own characters! 👾\n\nExplore more powerful AI features\n\nExplore what other creators are making with Zootopia OC Maker and get inspired to design your own unique animal characters.\n\nCreate your Zootopia-inspired character in just four steps:\n\nProvide details like species, job, district of residence, personality, and appearance.\n\nChoose from different Zootopia-inspired looks—classic, movie-style, or stylized versions.\n\nAI gives you multiple designs—keep refining until it matches your original vision.\n\nDownload high-quality results for stories, comics, RP, or creative projects.\n\nZootopia OC Maker is an AI-powered tool for fans who want to create original animal characters that naturally fit into the world of Zootopia. Build predators, prey, officers, civilians, hustlers, performers, or residents from any district.\n\nBring your Zootopia-inspired ideas to life with AI that captures the charm and diversity of the Zootopia universe.\n\nFeatures that help you design unique animal characters true to the Zootopia world.\n\nChoose from mammals of all sizes—from tiny rodents to massive elephants.\n\nCreate characters reflecting the culture and environment of each Zootopia district.\n\nSwitch between movie-style rendering, cartoon style, or stylized art.\n\nGet personality traits, occupations, relationships, and backstory elements.\n\nCreate families, police squads, gangs, or community groups with interconnected stories.\n\nDownload crisp, high-resolution images ready for creative use.\n\nFeedback from fans who used Zootopia OC Maker to design their dream animal characters.\n\nFrequently asked questions about creating Zootopia-inspired characters.\n\nIt’s an AI tool that creates original Zootopia-style animal characters. Describe species, occupation, personality, and more, and AI generates visuals and profiles.\n\nNo! Anyone can use it—the AI handles artwork while you focus on creativity.\n\nPolice officers, criminals, citizens, performers, workers, politicians, and more—any mammal species.\n\nUsually under a minute depending on details and chosen style.\n\nYou receive high-quality images plus optional character profiles: job, district, personality traits, and background.\n\nYes! Change appearance, species details, clothing, or art styles. The AI adjusts based on your edits.\n\nJoin the community of fans already building their own animal characters with this OC Maker.",
    "readingTime": 2,
    "keywords": [
      "job district",
      "personality traits",
      "zootopia oc maker",
      "unique animal",
      "animal characters",
      "create",
      "design",
      "fans",
      "zootopia-inspired",
      "species"
    ],
    "qualityScore": 1,
    "link": "https://aiocmaker.com/oc-maker/zootopia-oc-maker",
    "thumbnail_url": "https://s1.wordlebot.net/og.jpg",
    "created_at": "2025-12-13T06:54:03.983Z",
    "topic": "tech"
  },
  {
    "slug": "ignoring-ai-bubble-fears-investors-bet-nvidia-and-google-will-fuel-taiwan-stocks-to-record",
    "title": "Ignoring AI bubble fears, investors bet Nvidia and Google will fuel Taiwan stocks to record",
    "description": "Taiwan's tech-heavy stocks show few signs of slowing a rally even as AI bubble worries cast a shadow over global markets, underscoring home-grown confidence in the structural advantages in AI that foreign investors may have overlooked.  Taiwan's benchmark index is poised to breach ​a record 30,000 points in 2026, investors say, extending a three-year surge that has seen the stock market nearly double as the island rides a wave of demand ‌for chips that power artificial intelligence.  While foreign money worries about stretched AI valuations, Taiwanese investors have enthusiastically ploughed into the market.",
    "fullText": "TAIPEI/SINGAPORE, Dec 12 (Reuters) - Taiwan's tech-heavy stocks show few signs of slowing a rally even as AI bubble worries cast a shadow over global markets, underscoring home-grown confidence in the structural advantages in AI that foreign investors may have overlooked.\n\nTaiwan's benchmark index is poised to breach ​a record 30,000 points in 2026, investors say, extending a three-year surge that has seen the stock market nearly double as the island rides a wave of demand ‌for chips that power artificial intelligence.\n\nWhile foreign money worries about stretched AI valuations, Taiwanese investors have enthusiastically ploughed into the market.\n\nAnalysts say domestic investors are betting on Taiwan's unique position as the lynchpin of an AI supply chain, where ‌even increasing competition in the sector would only benefit Taiwanese firms, including TSMC, the world's largest contract chipmaker.\n\nOne major focus of anxiety around AI comes from uncertainty about Nvidia's ability to sustain its market dominance, with Google's tensor processing units (TPUs) emerging as a potentially more cost-effective alternative to Nvidia's graphics processing units (GPUs).\n\nBut it's a win-win scenario for Taiwan because the island is essential to supply chains of both the GPU and TPU, the building blocks of AI computing power.\n\n\"Taiwan is a major beneficiary of the AI market,\" said Piter Yang, a fund manager of Fuh Hwa Securities Investment Trust Co, citing the ⁠advantage of Taiwan being the world's semiconductor hub.\n\nAnd for now, as ‌a promising future fuels optimism, Taiwan markets and local investors seem relatively unfazed by the AI bubble fears, just as they remain calm in the face of rising geopolitical tensions with Beijing that have often spooked foreign investors.\n\nGains in Taiwan's market have also been underpinned ‍by earnings growth, leaving it with a reasonably steady price-to-earnings ratio of 21, below that of the Nasdaq and the Nikkei, meaning the rally has not made stocks more expensive.\n\n\"We are not worried about an AI bubble,\" said Li Fang-kuo, chairman of the securities investment arm of food conglomerate Uni-President. \"We are comfortable with where the valuations stand.\"\n\nLi pointed out that several of the magnificent seven companies in the U.S. have gross ​margins of as much as 70% or higher. \"So it's not comparable to the dot-com bubble, when companies were not generating meaningful earnings.\"",
    "readingTime": 2,
    "keywords": [
      "processing units",
      "securities investment",
      "foreign investors",
      "market",
      "bubble",
      "stocks",
      "rally",
      "worries",
      "markets",
      "island"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/ignoring-ai-bubble-fears-investors-053150245.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/1303e6d6fc5d27d84e672269b5c5eb00",
    "created_at": "2025-12-13T06:54:00.470Z",
    "topic": "finance"
  },
  {
    "slug": "creative-workers-wont-be-replaced-by-aibut-their-roles-will-change-to-become-directors-managing-ai-agents-executives-say",
    "title": "Creative workers won’t be replaced by AI—but their roles will change to become ‘directors’ managing AI agents, executives say",
    "description": "AI agents are taking over some routine creative tasks, but executives say the shift will transform workers into “directors” who delegate to AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/creative-work-ai-agents-automation-salesforce-autodesk-accenture-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974684455_c708b812f4_o.jpg?resize=1200,600",
    "created_at": "2025-12-13T03:41:00.982Z",
    "topic": "business"
  },
  {
    "slug": "amazon-prime-video-scraps-aipowered-tv-show-recap-after-fallout-fallout",
    "title": "Amazon Prime Video scraps AI-powered TV show recap after 'Fallout' fallout",
    "description": "Almost a month after Prime Video launched AI-powered Video Recaps, viewers said it shared incorrect plot details about season one of \"Fallout.\"",
    "fullText": "Given the length of time it can take for the new season of your favorite TV show to come out, it's understandable that you might want a little video recap of what's happened so far.\n\nIdeally, that recap is accurate.\n\nFans of Amazon's hit show \"Fallout\" said that wasn't the case in its AI-made synopsis of season one, released ahead of the hit show's new season next week. Fans quickly spotted factual errors, and Amazon Prime Video took down the recap.\n\nOne Redditor said the AI feature told viewers that a flashback featuring the Ghoul (one of the main characters, played by Walton Goggins) took place in the 1950s instead of 2077.\n\nAn X user posted that the recap also mischaracterized the agreement the Ghoul and Lucy MacLean (played by Ella Purnell) made in the \"Fallout\" finale.\n\nInstead of saying the pair is teaming up to find Lucy's father, the recap said the Ghoul gave Lucy an ultimatum: \"die or join him.\"\n\nAmazon first launched its Video Recap, a feature that allows users to catch up on Prime Original TV shows between seasons, for beta testing in November.\n\n\"Video Recaps use AI to identify a show's most important plot points, combining them with synchronized voice narration, dialogue snippets, and music to create a visual summary that prepares viewers for the new season,\" the company said in a press release at the time.\n\nThe TV shows that Amazon said were undergoing Video Recaps testing — \"Jack Ryan,\" \"Upload,\" \"Bosch,\" and \"The Rig\" — did not include the feature at the time of writing.\n\nRepresentatives for Amazon did not respond to a request for comment from Business Insider.\n\nLike so many companies, Amazon is investing heavily in AI.\n\nDuring the company's February earnings call, Chief Finance Officer Brian Olsavsky said that 2025 capital expenditures could reach over $100 billion, with the majority of it going toward AI and Amazon Web Services, its cloud computing platform.\n\nMany of Amazon's consumer services have integrated AI to enhance user engagement and experience, such as product suggestions and helping shoppers on its online platform find clothes that fit. In February, Amazon unveiled Alexa+, the next generation of Alexa, which is powered by generative AI to make it more conversational and personalized for users.\n\nEmbracing AI at Amazon, though, hasn't been without growing pains. In October, the company cited AI as it announced it would lay off 14,000 staff members.\n\n\"This generation of AI is the most transformative technology we've seen since the internet, and it's enabling companies to innovate much faster than ever before (in existing market segments and altogether new ones),\" Beth Galetti, Amazon's senior vice president of people experience and technology, wrote in a blog post at the time.\n\nIn an internal message to the remaining staff, Amazon Vice President of Device Software and Services Tapas Roy asked them to \"lean in on AI.\"\n\n\"Moving forward, we remain focused on our mission to help product teams launch delightful products,\" Roy wrote. \"In support of this mission, I encourage you all to: Focus on the work that most directly impacts our customers, lean in on Al to enhance your effectiveness, [and] raise your hand when you see opportunities to simplify or eliminate unnecessary processes.\"",
    "readingTime": 3,
    "keywords": [
      "vice president",
      "season",
      "feature",
      "services",
      "amazon",
      "it's",
      "fallout",
      "show's",
      "viewers",
      "instead"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/fallout-amazon-tv-show-ai-video-recaps-errors-2025-12",
    "thumbnail_url": "https://i.insider.com/693c6c5d64858d02d216bd89?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.440Z",
    "topic": "finance"
  },
  {
    "slug": "disney-employees-detail-its-internal-ai-strategy-from-disneygpt-to-a-new-jarvis-tool-in-the-works",
    "title": "Disney employees detail its internal AI strategy, from 'DisneyGPT' to a new 'Jarvis' tool in the works",
    "description": "Disney staffers spoke about the company's OpenAI deal and AI strategy, including AI tools they are using and one in development codenamed \"Jarvis.\"",
    "fullText": "Disney's billion-dollar OpenAI deal isn't the only way the company is embracing AI. In recent months, the Mouse House has been quietly adding new AI tools to its arsenal and encouraging staff to use them.\n\n\"They clearly see where things are headed,\" a longtime software engineer at Disney said. This marked a shift from this summer, when Disney had seemed \"hesitant to rely on AI tools,\" they said.\n\nDisney has given its employees access to several AI tools, including Microsoft Copilot and Amazon's Q Developer. Thanks to Disney's OpenAI deal, employees will also soon have access to the enterprise version of ChatGPT, the company said.\n\nThen there's a \"DisneyGPT\" chatbot that four staffers said helps with internal requests, such as creating IT support tickets, viewing the company roster, or analyzing a project's financials.\n\nIn an email sent to staff on October 2, Disney introduced the beta version of the chatbot, describing it as a \"new partner in productivity\" designed to help \"unlock the magic of your imagination.\" A December update enabled employees to upload Excel and PowerPoint files to the bot.\n\nDisneyGPT draws on signature Disney themes, with a prompt asking users if they're \"ready for an enchanting adventure\" and \"a verified collection of Walt Disney quotes\" that are \"tagged by themes like imagination, perseverance, and leadership,\" according to the chatbot's December update log. Otherwise, employees said DisneyGPT is mostly a standard AI chatbot.\n\nThere's also an AI chatbot in the works codenamed \"Jarvis,\" four employees said. Jarvis, named for the personal assistant \"J.A.R.V.I.S.\" from \"Iron Man,\" would be an agentic AI tool — more advanced than DisneyGPT — that completes tasks on an employee's behalf, a high-level staffer with direct knowledge of the company's AI efforts said. This person said Jarvis is in its early stages and is \"not fully baked.\"\n\n\"It's definitely something they want to push for everyone to lean into more,\" a Disney manager said of AI.\n\nCompanies in every industry are racing to adopt AI tools to boost productivity. Disney is going further than many, however. The OpenAI deal makes Disney the first major entertainment company to invest in the AI juggernaut, and allows its beloved characters to be used in the video generator Sora.\n\nThis reflects Disney's long tradition of merging innovation and entertainment, dating back to its founder, Walt.\n\nThree of the eight Disney employees who spoke with Business Insider expressed concerns about using AI, specifically that it could replace humans and threaten job security.\n\nThe high-level employee with direct knowledge of Disney's AI strategy said that while AI is a \"top priority,\" it isn't a cure-all. It can make mistakes and lacks a \"personalized touch\" that people provide, they said.\n\n\"If you use AI everywhere, it's going to be counterproductive,\" this person said, adding that tasks still need human creativity.\n\nDisney spokespeople didn't respond to several requests for comment on its internal AI efforts.\n\nOn an internal Disney website explaining its AI policy and tools, the company said it employs a \"responsible and human-centric approach to using AI.\"\n\n\"That means humans are, and will remain, the creative engine of the company,\" Disney said on the site. \"We believe, fundamentally, that human creativity and curiosity are immense and unique — and are at the heart of Disney.\"\n\n\"Simultaneously, our consistent embrace of new technologies has been a key part of empowering our creators and maintaining our leadership in creativity and innovation,\" the company continued in its \"Responsible AI Use\" section.\n\nSeven of the eight Disney staffers Business Insider interviewed have tried or regularly use DisneyGPT or Copilot, which is integrated into employees' email accounts and documents. Many use those AI tools for simple, routine tasks, like writing emails.\n\nDisney has a portal on its website that outlines its AI policy and lists Disney-approved AI tools. Two employees said the company has pointed staffers to AI education or compliance training courses.\n\nSome unsanctioned AI tools like Anthropic's Claude can be more effective than Disney-approved AI tools, three staffers said.\n\nOne employee at Disney-owned ESPN said their manager told them they could use personal accounts on non-approved AI chatbots for work.\n\n\"I'm just using a personal account because Disney isn't allowing us to use these tools yet,\" the ESPN employee said.\n\nThe staffer with direct knowledge of Disney's AI efforts said leadership had tried to make communications about AI \"clear across the board,\" but acknowledged that workers might not \"understand the implications\" of data security risks that could arise from using unsanctioned AI tools. Some staffers told Business Insider it was hard for them to keep up with the availability and restrictions on various AI tools.\n\nWhile some Disney employees expressed mixed feelings about AI, the more bullish among them said Disney was wise to strike a deal with OpenAI.\n\n\"This type of a partnership at least establishes the precedent for getting paid,\" the ESPN employee said.\n\nA Disney ads employee said they believed Disney's deal with OpenAI would \"pay off\" and \"be massive\" in five to 10 years, even if there are growing pains.\n\n\"Disney is smart to push into this,\" this staffer said. \"They are setting the rules of the game, or at least trying.\"",
    "readingTime": 5,
    "keywords": [
      "espn employee",
      "openai deal",
      "direct knowledge",
      "human creativity",
      "disney employees",
      "business insider",
      "disney's ai",
      "disney-approved ai",
      "tools",
      "disneygpt"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/disney-ai-strategy-employees-disneygpt-openai-deal-chatgpt-2025-12",
    "thumbnail_url": "https://i.insider.com/693c532264858d02d216b98d?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.324Z",
    "topic": "finance"
  },
  {
    "slug": "google-researchers-find-the-best-ai-model-is-69-right",
    "title": "Google researchers find the best AI model is 69% right",
    "description": "Here's what this means for law firms and other businesses that are betting on AI.",
    "fullText": "We just got a sobering picture of how often AI models get their facts straight. This week, Google DeepMind introduced the FACTS Benchmark Suite, which measures how reliably AI models produce factually accurate answers.\n\nIt tests models in four areas: answering factoid questions from internal knowledge, using web search effectively, grounding responses in long documents, and interpreting images. The best model, Google's Gemini 3 Pro, reached 69% accuracy, with other leading models falling well below that.\n\nFor context, if any of the reporters I manage filed stories that were 69% accurate, I would fire them.\n\nBeyond journalism, this number should matter to businesses betting on AI. While models excel at speed and fluency, their factual reliability still lags far behind human expectations, especially in tasks involving niche knowledge, complex reasoning, or precise grounding in source material.\n\nEven small factual errors can have outsized consequences in sectors such as finance, healthcare, and the law. This week, my talented colleague Melia Russell looked at how law firms are handling the rise of AI models as a source of legal truth. It's messy: She recounts how one firm fired an employee because they filed a document riddled with fake cases after using ChatGPT to draft it.\n\nThe FACTS benchmark is a warning but also a roadmap: by quantifying where and how models fail, Google hopes to accelerate progress. But for now, the takeaway is clear: AI is getting better, but it's still wrong about one-third of the time.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "facts benchmark",
      "models",
      "accurate",
      "knowledge",
      "grounding",
      "filed",
      "factual",
      "it's",
      "google"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/google-researchers-find-best-ai-model-69-right-2025-12",
    "thumbnail_url": "https://i.insider.com/693c873c04eda4732f2d7991?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.164Z",
    "topic": "science"
  },
  {
    "slug": "how-i-got-ai-to-help-me-sell-my-old-couch",
    "title": "How I got AI to help me sell my old couch",
    "description": "Google's Gemini AI chatbot quickly identified an old furniture model, making it easier to sell.",
    "fullText": "The Barr family purchased a new couch recently, and we've been trying to sell the old one. My wife posted in a local email group and a potential buyer got in touch with a question.\n\n\"Do you happen to know the model? I would love to look it up online rather than asking you lots of questions. :) Thanks!\" she wrote.\n\nThis is an old couch, so all product codes dissolved in the sands of time years ago. So, I took two photos of the furniture, uploaded them to Gemini, and asked for help. The Google chatbot sent back its best guess in seconds:\n\n\"Tillary Sectional: This is a very popular, modular West Elm sofa that was available around that time.\n\nAppearance Match: The low back and deep seat are very characteristic of the Tillary. The Tillary is known for having interchangeable backrests that can be moved or removed, and your sofa's armless chaise and backrests look like they might be loose cushions or pieces, which is a key Tillary feature.\n\nNote: Search results show the Tillary was being reviewed and discussed around 2014, making it a strong possibility for a 2013 purchase.\"\n\nGemini also shared other useful tips on how to identify the product, such as \"Some West Elm couches have a zippered compartment on the back or bottom where extra components (like legs or connectors) are stored, and a tag may be inside.\"\n\nThat was enough to find a product match and send all the details over to the buyer. We closed the deal, for $200, on Tuesday. That's enough for 10 months of a Gemini Pro subscription.\n\nThis holiday period, the Barr family plans to spend a lot of time slouching on our new, fancy couch. I call it the \"AI bubble couch.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "barr family",
      "couch",
      "product",
      "back",
      "email",
      "buyer",
      "look",
      "backrests",
      "tillary",
      "gemini"
    ],
    "qualityScore": 0.95,
    "link": "https://www.businessinsider.com/google-gemini-ai-help-sell-couch-2025-12",
    "thumbnail_url": "https://i.insider.com/693c898e832e0ef1ead62c46?width=1200&format=jpeg",
    "created_at": "2025-12-13T03:41:00.012Z",
    "topic": "finance"
  },
  {
    "slug": "metas-pivot-from-open-source-to-moneymaking-ai-model",
    "title": "Meta's Pivot from Open Source to Money-Making AI Model",
    "description": "Meta Platforms Inc.’s Mark Zuckerberg, months into building one of the priciest teams in technology history, is getting personally involved in day-to-day work and pivoting the company’s focus to an artificial intelligence model customers pay to use.",
    "fullText": "TechnologyAIBy Kurt Wagner and Riley GriffinSaveMeta Platforms Inc.’s Mark Zuckerberg, months into building one of the priciest teams in technology history, is getting personally involved in day-to-day work and pivoting the company’s focus to an artificial intelligence model customers pay to use.One new model, codenamed Avocado, is expected to debut sometime next spring, and may be launched as a “closed” model — one that can be tightly controlled and that Meta can sell access to, according to people familiar with the matter, who declined to speak publicly about internal plans. The move, which aligns with what rivals Google and OpenAI do with their models, would mark the biggest departure to date from the open-source strategy Meta has touted for years. Open-source models allow outside developers and researchers to review and build upon the code. Meta’s new Chief AI Officer Alexandr Wang is an advocate of closed models, according to the people.",
    "readingTime": 1,
    "keywords": [
      "model",
      "models",
      "mark",
      "closed",
      "meta",
      "open-source"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-10/inside-meta-s-pivot-from-open-source-to-money-making-ai-model",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iSVRoye_WlMo/v0/1200x799.jpg",
    "created_at": "2025-12-13T03:40:59.962Z",
    "topic": "tech"
  },
  {
    "slug": "you-can-use-circle-to-search-to-identify-scams-on-android",
    "title": "You Can Use 'Circle to Search' to Identify Scams on Android",
    "description": "Google's AI tools are getting scam detection capabilities.",
    "fullText": "Android users are getting more tools to combat the seemingly endless stream of scam texts from bad actors looking to steal your data and your money. Circle to Search and Google Lens can now assess messages for scam red flags, and if possible fraud is detected, you'll get recommendations for what to do (or not do) next. Even if you think you know the telltale signs of a scam—a sense of urgency, a demand for money or personal information, a link to log in or pay—using these tools can confirm your suspicions, especially when you feel pressured to act.\n\nTo activate Circle to Search, long press the home button or navigation bar on your device and circle the text you want to scan. Alternatively, you can take a screenshot, open Lens in the Google app (also available on iOS), and tap the screenshot. The feature works for text messages as well as communication on messaging apps and social media sites. Google says the capability is available \"when our systems have high confidence in the quality of the response.\"\n\nThis is just the latest in the Google's suite of security features meant to protect against fraud. Pixel users have real-time, AI-powered scam detection, which identifies and alerts you to suspicious conversational patterns in Google Messages and Phone by Google. In-call protections for Android prevent you from taking certain actions, such as sideloading new apps and changing accessibility permission, on your device while on the phone with anyone not saved in your contacts.\n\nEarlier this month, Google also expanded its in-call scam detection feature, meant to combat bank impersonation schemes, to U.S. users. If you are on a call with a number that's not in your contacts and try to open a participating financial app, you'll get a notification reminding you not to share information and a one-click option to stop screen-sharing and end the call.",
    "readingTime": 2,
    "keywords": [
      "scam detection",
      "users",
      "circle",
      "android",
      "tools",
      "combat",
      "money",
      "fraud",
      "you'll",
      "device"
    ],
    "qualityScore": 0.75,
    "link": "https://lifehacker.com/tech/circle-to-search-can-now-identify-scams-on-android?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KC9SAFF9FGZWDBX4J2A5SMKB/hero-image.fill.size_1200x675.jpg",
    "created_at": "2025-12-13T03:40:59.006Z",
    "topic": "tech"
  },
  {
    "slug": "tension-over-feds-dual-mandate-ai-growths-impact-on-spreads-credits-real-yield-12122025",
    "title": "Tension Over Fed's Dual Mandate, AI Growth's Impact on Spreads, Credits | Real Yield 12/12/2025",
    "description": "\"Bloomberg Real Yield\" highlights the market-moving news you need to know. Today's guests: JPMorgan Private Bank Global head of Macro and Fixed Income Strategy Alexander Wolf, Richard Bernstein Advisors Deputy CIO Mike Contopoulos, Wells Fargo Global Head of High Grade Debt Syndicate Maureen O'Connor and BlackRock Head of Macro Credit Research Amanda Lynam.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/real-yield-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iu9B06KM_hRw/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:10.014Z",
    "topic": "finance"
  },
  {
    "slug": "ai-campus-developer-fermi-drops-after-tenant-ends-agreement",
    "title": "AI Campus Developer Fermi Drops After Tenant Ends Agreement",
    "description": "Fermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.",
    "fullText": "TechnologyAIBy Naureen S MalikSaveFermi Inc. plunged as much as 46% on Friday after the power developer, co-founded by former Texas governor Rick Perry, said a tenant terminated a $150 million agreement tied to its proposed artificial intelligence campus in West Texas.The company said its first investment-grade tenant canceled a deal from Nov. 4 that would have provided as much as $150 million to fund construction costs, according to a filing Friday. No funds had been drawn under that agreement.",
    "readingTime": 1,
    "keywords": [
      "tenant",
      "agreement"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/fermi-falls-51-after-ai-campus-tenant-ends-150-million-deal",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i63XDNyxBC8Q/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.711Z",
    "topic": "finance"
  },
  {
    "slug": "tech-rout-drags-stocks-lower-oracle-broadcom-fall-on-ai-angst",
    "title": "Tech Rout Drags Stocks Lower; Oracle, Broadcom Fall on AI Angst",
    "description": "A rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.",
    "fullText": "MarketsBy Alexandra SemenovaSaveA rotation out of technology stocks gained momentum Friday after disappointing earnings from Broadcom Inc. and anxiety about the completion dates for some of Oracle Corp.’s data centers renewed worries about the artificial intelligence trade.The Nasdaq 100 Index dropped 1.5% at 1:30 p.m. in New York, while the S&P 500 Index fell 0.9%. Broadcom slumped 11%, weighing on artificial intelligence peers after its sales outlook for the AI market failed to meet investors’ expectations. Shares of Oracle lost 3.3% after Bloomberg reported that the company has pushed back timelines for some of the infrastructure it’s developing for OpenAI to 2028 from 2027.",
    "readingTime": 1,
    "keywords": [
      "artificial intelligence",
      "broadcom",
      "oracle",
      "index"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bloomberg.com/news/articles/2025-12-12/s-p-500-wavers-as-investors-rotate-out-of-technology-behemoths",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.gSDwOLgE7g/v1/1200x800.jpg",
    "created_at": "2025-12-12T18:56:09.528Z",
    "topic": "finance"
  },
  {
    "slug": "broadcom-hit-hard-as-ai-backlog-squeezes-margins-open-interest-12122025",
    "title": "Broadcom Hit Hard as AI Backlog Squeezes Margins | Open Interest 12/12/2025",
    "description": "Get a jump start on the US trading day with Matt Miller and Dani Burger on \"Bloomberg Open Interest.\" A Santa rally tries to take hold — with global stocks eyeing records and the U.S. market hitting its first all-time high in six weeks. But tech caution lingers as Broadcom slips on lofty AI hopes, while UBS jumps to a 17-year high on plans to ease capital demands.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2025-12-12/open-interest-12-12-2025-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iZ5fnJN9b.1U/v3/-1x-1.jpg",
    "created_at": "2025-12-12T18:56:09.512Z",
    "topic": "finance"
  },
  {
    "slug": "stocks-tumble-as-traders-ai-bets-take-a-hit-markets-wrap",
    "title": "Stocks Tumble as Traders’ AI Bets Take a Hit: Markets Wrap",
    "description": "US stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed.",
    "fullText": "MarketsBy Cristin FlanaganSaveUS stocks extended losses as a selloff in the year’s biggest artificial intelligence winners dragged global gauges back from the brink of record highs. Longer-dated bond yields climbed. A disappointing sales outlook from chipmaker Broadcom Inc. weighed on rivals and further fueled investor anxiety over AI wagers initially sparked by Oracle Corp. The AI bellwether’s stock drop started Thursday following a forecast for rising outlays and a longer timeline to a revenue payoff. The slump deepened on a report of delays to some of Oracle’s data center projects Friday. Shares of companies tied to the power infrastructure also slid.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2025-12-11/stock-market-today-dow-s-p-live-updates",
    "thumbnail_url": "https://assets.bwbx.io/s3/lightsaber/_next/static/media/social-markets.e062a0c0.jpg",
    "created_at": "2025-12-12T18:56:09.464Z",
    "topic": "finance"
  },
  {
    "slug": "a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm",
    "title": "A Glance at GPU Goodness in Java: LLM Inference with TornadoVM",
    "description": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If […]",
    "fullText": "It seems like it’s become a tradition that I announce I have joined a new company for the Java Advent of Code. At least this time it’s actually an old friend: I am excited to be back at Red Hat, in the llm-d team! Does that mean I forgot about Java? Of course not. If anything, this is an opportunity to learn more about GPU programming, and since Java is my comfort-zone language, what better occasion than looking into TornadoVM?\n\nRecently, the TornadoVM team released gpullama3, a proof-of-concept demonstrating LLM inference on GPUs using pure Java. Let’s explore this together!\n\nTornadoVM is a plugin for the OpenJDK that enables Java programs to automatically run on heterogeneous hardware (GPUs, FPGAs, and multi-core CPUs) using standard Java code annotated for parallel compute.\n\nTransformer-based language models are computationally expensive but highly-parallelizable. At inference time, generating each token requires matrix multiplications across billions of parameters. GPUs excel at these operations because they can perform thousands of computations in parallel. Thus, TornadoVM is the perfect tool for this kind of workload.\n\nInstalling GPULlama3.java was surprisingly straightforward. Make sure you have your favorite flavor of JDK 21 installed. I use sdkman, so I made sure I had Temurin 21 installed:\n\nThen you’ll want to make sure you have installed cmake, a C/C++ toolchain, Python and pip. Now you can clone the repo:\n\nand follow the instructions on the README; for instance, on macOS/Linux:\n\nYou can verify the installation was successful by running one example:\n\nOf course, make sure you replace tornado-examples-1.1.2-dev-e1d2d12.jar with the right jar name! Your output should look something like this:\n\nThe @Parallel annotation tells TornadoVM this loop can be parallelized. The TaskGraph API manages data movement and execution scheduling. You can compile it with the following (if you followed the installation guide correctly $TORNADO_SDK will point to the right path):\n\nNotice that -g is required for this to work correctly. Now you can run it with:\n\nIt will print the first 10 items in the resulting vector.\n\nThe gpullama3 project demonstrates running a Llama 3 model entirely in Java with GPU acceleration. Assuming you are back at the root of the repo, continue with the setup procedure.\n\nNow let’s download a compatible model using the HuggingFace CLI:\n\nTry it! Even on my poor MacBook Air with 8 GB RAM (provided I don’t have too many applications open) this returns:\n\nDisclaimer: even if you have better CPU/GPUs at your disposal, they are unlikely to affect the quality of the joke.\n\nGPULlama3.java currently supports a few FP16 (16-bit floating point) and 8-bit quantized models:\n\nDepending on the model being selected, a different execution plan will be built. The execution plan corresponds to the model architecture. In our case, we picked the unquantized Llama 3.2 1B FP16. Let’s take a look at the setupTornadoForwardPlan() method in FP16LayerPlanner, used by LLama 3.2:\n\nIn the Activation layer we mostly look up token embeddings and apply an initial normalization step, while the Logit layer is where we convert the model’s internal representation into token predictions. So let’s concentrate a bit more on the Feed-Forward Network layer (FFN), and in particular on the Attention implementation. The LlamaFP16FFNLayers#setupSingleFFNLayer method is a bit cryptic at a first glance; let’st start from its signature:\n\nThe method is building a TaskGraph, essentially describing the data flow of our GPU kernels. Let’s focus on QKV and attention, using Sebastian Raschka1‘s excellent Python Notebook as a reference. The following is the architecture diagram of the Llama 3.2 1B model:\n\nFor obvious reasons of brevity, we aren’t going to explore this in detail, but we do want to take a look at the implementation of the attention heads. In particular, let’s take a look at how we compute the Query, Key, Value matrices (Q,K,V = project(x) in the Python version):\n\nThis is followed by the RoPE rescaling to encode token positions:\n\nNow we are ready to compute attention. The generic version (there is also an NVidia-specific implementation) is:\n\nLet’s drill down into TransformerComputeKernelsLayered::processHeadsParallel to see how that is performed. The following is one of the GPU kernels. It essentially computes:\n\nYou will notice that the method:\n\nAfter the attention mechanism computes relationships between tokens, the result is added to the original input, normalized, and passed through a feed-forward network. This process repeats across multiple layers before finally producing the next-token prediction (the logit layer).\n\nBecause it’s an autoregressive model, this entire process repeats for each token, using the previously generated sequence as input.\n\nIn short, TornadoVM handled GPU compilation and execution transparently, allowing a pure Java program to perform LLM inference!\n\nWe’ve completed our whirlwind tour of Llama3GPU.java and TornadoVM. If your head is still spinning, don’t worry, you’re not alone! It’s a lot to take in, but I hope this post has sparked your interest and inspired you to dig deeper: I know I will!\n\nThis site uses Akismet to reduce spam. Learn how your comment data is processed.",
    "readingTime": 5,
    "keywords": [
      "llm inference",
      "gpu kernels",
      "pure java",
      "llama model",
      "process repeats",
      "execution plan",
      "logit layer",
      "token",
      "look",
      "attention"
    ],
    "qualityScore": 1,
    "link": "https://www.javaadvent.com/2025/12/a-glance-at-gpu-goodness-in-java-llm-inference-with-tornadovm.html",
    "thumbnail_url": "https://i0.wp.com/www.javaadvent.com/content/uploads/2025/11/tornadovm-gpullama3.png?fit=1024%2C1024&ssl=1",
    "created_at": "2025-12-12T18:56:04.854Z",
    "topic": "tech"
  },
  {
    "slug": "safeshell-reversible-shell-commands-for-local-ai-agents",
    "title": "SafeShell – reversible shell commands for local AI agents",
    "description": "Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible. - qhkm/safeshell",
    "fullText": "qhkm\n\n /\n\n safeshell\n\n Public\n\n Safe shell operations with automatic checkpoints for AI agents. Let agents run freely. Everything is reversible.\n\n License\n\n MIT license\n\n 5\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n qhkm/safeshell",
    "readingTime": 1,
    "keywords": [
      "agents",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/qhkm/safeshell",
    "thumbnail_url": "https://opengraph.githubassets.com/682605a64fdbc61dcd8e5ba1cd013f5a5b40bb3a5a49c5137fe779101aefc528/qhkm/safeshell",
    "created_at": "2025-12-12T18:56:04.468Z",
    "topic": "tech"
  },
  {
    "slug": "facilitating-ai-adoption-at-imprint",
    "title": "Facilitating AI Adoption at Imprint",
    "description": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout.",
    "fullText": "I’ve been working on internal “AI” adoption, which is really LLM-tooling and agent adoption,\nfor the past 18 months or so.\nThis is a problem that I think is, at minimum, a side-quest for every engineering leader in the current era.\nGiven the sheer number of folks working on this problem within their own company, I wanted to write up my “working notes”\nof what I’ve learned.\n\nThis isn’t a recommendation about what you should do, merely a recap of how I’ve approached the problem thus far,\nand what I’ve learned through ongoing iteration. I hope the thinking here will be useful to you, or at least validates\nsome of what you’re experiencing in your rollout. The further you read, the more specific this will get,\nending with cheap-turpentine-esque topics like getting agents to reliably translate human-readable text representations of Slack entities into mrkdwn formatting of the correct underlying entity.\n\nI am hiring:\nIf you’re interested in working together with me on internal agent and AI adoption at Imprint,\nwe are hiring our founding Senior Software Engineer, AI.\nThe ideal candidate is a product engineer who’s spent some time experimenting with agents,\nand wants to spend the next year or two digging into this space.\n\nAs technologists, I think one of the basics we owe our teams is spending time\nworking directly with new tools to develop an intuition for how they do, and don’t work.\nAI adoption is no different.\n\nTowards that end, I started with a bit of reading, especially Chip Huyen’s AI Engineering,\nand then dove in a handful of bounded projects: building my rudimentary own agent platform\nusing Claude code for implementation,\ncreating a trivial MCP for searching my blog posts,\nand an agent to comment on Notion documents.\n\nEach of these projects was two to ten hours, and extremely clarifying.\nTool use is, in particular, something that seemed like magic until I\nimplemented a simple tool-using agent, at which point it become something extremely non-magical\nthat I could reason about and understand.\n\nImprint’s general approach to refining AI adoption is strategy testing:\nidentify a few goals, pick an initial approach, and then iterate rapidly in the details until the approach genuinely works.\nIn an era of crushing optics, senior leaders immersing themselves in the details is one of our few defenses.\n\nShortly after joining, I partnered with the executive team to draft the above strategy for AI adoption.\nAfter a modest amount of debate, the pillars we landed on were:\n\nAs you see from those principles, and my earlier comment, my biggest fear for AI adoption is\nthat they can focus on creating the impression of adopting AI, rather than focusing on creating additional productivity.\nOptics are a core part of any work, but almost all interesting work occurs where optics and reality\nintersect, which these pillars aimed to support.\n\nAs an aside, in terms of the components of strategy in\nCrafting Engineering Strategy, this is really just\nthe strategy’s policy.\nIn addition, we used strategy testing to refine our approach,\ndefined a concrete set of initial actions to operationalize it (they’re a bit too specific to share externally),\nand did some brief exploration to make sure I wasn’t overfitting on\nmy prior work at Carta.\n\nMy first step towards adoption was collecting as many internal examples of tips and tricks as possible into\na single Notion database. I took a very broad view on what qualified, with the belief that showing\nmany different examples of using tools–especially across different functions–is both useful and inspiring.\n\nI’ve continued extending this, with contributions from across the company, and it’s become a useful resource\nfor both humans and bots alike to provide suggestions on approaching problems with AI tooling.\n\nOne of my core beliefs in our approach is that making prompts discoverable\nwithin the company is extremely valuable.\nDiscoverability solves four distinct problems:\n\nMy core approach is that every agent’s prompt is stored in a single Notion database\nwhich is readable by everyone in the company. Most prompts are editable by everyone,\nbut some have editing restrictions.\n\nHere’s an example of a prompt we use for routing incoming Jira issues from Customer Support\nto the correct engineering team.\n\nHere’s a second example, this time of responding to requests in our Infrastructure Engineering\nteam’s request channel.\n\nPretty much all prompts end with an instruction to include a link to the prompt\nin the generated message. This ensures it’s easy to go from a mediocre response\nto the prompt-driving the response, so that you can fix it.\n\nIn addition to collecting tips and prompts, the next obvious step for AI adoption\nis identifying a standard AI platform to be used within the company, e.g. ChatGPT,\nClaude, Gemini or what not.\n\nWe’ve gone with OpenAI for everyone.\nIn addition to standardizing on a platform, we made sure account provisioning was\nautomatic and in place on day one.\nTo the surprise of no one who’s worked in or adjacent to IT,\na lot of revolutionary general AI adoption is… really just account provisioning and access controls.\nThese are the little details that can so easily derail the broader plan if you don’t dive into them.\n\nWithin Engineering, we also provide both Cursor and Claude.\nThat said, the vast majority of our Claude usage is done via AWS Bedrock,\nwhich we use to power Claude Code… and we use Claude Code quite a bit.\n\nWhile there’s a general industry push towards adopting more AI tooling,\nI find that a significant majority of “AI tools” are just SaaS vendors that\ntalk about AI in their marketing pitches. We have continued to adopt vendors,\nbut have worked internally to help teams evaluate which “AI tools” are meaningful.\n\nWe’ve spent a fair amount of time going deep on integrating with AI tooling for chat and IVR\ntooling, but that’s a different post entirely.\n\nMeasuring AI adoption is, like all measurement topics, fraught.\nAltogether, I’ve found measuring tool adoption very useful for identifying the right\nquestions to ask. Why haven’t you used Cursor? Or Claude Code? Or whatever? These are fascinating\nquestions to dig into. I try to look at usage data at least once a month, with a particular focus\non two questions:\n\nAt the core, I believe folks who aren’t adopting tools are rational non-adopters,\nand spending some time understanding the (appearance of) resistance goes further than\ntop-down mandate. I think it’s often an education gap that is bridged easily enough.\nConceivably, at some point I’ll discover a point of diminishing returns, where the lack\nof progress is stymied on folks who are rejecting AI tooling–or because the AI tooling\nisn’t genuinely useful–but I haven’t found that point yet.\n\nThe next few sections are about building internal agents.\nThe core implementation is a single stateless lambda which handles a wide variety of HTTP requests,\nsimilar-ish to Zapier.\nThis is currently implemented in Python, and is roughly 3,000 lines of code,\nmuch of it dedicated to oddities like formatting Slack messages, etc.\n\nFor the record, I did originally attempt to do this within Zapier,\nbut I found that Zapier simply doesn’t facilitate the precision I believe is necessary to do this effectively.\nI also think that Zapier isn’t particularly approachable for a non-engineering audience.\n\nAs someone who spent a long time working in platform engineering,\nI still want to believe that you can build a platform, and users will come.\nIndeed, I think it’s true that a small number of early adopters will come,\nif the problem is sufficiently painful for them,\nas was the case for Uber’s service migration (2014).\n\nHowever, what we’ve found effective for driving adoption is basically the opposite of that.\nWhat’s really worked is the intersection of platform engineering and old-fashioned product engineering:\n\nSome examples of the projects where we’ve gotten traction internally:\n\nFor all of these projects that have worked, the formula has been\nthe opposite of “build a platform and they will come.” Instead it’s\nrequired deep partnership from folks with experience building AI agents and\nusing AI tooling to make progress. The learning curve for effective AI adoption\nin important or production-like workflows remains meaningfully high.\n\nAgents that use powerful tools represent a complex configuration problem.\nFirst, exposing too many tools–especially tools that the prompt author doesn’t effectively understand–makes\nit very difficult to create reliable workflows. For example, we have an exit_early command that allows terminating\nthe agent early: this is very effective in many cases, but is also easy to break your bot.\nSimilarly, we have a slack_chat command that allows posting across channels, which can support a variety of useful\nworkflows (e.g. warm-handoffs of a question in one channel into a more appropriate alternative),\nbut can also spam folks.\nSecond, as tools get more powerful, they can introduce complex security scenarios.\n\nTo address both of these, we currently store configuration in a code-reviewed Git repository.\nHere’s an example of a JIRA project.\n\nHere’s another for specifying a Slack responder bot.\n\nCompared to a JSON file, we can statically type the configuration, and it’s easy to extend over time.\nFor example, we might want to extend slack_chat to restrict which channels a given bot is allowed to\npublish into, which would be easy enough.\nFor most agents today, the one thing not under Git-version control is the prompts themselves, which are versioned by Notion.\nHowever, we can easily require specific agents to use prompts within the Git-managed repository for sensitive scenarios.\n\nAfter passing tests, linting and typechecking, the configurations are automatically deployed.\n\nIt’s sort of funny to mention, but one thing that has in practice really interfered with\neasily writing effective prompts is making it easy to write things like @Will Larson which\nis then translated into <@U12345> or whatever the appropriate Slack identifier is for a given\nuser, channel, or user group. The same problem exists for Jira groups, Notion pages and databases,\nand so on.\n\nThis is a good example of where centralizing prompts is useful. I got comfortable pulling the unique\nidentifiers myself, but it became evident that most others were not.\nThis eventually ended with three tools for Slack resolution: slack_lookup which takes a list\nof references to lookup, slack_lookup_prefix which finds all Slack entities that start with\na given prefix (useful to pull all channels or groups starting with @oncall-, for example, rather than having to hard-code the list in your prompt), and slack_search_name which uses string-distance to find potential matches (again, useful for dealing with typos).\n\nIf this sounds bewildering, it’s largely the result of Slack not exposing relevant APIs for this sort of lookup.\nSlack’s APIs want to use IDs to retrieve users, groups and channels, so you have to maintain your own cache of\nthese items to perform a lookup. Performing the lookups, especially for users, is itself messy. Slack users have\na minimum of three ways they might be referenced: user.profile.display_name, user.name, and user.real_name,\nonly a subset of which are set for any given user.\nThe correct logic here is, as best I can tell, to find a match against user.profile.display_name, then use that if it exists.\nThen do the same for user.name and finally user.real_name. If you take the first user that matches one of those three,\nyou’ll use the wrong user in some scenarios.\n\nIn addition to providing tools to LLMs for resolving names, I also have a final mandatory check for each response\nto ensure the returned references refer to real items. If not, I inject which ones are invalid into the context window and perform an additional agent loop with only entity-resolution tools available.\nThis feels absurd, but it was only at this point that things really started working consistently.\n\nAs an aside, I was embarassed by these screenshots, and earlier today I made the same changes for Notion pages and databases\nas I had previously for Slack.\n\nSimilarly to foreign entity resolution,\nthere’s a similar problem with Slack’s mrkdwn variant of Markdown\nand JIRA’s Atlassian Document Format:\nthey’re both strict.\n\nThe tools that call into those APIs now have strict instructions on formatting. These had been contained in individual\nprompts, but they started showing up in every prompt, so I knew I needed to bring them into the agent framework itself\nrather than forcing every prompt-author to understand the problem.\n\nMy guess is that I need to add a validation step similar to the one I added for entity-resolution,\nand that until I do so, I’ll continue to have a small number of very infrequent but annoying rendering issues,\nTo be honest, I personally don’t mind the rendering issues, but that creates a lot of uncertainty for others using agents, so I think solving them is a requirement.\n\nToday, all logs, especially tool usage, are fed into two places. First, it goes into Datadog for full logging visibility.\nSecond, and perhaps more usefully for non-engineers, they feed into a Slack channel, #ai-logs which create visibility\ninto which tools are used and with which (potentially truncated) parameters.\n\nLonger term, I imagine this will be exposed via a dedicated internal web UX, but generally speaking I’ve found that\nthe subset of folks who are actively developing agents are pretty willing to deal with a bit of cruft.\nSimilarly the folks who aren’t developing agents directly don’t really care, they want it to work perfectly every time,\nand aren’t spending time looking at logs.\n\nThe biggest internal opportunity that I see today is figuring out how to\nget non-engineers an experience equivalent to running Claude Code locally with\nall their favorite MCP servers plugged in.\nI’ve wanted ChatGPT or Claude.ai to provide this, but they don’t really quite get there,\nClaude Desktop is close, but is somewhat messy to configure as we think about finding a tool\nthat we can easily allow everyone internally to customize and use on a daily basis.\n\nI’m still looking for what the right tool is here. If anyone has any great suggestions\nthat we can be somewhat confident will still exist in two years, and don’t require sending\na bunch of internal data to a very early stage company, then I’m curious to hear!\n\nYou’re supposed to start a good conclusion with some sort of punchy anecdote that\nilluminates your overall thesis in a new way. I’m not sure if I can quite meet that bar,\nbut the four most important ideas for me are:\n\nI’m curious what other folks are finding!",
    "readingTime": 13,
    "keywords": [
      "i’m curious",
      "notion database",
      "notion pages",
      "i’ve learned",
      "slack entities",
      "account provisioning",
      "strategy testing",
      "developing agents",
      "platform engineering",
      "claude code"
    ],
    "qualityScore": 1,
    "link": "https://lethain.com/company-ai-adoption/",
    "thumbnail_url": "https://lethain.com/static/author.png",
    "created_at": "2025-12-12T18:56:03.515Z",
    "topic": "tech"
  },
  {
    "slug": "ai-can-write-your-code-it-cant-do-your-job",
    "title": "AI Can Write Your Code. It Can't Do Your Job",
    "description": "The companies building AI are spending billions to acquire engineers, not replace them. Here’s why your job is safer than you think.",
    "fullText": "In May, OpenAI agreed to pay $3 billion for Windsurf, the AI coding assistant formerly known as Codeium. Three billion dollars. For a VSCode fork.\n\nThe deal eventually fell apart, but what matters is that they wanted to do it in the first place.\n\nLast week, Anthropic made an interesting acquisition: they bought Bun, the JavaScript runtime. Bun is open source and MIT-licensed. Anthropic could have forked it and built on top of it for free. They have Claude Code, an excellent code-writing tool.\n\nInstead, they bought the company. Because they wanted Jarred Sumner and his team.\n\nThis is what I keep coming back to when I see another “Programming is dead” post go viral. The companies building AI, the ones who supposedly know exactly what it can and can’t do, are spending billions to acquire engineering talent. Not fire them, acquire them.\n\nIf OpenAI believed GPT could replace software engineers, why wouldn’t they build their own VS Code fork for a fraction of that cost? If Anthropic thought Claude could do the work, why make an acquisition at all?\n\nHere’s my take: AI can replace most of programming, but programming isn’t the job.\n\nProgramming is a task. It’s one of many things you do as part of your work. But if you’re a software engineer, your actual job is more than typing code into an editor.\n\nThe mistake people make is conflating the task with the role. It’s like saying calculators replaced accountants. Calculators automated arithmetic, but arithmetic was never the job. The job was understanding financials, advising clients, making judgment calls, etc. The calculator just made accountants faster at the mechanical part.\n\nAI is doing something similar for us.\n\nThink about what you actually do in a given week.\n\nYou sit in a meeting where someone describes a vague problem, and you’re the one who figures out what they actually need. You look at a codebase and decide which parts to change and which to leave alone. You push back on a feature request because you know it’ll create technical debt that’ll haunt the team for years. You review a colleague’s PR and catch a subtle bug that would’ve broken production. You make a call on whether to ship now or wait for more testing.\n\nNone of that is programming, but it’s all your job.\n\nI’m not going to pretend nothing is changing.\n\nWill some companies use AI as an excuse to cut headcount? Absolutely. Some already have. There will be layoffs blamed on “AI efficiency gains” that are really just cost-cutting dressed up as something else.\n\nBut think about who stays and who goes in that scenario. It’s not random. The engineers who understand that programming isn’t the job, the ones who bring judgment, context, and the ability to figure out what to build, those are the ones who stay. The ones who only brought code output might be at risk\n\nA common worry is that juniors will get left behind. If AI handles the “doing” part, how do they build judgment? I actually think the opposite is true. AI compresses the feedback loop. What used to take days of flipping through books or waiting for Stack Overflow answers now takes seconds. The best juniors aren’t skipping steps, but getting through them faster.\n\nNow think about your own situation. Say you were hired two years ago, before the current AI wave. Your company wanted you. They saw value in what you bring. Now, with AI tools, you’re significantly more productive. You ship faster. You handle more complexity. You’re better at your job than ever before.\n\n“You got way more productive, so we’re letting you go” is not a sentence that makes a lot of sense.\n\nIf you’re reading this, you’re already thinking about this stuff. That puts you ahead. Here’s how to stay there:\n\nThe shape of the work is changing: some tasks that used to take hours now take minutes, some skills matter less, others more.\n\nBut different isn’t dead. The engineers who will thrive understand that their value was never in the typing, but in the thinking, in knowing which problems to solve, in making the right trade-offs, in shipping software that actually helps people.\n\nOpenAI and Anthropic could build their own tools. They have the best AI in the world. Instead, they’re spending billions on engineers. That should tell you something.",
    "readingTime": 4,
    "keywords": [
      "programming isn’t",
      "you’re",
      "ones",
      "engineers",
      "it’s",
      "software",
      "judgment",
      "faster",
      "fork",
      "acquisition"
    ],
    "qualityScore": 1,
    "link": "https://terriblesoftware.org/2025/12/11/ai-can-write-your-code-it-cant-do-your-job/",
    "thumbnail_url": "https://terriblesoftware.org/wp-content/uploads/2025/12/chjpdmf0zs9sci9pbwfnzxmvd2vic2l0zs8ymdiylta0l3vwd2s2mtc5nzyync13awtpbwvkawetaw1hz2uta293ctv0bheuanbn.webp",
    "created_at": "2025-12-12T18:56:02.981Z",
    "topic": "tech"
  },
  {
    "slug": "2-artificial-intelligence-stocks-that-could-help-make-you-a-fortune-in-2026",
    "title": "2 Artificial Intelligence Stocks That Could Help Make You a Fortune in 2026",
    "description": "Broadcom and UiPath both have huge opportunities in front of them.",
    "fullText": "Broadcom has a massive opportunity ahead with custom AI chips.\n\nUiPath has huge potential upside as its revenue starts to accelerate.\n\nThese 10 stocks could mint the next wave of millionaires ›\n\nAs 2025 begins to wind down, it will go down as another strong year for artificial intelligence (AI) stocks. Meanwhile, with AI still appearing to be in its early innings, the group could help lead the market higher in 2026 once again.\n\nLet's look at two AI stocks that could help you make a fortune in 2026.\n\nOne AI stock that looks like it could outperform in 2026 is Broadcom (NASDAQ: AVGO), as it has some of the best growth prospects of any AI infrastructure company.\n\nThe company is already seeing strong growth coming from its data center networking portfolio, which helps transfer data and distribute AI workloads across servers to help optimize performance. Products like its Tomahawk Ethernet switch and Jericho4 Ethernet fabric router are popular and helping power its networking growth.\n\nHowever, Broadcom's ASICs (application-specific integrated circuits) business is what should get investors excited the most. ASICs are custom chips that are pre-programmed to handle specific tasks, and because they are purpose-built, they tend to deliver improved performance with greater energy efficiency than general-purpose chips, such as graphics processing units (GPUs). Broadcom made a name for itself in this business when it helped Alphabet design its well-regarded tensor processing units (TPUs) that are helping Alphabet power much of its internal AI workloads, as well as those for external cloud computing customers.\n\nThat success has led to other hyperscalers (owners of large data centers) partnering with Broadcom to design their own custom chips. The company has called out its three custom AI chip customers furthest along as being an up to $90 billion opportunity in fiscal 2027, and then announced that a fourth customer has placed a $10 billion order for next year. It also recently struck a deal with OpenAI to supply it with 10 gigawatts of custom AI chips, in a deal worth hundreds of millions of dollars.\n\nWith these deals in place, Broadcom could see explosive growth in the coming years, which could propel its stock much higher in 2026 and beyond.\n\nAnother company whose stock could help you make a fortune next year is UiPath (NYSE: PATH). The company is in the midst of a transformation that could see it become one of the most important players in agentic AI.\n\nUiPath is a stalwart in the field of robotic process automation (RPA), which uses software bots to perform simple, rules-based tasks. However, it's using this background in managing software bots to become an orchestration platform that can manage both software bots and AI agents.",
    "readingTime": 3,
    "keywords": [
      "processing units",
      "software bots",
      "custom chips",
      "growth",
      "stocks",
      "stock",
      "opportunity",
      "another",
      "higher",
      "fortune"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/2-artificial-intelligence-stocks-could-090500087.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/ArCO_5RCQc_Aa8M.K4K4QA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/motleyfool.com/68ea2d44f90c910427485d4936367d7b",
    "created_at": "2025-12-12T18:56:00.581Z",
    "topic": "finance"
  },
  {
    "slug": "if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography",
    "title": "If Google wins AI race, Nvidia is 'in trouble,' says author of Jensen Huang biography",
    "description": "Jensen Huang biography author Stephen Witt explains why Google's self-developed AI model, Gemini, could pose a threat to Nvidia's AI dominance",
    "fullText": "Nvidia's (NVDA) AI turf could take a blow if Google (GOOGL, GOOG) keeps firing on all cylinders.\n\n\"The biggest risk right now obviously is Google,\" said Stephen Witt, author of \"The Thinking Machine,\" a Jensen Huang biography.\n\nThat risk, he told Yahoo Finance's Opening Bid, is largely tied to Google's Gemini model. Witt described it as the \"best AI right now in the benchmarks outside the Nvidia stack.\"\n\nWitt explained that Gemini was trained entirely on its Tensor Processing Units (TPUs). If Google proves it can sustain world-leading AI development using only its homegrown chip stack, it sets a potent precedent for other tech giants to follow suit.\n\n\"That's a huge risk,\" Witt said. \"If Google ends up winning this AI race ... Nvidia will be in trouble.\"\n\nThis risk, coupled with competition from rivals like Broadcom (AVGO) and Advanced Micro Devices (AMD), is why \"it's very easy to imagine a world\" where Nvidia's high-flying stock declines. The AI chipmaker's shares are up over 1,270% in the past five years.\n\nTo mitigate the core risk of rivals like Google winning the chip war, Nvidia CEO Jensen Huang is already looking past generative AI. Witt said a significant amount of the CEO's personal effort is being poured into the next great computing wave: robotics.\n\nIf Huang can dominate the robotics wave, he said, \"that will mean several trillion dollars in market capitalization for this company.\"\n\nHowever, Nvidia has another issue: the lack of any clear succession plan.\n\n\"It's just Jensen at the top,\" Witt said. \"There's no second in command. There's no obvious successor.\" He noted that the board has been silent, and Huang has offered no advice on a succession strategy.\n\nThat suggests Nvidia's $4 trillion valuation — which accounts for over 8% of the entire S&P 500 (^GSPC) — is, in many ways, resting solely on Huang's vision.\n\nWitt described Huang as a \"world-class engineer\" who could \"design these microchips himself,\" a skill that whoever takes the helm must also possess. He noted that neither of Huang's two children, who work at the company, has a technical background, making them noncontenders for the top spot.\n\nWitt also provided a look behind the polished stage persona of Huang, known for his trademark leather jacket. Beneath the showmanship is a highly intense, \"almost totally neurotic\" leader who is driven not by optimism, but by fear.\n\n\"He's driven by negative emotions, things like fear of failure, guilt, even shame are what make Jensen get up in the morning and work so hard to make Nvidia succeed,\" Witt explained.",
    "readingTime": 3,
    "keywords": [
      "jensen huang",
      "risk",
      "witt",
      "stack",
      "chip",
      "rivals",
      "it's",
      "wave",
      "robotics",
      "succession"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/if-google-wins-ai-race-nvidia-is-in-trouble-says-author-of-jensen-huang-biography-184624884.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/pgRIv4CaXitTJsbNTIjhsA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2025-12/60ef8cc0-d6b2-11f0-9a17-1d997177f998",
    "created_at": "2025-12-12T18:55:59.740Z",
    "topic": "finance"
  },
  {
    "slug": "doom-dev-id-software-forms-a-walltowall-union",
    "title": "Doom Dev id Software Forms A \"Wall-To-Wall\" Union",
    "description": "Developer id Software, a Texas-based studio known for the Doom games (including The Game Awards-winning The Dark Ages), has, has formed a union under the Communications Workers of America (CWA). It's a \"wall-to-wall\" guild built to protect employees from AI while negotiating for ample benefits, such as remote work, and Microsoft appears to have recognized the studio's union.\nIn a press release on the CWA's website, id Software's 165-person union will join the CWA Local 6215 division in Richardson, Texas. Producer Andrew Willis noted how important it is for workers to fight back against the injustices facing the games industry at the moment.\n\"The wall-to-wall organizing effort at id Software was much needed; it's incredibly important that developers across the industry unite to push back on all the unilateral workplace changes that are being handed down from industry executives,\" Willis said.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/doom-dev-id-software-forms-a-wall-to-wall-union/1100-6536938/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1578/15789366/4621767-dtdaimage.jpg",
    "created_at": "2025-12-12T18:55:57.349Z",
    "topic": "tech"
  },
  {
    "slug": "godmother-of-ai-says-degrees-are-less-important-in-hiring-than-how-quickly-can-you-superpower-yourself-with-new-tools",
    "title": "‘Godmother of AI’ says degrees are less important in hiring than ‘how quickly can you superpower yourself’ with new tools",
    "description": "Instead, she looks to hire software engineers with AI fluency to her startup that aims to revolutionize the tech.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/12/fei-fei-li-stanford-professor-godmother-ai-college-degrees-skills-talent-ceo/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247144876-e1765553881661.jpg?resize=1200,600",
    "created_at": "2025-12-12T18:55:54.101Z",
    "topic": "business"
  },
  {
    "slug": "broadcom-is-the-latest-victim-of-skyhigh-expectations-from-ai-investors",
    "title": "Broadcom is the latest victim of sky-high expectations from AI investors",
    "description": "Broadcom shares tumbled on Friday as investors balked at some disappointing aspects of the company's outlook heading into 2026.",
    "fullText": "Broadcom is the latest victim of investors punishing high-flying AI companies.\n\nThe chipmaker tumbled 8% as investors took in its stellar results for the last quarter, but were left disappointed by certain aspects of the company's outlook.\n\nThe firm beat on earnings and revenue, leading shares to initially rise after-hours on Thursday, before falling into the red as CEO Hock Tan dug into the results in the call with analysts.\n\n\"It was surprising to see a call that started with such good numbers and such a great story end with frustration,\" Josh Meyers, an executive director at JPMorgan, wrote in a client note on Friday.\n\nHere's where major indexes stood shortly after the 9:30 a.m. ET opening bell on Friday:\n\nOther chip stocks also lost slightly, extending a decline in the sector that kicked off after Oracle reported earnings earlier in the week. Here were some of the notable moves:\n\nBroadcom investors seemed disappointed in how the company didn't issue full AI revenue guidance for the coming year, Deutsche Bank and JPMorgan wrote on Friday. Broadcom said it expected AI semiconductor revenue to double to $8.2 billion in the following quarter.\n\nInvestors also seemed \"underwhelmed\" by the firm's $73 billion backlog of AI product orders over the next 18 months, Paul Hickey, the co-founder of Bespoke Investment Group, said in a note.\n\n\"Somehow some investors seized on this as 'not enough,' which compounded an earlier narrative today that somehow we needed more visibility on F27 AI revenue (no idea why this is suddenly an issue),\" JPMorgan's Meyers wrote.\n\nSome investors also feel that the Tan was more \"buttoned-up\" about the company's results than they would have liked, Meyers said, citing his conversations with shareholders.\n\nThe stock is a crowded trade in the already popular AI theme, and some may also think the market \"just needed to take a breath\" from the AI trade, Meyers said. Shares of Broadcom are still up more than 56% this year.\n\nInvestors have put more pressure on the semiconductor sector in recent months amid concerns about the sustainability of the AI trade, which has led to some firms getting punished despite beating on earnings and revenue.\n\nOracle shares plunged 14% on Thursday as investors took in lower-than-expected quarterly revenue and worries that the software giant is overspending on AI.\n\nMeta and Microsoft shares also dropped after the companies reported earnings in October, as both tech titans promised to spend more on AI in the coming years.",
    "readingTime": 3,
    "keywords": [
      "investors",
      "revenue",
      "earnings",
      "trade",
      "quarter",
      "disappointed",
      "company's",
      "note",
      "sector",
      "oracle"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/broadcom-stock-price-avgo-q4-earnings-ai-chips-revenue-outlook-2025-12",
    "thumbnail_url": "https://i.insider.com/693c294064858d02d216b42a?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.125Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-making-the-chros-job-a-whole-lot-bigger",
    "title": "How AI is making the CHRO's job a whole lot bigger",
    "description": "AI is reshaping the CHRO role, requiring HR leaders to become AI strategists and bridge people, technology, and data in today's workforce.",
    "fullText": "AI is changing how companies hire, train, and lead, and in the process, the chief human resources officer's role is expanding.\n\nToday's top HR leaders are becoming AI strategists, helping their organizations navigate the next wave of workplace transformation.\n\n\"The old model of HR was employees over here, technology over there,\" says Thomas Hutzschenreuter, a university professor at the Technical University of Munich (TUM). \"But the new model of work is human-AI collaboration.\"\n\nAI is a coworker now, he says, and that means that \"HR has a bigger mandate. They need to understand not just people and culture, but go deeper into the strategy, the business, and the technology itself.\"\n\nTo understand how companies are navigating the shift, Business Insider spoke with people leaders at Citizens Bank, one of the largest banks in the Northeast; Boston Consulting Group, a global consultancy; and UiPath, an automation software testing company.\n\nAll interviews have been edited for brevity.\n\nCHROs are becoming the architects of the future of work, bridging people, technology, and data.\n\nThere are many questions we are in the middle of that are germane to how we as an organization move forward, such as: What's going to happen to entry-level roles? What roles are emerging? And how do we reskill people in a way that prepares them to make shifts thoughtfully?\n\nWe need people who can quickly learn, adapt, and change. Our technologists need to develop their business acumen, and our business folks need to develop their digital and technical fluency. The lines are blurring.\n\nMy HR team is developing a baseline of skills and capabilities. We're having conversations with consulting partners and clients. There's an openness to communal learning because everyone is trying to figure out the same things: what the AI-driven workforce will look like, how to break work into tasks for AI vs. humans, and what AI agents can handle versus humans.\n\nWe're subject to a lot of regulatory oversight in our industry. It's great that people can develop their own AI agents — there's a push to decentralize these capabilities — but we need to be mindful of risk and governance and how we do this in a safe, ethical way.\n\nAI is changing how work gets done and what work gets done. Business models are evolving, and the way companies serve clients is shifting. The CHRO role now requires adapting to both at once. It's a tall order.\n\nIn consulting, our ability to add value means constantly evolving our approach to human capital. The issues are constant; the pace is what's different. Today, a quarter of our business involves AI, which wasn't true even two years ago.\n\nWe need our people to be AI fluent. About 90% of our workforce uses AI regularly, and more than half use it daily. To get there, we've built a multi-layered support system: a 1,400-person enablement network acting as evangelists and coaches.\n\nWe've upskilled more than 100 team coaches to provide hands-on support. We deploy experts directly into teams to help them reimagine workflows and run innovation competitions to keep momentum going.\n\nOur HR team has taken the lead. We started with recruiting — consolidating six IT systems into one and integrating AI throughout the platform and across performance management and development.\n\nWe're also experimenting with voice tools, chat interfaces, and AI avatars for real-time coaching. These tools give employees confidence, learning opportunities, and instant feedback. They don't replace managers — they free them up for higher-level thinking and relationship-building.\n\nOur business is automation, so that muscle is very strong for my team. But the next frontier of agentic AI is an adjustment.\n\nWe're using these AI agents — but we're also creating them. One agent, almost in production, helps with performance reviews, which is a time-consuming and sometimes dreaded task. Our agent helps employees write their self-assessment and collects feedback, bringing it together much quicker. It also helps managers by consolidating feedback from multiple resources.\n\nIt won't make rating decisions on the manager's behalf, but it makes the year-end much more seamless. Instead of spending time on admin, managers can focus on the feedback itself and my team on the right framework for career development.\n\nThere are a lot of unknowns at the moment, and fear is natural. But it should fuel curiosity and development. This is the time to think about career development seriously.\n\nWe have this idea that AI is only affecting entry-level or lower-level jobs. The truth is that technology is replacing skills that very highly skilled people have been doing.\n\nIf you look at the medical field and aviation — areas where we always thought technology wouldn't touch — that's no longer the case. It's not going to happen overnight. We have time to prepare. But it's relevant for everybody in any profession.",
    "readingTime": 4,
    "keywords": [
      "career development",
      "technology",
      "team",
      "we're",
      "feedback",
      "employees",
      "agents",
      "managers",
      "business",
      "changing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-transforms-chro-roles-bridge-people-tech-business-strategy-2025-12",
    "thumbnail_url": "https://i.insider.com/6939c47a71107c9f3457b614?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:53.066Z",
    "topic": "finance"
  },
  {
    "slug": "companies-are-finally-paying-for-ai-and-paying-big",
    "title": "Companies are finally paying for AI, and paying big",
    "description": "AI enterprise spending is about to surge as CIOs allocate new budgets for generative AI projects in 2026, surveys finds.",
    "fullText": "For much of the past year, Wall Street and Silicon Valley have wrestled with the same uncomfortable question: Will companies really spend money on AI, or is the hype just outpacing budgets?\n\nA new CIO survey from RBC Capital suggests that question may finally have an answer, and it's a resounding yes.\n\nRBC recently polled 117 IT professionals at companies with annual revenue ranging from below $250 million to more than $25 billion. 90% of the respondents said their organizations plan to spend more on AI in 2026.\n\n\"Overall, we came away increasingly optimistic of macro/budget stabilization taking shape in 2026 and encouraged by the pace of early GenAI adoption,\" the RBC analysts wrote in a research note summarizing the findings.\n\nCIOs are not only moving rapidly into production with AI systems, but they are also setting aside dedicated budgets to fund that adoption.\n\nA striking 90% of technology leaders said their organizations are creating new budgets specifically for generative AI and LLM projects, up from 85% the year before. That suggests AI is becoming additive rather than substitutive in enterprise tech spending.\n\nEven more telling: 60% of respondents said they are already in production with AI initiatives, a jump from 39% the previous year. Another 32% expect to be in production within six months.\n\nThis shift comes after months of skepticism from investors who questioned whether businesses would convert pilot projects into real spending. The survey data suggests that moment is now arriving.\n\nCIOs overwhelmingly cited AI as the top category for increased software spending next year, surpassing cybersecurity and IT service management. And in open-ended responses, executives repeatedly named AI as their biggest area of investment for 2026, often paired with infrastructure upgrades and automation initiatives, according to the RBC survey.\n\nUse cases are expanding beyond experimentation. Seventy-six percent of CIOs said their AI strategies now target both cost savings and revenue generation, a shift that reinforces AI's transition from a novelty to a competitive mandate.\n\nConcerns remain — data privacy tops the list — but those worries are no longer slowing adoption. Instead, AI is becoming the primary force expanding IT budgets heading into 2026.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 2,
    "keywords": [
      "budgets",
      "survey",
      "adoption",
      "cios",
      "production",
      "revenue",
      "respondents",
      "organizations",
      "projects",
      "initiatives"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/companies-finally-paying-ai-cio-survey-2025-12",
    "thumbnail_url": "https://i.insider.com/693b59c204eda4732f2d6898?width=1200&format=jpeg",
    "created_at": "2025-12-12T18:55:52.598Z",
    "topic": "finance"
  },
  {
    "slug": "openais-merch-store-offers-a-glimpse-inside-the-companys-vibe",
    "title": "OpenAI's merch store offers a glimpse inside the company's vibe",
    "description": "The \"OpenAI Supply Co.\" has 10 merch items available for purchase, and dozens of more archived designs. Most sizes have sold out.",
    "fullText": "You can now wear ChatGPT on your sleeve — or head or shin.\n\nAs part of its 10-year anniversary celebration, OpenAI dropped a link on its X feed to a merchandise store. The \"OpenAI Supply Co.\" seems suited for the company's engineers, with a space to log in with a company email. Indeed, most of the items listed are archives of old designs — but a few are available for purchase.\n\nThe \"Supply Co.\" site was marked as \"coming soon\" in July 2024, according to the Internet Archive. But this appears to be the first time ChatGPT users who aren't employees can actually buy something from it.\n\nOpenAI fans ate it up. The post garnered over 3,000 likes within 15 hours, and multiple sizes of the for-sale items were quickly sold out. If you're anything other than an extra small or a small, you're out of luck on sweatshirts and tees.\n\nThe items OpenAI listed give a glimpse inside the company — or at least its swag.\n\nThere are five Pokémon-style trading cards. Their subjects include Sora 2 (\"shape-shifter\"), GPT-5 (\"two worlds, one model\"), image generation (with a \"huge\" wow factor), Sora (\"sci-fi\"), and the OpenAI Blossom (\"back and better\").\n\nPokémon has recently been a point of contention for the company, after its Sora video generator began booting out unauthorized versions of Pikachu.\n\nMuch of the site is themed around AGI, or artificial general intelligence, a much debated breakthrough milestone that many AI companies are racing to hit. One shirt reads: \"AGI that benefits all of humanity,\" a line from OpenAI's charter. On the employee log-in, the suggested email is agi@openai.com.\n\nThe assortment of hats also offers clues. There are Sora beanies and baseball caps with the word \"research.\" One cap has the chatbot's phone number, 1-800-CHATGPT. (Yes, the number still works.)\n\nAnother cap has OpenAI in red letters on camo print, resembling the popular Harris/Walz hat, which nods to Chappell Roan.\n\nThe baseball caps kept coming. There's one with silver flames, a piece of early 2000s nostalgia. There's another with the letters \"SF\" on it, firmly planting OpenAI in the city of San Francisco.\n\nAll the way at the bottom of the page is a baseball cap with the words \"Thinking deeply.\" The site says that it was released in September 2024 in honor of OpenAI's reasoning model. It also looks remarkably similar to Anthropic's \"thinking\" caps, which launched a year later at the company's Air Mail pop-up.\n\nAnthropic's \"thinking\" caps quickly became a status symbol, signifying the wearer's closeness to the AI boom. Cursor's tab keys had a similar effect, as did OpenAI's DevDay token plaques.\n\nIt's possible that this merchandise drop will have the same effect. Your ChatGPT crew neck could give you caché.\n\nThe fans have clearly been hungry. Fan-created merchandise concepts have long floated around X. Some even turned their designs into unauthorized businesses.\n\nThirty minutes before its post about the tenth anniversary, OpenAI responded to a fan post. Developer Tibor Blaho posted some of the merch, saying that the company should make its store \"public instead of keeping it employee-only.\" OpenAI responded with the link and an eye emoji.\n\nBlaho's post was 10 months ago.",
    "readingTime": 3,
    "keywords": [
      "openai responded",
      "baseball caps",
      "sora",
      "merchandise",
      "items",
      "site",
      "anniversary",
      "link",
      "store",
      "company's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-merch-supply-co-2025-12",
    "thumbnail_url": "https://i.insider.com/693c27cb64858d02d216b405?width=1113&format=jpeg",
    "created_at": "2025-12-12T18:55:52.542Z",
    "topic": "finance"
  },
  {
    "slug": "new-research-on-ai-and-fairness-in-hiring",
    "title": "New Research on AI and Fairness in Hiring",
    "description": "AI promises to make hiring fairer by reducing human bias, yet it often reshapes what fairness means—and locks in one definition. A three-year study of a global consumer-goods firm found that their algorithmic system privileged a rigid definition that sidelined manager’s local judgment. This resulted in narrow candidate pools and unhappy hiring managers. The study underlined that fairness isn’t embedded in code, it’s negotiated by people who design and deploy it. To make AI hiring systems work better for more people, leaders must ask: Which versions of fairness exist?",
    "fullText": "New Research on AI and Fairness in Hiring by Elmira van den Broek, Anastasia Sergeeva and Marleen HuysmanDecember 12, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintWill AI improve or degrade fairness? With nearly 90% of companies now using some form of AI in hiring, this question is top of mind for many leaders, and it tends to split them into two camps. One side believes algorithms will make hiring fairer by reducing human “bias” and “noise” in decision-making. The other warns that algorithms can reproduce and even amplify existing inequalities at scale. Both overlook a crucial reality: When AI is adopted, it reshapes what counts as fair in the first place.",
    "readingTime": 1,
    "keywords": [
      "hiring",
      "algorithms",
      "fairness"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/new-research-on-ai-and-fairness-in-hiring",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_13_200560131-001.jpg",
    "created_at": "2025-12-12T18:55:51.703Z",
    "topic": "science"
  },
  {
    "slug": "trumps-ai-order-faces-political-and-legal-hurdles",
    "title": "Trump's AI order faces political and legal hurdles",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/politics-news/trumps-ai-order-faces-political-and-legal-hurdles-4406498",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPELBB11W_L.jpg",
    "created_at": "2025-12-12T18:55:51.568Z",
    "topic": "finance"
  },
  {
    "slug": "the-best-big-media-merger-is-no-merger-at-all",
    "title": "The Best Big Media Merger Is No Merger at All",
    "description": "The state of streaming is... bad. It’s very bad. The first step in wanting to watch anything is a web search: “Where can I stream X?” Then you have to scroll past an AI summary with no answers, and then scroll past the sponsored links.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.eff.org/deeplinks/2025/12/best-big-media-merger-no-merger-all",
    "thumbnail_url": "https://www.eff.org/files/banner_library/icon-2019-innovation.png",
    "created_at": "2025-12-12T13:47:26.391Z",
    "topic": "tech"
  },
  {
    "slug": "disney-wants-you-to-aigenerate-yourself-into-your-favorite-marvel-movie",
    "title": "Disney wants you to AI-generate yourself into your favorite Marvel movie",
    "description": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n Continue reading...",
    "fullText": "The media company is investing $1bn in OpenAI – and allowing its characters to be used in generated videos\n\nUsers of OpenAI’s video generation app will soon be able to see their own faces alongside characters from Marvel, Pixar, Star Wars and Disney’s animated films, according to a joint announcement from the startup and Disney on Thursday. Perhaps you, Lightning McQueen and Iron Man are all dancing together in the Mos Eisley Cantina.\n\nSora is an app made by OpenAI, the firm behind ChatGPT, which allows users to generate videos of up to 20 seconds through short text prompts. The startup previously attempted to steer Sora’s output away from unlicensed copyrighted material, though with little success, which prompted threats of lawsuits by rights holders.\n\nDisney announced that it would invest $1bn in OpenAI and, under a three-year deal perhaps worth even more than that large sum, that it would license about 200 of its iconic characters – from R2-D2 to Stitch – for users to play with in OpenAI’s video generation app.\n\nAt a time of intense anxiety in Hollywood over the impact of AI on the livelihoods of writers, actors, visual effects artists and other creatives, Disney stressed its agreement with OpenAI would not cover talent likenesses or voices.\n\nThe announcement was framed as an extraordinary opportunity to empower fans.\n\nThink of the “fan-inspired Sora short form videos”, as Disney called them in a press release – akin to taking an AI-generated version of a photo with Princess Jasmine at Disney World. OpenAI included screenshots of these kinds of videos in its press release, indicating how the two companies expect people to use the app’s new cast. Sora already allows users to generate videos that include their own likenesses.\n\nBob Iger, Disney’s CEO, said the licensing deal would place “imagination and creativity directly into the hands of Disney fans in ways we’ve never seen before”.\n\nThey may even offer a chance at wide viewership, with some fan-made videos being displayed on the Disney+ streaming service, a move seemingly designed to compete with TikTok’s and YouTube Shorts’ infinite feeds, which themselves often include clips of popular TV shows and movies.",
    "readingTime": 2,
    "keywords": [
      "press release",
      "generation app",
      "allows users",
      "generate videos",
      "characters",
      "disney",
      "announcement",
      "startup",
      "deal",
      "likenesses"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2025/dec/11/disney-openai-sora",
    "thumbnail_url": "https://i.guim.co.uk/img/media/d99390e95d50b47f91bcc8a3130e524c618e635d/436_0_4324_3458/master/4324.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=67d482fa7d7bed846eb736aeb1dfde1c",
    "created_at": "2025-12-12T13:47:25.564Z",
    "topic": "tech"
  },
  {
    "slug": "elon-musk-teams-with-el-salvador-to-bring-grok-chatbot-to-public-schools",
    "title": "Elon Musk teams with El Salvador to bring Grok chatbot to public schools",
    "description": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n Continue reading...",
    "fullText": "President Nayib Bukele entrusting chatbot known for calling itself ‘MechaHitler’ to create ‘AI-powered’ curricula\n\nElon Musk is partnering with the government of El Salvador to bring his artificial intelligence company’s chatbot, Grok, to more than 1 million students across the country, according to a Thursday announcement by xAI. Over the next two years, the plan is to “deploy” the chatbot to more than 5,000 public schools in an “AI-powered education program”.\n\nxAI’s Grok is more known for referring to itself as “MechaHitler” and espousing far-right conspiracy theories than it is for public education. Over the past year, the chatbot has spewed various antisemitic content, decried “white genocide” and claimed Donald Trump won the 2020 election.\n\nNayib Bukele, El Salvador’s president, is now entrusting the chatbot to create curricula in classrooms across the country. Bukele has long embraced technology, making El Salvador the first county in the world to use bitcoin as legal tender, and being one of the first Central American presidents to use Twitter, now X, as a platform. He is also known for ruling with an iron fist and working with Trump to incarcerate deportees to El Salvador’s notorious Cecot prison.\n\n“El Salvador doesn’t just wait for the future to happen; we build it,” Bukele said in a statement about the partnership with xAI. “This partnership is destined to deliver something rather extraordinary for all of humanity.”\n\nMusk touted his partnership with Bukele on Thursday. On X, between posts about “white genocide” and blaming asylum seekers for crime, Musk posted comments about Grok being spread throughout El Salvador’s schools.\n\nHe reposted positively to a comment from Katie Miller, the wife of Trump’s senior adviser Stephen Miller, in which she wrote: “If we are serious about restoring education to math, science and English – why would we allow left leaning liberal [sic] AI our kids? This unlocks non-woke educational tools for our kids.”\n\nxAI is not the first artificial intelligence company to introduce chatbots to public schools. OpenAI announced a partnership with Estonia in February where it could provide all students and teachers in the country’s secondary school system with a customized ChatGPT. Students in rural Colombia also started using Meta’s AI chatbots in 2023 and within a year, teachers began blaming the tech for low grades and failing exams, according to Rest of World.\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‘Secure Messaging’.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 3,
    "keywords": [
      "nayib bukele",
      "guardian app",
      "artificial intelligence",
      "white genocide",
      "el salvador",
      "el salvador’s",
      "chatbot",
      "partnership",
      "grok",
      "schools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2025/dec/11/elon-musk-el-salvador-grok",
    "thumbnail_url": "https://i.guim.co.uk/img/media/7110440275e2c1e8231708520c23cbc728846c00/401_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=585578e2aeb3d5963fc6677b1ca099f4",
    "created_at": "2025-12-12T13:47:25.075Z",
    "topic": "tech"
  }
]